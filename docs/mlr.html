<!DOCTYPE html><html><head><title>Help for package mlr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#addRRMeasure'><p>Compute new measures for existing ResampleResult</p></a></li>
<li><a href='#Aggregation'><p>Aggregation object.</p></a></li>
<li><a href='#aggregations'><p>Aggregation methods.</p></a></li>
<li><a href='#agri.task'><p>European Union Agricultural Workforces clustering task.</p></a></li>
<li><a href='#analyzeFeatSelResult'><p>Show and visualize the steps of feature selection.</p></a></li>
<li><a href='#asROCRPrediction'><p>Converts predictions to a format package ROCR can handle.</p></a></li>
<li><a href='#batchmark'><p>Run machine learning benchmarks as distributed experiments.</p></a></li>
<li><a href='#bc.task'><p>Wisconsin Breast Cancer classification task.</p></a></li>
<li><a href='#benchmark'><p>Benchmark experiment for multiple learners and tasks.</p></a></li>
<li><a href='#BenchmarkResult'><p>BenchmarkResult object.</p></a></li>
<li><a href='#bh.task'><p>Boston Housing regression task.</p></a></li>
<li><a href='#cache_helpers'><p>Get or delete mlr cache directory</p></a></li>
<li><a href='#calculateConfusionMatrix'><p>Confusion matrix.</p></a></li>
<li><a href='#calculateROCMeasures'><p>Calculate receiver operator measures.</p></a></li>
<li><a href='#capLargeValues'><p>Convert large/infinite numeric values in a data.frame or task.</p></a></li>
<li><a href='#changeData'><p>Change Task Data</p></a></li>
<li><a href='#checkLearner'><p>Exported for internal use only.</p></a></li>
<li><a href='#checkPredictLearnerOutput'><p>Check output returned by predictLearner.</p></a></li>
<li><a href='#configureMlr'><p>Configures the behavior of the package.</p></a></li>
<li><a href='#ConfusionMatrix'><p>Confusion matrix</p></a></li>
<li><a href='#convertBMRToRankMatrix'><p>Convert BenchmarkResult to a rank-matrix.</p></a></li>
<li><a href='#convertMLBenchObjToTask'><p>Convert a machine learning benchmark / demo object from package mlbench to a task.</p></a></li>
<li><a href='#costiris.task'><p>Iris cost-sensitive classification task.</p></a></li>
<li><a href='#createDummyFeatures'><p>Generate dummy variables for factor features.</p></a></li>
<li><a href='#createSpatialResamplingPlots'><p>Create (spatial) resampling plot objects.</p></a></li>
<li><a href='#crossover'><p>Crossover.</p></a></li>
<li><a href='#downsample'><p>Downsample (subsample) a task or a data.frame.</p></a></li>
<li><a href='#dropFeatures'><p>Drop some features of task.</p></a></li>
<li><a href='#estimateRelativeOverfitting'><p>Estimate relative overfitting.</p></a></li>
<li><a href='#estimateResidualVariance'><p>Estimate the residual variance.</p></a></li>
<li><a href='#extractFDABsignal'><p>Bspline mlq features</p></a></li>
<li><a href='#extractFDADTWKernel'><p>DTW kernel features</p></a></li>
<li><a href='#extractFDAFeatures'><p>Extract features from functional data.</p></a></li>
<li><a href='#extractFDAFourier'><p>Fast Fourier transform features.</p></a></li>
<li><a href='#extractFDAFPCA'><p>Extract functional principal component analysis features.</p></a></li>
<li><a href='#extractFDAMultiResFeatures'><p>Multiresolution feature extraction.</p></a></li>
<li><a href='#extractFDATsfeatures'><p>Time-Series Feature Heuristics</p></a></li>
<li><a href='#extractFDAWavelets'><p>Discrete Wavelet transform features.</p></a></li>
<li><a href='#FailureModel'><p>Failure model.</p></a></li>
<li><a href='#FeatSelControl'><p>Create control structures for feature selection.</p></a></li>
<li><a href='#FeatSelResult'><p>Result of feature selection.</p></a></li>
<li><a href='#filterFeatures'><p>Filter features by thresholding filter values.</p></a></li>
<li><a href='#friedmanPostHocTestBMR'><p>Perform a posthoc Friedman-Nemenyi test.</p></a></li>
<li><a href='#friedmanTestBMR'><p>Perform overall Friedman test for a BenchmarkResult.</p></a></li>
<li><a href='#fuelsubset.task'><p>FuelSubset functional data regression task.</p></a></li>
<li><a href='#generateCalibrationData'><p>Generate classifier calibration data.</p></a></li>
<li><a href='#generateCritDifferencesData'><p>Generate data for critical-differences plot.</p></a></li>
<li><a href='#generateFeatureImportanceData'><p>Generate feature importance.</p></a></li>
<li><a href='#generateFilterValuesData'><p>Calculates feature filter values.</p></a></li>
<li><a href='#generateHyperParsEffectData'><p>Generate hyperparameter effect data.</p></a></li>
<li><a href='#generateLearningCurveData'><p>Generates a learning curve.</p></a></li>
<li><a href='#generatePartialDependenceData'><p>Generate partial dependence.</p></a></li>
<li><a href='#generateThreshVsPerfData'><p>Generate threshold vs. performance(s) for 2-class classification.</p></a></li>
<li><a href='#getBMRAggrPerformances'><p>Extract the aggregated performance values from a benchmark result.</p></a></li>
<li><a href='#getBMRFeatSelResults'><p>Extract the feature selection results from a benchmark result.</p></a></li>
<li><a href='#getBMRFilteredFeatures'><p>Extract the feature selection results from a benchmark result.</p></a></li>
<li><a href='#getBMRLearnerIds'><p>Return learner ids used in benchmark.</p></a></li>
<li><a href='#getBMRLearners'><p>Return learners used in benchmark.</p></a></li>
<li><a href='#getBMRLearnerShortNames'><p>Return learner short.names used in benchmark.</p></a></li>
<li><a href='#getBMRMeasureIds'><p>Return measures IDs used in benchmark.</p></a></li>
<li><a href='#getBMRMeasures'><p>Return measures used in benchmark.</p></a></li>
<li><a href='#getBMRModels'><p>Extract all models from benchmark result.</p></a></li>
<li><a href='#getBMRPerformances'><p>Extract the test performance values from a benchmark result.</p></a></li>
<li><a href='#getBMRPredictions'><p>Extract the predictions from a benchmark result.</p></a></li>
<li><a href='#getBMRTaskDescriptions'><p>Extract all task descriptions from benchmark result (DEPRECATED).</p></a></li>
<li><a href='#getBMRTaskDescs'><p>Extract all task descriptions from benchmark result.</p></a></li>
<li><a href='#getBMRTaskIds'><p>Return task ids used in benchmark.</p></a></li>
<li><a href='#getBMRTuneResults'><p>Extract the tuning results from a benchmark result.</p></a></li>
<li><a href='#getCaretParamSet'><p>Get tuning parameters from a learner of the caret R-package.</p></a></li>
<li><a href='#getClassWeightParam'><p>Get the class weight parameter of a learner.</p></a></li>
<li><a href='#getConfMatrix'><p>Confusion matrix.</p></a></li>
<li><a href='#getDefaultMeasure'><p>Get default measure.</p></a></li>
<li><a href='#getFailureModelDump'><p>Return the error dump of FailureModel.</p></a></li>
<li><a href='#getFailureModelMsg'><p>Return error message of FailureModel.</p></a></li>
<li><a href='#getFeatSelResult'><p>Returns the selected feature set and optimization path after training.</p></a></li>
<li><a href='#getFeatureImportance'><p>Calculates feature importance values for trained models.</p></a></li>
<li><a href='#getFeatureImportanceLearner'><p>Calculates feature importance values for a given learner.</p></a></li>
<li><a href='#getFilteredFeatures'><p>Returns the filtered features.</p></a></li>
<li><a href='#getFunctionalFeatures'><p>Get only functional features from a task or a data.frame.</p></a></li>
<li><a href='#getHomogeneousEnsembleModels'><p>Deprecated, use <code>getLearnerModel</code> instead.</p></a></li>
<li><a href='#getHyperPars'><p>Get current parameter settings for a learner.</p></a></li>
<li><a href='#getLearnerId'><p>Get the ID of the learner.</p></a></li>
<li><a href='#getLearnerModel'><p>Get underlying R model of learner integrated into mlr.</p></a></li>
<li><a href='#getLearnerNote'><p>Get the note for the learner.</p></a></li>
<li><a href='#getLearnerPackages'><p>Get the required R packages of the learner.</p></a></li>
<li><a href='#getLearnerParamSet'><p>Get the parameter set of the learner.</p></a></li>
<li><a href='#getLearnerParVals'><p>Get the parameter values of the learner.</p></a></li>
<li><a href='#getLearnerPredictType'><p>Get the predict type of the learner.</p></a></li>
<li><a href='#getLearnerShortName'><p>Get the short name of the learner.</p></a></li>
<li><a href='#getLearnerType'><p>Get the type of the learner.</p></a></li>
<li><a href='#getMlrOptions'><p>Returns a list of mlr's options.</p></a></li>
<li><a href='#getMultilabelBinaryPerformances'><p>Retrieve binary classification measures for multilabel classification predictions.</p></a></li>
<li><a href='#getNestedTuneResultsOptPathDf'><p>Get the <code>opt.path</code>s from each tuning step from the outer resampling.</p></a></li>
<li><a href='#getNestedTuneResultsX'><p>Get the tuned hyperparameter settings from a nested tuning.</p></a></li>
<li><a href='#getOOBPreds'><p>Extracts out-of-bag predictions from trained models.</p></a></li>
<li><a href='#getOOBPredsLearner'><p>Provides out-of-bag predictions for a given model and the corresponding learner.</p></a></li>
<li><a href='#getParamSet'><p>Get a description of all possible parameter settings for a learner.</p></a></li>
<li><a href='#getPredictionDump'><p>Return the error dump of a failed Prediction.</p></a></li>
<li><a href='#getPredictionProbabilities'><p>Get probabilities for some classes.</p></a></li>
<li><a href='#getPredictionResponse'><p>Get response / truth from prediction object.</p></a></li>
<li><a href='#getPredictionTaskDesc'><p>Get summarizing task description from prediction.</p></a></li>
<li><a href='#getProbabilities'><p>Deprecated, use <code>getPredictionProbabilities</code> instead.</p></a></li>
<li><a href='#getResamplingIndices'><p>Get the resampling indices from a tuning or feature selection wrapper..</p></a></li>
<li><a href='#getRRDump'><p>Return the error dump of ResampleResult.</p></a></li>
<li><a href='#getRRPredictionList'><p>Get list of predictions for train and test set of each single resample iteration.</p></a></li>
<li><a href='#getRRPredictions'><p>Get predictions from resample results.</p></a></li>
<li><a href='#getRRTaskDesc'><p>Get task description from resample results (DEPRECATED).</p></a></li>
<li><a href='#getRRTaskDescription'><p>Get task description from resample results (DEPRECATED).</p></a></li>
<li><a href='#getStackedBaseLearnerPredictions'><p>Returns the predictions for each base learner.</p></a></li>
<li><a href='#getTaskClassLevels'><p>Get the class levels for classification and multilabel tasks.</p></a></li>
<li><a href='#getTaskCosts'><p>Extract costs in task.</p></a></li>
<li><a href='#getTaskData'><p>Extract data in task.</p></a></li>
<li><a href='#getTaskDesc'><p>Get a summarizing task description.</p></a></li>
<li><a href='#getTaskDescription'><p>Deprecated, use getTaskDesc instead.</p></a></li>
<li><a href='#getTaskFeatureNames'><p>Get feature names of task.</p></a></li>
<li><a href='#getTaskFormula'><p>Get formula of a task.</p></a></li>
<li><a href='#getTaskId'><p>Get the id of the task.</p></a></li>
<li><a href='#getTaskNFeats'><p>Get number of features in task.</p></a></li>
<li><a href='#getTaskSize'><p>Get number of observations in task.</p></a></li>
<li><a href='#getTaskTargetNames'><p>Get the name(s) of the target column(s).</p></a></li>
<li><a href='#getTaskTargets'><p>Get target data of task.</p></a></li>
<li><a href='#getTaskType'><p>Get the type of the task.</p></a></li>
<li><a href='#getTuneResult'><p>Returns the optimal hyperparameters and optimization path after training.</p></a></li>
<li><a href='#getTuneResultOptPath'><p>Get the optimization path of a tuning result.</p></a></li>
<li><a href='#gunpoint.task'><p>Gunpoint functional data classification task.</p></a></li>
<li><a href='#hasFunctionalFeatures'><p>Check whether the object contains functional features.</p></a></li>
<li><a href='#hasProperties'><p>Deprecated, use <code>hasLearnerProperties</code> instead.</p></a></li>
<li><a href='#helpLearner'><p>Access help page of learner functions.</p></a></li>
<li><a href='#helpLearnerParam'><p>Get specific help for a learner's parameters.</p></a></li>
<li><a href='#imputations'><p>Built-in imputation methods.</p></a></li>
<li><a href='#impute'><p>Impute and re-impute data</p></a></li>
<li><a href='#iris.task'><p>Iris classification task.</p></a></li>
<li><a href='#isFailureModel'><p>Is the model a FailureModel?</p></a></li>
<li><a href='#joinClassLevels'><p>Join some class existing levels to new, larger class levels for classification problems.</p></a></li>
<li><a href='#learnerArgsToControl'><p>Convert arguments to control structure.</p></a></li>
<li><a href='#LearnerProperties'><p>Query properties of learners.</p></a></li>
<li><a href='#learners'><p>List of supported learning algorithms.</p></a></li>
<li><a href='#listFilterEnsembleMethods'><p>List ensemble filter methods.</p></a></li>
<li><a href='#listFilterMethods'><p>List filter methods.</p></a></li>
<li><a href='#listLearnerProperties'><p>List the supported learner properties</p></a></li>
<li><a href='#listLearners'><p>Find matching learning algorithms.</p></a></li>
<li><a href='#listMeasureProperties'><p>List the supported measure properties.</p></a></li>
<li><a href='#listMeasures'><p>Find matching measures.</p></a></li>
<li><a href='#listTaskTypes'><p>List the supported task types in mlr</p></a></li>
<li><a href='#lung.task'><p>NCCTG Lung Cancer survival task.</p></a></li>
<li><a href='#makeAggregation'><p>Specify your own aggregation of measures.</p></a></li>
<li><a href='#makeBaggingWrapper'><p>Fuse learner with the bagging technique.</p></a></li>
<li><a href='#makeBaseWrapper'><p>Exported for internal use only.</p></a></li>
<li><a href='#makeChainModel'><p>Only exported for internal use.</p></a></li>
<li><a href='#makeClassificationViaRegressionWrapper'><p>Classification via regression wrapper.</p></a></li>
<li><a href='#makeClassifTask'><p>Create a classification task.</p></a></li>
<li><a href='#makeClassifTaskDesc'><p>Exported for internal use.</p></a></li>
<li><a href='#makeClusterTask'><p>Create a cluster task.</p></a></li>
<li><a href='#makeConstantClassWrapper'><p>Wraps a classification learner to support problems where the class label is (almost) constant.</p></a></li>
<li><a href='#makeCostMeasure'><p>Creates a measure for non-standard misclassification costs.</p></a></li>
<li><a href='#makeCostSensClassifWrapper'><p>Wraps a classification learner for use in cost-sensitive learning.</p></a></li>
<li><a href='#makeCostSensRegrWrapper'><p>Wraps a regression learner for use in cost-sensitive learning.</p></a></li>
<li><a href='#makeCostSensTask'><p>Create a cost-sensitive classification task.</p></a></li>
<li><a href='#makeCostSensWeightedPairsWrapper'><p>Wraps a classifier for cost-sensitive learning to produce a weighted pairs model.</p></a></li>
<li><a href='#makeCustomResampledMeasure'><p>Construct your own resampled performance measure.</p></a></li>
<li><a href='#makeDownsampleWrapper'><p>Fuse learner with simple downsampling (subsampling).</p></a></li>
<li><a href='#makeDummyFeaturesWrapper'><p>Fuse learner with dummy feature creator.</p></a></li>
<li><a href='#makeExtractFDAFeatMethod'><p>Constructor for FDA feature extraction methods.</p></a></li>
<li><a href='#makeExtractFDAFeatsWrapper'><p>Fuse learner with an extractFDAFeatures method.</p></a></li>
<li><a href='#makeFeatSelWrapper'><p>Fuse learner with feature selection.</p></a></li>
<li><a href='#makeFilter'><p>Create a feature filter.</p></a></li>
<li><a href='#makeFilterEnsemble'><p>Create an ensemble feature filter.</p></a></li>
<li><a href='#makeFilterWrapper'><p>Fuse learner with a feature filter method.</p></a></li>
<li><a href='#makeFixedHoldoutInstance'><p>Generate a fixed holdout instance for resampling.</p></a></li>
<li><a href='#makeFunctionalData'><p>Create a data.frame containing functional features from a normal data.frame.</p></a></li>
<li><a href='#makeImputeMethod'><p>Create a custom imputation method.</p></a></li>
<li><a href='#makeImputeWrapper'><p>Fuse learner with an imputation method.</p></a></li>
<li><a href='#makeLearner'><p>Create learner object.</p></a></li>
<li><a href='#makeLearners'><p>Create multiple learners at once.</p></a></li>
<li><a href='#makeMeasure'><p>Construct performance measure.</p></a></li>
<li><a href='#makeModelMultiplexer'><p>Create model multiplexer for model selection to tune over multiple</p>
possible models.</a></li>
<li><a href='#makeModelMultiplexerParamSet'><p>Creates a parameter set for model multiplexer tuning.</p></a></li>
<li><a href='#makeMulticlassWrapper'><p>Fuse learner with multiclass method.</p></a></li>
<li><a href='#makeMultilabelBinaryRelevanceWrapper'><p>Use binary relevance method to create a multilabel learner.</p></a></li>
<li><a href='#makeMultilabelClassifierChainsWrapper'><p>Use classifier chains method (CC) to create a multilabel learner.</p></a></li>
<li><a href='#makeMultilabelDBRWrapper'><p>Use dependent binary relevance method (DBR) to create a multilabel learner.</p></a></li>
<li><a href='#makeMultilabelNestedStackingWrapper'><p>Use nested stacking method to create a multilabel learner.</p></a></li>
<li><a href='#makeMultilabelStackingWrapper'><p>Use stacking method (stacked generalization) to create a multilabel learner.</p></a></li>
<li><a href='#makeMultilabelTask'><p>Create a multilabel task.</p></a></li>
<li><a href='#makeOverBaggingWrapper'><p>Fuse learner with the bagging technique and oversampling for imbalancy correction.</p></a></li>
<li><a href='#makePreprocWrapper'><p>Fuse learner with preprocessing.</p></a></li>
<li><a href='#makePreprocWrapperCaret'><p>Fuse learner with preprocessing.</p></a></li>
<li><a href='#makeRegrTask'><p>Create a regression task.</p></a></li>
<li><a href='#makeRemoveConstantFeaturesWrapper'><p>Fuse learner with removal of constant features preprocessing.</p></a></li>
<li><a href='#makeResampleDesc'><p>Create a description object for a resampling strategy.</p></a></li>
<li><a href='#makeResampleInstance'><p>Instantiates a resampling strategy object.</p></a></li>
<li><a href='#makeRLearner.classif.fdausc.glm'><p>Classification of functional data by Generalized Linear Models.</p></a></li>
<li><a href='#makeRLearner.classif.fdausc.kernel'><p>Learner for kernel classification for functional data.</p></a></li>
<li><a href='#makeRLearner.classif.fdausc.np'><p>Learner for nonparametric classification for functional data.</p></a></li>
<li><a href='#makeSMOTEWrapper'><p>Fuse learner with SMOTE oversampling for imbalancy correction in binary classification.</p></a></li>
<li><a href='#makeStackedLearner'><p>Create a stacked learner object.</p></a></li>
<li><a href='#makeSurvTask'><p>Create a survival task.</p></a></li>
<li><a href='#makeTaskDescInternal'><p>Exported for internal use.</p></a></li>
<li><a href='#makeTuneControlCMAES'><p>Create control object for hyperparameter tuning with CMAES.</p></a></li>
<li><a href='#makeTuneControlDesign'><p>Create control object for hyperparameter tuning with predefined design.</p></a></li>
<li><a href='#makeTuneControlGenSA'><p>Create control object for hyperparameter tuning with GenSA.</p></a></li>
<li><a href='#makeTuneControlGrid'><p>Create control object for hyperparameter tuning with grid search.</p></a></li>
<li><a href='#makeTuneControlIrace'><p>Create control object for hyperparameter tuning with Irace.</p></a></li>
<li><a href='#makeTuneControlMBO'><p>Create control object for hyperparameter tuning with MBO.</p></a></li>
<li><a href='#makeTuneControlRandom'><p>Create control object for hyperparameter tuning with random search.</p></a></li>
<li><a href='#makeTuneWrapper'><p>Fuse learner with tuning.</p></a></li>
<li><a href='#makeUndersampleWrapper'><p>Fuse learner with simple ove/underrsampling for imbalancy correction in binary classification.</p></a></li>
<li><a href='#makeWeightedClassesWrapper'><p>Wraps a classifier for weighted fitting where each class receives a weight.</p></a></li>
<li><a href='#makeWrappedModel'><p>Induced model of learner.</p></a></li>
<li><a href='#MeasureProperties'><p>Query properties of measures.</p></a></li>
<li><a href='#measures'><p>Performance measures.</p></a></li>
<li><a href='#mergeBenchmarkResults'><p>Merge different BenchmarkResult objects.</p></a></li>
<li><a href='#mergeSmallFactorLevels'><p>Merges small levels of factors into new level.</p></a></li>
<li><a href='#mlr-package'><p>mlr: Machine Learning in R</p></a></li>
<li><a href='#mlrFamilies'><p>mlr documentation families</p></a></li>
<li><a href='#mtcars.task'><p>Motor Trend Car Road Tests clustering task.</p></a></li>
<li><a href='#normalizeFeatures'><p>Normalize features.</p></a></li>
<li><a href='#oversample'><p>Over- or undersample binary classification task to handle class imbalancy.</p></a></li>
<li><a href='#parallelization'><p>Supported parallelization methods</p></a></li>
<li><a href='#performance'><p>Measure performance of prediction.</p></a></li>
<li><a href='#phoneme.task'><p>Phoneme functional data multilabel classification task.</p></a></li>
<li><a href='#pid.task'><p>PimaIndiansDiabetes classification task.</p></a></li>
<li><a href='#plotBMRBoxplots'><p>Create box or violin plots for a BenchmarkResult.</p></a></li>
<li><a href='#plotBMRRanksAsBarChart'><p>Create a bar chart for ranks in a BenchmarkResult.</p></a></li>
<li><a href='#plotBMRSummary'><p>Plot a benchmark summary.</p></a></li>
<li><a href='#plotCalibration'><p>Plot calibration data using ggplot2.</p></a></li>
<li><a href='#plotCritDifferences'><p>Plot critical differences for a selected measure.</p></a></li>
<li><a href='#plotFilterValues'><p>Plot filter values using ggplot2.</p></a></li>
<li><a href='#plotHyperParsEffect'><p>Plot the hyperparameter effects data</p></a></li>
<li><a href='#plotLearnerPrediction'><p>Visualizes a learning algorithm on a 1D or 2D data set.</p></a></li>
<li><a href='#plotLearningCurve'><p>Plot learning curve data using ggplot2.</p></a></li>
<li><a href='#plotPartialDependence'><p>Plot a partial dependence with ggplot2.</p></a></li>
<li><a href='#plotResiduals'><p>Create residual plots for prediction objects or benchmark results.</p></a></li>
<li><a href='#plotROCCurves'><p>Plots a ROC curve using ggplot2.</p></a></li>
<li><a href='#plotThreshVsPerf'><p>Plot threshold vs. performance(s) for 2-class classification using ggplot2.</p></a></li>
<li><a href='#plotTuneMultiCritResult'><p>Plots multi-criteria results after tuning using ggplot2.</p></a></li>
<li><a href='#predict.WrappedModel'><p>Predict new data.</p></a></li>
<li><a href='#Prediction'><p>Prediction object.</p></a></li>
<li><a href='#predictLearner'><p>Predict new data with an R learner.</p></a></li>
<li><a href='#reduceBatchmarkResults'><p>Reduce results of a batch-distributed benchmark.</p></a></li>
<li><a href='#reextractFDAFeatures'><p>Re-extract features from a data set</p></a></li>
<li><a href='#reimpute'><p>Re-impute a data set</p></a></li>
<li><a href='#removeConstantFeatures'><p>Remove constant features from a data set.</p></a></li>
<li><a href='#removeHyperPars'><p>Remove hyperparameters settings of a learner.</p></a></li>
<li><a href='#resample'><p>Fit models according to a resampling strategy.</p></a></li>
<li><a href='#ResamplePrediction'><p>Prediction from resampling.</p></a></li>
<li><a href='#ResampleResult'><p>ResampleResult object.</p></a></li>
<li><a href='#RLearner'><p>Internal construction / wrapping of learner object.</p></a></li>
<li><a href='#selectFeatures'><p>Feature selection by wrapper approach.</p></a></li>
<li><a href='#setAggregation'><p>Set aggregation function of measure.</p></a></li>
<li><a href='#setHyperPars'><p>Set the hyperparameters of a learner object.</p></a></li>
<li><a href='#setHyperPars2'><p>Only exported for internal use.</p></a></li>
<li><a href='#setId'><p>Set the id of a learner object.</p></a></li>
<li><a href='#setLearnerId'><p>Set the ID of a learner object.</p></a></li>
<li><a href='#setMeasurePars'><p>Set parameters of performance measures</p></a></li>
<li><a href='#setPredictThreshold'><p>Set the probability threshold the learner should use.</p></a></li>
<li><a href='#setPredictType'><p>Set the type of predictions the learner should return.</p></a></li>
<li><a href='#setThreshold'><p>Set threshold of prediction object.</p></a></li>
<li><a href='#simplifyMeasureNames'><p>Simplify measure names.</p></a></li>
<li><a href='#smote'><p>Synthetic Minority Oversampling Technique to handle class imbalancy in binary classification.</p></a></li>
<li><a href='#sonar.task'><p>Sonar classification task.</p></a></li>
<li><a href='#spam.task'><p>Spam classification task.</p></a></li>
<li><a href='#spatial.task'><p>J. Muenchow's Ecuador landslide data set</p></a></li>
<li><a href='#subsetTask'><p>Subset data in task.</p></a></li>
<li><a href='#summarizeColumns'><p>Summarize columns of data.frame or task.</p></a></li>
<li><a href='#summarizeLevels'><p>Summarizes factors of a data.frame by tabling them.</p></a></li>
<li><a href='#Task'><p>Create a classification, regression, survival, cluster, cost-sensitive classification or</p>
multilabel task.</a></li>
<li><a href='#TaskDesc'><p>Description object for task.</p></a></li>
<li><a href='#train'><p>Train a learning algorithm.</p></a></li>
<li><a href='#trainLearner'><p>Train an R learner.</p></a></li>
<li><a href='#TuneControl'><p>Control object for tuning</p></a></li>
<li><a href='#TuneMultiCritControl'><p>Create control structures for multi-criteria tuning.</p></a></li>
<li><a href='#TuneMultiCritResult'><p>Result of multi-criteria tuning.</p></a></li>
<li><a href='#tuneParams'><p>Hyperparameter tuning.</p></a></li>
<li><a href='#tuneParamsMultiCrit'><p>Hyperparameter tuning for multiple measures at once.</p></a></li>
<li><a href='#TuneResult'><p>Result of tuning.</p></a></li>
<li><a href='#tuneThreshold'><p>Tune prediction threshold.</p></a></li>
<li><a href='#wpbc.task'><p>Wisonsin Prognostic Breast Cancer (WPBC) survival task.</p></a></li>
<li><a href='#yeast.task'><p>Yeast multilabel classification task.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Machine Learning in R</td>
</tr>
<tr>
<td>Version:</td>
<td>2.19.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Interface to a large number of classification and regression
    techniques, including machine-readable parameter descriptions. There
    is also an experimental extension for survival analysis, clustering
    and general, example-specific cost-sensitive learning. Generic
    resampling, including cross-validation, bootstrapping and subsampling.
    Hyperparameter tuning with modern optimization techniques, for single-
    and multi-objective problems.  Filter and wrapper methods for feature
    selection. Extension of basic learners with additional operations
    common in machine learning, also allowing for easy nested resampling.
    Most operations can be parallelized.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-2-Clause">BSD_2_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://mlr.mlr-org.com">https://mlr.mlr-org.com</a>, <a href="https://github.com/mlr-org/mlr">https://github.com/mlr-org/mlr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mlr-org/mlr/issues">https://github.com/mlr-org/mlr/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>ParamHelpers (&ge; 1.10), R (&ge; 3.0.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>backports (&ge; 1.1.0), BBmisc (&ge; 1.11), checkmate (&ge; 1.8.2),
data.table (&ge; 1.12.4), ggplot2, methods, parallelMap (&ge; 1.3),
stats, stringi, survival, utils, XML</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ada, adabag, bartMachine, batchtools, bit64, brnn, bst, C50,
care, caret (&ge; 6.0-57), class, clue, cluster, ClusterR,
clusterSim (&ge; 0.44-5), cmaes, cowplot, crs, Cubist, deepnet,
DiceKriging, e1071, earth, elasticnet, emoa, evtree, fda.usc,
FDboost, FNN, forecast (&ge; 8.3), fpc, frbs, FSelector,
FSelectorRcpp (&ge; 0.3.5), gbm, GenSA, ggpubr, glmnet, GPfit,
h2o (&ge; 3.6.0.8), Hmisc, irace (&ge; 2.0), kernlab, kknn, klaR,
knitr, laGP, LiblineaR, lintr (&ge; 1.0.0.9001), MASS, mboost,
mco, mda, memoise, mlbench, mldr, mlrMBO, mmpf, modeltools,
mRMRe, neuralnet, nnet, numDeriv, pamr, pander, party, pec,
penalized (&ge; 0.9-47), pls, PMCMRplus, praznik (&ge; 5.0.0),
randomForest, ranger (&ge; 0.8.0), rappdirs, refund, rex, rFerns,
rgenoud, rmarkdown, Rmpi, ROCR, rotationForest, rpart, RRF,
rsm, RSNNS, rucrdtw, RWeka, sda, sf, smoof, sparseLDA, stepPlr,
survAUC, svglite, SwarmSVM, testthat, tgp, TH.data, tidyr,
tsfeatures, vdiffr, wavelets, xgboost (&ge; 0.7)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>true</td>
</tr>
<tr>
<td>Config/testthat/start-first:</td>
<td>featsel_plotFilterValues,base_plotResiduals,base_generateHyperParsEffect,
classif_bartMachine, tune_tuneIrace, featsel_filters,
learners_all*, regr_h2ogbm</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>gdal (optional), geos (optional), proj (optional),
udunits (optional), gsl (optional), gmp (optional), glu
(optional), jags (optional), mpfr (optional), openmpi
(optional)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-09-08 17:02:32 UTC; pjs</td>
</tr>
<tr>
<td>Author:</td>
<td>Bernd Bischl <a href="https://orcid.org/0000-0001-6002-6980"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Michel Lang <a href="https://orcid.org/0000-0001-9754-0393"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Lars Kotthoff [aut],
  Patrick Schratz <a href="https://orcid.org/0000-0003-0748-6624"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Julia Schiffner [aut],
  Jakob Richter [aut],
  Zachary Jones [aut],
  Giuseppe Casalicchio
    <a href="https://orcid.org/0000-0001-5324-5966"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Mason Gallo [aut],
  Jakob Bossek <a href="https://orcid.org/0000-0002-4121-4668"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Erich Studerus <a href="https://orcid.org/0000-0003-4233-0182"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Leonard Judt [ctb],
  Tobias Kuehn [ctb],
  Pascal Kerschke <a href="https://orcid.org/0000-0003-2862-1418"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Florian Fendt [ctb],
  Philipp Probst <a href="https://orcid.org/0000-0001-8402-6790"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Xudong Sun <a href="https://orcid.org/0000-0003-3269-2307"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Janek Thomas <a href="https://orcid.org/0000-0003-4511-6245"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Bruno Vieira [ctb],
  Laura Beggel <a href="https://orcid.org/0000-0002-8872-8535"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Quay Au <a href="https://orcid.org/0000-0002-5252-8902"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Martin Binder [ctb],
  Florian Pfisterer [ctb],
  Stefan Coors [ctb],
  Steve Bronder [ctb],
  Alexander Engelhardt [ctb],
  Christoph Molnar [ctb],
  Annette Spooner [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Patrick Schratz &lt;patrick.schratz@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-09-29 13:30:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='addRRMeasure'>Compute new measures for existing ResampleResult</h2><span id='topic+addRRMeasure'></span>

<h3>Description</h3>

<p>Adds new measures to an existing <code>ResampleResult</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addRRMeasure(res, measures)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addRRMeasure_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>)<br />
The result of <a href="#topic+resample">resample</a> run with <code>keep.pred = TRUE</code>.</p>
</td></tr>
<tr><td><code id="addRRMeasure_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ResampleResult">ResampleResult</a>).
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>

<hr>
<h2 id='Aggregation'>Aggregation object.</h2><span id='topic+Aggregation'></span>

<h3>Description</h3>

<p>An aggregation method reduces the performance values of the test
(and possibly the training sets) to a single value.
To see all possible implemented aggregations look at <a href="#topic+aggregations">aggregations</a>.
</p>
<p>The aggregation can access all relevant information of the result after resampling
and combine them into a single value. Though usually something very simple
like taking the mean of the test set performances is done.
</p>
<p>Object members:
</p>

<dl>
<dt>id (<code>character(1)</code>)</dt><dd><p>Name of the aggregation method.</p>
</dd>
<dt>name (<code>character(1)</code>)</dt><dd><p>Long name of the aggregation method.</p>
</dd>
<dt>properties (<a href="base.html#topic+character">character</a>)</dt><dd><p>Properties of the aggregation.</p>
</dd>
<dt>fun ('function(task, perf.test, perf.train, measure, group, pred)])</dt><dd><p>Aggregation function.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><a href="#topic+makeAggregation">makeAggregation</a>
</p>

<hr>
<h2 id='aggregations'>Aggregation methods.</h2><span id='topic+aggregations'></span><span id='topic+test.mean'></span><span id='topic+test.sd'></span><span id='topic+test.median'></span><span id='topic+test.min'></span><span id='topic+test.max'></span><span id='topic+test.sum'></span><span id='topic+test.range'></span><span id='topic+test.rmse'></span><span id='topic+train.mean'></span><span id='topic+train.sd'></span><span id='topic+train.median'></span><span id='topic+train.min'></span><span id='topic+train.max'></span><span id='topic+train.sum'></span><span id='topic+train.range'></span><span id='topic+train.rmse'></span><span id='topic+b632'></span><span id='topic+b632plus'></span><span id='topic+testgroup.mean'></span><span id='topic+testgroup.sd'></span><span id='topic+test.join'></span>

<h3>Description</h3>


<ul>
<li><p><strong>test.mean</strong><br /> Mean of performance values on test sets.
</p>
</li>
<li><p><strong>test.sd</strong><br /> Standard deviation of performance values on test sets.
</p>
</li>
<li><p><strong>test.median</strong><br /> Median of performance values on test sets.
</p>
</li>
<li><p><strong>test.min</strong><br /> Minimum of performance values on test sets.
</p>
</li>
<li><p><strong>test.max</strong><br /> Maximum of performance values on test sets.
</p>
</li>
<li><p><strong>test.sum</strong><br /> Sum of performance values on test sets.
</p>
</li>
<li><p><strong>train.mean</strong><br /> Mean of performance values on training sets.
</p>
</li>
<li><p><strong>train.sd</strong><br /> Standard deviation of performance values on training sets.
</p>
</li>
<li><p><strong>train.median</strong><br /> Median of performance values on training sets.
</p>
</li>
<li><p><strong>train.min</strong><br /> Minimum of performance values on training sets.
</p>
</li>
<li><p><strong>train.max</strong><br /> Maximum of performance values on training sets.
</p>
</li>
<li><p><strong>train.sum</strong><br /> Sum of performance values on training sets.
</p>
</li>
<li><p><strong>b632</strong><br /> Aggregation for B632 bootstrap.
</p>
</li>
<li><p><strong>b632plus</strong><br /> Aggregation for B632+ bootstrap.
</p>
</li>
<li><p><strong>testgroup.mean</strong><br /> Performance values on test sets are grouped according
to resampling method. The mean for every group is calculated, then the mean of those means.
Mainly used for repeated CV.
</p>
</li>
<li><p><strong>testgroup.sd</strong><br /> Similar to <strong>testgroup.mean</strong> - after
the mean for every group is calculated, the standard deviation of those means is obtained.
Mainly used for repeated CV.
</p>
</li>
<li><p><strong>test.join</strong><br /> Performance measure on joined test sets.
This is especially useful for small sample sizes where unbalanced group sizes have a significant impact
on the aggregation, especially for cross-validation test.join might make sense now.
For the repeated CV, the performance is calculated on each repetition and then aggregated
with the arithmetic mean.
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="#topic+Aggregation">Aggregation</a>
</p>

<hr>
<h2 id='agri.task'>European Union Agricultural Workforces clustering task.</h2><span id='topic+agri.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>agri.task</code>).
</p>


<h3>References</h3>

<p>See <a href="cluster.html#topic+agriculture">cluster::agriculture</a>.
</p>

<hr>
<h2 id='analyzeFeatSelResult'>Show and visualize the steps of feature selection.</h2><span id='topic+analyzeFeatSelResult'></span>

<h3>Description</h3>

<p>This function prints the steps <a href="#topic+selectFeatures">selectFeatures</a> took to find its optimal set
of features and the reason why it stopped.
It can also print information about all calculations done in each intermediate step.
</p>
<p>Currently only implemented for sequential feature selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyzeFeatSelResult(res, reduce = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyzeFeatSelResult_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+FeatSelResult">FeatSelResult</a>)<br />
The result of of <a href="#topic+selectFeatures">selectFeatures</a>.</p>
</td></tr>
<tr><td><code id="analyzeFeatSelResult_+3A_reduce">reduce</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Per iteration: Print only the selected feature (or all features that were evaluated)?
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>invisible(NULL)</code>).
</p>


<h3>See Also</h3>

<p>Other featsel: 
<code><a href="#topic+FeatSelControl">FeatSelControl</a></code>,
<code><a href="#topic+getFeatSelResult">getFeatSelResult</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+selectFeatures">selectFeatures</a>()</code>
</p>

<hr>
<h2 id='asROCRPrediction'>Converts predictions to a format package ROCR can handle.</h2><span id='topic+asROCRPrediction'></span>

<h3>Description</h3>

<p>Converts predictions to a format package ROCR can handle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>asROCRPrediction(pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asROCRPrediction_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other roc: 
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>
</p>
<p>Other predict: 
<code><a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a>()</code>,
<code><a href="#topic+getPredictionResponse">getPredictionResponse</a>()</code>,
<code><a href="#topic+getPredictionTaskDesc">getPredictionTaskDesc</a>()</code>,
<code><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='batchmark'>Run machine learning benchmarks as distributed experiments.</h2><span id='topic+batchmark'></span>

<h3>Description</h3>

<p>This function is a very parallel version of <a href="#topic+benchmark">benchmark</a> using
<span class="pkg">batchtools</span>. Experiments are created in the provided registry for each
combination of learners, tasks and resamplings. The experiments are then
stored in a registry and the runs can be started via
<a href="batchtools.html#topic+submitJobs">batchtools::submitJobs</a>. A job is one train/test split of the outer
resampling. In case of nested resampling (e.g. with <a href="#topic+makeTuneWrapper">makeTuneWrapper</a>), each
job is a full run of inner resampling, which can be parallelized in a second
step with <span class="pkg">ParallelMap</span>.
</p>
<p>For details on the usage and support backends have a look at the batchtools
tutorial page: <a href="https://github.com/mllg/batchtools">https://github.com/mllg/batchtools</a>.
</p>
<p>The general workflow with <code>batchmark</code> looks like this:
</p>

<ol>
<li><p> Create an ExperimentRegistry using <a href="batchtools.html#topic+makeExperimentRegistry">batchtools::makeExperimentRegistry</a>.
</p>
</li>
<li><p> Call <code>batchmark(...)</code> which defines jobs for all learners and tasks in an <a href="base.html#topic+expand.grid">base::expand.grid</a> fashion.
</p>
</li>
<li><p> Submit jobs using <a href="batchtools.html#topic+submitJobs">batchtools::submitJobs</a>.
</p>
</li>
<li><p> Babysit the computation, wait for all jobs to finish using <a href="batchtools.html#topic+waitForJobs">batchtools::waitForJobs</a>.
</p>
</li>
<li><p> Call <code>reduceBatchmarkResult()</code> to reduce results into a <a href="#topic+BenchmarkResult">BenchmarkResult</a>.
</p>
</li></ol>

<p>If you want to use this with <span class="pkg">OpenML</span> datasets you can generate tasks
from a vector of dataset IDs easily with <code>tasks = lapply(data.ids, function(x) convertOMLDataSetToMlr(getOMLDataSet(x)))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batchmark(
  learners,
  tasks,
  resamplings,
  measures,
  keep.pred = TRUE,
  keep.extract = FALSE,
  models = FALSE,
  reg = batchtools::getDefaultRegistry()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="batchmark_+3A_learners">learners</code></td>
<td>
<p>(list of <a href="#topic+Learner">Learner</a> | <a href="base.html#topic+character">character</a>)<br />
Learning algorithms which should be compared, can also be a single learner.
If you pass strings the learners will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_tasks">tasks</code></td>
<td>
<p>list of <a href="#topic+Task">Task</a><br />
Tasks that learners should be run on.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_resamplings">resamplings</code></td>
<td>
<p>[(list of) <a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy for each tasks.
If only one is provided, it will be replicated to match the number of tasks.
If missing, a 10-fold cross validation is used.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_measures">measures</code></td>
<td>
<p>(list of <a href="#topic+Measure">Measure</a>)<br />
Performance measures for all tasks.
If missing, the default measure of the first task is used.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_keep.pred">keep.pred</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the prediction data in the <code>pred</code> slot of the result object.
If you do many experiments (on larger data sets) these objects might unnecessarily increase
object size / mem usage, if you do not really need them.
The default is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_keep.extract">keep.extract</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the <code>extract</code> slot of the result object. When creating a lot of
benchmark results with extensive tuning, the resulting R objects can become
very large in size. That is why the tuning results stored in the <code>extract</code>
slot are removed by default (<code>keep.extract = FALSE</code>). Note that when
<code>keep.extract = FALSE</code> you will not be able to conduct analysis in the
tuning results.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_models">models</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should all fitted models be stored in the <a href="#topic+ResampleResult">ResampleResult</a>?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="batchmark_+3A_reg">reg</code></td>
<td>
<p>(<a href="batchtools.html#topic+makeRegistry">batchtools::Registry</a>)<br />
Registry, created by <a href="batchtools.html#topic+makeExperimentRegistry">batchtools::makeExperimentRegistry</a>. If not
explicitly passed, uses the last created registry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="data.table.html#topic+data.table">data.table</a>). Generated job ids are stored in the column
&ldquo;job.id&rdquo;.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='bc.task'>Wisconsin Breast Cancer classification task.</h2><span id='topic+bc.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>bc.task</code>).
</p>


<h3>References</h3>

<p>See <a href="mlbench.html#topic+BreastCancer">mlbench::BreastCancer</a>.
The column <code>"Id"</code> and all incomplete cases have been removed from the task.
</p>

<hr>
<h2 id='benchmark'>Benchmark experiment for multiple learners and tasks.</h2><span id='topic+benchmark'></span>

<h3>Description</h3>

<p>Complete benchmark experiment to compare different learning algorithms across one or more tasks
w.r.t. a given resampling strategy. Experiments are paired, meaning always the same
training / test sets are used for the different learners.
Furthermore, you can of course pass &ldquo;enhanced&rdquo; learners via wrappers, e.g., a
learner can be automatically tuned using <a href="#topic+makeTuneWrapper">makeTuneWrapper</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>benchmark(
  learners,
  tasks,
  resamplings,
  measures,
  keep.pred = TRUE,
  keep.extract = FALSE,
  models = FALSE,
  show.info = getMlrOption("show.info")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="benchmark_+3A_learners">learners</code></td>
<td>
<p>(list of <a href="#topic+Learner">Learner</a> | <a href="base.html#topic+character">character</a>)<br />
Learning algorithms which should be compared, can also be a single learner.
If you pass strings the learners will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_tasks">tasks</code></td>
<td>
<p>list of <a href="#topic+Task">Task</a><br />
Tasks that learners should be run on.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_resamplings">resamplings</code></td>
<td>
<p>(list of <a href="#topic+ResampleDesc">ResampleDesc</a> | <a href="#topic+ResampleInstance">ResampleInstance</a>)<br />
Resampling strategy for each tasks.
If only one is provided, it will be replicated to match the number of tasks.
If missing, a 10-fold cross validation is used.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_measures">measures</code></td>
<td>
<p>(list of <a href="#topic+Measure">Measure</a>)<br />
Performance measures for all tasks.
If missing, the default measure of the first task is used.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_keep.pred">keep.pred</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the prediction data in the <code>pred</code> slot of the result object.
If you do many experiments (on larger data sets) these objects might unnecessarily increase
object size / mem usage, if you do not really need them.
The default is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_keep.extract">keep.extract</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the <code>extract</code> slot of the result object. When creating a lot of
benchmark results with extensive tuning, the resulting R objects can become
very large in size. That is why the tuning results stored in the <code>extract</code>
slot are removed by default (<code>keep.extract = FALSE</code>). Note that when
<code>keep.extract = FALSE</code> you will not be able to conduct analysis in the
tuning results.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_models">models</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should all fitted models be stored in the <a href="#topic+ResampleResult">ResampleResult</a>?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="benchmark_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+BenchmarkResult">BenchmarkResult</a>.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lrns = list(makeLearner("classif.lda"), makeLearner("classif.rpart"))
tasks = list(iris.task, sonar.task)
rdesc = makeResampleDesc("CV", iters = 2L)
meas = list(acc, ber)
bmr = benchmark(lrns, tasks, rdesc, measures = meas)
rmat = convertBMRToRankMatrix(bmr)
print(rmat)
plotBMRSummary(bmr)
plotBMRBoxplots(bmr, ber, style = "violin")
plotBMRRanksAsBarChart(bmr, pos = "stack")
friedmanTestBMR(bmr)
friedmanPostHocTestBMR(bmr, p.value = 0.05)
</code></pre>

<hr>
<h2 id='BenchmarkResult'>BenchmarkResult object.</h2><span id='topic+BenchmarkResult'></span>

<h3>Description</h3>

<p>Result of a benchmark experiment conducted by <a href="#topic+benchmark">benchmark</a>
with the following members:
</p>

<dl>
<dt>results (list of <a href="#topic+ResampleResult">ResampleResult</a>):</dt><dd>
<p>A nested <a href="base.html#topic+list">list</a> of resample results,
first ordered by task id, then by learner id.
</p>
</dd>
<dt>measures (list of <a href="#topic+Measure">Measure</a>):</dt><dd>
<p>The performance measures used in the benchmark experiment.
</p>
</dd>
<dt>learners (list of <a href="#topic+Learner">Learner</a>):</dt><dd>
<p>The learning algorithms compared in the benchmark experiment.
</p>
</dd>
</dl>

<p>The print method of this object shows aggregated performance values
for all tasks and learners.
</p>
<p>It is recommended to
retrieve required information via the <code style="white-space: pre;">&#8288;getBMR*&#8288;</code> getter functions.
You can also convert the object using <a href="base.html#topic+as.data.frame">as.data.frame</a>.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='bh.task'>Boston Housing regression task.</h2><span id='topic+bh.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>bh.task</code>).
</p>


<h3>References</h3>

<p>See <a href="mlbench.html#topic+BostonHousing">mlbench::BostonHousing</a>.
</p>

<hr>
<h2 id='cache_helpers'>Get or delete mlr cache directory</h2><span id='topic+cache_helpers'></span><span id='topic+getCacheDir'></span><span id='topic+deleteCacheDir'></span>

<h3>Description</h3>

<p>Helper functions to deal with mlr caching.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCacheDir()

deleteCacheDir()
</code></pre>


<h3>Details</h3>

<p><code>getCacheDir()</code> returns the default mlr cache directory <br />
<code>deleteCacheDir()</code> clears the default mlr cache directory. Custom cache
directories must be deleted by hand.
</p>

<hr>
<h2 id='calculateConfusionMatrix'>Confusion matrix.</h2><span id='topic+calculateConfusionMatrix'></span><span id='topic+print.ConfusionMatrix'></span>

<h3>Description</h3>

<p>Calculates the confusion matrix for a (possibly resampled) prediction.
Rows indicate true classes, columns predicted classes. The marginal elements count the number of
classification errors for the respective row or column, i.e., the number of errors
when you condition on the corresponding true (rows) or predicted (columns) class.
The last bottom right element displays the total amount of errors.
</p>
<p>A list is returned that contains multiple matrices.
If <code>relative = TRUE</code> we compute three matrices, one with absolute values and two with relative.
The relative confusion matrices are normalized based on rows and columns respectively,
if <code>FALSE</code> we only compute the absolute value matrix.
</p>
<p>The <code>print</code> function returns the relative matrices in
a compact way so that both row and column marginals can be seen in one matrix.
For details see <a href="#topic+ConfusionMatrix">ConfusionMatrix</a>.
</p>
<p>Note that for resampling no further aggregation is currently performed.
All predictions on all test sets are joined to a vector yhat, as are all labels
joined to a vector y. Then yhat is simply tabulated vs. y, as if both were computed on
a single test set. This probably mainly makes sense when cross-validation is used for resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateConfusionMatrix(pred, relative = FALSE, sums = FALSE, set = "both")

## S3 method for class 'ConfusionMatrix'
print(x, both = TRUE, digits = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculateConfusionMatrix_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_relative">relative</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code> two additional matrices are calculated. One is normalized by rows and one by
columns.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_sums">sums</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code> add absolute number of observations in each group.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_set">set</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specifies which part(s) of the data are used for the calculation.
If <code>set</code> equals <code>train</code> or <code>test</code>, the <code>pred</code> object must be the result of a
resampling, otherwise an error is thrown.
Defaults to &ldquo;both&rdquo;. Possible values are &ldquo;train&rdquo;, &ldquo;test&rdquo;, or &ldquo;both&rdquo;.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+ConfusionMatrix">ConfusionMatrix</a>)<br />
Object to print.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_both">both</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code> both the absolute and relative confusion matrices are printed.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_digits">digits</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
How many numbers after the decimal point should be printed, only relevant for relative confusion matrices.</p>
</td></tr>
<tr><td><code id="calculateConfusionMatrix_+3A_...">...</code></td>
<td>
<p>(any)<br />
Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ConfusionMatrix">ConfusionMatrix</a>).
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>print(ConfusionMatrix)</code>: 
</p>
</li></ul>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># get confusion matrix after simple manual prediction
allinds = 1:150
train = sample(allinds, 75)
test = setdiff(allinds, train)
mod = train("classif.lda", iris.task, subset = train)
pred = predict(mod, iris.task, subset = test)
print(calculateConfusionMatrix(pred))
print(calculateConfusionMatrix(pred, sums = TRUE))
print(calculateConfusionMatrix(pred, relative = TRUE))

# now after cross-validation
r = crossval("classif.lda", iris.task, iters = 2L)
print(calculateConfusionMatrix(r$pred))
</code></pre>

<hr>
<h2 id='calculateROCMeasures'>Calculate receiver operator measures.</h2><span id='topic+calculateROCMeasures'></span><span id='topic+print.ROCMeasures'></span>

<h3>Description</h3>

<p>Calculate the absolute number of correct/incorrect classifications and the following evaluation measures:
</p>

<ul>
<li> <p><code>tpr</code> True positive rate (Sensitivity, Recall)
</p>
</li>
<li> <p><code>fpr</code> False positive rate (Fall-out)
</p>
</li>
<li> <p><code>fnr</code> False negative rate (Miss rate)
</p>
</li>
<li> <p><code>tnr</code> True negative rate (Specificity)
</p>
</li>
<li> <p><code>ppv</code> Positive predictive value (Precision)
</p>
</li>
<li> <p><code>for</code> False omission rate
</p>
</li>
<li> <p><code>lrp</code> Positive likelihood ratio (LR+)
</p>
</li>
<li> <p><code>fdr</code> False discovery rate
</p>
</li>
<li> <p><code>npv</code> Negative predictive value
</p>
</li>
<li> <p><code>acc</code> Accuracy
</p>
</li>
<li> <p><code>lrm</code> Negative likelihood ratio (LR-)
</p>
</li>
<li> <p><code>dor</code> Diagnostic odds ratio
</p>
</li></ul>

<p>For details on the used measures see <a href="#topic+measures">measures</a> and also
<a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">https://en.wikipedia.org/wiki/Receiver_operating_characteristic</a>.
</p>
<p>The element for the false omission rate in the resulting object is not called <code>for</code> but
<code>fomr</code> since <code>for</code> should never be used as a variable name in an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculateROCMeasures(pred)

## S3 method for class 'ROCMeasures'
print(x, abbreviations = TRUE, digits = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculateROCMeasures_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="calculateROCMeasures_+3A_x">x</code></td>
<td>
<p>(<code>ROCMeasures</code>)<br />
Created by <a href="#topic+calculateROCMeasures">calculateROCMeasures</a>.</p>
</td></tr>
<tr><td><code id="calculateROCMeasures_+3A_abbreviations">abbreviations</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code> a short paragraph with explanations of the used measures is printed additionally.</p>
</td></tr>
<tr><td><code id="calculateROCMeasures_+3A_digits">digits</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of digits the measures are rounded to.</p>
</td></tr>
<tr><td><code id="calculateROCMeasures_+3A_...">...</code></td>
<td>
<p><code>(any)</code><br />
Currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>ROCMeasures</code>).
A list containing two elements <code>confusion.matrix</code> which is
the 2 times 2 confusion matrix of absolute frequencies and <code>measures</code>, a list of the above mentioned measures.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>print(ROCMeasures)</code>: 
</p>
</li></ul>


<h3>See Also</h3>

<p>Other roc: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>
</p>
<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lrn = makeLearner("classif.rpart", predict.type = "prob")
fit = train(lrn, sonar.task)
pred = predict(fit, task = sonar.task)
calculateROCMeasures(pred)
</code></pre>

<hr>
<h2 id='capLargeValues'>Convert large/infinite numeric values in a data.frame or task.</h2><span id='topic+capLargeValues'></span>

<h3>Description</h3>

<p>Convert numeric entries which large/infinite (absolute) values
in a data.frame or task.
Only numeric/integer columns are affected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>capLargeValues(
  obj,
  target = character(0L),
  cols = NULL,
  threshold = Inf,
  impute = threshold,
  what = "abs"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="capLargeValues_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="capLargeValues_+3A_target">target</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Name of the column(s) specifying the response.
Target columns will not be capped.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="capLargeValues_+3A_cols">cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Which columns to convert.
Default is all numeric columns.</p>
</td></tr>
<tr><td><code id="capLargeValues_+3A_threshold">threshold</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Threshold for capping.
Every entry whose absolute value is equal or larger is converted.
Default is <code>Inf</code>.</p>
</td></tr>
<tr><td><code id="capLargeValues_+3A_impute">impute</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Replacement value for large entries.
Large negative entries are converted to <code>-impute</code>.
Default is <code>threshold</code>.</p>
</td></tr>
<tr><td><code id="capLargeValues_+3A_what">what</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What kind of entries are affected?
&ldquo;abs&rdquo; means <code>abs(x) &gt; threshold</code>,
&ldquo;pos&rdquo; means <code>abs(x) &gt; threshold &amp;&amp; x &gt; 0</code>,
&ldquo;neg&rdquo; means <code>abs(x) &gt; threshold &amp;&amp; x &lt; 0</code>.
Default is &ldquo;abs&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>)
</p>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>capLargeValues(iris, threshold = 5, impute = 5)
</code></pre>

<hr>
<h2 id='changeData'>Change Task Data</h2><span id='topic+changeData'></span>

<h3>Description</h3>

<p>Mainly for internal use. Changes the data associated with a task, without modifying other task properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>changeData(task, data, costs, weights, coordinates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="changeData_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="changeData_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
The new data to associate with the task. The names and types of the feature columns must match with the old data.</p>
</td></tr>
<tr><td><code id="changeData_+3A_costs">costs</code></td>
<td>
<p>([data.frame'<br />
Optional: cost matrix.</p>
</td></tr>
<tr><td><code id="changeData_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional: weight vector.</p>
</td></tr>
</table>

<hr>
<h2 id='checkLearner'>Exported for internal use only.</h2><span id='topic+checkLearner'></span>

<h3>Description</h3>

<p>Exported for internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkLearner(learner, type = NULL, props = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkLearner_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner to check, or the name of the learner to create</p>
</td></tr>
<tr><td><code id="checkLearner_+3A_type">type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What type of learner to require.</p>
</td></tr>
<tr><td><code id="checkLearner_+3A_props">props</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What properties to require.</p>
</td></tr>
</table>

<hr>
<h2 id='checkPredictLearnerOutput'>Check output returned by predictLearner.</h2><span id='topic+checkPredictLearnerOutput'></span>

<h3>Description</h3>

<p>Check the output coming from a Learner's internal
<code>predictLearner</code> function.
</p>
<p>This function is for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkPredictLearnerOutput(learner, model, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkPredictLearnerOutput_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a>)<br />
The learner.</p>
</td></tr>
<tr><td><code id="checkPredictLearnerOutput_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)]<br />
Model produced by training.</p>
</td></tr>
<tr><td><code id="checkPredictLearnerOutput_+3A_p">p</code></td>
<td>
<p>(any)<br />
The prediction made by <code>learner</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(any). A sanitized version of <code>p</code>.
</p>

<hr>
<h2 id='configureMlr'>Configures the behavior of the package.</h2><span id='topic+configureMlr'></span>

<h3>Description</h3>

<p>Configuration is done by setting custom <a href="base.html#topic+options">options</a>.
</p>
<p>If you do not set an option here, its current value will be kept.
</p>
<p>If you call this function with an empty argument list, everything is set to its defaults.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>configureMlr(
  show.info,
  on.learner.error,
  on.learner.warning,
  on.par.without.desc,
  on.par.out.of.bounds,
  on.measure.not.applicable,
  show.learner.output,
  on.error.dump
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="configureMlr_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Some methods of mlr support a <code>show.info</code> argument to enable
verbose output on the console. This option sets the default value for these arguments.
Setting the argument manually in one of these functions will overwrite the default
value for that specific function call.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_on.learner.error">on.learner.error</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What should happen if an error in an underlying learning algorithm is caught:<br />
&ldquo;stop&rdquo;: R exception is generated.<br />
&ldquo;warn&rdquo;: A <code>FailureModel</code> will be created, which predicts only NAs and a warning will be generated.<br />
&ldquo;quiet&rdquo;: Same as &ldquo;warn&rdquo; but without the warning.<br />
Default is &ldquo;stop&rdquo;.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_on.learner.warning">on.learner.warning</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What should happen if a warning in an underlying learning algorithm is generated:<br />
&ldquo;warn&rdquo;: The warning is generated as usual.<br />
&ldquo;quiet&rdquo;: The warning is suppressed.<br />
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_on.par.without.desc">on.par.without.desc</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What should happen if a parameter of a learner is set to a value, but no parameter description object exists,
indicating a possibly wrong name:<br />
&ldquo;stop&rdquo;: R exception is generated.<br />
&ldquo;warn&rdquo;: Warning, but parameter is still passed along to learner.<br />
&ldquo;quiet&rdquo;: Same as &ldquo;warn&rdquo; but without the warning.<br />
Default is &ldquo;stop&rdquo;.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_on.par.out.of.bounds">on.par.out.of.bounds</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What should happen if a parameter of a learner is set to an out of bounds value.<br />
&ldquo;stop&rdquo;: R exception is generated.<br />
&ldquo;warn&rdquo;: Warning, but parameter is still passed along to learner.<br />
&ldquo;quiet&rdquo;: Same as &ldquo;warn&rdquo; but without the warning.<br />
Default is &ldquo;stop&rdquo;.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_on.measure.not.applicable">on.measure.not.applicable</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
What should happen if a measure is not applicable to a learner.<br />
&ldquo;stop&rdquo;: R exception is generated.<br />
&ldquo;warn&rdquo;: Warning, but value of the measure will be <code>NA</code>.<br />
&ldquo;quiet&rdquo;: Same as &ldquo;warn&rdquo; but without the warning.<br />
Default is &ldquo;stop&rdquo;.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_show.learner.output">show.learner.output</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the output of the learning algorithm during training and prediction be shown or captured and
suppressed?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="configureMlr_+3A_on.error.dump">on.error.dump</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Specify whether <a href="#topic+FailureModel">FailureModel</a> models and failed predictions should contain an error dump
that can be used with <code>debugger</code> to inspect an error. This option is only effective if <code>on.learner.error</code>
is &ldquo;warn&rdquo; or &ldquo;quiet&rdquo;. If it is <code>TRUE</code>, the dump can be accessed using
<a href="#topic+getFailureModelDump">getFailureModelDump</a> on the <a href="#topic+FailureModel">FailureModel</a>, <a href="#topic+getPredictionDump">getPredictionDump</a> on the failed prediction, and <a href="#topic+getRRDump">getRRDump</a> on resample predictions.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>invisible(NULL)</code>).
</p>


<h3>See Also</h3>

<p>Other configure: 
<code><a href="#topic+getMlrOptions">getMlrOptions</a>()</code>
</p>

<hr>
<h2 id='ConfusionMatrix'>Confusion matrix</h2><span id='topic+ConfusionMatrix'></span>

<h3>Description</h3>

<p>The result of <a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>.
</p>
<p>Object members:
</p>

<dl>
<dt>result (<a href="base.html#topic+matrix">matrix</a>)</dt><dd><p>Confusion matrix of absolute values and marginals. Can also contain
row and column sums of observations.</p>
</dd>
<dt>task.desc (<a href="#topic+TaskDesc">TaskDesc</a>)</dt><dd><p>Additional information about the task.</p>
</dd>
<dt>sums (<code>logical(1)</code>)</dt><dd><p>Flag if marginal sums of observations are calculated.</p>
</dd>
<dt>relative (<code>logical(1)</code>)</dt><dd><p>Flag if the relative confusion matrices are calculated.</p>
</dd>
<dt>relative.row (<a href="base.html#topic+matrix">matrix</a>)</dt><dd><p>Confusion matrix of relative values and marginals normalized by row.</p>
</dd>
<dt>relative.col (<a href="base.html#topic+matrix">matrix</a>)</dt><dd><p>Confusion matrix of relative values and marginals normalized by column.</p>
</dd>
<dt>relative.error (<code>numeric(1)</code>)</dt><dd><p>Relative error overall.</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>

<hr>
<h2 id='convertBMRToRankMatrix'>Convert BenchmarkResult to a rank-matrix.</h2><span id='topic+convertBMRToRankMatrix'></span>

<h3>Description</h3>

<p>Computes a matrix of all the ranks of different algorithms
over different datasets (tasks). Ranks are computed from aggregated
measures.
Smaller ranks imply better methods, so for measures that are minimized, small ranks imply small scores.
for measures that are maximized, small ranks imply large scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertBMRToRankMatrix(
  bmr,
  measure = NULL,
  ties.method = "average",
  aggregation = "default"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertBMRToRankMatrix_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="convertBMRToRankMatrix_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="convertBMRToRankMatrix_+3A_ties.method">ties.method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
See <a href="base.html#topic+rank">base::rank</a> for details.</p>
</td></tr>
<tr><td><code id="convertBMRToRankMatrix_+3A_aggregation">aggregation</code></td>
<td>
<p>(<code>character(1)</code>) <br />
&ldquo;mean&rdquo; or &ldquo;default&rdquo;. See <a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>
for details on &ldquo;default&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+matrix">matrix</a>) with measure ranks as entries.
The matrix has one row for each <code>learner</code>, and one column for each <code>task</code>.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='convertMLBenchObjToTask'>Convert a machine learning benchmark / demo object from package mlbench to a task.</h2><span id='topic+convertMLBenchObjToTask'></span>

<h3>Description</h3>

<p>We auto-set the target column, drop any column which is called &ldquo;Id&rdquo; and
convert logicals to factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convertMLBenchObjToTask(x, n = 100L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convertMLBenchObjToTask_+3A_x">x</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of an mlbench function or dataset.</p>
</td></tr>
<tr><td><code id="convertMLBenchObjToTask_+3A_n">n</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of observations for data simul functions.
Note that for a few mlbench function this setting is not exactly respected by mlbench.
Default is 100.</p>
</td></tr>
<tr><td><code id="convertMLBenchObjToTask_+3A_...">...</code></td>
<td>
<p>(any)<br />
Passed on to data simul functions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>print(convertMLBenchObjToTask("Ionosphere"))
print(convertMLBenchObjToTask("mlbench.spirals", n = 100, sd = 0.1))
</code></pre>

<hr>
<h2 id='costiris.task'>Iris cost-sensitive classification task.</h2><span id='topic+costiris.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>costiris.task</code>).
</p>


<h3>References</h3>

<p>See <a href="datasets.html#topic+iris">datasets::iris</a>.
The cost matrix was generated artificially following
</p>
<p>Tu, H.-H. and Lin, H.-T. (2010), One-sided support vector regression for multiclass cost-sensitive classification.
In ICML, J. Frnkranz and T. Joachims, Eds., Omnipress, 1095&ndash;1102.
</p>

<hr>
<h2 id='createDummyFeatures'>Generate dummy variables for factor features.</h2><span id='topic+createDummyFeatures'></span>

<h3>Description</h3>

<p>Replace all factor features with their dummy variables. Internally <a href="stats.html#topic+model.matrix">model.matrix</a> is used.
Non factor features will be left untouched and passed to the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createDummyFeatures(
  obj,
  target = character(0L),
  method = "1-of-n",
  cols = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createDummyFeatures_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="createDummyFeatures_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
Only used when <code>obj</code> is a data.frame, otherwise ignored.
If survival analysis is applicable, these are the names of the survival time and event columns,
so it has length 2.
For multilabel classification these are the names of logical columns that indicate whether
a class label is present and the number of target variables corresponds to the number of
classes.</p>
</td></tr>
<tr><td><code id="createDummyFeatures_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Available are:
</p>

<dl>
<dt>&quot;1-of-n&quot;:</dt><dd><p>For n factor levels there will be n dummy variables.</p>
</dd>
<dt>&quot;reference&quot;:</dt><dd><p>There will be n-1 dummy variables leaving out the first factor level of each variable.</p>
</dd>
</dl>

<p>Default is &ldquo;1-of-n&rdquo;.</p>
</td></tr>
<tr><td><code id="createDummyFeatures_+3A_cols">cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Columns to create dummy features for. Default is to use all columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>. Same type as <code>obj</code>.
</p>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>

<hr>
<h2 id='createSpatialResamplingPlots'>Create (spatial) resampling plot objects.</h2><span id='topic+createSpatialResamplingPlots'></span>

<h3>Description</h3>

<p>Visualize partitioning of resample objects with spatial
information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createSpatialResamplingPlots(
  task = NULL,
  resample = NULL,
  crs = NULL,
  datum = 4326,
  repetitions = 1,
  color.train = "#0072B5",
  color.test = "#E18727",
  point.size = 0.5,
  axis.text.size = 14,
  x.axis.breaks = waiver(),
  y.axis.breaks = waiver()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createSpatialResamplingPlots_+3A_task">task</code></td>
<td>
<p><a href="#topic+Task">Task</a> <br />
Task object.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_resample">resample</code></td>
<td>
<p><a href="#topic+ResampleResult">ResampleResult</a> or named <code>list</code> with (multiple)
<a href="#topic+ResampleResult">ResampleResult</a><br />
As returned by <a href="#topic+resample">resample</a>.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_crs">crs</code></td>
<td>
<p><a href="base.html#topic+integer">integer</a><br />
Coordinate reference system (EPSG code number) for the supplied
coordinates in the <code>Task</code>.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_datum">datum</code></td>
<td>
<p><a href="base.html#topic+integer">integer</a><br />
Coordinate reference system which should be used in the resulting map.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_repetitions">repetitions</code></td>
<td>
<p><a href="base.html#topic+integer">integer</a><br />
Number of repetitions.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_color.train">color.train</code></td>
<td>
<p><a href="base.html#topic+character">character</a><br />
Color for train set.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_color.test">color.test</code></td>
<td>
<p><a href="base.html#topic+character">character</a><br />
Color for test set.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_point.size">point.size</code></td>
<td>
<p><a href="base.html#topic+integer">integer</a><br />
Point size.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_axis.text.size">axis.text.size</code></td>
<td>
<p><a href="base.html#topic+integer">integer</a><br />
Font size of axis labels.</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_x.axis.breaks">x.axis.breaks</code></td>
<td>
<p><a href="base.html#topic+numeric">numeric</a><br />
Custom x axis breaks</p>
</td></tr>
<tr><td><code id="createSpatialResamplingPlots_+3A_y.axis.breaks">y.axis.breaks</code></td>
<td>
<p><a href="base.html#topic+numeric">numeric</a><br />
Custom y axis breaks</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a named list is given to <code>resample</code>, names will appear in the title of
each fold.
If multiple inputs are given to <code>resample</code>, these must be named.
</p>
<p>This function makes a hard cut at five columns of the resulting gridded plot.
This means if the <code>resample</code> object consists of <code>folds &gt; 5</code>, these folds will
be put into the new row.
</p>
<p>For file saving, we recommend to use <a href="cowplot.html#topic+save_plot">cowplot::save_plot</a>.
</p>
<p>When viewing the resulting plot in RStudio, margins may appear to be
different than they really are.
Make sure to save the file to disk and inspect the image.
</p>
<p>When modifying axis breaks, negative values need to be used if the area is
located in either the western or southern hemisphere.
Use positive values for the northern and eastern hemisphere.
</p>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> of <code>2L</code> containing (1) multiple 'gg&ldquo; objects and (2) their
corresponding labels.
</p>


<h3>CRS</h3>

<p>The crs has to be suitable for the coordinates stored in the <code>Task</code>.
For example, if the coordinates are UTM, <code>crs</code> should be set to a
UTM projection.
Due to a limited axis space in the resulting grid (especially on the x-axis),
the data will by default projected into a lat/lon projection, specifically
EPSG 4326.
If other projections are desired for the resulting map, please set argument
<code>datum</code> accordingly. This argument will be passed onto <a href="ggplot2.html#topic+ggsf">ggplot2::coord_sf</a>.
</p>


<h3>Author(s)</h3>

<p>Patrick Schratz
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rdesc = makeResampleDesc("SpRepCV", folds = 5, reps = 4)
r = resample(makeLearner("classif.qda"), spatial.task, rdesc)

## -------------------------------------------------------------
## single unnamed resample input with 5 folds and 2 repetitions
## -------------------------------------------------------------

plots = createSpatialResamplingPlots(spatial.task, r, crs = 32717,
  repetitions = 2, x.axis.breaks = c(-79.065, -79.085),
  y.axis.breaks = c(-3.970, -4))
cowplot::plot_grid(plotlist = plots[["Plots"]], ncol = 5, nrow = 2,
  labels = plots[["Labels"]])

## --------------------------------------------------------------------------
## single named resample input with 5 folds and 1 repetition and 32717 datum
## --------------------------------------------------------------------------

plots = createSpatialResamplingPlots(spatial.task, list("Resamp" = r),
  crs = 32717, datum = 32717, repetitions = 1)
cowplot::plot_grid(plotlist = plots[["Plots"]], ncol = 5, nrow = 1,
  labels = plots[["Labels"]])

## -------------------------------------------------------------
## multiple named resample inputs with 5 folds and 1 repetition
## -------------------------------------------------------------

rdesc1 = makeResampleDesc("SpRepCV", folds = 5, reps = 4)
r1 = resample(makeLearner("classif.qda"), spatial.task, rdesc1)
rdesc2 = makeResampleDesc("RepCV", folds = 5, reps = 4)
r2 = resample(makeLearner("classif.qda"), spatial.task, rdesc2)

plots = createSpatialResamplingPlots(spatial.task,
  list("SpRepCV" = r1, "RepCV" = r2), crs = 32717, repetitions = 1,
  x.axis.breaks = c(-79.055, -79.085), y.axis.breaks = c(-3.975, -4))
cowplot::plot_grid(plotlist = plots[["Plots"]], ncol = 5, nrow = 2,
  labels = plots[["Labels"]])

## -------------------------------------------------------------------------------------
## Complex arrangements of multiple named resample inputs with 5 folds and 1 repetition
## -------------------------------------------------------------------------------------

p1 = cowplot::plot_grid(plots[["Plots"]][[1]], plots[["Plots"]][[2]],
  plots[["Plots"]][[3]], ncol = 3, nrow = 1, labels = plots[["Labels"]][1:3],
  label_size = 18)
p12 = cowplot::plot_grid(plots[["Plots"]][[4]], plots[["Plots"]][[5]],
  ncol = 2, nrow = 1, labels = plots[["Labels"]][4:5], label_size = 18)

p2 = cowplot::plot_grid(plots[["Plots"]][[6]], plots[["Plots"]][[7]],
  plots[["Plots"]][[8]], ncol = 3, nrow = 1, labels = plots[["Labels"]][6:8],
  label_size = 18)
p22 = cowplot::plot_grid(plots[["Plots"]][[9]], plots[["Plots"]][[10]],
  ncol = 2, nrow = 1, labels = plots[["Labels"]][9:10], label_size = 18)

cowplot::plot_grid(p1, p12, p2, p22, ncol = 1)

</code></pre>

<hr>
<h2 id='crossover'>Crossover.</h2><span id='topic+crossover'></span>

<h3>Description</h3>

<p>Takes two bit strings and creates a new one of the same size by selecting the items from the first string or
the second, based on a given rate (the probability of choosing an element from the first string).
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="crossover_+3A_x">x</code></td>
<td>
<p>(<a href="base.html#topic+logical">logical</a>)<br />
First parent string.</p>
</td></tr>
<tr><td><code id="crossover_+3A_y">y</code></td>
<td>
<p>(<a href="base.html#topic+logical">logical</a>)<br />
Second parent string.</p>
</td></tr>
<tr><td><code id="crossover_+3A_rate">rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
A number representing the probability of selecting an element of the first string.
Default is <code>0.5</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+crossover">crossover</a>).
</p>

<hr>
<h2 id='downsample'>Downsample (subsample) a task or a data.frame.</h2><span id='topic+downsample'></span>

<h3>Description</h3>

<p>Decrease the observations in a <code>task</code> or a <code>ResampleInstance</code>
to a given percentage of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>downsample(obj, perc = 1, stratify = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="downsample_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+ResampleInstance">ResampleInstance</a>)<br />
Input data or a <code>ResampleInstance</code>.</p>
</td></tr>
<tr><td><code id="downsample_+3A_perc">perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Percentage from (0, 1).
Default is 1.</p>
</td></tr>
<tr><td><code id="downsample_+3A_stratify">stratify</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Only for classification:
Should the downsampled data be stratified according to the target classes?
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>([data.frame<code style="white-space: pre;">&#8288;| [Task] | [ResampleInstance]). Same type as&#8288;</code>obj'.
</p>


<h3>See Also</h3>

<p><a href="#topic+makeResampleInstance">makeResampleInstance</a>
</p>
<p>Other downsample: 
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>
</p>

<hr>
<h2 id='dropFeatures'>Drop some features of task.</h2><span id='topic+dropFeatures'></span>

<h3>Description</h3>

<p>Drop some features of task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dropFeatures(task, features)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dropFeatures_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="dropFeatures_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Features to drop.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Task">Task</a>.
</p>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>

<hr>
<h2 id='estimateRelativeOverfitting'>Estimate relative overfitting.</h2><span id='topic+estimateRelativeOverfitting'></span>

<h3>Description</h3>

<p>Estimates the relative overfitting of a model as the ratio of the difference in test and train performance to the difference of test performance in the no-information case and train performance.
In the no-information case the features carry no information with respect to the prediction. This is simulated by permuting features and predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimateRelativeOverfitting(
  predish,
  measures,
  task,
  learner = NULL,
  pred.train = NULL,
  iter = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimateRelativeOverfitting_+3A_predish">predish</code></td>
<td>
<p>(<a href="#topic+ResampleDesc">ResampleDesc</a> | <a href="#topic+ResamplePrediction">ResamplePrediction</a> | <a href="#topic+Prediction">Prediction</a>)<br />
Resampling strategy or resampling prediction or test predictions.</p>
</td></tr>
<tr><td><code id="estimateRelativeOverfitting_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="estimateRelativeOverfitting_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="estimateRelativeOverfitting_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="estimateRelativeOverfitting_+3A_pred.train">pred.train</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Training predictions. Only needed if test predictions are passed.</p>
</td></tr>
<tr><td><code id="estimateRelativeOverfitting_+3A_iter">iter</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Iteration number. Default 1, usually you don't need to specify this. Only needed if test predictions are passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently only support for classification and regression tasks is implemented.
</p>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>). Relative overfitting estimate(s), named by measure(s), for each resampling iteration.
</p>


<h3>References</h3>

<p>Bradley Efron and Robert Tibshirani; Improvements on Cross-Validation: The .632+ Bootstrap Method, Journal of the American Statistical Association, Vol. 92, No. 438. (Jun., 1997), pp. 548-560.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>task = makeClassifTask(data = iris, target = "Species")
rdesc = makeResampleDesc("CV", iters = 2)
estimateRelativeOverfitting(rdesc, acc, task, makeLearner("classif.knn"))
estimateRelativeOverfitting(rdesc, acc, task, makeLearner("classif.lda"))
rpred = resample("classif.knn", task, rdesc)$pred
estimateRelativeOverfitting(rpred, acc, task)
</code></pre>

<hr>
<h2 id='estimateResidualVariance'>Estimate the residual variance.</h2><span id='topic+estimateResidualVariance'></span>

<h3>Description</h3>

<p>Estimate the residual variance of a regression model on a given task.
If a regression learner is provided instead of a model, the model is
trained (see <a href="#topic+train">train</a>) first.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimateResidualVariance(x, task, data, target)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimateResidualVariance_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> or <a href="#topic+WrappedModel">WrappedModel</a>)<br />
Learner or wrapped model.</p>
</td></tr>
<tr><td><code id="estimateResidualVariance_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+RegrTask">RegrTask</a>)<br />
Regression task.
If missing, <code>data</code> and <code>target</code> must be supplied.</p>
</td></tr>
<tr><td><code id="estimateResidualVariance_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable.
If missing, <code>task</code> must be supplied.</p>
</td></tr>
<tr><td><code id="estimateResidualVariance_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of the target variable.
If missing, <code>task</code> must be supplied.</p>
</td></tr>
</table>

<hr>
<h2 id='extractFDABsignal'>Bspline mlq features</h2><span id='topic+extractFDABsignal'></span>

<h3>Description</h3>

<p>The function extracts features from functional data based on the Bspline fit.
For more details refer to <code><a href="FDboost.html#topic+bsignal">FDboost::bsignal()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDABsignal(bsignal.knots = 10L, bsignal.df = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDABsignal_+3A_bsignal.knots">bsignal.knots</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of knots for bspline.</p>
</td></tr>
<tr><td><code id="extractFDABsignal_+3A_bsignal.df">bsignal.df</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
The effective degree of freedom of penalized bspline.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDADTWKernel">extractFDADTWKernel</a>()</code>,
<code><a href="#topic+extractFDAFPCA">extractFDAFPCA</a>()</code>,
<code><a href="#topic+extractFDAFourier">extractFDAFourier</a>()</code>,
<code><a href="#topic+extractFDAMultiResFeatures">extractFDAMultiResFeatures</a>()</code>,
<code><a href="#topic+extractFDATsfeatures">extractFDATsfeatures</a>()</code>,
<code><a href="#topic+extractFDAWavelets">extractFDAWavelets</a>()</code>
</p>

<hr>
<h2 id='extractFDADTWKernel'>DTW kernel features</h2><span id='topic+extractFDADTWKernel'></span>

<h3>Description</h3>

<p>The function extracts features from functional data based on the DTW distance with a reference dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDADTWKernel(
  ref.method = "random",
  n.refs = 0.05,
  refs = NULL,
  dtwwindow = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDADTWKernel_+3A_ref.method">ref.method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
How should the reference curves be obtained?
Method <code>random</code> draws <code>n.refs</code> random reference curves, while <code>all</code> uses all curves as references.
In order to use user-provided reference curves, this parameter is set to <code>fixed</code>.</p>
</td></tr>
<tr><td><code id="extractFDADTWKernel_+3A_n.refs">n.refs</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Number of reference curves to be drawn (as a fraction of the number of observations in the training data).</p>
</td></tr>
<tr><td><code id="extractFDADTWKernel_+3A_refs">refs</code></td>
<td>
<p>(<code>matrix</code>|<code>integer(n)</code>)<br />
Integer vector of training set row indices or a matrix of reference curves with the same length as
the functionals in the training data. Overwrites <code>ref.method</code> and <code>n.refs</code>.</p>
</td></tr>
<tr><td><code id="extractFDADTWKernel_+3A_dtwwindow">dtwwindow</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Size of the warping window size (as a proportion of query length).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDABsignal">extractFDABsignal</a>()</code>,
<code><a href="#topic+extractFDAFPCA">extractFDAFPCA</a>()</code>,
<code><a href="#topic+extractFDAFourier">extractFDAFourier</a>()</code>,
<code><a href="#topic+extractFDAMultiResFeatures">extractFDAMultiResFeatures</a>()</code>,
<code><a href="#topic+extractFDATsfeatures">extractFDATsfeatures</a>()</code>,
<code><a href="#topic+extractFDAWavelets">extractFDAWavelets</a>()</code>
</p>

<hr>
<h2 id='extractFDAFeatures'>Extract features from functional data.</h2><span id='topic+extractFDAFeatures'></span>

<h3>Description</h3>

<p>Extract non-functional features from functional features using various methods.
</p>
<p>The function <a href="#topic+extractFDAFeatures">extractFDAFeatures</a> performs the extraction for all functional features
via the methods specified in <code>feat.methods</code> and transforms all mentioned functional
(matrix) features into regular data.frame columns.
Additionally, a &ldquo;<code>extractFDAFeatDesc</code>&rdquo; object
which contains learned coefficients and other helpful data for
re-extraction during the predict-phase is returned. This can be used with
<a href="#topic+reextractFDAFeatures">reextractFDAFeatures</a> in order to extract features during the prediction phase.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDAFeatures(obj, target = character(0L), feat.methods = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDAFeatures_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="base.html#topic+data.frame">data.frame</a>)<br />
Task or data.frame to extract functional features from.
Must contain functional features as matrix columns.</p>
</td></tr>
<tr><td><code id="extractFDAFeatures_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Task target column. Only necessary for data.frames
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="extractFDAFeatures_+3A_feat.methods">feat.methods</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
List of functional features along with the desired methods for each functional feature.
&ldquo;all&rdquo; applies the <a href="#topic+extractFDAFeatures">extractFDAFeatures</a> method to each
functional feature.
Names of <code>feat.methods</code> must match column names of functional features.
Available feature extraction methods are available under family <code>fda_featextractor</code>.
Specifying a functional feature multiple times with different extraction methods allows
for the extraction of different features from the same functional.
Default is <code><a href="base.html#topic+list">list()</a></code> which does nothing.</p>
</td></tr>
<tr><td><code id="extractFDAFeatures_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further hyperparameters passed on to the <code>feat.methods</code> specified above.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The description object contains these slots:
</p>

<ul>
<li><p> target (<code>character</code>): See argument.
</p>
</li>
<li><p> coln (<code>character</code>): Colum names of data.
</p>
</li>
<li><p> fd.cols (<code>character</code>): Functional feature names.
</p>
</li>
<li><p> extractFDAFeat (<code>list</code>): Contains <code>feature.methods</code> and relevant
parameters for reextraction.
</p>
</li></ul>



<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>)
</p>

<ul>
<li><p> data | task (<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>): Extracted features, same type as obj.
</p>
</li>
<li><p> desc (<code>extracFDAFeatDesc</code>): Description object. See description for details.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other fda: 
<code><a href="#topic+makeExtractFDAFeatMethod">makeExtractFDAFeatMethod</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = data.frame(x = matrix(rnorm(24), ncol = 8), y = factor(c("a", "a", "b")))
fdf = makeFunctionalData(df, fd.features = list(x1 = 1:4, x2 = 5:8), exclude.cols = "y")
task = makeClassifTask(data = fdf, target = "y")
extracted = extractFDAFeatures(task,
  feat.methods = list("x1" = extractFDAFourier(), "x2" = extractFDAWavelets(filter = "haar")))
print(extracted$task)
reextractFDAFeatures(task, extracted$desc)
</code></pre>

<hr>
<h2 id='extractFDAFourier'>Fast Fourier transform features.</h2><span id='topic+extractFDAFourier'></span>

<h3>Description</h3>

<p>The function extracts features from functional data based on the fast fourier
transform. For more details refer to <a href="stats.html#topic+fft">stats::fft</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDAFourier(trafo.coeff = "phase")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDAFourier_+3A_trafo.coeff">trafo.coeff</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specifies which transformation of the complex frequency domain
representation should be calculated as a feature representation.
Must be one of &ldquo;amplitude&rdquo; or &ldquo;phase&rdquo;.
Default is &ldquo;phase&rdquo;.
The phase shift is returned in Rad, i.e. values lie in [-180, 180].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDABsignal">extractFDABsignal</a>()</code>,
<code><a href="#topic+extractFDADTWKernel">extractFDADTWKernel</a>()</code>,
<code><a href="#topic+extractFDAFPCA">extractFDAFPCA</a>()</code>,
<code><a href="#topic+extractFDAMultiResFeatures">extractFDAMultiResFeatures</a>()</code>,
<code><a href="#topic+extractFDATsfeatures">extractFDATsfeatures</a>()</code>,
<code><a href="#topic+extractFDAWavelets">extractFDAWavelets</a>()</code>
</p>

<hr>
<h2 id='extractFDAFPCA'>Extract functional principal component analysis features.</h2><span id='topic+extractFDAFPCA'></span>

<h3>Description</h3>

<p>The function extracts the functional principal components from a data.frame
containing functional features. Uses <code>stats::prcomp</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDAFPCA(rank. = NULL, center = TRUE, scale. = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDAFPCA_+3A_rank.">rank.</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of principal components to extract.
Default is <code>NULL</code></p>
</td></tr>
<tr><td><code id="extractFDAFPCA_+3A_center">center</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
Should data be centered before applying PCA?</p>
</td></tr>
<tr><td><code id="extractFDAFPCA_+3A_scale.">scale.</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
Should data be scaled before applying PCA?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDABsignal">extractFDABsignal</a>()</code>,
<code><a href="#topic+extractFDADTWKernel">extractFDADTWKernel</a>()</code>,
<code><a href="#topic+extractFDAFourier">extractFDAFourier</a>()</code>,
<code><a href="#topic+extractFDAMultiResFeatures">extractFDAMultiResFeatures</a>()</code>,
<code><a href="#topic+extractFDATsfeatures">extractFDATsfeatures</a>()</code>,
<code><a href="#topic+extractFDAWavelets">extractFDAWavelets</a>()</code>
</p>

<hr>
<h2 id='extractFDAMultiResFeatures'>Multiresolution feature extraction.</h2><span id='topic+extractFDAMultiResFeatures'></span>

<h3>Description</h3>

<p>The function extracts currently the mean of multiple segments of each curve and stacks them
as features. The segments length are set in a hierachy way so the features
cover different resolution levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDAMultiResFeatures(res.level = 3L, shift = 0.5, seg.lens = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDAMultiResFeatures_+3A_res.level">res.level</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of resolution hierachy, each length is divided by a factor of 2.</p>
</td></tr>
<tr><td><code id="extractFDAMultiResFeatures_+3A_shift">shift</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
The overlapping proportion when slide the window for one step.</p>
</td></tr>
<tr><td><code id="extractFDAMultiResFeatures_+3A_seg.lens">seg.lens</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Curve subsequence lengths. Needs to sum up to the length of the functional.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDABsignal">extractFDABsignal</a>()</code>,
<code><a href="#topic+extractFDADTWKernel">extractFDADTWKernel</a>()</code>,
<code><a href="#topic+extractFDAFPCA">extractFDAFPCA</a>()</code>,
<code><a href="#topic+extractFDAFourier">extractFDAFourier</a>()</code>,
<code><a href="#topic+extractFDATsfeatures">extractFDATsfeatures</a>()</code>,
<code><a href="#topic+extractFDAWavelets">extractFDAWavelets</a>()</code>
</p>

<hr>
<h2 id='extractFDATsfeatures'>Time-Series Feature Heuristics</h2><span id='topic+extractFDATsfeatures'></span>

<h3>Description</h3>

<p>The function extracts features from functional data based on known Heuristics.
For more details refer to <code><a href="tsfeatures.html#topic+tsfeatures">tsfeatures::tsfeatures()</a></code>.
Under the hood this function uses the package <code><a href="tsfeatures.html#topic+tsfeatures">tsfeatures::tsfeatures()</a></code>.
For more information see Hyndman, Wang and Laptev, Large-Scale Unusual Time Series Detection, ICDM 2015.
</p>
<p>Note: Currently computes the following features:<br />
&quot;frequency&quot;, &quot;stl_features&quot;, &quot;entropy&quot;, &quot;acf_features&quot;, &quot;arch_stat&quot;,
&quot;crossing_points&quot;, &quot;flat_spots&quot;, &quot;hurst&quot;,  &quot;holt_parameters&quot;, &quot;lumpiness&quot;,
&quot;max_kl_shift&quot;, &quot;max_var_shift&quot;, &quot;max_level_shift&quot;, &quot;stability&quot;, &quot;nonlinearity&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDATsfeatures(
  scale = TRUE,
  trim = FALSE,
  trim_amount = 0.1,
  parallel = FALSE,
  na.action = na.pass,
  feats = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDATsfeatures_+3A_scale">scale</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If TRUE, time series are scaled to mean 0 and sd 1 before features are computed.</p>
</td></tr>
<tr><td><code id="extractFDATsfeatures_+3A_trim">trim</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If TRUE, time series are trimmed by <code>trim_amount</code> before features are computed.
Values larger than trim_amount in absolute value are set to NA.</p>
</td></tr>
<tr><td><code id="extractFDATsfeatures_+3A_trim_amount">trim_amount</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Default level of trimming if <code>trim==TRUE</code>.</p>
</td></tr>
<tr><td><code id="extractFDATsfeatures_+3A_parallel">parallel</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code>, multiple cores (or multiple sessions) will be used.
This only speeds things up when there are a large number of time series.</p>
</td></tr>
<tr><td><code id="extractFDATsfeatures_+3A_na.action">na.action</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
A function to handle missing values. Use <code>na.interp</code> to estimate missing values</p>
</td></tr>
<tr><td><code id="extractFDATsfeatures_+3A_feats">feats</code></td>
<td>
<p>(<code>character</code>)<br />
A character vector of function names to apply to each time-series in order to extract features.<br />
Default:<br />
feats = c(&quot;frequency&quot;, &quot;stl_features&quot;, &quot;entropy&quot;, &quot;acf_features&quot;, &quot;arch_stat&quot;,
&quot;crossing_points&quot;, &quot;flat_spots&quot;, &quot;hurst&quot;,  &quot;holt_parameters&quot;, &quot;lumpiness&quot;,
&quot;max_kl_shift&quot;, &quot;max_var_shift&quot;, &quot;max_level_shift&quot;, &quot;stability&quot;, &quot;nonlinearity&quot;)</p>
</td></tr>
<tr><td><code id="extractFDATsfeatures_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further arguments passed on to the respective tsfeatures functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>)
</p>


<h3>References</h3>

<p>Hyndman, Wang and Laptev, Large-Scale Unusual Time Series Detection, ICDM 2015.
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDABsignal">extractFDABsignal</a>()</code>,
<code><a href="#topic+extractFDADTWKernel">extractFDADTWKernel</a>()</code>,
<code><a href="#topic+extractFDAFPCA">extractFDAFPCA</a>()</code>,
<code><a href="#topic+extractFDAFourier">extractFDAFourier</a>()</code>,
<code><a href="#topic+extractFDAMultiResFeatures">extractFDAMultiResFeatures</a>()</code>,
<code><a href="#topic+extractFDAWavelets">extractFDAWavelets</a>()</code>
</p>

<hr>
<h2 id='extractFDAWavelets'>Discrete Wavelet transform features.</h2><span id='topic+extractFDAWavelets'></span>

<h3>Description</h3>

<p>The function extracts discrete wavelet transform coefficients from the raw
functional data.
See <a href="wavelets.html#topic+dwt">wavelets::dwt</a> for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractFDAWavelets(filter = "la8", boundary = "periodic")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractFDAWavelets_+3A_filter">filter</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specifies which filter should be used.
Must be one of <code>d</code>|<code>la</code>|<code>bl</code>|<code>c</code> followed by an even
number for the level of the filter.
The level of the filter needs to be smaller or equal then the time-series length.
For more information and acceptable filters see <code>help(wt.filter)</code>.
Defaults to <code>la8</code>.</p>
</td></tr>
<tr><td><code id="extractFDAWavelets_+3A_boundary">boundary</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Boundary to be used.
&ldquo;periodic&rdquo; assumes circular time series,
for &ldquo;reflection&rdquo; the series is extended to twice its length.
Default is &ldquo;periodic&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other fda_featextractor: 
<code><a href="#topic+extractFDABsignal">extractFDABsignal</a>()</code>,
<code><a href="#topic+extractFDADTWKernel">extractFDADTWKernel</a>()</code>,
<code><a href="#topic+extractFDAFPCA">extractFDAFPCA</a>()</code>,
<code><a href="#topic+extractFDAFourier">extractFDAFourier</a>()</code>,
<code><a href="#topic+extractFDAMultiResFeatures">extractFDAMultiResFeatures</a>()</code>,
<code><a href="#topic+extractFDATsfeatures">extractFDATsfeatures</a>()</code>
</p>

<hr>
<h2 id='FailureModel'>Failure model.</h2><span id='topic+FailureModel'></span>

<h3>Description</h3>

<p>A subclass of <a href="#topic+WrappedModel">WrappedModel</a>. It is created
</p>

<ul>
<li><p> if you set the respective option in <a href="#topic+configureMlr">configureMlr</a> -
when a model internally crashed during training.
The model always predicts NAs.
</p>
</li></ul>

<p>The if mlr option <code>on.error.dump</code> is <code>TRUE</code>, the
<code>FailureModel</code> contains the debug trace of the error.
It can be accessed with <code>getFailureModelDump</code> and
inspected with <code>debugger</code>.
</p>
<p>Its encapsulated <code>learner.model</code> is simply a string:
The error message that was generated when the model crashed.
The following code shows how to access the message.
</p>


<h3>See Also</h3>

<p>Other debug: 
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+getPredictionDump">getPredictionDump</a>()</code>,
<code><a href="#topic+getRRDump">getRRDump</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>configureMlr(on.learner.error = "warn")
data = iris
data$newfeat = 1 # will make LDA crash
task = makeClassifTask(data = data, target = "Species")
m = train("classif.lda", task) # LDA crashed, but mlr catches this
print(m)
print(m$learner.model) # the error message
p = predict(m, task) # this will predict NAs
print(p)
print(performance(p))
configureMlr(on.learner.error = "stop")
</code></pre>

<hr>
<h2 id='FeatSelControl'>Create control structures for feature selection.</h2><span id='topic+FeatSelControl'></span><span id='topic+FeatSelControlExhaustive'></span><span id='topic+FeatSelControlRandom'></span><span id='topic+FeatSelControlSequential'></span><span id='topic+FeatSelControlGA'></span><span id='topic+makeFeatSelControlExhaustive'></span><span id='topic+makeFeatSelControlGA'></span><span id='topic+makeFeatSelControlRandom'></span><span id='topic+makeFeatSelControlSequential'></span>

<h3>Description</h3>

<p>Feature selection method used by <a href="#topic+selectFeatures">selectFeatures</a>.<br />
The methods used here follow a wrapper approach, described in
Kohavi and John (1997) (see references).
</p>
<p>The following optimization algorithms are available:
</p>

<dl>
<dt>FeatSelControlExhaustive</dt><dd><p>Exhaustive search. All feature sets (up to a certain number
of features <code>max.features</code>) are searched.</p>
</dd>
<dt>FeatSelControlRandom</dt><dd><p>Random search. Features vectors are randomly drawn,
up to a certain number of features <code>max.features</code>.
A feature is included in the current set with probability <code>prob</code>.
So we are basically drawing (0,1)-membership-vectors, where each element
is Bernoulli(<code>prob</code>) distributed.</p>
</dd>
<dt>FeatSelControlSequential</dt><dd><p>Deterministic forward or backward search. That means extending
(forward) or shrinking (backward) a feature set.
Depending on the given <code>method</code> different approaches are taken.<br />
<code>sfs</code> Sequential Forward Search: Starting from an empty model, in each step the feature increasing
the performance measure the most is added to the model.<br />
<code>sbs</code> Sequential Backward Search: Starting from a model with all features, in each step the feature
decreasing the performance measure the least is removed from the model.<br />
<code>sffs</code> Sequential Floating Forward Search: Starting from an empty model, in each step the algorithm
chooses the best model from all models with one additional feature and from all models with one
feature less.<br />
<code>sfbs</code> Sequential Floating Backward Search: Similar to <code>sffs</code> but starting with a full model.</p>
</dd>
<dt>FeatSelControlGA</dt><dd><p>Search via genetic algorithm.
The GA is a simple (<code>mu</code>, <code>lambda</code>) or (<code>mu</code> + <code>lambda</code>) algorithm,
depending on the <code>comma</code> setting.
A comma strategy selects a new population of size <code>mu</code> out of the
<code>lambda</code> &gt; <code>mu</code> offspring.
A plus strategy uses the joint pool of <code>mu</code> parents and <code>lambda</code> offspring
for selecting <code>mu</code> new candidates.
Out of those <code>mu</code> features, the new <code>lambda</code> features are generated
by randomly choosing pairs of parents. These are crossed over and <code>crossover.rate</code>
represents the probability of choosing a feature from the first parent instead of
the second parent.
The resulting offspring is mutated, i.e., its bits are flipped with
probability <code>mutation.rate</code>. If <code>max.features</code> is set, offspring are
repeatedly generated until the setting is satisfied.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>makeFeatSelControlExhaustive(
  same.resampling.instance = TRUE,
  maxit = NA_integer_,
  max.features = NA_integer_,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default"
)

makeFeatSelControlGA(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  maxit = NA_integer_,
  max.features = NA_integer_,
  comma = FALSE,
  mu = 10L,
  lambda,
  crossover.rate = 0.5,
  mutation.rate = 0.05,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default"
)

makeFeatSelControlRandom(
  same.resampling.instance = TRUE,
  maxit = 100L,
  max.features = NA_integer_,
  prob = 0.5,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default"
)

makeFeatSelControlSequential(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  method,
  alpha = 0.01,
  beta = -0.001,
  maxit = NA_integer_,
  max.features = NA_integer_,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FeatSelControl_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_maxit">maxit</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximal number of iterations. Note, that this is usually not equal to the number
of function evaluations.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_max.features">max.features</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximal number of features.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each feature set evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_comma">comma</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Parameter of the GA feature selection, indicating whether to use a (<code>mu</code>, <code>lambda</code>)
or (<code>mu</code> + <code>lambda</code>) GA. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_mu">mu</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Parameter of the GA feature selection. Size of the parent population.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_lambda">lambda</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Parameter of the GA feature selection. Size of the children population (should be smaller
or equal to <code>mu</code>).</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_crossover.rate">crossover.rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Parameter of the GA feature selection. Probability of choosing a bit from the first parent
within the crossover mutation.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_mutation.rate">mutation.rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Parameter of the GA feature selection. Probability of flipping a feature bit, i.e. switch
between selecting / deselecting a feature.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_prob">prob</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Parameter of the random feature selection. Probability of choosing a feature.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Parameter of the sequential feature selection. A character representing the method. Possible
values are <code>sfs</code> (forward search), <code>sbs</code> (backward search), <code>sffs</code>
(floating forward search) and <code>sfbs</code> (floating backward search).</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_alpha">alpha</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Parameter of the sequential feature selection.
Minimal required value of improvement difference for a forward / adding step.
Default is 0.01.</p>
</td></tr>
<tr><td><code id="FeatSelControl_+3A_beta">beta</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Parameter of the sequential feature selection.
Minimal required value of improvement difference for a backward / removing step.
Negative values imply that you allow a slight decrease for the removal of a feature.
Default is -0.001.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+FeatSelControl">FeatSelControl</a>). The specific subclass is one of
<a href="#topic+FeatSelControlExhaustive">FeatSelControlExhaustive</a>, <a href="#topic+FeatSelControlRandom">FeatSelControlRandom</a>,
<a href="#topic+FeatSelControlSequential">FeatSelControlSequential</a>, <a href="#topic+FeatSelControlGA">FeatSelControlGA</a>.
</p>


<h3>References</h3>

<p>Ron Kohavi and George H. John,
Wrappers for feature subset selection, Artificial Intelligence Volume 97, 1997, 273-324.
<a href="http://ai.stanford.edu/~ronnyk/wrappersPrint.pdf">http://ai.stanford.edu/~ronnyk/wrappersPrint.pdf</a>.<br />
</p>


<h3>See Also</h3>

<p>Other featsel: 
<code><a href="#topic+analyzeFeatSelResult">analyzeFeatSelResult</a>()</code>,
<code><a href="#topic+getFeatSelResult">getFeatSelResult</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+selectFeatures">selectFeatures</a>()</code>
</p>

<hr>
<h2 id='FeatSelResult'>Result of feature selection.</h2><span id='topic+FeatSelResult'></span>

<h3>Description</h3>

<p>Container for results of feature selection.
Contains the obtained features, their performance values
and the optimization path which lead there.  <br />
You can visualize it using <a href="#topic+analyzeFeatSelResult">analyzeFeatSelResult</a>.
</p>


<h3>Details</h3>

<p>Object members:
</p>

<dl>
<dt>learner (<a href="#topic+Learner">Learner</a>)</dt><dd><p>Learner that was optimized.</p>
</dd>
<dt>control (<a href="#topic+FeatSelControl">FeatSelControl</a>)</dt><dd><p> Control object from feature selection.</p>
</dd>
<dt>x (<a href="base.html#topic+character">character</a>)</dt><dd><p>Vector of feature names identified as optimal.</p>
</dd>
<dt>y (<a href="base.html#topic+numeric">numeric</a>)</dt><dd><p>Performance values for optimal <code>x</code>.</p>
</dd>
<dt>threshold (<a href="base.html#topic+numeric">numeric</a>)</dt><dd><p>Vector of finally found and used thresholds
if <code>tune.threshold</code> was enabled in <a href="#topic+FeatSelControl">FeatSelControl</a>, otherwise not present and
hence <code>NULL</code>.</p>
</dd>
<dt>opt.path (<a href="ParamHelpers.html#topic+OptPath">ParamHelpers::OptPath</a>)</dt><dd><p>Optimization path which lead to <code>x</code>.</p>
</dd>
</dl>


<hr>
<h2 id='filterFeatures'>Filter features by thresholding filter values.</h2><span id='topic+filterFeatures'></span>

<h3>Description</h3>

<p>First, calls <a href="#topic+generateFilterValuesData">generateFilterValuesData</a>.
Features are then selected via <code>select</code> and <code>val</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filterFeatures(
  task,
  method = "FSelectorRcpp_information.gain",
  fval = NULL,
  perc = NULL,
  abs = NULL,
  threshold = NULL,
  fun = NULL,
  fun.args = NULL,
  mandatory.feat = NULL,
  select.method = NULL,
  base.methods = NULL,
  cache = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filterFeatures_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
See <a href="#topic+listFilterMethods">listFilterMethods</a>.
Default is &ldquo;FSelectorRcpp_information.gain&rdquo;.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_fval">fval</code></td>
<td>
<p>(<a href="#topic+FilterValues">FilterValues</a>)<br />
Result of <a href="#topic+generateFilterValuesData">generateFilterValuesData</a>.
If you pass this, the filter values in the object are used for feature
filtering.
<code>method</code> and <code>...</code> are ignored then.
Default is <code>NULL</code> and not used.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_perc">perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If set, select <code>perc</code>*100 top scoring features.
<code>perc = 1</code> means to select all features.<code style="white-space: pre;">&#8288;Mutually exclusive with arguments&#8288;</code>abs<code style="white-space: pre;">&#8288;, &#8288;</code>threshold<code>and</code>fun'.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_abs">abs</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If set, select <code>abs</code> top scoring features.
Mutually exclusive with arguments <code>perc</code>, <code>threshold</code> and <code>fun</code>.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_threshold">threshold</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If set, select features whose score exceeds <code>threshold</code>.
Mutually exclusive with arguments <code>perc</code>, <code>abs</code> and <code>fun</code>.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_fun">fun</code></td>
<td>
<p>(<code>function</code>)<br />
If set, select features via a custom thresholding function, which must
return the number of top scoring features to select. Mutually exclusive
with arguments <code>perc</code>, <code>abs</code> and <code>threshold</code>.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_fun.args">fun.args</code></td>
<td>
<p>(any)<br />
Arguments passed to the custom thresholding function.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_mandatory.feat">mandatory.feat</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Mandatory features which are always included regardless of their scores</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_select.method">select.method</code></td>
<td>
<p>If multiple methods are supplied in argument <code>method</code>,
specify the method that is used for the final subsetting.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_base.methods">base.methods</code></td>
<td>
<p>If <code>method</code> is an ensemble filter, specify the base
filter methods which the ensemble method will use.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_cache">cache</code></td>
<td>
<p>(<code>character(1)</code> | <a href="base.html#topic+logical">logical</a>)<br />
Whether to use caching during filter value creation. See details.</p>
</td></tr>
<tr><td><code id="filterFeatures_+3A_...">...</code></td>
<td>
<p>(any)<br />
Passed down to selected filter method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Task">Task</a>.
</p>


<h3>Caching</h3>

<p>If <code>cache = TRUE</code>, the default mlr cache directory is used to cache
filter values. The directory is operating system dependent and can be
checked with <code>getCacheDir()</code>.<br />
The default cache can be cleared with <code>deleteCacheDir()</code>.
Alternatively, a custom directory can be passed to store the cache.
</p>
<p>Note that caching is not thread safe. It will work for parallel
computation on many systems, but there is no guarantee.
</p>


<h3>Simple and ensemble filters</h3>

<p>Besides passing (multiple) simple filter methods you can also pass an
ensemble filter method (in a list). The ensemble method will use the simple
methods to calculate its ranking. See <code>listFilterEnsembleMethods()</code> for
available ensemble methods.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># simple filter
filterFeatures(iris.task, method = "FSelectorRcpp_gain.ratio", abs = 2)
# ensemble filter
filterFeatures(iris.task, method = "E-min",
  base.methods = c("FSelectorRcpp_gain.ratio",
    "FSelectorRcpp_information.gain"), abs = 2)
</code></pre>

<hr>
<h2 id='friedmanPostHocTestBMR'>Perform a posthoc Friedman-Nemenyi test.</h2><span id='topic+friedmanPostHocTestBMR'></span>

<h3>Description</h3>

<p>Performs a <a href="PMCMRplus.html#topic+frdAllPairsNemenyiTest">PMCMRplus::frdAllPairsNemenyiTest</a> for a
<a href="#topic+BenchmarkResult">BenchmarkResult</a> and a selected measure.
</p>
<p>This means <em>all pairwise comparisons</em> of <code>learners</code> are performed. The null
hypothesis of the post hoc test is that each pair of learners is equal. If
the null hypothesis of the included ad hoc <a href="stats.html#topic+friedman.test">stats::friedman.test</a> can be
rejected an object of class <code>pairwise.htest</code> is returned. If not, the
function returns the corresponding <a href="stats.html#topic+friedman.test">friedman.test</a>.
</p>
<p>Note that benchmark results for at least two learners on at least two tasks
are required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>friedmanPostHocTestBMR(
  bmr,
  measure = NULL,
  p.value = 0.05,
  aggregation = "default"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="friedmanPostHocTestBMR_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="friedmanPostHocTestBMR_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="friedmanPostHocTestBMR_+3A_p.value">p.value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
p-value for the tests. Default: 0.05</p>
</td></tr>
<tr><td><code id="friedmanPostHocTestBMR_+3A_aggregation">aggregation</code></td>
<td>
<p>(<code>character(1)</code>) <br />
&ldquo;mean&rdquo; or &ldquo;default&rdquo;. See <a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>
for details on &ldquo;default&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>pairwise.htest</code>): See <a href="PMCMRplus.html#topic+frdAllPairsNemenyiTest">PMCMRplus::frdAllPairsNemenyiTest</a> for
details.
Additionally two components are added to the list:
</p>

<ul>
<li><p> f.rejnull (<code>logical(1)</code>):<br /> Whether the according friedman.test rejects
the Null hypothesis at the selected p.value
</p>
</li>
<li><p> crit.difference (<code>list(2)</code>):<br /> Minimal difference the mean ranks of two
learners need to have in order to be significantly different
</p>
</li></ul>



<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='friedmanTestBMR'>Perform overall Friedman test for a BenchmarkResult.</h2><span id='topic+friedmanTestBMR'></span>

<h3>Description</h3>

<p>Performs a <a href="stats.html#topic+friedman.test">stats::friedman.test</a> for a selected measure.
The null hypothesis is that apart from an effect of the different
(<a href="#topic+Task">Task</a>), the location parameter (aggregated performance measure)
is the same for each <a href="#topic+Learner">Learner</a>.
Note that benchmark results for at least two learners on at least two tasks
are required.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>friedmanTestBMR(bmr, measure = NULL, aggregation = "default")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="friedmanTestBMR_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="friedmanTestBMR_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="friedmanTestBMR_+3A_aggregation">aggregation</code></td>
<td>
<p>(<code>character(1)</code>) <br />
&ldquo;mean&rdquo; or &ldquo;default&rdquo;. See <a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>
for details on &ldquo;default&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>htest</code>): See <a href="stats.html#topic+friedman.test">stats::friedman.test</a> for details.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='fuelsubset.task'>FuelSubset functional data regression task.</h2><span id='topic+fuelsubset.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>fuelsubset.task</code>).
2 functional covariates and 1 scalar covariate.
You have to predict the heat value of some fuel based on the
ultraviolet radiation spectrum and infrared ray radiation and one scalar
column called h2o.
</p>


<h3>Details</h3>

<p>The features and grids are scaled in the same way as in <a href="FDboost.html#topic+FDboost">FDboost::FDboost</a>.
</p>


<h3>References</h3>

<p>See Brockhaus, S., Scheipl, F., Hothorn, T., &amp; Greven, S. (2015). The functional linear array model. Statistical Modelling, 15(3), 279300.
</p>

<hr>
<h2 id='generateCalibrationData'>Generate classifier calibration data.</h2><span id='topic+generateCalibrationData'></span><span id='topic+CalibrationData'></span>

<h3>Description</h3>

<p>A calibrated classifier is one where the predicted probability of a class closely matches the
rate at which that class occurs, e.g. for data points which are assigned a predicted probability
of class A of .8, approximately 80 percent of such points should belong to class A if the classifier
is well calibrated. This is estimated empirically by grouping data points with similar predicted
probabilities for each class, and plotting the rate of each class within each bin against the
predicted probability bins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateCalibrationData(obj, breaks = "Sturges", groups = NULL, task.id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateCalibrationData_+3A_obj">obj</code></td>
<td>
<p>(list of <a href="#topic+Prediction">Prediction</a> | list of <a href="#topic+ResampleResult">ResampleResult</a> | <a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Single prediction object, list of them, single resample result, list of them, or a benchmark result.
In case of a list probably produced by different learners you want to compare, then
name the list with the names you want to see in the plots, probably
learner shortnames or ids.</p>
</td></tr>
<tr><td><code id="generateCalibrationData_+3A_breaks">breaks</code></td>
<td>
<p>(<code>character(1)</code> | <a href="base.html#topic+numeric">numeric</a>)<br />
If <code>character(1)</code>, the algorithm to use in generating probability bins.
See <a href="graphics.html#topic+hist">hist</a> for details.
If <a href="base.html#topic+numeric">numeric</a>, the cut points for the bins.
Default is &ldquo;Sturges&rdquo;.</p>
</td></tr>
<tr><td><code id="generateCalibrationData_+3A_groups">groups</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of bins to construct.
If specified, <code>breaks</code> is ignored.
Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="generateCalibrationData_+3A_task.id">task.id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Selected task in <a href="#topic+BenchmarkResult">BenchmarkResult</a> to do plots for, ignored otherwise.
Default is first task.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+CalibrationData">CalibrationData</a>. A <a href="base.html#topic+list">list</a> containing:
</p>
<table>
<tr><td><code>proportion</code></td>
<td>
<p><a href="base.html#topic+data.frame">data.frame</a> with columns:
</p>

<ul>
<li> <p><code>Learner</code> Name of learner.
</p>
</li>
<li> <p><code>bin</code> Bins calculated according to the <code>breaks</code> or <code>groups</code> argument.
</p>
</li>
<li> <p><code>Class</code> Class labels (for binary classification only the positive class).
</p>
</li>
<li> <p><code>Proportion</code> Proportion of observations from class <code>Class</code> among all
observations with posterior probabilities of class <code>Class</code> within the
interval given in <code>bin</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p><a href="base.html#topic+data.frame">data.frame</a> with columns:
</p>

<ul>
<li> <p><code>Learner</code> Name of learner.
</p>
</li>
<li> <p><code>truth</code> True class label.
</p>
</li>
<li> <p><code>Class</code> Class labels (for binary classification only the positive class).
</p>
</li>
<li> <p><code>Probability</code> Predicted posterior probability of <code>Class</code>.
</p>
</li>
<li> <p><code>bin</code> Bin corresponding to <code>Probability</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code>task</code></td>
<td>
<p>(<a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task description.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Vuk, Miha, and Curk, Tomaz. &ldquo;ROC Curve, Lift Chart, and Calibration Plot.&rdquo; Metodoloski zvezki. Vol. 3. No. 1 (2006): 89-108.
</p>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>
<p>Other calibration: 
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>
</p>

<hr>
<h2 id='generateCritDifferencesData'>Generate data for critical-differences plot.</h2><span id='topic+generateCritDifferencesData'></span>

<h3>Description</h3>

<p>Generates data that can be used to plot a
critical differences plot. Computes the critical differences according
to either the
<code>"Bonferroni-Dunn"</code> test or the <code>"Nemenyi"</code> test.<br />
<code>"Bonferroni-Dunn"</code> usually yields higher power as it does not
compare all algorithms to each other, but all algorithms to a
<code>baseline</code> instead. <br />
Learners are drawn on the y-axis according to their average rank. <br />
For <code>test = "nemenyi"</code> a bar is drawn, connecting all groups of not
significantly different learners.<br />
For <code>test = "bd"</code> an interval is drawn arround the algorithm selected
as a baseline. All learners within this interval are not signifcantly different
from the baseline. <br />
Calculation:
</p>
<p style="text-align: center;"><code class="reqn">CD = q_{\alpha} \sqrt{\left(\frac{k(k+1)}{6N}\right)}</code>
</p>
 <p><br />
Where <code class="reqn">q_\alpha</code> is based on the studentized range statistic.
See references for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateCritDifferencesData(
  bmr,
  measure = NULL,
  p.value = 0.05,
  baseline = NULL,
  test = "bd"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateCritDifferencesData_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="generateCritDifferencesData_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="generateCritDifferencesData_+3A_p.value">p.value</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
P-value for the critical difference. Default: 0.05</p>
</td></tr>
<tr><td><code id="generateCritDifferencesData_+3A_baseline">baseline</code></td>
<td>
<p>(<code>character(1)</code>): (<code>learner.id</code>) <br />
Select a <code>learner.id</code> as baseline for the <code>test = "bd"</code>
(&quot;Bonferroni-Dunn&quot;) critical differences
diagram. The critical difference interval will then be positioned arround this learner.
Defaults to best performing algorithm. <br />
For <code>test = "nemenyi"</code>, no baseline is needed as it performs <em>all pairwise
comparisons</em>.</p>
</td></tr>
<tr><td><code id="generateCritDifferencesData_+3A_test">test</code></td>
<td>
<p>(<code>character(1)</code>) <br />
Test for which the critical differences are computed. <br />
&ldquo;bd&rdquo; for the Bonferroni-Dunn Test, which is comparing all
classifiers to a <code>baseline</code>, thus performing a comparison
of one classifier to all others. <br />
Algorithms not connected by a single line are statistically different
from the baseline. <br />
&ldquo;nemenyi&rdquo; for the <a href="PMCMRplus.html#topic+frdAllPairsNemenyiTest">PMCMRplus::frdAllPairsNemenyiTest</a>
which is comparing all classifiers to each other. The null hypothesis that
there is a difference between the classifiers can not be rejected for all
classifiers that have a single grey bar connecting them.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>critDifferencesData</code>). List containing:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p>(data.frame) containing the info for the descriptive
part of the plot</p>
</td></tr>
<tr><td><code>friedman.nemenyi.test</code></td>
<td>
<p>(list) of class <code>pairwise.htest</code> <br />
contains the calculated
<a href="PMCMRplus.html#topic+frdAllPairsNemenyiTest">PMCMRplus::frdAllPairsNemenyiTest</a></p>
</td></tr>
<tr><td><code>cd.info</code></td>
<td>
<p>(list) containing info on the critical difference
and its positioning</p>
</td></tr>
<tr><td><code>baseline</code></td>
<td>
<p><code>baseline</code> chosen for plotting</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p.value used for the <a href="PMCMRplus.html#topic+frdAllPairsNemenyiTest">PMCMRplus::frdAllPairsNemenyiTest</a>
and for computation of the critical difference</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>
<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='generateFeatureImportanceData'>Generate feature importance.</h2><span id='topic+generateFeatureImportanceData'></span><span id='topic+FeatureImportanceData'></span>

<h3>Description</h3>

<p>Estimate how important individual features or groups of features are by contrasting prediction performances. For method &ldquo;permutation.importance&rdquo; compute the change in performance from permuting the values of a feature (or a group of features) and compare that to the predictions made on the unmcuted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateFeatureImportanceData(
  task,
  method = "permutation.importance",
  learner,
  features = getTaskFeatureNames(task),
  interaction = FALSE,
  measure,
  contrast = function(x, y) x - y,
  aggregation = mean,
  nmc = 50L,
  replace = TRUE,
  local = FALSE,
  show.info = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateFeatureImportanceData_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The method used to compute the feature importance.
The only method available is &ldquo;permutation.importance&rdquo;.
Default is &ldquo;permutation.importance&rdquo;.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
The features to compute the importance of.
The default is all of the features contained in the <a href="#topic+Task">Task</a>.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_interaction">interaction</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to compute the importance of the <code>features</code> argument jointly.
For <code>method = "permutation.importance"</code> this entails permuting the values of
all <code>features</code> together and then contrasting the performance with that of
the performance without the features being permuted.
The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_contrast">contrast</code></td>
<td>
<p>(<code>function</code>)<br />
A difference function that takes a numeric vector and returns a numeric vector
of the same length.
The default is element-wise difference between the vectors.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_aggregation">aggregation</code></td>
<td>
<p>(<code>function</code>)<br />
A function which aggregates the differences.
This function must take a numeric vector and return a numeric vector of length 1.
The default is <code>mean</code>.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_nmc">nmc</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of Monte-Carlo iterations to use in computing the feature importance.
If <code>nmc == -1</code> and <code>method = "permutation.importance"</code> then all
permutations of the <code>features</code> are used.
The default is 50.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_replace">replace</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not to sample the feature values with or without replacement.
The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_local">local</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to compute the per-observation importance.
The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generateFeatureImportanceData_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether progress output (feature name, time elapsed) should be displayed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>FeatureImportance</code>). A named list which contains the computed feature importance and the input arguments.
</p>
<p>Object members:
</p>
<table>
<tr><td><code>res</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Has columns for each feature or combination of features (colon separated) for which the importance is computed.
A row coresponds to importance of the feature specified in the column for the target.
</p>
</td></tr>
<tr><td><code>interaction</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not the importance of the <code>features</code> was computed jointly rather than individually.
</p>
</td></tr>
<tr><td><code>measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)</p>
</td></tr></table>
<p><br />
The measure used to compute performance.
</p>
<table>
<tr><td><code>contrast</code></td>
<td>
<p>(<code>function</code>)<br />
The function used to compare the performance of predictions.
</p>
</td></tr>
<tr><td><code>aggregation</code></td>
<td>
<p>(<code>function</code>)<br />
The function which is used to aggregate the contrast between the performance of predictions across Monte-Carlo iterations.
</p>
</td></tr>
<tr><td><code>replace</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not, when <code>method = "permutation.importance"</code>, the feature values
are sampled with replacement.
</p>
</td></tr>
<tr><td><code>nmc</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of Monte-Carlo iterations used to compute the feature importance.
When <code>nmc == -1</code> and <code>method = "permutation.importance"</code> all permutations are used.
</p>
</td></tr>
<tr><td><code>local</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether observation-specific importance is computed for the <code>features</code>.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jerome Friedman; Greedy Function Approximation: A Gradient Boosting Machine, Annals of Statistics, Vol. 29, No. 5 (Oct., 2001), pp. 1189-1232.
</p>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
lrn = makeLearner("classif.rpart", predict.type = "prob")
fit = train(lrn, iris.task)
imp = generateFeatureImportanceData(iris.task, "permutation.importance",
  lrn, "Petal.Width", nmc = 10L, local = TRUE)
</code></pre>

<hr>
<h2 id='generateFilterValuesData'>Calculates feature filter values.</h2><span id='topic+generateFilterValuesData'></span><span id='topic+FilterValues'></span>

<h3>Description</h3>

<p>Calculates numerical filter values for features.
For a list of features, use <a href="#topic+listFilterMethods">listFilterMethods</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateFilterValuesData(
  task,
  method = "FSelectorRcpp_information.gain",
  nselect = getTaskNFeats(task),
  ...,
  more.args = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateFilterValuesData_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="generateFilterValuesData_+3A_method">method</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a> | <a href="base.html#topic+list">list</a>)<br />
Filter method(s).
In case of ensemble filters the <code>list</code> notation needs to be used.
See the examples for more information.
Default is &ldquo;FSelectorRcpp_information.gain&rdquo;.</p>
</td></tr>
<tr><td><code id="generateFilterValuesData_+3A_nselect">nselect</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of scores to request. Scores are getting calculated for all features
per default.</p>
</td></tr>
<tr><td><code id="generateFilterValuesData_+3A_...">...</code></td>
<td>
<p>(any)<br />
Passed down to selected method. Can only be use if <code>method</code> contains one
element.</p>
</td></tr>
<tr><td><code id="generateFilterValuesData_+3A_more.args">more.args</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
Extra args passed down to filter methods. List elements are named with the
filter <code>method</code> name the args should be passed down to.
A more general and flexible option than <code>...</code>.
Default is empty list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+FilterValues">FilterValues</a>). A <code>list</code> containing:
</p>
<table>
<tr><td><code>task.desc</code></td>
<td>
<p>[<a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task description.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>(<code>data.frame</code>) with columns:
</p>

<ul>
<li> <p><code>name</code>(<a href="base.html#topic+character">character</a>)<br />
Name of feature.
</p>
</li>
<li> <p><code>type</code>(<a href="base.html#topic+character">character</a>)<br />
Feature column type.
</p>
</li>
<li> <p><code>method</code>(<a href="base.html#topic+numeric">numeric</a>)<br />
One column for each method with the feature importance values.
</p>
</li></ul>
</td></tr>
</table>


<h3>Simple and ensemble filters</h3>

<p>Besides passing (multiple) simple filter methods you can also pass an
ensemble filter method (in a list). The ensemble method will use the simple
methods to calculate its ranking. See <code>listFilterEnsembleMethods()</code> for
available ensemble methods.
</p>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>
<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># two simple filter methods
fval = generateFilterValuesData(iris.task,
  method = c("FSelectorRcpp_gain.ratio", "FSelectorRcpp_information.gain"))
# using ensemble method "E-mean"
fval = generateFilterValuesData(iris.task,
  method = list("E-mean", c("FSelectorRcpp_gain.ratio",
    "FSelectorRcpp_information.gain")))
</code></pre>

<hr>
<h2 id='generateHyperParsEffectData'>Generate hyperparameter effect data.</h2><span id='topic+generateHyperParsEffectData'></span>

<h3>Description</h3>

<p>Generate cleaned hyperparameter effect data from a tuning result or from a
nested cross-validation tuning result. The object returned can be used for
custom visualization or passed downstream to an out of the box mlr method,
<a href="#topic+plotHyperParsEffect">plotHyperParsEffect</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateHyperParsEffectData(
  tune.result,
  include.diagnostics = FALSE,
  trafo = FALSE,
  partial.dep = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateHyperParsEffectData_+3A_tune.result">tune.result</code></td>
<td>
<p>(<a href="#topic+TuneResult">TuneResult</a> | <a href="#topic+ResampleResult">ResampleResult</a>)<br />
Result of <a href="#topic+tuneParams">tuneParams</a> (or <a href="#topic+resample">resample</a> ONLY when used
for nested cross-validation). The tuning result (or results if the
output is from nested cross-validation), also containing the
optimizer results. If nested CV output is passed, each element in the list
will be considered a separate run, and the data from each run will be
included in the dataframe within the returned <code>HyperParsEffectData</code>.</p>
</td></tr>
<tr><td><code id="generateHyperParsEffectData_+3A_include.diagnostics">include.diagnostics</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should diagnostic info (eol and error msg) be included?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generateHyperParsEffectData_+3A_trafo">trafo</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the units of the hyperparameter path be converted to the
transformed scale? This is only useful when trafo was used to create the
path.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generateHyperParsEffectData_+3A_partial.dep">partial.dep</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should partial dependence be requested based on converting to reg task? This
sets a flag so that we know to use partial dependence downstream. This
should most likely be set to <code>TRUE</code> if 2 or more hyperparameters were
tuned simultaneously. Partial dependence should always be requested when
more than 2 hyperparameters were tuned simultaneously. Setting to
<code>TRUE</code> will cause <a href="#topic+plotHyperParsEffect">plotHyperParsEffect</a> to automatically
plot partial dependence when called downstream.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>HyperParsEffectData</code>)
Object containing the hyperparameter effects dataframe, the tuning
performance measures used, the hyperparameters used, a flag for including
diagnostic info, a flag for whether nested cv was used, a flag for whether
partial dependence should be generated, and the optimization algorithm used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# 3-fold cross validation
ps = makeParamSet(makeDiscreteParam("C", values = 2^(-4:4)))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)
res = tuneParams("classif.ksvm", task = pid.task, resampling = rdesc,
  par.set = ps, control = ctrl)
data = generateHyperParsEffectData(res)
plt = plotHyperParsEffect(data, x = "C", y = "mmce.test.mean")
plt + ylab("Misclassification Error")

# nested cross validation
ps = makeParamSet(makeDiscreteParam("C", values = 2^(-4:4)))
ctrl = makeTuneControlGrid()
rdesc = makeResampleDesc("CV", iters = 3L)
lrn = makeTuneWrapper("classif.ksvm", control = ctrl,
  resampling = rdesc, par.set = ps)
res = resample(lrn, task = pid.task, resampling = cv2,
  extract = getTuneResult)
data = generateHyperParsEffectData(res)
plotHyperParsEffect(data, x = "C", y = "mmce.test.mean", plot.type = "line")

## End(Not run)
</code></pre>

<hr>
<h2 id='generateLearningCurveData'>Generates a learning curve.</h2><span id='topic+generateLearningCurveData'></span><span id='topic+LearningCurveData'></span>

<h3>Description</h3>

<p>Observe how the performance changes with an increasing number of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateLearningCurveData(
  learners,
  task,
  resampling = NULL,
  percs = seq(0.1, 1, by = 0.1),
  measures,
  stratify = FALSE,
  show.info = getMlrOption("show.info")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateLearningCurveData_+3A_learners">learners</code></td>
<td>
<p>[(list of) <a href="#topic+Learner">Learner</a>)<br />
Learning algorithms which should be compared.</p>
</td></tr>
<tr><td><code id="generateLearningCurveData_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="generateLearningCurveData_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleDesc">ResampleDesc</a> | <a href="#topic+ResampleInstance">ResampleInstance</a>)<br />
Resampling strategy to evaluate the performance measure.
If no strategy is given a default &quot;Holdout&quot; will be performed.</p>
</td></tr>
<tr><td><code id="generateLearningCurveData_+3A_percs">percs</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Vector of percentages to be drawn from the training split.
These values represent the x-axis.
Internally <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used in combination with <a href="#topic+benchmark">benchmark</a>.
Thus for each percentage a different set of observations is drawn resulting in noisy performance measures as the quality of the sample can differ.</p>
</td></tr>
<tr><td><code id="generateLearningCurveData_+3A_measures">measures</code></td>
<td>
<p>[(list of) <a href="#topic+Measure">Measure</a>)<br />
Performance measures to generate learning curves for, representing the y-axis.</p>
</td></tr>
<tr><td><code id="generateLearningCurveData_+3A_stratify">stratify</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Only for classification:
Should the downsampled data be stratified according to the target classes?</p>
</td></tr>
<tr><td><code id="generateLearningCurveData_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+LearningCurveData">LearningCurveData</a>). A <code>list</code> containing:
</p>

<ul>
<li><p> The <a href="#topic+Task">Task</a>
</p>
</li>
<li><p> List of <a href="#topic+Measure">Measure</a>)<br />
Performance measures
</p>
</li>
<li><p> data (<a href="base.html#topic+data.frame">data.frame</a>) with columns:
</p>

<ul>
<li> <p><code>learner</code> Names of learners.
</p>
</li>
<li> <p><code>percentage</code> Percentages drawn from the training split.
</p>
</li>
<li><p> One column for each <a href="#topic+Measure">Measure</a> passed to <a href="#topic+generateLearningCurveData">generateLearningCurveData</a>.
</p>
</li></ul>

</li></ul>



<h3>See Also</h3>

<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>
<p>Other learning_curve: 
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>r = generateLearningCurveData(list("classif.rpart", "classif.knn"),
  task = sonar.task, percs = seq(0.2, 1, by = 0.2),
  measures = list(tp, fp, tn, fn),
  resampling = makeResampleDesc(method = "Subsample", iters = 5),
  show.info = FALSE)
plotLearningCurve(r)
</code></pre>

<hr>
<h2 id='generatePartialDependenceData'>Generate partial dependence.</h2><span id='topic+generatePartialDependenceData'></span><span id='topic+PartialDependenceData'></span>

<h3>Description</h3>

<p>Estimate how the learned prediction function is affected by one or more features.
For a learned function f(x) where x is partitioned into x_s and x_c, the partial dependence of
f on x_s can be summarized by averaging over x_c and setting x_s to a range of values of interest,
estimating E_(x_c)(f(x_s, x_c)). The conditional expectation of f at observation i is estimated similarly.
Additionally, partial derivatives of the marginalized function w.r.t. the features can be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generatePartialDependenceData(
  obj,
  input,
  features = NULL,
  interaction = FALSE,
  derivative = FALSE,
  individual = FALSE,
  fun = mean,
  bounds = c(qnorm(0.025), qnorm(0.975)),
  uniform = TRUE,
  n = c(10, NA),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generatePartialDependenceData_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Result of <a href="#topic+train">train</a>.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_input">input</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_features">features</code></td>
<td>
<p><a href="base.html#topic+character">character</a><br />
A vector of feature names contained in the training data.
If not specified all features in the <code>input</code> will be used.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_interaction">interaction</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether the <code>features</code> should be interacted or not. If <code>TRUE</code> then the Cartesian product of the
prediction grid for each feature is taken, and the partial dependence at each unique combination of
values of the features is estimated. Note that if the length of <code>features</code> is greater than two,
<a href="#topic+plotPartialDependence">plotPartialDependence</a> cannot be used.
If <code>FALSE</code> each feature is considered separately. In this case <code>features</code> can be much longer
than two.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_derivative">derivative</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not the partial derivative of the learned function with respect to the features should be
estimated. If <code>TRUE</code> <code>interaction</code> must be <code>FALSE</code>. The partial derivative of individual
observations may be estimated. Note that computation time increases as the learned prediction function
is evaluated at <code>gridsize</code> points * the number of points required to estimate the partial derivative.
Additional arguments may be passed to <a href="numDeriv.html#topic+grad">numDeriv::grad</a> (for regression or survival tasks) or
<a href="numDeriv.html#topic+jacobian">numDeriv::jacobian</a> (for classification tasks). Note that functions which are not smooth may
result in estimated derivatives of 0 (for points where the function does not change within +/- epsilon)
or estimates trending towards +/- infinity (at discontinuities).
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_individual">individual</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to plot the individual conditional expectation curves rather than the aggregated curve, i.e.,
rather than aggregating (using <code>fun</code>) the partial dependences of <code>features</code>, plot the
partial dependences of all observations in <code>data</code> across all values of the <code>features</code>.
The algorithm is developed in Goldstein, Kapelner, Bleich, and Pitkin (2015).
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_fun">fun</code></td>
<td>
<p><code>function</code><br />
</p>
<p>A function which operates on the output on the predictions made on the <code>input</code> data. For regression
this means a numeric vector, and, e.g., for a multiclass classification problem, this migh instead be probabilities
which are returned as a numeric matrix. This argument can return vectors of arbitrary length, however,
if their length is greater than one, they must by named, e.g., <code>fun = mean</code> or
<code>fun = function(x) c("mean" = mean(x), "variance" = var(x))</code>.
The default is the mean, unless <code>obj</code> is classification with <code>predict.type = "response"</code>
in which case the default is the proportion of observations predicted to be in each class.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_bounds">bounds</code></td>
<td>
<p>(<code>numeric(2)</code>)<br />
The value (lower, upper) the estimated standard error is multiplied by to estimate the bound on a
confidence region for a partial dependence. Ignored if <code>predict.type != "se"</code> for the learner.
Default is the 2.5 and 97.5 quantiles (-1.96, 1.96) of the Gaussian distribution.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_uniform">uniform</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not the prediction grid for the <code>features</code> is a uniform grid of size <code>n[1]</code> or sampled with
replacement from the <code>input</code>.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_n">n</code></td>
<td>
<p>(<code>integer21</code>)<br />
The first element of <code>n</code> gives the size of the prediction grid created for each feature.
The second element of <code>n</code> gives the size of the sample to be drawn without replacement from the <code>input</code> data.
Setting <code>n[2]</code> less than the number of rows in the <code>input</code> will decrease computation time.
The default for <code>n[1]</code> is 10, and the default for <code>n[2]</code> is the number of rows in the <code>input</code>.</p>
</td></tr>
<tr><td><code id="generatePartialDependenceData_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <a href="mmpf.html#topic+marginalPrediction">mmpf::marginalPrediction</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+PartialDependenceData">PartialDependenceData</a>. A named list, which contains the partial dependence,
input data, target, features, task description, and other arguments controlling the type of
partial dependences made.
</p>
<p>Object members:
</p>
<table>
<tr><td><code>data</code></td>
<td>
<p><a href="base.html#topic+data.frame">data.frame</a><br />
Has columns for the prediction: one column for regression and
survival analysis, and a column for class and the predicted probability for classification as well
as a a column for each element of <code>features</code>. If <code>individual = TRUE</code> then there is an
additional column <code>idx</code> which gives the index of the <code>data</code> that each prediction corresponds to.</p>
</td></tr>
<tr><td><code>task.desc</code></td>
<td>
<p><a href="#topic+TaskDesc">TaskDesc</a><br />
Task description.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>Target feature for regression, target feature levels for classification,
survival and event indicator for survival.</p>
</td></tr>
<tr><td><code>features</code></td>
<td>
<p><a href="base.html#topic+character">character</a><br />
Features argument input.</p>
</td></tr>
<tr><td><code>interaction</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not the features were interacted (i.e. conditioning).</p>
</td></tr>
<tr><td><code>derivative</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether or not the partial derivative was estimated.</p>
</td></tr>
<tr><td><code>individual</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether the partial dependences were aggregated or the individual curves are retained.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. &ldquo;Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation.&rdquo; Journal of Computational and Graphical Statistics. Vol. 24, No. 1 (2015): 44-65.
</p>
<p>Friedman, Jerome. &ldquo;Greedy Function Approximation: A Gradient Boosting Machine.&rdquo; The Annals of Statistics. Vol. 29. No. 5 (2001): 1189-1232.
</p>


<h3>See Also</h3>

<p>Other partial_dependence: 
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>
</p>
<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lrn = makeLearner("regr.svm")
fit = train(lrn, bh.task)
pd = generatePartialDependenceData(fit, bh.task, "lstat")
plotPartialDependence(pd, data = getTaskData(bh.task))

lrn = makeLearner("classif.rpart", predict.type = "prob")
fit = train(lrn, iris.task)
pd = generatePartialDependenceData(fit, iris.task, "Petal.Width")
plotPartialDependence(pd, data = getTaskData(iris.task))
</code></pre>

<hr>
<h2 id='generateThreshVsPerfData'>Generate threshold vs. performance(s) for 2-class classification.</h2><span id='topic+generateThreshVsPerfData'></span><span id='topic+ThreshVsPerfData'></span>

<h3>Description</h3>

<p>Generates data on threshold vs. performance(s) for 2-class classification that can be used for plotting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateThreshVsPerfData(
  obj,
  measures,
  gridsize = 100L,
  aggregate = TRUE,
  task.id = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateThreshVsPerfData_+3A_obj">obj</code></td>
<td>
<p>(list of <a href="#topic+Prediction">Prediction</a> | list of <a href="#topic+ResampleResult">ResampleResult</a> | <a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Single prediction object, list of them, single resample result, list of them, or a benchmark result.
In case of a list probably produced by different learners you want to compare, then
name the list with the names you want to see in the plots, probably
learner shortnames or ids.</p>
</td></tr>
<tr><td><code id="generateThreshVsPerfData_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="generateThreshVsPerfData_+3A_gridsize">gridsize</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Grid resolution for x-axis (threshold).
Default is 100.</p>
</td></tr>
<tr><td><code id="generateThreshVsPerfData_+3A_aggregate">aggregate</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to aggregate <a href="#topic+ResamplePrediction">ResamplePrediction</a>s or to plot the performance
of each iteration separately.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="generateThreshVsPerfData_+3A_task.id">task.id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Selected task in <a href="#topic+BenchmarkResult">BenchmarkResult</a> to do plots for, ignored otherwise.
Default is first task.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ThreshVsPerfData">ThreshVsPerfData</a>). A named list containing the measured performance
across the threshold grid, the measures, and whether the performance estimates were
aggregated (only applicable for (list of) <a href="#topic+ResampleResult">ResampleResult</a>s).
</p>


<h3>See Also</h3>

<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>
<p>Other thresh_vs_perf: 
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>

<hr>
<h2 id='getBMRAggrPerformances'>Extract the aggregated performance values from a benchmark result.</h2><span id='topic+getBMRAggrPerformances'></span>

<h3>Description</h3>

<p>Either a list of lists of &ldquo;aggr&rdquo; numeric vectors, as returned by
<a href="#topic+resample">resample</a>, or these objects are rbind-ed with extra columns
&ldquo;task.id&rdquo; and &ldquo;learner.id&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRAggrPerformances(
  bmr,
  task.ids = NULL,
  learner.ids = NULL,
  as.df = FALSE,
  drop = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRAggrPerformances_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRAggrPerformances_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRAggrPerformances_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRAggrPerformances_+3A_as.df">as.df</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Return one <a href="base.html#topic+data.frame">data.frame</a> as result - or a list of lists of objects?.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getBMRAggrPerformances_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> | <a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRFeatSelResults'>Extract the feature selection results from a benchmark result.</h2><span id='topic+getBMRFeatSelResults'></span>

<h3>Description</h3>

<p>Returns a nested list of <a href="#topic+FeatSelResult">FeatSelResult</a>s. The first level of nesting is by data set, the second by learner, the third for the benchmark resampling iterations. If <code>as.df</code> is <code>TRUE</code>, a data frame with &ldquo;task.id&rdquo;, &ldquo;learner.id&rdquo;, the resample iteration and the selected features is returned.
</p>
<p>Note that if more than one feature is selected and a data frame is requested, there will be multiple rows for the same dataset-learner-iteration; one for each selected feature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRFeatSelResults(
  bmr,
  task.ids = NULL,
  learner.ids = NULL,
  as.df = FALSE,
  drop = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRFeatSelResults_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRFeatSelResults_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRFeatSelResults_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRFeatSelResults_+3A_as.df">as.df</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Return one <a href="base.html#topic+data.frame">data.frame</a> as result - or a list of lists of objects?.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getBMRFeatSelResults_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> | <a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRFilteredFeatures'>Extract the feature selection results from a benchmark result.</h2><span id='topic+getBMRFilteredFeatures'></span>

<h3>Description</h3>

<p>Returns a nested list of characters The first level of nesting is by data set, the second by learner, the third for the benchmark resampling iterations. The list at the lowest level is the list of selected features. If <code>as.df</code> is <code>TRUE</code>, a data frame with &ldquo;task.id&rdquo;, &ldquo;learner.id&rdquo;, the resample iteration and the selected features is returned.
</p>
<p>Note that if more than one feature is selected and a data frame is requested, there will be multiple rows for the same dataset-learner-iteration; one for each selected feature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRFilteredFeatures(
  bmr,
  task.ids = NULL,
  learner.ids = NULL,
  as.df = FALSE,
  drop = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRFilteredFeatures_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRFilteredFeatures_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRFilteredFeatures_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRFilteredFeatures_+3A_as.df">as.df</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Return one <a href="base.html#topic+data.frame">data.frame</a> as result - or a list of lists of objects?.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getBMRFilteredFeatures_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> | <a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRLearnerIds'>Return learner ids used in benchmark.</h2><span id='topic+getBMRLearnerIds'></span>

<h3>Description</h3>

<p>Gets the IDs of the learners used in a benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRLearnerIds(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRLearnerIds_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRLearners'>Return learners used in benchmark.</h2><span id='topic+getBMRLearners'></span>

<h3>Description</h3>

<p>Gets the learners used in a benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRLearners(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRLearners_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRLearnerShortNames'>Return learner short.names used in benchmark.</h2><span id='topic+getBMRLearnerShortNames'></span>

<h3>Description</h3>

<p>Gets the learner short.names of the learners used in a benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRLearnerShortNames(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRLearnerShortNames_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRMeasureIds'>Return measures IDs used in benchmark.</h2><span id='topic+getBMRMeasureIds'></span>

<h3>Description</h3>

<p>Gets the IDs of the measures used in a benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRMeasureIds(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRMeasureIds_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRMeasures'>Return measures used in benchmark.</h2><span id='topic+getBMRMeasures'></span>

<h3>Description</h3>

<p>Gets the measures used in a benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRMeasures(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRMeasures_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRModels'>Extract all models from benchmark result.</h2><span id='topic+getBMRModels'></span>

<h3>Description</h3>

<p>A list of lists containing all <a href="#topic+WrappedModel">WrappedModel</a>s trained in the benchmark experiment.
</p>
<p>If <code>models</code> is <code>FALSE</code> in the call to <a href="#topic+benchmark">benchmark</a>, the function will return <code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRModels(bmr, task.ids = NULL, learner.ids = NULL, drop = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRModels_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRModels_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRModels_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRModels_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRPerformances'>Extract the test performance values from a benchmark result.</h2><span id='topic+getBMRPerformances'></span>

<h3>Description</h3>

<p>Either a list of lists of &ldquo;measure.test&rdquo; data.frames, as returned by
<a href="#topic+resample">resample</a>, or these objects are rbind-ed with extra columns
&ldquo;task.id&rdquo; and &ldquo;learner.id&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRPerformances(
  bmr,
  task.ids = NULL,
  learner.ids = NULL,
  as.df = FALSE,
  drop = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRPerformances_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRPerformances_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRPerformances_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRPerformances_+3A_as.df">as.df</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Return one <a href="base.html#topic+data.frame">data.frame</a> as result - or a list of lists of objects?.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getBMRPerformances_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> | <a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRPredictions'>Extract the predictions from a benchmark result.</h2><span id='topic+getBMRPredictions'></span>

<h3>Description</h3>

<p>Either a list of lists of <a href="#topic+ResamplePrediction">ResamplePrediction</a> objects, as returned by
<a href="#topic+resample">resample</a>, or these objects are rbind-ed with extra columns
&ldquo;task.id&rdquo; and &ldquo;learner.id&rdquo;.
</p>
<p>If <code>predict.type</code> is &ldquo;prob&rdquo;, the probabilities for each class are returned in addition to the response.
</p>
<p>If <code>keep.pred</code> is <code>FALSE</code> in the call to <a href="#topic+benchmark">benchmark</a>, the function will return <code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRPredictions(
  bmr,
  task.ids = NULL,
  learner.ids = NULL,
  as.df = FALSE,
  drop = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRPredictions_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRPredictions_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRPredictions_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRPredictions_+3A_as.df">as.df</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Return one <a href="base.html#topic+data.frame">data.frame</a> as result - or a list of lists of objects?.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getBMRPredictions_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> | <a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRTaskDescriptions'>Extract all task descriptions from benchmark result (DEPRECATED).</h2><span id='topic+getBMRTaskDescriptions'></span>

<h3>Description</h3>

<p>A list containing all <a href="#topic+TaskDesc">TaskDesc</a>s for each task contained in the benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRTaskDescriptions(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRTaskDescriptions_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>).
</p>

<hr>
<h2 id='getBMRTaskDescs'>Extract all task descriptions from benchmark result.</h2><span id='topic+getBMRTaskDescs'></span>

<h3>Description</h3>

<p>A list containing all <a href="#topic+TaskDesc">TaskDesc</a>s for each task contained in the benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRTaskDescs(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRTaskDescs_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRTaskIds'>Return task ids used in benchmark.</h2><span id='topic+getBMRTaskIds'></span>

<h3>Description</h3>

<p>Gets the task IDs used in a benchmark experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRTaskIds(bmr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRTaskIds_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getBMRTuneResults'>Extract the tuning results from a benchmark result.</h2><span id='topic+getBMRTuneResults'></span>

<h3>Description</h3>

<p>Returns a nested list of <a href="#topic+TuneResult">TuneResult</a>s. The first level of nesting is by data set, the second by learner, the third for the benchmark resampling iterations. If <code>as.df</code> is <code>TRUE</code>, a data frame with the &ldquo;task.id&rdquo;, &ldquo;learner.id&rdquo;, the resample iteration, the parameter values and the performances is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getBMRTuneResults(
  bmr,
  task.ids = NULL,
  learner.ids = NULL,
  as.df = FALSE,
  drop = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getBMRTuneResults_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="getBMRTuneResults_+3A_task.ids">task.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain tasks.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRTuneResults_+3A_learner.ids">learner.ids</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Restrict result to certain learners.
Default is all.</p>
</td></tr>
<tr><td><code id="getBMRTuneResults_+3A_as.df">as.df</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Return one <a href="base.html#topic+data.frame">data.frame</a> as result - or a list of lists of objects?.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getBMRTuneResults_+3A_drop">drop</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If drop is <code>FALSE</code> (the default), a nested list with
the following structure is returned:<br />
<code>res[task.ids][learner.ids]</code>.<br />
If drop is set to <code>TRUE</code> it is checked if the list
structure can be simplified.<br />
If only one learner was passed, a list with entries
for each task is returned.<br />
If only one task was passed, the entries are named after
the corresponding learner.<br />
For an experiment with both one task and learner,
the whole list structure is removed.<br />
Note that the name of the
task/learner will be dropped from the return object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a> | <a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>

<hr>
<h2 id='getCaretParamSet'>Get tuning parameters from a learner of the caret R-package.</h2><span id='topic+getCaretParamSet'></span>

<h3>Description</h3>

<p>Constructs a grid of tuning parameters from a learner of the <code>caret</code>
R-package. These values are then converted into a list of non-tunable
parameters (<code>par.vals</code>) and a tunable
<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a> (<code>par.set</code>), which can be used by
<a href="#topic+tuneParams">tuneParams</a> for tuning the learner. Numerical parameters will
either be specified by their lower and upper bounds or they will be
discretized into specific values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCaretParamSet(learner, length = 3L, task, discretize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCaretParamSet_+3A_learner">learner</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The name of the learner from <code>caret</code>
(cf. <a href="https://topepo.github.io/caret/available-models.html">https://topepo.github.io/caret/available-models.html</a>). Note that the
names in <code>caret</code> often differ from the ones in <code>mlr</code>.</p>
</td></tr>
<tr><td><code id="getCaretParamSet_+3A_length">length</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
A length / precision parameter which is used by <code>caret</code> for
generating the grid of tuning parameters. <code>caret</code> generates either as
many values per tuning parameter / dimension as defined by <code>length</code>
or only a single value (in case of non-tunable <code>par.vals</code>).</p>
</td></tr>
<tr><td><code id="getCaretParamSet_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
Learning task, which might be requested for creating the tuning grid.</p>
</td></tr>
<tr><td><code id="getCaretParamSet_+3A_discretize">discretize</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the numerical parameters be discretized? Alternatively, they will
be defined by their lower and upper bounds. The default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>list(2)</code>). A list of parameters:
</p>

<ul>
<li><p><code>par.vals</code> contains a list of all constant tuning parameters
</p>
</li>
<li><p><code>par.set</code> is a <a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a>, containing all the configurable
tuning parameters
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("caret") &amp;&amp; requireNamespace("mlbench")) {
  library(caret)
  classifTask = makeClassifTask(data = iris, target = "Species")

  # (1) classification (random forest) with discretized parameters
  getCaretParamSet("rf", length = 9L, task = classifTask, discretize = TRUE)

  # (2) regression (gradient boosting machine) without discretized parameters
  library(mlbench)
  data(BostonHousing)
  regrTask = makeRegrTask(data = BostonHousing, target = "medv")
  getCaretParamSet("gbm", length = 9L, task = regrTask, discretize = FALSE)
}
</code></pre>

<hr>
<h2 id='getClassWeightParam'>Get the class weight parameter of a learner.</h2><span id='topic+getClassWeightParam'></span>

<h3>Description</h3>

<p>Gets the class weight parameter of a learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getClassWeightParam(learner, lrn.id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getClassWeightParam_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="getClassWeightParam_+3A_lrn.id">lrn.id</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Only used for <code>BaseEnsembles</code>. It is possible that multiple learners in a base
ensemble have a class weight param. Specify the learner from which the class weight should
be extracted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+numeric">numeric</a> LearnerParam:
A numeric parameter object, containing the class weight parameter of the given learner.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getConfMatrix'>Confusion matrix.</h2><span id='topic+getConfMatrix'></span>

<h3>Description</h3>

<p><code>getConfMatrix</code> is deprecated. Please use <a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>.
</p>
<p>Calculates confusion matrix for (possibly resampled) prediction.
Rows indicate true classes, columns predicted classes.
</p>
<p>The marginal elements count the number of classification
errors for the respective row or column, i.e., the number of errors
when you condition on the corresponding true (rows) or predicted
(columns) class. The last element in the margin diagonal
displays the total amount of errors.
</p>
<p>Note that for resampling no further aggregation is currently performed.
All predictions on all test sets are joined to a vector yhat, as are all labels
joined to a vector y. Then yhat is simply tabulated vs y, as if both were computed on
a single test set. This probably mainly makes sense when cross-validation is used for resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getConfMatrix(pred, relative = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getConfMatrix_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="getConfMatrix_+3A_relative">relative</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code> rows are normalized to show relative frequencies.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+matrix">matrix</a>). A confusion matrix.
</p>


<h3>See Also</h3>

<p><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>
</p>

<hr>
<h2 id='getDefaultMeasure'>Get default measure.</h2><span id='topic+getDefaultMeasure'></span>

<h3>Description</h3>

<p>Get the default measure for a task type, task, task description or a learner.
Currently these are:
classif: mmce<br />
regr: mse<br />
cluster: db<br />
surv: cindex<br />
costsen: mcp<br />
multilabel: multilabel.hamloss<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDefaultMeasure(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getDefaultMeasure_+3A_x">x</code></td>
<td>
<p>([character(1)' | <a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a> | <a href="#topic+Learner">Learner</a>)<br />
Task type, task, task description, learner name, a learner, or a type of learner (e.g. &quot;classif&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Measure">Measure</a>).
</p>

<hr>
<h2 id='getFailureModelDump'>Return the error dump of FailureModel.</h2><span id='topic+getFailureModelDump'></span>

<h3>Description</h3>

<p>Returns the error dump that can be used with <code>debugger()</code> to evaluate errors.
If <a href="#topic+configureMlr">configureMlr</a> configuration <code>on.error.dump</code> is <code>FALSE</code>, this returns
<code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFailureModelDump(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFailureModelDump_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>last.dump</code>).
</p>

<hr>
<h2 id='getFailureModelMsg'>Return error message of FailureModel.</h2><span id='topic+getFailureModelMsg'></span>

<h3>Description</h3>

<p>Such a model is created when one sets the corresponding option in <a href="#topic+configureMlr">configureMlr</a>.
If no failure occurred, <code>NA</code> is returned.
</p>
<p>For complex wrappers this getter returns the first error message encountered in ANY model that failed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFailureModelMsg(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFailureModelMsg_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>

<hr>
<h2 id='getFeatSelResult'>Returns the selected feature set and optimization path after training.</h2><span id='topic+getFeatSelResult'></span>

<h3>Description</h3>

<p>Returns the selected feature set and optimization path after training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFeatSelResult(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFeatSelResult_+3A_object">object</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Trained Model created with <a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+FeatSelResult">FeatSelResult</a>).
</p>


<h3>See Also</h3>

<p>Other featsel: 
<code><a href="#topic+FeatSelControl">FeatSelControl</a></code>,
<code><a href="#topic+analyzeFeatSelResult">analyzeFeatSelResult</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+selectFeatures">selectFeatures</a>()</code>
</p>

<hr>
<h2 id='getFeatureImportance'>Calculates feature importance values for trained models.</h2><span id='topic+getFeatureImportance'></span>

<h3>Description</h3>

<p>For some learners it is possible to calculate a feature importance measure.
<code>getFeatureImportance</code> extracts those values from trained models.
See below for a list of supported learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFeatureImportance(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFeatureImportance_+3A_object">object</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Wrapped model, result of <code><a href="#topic+train">train()</a></code>.</p>
</td></tr>
<tr><td><code id="getFeatureImportance_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional parameters, which are passed to the underlying importance value
generating function.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> boosting <br />
Measure which accounts the gain of Gini index given by a feature
in a tree and the weight of that tree.
</p>
</li>
<li><p> cforest <br />
Permutation principle of the 'mean decrease in accuracy' principle in
randomForest. If <code>auc=TRUE</code> (only for binary classification), area under
the curve is used as measure.  The algorithm used for the survival learner
is 'extremely slow and experimental; use at your own risk'. See
<code><a href="party.html#topic+varimp">party::varimp()</a></code> for details and further parameters.
</p>
</li>
<li><p> gbm <br />
Estimation of relative influence for each feature. See
<code><a href="gbm.html#topic+relative.influence">gbm::relative.influence()</a></code>
for details and further parameters.
</p>
</li>
<li><p> h2o <br />
Relative feature importances as returned by
<code><a href="h2o.html#topic+h2o.varimp">h2o::h2o.varimp()</a></code>.
</p>
</li>
<li><p> randomForest <br />
For <code>type = 2</code> (the default) the 'MeanDecreaseGini' is measured, which is
based on the Gini impurity index used for the calculation of the nodes.
Alternatively, you can set <code>type</code> to 1, then the measure is the mean
decrease in accuracy calculated on OOB data. Note, that in this case the
learner's parameter <code>importance</code> needs to be set to be able to compute
feature importance values.
See <code><a href="randomForest.html#topic+importance">randomForest::importance()</a></code> for details.
</p>
</li>
<li><p> RRF <br />
This is identical to randomForest.
</p>
</li>
<li><p> ranger <br />
Supports both measures mentioned above for the randomForest
learner. Note, that you need to specifically set the learners parameter
<code>importance</code>, to be able to compute feature importance measures.
See <code><a href="ranger.html#topic+importance.ranger">ranger::importance()</a></code> and
<code><a href="ranger.html#topic+ranger">ranger::ranger()</a></code> for details.
</p>
</li>
<li><p> rpart <br />
Sum of decrease in impurity for each of the surrogate variables at each
node
</p>
</li>
<li><p> xgboost <br />
The value implies the relative contribution of the corresponding feature
to the model calculated by taking each feature's contribution for each
tree in the model. The exact computation of the importance in xgboost is
undocumented.
</p>
</li></ul>



<h3>Value</h3>

<p>(<code>FeatureImportance</code>) An object containing a <code>data.frame</code> of the
variable importances and further information.
</p>

<hr>
<h2 id='getFeatureImportanceLearner'>Calculates feature importance values for a given learner.</h2><span id='topic+getFeatureImportanceLearner'></span>

<h3>Description</h3>

<p>This function is mostly for internal usage. To calculate feature importance use <a href="#topic+getFeatureImportance">getFeatureImportance</a>.
</p>
<p>The return value is a named numeric vector. There does not need to be one value for each feature in the dataset.
In <a href="#topic+getFeatureImportance">getFeatureImportance</a> missing features will get an importance of zero and if the vector contains <code>NA</code>
they will also be replaced with zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFeatureImportanceLearner(.learner, .model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFeatureImportanceLearner_+3A_.learner">.learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.</p>
</td></tr>
<tr><td><code id="getFeatureImportanceLearner_+3A_.model">.model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The model.</p>
</td></tr>
<tr><td><code id="getFeatureImportanceLearner_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional parameters, which are passed to the underlying importance value
generating function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+numeric">numeric</a>) A named vector of variable importance.
</p>

<hr>
<h2 id='getFilteredFeatures'>Returns the filtered features.</h2><span id='topic+getFilteredFeatures'></span>

<h3>Description</h3>

<p>Returns the filtered features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFilteredFeatures(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFilteredFeatures_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Trained Model created with <a href="#topic+makeFilterWrapper">makeFilterWrapper</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>

<hr>
<h2 id='getFunctionalFeatures'>Get only functional features from a task or a data.frame.</h2><span id='topic+getFunctionalFeatures'></span><span id='topic+getFunctionalFeatures.Task'></span><span id='topic+getFunctionalFeatures.data.frame'></span>

<h3>Description</h3>

<p>The parameters &ldquo;subset&rdquo;, &ldquo;features&rdquo;, and &ldquo;recode.target&rdquo;
are ignored for the data.frame method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFunctionalFeatures(object, subset = NULL, features, recode.target = "no")

## S3 method for class 'Task'
getFunctionalFeatures(object, subset = NULL, features, recode.target = "no")

## S3 method for class 'data.frame'
getFunctionalFeatures(object, subset = NULL, features, recode.target = "no")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFunctionalFeatures_+3A_object">object</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>/<a href="base.html#topic+data.frame">data.frame</a>)<br />
Object to check on.</p>
</td></tr>
<tr><td><code id="getFunctionalFeatures_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
<tr><td><code id="getFunctionalFeatures_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a> | <a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a>)<br />
Vector of selected inputs. You can either pass a character vector with the
feature names, a vector of indices, or a logical vector.<br />
In case of an index vector each element denotes the position of the feature
name returned by <a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>.<br />
Note that the target feature is always included in the
resulting task, you should not pass it here.
Default is to use all features.</p>
</td></tr>
<tr><td><code id="getFunctionalFeatures_+3A_recode.target">recode.target</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should target classes be recoded? Supported are binary and multilabel classification and survival.
Possible values for binary classification are &ldquo;01&rdquo;, &ldquo;-1+1&rdquo; and &ldquo;drop.levels&rdquo;.
In the two latter cases the target vector is converted into a numeric vector.
The positive class is coded as &ldquo;+1&rdquo; and the negative class either as &ldquo;0&rdquo; or &ldquo;-1&rdquo;.
&ldquo;drop.levels&rdquo; will remove empty factor levels in the target column.
In the multilabel case the logical targets can be converted to factors with &ldquo;multilabel.factor&rdquo;.
For survival, you may choose to recode the survival times to &ldquo;left&rdquo;, &ldquo;right&rdquo; or &ldquo;interval2&rdquo; censored times
using &ldquo;lcens&rdquo;, &ldquo;rcens&rdquo; or &ldquo;icens&rdquo;, respectively.
See <a href="survival.html#topic+Surv">survival::Surv</a> for the format specification.
Default for both binary classification and survival is &ldquo;no&rdquo; (do nothing).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>data.frame</code> containing only the functional features.
</p>

<hr>
<h2 id='getHomogeneousEnsembleModels'>Deprecated, use <code>getLearnerModel</code> instead.</h2><span id='topic+getHomogeneousEnsembleModels'></span>

<h3>Description</h3>

<p>Deprecated, use <code>getLearnerModel</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getHomogeneousEnsembleModels(model, learner.models = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getHomogeneousEnsembleModels_+3A_model">model</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="getHomogeneousEnsembleModels_+3A_learner.models">learner.models</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
</table>

<hr>
<h2 id='getHyperPars'>Get current parameter settings for a learner.</h2><span id='topic+getHyperPars'></span>

<h3>Description</h3>

<p>Retrieves the current hyperparameter settings of a learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getHyperPars(learner, for.fun = c("train", "predict", "both"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getHyperPars_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a>)<br /> The learner.</p>
</td></tr>
<tr><td><code id="getHyperPars_+3A_for.fun">for.fun</code></td>
<td>
<p>(<code>character(1)</code>)<br /> Restrict the returned settings to
hyperparameters corresponding to <code>when</code> the are used (see
<a href="ParamHelpers.html#topic+LearnerParam">ParamHelpers::LearnerParam</a>). Must be a subset of: &ldquo;train&rdquo;,
&ldquo;predict&rdquo; or &ldquo;both&rdquo;. Default is <code>c("train", "predict", "both")</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function only shows hyperparameters that differ from the
learner default (because <code>mlr</code> changed the default) or if the user set
hyperparameters manually during learner creation. If you want to have an
overview of all available hyperparameters use <code><a href="#topic+getParamSet">getParamSet()</a></code>.
</p>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). A named list of values.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>getHyperPars(makeLearner("classif.ranger"))

## set learner hyperparameter `mtry` manually
getHyperPars(makeLearner("classif.ranger", mtry = 100))
</code></pre>

<hr>
<h2 id='getLearnerId'>Get the ID of the learner.</h2><span id='topic+getLearnerId'></span>

<h3>Description</h3>

<p>Get the ID of the learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerId(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerId_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerModel'>Get underlying R model of learner integrated into mlr.</h2><span id='topic+getLearnerModel'></span>

<h3>Description</h3>

<p>Get underlying R model of learner integrated into mlr.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerModel(model, more.unwrap = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerModel_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The model, returned by e.g., <a href="#topic+train">train</a>.</p>
</td></tr>
<tr><td><code id="getLearnerModel_+3A_more.unwrap">more.unwrap</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Some learners are not basic learners from R, but implemented in mlr as meta-techniques.
Examples are everything that inherits from <code>HomogeneousEnsemble</code>.
In these cases, the <code>learner.model</code> is often a list of mlr <a href="#topic+WrappedModel">WrappedModel</a>s.
This option allows to strip them further to basic R models.
The option is simply ignored for basic learner models.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(any). A fitted model, depending the learner / wrapped package. E.g., a
model of class <a href="rpart.html#topic+rpart">rpart::rpart</a> for learner &ldquo;classif.rpart&rdquo;.
</p>

<hr>
<h2 id='getLearnerNote'>Get the note for the learner.</h2><span id='topic+getLearnerNote'></span>

<h3>Description</h3>

<p>Get the note for the learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerNote(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerNote_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerPackages'>Get the required R packages of the learner.</h2><span id='topic+getLearnerPackages'></span>

<h3>Description</h3>

<p>Get the R packages the learner requires.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerPackages(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerPackages_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerParamSet'>Get the parameter set of the learner.</h2><span id='topic+getLearnerParamSet'></span>

<h3>Description</h3>

<p>Alias for <a href="#topic+getParamSet">getParamSet</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerParamSet(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerParamSet_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ParamSet.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerParVals'>Get the parameter values of the learner.</h2><span id='topic+getLearnerParVals'></span>

<h3>Description</h3>

<p>Alias for <a href="#topic+getHyperPars">getHyperPars</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerParVals(learner, for.fun = c("train", "predict", "both"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerParVals_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="getLearnerParVals_+3A_for.fun">for.fun</code></td>
<td>
<p>(<code>character(1)</code>)<br /> Restrict the returned settings to
hyperparameters corresponding to <code>when</code> the are used (see
<a href="ParamHelpers.html#topic+LearnerParam">ParamHelpers::LearnerParam</a>). Must be a subset of: &ldquo;train&rdquo;,
&ldquo;predict&rdquo; or &ldquo;both&rdquo;. Default is <code>c("train", "predict", "both")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). A named list of values.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerPredictType'>Get the predict type of the learner.</h2><span id='topic+getLearnerPredictType'></span>

<h3>Description</h3>

<p>Get the predict type of the learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerPredictType(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerPredictType_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerShortName'>Get the short name of the learner.</h2><span id='topic+getLearnerShortName'></span>

<h3>Description</h3>

<p>For an ordinary learner simply its short name is returned.
For wrapped learners, the wrapper id is successively attached to the short
name of the base learner. E.g: &ldquo;rf.bagged.imputed&rdquo;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerShortName(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerShortName_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getLearnerType'>Get the type of the learner.</h2><span id='topic+getLearnerType'></span>

<h3>Description</h3>

<p>Get the type of the learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getLearnerType(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getLearnerType_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getMlrOptions'>Returns a list of mlr's options.</h2><span id='topic+getMlrOptions'></span>

<h3>Description</h3>

<p>Gets the options for mlr.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMlrOptions()
</code></pre>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>).
</p>


<h3>See Also</h3>

<p>Other configure: 
<code><a href="#topic+configureMlr">configureMlr</a>()</code>
</p>

<hr>
<h2 id='getMultilabelBinaryPerformances'>Retrieve binary classification measures for multilabel classification predictions.</h2><span id='topic+getMultilabelBinaryPerformances'></span>

<h3>Description</h3>

<p>Measures the quality of each binary label prediction w.r.t. some binary classification
performance measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMultilabelBinaryPerformances(pred, measures)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMultilabelBinaryPerformances_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Multilabel Prediction object.</p>
</td></tr>
<tr><td><code id="getMultilabelBinaryPerformances_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate, must be applicable to binary classification performance.
Default is <code>mmce</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(named <code>matrix</code>). Performance value(s), column names are measure(s), row names are labels.
</p>


<h3>See Also</h3>

<p>Other multilabel: 
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see makeMultilabelBinaryRelevanceWrapper
</code></pre>

<hr>
<h2 id='getNestedTuneResultsOptPathDf'>Get the <code>opt.path</code>s from each tuning step from the outer resampling.</h2><span id='topic+getNestedTuneResultsOptPathDf'></span>

<h3>Description</h3>

<p>After you resampled a tuning wrapper (see <a href="#topic+makeTuneWrapper">makeTuneWrapper</a>)
with <code>resample(..., extract = getTuneResult)</code> this helper returns a <code>data.frame</code> with
with all <code>opt.path</code>s combined by <code>rbind</code>.
An additional column <code>iter</code> indicates to what resampling iteration the row belongs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNestedTuneResultsOptPathDf(r, trafo = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getNestedTuneResultsOptPathDf_+3A_r">r</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>) <br />
The result of resampling of a tuning wrapper.</p>
</td></tr>
<tr><td><code id="getNestedTuneResultsOptPathDf_+3A_trafo">trafo</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the units of the hyperparameter path be converted to the
transformed scale? This is only necessary when trafo was used to create
the <code>opt.path</code>s. Note that <code>opt.path</code>s are always stored on the
untransformed scale.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>). See above.
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see example of makeTuneWrapper
</code></pre>

<hr>
<h2 id='getNestedTuneResultsX'>Get the tuned hyperparameter settings from a nested tuning.</h2><span id='topic+getNestedTuneResultsX'></span>

<h3>Description</h3>

<p>After you resampled a tuning wrapper (see <a href="#topic+makeTuneWrapper">makeTuneWrapper</a>)
with <code>resample(..., extract = getTuneResult)</code> this helper returns a <code>data.frame</code> with
the best found hyperparameter settings for each resampling iteration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getNestedTuneResultsX(r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getNestedTuneResultsX_+3A_r">r</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>) <br />
The result of resampling of a tuning wrapper.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>). One column for each tuned hyperparameter and one row for each outer resampling iteration.
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see example of makeTuneWrapper
</code></pre>

<hr>
<h2 id='getOOBPreds'>Extracts out-of-bag predictions from trained models.</h2><span id='topic+getOOBPreds'></span>

<h3>Description</h3>

<p>Learners like <code>randomForest</code> produce out-of-bag predictions.
<code>getOOBPreds</code> extracts this information from trained models and builds a
prediction object as provided by predict (with prediction time set to NA).
In the classification case:
What is stored exactly in the (<a href="#topic+Prediction">Prediction</a>) object depends
on the <code>predict.type</code> setting of the <a href="#topic+Learner">Learner</a>.
</p>
<p>You can call <code>listLearners(properties = "oobpreds")</code> to get a list of learners
which provide this.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getOOBPreds(model, task)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getOOBPreds_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The model.</p>
</td></tr>
<tr><td><code id="getOOBPreds_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Prediction">Prediction</a>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>training.set = sample(1:150, 50)
lrn = makeLearner("classif.ranger", predict.type = "prob", predict.threshold = 0.6)
mod = train(lrn, sonar.task, subset = training.set)
oob = getOOBPreds(mod, sonar.task)
oob
performance(oob, measures = list(auc, mmce))
</code></pre>

<hr>
<h2 id='getOOBPredsLearner'>Provides out-of-bag predictions for a given model and the corresponding learner.</h2><span id='topic+getOOBPredsLearner'></span>

<h3>Description</h3>

<p>This function is mostly for internal usage. To get out-of-bag predictions use <a href="#topic+getOOBPreds">getOOBPreds</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getOOBPredsLearner(.learner, .model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getOOBPredsLearner_+3A_.learner">.learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a>)<br />
The learner.</p>
</td></tr>
<tr><td><code id="getOOBPredsLearner_+3A_.model">.model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Wrapped model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Same output structure as in (<a href="#topic+predictLearner">predictLearner</a>).
</p>

<hr>
<h2 id='getParamSet'>Get a description of all possible parameter settings for a learner.</h2><span id='topic+getParamSet'></span>

<h3>Description</h3>

<p>Returns the <a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a> from a <a href="#topic+Learner">Learner</a>.
</p>


<h3>Value</h3>

<p>ParamSet.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getPredictionDump'>Return the error dump of a failed Prediction.</h2><span id='topic+getPredictionDump'></span>

<h3>Description</h3>

<p>Returns the error dump that can be used with <code>debugger()</code> to evaluate errors.
If <a href="#topic+configureMlr">configureMlr</a> configuration <code>on.error.dump</code> is <code>FALSE</code> or if the
prediction did not fail, this returns <code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPredictionDump(pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPredictionDump_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>last.dump</code>).
</p>


<h3>See Also</h3>

<p>Other debug: 
<code><a href="#topic+FailureModel">FailureModel</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+getRRDump">getRRDump</a>()</code>
</p>

<hr>
<h2 id='getPredictionProbabilities'>Get probabilities for some classes.</h2><span id='topic+getPredictionProbabilities'></span>

<h3>Description</h3>

<p>Get probabilities for some classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPredictionProbabilities(pred, cl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPredictionProbabilities_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="getPredictionProbabilities_+3A_cl">cl</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Names of classes.
Default is either all classes for multi-class / multilabel problems or the positive class for binary classification.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>) with numerical columns or a numerical vector if length of <code>cl</code> is 1.
Order of columns is defined by <code>cl</code>.
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>,
<code><a href="#topic+getPredictionResponse">getPredictionResponse</a>()</code>,
<code><a href="#topic+getPredictionTaskDesc">getPredictionTaskDesc</a>()</code>,
<code><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.lda", predict.type = "prob")
mod = train(lrn, task)
# predict probabilities
pred = predict(mod, newdata = iris)

# Get probabilities for all classes
head(getPredictionProbabilities(pred))

# Get probabilities for a subset of classes
head(getPredictionProbabilities(pred, c("setosa", "virginica")))
</code></pre>

<hr>
<h2 id='getPredictionResponse'>Get response / truth from prediction object.</h2><span id='topic+getPredictionResponse'></span><span id='topic+getPredictionSE'></span><span id='topic+getPredictionTruth'></span>

<h3>Description</h3>

<p>The following types are returned, depending on task type:
</p>

<table>
<tr>
 <td style="text-align: left;">
classif     </td><td style="text-align: left;"> factor</td>
</tr>
<tr>
 <td style="text-align: left;">
regr        </td><td style="text-align: left;"> numeric</td>
</tr>
<tr>
 <td style="text-align: left;">
se          </td><td style="text-align: left;"> numeric</td>
</tr>
<tr>
 <td style="text-align: left;">
cluster     </td><td style="text-align: left;"> integer</td>
</tr>
<tr>
 <td style="text-align: left;">
surv        </td><td style="text-align: left;"> numeric</td>
</tr>
<tr>
 <td style="text-align: left;">
multilabel  </td><td style="text-align: left;"> logical matrix, columns named with labels</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Usage</h3>

<pre><code class='language-R'>getPredictionResponse(pred)

getPredictionSE(pred)

getPredictionTruth(pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPredictionResponse_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See above.
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>,
<code><a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a>()</code>,
<code><a href="#topic+getPredictionTaskDesc">getPredictionTaskDesc</a>()</code>,
<code><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getPredictionTaskDesc'>Get summarizing task description from prediction.</h2><span id='topic+getPredictionTaskDesc'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPredictionTaskDesc(pred)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPredictionTaskDesc_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ret_taskdesc
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>,
<code><a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a>()</code>,
<code><a href="#topic+getPredictionResponse">getPredictionResponse</a>()</code>,
<code><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='getProbabilities'>Deprecated, use <code>getPredictionProbabilities</code> instead.</h2><span id='topic+getProbabilities'></span>

<h3>Description</h3>

<p>Deprecated, use <code>getPredictionProbabilities</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getProbabilities(pred, cl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getProbabilities_+3A_pred">pred</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="getProbabilities_+3A_cl">cl</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
</table>

<hr>
<h2 id='getResamplingIndices'>Get the resampling indices from a tuning or feature selection wrapper..</h2><span id='topic+getResamplingIndices'></span>

<h3>Description</h3>

<p>After you resampled a tuning or feature selection wrapper (see <a href="#topic+makeTuneWrapper">makeTuneWrapper</a>)
with <code>resample(..., extract = getTuneResult)</code> or <code>resample(..., extract = getFeatSelResult)</code> this helper returns a <code>list</code> with
the resampling indices used for the respective method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getResamplingIndices(object, inner = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getResamplingIndices_+3A_object">object</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>) <br />
The result of resampling of a tuning or feature selection wrapper.</p>
</td></tr>
<tr><td><code id="getResamplingIndices_+3A_inner">inner</code></td>
<td>
<p>(<a href="base.html#topic+logical">logical</a>) <br />
If <code>TRUE</code>, returns the inner indices of a nested resampling setting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). One list for each outer resampling fold.
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.rpart")
# stupid mini grid
ps = makeParamSet(
  makeDiscreteParam("cp", values = c(0.05, 0.1)),
  makeDiscreteParam("minsplit", values = c(10, 20))
)
ctrl = makeTuneControlGrid()
inner = makeResampleDesc("Holdout")
outer = makeResampleDesc("CV", iters = 2)
lrn = makeTuneWrapper(lrn, resampling = inner, par.set = ps, control = ctrl)
# nested resampling for evaluation
# we also extract tuned hyper pars in each iteration and by that the resampling indices
r = resample(lrn, task, outer, extract = getTuneResult)
# get tuning indices
getResamplingIndices(r, inner = TRUE)
</code></pre>

<hr>
<h2 id='getRRDump'>Return the error dump of ResampleResult.</h2><span id='topic+getRRDump'></span>

<h3>Description</h3>

<p>Returns the error dumps generated during resampling, which can be used with <code>debugger()</code>
to debug errors. These dumps are saved if <a href="#topic+configureMlr">configureMlr</a> configuration <code>on.error.dump</code>,
or the corresponding learner <code>config</code>, is <code>TRUE</code>.
</p>
<p>The returned object is a list with as many entries as the resampling being used has folds. Each of these
entries can have a subset of the following slots, depending on which step in the resampling iteration failed:
&ldquo;train&rdquo; (error during training step), &ldquo;predict.train&rdquo; (prediction on training subset),
&ldquo;predict.test&rdquo; (prediction on test subset).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRRDump(res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRRDump_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>)<br />
The result of <a href="#topic+resample">resample</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+list">list</a>.
</p>


<h3>See Also</h3>

<p>Other debug: 
<code><a href="#topic+FailureModel">FailureModel</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+getPredictionDump">getPredictionDump</a>()</code>
</p>

<hr>
<h2 id='getRRPredictionList'>Get list of predictions for train and test set of each single resample iteration.</h2><span id='topic+getRRPredictionList'></span>

<h3>Description</h3>

<p>This function creates a list with two slots <code>train</code> and <code>test</code> where
each slot is again a list of <a href="#topic+Prediction">Prediction</a> objects for each single
resample iteration.
In case that <code>predict = "train"</code> was used for the resample description
(see <a href="#topic+makeResampleDesc">makeResampleDesc</a>), the slot <code>test</code> will be <code>NULL</code>
and in case that <code>predict = "test"</code> was used, the slot <code>train</code> will be
<code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRRPredictionList(res, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRRPredictionList_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>)<br />
The result of <a href="#topic+resample">resample</a> run with <code>keep.pred = TRUE</code>.</p>
</td></tr>
<tr><td><code id="getRRPredictionList_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further options passed to <a href="#topic+makePrediction">makePrediction</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+list">list</a>.
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>

<hr>
<h2 id='getRRPredictions'>Get predictions from resample results.</h2><span id='topic+getRRPredictions'></span>

<h3>Description</h3>

<p>Very simple getter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRRPredictions(res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRRPredictions_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>)<br />
The result of <a href="#topic+resample">resample</a> run with <code>keep.pred = TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ResamplePrediction">ResamplePrediction</a>).
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>

<hr>
<h2 id='getRRTaskDesc'>Get task description from resample results (DEPRECATED).</h2><span id='topic+getRRTaskDesc'></span>

<h3>Description</h3>

<p>Get a summarizing task description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRRTaskDesc(res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRRTaskDesc_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>)<br />
The result of <a href="#topic+resample">resample</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TaskDesc">TaskDesc</a>).
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>

<hr>
<h2 id='getRRTaskDescription'>Get task description from resample results (DEPRECATED).</h2><span id='topic+getRRTaskDescription'></span>

<h3>Description</h3>

<p>Get a summarizing task description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRRTaskDescription(res)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRRTaskDescription_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+ResampleResult">ResampleResult</a>)<br />
The result of <a href="#topic+resample">resample</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TaskDesc">TaskDesc</a>).
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>

<hr>
<h2 id='getStackedBaseLearnerPredictions'>Returns the predictions for each base learner.</h2><span id='topic+getStackedBaseLearnerPredictions'></span>

<h3>Description</h3>

<p>Returns the predictions for each base learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getStackedBaseLearnerPredictions(model, newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getStackedBaseLearnerPredictions_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br /> Wrapped model, result of train.</p>
</td></tr>
<tr><td><code id="getStackedBaseLearnerPredictions_+3A_newdata">newdata</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
New observations, for which the predictions using the specified base learners should be returned.
Default is <code>NULL</code> and extracts the base learner predictions that were made during the training.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>None.
</p>

<hr>
<h2 id='getTaskClassLevels'>Get the class levels for classification and multilabel tasks.</h2><span id='topic+getTaskClassLevels'></span>

<h3>Description</h3>

<p>NB: For multilabel, <a href="#topic+getTaskTargetNames">getTaskTargetNames</a> and <a href="#topic+getTaskClassLevels">getTaskClassLevels</a>
actually return the same thing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskClassLevels(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskClassLevels_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskCosts'>Extract costs in task.</h2><span id='topic+getTaskCosts'></span>

<h3>Description</h3>

<p>Returns &ldquo;NULL&rdquo; if the task is not of type &ldquo;costsens&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskCosts(task, subset = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskCosts_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+CostSensTask">CostSensTask</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="getTaskCosts_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>matrix</code> | <code>NULL</code>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskData'>Extract data in task.</h2><span id='topic+getTaskData'></span>

<h3>Description</h3>

<p>Useful in <a href="#topic+trainLearner">trainLearner</a> when you add a learning machine to the package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskData(
  task,
  subset = NULL,
  features,
  target.extra = FALSE,
  recode.target = "no",
  functionals.as = "dfcols"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskData_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="getTaskData_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
<tr><td><code id="getTaskData_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a> | <a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a>)<br />
Vector of selected inputs. You can either pass a character vector with the
feature names, a vector of indices, or a logical vector.<br />
In case of an index vector each element denotes the position of the feature
name returned by <a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>.<br />
Note that the target feature is always included in the
resulting task, you should not pass it here.
Default is to use all features.</p>
</td></tr>
<tr><td><code id="getTaskData_+3A_target.extra">target.extra</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should target vector be returned separately?
If not, a single data.frame including the target columns is returned, otherwise a list
with the input data.frame and an extra vector or data.frame for the targets.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="getTaskData_+3A_recode.target">recode.target</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should target classes be recoded? Supported are binary and multilabel classification and survival.
Possible values for binary classification are &ldquo;01&rdquo;, &ldquo;-1+1&rdquo; and &ldquo;drop.levels&rdquo;.
In the two latter cases the target vector is converted into a numeric vector.
The positive class is coded as &ldquo;+1&rdquo; and the negative class either as &ldquo;0&rdquo; or &ldquo;-1&rdquo;.
&ldquo;drop.levels&rdquo; will remove empty factor levels in the target column.
In the multilabel case the logical targets can be converted to factors with &ldquo;multilabel.factor&rdquo;.
For survival, you may choose to recode the survival times to &ldquo;left&rdquo;, &ldquo;right&rdquo; or &ldquo;interval2&rdquo; censored times
using &ldquo;lcens&rdquo;, &ldquo;rcens&rdquo; or &ldquo;icens&rdquo;, respectively.
See <a href="survival.html#topic+Surv">survival::Surv</a> for the format specification.
Default for both binary classification and survival is &ldquo;no&rdquo; (do nothing).</p>
</td></tr>
<tr><td><code id="getTaskData_+3A_functionals.as">functionals.as</code></td>
<td>
<p>(<code>character(1)</code>)<br />
How to represents functional features?
Option &ldquo;matrix&rdquo;: Keep them as matrix columns in the data.frame.
Option &ldquo;dfcols&rdquo;: Convert them to individual numeric data.frame columns.
Default is &ldquo;dfcols&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either a data.frame or a list with data.frame <code>data</code> and vector <code>target</code>.
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("mlbench")
data(BreastCancer)

df = BreastCancer
df$Id = NULL
task = makeClassifTask(id = "BreastCancer", data = df, target = "Class", positive = "malignant")
head(getTaskData)
head(getTaskData(task, features = c("Cell.size", "Cell.shape"), recode.target = "-1+1"))
head(getTaskData(task, subset = 1:100, recode.target = "01"))
</code></pre>

<hr>
<h2 id='getTaskDesc'>Get a summarizing task description.</h2><span id='topic+getTaskDesc'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskDesc(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskDesc_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ret_taskdesc
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskDescription'>Deprecated, use <a href="#topic+getTaskDesc">getTaskDesc</a> instead.</h2><span id='topic+getTaskDescription'></span>

<h3>Description</h3>

<p>Deprecated, use <a href="#topic+getTaskDesc">getTaskDesc</a> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskDescription(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskDescription_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>

<hr>
<h2 id='getTaskFeatureNames'>Get feature names of task.</h2><span id='topic+getTaskFeatureNames'></span>

<h3>Description</h3>

<p>Target column name is not included.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskFeatureNames(task)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskFeatureNames_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskFormula'>Get formula of a task.</h2><span id='topic+getTaskFormula'></span>

<h3>Description</h3>

<p>This is usually simply <code style="white-space: pre;">&#8288;&lt;target&gt; ~ &#8288;</code>.
For multilabel it is <code style="white-space: pre;">&#8288;&lt;target_1&gt; + ... + &lt;target_k&gt; ~&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskFormula(
  x,
  target = getTaskTargetNames(x),
  explicit.features = FALSE,
  env = parent.frame()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskFormula_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
<tr><td><code id="getTaskFormula_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Left hand side of the formula.
Default is defined by task <code>x</code>.</p>
</td></tr>
<tr><td><code id="getTaskFormula_+3A_explicit.features">explicit.features</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the features (right hand side of the formula) be explicitly listed?
Default is <code>FALSE</code>, i.e., they will be represented as <code>"."</code>.</p>
</td></tr>
<tr><td><code id="getTaskFormula_+3A_env">env</code></td>
<td>
<p>(<a href="base.html#topic+environment">environment</a>)<br />
Environment of the formula.
Default is <code>parent.frame()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="stats.html#topic+formula">formula</a>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskId'>Get the id of the task.</h2><span id='topic+getTaskId'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskId(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskId_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskNFeats'>Get number of features in task.</h2><span id='topic+getTaskNFeats'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskNFeats(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskNFeats_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>integer(1)</code>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskSize'>Get number of observations in task.</h2><span id='topic+getTaskSize'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskSize(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskSize_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>integer(1)</code>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskTargetNames'>Get the name(s) of the target column(s).</h2><span id='topic+getTaskTargetNames'></span>

<h3>Description</h3>

<p>NB: For multilabel, <a href="#topic+getTaskTargetNames">getTaskTargetNames</a> and <a href="#topic+getTaskClassLevels">getTaskClassLevels</a>
actually return the same thing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskTargetNames(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskTargetNames_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTaskTargets'>Get target data of task.</h2><span id='topic+getTaskTargets'></span>

<h3>Description</h3>

<p>Get target data of task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskTargets(task, recode.target = "no")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskTargets_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="getTaskTargets_+3A_recode.target">recode.target</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should target classes be recoded? Supported are binary and multilabel classification and survival.
Possible values for binary classification are &ldquo;01&rdquo;, &ldquo;-1+1&rdquo; and &ldquo;drop.levels&rdquo;.
In the two latter cases the target vector is converted into a numeric vector.
The positive class is coded as &ldquo;+1&rdquo; and the negative class either as &ldquo;0&rdquo; or &ldquo;-1&rdquo;.
&ldquo;drop.levels&rdquo; will remove empty factor levels in the target column.
In the multilabel case the logical targets can be converted to factors with &ldquo;multilabel.factor&rdquo;.
For survival, you may choose to recode the survival times to &ldquo;left&rdquo;, &ldquo;right&rdquo; or &ldquo;interval2&rdquo; censored times
using &ldquo;lcens&rdquo;, &ldquo;rcens&rdquo; or &ldquo;icens&rdquo;, respectively.
See <a href="survival.html#topic+Surv">survival::Surv</a> for the format specification.
Default for both binary classification and survival is &ldquo;no&rdquo; (do nothing).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>factor</code> for classification or a <code>numeric</code> for regression, a data.frame
of logical columns for multilabel.
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>task = makeClassifTask(data = iris, target = "Species")
getTaskTargets(task)
</code></pre>

<hr>
<h2 id='getTaskType'>Get the type of the task.</h2><span id='topic+getTaskType'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTaskType(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTaskType_+3A_x">x</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="#topic+TaskDesc">TaskDesc</a>)<br />
Task or its description object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>character(1)</code>).
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+subsetTask">subsetTask</a>()</code>
</p>

<hr>
<h2 id='getTuneResult'>Returns the optimal hyperparameters and optimization path after training.</h2><span id='topic+getTuneResult'></span>

<h3>Description</h3>

<p>Returns the optimal hyperparameters and optimization path after training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTuneResult(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTuneResult_+3A_object">object</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Trained Model created with <a href="#topic+makeTuneWrapper">makeTuneWrapper</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneResult">TuneResult</a>).
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='getTuneResultOptPath'>Get the optimization path of a tuning result.</h2><span id='topic+getTuneResultOptPath'></span>

<h3>Description</h3>

<p>Returns the opt.path from a (<a href="#topic+TuneResult">TuneResult</a>) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTuneResultOptPath(tune.result, as.df = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTuneResultOptPath_+3A_tune.result">tune.result</code></td>
<td>
<p>(<a href="#topic+TuneResult">TuneResult</a>) <br />
A tuning result of the (<a href="#topic+tuneParams">tuneParams</a>) function.</p>
</td></tr>
<tr><td><code id="getTuneResultOptPath_+3A_as.df">as.df</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the optimization path be returned as a data frame?
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="ParamHelpers.html#topic+OptPath">ParamHelpers::OptPath</a>) or (<a href="base.html#topic+data.frame">data.frame</a>).
</p>

<hr>
<h2 id='gunpoint.task'>Gunpoint functional data classification task.</h2><span id='topic+gunpoint.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>gunpoint.task</code>).
You have to classify whether a person raises up a gun or just an empty hand.
</p>


<h3>References</h3>

<p>See Ratanamahatana, C. A. &amp; Keogh. E. (2004). Everything you know
about Dynamic Time Warping is Wrong. Proceedings of SIAM International
Conference on Data Mining (SDM05), 506-510.
</p>

<hr>
<h2 id='hasFunctionalFeatures'>Check whether the object contains functional features.</h2><span id='topic+hasFunctionalFeatures'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hasFunctionalFeatures(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hasFunctionalFeatures_+3A_obj">obj</code></td>
<td>
<p>(<code>Task</code> | <code>TaskDesc</code> | <code>data.frame</code>)<br />
Object to check.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>logical(1)</code>)
</p>

<hr>
<h2 id='hasProperties'>Deprecated, use <code>hasLearnerProperties</code> instead.</h2><span id='topic+hasProperties'></span>

<h3>Description</h3>

<p>Deprecated, use <code>hasLearnerProperties</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hasProperties(learner, props)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hasProperties_+3A_learner">learner</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="hasProperties_+3A_props">props</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
</table>

<hr>
<h2 id='helpLearner'>Access help page of learner functions.</h2><span id='topic+helpLearner'></span>

<h3>Description</h3>

<p>Interactive function that gives the user quick access to the
help pages associated with various functions involved in the given learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>helpLearner(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="helpLearner_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>
<p>Other help: 
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>
</p>

<hr>
<h2 id='helpLearnerParam'>Get specific help for a learner's parameters.</h2><span id='topic+helpLearnerParam'></span>

<h3>Description</h3>

<p>Print the description of parameters of a given learner. The description
is automatically extracted from the help pages of the learner, so it may be incomplete.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>helpLearnerParam(learner, param = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="helpLearnerParam_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="helpLearnerParam_+3A_param">param</code></td>
<td>
<p>(<code>character</code> | NULL)<br />
Parameter(s) to describe. Defaults to NULL, which prints information on the documentation
status of all parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>
<p>Other help: 
<code><a href="#topic+helpLearner">helpLearner</a>()</code>
</p>

<hr>
<h2 id='imputations'>Built-in imputation methods.</h2><span id='topic+imputations'></span><span id='topic+imputeConstant'></span><span id='topic+imputeMedian'></span><span id='topic+imputeMean'></span><span id='topic+imputeMode'></span><span id='topic+imputeMin'></span><span id='topic+imputeMax'></span><span id='topic+imputeUniform'></span><span id='topic+imputeNormal'></span><span id='topic+imputeHist'></span><span id='topic+imputeLearner'></span>

<h3>Description</h3>

<p>The built-ins are:
</p>

<ul>
<li> <p><code>imputeConstant(const)</code> for imputation using a constant value,
</p>
</li>
<li> <p><code>imputeMedian()</code> for imputation using the median,
</p>
</li>
<li> <p><code>imputeMode()</code> for imputation using the mode,
</p>
</li>
<li> <p><code>imputeMin(multiplier)</code> for imputing constant values shifted below the minimum
using <code>min(x) - multiplier * diff(range(x))</code>,
</p>
</li>
<li> <p><code>imputeMax(multiplier)</code> for imputing constant values shifted above the maximum
using <code>max(x) + multiplier * diff(range(x))</code>,
</p>
</li>
<li> <p><code>imputeNormal(mean, sd)</code> for imputation using normally
distributed random values. Mean and standard deviation will be calculated
from the data if not provided.
</p>
</li>
<li> <p><code>imputeHist(breaks, use.mids)</code> for imputation using random values
with probabilities calculated using <code>table</code> or <code>hist</code>.
</p>
</li>
<li> <p><code>imputeLearner(learner, features = NULL)</code> for imputations using the response
of a classification or regression learner.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>imputeConstant(const)

imputeMedian()

imputeMean()

imputeMode()

imputeMin(multiplier = 1)

imputeMax(multiplier = 1)

imputeUniform(min = NA_real_, max = NA_real_)

imputeNormal(mu = NA_real_, sd = NA_real_)

imputeHist(breaks, use.mids = TRUE)

imputeLearner(learner, features = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputations_+3A_const">const</code></td>
<td>
<p>(any)<br />
Constant valued use for imputation.</p>
</td></tr>
<tr><td><code id="imputations_+3A_multiplier">multiplier</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Value that stored minimum or maximum is multiplied with when imputation is done.</p>
</td></tr>
<tr><td><code id="imputations_+3A_min">min</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Lower bound for uniform distribution.
If NA (default), it will be estimated from the data.</p>
</td></tr>
<tr><td><code id="imputations_+3A_max">max</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Upper bound for uniform distribution.
If NA (default), it will be estimated from the data.</p>
</td></tr>
<tr><td><code id="imputations_+3A_mu">mu</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Mean of normal distribution. If missing it will be estimated from the data.</p>
</td></tr>
<tr><td><code id="imputations_+3A_sd">sd</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Standard deviation of normal distribution. If missing it will be estimated from the data.</p>
</td></tr>
<tr><td><code id="imputations_+3A_breaks">breaks</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Number of breaks to use in <a href="graphics.html#topic+hist">graphics::hist</a>. If missing,
defaults to auto-detection via &ldquo;Sturges&rdquo;.</p>
</td></tr>
<tr><td><code id="imputations_+3A_use.mids">use.mids</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>x</code> is numeric and a histogram is used, impute with bin mids (default)
or instead draw uniformly distributed samples within bin range.</p>
</td></tr>
<tr><td><code id="imputations_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
Supervised learner. Its predictions will be used for imputations.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.
Note that the target column is not available for this operation.</p>
</td></tr>
<tr><td><code id="imputations_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Features to use in <code>learner</code> for prediction.
Default is <code>NULL</code> which uses all available features except the target column
of the original task.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other impute: 
<code><a href="#topic+impute">impute</a>()</code>,
<code><a href="#topic+makeImputeMethod">makeImputeMethod</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+reimpute">reimpute</a>()</code>
</p>

<hr>
<h2 id='impute'>Impute and re-impute data</h2><span id='topic+impute'></span>

<h3>Description</h3>

<p>Allows imputation of missing feature values through various techniques.
Note that you have the possibility to re-impute a data set
in the same way as the imputation was performed during training.
This especially comes in handy during resampling when one wants to perform the
same imputation on the test set as on the training set.
</p>
<p>The function <code>impute</code> performs the imputation on a data set and returns,
alongside with the imputed data set, an &ldquo;ImputationDesc&rdquo; object
which can contain &ldquo;learned&rdquo; coefficients and helpful data.
It can then be passed together with a new data set to <a href="#topic+reimpute">reimpute</a>.
</p>
<p>The imputation techniques can be specified for certain features or for feature classes,
see function arguments.
</p>
<p>You can either provide an arbitrary object, use a built-in imputation method listed
under <a href="#topic+imputations">imputations</a> or create one yourself using <a href="#topic+makeImputeMethod">makeImputeMethod</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute(
  obj,
  target = character(0L),
  classes = list(),
  cols = list(),
  dummy.classes = character(0L),
  dummy.cols = character(0L),
  dummy.type = "factor",
  force.dummies = FALSE,
  impute.new.levels = TRUE,
  recode.factor.levels = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="impute_+3A_target">target</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Name of the column(s) specifying the response.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_classes">classes</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
Named list containing imputation techniques for classes of columns.
E.g. <code>list(numeric = imputeMedian())</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_cols">cols</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
Named list containing names of imputation methods to impute missing values
in the data column referenced by the list element's name. Overrules imputation set via
<code>classes</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_dummy.classes">dummy.classes</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Classes of columns to create dummy columns for.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_dummy.cols">dummy.cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Column names to create dummy columns (containing binary missing indicator) for.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_dummy.type">dummy.type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
How dummy columns are encoded. Either as 0/1 with type &ldquo;numeric&rdquo;
or as &ldquo;factor&rdquo;.
Default is &ldquo;factor&rdquo;.</p>
</td></tr>
<tr><td><code id="impute_+3A_force.dummies">force.dummies</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Force dummy creation even if the respective data column does not
contain any NAs. Note that (a) most learners will complain about
constant columns created this way but (b) your feature set might
be stochastic if you turn this off.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_impute.new.levels">impute.new.levels</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If new, unencountered factor level occur during reimputation,
should these be handled as NAs and then be imputed the same way?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_recode.factor.levels">recode.factor.levels</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Recode factor levels after reimputation, so they match the respective element of
<code>lvls</code> (in the description object) and therefore match the levels of the
feature factor in the training data after imputation?.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The description object contains these slots
</p>

<ul>
<li><p> target (<a href="base.html#topic+character">character</a>): See argument
</p>
</li>
<li><p> features (<a href="base.html#topic+character">character</a>): Feature names (column names of <code>data</code>)
</p>
</li>
<li><p> classes (<a href="base.html#topic+character">character</a>): Feature classes (storage type of <code>data</code>)
</p>
</li>
<li><p> lvls (named <a href="base.html#topic+list">list</a>): Mapping of column names of factor features to their levels, including newly created ones during imputation
</p>
</li>
<li><p> impute (named <a href="base.html#topic+list">list</a>): Mapping of column names to imputation functions
</p>
</li>
<li><p> dummies (named <a href="base.html#topic+list">list</a>): Mapping of column names to imputation functions
</p>
</li>
<li><p> impute.new.levels (<code>logical(1)</code>): See argument
</p>
</li>
<li><p> recode.factor.levels (<code>logical(1)</code>): See argument
</p>
</li></ul>



<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>)
</p>

<ul>
<li><p> data (<a href="base.html#topic+data.frame">data.frame</a>): Imputed data.
</p>
</li>
<li><p> desc (<code>ImputationDesc</code>): Description object.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other impute: 
<code><a href="#topic+imputations">imputations</a></code>,
<code><a href="#topic+makeImputeMethod">makeImputeMethod</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+reimpute">reimpute</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = data.frame(x = c(1, 1, NA), y = factor(c("a", "a", "b")), z = 1:3)
imputed = impute(df, target = character(0), cols = list(x = 99, y = imputeMode()))
print(imputed$data)
reimpute(data.frame(x = NA_real_), imputed$desc)
</code></pre>

<hr>
<h2 id='iris.task'>Iris classification task.</h2><span id='topic+iris.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>iris.task</code>).
</p>


<h3>References</h3>

<p>See <a href="datasets.html#topic+iris">datasets::iris</a>.
</p>

<hr>
<h2 id='isFailureModel'>Is the model a FailureModel?</h2><span id='topic+isFailureModel'></span>

<h3>Description</h3>

<p>Such a model is created when one sets the corresponding option in <a href="#topic+configureMlr">configureMlr</a>.
</p>
<p>For complex wrappers this getter returns <code>TRUE</code> if ANY model contained in it failed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>isFailureModel(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="isFailureModel_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>logical(1)</code>).
</p>

<hr>
<h2 id='joinClassLevels'>Join some class existing levels to new, larger class levels for classification problems.</h2><span id='topic+joinClassLevels'></span>

<h3>Description</h3>

<p>Join some class existing levels to new, larger class levels for classification problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>joinClassLevels(task, new.levels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="joinClassLevels_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="joinClassLevels_+3A_new.levels">new.levels</code></td>
<td>
<p>(<code>list</code> of <code>character</code>)<br />
Element names specify the new class levels to create, while the corresponding element
character vector specifies the existing class levels which will be joined to the new one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Task">Task</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>joinClassLevels(iris.task, new.levels = list(foo = c("setosa", "virginica")))
</code></pre>

<hr>
<h2 id='learnerArgsToControl'>Convert arguments to control structure.</h2><span id='topic+learnerArgsToControl'></span>

<h3>Description</h3>

<p>Find all elements in <code>...</code> which are not missing and
call <code>control</code> on them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnerArgsToControl(control, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="learnerArgsToControl_+3A_control">control</code></td>
<td>
<p>(<code>function</code>)<br />
Function that creates control structure.</p>
</td></tr>
<tr><td><code id="learnerArgsToControl_+3A_...">...</code></td>
<td>
<p>(any)<br />
Arguments for control structure function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Control structure for learner.
</p>

<hr>
<h2 id='LearnerProperties'>Query properties of learners.</h2><span id='topic+LearnerProperties'></span><span id='topic+getLearnerProperties'></span><span id='topic+hasLearnerProperties'></span>

<h3>Description</h3>

<p>Properties can be accessed with <code>getLearnerProperties(learner)</code>, which returns a
character vector.
</p>
<p>The learner properties are defined as follows:
</p>

<dl>
<dt>numerics, factors, ordered</dt><dd><p>Can numeric, factor or ordered factor features be handled?</p>
</dd>
<dt>functionals</dt><dd><p>Can an arbitrary number of functional features be handled?</p>
</dd>
<dt>single.functional</dt><dd><p>Can exactly one functional feature be handled?</p>
</dd>
<dt>missings</dt><dd><p>Can missing values in features be handled?</p>
</dd>
<dt>weights</dt><dd><p>Can observations be weighted during fitting?</p>
</dd>
<dt>oneclas, twoclass, multiclass</dt><dd><p>Only for classif: Can one-class, two-class or multi-class classification problems be handled?</p>
</dd>
<dt>class.weights</dt><dd><p>Only for classif: Can class weights be handled?</p>
</dd>
<dt>rcens, lcens, icens</dt><dd><p>Only for surv: Can right, left, or interval censored data be handled?</p>
</dd>
<dt>prob</dt><dd><p>For classif, cluster, multilabel, surv: Can probabilites be predicted?</p>
</dd>
<dt>se</dt><dd><p>Only for regr: Can standard errors be predicted?</p>
</dd>
<dt>oobpreds</dt><dd><p>Only for classif, regr and surv: Can out of bag predictions be extracted from the trained model?</p>
</dd>
<dt>featimp</dt><dd><p>For classif, regr, surv: Does the model support extracting information on feature importance?</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>getLearnerProperties(learner)

hasLearnerProperties(learner, props)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LearnerProperties_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="LearnerProperties_+3A_props">props</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Vector of properties to query.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>getLearnerProperties</code> returns a character vector with learner properties.
<code>hasLearnerProperties</code> returns a logical vector of the same length as <code>props</code>.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='learners'>List of supported learning algorithms.</h2><span id='topic+learners'></span>

<h3>Description</h3>

<p>All supported learners can be found by <a href="#topic+listLearners">listLearners</a> or as a table
in the tutorial appendix: <a href="https://mlr.mlr-org.com/articles/tutorial/integrated_learners.html">https://mlr.mlr-org.com/articles/tutorial/integrated_learners.html</a>.
</p>

<hr>
<h2 id='listFilterEnsembleMethods'>List ensemble filter methods.</h2><span id='topic+listFilterEnsembleMethods'></span>

<h3>Description</h3>

<p>Returns a subset-able dataframe with filter information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listFilterEnsembleMethods(desc = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listFilterEnsembleMethods_+3A_desc">desc</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Provide more detailed information about filters.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>

<hr>
<h2 id='listFilterMethods'>List filter methods.</h2><span id='topic+listFilterMethods'></span>

<h3>Description</h3>

<p>Returns a subset-able dataframe with filter information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listFilterMethods(
  desc = TRUE,
  tasks = FALSE,
  features = FALSE,
  include.deprecated = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listFilterMethods_+3A_desc">desc</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Provide more detailed information about filters.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="listFilterMethods_+3A_tasks">tasks</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Provide information on supported tasks.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="listFilterMethods_+3A_features">features</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Provide information on supported features.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="listFilterMethods_+3A_include.deprecated">include.deprecated</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should deprecated filter methods be included in the list.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>

<hr>
<h2 id='listLearnerProperties'>List the supported learner properties</h2><span id='topic+listLearnerProperties'></span>

<h3>Description</h3>

<p>This is useful for determining which learner properties are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listLearnerProperties(type = "any")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listLearnerProperties_+3A_type">type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Only return properties for a specified task type. Default is &ldquo;any&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>

<hr>
<h2 id='listLearners'>Find matching learning algorithms.</h2><span id='topic+listLearners'></span><span id='topic+listLearners.default'></span><span id='topic+listLearners.character'></span><span id='topic+listLearners.Task'></span>

<h3>Description</h3>

<p>Returns learning algorithms which have specific characteristics, e.g.
whether they support missing values, case weights, etc.
</p>
<p>Note that the packages of all learners are loaded during the search if you create them.
This can be a lot. If you do not create them we only inspect properties of the S3 classes.
This will be a lot faster.
</p>
<p>Note that for general cost-sensitive learning, mlr currently supports mainly
&ldquo;wrapper&rdquo; approaches like <a href="#topic+CostSensWeightedPairsWrapper">CostSensWeightedPairsWrapper</a>,
which are not listed, as they are not basic R learning algorithms.
The same applies for many multilabel methods, see, e.g., <a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listLearners(
  obj = NA_character_,
  properties = character(0L),
  quiet = TRUE,
  warn.missing.packages = TRUE,
  check.packages = FALSE,
  create = FALSE
)

## Default S3 method:
listLearners(
  obj = NA_character_,
  properties = character(0L),
  quiet = TRUE,
  warn.missing.packages = TRUE,
  check.packages = FALSE,
  create = FALSE
)

## S3 method for class 'character'
listLearners(
  obj = NA_character_,
  properties = character(0L),
  quiet = TRUE,
  warn.missing.packages = TRUE,
  check.packages = FALSE,
  create = FALSE
)

## S3 method for class 'Task'
listLearners(
  obj = NA_character_,
  properties = character(0L),
  quiet = TRUE,
  warn.missing.packages = TRUE,
  check.packages = TRUE,
  create = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listLearners_+3A_obj">obj</code></td>
<td>
<p>(<code>character(1)</code> | <a href="#topic+Task">Task</a>)<br />
Either <code>character(1)</code> task or the type of the task, in the latter case one of:
&ldquo;classif&rdquo; &ldquo;regr&rdquo; &ldquo;surv&rdquo; &ldquo;costsens&rdquo; &ldquo;cluster&rdquo; &ldquo;multilabel&rdquo;.
Default is <code>NA</code> matching all types.</p>
</td></tr>
<tr><td><code id="listLearners_+3A_properties">properties</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Set of required properties to filter for. Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="listLearners_+3A_quiet">quiet</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Construct learners quietly to check their properties, shows no package startup messages.
Turn off if you suspect errors.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="listLearners_+3A_warn.missing.packages">warn.missing.packages</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If some learner cannot be constructed because its package is missing,
should a warning be shown?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="listLearners_+3A_check.packages">check.packages</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Check if required packages are installed. Calls <code>find.package()</code>.
If <code>create</code> is <code>TRUE</code>, this is done implicitly and the value of this parameter is ignored.
If <code>create</code> is <code>FALSE</code> and <code>check.packages</code> is <code>TRUE</code> the returned table only
contains learners whose dependencies are installed.
If <code>check.packages</code> set to <code>FALSE</code>, learners that cannot actually be constructed because
of missing packages may be returned.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="listLearners_+3A_create">create</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Instantiate objects (or return info table)?
Packages are loaded if and only if this option is <code>TRUE</code>.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>([data.frame<code>|</code>list' of <a href="#topic+Learner">Learner</a>).
Either a descriptive data.frame that allows access to all properties of the learners
or a list of created learner objects (named by ids of listed learners).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
listLearners("classif", properties = c("multiclass", "prob"))
data = iris
task = makeClassifTask(data = data, target = "Species")
listLearners(task)

## End(Not run)
</code></pre>

<hr>
<h2 id='listMeasureProperties'>List the supported measure properties.</h2><span id='topic+listMeasureProperties'></span>

<h3>Description</h3>

<p>This is useful for determining which measure properties are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listMeasureProperties()
</code></pre>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>

<hr>
<h2 id='listMeasures'>Find matching measures.</h2><span id='topic+listMeasures'></span><span id='topic+listMeasures.default'></span><span id='topic+listMeasures.character'></span><span id='topic+listMeasures.Task'></span>

<h3>Description</h3>

<p>Returns the matching measures which have specific characteristics, e.g.
whether they supports classification or regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listMeasures(obj, properties = character(0L), create = FALSE)

## Default S3 method:
listMeasures(obj, properties = character(0L), create = FALSE)

## S3 method for class 'character'
listMeasures(obj, properties = character(0L), create = FALSE)

## S3 method for class 'Task'
listMeasures(obj, properties = character(0L), create = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="listMeasures_+3A_obj">obj</code></td>
<td>
<p>(<code>character(1)</code> | <a href="#topic+Task">Task</a>)<br />
Either <code>character(1)</code> task or the type of the task, in the latter case one of:
&ldquo;classif&rdquo; &ldquo;regr&rdquo; &ldquo;surv&rdquo; &ldquo;costsens&rdquo; &ldquo;cluster&rdquo; &ldquo;multilabel&rdquo;.
Default is <code>NA</code> matching all types.</p>
</td></tr>
<tr><td><code id="listMeasures_+3A_properties">properties</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Set of required properties to filter for.
See <a href="#topic+Measure">Measure</a> for some standardized properties.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="listMeasures_+3A_create">create</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Instantiate objects (or return strings)?
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>([character<code>|</code>list' of <a href="#topic+Measure">Measure</a>). Class names of matching
measures or instantiated objects.
</p>

<hr>
<h2 id='listTaskTypes'>List the supported task types in mlr</h2><span id='topic+listTaskTypes'></span>

<h3>Description</h3>

<p>Returns a character vector with each of the supported task types in mlr.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>listTaskTypes()
</code></pre>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>

<hr>
<h2 id='lung.task'>NCCTG Lung Cancer survival task.</h2><span id='topic+lung.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>lung.task</code>).
</p>


<h3>References</h3>

<p>See <a href="survival.html#topic+lung">survival::lung</a>.
Incomplete cases have been removed from the task.
</p>

<hr>
<h2 id='makeAggregation'>Specify your own aggregation of measures.</h2><span id='topic+makeAggregation'></span>

<h3>Description</h3>

<p>This is an advanced feature of mlr. It gives access to some
inner workings so the result might not be compatible with everything!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeAggregation(id, name = id, properties, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeAggregation_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of the aggregation method (preferably the same name as the generated function).</p>
</td></tr>
<tr><td><code id="makeAggregation_+3A_name">name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Long name of the aggregation method. Default is <code>id</code>.</p>
</td></tr>
<tr><td><code id="makeAggregation_+3A_properties">properties</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Set of aggregation properties.
</p>

<dl>
<dt>req.train</dt><dd><p>Are prediction or train sets required to calculate the aggregation?</p>
</dd>
<dt>req.test</dt><dd><p>Are prediction or test sets required to calculate the aggregation?</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="makeAggregation_+3A_fun">fun</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(task, perf.test, perf.train, measure, group, pred)&#8288;</code>)<br />
Calculates the aggregated performance. In most cases you will only need the performances
<code>perf.test</code> and optionally <code>perf.train</code> on the test and training data sets.
</p>

<dl>
<dt><code>task</code> (<a href="#topic+Task">Task</a>)</dt><dd><p>The task.</p>
</dd>
<dt><code>perf.test</code> (<a href="base.html#topic+numeric">numeric</a>)</dt><dd>
<p><a href="#topic+performance">performance</a> results on the test data sets.</p>
</dd>
<dt><code>perf.train</code> (<a href="base.html#topic+numeric">numeric</a>)</dt><dd>
<p><a href="#topic+performance">performance</a> results on the training data sets.</p>
</dd>
<dt><code>measure</code> (<a href="#topic+Measure">Measure</a>)</dt><dd>
<p>Performance measure.</p>
</dd>
<dt><code>group</code> (<a href="base.html#topic+factor">factor</a>)</dt><dd>
<p>Grouping of resampling iterations. This encodes whether specific iterations
'belong together' (e.g. repeated CV).</p>
</dd>
<dt><code>pred</code> (<a href="#topic+Prediction">Prediction</a>)</dt><dd>
<p>Prediction object.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Aggregation">Aggregation</a>).
</p>


<h3>See Also</h3>

<p><a href="#topic+aggregations">aggregations</a>, <a href="#topic+setAggregation">setAggregation</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># computes the interquartile range on all performance values
test.iqr = makeAggregation(
  id = "test.iqr", name = "Test set interquartile range",
  properties = "req.test",
  fun = function(task, perf.test, perf.train, measure, group, pred) IQR(perf.test)
)
</code></pre>

<hr>
<h2 id='makeBaggingWrapper'>Fuse learner with the bagging technique.</h2><span id='topic+makeBaggingWrapper'></span>

<h3>Description</h3>

<p>Fuses a learner with the bagging method
(i.e., similar to what a <code>randomForest</code> does).
Creates a learner object, which can be
used like any other learner object.
Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>
<p>Bagging is implemented as follows:
For each iteration a random data subset is sampled (with or without replacement)
and potentially the number of features is also restricted to
a random subset. Note that this is usually handled in a slightly different way
in the random forest where features are sampled at each tree split).
</p>
<p>Prediction works as follows:
For classification we do majority voting to create a discrete label and
probabilities are predicted by considering the proportions of all predicted labels.
For regression the mean value and the standard deviations across predictions is computed.
</p>
<p>Note that the passed base learner must always have <code>predict.type = 'response'</code>,
while the BaggingWrapper can estimate probabilities and standard errors, so it can
be set, e.g., to <code>predict.type = 'prob'</code>. For this reason, when you call
<a href="#topic+setPredictType">setPredictType</a>, the type is only set for the BaggingWrapper, not passed
down to the inner learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeBaggingWrapper(
  learner,
  bw.iters = 10L,
  bw.replace = TRUE,
  bw.size,
  bw.feats = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeBaggingWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeBaggingWrapper_+3A_bw.iters">bw.iters</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Iterations = number of fitted models in bagging.
Default is 10.</p>
</td></tr>
<tr><td><code id="makeBaggingWrapper_+3A_bw.replace">bw.replace</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Sample bags with replacement (bootstrapping)?
Default is TRUE.</p>
</td></tr>
<tr><td><code id="makeBaggingWrapper_+3A_bw.size">bw.size</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Percentage size of sampled bags.
Default is 1 for bootstrapping and 0.632 for subsampling.</p>
</td></tr>
<tr><td><code id="makeBaggingWrapper_+3A_bw.feats">bw.feats</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Percentage size of randomly selected features in bags.
Default is 1.
At least one feature will always be selected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeBaseWrapper'>Exported for internal use only.</h2><span id='topic+makeBaseWrapper'></span>

<h3>Description</h3>

<p>Exported for internal use only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeBaseWrapper(
  id,
  type,
  next.learner,
  package = character(0L),
  par.set = makeParamSet(),
  par.vals = list(),
  learner.subclass,
  model.subclass,
  cache = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeBaseWrapper_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object. Used to display object.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_type">type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Learner type.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_next.learner">next.learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a>)<br />
Learner to wrap.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_package">package</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Packages to load when loading learner.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_par.set">par.set</code></td>
<td>
<p>(ParamSet)<br />
Parameter set.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Optional list of named (hyper)parameter values.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_learner.subclass">learner.subclass</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Class to assign the new object.</p>
</td></tr>
<tr><td><code id="makeBaseWrapper_+3A_model.subclass">model.subclass</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Class to assign learner models.</p>
</td></tr>
</table>

<hr>
<h2 id='makeChainModel'>Only exported for internal use.</h2><span id='topic+makeChainModel'></span>

<h3>Description</h3>

<p>Only exported for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeChainModel(next.model, cl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeChainModel_+3A_next.model">next.model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The next model.</p>
</td></tr>
<tr><td><code id="makeChainModel_+3A_cl">cl</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Subclass to assign to the resulting model.</p>
</td></tr>
</table>

<hr>
<h2 id='makeClassificationViaRegressionWrapper'>Classification via regression wrapper.</h2><span id='topic+makeClassificationViaRegressionWrapper'></span>

<h3>Description</h3>

<p>Builds regression models that predict for the positive class whether a particular example belongs to it (1) or not (-1).
</p>
<p>Probabilities are generated by transforming the predictions with a softmax.
</p>
<p>Inspired by WEKA's ClassificationViaRegression (http://weka.sourceforge.net/doc.dev/weka/classifiers/meta/ClassificationViaRegression.html).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeClassificationViaRegressionWrapper(learner, predict.type = "response")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeClassificationViaRegressionWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeClassificationViaRegressionWrapper_+3A_predict.type">predict.type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
&ldquo;response&rdquo; (= labels) or &ldquo;prob&rdquo; (= probabilities and labels by selecting the one with maximal probability).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lrn = makeLearner("regr.rpart")
lrn = makeClassificationViaRegressionWrapper(lrn)
mod = train(lrn, sonar.task, subset = 1:140)
predictions = predict(mod, newdata = getTaskData(sonar.task)[141:208, 1:60])
</code></pre>

<hr>
<h2 id='makeClassifTask'>Create a classification task.</h2><span id='topic+makeClassifTask'></span><span id='topic+ClassifTask'></span>

<h3>Description</h3>

<p>Create a classification task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeClassifTask(
  id = deparse(substitute(data)),
  data,
  target,
  weights = NULL,
  blocking = NULL,
  coordinates = NULL,
  positive = NA_character_,
  fixup.data = "warn",
  check.data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeClassifTask_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
For survival analysis these are the names of the survival time and event columns,
so it has length 2. For multilabel classification it contains the names of the logical
columns that encode whether a label is present or not and its length corresponds to the
number of classes.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
Cannot be set for cost-sensitive learning.
Default is <code>NULL</code> which means no (= equal) weights.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_positive">positive</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Positive class for binary classification (otherwise ignored and set to NA).
Default is the first factor level of the target attribute.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="makeClassifTask_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+Task">Task</a> <a href="#topic+CostSensTask">CostSensTask</a> <a href="#topic+ClusterTask">ClusterTask</a> <a href="#topic+MultilabelTask">MultilabelTask</a> <a href="#topic+RegrTask">RegrTask</a> <a href="#topic+SurvTask">SurvTask</a>
</p>

<hr>
<h2 id='makeClassifTaskDesc'>Exported for internal use.</h2><span id='topic+makeClassifTaskDesc'></span><span id='topic+makeClusterTaskDesc'></span><span id='topic+makeCostSensTaskDesc'></span><span id='topic+makeMultilabelTaskDesc'></span><span id='topic+makeRegrTaskDesc'></span><span id='topic+makeSurvTaskDesc'></span><span id='topic+makeTaskDesc'></span>

<h3>Description</h3>

<p>Exported for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeClassifTaskDesc(id, data, target, weights, blocking, positive, coordinates)

makeClusterTaskDesc(id, data, weights, blocking, coordinates)

makeCostSensTaskDesc(id, data, target, blocking, costs, coordinates)

makeMultilabelTaskDesc(id, data, target, weights, blocking, coordinates)

makeRegrTaskDesc(id, data, target, weights, blocking, coordinates)

makeSurvTaskDesc(id, data, target, weights, blocking, coordinates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeClassifTaskDesc_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
task id</p>
</td></tr>
<tr><td><code id="makeClassifTaskDesc_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
data</p>
</td></tr>
<tr><td><code id="makeClassifTaskDesc_+3A_target">target</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
target columns</p>
</td></tr>
<tr><td><code id="makeClassifTaskDesc_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
weights</p>
</td></tr>
<tr><td><code id="makeClassifTaskDesc_+3A_blocking">blocking</code></td>
<td>
<p>([numeric'<br />
task data blocking</p>
</td></tr>
<tr><td><code id="makeClassifTaskDesc_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided (<a href="base.html#topic+data.frame">data.frame</a>) needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
</table>

<hr>
<h2 id='makeClusterTask'>Create a cluster task.</h2><span id='topic+makeClusterTask'></span><span id='topic+ClusterTask'></span>

<h3>Description</h3>

<p>Create a cluster task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeClusterTask(
  id = deparse(substitute(data)),
  data,
  weights = NULL,
  blocking = NULL,
  coordinates = NULL,
  fixup.data = "warn",
  check.data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeClusterTask_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="makeClusterTask_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="makeClusterTask_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
Cannot be set for cost-sensitive learning.
Default is <code>NULL</code> which means no (= equal) weights.</p>
</td></tr>
<tr><td><code id="makeClusterTask_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="makeClusterTask_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
<tr><td><code id="makeClusterTask_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="makeClusterTask_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+Task">Task</a> <a href="#topic+ClassifTask">ClassifTask</a> <a href="#topic+CostSensTask">CostSensTask</a> <a href="#topic+MultilabelTask">MultilabelTask</a> <a href="#topic+RegrTask">RegrTask</a> <a href="#topic+SurvTask">SurvTask</a>
</p>

<hr>
<h2 id='makeConstantClassWrapper'>Wraps a classification learner to support problems where the class label is (almost) constant.</h2><span id='topic+makeConstantClassWrapper'></span>

<h3>Description</h3>

<p>If the training data contains only a single class (or almost only a single class), this wrapper creates a model that always predicts the constant class in the training data. In all other cases, the underlying learner is trained and the resulting model used for predictions.
</p>
<p>Probabilities can be predicted and will be 1 or 0 depending on whether the label matches the majority class or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeConstantClassWrapper(learner, frac = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeConstantClassWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeConstantClassWrapper_+3A_frac">frac</code></td>
<td>
<p><code>numeric(1)</code><br />
The fraction of labels in [0, 1) that can be different from the majority label. Default is 0, which means that constant labels are only predicted if there is exactly one label in the data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeCostMeasure'>Creates a measure for non-standard misclassification costs.</h2><span id='topic+makeCostMeasure'></span>

<h3>Description</h3>

<p>Creates a cost measure for non-standard classification error costs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCostMeasure(
  id = "costs",
  minimize = TRUE,
  costs,
  combine = mean,
  best = NULL,
  worst = NULL,
  name = id,
  note = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeCostMeasure_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of measure.
Default is &ldquo;costs&rdquo;.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_minimize">minimize</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the measure be minimized?
Otherwise you are effectively specifying a benefits matrix.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_costs">costs</code></td>
<td>
<p>(<a href="base.html#topic+matrix">matrix</a>)<br />
Matrix of misclassification costs. Rows and columns have to be named with class labels, order does not matter.
Rows indicate true classes, columns predicted classes.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_combine">combine</code></td>
<td>
<p>(<code>function</code>)<br />
How to combine costs over all cases for a SINGLE test set?
Note this is not the same as the <code>aggregate</code> argument in <a href="#topic+makeMeasure">makeMeasure</a>
You can set this as well via <a href="#topic+setAggregation">setAggregation</a>, as for any measure.
Default is <a href="base.html#topic+mean">mean</a>.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_best">best</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Best obtainable value for measure.
Default is -<code>Inf</code> or <code>Inf</code>, depending on <code>minimize</code>.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_worst">worst</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Worst obtainable value for measure.
Default is <code>Inf</code> or -<code>Inf</code>, depending on <code>minimize</code>.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_name">name</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>) <br />
Name of the measure. Default is <code>id</code>.</p>
</td></tr>
<tr><td><code id="makeCostMeasure_+3A_note">note</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>) <br />
Description and additional notes for the measure. Default is &ldquo;&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Measure">Measure</a>.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>

<hr>
<h2 id='makeCostSensClassifWrapper'>Wraps a classification learner for use in cost-sensitive learning.</h2><span id='topic+makeCostSensClassifWrapper'></span><span id='topic+CostSensClassifWrapper'></span><span id='topic+CostSensClassifModel'></span>

<h3>Description</h3>

<p>Creates a wrapper, which can be used like any other learner object.
The classification model can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>
<p>This is a very naive learner, where the costs are transformed into classification labels -
the label for each case is the name of class with minimal costs.
(If ties occur, the label which is better on average w.r.t. costs over all training data is
preferred.)
Then the classifier is fitted to that data and subsequently used for prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCostSensClassifWrapper(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeCostSensClassifWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The classification learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other costsens: 
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeCostSensTask">makeCostSensTask</a>()</code>,
<code><a href="#topic+makeCostSensWeightedPairsWrapper">makeCostSensWeightedPairsWrapper</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeCostSensRegrWrapper'>Wraps a regression learner for use in cost-sensitive learning.</h2><span id='topic+makeCostSensRegrWrapper'></span><span id='topic+CostSensRegrWrapper'></span><span id='topic+CostSensRegrModel'></span>

<h3>Description</h3>

<p>Creates a wrapper, which can be used like any other learner object.
Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>
<p>For each class in the task, an individual regression model is fitted for the costs of that class.
During prediction, the class with the lowest predicted costs is selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCostSensRegrWrapper(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeCostSensRegrWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The regression learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other costsens: 
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensTask">makeCostSensTask</a>()</code>,
<code><a href="#topic+makeCostSensWeightedPairsWrapper">makeCostSensWeightedPairsWrapper</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeCostSensTask'>Create a cost-sensitive classification task.</h2><span id='topic+makeCostSensTask'></span><span id='topic+CostSensTask'></span>

<h3>Description</h3>

<p>Create a cost-sensitive classification task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCostSensTask(
  id = deparse(substitute(data)),
  data,
  costs,
  blocking = NULL,
  coordinates = NULL,
  fixup.data = "warn",
  check.data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeCostSensTask_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="makeCostSensTask_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="makeCostSensTask_+3A_costs">costs</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A numeric matrix or data frame containing the costs of misclassification.
We assume the general case of observation specific costs.
This means we have n rows, corresponding to the observations, in the same order as <code>data</code>.
The columns correspond to classes and their names are the class labels
(if unnamed we use y1 to yk as labels).
Each entry (i,j) of the matrix specifies the cost of predicting class j
for observation i.</p>
</td></tr>
<tr><td><code id="makeCostSensTask_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="makeCostSensTask_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
<tr><td><code id="makeCostSensTask_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="makeCostSensTask_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+Task">Task</a> <a href="#topic+ClassifTask">ClassifTask</a> <a href="#topic+ClusterTask">ClusterTask</a> <a href="#topic+MultilabelTask">MultilabelTask</a> <a href="#topic+RegrTask">RegrTask</a> <a href="#topic+SurvTask">SurvTask</a>
</p>
<p>Other costsens: 
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeCostSensWeightedPairsWrapper">makeCostSensWeightedPairsWrapper</a>()</code>
</p>

<hr>
<h2 id='makeCostSensWeightedPairsWrapper'>Wraps a classifier for cost-sensitive learning to produce a weighted pairs model.</h2><span id='topic+makeCostSensWeightedPairsWrapper'></span><span id='topic+CostSensWeightedPairsWrapper'></span><span id='topic+CostSensWeightedPairsModel'></span>

<h3>Description</h3>

<p>Creates a wrapper, which can be used like any other learner object.
Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>
<p>For each pair of labels, we fit a binary classifier.
For each observation we define the label to be the element of the pair with minimal costs.
During fitting, we also weight the observation with the absolute difference in costs.
Prediction is performed by simple voting.
</p>
<p>This approach is sometimes called cost-sensitive one-vs-one (CS-OVO),
because it is obviously very similar to the
one-vs-one approach where one reduces a normal multi-class problem to
multiple binary ones and aggregates by voting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCostSensWeightedPairsWrapper(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeCostSensWeightedPairsWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The classification learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Learner">Learner</a>).
</p>


<h3>References</h3>

<p>Lin, HT.:
Reduction from Cost-sensitive Multiclass Classification to
One-versus-one Binary Classification.
In: Proceedings of the Sixth Asian Conference on Machine Learning.
JMLR Workshop and Conference Proceedings, vol 39, pp. 371-386. JMLR W&amp;CP (2014).
<a href="https://proceedings.mlr.press/v39/lin14.pdf">https://proceedings.mlr.press/v39/lin14.pdf</a>
</p>


<h3>See Also</h3>

<p>Other costsens: 
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeCostSensTask">makeCostSensTask</a>()</code>
</p>

<hr>
<h2 id='makeCustomResampledMeasure'>Construct your own resampled performance measure.</h2><span id='topic+makeCustomResampledMeasure'></span>

<h3>Description</h3>

<p>Construct your own performance measure, used after resampling. Note that
individual training / test set performance values will be set to <code>NA</code>, you
only calculate an aggregated value. If you can define a function that makes
sense for every single training / test set, implement your own <a href="#topic+Measure">Measure</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeCustomResampledMeasure(
  measure.id,
  aggregation.id,
  minimize = TRUE,
  properties = character(0L),
  fun,
  extra.args = list(),
  best = NULL,
  worst = NULL,
  measure.name = measure.id,
  aggregation.name = aggregation.id,
  note = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeCustomResampledMeasure_+3A_measure.id">measure.id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Short name of measure.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_aggregation.id">aggregation.id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Short name of aggregation.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_minimize">minimize</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the measure be minimized?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_properties">properties</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Set of measure properties. For a list of values see <a href="#topic+Measure">Measure</a>.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_fun">fun</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(task, group, pred, extra.args)&#8288;</code>)<br />
Calculates performance value from <a href="#topic+ResamplePrediction">ResamplePrediction</a> object. For rare
cases you can also use the task, the grouping or the extra arguments
<code>extra.args</code>.
- <code>task</code> (<a href="#topic+Task">Task</a>)<br />
The task.
- <code>group</code> (<a href="base.html#topic+factor">factor</a>)<br />
Grouping of resampling iterations. This encodes whether specific
iterations 'belong together' (e.g. repeated CV).
- <code>pred</code> (<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.
- <code>extra.args</code> (<a href="base.html#topic+list">list</a>)<br />
See below.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_extra.args">extra.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
List of extra arguments which will always be passed to <code>fun</code>.
Default is empty list.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_best">best</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Best obtainable value for measure.
Default is -<code>Inf</code> or <code>Inf</code>, depending on <code>minimize</code>.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_worst">worst</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Worst obtainable value for measure.
Default is <code>Inf</code> or -<code>Inf</code>, depending on <code>minimize</code>.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_measure.name">measure.name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Long name of measure.
Default is <code>measure.id</code>.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_aggregation.name">aggregation.name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Long name of the aggregation.
Default is <code>aggregation.id</code>.</p>
</td></tr>
<tr><td><code id="makeCustomResampledMeasure_+3A_note">note</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>) <br />
Description and additional notes for the measure. Default is &ldquo;&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Measure">Measure</a>.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>

<hr>
<h2 id='makeDownsampleWrapper'>Fuse learner with simple downsampling (subsampling).</h2><span id='topic+makeDownsampleWrapper'></span>

<h3>Description</h3>

<p>Creates a learner object, which can be
used like any other learner object.
It will only be trained on a subset of the original data to save computational time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeDownsampleWrapper(learner, dw.perc = 1, dw.stratify = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeDownsampleWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeDownsampleWrapper_+3A_dw.perc">dw.perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
See <a href="#topic+downsample">downsample</a>.
Default is 1.</p>
</td></tr>
<tr><td><code id="makeDownsampleWrapper_+3A_dw.stratify">dw.stratify</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
See <a href="#topic+downsample">downsample</a>.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other downsample: 
<code><a href="#topic+downsample">downsample</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeDummyFeaturesWrapper'>Fuse learner with dummy feature creator.</h2><span id='topic+makeDummyFeaturesWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with the dummy feature creator (see <a href="#topic+createDummyFeatures">createDummyFeatures</a>).
Returns a learner which can be used like any other learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeDummyFeaturesWrapper(learner, method = "1-of-n", cols = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeDummyFeaturesWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeDummyFeaturesWrapper_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Available are:
</p>

<dl>
<dt>&quot;1-of-n&quot;:</dt><dd><p>For n factor levels there will be n dummy variables.</p>
</dd>
<dt>&quot;reference&quot;:</dt><dd><p>There will be n-1 dummy variables leaving out the first factor level of each variable.</p>
</dd>
</dl>

<p>Default is &ldquo;1-of-n&rdquo;.</p>
</td></tr>
<tr><td><code id="makeDummyFeaturesWrapper_+3A_cols">cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Columns to create dummy features for. Default is to use all columns.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeExtractFDAFeatMethod'>Constructor for FDA feature extraction methods.</h2><span id='topic+makeExtractFDAFeatMethod'></span>

<h3>Description</h3>

<p>This can be used to implement custom FDA feature extraction.
Takes a <code>learn</code> and a <code>reextract</code> function along with some optional
parameters to those as argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeExtractFDAFeatMethod(learn, reextract, args = list(), par.set = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeExtractFDAFeatMethod_+3A_learn">learn</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, target, col, ...)&#8288;</code>)<br />
Function to learn and extract information on functional column <code>col</code>.
Arguments are:
</p>

<ul>
<li><p> data <a href="base.html#topic+data.frame">data.frame</a><br />
Data.frame containing matricies with one row per observation of a single functional
or time series and one column per meahttps://github.com/mlr-org/mlr/pull/2005/conflict?name=R%252FextractFDAFeatures.R&amp;ancestor_oid=bdc5d882cc86adac456842bebf1a2cf9bb0eb648&amp;base_oid=55d472e23f5c3eb8099607bd9f539034d93e82a4&amp;head_oid=4076800589c60b20acc926e5a545df9f73193b65surement time point.
All entries need to be numeric.
</p>
</li>
<li><p> target (<code>character(1)</code>)<br />
Name of the target variable. Default: &ldquo;NULL&rdquo;.
The variable is only set to be consistent with the API.
</p>
</li>
<li><p> col (<code>character(1)</code> | <code>numeric(1)</code>)<br />
column names or indices, the extraction should be performed on.
The function has to return a named list of values.
</p>
</li></ul>
</td></tr>
<tr><td><code id="makeExtractFDAFeatMethod_+3A_reextract">reextract</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, target, col, ...)&#8288;</code>)<br />
Function used for reextracting data in predict phase.
Can be equal to <code>learn</code>.</p>
</td></tr>
<tr><td><code id="makeExtractFDAFeatMethod_+3A_args">args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Named list of arguments to pass to <code>learn</code> via <code>...</code>.</p>
</td></tr>
<tr><td><code id="makeExtractFDAFeatMethod_+3A_par.set">par.set</code></td>
<td>
<p>(ParamSet)<br />
Paramset added to the learner if used in conjunction with a <a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>.
Can be <code>NULL</code>.'</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other fda: 
<code><a href="#topic+extractFDAFeatures">extractFDAFeatures</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>
</p>

<hr>
<h2 id='makeExtractFDAFeatsWrapper'>Fuse learner with an extractFDAFeatures method.</h2><span id='topic+makeExtractFDAFeatsWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with an extractFDAFeatures method. Creates a learner object, which can be
used like any other learner object.
Internally uses <a href="#topic+extractFDAFeatures">extractFDAFeatures</a> before training the learner and
<a href="#topic+reextractFDAFeatures">reextractFDAFeatures</a> before predicting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeExtractFDAFeatsWrapper(learner, feat.methods = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeExtractFDAFeatsWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeExtractFDAFeatsWrapper_+3A_feat.methods">feat.methods</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
List of functional features along with the desired methods for each functional feature.
&ldquo;all&rdquo; applies the <a href="#topic+extractFDAFeatures">extractFDAFeatures</a> method to each
functional feature.
Names of <code>feat.methods</code> must match column names of functional features.
Available feature extraction methods are available under family <code>fda_featextractor</code>.
Specifying a functional feature multiple times with different extraction methods allows
for the extraction of different features from the same functional.
Default is <code><a href="base.html#topic+list">list()</a></code> which does nothing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other fda: 
<code><a href="#topic+extractFDAFeatures">extractFDAFeatures</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatMethod">makeExtractFDAFeatMethod</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeFeatSelWrapper'>Fuse learner with feature selection.</h2><span id='topic+makeFeatSelWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with a search strategy to select variables.
Creates a learner object, which can be used like any other learner object,
but which internally uses <a href="#topic+selectFeatures">selectFeatures</a>.
If the train function is called on it, the search strategy and resampling are
invoked to select an optimal set of variables. Finally, a model is fitted on
the complete training data with these variables and returned. See
<a href="#topic+selectFeatures">selectFeatures</a> for more details.
</p>
<p>After training, the optimal features (and other related information) can be
retrieved with <a href="#topic+getFeatSelResult">getFeatSelResult</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeFeatSelWrapper(
  learner,
  resampling,
  measures,
  bit.names,
  bits.to.features,
  control,
  show.info = getMlrOption("show.info")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeFeatSelWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeFeatSelWrapper_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleInstance">ResampleInstance</a> | <a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy for feature selection. If you pass a description, it is
instantiated once at the beginning by default, so all points are evaluated
on the same training/test sets. If you want to change that behavior, look
at <a href="#topic+FeatSelControl">FeatSelControl</a>.</p>
</td></tr>
<tr><td><code id="makeFeatSelWrapper_+3A_measures">measures</code></td>
<td>
<p>(list of <a href="#topic+Measure">Measure</a> | <a href="#topic+Measure">Measure</a>)<br />
Performance measures to evaluate. The first measure, aggregated by the first aggregation function
is optimized, others are simply evaluated.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="makeFeatSelWrapper_+3A_bit.names">bit.names</code></td>
<td>
<p><a href="base.html#topic+character">character</a><br />
Names of bits encoding the solutions. Also defines the total number of bits
in the encoding. Per default these are the feature names of the task. Has
to be used together with <code>bits.to.features</code>.</p>
</td></tr>
<tr><td><code id="makeFeatSelWrapper_+3A_bits.to.features">bits.to.features</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(x, task)&#8288;</code>)<br />
Function which transforms an integer-0-1 vector into a character vector of
selected features. Per default a value of 1 in the ith bit selects the ith
feature to be in the candidate solution. The vector <code>x</code> will correspond to
the <code>bit.names</code> and has to be of the same length.</p>
</td></tr>
<tr><td><code id="makeFeatSelWrapper_+3A_control">control</code></td>
<td>
<p>[see <a href="#topic+FeatSelControl">FeatSelControl</a>)
Control object for search method.
Also selects the optimization algorithm for feature selection.</p>
</td></tr>
<tr><td><code id="makeFeatSelWrapper_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other featsel: 
<code><a href="#topic+FeatSelControl">FeatSelControl</a></code>,
<code><a href="#topic+analyzeFeatSelResult">analyzeFeatSelResult</a>()</code>,
<code><a href="#topic+getFeatSelResult">getFeatSelResult</a>()</code>,
<code><a href="#topic+selectFeatures">selectFeatures</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># nested resampling with feature selection (with a nonsense algorithm for selection)
outer = makeResampleDesc("CV", iters = 2L)
inner = makeResampleDesc("Holdout")
ctrl = makeFeatSelControlRandom(maxit = 1)
lrn = makeFeatSelWrapper("classif.ksvm", resampling = inner, control = ctrl)
# we also extract the selected features for all iteration here
r = resample(lrn, iris.task, outer, extract = getFeatSelResult)
</code></pre>

<hr>
<h2 id='makeFilter'>Create a feature filter.</h2><span id='topic+makeFilter'></span>

<h3>Description</h3>

<p>Creates and registers custom feature filters. Implemented filters
can be listed with <a href="#topic+listFilterMethods">listFilterMethods</a>. Additional
documentation for the <code>fun</code> parameter specific to each filter can
be found in the description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeFilter(name, desc, pkg, supported.tasks, supported.features, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeFilter_+3A_name">name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Identifier for the filter.</p>
</td></tr>
<tr><td><code id="makeFilter_+3A_desc">desc</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Short description of the filter.</p>
</td></tr>
<tr><td><code id="makeFilter_+3A_pkg">pkg</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Source package where the filter is implemented.</p>
</td></tr>
<tr><td><code id="makeFilter_+3A_supported.tasks">supported.tasks</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Task types supported.</p>
</td></tr>
<tr><td><code id="makeFilter_+3A_supported.features">supported.features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Feature types supported.</p>
</td></tr>
<tr><td><code id="makeFilter_+3A_fun">fun</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(task, nselect, ...&#8288;</code>)<br />
Function which takes a task and returns a named numeric vector of scores,
one score for each feature of <code>task</code>.
Higher scores mean higher importance of the feature.
At least <code>nselect</code> features must be calculated, the remaining may be
set to <code>NA</code> or omitted, and thus will not be selected.
the original order will be restored if necessary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class &ldquo;Filter&rdquo;.
</p>


<h3>References</h3>

<p>Kira, Kenji and Rendell, Larry (1992). The Feature Selection Problem: Traditional
Methods and a New Algorithm. AAAI-92 Proceedings.
</p>
<p>Kononenko, Igor et al. Overcoming the myopia of inductive learning algorithms
with RELIEFF (1997), Applied Intelligence, 7(1), p39-55.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>

<hr>
<h2 id='makeFilterEnsemble'>Create an ensemble feature filter.</h2><span id='topic+makeFilterEnsemble'></span>

<h3>Description</h3>

<p>Creates and registers custom ensemble feature filters. Implemented ensemble filters
can be listed with <a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>. Additional
documentation for the <code>fun</code> parameter specific to each filter can
be found in the description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeFilterEnsemble(name, base.methods, desc, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeFilterEnsemble_+3A_name">name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Identifier for the filter.</p>
</td></tr>
<tr><td><code id="makeFilterEnsemble_+3A_base.methods">base.methods</code></td>
<td>
<p>the base filter methods which the ensemble method
will use.</p>
</td></tr>
<tr><td><code id="makeFilterEnsemble_+3A_desc">desc</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Short description of the filter.</p>
</td></tr>
<tr><td><code id="makeFilterEnsemble_+3A_fun">fun</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(task, nselect, ...&#8288;</code>)<br />
Function which takes a task and returns a named numeric vector of scores,
one score for each feature of <code>task</code>.
Higher scores mean higher importance of the feature.
At least <code>nselect</code> features must be calculated, the remaining may be
set to <code>NA</code> or omitted, and thus will not be selected.
the original order will be restored if necessary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class &ldquo;FilterEnsemble&rdquo;.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>

<hr>
<h2 id='makeFilterWrapper'>Fuse learner with a feature filter method.</h2><span id='topic+makeFilterWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with a filter method. Creates a learner
object, which can be used like any other learner object. Internally uses
<a href="#topic+filterFeatures">filterFeatures</a> before every model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeFilterWrapper(
  learner,
  fw.method = "FSelectorRcpp_information.gain",
  fw.base.methods = NULL,
  fw.perc = NULL,
  fw.abs = NULL,
  fw.threshold = NULL,
  fw.fun = NULL,
  fw.fun.args = NULL,
  fw.mandatory.feat = NULL,
  cache = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeFilterWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.method">fw.method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Filter method. See <a href="#topic+listFilterMethods">listFilterMethods</a>.
Default is &ldquo;FSelectorRcpp_information.gain&rdquo;.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.base.methods">fw.base.methods</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Simple Filter methods for ensemble filters. See <a href="#topic+listFilterMethods">listFilterMethods</a>. Can
only be used in combination with ensemble filters. See
<a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.perc">fw.perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If set, select <code>fw.perc</code>*100 top scoring features. Mutually exclusive with
arguments <code>fw.abs</code>, <code>fw.threshold</code> and 'fw.fun.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.abs">fw.abs</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If set, select <code>fw.abs</code> top scoring features.
Mutually exclusive with arguments <code>fw.perc</code>, <code>fw.threshold</code> and <code>fw.fun</code>.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.threshold">fw.threshold</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If set, select features whose score exceeds <code>fw.threshold</code>. Mutually
exclusive with arguments <code>fw.perc</code>, <code>fw.abs</code> and <code>fw.fun</code>.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.fun">fw.fun</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function)&#8288;</code>)<br />
If set, select features via a custom thresholding function, which must
return the number of top scoring features to select. Mutually exclusive
with arguments <code>fw.perc</code>, <code>fw.abs</code> and <code>fw.threshold</code>.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.fun.args">fw.fun.args</code></td>
<td>
<p>(any)<br />
Arguments passed to the custom thresholding function</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_fw.mandatory.feat">fw.mandatory.feat</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Mandatory features which are always
included regardless of their scores</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_cache">cache</code></td>
<td>
<p>(<code>character(1)</code> | <a href="base.html#topic+logical">logical</a>)<br />
Whether to use caching during
filter value creation. See details.</p>
</td></tr>
<tr><td><code id="makeFilterWrapper_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional parameters passed down to the filter. If you are using more than
one filter method, you need to pass the arguments in a named list via
<code>more.args</code>. For example <code>more.args = list("FSelectorRcpp_information.gain" = list(equal = TRUE))</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>ensemble = TRUE</code>, ensemble feature selection using all methods specified
in <code>fw.method</code> is performed. At least two methods need to be selected.
</p>
<p>After training, the selected features can be retrieved with
<a href="#topic+getFilteredFeatures">getFilteredFeatures</a>.
</p>
<p>Note that observation weights do not influence the filtering and are simply
passed down to the next learner.
</p>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>Caching</h3>

<p>If <code>cache = TRUE</code>, the default mlr cache directory is used to cache filter
values. The directory is operating system dependent and can be checked with
<code>getCacheDir()</code>. Alternatively a custom directory can be passed to store
the cache. The cache can be cleared with <code>deleteCacheDir()</code>. Caching is
disabled by default. Care should be taken when operating on large clusters
due to possible write conflicts to disk if multiple workers try to write
the same cache at the same time.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>,
<code><a href="#topic+plotFilterValues">plotFilterValues</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.lda")
inner = makeResampleDesc("Holdout")
outer = makeResampleDesc("CV", iters = 2)
lrn = makeFilterWrapper(lrn, fw.perc = 0.5)
mod = train(lrn, task)
print(getFilteredFeatures(mod))
# now nested resampling, where we extract the features that the filter method selected
r = resample(lrn, task, outer, extract = function(model) {
  getFilteredFeatures(model)
})
print(r$extract)

# usage of an ensemble filter
lrn = makeLearner("classif.lda")
lrn = makeFilterWrapper(lrn, fw.method = "E-Borda",
  fw.base.methods = c("FSelectorRcpp_gain.ratio", "FSelectorRcpp_information.gain"),
  fw.perc = 0.5)
r = resample(lrn, task, outer, extract = function(model) {
  getFilteredFeatures(model)
})
print(r$extract)

# usage of a custom thresholding function
biggest_gap = function(values, diff) {
  gap_size = 0
  gap_location = 0

  for (i in (diff + 1):length(values)) {
    gap = values[[i - diff]] - values[[i]]
    if (gap &gt; gap_size) {
      gap_size = gap
      gap_location = i - 1
    }
  }
  return(gap_location)
}

lrn = makeLearner("classif.lda")
lrn = makeFilterWrapper(lrn, fw.method = "FSelectorRcpp_information.gain",
  fw.fun = biggest_gap, fw.fun.args = list("diff" = 1))
r = resample(lrn, task, outer, extract = function(model) {
  getFilteredFeatures(model)
})
print(r$extract)

</code></pre>

<hr>
<h2 id='makeFixedHoldoutInstance'>Generate a fixed holdout instance for resampling.</h2><span id='topic+makeFixedHoldoutInstance'></span>

<h3>Description</h3>

<p>Generate a fixed holdout instance for resampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeFixedHoldoutInstance(train.inds, test.inds, size)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeFixedHoldoutInstance_+3A_train.inds">train.inds</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Indices for training set.</p>
</td></tr>
<tr><td><code id="makeFixedHoldoutInstance_+3A_test.inds">test.inds</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Indices for test set.</p>
</td></tr>
<tr><td><code id="makeFixedHoldoutInstance_+3A_size">size</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Size of the data set to resample.
The function needs to know the largest possible index of the whole data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ResampleInstance">ResampleInstance</a>).
</p>

<hr>
<h2 id='makeFunctionalData'>Create a data.frame containing functional features from a normal data.frame.</h2><span id='topic+makeFunctionalData'></span>

<h3>Description</h3>

<p>To work with functional features, those features need to be
stored as a <code>matrix</code> column in the data.frame, so <code>mlr</code> can automatically
recognize them as functional features.
This function allows for an easy conversion from a data.frame with numeric columns
to the required format. If the data already contains matrix columns, they are left as-is
if not specified otherwise in <code>fd.features</code>. See <code>Examples</code> for the structure
of the generated output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeFunctionalData(data, fd.features = NULL, exclude.cols = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeFunctionalData_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>) <br />
A data.frame that contains the functional features as numeric columns.</p>
</td></tr>
<tr><td><code id="makeFunctionalData_+3A_fd.features">fd.features</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>) <br />
Named list containing <code>integer</code> column indices or <code>character</code> column names.
Each element defines a functional feature, in the given order of the indices or column names.
The name of the list element defines the name of the functional feature.
All selected columns have to correspond to numeric data.frame entries.
The default is <code>NULL</code>, which means all numeric features are considered
to be a single functional &ldquo;fd1&rdquo;.</p>
</td></tr>
<tr><td><code id="makeFunctionalData_+3A_exclude.cols">exclude.cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a> | <a href="base.html#topic+integer">integer</a>)<br />
Column names or indices to exclude from conversion to functionals, even if they
are in included in <code>fd.features</code>.
Default is not to exclude anything.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data.frame where columns 1:6 and 8:10 belong to a functional feature
d1 = data.frame(matrix(rnorm(100), nrow = 10), "target" = seq_len(10))
# Transform to functional data
d2 = makeFunctionalData(d1, fd.features = list("fd1" = 1:6, "fd2" = 8:10))
# Create a regression task
makeRegrTask(data = d2, target = "target")
</code></pre>

<hr>
<h2 id='makeImputeMethod'>Create a custom imputation method.</h2><span id='topic+makeImputeMethod'></span>

<h3>Description</h3>

<p>This is a constructor to create your own imputation methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeImputeMethod(learn, impute, args = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeImputeMethod_+3A_learn">learn</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, target, col, ...)&#8288;</code>)<br />
Function to learn and extract information on column <code>col</code>
out of data frame <code>data</code>. Argument <code>target</code> specifies
the target column of the learning task.
The function has to return a named list of values.</p>
</td></tr>
<tr><td><code id="makeImputeMethod_+3A_impute">impute</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, target, col, ...)&#8288;</code>)<br />
Function to impute missing values in <code>col</code> using information
returned by <code>learn</code> on the same column.
All list elements of the return values o <code>learn</code>
are passed to this function into <code>...</code>.</p>
</td></tr>
<tr><td><code id="makeImputeMethod_+3A_args">args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Named list of arguments to pass to <code>learn</code> via <code>...</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other impute: 
<code><a href="#topic+imputations">imputations</a></code>,
<code><a href="#topic+impute">impute</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+reimpute">reimpute</a>()</code>
</p>

<hr>
<h2 id='makeImputeWrapper'>Fuse learner with an imputation method.</h2><span id='topic+makeImputeWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with an imputation method. Creates a learner object, which can be
used like any other learner object.
Internally uses <a href="#topic+impute">impute</a> before training the learner and <a href="#topic+reimpute">reimpute</a>
before predicting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeImputeWrapper(
  learner,
  classes = list(),
  cols = list(),
  dummy.classes = character(0L),
  dummy.cols = character(0L),
  dummy.type = "factor",
  force.dummies = FALSE,
  impute.new.levels = TRUE,
  recode.factor.levels = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeImputeWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_classes">classes</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
Named list containing imputation techniques for classes of columns.
E.g. <code>list(numeric = imputeMedian())</code>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_cols">cols</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br />
Named list containing names of imputation methods to impute missing values
in the data column referenced by the list element's name. Overrules imputation set via
<code>classes</code>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_dummy.classes">dummy.classes</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Classes of columns to create dummy columns for.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_dummy.cols">dummy.cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Column names to create dummy columns (containing binary missing indicator) for.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_dummy.type">dummy.type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
How dummy columns are encoded. Either as 0/1 with type &ldquo;numeric&rdquo;
or as &ldquo;factor&rdquo;.
Default is &ldquo;factor&rdquo;.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_force.dummies">force.dummies</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Force dummy creation even if the respective data column does not
contain any NAs. Note that (a) most learners will complain about
constant columns created this way but (b) your feature set might
be stochastic if you turn this off.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_impute.new.levels">impute.new.levels</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If new, unencountered factor level occur during reimputation,
should these be handled as NAs and then be imputed the same way?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeImputeWrapper_+3A_recode.factor.levels">recode.factor.levels</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Recode factor levels after reimputation, so they match the respective element of
<code>lvls</code> (in the description object) and therefore match the levels of the
feature factor in the training data after imputation?.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other impute: 
<code><a href="#topic+imputations">imputations</a></code>,
<code><a href="#topic+impute">impute</a>()</code>,
<code><a href="#topic+makeImputeMethod">makeImputeMethod</a>()</code>,
<code><a href="#topic+reimpute">reimpute</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeLearner'>Create learner object.</h2><span id='topic+makeLearner'></span><span id='topic+Learner'></span>

<h3>Description</h3>

<p>For a classification learner the <code>predict.type</code> can be set to
&ldquo;prob&rdquo; to predict probabilities and the maximum value selects the
label. The threshold used to assign the label can later be changed using the
<a href="#topic+setThreshold">setThreshold</a> function.
</p>
<p>To see all possible properties of a learner, go to: <a href="#topic+LearnerProperties">LearnerProperties</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeLearner(
  cl,
  id = cl,
  predict.type = "response",
  predict.threshold = NULL,
  fix.factors.prediction = FALSE,
  ...,
  par.vals = list(),
  config = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeLearner_+3A_cl">cl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Class of learner. By convention, all classification learners
start with &ldquo;classif.&rdquo; all regression learners with
&ldquo;regr.&rdquo; all survival learners start with &ldquo;surv.&rdquo;
all clustering learners with &ldquo;cluster.&rdquo; and all multilabel
classification learners start with &ldquo;multilabel.&rdquo;.
A list of all integrated learners is available on the
<a href="#topic+learners">learners</a> help page.</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br /> Id string for object. Used to display object.
Default is <code>cl</code>.</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_predict.type">predict.type</code></td>
<td>
<p>(<code>character(1)</code>)<br /> Classification: &ldquo;response&rdquo; (=
labels) or &ldquo;prob&rdquo; (= probabilities and labels by selecting the ones
with maximal probability). Regression: &ldquo;response&rdquo; (= mean response)
or &ldquo;se&rdquo; (= standard errors and mean response). Survival:
&ldquo;response&rdquo; (= some sort of orderable risk) or &ldquo;prob&rdquo; (= time
dependent probabilities). Clustering: &ldquo;response&rdquo; (= cluster IDS) or
&ldquo;prob&rdquo; (= fuzzy cluster membership probabilities), Multilabel:
&ldquo;response&rdquo; (= logical matrix indicating the predicted class labels)
or &ldquo;prob&rdquo; (= probabilities and corresponding logical matrix
indicating class labels). Default is &ldquo;response&rdquo;.</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_predict.threshold">predict.threshold</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Threshold to produce class labels. Has to be a named vector, where names correspond to class labels.
Only for binary classification it can be a single numerical threshold for the positive class.
See <a href="#topic+setThreshold">setThreshold</a> for details on how it is applied.
Default is <code>NULL</code> which means 0.5 / an equal threshold for each class.</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_fix.factors.prediction">fix.factors.prediction</code></td>
<td>
<p>(<code>logical(1)</code>)<br /> In some cases, problems occur
in underlying learners for factor features during prediction. If the new
features have LESS factor levels than during training (a strict subset),
the learner might produce an  error like &ldquo;type of predictors in new
data do not match that of the training data&rdquo;. In this case one can repair
this problem by setting this option to <code>TRUE</code>. We will simply add the
missing factor levels missing from the test feature (but present in
training) to that feature. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_...">...</code></td>
<td>
<p>(any)<br /> Optional named (hyper)parameters. If you want to set
specific hyperparameters for a learner during model creation, these should
go here. You can get a list of available hyperparameters using
<code style="white-space: pre;">&#8288;getParamSet(&lt;learner&gt;)&#8288;</code>. Alternatively hyperparameters can be given using
the <code>par.vals</code> argument but <code>...</code> should be preferred!</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br /> Optional list of named (hyper)parameters. The
arguments in <code>...</code> take precedence over values in this list. We strongly
encourage you to use <code>...</code> for passing hyperparameters.</p>
</td></tr>
<tr><td><code id="makeLearner_+3A_config">config</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a>)<br /> Named list of config option to overwrite
global settings set via <a href="#topic+configureMlr">configureMlr</a> for this specific learner.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Learner">Learner</a>).
</p>


<h3><code>par.vals</code> vs. <code>...</code></h3>

<p>The former aims at specifying default hyperparameter settings from <code>mlr</code>
which differ from the actual defaults in the underlying learner. For
example, <code>respect.unordered.factors</code> is set to <code>order</code> in <code>mlr</code> while the
default in <a href="ranger.html#topic+ranger">ranger::ranger</a> depends on the argument <code>splitrule</code>.
<code style="white-space: pre;">&#8288;getHyperPars(&lt;learner&gt;)&#8288;</code> can be used to query hyperparameter defaults that
differ from the underlying learner. This function also shows all
hyperparameters set by the user during learner creation (if these differ
from the learner defaults).
</p>


<h3>regr.randomForest</h3>

<p>For this learner we added additional uncertainty estimation functionality
(<code>predict.type = "se"</code>) for the randomForest, which is not provided by the
underlying package.
</p>
<p>Currently implemented methods are:
</p>

<ul>
<li><p> If <code>se.method = "jackknife"</code> the standard error of a prediction is
estimated by computing the jackknife-after-bootstrap, the mean-squared
difference between the prediction made by only using trees which did not
contain said observation and the ensemble prediction.
</p>
</li>
<li><p> If <code>se.method = "bootstrap"</code> the standard error of a prediction is
estimated by bootstrapping the random forest, where the number of bootstrap
replicates and the number of trees in the ensemble are controlled by
<code>se.boot</code> and <code>se.ntree</code> respectively, and then taking the standard deviation
of the bootstrap predictions. The &quot;brute force&quot; bootstrap is executed when
<code>ntree = se.ntree</code>, the latter of which controls the number of trees in the
individual random forests which are bootstrapped. The &quot;noisy bootstrap&quot; is
executed when <code>se.ntree &lt; ntree</code> which is less computationally expensive. A
Monte-Carlo bias correction may make the latter option preferable in many
cases. Defaults are <code>se.boot = 50</code> and <code>se.ntree = 100</code>.
</p>
</li>
<li><p> If <code>se.method = "sd"</code>, the default, the standard deviation of the
predictions across trees is returned as the variance estimate. This can be
computed quickly but is also a very naive estimator. </p>
</li></ul>

<p>For both &ldquo;jackknife&rdquo; and &ldquo;bootstrap&rdquo;, a Monte-Carlo bias
correction is applied and, in the case that this results in a negative
variance estimate, the values are truncated at 0.
</p>
<p>Note that when using the &ldquo;jackknife&rdquo; procedure for se estimation,
using a small number of trees can lead to training data observations that are
never out-of-bag. The current implementation ignores these observations, but
in the original definition, the resulting se estimation would be undefined.
</p>
<p>Please note that all of the mentioned <code>se.method</code> variants do not affect the
computation of the posterior mean &ldquo;response&rdquo; value. This is always the
same as from the underlying randomForest.
</p>


<h3>regr.featureless</h3>

<p>A very basic baseline method which is useful for model comparisons (if you
don't beat this, you very likely have a problem).
Does not consider any features of the task and only uses the target feature
of the training data to make predictions.
Using observation weights is currently not supported.
</p>
<p>Methods &ldquo;mean&rdquo; and &ldquo;median&rdquo; always predict a constant value
for each new observation which corresponds to the observed mean or median of
the target feature in training data, respectively.
</p>
<p>The default method is &ldquo;mean&rdquo; which corresponds to the ZeroR algorithm
from WEKA.
</p>


<h3>classif.featureless</h3>

<p>Method &ldquo;majority&rdquo; predicts always the majority class for each new
observation. In the case of ties, one randomly sampled, constant class is
predicted for all observations in the test set.
This method is used as the default. It is very similar to the ZeroR
classifier from WEKA. The only difference is
that ZeroR always predicts the first class of the tied class values instead
of sampling them randomly.
</p>
<p>Method &ldquo;sample-prior&rdquo; always samples a random class for each
individual test observation according to the prior probabilities observed in
the training data.
</p>
<p>If you opt to predict probabilities, the class probabilities always
correspond to the prior probabilities observed in the training data.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>makeLearner("classif.rpart")
makeLearner("classif.lda", predict.type = "prob")
lrn = makeLearner("classif.lda", method = "t", nu = 10)
getHyperPars(lrn)
</code></pre>

<hr>
<h2 id='makeLearners'>Create multiple learners at once.</h2><span id='topic+makeLearners'></span>

<h3>Description</h3>

<p>Small helper function that can save some typing when creating mutiple learner objects.
Calls <a href="#topic+makeLearner">makeLearner</a> multiple times internally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeLearners(cls, ids = NULL, type = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeLearners_+3A_cls">cls</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Classes of learners.</p>
</td></tr>
<tr><td><code id="makeLearners_+3A_ids">ids</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Id strings. Must be unique.
Default is <code>cls</code>.</p>
</td></tr>
<tr><td><code id="makeLearners_+3A_type">type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Shortcut to prepend type string to <code>cls</code> so one can set <code>cls = "rpart"</code>.
Default is <code>NULL</code>, i.e., this is not used.</p>
</td></tr>
<tr><td><code id="makeLearners_+3A_...">...</code></td>
<td>
<p>(any)<br /> Optional named (hyper)parameters. If you want to set
specific hyperparameters for a learner during model creation, these should
go here. You can get a list of available hyperparameters using
<code style="white-space: pre;">&#8288;getParamSet(&lt;learner&gt;)&#8288;</code>. Alternatively hyperparameters can be given using
the <code>par.vals</code> argument but <code>...</code> should be preferred!</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(named list of <a href="#topic+Learner">Learner</a>). Named by <code>ids</code>.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>makeLearners(c("rpart", "lda"), type = "classif", predict.type = "prob")
</code></pre>

<hr>
<h2 id='makeMeasure'>Construct performance measure.</h2><span id='topic+makeMeasure'></span><span id='topic+Measure'></span>

<h3>Description</h3>

<p>A measure object encapsulates a function to evaluate the performance of a
prediction. Information about already implemented measures can be obtained
here: <a href="#topic+measures">measures</a>.
</p>
<p>A learner is trained on a training set d1, results in a model m and predicts
another set d2 (which may be a different one or the training set) resulting
in the prediction. The performance measure can now be defined using all of
the information of the original task, the fitted model and the prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMeasure(
  id,
  minimize,
  properties = character(0L),
  fun,
  extra.args = list(),
  aggr = test.mean,
  best = NULL,
  worst = NULL,
  name = id,
  note = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMeasure_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of measure.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_minimize">minimize</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the measure be minimized?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_properties">properties</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Set of measure properties. Some standard property names include:
- classif: Is the measure applicable for classification?
- classif.multi: Is the measure applicable for multi-class classification?
- multilabel: Is the measure applicable for multilabel classification?
- regr: Is the measure applicable for regression?
- surv: Is the measure applicable for survival?
- cluster: Is the measure applicable for cluster?
- costsens: Is the measure applicable for cost-sensitive learning?
- req.pred: Is prediction object required in calculation? Usually the case.
- req.truth: Is truth column required in calculation? Usually the case.
- req.task: Is task object required in calculation? Usually not the case
- req.model: Is model object required in calculation? Usually not the case.
- req.feats: Are feature values required in calculation? Usually not the case.
- req.prob: Are predicted probabilities required in calculation? Usually not the case, example would be AUC.
</p>
<p>Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_fun">fun</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(task, model, pred, feats, extra.args)&#8288;</code>)<br />
Calculates the performance value. Usually you will only need the prediction
object <code>pred</code>.
- <code>task</code> (<a href="#topic+Task">Task</a>)<br />
The task.
- <code>model</code> (<a href="#topic+WrappedModel">WrappedModel</a>)<br />
The fitted model.
- <code>pred</code> (<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.
- <code>feats</code> (<a href="base.html#topic+data.frame">data.frame</a>)<br />
The features.
- <code>extra.args</code> (<a href="base.html#topic+list">list</a>)<br />
See below.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_extra.args">extra.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
List of extra arguments which will always be passed to <code>fun</code>.
Can be changed after construction via <code><a href="#topic+setMeasurePars">setMeasurePars()</a></code>.
Default is empty list.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_aggr">aggr</code></td>
<td>
<p>(<a href="#topic+Aggregation">Aggregation</a>)<br />
Aggregation function, which is used to aggregate the values measured
on test / training sets of the measure to a single value.
Default is <a href="#topic+test.mean">test.mean</a>.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_best">best</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Best obtainable value for measure.
Default is -<code>Inf</code> or <code>Inf</code>, depending on <code>minimize</code>.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_worst">worst</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Worst obtainable value for measure.
Default is <code>Inf</code> or -<code>Inf</code>, depending on <code>minimize</code>.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_name">name</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>) <br />
Name of the measure. Default is <code>id</code>.</p>
</td></tr>
<tr><td><code id="makeMeasure_+3A_note">note</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>) <br />
Description and additional notes for the measure. Default is &ldquo;&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Measure">Measure</a>.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f = function(task, model, pred, extra.args) {
  sum((pred$data$response - pred$data$truth)^2)
}
makeMeasure(id = "my.sse", minimize = TRUE,
  properties = c("regr", "response"), fun = f)
</code></pre>

<hr>
<h2 id='makeModelMultiplexer'>Create model multiplexer for model selection to tune over multiple
possible models.</h2><span id='topic+makeModelMultiplexer'></span><span id='topic+ModelMultiplexer'></span>

<h3>Description</h3>

<p>Combines multiple base learners by dispatching
on the hyperparameter &ldquo;selected.learner&rdquo; to a specific model class.
This allows to tune not only the model class (SVM, random forest, etc) but also
their hyperparameters in one go. Combine this with <a href="#topic+tuneParams">tuneParams</a> and
<a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a> for a very powerful approach, see example below.
</p>
<p>The parameter set is the union of all (unique) base learners. In order to
avoid name clashes all parameter names are prefixed with the base learner id,
i.e. <code>learnerId.parameterName</code>.
</p>
<p>The predict.type of the Multiplexer is inherited from the predict.type of the
base learners.
</p>
<p>The getter <a href="#topic+getLearnerProperties">getLearnerProperties</a> returns the properties of the
selected base learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeModelMultiplexer(base.learners)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeModelMultiplexer_+3A_base.learners">base.learners</code></td>
<td>
<p>([list' of <a href="#topic+Learner">Learner</a>)<br />
List of Learners with unique IDs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ModelMultiplexer">ModelMultiplexer</a>). A <a href="#topic+Learner">Learner</a> specialized as <code>ModelMultiplexer</code>.
</p>


<h3>Note</h3>

<p>Note that logging output during tuning is somewhat shortened to make it
more readable. I.e., the artificial prefix before parameter names is
suppressed.
</p>


<h3>See Also</h3>

<p>Other multiplexer: 
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>
</p>
<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)

library(BBmisc)
bls = list(
  makeLearner("classif.ksvm"),
  makeLearner("classif.randomForest")
)
lrn = makeModelMultiplexer(bls)
# simple way to contruct param set for tuning
# parameter names are prefixed automatically and the 'requires'
# element is set, too, to make all paramaters subordinate to 'selected.learner'
ps = makeModelMultiplexerParamSet(lrn,
  makeNumericParam("sigma", lower = -10, upper = 10, trafo = function(x) 2^x),
  makeIntegerParam("ntree", lower = 1L, upper = 500L)
)
print(ps)
rdesc = makeResampleDesc("CV", iters = 2L)
# to save some time we use random search. but you probably want something like this:
# ctrl = makeTuneControlIrace(maxExperiments = 500L)
ctrl = makeTuneControlRandom(maxit = 10L)
res = tuneParams(lrn, iris.task, rdesc, par.set = ps, control = ctrl)
print(res)

df = as.data.frame(res$opt.path)
print(head(df[, -ncol(df)]))

# more unique and reliable way to construct the param set
ps = makeModelMultiplexerParamSet(lrn,
  classif.ksvm = makeParamSet(
    makeNumericParam("sigma", lower = -10, upper = 10, trafo = function(x) 2^x)
  ),
  classif.randomForest = makeParamSet(
    makeIntegerParam("ntree", lower = 1L, upper = 500L)
  )
)

# this is how you would construct the param set manually, works too
ps = makeParamSet(
  makeDiscreteParam("selected.learner", values = extractSubList(bls, "id")),
  makeNumericParam("classif.ksvm.sigma", lower = -10, upper = 10, trafo = function(x) 2^x,
    requires = quote(selected.learner == "classif.ksvm")),
  makeIntegerParam("classif.randomForest.ntree", lower = 1L, upper = 500L,
    requires = quote(selected.learner == "classif.randomForst"))
)

# all three ps-objects are exactly the same internally.

</code></pre>

<hr>
<h2 id='makeModelMultiplexerParamSet'>Creates a parameter set for model multiplexer tuning.</h2><span id='topic+makeModelMultiplexerParamSet'></span>

<h3>Description</h3>

<p>Handy way to create the param set with less typing.
</p>
<p>The following is done automatically:
</p>

<ul>
<li><p>The <code>selected.learner</code> param is created
</p>
</li>
<li><p>Parameter names are prefixed.
</p>
</li>
<li><p>The <code>requires</code> field of each param is set.
This makes all parameters subordinate to <code>selected.learner</code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>makeModelMultiplexerParamSet(multiplexer, ..., .check = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeModelMultiplexerParamSet_+3A_multiplexer">multiplexer</code></td>
<td>
<p>(<a href="#topic+ModelMultiplexer">ModelMultiplexer</a>)<br />
The muliplexer learner.</p>
</td></tr>
<tr><td><code id="makeModelMultiplexerParamSet_+3A_...">...</code></td>
<td>
<p>(<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a> | <a href="ParamHelpers.html#topic+Param">ParamHelpers::Param</a>)<br />
(a) First option: Named param sets. Names must correspond to base learners.
You only need to enter the parameters you want to tune without reference
to the <code>selected.learner</code> field in any way.<br />
(b) Second option. Just the params you would enter in the param sets.
Even shorter to create. Only works when it can be uniquely identified to which
learner each of your passed parameters belongs.</p>
</td></tr>
<tr><td><code id="makeModelMultiplexerParamSet_+3A_.check">.check</code></td>
<td>
<p>(<a href="base.html#topic+logical">logical</a>)<br />
Check that for each param in <code>...</code> one param in found in the base learners.
Default is <code>TRUE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>ParamSet.
</p>


<h3>See Also</h3>

<p>Other multiplexer: 
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>
</p>
<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See makeModelMultiplexer
</code></pre>

<hr>
<h2 id='makeMulticlassWrapper'>Fuse learner with multiclass method.</h2><span id='topic+makeMulticlassWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with a multi-class method.
Creates a learner object, which can be used like any other learner object.
This way learners which can only handle binary classification will be able to
handle multi-class problems, too.
</p>
<p>We use a multiclass-to-binary reduction principle, where multiple binary
problems are created from the multiclass task. How these binary problems
are generated is defined by an error-correcting-output-code (ECOC) code book.
This also allows the simple and well-known one-vs-one and one-vs-rest
approaches. Decoding is currently done via Hamming decoding, see
e.g. here <a href="https://jmlr.org/papers/volume11/escalera10a/escalera10a.pdf">https://jmlr.org/papers/volume11/escalera10a/escalera10a.pdf</a>.
</p>
<p>Currently, the approach always operates on the discrete predicted labels
of the binary base models (instead of their probabilities) and the created
wrapper cannot predict posterior probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMulticlassWrapper(learner, mcw.method = "onevsrest")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMulticlassWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeMulticlassWrapper_+3A_mcw.method">mcw.method</code></td>
<td>
<p>(<code>character(1)</code> | <code>function</code>) <br />
&ldquo;onevsone&rdquo; or &ldquo;onevsrest&rdquo;.
You can also pass a function, with signature <code style="white-space: pre;">&#8288;function(task)&#8288;</code> and which
returns a ECOC codematrix with entries +1,-1,0.
Columns define new binary problems, rows correspond to classes (rows must be named).
0 means class is not included in binary problem.
Default is &ldquo;onevsrest&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeMultilabelBinaryRelevanceWrapper'>Use binary relevance method to create a multilabel learner.</h2><span id='topic+makeMultilabelBinaryRelevanceWrapper'></span>

<h3>Description</h3>

<p>Every learner which is implemented in mlr and which supports binary
classification can be converted to a wrapped binary relevance multilabel learner.
The multilabel classification problem is converted into simple binary classifications
for each label/target on which the binary learner is applied.
</p>
<p>Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>
<p>Note that it does not make sense to set a threshold in the used base <code>learner</code>
when you predict probabilities.
On the other hand, it can make a lot of sense, to call <a href="#topic+setThreshold">setThreshold</a>
on the <code>MultilabelBinaryRelevanceWrapper</code> for each label indvidually;
Or to tune these thresholds with <a href="#topic+tuneThreshold">tuneThreshold</a>; especially when you face very
unabalanced class distributions for each binary label.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMultilabelBinaryRelevanceWrapper(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMultilabelBinaryRelevanceWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>References</h3>

<p>Tsoumakas, G., &amp; Katakis, I. (2006)
<em>Multi-label classification: An overview.</em>
Dept. of Informatics, Aristotle University of Thessaloniki, Greece.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>
<p>Other multilabel: 
<code><a href="#topic+getMultilabelBinaryPerformances">getMultilabelBinaryPerformances</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d = getTaskData(yeast.task)
# drop some labels so example runs faster
d = d[seq(1, nrow(d), by = 20), c(1:2, 15:17)]
task = makeMultilabelTask(data = d, target = c("label1", "label2"))
lrn = makeLearner("classif.rpart")
lrn = makeMultilabelBinaryRelevanceWrapper(lrn)
lrn = setPredictType(lrn, "prob")
# train, predict and evaluate
mod = train(lrn, task)
pred = predict(mod, task)
performance(pred, measure = list(multilabel.hamloss, multilabel.subset01, multilabel.f1))
# the next call basically has the same structure for any multilabel meta wrapper
getMultilabelBinaryPerformances(pred, measures = list(mmce, auc))
# above works also with predictions from resample!
</code></pre>

<hr>
<h2 id='makeMultilabelClassifierChainsWrapper'>Use classifier chains method (CC) to create a multilabel learner.</h2><span id='topic+makeMultilabelClassifierChainsWrapper'></span>

<h3>Description</h3>

<p>Every learner which is implemented in mlr and which supports binary
classification can be converted to a wrapped classifier chains multilabel learner.
CC trains a binary classifier for each label following a given order. In training phase,
the feature space of each classifier is extended with true label information of all previous
labels in the chain. During the prediction phase, when true labels are not available, they are
replaced by predicted labels.
</p>
<p>Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMultilabelClassifierChainsWrapper(learner, order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMultilabelClassifierChainsWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeMultilabelClassifierChainsWrapper_+3A_order">order</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Specifies the chain order using the names of the target labels.
E.g. for <code>m</code> target labels, this must be a character vector of length <code>m</code> that contains a permutation of the target label names.
Default is <code>NULL</code> which uses a random ordering of the target label names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>References</h3>

<p>Montanes, E. et al. (2013)
<em>Dependent binary relevance models for multi-label classification</em>
Artificial Intelligence Center, University of Oviedo at Gijon, Spain.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>
<p>Other multilabel: 
<code><a href="#topic+getMultilabelBinaryPerformances">getMultilabelBinaryPerformances</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d = getTaskData(yeast.task)
# drop some labels so example runs faster
d = d[seq(1, nrow(d), by = 20), c(1:2, 15:17)]
task = makeMultilabelTask(data = d, target = c("label1", "label2"))
lrn = makeLearner("classif.rpart")
lrn = makeMultilabelBinaryRelevanceWrapper(lrn)
lrn = setPredictType(lrn, "prob")
# train, predict and evaluate
mod = train(lrn, task)
pred = predict(mod, task)
performance(pred, measure = list(multilabel.hamloss, multilabel.subset01, multilabel.f1))
# the next call basically has the same structure for any multilabel meta wrapper
getMultilabelBinaryPerformances(pred, measures = list(mmce, auc))
# above works also with predictions from resample!
</code></pre>

<hr>
<h2 id='makeMultilabelDBRWrapper'>Use dependent binary relevance method (DBR) to create a multilabel learner.</h2><span id='topic+makeMultilabelDBRWrapper'></span>

<h3>Description</h3>

<p>Every learner which is implemented in mlr and which supports binary
classification can be converted to a wrapped DBR multilabel learner.
The multilabel classification problem is converted into simple binary classifications
for each label/target on which the binary learner is applied.
For each target, actual information of all binary labels (except the target variable) is used as additional features.
During prediction these labels need are obtained by the binary relevance method using the same binary learner.
</p>
<p>Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMultilabelDBRWrapper(learner)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMultilabelDBRWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>References</h3>

<p>Montanes, E. et al. (2013)
<em>Dependent binary relevance models for multi-label classification</em>
Artificial Intelligence Center, University of Oviedo at Gijon, Spain.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>
<p>Other multilabel: 
<code><a href="#topic+getMultilabelBinaryPerformances">getMultilabelBinaryPerformances</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d = getTaskData(yeast.task)
# drop some labels so example runs faster
d = d[seq(1, nrow(d), by = 20), c(1:2, 15:17)]
task = makeMultilabelTask(data = d, target = c("label1", "label2"))
lrn = makeLearner("classif.rpart")
lrn = makeMultilabelBinaryRelevanceWrapper(lrn)
lrn = setPredictType(lrn, "prob")
# train, predict and evaluate
mod = train(lrn, task)
pred = predict(mod, task)
performance(pred, measure = list(multilabel.hamloss, multilabel.subset01, multilabel.f1))
# the next call basically has the same structure for any multilabel meta wrapper
getMultilabelBinaryPerformances(pred, measures = list(mmce, auc))
# above works also with predictions from resample!
</code></pre>

<hr>
<h2 id='makeMultilabelNestedStackingWrapper'>Use nested stacking method to create a multilabel learner.</h2><span id='topic+makeMultilabelNestedStackingWrapper'></span>

<h3>Description</h3>

<p>Every learner which is implemented in mlr and which supports binary
classification can be converted to a wrapped nested stacking multilabel learner.
Nested stacking trains a binary classifier for each label following a given order. In training phase,
the feature space of each classifier is extended with predicted label information (by cross validation)
of all previous labels in the chain.
During the prediction phase, predicted labels are obtained by the classifiers, which have been learned on
all training data.
</p>
<p>Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMultilabelNestedStackingWrapper(learner, order = NULL, cv.folds = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMultilabelNestedStackingWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeMultilabelNestedStackingWrapper_+3A_order">order</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Specifies the chain order using the names of the target labels.
E.g. for <code>m</code> target labels, this must be a character vector of length <code>m</code> that contains a permutation of the target label names.
Default is <code>NULL</code> which uses a random ordering of the target label names.</p>
</td></tr>
<tr><td><code id="makeMultilabelNestedStackingWrapper_+3A_cv.folds">cv.folds</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of folds for the inner cross validation method to predict labels for the augmented feature space. Default is <code>2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>References</h3>

<p>Montanes, E. et al. (2013),
<em>Dependent binary relevance models for multi-label classification</em>
Artificial Intelligence Center, University of Oviedo at Gijon, Spain.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>
<p>Other multilabel: 
<code><a href="#topic+getMultilabelBinaryPerformances">getMultilabelBinaryPerformances</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d = getTaskData(yeast.task)
# drop some labels so example runs faster
d = d[seq(1, nrow(d), by = 20), c(1:2, 15:17)]
task = makeMultilabelTask(data = d, target = c("label1", "label2"))
lrn = makeLearner("classif.rpart")
lrn = makeMultilabelBinaryRelevanceWrapper(lrn)
lrn = setPredictType(lrn, "prob")
# train, predict and evaluate
mod = train(lrn, task)
pred = predict(mod, task)
performance(pred, measure = list(multilabel.hamloss, multilabel.subset01, multilabel.f1))
# the next call basically has the same structure for any multilabel meta wrapper
getMultilabelBinaryPerformances(pred, measures = list(mmce, auc))
# above works also with predictions from resample!
</code></pre>

<hr>
<h2 id='makeMultilabelStackingWrapper'>Use stacking method (stacked generalization) to create a multilabel learner.</h2><span id='topic+makeMultilabelStackingWrapper'></span>

<h3>Description</h3>

<p>Every learner which is implemented in mlr and which supports binary
classification can be converted to a wrapped stacking multilabel learner.
Stacking trains a binary classifier for each label using predicted label information of all labels (including the target label)
as additional features (by cross validation).
During prediction these labels need are obtained by the binary relevance method using the same binary learner.
</p>
<p>Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMultilabelStackingWrapper(learner, cv.folds = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMultilabelStackingWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeMultilabelStackingWrapper_+3A_cv.folds">cv.folds</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of folds for the inner cross validation method to predict labels for the augmented feature space. Default is <code>2</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>References</h3>

<p>Montanes, E. et al. (2013)
<em>Dependent binary relevance models for multi-label classification</em>
Artificial Intelligence Center, University of Oviedo at Gijon, Spain.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>
<p>Other multilabel: 
<code><a href="#topic+getMultilabelBinaryPerformances">getMultilabelBinaryPerformances</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d = getTaskData(yeast.task)
# drop some labels so example runs faster
d = d[seq(1, nrow(d), by = 20), c(1:2, 15:17)]
task = makeMultilabelTask(data = d, target = c("label1", "label2"))
lrn = makeLearner("classif.rpart")
lrn = makeMultilabelBinaryRelevanceWrapper(lrn)
lrn = setPredictType(lrn, "prob")
# train, predict and evaluate
mod = train(lrn, task)
pred = predict(mod, task)
performance(pred, measure = list(multilabel.hamloss, multilabel.subset01, multilabel.f1))
# the next call basically has the same structure for any multilabel meta wrapper
getMultilabelBinaryPerformances(pred, measures = list(mmce, auc))
# above works also with predictions from resample!
</code></pre>

<hr>
<h2 id='makeMultilabelTask'>Create a multilabel task.</h2><span id='topic+makeMultilabelTask'></span><span id='topic+MultilabelTask'></span>

<h3>Description</h3>

<p>Create a multilabel task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeMultilabelTask(
  id = deparse(substitute(data)),
  data,
  target,
  weights = NULL,
  blocking = NULL,
  coordinates = NULL,
  fixup.data = "warn",
  check.data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeMultilabelTask_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
For survival analysis these are the names of the survival time and event columns,
so it has length 2. For multilabel classification it contains the names of the logical
columns that encode whether a label is present or not and its length corresponds to the
number of classes.</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
Cannot be set for cost-sensitive learning.
Default is <code>NULL</code> which means no (= equal) weights.</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="makeMultilabelTask_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For multilabel classification we assume that the presence of labels is encoded via logical
columns in <code>data</code>. The name of the column specifies the name of the label. <code>target</code>
is then a char vector that points to these columns.
</p>


<h3>Note</h3>

<p>For multilabel classification we assume that the presence of labels is encoded via logical
columns in <code>data</code>. The name of the column specifies the name of the label. <code>target</code>
is then a char vector that points to these columns.
</p>


<h3>See Also</h3>

<p><a href="#topic+Task">Task</a> <a href="#topic+ClassifTask">ClassifTask</a> <a href="#topic+ClusterTask">ClusterTask</a> <a href="#topic+CostSensTask">CostSensTask</a> <a href="#topic+RegrTask">RegrTask</a> <a href="#topic+SurvTask">SurvTask</a>
</p>

<hr>
<h2 id='makeOverBaggingWrapper'>Fuse learner with the bagging technique and oversampling for imbalancy correction.</h2><span id='topic+makeOverBaggingWrapper'></span>

<h3>Description</h3>

<p>Fuses a classification learner for binary classification with an over-bagging method
for imbalancy correction when we have strongly unequal class sizes.
Creates a learner object, which can be
used like any other learner object.
Models can easily be accessed via <a href="#topic+getLearnerModel">getLearnerModel</a>.
</p>
<p>OverBagging is implemented as follows:
For each iteration a random data subset is sampled. Class examples
are oversampled with replacement with a given rate.
Members of the other class are either simply copied into each bag, or bootstrapped with replacement
until we have as many majority class examples as in the original training data.
Features are currently not changed or sampled.
</p>
<p>Prediction works as follows:
For classification we do majority voting to create a discrete label and
probabilities are predicted by considering the proportions of all predicted labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeOverBaggingWrapper(
  learner,
  obw.iters = 10L,
  obw.rate = 1,
  obw.maxcl = "boot",
  obw.cl = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeOverBaggingWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeOverBaggingWrapper_+3A_obw.iters">obw.iters</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of fitted models in bagging.
Default is 10.</p>
</td></tr>
<tr><td><code id="makeOverBaggingWrapper_+3A_obw.rate">obw.rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Factor to upsample a class in each bag.
Must be between 1 and <code>Inf</code>,
where 1 means no oversampling and 2 would mean doubling the class size.
Default is 1.</p>
</td></tr>
<tr><td><code id="makeOverBaggingWrapper_+3A_obw.maxcl">obw.maxcl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
How should other class (usually larger class) be handled?
&ldquo;all&rdquo; means every instance of the class gets in each bag,
&ldquo;boot&rdquo; means the class instances are bootstrapped in each iteration.
Default is &ldquo;boot&rdquo;.</p>
</td></tr>
<tr><td><code id="makeOverBaggingWrapper_+3A_obw.cl">obw.cl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Which class should be over- or undersampled. If <code>NULL</code>, <code>makeOverBaggingWrapper</code>
will take the smaller class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other imbalancy: 
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+oversample">oversample</a>()</code>,
<code><a href="#topic+smote">smote</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makePreprocWrapper'>Fuse learner with preprocessing.</h2><span id='topic+makePreprocWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with a preprocessing method. Creates a learner object, which can be
used like any other learner object, but which internally preprocesses the data as requested.
If the train or predict function is called on data / a task, the preprocessing is always performed automatically.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makePreprocWrapper(
  learner,
  train,
  predict,
  par.set = makeParamSet(),
  par.vals = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makePreprocWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makePreprocWrapper_+3A_train">train</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, target, args)&#8288;</code>)<br />
Function to preprocess the data before training.
<code>target</code> is a string and denotes the target variable in <code>data</code>.
<code>args</code> is a list of further arguments and parameters to influence the
preprocessing.
Must return a <code>list(data, control)</code>, where <code>data</code> is the preprocessed
data and <code>control</code> stores all information necessary to do the preprocessing
before predictions.</p>
</td></tr>
<tr><td><code id="makePreprocWrapper_+3A_predict">predict</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, target, args, control)&#8288;</code>)<br />
Function to preprocess the data before prediction.
<code>target</code> is a string and denotes the target variable in <code>data</code>.
<code>args</code> are the args that were passed to <code>train</code>.
<code>control</code> is the object you returned in <code>train</code>.
Must return the processed data.</p>
</td></tr>
<tr><td><code id="makePreprocWrapper_+3A_par.set">par.set</code></td>
<td>
<p>(<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a>)<br />
Parameter set of <a href="ParamHelpers.html#topic+LearnerParam">ParamHelpers::LearnerParam</a> objects to describe the
parameters in <code>args</code>.
Default is empty set.</p>
</td></tr>
<tr><td><code id="makePreprocWrapper_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Named list of default values for params in <code>args</code> respectively <code>par.set</code>.
Default is empty list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Learner">Learner</a>).
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makePreprocWrapperCaret'>Fuse learner with preprocessing.</h2><span id='topic+makePreprocWrapperCaret'></span>

<h3>Description</h3>

<p>Fuses a learner with preprocessing methods provided by <a href="caret.html#topic+preProcess">caret::preProcess</a>.
Before training the preprocessing will be performed and the preprocessing model will be stored.
Before prediction the preprocessing model will transform the test data according to the trained model.
</p>
<p>After being wrapped the learner will support missing values although this will only be the case if <code>ppc.knnImpute</code>, <code>ppc.bagImpute</code> or <code>ppc.medianImpute</code> is set to <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makePreprocWrapperCaret(learner, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makePreprocWrapperCaret_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makePreprocWrapperCaret_+3A_...">...</code></td>
<td>
<p>(any)<br />
See <a href="caret.html#topic+preProcess">caret::preProcess</a> for parameters not listed above.
If you use them you might want to define them in the <code>add.par.set</code> so that they can be tuned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeRegrTask'>Create a regression task.</h2><span id='topic+makeRegrTask'></span><span id='topic+RegrTask'></span>

<h3>Description</h3>

<p>Create a regression task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeRegrTask(
  id = deparse(substitute(data)),
  data,
  target,
  weights = NULL,
  blocking = NULL,
  coordinates = NULL,
  fixup.data = "warn",
  check.data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeRegrTask_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
For survival analysis these are the names of the survival time and event columns,
so it has length 2. For multilabel classification it contains the names of the logical
columns that encode whether a label is present or not and its length corresponds to the
number of classes.</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
Cannot be set for cost-sensitive learning.
Default is <code>NULL</code> which means no (= equal) weights.</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="makeRegrTask_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+Task">Task</a> <a href="#topic+ClassifTask">ClassifTask</a> <a href="#topic+CostSensTask">CostSensTask</a> <a href="#topic+ClusterTask">ClusterTask</a> <a href="#topic+MultilabelTask">MultilabelTask</a> <a href="#topic+SurvTask">SurvTask</a>
</p>

<hr>
<h2 id='makeRemoveConstantFeaturesWrapper'>Fuse learner with removal of constant features preprocessing.</h2><span id='topic+makeRemoveConstantFeaturesWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with the preprocessing implemented in <a href="#topic+removeConstantFeatures">removeConstantFeatures</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeRemoveConstantFeaturesWrapper(
  learner,
  perc = 0,
  dont.rm = character(0L),
  na.ignore = FALSE,
  wrap.tol = .Machine$double.eps^0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeRemoveConstantFeaturesWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeRemoveConstantFeaturesWrapper_+3A_perc">perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
The percentage of a feature values in [0, 1) that must differ from the mode value.
Default is 0, which means only constant features with exactly one observed level are removed.</p>
</td></tr>
<tr><td><code id="makeRemoveConstantFeaturesWrapper_+3A_dont.rm">dont.rm</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Names of the columns which must not be deleted.
Default is no columns.</p>
</td></tr>
<tr><td><code id="makeRemoveConstantFeaturesWrapper_+3A_na.ignore">na.ignore</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should NAs be ignored in the percentage calculation?
(Or should they be treated as a single, extra level in the percentage calculation?)
Note that if the feature has only missing values, it is always removed.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeRemoveConstantFeaturesWrapper_+3A_wrap.tol">wrap.tol</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Numerical tolerance to treat two numbers as equal.
Variables stored as <code>double</code> will get rounded accordingly before computing the mode.
Default is <code>sqrt(.Maschine$double.eps)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeResampleDesc'>Create a description object for a resampling strategy.</h2><span id='topic+makeResampleDesc'></span><span id='topic+ResampleDesc'></span><span id='topic+hout'></span><span id='topic+cv2'></span><span id='topic+cv3'></span><span id='topic+cv5'></span><span id='topic+cv10'></span>

<h3>Description</h3>

<p>A description of a resampling algorithm contains all necessary information to
create a <a href="#topic+ResampleInstance">ResampleInstance</a>, when given the size of the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeResampleDesc(
  method,
  predict = "test",
  ...,
  stratify = FALSE,
  stratify.cols = NULL,
  fixed = FALSE,
  blocking.cv = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeResampleDesc_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
&ldquo;CV&rdquo; for cross-validation, &ldquo;LOO&rdquo; for leave-one-out, &ldquo;RepCV&rdquo; for
repeated cross-validation, &ldquo;Bootstrap&rdquo; for out-of-bag bootstrap, &ldquo;Subsample&rdquo; for
subsampling, &ldquo;Holdout&rdquo; for holdout, &ldquo;GrowingWindowCV&rdquo; for growing window
cross-validation, &ldquo;FixedWindowCV&rdquo; for fixed window cross validation.</p>
</td></tr>
<tr><td><code id="makeResampleDesc_+3A_predict">predict</code></td>
<td>
<p>(<code>character(1)</code>)<br />
What to predict during resampling: &ldquo;train&rdquo;, &ldquo;test&rdquo; or &ldquo;both&rdquo; sets.
Default is &ldquo;test&rdquo;.</p>
</td></tr>
<tr><td><code id="makeResampleDesc_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further parameters for strategies.<br />
</p>

<dl>
<dt>iters (<code>integer(1)</code>)</dt><dd><p>Number of iterations, for &ldquo;CV&rdquo;, &ldquo;Subsample&rdquo;
and &ldquo;Bootstrap&rdquo;.</p>
</dd>
<dt>split (<code>numeric(1)</code>)</dt><dd><p>Proportion of training cases for &ldquo;Holdout&rdquo; and
&ldquo;Subsample&rdquo; between 0 and 1. Default is 2 / 3.</p>
</dd>
<dt>reps (<code>integer(1)</code>)</dt><dd><p>Repeats for &ldquo;RepCV&rdquo;. Here <code>iters = folds * reps</code>.
Default is 10.</p>
</dd>
<dt>folds (<code>integer(1)</code>)</dt><dd><p>Folds in the repeated CV for <code>RepCV</code>.
Here <code>iters = folds * reps</code>. Default is 10.</p>
</dd>
<dt>horizon (<code>numeric(1)</code>)</dt><dd><p>Number of observations in the forecast test set for &ldquo;GrowingWindowCV&rdquo;
and &ldquo;FixedWindowCV&rdquo;. When <code>horizon &gt; 1</code> this will be treated as the number of
observations to forecast, else it will be a fraction of the initial window. IE,
for 100 observations, initial window of .5, and horizon of .2, the test set will have
10 observations. Default is 1.</p>
</dd>
<dt>initial.window (<code>numeric(1)</code>)</dt><dd><p>Fraction of observations to start with
in the training set for &ldquo;GrowingWindowCV&rdquo; and &ldquo;FixedWindowCV&rdquo;.
When <code>initial.window &gt; 1</code> this will be treated as the number of
observations in the initial window, else it will be treated as the fraction
of observations to have in the initial window. Default is 0.5.</p>
</dd>
<dt>skip (<code>numeric(1)</code>)</dt><dd><p> How many resamples to skip to thin the total amount
for &ldquo;GrowingWindowCV&rdquo; and &ldquo;FixedWindowCV&rdquo;. This is passed through as the &ldquo;by&rdquo; argument
in <code>seq()</code>. When <code>skip &gt; 1</code> this will be treated as the increment of the sequence of resampling indices,
else it will be a fraction of the total training indices. IE for 100 training sets and a value of .2, the increment
of the resampling indices will be 20. Default is &ldquo;horizon&rdquo; which gives mutually exclusive chunks
of test indices.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="makeResampleDesc_+3A_stratify">stratify</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should stratification be done for the target variable?
For classification tasks, this means that the resampling strategy is applied to all classes
individually and the resulting index sets are joined to make sure that the proportion of
observations in each training set is as in the original data set. Useful for imbalanced class sizes.
For survival tasks stratification is done on the events, resulting in training sets with comparable
censoring rates.</p>
</td></tr>
<tr><td><code id="makeResampleDesc_+3A_stratify.cols">stratify.cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Stratify on specific columns referenced by name. All columns have to be factor or integer.
Note that you have to ensure yourself that stratification is possible, i.e.
that each strata contains enough observations.
This argument and <code>stratify</code> are mutually exclusive.</p>
</td></tr>
<tr><td><code id="makeResampleDesc_+3A_fixed">fixed</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether indices supplied via argument 'blocking' in the task should be used as
fully pre-defined indices. Default is <code>FALSE</code> which means
they will be used following the 'blocking' approach.
<code>fixed</code> only works with ResampleDesc <code>CV</code> and the supplied indices must match
the number of observations. When <code>fixed = TRUE</code>, the <code>iters</code> argument will be ignored
and is interally set to the number of supplied factor levels in <code>blocking</code>.</p>
</td></tr>
<tr><td><code id="makeResampleDesc_+3A_blocking.cv">blocking.cv</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should 'blocking' be used in <code>CV</code>? Default to <code>FALSE</code>.
This is different to <code>fixed = TRUE</code> and cannot be combined. Please check the mlr online tutorial
for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some notes on some special strategies:
</p>

<dl>
<dt>Repeated cross-validation</dt><dd><p>Use &ldquo;RepCV&rdquo;. Then you have to set the aggregation function
for your preferred performance measure to &ldquo;testgroup.mean&rdquo;
via <a href="#topic+setAggregation">setAggregation</a>.</p>
</dd>
<dt>B632 bootstrap</dt><dd><p>Use &ldquo;Bootstrap&rdquo; for bootstrap and set predict to &ldquo;both&rdquo;.
Then you have to set the aggregation function for your preferred performance measure to
&ldquo;b632&rdquo; via <a href="#topic+setAggregation">setAggregation</a>.</p>
</dd>
<dt>B632+ bootstrap</dt><dd><p>Use &ldquo;Bootstrap&rdquo; for bootstrap and set predict to &ldquo;both&rdquo;.
Then you have to set the aggregation function for your preferred performance measure to
&ldquo;b632plus&rdquo; via <a href="#topic+setAggregation">setAggregation</a>.</p>
</dd>
<dt>Fixed Holdout set</dt><dd><p>Use <a href="#topic+makeFixedHoldoutInstance">makeFixedHoldoutInstance</a>.</p>
</dd>
</dl>

<p>Object slots:
</p>

<dl>
<dt>id (<code>character(1)</code>)</dt><dd><p>Name of resampling strategy.</p>
</dd>
<dt>iters (<code>integer(1)</code>)</dt><dd><p>Number of iterations. Note that this is always the complete number
of generated train/test sets, so for a 10-times repeated 5fold cross-validation it would be 50.</p>
</dd>
<dt>predict (<code>character(1)</code>)</dt><dd><p>See argument.</p>
</dd>
<dt>stratify (<code>logical(1)</code>)</dt><dd><p>See argument.</p>
</dd>
<dt>All parameters passed in ... under the respective argument name</dt><dd><p>See arguments.</p>
</dd>
</dl>



<h3>Value</h3>

<p>(<a href="#topic+ResampleDesc">ResampleDesc</a>).
</p>


<h3>Standard ResampleDesc objects</h3>

<p>For common resampling strategies you can save some typing
by using the following description objects:
</p>

<dl>
<dt>hout</dt><dd><p>holdout a.k.a. test sample estimation
(two-thirds training set, one-third testing set)</p>
</dd>
<dt>cv2</dt><dd><p>2-fold cross-validation</p>
</dd>
<dt>cv3</dt><dd><p>3-fold cross-validation</p>
</dd>
<dt>cv5</dt><dd><p>5-fold cross-validation</p>
</dd>
<dt>cv10</dt><dd><p>10-fold cross-validation</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Bootstraping
makeResampleDesc("Bootstrap", iters = 10)
makeResampleDesc("Bootstrap", iters = 10, predict = "both")

# Subsampling
makeResampleDesc("Subsample", iters = 10, split = 3 / 4)
makeResampleDesc("Subsample", iters = 10)

# Holdout a.k.a. test sample estimation
makeResampleDesc("Holdout")
</code></pre>

<hr>
<h2 id='makeResampleInstance'>Instantiates a resampling strategy object.</h2><span id='topic+makeResampleInstance'></span><span id='topic+ResampleInstance'></span>

<h3>Description</h3>

<p>This class encapsulates training and test sets generated from the data set for a number
of iterations. It mainly stores a set of integer vectors indicating the training and
test examples for each iteration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeResampleInstance(desc, task, size, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeResampleInstance_+3A_desc">desc</code></td>
<td>
<p>(<a href="#topic+ResampleDesc">ResampleDesc</a> | <code>character(1)</code>)<br />
Resampling description object or name of resampling strategy.
In the latter case <a href="#topic+makeResampleDesc">makeResampleDesc</a> will be called internally on the string.</p>
</td></tr>
<tr><td><code id="makeResampleInstance_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
Data of task to resample from.
Prefer to pass this instead of <code>size</code>.</p>
</td></tr>
<tr><td><code id="makeResampleInstance_+3A_size">size</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Size of the data set to resample.
Can be used instead of <code>task</code>.</p>
</td></tr>
<tr><td><code id="makeResampleInstance_+3A_...">...</code></td>
<td>
<p>(any)<br />
Passed down to <a href="#topic+makeResampleDesc">makeResampleDesc</a> in case
you passed a string in <code>desc</code>.
Otherwise ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Object slots:
</p>

<dl>
<dt>desc (<a href="#topic+ResampleDesc">ResampleDesc</a>)</dt><dd><p>See argument.</p>
</dd>
<dt>size (<code>integer(1)</code>)</dt><dd><p>See argument.</p>
</dd>
<dt>train.inds (list of <a href="base.html#topic+integer">integer</a>)</dt><dd><p>List of of training indices for all iterations.</p>
</dd>
<dt>test.inds (list of <a href="base.html#topic+integer">integer</a>)</dt><dd><p>List of of test indices for all iterations.</p>
</dd>
<dt>group (<a href="base.html#topic+factor">factor</a>)</dt><dd><p>Optional grouping of resampling iterations. This encodes whether
specific iterations 'belong together' (e.g. repeated CV), and it can later be used to
aggregate performance values accordingly. Default is 'factor()'.</p>
</dd>
</dl>



<h3>Value</h3>

<p>(<a href="#topic+ResampleInstance">ResampleInstance</a>).
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rdesc = makeResampleDesc("Bootstrap", iters = 10)
rin = makeResampleInstance(rdesc, task = iris.task)

rdesc = makeResampleDesc("CV", iters = 50)
rin = makeResampleInstance(rdesc, size = nrow(iris))

rin = makeResampleInstance("CV", iters = 10, task = iris.task)
</code></pre>

<hr>
<h2 id='makeRLearner.classif.fdausc.glm'>Classification of functional data by Generalized Linear Models.</h2><span id='topic+makeRLearner.classif.fdausc.glm'></span>

<h3>Description</h3>

<p>Learner for classification using Generalized Linear Models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'classif.fdausc.glm'
makeRLearner()
</code></pre>

<hr>
<h2 id='makeRLearner.classif.fdausc.kernel'>Learner for kernel classification for functional data.</h2><span id='topic+makeRLearner.classif.fdausc.kernel'></span>

<h3>Description</h3>

<p>Learner for kernel Classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'classif.fdausc.kernel'
makeRLearner()
</code></pre>

<hr>
<h2 id='makeRLearner.classif.fdausc.np'>Learner for nonparametric classification for functional data.</h2><span id='topic+makeRLearner.classif.fdausc.np'></span>

<h3>Description</h3>

<p>Learner for Nonparametric Supervised Classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'classif.fdausc.np'
makeRLearner()
</code></pre>

<hr>
<h2 id='makeSMOTEWrapper'>Fuse learner with SMOTE oversampling for imbalancy correction in binary classification.</h2><span id='topic+makeSMOTEWrapper'></span>

<h3>Description</h3>

<p>Creates a learner object, which can be
used like any other learner object.
Internally uses <a href="#topic+smote">smote</a> before every model fit.
</p>
<p>Note that observation weights do not influence the sampling and are simply passed
down to the next learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeSMOTEWrapper(
  learner,
  sw.rate = 1,
  sw.nn = 5L,
  sw.standardize = TRUE,
  sw.alt.logic = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeSMOTEWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeSMOTEWrapper_+3A_sw.rate">sw.rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Factor to oversample the smaller class. Must be between 1 and <code>Inf</code>,
where 1 means no oversampling and 2 would mean doubling the class size.
Default is 1.</p>
</td></tr>
<tr><td><code id="makeSMOTEWrapper_+3A_sw.nn">sw.nn</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of nearest neighbors to consider.
Default is 5.</p>
</td></tr>
<tr><td><code id="makeSMOTEWrapper_+3A_sw.standardize">sw.standardize</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Standardize input variables before calculating the nearest neighbors
for data sets with numeric input variables only. For mixed variables
(numeric and factor) the gower distance is used and variables are
standardized anyway.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeSMOTEWrapper_+3A_sw.alt.logic">sw.alt.logic</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Use an alternative logic for selection of minority class observations.
Instead of sampling a minority class element AND one of its nearest
neighbors, each minority class element is taken multiple times (depending
on rate) for the interpolation and only the corresponding nearest neighbor
is sampled.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeStackedLearner'>Create a stacked learner object.</h2><span id='topic+makeStackedLearner'></span>

<h3>Description</h3>

<p>A stacked learner uses predictions of several base learners and
fits a super learner using these predictions as features in order to
predict the outcome. The following stacking methods are available:
</p>

<ul>
<li> <p><code>average</code><br /> Averaging of base learner predictions without weights.
</p>
</li>
<li> <p><code>stack.nocv</code><br /> Fits the super learner, where in-sample predictions of
the base learners are used.
</p>
</li>
<li> <p><code>stack.cv</code><br /> Fits the super learner, where the base learner predictions
are computed by cross-validated predictions (the resampling strategy can be
set via the <code>resampling</code> argument).
</p>
</li>
<li> <p><code>hill.climb</code><br /> Select a subset of base learner predictions by hill
climbing algorithm.
</p>
</li>
<li> <p><code>compress</code><br /> Train a neural network to compress the model from a
collection of base learners.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>makeStackedLearner(
  base.learners,
  super.learner = NULL,
  predict.type = NULL,
  method = "stack.nocv",
  use.feat = FALSE,
  resampling = NULL,
  parset = list()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeStackedLearner_+3A_base.learners">base.learners</code></td>
<td>
<p>((list of) <a href="#topic+Learner">Learner</a>)<br />
A list of learners created with <code>makeLearner</code>.</p>
</td></tr>
<tr><td><code id="makeStackedLearner_+3A_super.learner">super.learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | character(1))<br />
The super learner that makes the final prediction based on the base
learners. If you pass a string, the super learner will be created via
<code>makeLearner</code>. Not used for <code>method = 'average'</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="makeStackedLearner_+3A_predict.type">predict.type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Sets the type of the final prediction for <code>method = 'average'</code>. For other
methods, the predict type should be set within <code>super.learner</code>. If the type
of the base learner prediction, which is set up within <code>base.learners</code>, is
</p>

<ul>
<li> <p><code>"prob"</code><br /> then <code>predict.type = 'prob'</code> will use the average of all
base learner predictions and <code>predict.type = 'response'</code> will use the
class with highest probability as final prediction.
</p>
</li>
<li> <p><code>"response"</code><br /> then, for classification tasks with <code>predict.type =    'prob'</code>, the final prediction will be the relative frequency based on the
predicted base learner classes and classification tasks with <code>predict.type    = 'response'</code> will use majority vote of the base learner predictions to
determine the final prediction. For regression tasks, the final prediction
will be the average of the base learner predictions.
</p>
</li></ul>
</td></tr>
<tr><td><code id="makeStackedLearner_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
&ldquo;average&rdquo; for averaging the predictions of the base learners,
&ldquo;stack.nocv&rdquo; for building a super learner using the predictions of
the base learners,
&ldquo;stack.cv&rdquo; for building a super learner using cross-validated
predictions of the base learners.
&ldquo;hill.climb&rdquo; for averaging the predictions of the base learners,
with the weights learned from hill climbing algorithm and
&ldquo;compress&rdquo; for compressing the model to mimic the predictions of a
collection of base learners while speeding up the predictions and reducing
the size of the model. Default is &ldquo;stack.nocv&rdquo;,</p>
</td></tr>
<tr><td><code id="makeStackedLearner_+3A_use.feat">use.feat</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether the original features should also be passed to the super learner.
Not used for <code>method = 'average'</code>.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeStackedLearner_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy for <code>method = 'stack.cv'</code>.
Currently only CV is allowed for resampling.
The default <code>NULL</code> uses 5-fold CV.</p>
</td></tr>
<tr><td><code id="makeStackedLearner_+3A_parset">parset</code></td>
<td>
<p>the parameters for <code>hill.climb</code> method, including
</p>

<ul>
<li> <p><code>replace</code><br /> Whether a base learner can be selected more than once.
</p>
</li>
<li> <p><code>init</code><br /> Number of best models being included before the selection algorithm.
</p>
</li>
<li> <p><code>bagprob</code><br /> The proportion of models being considered in one round of selection.
</p>
</li>
<li> <p><code>bagtime</code><br /> The number of rounds of the bagging selection.
</p>
</li>
<li> <p><code>metric</code><br /> The result evaluation metric function taking two parameters
<code>pred</code> and <code>true</code>, the smaller the score the better.
</p>
</li></ul>

<p>the parameters for <code>compress</code> method, including
</p>

<ul>
<li><p> k<br /> the size multiplier of the generated data
</p>
</li>
<li><p> prob<br /> the probability to exchange values
</p>
</li>
<li><p> s<br /> the standard deviation of each numerical feature
</p>
</li></ul>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Classification
data(iris)
tsk = makeClassifTask(data = iris, target = "Species")
base = c("classif.rpart", "classif.lda", "classif.svm")
lrns = lapply(base, makeLearner)
lrns = lapply(lrns, setPredictType, "prob")
m = makeStackedLearner(base.learners = lrns,
  predict.type = "prob", method = "hill.climb")
tmp = train(m, tsk)
res = predict(tmp, tsk)

# Regression
data(BostonHousing, package = "mlbench")
tsk = makeRegrTask(data = BostonHousing, target = "medv")
base = c("regr.rpart", "regr.svm")
lrns = lapply(base, makeLearner)
m = makeStackedLearner(base.learners = lrns,
  predict.type = "response", method = "compress")
tmp = train(m, tsk)
res = predict(tmp, tsk)
</code></pre>

<hr>
<h2 id='makeSurvTask'>Create a survival task.</h2><span id='topic+makeSurvTask'></span><span id='topic+SurvTask'></span>

<h3>Description</h3>

<p>Create a survival task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeSurvTask(
  id = deparse(substitute(data)),
  data,
  target,
  weights = NULL,
  blocking = NULL,
  coordinates = NULL,
  fixup.data = "warn",
  check.data = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeSurvTask_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
For survival analysis these are the names of the survival time and event columns,
so it has length 2. For multilabel classification it contains the names of the logical
columns that encode whether a label is present or not and its length corresponds to the
number of classes.</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
Cannot be set for cost-sensitive learning.
Default is <code>NULL</code> which means no (= equal) weights.</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="makeSurvTask_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+Task">Task</a> <a href="#topic+ClassifTask">ClassifTask</a> <a href="#topic+ClusterTask">ClusterTask</a> <a href="#topic+CostSensTask">CostSensTask</a> <a href="#topic+MultilabelTask">MultilabelTask</a> <a href="#topic+RegrTask">RegrTask</a>
</p>

<hr>
<h2 id='makeTaskDescInternal'>Exported for internal use.</h2><span id='topic+makeTaskDescInternal'></span>

<h3>Description</h3>

<p>Exported for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTaskDescInternal(type, id, data, target, weights, blocking, coordinates)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTaskDescInternal_+3A_type">type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Task type.</p>
</td></tr>
<tr><td><code id="makeTaskDescInternal_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
task id</p>
</td></tr>
<tr><td><code id="makeTaskDescInternal_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
data</p>
</td></tr>
<tr><td><code id="makeTaskDescInternal_+3A_target">target</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
target columns</p>
</td></tr>
<tr><td><code id="makeTaskDescInternal_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
weights</p>
</td></tr>
<tr><td><code id="makeTaskDescInternal_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
task data blocking</p>
</td></tr>
<tr><td><code id="makeTaskDescInternal_+3A_coordinates">coordinates</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
whether spatial coordinates have been provided</p>
</td></tr>
</table>

<hr>
<h2 id='makeTuneControlCMAES'>Create control object for hyperparameter tuning with CMAES.</h2><span id='topic+makeTuneControlCMAES'></span><span id='topic+TuneControlCMAES'></span>

<h3>Description</h3>

<p>CMA Evolution Strategy with method <a href="cmaes.html#topic+cma_es">cmaes::cma_es</a>.
Can handle numeric(vector) and integer(vector) hyperparameters, but no dependencies.
For integers the internally proposed numeric values are automatically rounded.
The sigma variance parameter is initialized to 1/4 of the span of box-constraints per
parameter dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlCMAES(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  start = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlCMAES_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_start">start</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Named list of initial parameter values.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function
evaluations. The <code>budget</code> corresponds to the product of the number of generations
(<code>maxit</code>) and the number of offsprings per generation
(<code>lambda</code>).</p>
</td></tr>
<tr><td><code id="makeTuneControlCMAES_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further control parameters passed to the <code>control</code> arguments of
<a href="cmaes.html#topic+cma_es">cmaes::cma_es</a> or <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a>, as well as
towards the <code>tunerConfig</code> argument of <a href="irace.html#topic+irace">irace::irace</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlCMAES">TuneControlCMAES</a>)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneControlDesign'>Create control object for hyperparameter tuning with predefined design.</h2><span id='topic+makeTuneControlDesign'></span><span id='topic+TuneControlDesign'></span>

<h3>Description</h3>

<p>Completely pre-specifiy a <code>data.frame</code> of design points to be evaluated
during tuning. All kinds of parameter types can be handled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlDesign(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  design = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlDesign_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlDesign_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="makeTuneControlDesign_+3A_design">design</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
<code>data.frame</code> containing the different parameter settings to be evaluated.
The columns have to be named according to the <code>ParamSet</code> which will be used in <code>tune()</code>.
Proper designs can be created with <a href="ParamHelpers.html#topic+generateDesign">ParamHelpers::generateDesign</a> for instance.</p>
</td></tr>
<tr><td><code id="makeTuneControlDesign_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlDesign_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlDesign_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlDesign">TuneControlDesign</a>)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneControlGenSA'>Create control object for hyperparameter tuning with GenSA.</h2><span id='topic+makeTuneControlGenSA'></span><span id='topic+TuneControlGenSA'></span>

<h3>Description</h3>

<p>Generalized simulated annealing with method <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a>.
Can handle numeric(vector) and integer(vector) hyperparameters, but no dependencies.
For integers the internally proposed numeric values are automatically rounded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlGenSA(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  start = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlGenSA_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_start">start</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Named list of initial parameter values.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function
evaluations. <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a> defines the <code>budget</code> via
the argument <code>max.call</code>. However, one should note that this algorithm
does not stop its local search before its end. This behavior might lead
to an extension of the defined budget and will result in a warning.</p>
</td></tr>
<tr><td><code id="makeTuneControlGenSA_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further control parameters passed to the <code>control</code> arguments of
<a href="cmaes.html#topic+cma_es">cmaes::cma_es</a> or <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a>, as well as
towards the <code>tunerConfig</code> argument of <a href="irace.html#topic+irace">irace::irace</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlGenSA">TuneControlGenSA</a>).
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneControlGrid'>Create control object for hyperparameter tuning with grid search.</h2><span id='topic+makeTuneControlGrid'></span><span id='topic+TuneControlGrid'></span>

<h3>Description</h3>

<p>A basic grid search can handle all kinds of parameter types.
You can either use their correct param type and <code>resolution</code>,
or discretize them yourself by always using <a href="ParamHelpers.html#topic+Param">ParamHelpers::makeDiscreteParam</a>
in the <code>par.set</code> passed to <a href="#topic+tuneParams">tuneParams</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlGrid(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  resolution = 10L,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlGrid_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_resolution">resolution</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Resolution of the grid for each numeric/integer parameter in <code>par.set</code>.
For vector parameters, it is the resolution per dimension.
Either pass one resolution for all parameters, or a named vector.
See <a href="ParamHelpers.html#topic+generateGridDesign">ParamHelpers::generateGridDesign</a>.
Default is 10.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="makeTuneControlGrid_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function
evaluations. If set, must equal the size of the grid.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlGrid">TuneControlGrid</a>)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneControlIrace'>Create control object for hyperparameter tuning with Irace.</h2><span id='topic+makeTuneControlIrace'></span><span id='topic+TuneControlIrace'></span>

<h3>Description</h3>

<p>Tuning with iterated F-Racing with method <a href="irace.html#topic+irace">irace::irace</a>. All
kinds of parameter types can be handled. We return the best of the final
elite candidates found by irace in the last race. Its estimated performance
is the mean of all evaluations ever done for that candidate. More information
on irace can be found in package vignette: <code>vignette("irace-package", package = "irace")</code>
</p>
<p>For resampling you have to pass a <a href="#topic+ResampleDesc">ResampleDesc</a>, not a <a href="#topic+ResampleInstance">ResampleInstance</a>.
The resampling strategy is randomly instantiated <code>n.instances</code> times and
these are the instances in the sense of irace (<code>instances</code> element of
<code>tunerConfig</code> in <a href="irace.html#topic+irace">irace::irace</a>). Also note that irace will always store its
tuning results in a file on disk, see the package documentation for details
on this and how to change the file path.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlIrace(
  impute.val = NULL,
  n.instances = 100L,
  show.irace.output = FALSE,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlIrace_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_n.instances">n.instances</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of random resampling instances for irace, see details.
Default is 100.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_show.irace.output">show.irace.output</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Show console output of irace while tuning?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function
evaluations. It is passed to <code>maxExperiments</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlIrace_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further control parameters passed to the <code>control</code> arguments of
<a href="cmaes.html#topic+cma_es">cmaes::cma_es</a> or <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a>, as well as
towards the <code>tunerConfig</code> argument of <a href="irace.html#topic+irace">irace::irace</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlIrace">TuneControlIrace</a>)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneControlMBO'>Create control object for hyperparameter tuning with MBO.</h2><span id='topic+makeTuneControlMBO'></span><span id='topic+TuneControlMBO'></span>

<h3>Description</h3>

<p>Model-based / Bayesian optimization with the function
<a href="mlrMBO.html#topic+mbo">mlrMBO::mbo</a> from the <span class="pkg">mlrMBO</span> package.
Please refer to <a href="https://github.com/mlr-org/mlrMBO">https://github.com/mlr-org/mlrMBO</a> for further info.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlMBO(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  learner = NULL,
  mbo.control = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  continue = FALSE,
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  mbo.design = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlMBO_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>NULL</code>)<br />
The surrogate learner: A regression learner to model performance landscape.
For the default, <code>NULL</code>, <span class="pkg">mlrMBO</span> will automatically create a suitable learner based on the rules described in <a href="mlrMBO.html#topic+makeMBOLearner">mlrMBO::makeMBOLearner</a>.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_mbo.control">mbo.control</code></td>
<td>
<p>(<a href="mlrMBO.html#topic+makeMBOControl">mlrMBO::MBOControl</a> | <code>NULL</code>)<br />
Control object for model-based optimization tuning.
For the default, <code>NULL</code>, the control object will be created with all the defaults as described in <a href="mlrMBO.html#topic+makeMBOControl">mlrMBO::makeMBOControl</a>.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_continue">continue</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Resume calculation from previous run using <a href="mlrMBO.html#topic+mboContinue">mlrMBO::mboContinue</a>?
Requires &ldquo;save.file.path&rdquo; to be set.
Note that the <a href="ParamHelpers.html#topic+OptPath">ParamHelpers::OptPath</a> in the <a href="mlrMBO.html#topic+OptResult">mlrMBO::OptResult</a>
will only include the evaluations after the continuation.
The complete OptPath will be found in the slot <code style="white-space: pre;">&#8288;$mbo.result$opt.path&#8288;</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function evaluations.</p>
</td></tr>
<tr><td><code id="makeTuneControlMBO_+3A_mbo.design">mbo.design</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <code>NULL</code>)<br />
Initial design as data frame.
If the parameters have corresponding trafo functions,
the design must not be transformed before it is passed!
For the default, <code>NULL</code>, a default design is created like described in <a href="mlrMBO.html#topic+mbo">mlrMBO::mbo</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlMBO">TuneControlMBO</a>)
</p>


<h3>References</h3>

<p>Bernd Bischl, Jakob Richter, Jakob Bossek, Daniel Horn, Janek Thomas and Michel Lang; mlrMBO: A Modular Framework for Model-Based Optimization of Expensive Black-Box Functions, Preprint: <a href="https://arxiv.org/abs/1703.03373">https://arxiv.org/abs/1703.03373</a> (2017).
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneControlRandom'>Create control object for hyperparameter tuning with random search.</h2><span id='topic+makeTuneControlRandom'></span><span id='topic+TuneControlRandom'></span>

<h3>Description</h3>

<p>Random search. All kinds of parameter types can be handled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneControlRandom(
  same.resampling.instance = TRUE,
  maxit = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneControlRandom_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlRandom_+3A_maxit">maxit</code></td>
<td>
<p>(<code>integer(1)</code> | NULL)<br />
Number of iterations for random search.
Default is 100.</p>
</td></tr>
<tr><td><code id="makeTuneControlRandom_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="makeTuneControlRandom_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="makeTuneControlRandom_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="makeTuneControlRandom_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="makeTuneControlRandom_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function
evaluations. The <code>budget</code> equals the number of iterations (<code>maxit</code>) performed by
the random search algorithm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneControlRandom">TuneControlRandom</a>)
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='makeTuneWrapper'>Fuse learner with tuning.</h2><span id='topic+makeTuneWrapper'></span>

<h3>Description</h3>

<p>Fuses a base learner with a search strategy to select its hyperparameters.
Creates a learner object, which can be used like any other learner object,
but which internally uses <a href="#topic+tuneParams">tuneParams</a>.
If the train function is called on it,
the search strategy and resampling are invoked
to select an optimal set of hyperparameter values. Finally, a model is fitted on the
complete training data with these optimal hyperparameters and returned.
See <a href="#topic+tuneParams">tuneParams</a> for more details.
</p>
<p>After training, the optimal hyperparameters (and other related information) can be retrieved with
<a href="#topic+getTuneResult">getTuneResult</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeTuneWrapper(
  learner,
  resampling,
  measures,
  par.set,
  control,
  show.info = getMlrOption("show.info")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeTuneWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeTuneWrapper_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleInstance">ResampleInstance</a> | <a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy to evaluate points in hyperparameter space. If you pass a description,
it is instantiated once at the beginning by default, so all points are
evaluated on the same training/test sets.
If you want to change that behavior, look at <a href="#topic+TuneControl">TuneControl</a>.</p>
</td></tr>
<tr><td><code id="makeTuneWrapper_+3A_measures">measures</code></td>
<td>
<p>(list of <a href="#topic+Measure">Measure</a> | <a href="#topic+Measure">Measure</a>)<br />
Performance measures to evaluate. The first measure, aggregated by the first aggregation function
is optimized, others are simply evaluated.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="makeTuneWrapper_+3A_par.set">par.set</code></td>
<td>
<p>(<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a>)<br />
Collection of parameters and their constraints for optimization.
Dependent parameters with a <code>requires</code> field must use <code>quote</code> and not
<code>expression</code> to define it.</p>
</td></tr>
<tr><td><code id="makeTuneWrapper_+3A_control">control</code></td>
<td>
<p>(<a href="#topic+TuneControl">TuneControl</a>)<br />
Control object for search method. Also selects the optimization algorithm for tuning.</p>
</td></tr>
<tr><td><code id="makeTuneWrapper_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.rpart")
# stupid mini grid
ps = makeParamSet(
  makeDiscreteParam("cp", values = c(0.05, 0.1)),
  makeDiscreteParam("minsplit", values = c(10, 20))
)
ctrl = makeTuneControlGrid()
inner = makeResampleDesc("Holdout")
outer = makeResampleDesc("CV", iters = 2)
lrn = makeTuneWrapper(lrn, resampling = inner, par.set = ps, control = ctrl)
mod = train(lrn, task)
print(getTuneResult(mod))
# nested resampling for evaluation
# we also extract tuned hyper pars in each iteration
r = resample(lrn, task, outer, extract = getTuneResult)
print(r$extract)
getNestedTuneResultsOptPathDf(r)
getNestedTuneResultsX(r)

</code></pre>

<hr>
<h2 id='makeUndersampleWrapper'>Fuse learner with simple ove/underrsampling for imbalancy correction in binary classification.</h2><span id='topic+makeUndersampleWrapper'></span><span id='topic+makeOversampleWrapper'></span>

<h3>Description</h3>

<p>Creates a learner object, which can be
used like any other learner object.
Internally uses <a href="#topic+oversample">oversample</a> or <a href="#topic+undersample">undersample</a> before every model fit.
</p>
<p>Note that observation weights do not influence the sampling and are simply passed
down to the next learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeUndersampleWrapper(learner, usw.rate = 1, usw.cl = NULL)

makeOversampleWrapper(learner, osw.rate = 1, osw.cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeUndersampleWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeUndersampleWrapper_+3A_usw.rate">usw.rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Factor to downsample a class. Must be between 0 and 1,
where 1 means no downsampling, 0.5 implies reduction to 50 percent
and 0 would imply reduction to 0 observations.
Default is 1.</p>
</td></tr>
<tr><td><code id="makeUndersampleWrapper_+3A_usw.cl">usw.cl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Class that should be undersampled.
Default is <code>NULL</code>, which means the larger one.</p>
</td></tr>
<tr><td><code id="makeUndersampleWrapper_+3A_osw.rate">osw.rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Factor to oversample a class. Must be between 1 and <code>Inf</code>,
where 1 means no oversampling and 2 would mean doubling the class size.
Default is 1.</p>
</td></tr>
<tr><td><code id="makeUndersampleWrapper_+3A_osw.cl">osw.cl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Class that should be oversampled.
Default is <code>NULL</code>, which means the smaller one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other imbalancy: 
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+oversample">oversample</a>()</code>,
<code><a href="#topic+smote">smote</a>()</code>
</p>
<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeWeightedClassesWrapper">makeWeightedClassesWrapper</a>()</code>
</p>

<hr>
<h2 id='makeWeightedClassesWrapper'>Wraps a classifier for weighted fitting where each class receives a weight.</h2><span id='topic+makeWeightedClassesWrapper'></span>

<h3>Description</h3>

<p>Creates a wrapper, which can be used like any other learner object.
</p>
<p>Fitting is performed in a weighted fashion where each observation receives a weight,
depending on the class it belongs to, see <code>wcw.weight</code>.
This might help to mitigate problems caused by imbalanced class distributions.
</p>
<p>This weighted fitting can be achieved in two ways:
</p>
<p>a) The learner already has a parameter for class weighting, so one weight can directly be defined
per class. Example: &ldquo;classif.ksvm&rdquo; and parameter <code>class.weights</code>.
In this case we don't really do anything fancy. We convert <code>wcw.weight</code> a bit,
but basically simply bind its value to the class weighting param.
The wrapper in this case simply offers a convenient, consistent fashion for class weighting -
and tuning! See example below.
</p>
<p>b) The learner does not have a direct parameter to support class weighting, but
supports observation weights, so <code>hasLearnerProperties(learner, 'weights')</code> is <code>TRUE</code>.
This means that an individual, arbitrary weight can be set per observation during training.
We set this weight depending on the class internally in the wrapper. Basically we introduce
something like a new &ldquo;class.weights&rdquo; parameter for the learner via observation weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeWeightedClassesWrapper(learner, wcw.param = NULL, wcw.weight = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeWeightedClassesWrapper_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The classification learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeWeightedClassesWrapper_+3A_wcw.param">wcw.param</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of already existing learner parameter, which allows class weighting.
The default (<code>wcw.param = NULL</code>) will use the parameter defined in
the learner (<code>class.weights.param</code>). During training, the parameter
must accept a named vector of class weights, where length equals the
number of classes.</p>
</td></tr>
<tr><td><code id="makeWeightedClassesWrapper_+3A_wcw.weight">wcw.weight</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Weight for each class.
Must be a vector of the same number of elements as classes are in task,
and must also be in the same order as the class levels are in
<code>getTaskDesc(task)$class.levels</code>.
For convenience, one must pass a single number in case of binary classification, which
is then taken as the weight of the positive class, while the negative class receives a weight
of 1.
Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other wrapper: 
<code><a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>()</code>,
<code><a href="#topic+makeClassificationViaRegressionWrapper">makeClassificationViaRegressionWrapper</a>()</code>,
<code><a href="#topic+makeConstantClassWrapper">makeConstantClassWrapper</a>()</code>,
<code><a href="#topic+makeCostSensClassifWrapper">makeCostSensClassifWrapper</a>()</code>,
<code><a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>()</code>,
<code><a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a>()</code>,
<code><a href="#topic+makeDummyFeaturesWrapper">makeDummyFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeExtractFDAFeatsWrapper">makeExtractFDAFeatsWrapper</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>,
<code><a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelClassifierChainsWrapper">makeMultilabelClassifierChainsWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelDBRWrapper">makeMultilabelDBRWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelNestedStackingWrapper">makeMultilabelNestedStackingWrapper</a>()</code>,
<code><a href="#topic+makeMultilabelStackingWrapper">makeMultilabelStackingWrapper</a>()</code>,
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makePreprocWrapperCaret">makePreprocWrapperCaret</a>()</code>,
<code><a href="#topic+makePreprocWrapper">makePreprocWrapper</a>()</code>,
<code><a href="#topic+makeRemoveConstantFeaturesWrapper">makeRemoveConstantFeaturesWrapper</a>()</code>,
<code><a href="#topic+makeSMOTEWrapper">makeSMOTEWrapper</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# using the direct parameter of the SVM (which is already defined in the learner)
lrn = makeWeightedClassesWrapper("classif.ksvm", wcw.weight = 0.01)
res = holdout(lrn, sonar.task)
print(calculateConfusionMatrix(res$pred))

# using the observation weights of logreg
lrn = makeWeightedClassesWrapper("classif.logreg", wcw.weight = 0.01)
res = holdout(lrn, sonar.task)
print(calculateConfusionMatrix(res$pred))

# tuning the imbalancy param and the SVM param in one go
lrn = makeWeightedClassesWrapper("classif.ksvm", wcw.param = "class.weights")
ps = makeParamSet(
  makeNumericParam("wcw.weight", lower = 1, upper = 10),
  makeNumericParam("C", lower = -12, upper = 12, trafo = function(x) 2^x),
  makeNumericParam("sigma", lower = -12, upper = 12, trafo = function(x) 2^x)
)
ctrl = makeTuneControlRandom(maxit = 3L)
rdesc = makeResampleDesc("CV", iters = 2L, stratify = TRUE)
res = tuneParams(lrn, sonar.task, rdesc, par.set = ps, control = ctrl)
print(res)
# print(res$opt.path)

</code></pre>

<hr>
<h2 id='makeWrappedModel'>Induced model of learner.</h2><span id='topic+makeWrappedModel'></span><span id='topic+WrappedModel'></span>

<h3>Description</h3>

<p>Result from <a href="#topic+train">train</a>.
</p>
<p>It internally stores the underlying fitted model,
the subset used for training, features used for training, levels of factors in the
data set and computation time that was spent for training.
</p>
<p>Object members: See arguments.
</p>
<p>The constructor <code>makeWrappedModel</code> is mainly for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeWrappedModel(
  learner,
  learner.model,
  task.desc,
  subset,
  features,
  factor.levels,
  time
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeWrappedModel_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="makeWrappedModel_+3A_learner.model">learner.model</code></td>
<td>
<p>(any)<br />
Underlying model.</p>
</td></tr>
<tr><td><code id="makeWrappedModel_+3A_task.desc">task.desc</code></td>
<td>
<p><a href="#topic+TaskDesc">TaskDesc</a><br />
Task description object.</p>
</td></tr>
<tr><td><code id="makeWrappedModel_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
<tr><td><code id="makeWrappedModel_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Features used for training.</p>
</td></tr>
<tr><td><code id="makeWrappedModel_+3A_factor.levels">factor.levels</code></td>
<td>
<p>(named <a href="base.html#topic+list">list</a> of <a href="base.html#topic+character">character</a>)<br />
Levels of factor variables (features and potentially target) in training data.
Named by variable name, non-factors do not occur in the list.</p>
</td></tr>
<tr><td><code id="makeWrappedModel_+3A_time">time</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Computation time for model fit in seconds.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+WrappedModel">WrappedModel</a>.
</p>

<hr>
<h2 id='MeasureProperties'>Query properties of measures.</h2><span id='topic+MeasureProperties'></span><span id='topic+getMeasureProperties'></span><span id='topic+hasMeasureProperties'></span>

<h3>Description</h3>

<p>Properties can be accessed with <code>getMeasureProperties(measure)</code>, which returns a
character vector.
</p>
<p>The measure properties are defined in <a href="#topic+Measure">Measure</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMeasureProperties(measure)

hasMeasureProperties(measure, props)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MeasureProperties_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="MeasureProperties_+3A_props">props</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Vector of properties to query.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>getMeasureProperties</code> returns a character vector with measure properties.
<code>hasMeasureProperties</code> returns a logical vector of the same length as <code>props</code>.
</p>

<hr>
<h2 id='measures'>Performance measures.</h2><span id='topic+measures'></span><span id='topic+featperc'></span><span id='topic+timetrain'></span><span id='topic+timepredict'></span><span id='topic+timeboth'></span><span id='topic+sse'></span><span id='topic+measureSSE'></span><span id='topic+mse'></span><span id='topic+measureMSE'></span><span id='topic+rmse'></span><span id='topic+measureRMSE'></span><span id='topic+medse'></span><span id='topic+measureMEDSE'></span><span id='topic+sae'></span><span id='topic+measureSAE'></span><span id='topic+mae'></span><span id='topic+measureMAE'></span><span id='topic+medae'></span><span id='topic+measureMEDAE'></span><span id='topic+rsq'></span><span id='topic+measureRSQ'></span><span id='topic+expvar'></span><span id='topic+measureEXPVAR'></span><span id='topic+rrse'></span><span id='topic+measureRRSE'></span><span id='topic+rae'></span><span id='topic+measureRAE'></span><span id='topic+mape'></span><span id='topic+measureMAPE'></span><span id='topic+msle'></span><span id='topic+measureMSLE'></span><span id='topic+rmsle'></span><span id='topic+measureRMSLE'></span><span id='topic+kendalltau'></span><span id='topic+measureKendallTau'></span><span id='topic+spearmanrho'></span><span id='topic+measureSpearmanRho'></span><span id='topic+mmce'></span><span id='topic+measureMMCE'></span><span id='topic+acc'></span><span id='topic+measureACC'></span><span id='topic+ber'></span><span id='topic+measureBER'></span><span id='topic+multiclass.aunu'></span><span id='topic+measureAUNU'></span><span id='topic+multiclass.aunp'></span><span id='topic+measureAUNP'></span><span id='topic+multiclass.au1u'></span><span id='topic+measureAU1U'></span><span id='topic+multiclass.au1p'></span><span id='topic+measureAU1P'></span><span id='topic+multiclass.brier'></span><span id='topic+measureMulticlassBrier'></span><span id='topic+logloss'></span><span id='topic+measureLogloss'></span><span id='topic+ssr'></span><span id='topic+measureSSR'></span><span id='topic+qsr'></span><span id='topic+measureQSR'></span><span id='topic+lsr'></span><span id='topic+measureLSR'></span><span id='topic+kappa'></span><span id='topic+measureKAPPA'></span><span id='topic+wkappa'></span><span id='topic+measureWKAPPA'></span><span id='topic+auc'></span><span id='topic+measureAUC'></span><span id='topic+brier'></span><span id='topic+measureBrier'></span><span id='topic+brier.scaled'></span><span id='topic+measureBrierScaled'></span><span id='topic+bac'></span><span id='topic+measureBAC'></span><span id='topic+tp'></span><span id='topic+measureTP'></span><span id='topic+tn'></span><span id='topic+measureTN'></span><span id='topic+fp'></span><span id='topic+measureFP'></span><span id='topic+fn'></span><span id='topic+measureFN'></span><span id='topic+tpr'></span><span id='topic+measureTPR'></span><span id='topic+tnr'></span><span id='topic+measureTNR'></span><span id='topic+fpr'></span><span id='topic+measureFPR'></span><span id='topic+fnr'></span><span id='topic+measureFNR'></span><span id='topic+ppv'></span><span id='topic+measurePPV'></span><span id='topic+npv'></span><span id='topic+measureNPV'></span><span id='topic+fdr'></span><span id='topic+measureFDR'></span><span id='topic+mcc'></span><span id='topic+measureMCC'></span><span id='topic+f1'></span><span id='topic+measureF1'></span><span id='topic+gmean'></span><span id='topic+measureGMEAN'></span><span id='topic+gpr'></span><span id='topic+measureGPR'></span><span id='topic+multilabel.hamloss'></span><span id='topic+measureMultilabelHamloss'></span><span id='topic+multilabel.subset01'></span><span id='topic+measureMultilabelSubset01'></span><span id='topic+multilabel.f1'></span><span id='topic+measureMultilabelF1'></span><span id='topic+multilabel.acc'></span><span id='topic+measureMultilabelACC'></span><span id='topic+multilabel.ppv'></span><span id='topic+measureMultilabelPPV'></span><span id='topic+multilabel.tpr'></span><span id='topic+measureMultilabelTPR'></span><span id='topic+cindex'></span><span id='topic+cindex.uno'></span><span id='topic+iauc.uno'></span><span id='topic+ibrier'></span><span id='topic+meancosts'></span><span id='topic+mcp'></span><span id='topic+db'></span><span id='topic+G1'></span><span id='topic+G2'></span><span id='topic+silhouette'></span>

<h3>Description</h3>

<p>A performance measure is evaluated after a single train/predict step and
returns a single number to assess the quality of the prediction (or maybe
only the model, think AIC). The measure itself knows whether it wants to be
minimized or maximized and for what tasks it is applicable.
</p>
<p>All supported measures can be found by <a href="#topic+listMeasures">listMeasures</a> or as a table in the
tutorial appendix: <a href="https://mlr.mlr-org.com/articles/tutorial/measures.html">https://mlr.mlr-org.com/articles/tutorial/measures.html</a>.
</p>
<p>If you want a measure for a misclassification cost matrix, look at
<a href="#topic+makeCostMeasure">makeCostMeasure</a>. If you want to implement your own measure, look at
<a href="#topic+makeMeasure">makeMeasure</a>.
</p>
<p>Most measures can directly be accessed via the function named after the
scheme measureX (e.g. measureSSE).
</p>
<p>For clustering measures, we compact the predicted cluster IDs such that they
form a continuous series starting with 1. If this is not the case, some of
the measures will generate warnings.
</p>
<p>Some measure have parameters. Their defaults are set in the constructor
<a href="#topic+makeMeasure">makeMeasure</a> and can be overwritten using <a href="#topic+setMeasurePars">setMeasurePars</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measureSSE(truth, response)

measureMSE(truth, response)

measureRMSE(truth, response)

measureMEDSE(truth, response)

measureSAE(truth, response)

measureMAE(truth, response)

measureMEDAE(truth, response)

measureRSQ(truth, response)

measureEXPVAR(truth, response)

measureRRSE(truth, response)

measureRAE(truth, response)

measureMAPE(truth, response)

measureMSLE(truth, response)

measureRMSLE(truth, response)

measureKendallTau(truth, response)

measureSpearmanRho(truth, response)

measureMMCE(truth, response)

measureACC(truth, response)

measureBER(truth, response)

measureAUNU(probabilities, truth)

measureAUNP(probabilities, truth)

measureAU1U(probabilities, truth)

measureAU1P(probabilities, truth)

measureMulticlassBrier(probabilities, truth)

measureLogloss(probabilities, truth)

measureSSR(probabilities, truth)

measureQSR(probabilities, truth)

measureLSR(probabilities, truth)

measureKAPPA(truth, response)

measureWKAPPA(truth, response)

measureAUC(probabilities, truth, negative, positive)

measureBrier(probabilities, truth, negative, positive)

measureBrierScaled(probabilities, truth, negative, positive)

measureBAC(truth, response)

measureTP(truth, response, positive)

measureTN(truth, response, negative)

measureFP(truth, response, positive)

measureFN(truth, response, negative)

measureTPR(truth, response, positive)

measureTNR(truth, response, negative)

measureFPR(truth, response, negative, positive)

measureFNR(truth, response, negative, positive)

measurePPV(truth, response, positive, probabilities = NULL)

measureNPV(truth, response, negative)

measureFDR(truth, response, positive)

measureMCC(truth, response, negative, positive)

measureF1(truth, response, positive)

measureGMEAN(truth, response, negative, positive)

measureGPR(truth, response, positive)

measureMultilabelHamloss(truth, response)

measureMultilabelSubset01(truth, response)

measureMultilabelF1(truth, response)

measureMultilabelACC(truth, response)

measureMultilabelPPV(truth, response)

measureMultilabelTPR(truth, response)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="measures_+3A_truth">truth</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
Vector of the true class.</p>
</td></tr>
<tr><td><code id="measures_+3A_response">response</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
Vector of the predicted class.</p>
</td></tr>
<tr><td><code id="measures_+3A_probabilities">probabilities</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a> | <a href="base.html#topic+matrix">matrix</a>)<br />
a) For purely binary classification measures: The predicted probabilities for the positive class as a numeric vector.
b) For multiclass classification measures: The predicted probabilities for all classes, always as a numeric matrix, where
columns are named with class labels.</p>
</td></tr>
<tr><td><code id="measures_+3A_negative">negative</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The name of the negative class.</p>
</td></tr>
<tr><td><code id="measures_+3A_positive">positive</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The name of the positive class.</p>
</td></tr>
</table>


<h3>References</h3>

<p>He, H. &amp; Garcia, E. A. (2009)
<em>Learning from Imbalanced Data.</em>
IEEE Transactions on Knowledge and Data Engineering, vol. 21, no. 9. pp. 1263-1284.
</p>
<p>H. Uno et al.
<em>On the C-statistics for Evaluating Overall Adequacy of Risk Prediction Procedures with Censored Survival Data</em>
Statistics in medicine. 2011;30(10):1105-1117. <a href="https://doi.org/10.1002/sim.4154">doi:10.1002/sim.4154</a>.
</p>
<p>H. Uno et al.
<em>Evaluating Prediction Rules for T-Year Survivors with Censored Regression Models</em>
Journal of the American Statistical Association 102, no. 478 (2007): 527-37.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>

<hr>
<h2 id='mergeBenchmarkResults'>Merge different BenchmarkResult objects.</h2><span id='topic+mergeBenchmarkResults'></span>

<h3>Description</h3>

<p>The function automatically combines a list of <a href="#topic+BenchmarkResult">BenchmarkResult</a>
objects into a single <a href="#topic+BenchmarkResult">BenchmarkResult</a> object as long as the full
crossproduct of all task-learner combinations are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergeBenchmarkResults(bmrs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergeBenchmarkResults_+3A_bmrs">bmrs</code></td>
<td>
<p>(list of <a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
<code>BenchmarkResult</code> objects that should be merged.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that if you want to merge several <a href="#topic+BenchmarkResult">BenchmarkResult</a> objects,
you must ensure that all possible learner and task combinations will be
contained in the returned object. Otherwise, the user will be notified
which task-learner combinations are missing or duplicated.
</p>
<p>When merging <a href="#topic+BenchmarkResult">BenchmarkResult</a> objects with different measures, all missing
measures will automatically be recomputed.
</p>


<h3>Value</h3>

<p><a href="#topic+BenchmarkResult">BenchmarkResult</a>
</p>

<hr>
<h2 id='mergeSmallFactorLevels'>Merges small levels of factors into new level.</h2><span id='topic+mergeSmallFactorLevels'></span>

<h3>Description</h3>

<p>Merges factor levels that occur only infrequently into combined levels with a higher frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergeSmallFactorLevels(
  task,
  cols = NULL,
  min.perc = 0.01,
  new.level = ".merged"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergeSmallFactorLevels_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="mergeSmallFactorLevels_+3A_cols">cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)
Which columns to convert.
Default is all factor and character columns.</p>
</td></tr>
<tr><td><code id="mergeSmallFactorLevels_+3A_min.perc">min.perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
The smallest levels of a factor are merged until their combined proportion
w.r.t. the length of the factor exceeds <code>min.perc</code>.
Must be between 0 and 1.
Default is 0.01.</p>
</td></tr>
<tr><td><code id="mergeSmallFactorLevels_+3A_new.level">new.level</code></td>
<td>
<p>(<code>character(1)</code>)<br />
New name of merged level.
Default is &ldquo;.merged&rdquo;</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>Task</code>, where merged levels are combined into a new level of name <code>new.level</code>.
</p>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>

<hr>
<h2 id='mlr-package'>mlr: Machine Learning in R</h2><span id='topic+mlr'></span><span id='topic+mlr-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Interface to a large number of classification and regression techniques, including machine-readable parameter descriptions. There is also an experimental extension for survival analysis, clustering and general, example-specific cost-sensitive learning. Generic resampling, including cross-validation, bootstrapping and subsampling. Hyperparameter tuning with modern optimization techniques, for single- and multi-objective problems. Filter and wrapper methods for feature selection. Extension of basic learners with additional operations common in machine learning, also allowing for easy nested resampling. Most operations can be parallelized.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Patrick Schratz <a href="mailto:patrick.schratz@gmail.com">patrick.schratz@gmail.com</a> (<a href="https://orcid.org/0000-0003-0748-6624">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Bernd Bischl <a href="mailto:bernd_bischl@gmx.net">bernd_bischl@gmx.net</a> (<a href="https://orcid.org/0000-0001-6002-6980">ORCID</a>)
</p>
</li>
<li><p> Michel Lang <a href="mailto:michellang@gmail.com">michellang@gmail.com</a> (<a href="https://orcid.org/0000-0001-9754-0393">ORCID</a>)
</p>
</li>
<li><p> Lars Kotthoff <a href="mailto:larsko@uwyo.edu">larsko@uwyo.edu</a>
</p>
</li>
<li><p> Julia Schiffner <a href="mailto:schiffner@math.uni-duesseldorf.de">schiffner@math.uni-duesseldorf.de</a>
</p>
</li>
<li><p> Jakob Richter <a href="mailto:code@jakob-r.de">code@jakob-r.de</a>
</p>
</li>
<li><p> Zachary Jones <a href="mailto:zmj@zmjones.com">zmj@zmjones.com</a>
</p>
</li>
<li><p> Giuseppe Casalicchio <a href="mailto:giuseppe.casalicchio@stat.uni-muenchen.de">giuseppe.casalicchio@stat.uni-muenchen.de</a> (<a href="https://orcid.org/0000-0001-5324-5966">ORCID</a>)
</p>
</li>
<li><p> Mason Gallo <a href="mailto:masonagallo@gmail.com">masonagallo@gmail.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Jakob Bossek <a href="mailto:jakob.bossek@tu-dortmund.de">jakob.bossek@tu-dortmund.de</a> (<a href="https://orcid.org/0000-0002-4121-4668">ORCID</a>) [contributor]
</p>
</li>
<li><p> Erich Studerus <a href="mailto:erich.studerus@upkbs.ch">erich.studerus@upkbs.ch</a> (<a href="https://orcid.org/0000-0003-4233-0182">ORCID</a>) [contributor]
</p>
</li>
<li><p> Leonard Judt <a href="mailto:leonard.judt@tu-dortmund.de">leonard.judt@tu-dortmund.de</a> [contributor]
</p>
</li>
<li><p> Tobias Kuehn <a href="mailto:tobi.kuehn@gmx.de">tobi.kuehn@gmx.de</a> [contributor]
</p>
</li>
<li><p> Pascal Kerschke <a href="mailto:kerschke@uni-muenster.de">kerschke@uni-muenster.de</a> (<a href="https://orcid.org/0000-0003-2862-1418">ORCID</a>) [contributor]
</p>
</li>
<li><p> Florian Fendt <a href="mailto:flo_fendt@gmx.de">flo_fendt@gmx.de</a> [contributor]
</p>
</li>
<li><p> Philipp Probst <a href="mailto:philipp_probst@gmx.de">philipp_probst@gmx.de</a> (<a href="https://orcid.org/0000-0001-8402-6790">ORCID</a>) [contributor]
</p>
</li>
<li><p> Xudong Sun <a href="mailto:xudong.sun@stat.uni-muenchen.de">xudong.sun@stat.uni-muenchen.de</a> (<a href="https://orcid.org/0000-0003-3269-2307">ORCID</a>) [contributor]
</p>
</li>
<li><p> Janek Thomas <a href="mailto:janek.thomas@stat.uni-muenchen.de">janek.thomas@stat.uni-muenchen.de</a> (<a href="https://orcid.org/0000-0003-4511-6245">ORCID</a>) [contributor]
</p>
</li>
<li><p> Bruno Vieira <a href="mailto:bruno.hebling.vieira@usp.br">bruno.hebling.vieira@usp.br</a> [contributor]
</p>
</li>
<li><p> Laura Beggel <a href="mailto:laura.beggel@web.de">laura.beggel@web.de</a> (<a href="https://orcid.org/0000-0002-8872-8535">ORCID</a>) [contributor]
</p>
</li>
<li><p> Quay Au <a href="mailto:quay.au@stat.uni-muenchen.de">quay.au@stat.uni-muenchen.de</a> (<a href="https://orcid.org/0000-0002-5252-8902">ORCID</a>) [contributor]
</p>
</li>
<li><p> Martin Binder <a href="mailto:ma.binder@campus.lmu.de">ma.binder@campus.lmu.de</a> [contributor]
</p>
</li>
<li><p> Florian Pfisterer <a href="mailto:pfistererf@googlemail.com">pfistererf@googlemail.com</a> [contributor]
</p>
</li>
<li><p> Stefan Coors <a href="mailto:stefan.coors@gmx.net">stefan.coors@gmx.net</a> [contributor]
</p>
</li>
<li><p> Steve Bronder <a href="mailto:sab2287@columbia.edu">sab2287@columbia.edu</a> [contributor]
</p>
</li>
<li><p> Alexander Engelhardt <a href="mailto:alexander.w.engelhardt@gmail.com">alexander.w.engelhardt@gmail.com</a> [contributor]
</p>
</li>
<li><p> Christoph Molnar <a href="mailto:christoph.molnar@stat.uni-muenchen.de">christoph.molnar@stat.uni-muenchen.de</a> [contributor]
</p>
</li>
<li><p> Annette Spooner <a href="mailto:a.spooner@unsw.edu.au">a.spooner@unsw.edu.au</a> [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://mlr.mlr-org.com">https://mlr.mlr-org.com</a>
</p>
</li>
<li> <p><a href="https://github.com/mlr-org/mlr">https://github.com/mlr-org/mlr</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/mlr-org/mlr/issues">https://github.com/mlr-org/mlr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='mlrFamilies'>mlr documentation families</h2><span id='topic+mlrFamilies'></span>

<h3>Description</h3>

<p>List of all mlr documentation families with members.</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlrFamilies_+3A_benchmark">benchmark</code></td>
<td>
<p>batchmark, reduceBatchmarkResults, benchmark, benchmarkParallel, getBMRTaskIds, getBMRLearners, getBMRLearnerIds, getBMRLearnerShortNames, getBMRMeasures, getBMRMeasureIds, getBMRPredictions, getBMRPerformances, getBMRAggrPerformances, getBMRTuneResults, getBMRFeatSelResults, getBMRFilteredFeatures, getBMRModels, getBMRTaskDescs, convertBMRToRankMatrix, friedmanPostHocTestBMR, friedmanTestBMR, plotBMRBoxplots, plotBMRRanksAsBarChart, generateCritDifferencesData, plotCritDifferences</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_calibration">calibration</code></td>
<td>
<p>generateCalibrationData, plotCalibration</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_configure">configure</code></td>
<td>
<p>configureMlr, getMlrOptions</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_costsens">costsens</code></td>
<td>
<p>makeCostSensTask, makeCostSensWeightedPairsWrapper</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_debug">debug</code></td>
<td>
<p>predictFailureModel, getPredictionDump, getRRDump, print.ResampleResult</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_downsample">downsample</code></td>
<td>
<p>downsample</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_eda_and_preprocess">eda_and_preprocess</code></td>
<td>
<p>capLargeValues, createDummyFeatures, dropFeatures, mergeSmallFactorLevels, normalizeFeatures, removeConstantFeatures, summarizeColumns, summarizeLevels</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_extractfdafeatures">extractFDAFeatures</code></td>
<td>
<p>reextractFDAFeatures</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_fda_featextractor">fda_featextractor</code></td>
<td>
<p>extractFDAFourier, extractFDAWavelets, extractFDAFPCA, extractFDAMultiResFeatures</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_fda">fda</code></td>
<td>
<p>makeExtractFDAFeatMethod, extractFDAFeatures</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_featsel">featsel</code></td>
<td>
<p>analyzeFeatSelResult, makeFeatSelControl, getFeatSelResult, selectFeatures</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_filter">filter</code></td>
<td>
<p>filterFeatures, makeFilter, listFilterMethods, getFilteredFeatures, generateFilterValuesData, getFilterValues</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_generate_plot_data">generate_plot_data</code></td>
<td>
<p>generateFeatureImportanceData, plotFilterValues, generatePartialDependenceData</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_help">help</code></td>
<td>
<p>helpLearner, helpLearnerParam</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_imbalancy">imbalancy</code></td>
<td>
<p>oversample, smote</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_impute">impute</code></td>
<td>
<p>makeImputeMethod, imputeConstant, impute, reimpute</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_learner">learner</code></td>
<td>
<p>getClassWeightParam, getHyperPars, getParamSet.Learner, getLearnerType, getLearnerId, getLearnerPredictType, getLearnerPackages, getLearnerParamSet, getLearnerParVals, setLearnerId, getLearnerShortName, getLearnerProperties, makeLearner, makeLearners, removeHyperPars, setHyperPars, setId, setPredictThreshold, setPredictType</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_learning_curve">learning_curve</code></td>
<td>
<p>generateLearningCurveData</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_multilabel">multilabel</code></td>
<td>
<p>getMultilabelBinaryPerformances, makeMultilabelBinaryRelevanceWrapper, makeMultilabelClassifierChainsWrapper, makeMultilabelDBRWrapper, makeMultilabelNestedStackingWrapper, makeMultilabelStackingWrapper</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_performance">performance</code></td>
<td>
<p>calculateConfusionMatrix, calculateROCMeasures, makeCustomResampledMeasure, makeCostMeasure, setMeasurePars, setAggregation, makeMeasure, featperc, performance, estimateRelativeOverfitting</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_plot">plot</code></td>
<td>
<p>createSpatialResamplingPlots, plotLearningCurve, plotPartialDependence, plotBMRSummary, plotResiduals</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_predict">predict</code></td>
<td>
<p>asROCRPrediction, getPredictionProbabilities, getPredictionTaskDesc, getPredictionResponse, predict.WrappedModel</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_resample">resample</code></td>
<td>
<p>makeResampleDesc, makeResampleInstance, makeResamplePrediction, resample, getRRPredictions, getRRTaskDescription, getRRTaskDesc, getRRPredictionList, addRRMeasure</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_task">task</code></td>
<td>
<p>getTaskDesc, getTaskType, getTaskId, getTaskTargetNames, getTaskClassLevels, getTaskFeatureNames, getTaskNFeats, getTaskSize, getTaskFormula, getTaskTargets, getTaskData, getTaskCosts, subsetTask</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_thresh_vs_perf">thresh_vs_perf</code></td>
<td>
<p>generateThreshVsPerfData, plotThreshVsPerf, plotROCCurves</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_tune">tune</code></td>
<td>
<p>getNestedTuneResultsX, getNestedTuneResultsOptPathDf, getResamplingIndices, getTuneResult, makeModelMultiplexerParamSet, makeModelMultiplexer, makeTuneControlCMAES, makeTuneControlDesign, makeTuneControlGenSA, makeTuneControlGrid, makeTuneControlIrace, makeTuneControlMBO, makeTuneControl, makeTuneControlRandom, tuneParams, tuneThreshold</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_tune_multicrit">tune_multicrit</code></td>
<td>
<p>plotTuneMultiCritResult, makeTuneMultiCritControl, tuneParamsMultiCrit</p>
</td></tr>
<tr><td><code id="mlrFamilies_+3A_wrapper">wrapper</code></td>
<td>
<p>makeBaggingWrapper, makeClassificationViaRegressionWrapper, makeConstantClassWrapper, makeCostSensClassifWrapper, makeCostSensRegrWrapper, makeDownsampleWrapper, makeDummyFeaturesWrapper, makeExtractFDAFeatsWrapper, makeFeatSelWrapper, makeFilterWrapper, makeImputeWrapper, makeMulticlassWrapper, makeOverBaggingWrapper, makeUndersampleWrapper, makePreprocWrapperCaret, makePreprocWrapper, makeRemoveConstantFeaturesWrapper, makeSMOTEWrapper, makeTuneWrapper, makeWeightedClassesWrapper</p>
</td></tr>
</table>

<hr>
<h2 id='mtcars.task'>Motor Trend Car Road Tests clustering task.</h2><span id='topic+mtcars.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>mtcars.task</code>).
</p>


<h3>References</h3>

<p>See <a href="datasets.html#topic+mtcars">datasets::mtcars</a>.
</p>

<hr>
<h2 id='normalizeFeatures'>Normalize features.</h2><span id='topic+normalizeFeatures'></span>

<h3>Description</h3>

<p>Normalize features by different methods.
Internally <a href="BBmisc.html#topic+normalize">BBmisc::normalize</a> is used for every feature column.
Non numerical features will be left untouched and passed to the result.
For constant features most methods fail, special behaviour for this case is implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalizeFeatures(
  obj,
  target = character(0L),
  method = "standardize",
  cols = NULL,
  range = c(0, 1),
  on.constant = "quiet"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalizeFeatures_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="normalizeFeatures_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
Only used when <code>obj</code> is a data.frame, otherwise ignored.
If survival analysis is applicable, these are the names of the survival time and event columns,
so it has length 2.
For multilabel classification these are the names of logical columns that indicate whether
a class label is present and the number of target variables corresponds to the number of
classes.</p>
</td></tr>
<tr><td><code id="normalizeFeatures_+3A_method">method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Normalizing method. Available are:<br />
&ldquo;center&rdquo;: Subtract mean.<br />
&ldquo;scale&rdquo;: Divide by standard deviation.<br />
&ldquo;standardize&rdquo;: Center and scale.<br />
&ldquo;range&rdquo;: Scale to a given range.<br /></p>
</td></tr>
<tr><td><code id="normalizeFeatures_+3A_cols">cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Columns to normalize. Default is to use all numeric columns.</p>
</td></tr>
<tr><td><code id="normalizeFeatures_+3A_range">range</code></td>
<td>
<p>(<code>numeric(2)</code>)<br />
Range for method &ldquo;range&rdquo;.
Default is <code>c(0,1)</code>.</p>
</td></tr>
<tr><td><code id="normalizeFeatures_+3A_on.constant">on.constant</code></td>
<td>
<p>(<code>character(1)</code>)<br />
How should constant vectors be treated? Only used, of &ldquo;method != center&rdquo;,
since this methods does not fail for constant vectors. Possible actions are:<br />
&ldquo;quiet&rdquo;: Depending on the method, treat them quietly:<br />
&ldquo;scale&rdquo;: No division by standard deviation is done, input values.
will be returned untouched.<br />
&ldquo;standardize&rdquo;: Only the mean is subtracted, no division is done.<br />
&ldquo;range&rdquo;: All values are mapped to the mean of the given range.<br />
&ldquo;warn&rdquo;: Same behaviour as &ldquo;quiet&rdquo;, but print a warning message.<br />
&ldquo;stop&rdquo;: Stop with an error.<br /></p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>. Same type as <code>obj</code>.
</p>


<h3>See Also</h3>

<p><a href="BBmisc.html#topic+normalize">BBmisc::normalize</a>
</p>
<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>

<hr>
<h2 id='oversample'>Over- or undersample binary classification task to handle class imbalancy.</h2><span id='topic+oversample'></span><span id='topic+undersample'></span>

<h3>Description</h3>

<p>Oversampling: For a given class (usually the smaller one) all existing observations are
taken and copied and extra observations are added by randomly sampling with replacement from this class.
</p>
<p>Undersampling: For a given class (usually the larger one) the number of observations is
reduced (downsampled) by randomly sampling without replacement from this class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>oversample(task, rate, cl = NULL)

undersample(task, rate, cl = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oversample_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="oversample_+3A_rate">rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Factor to upsample or downsample a class.
For undersampling: Must be between 0 and 1,
where 1 means no downsampling, 0.5 implies reduction to 50 percent
and 0 would imply reduction to 0 observations.
For oversampling: Must be between 1 and <code>Inf</code>,
where 1 means no oversampling and 2 would mean doubling the class size.</p>
</td></tr>
<tr><td><code id="oversample_+3A_cl">cl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Which class should be over- or undersampled. If <code>NULL</code>, <code>oversample</code>
will select the smaller and <code>undersample</code> the larger class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Task">Task</a>.
</p>


<h3>See Also</h3>

<p>Other imbalancy: 
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+smote">smote</a>()</code>
</p>

<hr>
<h2 id='parallelization'>Supported parallelization methods</h2><span id='topic+parallelization'></span>

<h3>Description</h3>

<p>mlr supports different methods to activate parallel computing capabilities through the integration of the <a href="parallelMap.html#topic+parallelMap">parallelMap::parallelMap</a> package, which supports all major parallelization backends for R.
You can start parallelization with <code><a href="parallelMap.html#topic+parallelStart">parallelStart</a>*</code>, where <code>*</code> should be replaced with the chosen backend.
<a href="parallelMap.html#topic+parallelStop">parallelMap::parallelStop</a> is used to stop all parallelization backends.
</p>
<p>Parallelization is divided into different levels and will automatically be carried out for the first level that occurs, e.g. if you call <code>resample()</code> after <a href="parallelMap.html#topic+parallelStart">parallelMap::parallelStart</a>, each resampling iteration is a parallel job and possible underlying calls like parameter tuning won't be parallelized further.
</p>
<p>The supported levels of parallelization are:
</p>

<dl>
<dt><code>"mlr.resample"</code></dt><dd><p>Each resampling iteration (a train/test step) is a parallel job.</p>
</dd>
<dt><code>"mlr.benchmark"</code></dt><dd><p>Each experiment &quot;run this learner on this data set&quot; is a parallel job.</p>
</dd>
<dt><code>"mlr.tuneParams"</code></dt><dd><p>Each evaluation in hyperparameter space &quot;resample with these parameter settings&quot; is a parallel job.
How many of these can be run independently in parallel depends on the tuning algorithm.
For grid search or random search there is no limit, but for other tuners it depends on how many points to evaluate are produced in each iteration of the optimization.
If a tuner works in a purely sequential fashion, we cannot work magic and the hyperparameter evaluation will also run sequentially. But note that you can still parallelize the underlying resampling.</p>
</dd>
<dt><code>"mlr.selectFeatures"</code></dt><dd><p>Each evaluation in feature space &quot;resample with this feature subset&quot; is a parallel job. The same comments as for <code>"mlr.tuneParams"</code> apply here.</p>
</dd>
<dt><code>"mlr.ensemble"</code></dt><dd><p>For all ensemble methods, the training and prediction of each individual learner is a parallel job.
Supported ensemble methods are the <a href="#topic+makeBaggingWrapper">makeBaggingWrapper</a>, <a href="#topic+makeCostSensRegrWrapper">makeCostSensRegrWrapper</a>, <a href="#topic+makeMulticlassWrapper">makeMulticlassWrapper</a>, <a href="#topic+makeMultilabelBinaryRelevanceWrapper">makeMultilabelBinaryRelevanceWrapper</a> and the <a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>.</p>
</dd>
</dl>


<hr>
<h2 id='performance'>Measure performance of prediction.</h2><span id='topic+performance'></span>

<h3>Description</h3>

<p>Measures the quality of a prediction w.r.t. some performance measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance(
  pred,
  measures,
  task = NULL,
  model = NULL,
  feats = NULL,
  simpleaggr = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performance_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="performance_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="performance_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
Learning task, might be requested by performance measure, usually not needed except for clustering or survival.</p>
</td></tr>
<tr><td><code id="performance_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Model built on training data, might be requested by performance measure, usually not needed except for survival.</p>
</td></tr>
<tr><td><code id="performance_+3A_feats">feats</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Features of predicted data, usually not needed except for clustering.
If the prediction was generated from a <code>task</code>, you can also pass this instead and the features
are extracted from it.</p>
</td></tr>
<tr><td><code id="performance_+3A_simpleaggr">simpleaggr</code></td>
<td>
<p>(<a href="base.html#topic+logical">logical</a>)<br />
If TRUE, aggregation of <code>ResamplePrediction</code> objects is skipped. This is used internally for threshold tuning. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(named <a href="base.html#topic+numeric">numeric</a>). Performance value(s), named by measure(s).
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>training.set = seq(1, nrow(iris), by = 2)
test.set = seq(2, nrow(iris), by = 2)

task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.lda")
mod = train(lrn, task, subset = training.set)
pred = predict(mod, newdata = iris[test.set, ])
performance(pred, measures = mmce)

# Compute multiple performance measures at once
ms = list("mmce" = mmce, "acc" = acc, "timetrain" = timetrain)
performance(pred, measures = ms, task, mod)
</code></pre>

<hr>
<h2 id='phoneme.task'>Phoneme functional data multilabel classification task.</h2><span id='topic+phoneme.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>phoneme.task</code>).
The task contains a single functional covariate and 5 equally big classes (aa, ao, dcl, iy, sh).
The aim is to predict the class of the phoneme in the functional.
The dataset is contained in the package fda.usc.
</p>


<h3>References</h3>

<p>F. Ferraty and P. Vieu (2003) &quot;Curve discrimination: a nonparametric functional approach&quot;, Computational Statistics and Data Analysis, 44(1-2), 161-173.
F. Ferraty and P. Vieu (2006) Nonparametric functional data analysis, New York: Springer.
T. Hastie and R. Tibshirani and J. Friedman (2009) The elements of statistical learning: Data mining, inference and prediction, 2nd edn, New York: Springer.
</p>

<hr>
<h2 id='pid.task'>PimaIndiansDiabetes classification task.</h2><span id='topic+pid.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>pid.task</code>).
</p>


<h3>References</h3>

<p>See <a href="mlbench.html#topic+PimaIndiansDiabetes">mlbench::PimaIndiansDiabetes</a>.
Note that this is the uncorrected version from mlbench.
</p>

<hr>
<h2 id='plotBMRBoxplots'>Create box or violin plots for a BenchmarkResult.</h2><span id='topic+plotBMRBoxplots'></span>

<h3>Description</h3>

<p>Plots box or violin plots for a selected <code>measure</code> across all iterations
of the resampling strategy, faceted by the <code>task.id</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBMRBoxplots(
  bmr,
  measure = NULL,
  style = "box",
  order.lrns = NULL,
  order.tsks = NULL,
  pretty.names = TRUE,
  facet.wrap.nrow = NULL,
  facet.wrap.ncol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBMRBoxplots_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="plotBMRBoxplots_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="plotBMRBoxplots_+3A_style">style</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Type of plot, can be &ldquo;box&rdquo; for a boxplot or &ldquo;violin&rdquo; for a violin plot.
Default is &ldquo;box&rdquo;.</p>
</td></tr>
<tr><td><code id="plotBMRBoxplots_+3A_order.lrns">order.lrns</code></td>
<td>
<p>(<code>character(n.learners)</code>)<br />
Character vector with <code>learner.ids</code> in new order.</p>
</td></tr>
<tr><td><code id="plotBMRBoxplots_+3A_order.tsks">order.tsks</code></td>
<td>
<p>(<code>character(n.tasks)</code>)<br />
Character vector with <code>task.ids</code> in new order.</p>
</td></tr>
<tr><td><code id="plotBMRBoxplots_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the <a href="#topic+Measure">Measure</a> name and the <a href="#topic+Learner">Learner</a>
short name instead of the id. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotBMRBoxplots_+3A_facet.wrap.nrow">facet.wrap.nrow</code>, <code id="plotBMRBoxplots_+3A_facet.wrap.ncol">facet.wrap.ncol</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Number of rows and columns for facetting. Default for both is <code>NULL</code>.
In this case ggplot's <code>facet_wrap</code> will choose the layout itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>
<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='plotBMRRanksAsBarChart'>Create a bar chart for ranks in a BenchmarkResult.</h2><span id='topic+plotBMRRanksAsBarChart'></span>

<h3>Description</h3>

<p>Plots a bar chart from the ranks of algorithms. Alternatively,
tiles can be plotted for every rank-task combination, see <code>pos</code>
for details. In all plot variants the ranks of the learning algorithms are displayed on
the x-axis. Areas are always colored according to the <code>learner.id</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBMRRanksAsBarChart(
  bmr,
  measure = NULL,
  ties.method = "average",
  aggregation = "default",
  pos = "stack",
  order.lrns = NULL,
  order.tsks = NULL,
  pretty.names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_ties.method">ties.method</code></td>
<td>
<p>(<code>character(1)</code>)<br />
See <a href="base.html#topic+rank">rank</a> for details.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_aggregation">aggregation</code></td>
<td>
<p>(<code>character(1)</code>) <br />
&ldquo;mean&rdquo; or &ldquo;default&rdquo;. See <a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>
for details on &ldquo;default&rdquo;.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_pos">pos</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Optionally set how the bars are positioned in ggplot2.
Ranks are plotted on the x-axis.
&ldquo;tile&rdquo; plots a heat map with <code>task</code> as the y-axis.
Allows identification of the performance in a special task.
&ldquo;stack&rdquo; plots a stacked bar plot.
Allows for comparison of learners within and and across ranks.
&ldquo;dodge&rdquo; plots a bar plot with bars next to each other instead
of stacked bars.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_order.lrns">order.lrns</code></td>
<td>
<p>(<code>character(n.learners)</code>)<br />
Character vector with <code>learner.ids</code> in new order.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_order.tsks">order.tsks</code></td>
<td>
<p>(<code>character(n.tasks)</code>)<br />
Character vector with <code>task.ids</code> in new order.</p>
</td></tr>
<tr><td><code id="plotBMRRanksAsBarChart_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the short name of the learner instead of its ID in labels. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>
<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='plotBMRSummary'>Plot a benchmark summary.</h2><span id='topic+plotBMRSummary'></span>

<h3>Description</h3>

<p>Creates a scatter plot, where each line refers to a task.
On that line the aggregated scores for all learners are plotted, for that task.
Optionally, you can apply a rank transformation or just use one of ggplot2's transformations
like <a href="ggplot2.html#topic+scale_continuous">ggplot2::scale_x_log10</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotBMRSummary(
  bmr,
  measure = NULL,
  trafo = "none",
  order.tsks = NULL,
  pointsize = 4L,
  jitter = 0.05,
  pretty.names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotBMRSummary_+3A_bmr">bmr</code></td>
<td>
<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Benchmark result.</p>
</td></tr>
<tr><td><code id="plotBMRSummary_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.
Default is the first measure used in the benchmark experiment.</p>
</td></tr>
<tr><td><code id="plotBMRSummary_+3A_trafo">trafo</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Currently either &ldquo;none&rdquo; or &ldquo;rank&rdquo;, the latter performing a rank transformation
(with average handling of ties) of the scores per task.
NB: You can add always add <a href="ggplot2.html#topic+scale_continuous">ggplot2::scale_x_log10</a> to the result to put scores on a log scale.
Default is &ldquo;none&rdquo;.</p>
</td></tr>
<tr><td><code id="plotBMRSummary_+3A_order.tsks">order.tsks</code></td>
<td>
<p>(<code>character(n.tasks)</code>)<br />
Character vector with <code>task.ids</code> in new order.</p>
</td></tr>
<tr><td><code id="plotBMRSummary_+3A_pointsize">pointsize</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Point size for ggplot2 <a href="ggplot2.html#topic+geom_point">ggplot2::geom_point</a> for data points.
Default is 4.</p>
</td></tr>
<tr><td><code id="plotBMRSummary_+3A_jitter">jitter</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Small vertical jitter to deal with overplotting in case of equal scores.
Default is 0.05.</p>
</td></tr>
<tr><td><code id="plotBMRSummary_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the short name of the learner instead of its ID in labels. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>
<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='plotCalibration'>Plot calibration data using ggplot2.</h2><span id='topic+plotCalibration'></span>

<h3>Description</h3>

<p>Plots calibration data from <a href="#topic+generateCalibrationData">generateCalibrationData</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCalibration(
  obj,
  smooth = FALSE,
  reference = TRUE,
  rag = TRUE,
  facet.wrap.nrow = NULL,
  facet.wrap.ncol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotCalibration_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+CalibrationData">CalibrationData</a>)<br />
Result of <a href="#topic+generateCalibrationData">generateCalibrationData</a>.</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_smooth">smooth</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use a loess smoother.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_reference">reference</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to plot a reference line showing perfect calibration.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_rag">rag</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to include a rag plot which shows a rug plot on the top which pertains to
positive cases and on the bottom which pertains to negative cases.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotCalibration_+3A_facet.wrap.nrow">facet.wrap.nrow</code>, <code id="plotCalibration_+3A_facet.wrap.ncol">facet.wrap.ncol</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Number of rows and columns for facetting. Default for both is <code>NULL</code>.
In this case ggplot's <code>facet_wrap</code> will choose the layout itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>
<p>Other calibration: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lrns = list(makeLearner("classif.rpart", predict.type = "prob"),
  makeLearner("classif.nnet", predict.type = "prob"))
fit = lapply(lrns, train, task = iris.task)
pred = lapply(fit, predict, task = iris.task)
names(pred) = c("rpart", "nnet")
out = generateCalibrationData(pred, groups = 3)
plotCalibration(out)

fit = lapply(lrns, train, task = sonar.task)
pred = lapply(fit, predict, task = sonar.task)
names(pred) = c("rpart", "lda")
out = generateCalibrationData(pred)
plotCalibration(out)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotCritDifferences'>Plot critical differences for a selected measure.</h2><span id='topic+plotCritDifferences'></span>

<h3>Description</h3>

<p>Plots a critical-differences diagram for all classifiers and a
selected measure. If a baseline is selected for the Bonferroni-Dunn test,
the critical difference interval will be positioned around the baseline. If
not, the best performing algorithm will be chosen as baseline.
</p>
<p>The positioning of some descriptive elements can be moved by modifying the
generated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCritDifferences(obj, baseline = NULL, pretty.names = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotCritDifferences_+3A_obj">obj</code></td>
<td>
<p>(<code>critDifferencesData</code>)
Result of <code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData()</a></code>.</p>
</td></tr>
<tr><td><code id="plotCritDifferences_+3A_baseline">baseline</code></td>
<td>
<p>(<code>character(1)</code>): (<code>learner.id</code>)<br />
Overwrites baseline from <code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData()</a></code>!<br />
Select a <code>learner.id</code> as baseline for the critical difference
diagram, the critical difference will be positioned around this learner.
Defaults to best performing algorithm.</p>
</td></tr>
<tr><td><code id="plotCritDifferences_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the short name of the learner instead of its ID in labels. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>References</h3>

<p>Janez Demsar, Statistical Comparisons of Classifiers over
Multiple Data Sets, JMLR, 2006
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>
<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+reduceBatchmarkResults">reduceBatchmarkResults</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see benchmark
</code></pre>

<hr>
<h2 id='plotFilterValues'>Plot filter values using ggplot2.</h2><span id='topic+plotFilterValues'></span>

<h3>Description</h3>

<p>Plot filter values using ggplot2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotFilterValues(
  fvalues,
  sort = "dec",
  n.show = nrow(fvalues$data),
  filter = NULL,
  feat.type.cols = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotFilterValues_+3A_fvalues">fvalues</code></td>
<td>
<p>(<a href="#topic+FilterValues">FilterValues</a>)<br />
Filter values.</p>
</td></tr>
<tr><td><code id="plotFilterValues_+3A_sort">sort</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Available options are:
</p>

<ul>
<li> <p><code>"dec"</code>-&gt; descending
</p>
</li>
<li> <p><code>"inc"</code> -&gt; increasing
</p>
</li>
<li> <p><code>"none"</code> -&gt; no sorting
</p>
</li></ul>

<p>Default is decreasing.</p>
</td></tr>
<tr><td><code id="plotFilterValues_+3A_n.show">n.show</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of features (maximal) to show.
Default is to plot all features.</p>
</td></tr>
<tr><td><code id="plotFilterValues_+3A_filter">filter</code></td>
<td>
<p>(<code>character(1)</code>)
In case <code>fvalues</code> contains multiple filter methods, which method should be
plotted?</p>
</td></tr>
<tr><td><code id="plotFilterValues_+3A_feat.type.cols">feat.type.cols</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to color different feature types (e.g. numeric | factor).
Default is to use no colors (<code>feat.type.cols = FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other filter: 
<code><a href="#topic+filterFeatures">filterFeatures</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+getFilteredFeatures">getFilteredFeatures</a>()</code>,
<code><a href="#topic+listFilterEnsembleMethods">listFilterEnsembleMethods</a>()</code>,
<code><a href="#topic+listFilterMethods">listFilterMethods</a>()</code>,
<code><a href="#topic+makeFilterEnsemble">makeFilterEnsemble</a>()</code>,
<code><a href="#topic+makeFilterWrapper">makeFilterWrapper</a>()</code>,
<code><a href="#topic+makeFilter">makeFilter</a>()</code>
</p>
<p>Other generate_plot_data: 
<code><a href="#topic+generateCalibrationData">generateCalibrationData</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+generateFeatureImportanceData">generateFeatureImportanceData</a>()</code>,
<code><a href="#topic+generateFilterValuesData">generateFilterValuesData</a>()</code>,
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>,
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>,
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fv = generateFilterValuesData(iris.task, method = "variance")
plotFilterValues(fv)
</code></pre>

<hr>
<h2 id='plotHyperParsEffect'>Plot the hyperparameter effects data</h2><span id='topic+plotHyperParsEffect'></span>

<h3>Description</h3>

<p>Plot hyperparameter validation path. Automated plotting method for
<code>HyperParsEffectData</code> object. Useful for determining the importance
or effect of a particular hyperparameter on some performance measure and/or
optimizer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotHyperParsEffect(
  hyperpars.effect.data,
  x = NULL,
  y = NULL,
  z = NULL,
  plot.type = "scatter",
  loess.smooth = FALSE,
  facet = NULL,
  global.only = TRUE,
  interpolate = NULL,
  show.experiments = FALSE,
  show.interpolated = FALSE,
  nested.agg = mean,
  partial.dep.learn = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotHyperParsEffect_+3A_hyperpars.effect.data">hyperpars.effect.data</code></td>
<td>
<p>(<code>HyperParsEffectData</code>)<br />
Result of <a href="#topic+generateHyperParsEffectData">generateHyperParsEffectData</a></p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_x">x</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specify what should be plotted on the x axis. Must be a column from
<code>HyperParsEffectData$data</code>. For partial dependence, this is assumed to
be a hyperparameter.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_y">y</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specify what should be plotted on the y axis. Must be a column from
<code>HyperParsEffectData$data</code></p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_z">z</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specify what should be used as the extra axis for a particular geom. This
could be for the fill on a heatmap or color aesthetic for a line. Must be a
column from <code>HyperParsEffectData$data</code>. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_plot.type">plot.type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specify the type of plot: &ldquo;scatter&rdquo; for a scatterplot, &ldquo;heatmap&rdquo; for a
heatmap, &ldquo;line&rdquo; for a scatterplot with a connecting line, or &ldquo;contour&rdquo; for a
contour plot layered ontop of a heatmap.
Default is &ldquo;scatter&rdquo;.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_loess.smooth">loess.smooth</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code>, will add loess smoothing line to plots where possible. Note that
this is probably only useful when <code>plot.type</code> is set to either
&ldquo;scatter&rdquo; or &ldquo;line&rdquo;. Must be a column from
<code>HyperParsEffectData$data</code>. Not used with partial dependence.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_facet">facet</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Specify what should be used as the facet axis for a particular geom. When
using nested cross validation, set this to &ldquo;nested_cv_run&rdquo; to obtain a facet
for each outer loop. Must be a column from <code>HyperParsEffectData$data</code>.
Please note that facetting is not supported with partial dependence plots!
Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_global.only">global.only</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code>, will only plot the current global optima when setting
x = &quot;iteration&quot; and y as a performance measure from
<code>HyperParsEffectData$measures</code>. Set this to FALSE to always plot the
performance of every iteration, even if it is not an improvement. Not used
with partial dependence.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_interpolate">interpolate</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
If not <code>NULL</code>, will interpolate non-complete grids in order to visualize a more
complete path. Only meaningful when attempting to plot a heatmap or contour.
This will fill in &ldquo;empty&rdquo; cells in the heatmap or contour plot. Note that
cases of irregular hyperparameter paths, you will most likely need to use
this to have a meaningful visualization. Accepts either a regression <a href="#topic+Learner">Learner</a>
object or the learner as a string for interpolation. This cannot be used with partial
dependence.
Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_show.experiments">show.experiments</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code>, will overlay the plot with points indicating where an experiment
ran. This is only useful when creating a heatmap or contour plot with
interpolation so that you can see which points were actually on the
original path. Note: if any learner crashes occurred within the path, this
will become <code>TRUE</code>. Not used with partial dependence.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_show.interpolated">show.interpolated</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
If <code>TRUE</code>, will overlay the plot with points indicating where interpolation
ran. This is only useful when creating a heatmap or contour plot with
interpolation so that you can see which points were interpolated. Not used
with partial dependence.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_nested.agg">nested.agg</code></td>
<td>
<p>(<code>function</code>)<br />
The function used to aggregate nested cross validation runs when plotting 2
hyperparameters. This is also used for nested aggregation in partial
dependence.
Default is <code>mean</code>.</p>
</td></tr>
<tr><td><code id="plotHyperParsEffect_+3A_partial.dep.learn">partial.dep.learn</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The regression learner used to learn partial dependence. Must be specified if
&ldquo;partial.dep&rdquo; is set to <code>TRUE</code> in
<a href="#topic+generateHyperParsEffectData">generateHyperParsEffectData</a>. Accepts either a <a href="#topic+Learner">Learner</a>
object or the learner as a string for learning partial dependence.
Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>Note</h3>

<p>Any NAs incurred from learning algorithm crashes will be indicated in
the plot (except in the case of partial dependence) and the NA values will be
replaced with the column min/max depending on the optimal values for the
respective measure. Execution time will be replaced with the max.
Interpolation by its nature will result in predicted values for the
performance measure. Use interpolation with caution. If &ldquo;partial.dep&rdquo;
is set to <code>TRUE</code> in <a href="#topic+generateHyperParsEffectData">generateHyperParsEffectData</a>, only
partial dependence will be plotted.
</p>
<p>Since a ggplot2 plot object is returned, the user can change the axis labels
and other aspects of the plot using the appropriate ggplot2 syntax.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see generateHyperParsEffectData
</code></pre>

<hr>
<h2 id='plotLearnerPrediction'>Visualizes a learning algorithm on a 1D or 2D data set.</h2><span id='topic+plotLearnerPrediction'></span>

<h3>Description</h3>

<p>Trains the model for 1 or 2 selected features, then displays it via <a href="ggplot2.html#topic+ggplot">ggplot2::ggplot</a>.
Good for teaching or exploring models.
</p>
<p>For classification and clustering, only 2D plots are supported. The data points, the classification and
potentially through color alpha blending the posterior probabilities are shown.
</p>
<p>For regression, 1D and 2D plots are supported. 1D shows the data, the estimated mean and potentially
the estimated standard error. 2D does not show estimated standard error,
but only the estimated mean via background color.
</p>
<p>The plot title displays the model id, its parameters, the training performance
and the cross-validation performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotLearnerPrediction(
  learner,
  task,
  features = NULL,
  measures,
  cv = 10L,
  ...,
  gridsize,
  pointsize = 2,
  prob.alpha = TRUE,
  se.band = TRUE,
  err.mark = "train",
  bg.cols = c("darkblue", "green", "darkred"),
  err.col = "white",
  err.size = pointsize,
  greyscale = FALSE,
  pretty.names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotLearnerPrediction_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Selected features for model.
By default the first 2 features are used.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_cv">cv</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Do cross-validation and display in plot title?
Number of folds. 0 means no CV.
Default is 10.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_...">...</code></td>
<td>
<p>(any)<br />
Parameters for <code>learner</code>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_gridsize">gridsize</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Grid resolution per axis for background predictions.
Default is 500 for 1D and 100 for 2D.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_pointsize">pointsize</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Pointsize for ggplot2 <a href="ggplot2.html#topic+geom_point">ggplot2::geom_point</a> for data points.
Default is 2.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_prob.alpha">prob.alpha</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
For classification: Set alpha value of background to probability for
predicted class? Allows visualization of &ldquo;confidence&rdquo; for prediction.
If not, only a constant color is displayed in the background for the predicted label.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_se.band">se.band</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
For regression in 1D: Show band for standard error estimation?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_err.mark">err.mark</code></td>
<td>
<p>(<code>character(1)</code>):
For classification: Either mark error of the model on the training data (&ldquo;train&rdquo;) or
during cross-validation (&ldquo;cv&rdquo;) or not at all with &ldquo;none&rdquo;.
Default is &ldquo;train&rdquo;.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_bg.cols">bg.cols</code></td>
<td>
<p>(<code>character(3)</code>)<br />
Background colors for classification and regression.
Sorted from low, medium to high.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_err.col">err.col</code></td>
<td>
<p>(<code>character(1)</code>)<br />
For classification: Color of misclassified data points.
Default is &ldquo;white&rdquo;</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_err.size">err.size</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
For classification: Size of misclassified data points.
Default is <code>pointsize</code>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_greyscale">greyscale</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the plot be greyscale completely?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotLearnerPrediction_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the short name of the learner instead of its ID in labels. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The ggplot2 object.
</p>

<hr>
<h2 id='plotLearningCurve'>Plot learning curve data using ggplot2.</h2><span id='topic+plotLearningCurve'></span>

<h3>Description</h3>

<p>Visualizes data size (percentage used for model) vs. performance measure(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotLearningCurve(
  obj,
  facet = "measure",
  pretty.names = TRUE,
  facet.wrap.nrow = NULL,
  facet.wrap.ncol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotLearningCurve_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+LearningCurveData">LearningCurveData</a>)<br />
Result of <a href="#topic+generateLearningCurveData">generateLearningCurveData</a>, with class <code>LearningCurveData</code>.</p>
</td></tr>
<tr><td><code id="plotLearningCurve_+3A_facet">facet</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Selects &ldquo;measure&rdquo; or &ldquo;learner&rdquo; to be the facetting variable.
The variable mapped to <code>facet</code> must have more than one unique value, otherwise it will
be ignored. The variable not chosen is mapped to color if it has more than one unique value.
The default is &ldquo;measure&rdquo;.</p>
</td></tr>
<tr><td><code id="plotLearningCurve_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the <a href="#topic+Measure">Measure</a> name instead of the id in the plot.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotLearningCurve_+3A_facet.wrap.nrow">facet.wrap.nrow</code>, <code id="plotLearningCurve_+3A_facet.wrap.ncol">facet.wrap.ncol</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Number of rows and columns for facetting. Default for both is <code>NULL</code>.
In this case ggplot's <code>facet_wrap</code> will choose the layout itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other learning_curve: 
<code><a href="#topic+generateLearningCurveData">generateLearningCurveData</a>()</code>
</p>
<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>

<hr>
<h2 id='plotPartialDependence'>Plot a partial dependence with ggplot2.</h2><span id='topic+plotPartialDependence'></span>

<h3>Description</h3>

<p>Plot a partial dependence from <a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a> using ggplot2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPartialDependence(
  obj,
  geom = "line",
  facet = NULL,
  facet.wrap.nrow = NULL,
  facet.wrap.ncol = NULL,
  p = 1,
  data = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotPartialDependence_+3A_obj">obj</code></td>
<td>
<p><a href="#topic+PartialDependenceData">PartialDependenceData</a><br />
Generated by <a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>.</p>
</td></tr>
<tr><td><code id="plotPartialDependence_+3A_geom">geom</code></td>
<td>
<p>(<code>charater(1)</code>)<br />
The type of geom to use to display the data. Can be &ldquo;line&rdquo; or &ldquo;tile&rdquo;.
For tiling at least two features must be used with <code>interaction = TRUE</code> in the call to
<a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>. This may be used in conjuction with the
<code>facet</code> argument if three features are specified in the call to
<a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>.
Default is &ldquo;line&rdquo;.</p>
</td></tr>
<tr><td><code id="plotPartialDependence_+3A_facet">facet</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The name of a feature to be used for facetting.
This feature must have been an element of the <code>features</code> argument to
<a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a> and is only applicable when said argument had length
greater than 1.
The feature must be a factor or an integer.
If <a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a> is called with the <code>interaction</code> argument <code>FALSE</code>
(the default) with argument <code>features</code> of length greater than one, then <code>facet</code> is ignored and
each feature is plotted in its own facet.
Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="plotPartialDependence_+3A_facet.wrap.nrow">facet.wrap.nrow</code>, <code id="plotPartialDependence_+3A_facet.wrap.ncol">facet.wrap.ncol</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Number of rows and columns for facetting. Default for both is <code>NULL</code>.
In this case ggplot's <code>facet_wrap</code> will choose the layout itself.</p>
</td></tr>
<tr><td><code id="plotPartialDependence_+3A_p">p</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
If <code>individual = TRUE</code> then <code>sample</code> allows the user to sample without replacement
from the output to make the display more readable. Each row is sampled with probability <code>p</code>.
Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="plotPartialDependence_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Data points to plot. Usually the training data. For survival and binary classification tasks a rug plot
wherein ticks represent failures or instances of the positive class are shown. For regression tasks
points are shown. For multiclass classification tasks ticks are shown and colored according to their class.
Both the features and the target must be included.
Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other partial_dependence: 
<code><a href="#topic+generatePartialDependenceData">generatePartialDependenceData</a>()</code>
</p>
<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>

<hr>
<h2 id='plotResiduals'>Create residual plots for prediction objects or benchmark results.</h2><span id='topic+plotResiduals'></span>

<h3>Description</h3>

<p>Plots for model diagnostics. Provides scatterplots of true vs. predicted values
and histograms of the model's residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotResiduals(
  obj,
  type = "scatterplot",
  loess.smooth = TRUE,
  rug = TRUE,
  pretty.names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotResiduals_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a> | <a href="#topic+BenchmarkResult">BenchmarkResult</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="plotResiduals_+3A_type">type</code></td>
<td>
<p>Type of plot. Can be &ldquo;scatterplot&rdquo;, the default. Or
&ldquo;hist&rdquo;, for a histogram, or in case of classification problems
a barplot, displaying the residuals.</p>
</td></tr>
<tr><td><code id="plotResiduals_+3A_loess.smooth">loess.smooth</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should a loess smoother be added to the plot? Defaults to <code>TRUE</code>.
Only applicable for regression tasks and if <code>type</code> is set to <code>scatterplot</code>.</p>
</td></tr>
<tr><td><code id="plotResiduals_+3A_rug">rug</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should marginal distributions be added to the plot? Defaults to <code>TRUE</code>.
Only applicable for regression tasks and if <code>type</code> is set to <code>scatterplot</code>.</p>
</td></tr>
<tr><td><code id="plotResiduals_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the short name of the learner instead of its ID in labels.
Defaults to <code>TRUE</code>. <br />
Only applicable if a <a href="#topic+BenchmarkResult">BenchmarkResult</a>
is passed to <code>obj</code> in the function call, ignored otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>

<hr>
<h2 id='plotROCCurves'>Plots a ROC curve using ggplot2.</h2><span id='topic+plotROCCurves'></span>

<h3>Description</h3>

<p>Plots a ROC curve from predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotROCCurves(
  obj,
  measures,
  diagonal = TRUE,
  pretty.names = TRUE,
  facet.learner = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotROCCurves_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+ThreshVsPerfData">ThreshVsPerfData</a>)<br />
Result of <a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>.</p>
</td></tr>
<tr><td><code id="plotROCCurves_+3A_measures">measures</code></td>
<td>
<p>([list(2)' of <a href="#topic+Measure">Measure</a>)<br />
Default is the first 2 measures passed to <a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>.</p>
</td></tr>
<tr><td><code id="plotROCCurves_+3A_diagonal">diagonal</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to plot a dashed diagonal line.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotROCCurves_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the <a href="#topic+Measure">Measure</a> name instead of the id in the plot.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotROCCurves_+3A_facet.learner">facet.learner</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Weather to use facetting or different colors to compare multiple learners.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>
<p>Other thresh_vs_perf: 
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotThreshVsPerf">plotThreshVsPerf</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
lrn = makeLearner("classif.rpart", predict.type = "prob")
fit = train(lrn, sonar.task)
pred = predict(fit, task = sonar.task)
roc = generateThreshVsPerfData(pred, list(fpr, tpr))
plotROCCurves(roc)

r = bootstrapB632plus(lrn, sonar.task, iters = 3)
roc_r = generateThreshVsPerfData(r, list(fpr, tpr), aggregate = FALSE)
plotROCCurves(roc_r)

r2 = crossval(lrn, sonar.task, iters = 3)
roc_l = generateThreshVsPerfData(list(boot = r, cv = r2), list(fpr, tpr), aggregate = FALSE)
plotROCCurves(roc_l)

</code></pre>

<hr>
<h2 id='plotThreshVsPerf'>Plot threshold vs. performance(s) for 2-class classification using ggplot2.</h2><span id='topic+plotThreshVsPerf'></span>

<h3>Description</h3>

<p>Plots threshold vs. performance(s) data that has been generated with <a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotThreshVsPerf(
  obj,
  measures = obj$measures,
  facet = "measure",
  mark.th = NA_real_,
  pretty.names = TRUE,
  facet.wrap.nrow = NULL,
  facet.wrap.ncol = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotThreshVsPerf_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+ThreshVsPerfData">ThreshVsPerfData</a>)<br />
Result of <a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>.</p>
</td></tr>
<tr><td><code id="plotThreshVsPerf_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to plot.
Must be a subset of those used in <a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>.
Default is all the measures stored in <code>obj</code> generated by
<a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>.</p>
</td></tr>
<tr><td><code id="plotThreshVsPerf_+3A_facet">facet</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Selects &ldquo;measure&rdquo; or &ldquo;learner&rdquo; to be the facetting variable.
The variable mapped to <code>facet</code> must have more than one unique value, otherwise it will
be ignored. The variable not chosen is mapped to color if it has more than one unique value.
The default is &ldquo;measure&rdquo;.</p>
</td></tr>
<tr><td><code id="plotThreshVsPerf_+3A_mark.th">mark.th</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Mark given threshold with vertical line?
Default is <code>NA</code> which means not to do it.</p>
</td></tr>
<tr><td><code id="plotThreshVsPerf_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the <a href="#topic+Measure">Measure</a> name instead of the id in the plot.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotThreshVsPerf_+3A_facet.wrap.nrow">facet.wrap.nrow</code>, <code id="plotThreshVsPerf_+3A_facet.wrap.ncol">facet.wrap.ncol</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Number of rows and columns for facetting. Default for both is <code>NULL</code>.
In this case ggplot's <code>facet_wrap</code> will choose the layout itself.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other plot: 
<code><a href="#topic+createSpatialResamplingPlots">createSpatialResamplingPlots</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCalibration">plotCalibration</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>,
<code><a href="#topic+plotLearningCurve">plotLearningCurve</a>()</code>,
<code><a href="#topic+plotPartialDependence">plotPartialDependence</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>,
<code><a href="#topic+plotResiduals">plotResiduals</a>()</code>
</p>
<p>Other thresh_vs_perf: 
<code><a href="#topic+generateThreshVsPerfData">generateThreshVsPerfData</a>()</code>,
<code><a href="#topic+plotROCCurves">plotROCCurves</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lrn = makeLearner("classif.rpart", predict.type = "prob")
mod = train(lrn, sonar.task)
pred = predict(mod, sonar.task)
pvs = generateThreshVsPerfData(pred, list(acc, setAggregation(acc, train.mean)))
plotThreshVsPerf(pvs)
</code></pre>

<hr>
<h2 id='plotTuneMultiCritResult'>Plots multi-criteria results after tuning using ggplot2.</h2><span id='topic+plotTuneMultiCritResult'></span>

<h3>Description</h3>

<p>Visualizes the pareto front and possibly the dominated points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotTuneMultiCritResult(
  res,
  path = TRUE,
  col = NULL,
  shape = NULL,
  pointsize = 2,
  pretty.names = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotTuneMultiCritResult_+3A_res">res</code></td>
<td>
<p>(<a href="#topic+TuneMultiCritResult">TuneMultiCritResult</a>)<br />
Result of <a href="#topic+tuneParamsMultiCrit">tuneParamsMultiCrit</a>.</p>
</td></tr>
<tr><td><code id="plotTuneMultiCritResult_+3A_path">path</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Visualize all evaluated points (or only the non-dominated pareto front)?
For the full path, the size of the points on the front is slightly increased.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotTuneMultiCritResult_+3A_col">col</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Which column of <code>res$opt.path</code> should be mapped to ggplot2 color?
Default is <code>NULL</code>, which means none.</p>
</td></tr>
<tr><td><code id="plotTuneMultiCritResult_+3A_shape">shape</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Which column of <code>res$opt.path</code> should be mapped to ggplot2 shape?
Default is <code>NULL</code>, which means none.</p>
</td></tr>
<tr><td><code id="plotTuneMultiCritResult_+3A_pointsize">pointsize</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Point size for ggplot2 <a href="ggplot2.html#topic+geom_point">ggplot2::geom_point</a> for data points.
Default is 2.</p>
</td></tr>
<tr><td><code id="plotTuneMultiCritResult_+3A_pretty.names">pretty.names</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to use the ID of the measures instead of their name in labels. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 plot object.
</p>


<h3>See Also</h3>

<p>Other tune_multicrit: 
<code><a href="#topic+TuneMultiCritControl">TuneMultiCritControl</a></code>,
<code><a href="#topic+tuneParamsMultiCrit">tuneParamsMultiCrit</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see tuneParamsMultiCrit
</code></pre>

<hr>
<h2 id='predict.WrappedModel'>Predict new data.</h2><span id='topic+predict.WrappedModel'></span>

<h3>Description</h3>

<p>Predict the target variable of new data using a fitted model.
What is stored exactly in the (<a href="#topic+Prediction">Prediction</a>) object depends
on the <code>predict.type</code> setting of the <a href="#topic+Learner">Learner</a>.
If <code>predict.type</code> was set to &ldquo;prob&rdquo; probability thresholding
can be done calling the <a href="#topic+setThreshold">setThreshold</a> function on the
prediction object.
</p>
<p>The row names of the input <code>task</code> or <code>newdata</code> are preserved in the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'WrappedModel'
predict(object, task, newdata, subset = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.WrappedModel_+3A_object">object</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Wrapped model, result of <a href="#topic+train">train</a>.</p>
</td></tr>
<tr><td><code id="predict.WrappedModel_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task. If this is passed, data from this task is predicted.</p>
</td></tr>
<tr><td><code id="predict.WrappedModel_+3A_newdata">newdata</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
New observations which should be predicted.
Pass this alternatively instead of <code>task</code>.</p>
</td></tr>
<tr><td><code id="predict.WrappedModel_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
<tr><td><code id="predict.WrappedModel_+3A_...">...</code></td>
<td>
<p>(any)<br />
Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Prediction">Prediction</a>).
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>,
<code><a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a>()</code>,
<code><a href="#topic+getPredictionResponse">getPredictionResponse</a>()</code>,
<code><a href="#topic+getPredictionTaskDesc">getPredictionTaskDesc</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># train and predict
train.set = seq(1, 150, 2)
test.set = seq(2, 150, 2)
model = train("classif.lda", iris.task, subset = train.set)
p = predict(model, newdata = iris, subset = test.set)
print(p)
predict(model, task = iris.task, subset = test.set)

# predict now probabiliies instead of class labels
lrn = makeLearner("classif.lda", predict.type = "prob")
model = train(lrn, iris.task, subset = train.set)
p = predict(model, task = iris.task, subset = test.set)
print(p)
getPredictionProbabilities(p)
</code></pre>

<hr>
<h2 id='Prediction'>Prediction object.</h2><span id='topic+Prediction'></span><span id='topic+makePrediction'></span>

<h3>Description</h3>

<p>Result from <a href="#topic+predict.WrappedModel">predict.WrappedModel</a>.
Use <code>as.data.frame</code> to access all information in a convenient format.
The function <a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a> is useful to access predicted probabilities.
</p>
<p>The <code>data</code> member of the object contains always the following columns:
<code>id</code>, index numbers of predicted cases from the task, <code>response</code>
either a numeric or a factor, the predicted response values, <code>truth</code>,
either a numeric or a factor, the true target values.
If probabilities were predicted, as many numeric columns as there were classes named
<code>prob.classname</code>. If standard errors were predicted, a numeric column named <code>se</code>.
</p>
<p>The constructor <code>makePrediction</code> is mainly for internal use.
</p>
<p>Object members:
</p>

<dl>
<dt>predict.type (<code>character(1)</code>)</dt><dd><p>Type set in <a href="#topic+setPredictType">setPredictType</a>.</p>
</dd>
<dt>data (<a href="base.html#topic+data.frame">data.frame</a>)</dt><dd><p>See details.</p>
</dd>
<dt>threshold (<code>numeric(1)</code>)</dt><dd><p>Threshold set in predict function.</p>
</dd>
<dt>task.desc (<a href="#topic+TaskDesc">TaskDesc</a>)</dt><dd><p>Task description object.</p>
</dd>
<dt>time (<code>numeric(1)</code>)</dt><dd><p>Time learner needed to generate predictions.</p>
</dd>
<dt>error (<code>character(1)</code>)</dt><dd><p>Any error messages generated by the learner (default NA_character_).</p>
</dd>
</dl>

<p>Internal, do not use!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makePrediction(
  task.desc,
  row.names,
  id,
  truth,
  predict.type,
  predict.threshold = NULL,
  y,
  time,
  error = NA_character_,
  dump = NULL
)
</code></pre>

<hr>
<h2 id='predictLearner'>Predict new data with an R learner.</h2><span id='topic+predictLearner'></span>

<h3>Description</h3>

<p>Mainly for internal use. Predict new data with a fitted model.
You have to implement this method if you want to add another learner to this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictLearner(.learner, .model, .newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictLearner_+3A_.learner">.learner</code></td>
<td>
<p>(<a href="#topic+RLearner">RLearner</a>)<br />
Wrapped learner.</p>
</td></tr>
<tr><td><code id="predictLearner_+3A_.model">.model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Model produced by training.</p>
</td></tr>
<tr><td><code id="predictLearner_+3A_.newdata">.newdata</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
New data to predict. Does not include target column.</p>
</td></tr>
<tr><td><code id="predictLearner_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional parameters, which need to be passed to the underlying predict function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Your implementation must adhere to the following:
Predictions for the observations in <code>.newdata</code> must be made based on the fitted
model (<code>.model$learner.model</code>).
All parameters in <code>...</code> must be passed to the underlying predict function.
</p>


<h3>Value</h3>


<ul>
<li><p> For classification: Either a factor with class labels for type
&ldquo;response&rdquo; or, if the learner supports this, a matrix of class probabilities
for type &ldquo;prob&rdquo;. In the latter case the columns must be named with the class
labels.
</p>
</li>
<li><p> For regression: Either a numeric vector for type &ldquo;response&rdquo; or,
if the learner supports this, a matrix with two columns for type &ldquo;se&rdquo;.
In the latter case the first column contains the estimated response (mean value)
and the second column the estimated standard errors.
</p>
</li>
<li><p> For survival: Either a numeric vector with some sort of orderable risk
for type &ldquo;response&rdquo; or, if supported, a numeric vector with time dependent
probabilities for type &ldquo;prob&rdquo;.
</p>
</li>
<li><p> For clustering: Either an integer with cluster IDs for type &ldquo;response&rdquo;
or, if supported, a matrix of membership probabilities for type &ldquo;prob&rdquo;.
</p>
</li>
<li><p> For multilabel: A logical matrix that indicates predicted class labels for type
&ldquo;response&rdquo; or, if supported, a matrix of class probabilities for type
&ldquo;prob&rdquo;. The columns must be named with the class labels.
</p>
</li></ul>


<hr>
<h2 id='reduceBatchmarkResults'>Reduce results of a batch-distributed benchmark.</h2><span id='topic+reduceBatchmarkResults'></span>

<h3>Description</h3>

<p>This creates a <a href="#topic+BenchmarkResult">BenchmarkResult</a> from a <a href="batchtools.html#topic+makeExperimentRegistry">batchtools::ExperimentRegistry</a>.
To setup the benchmark have a look at <a href="#topic+batchmark">batchmark</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reduceBatchmarkResults(
  ids = NULL,
  keep.pred = TRUE,
  keep.extract = FALSE,
  show.info = getMlrOption("show.info"),
  reg = batchtools::getDefaultRegistry()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reduceBatchmarkResults_+3A_ids">ids</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> or <a href="base.html#topic+integer">integer</a>)<br />
A <a href="base.html#topic+data.frame">base::data.frame</a> (or <a href="data.table.html#topic+data.table">data.table::data.table</a>)
with a column named &ldquo;job.id&rdquo;.
Alternatively, you may also pass a vector of integerish job ids.
If not set, defaults to all successfully terminated jobs (return value of <a href="batchtools.html#topic+findJobs">batchtools::findDone</a>.</p>
</td></tr>
<tr><td><code id="reduceBatchmarkResults_+3A_keep.pred">keep.pred</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the prediction data in the <code>pred</code> slot of the result object.
If you do many experiments (on larger data sets) these objects might unnecessarily increase
object size / mem usage, if you do not really need them.
The default is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="reduceBatchmarkResults_+3A_keep.extract">keep.extract</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the <code>extract</code> slot of the result object. When creating a lot of
benchmark results with extensive tuning, the resulting R objects can become
very large in size. That is why the tuning results stored in the <code>extract</code>
slot are removed by default (<code>keep.extract = FALSE</code>). Note that when
<code>keep.extract = FALSE</code> you will not be able to conduct analysis in the
tuning results.</p>
</td></tr>
<tr><td><code id="reduceBatchmarkResults_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
<tr><td><code id="reduceBatchmarkResults_+3A_reg">reg</code></td>
<td>
<p>(<a href="batchtools.html#topic+makeExperimentRegistry">batchtools::ExperimentRegistry</a>)<br />
Registry, created by <a href="batchtools.html#topic+makeExperimentRegistry">batchtools::makeExperimentRegistry</a>. If not explicitly passed,
uses the last created registry.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+BenchmarkResult">BenchmarkResult</a>).
</p>


<h3>See Also</h3>

<p>Other benchmark: 
<code><a href="#topic+BenchmarkResult">BenchmarkResult</a></code>,
<code><a href="#topic+batchmark">batchmark</a>()</code>,
<code><a href="#topic+benchmark">benchmark</a>()</code>,
<code><a href="#topic+convertBMRToRankMatrix">convertBMRToRankMatrix</a>()</code>,
<code><a href="#topic+friedmanPostHocTestBMR">friedmanPostHocTestBMR</a>()</code>,
<code><a href="#topic+friedmanTestBMR">friedmanTestBMR</a>()</code>,
<code><a href="#topic+generateCritDifferencesData">generateCritDifferencesData</a>()</code>,
<code><a href="#topic+getBMRAggrPerformances">getBMRAggrPerformances</a>()</code>,
<code><a href="#topic+getBMRFeatSelResults">getBMRFeatSelResults</a>()</code>,
<code><a href="#topic+getBMRFilteredFeatures">getBMRFilteredFeatures</a>()</code>,
<code><a href="#topic+getBMRLearnerIds">getBMRLearnerIds</a>()</code>,
<code><a href="#topic+getBMRLearnerShortNames">getBMRLearnerShortNames</a>()</code>,
<code><a href="#topic+getBMRLearners">getBMRLearners</a>()</code>,
<code><a href="#topic+getBMRMeasureIds">getBMRMeasureIds</a>()</code>,
<code><a href="#topic+getBMRMeasures">getBMRMeasures</a>()</code>,
<code><a href="#topic+getBMRModels">getBMRModels</a>()</code>,
<code><a href="#topic+getBMRPerformances">getBMRPerformances</a>()</code>,
<code><a href="#topic+getBMRPredictions">getBMRPredictions</a>()</code>,
<code><a href="#topic+getBMRTaskDescs">getBMRTaskDescs</a>()</code>,
<code><a href="#topic+getBMRTaskIds">getBMRTaskIds</a>()</code>,
<code><a href="#topic+getBMRTuneResults">getBMRTuneResults</a>()</code>,
<code><a href="#topic+plotBMRBoxplots">plotBMRBoxplots</a>()</code>,
<code><a href="#topic+plotBMRRanksAsBarChart">plotBMRRanksAsBarChart</a>()</code>,
<code><a href="#topic+plotBMRSummary">plotBMRSummary</a>()</code>,
<code><a href="#topic+plotCritDifferences">plotCritDifferences</a>()</code>
</p>

<hr>
<h2 id='reextractFDAFeatures'>Re-extract features from a data set</h2><span id='topic+reextractFDAFeatures'></span>

<h3>Description</h3>

<p>This function accepts a data frame or a task and an extractFDAFeatDesc
(a FDA feature extraction description)
as returned by <a href="#topic+extractFDAFeatures">extractFDAFeatures</a> to extract features
from previously unseen data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reextractFDAFeatures(obj, desc, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reextractFDAFeatures_+3A_obj">obj</code></td>
<td>
<p>(<a href="#topic+Task">Task</a> | <a href="base.html#topic+data.frame">data.frame</a>)<br />
Task or data.frame to extract functional features from. Must contain functional features
as matrix columns.</p>
</td></tr>
<tr><td><code id="reextractFDAFeatures_+3A_desc">desc</code></td>
<td>
<p>(<code>extractFDAFeatDesc</code>)<br />
FDAFeature extraction description as returned by <a href="#topic+extractFDAFeatures">extractFDAFeatures</a></p>
</td></tr>
<tr><td><code id="reextractFDAFeatures_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further args passed on to methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+data.frame">data.frame</a> or <a href="#topic+Task">Task</a> containing the extracted Features
</p>

<hr>
<h2 id='reimpute'>Re-impute a data set</h2><span id='topic+reimpute'></span>

<h3>Description</h3>

<p>This function accepts a data frame or a task and an imputation description
as returned by <a href="#topic+impute">impute</a> to perform the following actions:
</p>

<ol>
<li><p> Restore dropped columns, setting them to <code>NA</code>
</p>
</li>
<li><p> Add dummy variables for columns as specified in <code>impute</code>
</p>
</li>
<li><p> Optionally check factors for new levels to treat them as <code>NA</code>s
</p>
</li>
<li><p> Reorder factor levels to ensure identical integer representation as
before
</p>
</li>
<li><p> Impute missing values using previously collected data
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>reimpute(obj, desc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reimpute_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="reimpute_+3A_desc">desc</code></td>
<td>
<p>(<code>ImputationDesc</code>)<br />
Imputation description as returned by <a href="#topic+impute">impute</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Imputated <code>data.frame</code> or task with imputed data.
</p>


<h3>See Also</h3>

<p>Other impute: 
<code><a href="#topic+imputations">imputations</a></code>,
<code><a href="#topic+impute">impute</a>()</code>,
<code><a href="#topic+makeImputeMethod">makeImputeMethod</a>()</code>,
<code><a href="#topic+makeImputeWrapper">makeImputeWrapper</a>()</code>
</p>

<hr>
<h2 id='removeConstantFeatures'>Remove constant features from a data set.</h2><span id='topic+removeConstantFeatures'></span>

<h3>Description</h3>

<p>Constant features can lead to errors in some models and obviously provide
no information in the training set that can be learned from.
With the argument &ldquo;perc&rdquo;, there is a possibility to also remove
features for which less than &ldquo;perc&rdquo; percent of the observations
differ from the mode value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeConstantFeatures(
  obj,
  perc = 0,
  dont.rm = character(0L),
  na.ignore = FALSE,
  wrap.tol = .Machine$double.eps^0.5,
  show.info = getMlrOption("show.info"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="removeConstantFeatures_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="removeConstantFeatures_+3A_perc">perc</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
The percentage of a feature values in [0, 1) that must differ from the mode value.
Default is 0, which means only constant features with exactly one observed level are removed.</p>
</td></tr>
<tr><td><code id="removeConstantFeatures_+3A_dont.rm">dont.rm</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Names of the columns which must not be deleted.
Default is no columns.</p>
</td></tr>
<tr><td><code id="removeConstantFeatures_+3A_na.ignore">na.ignore</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should NAs be ignored in the percentage calculation?
(Or should they be treated as a single, extra level in the percentage calculation?)
Note that if the feature has only missing values, it is always removed.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="removeConstantFeatures_+3A_wrap.tol">wrap.tol</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Numerical tolerance to treat two numbers as equal.
Variables stored as <code>double</code> will get rounded accordingly before computing the mode.
Default is <code>sqrt(.Maschine$double.eps)</code>.</p>
</td></tr>
<tr><td><code id="removeConstantFeatures_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
<tr><td><code id="removeConstantFeatures_+3A_...">...</code></td>
<td>
<p>To ensure backward compatibility with old argument <code>tol</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>. Same type as <code>obj</code>.
</p>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>

<hr>
<h2 id='removeHyperPars'>Remove hyperparameters settings of a learner.</h2><span id='topic+removeHyperPars'></span>

<h3>Description</h3>

<p>Remove settings (previously set through mlr) for some parameters.
Which means that the default behavior for that param will now be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeHyperPars(learner, ids = character(0L))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="removeHyperPars_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="removeHyperPars_+3A_ids">ids</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Parameter names to remove settings for.
Default is <code>character(0L)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='resample'>Fit models according to a resampling strategy.</h2><span id='topic+resample'></span><span id='topic+crossval'></span><span id='topic+repcv'></span><span id='topic+holdout'></span><span id='topic+subsample'></span><span id='topic+bootstrapOOB'></span><span id='topic+bootstrapB632'></span><span id='topic+bootstrapB632plus'></span><span id='topic+growingcv'></span><span id='topic+fixedcv'></span>

<h3>Description</h3>

<p>The function <code>resample</code> fits a model specified by <a href="#topic+Learner">Learner</a> on a <a href="#topic+Task">Task</a>
and calculates predictions and performance <a href="#topic+measures">measures</a> for all training
and all test sets specified by a either a resampling description (<a href="#topic+ResampleDesc">ResampleDesc</a>)
or resampling instance (<a href="#topic+ResampleInstance">ResampleInstance</a>).
</p>
<p>You are able to return all fitted models (parameter <code>models</code>) or extract specific parts
of the models (parameter <code>extract</code>) as returning all of them completely
might be memory intensive.
</p>
<p>The remaining functions on this page are convenience wrappers for the various
existing resampling strategies. Note that if you need to work with precomputed training and
test splits (i.e., resampling instances), you have to stick with <code>resample</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resample(
  learner,
  task,
  resampling,
  measures,
  weights = NULL,
  models = FALSE,
  extract,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

crossval(
  learner,
  task,
  iters = 10L,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

repcv(
  learner,
  task,
  folds = 10L,
  reps = 10L,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

holdout(
  learner,
  task,
  split = 2/3,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

subsample(
  learner,
  task,
  iters = 30,
  split = 2/3,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

bootstrapOOB(
  learner,
  task,
  iters = 30,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

bootstrapB632(
  learner,
  task,
  iters = 30,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

bootstrapB632plus(
  learner,
  task,
  iters = 30,
  stratify = FALSE,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

growingcv(
  learner,
  task,
  horizon = 1,
  initial.window = 0.5,
  skip = 0,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)

fixedcv(
  learner,
  task,
  horizon = 1L,
  initial.window = 0.5,
  skip = 0,
  measures,
  models = FALSE,
  keep.pred = TRUE,
  ...,
  show.info = getMlrOption("show.info")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resample_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="resample_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleDesc">ResampleDesc</a> or <a href="#topic+ResampleInstance">ResampleInstance</a>)<br />
Resampling strategy.
If a description is passed, it is instantiated automatically.</p>
</td></tr>
<tr><td><code id="resample_+3A_measures">measures</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a> | list of <a href="#topic+Measure">Measure</a>)<br />
Performance measure(s) to evaluate.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
If given, must be of same length as observations in task and in corresponding order.
Overwrites weights specified in the <code>task</code>.
By default <code>NULL</code> which means no weights are used unless specified in the task.</p>
</td></tr>
<tr><td><code id="resample_+3A_models">models</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should all fitted models be returned?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="resample_+3A_extract">extract</code></td>
<td>
<p>(<code>function</code>)<br />
Function used to extract information from a fitted model during resampling.
Is applied to every <a href="#topic+WrappedModel">WrappedModel</a> resulting from calls to <a href="#topic+train">train</a>
during resampling.
Default is to extract nothing.</p>
</td></tr>
<tr><td><code id="resample_+3A_keep.pred">keep.pred</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Keep the prediction data in the <code>pred</code> slot of the result object.
If you do many experiments (on larger data sets) these objects might unnecessarily increase
object size / mem usage, if you do not really need them.
The default is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="resample_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further hyperparameters passed to <code>learner</code>.</p>
</td></tr>
<tr><td><code id="resample_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_iters">iters</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_stratify">stratify</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_folds">folds</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_reps">reps</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_split">split</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_horizon">horizon</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_initial.window">initial.window</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
<tr><td><code id="resample_+3A_skip">skip</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
See <a href="#topic+ResampleDesc">ResampleDesc</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+ResampleResult">ResampleResult</a>).
</p>


<h3>Note</h3>

<p>If you would like to include results from the training data set, make
sure to appropriately adjust the resampling strategy and the aggregation for
the measure. See example code below.
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>task = makeClassifTask(data = iris, target = "Species")
rdesc = makeResampleDesc("CV", iters = 2)
r = resample(makeLearner("classif.qda"), task, rdesc)
print(r$aggr)
print(r$measures.test)
print(r$pred)

# include the training set performance as well
rdesc = makeResampleDesc("CV", iters = 2, predict = "both")
r = resample(makeLearner("classif.qda"), task, rdesc,
  measures = list(mmce, setAggregation(mmce, train.mean)))
print(r$aggr)
</code></pre>

<hr>
<h2 id='ResamplePrediction'>Prediction from resampling.</h2><span id='topic+ResamplePrediction'></span>

<h3>Description</h3>

<p>Contains predictions from resampling, returned (among other stuff) by function <a href="#topic+resample">resample</a>.
Can basically be used in the same way as <a href="#topic+Prediction">Prediction</a>, its super class.
The main differences are:
(a) The internal data.frame (member <code>data</code>) contains an additional column <code>iter</code>, specifying the iteration
of the resampling strategy, and and additional columns <code>set</code>, specifying whether the prediction
was from an observation in the &ldquo;train&rdquo; or &ldquo;test&rdquo; set. (b) The prediction <code>time</code> is
a numeric vector, its length equals the number of iterations.
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResampleResult">ResampleResult</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>

<hr>
<h2 id='ResampleResult'>ResampleResult object.</h2><span id='topic+ResampleResult'></span>

<h3>Description</h3>

<p>A container for resample results.
</p>


<h3>Details</h3>

<p>Resample Result:
</p>
<p>A resample result is created by resample and
contains the following object members:
</p>

<dl>
<dt>task.id (<code>character(1)</code>):</dt><dd>
<p>Name of the Task.
</p>
</dd>
<dt>learner.id (<code>character(1)</code>):</dt><dd>
<p>Name of the Learner.
</p>
</dd>
<dt>measures.test (<a href="base.html#topic+data.frame">data.frame</a>):</dt><dd>
<p>Gives you access to performance measurements
on the individual test sets. Rows correspond to sets in resampling iterations,
columns to performance measures.
</p>
</dd>
<dt>measures.train (<a href="base.html#topic+data.frame">data.frame</a>):</dt><dd>
<p>Gives you access to performance measurements
on the individual training sets. Rows correspond to sets in resampling iterations,
columns to performance measures. Usually not available, only if specifically requested,
see general description above.
</p>
</dd>
<dt>aggr (<a href="base.html#topic+numeric">numeric</a>):</dt><dd>
<p>Named vector of aggregated performance values. Names are coded like
this <code style="white-space: pre;">&#8288;&lt;measure&gt;.&lt;aggregation&gt;&#8288;</code>.
</p>
</dd>
<dt>err.msgs (<a href="base.html#topic+data.frame">data.frame</a>):</dt><dd>
<p>Number of rows equals resampling iterations
and columns are: <code>iter</code>, <code>train</code>, <code>predict</code>.
Stores error messages generated during train or predict, if these were caught
via <a href="#topic+configureMlr">configureMlr</a>.
</p>
</dd>
<dt>err.dumps (list of list of <a href="utils.html#topic+dump.frames">dump.frames</a>):</dt><dd>
<p>List with length equal to number of resampling iterations. Contains lists
of <code>dump.frames</code> objects that can be fed to <code>debugger()</code> to inspect
error dumps generated on learner errors. One iteration can generate more than
one error dump depending on which of training, prediction on training set,
or prediction on test set, operations fail. Therefore the lists have named
slots <code style="white-space: pre;">&#8288;$train&#8288;</code>, <code style="white-space: pre;">&#8288;$predict.train&#8288;</code>, or <code style="white-space: pre;">&#8288;$predict.test&#8288;</code> if relevant.
The error dumps are only saved when option <code>on.error.dump</code> is <code>TRUE</code>.
</p>
</dd>
<dt>pred (<a href="#topic+ResamplePrediction">ResamplePrediction</a>):</dt><dd>
<p>Container for all predictions during resampling.
</p>
</dd>
<dt>models [list of <a href="#topic+WrappedModel">WrappedModel</a>):</dt><dd>
<p>List of fitted models or <code>NULL</code>.
</p>
</dd>
<dt>extract (<a href="base.html#topic+list">list</a>):</dt><dd>
<p>List of extracted parts from fitted models or <code>NULL</code>.
</p>
</dd>
<dt>runtime (<code>numeric(1)</code>):</dt><dd>
<p>Time in seconds it took to execute the resampling.
</p>
</dd>
</dl>

<p>The print method of this object gives a short overview, including
task and learner ids, aggregated measures and runtime for the resampling.
</p>


<h3>See Also</h3>

<p>Other resample: 
<code><a href="#topic+ResamplePrediction">ResamplePrediction</a></code>,
<code><a href="#topic+addRRMeasure">addRRMeasure</a>()</code>,
<code><a href="#topic+getRRPredictionList">getRRPredictionList</a>()</code>,
<code><a href="#topic+getRRPredictions">getRRPredictions</a>()</code>,
<code><a href="#topic+getRRTaskDescription">getRRTaskDescription</a>()</code>,
<code><a href="#topic+getRRTaskDesc">getRRTaskDesc</a>()</code>,
<code><a href="#topic+makeResampleDesc">makeResampleDesc</a>()</code>,
<code><a href="#topic+makeResampleInstance">makeResampleInstance</a>()</code>,
<code><a href="#topic+resample">resample</a>()</code>
</p>
<p>Other debug: 
<code><a href="#topic+FailureModel">FailureModel</a></code>,
<code><a href="#topic+getPredictionDump">getPredictionDump</a>()</code>,
<code><a href="#topic+getRRDump">getRRDump</a>()</code>
</p>

<hr>
<h2 id='RLearner'>Internal construction / wrapping of learner object.</h2><span id='topic+RLearner'></span><span id='topic+RLearnerClassif'></span><span id='topic+RLearnerCluster'></span><span id='topic+RLearnerMultilabel'></span><span id='topic+RLearnerRegr'></span><span id='topic+RLearnerSurv'></span><span id='topic+makeRLearner'></span><span id='topic+makeRLearnerClassif'></span><span id='topic+makeRLearnerMultilabel'></span><span id='topic+makeRLearnerRegr'></span><span id='topic+makeRLearnerSurv'></span><span id='topic+makeRLearnerCluster'></span><span id='topic+makeRLearnerCostSens'></span>

<h3>Description</h3>

<p>Wraps an already implemented learning method from R to make it accessible to mlr.
Call this method in your constructor. You have to pass an id (name), the required
package(s), a description object for all changeable parameters (you do not have to do this for the
learner to work, but it is strongly recommended), and use property tags to define
features of the learner.
</p>
<p>For a general overview on how to integrate a learning algorithm into mlr's system, please read the
section in the online tutorial:
<a href="https://mlr.mlr-org.com/articles/tutorial/create_learner.html">https://mlr.mlr-org.com/articles/tutorial/create_learner.html</a>
</p>
<p>To see all possible properties of a learner, go to: <a href="#topic+LearnerProperties">LearnerProperties</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeRLearner()

makeRLearnerClassif(
  cl,
  package,
  par.set,
  par.vals = list(),
  properties = character(0L),
  name = cl,
  short.name = cl,
  note = "",
  class.weights.param = NULL,
  callees = character(0L)
)

makeRLearnerMultilabel(
  cl,
  package,
  par.set,
  par.vals = list(),
  properties = character(0L),
  name = cl,
  short.name = cl,
  note = "",
  callees = character(0L)
)

makeRLearnerRegr(
  cl,
  package,
  par.set,
  par.vals = list(),
  properties = character(0L),
  name = cl,
  short.name = cl,
  note = "",
  callees = character(0L)
)

makeRLearnerSurv(
  cl,
  package,
  par.set,
  par.vals = list(),
  properties = character(0L),
  name = cl,
  short.name = cl,
  note = "",
  callees = character(0L)
)

makeRLearnerCluster(
  cl,
  package,
  par.set,
  par.vals = list(),
  properties = character(0L),
  name = cl,
  short.name = cl,
  note = "",
  callees = character(0L)
)

makeRLearnerCostSens(
  cl,
  package,
  par.set,
  par.vals = list(),
  properties = character(0L),
  name = cl,
  short.name = cl,
  note = "",
  callees = character(0L)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RLearner_+3A_cl">cl</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Class of learner. By convention, all classification learners
start with &ldquo;classif.&rdquo; all regression learners with
&ldquo;regr.&rdquo; all survival learners start with &ldquo;surv.&rdquo;
all clustering learners with &ldquo;cluster.&rdquo; and all multilabel
classification learners start with &ldquo;multilabel.&rdquo;.
A list of all integrated learners is available on the
<a href="#topic+learners">learners</a> help page.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_package">package</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Package(s) to load for the implementation of the learner.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_par.set">par.set</code></td>
<td>
<p>(<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a>)<br />
Parameter set of (hyper)parameters and their constraints.
Dependent parameters with a <code>requires</code> field must use <code>quote</code> and not
<code>expression</code> to define it.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Always set hyperparameters to these values when the object is constructed.
Useful when default values are missing in the underlying function.
The values can later be overwritten when the user sets hyperparameters.
Default is empty list.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_properties">properties</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Set of learner properties. See above.
Default is <code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_name">name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Meaningful name for learner.
Default is <code>id</code>.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_short.name">short.name</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Short name for learner.
Should only be a few characters so it can be used in plots and tables.
Default is <code>id</code>.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_note">note</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Additional notes regarding the learner and its integration in mlr.
Default is &ldquo;&rdquo;.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_class.weights.param">class.weights.param</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Name of the parameter, which can be used for providing class weights.</p>
</td></tr>
<tr><td><code id="RLearner_+3A_callees">callees</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Character vector naming all functions of the learner's package being called which
have a relevant R help page.
Default is <code>character(0)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+RLearner">RLearner</a>). The specific subclass is one of <a href="#topic+RLearnerClassif">RLearnerClassif</a>,
<a href="#topic+RLearnerCluster">RLearnerCluster</a>, <a href="#topic+RLearnerMultilabel">RLearnerMultilabel</a>,
<a href="#topic+RLearnerRegr">RLearnerRegr</a>, <a href="#topic+RLearnerSurv">RLearnerSurv</a>.
</p>

<hr>
<h2 id='selectFeatures'>Feature selection by wrapper approach.</h2><span id='topic+selectFeatures'></span>

<h3>Description</h3>

<p>Optimizes the features for a classification or regression problem by choosing
a variable selection wrapper approach. Allows for different optimization
methods, such as forward search or a genetic algorithm. You can select such
an algorithm (and its settings) by passing a corresponding control object.
For a complete list of implemented algorithms look at the subclasses of
(<a href="#topic+FeatSelControl">FeatSelControl</a>).
</p>
<p>All algorithms operate on a 0-1-bit encoding of candidate solutions. Per
default a single bit corresponds to a single feature, but you are able to
change this by using the arguments <code>bit.names</code> and <code>bits.to.features</code>. Thus
allowing you to switch on whole groups of features with a single bit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectFeatures(
  learner,
  task,
  resampling,
  measures,
  bit.names,
  bits.to.features,
  control,
  show.info = getMlrOption("show.info")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectFeatures_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleInstance">ResampleInstance</a> | <a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy for feature selection. If you pass a description, it is
instantiated once at the beginning by default, so all points are evaluated
on the same training/test sets. If you want to change that behavior, look
at <a href="#topic+FeatSelControl">FeatSelControl</a>.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_measures">measures</code></td>
<td>
<p>(list of <a href="#topic+Measure">Measure</a> | <a href="#topic+Measure">Measure</a>)<br />
Performance measures to evaluate. The first measure, aggregated by the first aggregation function
is optimized, others are simply evaluated.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_bit.names">bit.names</code></td>
<td>
<p><a href="base.html#topic+character">character</a><br />
Names of bits encoding the solutions. Also defines the total number of bits
in the encoding. Per default these are the feature names of the task. Has
to be used together with <code>bits.to.features</code>.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_bits.to.features">bits.to.features</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(x, task)&#8288;</code>)<br />
Function which transforms an integer-0-1 vector into a character vector of
selected features. Per default a value of 1 in the ith bit selects the ith
feature to be in the candidate solution. The vector <code>x</code> will correspond to
the <code>bit.names</code> and has to be of the same length.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_control">control</code></td>
<td>
<p>[see <a href="#topic+FeatSelControl">FeatSelControl</a>)
Control object for search method.
Also selects the optimization algorithm for feature selection.</p>
</td></tr>
<tr><td><code id="selectFeatures_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+FeatSelResult">FeatSelResult</a>).
</p>


<h3>See Also</h3>

<p>Other featsel: 
<code><a href="#topic+FeatSelControl">FeatSelControl</a></code>,
<code><a href="#topic+analyzeFeatSelResult">analyzeFeatSelResult</a>()</code>,
<code><a href="#topic+getFeatSelResult">getFeatSelResult</a>()</code>,
<code><a href="#topic+makeFeatSelWrapper">makeFeatSelWrapper</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rdesc = makeResampleDesc("Holdout")
ctrl = makeFeatSelControlSequential(method = "sfs", maxit = NA)
res = selectFeatures("classif.rpart", iris.task, rdesc, control = ctrl)
analyzeFeatSelResult(res)

</code></pre>

<hr>
<h2 id='setAggregation'>Set aggregation function of measure.</h2><span id='topic+setAggregation'></span>

<h3>Description</h3>

<p>Set how this measure will be aggregated after resampling.
To see possible aggregation functions: <a href="#topic+aggregations">aggregations</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setAggregation(measure, aggr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setAggregation_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.</p>
</td></tr>
<tr><td><code id="setAggregation_+3A_aggr">aggr</code></td>
<td>
<p>(<a href="#topic+Aggregation">Aggregation</a>)<br />
Aggregation function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Measure">Measure</a>) with changed aggregation behaviour.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setMeasurePars">setMeasurePars</a>()</code>
</p>

<hr>
<h2 id='setHyperPars'>Set the hyperparameters of a learner object.</h2><span id='topic+setHyperPars'></span>

<h3>Description</h3>

<p>Set the hyperparameters of a learner object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setHyperPars(learner, ..., par.vals = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setHyperPars_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="setHyperPars_+3A_...">...</code></td>
<td>
<p>(any)<br /> Optional named (hyper)parameters. If you want to set
specific hyperparameters for a learner during model creation, these should
go here. You can get a list of available hyperparameters using
<code style="white-space: pre;">&#8288;getParamSet(&lt;learner&gt;)&#8288;</code>. Alternatively hyperparameters can be given using
the <code>par.vals</code> argument but <code>...</code> should be preferred!</p>
</td></tr>
<tr><td><code id="setHyperPars_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br /> Optional list of named (hyper)parameters. The
arguments in <code>...</code> take precedence over values in this list. We strongly
encourage you to use <code>...</code> for passing hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>Note</h3>

<p>If a named (hyper)parameter can't be found for the given learner, the 3
closest (hyper)parameter names will be output in case the user mistyped.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cl1 = makeLearner("classif.ksvm", sigma = 1)
cl2 = setHyperPars(cl1, sigma = 10, par.vals = list(C = 2))
print(cl1)
# note the now set and altered hyperparameters:
print(cl2)
</code></pre>

<hr>
<h2 id='setHyperPars2'>Only exported for internal use.</h2><span id='topic+setHyperPars2'></span>

<h3>Description</h3>

<p>Only exported for internal use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setHyperPars2(learner, par.vals)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setHyperPars2_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a>)<br />
The learner.</p>
</td></tr>
<tr><td><code id="setHyperPars2_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
List of named (hyper)parameter settings.</p>
</td></tr>
</table>

<hr>
<h2 id='setId'>Set the id of a learner object.</h2><span id='topic+setId'></span>

<h3>Description</h3>

<p>Deprecated, use <a href="#topic+setLearnerId">setLearnerId</a> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setId(learner, id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setId_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="setId_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
New id for learner.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='setLearnerId'>Set the ID of a learner object.</h2><span id='topic+setLearnerId'></span>

<h3>Description</h3>

<p>Set the ID of the learner.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setLearnerId(learner, id)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setLearnerId_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="setLearnerId_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
New ID for learner.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='setMeasurePars'>Set parameters of performance measures</h2><span id='topic+setMeasurePars'></span>

<h3>Description</h3>

<p>Sets hyperparameters of measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setMeasurePars(measure, ..., par.vals = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setMeasurePars_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure.</p>
</td></tr>
<tr><td><code id="setMeasurePars_+3A_...">...</code></td>
<td>
<p>(any)<br />
Named (hyper)parameters with new settings. Alternatively these can be passed
using the <code>par.vals</code> argument.</p>
</td></tr>
<tr><td><code id="setMeasurePars_+3A_par.vals">par.vals</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Optional list of named (hyper)parameter settings. The arguments in
<code>...</code> take precedence over values in this list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Measure">Measure</a>.
</p>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+ConfusionMatrix">ConfusionMatrix</a></code>,
<code><a href="#topic+calculateConfusionMatrix">calculateConfusionMatrix</a>()</code>,
<code><a href="#topic+calculateROCMeasures">calculateROCMeasures</a>()</code>,
<code><a href="#topic+estimateRelativeOverfitting">estimateRelativeOverfitting</a>()</code>,
<code><a href="#topic+makeCostMeasure">makeCostMeasure</a>()</code>,
<code><a href="#topic+makeCustomResampledMeasure">makeCustomResampledMeasure</a>()</code>,
<code><a href="#topic+makeMeasure">makeMeasure</a>()</code>,
<code><a href="#topic+measures">measures</a></code>,
<code><a href="#topic+performance">performance</a>()</code>,
<code><a href="#topic+setAggregation">setAggregation</a>()</code>
</p>

<hr>
<h2 id='setPredictThreshold'>Set the probability threshold the learner should use.</h2><span id='topic+setPredictThreshold'></span>

<h3>Description</h3>

<p>See <code>predict.threshold</code> in <a href="#topic+makeLearner">makeLearner</a> and <a href="#topic+setThreshold">setThreshold</a>.
</p>
<p>For complex wrappers only the top-level <code>predict.type</code> is currently set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setPredictThreshold(learner, predict.threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setPredictThreshold_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="setPredictThreshold_+3A_predict.threshold">predict.threshold</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Threshold to produce class labels. Has to be a named vector, where names correspond to class labels.
Only for binary classification it can be a single numerical threshold for the positive class.
See <a href="#topic+setThreshold">setThreshold</a> for details on how it is applied.
Default is <code>NULL</code> which means 0.5 / an equal threshold for each class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>,
<code><a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a>()</code>,
<code><a href="#topic+getPredictionResponse">getPredictionResponse</a>()</code>,
<code><a href="#topic+getPredictionTaskDesc">getPredictionTaskDesc</a>()</code>,
<code><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>
<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictType">setPredictType</a>()</code>
</p>

<hr>
<h2 id='setPredictType'>Set the type of predictions the learner should return.</h2><span id='topic+setPredictType'></span>

<h3>Description</h3>

<p>Possible prediction types are:
Classification: Labels or class probabilities (including labels).
Regression: Numeric or response or standard errors (including numeric response).
Survival: Linear predictor or survival probability.
</p>
<p>For complex wrappers the predict type is usually also passed down the
encapsulated learner in a recursive fashion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setPredictType(learner, predict.type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setPredictType_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="setPredictType_+3A_predict.type">predict.type</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Classification: &ldquo;response&rdquo; or &ldquo;prob&rdquo;.
Regression: &ldquo;response&rdquo; or &ldquo;se&rdquo;.
Survival: &ldquo;response&rdquo; (linear predictor) or &ldquo;prob&rdquo;.
Clustering: &ldquo;response&rdquo; or &ldquo;prob&rdquo;.
Default is &ldquo;response&rdquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Learner">Learner</a>.
</p>


<h3>See Also</h3>

<p>Other predict: 
<code><a href="#topic+asROCRPrediction">asROCRPrediction</a>()</code>,
<code><a href="#topic+getPredictionProbabilities">getPredictionProbabilities</a>()</code>,
<code><a href="#topic+getPredictionResponse">getPredictionResponse</a>()</code>,
<code><a href="#topic+getPredictionTaskDesc">getPredictionTaskDesc</a>()</code>,
<code><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>
</p>
<p>Other learner: 
<code><a href="#topic+LearnerProperties">LearnerProperties</a></code>,
<code><a href="#topic+getClassWeightParam">getClassWeightParam</a>()</code>,
<code><a href="#topic+getHyperPars">getHyperPars</a>()</code>,
<code><a href="#topic+getLearnerId">getLearnerId</a>()</code>,
<code><a href="#topic+getLearnerNote">getLearnerNote</a>()</code>,
<code><a href="#topic+getLearnerPackages">getLearnerPackages</a>()</code>,
<code><a href="#topic+getLearnerParVals">getLearnerParVals</a>()</code>,
<code><a href="#topic+getLearnerParamSet">getLearnerParamSet</a>()</code>,
<code><a href="#topic+getLearnerPredictType">getLearnerPredictType</a>()</code>,
<code><a href="#topic+getLearnerShortName">getLearnerShortName</a>()</code>,
<code><a href="#topic+getLearnerType">getLearnerType</a>()</code>,
<code><a href="#topic+getParamSet">getParamSet</a>()</code>,
<code><a href="#topic+helpLearnerParam">helpLearnerParam</a>()</code>,
<code><a href="#topic+helpLearner">helpLearner</a>()</code>,
<code><a href="#topic+makeLearners">makeLearners</a>()</code>,
<code><a href="#topic+makeLearner">makeLearner</a>()</code>,
<code><a href="#topic+removeHyperPars">removeHyperPars</a>()</code>,
<code><a href="#topic+setHyperPars">setHyperPars</a>()</code>,
<code><a href="#topic+setId">setId</a>()</code>,
<code><a href="#topic+setLearnerId">setLearnerId</a>()</code>,
<code><a href="#topic+setPredictThreshold">setPredictThreshold</a>()</code>
</p>

<hr>
<h2 id='setThreshold'>Set threshold of prediction object.</h2><span id='topic+setThreshold'></span>

<h3>Description</h3>

<p>Set threshold of prediction object for classification or multilabel classification.
Creates corresponding discrete class response for the newly set threshold.
For binary classification: The positive class is predicted if the probability value exceeds the threshold.
For multiclass: Probabilities are divided by corresponding thresholds and the class with maximum resulting value is selected.
The result of both are equivalent if in the multi-threshold case the values are greater than 0 and sum to 1.
For multilabel classification: A label is predicted (with entry <code>TRUE</code>) if a probability matrix entry
exceeds the threshold of the corresponding label.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setThreshold(pred, threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setThreshold_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="setThreshold_+3A_threshold">threshold</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Threshold to produce class labels. Has to be a named vector, where names correspond to class labels.
Only for binary classification it can be a single numerical threshold for the positive class.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Prediction">Prediction</a>) with changed threshold and corresponding response.
</p>


<h3>See Also</h3>

<p><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create task and train learner (LDA)
task = makeClassifTask(data = iris, target = "Species")
lrn = makeLearner("classif.lda", predict.type = "prob")
mod = train(lrn, task)

# predict probabilities and compute performance
pred = predict(mod, newdata = iris)
performance(pred, measures = mmce)
head(as.data.frame(pred))

# adjust threshold and predict probabilities again
threshold = c(setosa = 0.4, versicolor = 0.3, virginica = 0.3)
pred = setThreshold(pred, threshold = threshold)
performance(pred, measures = mmce)
head(as.data.frame(pred))
</code></pre>

<hr>
<h2 id='simplifyMeasureNames'>Simplify measure names.</h2><span id='topic+simplifyMeasureNames'></span>

<h3>Description</h3>

<p>Clips aggregation names from character vector.
E.g: 'mmce.test.mean' becomes 'mmce'.
Elements that don't contain a measure name are ignored and returned unchanged.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplifyMeasureNames(xs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simplifyMeasureNames_+3A_xs">xs</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Character vector that (possibly) contains aggregated measure names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+character">character</a>).
</p>

<hr>
<h2 id='smote'>Synthetic Minority Oversampling Technique to handle class imbalancy in binary classification.</h2><span id='topic+smote'></span>

<h3>Description</h3>

<p>In each iteration, samples one minority class element x1, then one of x1's nearest neighbors: x2.
Both points are now interpolated / convex-combined, resulting in a new virtual data point x3
for the minority class.
</p>
<p>The method handles factor features, too. The gower distance is used for nearest neighbor
calculation, see <a href="cluster.html#topic+daisy">cluster::daisy</a>.
For interpolation, the new factor level for x3
is sampled from the two given levels of x1 and x2 per feature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smote(task, rate, nn = 5L, standardize = TRUE, alt.logic = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smote_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="smote_+3A_rate">rate</code></td>
<td>
<p>(<code>numeric(1)</code>)<br />
Factor to upsample the smaller class.
Must be between 1 and <code>Inf</code>,
where 1 means no oversampling and 2 would mean doubling the class size.</p>
</td></tr>
<tr><td><code id="smote_+3A_nn">nn</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of nearest neighbors to consider.
Default is 5.</p>
</td></tr>
<tr><td><code id="smote_+3A_standardize">standardize</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Standardize input variables before calculating the nearest neighbors
for data sets with numeric input variables only. For mixed variables
(numeric and factor) the gower distance is used and variables are
standardized anyway.
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="smote_+3A_alt.logic">alt.logic</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Use an alternative logic for selection of minority class observations.
Instead of sampling a minority class element AND one of its nearest
neighbors, each minority class element is taken multiple times (depending
on rate) for the interpolation and only the corresponding nearest neighbor
is sampled.
Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Task">Task</a>.
</p>


<h3>References</h3>

<p>Chawla, N., Bowyer, K., Hall, L., &amp; Kegelmeyer, P. (2000)
<em>SMOTE: Synthetic Minority Over-sampling TEchnique.</em>
In International Conference of Knowledge Based Computer Systems, pp. 46-57.
National Center for Software Technology, Mumbai, India, Allied Press.
</p>


<h3>See Also</h3>

<p>Other imbalancy: 
<code><a href="#topic+makeOverBaggingWrapper">makeOverBaggingWrapper</a>()</code>,
<code><a href="#topic+makeUndersampleWrapper">makeUndersampleWrapper</a>()</code>,
<code><a href="#topic+oversample">oversample</a>()</code>
</p>

<hr>
<h2 id='sonar.task'>Sonar classification task.</h2><span id='topic+sonar.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>sonar.task</code>).
</p>


<h3>References</h3>

<p>See <a href="mlbench.html#topic+Sonar">mlbench::Sonar</a>.
</p>

<hr>
<h2 id='spam.task'>Spam classification task.</h2><span id='topic+spam.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>spam.task</code>).
</p>


<h3>References</h3>

<p>See <a href="kernlab.html#topic+spam">kernlab::spam</a>.
</p>

<hr>
<h2 id='spatial.task'>J. Muenchow's Ecuador landslide data set</h2><span id='topic+spatial.task'></span>

<h3>Description</h3>

<p>Data set created by Jannes Muenchow, University of Erlangen-Nuremberg,
Germany.
These data should be cited as Muenchow et al. (2012) (see reference below).
This publication also contains additional information on data collection and
the geomorphology of the area. The data set provded here is (a subset of) the
one from the 'natural' part of the RBSF area and corresponds to landslide
distribution in the year 2000.
</p>


<h3>Format</h3>

<p>a <code>data.frame</code> with point samples of landslide and
non-landslide locations in a study area in the Andes of southern Ecuador.
</p>


<h3>References</h3>

<p>Muenchow, J., Brenning, A., Richter, M., 2012. Geomorphic process
rates of landslides along a humidity gradient in the tropical Andes.
Geomorphology, 139-140: 271-284.
</p>
<p>Brenning, A., 2005. Spatial prediction models for landslide hazards:
review, comparison and evaluation.
Natural Hazards and Earth System Sciences, 5(6): 853-862.
</p>

<hr>
<h2 id='subsetTask'>Subset data in task.</h2><span id='topic+subsetTask'></span>

<h3>Description</h3>

<p>See title.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsetTask(task, subset = NULL, features)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsetTask_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="subsetTask_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
<tr><td><code id="subsetTask_+3A_features">features</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a> | <a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a>)<br />
Vector of selected inputs. You can either pass a character vector with the
feature names, a vector of indices, or a logical vector.<br />
In case of an index vector each element denotes the position of the feature
name returned by <a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>.<br />
Note that the target feature is always included in the
resulting task, you should not pass it here.
Default is to use all features.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+Task">Task</a>). Task with subsetted data.
</p>


<h3>See Also</h3>

<p>Other task: 
<code><a href="#topic+getTaskClassLevels">getTaskClassLevels</a>()</code>,
<code><a href="#topic+getTaskCosts">getTaskCosts</a>()</code>,
<code><a href="#topic+getTaskData">getTaskData</a>()</code>,
<code><a href="#topic+getTaskDesc">getTaskDesc</a>()</code>,
<code><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>()</code>,
<code><a href="#topic+getTaskFormula">getTaskFormula</a>()</code>,
<code><a href="#topic+getTaskId">getTaskId</a>()</code>,
<code><a href="#topic+getTaskNFeats">getTaskNFeats</a>()</code>,
<code><a href="#topic+getTaskSize">getTaskSize</a>()</code>,
<code><a href="#topic+getTaskTargetNames">getTaskTargetNames</a>()</code>,
<code><a href="#topic+getTaskTargets">getTaskTargets</a>()</code>,
<code><a href="#topic+getTaskType">getTaskType</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>task = makeClassifTask(data = iris, target = "Species")
subsetTask(task, subset = 1:100)
</code></pre>

<hr>
<h2 id='summarizeColumns'>Summarize columns of data.frame or task.</h2><span id='topic+summarizeColumns'></span>

<h3>Description</h3>

<p>Summarizes a data.frame, somewhat differently than the normal <a href="base.html#topic+summary">summary</a> function of R.
The function is mainly useful as a basic EDA tool on data.frames before they are converted to tasks,
but can be used on tasks as well.
</p>
<p>Columns can be of type numeric, integer, logical, factor, or character.
Characters and logicals will be treated as factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeColumns(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarizeColumns_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+data.frame">data.frame</a>). With columns:
</p>
<table>
<tr><td><code>name</code></td>
<td>
<p>Name of column.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>Data type of column.</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>Number of NAs in column.</p>
</td></tr>
<tr><td><code>disp</code></td>
<td>
<p>Measure of dispersion, for numerics and integers <a href="stats.html#topic+sd">sd</a> is used, for
categorical columns the qualitative variation.</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>Mean value of column, NA for categorical columns.</p>
</td></tr>
<tr><td><code>median</code></td>
<td>
<p>Median value of column, NA for categorical columns.</p>
</td></tr>
<tr><td><code>mad</code></td>
<td>
<p>MAD of column, NA for categorical columns.</p>
</td></tr>
<tr><td><code>min</code></td>
<td>
<p>Minimal value of column, for categorical columns the size of the smallest category.</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>Maximal value of column, for categorical columns the size of the largest category.</p>
</td></tr>
<tr><td><code>nlevs</code></td>
<td>
<p>For categorical columns, the number of factor levels, NA else.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeLevels">summarizeLevels</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarizeColumns(iris)
</code></pre>

<hr>
<h2 id='summarizeLevels'>Summarizes factors of a data.frame by tabling them.</h2><span id='topic+summarizeLevels'></span>

<h3>Description</h3>

<p>Characters and logicals will be treated as factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeLevels(obj, cols = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarizeLevels_+3A_obj">obj</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <a href="#topic+Task">Task</a>)<br />
Input data.</p>
</td></tr>
<tr><td><code id="summarizeLevels_+3A_cols">cols</code></td>
<td>
<p>(<a href="base.html#topic+character">character</a>)<br />
Restrict result to columns in <code>cols</code>.
Default is all factor, character and logical columns of <code>obj</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). Named list of tables.
</p>


<h3>See Also</h3>

<p>Other eda_and_preprocess: 
<code><a href="#topic+capLargeValues">capLargeValues</a>()</code>,
<code><a href="#topic+createDummyFeatures">createDummyFeatures</a>()</code>,
<code><a href="#topic+dropFeatures">dropFeatures</a>()</code>,
<code><a href="#topic+mergeSmallFactorLevels">mergeSmallFactorLevels</a>()</code>,
<code><a href="#topic+normalizeFeatures">normalizeFeatures</a>()</code>,
<code><a href="#topic+removeConstantFeatures">removeConstantFeatures</a>()</code>,
<code><a href="#topic+summarizeColumns">summarizeColumns</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>summarizeLevels(iris)
</code></pre>

<hr>
<h2 id='Task'>Create a classification, regression, survival, cluster, cost-sensitive classification or
multilabel task.</h2><span id='topic+Task'></span>

<h3>Description</h3>

<p>The task encapsulates the data and specifies - through its subclasses -
the type of the task.
It also contains a description object detailing further aspects of the data.
</p>
<p>Useful operators are:
</p>

<ul>
<li> <p><a href="#topic+getTaskFormula">getTaskFormula</a>,
</p>
</li>
<li> <p><a href="#topic+getTaskFeatureNames">getTaskFeatureNames</a>,
</p>
</li>
<li> <p><a href="#topic+getTaskData">getTaskData</a>,
</p>
</li>
<li> <p><a href="#topic+getTaskTargets">getTaskTargets</a>, and
</p>
</li>
<li> <p><a href="#topic+subsetTask">subsetTask</a>.
</p>
</li></ul>

<p>Object members:
</p>

<dl>
<dt>env (<code>environment</code>)</dt><dd><p>Environment where data for the task are stored.
Use <a href="#topic+getTaskData">getTaskData</a> in order to access it.</p>
</dd>
<dt>weights (<a href="base.html#topic+numeric">numeric</a>)</dt><dd><p>See argument. <code>NULL</code> if not present.</p>
</dd>
<dt>blocking (<a href="base.html#topic+factor">factor</a>)</dt><dd><p>See argument. <code>NULL</code> if not present.</p>
</dd>
<dt>task.desc (<a href="#topic+TaskDesc">TaskDesc</a>)</dt><dd><p>Encapsulates further information about the task.</p>
</dd>
</dl>

<p>Functional data can be added to a task via matrix columns. For more information refer to
<a href="#topic+makeFunctionalData">makeFunctionalData</a>.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="Task_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Id string for object.
Default is the name of the R variable passed to <code>data</code>.</p>
</td></tr>
<tr><td><code id="Task_+3A_data">data</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A data frame containing the features and target variable(s).</p>
</td></tr>
<tr><td><code id="Task_+3A_target">target</code></td>
<td>
<p>(<code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)<br />
Name(s) of the target variable(s).
For survival analysis these are the names of the survival time and event columns,
so it has length 2. For multilabel classification it contains the names of the logical
columns that encode whether a label is present or not and its length corresponds to the
number of classes.</p>
</td></tr>
<tr><td><code id="Task_+3A_costs">costs</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
A numeric matrix or data frame containing the costs of misclassification.
We assume the general case of observation specific costs.
This means we have n rows, corresponding to the observations, in the same order as <code>data</code>.
The columns correspond to classes and their names are the class labels
(if unnamed we use y1 to yk as labels).
Each entry (i,j) of the matrix specifies the cost of predicting class j
for observation i.</p>
</td></tr>
<tr><td><code id="Task_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
Cannot be set for cost-sensitive learning.
Default is <code>NULL</code> which means no (= equal) weights.</p>
</td></tr>
<tr><td><code id="Task_+3A_blocking">blocking</code></td>
<td>
<p>(<a href="base.html#topic+factor">factor</a>)<br />
An optional factor of the same length as the number of observations.
Observations with the same blocking level &ldquo;belong together&rdquo;.
Specifically, they are either put all in the training or the test set
during a resampling iteration.
Default is <code>NULL</code> which means no blocking.</p>
</td></tr>
<tr><td><code id="Task_+3A_positive">positive</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Positive class for binary classification (otherwise ignored and set to NA).
Default is the first factor level of the target attribute.</p>
</td></tr>
<tr><td><code id="Task_+3A_fixup.data">fixup.data</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Should some basic cleaning up of data be performed?
Currently this means removing empty factor levels for the columns.
Possible choices are:
&ldquo;no&rdquo; = Don't do it.
&ldquo;warn&rdquo; = Do it but warn about it.
&ldquo;quiet&rdquo; = Do it but keep silent.
Default is &ldquo;warn&rdquo;.</p>
</td></tr>
<tr><td><code id="Task_+3A_check.data">check.data</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should sanity of data be checked initially at task creation?
You should have good reasons to turn this off (one might be speed).
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="Task_+3A_coordinates">coordinates</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a>)<br />
Coordinates of a spatial data set that will be used for spatial partitioning of the data in a spatial cross-validation resampling setting.
Coordinates have to be numeric values.
Provided <a href="base.html#topic+data.frame">data.frame</a> needs to have the same number of rows as data and consist of at least two dimensions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="#topic+Task">Task</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ClassifTask">ClassifTask</a> <a href="#topic+ClusterTask">ClusterTask</a> <a href="#topic+CostSensTask">CostSensTask</a> <a href="#topic+MultilabelTask">MultilabelTask</a> <a href="#topic+RegrTask">RegrTask</a> <a href="#topic+SurvTask">SurvTask</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("mlbench")) {
  library(mlbench)
  data(BostonHousing)
  data(Ionosphere)

  makeClassifTask(data = iris, target = "Species")
  makeRegrTask(data = BostonHousing, target = "medv")
  # an example of a classification task with more than those standard arguments:
  blocking = factor(c(rep(1, 51), rep(2, 300)))
  makeClassifTask(id = "myIonosphere", data = Ionosphere, target = "Class",
    positive = "good", blocking = blocking)
  makeClusterTask(data = iris[, -5L])
}
</code></pre>

<hr>
<h2 id='TaskDesc'>Description object for task.</h2><span id='topic+TaskDesc'></span>

<h3>Description</h3>

<p>Description object for task, encapsulates basic properties of the task
without having to store the complete data set.
</p>


<h3>Details</h3>

<p>Object members:
</p>

<dl>
<dt>id (<code>character(1)</code>)</dt><dd><p>Id string of task.</p>
</dd>
<dt>type (<code>character(1)</code>)</dt><dd><p>Type of task, &ldquo;classif&rdquo; for classification,
&ldquo;regr&rdquo; for regression, &ldquo;surv&rdquo; for survival and &ldquo;cluster&rdquo; for
cluster analysis, &ldquo;costsens&rdquo; for cost-sensitive classification, and
&ldquo;multilabel&rdquo; for multilabel classification.</p>
</dd>
<dt>target (<code>character(0)</code> | <code>character(1)</code> | <code>character(2)</code> | <code>character(n.classes)</code>)</dt><dd>
<p>Name(s) of the target variable(s).
For &ldquo;surv&rdquo; these are the names of the survival time and event columns, so it has length 2.
For &ldquo;costsens&rdquo; it has length 0, as there is no target column, but a cost matrix instead.
For &ldquo;multilabel&rdquo; these are the names of logical columns that indicate whether a
class label is present and the number of target variables corresponds to the number of
classes.</p>
</dd>
<dt>size (<code>integer(1)</code>)</dt><dd><p>Number of cases in data set.</p>
</dd>
<dt>n.feat (<code>integer(2)</code>)</dt><dd><p>Number of features, named vector with entries:
&ldquo;numerics&rdquo;, &ldquo;factors&rdquo;, &ldquo;ordered&rdquo;, &ldquo;functionals&rdquo;.</p>
</dd>
<dt>has.missings (<code>logical(1)</code>)</dt><dd><p>Are missing values present?</p>
</dd>
<dt>has.weights (<code>logical(1)</code>)</dt><dd><p>Are weights specified for each observation?</p>
</dd>
<dt>has.blocking (<code>logical(1)</code>)</dt><dd><p>Is a blocking factor for cases available in the task?</p>
</dd>
<dt>class.levels (<a href="base.html#topic+character">character</a>)</dt><dd><p>All possible classes.
Only present for &ldquo;classif&rdquo;, &ldquo;costsens&rdquo;, and &ldquo;multilabel&rdquo;.</p>
</dd>
<dt>positive (<code>character(1)</code>)</dt><dd><p>Positive class label for binary classification.
Only present for &ldquo;classif&rdquo;, NA for multiclass.</p>
</dd>
<dt>negative (<code>character(1)</code>)</dt><dd><p>Negative class label for binary classification.
Only present for &ldquo;classif&rdquo;, NA for multiclass.</p>
</dd>
</dl>


<hr>
<h2 id='train'>Train a learning algorithm.</h2><span id='topic+train'></span>

<h3>Description</h3>

<p>Given a <a href="#topic+Task">Task</a>, creates a model for the learning machine
which can be used for predictions on new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train(learner, task, subset = NULL, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="train_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="train_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="train_+3A_subset">subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a> | <a href="base.html#topic+logical">logical</a> | <code>NULL</code>)<br />
Selected cases. Either a logical or an index vector.
By default <code>NULL</code> if all observations are used.</p>
</td></tr>
<tr><td><code id="train_+3A_weights">weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Optional, non-negative case weight vector to be used during fitting.
If given, must be of same length as <code>subset</code> and in corresponding order.
By default <code>NULL</code> which means no weights are used unless specified in the task (<a href="#topic+Task">Task</a>).
Weights from the task will be overwritten.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+WrappedModel">WrappedModel</a>).
</p>


<h3>See Also</h3>

<p><a href="#topic+predict.WrappedModel">predict.WrappedModel</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>training.set = sample(seq_len(nrow(iris)), nrow(iris) / 2)

## use linear discriminant analysis to classify iris data
task = makeClassifTask(data = iris, target = "Species")
learner = makeLearner("classif.lda", method = "mle")
mod = train(learner, task, subset = training.set)
print(mod)

## use random forest to classify iris data
task = makeClassifTask(data = iris, target = "Species")
learner = makeLearner("classif.rpart", minsplit = 7, predict.type = "prob")
mod = train(learner, task, subset = training.set)
print(mod)
</code></pre>

<hr>
<h2 id='trainLearner'>Train an R learner.</h2><span id='topic+trainLearner'></span>

<h3>Description</h3>

<p>Mainly for internal use. Trains a wrapped learner on a given training set.
You have to implement this method if you want to add another learner to this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trainLearner(.learner, .task, .subset, .weights = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trainLearner_+3A_.learner">.learner</code></td>
<td>
<p>(<a href="#topic+RLearner">RLearner</a>)<br />
Wrapped learner.</p>
</td></tr>
<tr><td><code id="trainLearner_+3A_.task">.task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
Task to train learner on.</p>
</td></tr>
<tr><td><code id="trainLearner_+3A_.subset">.subset</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Subset of cases for training set, index the task with this.
You probably want to use <a href="#topic+getTaskData">getTaskData</a> for this purpose.</p>
</td></tr>
<tr><td><code id="trainLearner_+3A_.weights">.weights</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
Weights for each observation.</p>
</td></tr>
<tr><td><code id="trainLearner_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional (hyper)parameters, which need to be passed to the underlying train function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Your implementation must adhere to the following:
The model must be fitted on the subset of <code>.task</code> given by <code>.subset</code>. All parameters
in <code>...</code> must be passed to the underlying training function.
</p>


<h3>Value</h3>

<p>(any). Model of the underlying learner.
</p>

<hr>
<h2 id='TuneControl'>Control object for tuning</h2><span id='topic+TuneControl'></span>

<h3>Description</h3>

<p>General tune control object.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="TuneControl_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_start">start</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Named list of initial parameter values.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="TuneControl_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further control parameters passed to the <code>control</code> arguments of
<a href="cmaes.html#topic+cma_es">cmaes::cma_es</a> or <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a>, as well as
towards the <code>tunerConfig</code> argument of <a href="irace.html#topic+irace">irace::irace</a>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>

<hr>
<h2 id='TuneMultiCritControl'>Create control structures for multi-criteria tuning.</h2><span id='topic+TuneMultiCritControl'></span><span id='topic+TuneMultiCritControlGrid'></span><span id='topic+TuneMultiCritControlRandom'></span><span id='topic+TuneMultiCritControlNSGA2'></span><span id='topic+TuneMultiCritControlMBO'></span><span id='topic+makeTuneMultiCritControlGrid'></span><span id='topic+makeTuneMultiCritControlMBO'></span><span id='topic+makeTuneMultiCritControlNSGA2'></span><span id='topic+makeTuneMultiCritControlRandom'></span>

<h3>Description</h3>

<p>The following tuners are available:
</p>

<dl>
<dt>makeTuneMultiCritControlGrid</dt><dd><p>Grid search. All kinds of parameter types can be handled.
You can either use their correct param type and <code>resolution</code>,
or discretize them yourself by always using <a href="ParamHelpers.html#topic+Param">ParamHelpers::makeDiscreteParam</a>
in the <code>par.set</code> passed to <a href="#topic+tuneParams">tuneParams</a>.</p>
</dd>
<dt>makeTuneMultiCritControlRandom</dt><dd><p>Random search. All kinds of parameter types can be handled.</p>
</dd>
<dt>makeTuneMultiCritControlNSGA2</dt><dd><p>Evolutionary method <a href="mco.html#topic+nsga2">mco::nsga2</a>.
Can handle numeric(vector) and integer(vector) hyperparameters, but no dependencies.
For integers the internally proposed numeric values are automatically rounded.</p>
</dd>
<dt>makeTuneMultiCritControlMBO</dt><dd><p>Model-based/ Bayesian optimization. All kinds of
parameter types can be handled.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>makeTuneMultiCritControlGrid(
  same.resampling.instance = TRUE,
  resolution = 10L,
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL
)

makeTuneMultiCritControlMBO(
  n.objectives = mbo.control$n.objectives,
  same.resampling.instance = TRUE,
  impute.val = NULL,
  learner = NULL,
  mbo.control = NULL,
  tune.threshold = FALSE,
  tune.threshold.args = list(),
  continue = FALSE,
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  mbo.design = NULL
)

makeTuneMultiCritControlNSGA2(
  same.resampling.instance = TRUE,
  impute.val = NULL,
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL,
  ...
)

makeTuneMultiCritControlRandom(
  same.resampling.instance = TRUE,
  maxit = 100L,
  log.fun = "default",
  final.dw.perc = NULL,
  budget = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TuneMultiCritControl_+3A_same.resampling.instance">same.resampling.instance</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the same resampling instance be used for all evaluations to reduce variance?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_resolution">resolution</code></td>
<td>
<p>(<a href="base.html#topic+integer">integer</a>)<br />
Resolution of the grid for each numeric/integer parameter in <code>par.set</code>.
For vector parameters, it is the resolution per dimension.
Either pass one resolution for all parameters, or a named vector.
See <a href="ParamHelpers.html#topic+generateGridDesign">ParamHelpers::generateGridDesign</a>.
Default is 10.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_log.fun">log.fun</code></td>
<td>
<p>(<code>function</code> | <code>character(1)</code>)<br />
Function used for logging. If set to &ldquo;default&rdquo; (the default), the evaluated design points, the resulting
performances, and the runtime will be reported.
If set to &ldquo;memory&rdquo; the memory usage for each evaluation will also be displayed, with <code>character(1)</code> small increase
in run time.
Otherwise <code>character(1)</code> function with arguments <code>learner</code>, <code>resampling</code>, <code>measures</code>,
<code>par.set</code>, <code>control</code>, <code>opt.path</code>, <code>dob</code>, <code>x</code>, <code>y</code>, <code>remove.nas</code>,
<code>stage</code> and <code>prev.stage</code> is expected.
The default displays the performance measures, the time needed for evaluating,
the currently used memory and the max memory ever used before
(the latter two both taken from <a href="base.html#topic+gc">gc</a>).
See the implementation for details.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_final.dw.perc">final.dw.perc</code></td>
<td>
<p>(<code>boolean</code>)<br />
If a Learner wrapped by a <a href="#topic+makeDownsampleWrapper">makeDownsampleWrapper</a> is used, you can define the value of <code>dw.perc</code> which is used to train the Learner with the final parameter setting found by the tuning.
Default is <code>NULL</code> which will not change anything.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_budget">budget</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Maximum budget for tuning. This value restricts the number of function
evaluations. In case of <code>makeTuneMultiCritControlGrid</code> this number
must be identical to the size of the grid. For
<code>makeTuneMultiCritControlRandom</code> the <code>budget</code> equals the number
of iterations (<code>maxit</code>) performed by the random search algorithm.
In case of <code>makeTuneMultiCritControlNSGA2</code> the <code>budget</code>
corresponds to the product of the maximum number of generations
(<code>max(generations)</code>) + 1 (for the initial population) and the size of
the population (<code>popsize</code>). For <code>makeTuneMultiCritControlMBO</code> the
<code>budget</code> equals the number of objective function evaluations, i.e. the
number of MBO iterations + the size of the initial design. If not <code>NULL</code>,
this will overwrite existing stopping conditions in <code>mbo.control</code>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_n.objectives">n.objectives</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of objectives, i.e. number of <a href="#topic+Measure">Measure</a>s to optimize.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_impute.val">impute.val</code></td>
<td>
<p>(<a href="base.html#topic+numeric">numeric</a>)<br />
If something goes wrong during optimization (e.g. the learner crashes),
this value is fed back to the tuner, so the tuning algorithm does not abort.
Imputation is only active if <code>on.learner.error</code> is configured not to stop in <a href="#topic+configureMlr">configureMlr</a>.
It is not stored in the optimization path, an NA and a corresponding error message are
logged instead.
Note that this value is later multiplied by -1 for maximization measures internally, so you
need to enter a larger positive value for maximization here as well.
Default is the worst obtainable value of the performance measure you optimize for when
you aggregate by mean value, or <code>Inf</code> instead.
For multi-criteria optimization pass a vector of imputation values, one for each of your measures,
in the same order as your measures.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>NULL</code>)<br />
The surrogate learner: A regression learner to model performance landscape.
For the default, <code>NULL</code>, <span class="pkg">mlrMBO</span> will automatically create a suitable learner based on the rules described in <a href="mlrMBO.html#topic+makeMBOLearner">mlrMBO::makeMBOLearner</a>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_mbo.control">mbo.control</code></td>
<td>
<p>(<a href="mlrMBO.html#topic+makeMBOControl">mlrMBO::MBOControl</a> | <code>NULL</code>)<br />
Control object for model-based optimization tuning.
For the default, <code>NULL</code>, the control object will be created with all the defaults as described in <a href="mlrMBO.html#topic+makeMBOControl">mlrMBO::makeMBOControl</a>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_tune.threshold">tune.threshold</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Should the threshold be tuned for the measure at hand, after each hyperparameter evaluation,
via <a href="#topic+tuneThreshold">tuneThreshold</a>?
Only works for classification if the predict type is &ldquo;prob&rdquo;.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_tune.threshold.args">tune.threshold.args</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Further arguments for threshold tuning that are passed down to <a href="#topic+tuneThreshold">tuneThreshold</a>.
Default is none.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_continue">continue</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Resume calculation from previous run using <a href="mlrMBO.html#topic+mboContinue">mlrMBO::mboContinue</a>?
Requires &ldquo;save.file.path&rdquo; to be set.
Note that the <a href="ParamHelpers.html#topic+OptPath">ParamHelpers::OptPath</a> in the <a href="mlrMBO.html#topic+OptResult">mlrMBO::OptResult</a>
will only include the evaluations after the continuation.
The complete OptPath will be found in the slot <code style="white-space: pre;">&#8288;$mbo.result$opt.path&#8288;</code>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_mbo.design">mbo.design</code></td>
<td>
<p>(<a href="base.html#topic+data.frame">data.frame</a> | <code>NULL</code>)<br />
Initial design as data frame.
If the parameters have corresponding trafo functions,
the design must not be transformed before it is passed!
For the default, <code>NULL</code>, a default design is created like described in <a href="mlrMBO.html#topic+mbo">mlrMBO::mbo</a>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further control parameters passed to the <code>control</code> arguments of
<a href="cmaes.html#topic+cma_es">cmaes::cma_es</a> or <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a>, as well as
towards the <code>tunerConfig</code> argument of <a href="irace.html#topic+irace">irace::irace</a>.</p>
</td></tr>
<tr><td><code id="TuneMultiCritControl_+3A_maxit">maxit</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Number of iterations for random search.
Default is 100.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneMultiCritControl">TuneMultiCritControl</a>). The specific subclass is one of
<a href="#topic+TuneMultiCritControlGrid">TuneMultiCritControlGrid</a>, <a href="#topic+TuneMultiCritControlRandom">TuneMultiCritControlRandom</a>,
<a href="#topic+TuneMultiCritControlNSGA2">TuneMultiCritControlNSGA2</a>, <a href="#topic+TuneMultiCritControlMBO">TuneMultiCritControlMBO</a>.
</p>


<h3>See Also</h3>

<p>Other tune_multicrit: 
<code><a href="#topic+plotTuneMultiCritResult">plotTuneMultiCritResult</a>()</code>,
<code><a href="#topic+tuneParamsMultiCrit">tuneParamsMultiCrit</a>()</code>
</p>

<hr>
<h2 id='TuneMultiCritResult'>Result of multi-criteria tuning.</h2><span id='topic+TuneMultiCritResult'></span>

<h3>Description</h3>

<p>Container for results of hyperparameter tuning.
Contains the obtained pareto set and front
and the optimization path which lead there.
</p>
<p>Object members:
</p>

<dl>
<dt>learner (<a href="#topic+Learner">Learner</a>)</dt><dd><p>Learner that was optimized.</p>
</dd>
<dt>control (<a href="#topic+TuneControl">TuneControl</a>)</dt><dd><p>Control object from tuning.</p>
</dd>
<dt>x (<a href="base.html#topic+list">list</a>)</dt><dd><p>List of lists of non-dominated hyperparameter settings in pareto set.
Note that when you have trafos on some of your params, <code>x</code> will always be
on the TRANSFORMED scale so you directly use it.</p>
</dd>
<dt>y (<a href="base.html#topic+matrix">matrix</a>)</dt><dd><p>Pareto front for <code>x</code>.</p>
</dd>
<dt>threshold</dt><dd><p>Currently <code>NULL</code>.</p>
</dd>
<dt>opt.path (<a href="ParamHelpers.html#topic+OptPath">ParamHelpers::OptPath</a>)</dt><dd><p>Optimization path which lead to <code>x</code>.
Note that when you have trafos on some of your params, the opt.path always contains the
UNTRANSFORMED values on the original scale. You can simply call <code>trafoOptPath(opt.path)</code> to
transform them, or, <code>as.data.frame{trafoOptPath(opt.path)}</code></p>
</dd>
<dt>ind (<code>integer(n)</code>)</dt><dd><p>Indices of Pareto optimal params in <code>opt.path</code>.</p>
</dd>
<dt>measures [(list of) <a href="#topic+Measure">Measure</a>)</dt><dd><p>Performance measures.</p>
</dd>
</dl>


<hr>
<h2 id='tuneParams'>Hyperparameter tuning.</h2><span id='topic+tuneParams'></span>

<h3>Description</h3>

<p>Optimizes the hyperparameters of a learner.
Allows for different optimization methods, such as grid search, evolutionary strategies,
iterated F-race, etc. You can select such an algorithm (and its settings)
by passing a corresponding control object. For a complete list of implemented algorithms look at
<a href="#topic+TuneControl">TuneControl</a>.
</p>
<p>Multi-criteria tuning can be done with <a href="#topic+tuneParamsMultiCrit">tuneParamsMultiCrit</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneParams(
  learner,
  task,
  resampling,
  measures,
  par.set,
  control,
  show.info = getMlrOption("show.info"),
  resample.fun = resample
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneParams_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleInstance">ResampleInstance</a> | <a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy to evaluate points in hyperparameter space. If you pass a description,
it is instantiated once at the beginning by default, so all points are
evaluated on the same training/test sets.
If you want to change that behavior, look at <a href="#topic+TuneControl">TuneControl</a>.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_measures">measures</code></td>
<td>
<p>(list of <a href="#topic+Measure">Measure</a> | <a href="#topic+Measure">Measure</a>)<br />
Performance measures to evaluate. The first measure, aggregated by the first aggregation function
is optimized, others are simply evaluated.
Default is the default measure for the task, see here <a href="#topic+getDefaultMeasure">getDefaultMeasure</a>.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_par.set">par.set</code></td>
<td>
<p>(<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a>)<br />
Collection of parameters and their constraints for optimization.
Dependent parameters with a <code>requires</code> field must use <code>quote</code> and not
<code>expression</code> to define it.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_control">control</code></td>
<td>
<p>(<a href="#topic+TuneControl">TuneControl</a>)<br />
Control object for search method. Also selects the optimization algorithm for tuning.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
<tr><td><code id="tuneParams_+3A_resample.fun">resample.fun</code></td>
<td>
<p>(<a href="base.html#topic+closure">closure</a>)<br />
The function to use for resampling. Defaults to <a href="#topic+resample">resample</a>. If a user-given function
is to be used instead, it should take the arguments &ldquo;learner&rdquo;, &ldquo;task&rdquo;, &ldquo;resampling&rdquo;,
&ldquo;measures&rdquo;, and &ldquo;show.info&rdquo;; see <a href="#topic+resample">resample</a>. Within this function,
it is easiest to call <a href="#topic+resample">resample</a> and possibly modify the result.
However, it is possible to return a list with only the following essential slots:
the &ldquo;aggr&rdquo; slot for general tuning, additionally the &ldquo;pred&rdquo; slot if threshold tuning is performed
(see <a href="#topic+TuneControl">TuneControl</a>), and the &ldquo;err.msgs&rdquo; and &ldquo;err.dumps&rdquo; slots for error reporting.
This parameter must be the default when <code>mbo</code> tuning is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneResult">TuneResult</a>).
</p>


<h3>Note</h3>

<p>If you would like to include results from the training data set, make
sure to appropriately adjust the resampling strategy and the aggregation for
the measure. See example code below.
</p>


<h3>See Also</h3>

<p><a href="#topic+generateHyperParsEffectData">generateHyperParsEffectData</a>
</p>
<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneThreshold">tuneThreshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
# a grid search for an SVM (with a tiny number of points...)
# note how easily we can optimize on a log-scale
ps = makeParamSet(
  makeNumericParam("C", lower = -12, upper = 12, trafo = function(x) 2^x),
  makeNumericParam("sigma", lower = -12, upper = 12, trafo = function(x) 2^x)
)
ctrl = makeTuneControlGrid(resolution = 2L)
rdesc = makeResampleDesc("CV", iters = 2L)
res = tuneParams("classif.ksvm", iris.task, rdesc, par.set = ps, control = ctrl)
print(res)
# access data for all evaluated points
df = as.data.frame(res$opt.path)
df1 = as.data.frame(res$opt.path, trafo = TRUE)
print(head(df[, -ncol(df)]))
print(head(df1[, -ncol(df)]))
# access data for all evaluated points - alternative
df2 = generateHyperParsEffectData(res)
df3 = generateHyperParsEffectData(res, trafo = TRUE)
print(head(df2$data[, -ncol(df2$data)]))
print(head(df3$data[, -ncol(df3$data)]))
## Not run: 
# we optimize the SVM over 3 kernels simultanously
# note how we use dependent params (requires = ...) and iterated F-racing here
ps = makeParamSet(
  makeNumericParam("C", lower = -12, upper = 12, trafo = function(x) 2^x),
  makeDiscreteParam("kernel", values = c("vanilladot", "polydot", "rbfdot")),
  makeNumericParam("sigma", lower = -12, upper = 12, trafo = function(x) 2^x,
    requires = quote(kernel == "rbfdot")),
  makeIntegerParam("degree", lower = 2L, upper = 5L,
    requires = quote(kernel == "polydot"))
)
print(ps)
ctrl = makeTuneControlIrace(maxExperiments = 5, nbIterations = 1, minNbSurvival = 1)
rdesc = makeResampleDesc("Holdout")
res = tuneParams("classif.ksvm", iris.task, rdesc, par.set = ps, control = ctrl)
print(res)
df = as.data.frame(res$opt.path)
print(head(df[, -ncol(df)]))

# include the training set performance as well
rdesc = makeResampleDesc("Holdout", predict = "both")
res = tuneParams("classif.ksvm", iris.task, rdesc, par.set = ps,
  control = ctrl, measures = list(mmce, setAggregation(mmce, train.mean)))
print(res)
df2 = as.data.frame(res$opt.path)
print(head(df2[, -ncol(df2)]))

## End(Not run)
</code></pre>

<hr>
<h2 id='tuneParamsMultiCrit'>Hyperparameter tuning for multiple measures at once.</h2><span id='topic+tuneParamsMultiCrit'></span>

<h3>Description</h3>

<p>Optimizes the hyperparameters of a learner in a multi-criteria fashion.
Allows for different optimization methods, such as grid search, evolutionary strategies, etc.
You can select such an algorithm (and its settings)
by passing a corresponding control object. For a complete list of implemented algorithms look at
<a href="#topic+TuneMultiCritControl">TuneMultiCritControl</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneParamsMultiCrit(
  learner,
  task,
  resampling,
  measures,
  par.set,
  control,
  show.info = getMlrOption("show.info"),
  resample.fun = resample
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneParamsMultiCrit_+3A_learner">learner</code></td>
<td>
<p>(<a href="#topic+Learner">Learner</a> | <code>character(1)</code>)<br />
The learner.
If you pass a string the learner will be created via <a href="#topic+makeLearner">makeLearner</a>.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
The task.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_resampling">resampling</code></td>
<td>
<p>(<a href="#topic+ResampleInstance">ResampleInstance</a> | <a href="#topic+ResampleDesc">ResampleDesc</a>)<br />
Resampling strategy to evaluate points in hyperparameter space. If you pass a description,
it is instantiated once at the beginning by default, so all points are
evaluated on the same training/test sets.
If you want to change that behavior, look at <a href="#topic+TuneMultiCritControl">TuneMultiCritControl</a>.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_measures">measures</code></td>
<td>
<p>[list of <a href="#topic+Measure">Measure</a>)<br />
Performance measures to optimize simultaneously.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_par.set">par.set</code></td>
<td>
<p>(<a href="ParamHelpers.html#topic+makeParamSet">ParamHelpers::ParamSet</a>)<br />
Collection of parameters and their constraints for optimization.
Dependent parameters with a <code>requires</code> field must use <code>quote</code> and not
<code>expression</code> to define it.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_control">control</code></td>
<td>
<p>(<a href="#topic+TuneMultiCritControl">TuneMultiCritControl</a>)<br />
Control object for search method. Also selects the optimization algorithm for tuning.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_show.info">show.info</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Print verbose output on console?
Default is set via <a href="#topic+configureMlr">configureMlr</a>.</p>
</td></tr>
<tr><td><code id="tuneParamsMultiCrit_+3A_resample.fun">resample.fun</code></td>
<td>
<p>(<a href="base.html#topic+closure">closure</a>)<br />
The function to use for resampling. Defaults to <a href="#topic+resample">resample</a> and should take the
same arguments as, and return the same result type as, <a href="#topic+resample">resample</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="#topic+TuneMultiCritResult">TuneMultiCritResult</a>).
</p>


<h3>See Also</h3>

<p>Other tune_multicrit: 
<code><a href="#topic+TuneMultiCritControl">TuneMultiCritControl</a></code>,
<code><a href="#topic+plotTuneMultiCritResult">plotTuneMultiCritResult</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# multi-criteria optimization of (tpr, fpr) with NGSA-II
lrn = makeLearner("classif.ksvm")
rdesc = makeResampleDesc("Holdout")
ps = makeParamSet(
  makeNumericParam("C", lower = -12, upper = 12, trafo = function(x) 2^x),
  makeNumericParam("sigma", lower = -12, upper = 12, trafo = function(x) 2^x)
)
ctrl = makeTuneMultiCritControlNSGA2(popsize = 4L, generations = 1L)
res = tuneParamsMultiCrit(lrn, sonar.task, rdesc, par.set = ps,
  measures = list(tpr, fpr), control = ctrl)
plotTuneMultiCritResult(res, path = TRUE)

</code></pre>

<hr>
<h2 id='TuneResult'>Result of tuning.</h2><span id='topic+TuneResult'></span>

<h3>Description</h3>

<p>Container for results of hyperparameter tuning.
Contains the obtained point in search space, its performance values
and the optimization path which lead there.
</p>
<p>Object members:
</p>

<dl>
<dt>learner (<a href="#topic+Learner">Learner</a>)</dt><dd><p>Learner that was optimized.</p>
</dd>
<dt>control (<a href="#topic+TuneControl">TuneControl</a>)</dt><dd><p>Control object from tuning.</p>
</dd>
<dt>x (<a href="base.html#topic+list">list</a>)</dt><dd><p>Named list of hyperparameter values identified as optimal.
Note that when you have trafos on some of your params, <code>x</code> will always be
on the TRANSFORMED scale so you directly use it.</p>
</dd>
<dt>y (<a href="base.html#topic+numeric">numeric</a>)</dt><dd><p>Performance values for optimal <code>x</code>.</p>
</dd>
<dt>threshold (<a href="base.html#topic+numeric">numeric</a>)</dt><dd><p>Vector of finally found and used thresholds
if <code>tune.threshold</code> was enabled in <a href="#topic+TuneControl">TuneControl</a>, otherwise not present and
hence <code>NULL</code>.</p>
</dd>
<dt>opt.path (<a href="ParamHelpers.html#topic+OptPath">ParamHelpers::OptPath</a>)</dt><dd><p>Optimization path which lead to <code>x</code>.
Note that when you have trafos on some of your params, the opt.path always contains the
UNTRANSFORMED values on the original scale. You can simply call <code>trafoOptPath(opt.path)</code> to
transform them, or, <code>as.data.frame{trafoOptPath(opt.path)}</code>.
If mlr option <code>on.error.dump</code> is <code>TRUE</code>, <code>OptPath</code> will have a <code>.dump</code> object
in its <code>extra</code> column which contains error dump traces from failed optimization evaluations.
It can be accessed by <code>getOptPathEl(opt.path)$extra$.dump</code>.</p>
</dd>
</dl>


<hr>
<h2 id='tuneThreshold'>Tune prediction threshold.</h2><span id='topic+tuneThreshold'></span>

<h3>Description</h3>

<p>Optimizes the threshold of predictions based on probabilities.
Works for classification and multilabel tasks.
Uses <a href="BBmisc.html#topic+optimizeSubInts">BBmisc::optimizeSubInts</a> for normal binary class problems and
<a href="GenSA.html#topic+GenSA">GenSA::GenSA</a> for multiclass and multilabel problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneThreshold(pred, measure, task, model, nsub = 20L, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tuneThreshold_+3A_pred">pred</code></td>
<td>
<p>(<a href="#topic+Prediction">Prediction</a>)<br />
Prediction object.</p>
</td></tr>
<tr><td><code id="tuneThreshold_+3A_measure">measure</code></td>
<td>
<p>(<a href="#topic+Measure">Measure</a>)<br />
Performance measure to optimize.
Default is the default measure for the task.</p>
</td></tr>
<tr><td><code id="tuneThreshold_+3A_task">task</code></td>
<td>
<p>(<a href="#topic+Task">Task</a>)<br />
Learning task. Rarely neeeded,
only when required for the performance measure.</p>
</td></tr>
<tr><td><code id="tuneThreshold_+3A_model">model</code></td>
<td>
<p>(<a href="#topic+WrappedModel">WrappedModel</a>)<br />
Fitted model. Rarely neeeded,
only when required for the performance measure.</p>
</td></tr>
<tr><td><code id="tuneThreshold_+3A_nsub">nsub</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
Passed to <a href="BBmisc.html#topic+optimizeSubInts">BBmisc::optimizeSubInts</a> for 2class problems.
Default is 20.</p>
</td></tr>
<tr><td><code id="tuneThreshold_+3A_control">control</code></td>
<td>
<p>(<a href="base.html#topic+list">list</a>)<br />
Control object for <a href="GenSA.html#topic+GenSA">GenSA::GenSA</a> when used.
Default is empty list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<a href="base.html#topic+list">list</a>). A named list with with the following components:
<code>th</code> is the optimal threshold, <code>perf</code> the performance value.
</p>


<h3>See Also</h3>

<p>Other tune: 
<code><a href="#topic+TuneControl">TuneControl</a></code>,
<code><a href="#topic+getNestedTuneResultsOptPathDf">getNestedTuneResultsOptPathDf</a>()</code>,
<code><a href="#topic+getNestedTuneResultsX">getNestedTuneResultsX</a>()</code>,
<code><a href="#topic+getResamplingIndices">getResamplingIndices</a>()</code>,
<code><a href="#topic+getTuneResult">getTuneResult</a>()</code>,
<code><a href="#topic+makeModelMultiplexerParamSet">makeModelMultiplexerParamSet</a>()</code>,
<code><a href="#topic+makeModelMultiplexer">makeModelMultiplexer</a>()</code>,
<code><a href="#topic+makeTuneControlCMAES">makeTuneControlCMAES</a>()</code>,
<code><a href="#topic+makeTuneControlDesign">makeTuneControlDesign</a>()</code>,
<code><a href="#topic+makeTuneControlGenSA">makeTuneControlGenSA</a>()</code>,
<code><a href="#topic+makeTuneControlGrid">makeTuneControlGrid</a>()</code>,
<code><a href="#topic+makeTuneControlIrace">makeTuneControlIrace</a>()</code>,
<code><a href="#topic+makeTuneControlMBO">makeTuneControlMBO</a>()</code>,
<code><a href="#topic+makeTuneControlRandom">makeTuneControlRandom</a>()</code>,
<code><a href="#topic+makeTuneWrapper">makeTuneWrapper</a>()</code>,
<code><a href="#topic+tuneParams">tuneParams</a>()</code>
</p>

<hr>
<h2 id='wpbc.task'>Wisonsin Prognostic Breast Cancer (WPBC) survival task.</h2><span id='topic+wpbc.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>wpbc.task</code>).
</p>


<h3>References</h3>

<p>See <a href="TH.data.html#topic+wpbc">TH.data::wpbc</a>.
Incomplete cases have been removed from the task.
</p>

<hr>
<h2 id='yeast.task'>Yeast multilabel classification task.</h2><span id='topic+yeast.task'></span>

<h3>Description</h3>

<p>Contains the task (<code>yeast.task</code>).
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Yeast">https://archive.ics.uci.edu/ml/datasets/Yeast</a> (In long instead of wide format)
</p>


<h3>References</h3>

<p>Elisseeff, A., &amp; Weston, J. (2001):
A kernel method for multi-labelled classification.
In Advances in neural information processing systems (pp. 681-687).
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
