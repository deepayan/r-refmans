<!DOCTYPE html><html lang="en"><head><title>Help for package DIRMR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DIRMR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#data'>
<p>Hox pupil popularity data</p></a></li>
<li><a href='#DECME'>
<p>DECME</p></a></li>
<li><a href='#DEM'>
<p>DEM</p></a></li>
<li><a href='#df1'>
<p>Hox pupil popularity data with missing popularity scores</p></a></li>
<li><a href='#DMCEM'>
<p>DMCEM</p></a></li>
<li><a href='#DMOPXEM'>
<p>DMOPXEM</p></a></li>
<li><a href='#DPXEM'>
<p>DPXEM</p></a></li>
<li><a href='#ECME'>
<p>ECME</p></a></li>
<li><a href='#EM'>
<p>EM</p></a></li>
<li><a href='#MCEM'>
<p>MCEM</p></a></li>
<li><a href='#MOPXEM'>
<p>MOPXEM</p></a></li>
<li><a href='#PXEM'>
<p>PXEM</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-11-22</td>
</tr>
<tr>
<td>Title:</td>
<td>Distributed Imputation for Random Effects Models with Missing
Responses</td>
</tr>
<tr>
<td>Description:</td>
<td>By adding over-relaxation factor to PXEM (Parameter Expanded Expectation Maximization) method, the MOPXEM (Monotonically Overrelaxed Parameter Expanded Expectation Maximization) method is obtained. Compare it with the existing EM (Expectation-Maximization)-like methods. Then, distribute and process five methods and compare them, achieving good performance in convergence speed and result quality.The philosophy of the package is described in Guo G. (2022) &lt;<a href="https://doi.org/10.1007%2Fs00180-022-01270-z">doi:10.1007/s00180-022-01270-z</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS,lava,mvtnorm</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>Guangbao Guo <a href="https://orcid.org/0000-0002-4115-6218"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Yaping Li [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Guangbao Guo &lt;ggb11111111@163.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-25 12:13:49 UTC; A</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-26 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='data'>
Hox pupil popularity data
</h2><span id='topic+data'></span>

<h3>Description</h3>

<p>data data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data")</code></pre>


<h3>Format</h3>

<p>A data frame with 2000 observations on the following 7 variables.
</p>

<dl>
<dt><code>PUPIL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SCHOOL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>POPULAR</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SEX</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TEXP</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CONST</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TEACHPOP</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original, complete dataset was generated by Joop Hox as an example of well-behaved multilevel data set.
</p>


<h3>Source</h3>

<p>The Heart failure data set comes from the R package&quot;mice&quot;.
</p>


<h3>References</h3>

<p>Hox, J. J. (2002) Multilevel analysis. Techniques and applications. Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data)
## maybe str(data) ; plot(data) ...
</code></pre>

<hr>
<h2 id='DECME'>
DECME
</h2><span id='topic+DECME'></span>

<h3>Description</h3>

<p>The DECME algorithm can significantly improve the speed of processing large-scale data sets. It can reduce the algorithm's memory requirements, enabling the algorithm to handle larger data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DECME(data,df1,M,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DECME_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="DECME_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="DECME_+3A_m">M</code></td>
<td>
<p>The number of Blocks</p>
</td></tr>
<tr><td><code id="DECME_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y011</code></td>
<td>
<p>The response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Ymean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhatmean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
DECME(data,df1,M=2,maxiter=15)
</code></pre>

<hr>
<h2 id='DEM'>
DEM
</h2><span id='topic+DEM'></span>

<h3>Description</h3>

<p>The DEM method is mainly applied to statistical analysis of large-scale datasets, where the dataset is distributed across different computing nodes to process data in parallel and update model parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DEM(data,df1,M,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="DEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="DEM_+3A_m">M</code></td>
<td>
<p>The number of Blocks</p>
</td></tr>
<tr><td><code id="DEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y011</code></td>
<td>
<p>The response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Ymean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhatmean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
DEM(data,df1,M=2,maxiter=15)
</code></pre>

<hr>
<h2 id='df1'>
Hox pupil popularity data with missing popularity scores
</h2><span id='topic+df1'></span>

<h3>Description</h3>

<p>df1 data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("df1")</code></pre>


<h3>Format</h3>

<p>A data frame with 2000 observations on the following 7 variables.
</p>

<dl>
<dt><code>PUPIL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SCHOOL</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>POPULAR</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>SEX</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TEXP</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>CONST</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TEACHPOP</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original, complete dataset was generated by Joop Hox as an example of well-behaved multilevel data set. The distributed data contains missing data in pupil popularity.
</p>


<h3>Source</h3>

<p>The Heart failure data set comes from the R package&quot;mice&quot;.
</p>


<h3>References</h3>

<p>Hox, J. J. (2002) Multilevel analysis. Techniques and applications. Mahwah, NJ: Lawrence Erlbaum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(df1)
## maybe str(df1) ; plot(df1) ...
</code></pre>

<hr>
<h2 id='DMCEM'>
DMCEM
</h2><span id='topic+DMCEM'></span>

<h3>Description</h3>

<p>The DMCEM method uses the sample mean to approximate the integral in step E, rather than performing a single Monte Carlo sampling on the entire dataset. This enables DMCEM to significantly reduce the computation time and memory consumption when processing large datasets, while updating model parameters by calculating the sample mean of each subset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DMCEM(data,df1,M,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DMCEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="DMCEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="DMCEM_+3A_m">M</code></td>
<td>
<p>The number of Blocks</p>
</td></tr>
<tr><td><code id="DMCEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y011</code></td>
<td>
<p>The response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Ymean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhatmean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
DMCEM(data,df1,M=2,maxiter=15)
</code></pre>

<hr>
<h2 id='DMOPXEM'>
DMOPXEM
</h2><span id='topic+DMOPXEM'></span>

<h3>Description</h3>

<p>In DMOPXEM method, data is allocated to different computing nodes for parallel processing. Each node independently executes the EM algorithm and updates the local model parameters. Then, each node passes the local model parameters to other nodes for the merging and updating of global model parameters.</p>


<h3>Usage</h3>

<pre><code class='language-R'>DMOPXEM(data,df1,M,omega,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DMOPXEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="DMOPXEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="DMOPXEM_+3A_m">M</code></td>
<td>
<p>The number of Blocks</p>
</td></tr>
<tr><td><code id="DMOPXEM_+3A_omega">omega</code></td>
<td>
<p>A variable of this method</p>
</td></tr>
<tr><td><code id="DMOPXEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y011</code></td>
<td>
<p>The response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Ymean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhatmean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
DMOPXEM(data,df1,M=2,omega=0.15,maxiter=15)
</code></pre>

<hr>
<h2 id='DPXEM'>
DPXEM</h2><span id='topic+DPXEM'></span>

<h3>Description</h3>

<p>The DPXEM method is mainly used for clustering analysis of large-scale datasets. It distributes the dataset across different computing nodes, processes the data in parallel, and updates model parameters. Through parallel processing, the DPXEM algorithm can significantly improve the speed of processing large-scale datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DPXEM(data,df1,M,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DPXEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="DPXEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="DPXEM_+3A_m">M</code></td>
<td>
<p>The number of Blocks</p>
</td></tr>
<tr><td><code id="DPXEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y011</code></td>
<td>
<p>The response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Ymean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
<tr><td><code>Yhatmean</code></td>
<td>
<p>The mean of response variable value after projection for each block</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
DPXEM(data,df1,M=2,maxiter=15)
</code></pre>

<hr>
<h2 id='ECME'>
ECME
</h2><span id='topic+ECME'></span>

<h3>Description</h3>

<p>The ECME method calculates the conditional expectation of each hidden variable based on known data and current parameter estimates. Then, based on the known data, the conditional expectation of the hidden variables, and the current parameter estimates, the likelihood function is maximized to update the parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECME(data,df1,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ECME_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="ECME_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="ECME_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y01</code></td>
<td>
<p>The response variable value after projection</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
ECME(data,df1,maxiter=15)
</code></pre>

<hr>
<h2 id='EM'>
EM
</h2><span id='topic+EM'></span>

<h3>Description</h3>

<p>The EM method is an iterative algorithm used for maximum likelihood estimation or maximum posterior probability estimation of parameters in probabilistic models with hidden variables. It is essentially a method for estimating parameters, based on existing sample data, to estimate parameter values that are consistent with the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EM(data,df1,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="EM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="EM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y01</code></td>
<td>
<p>The response variable value after projection</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
EM(data,df1,maxiter=15)
</code></pre>

<hr>
<h2 id='MCEM'>
MCEM
</h2><span id='topic+MCEM'></span>

<h3>Description</h3>

<p>The MCEM method is an algorithm that utilizes the Monte Carlo method to solve the difficult E-step integral in the EM algorithm. It avoids complex numerical integration calculations by converting the integral in the E-step into a numerical integral.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCEM(data, df1, maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MCEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="MCEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="MCEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y01</code></td>
<td>
<p>The response variable value after projection</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
MCEM(data,df1,maxiter=15)
</code></pre>

<hr>
<h2 id='MOPXEM'>
MOPXEM
</h2><span id='topic+MOPXEM'></span>

<h3>Description</h3>

<p>The MOPXEM method is an improved EM algorithm that combines the monotonic super-relaxation strategy with the PXEM strategy. The main idea of the MOPXEM method is to accelerate the EM algorithm using the ULS strategy, while simultaneously expanding and optimizing the model parameters using the PX-EM strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MOPXEM(data,df1,omega,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MOPXEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="MOPXEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="MOPXEM_+3A_omega">omega</code></td>
<td>
<p>A variable of this method</p>
</td></tr>
<tr><td><code id="MOPXEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y01</code></td>
<td>
<p>The response variable value after projection</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
MOPXEM(data,df1,omega=0.15,maxiter=15)
</code></pre>

<hr>
<h2 id='PXEM'>
PXEM
</h2><span id='topic+PXEM'></span>

<h3>Description</h3>

<p>The PXEM method is an algorithm that accelerates the convergence rate of the EM algorithm. By introducing additional parameters, improving the model, and expanding it, it has better parameter estimation results compared to the EM method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PXEM(data,df1,maxiter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PXEM_+3A_data">data</code></td>
<td>
<p>The real data sets with missing data used in the method</p>
</td></tr>
<tr><td><code id="PXEM_+3A_df1">df1</code></td>
<td>
<p>The real data sets used in the method</p>
</td></tr>
<tr><td><code id="PXEM_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Y01</code></td>
<td>
<p>The response variable value after projection</p>
</td></tr>
<tr><td><code>Yhat</code></td>
<td>
<p>The estimated response variable value after projection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Guangbao Guo,Yu Li</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(99)
library(MASS)
library(mvtnorm)
n=50;p=6;q=5;M=2;omega=0.15;ratio=0.1;maxiter=15;nob=round(n-(n*ratio))
dd.start=1;sigma2_e.start=1
X0=matrix(runif(n*p,0,2),ncol=p)
beta=matrix(rnorm(p*1,0,3),nrow=p)
Z0=matrix(runif(n*q,2,3),ncol=q)
e=matrix(rnorm(n*1,0,sigma2_e.start),n,1)
b=matrix(rnorm(q*1,0,1),q,1)
Y0=X0
df1=data.frame(Y=Y0,X=X0,Z=Z0)
misra=function(data,ratio){
  nob=round(n-(n*ratio))
  data[sample(n,n-nob),1]=NA
  return(data)}
data=misra(data=df1,ratio=0.1)
PXEM(data,df1,maxiter=15)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
