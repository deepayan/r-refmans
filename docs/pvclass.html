<!DOCTYPE html><html><head><title>Help for package pvclass</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pvclass}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pvclass-package'><p> P-Values for Classification</p></a></li>
<li><a href='#analyze.pvs'>
<p>Analyze P-Values</p></a></li>
<li><a href='#buerk'>
<p>Medical Dataset</p></a></li>
<li><a href='#cvpvs'><p> Cross-Validated P-Values</p></a></li>
<li><a href='#cvpvs.gaussian'><p> Cross-Validated P-Values (Gaussian)</p></a></li>
<li><a href='#cvpvs.knn'><p> Cross-Validated P-Values (k Nearest Neighbors)</p></a></li>
<li><a href='#cvpvs.logreg'><p> Cross-Validated P-Values (Penalized Multicategory Logistic Regression)</p></a></li>
<li><a href='#cvpvs.wnn'><p> Cross-Validated P-Values (Weighted Nearest Neighbors)</p></a></li>
<li><a href='#pvs'>
<p>P-Values to Classify New Observations</p></a></li>
<li><a href='#pvs.gaussian'>
<p>P-Values to Classify New Observations (Gaussian)</p></a></li>
<li><a href='#pvs.knn'>
<p>P-Values to Classify New Observations (k Nearest Neighbors)</p></a></li>
<li><a href='#pvs.logreg'>
<p>P-Values to Classify New Observations (Penalized Multicategory Logistic Regression)</p></a></li>
<li><a href='#pvs.wnn'>
<p>P-Values to Classify New Observations (Weighted Nearest Neighbors)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>P-Values for Classification</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-06-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Niki Zumbrunnen &lt;niki.zumbrunnen@gmail.com&gt;, 
	Lutz Duembgen &lt;lutz.duembgen@stat.unibe.ch&gt;.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Niki Zumbrunnen &lt;niki.zumbrunnen@gmail.com&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes nonparametric p-values for the potential class
        memberships of new observations as well as cross-validated
        p-values for the training data. The p-values are based on
        permutation tests applied to an estimated Bayesian likelihood
        ratio, using a plug-in statistic for the Gaussian model, 'k
        nearest neighbors', 'weighted nearest neighbors' or
        'penalized logistic regression'.
        Additionally, it provides graphical displays and quantitative
        analyses of the p-values.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-06-05 08:06:55 UTC; niki</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-06-05 15:13:51 UTC</td>
</tr>
</table>
<hr>
<h2 id='pvclass-package'> P-Values for Classification </h2><span id='topic+pvclass-package'></span><span id='topic+pvclass'></span>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations as well as cross-validated p-values for the training data. The p-values are based on permutation tests applied to an estimated Bayesian likelihood ratio, using a plug-in statistic for the Gaussian model, 'k nearest neighbors', 'weighted nearest neighbors' or 'penalized logistic regression'. <br />
Additionally, it provides graphical displays and quantitative analyses of the p-values.
</p>


<h3>Details</h3>

<p>Use <code><a href="#topic+cvpvs">cvpvs</a></code> to compute cross-validated p-values, <code><a href="#topic+pvs">pvs</a></code> to classify new observations and <code><a href="#topic+analyze.pvs">analyze.pvs</a></code> to analyze the p-values.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

cv &lt;- cvpvs(X,Y)
analyze.pvs(cv,Y)

pv &lt;- pvs(NewX, X, Y, method = 'k', k = 10)
analyze.pvs(pv)
</code></pre>

<hr>
<h2 id='analyze.pvs'>
Analyze P-Values
</h2><span id='topic+analyze.pvs'></span>

<h3>Description</h3>

<p>Graphical displays and quantitative analyses of a matrix of p-values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> analyze.pvs(pv, Y = NULL, alpha = 0.05, roc = TRUE, pvplot = TRUE, cex = 1) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyze.pvs_+3A_pv">pv</code></td>
<td>
<p> matrix with p-values, e.g. output of <code><a href="#topic+cvpvs">cvpvs</a></code> or <code><a href="#topic+pvs">pvs</a></code>. </p>
</td></tr>
<tr><td><code id="analyze.pvs_+3A_y">Y</code></td>
<td>
<p> optional. Vector indicating the classes which the observations belong to. </p>
</td></tr>
<tr><td><code id="analyze.pvs_+3A_alpha">alpha</code></td>
<td>
<p> test level, i.e. 1 - confidence level. </p>
</td></tr>
<tr><td><code id="analyze.pvs_+3A_roc">roc</code></td>
<td>
<p> logical. If <code>TRUE</code> and <code>Y</code> is not <code>NULL</code>, ROC curves are plotted.   </p>
</td></tr>
<tr><td><code id="analyze.pvs_+3A_pvplot">pvplot</code></td>
<td>
<p> logical. If <code>TRUE</code> or <code>Y</code> is <code>NULL</code>, the p-values are displayed graphically. </p>
</td></tr>
<tr><td><code id="analyze.pvs_+3A_cex">cex</code></td>
<td>
<p> A numerical value giving the amount by which plotting text should be magnified relative to the default. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Displays the p-values graphically, i.e. it plots for each p-value a rectangle. The area of this rectangle is proportional to the the p-value. The rectangle is drawn blue if the p-value is greater than <code>alpha</code> and red otherwise. <br />
If <code>Y</code> is not <code>NULL</code>, i.e. the class memberships of the observations are known (e.g. cross-validated p-values), then additionally it plots the empirical ROC curves and prints some empirical conditional inclusion probabilities <code class="reqn">I(b,\theta)</code> and/or pattern probabilities <code class="reqn">P(b,S)</code>. Precisely, <code class="reqn">I(b,\theta)</code> is the proportion of training observations of class <code class="reqn">b</code> whose p-value for class <code class="reqn">\theta</code> is greater than <code class="reqn">\alpha</code>, while <code class="reqn">P(b,S)</code> is the proportion of training observations of class <code class="reqn">b</code> such that the <code class="reqn">(1 - \alpha)</code>-prediction region equals <code class="reqn">S</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>T</code></td>
<td>
<p> Table containing empirical conditional inclusion and/or pattern probabilities for each class <code class="reqn">b</code>. In case of <code class="reqn">L = 2</code> or <code class="reqn">L=3</code> classes, all patterns <code class="reqn">S</code> are considered. In case of <code class="reqn">L &gt; 3</code>, all inclusion probabilities and some special patters <code class="reqn">S</code> are considered. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+cvpvs">cvpvs</a>, <a href="#topic+pvs">pvs</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

cv &lt;- cvpvs(X,Y)
analyze.pvs(cv,Y)

pv &lt;- pvs(NewX, X, Y, method = 'k', k = 10)
analyze.pvs(pv)
</code></pre>

<hr>
<h2 id='buerk'>
Medical Dataset
</h2><span id='topic+buerk'></span>

<h3>Description</h3>

<p>This data set collected by Dr. Bürk at the university hospital in Lübeck contains data of 21556 surgeries in a certain time period (end of the nineties). Besides the mortality and the morbidity it contains 21 variables describing the condition of the patient and the surgery.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(buerk)</code></pre>


<h3>Format</h3>

<p>A data frame with 21556 observations on the following 23 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>Age in years</p>
</dd>
<dt><code>sex</code></dt><dd><p>Sex (1 = female, 0 = male)</p>
</dd>
<dt><code>asa</code></dt><dd><p>ASA-Score (American Society of Anesthesiologists), describes the physical condition on an ordinal scale: <br />
1 = A normal healthy patient <br />
2 = A patient with mild systemic disease <br />
3 = A patient with severe systemic disease <br />
4 = A patient with severe systemic disease that is a constant threat to life <br />
5 = A moribund patient who is not expected to survive without the operation <br />
6 = A declared brain-dead patient whose organs are being removed for donor purposes</p>
</dd>
<dt><code>rf_cer</code></dt><dd><p>Risk factor: cerebral (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_car</code></dt><dd><p>Risk factor: cardiovascular (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_pul</code></dt><dd><p>Risk factor: pulmonary (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_ren</code></dt><dd><p>Risk factor: renal (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_hep</code></dt><dd><p>Risk factor: hepatic (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_imu</code></dt><dd><p>Risk factor: immunological (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_metab</code></dt><dd><p>Risk factor: metabolic (1 = yes, 0 = no)</p>
</dd>
<dt><code>rf_noc</code></dt><dd><p>Risk factor: uncooperative, unreliable (1 = yes, 0 = no)</p>
</dd>
<dt><code>e_malig</code></dt><dd><p>Etiology: malignant (1 = yes, 0 = no)</p>
</dd>
<dt><code>e_vascu</code></dt><dd><p>Etiology: vascular (1 = yes, 0 = no)</p>
</dd>
<dt><code>antibio</code></dt><dd><p>Antibiotics therapy (1 = yes, 0 = no)</p>
</dd>
<dt><code>op</code></dt><dd><p>Surgery indicated (1 = yes, 0 = no)</p>
</dd>
<dt><code>opacute</code></dt><dd><p>Emergency operation (1 = yes, 0 = no)</p>
</dd>
<dt><code>optime</code></dt><dd><p>Surgery time in minutes</p>
</dd>
<dt><code>opsepsis</code></dt><dd><p>Septic surgery (1 = yes, 0 = no)</p>
</dd>
<dt><code>opskill</code></dt><dd><p>Expirienced surgeond, i.e. senior physician (1 = yes, 0 = no)</p>
</dd>
<dt><code>blood</code></dt><dd><p>Blood transfusion necessary (1 = yes, 0 = no)</p>
</dd>
<dt><code>icu</code></dt><dd><p>Intensive care necessary (1 = yes, 0 = no)</p>
</dd>
<dt><code>mortal</code></dt><dd><p>Mortality (1 = yes, 0 = no)</p>
</dd>
<dt><code>morb</code></dt><dd><p>Morbidity (1 = yes, 0 = no)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>

<hr>
<h2 id='cvpvs'> Cross-Validated P-Values </h2><span id='topic+cvpvs'></span>

<h3>Description</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvpvs(X, Y, method = c('gaussian','knn','wnn', 'logreg'), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvpvs_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="cvpvs_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="cvpvs_+3A_method">method</code></td>
<td>

<p>one of the following methods: <br />
'gaussian': plug-in statistic for the standard Gaussian model, <br />
'knn': k nearest neighbors, <br />
'wnn': weighted nearest neighbors, <br />
'logreg': multicategory logistic regression with <code class="reqn">l1</code>-penalization.</p>
</td></tr>
<tr><td><code id="cvpvs_+3A_...">...</code></td>
<td>
<p> further arguments depending on the method (see <code><a href="#topic+cvpvs.gaussian">cvpvs.gaussian</a>,</code> <br />
<code><a href="#topic+cvpvs.knn">cvpvs.knn</a>, <a href="#topic+cvpvs.wnn">cvpvs.wnn</a>, <a href="#topic+cvpvs.logreg">cvpvs.logreg</a></code>). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using a plug-in statistic for the Gaussian model, 'k nearest neighbors', 'weighted nearest neighbors' or multicategory logistic regression with <code class="reqn">l1</code>-penalization (see <code><a href="#topic+cvpvs.gaussian">cvpvs.gaussian</a>, <a href="#topic+cvpvs.knn">cvpvs.knn</a>, <a href="#topic+cvpvs.wnn">cvpvs.wnn</a>, <a href="#topic+cvpvs.logreg">cvpvs.logreg</a></code>) with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations.
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the cross-validated p-values. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+cvpvs.gaussian">cvpvs.gaussian</a>, <a href="#topic+cvpvs.knn">cvpvs.knn</a>, <a href="#topic+cvpvs.wnn">cvpvs.wnn</a>, <a href="#topic+cvpvs.logreg">cvpvs.logreg</a>, <a href="#topic+pvs">pvs</a>, <a href="#topic+analyze.pvs">analyze.pvs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[,1:4]
Y &lt;- iris[,5]

cvpvs(X,Y,method='k',k=10,distance='d')
</code></pre>

<hr>
<h2 id='cvpvs.gaussian'> Cross-Validated P-Values (Gaussian) </h2><span id='topic+cvpvs.gaussian'></span>

<h3>Description</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. The p-values are based on a plug-in statistic for the standard Gaussian model. The latter means that the conditional distribution of <code class="reqn">X</code>, given <code class="reqn">Y=y</code>, is Gaussian with mean depending on <code class="reqn">y</code> and a global covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvpvs.gaussian(X, Y, cova = c('standard', 'M', 'sym'))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvpvs.gaussian_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="cvpvs.gaussian_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="cvpvs.gaussian_+3A_cova">cova</code></td>
<td>
<p> estimator for the covariance matrix: <br />
'standard': standard estimator, <br />
'M': M-estimator, <br />
'sym': symmetrized M-estimator. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using a plug-in statistic for the standard Gaussian model with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations.
</p>


<h3>Value</h3>

 
<p><code>PV</code> is a matrix containing the cross-validated p-values. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+cvpvs">cvpvs</a>, <a href="#topic+cvpvs.knn">cvpvs.knn</a>, <a href="#topic+cvpvs.wnn">cvpvs.wnn</a>, <a href="#topic+cvpvs.logreg">cvpvs.logreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[, 1:4]
Y &lt;- iris[, 5]

cvpvs.gaussian(X, Y, cova = 'standard')
</code></pre>

<hr>
<h2 id='cvpvs.knn'> Cross-Validated P-Values (k Nearest Neighbors) </h2><span id='topic+cvpvs.knn'></span>

<h3>Description</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. The p-values are based on 'k nearest neighbors'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvpvs.knn(X, Y, k = NULL, distance = c('euclidean', 'ddeuclidean',
          'mahalanobis'), cova = c('standard', 'M', 'sym'))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvpvs.knn_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="cvpvs.knn_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="cvpvs.knn_+3A_k">k</code></td>
<td>
<p> number of nearest neighbors. If <code>k</code> is a vector or <code>k = NULL</code>, the program searches for the best <code>k</code>. For more information see section 'Details'. </p>
</td></tr>
<tr><td><code id="cvpvs.knn_+3A_distance">distance</code></td>
<td>
<p> the distance measure: <br />
&quot;euclidean&quot;:    fixed Euclidean distance, <br />
&quot;ddeuclidean&quot;:  data driven Euclidean distance (component-wise standardization), <br />
&quot;mahalanobis&quot;:  Mahalanobis distance. </p>
</td></tr>
<tr><td><code id="cvpvs.knn_+3A_cova">cova</code></td>
<td>
<p> estimator for the covariance matrix: <br />
'standard': standard estimator, <br />
'M': M-estimator, <br />
'sym': symmetrized M-estimator. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'k nearest neighbors' with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations. <br />
If <code>k</code> is a vector, the program searches for the best <code>k</code>. To determine the best <code>k</code> for the p-value <code>PV[i,b]</code>, the class label of the training observation <code class="reqn">X[i,]</code> is set temporarily to <code>b</code> and then for all training observations with <code>Y[j] != b</code> the proportion of the <code>k</code> nearest neighbors of <code>X[j,]</code> belonging to class <code>b</code> is computed. Then the <code>k</code> which minimizes the sum of these values is chosen. <br />
If <code>k = NULL</code>, it is set to 2:ceiling(length(Y)/2).
</p>


<h3>Value</h3>

 
<p><code>PV</code> is a matrix containing the cross-validated p-values. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
If <code>k</code> is a vector or <code>NULL</code>, <code>PV</code> has an attribute <code>"opt.k"</code>, which is a matrix and <code>opt.k[i,b]</code> is the best <code>k</code> for observation <code>X[i,]</code> and class <code>b</code> (see section 'Details'). <code>opt.k[i,b]</code> is used to compute the p-value for observation <code>X[i,]</code> and class <code>b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+cvpvs">cvpvs</a>, <a href="#topic+cvpvs.gaussian">cvpvs.gaussian</a>, <a href="#topic+cvpvs.wnn">cvpvs.wnn</a>, <a href="#topic+cvpvs.logreg">cvpvs.logreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[, 1:4]
Y &lt;- iris[, 5]

cvpvs.knn(X, Y, k = c(5, 10, 15))
</code></pre>

<hr>
<h2 id='cvpvs.logreg'> Cross-Validated P-Values (Penalized Multicategory Logistic Regression) </h2><span id='topic+cvpvs.logreg'></span>

<h3>Description</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. The p-values are based on 'penalized logistic regression'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvpvs.logreg(X, Y, tau.o=10, find.tau=FALSE, delta=2, tau.max=80, tau.min=1,
             pen.method = c("vectors", "simple", "none"), progress = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvpvs.logreg_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_tau.o">tau.o</code></td>
<td>
<p> the penalty parameter (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_find.tau">find.tau</code></td>
<td>
<p> logical. If TRUE the program searches for the best <code>tau</code>. For more information see section 'Details'. </p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_delta">delta</code></td>
<td>
<p> factor for the penalty parameter. Should be greater than 1. Only needed if <code>find.tau == TRUE</code>. </p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_tau.max">tau.max</code></td>
<td>
<p> maximal penalty parameter considered.  Only needed if <code>find.tau == TRUE</code>.</p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_tau.min">tau.min</code></td>
<td>
<p> minimal penalty parameter considered.  Only needed if <code>find.tau == TRUE</code>.</p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_pen.method">pen.method</code></td>
<td>
<p> the method of penalization (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="cvpvs.logreg_+3A_progress">progress</code></td>
<td>
<p> optional parameter for reporting the status of the computations. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code>Y[i]</code> equals <code>b</code>, based on the remaining training observations.
<br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'penalized logistic regression'. This means, the conditional probability of <code class="reqn">Y = y</code>, given <code class="reqn">X = x</code>, is assumed to be proportional to <code class="reqn">exp(a_y + b_y^T x)</code>. The parameters <code class="reqn">a_y</code>, <code class="reqn">b_y</code> are estimated via penalized maximum log-likelihood. The penalization is either a weighted sum of the euclidean norms of the vectors <code class="reqn">(b_1[j],b_2[j],\ldots,b_L[j])</code> (<code>pen.method=='vectors'</code>) or a weighted sum of all moduli <code class="reqn">|b_y[j]|</code> (<code>pen.method=='simple'</code>). The weights are given by <code>tau.o</code> times the sample standard deviation (within groups) of the <code class="reqn">j</code>-th components of the feature vectors. 
In case of <code>pen.method=='none'</code>, no penalization is used, but this option may be unstable.
<br />
If <code>find.tau == TRUE</code>, the program searches for the best penalty parameter. To determine the best parameter <code>tau</code> for the p-value <code>PV[i,b]</code>, the class label of the training observation <code>X[i,]</code> is set temporarily to <code>b</code> and then for all training observations with <code>Y[j] != b</code> the estimated probability of <code>X[j,]</code> belonging to class <code>b</code> is computed. Then the <code>tau</code> which minimizes the sum of these values is chosen. First, <code>tau.o</code> is compared with <code>tau.o*delta</code>. If <code>tau.o*delta</code> is better, it is compared with <code>tau.o*delta^2</code>, etc. The maximal parameter considered is <code>tau.max</code>. If <code>tau.o</code> is better than <code>tau.o*delta</code>, it is compared with <code>tau.o*delta^-1</code>, etc. The minimal parameter considered is <code>tau.min</code>. 
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the cross-validated p-values. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>, based on the remaining training observations.
<br />
If <code>find.tau == TRUE</code>, <code>PV</code> has an attribute <code>"tau.opt"</code>, which is a matrix and <code>tau.opt[i,b]</code> is the best <code>tau</code> for observation <code>X[i,]</code> and class <code>b</code> (see section 'Details'). <code>tau.opt[i,b]</code> is used to compute the p-value for observation <code>X[i,]</code> and class <code>b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+cvpvs">cvpvs</a>, <a href="#topic+cvpvs.gaussian">cvpvs.gaussian</a>, <a href="#topic+cvpvs.knn">cvpvs.knn</a>, <a href="#topic+cvpvs.wnn">cvpvs.wnn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
X &lt;- iris[, 1:4]
Y &lt;- iris[, 5]

cvpvs.logreg(X, Y, tau.o=1, pen.method="vectors",progress=TRUE)

## End(Not run)

# A bigger data example: Buerk's hospital data.
## Not run: 
data(buerk)
X.raw &lt;- as.matrix(buerk[,1:21])
Y.raw &lt;- buerk[,22]
n0.raw &lt;- sum(1 - Y.raw)
n1 &lt;- sum(Y.raw)
n0 &lt;- 3*n1

X0 &lt;- X.raw[Y.raw==0,]
X1 &lt;- X.raw[Y.raw==1,]

tmpi0 &lt;- sample(1:n0.raw,size=n0,replace=FALSE)
tmpi1 &lt;- sample(1:n1    ,size=n1,replace=FALSE)

X &lt;- rbind(X0[tmpi0,],X1)
Y &lt;- c(rep(1,n0),rep(2,n1))

str(X)
str(Y)

PV &lt;- cvpvs.logreg(X,Y,
	tau.o=5,pen.method="v",progress=TRUE)

analyze.pvs(Y=Y,pv=PV,pvplot=FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='cvpvs.wnn'> Cross-Validated P-Values (Weighted Nearest Neighbors) </h2><span id='topic+cvpvs.wnn'></span>

<h3>Description</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. The p-values are based on 'weighted nearest-neighbors'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvpvs.wnn(X, Y, wtype = c('linear', 'exponential'), W = NULL,
          tau = 0.3, distance = c('euclidean', 'ddeuclidean',
          'mahalanobis'), cova = c('standard', 'M', 'sym'))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvpvs.wnn_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="cvpvs.wnn_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="cvpvs.wnn_+3A_wtype">wtype</code></td>
<td>
<p> type of the weight function (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="cvpvs.wnn_+3A_w">W</code></td>
<td>
<p> vector of the (decreasing) weights (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="cvpvs.wnn_+3A_tau">tau</code></td>
<td>
<p> parameter of the weight function. If <code>tau</code> is a vector or <code>tau = NULL</code>, the program searches for the best <code>tau</code>. For more information see section 'Details'. </p>
</td></tr>
<tr><td><code id="cvpvs.wnn_+3A_distance">distance</code></td>
<td>
<p> the distance measure: <br />
&quot;euclidean&quot;:    fixed Euclidean distance, <br />
&quot;ddeuclidean&quot;:  data driven Euclidean distance (component-wise standardization), <br />
&quot;mahalanobis&quot;:  Mahalanobis distance. </p>
</td></tr>
<tr><td><code id="cvpvs.wnn_+3A_cova">cova</code></td>
<td>
<p> estimator for the covariance matrix: <br />
'standard': standard estimator, <br />
'M': M-estimator, <br />
'sym': symmetrized M-estimator. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes cross-validated nonparametric p-values for the potential class memberships of the training data. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code>Y[i]</code> equals <code>b</code>.
<br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'weighted nearest neighbors' with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations. <br />
The (decreasing) weights for the observations can be either indicated with a <code class="reqn">n</code> dimensional vector <code>W</code> or (<code>if W = NULL</code>) one of the following weight functions can be used: <br />
linear: </p>
<p style="text-align: center;"><code class="reqn">W_i = \max(1-\frac{i}{n}/\tau,0),</code>
</p>

<p>exponential: </p>
<p style="text-align: center;"><code class="reqn">W_i = (1-\frac{i}{n})^\tau.</code>
</p>

<p>If <code>tau</code> is a vector, the program searches for the best <code>tau</code>. To determine the best <code>tau</code> for the p-value <code>PV[i,b]</code>, the class label of the training observation <code class="reqn">X[i,]</code> is set temporarily to <code>b</code> and then for all training observations with <code>Y[j] != b</code> the sum of the weights of the observations belonging to class <code>b</code> is computed. Then the <code>tau</code> which minimizes the sum of these values is chosen. <br />
If <code>W = NULL</code> and <code>tau = NULL</code>, <code>tau</code> is set to <code>seq(0.1,0.9,0.1)</code> if <code>wtype = "l"</code> and to <code>c(1,5,10,20)</code> if <code>wtype = "e"</code>. 
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the cross-validated p-values. Precisely, for each feature vector <code>X[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
If <code>tau</code> is a vector or <code>NULL</code> (and <code>W = NULL</code>), <code>PV</code> has an attribute <code>"opt.tau"</code>,  which is a matrix and <code>opt.tau[i,b]</code> is the best <code>tau</code> for observation <code>X[i,]</code> and class <code>b</code> (see section 'Details'). <code>"opt.tau"</code> is used to compute the p-values.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+cvpvs">cvpvs</a>, <a href="#topic+cvpvs.gaussian">cvpvs.gaussian</a>, <a href="#topic+cvpvs.knn">cvpvs.knn</a>, <a href="#topic+cvpvs.logreg">cvpvs.logreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[, 1:4]
Y &lt;- iris[, 5]

cvpvs.wnn(X, Y, wtype = 'l', tau = 0.5)
</code></pre>

<hr>
<h2 id='pvs'>
P-Values to Classify New Observations 
</h2><span id='topic+pvs'></span>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvs(NewX, X, Y, method = c('gaussian', 'knn', 'wnn', 'logreg'), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvs_+3A_newx">NewX</code></td>
<td>
<p> data matrix consisting of one or several new observations (row vectors) to be classified. </p>
</td></tr>
<tr><td><code id="pvs_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="pvs_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="pvs_+3A_method">method</code></td>
<td>

<p>one of the following methods: <br />
'gaussian': plug-in statistic for the standard Gaussian model, <br />
'knn': k nearest neighbors, <br />
'wnn': weighted nearest neighbors, <br />
'logreg': multicategory logistic regression with <code class="reqn">l1</code>-penalization.</p>
</td></tr> 
<tr><td><code id="pvs_+3A_...">...</code></td>
<td>
<p> further arguments depending on the method (see <code><a href="#topic+pvs.gaussian">pvs.gaussian</a>, <a href="#topic+pvs.knn">pvs.knn</a>, <a href="#topic+pvs.wnn">pvs.wnn</a>, <a href="#topic+pvs.logreg">pvs.logreg</a></code>). </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using a plug-in statistic for the Gaussian model, 'k nearest neighbors', 'weighted nearest neighbors' or multicategory logistic regression with <code class="reqn">l1</code>-penalization (see <code><a href="#topic+pvs.gaussian">pvs.gaussian</a>, <a href="#topic+pvs.knn">pvs.knn</a>, <a href="#topic+pvs.wnn">pvs.wnn</a>, <a href="#topic+pvs.logreg">pvs.logreg</a></code>) with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations.
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the p-values. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+pvs.gaussian">pvs.gaussian</a>, <a href="#topic+pvs.knn">pvs.knn</a>, <a href="#topic+pvs.wnn">pvs.wnn</a>, <a href="#topic+pvs.logreg">pvs.logreg</a>, <a href="#topic+cvpvs">cvpvs</a>, <a href="#topic+analyze.pvs">analyze.pvs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

pvs(NewX, X, Y, method = 'k', k = 10)
</code></pre>

<hr>
<h2 id='pvs.gaussian'>
P-Values to Classify New Observations (Gaussian)
</h2><span id='topic+pvs.gaussian'></span>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. The p-values are based on a plug-in statistic for the standard Gaussian model. The latter means that the conditional distribution of <code class="reqn">X</code>, given <code class="reqn">Y=y</code>, is Gaussian with mean depending on <code class="reqn">y</code> and a global covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvs.gaussian(NewX, X, Y, cova = c('standard', 'M', 'sym'))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvs.gaussian_+3A_newx">NewX</code></td>
<td>
<p> data matrix consisting of one or several new observations (row vectors) to be classified. </p>
</td></tr>
<tr><td><code id="pvs.gaussian_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="pvs.gaussian_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="pvs.gaussian_+3A_cova">cova</code></td>
<td>
<p> estimator for the covariance matrix: <br />
'standard': standard estimator, <br />
'M': M-estimator, <br />
'sym': symmetrized M-estimator. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using a plug-in statistic for the standard Gaussian model with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations.
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the p-values. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+pvs">pvs</a>, <a href="#topic+pvs.knn">pvs.knn</a>, <a href="#topic+pvs.wnn">pvs.wnn</a>, <a href="#topic+pvs.logreg">pvs.logreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

pvs.gaussian(NewX, X, Y, cova = 'standard')
</code></pre>

<hr>
<h2 id='pvs.knn'>
P-Values to Classify New Observations (k Nearest Neighbors)
</h2><span id='topic+pvs.knn'></span>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. The p-values are based on 'k nearest neighbors'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvs.knn(NewX, X, Y, k = NULL, distance = c('euclidean', 'ddeuclidean',
        'mahalanobis'), cova = c('standard', 'M', 'sym'))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvs.knn_+3A_newx">NewX</code></td>
<td>
<p> data matrix consisting of one or several new observations (row vectors) to be classified. </p>
</td></tr>
<tr><td><code id="pvs.knn_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="pvs.knn_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="pvs.knn_+3A_k">k</code></td>
<td>
<p> number of nearest neighbors. If <code>k</code> is a vector or <code>k = NULL</code>, the program searches for the best <code>k</code>. For more information see section 'Details'. </p>
</td></tr>
<tr><td><code id="pvs.knn_+3A_distance">distance</code></td>
<td>
<p> the distance measure: <br />
'euclidean':    fixed Euclidean distance, <br />
'ddeuclidean':  data driven Euclidean distance (component-wise standardization), <br />
'mahalanobis':  Mahalanobis distance. </p>
</td></tr>
<tr><td><code id="pvs.knn_+3A_cova">cova</code></td>
<td>
<p> estimator for the covariance matrix: <br />
'standard': standard estimator, <br />
'M': M-estimator, <br />
'sym': symmetrized M-estimator. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'k nearest neighbors' with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations. <br />
If <code>k</code> is a vector, the program searches for the best <code>k</code>. To determine the best <code>k</code> for the p-value <code>PV[i,b]</code>, the new observation <code>NewX[i,]</code> is added to the training data with class label <code>b</code> and then for all training observations with <code>Y[j] != b</code> the proportion of the <code>k</code> nearest neighbors of <code>X[j,]</code> belonging to class <code>b</code> is computed. Then the <code>k</code> which minimizes the sum of these values is chosen. <br />
If <code>k = NULL</code>, it is set to 2:ceiling(length(Y)/2).
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the p-values. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
If <code>k</code> is a vector or <code>NULL</code>, <code>PV</code> has an attribute <code>"opt.k"</code>, which is a matrix and <code>opt.k[i,b]</code> is the best <code>k</code> for observation <code>NewX[i,]</code> and class <code>b</code> (see section 'Details'). <code>opt.k[i,b]</code> is used to compute the p-value for observation <code>NewX[i,]</code> and class <code>b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+pvs">pvs</a>, <a href="#topic+pvs.gaussian">pvs.gaussian</a>, <a href="#topic+pvs.wnn">pvs.wnn</a>, <a href="#topic+pvs.logreg">pvs.logreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

pvs.knn(NewX, X, Y, k = c(5, 10, 15))
</code></pre>

<hr>
<h2 id='pvs.logreg'>
P-Values to Classify New Observations (Penalized Multicategory Logistic Regression)
</h2><span id='topic+pvs.logreg'></span>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. The p-values are based on 'penalized logistic regression'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvs.logreg(NewX, X, Y, tau.o = 10, find.tau=FALSE, delta=2, tau.max=80, tau.min=1,
           a0 = NULL, b0 = NULL,
           pen.method = c('vectors', 'simple', 'none'),
           progress = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvs.logreg_+3A_newx">NewX</code></td>
<td>
<p> data matrix consisting of one or several new observations (row vectors) to be classified. </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_tau.o">tau.o</code></td>
<td>
<p> the penalty parameter (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_find.tau">find.tau</code></td>
<td>
<p> logical. If TRUE the program searches for the best <code>tau</code>. For more information see section 'Details'. </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_delta">delta</code></td>
<td>
<p> factor for the penalty parameter. Should be greater than 1. Only needed if <code>find.tau == TRUE</code>. </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_tau.max">tau.max</code></td>
<td>
<p> maximal penalty parameter considered.  Only needed if <code>find.tau == TRUE</code>.</p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_tau.min">tau.min</code></td>
<td>
<p> minimal penalty parameter considered.  Only needed if <code>find.tau == TRUE</code>.</p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_a0">a0</code>, <code id="pvs.logreg_+3A_b0">b0</code></td>
<td>
<p> optional starting values for logistic regression. </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_pen.method">pen.method</code></td>
<td>
<p> the method of penalization (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="pvs.logreg_+3A_progress">progress</code></td>
<td>
<p> optional parameter for reporting the status of the computations. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code>Y[i]</code> equals <code>b</code>.
<br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'penalized logistic regression'. This means, the conditional probability of <code class="reqn">Y = y</code>, given <code class="reqn">X = x</code>, is assumed to be proportional to <code class="reqn">exp(a_y + b_y^T x)</code>. The parameters <code class="reqn">a_y</code>, <code class="reqn">b_y</code> are estimated via penalized maximum log-likelihood. The penalization is either a weighted sum of the euclidean norms of the vectors <code class="reqn">(b_1[j],b_2[j],\ldots,b_L[j])</code> (<code>pen.method=='vectors'</code>) or a weighted sum of all moduli <code class="reqn">|b_{\theta}[j]|</code> (<code>pen.method=='simple'</code>). The weights are given by <code>tau.o</code> times the sample standard deviation (within groups) of the <code class="reqn">j</code>-th components of the feature vectors. 
In case of <code>pen.method=='none'</code>, no penalization is used, but this option may be unstable.
<br />
If <code>find.tau == TRUE</code>, the program searches for the best penalty parameter. To determine the best parameter <code>tau</code> for the p-value <code>PV[i,b]</code>, the new observation <code>NewX[i,]</code> is added to the training data with class label <code>b</code> and then for all training observations with <code>Y[j] != b</code> the estimated probability of <code>X[j,]</code> belonging to class <code>b</code> is computed. Then the <code>tau</code> which minimizes the sum of these values is chosen. First, <code>tau.o</code> is compared with <code>tau.o*delta</code>. If <code>tau.o*delta</code> is better, it is compared with <code>tau.o*delta^2</code>, etc. The maximal parameter considered is <code>tau.max</code>. If <code>tau.o</code> is better than <code>tau.o*delta</code>, it is compared with <code>tau.o*delta^-1</code>, etc. The minimal parameter considered is <code>tau.min</code>. 
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the p-values. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>.
<br />
If <code>find.tau == TRUE</code>, <code>PV</code> has an attribute <code>"tau.opt"</code>, which is a matrix and <code>tau.opt[i,b]</code> is the best <code>tau</code> for observation <code>NewX[i,]</code> and class <code>b</code> (see section 'Details'). <code>tau.opt[i,b]</code> is used to compute the p-value for observation <code>NewX[i,]</code> and class <code>b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code> <a href="#topic+pvs">pvs</a>, <a href="#topic+pvs.gaussian">pvs.gaussian</a>, <a href="#topic+pvs.knn">pvs.knn</a>, <a href="#topic+pvs.wnn">pvs.wnn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

pvs.logreg(NewX, X, Y, tau.o=1, pen.method="vectors", progress=TRUE)

# A bigger data example: Buerk's hospital data.
## Not run: 
data(buerk)
X.raw &lt;- as.matrix(buerk[,1:21])
Y.raw &lt;- buerk[,22]
n0.raw &lt;- sum(1 - Y.raw)
n1 &lt;- sum(Y.raw)
n0 &lt;- 3*n1

X0 &lt;- X.raw[Y.raw==0,]
X1 &lt;- X.raw[Y.raw==1,]

tmpi0 &lt;- sample(1:n0.raw,size=3*n1,replace=FALSE)
tmpi1 &lt;- sample(1:n1    ,size=  n1,replace=FALSE)

Xtrain &lt;- rbind(X0[tmpi0[1:(n0-100)],],X1[1:(n1-100),])
Ytrain &lt;- c(rep(1,n0-100),rep(2,n1-100))
Xtest &lt;- rbind(X0[tmpi0[(n0-99):n0],],X1[(n1-99):n1,])
Ytest &lt;- c(rep(1,100),rep(2,100))

PV &lt;- pvs.logreg(Xtest,Xtrain,Ytrain,tau.o=2,progress=TRUE)
analyze.pvs(Y=Ytest,pv=PV,pvplot=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='pvs.wnn'>
P-Values to Classify New Observations (Weighted Nearest Neighbors)
</h2><span id='topic+pvs.wnn'></span>

<h3>Description</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. The p-values are based on 'weighted nearest-neighbors'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvs.wnn(NewX, X, Y, wtype = c('linear', 'exponential'), W = NULL,
        tau = 0.3, distance = c('euclidean', 'ddeuclidean',
        'mahalanobis'), cova = c('standard', 'M', 'sym'))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvs.wnn_+3A_newx">NewX</code></td>
<td>
<p> data matrix consisting of one or several new observations (row vectors) to be classified. </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_x">X</code></td>
<td>
<p> matrix containing training observations, where each observation is a row vector. </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_y">Y</code></td>
<td>
<p> vector indicating the classes which the training observations belong to. </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_wtype">wtype</code></td>
<td>
<p> type of the weight function (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_w">W</code></td>
<td>
<p> vector of the (decreasing) weights (see section 'Details' below). </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_tau">tau</code></td>
<td>
<p> parameter of the weight function. If <code>tau</code> is a vector or <code>tau = NULL</code>, the program searches for the best <code>tau</code>. For more information see section 'Details'. </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_distance">distance</code></td>
<td>
<p> the distance measure: <br />
'euclidean':    fixed Euclidean distance, <br />
'ddeuclidean':  data driven Euclidean distance (component-wise standardization), <br />
'mahalanobis':  Mahalanobis distance. </p>
</td></tr>
<tr><td><code id="pvs.wnn_+3A_cova">cova</code></td>
<td>
<p> estimator for the covariance matrix: <br />
'standard': standard estimator, <br />
'M': M-estimator, <br />
'sym': symmetrized M-estimator. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes nonparametric p-values for the potential class memberships of new observations. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
This p-value is based on a permutation test applied to an estimated Bayesian likelihood ratio, using 'weighted nearest neighbors' with estimated prior probabilities <code class="reqn">N(b)/n</code>. Here <code class="reqn">N(b)</code> is the number of observations of class <code class="reqn">b</code> and <code class="reqn">n</code> is the total number of observations. <br />
The (decreasing) weights for the observation can be either indicated with a <code class="reqn">n</code> dimensional vector <code>W</code> or (<code>if W = NULL</code>) one of the following weight functions can be used: <br />
linear: </p>
<p style="text-align: center;"><code class="reqn">W_i = \max(1-\frac{i}{n}/\tau,0),</code>
</p>

<p>exponential: </p>
<p style="text-align: center;"><code class="reqn">W_i = (1-\frac{i}{n})^\tau.</code>
</p>

<p>If <code>tau</code> is a vector, the program searches for the best <code>tau</code>. To determine the best <code>tau</code> for the p-value <code>PV[i,b]</code>, the new observation <code>NewX[i,]</code> is added to the training data with class label <code>b</code> and then for all training observations with <code>Y[j] != b</code> the sum of the weights of the observations belonging to class <code>b</code> is computed. Then the <code>tau</code> which minimizes the sum of these values is chosen. <br />
If <code>tau = NULL</code>, it is set to <code>seq(0.1,0.9,0.1)</code> if <code>wtype = "l"</code> and to <code>c(1,5,10,20)</code> if <code>wtype = "e"</code>. 
</p>


<h3>Value</h3>

<p><code>PV</code> is a matrix containing the p-values. Precisely, for each new observation <code>NewX[i,]</code> and each class <code>b</code> the number <code>PV[i,b]</code> is a p-value for the null hypothesis that <code class="reqn">Y[i] = b</code>. <br />
If <code>tau</code> is a vector or <code>NULL</code> (and <code>W = NULL</code>), <code>PV</code> has an attribute <code>"opt.tau"</code>,  which is a matrix and <code>opt.tau[i,b]</code> is the best <code>tau</code> for observation <code>NewX[i,]</code> and class <code>b</code> (see section 'Details'). <code>opt.tau[i,b]</code> is used to compute the p-value for observation <code>NewX[i,]</code> and class <code>b</code>.
</p>


<h3>Author(s)</h3>

<p>Niki Zumbrunnen <a href="mailto:niki.zumbrunnen@gmail.com">niki.zumbrunnen@gmail.com</a> <br />
Lutz Dümbgen <a href="mailto:lutz.duembgen@stat.unibe.ch">lutz.duembgen@stat.unibe.ch</a> <br />
<a href="www.imsv.unibe.ch/duembgen/index_ger.html">www.imsv.unibe.ch/duembgen/index_ger.html</a>
</p>


<h3>References</h3>

<p>Zumbrunnen N. and Dümbgen L. (2017)
pvclass: An R Package for p Values for Classification.
<em>Journal of Statistical Software <b>78(4)</b></em>, 1&ndash;19.
doi:10.18637/jss.v078.i04
</p>
<p>Dümbgen L., Igl B.-W. and Munk A. (2008)
P-Values for Classification.
<em>Electronic Journal of Statistics <b>2</b></em>, 468&ndash;493, available at <a href="http://dx.doi.org/10.1214/08-EJS245">http://dx.doi.org/10.1214/08-EJS245</a>.
</p>
<p>Zumbrunnen N. (2014)
P-Values for Classification – Computational Aspects and Asymptotics.
Ph.D. thesis, University of Bern, available at <a href="http://boris.unibe.ch/id/eprint/53585">http://boris.unibe.ch/id/eprint/53585</a>.
</p>


<h3>See Also</h3>

 
<p><code> <a href="#topic+pvs">pvs</a>, <a href="#topic+pvs.gaussian">pvs.gaussian</a>, <a href="#topic+pvs.knn">pvs.knn</a>, <a href="#topic+pvs.logreg">pvs.logreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- iris[c(1:49, 51:99, 101:149), 1:4]
Y &lt;- iris[c(1:49, 51:99, 101:149), 5]
NewX &lt;- iris[c(50, 100, 150), 1:4]

pvs.wnn(NewX, X, Y, wtype = 'l', tau = 0.5)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
