<!DOCTYPE html><html lang="en"><head><title>Help for package gbts</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gbts}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#gbts'><p>Hyperparameter Search for Gradient Boosted Trees</p></a></li>
<li><a href='#boston_housing'><p>Boston housing data</p></a></li>
<li><a href='#comperf'><p>Compute model performance</p></a></li>
<li><a href='#german_credit'><p>German credit data</p></a></li>
<li><a href='#predict.gbts'><p>Predict method for ensemble of Gradient Boosted Trees</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Hyperparameter Search for Gradient Boosted Trees</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-02-26</td>
</tr>
<tr>
<td>Author:</td>
<td>Waley W. J. Liang</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Waley W. J. Liang &lt;wliang10@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of hyperparameter optimization for Gradient
    Boosted Trees on binary classification and regression problems. The current
    version provides two optimization methods: Bayesian optimization and random
    search. Instead of giving the single best model, the final output is an 
    ensemble of Gradient Boosted Trees constructed via the method of ensemble 
    selection.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE [expanded from: GPL (&ge; 2) | file LICENSE]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, doRNG, foreach, gbm, earth</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-02-27 06:57:09 UTC; wl</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-02-27 08:41:32</td>
</tr>
</table>
<hr>
<h2 id='gbts'>Hyperparameter Search for Gradient Boosted Trees</h2><span id='topic+gbts'></span><span id='topic+gbts-package'></span>

<h3>Description</h3>

<p>This package implements hyperparameter optimization for Gradient Boosted
Trees (GBT) on binary classification and regression problems. The current
version provides two optimization methods:
</p>

<ul>
<li><p> Bayesian optimization:
</p>

<ol>
<li><p> A predictive model is built to capture the relationship between GBT
hyperparameters and the resulting predictive performance.
</p>
</li>
<li><p> Select the best hyperparameter setting (determined by a pre-specified
criterion) to try in the next iteration.
</p>
</li>
<li><p> Train GBT on the selected hyperparameter setting and compute validation
performance.
</p>
</li>
<li><p> Update the predictive model with the new validation performance. Go
back to step 2 and repeat.
</p>
</li></ol>

</li>
<li><p> Random search: each GBT is built with a randomly selected
hyperparameter setting.
</p>
</li></ul>

<p>Instead of returning a single GBT in the final output, an ensemble of GBTs
is produced via the method of ensemble selection. It selects GBTs with
replacement from a library into the ensemble, and returns the ensemble with
best validation performance. Model library and validation performance are
obtained from the hyperparameter search described above, by building GBTs
with different hyperparameter settings on the training dataset and obtaining
their performances on the validation dataset, based on cross-validation (CV).
Since selection from the library is done with replacement, each GBT may be
selected more than once into the ensemble. This function returns an ensemble
that contains only the unique GBTs with model weights calculated as the
number of model duplicates divided by the ensemble size. Each unique GBT in
the ensemble is re-trained on the full training data. Prediction is computed
as the weighted average of predictions from the re-trained GBTs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gbts(x, y, w = rep(1, nrow(x)), nitr = 200, nlhs = floor(nitr/2),
  nprd = 5000, kfld = 10, srch = c("bayes", "random"), nbst = 100,
  ensz = 100, nwrk = 2, rpkg = c("gbm"), pfmc = c("acc", "dev", "ks",
  "auc", "roc", "mse", "rsq", "mae"), cdfx = "fpr", cdfy = "tpr",
  dspt = 0.5, lower = c(2, 10, 0.1, 0.1, 0.01, 50, 1), upper = c(10, 200,
  1, 1, 0.1, 1000, 10), quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gbts_+3A_x">x</code></td>
<td>
<p>a data.frame of predictors. Categorical predictors represented as
<code>factors</code> are accepted.</p>
</td></tr>
<tr><td><code id="gbts_+3A_y">y</code></td>
<td>
<p>a vector of response values. For binary classification, <code>y</code>
must contain values of 0 and 1. It is unnecessary to convert <code>y</code> to a
factor variable. For regression, <code>y</code> must contain at least two unique
values.</p>
</td></tr>
<tr><td><code id="gbts_+3A_w">w</code></td>
<td>
<p>an optional vector of observation weights.</p>
</td></tr>
<tr><td><code id="gbts_+3A_nitr">nitr</code></td>
<td>
<p>an integer of the number of hyperparameter settings that are
sampled. For Bayesian optimization, <code>nitr</code> must be larger than
<code>nlhs</code>.</p>
</td></tr>
<tr><td><code id="gbts_+3A_nlhs">nlhs</code></td>
<td>
<p>an integer of the number of Latin Hypercube samples (each sample
is a hyperparameter setting) used to initialize the predictive model of GBT
performance. This is used for Bayesian optimization only. After
initialization, sequential search continues for <code>nitr-nlhs</code> iterations.</p>
</td></tr>
<tr><td><code id="gbts_+3A_nprd">nprd</code></td>
<td>
<p>an integer of the number of hyperparameter settings at which
GBT performance is estimated using the predictive model and the best is
selected to train GBT in the next iteration.</p>
</td></tr>
<tr><td><code id="gbts_+3A_kfld">kfld</code></td>
<td>
<p>an integer of the number of folds for cross-validation.</p>
</td></tr>
<tr><td><code id="gbts_+3A_srch">srch</code></td>
<td>
<p>a character of the search method such that <code>srch="bayes"</code>
performs Bayesian optimization (default), and <code>srch="random"</code> performs
random search.</p>
</td></tr>
<tr><td><code id="gbts_+3A_nbst">nbst</code></td>
<td>
<p>an integer of the number of bootstrap samples to construct the
predictive model of GBT performance.</p>
</td></tr>
<tr><td><code id="gbts_+3A_ensz">ensz</code></td>
<td>
<p>an integer value of the ensemble size - number of GBTs selected
into the ensemble. Since ensemble selection is done with replacement, the
number of unique GBTs may be less than <code>ensz</code>, but the sum of model
weights always equals <code>ensz</code>.</p>
</td></tr>
<tr><td><code id="gbts_+3A_nwrk">nwrk</code></td>
<td>
<p>an integer of the number of computing workers to use on a single
machine.</p>
</td></tr>
<tr><td><code id="gbts_+3A_rpkg">rpkg</code></td>
<td>
<p>a character indicating which R package implementation of GBT to
use. Currently, only the <code>gbm</code> R package is supported.</p>
</td></tr>
<tr><td><code id="gbts_+3A_pfmc">pfmc</code></td>
<td>
<p>a character of the performance metric used as the optimization
objective.
For binary classification, <code>pfmc</code> accepts:
</p>

<ul>
<li> <p><code>"acc"</code>: accuracy
</p>
</li>
<li> <p><code>"dev"</code>: deviance
</p>
</li>
<li> <p><code>"ks"</code>: Kolmogorov-Smirnov (KS) statistic
</p>
</li>
<li> <p><code>"auc"</code>: area under the ROC curve. Use the <code>cdfx</code> and
<code>cdfy</code> arguments to specify the cumulative distributions for the x-axis
and y-axis of the ROC curve, respectively. The default ROC curve is given by
true positive rate (y-axis) vs. false positive rate (x-axis).
</p>
</li>
<li> <p><code>"roc"</code>: rate on the y-axis of the ROC curve at a particular
decision point (threshold) on the x-axis specified by the <code>dspt</code>
argument. For example, if the desired performance metric is true positive
rate at the 5% false positive rate, specify <code>pfmc="roc"</code>,
<code>cdfx="fpr"</code>, <code>cdfy="tpr"</code>, and <code>dspt=0.05</code>.
</p>
</li></ul>

<p>For regression, <code>pfmc</code> accepts:
</p>

<ul>
<li> <p><code>"mse"</code>: mean squared error
</p>
</li>
<li> <p><code>"mae"</code>: mean absolute error
</p>
</li>
<li> <p><code>"rsq"</code>: r-squared (coefficient of determination)
</p>
</li></ul>
</td></tr>
<tr><td><code id="gbts_+3A_cdfx">cdfx</code></td>
<td>
<p>a character of the cumulative distribution for the x-axis.
Supported values are
</p>

<ul>
<li> <p><code>"fpr"</code>: false positive rate
</p>
</li>
<li> <p><code>"fnr"</code>: false negative rate
</p>
</li>
<li> <p><code>"rpp"</code>: rate of positive prediction
</p>
</li></ul>
</td></tr>
<tr><td><code id="gbts_+3A_cdfy">cdfy</code></td>
<td>
<p>a character of the cumulative distribution for the y-axis.
Supported values are
</p>

<ul>
<li> <p><code>"tpr"</code>: true positive rate
</p>
</li>
<li> <p><code>"tnr"</code>: true negative rate
</p>
</li></ul>
</td></tr>
<tr><td><code id="gbts_+3A_dspt">dspt</code></td>
<td>
<p>a decision point (threshold) in [0, 1] for binary classification.
If <code>pfmc="acc"</code>, instances with probabilities &lt;= <code>dspt</code> are
predicted as negative, and those with probabilities &gt; <code>dspt</code> are
predicted as positive. If <code>pfmc="roc"</code>, <code>dspt</code> is a threhold on the
x-axis of the ROC curve such that the corresponding value on the y-axis is
used as the performance metric. For example, if the desired performance
metric is the true positive rate at the 5% false positive rate, specify
<code>pfmc="roc"</code>, <code>cdfx="fpr"</code>, <code>cdfy="tpr"</code>, and <code>dspt=0.05</code>.</p>
</td></tr>
<tr><td><code id="gbts_+3A_lower">lower</code></td>
<td>
<p>a numeric vector containing the minimum values of
hyperparameters in the following order:
</p>

<ul>
<li><p> maximum tree depth
</p>
</li>
<li><p> leaf node size
</p>
</li>
<li><p> bag fraction
</p>
</li>
<li><p> fraction of predictors to try for each split
</p>
</li>
<li><p> shrinkage
</p>
</li>
<li><p> number of trees
</p>
</li>
<li><p> scale of weights for positive cases (for binary classification only)
</p>
</li></ul>
</td></tr>
<tr><td><code id="gbts_+3A_upper">upper</code></td>
<td>
<p>a numeric vector containing the maximum values of
hyperparameters in the order above.</p>
</td></tr>
<tr><td><code id="gbts_+3A_quiet">quiet</code></td>
<td>
<p>a logical of TRUE turns off the display of optimization progress
in the console.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of information with the following components:
</p>

<ul>
<li> <p><code>model</code>: an ensemble (list) of GBT model(s).
</p>
</li>
<li> <p><code>model_weight</code>: a vector of model weights whose sum equals
<code>ensz</code>.
</p>
</li>
<li> <p><code>best_idx</code>: an integer of the iteration index for the best
validation performance.
</p>
</li>
<li> <p><code>pred_val</code>: a matrix of cross-validation predictions where
<code>nrow(pred_val) = nrow(x)</code> and <code>ncol(pred_val) = nitr</code>.
</p>
</li>
<li> <p><code>perf_val</code>: a vector of cross-validation performance measures.
</p>
</li>
<li> <p><code>param</code>: a data.frame of hyperparameter settings visited. Each
row of the data.frame is a single hyperparameter setting.
</p>
</li>
<li> <p><code>objective</code>: a character of the objective function used.
</p>
</li>
<li> <p><code>time</code> a list of times:
</p>

<ul>
<li><p> pproc_time a numeric value of preprocessing time in minutes.
</p>
</li>
<li><p> binit_time a numeric value of initialization time in minutes for
Bayesian optimization.
</p>
</li>
<li><p> bsrch_time a numeric value of search time in minutes for
Bayesian optimization.
</p>
</li>
<li><p> rsrch_time a numeric value of random search time in minutes.
</p>
</li>
<li><p> enslt_time a numeric value of ensemble selection in minutes.
</p>
</li>
<li><p> refit_time a numeric value of refitting (on the full training data)
time in minutes.
</p>
</li>
<li><p> total_time a numeric value of the total time in minutes.
</p>
</li></ul>

</li>
<li> <p><code>...</code>: input arguments (excluding <code>x</code>, <code>y</code>, and
<code>w</code>).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Waley W. J. Liang &lt;<a href="mailto:wliang10@gmail.com">wliang10@gmail.com</a>&gt;
</p>


<h3>References</h3>

<p>Rich Caruana, Alexandru Niculescu-Mizil, Geoff Crew, and Alex
Ksikes. 2004. Ensemble selection from libraries of models. In Proceedings of
the 21st international conference on Machine learning (ICML'04).
<a href="http://www.cs.cornell.edu/~alexn/papers/shotgun.icml04.revised.rev2.pdf">http://www.cs.cornell.edu/~alexn/papers/shotgun.icml04.revised.rev2.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.gbts">predict.gbts</a></code>,
<code><a href="#topic+comperf">comperf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Binary classification

# Load German credit data
data(german_credit)
train &lt;- german_credit$train
test &lt;- german_credit$test
target_idx &lt;- german_credit$target_idx
pred_idx &lt;- german_credit$pred_idx

# Train a GBT model with optimization on AUC
model &lt;- gbts(train[, pred_idx], train[, target_idx], nitr = 200, pfmc = "auc")

# Predict on test data
yhat_test &lt;- predict(model, test[, pred_idx])

# Compute AUC on test data
comperf(test[, target_idx], yhat_test, pfmc = "auc")


# Regression

# Load Boston housing data
data(boston_housing)
train &lt;- boston_housing$train
test &lt;- boston_housing$test
target_idx &lt;- boston_housing$target_idx
pred_idx &lt;- boston_housing$pred_idx

# Train a GBT model with optimization on MSE
model &lt;- gbts(train[, pred_idx], train[, target_idx], nitr = 200, pfmc = "mse")

# Predict on test data
yhat_test &lt;- predict(model, test[, pred_idx])

# Compute MSE on test data
comperf(test[, target_idx], yhat_test, pfmc = "mse")

## End(Not run)
</code></pre>

<hr>
<h2 id='boston_housing'>Boston housing data</h2><span id='topic+boston_housing'></span>

<h3>Description</h3>

<p>This dataset concerns the values of 506 houses in suburbs of Boston.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boston_housing
</code></pre>


<h3>Format</h3>

<p>A list of 4 components:
</p>

<dl>
<dt>train</dt><dd><p>A <code>data.frame</code> of the training dataset which contains 354
rows and 14 columns.</p>
</dd>
<dt>test</dt><dd><p>A <code>data.frame</code> of the test dataset which contains 152 rows
and 14 columns.</p>
</dd>
<dt>target_idx</dt><dd><p>A column index of the target (response) varible.</p>
</dd>
<dt>pred_idx</dt><dd><p>A set of column indicies of the predictors.</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Housing">https://archive.ics.uci.edu/ml/datasets/Housing</a>
</p>

<hr>
<h2 id='comperf'>Compute model performance</h2><span id='topic+comperf'></span>

<h3>Description</h3>

<p>This function computes model performance given a vector of response values
and a vector of predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comperf(y, yhat, w = rep(1, length(y)), pfmc = NULL, cdfx = "fpr",
  cdfy = "tpr", dspt = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="comperf_+3A_y">y</code></td>
<td>
<p>a vector of numeric response values.</p>
</td></tr>
<tr><td><code id="comperf_+3A_yhat">yhat</code></td>
<td>
<p>a vector of model predictions.</p>
</td></tr>
<tr><td><code id="comperf_+3A_w">w</code></td>
<td>
<p>an optional vector of observation weights.</p>
</td></tr>
<tr><td><code id="comperf_+3A_pfmc">pfmc</code></td>
<td>
<p>a character of the performance metric. For binary classification,
<code>pfmc</code> accepts:
</p>

<ul>
<li> <p><code>"acc"</code>: accuracy
</p>
</li>
<li> <p><code>"dev"</code>: deviance
</p>
</li>
<li> <p><code>"ks"</code>: Kolmogorov-Smirnov (KS) statistic
</p>
</li>
<li> <p><code>"auc"</code>: area under the ROC curve. Use the <code>cdfx</code> and
<code>cdfy</code> arguments to specify the cumulative distributions for the x-axis
and y-axis of the ROC curve, respectively. The default ROC curve is given by
true positive rate (y-axis) vs. false positive rate (x-axis).
</p>
</li>
<li> <p><code>"roc"</code>: rate on the y-axis of the ROC curve at a particular
decision point (threshold) on the x-axis specified by the <code>dspt</code>
argument. For example, if the desired performance metric is true positive
rate at the 5% false positive rate, specify <code>pfmc="roc"</code>,
<code>cdfx="fpr"</code>, <code>cdfy="tpr"</code>, and <code>dspt=0.05</code>.
</p>
</li></ul>

<p>For regression, <code>pfmc</code> accepts:
</p>

<ul>
<li> <p><code>"mse"</code>: mean squared error
</p>
</li>
<li> <p><code>"mae"</code>: mean absolute error
</p>
</li>
<li> <p><code>"rsq"</code>: r-squared (coefficient of determination)
</p>
</li></ul>
</td></tr>
<tr><td><code id="comperf_+3A_cdfx">cdfx</code></td>
<td>
<p>a character of the cumulative distribution for the x-axis.
Supported values are
</p>

<ul>
<li> <p><code>"fpr"</code>: false positive rate
</p>
</li>
<li> <p><code>"fnr"</code>: false negative rate
</p>
</li>
<li> <p><code>"rpp"</code>: rate of positive prediction
</p>
</li></ul>
</td></tr>
<tr><td><code id="comperf_+3A_cdfy">cdfy</code></td>
<td>
<p>a character of the cumulative distribution for the y-axis.
Supported values are
</p>

<ul>
<li> <p><code>"tpr"</code>: true positive rate
</p>
</li>
<li> <p><code>"tnr"</code>: true negative rate
</p>
</li></ul>
</td></tr>
<tr><td><code id="comperf_+3A_dspt">dspt</code></td>
<td>
<p>a decision point (threshold) in [0, 1] for binary classification.
If <code>pfmc="acc"</code>, instances with probabilities &lt;= <code>dspt</code> are
predicted as negative, and those with probabilities &gt; <code>dspt</code> are
predicted as positive. If <code>pfmc="roc"</code>, <code>dspt</code> is a threhold on the
x-axis of the ROC curve such that the corresponding value on the y-axis is
used as the performance metric. For example, if the desired performance
metric is the true positive rate at the 5% false positive rate, specify
<code>pfmc="roc"</code>, <code>cdfx="fpr"</code>, <code>cdfy="tpr"</code>, and <code>dspt=0.05</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single or a vector of numeric values of model performance, or a
list of two components <code>x</code> and <code>y</code> representing the ROC curve.
</p>


<h3>Author(s)</h3>

<p>Waley W. J. Liang &lt;<a href="mailto:wliang10@gmail.com">wliang10@gmail.com</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gbts">gbts</a></code>,
<code><a href="#topic+predict.gbts">predict.gbts</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y = c(0, 1, 0, 1, 1, 1)
yhat = c(0.5, 0.9, 0.2, 0.7, 0.6,  0.4)
comperf(y, yhat, pfmc = "auc")
# 0.875

y = 1:10
yhat = c(1:5 - 0.1, 6:10 + 0.1)
comperf(y, yhat, pfmc = "mse")
# 0.01

</code></pre>

<hr>
<h2 id='german_credit'>German credit data</h2><span id='topic+german_credit'></span>

<h3>Description</h3>

<p>This dataset classifies 1,000 people described by a set of attributes as
good or bad credit risks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>german_credit
</code></pre>


<h3>Format</h3>

<p>A list of 4 components:
</p>

<dl>
<dt>train</dt><dd><p>A <code>data.frame</code> of the training dataset which contains 700
rows and 21 columns.</p>
</dd>
<dt>test</dt><dd><p>A <code>data.frame</code> of the test dataset which contains 300 rows
and 21 columns.</p>
</dd>
<dt>target_idx</dt><dd><p>A column index of the target (response) varible.</p>
</dd>
<dt>pred_idx</dt><dd><p>A set of column indicies of the predictors.</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)</a>
</p>

<hr>
<h2 id='predict.gbts'>Predict method for ensemble of Gradient Boosted Trees</h2><span id='topic+predict.gbts'></span>

<h3>Description</h3>

<p>This function generates predictions by weighted averaging the predictions
from each model in the ensemble returned from <code><a href="#topic+gbts">gbts</a></code>. Weighted
average is computed on the log-odds scale for binary classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gbts'
predict(object, x, nwrk = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.gbts_+3A_object">object</code></td>
<td>
<p>a model object returned from <code><a href="#topic+gbts">gbts</a></code>.</p>
</td></tr>
<tr><td><code id="predict.gbts_+3A_x">x</code></td>
<td>
<p>a data.frame of predictors. It must follow the same format as the
training dataset on which the model <code>object</code> is developed.</p>
</td></tr>
<tr><td><code id="predict.gbts_+3A_nwrk">nwrk</code></td>
<td>
<p>an integer of the number of computing workers to be used. If
<code>nwrk</code> is less than the number of available cores on the machine, it
uses all available cores.</p>
</td></tr>
<tr><td><code id="predict.gbts_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of predictions. In the case of binary classification,
predictions are probabilities.
</p>


<h3>Author(s)</h3>

<p>Waley W. J. Liang &lt;<a href="mailto:wliang10@gmail.com">wliang10@gmail.com</a>&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gbts">gbts</a></code>,
<code><a href="#topic+comperf">comperf</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
