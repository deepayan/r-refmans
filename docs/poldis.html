<!DOCTYPE html><html lang="en"><head><title>Help for package poldis</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {poldis}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#annotate_text'><p>Annotate text with NLP</p></a></li>
<li><a href='#extract_context'><p>Extract context for string matches</p></a></li>
<li><a href='#extract_date'><p>Extract dates from text</p></a></li>
<li><a href='#extract_locations'><p>Extract locations from strings</p></a></li>
<li><a href='#extract_match'><p>Extract text matches</p></a></li>
<li><a href='#extract_names'><p>Extract a list of possible names of individuals in texts</p></a></li>
<li><a href='#extract_text_similarities'><p>Extract similarities and differences in texts/segments</p></a></li>
<li><a href='#extract_title'><p>Extract first sentence from text</p></a></li>
<li><a href='#gather_related_terms'><p>Gather terms related to subjects</p></a></li>
<li><a href='#gather_topics'><p>Gather topic from political discourses</p></a></li>
<li><a href='#get_urgency'><p>Urgency Analysis</p></a></li>
<li><a href='#read_pdf'><p>Read text from PDFs</p></a></li>
<li><a href='#select_priorities'><p>Select future priorities from political discourses</p></a></li>
<li><a href='#sim_urgency'><p>Simulating urgency in priorities</p></a></li>
<li><a href='#split_text'><p>Split texts</p></a></li>
<li><a href='#US_News_Conferences_1960_1980'><p>US News Conferences Data from 1960 to 1980</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyse Political Texts</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-09-03</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Henrique Sposito &lt;henrique.sposito@graduateinstitute.ch&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Wrangle and annotate different types of political texts.
    It also introduces Urgency Analysis,
    a new method for the analysis of urgency in political texts.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://henriquesposito.com/poldis/">http://henriquesposito.com/poldis/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/henriquesposito/poldis/issues">https://github.com/henriquesposito/poldis/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, stringr, purrr, stringi, quanteda, spacyr, textstem,
tidyr, stringdist</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, testthat, tesseract, quanteda.textstats, keyATM,
messydates, pdftools, fmsb, ggplot2, tm, cli</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>True</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-09-04 16:00:04 UTC; henriquesposito</td>
</tr>
<tr>
<td>Author:</td>
<td>Henrique Sposito <a href="https://orcid.org/0000-0003-3420-6085"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut, ctb] (IHEID),
  James Hollway <a href="https://orcid.org/0000-0002-8361-9647"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb] (IHEID),
  Jael Tan <a href="https://orcid.org/0000-0002-6234-9764"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]
    (IHEID)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-09-04 16:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='annotate_text'>Annotate text with NLP</h2><span id='topic+annotate_text'></span>

<h3>Description</h3>

<p>This function relies on '{spacyr}' NLP parsing to annotate texts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>annotate_text(v, level = "words")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="annotate_text_+3A_v">v</code></td>
<td>
<p>Text vector</p>
</td></tr>
<tr><td><code id="annotate_text_+3A_level">level</code></td>
<td>
<p>At which level would you like to parse the text?
Options include &quot;words&quot; or &quot;sentences&quot;.
Defaults to &quot;words&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with syntax information by words or sentences in text.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#annotate_text(US_News_Conferences_1960_1980[1:2, 3])
#annotate_text(US_News_Conferences_1960_1980[1:2, 3], level = "sentence")
</code></pre>

<hr>
<h2 id='extract_context'>Extract context for string matches</h2><span id='topic+extract_context'></span>

<h3>Description</h3>

<p>A function for getting string matches and the context in which they occur.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_context(match, v, level = "sentences", n = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_context_+3A_match">match</code></td>
<td>
<p>Character string to be matched.
For multiple strings, please use &quot;|&quot; as a separator.</p>
</td></tr>
<tr><td><code id="extract_context_+3A_v">v</code></td>
<td>
<p>Text vector or annotated data frame.</p>
</td></tr>
<tr><td><code id="extract_context_+3A_level">level</code></td>
<td>
<p>At which text level do you want matches to be returned?
Defaults to &quot;sentences&quot;.
Options are sentences, words, and paragraph.</p>
</td></tr>
<tr><td><code id="extract_context_+3A_n">n</code></td>
<td>
<p>Number of sentences or words matched before and after string match.
Defaults to 1.
That is, one word or one sentence before, and after, string match.
For paragraphs, n is always set to one.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of string matches and their context.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
extract_context(match = "war|weapons of mass destruction|conflict|NATO|peace",
                v = US_News_Conferences_1960_1980$text[100],
                level = "sentences", n = 2)

</code></pre>

<hr>
<h2 id='extract_date'>Extract dates from text</h2><span id='topic+extract_date'></span>

<h3>Description</h3>

<p>Wrapper function for 'messydates::as_messydates'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_date(v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_date_+3A_v">v</code></td>
<td>
<p>Text vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of the dates in text.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#extract_date("Today is the twenty six of February of two thousand and twenty four")
</code></pre>

<hr>
<h2 id='extract_locations'>Extract locations from strings</h2><span id='topic+extract_locations'></span>

<h3>Description</h3>

<p>Extract locations from strings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_locations(v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_locations_+3A_v">v</code></td>
<td>
<p>Text vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function relies on geographical entity detection from NLP models.
</p>


<h3>Value</h3>

<p>A data frame of locations and the number of times they appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#extract_locations(c("This is the United States", "This is Sao Paulo",
#"I was in Rio de Janeiro and Sao Paulo, then back to the United States"))
</code></pre>

<hr>
<h2 id='extract_match'>Extract text matches</h2><span id='topic+extract_match'></span>

<h3>Description</h3>

<p>Get texts in which certain &quot;matches&quot; occur.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_match(v, match, invert = FALSE, ignore.case = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_match_+3A_v">v</code></td>
<td>
<p>Text vector or annotated data frame.</p>
</td></tr>
<tr><td><code id="extract_match_+3A_match">match</code></td>
<td>
<p>A regex match for a word(s) or expression.
For multiple words, please use &quot;|&quot; to divide them.</p>
</td></tr>
<tr><td><code id="extract_match_+3A_invert">invert</code></td>
<td>
<p>Do you want texts without certain matches to be returned?
By default FALSE.</p>
</td></tr>
<tr><td><code id="extract_match_+3A_ignore.case">ignore.case</code></td>
<td>
<p>Should case be ignored?
By default, TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list the same length as text variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
extract_match(c("This function was created on the 29 September 2021",
"Today is October 12, 2021"), "October")

</code></pre>

<hr>
<h2 id='extract_names'>Extract a list of possible names of individuals in texts</h2><span id='topic+extract_names'></span>

<h3>Description</h3>

<p>Extract a list of possible names of individuals in texts
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_names(v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_names_+3A_v">v</code></td>
<td>
<p>A text vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function relies on named entity recognition from NLP models.
</p>


<h3>Value</h3>

<p>A data frame of individual names and the number of times they appear.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#extract_names(US_News_Conferences_1960_1980[20, 3])
</code></pre>

<hr>
<h2 id='extract_text_similarities'>Extract similarities and differences in texts/segments</h2><span id='topic+extract_text_similarities'></span>

<h3>Description</h3>

<p>Extract similarities and differences in texts/segments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_text_similarities(v, comparison = "similarities", method)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_text_similarities_+3A_v">v</code></td>
<td>
<p>Text vector or annotated data frame.</p>
</td></tr>
<tr><td><code id="extract_text_similarities_+3A_comparison">comparison</code></td>
<td>
<p>How would you like to compare texts?
Options are &quot;similarities&quot;, for comparing similarities, or &quot;differences&quot;,
for comparing differences.
Defaults to &quot;similarities&quot;.</p>
</td></tr>
<tr><td><code id="extract_text_similarities_+3A_method">method</code></td>
<td>
<p>A method for checking similarities or differences between texts.
For similarities, defaults to &quot;correlation&quot; method.
Other methods for similarities include &quot;cosine&quot;, &quot;jaccard&quot;, &quot;ejaccard&quot;,
&quot;dice&quot;, &quot;edice&quot;, &quot;simple matching&quot;, and &quot;hamann&quot;.
For differences, defaults to &quot;euclidean&quot;.
Other methods for differences include &quot;manhattan&quot;, &quot;maximum&quot;,
&quot;canberra&quot;, and &quot;minkowski&quot;.
For more information on each of these methods and what are the implications
in selecting a method, please see '?quanteda.textstats::textstat_simil()'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of similarity scores between texts.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#extract_text_similarities(US_News_Conferences_1960_1980[1:2,3])
</code></pre>

<hr>
<h2 id='extract_title'>Extract first sentence from text</h2><span id='topic+extract_title'></span>

<h3>Description</h3>

<p>A lot of information is contained in the first sentence of a text.
In political texts, for example, dates and locations are often contained
in the first sentence of the text.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_title(v)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_title_+3A_v">v</code></td>
<td>
<p>Text vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the first sentences in text.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>extract_title("This is the first sentence. This is the second sentence.")
</code></pre>

<hr>
<h2 id='gather_related_terms'>Gather terms related to subjects</h2><span id='topic+gather_related_terms'></span>

<h3>Description</h3>

<p>Gather terms related to subjects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gather_related_terms(.data, dictionary)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gather_related_terms_+3A_.data">.data</code></td>
<td>
<p>A data frame, priorities data frame coded using
'select_priorities()', or text vector.
For data frames, function will search for &quot;text&quot; variable.
For priorities data frame function will search for &quot;priorities&quot; variable.</p>
</td></tr>
<tr><td><code id="gather_related_terms_+3A_dictionary">dictionary</code></td>
<td>
<p>The dictionary of 20 major political topics from the
Comparative Agendas Project (Jones et al., 2023) is used by default.
Users can also declare a custom dictionary as a vector or a list.
If users declare a vector, each element is treated as a independent topic.
If users declare a list of subjects and related terms, function understands
names as topic and words as terms.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function relies on keyword assisted topic models implemented
in the '{keyATM}' package to find related words based on the topics
provided and texts in which they appear.
</p>


<h3>Value</h3>

<p>A list of related terms to each of the topics declared in dictionary.
</p>


<h3>References</h3>

<p>Eshima S, Imai K, and Sasaki T. 2024.
“Keyword-Assisted Topic Models.”
_American Journal of Political Science_, 68(2): 730-750.
<a href="https://doi.org/10.1111/ajps.12779">doi:10.1111/ajps.12779</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#gather_related_terms(US_News_Conferences_1960_1980[1:5, 3], dictionary = "CAP")
#gather_related_terms(US_News_Conferences_1960_1980[1:5, 3],
#                     dictionary = c("military", "development"))
#gather_related_terms(US_News_Conferences_1960_1980[1:5, 3],
#                     dictionary = list("military" = c("military", "gun", "war"),
#                                       "development" = c("development", "interest rate", "banks")))
</code></pre>

<hr>
<h2 id='gather_topics'>Gather topic from political discourses</h2><span id='topic+gather_topics'></span>

<h3>Description</h3>

<p>Gather topic from political discourses
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gather_topics(.data, dictionary = "CAP")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gather_topics_+3A_.data">.data</code></td>
<td>
<p>A data frame, priorities data frame coded using
'select_priorities()', or text vector.
For data frames, function will search for &quot;text&quot; variable.
For priorities data frame function will search for &quot;priorities&quot; variable.
If missing, opens the webpage containing the political topics codebook.</p>
</td></tr>
<tr><td><code id="gather_topics_+3A_dictionary">dictionary</code></td>
<td>
<p>The dictionary of 20 major political topics from the
Comparative Agendas Project (Jones et al., 2023) is used by default.
Users can also declare a custom dictionary as a vector or a list.
If users declare a vector, each element is treated as a independent topic.
If users declare a list of subjects and related terms, function understands
names as topic and words as terms.
For more information on how the CAP topics were adapted, please run
'gather_topics()' to access the political topics codebook.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of topics present in each text separated by comma.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
gather_topics(US_News_Conferences_1960_1980[1:5, 3])
gather_topics(US_News_Conferences_1960_1980[1:5, 3],
              dictionary = c("military", "development"))
gather_topics(US_News_Conferences_1960_1980[1:5, 3],
              dictionary = list("military" = c("military", "gun", "war"),
                                "development" = c("development", "interest rate", "banks")))
#summary(gather_topics(US_News_Conferences_1960_1980[1:5, 3]))
#plot(gather_topics(US_News_Conferences_1960_1980[1:5, 3],
#                   dictionary = c("military", "development")))

</code></pre>

<hr>
<h2 id='get_urgency'>Urgency Analysis</h2><span id='topic+get_urgency'></span>

<h3>Description</h3>

<p>Urgency Analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_urgency(.data, summarise = "sum")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_urgency_+3A_.data">.data</code></td>
<td>
<p>A data frame, priorities data frame coded using
'select_priorities()', or text vector.
For data frames, function will search for &quot;text&quot; variable.
For priorities data frame function will search for &quot;priorities&quot; variable.
If missing, opens the webpage containing the urgency codebook.</p>
</td></tr>
<tr><td><code id="get_urgency_+3A_summarise">summarise</code></td>
<td>
<p>How to handle multiple matches for the same dimension
in the same text observation?
By default, multiple matches are added together and
their &quot;sum&quot; per text observation is returned.
Users can, instead, choose the &quot;mean&quot; which returns the average
score per dimension per text observation when there are multiple matches.
The &quot;mean&quot; can also be used as a form of normalization per
dimension and text observation in certain cases.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Urgency in political discourses is an expression of how necessary and/or
how soon an action should be undertaken or completed.
This is measured along four dimensions,
two related to necessity and two related to timing.
The first two dimensions, degree of intensity and degree of commitment,
relate to the necessity of taking the action, while the next two dimensions,
frequency of action and timing of action,
relate to the timing in which action is taken.
Our dictionary includes terms in each of these dimensions.
The terms included in each of these dimensions were validated and adjusted
through an online survey that took place between July and August of 2024.
The survey results were recorded as counts of the number of participants
who selected an urgency-related word as more urgent than its pair.
To analyze the survey results, we employed Bradley-Terry models for
paired comparisons.
A rank of the words for each dimension of urgency was obtained from the analysis,
which were then used to create the urgency word scores in the dictionaries.
For more information on the dimensions, scores, or the survey on urgency,
please run 'get_urgency()' to access the urgency codebook.
For priorities (i.e. coded using the 'select_priorities()'),
urgency scores are calculated by multiplying the commitment scores by all
other dimensions.
This is done because commitment words are indicative of political priorities,
For more information please refer to the 'select_priorities()' function.
For vectors or data frames urgency scores are calculated by
adding commitment and intensity dimension scores (i.e. how necessary)
and multiplying these by the sum of timing and frequency dimension
scores (i.e. how soon).
In both cases, zero urgency scores are indicative of no urgency but maximum
scores can vary.
</p>


<h3>Value</h3>

<p>A scored data frame for each dimension of urgency.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
get_urgency(US_News_Conferences_1960_1980[1:10, 3])
get_urgency(US_News_Conferences_1960_1980[1:10,])
#get_urgency(select_priorities(US_News_Conferences_1960_1980[1:2, 3]))
#summary(get_urgency(US_News_Conferences_1960_1980[1:10, 3]))
#plot(get_urgency(US_News_Conferences_1960_1980[1:10, 3]))
#get_urgency()

</code></pre>

<hr>
<h2 id='read_pdf'>Read text from PDFs</h2><span id='topic+read_pdf'></span>

<h3>Description</h3>

<p>Read text from PDFs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_pdf(path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_pdf_+3A_path">path</code></td>
<td>
<p>The path to a PDF file or a folder containing multiple PDFs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of texts.
</p>

<hr>
<h2 id='select_priorities'>Select future priorities from political discourses</h2><span id='topic+select_priorities'></span>

<h3>Description</h3>

<p>Political priorities are statements in which actors express their
intent or commitment to take political action in the future.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_priorities(.data, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="select_priorities_+3A_.data">.data</code></td>
<td>
<p>A (annotated) data frame or text vector.
For data frames, function will search for &quot;text&quot; variable.
For annotated data frames, please declare an annotated data frame
at the sentence level.</p>
</td></tr>
<tr><td><code id="select_priorities_+3A_na.rm">na.rm</code></td>
<td>
<p>Would you like political statements that do not contain a
political action to be removed?
By default, TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with syntax information by sentences and
a variable identifying which of these sentences are priorities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#select_priorities(US_News_Conferences_1960_1980[1:2,3])
</code></pre>

<hr>
<h2 id='sim_urgency'>Simulating urgency in priorities</h2><span id='topic+sim_urgency'></span>

<h3>Description</h3>

<p>Simulating urgency in priorities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_urgency(urgency, commitment, intensity, timing, frequency, pronoun = "We")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_urgency_+3A_urgency">urgency</code></td>
<td>
<p>Desired urgency score, optional.</p>
</td></tr>
<tr><td><code id="sim_urgency_+3A_commitment">commitment</code></td>
<td>
<p>Desired commitment score, optional.</p>
</td></tr>
<tr><td><code id="sim_urgency_+3A_intensity">intensity</code></td>
<td>
<p>Desired intensity score, optional.</p>
</td></tr>
<tr><td><code id="sim_urgency_+3A_timing">timing</code></td>
<td>
<p>Desired timing score, optional.</p>
</td></tr>
<tr><td><code id="sim_urgency_+3A_frequency">frequency</code></td>
<td>
<p>Desired frequency score, optional.</p>
</td></tr>
<tr><td><code id="sim_urgency_+3A_pronoun">pronoun</code></td>
<td>
<p>How would you like the simulated priorities to start?
By default, priorities start with the pronoun &quot;We&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users can declare a score for one or more of the
urgency dimensions or an urgency score.
This means, if users may not declare an urgency score and the
score for one or more dimensions at once.
In those cases, the urgency score is favored.
</p>


<h3>Value</h3>

<p>A sentence that matches the urgency or urgency dimension scores.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim_urgency()
sim_urgency(urgency = 0.5)
sim_urgency(urgency = 2.5)
sim_urgency(urgency = -2.5)
sim_urgency(commitment = 0.6)
sim_urgency(commitment = 0.6, intensity = 1.4)
sim_urgency(commitment = 0.6, intensity = 1.4, timing = 1.4)
sim_urgency(commitment = 0.6, intensity = 1.2, timing = 1.4, frequency = 1.8)

</code></pre>

<hr>
<h2 id='split_text'>Split texts</h2><span id='topic+split_text'></span>

<h3>Description</h3>

<p>Split texts into structured lists of lists according to a split sign.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_text(v, splitsign = "\\.")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="split_text_+3A_v">v</code></td>
<td>
<p>Text vector or annotated data frame.</p>
</td></tr>
<tr><td><code id="split_text_+3A_splitsign">splitsign</code></td>
<td>
<p>Where do you want to split?
By default sentences (&quot;.&quot;).
This can also be words, signals or other markers you want.
For special characters, please use escape sign before (i.e. &quot;\&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of lists the same length as vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
split_text("This is the first sentence. This is the second sentence.")

</code></pre>

<hr>
<h2 id='US_News_Conferences_1960_1980'>US News Conferences Data from 1960 to 1980</h2><span id='topic+US_News_Conferences_1960_1980'></span>

<h3>Description</h3>

<p>A dataset containing the news conferences from US presidents
from 1960 to 1980.
The dataset was gathered from the American Presidency Project website.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(US_News_Conferences_1960_1980)
</code></pre>


<h3>Format</h3>

<p>A data frame with 353 rows and 3 variables: the president,
the date, and the full text.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
