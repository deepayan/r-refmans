<!DOCTYPE html><html><head><title>Help for package LGDtoolkit</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {LGDtoolkit}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#embedded.blocks'><p>Embedded blocks regression</p></a></li>
<li><a href='#ensemble.blocks'><p>Ensemble blocks regression</p></a></li>
<li><a href='#heterogeneity'><p>Testing heterogeneity of the LGD rating model</p></a></li>
<li><a href='#homogeneity'><p>Testing homogeneity of the LGD rating model</p></a></li>
<li><a href='#interaction.transformer'><p>Extract risk factors interaction from decision tree</p></a></li>
<li><a href='#kfold.idx'><p>Indices for K-fold validation</p></a></li>
<li><a href='#kfold.vld'><p>K-fold model cross-validation</p></a></li>
<li><a href='#lgd.ds.c'><p>Synthetic modeling dataset</p></a></li>
<li><a href='#r.squared'><p>Coefficient of determination</p></a></li>
<li><a href='#rf.interaction.transformer'><p>Extract interactions from random forest</p></a></li>
<li><a href='#sc.merge'><p>Special case merging procedure</p></a></li>
<li><a href='#staged.blocks'><p>Staged blocks regression</p></a></li>
<li><a href='#stepFWD'><p>Customized stepwise (OLS &amp; fractional logistic) regression with p-value and trend check</p></a></li>
<li><a href='#stepRPC'><p>Stepwise (OLS &amp; fractional logistic) regression based on risk profile concept</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Collection of Tools for LGD Rating Model Development</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrija Djurovic &lt;djandrija@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The goal of this package is to cover the most common steps in Loss Given Default (LGD) rating model development.
             The main procedures available are those that refer to bivariate and multivariate analysis. In particular two statistical methods for 
             multivariate analysis are currently implemented â€“ OLS regression and fractional logistic regression.
             Both methods are also available within different blockwise model designs and both have customized stepwise algorithms. 
             Descriptions of these customized designs are available in Siddiqi (2016) &lt;<a href="https://doi.org/10.1002%2F9781119282396.ch10">doi:10.1002/9781119282396.ch10</a>&gt; and 
             Anderson, R.A. (2021) &lt;<a href="https://doi.org/10.1093%2Foso%2F9780192844194.001.0001">doi:10.1093/oso/9780192844194.001.0001</a>&gt;. 
             Although they are explained for PD model, the same designs are applicable for LGD model with different underlying regression methods 
             (OLS and fractional logistic regression). To cover other important steps for LGD model development, it is recommended to use 
             'LGDtoolkit' package along with 'PDtoolkit', and 'monobin' (or 'monobinShiny') packages.
             Additionally, 'LGDtoolkit' provides set of procedures handy for initial and periodical model validation. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/andrija-djurovic/LGDtoolkit">https://github.com/andrija-djurovic/LGDtoolkit</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, monobin</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-30 09:00:05 UTC; adjurovic</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrija Djurovic [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-30 09:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='embedded.blocks'>Embedded blocks regression</h2><span id='topic+embedded.blocks'></span>

<h3>Description</h3>

<p><code>embedded.blocks</code> performs blockwise regression where the predictions of each blocks' model is used as an
risk factor for the model of the following block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embedded.blocks(method, target, db, blocks, reg.type = "ols", p.value = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="embedded.blocks_+3A_method">method</code></td>
<td>
<p>Regression method applied on each block.
Available methods: <code>"stepFWD"</code> or <code>"stepRPC"</code>.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_blocks">blocks</code></td>
<td>
<p>Data frame with defined risk factor groups. It has to contain the following columns: <code>rf</code> and
<code>block</code>.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_reg.type">reg.type</code></td>
<td>
<p>Regression type. Available options are: <code>"ols"</code> for OLS regression and <code>"frac.logit"</code> for
fractional logistic regression. Default is <code>"ols"</code>. For <code>"frac.logit"</code> option, target has to have
all values between 0 and 1.</p>
</td></tr>
<tr><td><code id="embedded.blocks_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value for the estimated coefficient. For numerical risk factors this value is
is directly compared to p-value of the estimated coefficient, while for categorical
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>embedded.blocks</code> returns a list of three objects.<br />
The first object (<code>model</code>) is the list of the models of each block (an object of class inheriting from <code>"lm"</code>).<br />
The second object (<code>steps</code>), is the data frame with risk factors selected from the each block.<br />
The third object (<code>dev.db</code>), returns the list of block's model development databases.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+staged.blocks">staged.blocks</a></code>, <code><a href="#topic+ensemble.blocks">ensemble.blocks</a></code>, <code><a href="#topic+stepFWD">stepFWD</a></code> and <code><a href="#topic+stepRPC">stepRPC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#stepwise with discretized risk factors
#same procedure can be run on continuous risk factors and mixed risk factor types
num.rf &lt;- sapply(lgd.ds.c, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"lgd" &amp; num.rf]
num.rf
for	(i in 1:length(num.rf)) {
num.rf.l &lt;- num.rf[i]
lgd.ds.c[, num.rf.l] &lt;- sts.bin(x = lgd.ds.c[, num.rf.l], y = lgd.ds.c[, "lgd"])[[2]]	
}
str(lgd.ds.c)
set.seed(321)
blocks &lt;- data.frame(rf = names(lgd.ds.c)[!names(lgd.ds.c)%in%"lgd"], 
		   block = sample(1:3, ncol(lgd.ds.c) - 1, rep = TRUE))
blocks &lt;- blocks[order(blocks$block, blocks$rf), ]
lgd.ds.c$lgd[lgd.ds.c$lgd &gt; 1] &lt;- 1
res &lt;- LGDtoolkit::embedded.blocks(method = "stepRPC", 
		     target = "lgd",
		     db = lgd.ds.c, 
		     blocks = blocks,
		     reg.type = "frac.logit", 
		     p.value = 0.05)
names(res)
res$models
summary(res$models[[3]])
</code></pre>

<hr>
<h2 id='ensemble.blocks'>Ensemble blocks regression</h2><span id='topic+ensemble.blocks'></span>

<h3>Description</h3>

<p><code>ensemble.blocks</code> performs blockwise regression where the predictions of each blocks' model are
integrated into a final model. The final model is estimated in the form of OLS or fractional
logistic regression regression without any check of the estimated coefficients
(e.g. statistical significance or sign of the estimated coefficients).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ensemble.blocks(method, target, db, blocks, reg.type = "ols", p.value = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ensemble.blocks_+3A_method">method</code></td>
<td>
<p>Regression method applied on each block.
Available methods: <code>"stepFWD"</code> or <code>"stepRPC"</code>.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_blocks">blocks</code></td>
<td>
<p>Data frame with defined risk factor groups. It has to contain the following columns: <code>rf</code> and
<code>block</code>.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_reg.type">reg.type</code></td>
<td>
<p>Regression type. Available options are: <code>"ols"</code> for OLS regression and <code>"frac.logit"</code> for
fractional logistic regression. Default is <code>"ols"</code>. For <code>"frac.logit"</code> option, target has to have
all values between 0 and 1.</p>
</td></tr>
<tr><td><code id="ensemble.blocks_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value for the estimated coefficient. For numerical risk factors this value is
is directly compared to p-value of the estimated coefficient, while for categorical
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>embeded.blocks</code> returns a list of three objects.<br />
The first object (<code>model</code>) is the list of the models of each block (an object of class inheriting from <code>"lm"</code>).<br />
The second object (<code>steps</code>), is the data frame with risk factors selected from the each block.<br />
The third object (<code>dev.db</code>), returns the list of block's model development databases.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+staged.blocks">staged.blocks</a></code>, <code><a href="#topic+embedded.blocks">embedded.blocks</a></code>, <code><a href="#topic+stepFWD">stepFWD</a></code> and <code><a href="#topic+stepRPC">stepRPC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#stepwise with discretized risk factors
#same procedure can be run on continuous risk factors and mixed risk factor types
num.rf &lt;- sapply(lgd.ds.c, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"lgd" &amp; num.rf]
num.rf
for	(i in 1:length(num.rf)) {
num.rf.l &lt;- num.rf[i]
lgd.ds.c[, num.rf.l] &lt;- sts.bin(x = lgd.ds.c[, num.rf.l], y = lgd.ds.c[, "lgd"])[[2]]	
}
str(lgd.ds.c)
set.seed(2211)
blocks &lt;- data.frame(rf = names(lgd.ds.c)[!names(lgd.ds.c)%in%"lgd"], 
		   block = sample(1:3, ncol(lgd.ds.c) - 1, rep = TRUE))
blocks &lt;- blocks[order(blocks$block, blocks$rf), ]
res &lt;- LGDtoolkit::ensemble.blocks(method = "stepFWD", 
		     target = "lgd",
		     db = lgd.ds.c, 
		     blocks = blocks,
		     reg.type = "ols", 
		     p.value = 0.05)
names(res)
res$models
summary(res$models[[4]])
</code></pre>

<hr>
<h2 id='heterogeneity'>Testing heterogeneity of the LGD rating model</h2><span id='topic+heterogeneity'></span>

<h3>Description</h3>

<p><code>heterogeneity</code> performs heterogeneity testing of LGD model based on the rating pools.
This test is usually applied on application portfolio, but it can be applied also on model development sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heterogeneity(app.port, loss, pools, method = "t.test", alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heterogeneity_+3A_app.port">app.port</code></td>
<td>
<p>Application portfolio (data frame) which contains realized loss (LGD) values and
LGD pools in use.</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_loss">loss</code></td>
<td>
<p>Name of the column that represents realized loss (LGD).</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_pools">pools</code></td>
<td>
<p>Name of the column that represents LGD pools.</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_method">method</code></td>
<td>
<p>Statistical test. Available options are <code>t.test</code> (default) and <code>wilcox.test</code>.</p>
</td></tr>
<tr><td><code id="heterogeneity_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of statistical test. Default is 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Testing procedure starts with summarizing the number of observations and average loss per LGD pool.
After that statistical test is applied on adjacent rating grades. Testing hypothesis is that
average realized loss of pool <code>i</code> is less or greater than average realized loss of pools <code>i - 1</code>, where <code>i</code>
takes the values from 2 to the number of unique pools.
Direction of alternative hypothesis (less or greater) is determined automatically based on correlation direction
of realized average loss per pool.
Incomplete cases, identified based on realized loss (<code>loss</code>) and rating pool (<code>pools</code>)
columns are excluded from the summary table and testing procedure. If identified, warning will be returned.
</p>


<h3>Value</h3>

<p>The command <code>heterogeneity</code> returns a data frame with the following columns:
</p>

<ul>
<li><p> pool: Unique values of pool from application portfolio.
</p>
</li>
<li><p> no: Number of complete observations.
</p>
</li>
<li><p> mean: Average realized loss.
</p>
</li>
<li><p> alpha: Selected significance level
</p>
</li>
<li><p> p.val: Test p-value.
</p>
</li>
<li><p> res: Accepted hypothesis.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#build dummy model
rf &lt;- c("rf_02", "rf_01", "rf_16", "rf_03", "rf_09")
for   (i in 1:length(rf)) {
     rf_l &lt;- rf[i]
     lgd.ds.c[, rf_l] &lt;- sts.bin(x = lgd.ds.c[, rf_l], 
                                 y = lgd.ds.c[, "lgd"])[[2]]	
     }
str(lgd.ds.c)
frm &lt;- paste0("lgd ~ ", paste(rf, collapse = " + "))
model &lt;- lm(formula = as.formula(frm), data = lgd.ds.c)
summary(model)$coefficients
summary(model)$r.squared
#create lgd pools
lgd.ds.c$pred &lt;- unname(predict(model))
lgd.ds.c$pool &lt;- sts.bin(x = lgd.ds.c$pred, 
                        y = lgd.ds.c$lgd)[[2]]
#create dummy application portfolio
set.seed(642)
app.port &lt;- lgd.ds.c[sample(1:nrow(lgd.ds.c), 500, replace = FALSE), ]
#simulate realized lgd values
app.port$lgd.r &lt;- app.port$lgd
#test heterogeneity
heterogeneity(app.port = app.port, 
	  loss = "lgd.r", 
	  pools = "pool", 
             method = "t.test", 
             alpha = 0.05) 
</code></pre>

<hr>
<h2 id='homogeneity'>Testing homogeneity of the LGD rating model</h2><span id='topic+homogeneity'></span>

<h3>Description</h3>

<p><code>homogeneity</code> performs homogeneity testing of LGD model based on the rating pools and selected segment.
This test is usually applied on application portfolio, but it can be applied also on model development sample.
Additionally, this method requires higher number of observations per segment modalities within each rating in order
to produce available results. For segments with less than 30 observations, test is not performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>homogeneity(
  app.port,
  loss,
  pools,
  segment,
  segment.num,
  method = "t.test",
  alpha = 0.05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="homogeneity_+3A_app.port">app.port</code></td>
<td>
<p>Application portfolio (data frame) which contains at lease realized loss (LGD),
pools in use and variable used as a segment.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_loss">loss</code></td>
<td>
<p>Name of the column that represents realized loss (LGD).</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_pools">pools</code></td>
<td>
<p>Name of the column that represents LGD pools.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_segment">segment</code></td>
<td>
<p>Name of the column that represent testing segments. If it is of numeric type, than it is first grouped
into <code>segment.num</code> of groups otherwise is it used as supplied.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_segment.num">segment.num</code></td>
<td>
<p>Number of groups used for numeric variables supplied as a segment. Only applicable if <code>segment</code>
is of numeric type.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_method">method</code></td>
<td>
<p>Statistical test. Available options are <code>t.test</code> (default) and <code>wilcox.test</code>.</p>
</td></tr>
<tr><td><code id="homogeneity_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of statistical test. Default is 0.05.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Testing procedure is implemented for each rating separately comparing average realized loss from one segment modality to
the average realized loss from the rest of segment modalities.
</p>


<h3>Value</h3>

<p>The command <code>homogeneity</code> returns a data frame with the following columns:
</p>

<ul>
<li><p> segment.var: Variable used as a segment.
</p>
</li>
<li><p> pool: Unique values of pools from application portfolio..
</p>
</li>
<li><p> segment.mod: Tested segment modality. Average realized loss from this segment is compared with
average realized loss from the rest of the modalities within the each rating.
</p>
</li>
<li><p> no: Number of observations in the analyzed pool.
</p>
</li>
<li><p> avg: Average realized loss in the analyzed pool.
</p>
</li>
<li><p> avg.segment: Average realized loss per analyzed segment modality within certain pool.
</p>
</li>
<li><p> avg.rest: Average realized loss of the rest of segment modalities within certain pool.
</p>
</li>
<li><p> no.segment: Number of observations of the analyzed segment modality.
</p>
</li>
<li><p> no.rest: Number of observations of the rest of the segment modalities.
</p>
</li>
<li><p> p.val: Two proportion test (two sided) p-value.
</p>
</li>
<li><p> alpha: Selected significance level.
</p>
</li>
<li><p> res: Accepted hypothesis.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#build dummy model
rf &lt;- c("rf_01", "rf_02", "rf_16", "rf_03", "rf_09")
for   (i in 1:length(rf)) {
     rf_l &lt;- rf[i]
     lgd.ds.c[, rf_l] &lt;- sts.bin(x = lgd.ds.c[, rf_l], 
                                y = lgd.ds.c[, "lgd"])[[2]]	
     }
str(lgd.ds.c)
frm &lt;- paste0("lgd ~ ", paste(rf, collapse = " + "))
model &lt;- lm(formula = as.formula(frm), data = lgd.ds.c)
summary(model)$coefficients
#create lgd pools
lgd.ds.c$pred &lt;- unname(predict(model))
lgd.ds.c$pool &lt;- sts.bin(x = lgd.ds.c$pred, 
                        y = lgd.ds.c$lgd)[[2]]
#test homogeneity on development sample
#(the same procedure can be applied on application portfolio)
homogeneity(app.port = lgd.ds.c, 
           loss = "lgd", 
           pools = "pool", 
           segment = "rf_03", 
           segment.num = 3, 
           method = "t.test", 
           alpha = 0.05)
</code></pre>

<hr>
<h2 id='interaction.transformer'>Extract risk factors interaction from decision tree</h2><span id='topic+interaction.transformer'></span>

<h3>Description</h3>

<p><code>interaction.transformer</code> extracts the interaction between supplied risk factors from decision tree.
It implements customized decision tree algorithm that takes into account different conditions such as minimum
percentage of observations and defaults in each node, maximum tree depth and monotonicity condition
at each splitting node. Sum of squared errors is used as metric for node splitting .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interaction.transformer(
  db,
  rf,
  target,
  min.pct.obs,
  min.avg.rate,
  max.depth,
  monotonicity,
  create.interaction.rf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interaction.transformer_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for interaction extraction.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_rf">rf</code></td>
<td>
<p>Character vector of risk factor names on which decision tree is run.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_target">target</code></td>
<td>
<p>Name of target variable within db argument.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observation in each leaf.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum average target rate in each leaf..</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_max.depth">max.depth</code></td>
<td>
<p>Maximum number of splits.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_monotonicity">monotonicity</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, observed trend between risk factor and target will be preserved
in splitting node.</p>
</td></tr>
<tr><td><code id="interaction.transformer_+3A_create.interaction.rf">create.interaction.rf</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, second element of the output will be data frame with
interaction modalities.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>interaction.transformer</code> returns a list of two data frames. The first data frame provides
the tree summary. The second data frame is a new risk factor extracted from decision tree.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(LGDtoolkit)
data(lgd.ds.c)
it &lt;- LGDtoolkit::interaction.transformer(db = lgd.ds.c,
		              rf = c("rf_01", "rf_03"), 
                             target = "lgd",
                             min.pct.obs = 0.05,
                             min.avg.rate = 0.01,
                             max.depth = 2,
                             monotonicity = TRUE,
                             create.interaction.rf = TRUE)
names(it)
it[["tree.info"]]
tail(it[["interaction"]])
table(it[["interaction"]][, "rf.inter"], useNA = "always")
</code></pre>

<hr>
<h2 id='kfold.idx'>Indices for K-fold validation</h2><span id='topic+kfold.idx'></span>

<h3>Description</h3>

<p><code>kfold.idx</code> provides indices for K-fold validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfold.idx(target, k = 10, type, num.strata = 4, seed = 2191)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfold.idx_+3A_target">target</code></td>
<td>
<p>Continuous target variable.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_k">k</code></td>
<td>
<p>Number of folds. If <code>k</code> is equal or greater than the number of observations of
target variable, then validation procedure is equivalent to leave one out cross-validation (LOOCV)
method. Default is set to 10.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_type">type</code></td>
<td>
<p>Sampling type. Possible options are <code>"random"</code> and <code>"stratified"</code>.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_num.strata">num.strata</code></td>
<td>
<p>Number of strata for <code>"stratified"</code> type. Default is 4.</p>
</td></tr>
<tr><td><code id="kfold.idx_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 2191.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>kfold.idx</code> returns a list of k folds estimation and validation indices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#random k-folds
kf.r &lt;- LGDtoolkit::kfold.idx(target = lgd.ds.c$lgd, k = 5, 
			type = "random", seed = 2211)
sapply(kf.r, function(x) c(mean(lgd.ds.c$lgd[x[[1]]]), mean(lgd.ds.c$lgd[x[[2]]])))
sapply(kf.r, function(x) length(x[[2]]))
#stratified k-folds
kf.s &lt;- LGDtoolkit::kfold.idx(target = lgd.ds.c$lgd, k = 5, 
                              type = "stratified", num.strata = 10, seed = 2211)
sapply(kf.s, function(x) c(mean(lgd.ds.c$lgd[x[[1]]]), mean(lgd.ds.c$lgd[x[[2]]])))
sapply(kf.s, function(x) length(x[[2]]))
</code></pre>

<hr>
<h2 id='kfold.vld'>K-fold model cross-validation</h2><span id='topic+kfold.vld'></span>

<h3>Description</h3>

<p><code>kfold.vld</code> performs k-fold model cross-validation.
The main goal of this procedure is to generate main model performance metrics such as absolute mean
square error, root mean square error or R-squared based on resampling method. Note that functions' argument
model accepts <code>"lm"</code> and <code>"glm"</code> class but for <code>"glm"</code> only <code>"quasibinomial("logit")"</code>
family will be considered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfold.vld(model, k = 10, seed = 1984)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfold.vld_+3A_model">model</code></td>
<td>
<p>Model in use, an object of class inheriting from <code>"lm"</code></p>
</td></tr>
<tr><td><code id="kfold.vld_+3A_k">k</code></td>
<td>
<p>Number of folds. If <code>k</code> is equal or greater than the number of observations of
modeling data frame, then validation procedure is equivalent to leave one out cross-validation (LOOCV)
method. For LOOCV, R-squared is not calculated. Default is set to 10.</p>
</td></tr>
<tr><td><code id="kfold.vld_+3A_seed">seed</code></td>
<td>
<p>Random seed needed for ensuring the result reproducibility. Default is 1984.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>kfold.vld</code> returns a list of two objects.<br />
The first object (<code>iter</code>), returns iteration performance metrics.<br />
The second object (<code>summary</code>), is the data frame of iterations averages of performance metrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#discretized some risk factors
num.rf &lt;- c("rf_01", "rf_02", "rf_03", "rf_09", "rf_16")
for	(i in 1:length(num.rf)) {
num.rf.l &lt;- num.rf[i]
lgd.ds.c[, num.rf.l] &lt;- sts.bin(x = lgd.ds.c[, num.rf.l], y = lgd.ds.c[, "lgd"])[[2]]	
}
str(lgd.ds.c)
#run linear regression model
reg.mod.1 &lt;- lm(lgd ~ ., data = lgd.ds.c[, c(num.rf, "lgd")])
summary(reg.mod.1)$coefficients
#perform k-fold validation
LGDtoolkit::kfold.vld(model = reg.mod.1 , k = 10, seed = 1984)
#run fractional logistic regression model
lgd.ds.c$lgd[lgd.ds.c$lgd &gt; 1] &lt;- 1
reg.mod.2 &lt;- glm(lgd ~ ., family = quasibinomial("logit"), data = lgd.ds.c[, c(num.rf, "lgd")])
summary(reg.mod.2)$coefficients
LGDtoolkit::kfold.vld(model = reg.mod.2 , k = 10, seed = 1984)
</code></pre>

<hr>
<h2 id='lgd.ds.c'>Synthetic modeling dataset</h2><span id='topic+lgd.ds.c'></span>

<h3>Description</h3>

<p>Synthetic modeling dataset of observed LGD values for contracts with complete recovery process.
Dataset consists of 1200 observations and 19 risk factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lgd.ds.c
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 1200 rows and 20 columns.
</p>

<hr>
<h2 id='r.squared'>Coefficient of determination</h2><span id='topic+r.squared'></span>

<h3>Description</h3>

<p><code>r.squared</code> returns coefficient of determination for risk factors
supplied in data frame <code>db</code>. Implemented algorithm processes numerical as well
as categorical risk factor. <br />
Usually, this procedure is applied as starting point of bivariate analysis in LGD model development.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.squared(db, target)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r.squared_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for bivariate analysis.</p>
</td></tr>
<tr><td><code id="r.squared_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>r.squared</code> returns the data frames with a following statistics:
name of the processed risk factor (<code>rf</code>), type of processed risk factor (<code>rf.type</code>),
number of missing and infinite observations (<code>miss.inf</code>), percentage of missing and
infinite observations (<code>miss.inf.pct</code>), coefficient of determination (<code>r.squared</code>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
r.squared(db = lgd.ds.c, target = "lgd")
#add categorical risk factor
lgd.ds.c$rf_03_bin &lt;- sts.bin(x = lgd.ds.c$rf_03, y = lgd.ds.c$lgd)[[2]]
r.squared(db = lgd.ds.c, target = "lgd")
#add risk factor with all missing, only one complete case and zero variance risk factor
lgd.ds.c$rf_20 &lt;- NA
lgd.ds.c$rf_21 &lt;- c(1, rep(NA, nrow(lgd.ds.c) - 1))
lgd.ds.c$rf_22 &lt;- c(c(1, 1), rep(NA, nrow(lgd.ds.c) - 2))
r.squared(db = lgd.ds.c, target = "lgd")
</code></pre>

<hr>
<h2 id='rf.interaction.transformer'>Extract interactions from random forest</h2><span id='topic+rf.interaction.transformer'></span>

<h3>Description</h3>

<p><code>rf.interaction.transformer</code> extracts the interactions from random forest.
It implements customized random forest algorithm that takes into account different conditions (for single decision tree) such as minimum
percentage of observations and defaults in each node, maximum tree depth and monotonicity condition
at each splitting node. Sum of squared errors index is used as metric for node splitting .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rf.interaction.transformer(
  db,
  rf,
  target,
  num.rf = NA,
  num.tree,
  min.pct.obs,
  min.avg.rate,
  max.depth,
  monotonicity,
  create.interaction.rf,
  seed = 991
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rf.interaction.transformer_+3A_db">db</code></td>
<td>
<p>Data frame of risk factors and target variable supplied for interaction extraction.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_rf">rf</code></td>
<td>
<p>Character vector of risk factor names on which decision tree is run.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_target">target</code></td>
<td>
<p>Name of target variable within db argument.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_num.rf">num.rf</code></td>
<td>
<p>Number of risk factors randomly selected for each decision tree. If default value (<code>NA</code>) is supplied,
then number of risk factors will be calculated as <code>sqrt(number of all supplied risk factors)</code>.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_num.tree">num.tree</code></td>
<td>
<p>Number of decision trees used for random forest.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_min.pct.obs">min.pct.obs</code></td>
<td>
<p>Minimum percentage of observation in each leaf.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_min.avg.rate">min.avg.rate</code></td>
<td>
<p>Minimum average target rate in each leaf.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_max.depth">max.depth</code></td>
<td>
<p>Maximum number of splits.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_monotonicity">monotonicity</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, observed trend between risk factor and target will be preserved
in splitting node.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_create.interaction.rf">create.interaction.rf</code></td>
<td>
<p>Logical indicator. If <code>TRUE</code>, second element of the output will be data frame with
interaction modalities.</p>
</td></tr>
<tr><td><code id="rf.interaction.transformer_+3A_seed">seed</code></td>
<td>
<p>Random seed to ensure result reproducibility. Default is 991.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>rf.interaction.transformer</code> returns a list of two data frames. The first data frame provides
the trees summary. The second data frame is a new risk factor extracted from random forest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(LGDtoolkit)
data(lgd.ds.c)
rf.it &lt;- LGDtoolkit::rf.interaction.transformer(db = lgd.ds.c, 
		     rf = names(lgd.ds.c)[!names(lgd.ds.c)%in%"lgd"], 
		     target = "lgd",
		     num.rf = NA, 
		     num.tree = 3,
		     min.pct.obs = 0.05,
		     min.avg.rate = 0.01,
		     max.depth = 2,
		     monotonicity = TRUE,
		     create.interaction.rf = TRUE,
		     seed = 789)
names(rf.it)
rf.it[["tree.info"]]
tail(rf.it[["interaction"]])
table(rf.it[["interaction"]][, 1], useNA = "always")
</code></pre>

<hr>
<h2 id='sc.merge'>Special case merging procedure</h2><span id='topic+sc.merge'></span>

<h3>Description</h3>

<p><code>sc.merge</code> performs procedure of merging special case bins with one from complete cases.
This procedure can be used not only for LGD model development, but also for PD and EAD, i.e. for
all models that have categorical risk factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sc.merge(x, y, sc = "SC", sc.merge = "closest", force.trend = "modalities")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sc.merge_+3A_x">x</code></td>
<td>
<p>Categorical risk factor.</p>
</td></tr>
<tr><td><code id="sc.merge_+3A_y">y</code></td>
<td>
<p>Target variable.</p>
</td></tr>
<tr><td><code id="sc.merge_+3A_sc">sc</code></td>
<td>
<p>Vector of special case values. Default is set to <code>"SC"</code>.</p>
</td></tr>
<tr><td><code id="sc.merge_+3A_sc.merge">sc.merge</code></td>
<td>
<p>Merging method. Available options are: <code>"first"</code>, <code>"last"</code> and <code>"closest"</code>.
Default value is <code>"closest"</code> and it is determined as the bin with the closest average target rate.</p>
</td></tr>
<tr><td><code id="sc.merge_+3A_force.trend">force.trend</code></td>
<td>
<p>Defines how initial summary table will be ordered. Possible options are:<br />
<code>"modalities"</code> and <code>"y.avg"</code>. If  <code>"modalities"</code> is selected, then merging will be
performed forward based on alphabetic order of risk factor modalities. On the other hand,
if <code>"y.avg"</code> is selected, then bins merging will be performed forward based on increasing order of
mean of target variable per modality.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>sc.merge</code> generates a list of two objects. The first object, data frame <code>summary.tbl</code>
presents a summary table of final binning, while <code>x.trans</code> is a vector of recoded values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
rf.03.bin.s &lt;- sts.bin(x = lgd.ds.c$rf_03, y = lgd.ds.c$lgd)
rf.03.bin.s[[1]]
table(rf.03.bin.s[[2]])
lgd.ds.c$rf_03_bin &lt;- rf.03.bin.s[[2]]
rf.03.bin.c &lt;- sc.merge(x = lgd.ds.c$rf_03_bin, 
			y = lgd.ds.c$lgd, 
			sc = "SC", 
			sc.merge = "closest", 
			force.trend = "modalities")
str(rf.03.bin.c)
rf.03.bin.c[[1]]
table(rf.03.bin.c[[2]])
</code></pre>

<hr>
<h2 id='staged.blocks'>Staged blocks regression</h2><span id='topic+staged.blocks'></span>

<h3>Description</h3>

<p><code>staged.blocks</code> performs blockwise regression where the predictions of each blocks' model is used as an
offset for the model of the following block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>staged.blocks(method, target, db, blocks, reg.type = "ols", p.value = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="staged.blocks_+3A_method">method</code></td>
<td>
<p>Regression method applied on each block.
Available methods: <code>"stepFWD"</code> or <code>"stepRPC"</code>.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_target">target</code></td>
<td>
<p>Name of target variable within <code>db</code> argument.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_blocks">blocks</code></td>
<td>
<p>Data frame with defined risk factor groups. It has to contain the following columns: <code>rf</code> and
<code>block</code>.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_reg.type">reg.type</code></td>
<td>
<p>Regression type. Available options are: <code>"ols"</code> for OLS regression and <code>"frac.logit"</code> for
fractional logistic regression. Default is <code>"ols"</code>. For <code>"frac.logit"</code> option, target has to have
all values between 0 and 1.</p>
</td></tr>
<tr><td><code id="staged.blocks_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value for the estimated coefficient. For numerical risk factors this value is
is directly compared to p-value of the estimated coefficient, while for categorical
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>staged.blocks</code> returns a list of three objects.<br />
The first object (<code>model</code>) is the list of the models of each block (an object of class inheriting from <code>"lm"</code>).<br />
The second object (<code>steps</code>), is the data frame with risk factors selected from the each block.<br />
The third object (<code>dev.db</code>), returns the list of block's model development databases.<br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+embedded.blocks">embedded.blocks</a></code>, <code><a href="#topic+ensemble.blocks">ensemble.blocks</a></code>, <code><a href="#topic+stepFWD">stepFWD</a></code> and <code><a href="#topic+stepRPC">stepRPC</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(LGDtoolkit)
data(lgd.ds.c)
#stepwise with continuous risk factors
set.seed(123)
blocks &lt;- data.frame(rf = names(lgd.ds.c)[!names(lgd.ds.c)%in%"lgd"], 
		   block = sample(1:3, ncol(lgd.ds.c) - 1, rep = TRUE))
blocks &lt;- blocks[order(blocks$block, blocks$rf), ]
res &lt;- LGDtoolkit::staged.blocks(method = "stepFWD", 
		   target = "lgd",
		   db = lgd.ds.c,
		   reg.type = "ols", 
		   blocks = blocks,
		   p.value = 0.05)
names(res)
res$models
summary(res$models[[3]])
identical(unname(predict(res$models[[1]], newdata = res$dev.db[[1]])),
    res$dev.db[[2]]$offset.vals)

</code></pre>

<hr>
<h2 id='stepFWD'>Customized stepwise (OLS &amp; fractional logistic) regression with p-value and trend check</h2><span id='topic+stepFWD'></span>

<h3>Description</h3>

<p><code>stepFWD</code> customized stepwise regression with p-value and trend check. Trend check is performed
comparing observed trend between target and analyzed risk factor and trend of the estimated coefficients within the
linear regression. Note that procedure checks the column names of supplied <code>db</code> data frame therefore some
renaming (replacement of special characters) is possible to happen. For details check help example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepFWD(
  start.model,
  p.value = 0.05,
  db,
  reg.type = "ols",
  check.start.model = TRUE,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepFWD_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represents starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value of the estimated coefficients. For numerical risk factors this value is
is directly compared to the p-value of the estimated coefficients, while for categorical risk factors
multiple Wald test is employed and its p-value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. Risk factors can be categorized or continuous.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_reg.type">reg.type</code></td>
<td>
<p>Regression type. Available options are: <code>"ols"</code> for OLS regression and <code>"frac.logit"</code> for
fractional logistic regression. Default is <code>"ols"</code>. For <code>"frac.logit"</code> option, target has to have
all values between 0 and 1.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_check.start.model">check.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should be
checked for p-value and trend in stepwise process. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="stepFWD_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepFWD</code> returns a list of four objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if risk factor has more than 10 modalities or
if any of the bins (groups) has less than 5% of observations.<br />
The final, fourth, object <code>dev.db</code> returns the model development database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
#stepwise with discretized risk factors
#same procedure can be run on continuous risk factors and mixed risk factor types
num.rf &lt;- sapply(lgd.ds.c, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"lgd" &amp; num.rf]
num.rf
#select subset of numerical risk factors
num.rf &lt;- num.rf[1:10]
for	(i in 1:length(num.rf)) {
num.rf.l &lt;- num.rf[i]
lgd.ds.c[, num.rf.l] &lt;- sts.bin(x = lgd.ds.c[, num.rf.l], y = lgd.ds.c[, "lgd"])[[2]]	
}
str(lgd.ds.c)
res &lt;- LGDtoolkit::stepFWD(start.model = lgd ~ 1, 
	   p.value = 0.05, 
	   db = lgd.ds.c[, c(num.rf, "lgd")],
	   reg.type = "ols")
names(res)
summary(res$model)$coefficients
res$steps
summary(res$model)$r.squared
</code></pre>

<hr>
<h2 id='stepRPC'>Stepwise (OLS &amp; fractional logistic) regression based on risk profile concept</h2><span id='topic+stepRPC'></span>

<h3>Description</h3>

<p><code>stepRPC</code> customized stepwise regression with p-value and trend check which additionally takes into account
the order of supplied risk factors per group when selects a candidate for the final regression model. Trend check is performed
comparing observed trend between target and analyzed risk factor and trend of the estimated coefficients.
Note that procedure checks the column names of supplied <code>db</code> data frame therefore some
renaming (replacement of special characters) is possible to happen. For details, please, check the help example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepRPC(
  start.model,
  risk.profile,
  p.value = 0.05,
  db,
  reg.type = "ols",
  check.start.model = TRUE,
  offset.vals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepRPC_+3A_start.model">start.model</code></td>
<td>
<p>Formula class that represents the starting model. It can include some risk factors, but it can be
defined only with intercept (<code>y ~ 1</code> where <code>y</code> is target variable).</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_risk.profile">risk.profile</code></td>
<td>
<p>Data frame with defined risk profile. It has to contain the following columns: <code>rf</code> and
<code>group</code>. Column <code>group</code> defines order of groups that will be tested first as a candidate
for the regression model. Risk factors selected in each group are kept as a starting variables
for the next group testing. Column <code>rf</code> contains all candidate risk factors supplied for testing.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_p.value">p.value</code></td>
<td>
<p>Significance level of p-value of the estimated coefficients. For numerical risk factors this value is
is directly compared to the p-value of the estimated coefficients, while for categorical risk factors
multiple Wald test is employed and its value is used for comparison with selected threshold (<code>p.value</code>).</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_db">db</code></td>
<td>
<p>Modeling data with risk factors and target variable. All risk factors (apart from the risk factors from the starting model)
should be categorized and as of character type.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_reg.type">reg.type</code></td>
<td>
<p>Regression type. Available options are: <code>"ols"</code> for OLS regression and <code>"frac.logit"</code> for
fractional logistic regression. Default is <code>"ols"</code>. For <code>"frac.logit"</code> option, target has to have
all values between 0 and 1.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_check.start.model">check.start.model</code></td>
<td>
<p>Logical (<code>TRUE</code> or <code>FALSE</code>), if risk factors from the starting model should
checked for p-value and trend in stepwise process.</p>
</td></tr>
<tr><td><code id="stepRPC_+3A_offset.vals">offset.vals</code></td>
<td>
<p>This can be used to specify an a priori known component to be included in the linear predictor during fitting.
This should be <code>NULL</code> or a numeric vector of length equal to the number of cases. Default is <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The command <code>stepRPC</code> returns a list of four objects.<br />
The first object (<code>model</code>), is the final model, an object of class inheriting from <code>"glm"</code>.<br />
The second object (<code>steps</code>), is the data frame with risk factors selected at each iteration.<br />
The third object (<code>warnings</code>), is the data frame with warnings if any observed.
The warnings refer to the following checks: if risk factor has more than 10 modalities or
if any of the bins (groups) has less than 5% of observations.<br />
The final, fourth, object <code>dev.db</code> returns the model development database.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(monobin)
library(LGDtoolkit)
data(lgd.ds.c)
num.rf &lt;- sapply(lgd.ds.c, is.numeric)
num.rf &lt;- names(num.rf)[!names(num.rf)%in%"lgd" &amp; num.rf]
num.rf
for	(i in 1:length(num.rf)) {
num.rf.l &lt;- num.rf[i]
lgd.ds.c[, num.rf.l] &lt;- sts.bin(x = lgd.ds.c[, num.rf.l], y = lgd.ds.c[, "lgd"])[[2]]	
}
str(lgd.ds.c)
#define risk factor groups
set.seed(123)
rf.pg &lt;- data.frame(rf = names(lgd.ds.c)[!names(lgd.ds.c)%in%"lgd"], 
		  group = sample(1:5, ncol(lgd.ds.c) - 1, rep = TRUE))
rf.pg &lt;- rf.pg[order(rf.pg$group, rf.pg$r), ]
rf.pg
res &lt;- LGDtoolkit::stepRPC(start.model = lgd ~ 1, 
	   risk.profile = rf.pg, 
	   p.value = 0.05, 
	   db = lgd.ds.c,
	   reg.type = "ols")
names(res)
summary(res$model)$coefficients
summary(res$model)$r.squared
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
