<!DOCTYPE html><html lang="en"><head><title>Help for package scoringfunctions</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scoringfunctions}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#scoringfunctions-package'>
<p>Overview of the functions in the scoringfunctions package</p></a></li>
<li><a href='#aerr_sf'>
<p>Absolute error scoring function</p></a></li>
<li><a href='#aperr_sf'>
<p>Absolute percentage error scoring function</p></a></li>
<li><a href='#bmedian_sf'>
<p><code class="reqn">\beta</code>-median scoring function</p></a></li>
<li><a href='#bregman1_sf'>
<p>Bregman scoring function (type 1)</p></a></li>
<li><a href='#bregman2_sf'>
<p>Bregman scoring function (type 2, Patton scoring function)</p></a></li>
<li><a href='#bregman3_sf'>
<p>Bregman scoring function (type 3, QLIKE scoring function)</p></a></li>
<li><a href='#bregman4_sf'>
<p>Bregman scoring function (type 4, Patton scoring function)</p></a></li>
<li><a href='#capping_function'>
<p>Capping function</p></a></li>
<li><a href='#errorspread_sf'>
<p>Error - spread scoring function</p></a></li>
<li><a href='#expectile_if'>
<p>Expectile identification function</p></a></li>
<li><a href='#expectile_rs'>
<p>Realised expectile score</p></a></li>
<li><a href='#expectile_sf'>
<p>Asymmetric piecewise quadratic scoring function (expectile scoring function,</p>
expectile loss function)</a></li>
<li><a href='#ghuber_sf'>
<p>Generalized Huber scoring function</p></a></li>
<li><a href='#gpl1_sf'>
<p>Generalized piecewise linear power scoring function (type 1)</p></a></li>
<li><a href='#gpl2_sf'>
<p>Generalized piecewise linear power scoring function (type 2)</p></a></li>
<li><a href='#huber_rs'>
<p>Mean Huber score</p></a></li>
<li><a href='#huber_sf'>
<p>Huber scoring function</p></a></li>
<li><a href='#hubermean_if'>
<p>Huber mean identification function</p></a></li>
<li><a href='#huberquantile_if'>
<p>Huber quantile identification function</p></a></li>
<li><a href='#interval_sf'>
<p>Interval scoring function (Winkler scoring function)</p></a></li>
<li><a href='#linex_sf'>
<p>LINEX scoring function</p></a></li>
<li><a href='#lqmean_sf'>
<p><code class="reqn">L_q</code>-mean scoring function</p></a></li>
<li><a href='#lqquantile_sf'>
<p><code class="reqn">L_q</code>-quantile scoring function</p></a></li>
<li><a href='#mae'>
<p>Mean absolute error (MAE)</p></a></li>
<li><a href='#maelog_sf'>
<p>MAE-LOG scoring function</p></a></li>
<li><a href='#maesd_sf'>
<p>MAE-SD scoring function</p></a></li>
<li><a href='#mape'>
<p>Mean absolute percentage error (MAPE)</p></a></li>
<li><a href='#mean_if'>
<p>Mean identification function</p></a></li>
<li><a href='#meanlog_if'>
<p>Log-transformed identification function</p></a></li>
<li><a href='#mre'>
<p>Mean relative error (MRE)</p></a></li>
<li><a href='#mse'>
<p>Mean squared error (MSE)</p></a></li>
<li><a href='#mspe'>
<p>Mean squared percentage error (MSPE)</p></a></li>
<li><a href='#msre'>
<p>Mean squared relative error (MSRE)</p></a></li>
<li><a href='#mv_if'>
<p>Mean - variance identification function</p></a></li>
<li><a href='#mv_sf'>
<p>Mean - variance scoring function</p></a></li>
<li><a href='#nmoment_if'>
<p><code class="reqn">n</code>-th moment identification function</p></a></li>
<li><a href='#nmoment_sf'>
<p><code class="reqn">n</code>-th moment scoring function</p></a></li>
<li><a href='#nse'>
<p>Nash-Sutcliffe efficiency (NSE)</p></a></li>
<li><a href='#obsweighted_sf'>
<p>Observation-weighted scoring function</p></a></li>
<li><a href='#quantile_if'>
<p>Quantile identification function</p></a></li>
<li><a href='#quantile_level'>
<p>Sample quantile level function</p></a></li>
<li><a href='#quantile_rs'>
<p>Realised quantile score</p></a></li>
<li><a href='#quantile_sf'>
<p>Asymmetric piecewise linear scoring function (quantile scoring function,</p>
quantile loss function)</a></li>
<li><a href='#relerr_sf'>
<p>Relative error scoring function (MAE-PROP scoring function)</p></a></li>
<li><a href='#serr_sf'>
<p>Squared error scoring function</p></a></li>
<li><a href='#serrexp_sf'>
<p>Squared error exp scoring function</p></a></li>
<li><a href='#serrlog_sf'>
<p>Squared error log scoring function</p></a></li>
<li><a href='#serrpower_sf'>
<p>Squared error of power transformations scoring function</p></a></li>
<li><a href='#serrsq_sf'>
<p>Squared error of squares scoring function</p></a></li>
<li><a href='#sperr_sf'>
<p>Squared percentage error scoring function</p></a></li>
<li><a href='#srelerr_sf'>
<p>Squared relative error scoring function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-03</td>
</tr>
<tr>
<td>Title:</td>
<td>A Collection of Loss Functions for Assessing Point Forecasts</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Implements multiple consistent scoring functions
    (Gneiting T (2011) &lt;<a href="https://doi.org/10.1198%2Fjasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>&gt;) for assessing point
    forecasts and point predictions. Detailed documentation of scoring
    functions' properties is included for facilitating interpretation of
    results.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Author:</td>
<td>Hristos Tyralis <a href="https://orcid.org/0000-0002-8932-4997"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Georgia Papacharalampous
    <a href="https://orcid.org/0000-0001-5446-954X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hristos Tyralis &lt;montchrister@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-03 16:40:12 UTC; AB</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-03 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='scoringfunctions-package'> 
Overview of the functions in the scoringfunctions package
</h2><span id='topic+scoringfunctions-package'></span>

<h3>Description</h3>

<p>The scoringfunctions package implements consistent scoring (loss) functions and
identification functions
</p>


<h3>Details</h3>

<p>The package functions are categorized into the following classes:
</p>

<ul>
<li><p> 1. Scoring functions
</p>
</li>
<li><p> 1.1. Consistent scoring functions for one-dimensional functionals
</p>
</li>
<li><p> 1.2. Consistent scoring functions for two-dimensional functionals
</p>
</li>
<li><p> 1.3. Consistent scoring functions for multi-dimensional
functionals
</p>
</li>
<li><p> 2. Realised (average) score functions
</p>
</li>
<li><p> 2.1 Realised (average) score functions for one-dimensional
functionals
</p>
</li>
<li><p> 3. Skill score functions
</p>
</li>
<li><p> 3.1 Skill score functions for one-dimensional functionals
</p>
</li>
<li><p> 4. Identification functions
</p>
</li>
<li><p> 4.1. Identification functions for one-dimensional functionals
</p>
</li>
<li><p> 4.2. Identification functions for two-dimensional functionals
</p>
</li>
<li><p> 5. Functions for sample levels
</p>
</li>
<li><p> 6. Supporting functions
</p>
</li></ul>

<p>.
</p>


<h3>1. Scoring functions</h3>



<h4>1.1. Consistent scoring functions for one-dimensional functionals</h4>

<p><code class="reqn">\textit{1.1.1. Consistent scoring functions for the mean}</code>
</p>
<p><code><a href="#topic+bregman1_sf">bregman1_sf</a></code>: Bregman scoring function (type 1)
</p>
<p><code><a href="#topic+bregman2_sf">bregman2_sf</a></code>: Bregman scoring function (type 2, Patton scoring
function)
</p>
<p><code><a href="#topic+bregman3_sf">bregman3_sf</a></code>: Bregman scoring function (type 3, QLIKE scoring
function)
</p>
<p><code><a href="#topic+bregman4_sf">bregman4_sf</a></code>: Bregman scoring function (type 4, Patton scoring
function)
</p>
<p><code><a href="#topic+serr_sf">serr_sf</a></code>: Squared error scoring function
</p>
<p><code class="reqn">\textit{1.1.2. Consistent scoring functions for expectiles}</code>
</p>
<p><code><a href="#topic+expectile_sf">expectile_sf</a></code>: Asymmetric piecewise quadratic scoring function
(expectile scoring function, expectile loss function)
</p>
<p><code class="reqn">\textit{1.1.3. Consistent scoring functions for the median}</code>
</p>
<p><code><a href="#topic+aerr_sf">aerr_sf</a></code>: Absolute error scoring function
</p>
<p><code><a href="#topic+maelog_sf">maelog_sf</a></code>: MAE-LOG scoring function
</p>
<p><code><a href="#topic+maesd_sf">maesd_sf</a></code>: MAE-SD scoring function
</p>
<p><code class="reqn">\textit{1.1.4. Consistent scoring functions for quantiles}</code>
</p>
<p><code><a href="#topic+gpl1_sf">gpl1_sf</a></code>: Generalized piecewise linear power scoring function
(type 1)
</p>
<p><code><a href="#topic+gpl2_sf">gpl2_sf</a></code>: Generalized piecewise linear power scoring function
(type 2)
</p>
<p><code><a href="#topic+quantile_sf">quantile_sf</a></code>: Asymmetric piecewise linear scoring function
(quantile scoring function, quantile loss function)
</p>
<p><code class="reqn">\textit{1.1.5. Consistent scoring functions for Huber functionals}</code>
</p>
<p><code><a href="#topic+ghuber_sf">ghuber_sf</a></code>: Generalized Huber scoring function
</p>
<p><code><a href="#topic+huber_sf">huber_sf</a></code>: Huber scoring function
</p>
<p><code class="reqn">\textit{1.1.6. Consistent scoring functions for other functionals}</code>
</p>
<p><code><a href="#topic+aperr_sf">aperr_sf</a></code>: Absolute percentage error scoring function
</p>
<p><code><a href="#topic+bmedian_sf">bmedian_sf</a></code>: <code class="reqn">\beta</code>-median scoring function
</p>
<p><code><a href="#topic+linex_sf">linex_sf</a></code>: LINEX scoring function
</p>
<p><code><a href="#topic+lqmean_sf">lqmean_sf</a></code>: <code class="reqn">L_q</code>-mean scoring function
</p>
<p><code><a href="#topic+lqquantile_sf">lqquantile_sf</a></code>: <code class="reqn">L_q</code>-quantile scoring function
</p>
<p><code><a href="#topic+nmoment_sf">nmoment_sf</a></code>: <code class="reqn">n</code>-th moment scoring function
</p>
<p><code><a href="#topic+obsweighted_sf">obsweighted_sf</a></code>: Observation-weighted scoring function
</p>
<p><code><a href="#topic+relerr_sf">relerr_sf</a></code>: Relative error scoring function (MAE-PROP scoring
function)
</p>
<p><code><a href="#topic+serrexp_sf">serrexp_sf</a></code>: Squared error exp scoring function
</p>
<p><code><a href="#topic+serrlog_sf">serrlog_sf</a></code>: Squared error log scoring function
</p>
<p><code><a href="#topic+serrpower_sf">serrpower_sf</a></code>: Squared error of power transformations scoring
function
</p>
<p><code><a href="#topic+serrsq_sf">serrsq_sf</a></code>: Squared error of squares scoring function
</p>
<p><code><a href="#topic+sperr_sf">sperr_sf</a></code>: Squared percentage error scoring function
</p>
<p><code><a href="#topic+srelerr_sf">srelerr_sf</a></code>: Squared relative error scoring function
</p>



<h4>1.2. Consistent scoring functions for two-dimensional functionals</h4>

<p><code><a href="#topic+interval_sf">interval_sf</a></code>: Interval scoring function (Winkler scoring
function)
</p>
<p><code><a href="#topic+mv_sf">mv_sf</a></code>: Mean - variance scoring function
</p>



<h4>1.3. Consistent scoring functions for multi-dimensional functionals</h4>

<p><code><a href="#topic+errorspread_sf">errorspread_sf</a></code>: Error - spread scoring function
</p>



<h3>2. Realised (average) score functions</h3>



<h4>2.1. Realised (average) score functions for one-dimensional functionals</h4>

<p><code class="reqn">\textit{2.1.1. Realised (average) score functions for the mean}</code>
</p>
<p><code><a href="#topic+mse">mse</a></code>: Mean squared error (MSE)
</p>
<p><code class="reqn">\textit{2.1.2. Realised (average) score functions for expectiles}</code>
</p>
<p><code><a href="#topic+expectile_rs">expectile_rs</a></code>: Realised expectile score
</p>
<p><code class="reqn">\textit{2.1.3. Realised (average) score functions for the median}</code>
</p>
<p><code><a href="#topic+mae">mae</a></code>: Mean absolute error (MAE)
</p>
<p><code class="reqn">\textit{2.1.4. Realised (average) score functions for quantiles}</code>
</p>
<p><code><a href="#topic+quantile_rs">quantile_rs</a></code>: Realised quantile score
</p>
<p><code class="reqn">\textit{2.1.5. Realised (average) score functions for Huber functionals}</code>
</p>
<p><code><a href="#topic+huber_rs">huber_rs</a></code>: Mean Huber score
</p>
<p><code class="reqn">\textit{2.1.6. Realised (average) score functions for other functionals}</code>
</p>
<p><code><a href="#topic+mape">mape</a></code>: Mean absolute percentage error (MAPE)
</p>
<p><code><a href="#topic+mre">mre</a></code>: Mean relative error (MRE)
</p>
<p><code><a href="#topic+mspe">mspe</a></code>: Mean squared percentage error (MSPE)
</p>
<p><code><a href="#topic+msre">msre</a></code>: Mean squared relative error (MSRE)
</p>



<h3>3. Skill score functions</h3>



<h4>3.1. Skill score functions for one-dimensional functionals</h4>

<p><code class="reqn">\textit{3.1.1. Skill score functions for the mean}</code>
</p>
<p><code><a href="#topic+nse">nse</a></code>: Nash-Sutcliffe efficiency (NSE)
</p>



<h3>4. Identification functions</h3>



<h4>4.1. Identification functions for one-dimensional functionals</h4>

<p><code><a href="#topic+expectile_if">expectile_if</a></code>: Expectile identification function
</p>
<p><code><a href="#topic+hubermean_if">hubermean_if</a></code>: Huber mean identification function
</p>
<p><code><a href="#topic+huberquantile_if">huberquantile_if</a></code>: Huber quantile identification function
</p>
<p><code><a href="#topic+mean_if">mean_if</a></code>: Mean identification function
</p>
<p><code><a href="#topic+meanlog_if">meanlog_if</a></code>: Log-transformed identification function
</p>
<p><code><a href="#topic+nmoment_if">nmoment_if</a></code>: <code class="reqn">n</code>-th moment identification function
</p>
<p><code><a href="#topic+quantile_if">quantile_if</a></code>: Quantile identification function
</p>



<h4>4.2. Identification functions for two-dimensional functionals</h4>

<p><code><a href="#topic+mv_if">mv_if</a></code>: Mean - variance identification function
</p>



<h3>5. Functions for sample levels</h3>

<p><code><a href="#topic+quantile_level">quantile_level</a></code>: Sample quantile level function
</p>


<h3>6. Supporting functions</h3>

<p><code><a href="#topic+capping_function">capping_function</a></code>: Capping function
</p>

<hr>
<h2 id='aerr_sf'>
Absolute error scoring function
</h2><span id='topic+aerr_sf'></span>

<h3>Description</h3>

<p>The function aerr_sf computes the absolute error scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive median functional.
</p>
<p>The absolute error scoring function is defined in Table 1 in Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aerr_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aerr_sf_+3A_x">x</code></td>
<td>
<p>Predictive median functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="aerr_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The absolute error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := |x - y|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Vector of absolute errors.
</p>


<h3>Note</h3>

<p>For details on the absolute error scoring function, see Gneiting (2011).
</p>
<p>The median functional is the median of the probability distribution <code class="reqn">F</code> of
<code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The absolute error scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The absolute error scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for
the median functional. <code class="reqn">\mathbb{F}</code> is the family of probability
distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite
(Raiffa and Schlaifer 1961, p.196; Ferguson 1967, p.51; Thomson 1979; Saerens
2000; Gneiting 2011).
</p>


<h3>References</h3>

<p>Ferguson TS (1967) Mathematical Statistics: A Decision-Theoretic Approach.
Academic Press, New York.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Raiffa H,Schlaifer R (1961) Applied Statistical Decision Theory. Colonial Press,
Clinton.
</p>
<p>Saerens M (2000) Building cost functions minimizing to some summary statistics.
<em>IEEE Transactions on Neural Networks</em> <b>11(6)</b>:1263&ndash;1271.
<a href="https://doi.org/10.1109/72.883416">doi:10.1109/72.883416</a>.
</p>
<p>Thomson W (1979) Eliciting production possibilities from a well-informed
manager. <em>Journal of Economic Theory</em> <b>20(3)</b>:360&ndash;380.
<a href="https://doi.org/10.1016/0022-0531%2879%2990042-5">doi:10.1016/0022-0531(79)90042-5</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the absolute error scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 5),
    x = -2:2
)

df$absolute_error &lt;- aerr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='aperr_sf'>
Absolute percentage error scoring function
</h2><span id='topic+aperr_sf'></span>

<h3>Description</h3>

<p>The function aperr_sf computes the absolute percentage error scoring function
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">\textnormal{med}^{(-1)}(F)</code> functional.
</p>
<p>The absolute percentage error scoring function is defined in Table 1 in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aperr_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aperr_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\textnormal{med}^{(-1)}(F)</code> functional (prediction). It
can be a vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="aperr_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The absolute percentage error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := |(x - y)/y|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of absolute percentage errors.
</p>


<h3>Note</h3>

<p>For details on the absolute percentage error scoring function, see
Gneiting (2011).
</p>
<p>The <code class="reqn">\beta</code>-median functional, <code class="reqn">\textnormal{med}^{(\beta)}(F)</code> is the
median of a probability distribution whose density is proportional to
<code class="reqn">y^\beta f(y)</code>, where <code class="reqn">f</code> is the density of the probability distribution
<code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The absolute percentage error scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The absolute percentage error scoring function is strictly
<code class="reqn">\mathbb{F}^{(w)}</code>-consistent for the <code class="reqn">\textnormal{med}^{(-1)}(F)</code>
functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions for
which <code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite. <code class="reqn">\mathbb{F}^{(w)}</code> is
the subclass of probability distributions in <code class="reqn">\mathbb{F}</code>, which are such
that <code class="reqn">w(y) f(y)</code>, <code class="reqn">w(y) = 1/y</code> has finite integral over
<code class="reqn">(0, \infty)</code>, and the probability distribution <code class="reqn">F^{(w)}</code> with density
proportional to <code class="reqn">w(y) f(y)</code> belongs to <code class="reqn">\mathbb{F}</code> (see Theorems 5 and
9 in Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the absolute percentage error scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$absolute_percentage_error &lt;- aperr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='bmedian_sf'>
<code class="reqn">\beta</code>-median scoring function
</h2><span id='topic+bmedian_sf'></span>

<h3>Description</h3>

<p>The function bmedian_sf computes the <code class="reqn">\beta</code>-median scoring function
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">\textnormal{med}^{(\beta)}(F)</code> functional.
</p>
<p>The <code class="reqn">\beta</code>-median scoring function is defined in eq. (4) in Gneiting
(2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bmedian_sf(x, y, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bmedian_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\textnormal{med}^{(\beta)}(F)</code> functional (prediction).
It can be a vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="bmedian_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="bmedian_sf_+3A_b">b</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">\beta</code>-median scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, b) := |1 - (y/x)^b|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">b \neq 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, b) \geq 0, \forall x, y &gt; 0, b \neq 0</code>
</p>



<h3>Value</h3>

<p>Vector of <code class="reqn">\beta</code>-median losses.
</p>


<h3>Note</h3>

<p>For details on the <code class="reqn">\beta</code>-median scoring function, see Gneiting (2011).
</p>
<p>The <code class="reqn">\beta</code>-median functional, <code class="reqn">\textnormal{med}^{(\beta)}(F)</code> is the
median of a probability distribution whose density is proportional to
<code class="reqn">y^\beta f(y)</code>, where <code class="reqn">f</code> is the density of the probability distribution
<code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The <code class="reqn">\beta</code>-median scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The <code class="reqn">\beta</code>-median scoring function is strictly
<code class="reqn">\mathbb{F}^{(w)}</code>-consistent for the <code class="reqn">\textnormal{med}^{(\beta)}(F)</code>
functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions for
which <code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite. <code class="reqn">\mathbb{F}^{(w)}</code> is
the subclass of probability distributions in <code class="reqn">\mathbb{F}</code>, which are such
that <code class="reqn">w(y) f(y)</code>, <code class="reqn">w(y) = y^\beta</code> has finite integral over
<code class="reqn">(0, \infty)</code>, and the probability distribution <code class="reqn">F^{(w)}</code> with density
proportional to <code class="reqn">w(y) f(y)</code> belongs to <code class="reqn">\mathbb{F}</code> (see Theorems 5 and
9 in Gneiting 2011)
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the bmedian scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3,
    b = c(-1, 1, 2)
)

df$bmedian_error &lt;- bmedian_sf(x = df$x, y = df$y, b = df$b)

print(df)
</code></pre>

<hr>
<h2 id='bregman1_sf'>
Bregman scoring function (type 1)
</h2><span id='topic+bregman1_sf'></span>

<h3>Description</h3>

<p>The function bregman1_sf computes the Bregman scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive mean functional.
</p>
<p>The Bregman scoring function is defined by eq. (18) in Gneiting (2011) and the
form implemented here for <code class="reqn">\phi(x) = |x|^a</code> is defined by eq. (19) in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bregman1_sf(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bregman1_sf_+3A_x">x</code></td>
<td>
<p>Predictive mean functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="bregman1_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="bregman1_sf_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bregman scoring function (type 1) is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, a) := |y|^a - |x|^a - a \textnormal{sign}(x) |x|^{a - 1} (y - x)
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">a &gt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, a) \geq 0, \forall x, y \in \mathbb{R}, a &gt; 1</code>
</p>



<h3>Value</h3>

<p>Vector of Bregman losses.
</p>


<h3>Note</h3>

<p>The implemented function is denoted as type 1 since it corresponds to a specific
type of <code class="reqn">\phi(x)</code> of the general form of the Bregman scoring function
defined by eq. (18) in Gneiting (2011).
</p>
<p>For details on the Bregman scoring function, see Savage (1971), Banerjee et al.
(2005) and Gneiting (2011).
</p>
<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The Bregman scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The herein implemented Bregman scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the mean functional. <code class="reqn">\mathbb{F}</code> is the
family of probability distributions for which <code class="reqn">\textnormal{E}_F[Y]</code> and
<code class="reqn">\textnormal{E}_F[|Y|^a]</code> exist and are finite (Savage 1971; Gneiting 2011).
</p>


<h3>References</h3>

<p>Banerjee A, Guo X, Wang H (2005) On the optimality of conditional expectation as
a Bregman predictor. <em>IEEE Transactions on Information Theory</em>
<b>51(7)</b>:2664&ndash;2669. <a href="https://doi.org/10.1109/TIT.2005.850145">doi:10.1109/TIT.2005.850145</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Savage LJ  (1971) Elicitation of personal probabilities and expectations.
<em>Journal of the American Statistical Association</em> <b>66(337)</b>:783&ndash;810.
<a href="https://doi.org/10.1080/01621459.1971.10482346">doi:10.1080/01621459.1971.10482346</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Bregman scoring function (type 1).

df &lt;- data.frame(
    y = rep(x = 0, times = 7),
    x = c(-3, -2, -1, 0, 1, 2, 3),
    a = rep(x = 3, times = 7)
)

df$bregman1_penalty &lt;- bregman1_sf(x = df$x, y = df$y, a = df$a)

print(df)

# Equivalence of Bregman scoring function (type 1) and squared error scoring
# function, when a = 2.

set.seed(12345)

n &lt;- 100

x &lt;- runif(n, -20, 20)
y &lt;- runif(n, -20, 20)
a &lt;- rep(x = 2, times = n)

u &lt;- bregman1_sf(x = x, y = y, a = a)

v &lt;- serr_sf(x = x, y = y)

max(abs(u - v)) # values are slightly higher than 0 due to rounding error
min(abs(u - v))
</code></pre>

<hr>
<h2 id='bregman2_sf'>
Bregman scoring function (type 2, Patton scoring function)
</h2><span id='topic+bregman2_sf'></span>

<h3>Description</h3>

<p>The function bregman2_sf computes the Bregman scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive mean functional.
</p>
<p>The Bregman scoring function is defined by eq. (18) in Gneiting (2011) and the
form implemented here for <code class="reqn">\phi(x) = \dfrac{1}{b (b - 1)} x^b</code>,
<code class="reqn">b \in \R \setminus \lbrace 0, 1 \rbrace</code> is defined by eq. (20) in Gneiting
(2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bregman2_sf(x, y, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bregman2_sf_+3A_x">x</code></td>
<td>
<p>Predictive mean functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="bregman2_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="bregman2_sf_+3A_b">b</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bregman scoring function (type 2) is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, b) := \dfrac{1}{b (b - 1)} (y^b - x^b) -
            \dfrac{1}{b - 1} x^{b - 1} (y - x)
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">b \in \mathbb{R} \setminus \lbrace 0, 1 \rbrace</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, b) \geq 0, \forall x, y &gt; 0, b \in \mathbb{R} \setminus
        \lbrace 0, 1 \rbrace</code>
</p>



<h3>Value</h3>

<p>Vector of Bregman losses.
</p>


<h3>Note</h3>

<p>The implemented function is denoted as type 2 since it corresponds to a specific
type of <code class="reqn">\phi(x)</code> of the general form of the Bregman scoring function
defined by eq. (18) in Gneiting (2011).
</p>
<p>For details on the Bregman scoring function, see Savage (1971), Banerjee et al.
(2005) and Gneiting (2011). For details on the specific form implemented here,
see Patton (2011).
</p>
<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The Bregman scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The herein implemented Bregman scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the mean functional. <code class="reqn">\mathbb{F}</code> is the
family of probability distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y]</code>
and <code class="reqn">\textnormal{E}_F[\dfrac{1}{b (b - 1)} Y^b]</code> exist and are finite
(Savage 1971; Gneiting 2011).
</p>


<h3>References</h3>

<p>Banerjee A, Guo X, Wang H (2005) On the optimality of conditional expectation as
a Bregman predictor. <em>IEEE Transactions on Information Theory</em>
<b>51(7)</b>:2664&ndash;2669. <a href="https://doi.org/10.1109/TIT.2005.850145">doi:10.1109/TIT.2005.850145</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Patton AJ (2011) Volatility forecast comparison using imperfect volatility
proxies. <em>Journal of Econometrics</em> <b>160(1)</b>:246&ndash;256.
<a href="https://doi.org/10.1016/j.jeconom.2010.03.034">doi:10.1016/j.jeconom.2010.03.034</a>.
</p>
<p>Savage LJ  (1971) Elicitation of personal probabilities and expectations.
<em>Journal of the American Statistical Association</em> <b>66(337)</b>:783&ndash;810.
<a href="https://doi.org/10.1080/01621459.1971.10482346">doi:10.1080/01621459.1971.10482346</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Bregman scoring function (type 2).

df &lt;- data.frame(
    y = rep(x = 2, times = 6),
    x = rep(x = 1:3, times = 2),
    b = rep(x = c(-3, 3), each = 3)
)

df$bregman2_penalty &lt;- bregman2_sf(x = df$x, y = df$y, b = df$b)

print(df)

# The Bregman scoring function (type 2) is half the squared error scoring
# function, when b = 2.

df &lt;- data.frame(
    y = rep(x = 5.5, times = 10),
    x = 1:10,
    b = rep(x = 2, times = 10)
)

df$bregman2_penalty &lt;- bregman2_sf(x = df$x, y = df$y, b = df$b)

df$squared_error &lt;- serr_sf(x = df$x, y = df$y)

df$ratio &lt;- df$bregman2_penalty/df$squared_error

print(df)


# When a = b &gt; 1 the Bregman scoring function (type 2) coincides with the
# Bregman scoring function (type 1) up to a multiplicative constant.

df &lt;- data.frame(
    y = rep(x = 5.5, times = 10),
    x = 1:10,
    b = rep(x = c(3, 4), each = 5)
)

df$bregman2_penalty &lt;- bregman2_sf(x = df$x, y = df$y, b = df$b)

df$bregman1_penalty &lt;- bregman1_sf(x = df$x, y = df$y, a = df$b)

df$ratio &lt;- df$bregman2_penalty/df$bregman1_penalty

print(df)
</code></pre>

<hr>
<h2 id='bregman3_sf'>
Bregman scoring function (type 3, QLIKE scoring function)
</h2><span id='topic+bregman3_sf'></span>

<h3>Description</h3>

<p>The function bregman3_sf computes the Bregman scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive mean functional.
</p>
<p>The Bregman scoring function is defined by eq. (18) in Gneiting (2011) and the
form implemented here for <code class="reqn">\phi(x) = -\log(x)</code> is defined by eq. (20) in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bregman3_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bregman3_sf_+3A_x">x</code></td>
<td>
<p>Predictive mean functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="bregman3_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bregman scoring function (type 3) is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := (y/x) - \log(y/x) - 1</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of Bregman losses.
</p>


<h3>Note</h3>

<p>The implemented function is denoted as type 3 since it corresponds to a specific
type of <code class="reqn">\phi(x)</code> of the general form of the Bregman scoring function
defined by eq. (18) in Gneiting (2011).
</p>
<p>For details on the Bregman scoring function, see Savage (1971), Banerjee et al.
(2005) and Gneiting (2011). For details on the specific form implemented here,
see the QLIKE scoring function in Patton (2011).
</p>
<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The Bregman scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The herein implemented Bregman scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the mean functional. <code class="reqn">\mathbb{F}</code> is the
family of probability distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y]</code>
and <code class="reqn">\textnormal{E}_F[\log(Y)]</code> exist and are finite (Savage 1971; Gneiting
2011).
</p>


<h3>References</h3>

<p>Banerjee A, Guo X, Wang H (2005) On the optimality of conditional expectation as
a Bregman predictor. <em>IEEE Transactions on Information Theory</em>
<b>51(7)</b>:2664&ndash;2669. <a href="https://doi.org/10.1109/TIT.2005.850145">doi:10.1109/TIT.2005.850145</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Patton AJ (2011) Volatility forecast comparison using imperfect volatility
proxies. <em>Journal of Econometrics</em> <b>160(1)</b>:246&ndash;256.
<a href="https://doi.org/10.1016/j.jeconom.2010.03.034">doi:10.1016/j.jeconom.2010.03.034</a>.
</p>
<p>Savage LJ  (1971) Elicitation of personal probabilities and expectations.
<em>Journal of the American Statistical Association</em> <b>66(337)</b>:783&ndash;810.
<a href="https://doi.org/10.1080/01621459.1971.10482346">doi:10.1080/01621459.1971.10482346</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Bregman scoring function (type 3, QLIKE scoring function).

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$bregman3_penalty &lt;- bregman3_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='bregman4_sf'>
Bregman scoring function (type 4, Patton scoring function)
</h2><span id='topic+bregman4_sf'></span>

<h3>Description</h3>

<p>The function bregman4_sf computes the Bregman scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive mean functional.
</p>
<p>The Bregman scoring function is defined by eq. (18) in Gneiting (2011) and the
form implemented here for <code class="reqn">\phi(x) = x \log(x)</code> is defined by eq. (20) in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bregman4_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bregman4_sf_+3A_x">x</code></td>
<td>
<p>Predictive mean functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="bregman4_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bregman scoring function (type 4) is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := y \log(y/x) - y + x</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of Bregman losses.
</p>


<h3>Note</h3>

<p>The implemented function is denoted as type 4 since it corresponds to a specific
type of <code class="reqn">\phi(x)</code> of the general form of the Bregman scoring function
defined by eq. (18) in Gneiting (2011).
</p>
<p>For details on the Bregman scoring function, see Savage (1971), Banerjee et al.
(2005) and Gneiting (2011). For details on the specific form implemented here,
see Patton (2011).
</p>
<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The Bregman scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The herein implemented Bregman scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the mean functional. <code class="reqn">\mathbb{F}</code> is the
family of probability distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y]</code>
and <code class="reqn">\textnormal{E}_F[Y \log(Y)]</code> exist and are finite (Savage 1971;
Gneiting 2011).
</p>


<h3>References</h3>

<p>Banerjee A, Guo X, Wang H (2005) On the optimality of conditional expectation as
a Bregman predictor. <em>IEEE Transactions on Information Theory</em>
<b>51(7)</b>:2664&ndash;2669. <a href="https://doi.org/10.1109/TIT.2005.850145">doi:10.1109/TIT.2005.850145</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Patton AJ (2011) Volatility forecast comparison using imperfect volatility
proxies. <em>Journal of Econometrics</em> <b>160(1)</b>:246&ndash;256.
<a href="https://doi.org/10.1016/j.jeconom.2010.03.034">doi:10.1016/j.jeconom.2010.03.034</a>.
</p>
<p>Savage LJ  (1971) Elicitation of personal probabilities and expectations.
<em>Journal of the American Statistical Association</em> <b>66(337)</b>:783&ndash;810.
<a href="https://doi.org/10.1080/01621459.1971.10482346">doi:10.1080/01621459.1971.10482346</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Bregman scoring function (type 4).

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$bregman4_penalty &lt;- bregman4_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='capping_function'>
Capping function
</h2><span id='topic+capping_function'></span>

<h3>Description</h3>

<p>The function capping_function computes the value of the capping function,
defined in Taggart (2022), p.205.
</p>
<p>It is used by the generalized Huber loss function among others (see Taggart
2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>capping_function(t, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="capping_function_+3A_t">t</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="capping_function_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">t</code>).</p>
</td></tr>
<tr><td><code id="capping_function_+3A_b">b</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">t</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The capping function <code class="reqn">\kappa_{a,b}(t)</code> is defined by:
</p>
<p style="text-align: center;"><code class="reqn">\kappa_{a,b}(t) := \max \lbrace \min \lbrace t,b \rbrace, -a \rbrace</code>
</p>

<p>or equivalently,
</p>
<p style="text-align: center;"><code class="reqn">
        \kappa_{a,b}(t) := \left\{
        \begin{array}{ll}
        -a, &amp; t \leq -a\\
        t, &amp; -a &lt; t \leq b\\
        b, &amp; t &gt; b
        \end{array}
        \right.
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">t \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">a \geq 0</code>
</p>

<p style="text-align: center;"><code class="reqn">b \geq 0</code>
</p>



<h3>Value</h3>

<p>Vector of values of the capping function.
</p>


<h3>Note</h3>

<p>For the definition of the capping function, see Taggart (2022), p.205.
</p>


<h3>References</h3>

<p>Taggart RJ (2022) Point forecasting and forecast evaluation with generalized
Huber loss. <em>Electronic Journal of Statistics</em> <b>16</b>:201&ndash;231.
<a href="https://doi.org/10.1214/21-EJS1957">doi:10.1214/21-EJS1957</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the capping function.

df &lt;- data.frame(
    t = c(1, -1, 1, -1, 1, -1, 1, -1, 1, 1, 2.5, 2.5, 3.5, 3.5),
    a = c(0, 0, 0, 0, Inf, Inf, Inf, Inf, 2, 3, 2, 3, 2, 3),
    b = c(0, 0, Inf, Inf, 0, 0, Inf, Inf, 3, 2, 3, 2, 3, 2)
)

df$cf &lt;- capping_function(t = df$t, a = df$a, b = df$b)

print(df)
</code></pre>

<hr>
<h2 id='errorspread_sf'>
Error - spread scoring function
</h2><span id='topic+errorspread_sf'></span>

<h3>Description</h3>

<p>The function errorspread_sf computes the error - spread scoring function, when
<code class="reqn">y</code> materialises, <code class="reqn">x_1</code> is the predictive mean, <code class="reqn">x_2</code> is the
predictive variance and <code class="reqn">x_3</code> is the predictive skewness.
</p>
<p>The error - spread scoring function is defined by eq. (14) in Christensen et
al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>errorspread_sf(x1, x2, x3, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="errorspread_sf_+3A_x1">x1</code></td>
<td>
<p>Predictive mean (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="errorspread_sf_+3A_x2">x2</code></td>
<td>
<p>Predictive variance (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="errorspread_sf_+3A_x3">x3</code></td>
<td>
<p>Predictive skewness (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="errorspread_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x_1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The error - spread scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x_1, x_2, x_3, y) := (x_2 - (x_1 - y)^2 - (x_1 - y) x_2^{1/2} x_3)^2
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x_1 \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_2 &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">x_3 \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Vector of error - spread losses.
</p>


<h3>Note</h3>

<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Christensen et al. 2015).
</p>
<p>The variance functional is the variance
<code class="reqn">\textnormal{Var}_F[Y] := \textnormal{E}_F[Y^2] - (\textnormal{E}_F[Y])^{2}</code>
of the probability distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Christensen et al. 2015).
</p>
<p>The skewness functional is the skewness <code class="reqn">\textnormal{Sk}_F[Y] :=
\textnormal{E}_F[((Y - \textnormal{E}_F[Y])/(\textnormal{Var}_F[Y])^{1/2})^3]</code>
(Christensen et al. 2015).
</p>
<p>The error - spread scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The error - spread scoring function is strictly consistent for the triple (mean,
variance, skewness) functional (Christensen et al. 2015).
</p>


<h3>References</h3>

<p>Christensen HM, Moroz IM, Palmer TN (2015) Evaluation of ensemble forecast
uncertainty using a new proper score: Application to medium-range and seasonal
forecasts. <em>Quarterly Journal of the Royal Meteorological Society</em>
<b>141(687)(Part B)</b>:538&ndash;549. <a href="https://doi.org/10.1002/qj.2375">doi:10.1002/qj.2375</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the error - spread scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x1 = c(2, 2, -2, -2, 0, 0),
    x2 = c(1, 2, 1, 2, 1, 2),
    x3 = c(3, 3, -3, -3, 0, 0)
)

df$errorspread_penalty &lt;- errorspread_sf(x1 = df$x1, x2 = df$x2, x3 = df$x3,
    y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='expectile_if'>
Expectile identification function
</h2><span id='topic+expectile_if'></span>

<h3>Description</h3>

<p>The function expectile_if computes the expectile identification function at a
specific level <code class="reqn">p</code>, when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
expectile at level <code class="reqn">p</code>.
</p>
<p>The expectile identification function is defined in Table 9 in Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectile_if(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectile_if_+3A_x">x</code></td>
<td>
<p>Predictive expectile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="expectile_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="expectile_if_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The expectile identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, p) := 2 |\textbf{1} \lbrace x \geq y \rbrace - p| (x - y)</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, p) \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Vector of values of the expectile identification function.
</p>


<h3>Note</h3>

<p>For the definition of expectiles, see Newey and Powell (1987).
</p>
<p>The expectile identification function is a strict
<code class="reqn">\mathbb{F}</code>-identification function for the <code class="reqn">p</code>-expectile functional
(Gneiting 2011; Fissler and Ziegel 2016; Dimitriadis et al. 2024).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite (Gneiting 2011; Fissler and
Ziegel 2016; Dimitriadis et al. 2024).
</p>


<h3>References</h3>

<p>Dimitriadis T, Fissler T, Ziegel JF (2024) Osband's principle for identification
functions. <em>Statistical Papers</em> <b>65</b>:1125&ndash;1132.
<a href="https://doi.org/10.1007/s00362-023-01428-x">doi:10.1007/s00362-023-01428-x</a>.
</p>
<p>Fissler T, Ziegel JF (2016) Higher order elicitability and Osband's principle.
<em>The Annals of Statistics</em> <b>44(4)</b>:1680&ndash;1707.
<a href="https://doi.org/10.1214/16-AOS1439">doi:10.1214/16-AOS1439</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Newey WK, Powell JL (1987) Asymmetric least squares estimation and testing.
<em>Econometrica</em> <b>55(4)</b>:819&ndash;847. <a href="https://doi.org/10.2307/1911031">doi:10.2307/1911031</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the expectile identification function.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x = c(2, 2, -2, -2, 0, 0),
    p = rep(x = c(0.05, 0.95), times = 3)
)

df$expectile_if &lt;- expectile_if(x = df$x, y = df$y, p = df$p)
</code></pre>

<hr>
<h2 id='expectile_rs'>
Realised expectile score
</h2><span id='topic+expectile_rs'></span>

<h3>Description</h3>

<p>The function expectile_rs computes the realised expectile score at a specific
level <code class="reqn">p</code> when <code class="reqn">\textbf{\textit{y}}</code> materialises and
<code class="reqn">\textbf{\textit{x}}</code> is the prediction.
</p>
<p>Realised expectile score is a realised score corresponding to the expectile
scoring function <a href="#topic+expectile_sf">expectile_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectile_rs(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectile_rs_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="expectile_rs_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
<tr><td><code id="expectile_rs_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">\textbf{\textit{y}}</code>) or a scalar value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The realized expectile score is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}, p) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i, p)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
        L(x, y, p) := |\textbf{1} \lbrace x \geq y \rbrace - p| (x - y)^2
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}, p) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} \in \mathbb{R}^n,
    p \in (0, 1)</code>
</p>



<h3>Value</h3>

<p>Value of the realised expectile score.
</p>


<h3>Note</h3>

<p>For details on the expectile scoring function, see <a href="#topic+expectile_sf">expectile_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The realised expectile score is the realised (average) score corresponding to
the expectile scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the realised expectile score.

set.seed(12345)

x &lt;- 0.5

y &lt;- rnorm(n = 100, mean = 0, sd = 1)

print(expectile_rs(x = x, y = y, p = 0.7))

print(expectile_rs(x = rep(x = x, times = 100), y = y, p = 0.7))
</code></pre>

<hr>
<h2 id='expectile_sf'>
Asymmetric piecewise quadratic scoring function (expectile scoring function,
expectile loss function)
</h2><span id='topic+expectile_sf'></span>

<h3>Description</h3>

<p>The function expectile_sf computes the asymmetric piecewise quadratic scoring
function (expectile scoring function) at a specific level <code class="reqn">p</code>, when
<code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive expectile at level
<code class="reqn">p</code>.
</p>
<p>The asymmetric piecewise quadratic scoring function is defined by eq. (27) in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expectile_sf(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expectile_sf_+3A_x">x</code></td>
<td>
<p>Predictive expectile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="expectile_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="expectile_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The asymmetric piecewise quadratic scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p) := |\textbf{1} \lbrace x \geq y \rbrace - p| (x - y)^2
    </code>
</p>

<p>or equivalently,
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p) := p (\max \lbrace -(x - y), 0 \rbrace)^2 +
        (1 - p) (\max \lbrace x - y, 0 \rbrace)^2
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p) \geq 0, \forall x, y \in \mathbb{R}, p \in (0, 1)</code>
</p>



<h3>Value</h3>

<p>Vector of expectile losses.
</p>


<h3>Note</h3>

<p>For the definition of expectiles, see Newey and Powell (1987).
</p>
<p>The asymmetric piecewise quadratic scoring function is negatively oriented (i.e.
the smaller, the better).
</p>
<p>The asymmetric piecewise quadratic scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the <code class="reqn">p</code>-expectile functional.
<code class="reqn">\mathbb{F}</code> is the family  of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y^2]</code> exists and is finite (Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Newey WK, Powell JL (1987) Asymmetric least squares estimation and testing.
<em>Econometrica</em> <b>55(4)</b>:819&ndash;847.
<a href="https://doi.org/10.2307/1911031">doi:10.2307/1911031</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the asymmetric piecewise quadratic scoring function (expectile scoring
# function).

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x = c(2, 2, -2, -2, 0, 0),
    p = rep(x = c(0.05, 0.95), times = 3)
)

df$expectile_penalty &lt;- expectile_sf(x = df$x, y = df$y, p = df$p)

print(df)

# The asymmetric piecewise quadratic scoring function (expectile scoring
# function) at level p = 0.5 is half the squared error scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 3),
    x = c(-2, 0, 2),
    p = rep(x = c(0.5), times = 3)
)

df$expectile_penalty &lt;- expectile_sf(x = df$x, y = df$y, p = df$p)

df$squared_error &lt;- serr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='ghuber_sf'>
Generalized Huber scoring function
</h2><span id='topic+ghuber_sf'></span>

<h3>Description</h3>

<p>The function ghuber_sf computes the generalized Huber scoring function at a
specific level <code class="reqn">p</code> and parameters <code class="reqn">a</code> and <code class="reqn">b</code>, when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive Huber functional at level <code class="reqn">p</code>.
</p>
<p>The generalized Huber scoring function is defined by eq. (4.7) in Taggart (2022)
for <code class="reqn">\phi(t) = t^2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ghuber_sf(x, y, p, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ghuber_sf_+3A_x">x</code></td>
<td>
<p>Predictive Huber functional (prediction) at level <code class="reqn">p</code>. It can be a
vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="ghuber_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="ghuber_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="ghuber_sf_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="ghuber_sf_+3A_b">b</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized Huber scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, a, b) := |\textbf{1} \lbrace x \geq y \rbrace - p|
            (y^2 - (\kappa_{a,b}(x - y) + y)^2 + 2 x \kappa_{a,b}(x - y))
    </code>
</p>

<p>or equivalently
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, a, b) :=
        |\textbf{1} \lbrace x \geq y \rbrace - p| f_{a,b}(x - y)
    </code>
</p>

<p>or
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, a, b) :=
        p f_{a,b}(- \max \lbrace -(x - y), 0 \rbrace) +
        (1 - p) f_{a,b}(\max \lbrace x - y, 0 \rbrace)
    </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">f_{a,b}(t) := \kappa_{a,b}(t) (2 t - \kappa_{a,b}(t))</code>
</p>

<p>and <code class="reqn">\kappa_{a,b}(t)</code> is the capping function defined by:
</p>
<p style="text-align: center;"><code class="reqn">\kappa_{a,b}(t) := \max \lbrace \min \lbrace t,b \rbrace, -a \rbrace</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p style="text-align: center;"><code class="reqn">a &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">b &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p, a, b) \geq 0, \forall x, y \in \mathbb{R}, p \in (0, 1), a, b &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of generalized Huber losses.
</p>


<h3>Note</h3>

<p>For the definition of Huber functionals, see definition 3.3 in Taggart (2022).
The value of eq. (4.7) is twice the value of the equation in definition 4.2 in
Taggart (2002).
</p>
<p>The generalized Huber scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The generalized Huber scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent
for the <code class="reqn">p</code>-Huber functional. <code class="reqn">\mathbb{F}</code> is the family of probability
distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y^2 - (Y - a)^2]</code> and
<code class="reqn">\textnormal{E}_F[Y^2 - (Y + b)^2]</code> (or equivalently
<code class="reqn">\textnormal{E}_F[Y]</code>) exist and are finite (Taggart 2022).
</p>


<h3>References</h3>

<p>Taggart RJ (2022) Point forecasting and forecast evaluation with generalized
Huber loss. <em>Electronic Journal of Statistics</em> <b>16</b>:201&ndash;231.
<a href="https://doi.org/10.1214/21-EJS1957">doi:10.1214/21-EJS1957</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the generalized Huber scoring function.

set.seed(12345)

n &lt;- 10

df &lt;- data.frame(
    x = runif(n, -2, 2),
    y = runif(n, -2, 2),
    p = runif(n, 0, 1),
    a = runif(n, 0, 1),
    b = runif(n, 0, 1)
)

df$ghuber_penalty &lt;- ghuber_sf(x = df$x, y = df$y, p = df$p, a = df$a, b = df$b)

print(df)

# Equivalence of the generalized Huber scoring function and the asymmetric
# piecewise quadratic scoring function (expectile scoring function), when
# a = Inf and b = Inf.

set.seed(12345)

n &lt;- 100

x &lt;- runif(n, -20, 20)
y &lt;- runif(n, -20, 20)
p &lt;- runif(n, 0, 1)
a &lt;- rep(x = Inf, times = n)
b &lt;- rep(x = Inf, times = n)

u &lt;- ghuber_sf(x = x, y = y, p = p, a = a, b = b)
v &lt;- expectile_sf(x = x, y = y, p = p)

max(abs(u - v)) # values are slightly higher than 0 due to rounding error
min(abs(u - v))

# Equivalence of the generalized Huber scoring function and the Huber scoring
# function when p = 1/2 and a = b.

set.seed(12345)

n &lt;- 100

x &lt;- runif(n, -20, 20)
y &lt;- runif(n, -20, 20)
p &lt;- rep(x = 1/2, times = n)
a &lt;- runif(n, 0, 20)

u &lt;- ghuber_sf(x = x, y = y, p = p, a = a, b = a)
v &lt;- huber_sf(x = x, y = y, a = a)

max(abs(u - v)) # values are slightly higher than 0 due to rounding error
min(abs(u - v))
</code></pre>

<hr>
<h2 id='gpl1_sf'>
Generalized piecewise linear power scoring function (type 1)
</h2><span id='topic+gpl1_sf'></span>

<h3>Description</h3>

<p>The function gpl1_sf computes the generalized piecewise linear power scoring
function at a specific level <code class="reqn">p</code> for <code class="reqn">g(x) = x^b/|b|</code>, <code class="reqn">b &gt; 0</code>, when
<code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive quantile at level <code class="reqn">p</code>.
</p>
<p>The generalized piecewise linear power scoring function is defined by eq. (25)
in Gneiting (2011) and the form implemented here for the specific <code class="reqn">g(x)</code> is
defined by eq. (26) in Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpl1_sf(x, y, p, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpl1_sf_+3A_x">x</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="gpl1_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="gpl1_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="gpl1_sf_+3A_b">b</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized piecewise linear power scoring function (type 1) is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, b) :=
        (1/|b|) (\textbf{1} \lbrace x \geq y \rbrace - p) (x^b - y^b)
    </code>
</p>

<p>or equivalently
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, b) := (1/|b|) (p | \max \lbrace -(x^b - y^b), 0 \rbrace | +
        (1 - p) | \max \lbrace x^b - y^b, 0 \rbrace |)
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p style="text-align: center;"><code class="reqn">b &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p, b) \geq 0, \forall x, y &gt; 0, p \in (0, 1), b &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of generalized piecewise linear power losses.
</p>


<h3>Note</h3>

<p>The implemented function is denoted as type 1 since it corresponds to a specific
type of <code class="reqn">g(x)</code> of the general form of the generalized piecewise linear power
scoring function defined by eq. (25) in Gneiting (2011).
</p>
<p>For the definition of quantiles, see Koenker and Bassett Jr (1978).
</p>
<p>The generalized piecewise linear scoring function is negatively oriented (i.e.
the smaller, the better).
</p>
<p>The herein implemented generalized piecewise linear power scoring function is
strictly <code class="reqn">\mathbb{F}</code>-consistent for the <code class="reqn">p</code>-quantile functional.
<code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y^b]</code> exists and is finite (Thomson 1979; Saerens 2000;
Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Koenker R, Bassett Jr G (1978) Regression quantiles. <em>Econometrica</em>
<b>46(1)</b>:33&ndash;50. <a href="https://doi.org/10.2307/1913643">doi:10.2307/1913643</a>.
</p>
<p>Saerens M (2000) Building cost functions minimizing to some summary statistics.
<em>IEEE Transactions on Neural Networks</em> <b>11(6)</b>:1263&ndash;1271.
<a href="https://doi.org/10.1109/72.883416">doi:10.1109/72.883416</a>.
</p>
<p>Thomson W (1979) Eliciting production possibilities from a well-informed
manager. <em>Journal of Economic Theory</em> <b>20(3)</b>:360&ndash;380.
<a href="https://doi.org/10.1016/0022-0531%2879%2990042-5">doi:10.1016/0022-0531(79)90042-5</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the generalized piecewise linear scoring function (type 1).

df &lt;- data.frame(
    y = rep(x = 2, times = 6),
    x = c(1, 2, 3, 1, 2, 3),
    p = c(rep(x = 0.05, times = 3), rep(x = 0.95, times = 3)),
    b = rep(x = 2, times = 6)
)

df$gpl1_penalty &lt;- gpl1_sf(x = df$x, y = df$y, p = df$p, b = df$b)

print(df)

# Equivalence of generalized piecewise linear scoring function (type 1) and
# asymmetric piecewise linear scoring function (quantile scoring function), when
# b = 1.

set.seed(12345)

n &lt;- 100

x &lt;- runif(n, 0, 20)
y &lt;- runif(n, 0, 20)
p &lt;- runif(n, 0, 1)
b &lt;- rep(x = 1, times = n)

u &lt;- gpl1_sf(x = x, y = y, p = p, b = b)
v &lt;- quantile_sf(x = x, y = y, p = p)

max(abs(u - v))

# Equivalence of generalized piecewise linear scoring function (type 1) and
# MAE-SD scoring function, when p = 1/2 and b = 1/2.

set.seed(12345)

n &lt;- 100

x &lt;- runif(n, 0, 20)
y &lt;- runif(n, 0, 20)
p &lt;- rep(x = 0.5, times = n)
b &lt;- rep(x = 1/2, times = n)

u &lt;- gpl1_sf(x = x, y = y, p = p, b = b)
v &lt;- maesd_sf(x = x, y = y)

max(abs(u - v))
</code></pre>

<hr>
<h2 id='gpl2_sf'>
Generalized piecewise linear power scoring function (type 2)
</h2><span id='topic+gpl2_sf'></span>

<h3>Description</h3>

<p>The function gpl2_sf computes the generalized piecewise linea power scoring
function at a specific level <code class="reqn">p</code> for <code class="reqn">g(x) = \log(x)</code>, when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive quantile at level <code class="reqn">p</code>.
</p>
<p>The generalized piecewise linear power scoring function is negatively oriented
(i.e. the smaller, the better).
</p>
<p>The generalized piecewise linear scoring function is defined by eq. (25) in
Gneiting (2011) and the form implemented here for the specific <code class="reqn">g(x)</code> is
defined by eq. (26) in Gneiting (2011) for <code class="reqn">b = 0</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpl2_sf(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpl2_sf_+3A_x">x</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="gpl2_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="gpl2_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generalized piecewise linear power scoring function (type 2) is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p) := (\textbf{1} \lbrace x \geq y \rbrace - p) \log(x/y)
    </code>
</p>

<p>or equivalently
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p) := p | \max \lbrace -(\log(x) - \log(y)), 0 \rbrace | +
        (1 - p) | \max \lbrace \log(x) - \log(y), 0 \rbrace |
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p) \geq 0, \forall x, y &gt; 0, p \in (0, 1)</code>
</p>



<h3>Value</h3>

<p>Vector of generalized piecewise linear losses.
</p>


<h3>Note</h3>

<p>The implemented function is denoted as type 2 since it corresponds to a specific
type of <code class="reqn">g(x)</code> of the general form of the generalized piecewise linear power
scoring function defined by eq. (25) in Gneiting (2011).
</p>
<p>For the definition of quantiles, see Koenker and Bassett Jr (1978).
</p>
<p>The herein implemented generalized piecewise linear power scoring function is
strictly <code class="reqn">\mathbb{F}</code>-consistent for the <code class="reqn">p</code>-quantile functional.
<code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[\log(Y)]</code> exists and is finite (Thomson 1979; Saerens
2000; Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Koenker R, Bassett Jr G (1978) Regression quantiles. <em>Econometrica</em>
<b>46(1)</b>:33&ndash;50. <a href="https://doi.org/10.2307/1913643">doi:10.2307/1913643</a>.
</p>
<p>Saerens M (2000) Building cost functions minimizing to some summary statistics.
<em>IEEE Transactions on Neural Networks</em> <b>11(6)</b>:1263&ndash;1271.
<a href="https://doi.org/10.1109/72.883416">doi:10.1109/72.883416</a>.
</p>
<p>Thomson W (1979) Eliciting production possibilities from a well-informed
manager. <em>Journal of Economic Theory</em> <b>20(3)</b>:360&ndash;380.
<a href="https://doi.org/10.1016/0022-0531%2879%2990042-5">doi:10.1016/0022-0531(79)90042-5</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the generalized piecewise linear scoring function (type 2).

df &lt;- data.frame(
    y = rep(x = 2, times = 6),
    x = c(1, 2, 3, 1, 2, 3),
    p = c(rep(x = 0.05, times = 3), rep(x = 0.95, times = 3))
)

df$gpl2_penalty &lt;- gpl2_sf(x = df$x, y = df$y, p = df$p)

print(df)

# The generalized piecewise linear scoring function (type 2) is half the MAE-LOG
# scoring function.

df &lt;- data.frame(
    y = rep(x = 5.5, times = 10),
    x = 1:10,
    p = rep(x = 0.5, times = 10)
)

df$gpl2_penalty &lt;- gpl2_sf(x = df$x, y = df$y, p = df$p)

df$mae_log_penalty &lt;- maelog_sf(x = df$x, y = df$y)

df$ratio &lt;- df$gpl2_penalty/df$mae_log_penalty

print(df)
</code></pre>

<hr>
<h2 id='huber_rs'>
Mean Huber score
</h2><span id='topic+huber_rs'></span>

<h3>Description</h3>

<p>The function huber_rs computes the mean Huber score with parameter
<code class="reqn">a</code>, when <code class="reqn">\textbf{\textit{y}}</code> materialises and
<code class="reqn">\textbf{\textit{x}}</code> is the prediction.
</p>
<p>Mean Huber score is a realised score corresponding to the Huber scoring function
<a href="#topic+huber_sf">huber_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber_rs(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huber_rs_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="huber_rs_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
<tr><td><code id="huber_rs_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>) or a scalar.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean Huber score is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}, a) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i, a)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
        L(x, y, a) := \left\{
        \begin{array}{ll}
        \dfrac{1}{2} (x - y)^2, &amp; |x - y| \leq a\\
        a |x - y| - \dfrac{1}{2} a^2, &amp; |x - y| &gt; a
        \end{array}
        \right.
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">a &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}, a) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} \in \mathbb{R}^n, a &gt; 0</code>
</p>



<h3>Value</h3>

<p>Value of the mean Huber score.
</p>


<h3>Note</h3>

<p>For details on the Huber scoring function, see <a href="#topic+huber_sf">huber_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean Huber score is the realised (average) score corresponding to the Huber
scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Huber mean score.

set.seed(12345)

a &lt;- 0.5

x &lt;- 0

y &lt;- rnorm(n = 100, mean = 0, sd = 1)

print(huber_rs(x = x, y = y, a = a))

print(huber_rs(x = rep(x = x, times = 100), y = y, a = a))
</code></pre>

<hr>
<h2 id='huber_sf'>
Huber scoring function
</h2><span id='topic+huber_sf'></span>

<h3>Description</h3>

<p>The function huber_sf computes the Huber scoring function with parameter
<code class="reqn">a</code>, when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive Huber mean.
</p>
<p>The Huber scoring function is defined in Huber (1964).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huber_sf(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huber_sf_+3A_x">x</code></td>
<td>
<p>Predictive Huber mean (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="huber_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="huber_sf_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Huber scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, a) := \left\{
        \begin{array}{ll}
        \dfrac{1}{2} (x - y)^2, &amp; |x - y| \leq a\\
        a |x - y| - \dfrac{1}{2} a^2, &amp; |x - y| &gt; a
        \end{array}
        \right.
    </code>
</p>

<p>or equivalently
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, a) := (1/2) \kappa_{a,a}(x - y) (2 (x - y) - \kappa_{a,a}(x - y))
    </code>
</p>

<p>where <code class="reqn">\kappa_{a,b}(t)</code> is the capping function defined by:
</p>
<p style="text-align: center;"><code class="reqn">\kappa_{a,b}(t) := \max \lbrace \min \lbrace t,b \rbrace, -a \rbrace</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">a &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, a) \geq 0, \forall x, y \in \mathbb{R}, a &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of Huber losses.
</p>


<h3>Note</h3>

<p>For the definition of Huber mean, see Taggart (2022).
</p>
<p>The Huber scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The Huber scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for the Huber
mean. <code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for
which <code class="reqn">\textnormal{E}_F[Y^2 - (Y - a)^2]</code> and
<code class="reqn">\textnormal{E}_F[Y^2 - (Y + a)^2]</code> (or equivalently
<code class="reqn">\textnormal{E}_F[Y]</code>) exist and are finite (Taggart 2022).
</p>


<h3>References</h3>

<p>Huber PJ (1964) Robust estimation of a location parameter.
<em>Annals of Mathematical Statistics</em> <b>35(1)</b>:73&ndash;101.
<a href="https://doi.org/10.1214/aoms/1177703732">doi:10.1214/aoms/1177703732</a>.
</p>
<p>Taggart RJ (2022) Point forecasting and forecast evaluation with generalized
Huber loss. <em>Electronic Journal of Statistics</em> <b>16</b>:201&ndash;231.
<a href="https://doi.org/10.1214/21-EJS1957">doi:10.1214/21-EJS1957</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Huber scoring function.

df &lt;- data.frame(
    x = c(-3, -2, -1, 0, 1, 2, 3),
    y = c(0, 0, 0, 0, 0, 0, 0),
    a = c(2.7, 2.5, 0.6, 0.7, 0.9, 1.2, 5)
)

df$huber_penalty &lt;- huber_sf(x = df$x, y = df$y, a = df$a)

print(df)
</code></pre>

<hr>
<h2 id='hubermean_if'>
Huber mean identification function
</h2><span id='topic+hubermean_if'></span>

<h3>Description</h3>

<p>The function hubermean_if computes the Huber mean identification function with
parameter <code class="reqn">a</code>, when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive Huber
mean.
</p>
<p>The Huber mean identification function is defined by eq. (3.5) in Taggart
(2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hubermean_if(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hubermean_if_+3A_x">x</code></td>
<td>
<p>Predictive Huber mean (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="hubermean_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="hubermean_if_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Huber mean identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, a) := (1/2) \kappa_{a,a}(x - y)</code>
</p>

<p>where <code class="reqn">\kappa_{a,b}(t)</code> is the capping function defined by:
</p>
<p style="text-align: center;"><code class="reqn">\kappa_{a,b}(t) := \max \lbrace \min \lbrace t,b \rbrace, -a \rbrace</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">a &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of values of the Huber mean identification function.
</p>


<h3>Note</h3>

<p>For the definition of Huber mean, see Taggart (2022).
</p>
<p>The Huber mean identification function is a strict
<code class="reqn">\mathbb{F}</code>-identification function for the Huber mean functional (Taggart
2022).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
for which <code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite (Taggart 2022).
</p>


<h3>References</h3>

<p>Taggart RJ (2022) Point forecasting and forecast evaluation with generalized
Huber loss. <em>Electronic Journal of Statistics</em> <b>16</b>:201&ndash;231.
<a href="https://doi.org/10.1214/21-EJS1957">doi:10.1214/21-EJS1957</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Huber mean identification function.

df &lt;- data.frame(
    x = c(-3, -2, -1, 0, 1, 2, 3),
    y = c(0, 0, 0, 0, 0, 0, 0),
    a = c(2.7, 2.5, 0.6, 0.7, 0.9, 1.2, 5)
)

df$hubermean_if &lt;- hubermean_if(x = df$x, y = df$y, a = df$a)

print(df)
</code></pre>

<hr>
<h2 id='huberquantile_if'>
Huber quantile identification function
</h2><span id='topic+huberquantile_if'></span>

<h3>Description</h3>

<p>The function huberquantile_if computes the Huber quantile identification
function at a specific level <code class="reqn">p</code> and parameters <code class="reqn">a</code> and <code class="reqn">b</code>, when
<code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive Huber functional at level
<code class="reqn">p</code>.
</p>
<p>The Huber quantile identification function is defined by eq. (3.5) in Taggart
(2022).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huberquantile_if(x, y, p, a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="huberquantile_if_+3A_x">x</code></td>
<td>
<p>Predictive Huber functional (prediction) at level <code class="reqn">p</code>. It can be a
vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="huberquantile_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="huberquantile_if_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="huberquantile_if_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="huberquantile_if_+3A_b">b</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Huber quantile identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, a) := |\textbf{1} \lbrace x \geq y \rbrace - p|
    \kappa_{a,b}(x - y)</code>
</p>

<p>where <code class="reqn">\kappa_{a,b}(t)</code> is the capping function defined by:
</p>
<p style="text-align: center;"><code class="reqn">\kappa_{a,b}(t) := \max \lbrace \min \lbrace t,b \rbrace, -a \rbrace</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p style="text-align: center;"><code class="reqn">a &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">b &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of values of the Huber quantile identification function.
</p>


<h3>Note</h3>

<p>For the definition of Huber quantile, see Taggart (2022).
</p>
<p>The Huber quantile identification function is a strict
<code class="reqn">\mathbb{F}</code>-identification function for the Huber quantile functional
(Taggart 2022).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
for which <code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite (Taggart 2022).
</p>


<h3>References</h3>

<p>Taggart RJ (2022) Point forecasting and forecast evaluation with generalized
Huber loss. <em>Electronic Journal of Statistics</em> <b>16</b>:201&ndash;231.
<a href="https://doi.org/10.1214/21-EJS1957">doi:10.1214/21-EJS1957</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Huber quantile identification function.

set.seed(12345)

n &lt;- 10

df &lt;- data.frame(
    x = runif(n, -2, 2),
    y = runif(n, -2, 2),
    p = runif(n, 0, 1),
    a = runif(n, 0, 1),
    b = runif(n, 0, 1)
)

df$huberquantile_if &lt;- huberquantile_if(x = df$x, y = df$y, p = df$p, a = df$a,
    b = df$b)

print(df)
</code></pre>

<hr>
<h2 id='interval_sf'>
Interval scoring function (Winkler scoring function)
</h2><span id='topic+interval_sf'></span>

<h3>Description</h3>

<p>The function interval_sf computes the interval scoring function (Winkler scoring
function) when <code class="reqn">y</code> materialises and <code class="reqn">[x_1, x_2]</code> is the central
<code class="reqn">1 - p</code> prediction interval.
</p>
<p>The interval scoring function is defined by eq. (43) in Gneiting and Raftery
(2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interval_sf(x1, x2, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="interval_sf_+3A_x1">x1</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">p/2</code>. It can be a
vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="interval_sf_+3A_x2">x2</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">1 - p/2</code>. It can be a
vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="interval_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x_1</code>).</p>
</td></tr>
<tr><td><code id="interval_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interval scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x_1, x_2, y, p) := (x_2 - x_1) +
            (2/p) (x_1 - y) \textbf{1} \lbrace y &lt; x_1 \rbrace +
            (2/p) (y - x_2) \textbf{1} \lbrace y &gt; x_2 \rbrace
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x_1 \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_2 \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_1 &lt; x_2</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x_1, x_2, y, p) \geq 0, \forall x_1, x_2, y \in \mathbb{R},
    x_1 &lt; x_2, p \in (0, 1)</code>
</p>



<h3>Value</h3>

<p>Vector of interval losses.
</p>


<h3>Note</h3>

<p>For the definition of quantiles, see Koenker and Bassett Jr (1978).
</p>
<p>The interval scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The interval scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for the
central <code class="reqn">1 - p</code> prediction interval <code class="reqn">[x_1, x_2]</code>. <code class="reqn">x_1</code> and
<code class="reqn">x_2</code> are quantile functionals at levels <code class="reqn">p/2</code> and <code class="reqn">1 - p/2</code>
respectively.
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite (Dunsmore 1968; Winkler 1972;
Gneiting and Raftery 2007; Winkler and Murphy 1979; Fissler and Ziegel 2016;
Brehmer and Gneiting 2021).
</p>


<h3>References</h3>

<p>Brehmer JR, Gneiting T (2021) Scoring interval forecasts: Equal-tailed,
shortest, and modal interval. <em>Bernoulli</em> <b>27(3)</b>:1993&ndash;2010.
<a href="https://doi.org/10.3150/20-BEJ1298">doi:10.3150/20-BEJ1298</a>.
</p>
<p>Dunsmore IR (1968) A Bayesian approach to calibration.
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>
<b>30(2)</b>:396&ndash;405. <a href="https://doi.org/10.1111/j.2517-6161.1968.tb00740.x">doi:10.1111/j.2517-6161.1968.tb00740.x</a>.
</p>
<p>Fissler T, Ziegel JF (2016) Higher order elicitability and Osband's principle.
<em>The Annals of Statistics</em> <b>44(4)</b>:1680&ndash;1707.
<a href="https://doi.org/10.1214/16-AOS1439">doi:10.1214/16-AOS1439</a>.
</p>
<p>Gneiting T, Raftery AE (2007) Strictly proper scoring rules, prediction, and
estimation. <em>Journal of the American Statistical Association</em>
<b>102(477)</b>:359&ndash;378. <a href="https://doi.org/10.1198/016214506000001437">doi:10.1198/016214506000001437</a>.
</p>
<p>Koenker R, Bassett Jr G (1978) Regression quantiles. <em>Econometrica</em>
<b>46(1)</b>:33&ndash;50. <a href="https://doi.org/10.2307/1913643">doi:10.2307/1913643</a>.
</p>
<p>Winkler RL (1972) A decision-theoretic approach to interval estimation.
<em>Journal of the American Statistical Association</em> <b>67(337)</b>:187&ndash;191.
<a href="https://doi.org/10.1080/01621459.1972.10481224">doi:10.1080/01621459.1972.10481224</a>.
</p>
<p>Winkler RL, Murphy AH (1979) The use of probabilities in forecasts of maximum
and minimum temperatures.<em>Meteorological Magazine</em>
<b>108(1288)</b>:317&ndash;329.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the interval scoring function (Winkler scoring function).

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x1 = c(-3, -2, -1, 0, 1, 2),
    x2 = c(1, 2, 3, 4, 5, 6),
    p = rep(x = c(0.05, 0.95), times = 3)
)

df$interval_penalty &lt;- interval_sf(x1 = df$x1, x2 = df$x2, y = df$y, p = df$p)

print(df)
</code></pre>

<hr>
<h2 id='linex_sf'>
LINEX scoring function
</h2><span id='topic+linex_sf'></span>

<h3>Description</h3>

<p>The function linex_sf computes the LINEX scoring function with parameter <code class="reqn">a</code>
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">-(1/a) \log{\textnormal{E}_F[\textnormal{e}^{-a Y}]}</code> moment generating
functional.
</p>
<p>The LINEX scoring function is defined by Varian (1975).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linex_sf(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="linex_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">-(1/a) \log{\textnormal{E}_F[\textnormal{e}^{-a Y}]}</code>
moment generating functional (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="linex_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="linex_sf_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LINEX scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, a) := \textnormal{e}^{a (x - y)} - a (x - y) - 1</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">a \neq 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, a) \geq 0, \forall x, y \in \mathbb{R}, a \neq 0</code>
</p>



<h3>Value</h3>

<p>Vector of LINEX losses.
</p>


<h3>Note</h3>

<p>For details on the LINEX scoring function, see Varian (1975) and Zellner (1986).
</p>
<p>The LINEX scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The LINEX scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for
the <code class="reqn">-(1/a) \log{\textnormal{E}_F[\textnormal{e}^{-a Y}]}</code> moment generating
functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code>
for which <code class="reqn">\textnormal{E}_F[\textnormal{e}^{-a Y}]</code> and
<code class="reqn">\textnormal{E}_F[Y]</code> exist and are finite (Varian 1975; Zellner 1986;
Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Varian HR (1975) A Bayesian approach to real estate assessment. In: Fienberg SE,
Zellner A(eds) <em>Studies in Bayesian Econometrics and Statistics in Honor of
Leonard J. Savage</em>. Amsterdam: North-Holland, pp 195&ndash;208.
</p>
<p>Zellner A (1986) Bayesian estimation and prediction using asymmetric loss
functions. <em>Journal of the American Statistical Association</em>
<b>81(394)</b>:446&ndash;451. <a href="https://doi.org/10.1080/01621459.1986.10478289">doi:10.1080/01621459.1986.10478289</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the LINEX scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3,
    a = c(-1, 1, 2)
)

df$linex_loss &lt;- linex_sf(x = df$x, y = df$y, a = df$a)

print(df)
</code></pre>

<hr>
<h2 id='lqmean_sf'>
<code class="reqn">L_q</code>-mean scoring function
</h2><span id='topic+lqmean_sf'></span>

<h3>Description</h3>

<p>The function lqmean_sf computes the <code class="reqn">L_q</code>-mean scoring function, when
<code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive <code class="reqn">L_q</code>-mean.
</p>
<p>The <code class="reqn">L_q</code>-mean scoring function is defined by Chen (1996). It is equivalent
to the <code class="reqn">L_q</code>-quantile scoring function at level <code class="reqn">p = 1/2</code>, up to a
multiplicative constant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lqmean_sf(x, y, q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lqmean_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">L_q</code>-mean. It can be a vector of length <code class="reqn">n</code> (must
have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="lqmean_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="lqmean_sf_+3A_q">q</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">L_q</code>-mean scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, q) := |x - y|^q
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">q \geq 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, q) \geq 0, \forall x, y \in \mathbb{R}, q \geq 1</code>
</p>



<h3>Value</h3>

<p>Vector of <code class="reqn">L_q</code>-mean losses.
</p>


<h3>Note</h3>

<p>For the definition of <code class="reqn">L_q</code>-means, see Chen (1996). In particular,
<code class="reqn">L_q</code>-means are the solution of the equation
<code class="reqn">\textnormal{E}_F[V(x, Y, q)] = 0</code>, where
</p>
<p style="text-align: center;"><code class="reqn">
        V(x, y, p, q) := q \textnormal{sign}(x - y) |x - y|^{q - 1}
    </code>
</p>

<p><code class="reqn">L_q</code>-means are <code class="reqn">L_q</code>-quantiles at level <code class="reqn">p = 1/2</code>.
</p>
<p>The <code class="reqn">L_q</code>-mean scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The <code class="reqn">L_q</code>-mean scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent
for the <code class="reqn">L_q</code>-mean functional. <code class="reqn">\mathbb{F}</code> is the family of probability
distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y^q]</code> exists and is finite
(Chen 2016; Bellini 2014).
</p>


<h3>References</h3>

<p>Bellini F, Klar B, Muller A, Gianin ER (2014) Generalized quantiles as risk
measures. <em>Insurance: Mathematics and Economics</em> <b>54</b>:41&ndash;48.
<a href="https://doi.org/10.1016/j.insmatheco.2013.10.015">doi:10.1016/j.insmatheco.2013.10.015</a>.
</p>
<p>Chen Z (1996) Conditional <code class="reqn">L_p</code>-quantiles and their application to the
testing of symmetry in non-parametric regression.
<em>Statistics and Probability Letters</em> <b>29(2)</b>:107&ndash;115.
<a href="https://doi.org/10.1016/0167-7152%2895%2900163-8">doi:10.1016/0167-7152(95)00163-8</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Lq-mean scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x = c(2, 2, -2, -2, 0, 0),
    q = c(2, 3, 2, 3, 2, 3)
)

df$lqmean_penalty &lt;- lqmean_sf(x = df$x, y = df$y, q = df$q)

print(df)
</code></pre>

<hr>
<h2 id='lqquantile_sf'>
<code class="reqn">L_q</code>-quantile scoring function
</h2><span id='topic+lqquantile_sf'></span>

<h3>Description</h3>

<p>The function lqquantile_sf computes the <code class="reqn">L_q</code>-quantile scoring function at a
specific level <code class="reqn">p</code>, when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">L_q</code>-quantile at level <code class="reqn">p</code>.
</p>
<p>The <code class="reqn">L_q</code>-quantile scoring function is defined by Chen (1996).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lqquantile_sf(x, y, p, q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lqquantile_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">L_q</code>-quantile at level <code class="reqn">p</code>. It can be a vector of
length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="lqquantile_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="lqquantile_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="lqquantile_sf_+3A_q">q</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">L_q</code>-quantile scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, q) := |\textbf{1} \lbrace x \geq y \rbrace - p| |x - y|^q
    </code>
</p>

<p>or equivalently,
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p, q) := p |\max \lbrace -(x - y), 0 \rbrace|^q +
        (1 - p) |\max \lbrace x - y, 0 \rbrace|^q
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p style="text-align: center;"><code class="reqn">q \geq 2</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p, q) \geq 0, \forall x, y \in \mathbb{R}, p \in (0, 1),
        q \geq 2</code>
</p>



<h3>Value</h3>

<p>Vector of <code class="reqn">L_q</code>-quantile losses.
</p>


<h3>Note</h3>

<p>For the definition of <code class="reqn">L_q</code>-quantiles, see Chen (1996). In particular,
<code class="reqn">L_q</code>-quantiles at level <code class="reqn">p</code> are the solution of the equation
<code class="reqn">\textnormal{E}_F[V(x, Y, p, q)] = 0</code>, where
</p>
<p style="text-align: center;"><code class="reqn">
        V(x, y, p, q) := q (\textbf{1} \lbrace x \geq y \rbrace - p)
            |x - y|^{q - 1}
    </code>
</p>

<p>The <code class="reqn">L_q</code>-quantile scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The <code class="reqn">L_q</code>-quantile scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent
for the <code class="reqn">L_q</code>-quantile functional at level <code class="reqn">p</code>. <code class="reqn">\mathbb{F}</code> is the
family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y^q]</code> exists and is finite (Chen 2016; Bellini 2014).
</p>


<h3>References</h3>

<p>Bellini F, Klar B, Muller A, Gianin ER (2014) Generalized quantiles as risk
measures. <em>Insurance: Mathematics and Economics</em> <b>54</b>:41&ndash;48.
<a href="https://doi.org/10.1016/j.insmatheco.2013.10.015">doi:10.1016/j.insmatheco.2013.10.015</a>.
</p>
<p>Chen Z (1996) Conditional <code class="reqn">L_p</code>-quantiles and their application to the
testing of symmetry in non-parametric regression.
<em>Statistics and Probability Letters</em> <b>29(2)</b>:107&ndash;115.
<a href="https://doi.org/10.1016/0167-7152%2895%2900163-8">doi:10.1016/0167-7152(95)00163-8</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Lq-quantile scoring function at level p.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x = c(2, 2, -2, -2, 0, 0),
    p = rep(x = c(0.05, 0.95), times = 3),
    q = c(2, 3, 2, 3, 2, 3)
)

df$lqquantile_penalty &lt;- lqquantile_sf(x = df$x, y = df$y, p = df$p, q = df$q)

print(df)
</code></pre>

<hr>
<h2 id='mae'>
Mean absolute error (MAE)
</h2><span id='topic+mae'></span>

<h3>Description</h3>

<p>The function mae computes the mean absolute error when <code class="reqn">\textbf{\textit{y}}</code>
materialises and <code class="reqn">\textbf{\textit{x}}</code> is the prediction.
</p>
<p>Mean absolute error is a realised score corresponding to the absolute error
scoring function <a href="#topic+aerr_sf">aerr_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mae(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mae_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="mae_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean absolute error is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y) := |x - y|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>



<h3>Value</h3>

<p>Value of the mean absolute error.
</p>


<h3>Note</h3>

<p>For details on the absolute error scoring function, see <a href="#topic+aerr_sf">aerr_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean absolute error is the realised (average) score corresponding to the
absolute error scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean absolute error.

set.seed(12345)

x &lt;- 0

y &lt;- rnorm(n = 100, mean = 0, sd = 1)

print(mae(x = x, y = y))

print(mae(x = rep(x = x, times = 100), y = y))
</code></pre>

<hr>
<h2 id='maelog_sf'>
MAE-LOG scoring function
</h2><span id='topic+maelog_sf'></span>

<h3>Description</h3>

<p>The function maelog_sf computes the MAE-LOG scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive median functional.
</p>
<p>The MAE-LOG scoring function is defined by eq. (11) in Patton (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maelog_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maelog_sf_+3A_x">x</code></td>
<td>
<p>Predictive median functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="maelog_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MAE-LOG scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := |\log(x/y)|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of MAE-LOG losses.
</p>


<h3>Note</h3>

<p>For details on the MAE-LOG scoring function, see Gneiting (2011) and Patton
(2011).
</p>
<p>The median functional is the median of the probability distribution <code class="reqn">F</code> of
<code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The MAE-LOG scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The MAE-LOG scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for the
median functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions
<code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[\log(Y)]</code> exists and is finite (Thomson
1979; Saerens 2000; Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Patton AJ (2011) Volatility forecast comparison using imperfect volatility
proxies. <em>Journal of Econometrics</em> <b>160(1)</b>:246&ndash;256.
<a href="https://doi.org/10.1016/j.jeconom.2010.03.034">doi:10.1016/j.jeconom.2010.03.034</a>.
</p>
<p>Saerens M (2000) Building cost functions minimizing to some summary statistics.
<em>IEEE Transactions on Neural Networks</em> <b>11(6)</b>:1263&ndash;1271.
<a href="https://doi.org/10.1109/72.883416">doi:10.1109/72.883416</a>.
</p>
<p>Thomson W (1979) Eliciting production possibilities from a well-informed
manager. <em>Journal of Economic Theory</em> <b>20(3)</b>:360&ndash;380.
<a href="https://doi.org/10.1016/0022-0531%2879%2990042-5">doi:10.1016/0022-0531(79)90042-5</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the MAE-LOG scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$mae_log_penalty &lt;- maelog_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='maesd_sf'>
MAE-SD scoring function
</h2><span id='topic+maesd_sf'></span>

<h3>Description</h3>

<p>The function maesd_sf computes the MAE-SD scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive median functional.
</p>
<p>The MAE-SD scoring function is defined by eq. (12) in Patton (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maesd_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maesd_sf_+3A_x">x</code></td>
<td>
<p>Predictive median functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="maesd_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MAE-SD scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := |x^{1/2} - y^{1/2}|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of MAE-SD losses.
</p>


<h3>Note</h3>

<p>For details on the MAE-SD scoring function, see Gneiting (2011) and Patton
(2011).
</p>
<p>The median functional is the median of the probability distribution <code class="reqn">F</code> of
<code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The MAE-SD scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The MAE-SD scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for the
median functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions
<code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y^{1/2}]</code> exists and is finite (Thomson
1979; Saerens 2000; Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Patton AJ (2011) Volatility forecast comparison using imperfect volatility
proxies. <em>Journal of Econometrics</em> <b>160(1)</b>:246&ndash;256.
<a href="https://doi.org/10.1016/j.jeconom.2010.03.034">doi:10.1016/j.jeconom.2010.03.034</a>.
</p>
<p>Saerens M (2000) Building cost functions minimizing to some summary statistics.
<em>IEEE Transactions on Neural Networks</em> <b>11(6)</b>:1263&ndash;1271.
<a href="https://doi.org/10.1109/72.883416">doi:10.1109/72.883416</a>.
</p>
<p>Thomson W (1979) Eliciting production possibilities from a well-informed
manager. <em>Journal of Economic Theory</em> <b>20(3)</b>:360&ndash;380.
<a href="https://doi.org/10.1016/0022-0531%2879%2990042-5">doi:10.1016/0022-0531(79)90042-5</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the MAE-SD scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$mae_sd_penalty &lt;- maesd_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='mape'>
Mean absolute percentage error (MAPE)
</h2><span id='topic+mape'></span>

<h3>Description</h3>

<p>The function mape computes the mean absolute percentage error when
<code class="reqn">\textbf{\textit{y}}</code> materialises and <code class="reqn">\textbf{\textit{x}}</code> is the
prediction.
</p>
<p>Mean absolute percentage error is a realised score corresponding to the absolute
percentage error scoring function <a href="#topic+aperr_sf">aperr_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mape(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mape_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="mape_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean absolute pecentage error is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y) := |(x - y)/y|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} &gt; \textbf{0}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} &gt; \textbf{0}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{0} = (0, ..., 0)^\mathsf{T}</code>
</p>

<p>is the zero vector of length <code class="reqn">n</code> and the symbol <code class="reqn">&gt;</code> indicates pairwise
inequality.
</p>
<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} &gt; \textbf{0}</code>
</p>



<h3>Value</h3>

<p>Value of the mean absolute percentage error.
</p>


<h3>Note</h3>

<p>For details on the absolute percentage error scoring function, see
<a href="#topic+aperr_sf">aperr_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean absolute percentage error is the realised (average) score corresponding
to the absolute percentage error scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean absolute percentage error.

set.seed(12345)

x &lt;- 0.5

y &lt;- rlnorm(n = 100, mean = 0, sdlog = 1)

print(mape(x = x, y = y))

print(mape(x = rep(x = x, times = 100), y = y))
</code></pre>

<hr>
<h2 id='mean_if'>
Mean identification function
</h2><span id='topic+mean_if'></span>

<h3>Description</h3>

<p>The function mean_if computes the mean identification function , when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive mean.
</p>
<p>The mean identification function is defined in Table 9 in Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mean_if(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mean_if_+3A_x">x</code></td>
<td>
<p>Predictive mean (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="mean_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y) := x - y</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y) \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Vector of values of the mean identification function.
</p>


<h3>Note</h3>

<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The mean identification function is a strict <code class="reqn">\mathbb{F}</code>-identification
function for the mean functional. (Gneiting 2011; Fissler and Ziegel 2016;
Dimitriadis et al. 2024).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite (Gneiting 2011; Fissler and
Ziegel 2016; Dimitriadis et al. 2024).
</p>


<h3>References</h3>

<p>Dimitriadis T, Fissler T, Ziegel JF (2024) Osband's principle for identification
functions. <em>Statistical Papers</em> <b>65</b>:1125&ndash;1132.
<a href="https://doi.org/10.1007/s00362-023-01428-x">doi:10.1007/s00362-023-01428-x</a>.
</p>
<p>Fissler T, Ziegel JF (2016) Higher order elicitability and Osband's principle.
<em>The Annals of Statistics</em> <b>44(4)</b>:1680&ndash;1707.
<a href="https://doi.org/10.1214/16-AOS1439">doi:10.1214/16-AOS1439</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Newey WK, Powell JL (1987) Asymmetric least squares estimation and testing.
<em>Econometrica</em> <b>55(4)</b>:819&ndash;847. <a href="https://doi.org/10.2307/1911031">doi:10.2307/1911031</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean identification function.

df &lt;- data.frame(
    y = rep(x = 0, times = 3),
    x = c(-2, 0, 2)
)

df$mean_if &lt;- mean_if(x = df$x, y = df$y)
</code></pre>

<hr>
<h2 id='meanlog_if'>
Log-transformed identification function
</h2><span id='topic+meanlog_if'></span>

<h3>Description</h3>

<p>The function meanlog_if computes the log-transformed identification function,
when <code class="reqn">y</code> materialises and <code class="reqn">\exp(\textnormal{E}_F[\log(Y)])</code> is the
predictive functional.
</p>
<p>The log-transformed identification function is defined in Tyralis and
Papacharalampous (2025).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanlog_if(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="meanlog_if_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\exp(\textnormal{E}_F[\log(Y)])</code> functional. It can be
a vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="meanlog_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y) := \log(x) - \log(y)</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y) \in \mathbb{R}, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of values of the log-transformed identification function.
</p>


<h3>Note</h3>

<p>The log-transformed identification function is a strict
<code class="reqn">\mathbb{F}</code>-identification function for the log-transformed expectation
<code class="reqn">\exp(\textnormal{E}_F[\log(Y)])</code> (Tyralis and Papacharalampous 2025).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[\log(Y)]</code> exists and is finite (Tyralis and
Papacharalampous 2025).
</p>


<h3>References</h3>

<p>Tyralis H, Papacharalampous G (2025) Transformations of predictions and
realizations in consistent scoring functions. <a href="https://doi.org/10.48550/arXiv.2502.16542">doi:10.48550/arXiv.2502.16542</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the log-transformed identification function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$meanlog_if &lt;- meanlog_if(x = df$x, y = df$y)
</code></pre>

<hr>
<h2 id='mre'>
Mean relative error (MRE)
</h2><span id='topic+mre'></span>

<h3>Description</h3>

<p>The function mre computes the mean relative error when <code class="reqn">\textbf{\textit{y}}</code>
materialises and <code class="reqn">\textbf{\textit{x}}</code> is the prediction.
</p>
<p>Mean relative error is a realised score corresponding to the relative error
scoring function <a href="#topic+relerr_sf">relerr_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mre(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mre_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="mre_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean relative error is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y) := |(x - y)/x|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} &gt; \textbf{0}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} &gt; \textbf{0}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{0} = (0, ..., 0)^\mathsf{T}</code>
</p>

<p>is the zero vector of length <code class="reqn">n</code> and the symbol <code class="reqn">&gt;</code> indicates pairwise
inequality.
</p>
<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} &gt; \textbf{0}</code>
</p>



<h3>Value</h3>

<p>Value of the mean relative error.
</p>


<h3>Note</h3>

<p>For details on the relative error scoring function, see <a href="#topic+relerr_sf">relerr_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean relative error is the realised (average) score corresponding to the
relative error scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean relative error.

set.seed(12345)

x &lt;- 0.5

y &lt;- rlnorm(n = 100, mean = 0, sdlog = 1)

print(mre(x = x, y = y))

print(mre(x = rep(x = x, times = 100), y = y))
</code></pre>

<hr>
<h2 id='mse'>
Mean squared error (MSE)
</h2><span id='topic+mse'></span>

<h3>Description</h3>

<p>The function mse computes the mean squared error when <code class="reqn">\textbf{\textit{y}}</code>
materialises and <code class="reqn">\textbf{\textit{x}}</code> is the prediction.
</p>
<p>Mean squared error is a realised score corresponding to the squared error
scoring function <a href="#topic+serr_sf">serr_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mse_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="mse_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean squared error is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y) := (x - y)^2</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>



<h3>Value</h3>

<p>Value of the mean squared error.
</p>


<h3>Note</h3>

<p>For details on the squared error scoring function, see <a href="#topic+serr_sf">serr_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean squared error is the realised (average) score corresponding to the
squared error scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean squared error.

set.seed(12345)

x &lt;- 0

y &lt;- rnorm(n = 100, mean = 0, sd = 1)

print(mse(x = x, y = y))

print(mse(x = rep(x = x, times = 100), y = y))
</code></pre>

<hr>
<h2 id='mspe'>
Mean squared percentage error (MSPE)
</h2><span id='topic+mspe'></span>

<h3>Description</h3>

<p>The function mspe computes the mean squared percentage error when
<code class="reqn">\textbf{\textit{y}}</code> materialises and <code class="reqn">\textbf{\textit{x}}</code> is the
prediction.
</p>
<p>Mean squared percentage error is a realised score corresponding to the squared
percentage error scoring function <a href="#topic+sperr_sf">sperr_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mspe(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mspe_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="mspe_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean squared percentage error is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y) := ((x - y)/y)^{2}</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} &gt; \textbf{0}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} &gt; \textbf{0}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{0} = (0, ..., 0)^\mathsf{T}</code>
</p>

<p>is the zero vector of length <code class="reqn">n</code> and the symbol <code class="reqn">&gt;</code> indicates pairwise
inequality.
</p>
<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} &gt; \textbf{0}</code>
</p>



<h3>Value</h3>

<p>Value of the mean squared percentage error.
</p>


<h3>Note</h3>

<p>For details on the squared percentage error scoring function, see
<a href="#topic+sperr_sf">sperr_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean squared percentage error is the realised (average) score corresponding
to the squared percentage error scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean squared percentage error.

set.seed(12345)

x &lt;- 0.5

y &lt;- rlnorm(n = 100, mean = 0, sdlog = 1)

print(mspe(x = x, y = y))

print(mspe(x = rep(x = x, times = 100), y = y))
</code></pre>

<hr>
<h2 id='msre'>
Mean squared relative error (MSRE)
</h2><span id='topic+msre'></span>

<h3>Description</h3>

<p>The function msre computes the mean squared relative error when
<code class="reqn">\textbf{\textit{y}}</code> materialises and <code class="reqn">\textbf{\textit{x}}</code> is the
prediction.
</p>
<p>Mean squared relative error is a realised score corresponding to the squared
relative error scoring function <a href="#topic+srelerr_sf">srelerr_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>msre(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="msre_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="msre_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean squared relative error is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y) := ((x - y)/x)^{2}</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} &gt; \textbf{0}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} &gt; \textbf{0}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{0} = (0, ..., 0)^\mathsf{T}</code>
</p>

<p>is the zero vector of length <code class="reqn">n</code> and the symbol <code class="reqn">&gt;</code> indicates pairwise
inequality.
</p>
<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} &gt; \textbf{0}</code>
</p>



<h3>Value</h3>

<p>Value of the mean squared relative error.
</p>


<h3>Note</h3>

<p>For details on the squared relative error scoring function, see
<a href="#topic+srelerr_sf">srelerr_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The mean squared relative error is the realised (average) score corresponding to
the squared relative error scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean squared relative error.

set.seed(12345)

x &lt;- 0.5

y &lt;- rlnorm(n = 100, mean = 0, sdlog = 1)

print(msre(x = x, y = y))

print(msre(x = rep(x = x, times = 100), y = y))
</code></pre>

<hr>
<h2 id='mv_if'>
Mean - variance identification function
</h2><span id='topic+mv_if'></span>

<h3>Description</h3>

<p>The function mv_if computes the mean - variance identification function, when
<code class="reqn">y</code> materialises, <code class="reqn">x_1</code> is the predictive mean and <code class="reqn">x_2</code> is the
predictive variance.
</p>
<p>The mean - variance identification function is defined in proposition (3.11) in
Fissler and Ziegel (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mv_if(x1, x2, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mv_if_+3A_x1">x1</code></td>
<td>
<p>Predictive mean (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="mv_if_+3A_x2">x2</code></td>
<td>
<p>Predictive variance (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="mv_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x_1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean - variance identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        V(x_1, x_2, y) := (x_1 - y, x_2 + x_1^2 - y^2)
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x_1 \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_2 &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Matrix of mean - variance values of the identification function.
</p>


<h3>Note</h3>

<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The variance functional is the variance
<code class="reqn">\textnormal{Var}_F[Y] := \textnormal{E}_F[Y^2] - (\textnormal{E}_F[Y])^{2}</code>
of the probability distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011)
</p>
<p>The mean - variance identification function is a strict
<code class="reqn">\mathbb{F}</code>-identification function for the pair (mean, variance)
functional (Gneiting 2011; Fissler and Ziegel 2019; Dimitriadis et al. 2024).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y]</code> and <code class="reqn">\textnormal{E}_F[Y^2]</code> exist and are finite
(Gneiting 2011; Fissler and Ziegel 2019; Dimitriadis et al. 2024).
</p>


<h3>References</h3>

<p>Dimitriadis T, Fissler T, Ziegel JF (2024) Osband's principle for identification
functions. <em>Statistical Papers</em> <b>65</b>:1125&ndash;1132.
<a href="https://doi.org/10.1007/s00362-023-01428-x">doi:10.1007/s00362-023-01428-x</a>.
</p>
<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean - variance identification function.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x1 = c(2, 2, -2, -2, 0, 0),
    x2 = c(1, 2, 1, 2, 1, 2)
)

v &lt;- as.data.frame(mv_if(x1 = df$x1, x2 = df$x2, y = df$y))

print(cbind(df, v))
</code></pre>

<hr>
<h2 id='mv_sf'>
Mean - variance scoring function
</h2><span id='topic+mv_sf'></span>

<h3>Description</h3>

<p>The function mv_sf computes the mean - variance scoring function, when <code class="reqn">y</code>
materialises, <code class="reqn">x_1</code> is the predictive mean and <code class="reqn">x_2</code> is the predictive
variance.
</p>
<p>The mean - variance scoring function is defined by eq. (3.11) in Fissler and
Ziegel (2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mv_sf(x1, x2, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mv_sf_+3A_x1">x1</code></td>
<td>
<p>Predictive mean (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="mv_sf_+3A_x2">x2</code></td>
<td>
<p>Predictive variance (prediction). It can be a vector of length <code class="reqn">n</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="mv_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x_1</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean - variance scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x_1, x_2, y) := x_2^{-2} (x_1^2 - 2 x_2 - 2 x_1 y + y^2)
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x_1 \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">x_2 &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Vector of mean - variance losses.
</p>


<h3>Note</h3>

<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The variance functional is the variance
<code class="reqn">\textnormal{Var}_F[Y] := \textnormal{E}_F[Y^2] - (\textnormal{E}_F[Y])^{2}</code>
of the probability distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011)
</p>
<p>The mean - variance scoring function is negatively oriented (i.e.
the smaller, the better).
</p>
<p>The mean - variance scoring function is strictly consistent for the pair (mean,
variance) functional (Osband 1985, p.9; Gneiting 2011; Fissler and Ziegel 2019).
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Osband KH (1985) Providing Incentives for Better Cost Forecasting. PhD thesis,
University of California, Berkeley. <a href="https://doi.org/10.5281/zenodo.4355667">doi:10.5281/zenodo.4355667</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the mean - variance scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x1 = c(2, 2, -2, -2, 0, 0),
    x2 = c(1, 2, 1, 2, 1, 2)
)

df$mv_penalty &lt;- mv_sf(x1 = df$x1, x2 = df$x2, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='nmoment_if'>
<code class="reqn">n</code>-th moment identification function
</h2><span id='topic+nmoment_if'></span>

<h3>Description</h3>

<p>The function nmoment_if computes the <code class="reqn">n</code>-th moment identification function,
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive <code class="reqn">n</code>-th moment.
</p>
<p>The expectile identification function is defined in Table 9 in Gneiting (2011)
by setting <code class="reqn">r(t) = t^n</code> and <code class="reqn">s(t) = 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmoment_if(x, y, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nmoment_if_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">n</code>-th moment. It can be a vector of length <code class="reqn">m</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="nmoment_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">m</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="nmoment_if_+3A_n">n</code></td>
<td>
<p><code class="reqn">n</code>) is the moment order. It can be a vector of length <code class="reqn">m</code>
(must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">n</code>-th moment identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, n) := x - y^n</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">n \in \mathbb{N}</code>
</p>



<h3>Value</h3>

<p>Vector of values of the <code class="reqn">n</code>-th moment identification function.
</p>


<h3>Note</h3>

<p>The <code class="reqn">n</code>-th moment functional is the expectation <code class="reqn">\textnormal{E}_F[Y^n]</code>
of the probability distribution <code class="reqn">F</code> of <code class="reqn">y</code>.
</p>
<p>The <code class="reqn">n</code>-th moment identification function is a strict
<code class="reqn">\mathbb{F}</code>-identification function for the <code class="reqn">n</code>-th moment functional
(Gneiting 2011; Fissler and Ziegel 2016).
</p>
<p><code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y^n]</code> exists and is finite (Gneiting 2011; Fissler and
Ziegel 2016).
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2016) Higher order elicitability and Osband's principle.
<em>The Annals of Statistics</em> <b>44(4)</b>:1680&ndash;1707.
<a href="https://doi.org/10.1214/16-AOS1439">doi:10.1214/16-AOS1439</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the n-th moment scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 6),
    x = c(1, 2, 3, 1, 2, 3),
    n = c(2, 2, 2, 3, 3, 3)
)

df$nmoment_if &lt;- nmoment_if(x = df$x, y = df$y, n = df$n)

print(df)
</code></pre>

<hr>
<h2 id='nmoment_sf'>
<code class="reqn">n</code>-th moment scoring function
</h2><span id='topic+nmoment_sf'></span>

<h3>Description</h3>

<p>The function nmoment_sf computes the <code class="reqn">n</code>-th moment scoring function, when
<code class="reqn">y</code> materialises, and <code class="reqn">\textnormal{E}_F[Y^n]</code> is the predictive
<code class="reqn">n</code>-th moment.
</p>
<p>The <code class="reqn">n</code>-th moment scoring function is defined by eq. (22) in Gneiting (2011)
by setting <code class="reqn">r(t) = t^n</code>, <code class="reqn">s(t) = 1</code>, <code class="reqn">\phi(t) = t^2</code> and removing
all terms that are not functions of <code class="reqn">x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nmoment_sf(x, y, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nmoment_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">n</code>-th moment. It can be a vector of length <code class="reqn">m</code>
(must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="nmoment_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">m</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="nmoment_sf_+3A_n">n</code></td>
<td>
<p><code class="reqn">n</code>) is the moment order. It can be a vector of length <code class="reqn">m</code>
(must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code class="reqn">n</code>-th moment scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, n) := -x^2 - 2 x (y^n - x)
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">n \in \mathbb{N}</code>
</p>



<h3>Value</h3>

<p>Vector of <code class="reqn">n</code>-th moment losses.
</p>


<h3>Note</h3>

<p>The <code class="reqn">n</code>-th moment functional is the expectation <code class="reqn">\textnormal{E}_F[Y^n]</code>
of the probability distribution <code class="reqn">F</code> of <code class="reqn">y</code>.
</p>
<p>The <code class="reqn">n</code>-th moment scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The <code class="reqn">n</code>-th moment scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent
for the <code class="reqn">n</code>-th moment functional <code class="reqn">\textnormal{E}_F[Y^n]</code>
(Theorem 8 in Gneiting 2011). <code class="reqn">\mathbb{F}</code> is the family of probability
distributions <code class="reqn">F</code> for which <code class="reqn">\textnormal{E}_F[Y^]</code>,
<code class="reqn">\textnormal{E}_F[Y^2]</code>, <code class="reqn">\textnormal{E}_F[Y^n]</code> and
<code class="reqn">\textnormal{E}_F[Y^{n + 1}]</code> exist and are finite (Theorem 8 in Gneiting
2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the n-th moment scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 6),
    x = c(1, 2, 3, 1, 2, 3),
    n = c(2, 2, 2, 3, 3, 3)
)

df$nmoment_penalty &lt;- nmoment_sf(x = df$x, y = df$y, n = df$n)

print(df)
</code></pre>

<hr>
<h2 id='nse'>
Nash-Sutcliffe efficiency (NSE)
</h2><span id='topic+nse'></span>

<h3>Description</h3>

<p>The function nse computes the Nash-Sutcliffe efficiency when
<code class="reqn">\textbf{\textit{y}}</code> materialises and <code class="reqn">\textbf{\textit{x}}</code> is the
prediction.
</p>
<p>Nash-Sutcliffe efficiency is a skill score corresponding to the squared error
scoring function <a href="#topic+serr_sf">serr_sf</a>. It is defined in eq. (3) in Nash and Sutcliffe
(1970).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nse(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nse_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="nse_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Nash-Sutcliffe efficiency is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S_{\textnormal{skill}}(\textbf{\textit{x}}, \textbf{\textit{y}}) :=
    1 - S_{\textnormal{meth}}(\textbf{\textit{x}}, \textbf{\textit{y}}) /
    S_{\textnormal{ref}}(\textbf{\textit{x}}, \textbf{\textit{y}})</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{1} = (1, ..., 1)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\overline{\textbf{\textit{y}}} :=
    (1/n) \textbf{1}^\mathsf{T} \textbf{\textit{y}} =
    (1/n) \sum_{i = 1}^{n} y_i</code>
</p>

<p style="text-align: center;"><code class="reqn">L(x, y) := (x - y)^2</code>
</p>

<p>and the predictions of the method of interest as well as the reference
method are evaluated respectively by:
</p>
<p style="text-align: center;"><code class="reqn">S_{\textnormal{meth}}(\textbf{\textit{x}}, \textbf{\textit{y}}) :=
    (1/n) \sum_{i = 1}^{n} L(x_i, y_i)</code>
</p>

<p style="text-align: center;"><code class="reqn">S_{\textnormal{ref}}(\textbf{\textit{x}}, \textbf{\textit{y}}) :=
    (1/n) \sum_{i = 1}^{n} L(\overline{\textbf{\textit{y}}}, y_i)</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}) \leq 1,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>



<h3>Value</h3>

<p>Value of the Nash-Sutcliffe efficiency.
</p>


<h3>Note</h3>

<p>For details on the squared error scoring function, see <a href="#topic+serr_sf">serr_sf</a>.
</p>
<p>The concept of skill scores is defined by Gneiting (2011).
</p>
<p>The Nash-Sutcclife efficiency is defined in eq. (3) in Nash and Sutcliffe
(1970).
</p>
<p>The Nash-Sutcclife efficiency is positevely oriented (i.e. the larger, the
better).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Nash JE, Sutcliffe JV (1970) River flow forecasting through conceptual models
part I - A discussion of principles. <em>Journal of Hydrology</em>
<b>10(3)</b>:282&ndash;290. <a href="https://doi.org/10.1016/0022-1694%2870%2990255-6">doi:10.1016/0022-1694(70)90255-6</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the Nash-Sutcliffe efficiency.

set.seed(12345)

x &lt;- 0

y &lt;- rnorm(n = 100, mean = 0, sd = 1)

print(nse(x = x, y = y))

print(nse(x = rep(x = x, times = 100), y = y))

print(nse(x = mean(y), y = y))

print(nse(x = y, y = y))
</code></pre>

<hr>
<h2 id='obsweighted_sf'>
Observation-weighted scoring function
</h2><span id='topic+obsweighted_sf'></span>

<h3>Description</h3>

<p>The function obsweighted_sf computes the observation-weighted scoring function
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">\dfrac{\textnormal{E}_F [Y^{2}]}{\textnormal{E}_F [Y]}</code> functional.
</p>
<p>The observation-weighted scoring function is defined in p. 752 in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obsweighted_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="obsweighted_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\dfrac{\textnormal{E}_F [Y^{2}]}{\textnormal{E}_F [Y]}</code>
functional (prediction). It can be a vector of length <code class="reqn">n</code> (must have the
same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="obsweighted_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observation-weighted scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := y (x - y)^{2}</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of observation-weighted errors.
</p>


<h3>Note</h3>

<p>For details on the observation-weighted scoring function, see Gneiting (2011).
</p>
<p>The observation-weighted scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The observation-weighted scoring function is strictly consistent for the
<code class="reqn">\dfrac{\textnormal{E}_F [Y^{2}]}{\textnormal{E}_F [Y]}</code> functional.
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the observation-weighted scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$squared_relative_error &lt;- obsweighted_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='quantile_if'>
Quantile identification function
</h2><span id='topic+quantile_if'></span>

<h3>Description</h3>

<p>The function quantile_if computes the quantile identification function at a
specific level <code class="reqn">p</code>, when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
quantile at level <code class="reqn">p</code>.
</p>
<p>The quantile identification function is defined in Table 9 in Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_if(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_if_+3A_x">x</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="quantile_if_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="quantile_if_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The quantile identification function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, p) := \textbf{1} \lbrace x \geq y \rbrace - p</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">V(x, y, p) \in (-1, 1)</code>
</p>



<h3>Value</h3>

<p>Vector of values of the quantile identification function.
</p>


<h3>Note</h3>

<p>For the definition of quantiles, see Koenker and Bassett Jr (1978).
</p>
<p>The quantile identification function is a strict
<code class="reqn">\mathbb{F}_p</code>-identification function for the <code class="reqn">p</code>-quantile functional
(Gneiting 2011; Fissler and Ziegel 2016; Dimitriadis et al. 2024).
</p>
<p><code class="reqn">\mathbb{F}_p</code> is the family of probability distributions <code class="reqn">F</code> for which
there exists an <code class="reqn">y</code> with <code class="reqn">F(y) = p</code> (Gneiting 2011; Fissler and Ziegel
2016; Dimitriadis et al. 2024).
</p>


<h3>References</h3>

<p>Dimitriadis T, Fissler T, Ziegel JF (2024) Osband's principle for identification
functions. <em>Statistical Papers</em> <b>65</b>:1125&ndash;1132.
<a href="https://doi.org/10.1007/s00362-023-01428-x">doi:10.1007/s00362-023-01428-x</a>.
</p>
<p>Fissler T, Ziegel JF (2016) Higher order elicitability and Osband's principle.
<em>The Annals of Statistics</em> <b>44(4)</b>:1680&ndash;1707.
<a href="https://doi.org/10.1214/16-AOS1439">doi:10.1214/16-AOS1439</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Koenker R, Bassett Jr G (1978) Regression quantiles. <em>Econometrica</em>
<b>46(1)</b>:33&ndash;50. <a href="https://doi.org/10.2307/1913643">doi:10.2307/1913643</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the quantile identification function.

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x = c(2, 2, -2, -2, 0, 0),
    p = rep(x = c(0.05, 0.95), times = 3)
)

df$quantile_if &lt;- quantile_if(x = df$x, y = df$y, p = df$p)
</code></pre>

<hr>
<h2 id='quantile_level'>
Sample quantile level function
</h2><span id='topic+quantile_level'></span>

<h3>Description</h3>

<p>The function quantile_level computes the sample quantile level, when
<code class="reqn">\textbf{\textit{y}}</code> materialises and <code class="reqn">\textbf{\textit{x}}</code> is the
predictive quantile at level <code class="reqn">p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_level(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_level_+3A_x">x</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="quantile_level_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sample quantile level function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">P(x, y) := (1/n) \sum_{i = 1}^{n} V(x_i, y_i)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">V(x, y) := \textbf{1} \lbrace x \geq y \rbrace</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>



<h3>Value</h3>

<p>Value of the sample quantile level.
</p>


<h3>Note</h3>

<p>The sample quantile level is directly related to the quantile identification
function <a href="#topic+quantile_if">quantile_if</a>.
</p>
<p>If <code class="reqn">\textbf{\textit{y}}</code> materialises and <code class="reqn">\textbf{\textit{x}}</code> is the
predictive quantile at level <code class="reqn">p</code>, then ideally, the sample quantile level
should be equal to the nominal quantile level <code class="reqn">p</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the sample quantile level.

set.seed(12345)

x &lt;- qnorm(p = 0.75, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)

y &lt;- rnorm(n = 1000, mean = 0, sd = 1)

print(quantile_level(x = x, y = y))
</code></pre>

<hr>
<h2 id='quantile_rs'>
Realised quantile score
</h2><span id='topic+quantile_rs'></span>

<h3>Description</h3>

<p>The function quantile_rs computes the realised quantile score at a specific
level <code class="reqn">p</code> when <code class="reqn">\textbf{\textit{y}}</code> materialises and
<code class="reqn">\textbf{\textit{x}}</code> is the prediction.
</p>
<p>Realised quantile score is a realised score corresponding to the quantile
scoring function <a href="#topic+quantile_sf">quantile_sf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_rs(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_rs_+3A_x">x</code></td>
<td>
<p>Prediction. It can be a vector of length <code class="reqn">n</code> (must have the same
length as <code class="reqn">\textbf{\textit{y}}</code>).</p>
</td></tr>
<tr><td><code id="quantile_rs_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">\textbf{\textit{x}}</code>).</p>
</td></tr>
<tr><td><code id="quantile_rs_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">\textbf{\textit{y}}</code>) or a scalar value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The realized quantile score is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}, p) := (1/n)
    \sum_{i = 1}^{n} L(x_i, y_i, p)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} = (x_1, ..., x_n)^\mathsf{T}</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} = (y_1, ..., y_n)^\mathsf{T}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">L(x, y, p) := (\textbf{1} \lbrace x \geq y \rbrace - p) (x - y)</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">\textbf{\textit{x}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">\textbf{\textit{y}} \in \mathbb{R}^n</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(\textbf{\textit{x}}, \textbf{\textit{y}}, p) \geq 0,
    \forall \textbf{\textit{x}}, \textbf{\textit{y}} \in \mathbb{R}^n,
    p \in (0, 1)</code>
</p>



<h3>Value</h3>

<p>Value of the realised quantile score.
</p>


<h3>Note</h3>

<p>For details on the quantile scoring function, see <a href="#topic+quantile_sf">quantile_sf</a>.
</p>
<p>The concept of realised (average) scores is defined by Gneiting (2011) and
Fissler and Ziegel (2019).
</p>
<p>The realised quantile score is the realised (average) score corresponding to
the quantile scoring function.
</p>


<h3>References</h3>

<p>Fissler T, Ziegel JF (2019) Order-sensitivity and equivariance of scoring
functions. <em>Electronic Journal of Statistics</em> <b>13(1)</b>:1166&ndash;1211.
<a href="https://doi.org/10.1214/19-EJS1552">doi:10.1214/19-EJS1552</a>.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the realised quantile score.

set.seed(12345)

x &lt;- qnorm(p = 0.7, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE)

y &lt;- rnorm(n = 1000, mean = 0, sd = 1)

print(quantile_rs(x = x, y = y, p = 0.7))

print(quantile_rs(x = rep(x = x, times = 1000), y = y, p = 0.7))

print(quantile_rs(x = rep(x = x, times = 1000) - 0.1, y = y, p = 0.7))
</code></pre>

<hr>
<h2 id='quantile_sf'>
Asymmetric piecewise linear scoring function (quantile scoring function,
quantile loss function)
</h2><span id='topic+quantile_sf'></span>

<h3>Description</h3>

<p>The function quantile_sf computes the asymmetric piecewise linear scoring
function (quantile scoring function) at a specific level <code class="reqn">p</code>, when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive quantile at level <code class="reqn">p</code>.
</p>
<p>The asymmetric piecewise linear scoring function is defined by eq. (24) in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quantile_sf(x, y, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quantile_sf_+3A_x">x</code></td>
<td>
<p>Predictive quantile (prediction) at level <code class="reqn">p</code>. It can be a vector
of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="quantile_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="quantile_sf_+3A_p">p</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The assymetric piecewise linear scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p) := (\textbf{1} \lbrace x \geq y \rbrace - p) (x - y)</code>
</p>

<p>or equivalently,
</p>
<p style="text-align: center;"><code class="reqn">
        S(x, y, p) := p | \max \lbrace -(x - y), 0 \rbrace | +
        (1 - p) | \max \lbrace x - y, 0 \rbrace |
    </code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">0 &lt; p &lt; 1</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y, p) \geq 0, \forall x, y \in \mathbb{R}, p \in (0, 1)</code>
</p>



<h3>Value</h3>

<p>Vector of quantile losses.
</p>


<h3>Note</h3>

<p>For the definition of quantiles, see Koenker and Bassett Jr (1978).
</p>
<p>The asymmetric piecewise linear scoring function is negatively oriented (i.e.
the smaller, the better).
</p>
<p>The asymmetric piecewise linear scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the <code class="reqn">p</code>-quantile functional.
<code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[Y]</code> exists and is finite (Schlaifer 1961, p.196; Ferguson
1967, p.51; Thomson 1979; Saerens 2000; Gneiting 2011).
</p>


<h3>References</h3>

<p>Ferguson TS (1967) Mathematical Statistics: A Decision-Theoretic Approach.
Academic Press, New York.
</p>
<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Koenker R, Bassett Jr G (1978) Regression quantiles. <em>Econometrica</em>
<b>46(1)</b>:33&ndash;50. <a href="https://doi.org/10.2307/1913643">doi:10.2307/1913643</a>.
</p>
<p>Raiffa H,Schlaifer R (1961) Applied Statistical Decision Theory. Colonial Press,
Clinton.
</p>
<p>Saerens M (2000) Building cost functions minimizing to some summary statistics.
<em>IEEE Transactions on Neural Networks</em> <b>11(6)</b>:1263&ndash;1271.
<a href="https://doi.org/10.1109/72.883416">doi:10.1109/72.883416</a>.
</p>
<p>Thomson W (1979) Eliciting production possibilities from a well-informed
manager. <em>Journal of Economic Theory</em> <b>20(3)</b>:360&ndash;380.
<a href="https://doi.org/10.1016/0022-0531%2879%2990042-5">doi:10.1016/0022-0531(79)90042-5</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the asymmetric piecewise linear scoring function (quantile scoring
# function).

df &lt;- data.frame(
    y = rep(x = 0, times = 6),
    x = c(2, 2, -2, -2, 0, 0),
    p = rep(x = c(0.05, 0.95), times = 3)
)

df$quantile_penalty &lt;- quantile_sf(x = df$x, y = df$y, p = df$p)

print(df)

# The absolute error scoring function is twice the asymmetric piecewise linear
# scoring function (quantile scoring function) at level p = 0.5.

df &lt;- data.frame(
    y = rep(x = 0, times = 3),
    x = c(-2, 0, 2),
    p = rep(x = c(0.5), times = 3)
)

df$quantile_penalty &lt;- quantile_sf(x = df$x, y = df$y, p = df$p)

df$absolute_error &lt;- aerr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='relerr_sf'>
Relative error scoring function (MAE-PROP scoring function)
</h2><span id='topic+relerr_sf'></span>

<h3>Description</h3>

<p>The function relerr_sf computes the relative error scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive <code class="reqn">\textnormal{med}^{(1)}(F)</code>
functional.
</p>
<p>The relative error scoring function is defined in Table 1 in Gneiting (2011).
</p>
<p>The relative error scoring function is referred to as MAE-PROP scoring function
in eq. (13) in Patton (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relerr_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="relerr_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\textnormal{med}^{(1)}(F)</code> functional (prediction). It
can be a vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="relerr_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The relative error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := |(x - y)/x|</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of relative errors.
</p>


<h3>Note</h3>

<p>For details on the relative error scoring function, see Gneiting (2011).
</p>
<p>The <code class="reqn">\beta</code>-median functional, <code class="reqn">\textnormal{med}^{(\beta)}(F)</code> is the
median of a probability distribution whose density is proportional to
<code class="reqn">y^\beta f(y)</code>, where <code class="reqn">f</code> is the density of the probability distribution
<code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The relative error scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The relative error scoring function is strictly <code class="reqn">\mathbb{F}^{(w)}</code>-consistent for the
<code class="reqn">\textnormal{med}^{(1)}(F)</code> functional. <code class="reqn">\mathbb{F}</code> is the family of
probability distributions for which <code class="reqn">\textnormal{E}_F[Y]</code> exists and is
finite. <code class="reqn">\mathbb{F}^{(w)}</code> is the subclass of probability distributions in
<code class="reqn">\mathbb{F}</code>, which are such that <code class="reqn">w(y) f(y)</code>, <code class="reqn">w(y) = y</code> has finite
integral over <code class="reqn">(0, \infty)</code>, and the probability distribution <code class="reqn">F^{(w)}</code>
with density proportional to <code class="reqn">w(y) f(y)</code> belongs to <code class="reqn">\mathbb{F}</code> (see
Theorems 5 and 9 in Gneiting 2011)
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Patton AJ (2011) Volatility forecast comparison using imperfect volatility
proxies. <em>Journal of Econometrics</em> <b>160(1)</b>:246&ndash;256.
<a href="https://doi.org/10.1016/j.jeconom.2010.03.034">doi:10.1016/j.jeconom.2010.03.034</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the relative error scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$relative_error &lt;- relerr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='serr_sf'>
Squared error scoring function
</h2><span id='topic+serr_sf'></span>

<h3>Description</h3>

<p>The function serr_sf computes the squared error scoring function when <code class="reqn">y</code>
materialises and <code class="reqn">x</code> is the predictive mean functional.
</p>
<p>The squared error scoring function is defined in Table 1 in Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>serr_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="serr_sf_+3A_x">x</code></td>
<td>
<p>Predictive mean functional (prediction). It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="serr_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := (x - y)^2</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y \in \mathbb{R}</code>
</p>



<h3>Value</h3>

<p>Vector of squared errors.
</p>


<h3>Note</h3>

<p>For details on the squared error scoring function, see Savage (1971), Gneiting
(2011).
</p>
<p>The mean functional is the mean <code class="reqn">\textnormal{E}_F[Y]</code> of the probability
distribution <code class="reqn">F</code> of <code class="reqn">y</code> (Gneiting 2011).
</p>
<p>The squared error scoring function is negatively oriented (i.e. the smaller, the
better).
</p>
<p>The squared error scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent for
the mean functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions
<code class="reqn">F</code> for which the second moment exists and is finite (Savage 1971;
Gneiting 2011).
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Savage LJ  (1971) Elicitation of personal probabilities and expectations.
<em>Journal of the American Statistical Association</em> <b>66(337)</b>:783&ndash;810.
<a href="https://doi.org/10.1080/01621459.1971.10482346">doi:10.1080/01621459.1971.10482346</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squarer error scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 5),
    x = -2:2
)

df$squared_error &lt;- serr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='serrexp_sf'>
Squared error exp scoring function
</h2><span id='topic+serrexp_sf'></span>

<h3>Description</h3>

<p>The function serrexp_sf computes the squared error exp scoring function when
<code class="reqn">y</code> materialises and <code class="reqn">x</code> is the <code class="reqn">(1/a) \log(\textnormal{E}_F[\exp(aY)])</code>
predictive entropic risk measure (Gerber 1974).
</p>
<p>The squared error exp scoring function is defined in Fissler and Pesenti (2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>serrexp_sf(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="serrexp_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">(1/a) \log(\textnormal{E}_F[\exp(aY)])</code> functional
(prediction). It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="serrexp_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="serrexp_sf_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared error exp scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := (\exp(ax) - \exp(ay))^2</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">y \in \mathbb{R}</code>
</p>

<p style="text-align: center;"><code class="reqn">a \neq 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y \in \mathbb{R}, a \neq 0</code>
</p>



<h3>Value</h3>

<p>Vector of squared errors of exp-transformed variables.
</p>


<h3>Note</h3>

<p>For details on the squared error exp scoring function, see Fissler and Pesenti
(2023).
</p>
<p>The squared error exp scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The squared error exp scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent
for the <code class="reqn">(1/a) \log(\textnormal{E}_F[\exp(aY)])</code> entropic risk measure
functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code>
for which <code class="reqn">\textnormal{E}_F[\exp(aY)]</code> exists and is finite (Fissler and
Pesenti 2023; Tyralis and Papacharalampous 2025).
</p>


<h3>References</h3>

<p>Fissler T, Pesenti SM (2023) Sensitivity measures based on scoring functions.
<em>European Journal of Operational Research</em> <b>307(3)</b>:1408&ndash;1423.
<a href="https://doi.org/10.1016/j.ejor.2022.10.002">doi:10.1016/j.ejor.2022.10.002</a>.
</p>
<p>Gerber HU (1974) On additive premium calculation principles.
<em>ASTIN Bulletin: The Journal of the IAA</em> <b>7(3)</b>:215&ndash;222.
<a href="https://doi.org/10.1017/S0515036100006061">doi:10.1017/S0515036100006061</a>.
</p>
<p>Tyralis H, Papacharalampous G (2025) Transformations of predictions and
realizations in consistent scoring functions. <a href="https://doi.org/10.48550/arXiv.2502.16542">doi:10.48550/arXiv.2502.16542</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squarer error exp scoring function.

df &lt;- data.frame(
    y = rep(x = 0, times = 5),
    x = -2:2,
    a = c(-2, -1, 1, 2, 3)
)

df$squaredexp_error &lt;- serrexp_sf(x = df$x, y = df$y, a = df$a)

print(df)
</code></pre>

<hr>
<h2 id='serrlog_sf'>
Squared error log scoring function
</h2><span id='topic+serrlog_sf'></span>

<h3>Description</h3>

<p>The function serrlog_sf computes the squared error log scoring function when
<code class="reqn">y</code> materialises and <code class="reqn">x</code> is the <code class="reqn">\exp(\textnormal{E}_F[\log(Y)])</code>
predictive functional.
</p>
<p>The squared error log scoring function is defined in Houghton-Carr (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>serrlog_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="serrlog_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\exp(\textnormal{E}_F[\log(Y)])</code> functional
(prediction). It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="serrlog_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := (\log(x) - \log(y))^2</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of squared errors of log-transformed variables.
</p>


<h3>Note</h3>

<p>For details on the squared error log scoring function, see Houghton-Carr (1999).
</p>
<p>The squared error log scoring function is negatively oriented (i.e. the smaller,
the better).
</p>
<p>The squared error log scoring function is strictly <code class="reqn">\mathbb{F}</code>-consistent
for the <code class="reqn">\exp(\textnormal{E}_F[\log(Y)])</code> functional. <code class="reqn">\mathbb{F}</code> is
the family of probability distributions <code class="reqn">F</code> for which
<code class="reqn">\textnormal{E}_F[\log(Y)]</code> exists and is finite (Tyralis and
Papacharalampous 2025).
</p>


<h3>References</h3>

<p>Houghton-Carr HA (1999) Assessment criteria for simple conceptual daily
rainfall-runoff models. <em>Hydrological Sciences Journal</em>
<b>44(2)</b>:237&ndash;261. <a href="https://doi.org/10.1080/02626669909492220">doi:10.1080/02626669909492220</a>.
</p>
<p>Tyralis H, Papacharalampous G (2025) Transformations of predictions and
realizations in consistent scoring functions. <a href="https://doi.org/10.48550/arXiv.2502.16542">doi:10.48550/arXiv.2502.16542</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squarer error log scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$squaredlog_error &lt;- serrlog_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='serrpower_sf'>
Squared error of power transformations scoring function
</h2><span id='topic+serrpower_sf'></span>

<h3>Description</h3>

<p>The function serrpower_sf computes the squared error of power transformations
scoring function when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the
<code class="reqn">(\textnormal{E}_F[Y^a])^{(1/a)}</code> predictive functional.
</p>
<p>The squared error of power transformations scoring function is defined in
Tyralis and Papacharalampous (2025).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>serrpower_sf(x, y, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="serrpower_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">(\textnormal{E}_F[Y^a])^{(1/a)}</code> functional
(prediction). It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="serrpower_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
<tr><td><code id="serrpower_sf_+3A_a">a</code></td>
<td>
<p>It can be a vector of length <code class="reqn">n</code> (must have the same length as
<code class="reqn">y</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared error of power transformations scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := (x^a - y^a)^2</code>
</p>

<p>Domain of function:
</p>
<p>Case #1
</p>
<p style="text-align: center;"><code class="reqn">a &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">x \geq 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y \geq 0</code>
</p>

<p>Case #2
</p>
<p style="text-align: center;"><code class="reqn">a \neq 0</code>
</p>

<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y, a </code>
</p>



<h3>Value</h3>

<p>Vector of squared errors of power-transformed variables.
</p>


<h3>Note</h3>

<p>For details on the squared error of power tranformations scoring function, see
Tyralis and Papacharalampous (2025).
</p>
<p>The squared error of power tranformations scoring function is negatively
oriented (i.e. the smaller, the better).
</p>
<p>The squared error of power transformations scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the <code class="reqn">(\textnormal{E}_F[Y^a])^{(1/a)}</code>
functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code>
for which <code class="reqn">\textnormal{E}_F[Y^a]</code> exists and is finite (Tyralis and
Papacharalampous 2025).
</p>


<h3>References</h3>

<p>Tyralis H, Papacharalampous G (2025) Transformations of predictions and
realizations in consistent scoring functions. <a href="https://doi.org/10.48550/arXiv.2502.16542">doi:10.48550/arXiv.2502.16542</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squarer error of power tranformations scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3,
    a = 1:3
)

df$squaredpower_error &lt;- serrpower_sf(x = df$x, y = df$y, a = df$a)

print(df)
</code></pre>

<hr>
<h2 id='serrsq_sf'>
Squared error of squares scoring function
</h2><span id='topic+serrsq_sf'></span>

<h3>Description</h3>

<p>The function serrsq_sf computes the squared error of squares scoring function
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the <code class="reqn">\sqrt{\textnormal{E}_F[Y^2]}</code>
predictive functional.
</p>
<p>The squared error of squares scoring function is defined in Thirel et al.
(2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>serrsq_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="serrsq_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\sqrt{\textnormal{E}_F[Y^2]}</code> functional (prediction).
It can be a vector of length <code class="reqn">n</code> (must have the same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="serrsq_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared error of squares scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := (x^2 - y^2)^2</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x \geq 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y \geq 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y \geq 0</code>
</p>



<h3>Value</h3>

<p>Vector of squared errors of squared-transformed variables.
</p>


<h3>Note</h3>

<p>For details on the squared error of squares scoring function, see Thirel et al.
(2024).
</p>
<p>The squared error of squares scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The squared error of squares scoring function is strictly
<code class="reqn">\mathbb{F}</code>-consistent for the <code class="reqn">\sqrt{\textnormal{E}_F[Y^2]}</code>
functional. <code class="reqn">\mathbb{F}</code> is the family of probability distributions <code class="reqn">F</code>
for which <code class="reqn">\textnormal{E}_F[Y^2]</code> exists and is finite (Tyralis and
Papacharalampous 2025).
</p>


<h3>References</h3>

<p>Thirel G, Santos L, Delaigue O, Perrin C (2024) On the use of streamflow
transformations for hydrological model calibration.
<em>Hydrology and Earth System Sciences</em> <b>28(21)</b>:4837&ndash;4860.
<a href="https://doi.org/10.5194/hess-28-4837-2024">doi:10.5194/hess-28-4837-2024</a>.
</p>
<p>Tyralis H, Papacharalampous G (2025) Transformations of predictions and
realizations in consistent scoring functions. <a href="https://doi.org/10.48550/arXiv.2502.16542">doi:10.48550/arXiv.2502.16542</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squarer error of squares scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$squaredsq_error &lt;- serrsq_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='sperr_sf'>
Squared percentage error scoring function
</h2><span id='topic+sperr_sf'></span>

<h3>Description</h3>

<p>The function sperr_sf computes the squared percentage error scoring function
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">\dfrac{\textnormal{E}_F [Y^{-1}]}{\textnormal{E}_F [Y^{-2}]}</code> functional.
</p>
<p>The squared percentage error scoring function is defined in p. 752 in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sperr_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sperr_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\dfrac{\textnormal{E}_F [Y^{-1}]}{\textnormal{E}_F [Y^{-2}]}</code>
functional (prediction). It can be a vector of length <code class="reqn">n</code> (must have the
same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="sperr_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared percentage error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := ((x - y)/y)^{2}</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of squared percentage errors.
</p>


<h3>Note</h3>

<p>For details on the squared percentage error scoring function, see
Park and Stefanski (1998) and Gneiting (2011).
</p>
<p>The squared percentage error scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The squared percentage error scoring function is strictly consistent for the
<code class="reqn">\dfrac{\textnormal{E}_F [Y^{-1}]}{\textnormal{E}_F [Y^{-2}]}</code> functional.
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>
<p>Park H, Stefanski LA (1998) Relative-error prediction.
<em>Statistics and Probability Letters</em> <b>40(3)</b>:227&ndash;236.
<a href="https://doi.org/10.1016/S0167-7152%2898%2900088-1">doi:10.1016/S0167-7152(98)00088-1</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squared percentage error scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$squared_percentage_error &lt;- sperr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

<hr>
<h2 id='srelerr_sf'>
Squared relative error scoring function
</h2><span id='topic+srelerr_sf'></span>

<h3>Description</h3>

<p>The function srelerr_sf computes the squared relative error scoring function
when <code class="reqn">y</code> materialises and <code class="reqn">x</code> is the predictive
<code class="reqn">\dfrac{\textnormal{E}_F [Y^{2}]}{\textnormal{E}_F [Y]}</code> functional.
</p>
<p>The squared relative error scoring function is defined in p. 752 in
Gneiting (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>srelerr_sf(x, y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="srelerr_sf_+3A_x">x</code></td>
<td>
<p>Predictive <code class="reqn">\dfrac{\textnormal{E}_F [Y^{2}]}{\textnormal{E}_F [Y]}</code>
functional (prediction). It can be a vector of length <code class="reqn">n</code> (must have the
same length as <code class="reqn">y</code>).</p>
</td></tr>
<tr><td><code id="srelerr_sf_+3A_y">y</code></td>
<td>
<p>Realisation (true value) of process. It can be a vector of length
<code class="reqn">n</code> (must have the same length as <code class="reqn">x</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The squared relative error scoring function is defined by:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) := ((x - y)/x)^{2}</code>
</p>

<p>Domain of function:
</p>
<p style="text-align: center;"><code class="reqn">x &gt; 0</code>
</p>

<p style="text-align: center;"><code class="reqn">y &gt; 0</code>
</p>

<p>Range of function:
</p>
<p style="text-align: center;"><code class="reqn">S(x, y) \geq 0, \forall x, y &gt; 0</code>
</p>



<h3>Value</h3>

<p>Vector of squared relative errors.
</p>


<h3>Note</h3>

<p>For details on the squared relative error scoring function, see Gneiting (2011).
</p>
<p>The squared relative error scoring function is negatively oriented (i.e. the
smaller, the better).
</p>
<p>The squared relative error scoring function is strictly consistent for the
<code class="reqn">\dfrac{\textnormal{E}_F [Y^{2}]}{\textnormal{E}_F [Y]}</code> functional.
</p>


<h3>References</h3>

<p>Gneiting T (2011) Making and evaluating point forecasts.
<em>Journal of the American Statistical Association</em> <b>106(494)</b>:746&ndash;762.
<a href="https://doi.org/10.1198/jasa.2011.r10138">doi:10.1198/jasa.2011.r10138</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the squared percentage error scoring function.

df &lt;- data.frame(
    y = rep(x = 2, times = 3),
    x = 1:3
)

df$squared_relative_error &lt;- srelerr_sf(x = df$x, y = df$y)

print(df)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
