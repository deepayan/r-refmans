<!DOCTYPE html><html lang="en"><head><title>Help for package RWeka</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {RWeka}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dot'><p>Create DOT Representations</p></a></li>
<li><a href='#evaluate_Weka_classifier'><p>Model Statistics for R/Weka Classifiers</p></a></li>
<li><a href='#predict_Weka_classifier'><p>Model Predictions for R/Weka Classifiers</p></a></li>
<li><a href='#predict_Weka_clusterer'><p>Class Predictions for R/Weka Clusterers</p></a></li>
<li><a href='#read.arff'><p>Read Data from ARFF Files</p></a></li>
<li><a href='#Weka_associators'><p>R/Weka Associators</p></a></li>
<li><a href='#Weka_attribute_evaluators'><p>R/Weka Attribute Evaluators</p></a></li>
<li><a href='#Weka_classifier_functions'><p>R/Weka Classifier Functions</p></a></li>
<li><a href='#Weka_classifier_lazy'><p>R/Weka Lazy Learners</p></a></li>
<li><a href='#Weka_classifier_meta'><p>R/Weka Meta Learners</p></a></li>
<li><a href='#Weka_classifier_rules'><p>R/Weka Rule Learners</p></a></li>
<li><a href='#Weka_classifier_trees'><p>R/Weka Classifier Trees</p></a></li>
<li><a href='#Weka_classifiers'><p>R/Weka Classifiers</p></a></li>
<li><a href='#Weka_clusterers'><p>R/Weka Clusterers</p></a></li>
<li><a href='#Weka_control'><p>Control Weka Options</p></a></li>
<li><a href='#Weka_converters'><p>R/Weka File Loaders and Savers</p></a></li>
<li><a href='#Weka_filters'><p>R/Weka Filters</p></a></li>
<li><a href='#Weka_interfaces'><p>R/Weka interfaces</p></a></li>
<li><a href='#Weka_stemmers'><p>R/Weka Stemmers</p></a></li>
<li><a href='#Weka_tokenizers'><p>R/Weka Tokenizers</p></a></li>
<li><a href='#WOW'><p>Weka Option Wizard</p></a></li>
<li><a href='#WPM'><p>Weka Package Manager</p></a></li>
<li><a href='#write.arff'><p>Write Data into ARFF Files</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.4-46</td>
</tr>
<tr>
<td>Title:</td>
<td>R/Weka Interface</td>
</tr>
<tr>
<td>Description:</td>
<td>An R interface to Weka (Version 3.9.3).
   Weka is a collection of machine learning algorithms for data mining
   tasks written in Java, containing tools for data pre-processing,
   classification, regression, clustering, association rules, and
   visualization.  Package 'RWeka' contains the interface code, the
   Weka jar is in a separate package 'RWekajars'.  For more information
   on Weka see <a href="https://www.cs.waikato.ac.nz/ml/weka/">https://www.cs.waikato.ac.nz/ml/weka/</a>.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RWekajars (&ge; 3.9.3-1), rJava (&ge; 0.6-3), graphics, stats,
utils, grid</td>
</tr>
<tr>
<td>Suggests:</td>
<td>partykit (&ge; 0.8.0), mlbench, e1071</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Java (&gt;= 8)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-07 13:43:56 UTC; hornik</td>
</tr>
<tr>
<td>Author:</td>
<td>Kurt Hornik <a href="https://orcid.org/0000-0003-4198-9911"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Christian Buchta [ctb],
  Torsten Hothorn [ctb],
  Alexandros Karatzoglou [ctb],
  David Meyer [ctb],
  Achim Zeileis <a href="https://orcid.org/0000-0003-0918-3766"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kurt Hornik &lt;Kurt.Hornik@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-07 14:18:59 UTC</td>
</tr>
</table>
<hr>
<h2 id='dot'>Create DOT Representations</h2><span id='topic+write_to_dot'></span><span id='topic+write_to_dot.Weka_classifier'></span>

<h3>Description</h3>

<p>Write a DOT language representation of an object for processing via
Graphviz.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_to_dot(x, con = stdout(), ...)
## S3 method for class 'Weka_classifier'
write_to_dot(x, con = stdout(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dot_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object.</p>
</td></tr>
<tr><td><code id="dot_+3A_con">con</code></td>
<td>
<p>a <a href="base.html#topic+connection">connection</a> for writing the representation to.</p>
</td></tr>
<tr><td><code id="dot_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed from or to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Graphviz (<a href="https://www.graphviz.org">https://www.graphviz.org</a>) is open source graph
visualization software providing several main graph layout programs,
of which <code>dot</code> makes &ldquo;hierarchical&rdquo; or layered drawings of
directed graphs, and hence is typically most suitable for visualizing
classification trees.
</p>
<p>Using <code>dot</code>, the representation in file &lsquo;<span class="file">foo.dot</span>&rsquo; can be
transformed to PostScript or other displayable graphical formats using
(a variant of) <code>dot -Tps foo.dot &gt;foo.ps</code>.
</p>
<p>Some Weka classifiers (e.g., tree learners such as J48 and M5P)
implement a &ldquo;Drawable&rdquo; interface providing DOT representations
of the fitted models.  For such classifiers, the <code>write_to_dot</code>
method writes the representation to the specified connection. 
</p>

<hr>
<h2 id='evaluate_Weka_classifier'>Model Statistics for R/Weka Classifiers</h2><span id='topic+evaluate_Weka_classifier'></span>

<h3>Description</h3>

<p>Compute model performance statistics for a fitted Weka classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluate_Weka_classifier(object, newdata = NULL, cost = NULL, 
                         numFolds = 0, complexity = FALSE,
                         class = FALSE, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evaluate_Weka_classifier_+3A_object">object</code></td>
<td>
<p>a <code>Weka_classifier</code> object.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables
with which to evaluate.  If omitted or <code>NULL</code>, the training
instances are used.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_cost">cost</code></td>
<td>
<p>a square matrix of (mis)classification costs.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_numfolds">numFolds</code></td>
<td>
<p>the number of folds to use in cross-validation.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_complexity">complexity</code></td>
<td>
<p>option to include entropy-based statistics.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_class">class</code></td>
<td>
<p>option to include class statistics.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_seed">seed</code></td>
<td>
<p>optional seed for cross-validation.</p>
</td></tr>
<tr><td><code id="evaluate_Weka_classifier_+3A_...">...</code></td>
<td>
<p>further arguments passed to other methods (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes and extracts a non-redundant set of performance 
statistics that is suitable for model interpretation. By default the 
statistics are computed on the training data.
</p>
<p>Currently argument <code>...</code> only supports the logical variable
<code>normalize</code> which tells Weka to normalize the cost matrix so that
the cost of a correct classification is zero.
</p>
<p>Note that if the class variable is numeric only a subset of the statistics
are available. Arguments <code>complexity</code> and <code>class</code> are then
not applicable and therefore ignored. 
</p>


<h3>Value</h3>

<p>An object of class <code>Weka_classifier_evaluation</code>, a list of the
following components:
</p>
<table role = "presentation">
<tr><td><code>string</code></td>
<td>
<p>character, concatenation of the string representations
of the performance statistics.</p>
</td></tr>
<tr><td><code>details</code></td>
<td>
<p>vector, base statistics, e.g., the percentage of
instances correctly classified, etc.</p>
</td></tr>
<tr><td><code>detailsComplexity</code></td>
<td>
<p>vector, entropy-based statistics (if
selected).</p>
</td></tr>
<tr><td><code>detailsClass</code></td>
<td>
<p>matrix, class statistics, e.g., the true positive
rate, etc., for each level of the response variable (if selected).</p>
</td></tr>
<tr><td><code>confusionMatrix</code></td>
<td>
<p>table, cross-classification of true and
predicted classes.</p>
</td></tr>
</table>


<h3>References</h3>

<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco.    
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use some example data.
w &lt;- read.arff(system.file("arff","weather.nominal.arff", 
	       package = "RWeka"))

## Identify a decision tree.
m &lt;- J48(play~., data = w)
m

## Use 10 fold cross-validation.
e &lt;- evaluate_Weka_classifier(m,
                              cost = matrix(c(0,2,1,0), ncol = 2),
                              numFolds = 10, complexity = TRUE,
                              seed = 123, class = TRUE)
e
summary(e)
e$details
</code></pre>

<hr>
<h2 id='predict_Weka_classifier'>Model Predictions for R/Weka Classifiers</h2><span id='topic+predict.Weka_classifier'></span><span id='topic+fitted.Weka_classifier'></span>

<h3>Description</h3>

<p>Predicted values based on fitted Weka classifier models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Weka_classifier'
predict(object, newdata = NULL,
        type = c("class", "probability"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_Weka_classifier_+3A_object">object</code></td>
<td>
<p>an object of class inheriting from
<code>Weka_classifier</code>.</p>
</td></tr>
<tr><td><code id="predict_Weka_classifier_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables
with which to predict.  If omitted or <code>NULL</code>, the training
instances are used.</p>
</td></tr>
<tr><td><code id="predict_Weka_classifier_+3A_type">type</code></td>
<td>
<p>character string determining whether classes should be
predicted (numeric for regression, factor for classification) or
class probabilities (only available for classification).  May be
abbreviated.</p>
</td></tr>
<tr><td><code id="predict_Weka_classifier_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either a vector with classes or a matrix with the posterior class
probabilities, with rows corresponding to instances and columns to
classes.
</p>

<hr>
<h2 id='predict_Weka_clusterer'>Class Predictions for R/Weka Clusterers</h2><span id='topic+predict.Weka_clusterer'></span>

<h3>Description</h3>

<p>Predict class ids or memberships based on fitted Weka clusterers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Weka_clusterer'
predict(object, newdata = NULL,
        type = c("class_ids", "memberships"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_Weka_clusterer_+3A_object">object</code></td>
<td>
<p>an object of class inheriting from
<code>Weka_clusterer</code>.</p>
</td></tr>
<tr><td><code id="predict_Weka_clusterer_+3A_newdata">newdata</code></td>
<td>
<p>an optional data set for predictions are sought. This
must be given for predicting class memberships. If omitted or
<code>NULL</code>, the training instances are used for predicting class
ids.</p>
</td></tr>
<tr><td><code id="predict_Weka_clusterer_+3A_type">type</code></td>
<td>
<p>a character string indicating whether class ids or
memberships should be returned. May be abbreviated.</p>
</td></tr>
<tr><td><code id="predict_Weka_clusterer_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is only possible to predict class memberships if the Weka clusterer
provides a <code>distributionForInstance</code> method.
</p>

<hr>
<h2 id='read.arff'>Read Data from ARFF Files</h2><span id='topic+read.arff'></span><span id='topic+read.arff.R'></span>

<h3>Description</h3>

<p>Reads data from Weka Attribute-Relation File Format (<abbr><span class="acronym">ARFF</span></abbr>)
files. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.arff(file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read.arff_+3A_file">file</code></td>
<td>
<p>a character string with the name of the <abbr><span class="acronym">ARFF</span></abbr>
file to read from, or a <code><a href="base.html#topic+connection">connection</a></code> which will be
opened if necessary, and if so closed at the end of the function
call.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the data from the <abbr><span class="acronym">ARFF</span></abbr> file.
</p>


<h3>References</h3>

<p>Attribute-Relation File Format
<a href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/">https://waikato.github.io/weka-wiki/formats_and_processing/arff/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.arff">write.arff</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>read.arff(system.file("arff", "contact-lenses.arff",
                      package = "RWeka"))
</code></pre>

<hr>
<h2 id='Weka_associators'>R/Weka Associators</h2><span id='topic+Apriori'></span><span id='topic+Tertius'></span>

<h3>Description</h3>

<p>R interfaces to Weka association rule learning algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Apriori(x, control = NULL)
Tertius(x, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_associators_+3A_x">x</code></td>
<td>
<p>an R object with the data to be associated.</p>
</td></tr>
<tr><td><code id="Weka_associators_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Apriori</code> implements an Apriori-type algorithm, which iteratively
reduces the minimum support until it finds the required number of
rules with the given minimum confidence.
</p>
<p><code>Tertius</code> implements a Tertius-type algorithm.
</p>
<p>See the references for more information on these algorithms.
</p>


<h3>Value</h3>

<p>A list inheriting from class <code>Weka_associators</code> with components
including
</p>
<table role = "presentation">
<tr><td><code>associator</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildAssociations</code> method to the
training instances using the given control options.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>Tertius</code> requires Weka package <span class="pkg">tertius</span> to be installed.
</p>


<h3>References</h3>

<p>R. Agrawal and R. Srikant (1994).
Fast algorithms for mining association rules in large databases.
<em>Proceedings of the  International Conference on Very Large
Databases</em>, 478&ndash;499.
Santiago, Chile: Morgan Kaufmann, Los Altos, CA.
</p>
<p>P. A. Flach and N. Lachiche (1999).
Confirmation-guided discovery of first-order rules with Tertius.
<em>Machine Learning</em>, <b>42</b>, 61&ndash;95.
<a href="https://doi.org/10.1023/A%3A1007656703224">doi:10.1023/A:1007656703224</a>.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- read.arff(system.file("arff", "contact-lenses.arff",
                           package = "RWeka"))
## Apriori with defaults.
Apriori(x)
## Some options: set required number of rules to 20.
Apriori(x, Weka_control(N = 20))

## Not run: 
## Requires Weka package 'tertius' to be installed.
## Tertius with defaults.
Tertius(x)
## Some options: only classification rules (single item in the RHS).
Tertius(x, Weka_control(S = TRUE))

## End(Not run)
</code></pre>

<hr>
<h2 id='Weka_attribute_evaluators'>R/Weka Attribute Evaluators</h2><span id='topic+InfoGainAttributeEval'></span><span id='topic+GainRatioAttributeEval'></span>

<h3>Description</h3>

<p>R interfaces to Weka attribute evaluators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GainRatioAttributeEval(formula, data, subset, na.action, control = NULL)
InfoGainAttributeEval(formula, data, subset, na.action, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_attribute_evaluators_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of a model. Note that for
unsupervised filters the response can be omitted.</p>
</td></tr>
<tr><td><code id="Weka_attribute_evaluators_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_attribute_evaluators_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_attribute_evaluators_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_attribute_evaluators_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>GainRatioAttributeEval</code> evaluates the worth of an attribute by
measuring the gain ratio with respect to the class.
</p>
<p><code>InfoGainAttributeEval</code> evaluates the worth of an attribute by
measuring the information gain with respect to the class.
</p>
<p>Currently, only interfaces to classes which evaluate single attributes
(as opposed to subsets, technically, which implement the Weka
AttributeEvaluator interface) are possible.
</p>


<h3>Value</h3>

<p>A numeric vector with the figures of merit for the attributes
specified by the right hand side of <code>formula</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>InfoGainAttributeEval(Species ~ . , data = iris)
</code></pre>

<hr>
<h2 id='Weka_classifier_functions'>R/Weka Classifier Functions</h2><span id='topic+Weka_classifier_functions'></span><span id='topic+LinearRegression'></span><span id='topic+Logistic'></span><span id='topic+SMO'></span>

<h3>Description</h3>

<p>R interfaces to Weka regression and classification function learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinearRegression(formula, data, subset, na.action,
                 control = Weka_control(), options = NULL)
Logistic(formula, data, subset, na.action,
         control = Weka_control(), options = NULL)
SMO(formula, data, subset, na.action,
    control = Weka_control(), options = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_classifier_functions_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="Weka_classifier_functions_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_classifier_functions_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_classifier_functions_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_classifier_functions_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code> giving
options to be passed to the Weka learner.  Available options can be
obtained on-line using the Weka Option Wizard <code><a href="#topic+WOW">WOW</a></code>, or
the Weka documentation.</p>
</td></tr>
<tr><td><code id="Weka_classifier_functions_+3A_options">options</code></td>
<td>
<p>a named list of further options, or <code>NULL</code>
(default).  See <b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are a <code><a href="#topic+predict.Weka_classifier">predict</a></code> method for
predicting from the fitted models, and a <code>summary</code> method based
on <code><a href="#topic+evaluate_Weka_classifier">evaluate_Weka_classifier</a></code>.
</p>
<p><code>LinearRegression</code> builds suitable linear regression models,
using the Akaike criterion for model selection.
</p>
<p><code>Logistic</code> builds multinomial logistic regression models based on
ridge estimation (le Cessie and van Houwelingen, 1992).
</p>
<p><code>SMO</code> implements John C. Platt's sequential minimal optimization
algorithm for training a support vector classifier using polynomial or
<abbr><span class="acronym">RBF</span></abbr> kernels.  Multi-class problems are solved using pairwise
classification.  
</p>
<p>The model formulae should only use the &lsquo;<span class="samp">&#8288;+&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;-&#8288;</span>&rsquo; operators
to indicate the variables to be included or not used, respectively.
</p>
<p>Argument <code>options</code> allows further customization.  Currently,
options <code>model</code> and <code>instances</code> (or partial matches for
these) are used: if set to <code>TRUE</code>, the model frame or the
corresponding Weka instances, respectively, are included in the fitted
model object, possibly speeding up subsequent computations on the
object.  By default, neither is included.
</p>


<h3>Value</h3>

<p>A list inheriting from classes <code>Weka_functions</code> and
<code>Weka_classifiers</code> with components including
</p>
<table role = "presentation">
<tr><td><code>classifier</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildClassifier</code> method to build
the specified model using the given control options.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>a numeric vector or factor with the model
predictions for the training instances (the results of calling the
Weka <code>classifyInstance</code> method for the built classifier and
each instance).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>J. C. Platt (1998).
Fast training of Support Vector Machines using Sequential Minimal
Optimization.
In B. Schoelkopf, C. Burges, and A. Smola (eds.),
<em>Advances in Kernel Methods &mdash; Support Vector Learning</em>.
MIT Press.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco. 
</p>


<h3>See Also</h3>

<p><a href="#topic+Weka_classifiers">Weka_classifiers</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Linear regression:
## Using standard data set 'mtcars'.
LinearRegression(mpg ~ ., data = mtcars)
## Compare to R:
step(lm(mpg ~ ., data = mtcars), trace = 0)

## Using standard data set 'chickwts'.
LinearRegression(weight ~ feed, data = chickwts)
## (Note the interactions!)

## Logistic regression:
## Using standard data set 'infert'.
STATUS &lt;- factor(infert$case, labels = c("control", "case"))
Logistic(STATUS ~ spontaneous + induced, data = infert)
## Compare to R:
glm(STATUS ~ spontaneous + induced, data = infert, family = binomial())

## Sequential minimal optimization algorithm for training a support
## vector classifier, using am RBF kernel with a non-default gamma
## parameter (argument '-G') instead of the default polynomial kernel
## (from a question on r-help):
SMO(Species ~ ., data = iris,
    control = Weka_control(K =
    list("weka.classifiers.functions.supportVector.RBFKernel", G = 2)))
## In fact, by some hidden magic it also "works" to give the "base" name
## of the Weka kernel class:
SMO(Species ~ ., data = iris,
    control = Weka_control(K = list("RBFKernel", G = 2)))
</code></pre>

<hr>
<h2 id='Weka_classifier_lazy'>R/Weka Lazy Learners</h2><span id='topic+Weka_classifier_lazy'></span><span id='topic+IBk'></span><span id='topic+LBR'></span>

<h3>Description</h3>

<p>R interfaces to Weka lazy learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IBk(formula, data, subset, na.action,
    control = Weka_control(), options = NULL)
LBR(formula, data, subset, na.action,
    control = Weka_control(), options = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_classifier_lazy_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="Weka_classifier_lazy_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_classifier_lazy_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_classifier_lazy_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_classifier_lazy_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code> giving
options to be passed to the Weka learner.  Available options can be
obtained on-line using the Weka Option Wizard <code><a href="#topic+WOW">WOW</a></code>, or
the Weka documentation.</p>
</td></tr>
<tr><td><code id="Weka_classifier_lazy_+3A_options">options</code></td>
<td>
<p>a named list of further options, or <code>NULL</code>
(default).  See <b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are a <code><a href="#topic+predict.Weka_classifier">predict</a></code> method for
predicting from the fitted models, and a <code>summary</code> method based
on <code><a href="#topic+evaluate_Weka_classifier">evaluate_Weka_classifier</a></code>.
</p>
<p><code>IBk</code> provides a <code class="reqn">k</code>-nearest neighbors classifier, see Aha &amp;
Kibler (1991).
</p>
<p><code>LBR</code> (&ldquo;Lazy Bayesian Rules&rdquo;) implements a lazy learning
approach to lessening the attribute-independence assumption of naive
Bayes as suggested by Zheng &amp; Webb (2000).
</p>
<p>The model formulae should only use the &lsquo;<span class="samp">&#8288;+&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;-&#8288;</span>&rsquo; operators
to indicate the variables to be included or not used, respectively.
</p>
<p>Argument <code>options</code> allows further customization.  Currently,
options <code>model</code> and <code>instances</code> (or partial matches for
these) are used: if set to <code>TRUE</code>, the model frame or the
corresponding Weka instances, respectively, are included in the fitted
model object, possibly speeding up subsequent computations on the
object.  By default, neither is included.
</p>


<h3>Value</h3>

<p>A list inheriting from classes <code>Weka_lazy</code> and
<code>Weka_classifiers</code> with components including
</p>
<table role = "presentation">
<tr><td><code>classifier</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildClassifier</code> method to build
the specified model using the given control options.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>a numeric vector or factor with the model
predictions for the training instances (the results of calling the
Weka <code>classifyInstance</code> method for the built classifier and
each instance).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>LBR</code> requires Weka package <span class="pkg">lazyBayesianRules</span> to be
installed.
</p>


<h3>References</h3>

<p>D. Aha and D. Kibler (1991).
Instance-based learning algorithms.
<em>Machine Learning</em>, <b>6</b>, 37&ndash;66.
<a href="https://doi.org/10.1007/BF00153759">doi:10.1007/BF00153759</a>.
</p>
<p>Z. Zheng and G. Webb (2000).
Lazy learning of Bayesian rules.
<em>Machine Learning</em>, <b>41</b>/1, 53&ndash;84.
<a href="https://doi.org/10.1023/A%3A1007613203719">doi:10.1023/A:1007613203719</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+Weka_classifiers">Weka_classifiers</a>  
</p>

<hr>
<h2 id='Weka_classifier_meta'>R/Weka Meta Learners</h2><span id='topic+Weka_classifier_meta'></span><span id='topic+AdaBoostM1'></span><span id='topic+Bagging'></span><span id='topic+LogitBoost'></span><span id='topic+MultiBoostAB'></span><span id='topic+Stacking'></span><span id='topic+CostSensitiveClassifier'></span>

<h3>Description</h3>

<p>R interfaces to Weka meta learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdaBoostM1(formula, data, subset, na.action,
           control = Weka_control(), options = NULL)
Bagging(formula, data, subset, na.action,
        control = Weka_control(), options = NULL)
LogitBoost(formula, data, subset, na.action,
           control = Weka_control(), options = NULL)
MultiBoostAB(formula, data, subset, na.action,
             control = Weka_control(), options = NULL)
Stacking(formula, data, subset, na.action,
         control = Weka_control(), options = NULL)
CostSensitiveClassifier(formula, data, subset, na.action,
                        control = Weka_control(), options = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_classifier_meta_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="Weka_classifier_meta_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_classifier_meta_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_classifier_meta_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_classifier_meta_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code> giving
options to be passed to the Weka learner.  Available options can be
obtained on-line using the Weka Option Wizard <code><a href="#topic+WOW">WOW</a></code>, or
the Weka documentation.  Base classifiers with an available R/Weka
interface (see <code><a href="#topic+list_Weka_interfaces">list_Weka_interfaces</a></code>), can be specified
(using the <span class="option">W</span> option) via their &ldquo;base name&rdquo; as shown
in the interface registry (see the examples), or their interface
function.</p>
</td></tr>
<tr><td><code id="Weka_classifier_meta_+3A_options">options</code></td>
<td>
<p>a named list of further options, or <code>NULL</code>
(default).  See <b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are a <code><a href="#topic+predict.Weka_classifier">predict</a></code> method for
predicting from the fitted models, and a <code>summary</code> method based
on <code><a href="#topic+evaluate_Weka_classifier">evaluate_Weka_classifier</a></code>.
</p>
<p><code>AdaBoostM1</code> implements the AdaBoost M1 method of Freund and
Schapire (1996).
</p>
<p><code>Bagging</code> provides bagging (Breiman, 1996).
</p>
<p><code>LogitBoost</code> performs boosting via additive logistic regression
(Friedman, Hastie and Tibshirani, 2000).
</p>
<p><code>MultiBoostAB</code> implements MultiBoosting (Webb, 2000), an
extension to the AdaBoost technique for forming decision
committees which can be viewed as a combination of AdaBoost and
&ldquo;wagging&rdquo;.
</p>
<p><code>Stacking</code> provides stacking (Wolpert, 1992).
</p>
<p><code>CostSensitiveClassifier</code> makes its base classifier
cost-sensitive.
</p>
<p>The model formulae should only use the &lsquo;<span class="samp">&#8288;+&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;-&#8288;</span>&rsquo; operators
to indicate the variables to be included or not used, respectively.
</p>
<p>Argument <code>options</code> allows further customization.  Currently,
options <code>model</code> and <code>instances</code> (or partial matches for
these) are used: if set to <code>TRUE</code>, the model frame or the
corresponding Weka instances, respectively, are included in the fitted
model object, possibly speeding up subsequent computations on the
object.  By default, neither is included.
</p>


<h3>Value</h3>

<p>A list inheriting from classes <code>Weka_meta</code> and
<code>Weka_classifiers</code> with components including
</p>
<table role = "presentation">
<tr><td><code>classifier</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildClassifier</code> method to build
the specified model using the given control options.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>a numeric vector or factor with the model
predictions for the training instances (the results of calling the
Weka <code>classifyInstance</code> method for the built classifier and
each instance).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>multiBoostAB</code> requires Weka package <span class="pkg">multiBoostAB</span> to be
installed.
</p>


<h3>References</h3>

<p>L. Breiman (1996).
Bagging predictors.
<em>Machine Learning</em>, <b>24</b>/2, 123&ndash;140.
<a href="https://doi.org/10.1023/A%3A1018054314350">doi:10.1023/A:1018054314350</a>.
</p>
<p>Y. Freund and R. E. Schapire (1996).
Experiments with a new boosting algorithm.
In <em>Proceedings of the International Conference on Machine
Learning</em>, pages 148&ndash;156.
Morgan Kaufmann: San Francisco.
</p>
<p>J. H. Friedman, T. Hastie, and R. Tibshirani (2000).
Additive logistic regression: A statistical view of boosting.
<em>Annals of Statistics</em>, <b>28</b>/2, 337&ndash;374.
<a href="https://doi.org/10.1214/aos/1016218223">doi:10.1214/aos/1016218223</a>.
</p>
<p>G. I. Webb (2000).
MultiBoosting: A technique for combining boosting and wagging.
<em>Machine Learning</em>, <b>40</b>/2, 159&ndash;196.
<a href="https://doi.org/10.1023/A%3A1007659514849">doi:10.1023/A:1007659514849</a>.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco. 
</p>
<p>D. H. Wolpert (1992).
Stacked generalization.
<em>Neural Networks</em>, <b>5</b>, 241&ndash;259.
<a href="https://doi.org/10.1016/S0893-6080%2805%2980023-1">doi:10.1016/S0893-6080(05)80023-1</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+Weka_classifiers">Weka_classifiers</a>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Use AdaBoostM1 with decision stumps.
m1 &lt;- AdaBoostM1(Species ~ ., data = iris,
                 control = Weka_control(W = "DecisionStump"))
table(predict(m1), iris$Species)

summary(m1) # uses evaluate_Weka_classifier()

## Control options for the base classifiers employed by the meta
## learners (apart from Stacking) can be given as follows:
m2 &lt;- AdaBoostM1(Species ~ ., data = iris,
                 control = Weka_control(W = list(J48, M = 30)))
</code></pre>

<hr>
<h2 id='Weka_classifier_rules'>R/Weka Rule Learners</h2><span id='topic+Weka_classifier_rules'></span><span id='topic+JRip'></span><span id='topic+M5Rules'></span><span id='topic+OneR'></span><span id='topic+PART'></span>

<h3>Description</h3>

<p>R interfaces to Weka rule learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>JRip(formula, data, subset, na.action,
     control = Weka_control(), options = NULL)
M5Rules(formula, data, subset, na.action,
        control = Weka_control(), options = NULL)
OneR(formula, data, subset, na.action,
     control = Weka_control(), options = NULL)
PART(formula, data, subset, na.action,
     control = Weka_control(), options = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_classifier_rules_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="Weka_classifier_rules_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_classifier_rules_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_classifier_rules_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_classifier_rules_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code> giving
options to be passed to the Weka learner.  Available options can be
obtained on-line using the Weka Option Wizard <code><a href="#topic+WOW">WOW</a></code>, or
the Weka documentation.</p>
</td></tr>
<tr><td><code id="Weka_classifier_rules_+3A_options">options</code></td>
<td>
<p>a named list of further options, or <code>NULL</code>
(default).  See <b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are a <code><a href="#topic+predict.Weka_classifier">predict</a></code> method for
predicting from the fitted models, and a <code>summary</code> method based
on <code><a href="#topic+evaluate_Weka_classifier">evaluate_Weka_classifier</a></code>.
</p>
<p><code>JRip</code> implements a propositional rule learner, &ldquo;Repeated
Incremental Pruning to Produce Error Reduction&rdquo; (RIPPER), as proposed
by Cohen (1995).
</p>
<p><code>M5Rules</code> generates a decision list for regression problems using
separate-and-conquer.  In each iteration it builds an model tree using
M5 and makes the &ldquo;best&rdquo; leaf into a rule.  See Hall, Holmes and
Frank (1999) for more information.
</p>
<p><code>OneR</code> builds a simple 1-R classifier, see Holte (1993).
</p>
<p><code>PART</code> generates PART decision lists using the approach of Frank
and Witten (1998).
</p>
<p>The model formulae should only use the &lsquo;<span class="samp">&#8288;+&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;-&#8288;</span>&rsquo; operators
to indicate the variables to be included or not used, respectively.
</p>
<p>Argument <code>options</code> allows further customization.  Currently,
options <code>model</code> and <code>instances</code> (or partial matches for
these) are used: if set to <code>TRUE</code>, the model frame or the
corresponding Weka instances, respectively, are included in the fitted
model object, possibly speeding up subsequent computations on the
object.  By default, neither is included.
</p>


<h3>Value</h3>

<p>A list inheriting from classes <code>Weka_rules</code> and
<code>Weka_classifiers</code> with components including
</p>
<table role = "presentation">
<tr><td><code>classifier</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildClassifier</code> method to build
the specified model using the given control options.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>a numeric vector or factor with the model
predictions for the training instances (the results of calling the
Weka <code>classifyInstance</code> method for the built classifier and
each instance).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>W. W. Cohen (1995).
Fast effective rule induction.
In A. Prieditis and S. Russell (eds.),
<em>Proceedings of the 12th International Conference on Machine
Learning</em>, pages 115&ndash;123.
Morgan Kaufmann.
ISBN 1-55860-377-8.
<a href="https://doi.org/10.1016/B978-1-55860-377-6.50023-2">doi:10.1016/B978-1-55860-377-6.50023-2</a>.
</p>
<p>E. Frank and I. H. Witten (1998).
Generating accurate rule sets without global optimization.
In J. Shavlik (ed.),
<em>Machine Learning: Proceedings of the Fifteenth International
Conference</em>.
Morgan Kaufmann Publishers: San Francisco, CA.
<a href="https://www.cs.waikato.ac.nz/~eibe/pubs/ML98-57.ps.gz">https://www.cs.waikato.ac.nz/~eibe/pubs/ML98-57.ps.gz</a>
</p>
<p>M. Hall, G. Holmes, and E. Frank (1999).
Generating rule sets from model trees.
<em>Proceedings of the Twelfth Australian Joint Conference on
Artificial Intelligence</em>, Sydney, Australia, pages 1&ndash;12.
Springer-Verlag.
<a href="https://www.cs.waikato.ac.nz/~eibe/pubs/ajc.pdf">https://www.cs.waikato.ac.nz/~eibe/pubs/ajc.pdf</a>
</p>
<p>R. C. Holte (1993).
Very simple classification rules perform well on most commonly used
datasets.
<em>Machine Learning</em>, <b>11</b>, 63&ndash;91.
<a href="https://doi.org/10.1023/A%3A1022631118932">doi:10.1023/A:1022631118932</a>.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco. 
</p>


<h3>See Also</h3>

<p><a href="#topic+Weka_classifiers">Weka_classifiers</a>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>M5Rules(mpg ~ ., data = mtcars)

m &lt;- PART(Species ~ ., data = iris)
m
summary(m)
</code></pre>

<hr>
<h2 id='Weka_classifier_trees'>R/Weka Classifier Trees</h2><span id='topic+Weka_classifier_trees'></span><span id='topic+J48'></span><span id='topic+LMT'></span><span id='topic+M5P'></span><span id='topic+DecisionStump'></span><span id='topic+plot.Weka_tree'></span><span id='topic+parse_Weka_digraph'></span>

<h3>Description</h3>

<p>R interfaces to Weka regression and classification tree learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>J48(formula, data, subset, na.action,
    control = Weka_control(), options = NULL)
LMT(formula, data, subset, na.action,
    control = Weka_control(), options = NULL)
M5P(formula, data, subset, na.action,
    control = Weka_control(), options = NULL)
DecisionStump(formula, data, subset, na.action,
              control = Weka_control(), options = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_classifier_trees_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.</p>
</td></tr>
<tr><td><code id="Weka_classifier_trees_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_classifier_trees_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_classifier_trees_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_classifier_trees_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code> giving
options to be passed to the Weka learner.  Available options can be
obtained on-line using the Weka Option Wizard <code><a href="#topic+WOW">WOW</a></code>, or
the Weka documentation.</p>
</td></tr>
<tr><td><code id="Weka_classifier_trees_+3A_options">options</code></td>
<td>
<p>a named list of further options, or <code>NULL</code>
(default).  See <b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are a <code><a href="#topic+predict.Weka_classifier">predict</a></code> method for
predicting from the fitted models, and a <code>summary</code> method based
on <code><a href="#topic+evaluate_Weka_classifier">evaluate_Weka_classifier</a></code>.
</p>
<p>There is also a <code>plot</code> method for fitted binary <code>Weka_tree</code>s
via the facilities provided by package <span class="pkg">partykit</span>. This converts
the <code>Weka_tree</code> to a <code>party</code> object and then simply calls
the plot method of this class (see <code><a href="partykit.html#topic+plot.party">plot.party</a></code>).
</p>
<p>Provided the Weka classification tree learner implements the
&ldquo;Drawable&rdquo; interface (i.e., provides a <code>graph</code> method),
<code><a href="#topic+write_to_dot">write_to_dot</a></code> can be used to create a DOT representation
of the tree for visualization via Graphviz or the <span class="pkg">Rgraphviz</span>
package.
</p>
<p><code>J48</code> generates unpruned or pruned C4.5 decision trees (Quinlan,
1993).
</p>
<p><code>LMT</code> implements &ldquo;Logistic Model Trees&rdquo; (Landwehr, 2003;
Landwehr et al., 2005).
</p>
<p><code>M5P</code> (where the &lsquo;<span class="samp">&#8288;P&#8288;</span>&rsquo; stands for &lsquo;prime&rsquo;) generates M5
model trees using the M5' algorithm, which was introduced in Wang &amp;
Witten (1997) and enhances the original M5 algorithm by Quinlan
(1992).
</p>
<p><code>DecisionStump</code> implements decision stumps (trees with a single
split only), which are frequently used as base learners for meta
learners such as Boosting.
</p>
<p>The model formulae should only use the &lsquo;<span class="samp">&#8288;+&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;-&#8288;</span>&rsquo; operators
to indicate the variables to be included or not used, respectively.
</p>
<p>Argument <code>options</code> allows further customization.  Currently,
options <code>model</code> and <code>instances</code> (or partial matches for
these) are used: if set to <code>TRUE</code>, the model frame or the
corresponding Weka instances, respectively, are included in the fitted
model object, possibly speeding up subsequent computations on the
object.  By default, neither is included.
</p>
<p><code>parse_Weka_digraph</code> can parse the graph associated with a Weka
tree classifier (and obtained by invoking its <code>graph()</code> method in
Weka), returning a simple list with nodes and edges.
</p>


<h3>Value</h3>

<p>A list inheriting from classes <code>Weka_tree</code> and
<code>Weka_classifiers</code> with components including
</p>
<table role = "presentation">
<tr><td><code>classifier</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildClassifier</code> method to build
the specified model using the given control options.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>a numeric vector or factor with the model
predictions for the training instances (the results of calling the
Weka <code>classifyInstance</code> method for the built classifier and
each instance).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
</table>


<h3>References</h3>

<p>N. Landwehr (2003).
<em>Logistic Model Trees</em>.
Master's thesis, Institute for Computer Science, University of
Freiburg, Germany.
<a href="https://www.cs.uni-potsdam.de/ml/landwehr/diploma_thesis.pdf">https://www.cs.uni-potsdam.de/ml/landwehr/diploma_thesis.pdf</a>
</p>
<p>N. Landwehr, M. Hall, and E. Frank (2005).
Logistic Model Trees.
<em>Machine Learning</em>, <b>59</b>, 161&ndash;205.
<a href="https://doi.org/10.1007/s10994-005-0466-3">doi:10.1007/s10994-005-0466-3</a>.
</p>
<p>R. Quinlan (1993).
<em>C4.5: Programs for Machine Learning</em>.
Morgan Kaufmann Publishers, San Mateo, CA.
</p>
<p>R. Quinlan (1992).
Learning with continuous classes.
<em>Proceedings of the Australian Joint Conference on Artificial
Intelligence</em>, 343&ndash;348.
World Scientific, Singapore. 
</p>
<p>Y. Wang and I. H. Witten (1997).
Induction of model trees for predicting continuous classes.
<em>Proceedings of the European Conference on Machine
Learning</em>.
University of Economics, Faculty of Informatics and Statistics,
Prague.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco. 
</p>


<h3>See Also</h3>

<p><a href="#topic+Weka_classifiers">Weka_classifiers</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m1 &lt;- J48(Species ~ ., data = iris)

## print and summary
m1
summary(m1) # calls evaluate_Weka_classifier()
table(iris$Species, predict(m1)) # by hand

## visualization
## use partykit package
if(require("partykit", quietly = TRUE)) plot(m1)
## or Graphviz
write_to_dot(m1)
## or Rgraphviz
## Not run: 
library("Rgraphviz")
ff &lt;- tempfile()
write_to_dot(m1, ff)
plot(agread(ff))

## End(Not run)

## Using some Weka data sets ...

## J48
DF2 &lt;- read.arff(system.file("arff", "contact-lenses.arff",
                             package = "RWeka"))
m2 &lt;- J48(`contact-lenses` ~ ., data = DF2)
m2
table(DF2$`contact-lenses`, predict(m2))
if(require("partykit", quietly = TRUE)) plot(m2)

## M5P
DF3 &lt;- read.arff(system.file("arff", "cpu.arff", package = "RWeka"))
m3 &lt;- M5P(class ~ ., data = DF3)
m3
if(require("partykit", quietly = TRUE)) plot(m3)

## Logistic Model Tree.
DF4 &lt;- read.arff(system.file("arff", "weather.arff", package = "RWeka"))
m4 &lt;- LMT(play ~ ., data = DF4)
m4
table(DF4$play, predict(m4))

## Larger scale example.
if(require("mlbench", quietly = TRUE)
   &amp;&amp; require("partykit", quietly = TRUE)) {
    ## Predict diabetes status for Pima Indian women
    data("PimaIndiansDiabetes", package = "mlbench")
    ## Fit J48 tree with reduced error pruning
    m5 &lt;- J48(diabetes ~ ., data = PimaIndiansDiabetes,
              control = Weka_control(R = TRUE))
    plot(m5)
    ## (Make sure that the plotting device is big enough for the tree.)
}
</code></pre>

<hr>
<h2 id='Weka_classifiers'>R/Weka Classifiers</h2><span id='topic+Weka_classifiers'></span>

<h3>Description</h3>

<p>R interfaces to Weka classifiers.
</p>


<h3>Details</h3>

<p>Supervised learners, i.e., algorithms for classification and
regression, are termed &ldquo;classifiers&rdquo; by Weka.  (Numeric
prediction, i.e., regression, is interpreted as prediction of a
continuous class.)
</p>
<p>R interface functions to Weka classifiers are created by
<code><a href="#topic+make_Weka_classifier">make_Weka_classifier</a></code>, and have formals <code>formula</code>,
<code>data</code>, <code>subset</code>, <code>na.action</code>, and <code>control</code>
(default: none), where the first four have the &ldquo;usual&rdquo; meanings
for statistical modeling functions in R, and the last again specifies
the control options to be employed by the Weka learner.
</p>
<p>By default, the model formulae should only use the &lsquo;<span class="samp">&#8288;+&#8288;</span>&rsquo; and
&lsquo;<span class="samp">&#8288;-&#8288;</span>&rsquo; operators to indicate the variables to be included or not
used, respectively.
</p>
<p>See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for details on how <code>na.action</code> is
used.
</p>
<p>Objects created by these interfaces always inherit from class
<code>Weka_classifier</code>, and have at least suitable <code>print</code>,
<code>summary</code> (via <code><a href="#topic+evaluate_Weka_classifier">evaluate_Weka_classifier</a></code>), and
<code><a href="#topic+predict.Weka_classifier">predict</a></code> methods.
</p>


<h3>See Also</h3>

<p>Available &ldquo;standard&rdquo; interface functions are documented in
<a href="#topic+Weka_classifier_functions">Weka_classifier_functions</a>
(regression and classification function learners),
<a href="#topic+Weka_classifier_lazy">Weka_classifier_lazy</a> (lazy learners),
<a href="#topic+Weka_classifier_meta">Weka_classifier_meta</a> (meta learners),
<a href="#topic+Weka_classifier_rules">Weka_classifier_rules</a> (rule learners),
and
<a href="#topic+Weka_classifier_trees">Weka_classifier_trees</a> (regression and
classification tree learners).
</p>

<hr>
<h2 id='Weka_clusterers'>R/Weka Clusterers</h2><span id='topic+Cobweb'></span><span id='topic+FarthestFirst'></span><span id='topic+SimpleKMeans'></span><span id='topic+XMeans'></span><span id='topic+DBScan'></span>

<h3>Description</h3>

<p>R interfaces to Weka clustering algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Cobweb(x, control = NULL)
FarthestFirst(x, control = NULL)
SimpleKMeans(x, control = NULL)
XMeans(x, control = NULL)
DBScan(x, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_clusterers_+3A_x">x</code></td>
<td>
<p>an R object with the data to be clustered.</p>
</td></tr>
<tr><td><code id="Weka_clusterers_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is a <code><a href="#topic+predict.Weka_clusterer">predict</a></code> method for
predicting class ids or memberships from the fitted clusterers.
</p>
<p><code>Cobweb</code> implements the Cobweb (Fisher, 1987) and Classit
(Gennari et al., 1989) clustering algorithms.
</p>
<p><code>FarthestFirst</code> provides the &ldquo;farthest first traversal
algorithm&rdquo; by Hochbaum and Shmoys, which works as a fast simple
approximate clusterer modeled after simple <code class="reqn">k</code>-means.
</p>
<p><code>SimpleKMeans</code> provides clustering with the <code class="reqn">k</code>-means
algorithm.
</p>
<p><code>XMeans</code> provides <code class="reqn">k</code>-means extended by an
&ldquo;Improve-Structure part&rdquo; and automatically determines the
number of clusters.
</p>
<p><code>DBScan</code> provides the &ldquo;density-based clustering algorithm&rdquo;
by Ester, Kriegel, Sander, and Xu. Note that noise points are assigned
to <code>NA</code>.
</p>


<h3>Value</h3>

<p>A list inheriting from class <code>Weka_clusterers</code> with components
including
</p>
<table role = "presentation">
<tr><td><code>clusterer</code></td>
<td>
<p>a reference (of class
<code><a href="rJava.html#topic+jobjRef-class">jobjRef</a></code>) to a Java object
obtained by applying the Weka <code>buildClusterer</code> method to the
training instances using the given control options.</p>
</td></tr>
<tr><td><code>class_ids</code></td>
<td>
<p>a vector of integers indicating the class to which
each training instance is allocated (the results of calling the Weka
<code>clusterInstance</code> method for the built clusterer and each
instance).</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>XMeans</code> requires Weka package <span class="pkg">XMeans</span> to be installed.
</p>
<p><code>DBScan</code> requires Weka package <span class="pkg">optics_dbScan</span> to be
installed.
</p>


<h3>References</h3>

<p>M. Ester, H.-P. Kriegel, J. Sander, and X. Xu (1996).
A Density-Based Algorithm for Discovering Clusters in Large Spatial
Databases with Noise.
<em>Proceedings of the Second International Conference on Knowledge
Discovery and Data Mining (KDD'96)</em>,
Portland, OR, 226&ndash;231.
AAAI Press.
</p>
<p>D. H. Fisher (1987).
Knowledge acquisition via incremental conceptual clustering.
<em>Machine Learning</em>, <b>2</b>/2, 139&ndash;172.
<a href="https://doi.org/10.1023/A%3A1022852608280">doi:10.1023/A:1022852608280</a>.
</p>
<p>J. Gennari, P. Langley, and D. H. Fisher (1989).
Models of incremental concept formation.
<em>Artificial Intelligence</em>, <b>40</b>, 11&ndash;62.
</p>
<p>D. S. Hochbaum and D. B. Shmoys (1985).
A best possible heuristic for the <code class="reqn">k</code>-center problem,
<em>Mathematics of Operations Research</em>, <b>10</b>(2), 180&ndash;184.
<a href="https://doi.org/10.1287/moor.10.2.180">doi:10.1287/moor.10.2.180</a>.
</p>
<p>D. Pelleg and A. W. Moore (2006).
X-means: Extending K-means with Efficient Estimation of the Number of
Clusters.
In: <em>Seventeenth International Conference on Machine Learning</em>,
727&ndash;734.
Morgan Kaufmann.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cl1 &lt;- SimpleKMeans(iris[, -5], Weka_control(N = 3))
cl1
table(predict(cl1), iris$Species)

## Not run: 
## Requires Weka package 'XMeans' to be installed.
## Use XMeans with a KDTree.
cl2 &lt;- XMeans(iris[, -5],
              c("-L", 3, "-H", 7, "-use-kdtree",
                "-K", "weka.core.neighboursearch.KDTree -P"))
cl2
table(predict(cl2), iris$Species)

## End(Not run)
</code></pre>

<hr>
<h2 id='Weka_control'>Control Weka Options</h2><span id='topic+Weka_control'></span><span id='topic+print.Weka_control'></span><span id='topic+as.character.Weka_control'></span>

<h3>Description</h3>

<p>Set control options for Weka learners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Weka_control(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_control_+3A_...">...</code></td>
<td>
<p>named arguments of control options, see the details and
examples.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The available options for a Weka learner, <code>foo()</code> say, can be
queried by <code>WOW(foo)</code> and then conveniently set by
<code>Weka_control()</code>.  See below for an example.
</p>
<p>One can use lists for options taking multiple arguments, see the
documentation for <code><a href="#topic+SMO">SMO</a></code> for an example.
</p>


<h3>Value</h3>

<p>A list of class <code>Weka_control</code> which can be coerced to
<code>character</code> for passing it to Weka.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WOW">WOW</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Query J4.8 options:
WOW("J48")
## Learn J4.8 tree on iris data with default settings:
J48(Species ~ ., data = iris)
## Learn J4.8 tree with reduced error pruning (-R) and 
## minimum number of instances set to 5 (-M 5):
J48(Species ~ ., data = iris, control = Weka_control(R = TRUE, M = 5))
</code></pre>

<hr>
<h2 id='Weka_converters'>R/Weka File Loaders and Savers</h2><span id='topic+C45Loader'></span><span id='topic+XRFFLoader'></span><span id='topic+C45Saver'></span><span id='topic+XRFFSaver'></span>

<h3>Description</h3>

<p>R interfaces to Weka file loaders and savers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>C45Loader(file)
XRFFLoader(file)
C45Saver(x, file, control = NULL)
XRFFSaver(x, file, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_converters_+3A_file">file</code></td>
<td>
<p>a non-empty character string naming a file to read from or
write to.</p>
</td></tr>
<tr><td><code id="Weka_converters_+3A_x">x</code></td>
<td>
<p>the data to be written, preferably a matrix or data frame.
If not, coercion to a data frame is attempted.</p>
</td></tr>
<tr><td><code id="Weka_converters_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>C45Loader</code> and <code>C45Saver</code> use the format employed by the
C4.5 algorithm/software, where data is stored in two separate
&lsquo;<span class="file">.names</span>&rsquo; and &lsquo;<span class="file">.data</span>&rsquo; files.
</p>
<p><code>XRFFLoader</code> and <code>XRFFSaver</code> handle <abbr><span class="acronym">XRFF</span></abbr>
(eXtensible attribute-Relation File Format, an <abbr><span class="acronym">XML</span></abbr>-based
extension of Weka's native Attribute-Relation File Format) files.
</p>


<h3>Value</h3>

<p>Invisibly <code>NULL</code> for the savers.
</p>
<p>A data frame containing the data from the given file for the loaders.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.arff">read.arff</a></code>,
<code><a href="#topic+write.arff">write.arff</a></code>.
</p>

<hr>
<h2 id='Weka_filters'>R/Weka Filters</h2><span id='topic+Normalize'></span><span id='topic+Discretize'></span>

<h3>Description</h3>

<p>R interfaces to Weka filters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Normalize(formula, data, subset, na.action, control = NULL)
Discretize(formula, data, subset, na.action, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_filters_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of a model. Note that for
unsupervised filters the response can be omitted.</p>
</td></tr>
<tr><td><code id="Weka_filters_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the
model.</p>
</td></tr>
<tr><td><code id="Weka_filters_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="Weka_filters_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when
the data contain <code>NA</code>s.  See <code><a href="stats.html#topic+model.frame">model.frame</a></code> for
details.</p>
</td></tr>
<tr><td><code id="Weka_filters_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>Normalize</code> implements an unsupervised filter that normalizes all
instances of a dataset to have a given norm.  Only numeric values are 
considered, and the class attribute is ignored.
</p>
<p><code>Discretize</code> implements a supervised instance filter that
discretizes a range of numeric attributes in the dataset into nominal
attributes.  Discretization is by Fayyad &amp; Irani's <abbr><span class="acronym">MDL</span></abbr>
method (the default).
</p>
<p>Note that these methods ignore nominal attributes, i.e., variables of
class <code>factor</code>.
</p>


<h3>Value</h3>

<p>A data frame.
</p>


<h3>References</h3>

<p>U. M. Fayyad and K. B. Irani (1993).
Multi-interval discretization of continuous-valued attributes for
classification learning.
<em>Thirteenth International Joint Conference on Artificial
Intelligence</em>, 1022&ndash;1027.
Morgan Kaufmann.
</p>
<p>I. H. Witten and E. Frank (2005).
<em>Data Mining: Practical Machine Learning Tools and Techniques</em>.
2nd Edition, Morgan Kaufmann, San Francisco.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Using a Weka data set ...
w &lt;- read.arff(system.file("arff","weather.arff",
	       package = "RWeka"))

## Normalize (response irrelevant)
m1 &lt;- Normalize(~., data = w)
m1

## Discretize
m2 &lt;- Discretize(play ~., data = w)
m2
</code></pre>

<hr>
<h2 id='Weka_interfaces'>R/Weka interfaces</h2><span id='topic+make_Weka_associator'></span><span id='topic+make_Weka_attribute_evaluator'></span><span id='topic+make_Weka_classifier'></span><span id='topic+make_Weka_clusterer'></span><span id='topic+make_Weka_filter'></span><span id='topic+list_Weka_interfaces'></span><span id='topic+make_Weka_package_loader'></span>

<h3>Description</h3>

<p>Create an R interface to an existing Weka learner, attribute evaluator
or filter, or show the available interfaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_Weka_associator(name, class = NULL,
                     init = NULL, package = NULL)
make_Weka_attribute_evaluator(name, class = NULL,
                              init = NULL, package = NULL)
make_Weka_classifier(name, class = NULL, handlers = list(),
                     init = NULL, package = NULL)
make_Weka_clusterer(name, class = NULL,
                    init = NULL, package = NULL)
make_Weka_filter(name, class = NULL,
                 init = NULL, package = NULL)
list_Weka_interfaces()
make_Weka_package_loader(p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_interfaces_+3A_name">name</code></td>
<td>
<p>a character string giving the fully qualified name of
a Weka learner/filter class in <abbr><span class="acronym">JNI</span></abbr> notation.</p>
</td></tr>
<tr><td><code id="Weka_interfaces_+3A_class">class</code></td>
<td>
<p><code>NULL</code> (default), or a character vector giving the
names of R classes the objects returned by the interface function
should inherit from in addition to the default ones (for
representing associators, classifiers, and clusterers).</p>
</td></tr>
<tr><td><code id="Weka_interfaces_+3A_handlers">handlers</code></td>
<td>
<p>a named list of special handler functions, see
<b>Details</b>.</p>
</td></tr>
<tr><td><code id="Weka_interfaces_+3A_init">init</code></td>
<td>
<p><code>NULL</code>, or a function with no arguments to be called
when the interface is used for building the learner/filter, or
queried for available options via <code><a href="#topic+WOW">WOW</a></code>.  Typically,
this is used for loading Weka packages when interfacing
functionality in these.</p>
</td></tr>
<tr><td><code id="Weka_interfaces_+3A_package">package</code></td>
<td>
<p><code>NULL</code> (default), or a character string giving the
name of the external Weka package providing the learner/filter class
specified by <code>name</code>.</p>
</td></tr>
<tr><td><code id="Weka_interfaces_+3A_p">p</code></td>
<td>
<p>a character string naming a Weka package to be loaded via
<code><a href="#topic+WPM">WPM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>make_Weka_associator</code> and <code>make_Weka_clusterer</code> create an R
function providing an interface to a Weka association learner or a
Weka clusterer, respectively.  This interface function has formals
<code>x</code> and <code>control = NULL</code>, representing the training
instances and control options to be employed.  Objects created by
these interface functions always inherit from classes
<code>Weka_associator</code> and <code>Weka_clusterer</code>, respectively,
and have at least suitable <code>print</code> methods.  Fitted clusterers
also have a <code><a href="#topic+predict.Weka_clusterer">predict</a></code> method.
</p>
<p><code>make_Weka_classifier</code> creates an interface function for a Weka
classifier, with formals <code>formula</code>, <code>data</code>, <code>subset</code>,
<code>na.action</code>, and <code>control</code> (default: none), where the first
four have the &ldquo;usual&rdquo; meanings for statistical modeling
functions in R, and the last again specifies the control options to be
employed by the Weka learner.  Objects created by these interfaces
always inherit from class <code>Weka_classifier</code>, and have at least
suitable <code>print</code> and
<code><a href="#topic+predict.Weka_classifier">predict</a></code> methods.
</p>
<p><code>make_Weka_filter</code> creates an interface function for a Weka
filter, with formals <code>formula</code>, <code>data</code>, <code>subset</code>,
<code>na.action</code>, and <code>control = NULL</code>, where the first four have
the &ldquo;usual&rdquo; meanings for statistical modeling functions in R,
and the last again specifies the control options to be employed by the
Weka filter.  Note that the response variable can be omitted from 
<code>formula</code> if the filter is &ldquo;unsupervised&rdquo;.  Objects
created by these interface functions are (currently) always of class
<code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>
<p><code>make_Weka_attribute_evaluator</code> creates an interface function for
a Weka attribute evaluation class which implements the
<code>AttributeEvaluator</code> interface, with formals as for the
classifier interface functions.
</p>
<p>Certain aspects of the interface function can be customized by
providing handlers.  Currently, only <em>control</em> handlers
(functions given as the <code>control</code> component of the list of
handlers) are used for processing the given control arguments before
passing them to the Weka classifier.  This is used, e.g., by the meta
learners to allow the specification of registered base learners by
their &ldquo;base names&rdquo; (rather their full Weka/Java class names).
</p>
<p>In addition to creating interface functions, the interfaces are
registered (under the name of the Weka class interfaced), which in
particular allows the Weka Option Wizard (<code><a href="#topic+WOW">WOW</a></code>) to
conveniently give on-line information about available control options
for the interfaces.
</p>
<p><code>list_Weka_interfaces</code> lists the <em>available</em> interfaces.
</p>
<p>Finally, <code>make_Weka_package_loader</code> generates init hooks for
loading required and already installed Weka packages.
</p>
<p>It is straightforward to register new interfaces in addition to the
ones package <span class="pkg">RWeka</span> provides by default.
</p>


<h3>References</h3>

<p>K. Hornik, C. Buchta, and A. Zeileis (2009).
Open-source machine learning: R meets Weka.
<em>Computational Statistics</em>, <b>24</b>/2, 225&ndash;232.
<a href="https://doi.org/10.1007/s00180-008-0119-7">doi:10.1007/s00180-008-0119-7</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create an interface to Weka's Naive Bayes classifier.
NB &lt;- make_Weka_classifier("weka/classifiers/bayes/NaiveBayes")
## Note that this has a very useful print method:
NB
## And we can use the Weka Option Wizard for finding out more:
WOW(NB)
## And actually use the interface ...
if(require("e1071", quietly = TRUE) &amp;&amp;
   require("mlbench", quietly = TRUE)) {
    data("HouseVotes84", package = "mlbench")
    model &lt;- NB(Class ~ ., data = HouseVotes84)
    predict(model, HouseVotes84[1:10, -1])
    predict(model, HouseVotes84[1:10, -1], type = "prob")
}
## (Compare this to David Meyer's naiveBayes() in package 'e1071'.)
</code></pre>

<hr>
<h2 id='Weka_stemmers'>R/Weka Stemmers</h2><span id='topic+IteratedLovinsStemmer'></span><span id='topic+LovinsStemmer'></span>

<h3>Description</h3>

<p>R interfaces to Weka stemmers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IteratedLovinsStemmer(x, control = NULL)
LovinsStemmer(x, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_stemmers_+3A_x">x</code></td>
<td>
<p>a character vector with words to be stemmed.</p>
</td></tr>
<tr><td><code id="Weka_stemmers_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with the stemmed words.
</p>


<h3>References</h3>

<p>J. B. Lovins (1968),
Development of a stemming algorithm.
<em>Mechanical Translation and Computational Linguistics</em>,
<b>11</b>, 22&ndash;31.
</p>

<hr>
<h2 id='Weka_tokenizers'>R/Weka Tokenizers</h2><span id='topic+AlphabeticTokenizer'></span><span id='topic+NGramTokenizer'></span><span id='topic+WordTokenizer'></span>

<h3>Description</h3>

<p>R interfaces to Weka tokenizers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AlphabeticTokenizer(x, control = NULL)
NGramTokenizer(x, control = NULL)
WordTokenizer(x, control = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Weka_tokenizers_+3A_x">x</code></td>
<td>
<p>a character vector with strings to be tokenized.</p>
</td></tr>
<tr><td><code id="Weka_tokenizers_+3A_control">control</code></td>
<td>
<p>an object of class <code><a href="#topic+Weka_control">Weka_control</a></code>, or a
character vector of control options, or <code>NULL</code> (default).
Available options can be obtained on-line using the Weka Option
Wizard <code><a href="#topic+WOW">WOW</a></code>, or the Weka documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>AlphabeticTokenizer</code> is an alphabetic string tokenizer, where
tokens are to be formed only from contiguous alphabetic sequences.
</p>
<p><code>NGramTokenizer</code> splits strings into <code class="reqn">n</code>-grams with given
minimal and maximal numbers of grams.
</p>
<p><code>WordTokenizer</code> is a simple word tokenizer.
</p>


<h3>Value</h3>

<p>A character vector with the tokenized strings.
</p>

<hr>
<h2 id='WOW'>Weka Option Wizard</h2><span id='topic+WOW'></span>

<h3>Description</h3>

<p>Give on-line information about available control options for Weka
learners or filters and their R interfaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WOW(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WOW_+3A_x">x</code></td>
<td>
<p>a character string giving either the fully qualified name of
a Weka learner or filter class in <abbr><span class="acronym">JNI</span></abbr> notation, or the
name of an available R interface, or an object obtained from
applying these interfaces to build an associator, classifier,
clusterer, or filter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+list_Weka_interfaces">list_Weka_interfaces</a></code> for the available interface
functions.
</p>


<h3>References</h3>

<p>K. Hornik, C. Buchta, and A. Zeileis (2009).
Open-source machine learning: R meets Weka.
<em>Computational Statistics</em>, <b>24</b>/2, 225&ndash;232.
<a href="https://doi.org/10.1007/s00180-008-0119-7">doi:10.1007/s00180-008-0119-7</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## The name of an "existing" (registered) interface.
WOW("J48")
## The name of some Weka class (not necessarily in the interface
## registry):
WOW("weka/classifiers/bayes/NaiveBayes")
</code></pre>

<hr>
<h2 id='WPM'>Weka Package Manager</h2><span id='topic+WPM'></span>

<h3>Description</h3>

<p>Manage Weka packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WPM(cmd, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WPM_+3A_cmd">cmd</code></td>
<td>
<p>a character string specifying the action to be performed.
Must be one of <code>"refresh-cache"</code>,
<code>"list-packages"</code>,
<code>"package-info"</code>,
<code>"install-package"</code>, <code>"remove-package"</code>,
<code>"toggle-load-status"</code>
or <code>"load-packages"</code>
(or a unique abbreviation thereof).</p>
</td></tr>
<tr><td><code id="WPM_+3A_...">...</code></td>
<td>
<p>character strings giving further arguments required for the
action to be performed.  See <b>Details</b>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available actions and respective additional arguments are as follows.
</p>

<dl>
<dt><code>"refresh-cache"</code></dt><dd><p>Refresh the cached copy of the package
meta data from the central package repository.</p>
</dd>
<dt><code>"list-packages"</code></dt><dd><p>print information (version numbers and
short descriptions) about packages as specified by an additional
keyword which must be one of <code>"all"</code> (all packages the system
knows about), <code>"installed"</code> (all packages installed locally),
or (<code>"available"</code> (all known packages not installed locally),
or a unique abbreviation thereof.</p>
</dd>
<dt><code>"package-info"</code></dt><dd><p>print information (metadata) about a
package.  Requires two additional character string arguments: a
keyword and the package name.  The keyword must be one of
<code>"repository"</code> (print info from the repository) or 
<code>"installed"</code> (print info on the installed version), or a
unique abbreviation thereof.</p>
</dd>
<dt><code>"install-package"</code></dt><dd><p>install a package as specified by an
additional character string giving its name.  (In principle, one
could also provide a file path or URL to a zip file.)</p>
</dd>
<dt><code>"remove-package"</code></dt><dd><p>remove a given (installed) package.</p>
</dd>
<dt><code>"toggle-load-status"</code></dt><dd><p>toggle the load status of the
given (installed) packages.</p>
</dd>
<dt><code>"load-packages"</code></dt><dd><p>load all installed packages with
active load status.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Weka stores packages and their information in the Weka home directory,
as given by the value of the environment variable <span class="env">WEKA_HOME</span>; if
this is not set, the &lsquo;<span class="file">wekafiles</span>&rsquo; subdirectory of the user's home
directory is used.  If this Weka home directory was not created yet,
<code>WPM()</code> will instead use a temporary directory in the R session
directory: to achieve persistence, users need to create the Weka home
directory before using <code>WPM()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Start by building/refreshing the cache.
WPM("refresh-cache")
## Show the packages installed locally.
WPM("list-packages", "installed")
## Show the packages available from the central Weka package
## repository and not installed locally.
WPM("list-packages", "available")
## Show repository information about package XMeans.
WPM("package-info", "repository", "XMeans")

## End(Not run)
</code></pre>

<hr>
<h2 id='write.arff'>Write Data into ARFF Files</h2><span id='topic+write.arff'></span><span id='topic+write.arff.R'></span>

<h3>Description</h3>

<p>Writes data into Weka Attribute-Relation File Format (<abbr><span class="acronym">ARFF</span></abbr>)
files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.arff(x, file, eol = "\n")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write.arff_+3A_x">x</code></td>
<td>
<p>the data to be written, preferably a matrix or data frame.
If not, coercion to a data frame is attempted.</p>
</td></tr>
<tr><td><code id="write.arff_+3A_file">file</code></td>
<td>
<p>either a character string naming a file, or a connection.
<code>""</code> indicates output to the standard output connection.</p>
</td></tr>
<tr><td><code id="write.arff_+3A_eol">eol</code></td>
<td>
<p>the character(s) to print at the end of each line (row).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Attribute-Relation File Format
<a href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/">https://waikato.github.io/weka-wiki/formats_and_processing/arff/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.arff">read.arff</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>write.arff(iris, file = "")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
