<!DOCTYPE html><html lang="en"><head><title>Help for package SparseLPM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SparseLPM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SparseLPM-package'>
<p>The Sparse Latent Position Model for Nonnegative Interaction Data</p></a></li>
<li><a href='#slpm_elbo'><p>slpm_elbo</p></a></li>
<li><a href='#slpm_gen'><p>slpm_gen</p></a></li>
<li><a href='#slpm_gof'><p>slpm_gof</p></a></li>
<li><a href='#slpm_init'><p>slpm_init</p></a></li>
<li><a href='#slpm_nga'><p>slpm_nga</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>The Sparse Latent Position Model for Nonnegative Interaction
Data</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-08-29</td>
</tr>
<tr>
<td>Description:</td>
<td>Models the nonnegative entries of a rectangular adjacency matrix using a sparse latent position model, as illustrated in Rastelli, R. (2018) "The Sparse Latent Position Model for nonnegative weighted networks" &lt;<a href="https://doi.org/10.48550/arXiv.1808.09262">doi:10.48550/arXiv.1808.09262</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.10), gtools, vegan</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-08-31 21:15:10 UTC; riccardo</td>
</tr>
<tr>
<td>Author:</td>
<td>Riccardo Rastelli [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Riccardo Rastelli &lt;riccardoras@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-08-31 23:10:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='SparseLPM-package'>
The Sparse Latent Position Model for Nonnegative Interaction Data
</h2><span id='topic+SparseLPM-package'></span><span id='topic+SparseLPM'></span>

<h3>Description</h3>

<p>Models the nonnegative entries of a rectangular adjacency matrix using a sparse latent position model, as illustrated in Rastelli, R. (2018) &quot;The Sparse Latent Position Model for nonnegative weighted networks&quot; &lt;arXiv:1808.09262&gt;.
</p>


<h3>Author(s)</h3>

<p>Riccardo Rastelli
</p>
<p>Mantainer: Riccardo Rastelli &lt;riccardoras@gmail.com&gt;
</p>


<h3>References</h3>

<p>Rastelli, R. (2018) &quot;The Sparse Latent Position Model for nonnegative weighted networks&quot;, <a href="https://arxiv.org/abs/1808.09262">https://arxiv.org/abs/1808.09262</a>
</p>

<hr>
<h2 id='slpm_elbo'>slpm_elbo</h2><span id='topic+slpm_elbo'></span>

<h3>Description</h3>

<p>Evaluates the evidence lower bound for a given configuration of variational parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slpm_elbo(X, var_pars, hyper_pars, verbose = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slpm_elbo_+3A_x">X</code></td>
<td>
<p>Rectangular adjacency matrix with non-negative entries.</p>
</td></tr>
<tr><td><code id="slpm_elbo_+3A_var_pars">var_pars</code></td>
<td>
<p>A list defining the variational parameters of the model. See <em>Details</em> for more specific indications.</p>
</td></tr>
<tr><td><code id="slpm_elbo_+3A_hyper_pars">hyper_pars</code></td>
<td>
<p>A list defining the hyperparameters of the model. The list should contain three vectors of length <code>K</code> denoted <code>delta</code>, <code>a_gamma</code> and <code>b_gamma</code>, where <code>K</code> is the number of latent dimensions.</p>
</td></tr>
<tr><td><code id="slpm_elbo_+3A_verbose">verbose</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether a lengthy output should be printed out.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The list <code>var_pars</code> must contain:
</p>

<dl>
<dt>alpha_u_tilde</dt><dd><p><code>M*K</code> matrix denoting the Gaussian means for senders.</p>
</dd>
<dt>alpha_v_tilde</dt><dd><p><code>N*K</code> matrix denoting the Gaussian means for receivers.</p>
</dd>
<dt>beta_u_tilde</dt><dd><p><code>M*K</code> matrix denoting the Gaussian variances for senders.</p>
</dd>
<dt>beta_v_tilde</dt><dd><p><code>N*K</code> matrix denoting the Gaussian variances for receivers.</p>
</dd>
<dt>lambda_tilde</dt><dd><p><code>M*N*K</code> array representing the soft clustering for the edges. This may be interpreted as the posterior probability that edge <code>ij</code> is determined by the <code>k</code>-th latent dimension.</p>
</dd>
<dt>delta_tilde</dt><dd><p><code>K</code> dimensional vector containing the variational parameters for the mixing proportions. This may be interpreted as the importance of each latent dimension.</p>
</dd>
<dt>a_tilde</dt><dd><p><code>K</code> dimensional vector containing the shapes of the variational Gamma distributions associated to the precisions.</p>
</dd>
<dt>b_tilde</dt><dd><p><code>K</code> dimensional vector containing the rates of the variational Gamma distributions associated to the precisions.</p>
</dd>
</dl>



<h3>Value</h3>

<table role = "presentation">
<tr><td><code>computing_time</code></td>
<td>
<p>Number of seconds required for the evaluation.</p>
</td></tr>
<tr><td><code>elbo</code></td>
<td>
<p>Value of the ELBO for the given variational parameters.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
M &lt;- N &lt;- 10
K &lt;- 2
network &lt;- slpm_gen(M = M, N = N, K = K)
var_pars &lt;- slpm_init(X = network$adj, K = K)
hyper_pars &lt;- list(delta = rep(1,K), a_gamma = rep(1,K), b_gamma = rep(1,K))
slpm_elbo(X = network$adj, var_pars = var_pars, hyper_pars = hyper_pars, verbose = FALSE)
</code></pre>

<hr>
<h2 id='slpm_gen'>slpm_gen</h2><span id='topic+slpm_gen'></span>

<h3>Description</h3>

<p>Generates the adjacency matrix <code>adj</code> of a SparseLPM by sampling both the data and model parameters from the posterior distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slpm_gen(M, N, K, hyper_pars = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slpm_gen_+3A_m">M</code></td>
<td>
<p>Number of rows of <code>adj</code>.</p>
</td></tr>
<tr><td><code id="slpm_gen_+3A_n">N</code></td>
<td>
<p>Number of cols of <code>adj</code>.</p>
</td></tr>
<tr><td><code id="slpm_gen_+3A_k">K</code></td>
<td>
<p>Number of latent dimensions of the SparseLPM.</p>
</td></tr>
<tr><td><code id="slpm_gen_+3A_hyper_pars">hyper_pars</code></td>
<td>
<p>A list defining the hyperparameters of the model. If left as <code>NULL</code> all the hyperparameters are initialised to <code>1</code>. Otherwise, the list should contain three vectors of <code>K</code> positive values denoted <code>delta</code>, <code>a_gamma</code> and <code>b_gamma</code>, respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components:
</p>
<table role = "presentation">
<tr><td><code>adj</code></td>
<td>
<p>Generated adjacency matrix.</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>Generated latent positions for senders.</p>
</td></tr>
<tr><td><code>V</code></td>
<td>
<p>Generated latent positions for receivers.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>Latent variables attached to each of the edges, selecting which dimension determines the edge probability.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>Vector of the Gaussian precisions associated to the latent dimensions.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
network &lt;- slpm_gen(M = 10, N = 8, K = 2)
</code></pre>

<hr>
<h2 id='slpm_gof'>slpm_gof</h2><span id='topic+slpm_gof'></span>

<h3>Description</h3>

<p>Evaluates the expected adjacency matrix for a fitted SparseLPM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slpm_gof(var_pars)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slpm_gof_+3A_var_pars">var_pars</code></td>
<td>
<p>A list defining the variational parameters of the model. See <em>Details</em> for more specific indications.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The list <code>var_pars</code> must contain:
</p>

<dl>
<dt>alpha_u_tilde</dt><dd><p><code>M*K</code> matrix denoting the Gaussian means for senders.</p>
</dd>
<dt>alpha_v_tilde</dt><dd><p><code>N*K</code> matrix denoting the Gaussian means for receivers.</p>
</dd>
<dt>beta_u_tilde</dt><dd><p><code>M*K</code> matrix denoting the Gaussian variances for senders.</p>
</dd>
<dt>beta_v_tilde</dt><dd><p><code>N*K</code> matrix denoting the Gaussian variances for receivers.</p>
</dd>
<dt>lambda_tilde</dt><dd><p><code>M*N*K</code> array representing the soft clustering for the edges. This may be interpreted as the posterior probability that edge <code>ij</code> is determined by the <code>k</code>-th latent dimension.</p>
</dd>
<dt>delta_tilde</dt><dd><p><code>K</code> dimensional vector containing the variational parameters for the mixing proportions. This may be interpreted as the importance of each of the latent dimensions.</p>
</dd>
<dt>a_tilde</dt><dd><p><code>K</code> dimensional vector containing the shapes of the variational Gamma distributions associated to the precisions.</p>
</dd>
<dt>b_tilde</dt><dd><p><code>K</code> dimensional vector containing the rates of the variational Gamma distributions associated to the precisions.</p>
</dd>
</dl>
<p>Note that this function only uses the alphas and the lambdas. Also, to avoid numerical instability, the lambdas are automatically pre-transformed into a hard partitioning using a Maximum A Posterior method.

</p>


<h3>Value</h3>

<p>An adjacency matrix with non-negative entries.</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
M &lt;- N &lt;- 10
K &lt;- 2
fitted_var_pars &lt;- list()
fitted_var_pars$alpha_u_tilde = matrix(rnorm(M*K),M,K)
fitted_var_pars$alpha_v_tilde = matrix(rnorm(N*K),N,K)
fitted_var_pars$lambda_tilde = array(NA,c(M,N,K))
fitted_var_pars$lambda_tilde[,,1] = matrix(runif(M*N),M,N)
fitted_var_pars$lambda_tilde[,,2] = 1-fitted_var_pars$lambda_tilde[,,1]
expected_adj &lt;- slpm_gof(fitted_var_pars)
</code></pre>

<hr>
<h2 id='slpm_init'>slpm_init</h2><span id='topic+slpm_init'></span>

<h3>Description</h3>

<p>Initialises the variational parameters of a SparseLPM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slpm_init(X, K, method = "random", threshold = 0.1, stdev = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slpm_init_+3A_x">X</code></td>
<td>
<p>Rectangular adjacency matrix with non-negative entries.</p>
</td></tr>
<tr><td><code id="slpm_init_+3A_k">K</code></td>
<td>
<p>Number of latent dimensions of the SparseLPM.</p>
</td></tr>
<tr><td><code id="slpm_init_+3A_method">method</code></td>
<td>
<p>The variational parameters are initialised at random. However, if <code>method="distance"</code>, a distance-based method is used as described in Rastelli ... (2018).</p>
</td></tr>
<tr><td><code id="slpm_init_+3A_threshold">threshold</code></td>
<td>
<p>A small number added to each of the entries of <code>X</code> to avoid numerical instability.</p>
</td></tr>
<tr><td><code id="slpm_init_+3A_stdev">stdev</code></td>
<td>
<p>Standard deviation of the Gaussian used to generate the random latent positions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of variational parameters that can be used as input for <a href="#topic+slpm_nga">slpm_nga</a> or <a href="#topic+slpm_elbo">slpm_elbo</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
M &lt;- N &lt;- 10
K &lt;- 2
network &lt;- slpm_gen(M = M, N = N, K = K)
var_pars_init &lt;- slpm_init(X = network$adj, K = K)
</code></pre>

<hr>
<h2 id='slpm_nga'>slpm_nga</h2><span id='topic+slpm_nga'></span>

<h3>Description</h3>

<p>Runs a Natural Gradient Ascent algorithm to maximise the variational objective for a Sparse LPM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slpm_nga(X, K, var_pars_init, hyper_pars = NULL, tol = 0.01, n_iter_max = 100000,
        natural_gradient = T, learning_rate_factor_up = 2, learning_rate_factor_down = 2,
        verbose = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slpm_nga_+3A_x">X</code></td>
<td>
<p>Rectangular adjacency matrix with non-negative entries.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_k">K</code></td>
<td>
<p>The number of latent dimension of the model.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_var_pars_init">var_pars_init</code></td>
<td>
<p>List of variational parameters to be used as starting point for the optimisation. See <em>Details</em> for more specific indications.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_hyper_pars">hyper_pars</code></td>
<td>
<p>List defining the hyperparameters of the model. The list should contain three vectors of <code>K</code> positive values denoted <code>delta</code>, <code>a_gamma</code> and <code>b_gamma</code>, respectively, where <code>K</code> is the number of latent dimensions. If left as null, all <code>delta</code> parameters are set to <code>0.001</code>, whereas the rest is set to <code>1</code>.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_tol">tol</code></td>
<td>
<p>Positive number setting the stop condition: the algorithm stops if one entire iteration yields an increase in the objective function smaller than this value.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_n_iter_max">n_iter_max</code></td>
<td>
<p>Maximum number of iterations the algorithm should be run for.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_natural_gradient">natural_gradient</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether the natural gradient instead of the standard gradient should be used.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_learning_rate_factor_up">learning_rate_factor_up</code></td>
<td>
<p>Before any natural gradient ascent update, the current step size is multiplied by this number to ensure that the algorithms tries new solutions which are relatively far from the current one.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_learning_rate_factor_down">learning_rate_factor_down</code></td>
<td>
<p>During any natural gradient ascent update, if a certain step size leads to a decrease in the objective function, then the step is divided by this number repeatedly until an increase is ensured.</p>
</td></tr>
<tr><td><code id="slpm_nga_+3A_verbose">verbose</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether a lengthy output should be printed out.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>var_pars</code> and <code>var_pars_init</code> are lists with components:
</p>

<dl>
<dt>alpha_u_tilde</dt><dd><p><code>M*K</code> matrix representing the Gaussian means for the latent positions of senders.</p>
</dd>
<dt>alpha_v_tilde</dt><dd><p><code>N*K</code> matrix representing the Gaussian means for the latent positions of receivers.</p>
</dd>
<dt>beta_u_tilde</dt><dd><p><code>M*K</code> matrix representing the Gaussian variances for the latent positions of senders.</p>
</dd>
<dt>beta_v_tilde</dt><dd><p><code>N*K</code> matrix representing the Gaussian variances for the latent positions of receivers.</p>
</dd>
<dt>lambda_tilde</dt><dd><p><code>M*N*K</code> array with entries corresponding to the posterior probabilities of assigning each edge to each latent dimension.</p>
</dd>
<dt>delta_tilde</dt><dd><p>Vector of <code>K</code> positive values representing the Dirichlet parameters generating the mixing proportions.</p>
</dd>
<dt>a_tilde</dt><dd><p>Vector of <code>K</code> positive values corresponding to the shapes of the variational Gamma distribution on the precisions.</p>
</dd>
<dt>b_tilde</dt><dd><p>Vector of <code>K</code> positive values corresponding to the rates of the variational Gamma distribution on the precisions.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list with components:
</p>
<table role = "presentation">
<tr><td><code>computing_time</code></td>
<td>
<p>Number of seconds required for the optimisation process.</p>
</td></tr>
<tr><td><code>var_pars</code></td>
<td>
<p>List containing the optimal values for the variational parameters.</p>
</td></tr>
<tr><td><code>learning_rates_u</code></td>
<td>
<p>Current step-size for the update of the variational parameters of each Gaussian distribution on the latent positions of senders.</p>
</td></tr>
<tr><td><code>learning_rates_v</code></td>
<td>
<p>Current step-size for the update of the variational parameters of each Gaussian distribution on the latent positions of receivers.</p>
</td></tr>
<tr><td><code>elbo_values</code></td>
<td>
<p>Values of the variational objective at the end of each of the iterations.</p>
</td></tr>
<tr><td><code>elbo_init</code></td>
<td>
<p>Value of the variational objective for the initial configuration.</p>
</td></tr>
<tr><td><code>elbo_final</code></td>
<td>
<p>Value of the variational objective for the optimal solution found.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Rastelli, R. (2018) &quot;The Sparse Latent Position Model for nonnegative weighted networks&quot;, <a href="https://arxiv.org/abs/1808.09262">https://arxiv.org/abs/1808.09262</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12345)
network &lt;- slpm_gen(M = 15, N = 10, K = 2)
K &lt;- 6
var_pars_init &lt;- slpm_init(X = network$adj, K = K)
res &lt;- slpm_nga(X = network$adj, K = K, var_pars_init = var_pars_init)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
