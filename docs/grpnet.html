<!DOCTYPE html><html><head><title>Help for package grpnet</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {grpnet}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#auto'>
<p>Auto MPG Data Set</p></a></li>
<li><a href='#coef'>
<p>Extract Coefficients for cv.grpnet and grpnet Fits</p></a></li>
<li><a href='#cv.grpnet'>
<p>Cross-Validation for grpnet</p></a></li>
<li><a href='#grpnet'>
<p>Fit a Group Elastic Net Regularized GLM/GAM</p></a></li>
<li><a href='#plot.cv.grpnet'>
<p>Plot Cross-Validation Curve for cv.grpnet Fits</p></a></li>
<li><a href='#plot.grpnet'>
<p>Plot Coefficients for grpnet Fits</p></a></li>
<li><a href='#predict.cv.grpnet'>
<p>Predict Method for cv.grpnet Fits</p></a></li>
<li><a href='#predict.grpnet'>
<p>Predict Method for grpnet Fits</p></a></li>
<li><a href='#print'>
<p>S3 'print' Methods for grpnet</p></a></li>
<li><a href='#rk'>
<p>Reproducing Kernel Basis</p></a></li>
<li><a href='#rk.model.matrix'>
<p>Construct Design Matrices via Reproducing Kernels</p></a></li>
<li><a href='#row.kronecker'>
<p>Row-Wise Kronecker Product</p></a></li>
<li><a href='#StartupMessage'><p>Startup Message for grpnet</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Group Elastic Net Regularized GLMs and GAMs</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-20</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient algorithms for fitting generalized linear and additive models with group elastic net penalties. Implements group lasso, group MCP, and group SCAD with an optional group ridge penalty. Computes the regularization path for linear regression (gaussian), logistic regression (binomial), multinomial logistic regression (multinomial), log-linear count regression (poisson and negative.binomial), and log-linear continuous regression (gamma and inverse gaussian). Supports default and formula methods for model specification, k-fold cross-validation for tuning the regularization parameters, and nonparametric regression via tensor product reproducing kernel (smoothing spline) basis function expansion. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-20 16:37:55 UTC; nate</td>
</tr>
<tr>
<td>Author:</td>
<td>Nathaniel E. Helwig [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-20 23:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='auto'>
Auto MPG Data Set
</h2><span id='topic+auto'></span>

<h3>Description</h3>

<p>Miles per gallon and other characteristics of vehicles from the 1970s-1980s. A version of this dataset was used as the 1983 American Statistical Association Exposition dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("auto")</code></pre>


<h3>Format</h3>

<p>A data frame with 392 observations on the following 9 variables.
</p>

<dl>
<dt><code>mpg</code></dt><dd><p>miles per gallon (numeric vector)</p>
</dd>
<dt><code>cylinders</code></dt><dd><p>number of cylinders: 3,4,5,6,8 (ordered factor)</p>
</dd>
<dt><code>displacement</code></dt><dd><p>engine displacement in cubic inches (numeric vector)</p>
</dd>
<dt><code>horsepower</code></dt><dd><p>engine horsepower (integer vector)</p>
</dd>
<dt><code>weight</code></dt><dd><p>vehicle weight in of lbs. (integer vector)</p>
</dd>
<dt><code>acceleration</code></dt><dd><p>0-60 mph time in sec. (numeric vector)</p>
</dd>
<dt><code>model.year</code></dt><dd><p>ranging from 1970 to 1982 (integer vector)</p>
</dd>
<dt><code>origin</code></dt><dd><p>region of origin: American, European, Japanese (factor vector)</p>
</dd>
</dl>



<h3>Details</h3>

<p>This is a modified version of the &quot;Auto MPG Data Set&quot; on the UCI Machine Learning Repository, which is a modified version of the &quot;cars&quot; dataset on StatLib. 
</p>
<p>Compared to the version of the dataset in UCI's MLR, this version of the dataset has removed (i) the 6 rows with missing <code>horsepower</code> scores, and (ii) the last column giving the name of each vehicle (<code>car.name</code>).
</p>


<h3>Source</h3>

<p>The dataset was originally collected by Ernesto Ramos and David Donoho.
</p>
<p>StatLib&mdash;Datasets Archive at Carnegie Mellon University
http://lib.stat.cmu.edu/datasets/cars.data
</p>
<p>Machine Learning Repository at University of California Irvine
https://archive.ics.uci.edu/ml/datasets/Auto+MPG
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load data
data(auto)

# display structure
str(auto)

# display header
head(auto)

# see 'cv.grpnet' for cross-validation examples
?cv.grpnet

# see 'grpnet' for fitting examples
?grpnet
</code></pre>

<hr>
<h2 id='coef'>
Extract Coefficients for cv.grpnet and grpnet Fits
</h2><span id='topic+coef.cv.grpnet'></span><span id='topic+coef.grpnet'></span>

<h3>Description</h3>

<p>Obtain coefficients from a cross-validated group elastic net regularized GLM (cv.grpnet) or a group elastic net regularized GLM (grpnet) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpnet'
coef(object, 
     s = c("lambda.min", "lambda.1se"),
     ...)
     
## S3 method for class 'grpnet'
coef(object, 
     s = NULL,
     ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef_+3A_object">object</code></td>
<td>

<p>Object of class &quot;cv.grpnet&quot; or &quot;grpnet&quot;
</p>
</td></tr>
<tr><td><code id="coef_+3A_s">s</code></td>
<td>

<p>Lambda value(s) at which predictions should be obtained. For &quot;cv.grpnet&quot; objects, default uses the lambda that minimizes the cross-validation loss function. For &quot;grpnet&quot; objects, default uses <code>s = object$lambda</code>. Interpolation is used for <code>s</code> values that are not included in <code>object$lambda</code>.  
</p>
</td></tr>
<tr><td><code id="coef_+3A_...">...</code></td>
<td>

<p>Additional arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>coef.cv.grpnet</em>: <br />
Returns the coefficients that are used by the <code><a href="#topic+predict.cv.grpnet">predict.cv.grpnet</a></code> function to form predictions from a fit <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> object. 
</p>
<p><em>coef.grpnet</em>: <br />
Returns the coefficients that are used by the <code><a href="#topic+predict.grpnet">predict.grpnet</a></code> function to form predictions from a fit <code><a href="#topic+grpnet">grpnet</a></code> object. 
</p>


<h3>Value</h3>

<p>For multinomial response variables, returns a list of length <code>length(object$ylev)</code>, where the <code>j</code>-th element is a matrix of dimension <code>c(ncoef, length(s))</code> giving the coefficients for <code>object$ylev[j]</code>.
</p>
<p>For other response variables, returns a matrix of dimension <code>c(ncoef, length(s))</code>, where the <code>i</code>-th column gives the coefficients for <code>s[i]</code>.
</p>


<h3>Note</h3>

<p>The syntax of these functions closely mimics that of the <code>coef.cv.glmnet</code> and <code>coef.glmnet</code> functions in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.coef.grpnet">print.coef.grpnet</a></code> for printing <code><a href="#topic+coef.grpnet">coef.grpnet</a></code> objects
</p>
<p><code><a href="#topic+predict.cv.grpnet">predict.cv.grpnet</a></code> for predicting from <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> objects
</p>
<p><code><a href="#topic+predict.grpnet">predict.grpnet</a></code> for predicting from <code><a href="#topic+grpnet">grpnet</a></code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   grpnet   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto)

# extract coefs for regularization path (output = 12 x 100 matrix)
coef(mod)

# extract coefs at 3 particular points (output = 12 x 3 matrix)
coef(mod, s = c(1.5, 1, 0.5))


######***######   cv.grpnet   ######***######

# load data
data(auto)

# 5-fold cv (formula method, response = mpg)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, nfolds = 5, alpha = 1)

# extract coefs for "min" solution (output = 12 x 1 matrix)
coef(mod)

# extract coefs for "1se" solution (output = 12 x 1 matrix)
coef(mod, s = "lambda.1se")

# extract coefs at 3 particular points (output = 12 x 3 matrix)
coef(mod, s = c(1.5, 1, 0.5))
</code></pre>

<hr>
<h2 id='cv.grpnet'>
Cross-Validation for grpnet
</h2><span id='topic+cv.grpnet'></span><span id='topic+cv.grpnet.default'></span><span id='topic+cv.grpnet.formula'></span>

<h3>Description</h3>

<p>Implements k-fold cross-validation for <code><a href="#topic+grpnet">grpnet</a></code> to find the regularization parameters that minimize the prediction error (deviance, mean squared error, mean absolute error, or misclassification rate).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.grpnet(x, ...)

## Default S3 method:
cv.grpnet(x, 
          y, 
          group,
          weights = NULL,
          offset = NULL,
          alpha = c(0.01, 0.25, 0.5, 0.75, 1),
          type.measure = NULL,
          nfolds = 10, 
          foldid = NULL,
          same.lambda = FALSE,
          parallel = FALSE, 
          cluster = NULL, 
          verbose = interactive(), 
          ...)
           
## S3 method for class 'formula'
cv.grpnet(formula,
          data, 
          use.rk = TRUE,
          weights = NULL,
          offset = NULL,
          alpha = c(0.01, 0.25, 0.5, 0.75, 1),
          type.measure = NULL,
          nfolds = 10, 
          foldid = NULL, 
          same.lambda = FALSE,
          parallel = FALSE, 
          cluster = NULL, 
          verbose = interactive(), 
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.grpnet_+3A_x">x</code></td>
<td>

<p>Model (design) matrix of dimension <code>nobs</code> by <code>nvars</code> (<code class="reqn">n \times p</code>).
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_y">y</code></td>
<td>

<p>Response vector of length <code class="reqn">n</code>. Matrix inputs are allowed for binomial and multinomial families (see &quot;Binomial and multinomial&quot; section in <code><a href="#topic+grpnet">grpnet</a></code>).
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_group">group</code></td>
<td>

<p>Group label vector (factor, character, or integer) of length <code class="reqn">p</code>. Predictors with the same label are grouped together for regularization.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_formula">formula</code></td>
<td>

<p>Model formula: a symbolic description of the model to be fitted. Uses the same syntax as <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>. 
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_data">data</code></td>
<td>

<p>Optional data frame containing the variables referenced in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_use.rk">use.rk</code></td>
<td>

<p>If <code>TRUE</code> (default), the <code><a href="#topic+rk.model.matrix">rk.model.matrix</a></code> function is used to build the model matrix. Otherwise, the <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> function is used to build the model matrix. Additional arguments to the <code><a href="#topic+rk.model.matrix">rk.model.matrix</a></code> function can be passed via the <code>...</code> argument.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_weights">weights</code></td>
<td>

<p>Optional vector of length <code class="reqn">n</code> with non-negative weights to use for weighted (penalized) likelihood estimation. Defaults to a vector of ones.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_offset">offset</code></td>
<td>

<p>Optional vector of length <code class="reqn">n</code> with an a priori known term to be included in the model's linear predictor. Defaults to a vector of zeros.  
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_alpha">alpha</code></td>
<td>

<p>Scalar or vector specifying the elastic net tuning parameter <code class="reqn">\alpha</code>. If <code>alpha</code> is a vector (default), then (a) the same <code>foldid</code> is used to compute the cross-validation error for each <code class="reqn">\alpha</code>, and (b) the solution for the optimal <code class="reqn">\alpha</code> is returned. 
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_type.measure">type.measure</code></td>
<td>

<p>Loss function for cross-validation. Options include: <code>"deviance"</code> for model deviance, <code>"mse"</code> for mean squared error, <code>"mae"</code> for mean absolute error, or <code>"class"</code> for classification error. Note that <code>"class"</code> is only available for binomial and multinomial families. The default is classification error (for binomial and multinomial) or deviance (others).
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_nfolds">nfolds</code></td>
<td>

<p>Number of folds for cross-validation. 
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_foldid">foldid</code></td>
<td>

<p>Optional vector of length <code class="reqn">n</code> giving the fold identification for each observation. Must be coercible into a factor. After coersion, the <code>nfolds</code> argument is defined as <code>nfolds = nlevels(foldid)</code>.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_same.lambda">same.lambda</code></td>
<td>

<p>Logical specfying if the same <code class="reqn">\lambda</code> sequence should be used for fitting the model to each fold's data. If <code>FALSE</code> (default), the <code class="reqn">\lambda</code> sequence is determined separately holding out each fold, and the <code class="reqn">\lambda</code> sequence from the full model is used to align the predictions. If <code>TRUE</code>, the <code class="reqn">\lambda</code> sequence from the full model is used to fit the model for each fold. The default often provides better (i.e., more stable) computational performance.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_parallel">parallel</code></td>
<td>

<p>Logical specifying if sequential computing (default) or parallel computing should be used. If <code>TRUE</code>, the fitting for each fold is parallelized.
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_cluster">cluster</code></td>
<td>

<p>Optional cluster to use for parallel computing. If <code>parallel = TRUE</code> and <code>cluster = NULL</code>, then the cluster is defined <code>cluster = makeCluster(2L)</code>, which uses two cores. Recommended usage: <code>cluster = makeCluster(detectCores())</code>
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_verbose">verbose</code></td>
<td>

<p>Logical indicating if the fitting progress should be printed. Defaults to <code>TRUE</code> in interactive sessions and <code>FALSE</code> otherwise. 
</p>
</td></tr>
<tr><td><code id="cv.grpnet_+3A_...">...</code></td>
<td>

<p>Optional additional arguments for <code><a href="#topic+grpnet">grpnet</a></code> (e.g., <code>standardize</code>, <code>penalty.factor</code>, etc.)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls the <code><a href="#topic+grpnet">grpnet</a></code> function <code>nfolds+1</code> times: once on the full dataset to obtain the <code>lambda</code> sequence, and once holding out each fold's data to evaluate the prediction error. The syntax of (the default S3 method for) this function closely mimics that of the <code>cv.glmnet</code> function in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010). 
</p>
<p>Let <code class="reqn">\mathbf{D}_u = \{\mathbf{y}_u, \mathbf{X}_u\}</code> denote the <code class="reqn">u</code>-th fold's data, let <code class="reqn">\mathbf{D}_{[u]} = \{\mathbf{y}_{[u]}, \mathbf{X}_{[u]}\}</code> denote the full dataset excluding the <code class="reqn">u</code>-th fold's data, and let <code class="reqn">\boldsymbol\beta_{\lambda [u]}</code> denote the coefficient estimates obtained from fitting the model to <code class="reqn">\mathbf{D}_{[u]}</code> using the regularization parameter <code class="reqn">\lambda</code>. 
</p>
<p>The cross-validation error for the <code class="reqn">u</code>-th fold is defined as
</p>
<p style="text-align: center;"><code class="reqn">E_u(\lambda) = C(\boldsymbol\beta_{\lambda [u]} , \mathbf{D}_u)</code>
</p>

<p>where <code class="reqn">C(\cdot , \cdot)</code> denotes the cross-validation loss function that is specified by <code>type.measure</code>. For example, the <code>"mse"</code> loss function is defined as
</p>
<p style="text-align: center;"><code class="reqn">C(\boldsymbol\beta_{\lambda [u]} , \mathbf{D}_u) = \| \mathbf{y}_u - \mathbf{X}_u \boldsymbol\beta_{\lambda [u]} \|^2</code>
</p>

<p>where <code class="reqn">\| \cdot \|</code> denotes the L2 norm.
</p>
<p>The mean cross-validation error <code>cvm</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">\bar{E}(\lambda) = \frac{1}{v} \sum_{u = 1}^v E_u(\lambda) </code>
</p>

<p>where <code class="reqn">v</code> is the total number of folds. The standard error <code>cvsd</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn">S(\lambda) = \sqrt{ \frac{1}{v (v - 1)} \sum_{u=1}^v (E_u(\lambda) - \bar{E}(\lambda))^2 } </code>
</p>

<p>which is the classic definition of the standard error of the mean. 
</p>


<h3>Value</h3>

<table>
<tr><td><code>lambda</code></td>
<td>
<p>regularization parameter sequence for the full data</p>
</td></tr>
<tr><td><code>cvm</code></td>
<td>
<p>mean cross-validation error for each <code>lambda</code></p>
</td></tr>
<tr><td><code>cvsd</code></td>
<td>
<p>estimated standard error of <code>cvm</code></p>
</td></tr>
<tr><td><code>cvup</code></td>
<td>
<p>upper curve: <code>cvm + cvsd</code></p>
</td></tr>
<tr><td><code>cvlo</code></td>
<td>
<p>lower curve: <code>cvm - cvsd</code></p>
</td></tr>
<tr><td><code>nzero</code></td>
<td>
<p>number of non-zero groups for each <code>lambda</code></p>
</td></tr>
<tr><td><code>grpnet.fit</code></td>
<td>
<p>fitted grpnet object for the full data</p>
</td></tr>
<tr><td><code>lambda.min</code></td>
<td>
<p>value of <code>lambda</code> that minimizes <code>cvm</code></p>
</td></tr>
<tr><td><code>lambda.1se</code></td>
<td>
<p>largest <code>lambda</code> such that <code>cvm</code> is within one <code>cvsd</code> from the minimum (see Note)</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>two-element vector giving the indices of <code>lambda.min</code> and <code>lambda.1se</code> in the <code>lambda</code> vector, i.e., <code>c(minid, se1id)</code> as defined in the Note</p>
</td></tr>
<tr><td><code>type.measure</code></td>
<td>
<p>loss function for cross-validation (used for plot label)</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>matched call</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>input <code>alpha</code> vector and min(cvm) for each <code>alpha</code> (if <code>alpha</code> is a vector)</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>lambda.1se</code> is defined as follows:
</p>
<p><code>minid &lt;- which.min(cvm)</code> <br />
<code>min1se &lt;- cvm[minid] + cvsd[minid]</code> <br />
<code>se1id &lt;- which(cvm &lt;= min1se)[1]</code> <br />
<code>lambda.1se &lt;- lambda[se1id]</code>
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Breheny, P., &amp; Huang, J. (2015). Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors. <em>Statistics and Computing, 25</em>, 173-187. <a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>
</p>
<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>
<p>Yang, Y., &amp; Zou, H. (2015). A fast unified algorithm for solving group-lasso penalize learning problems. <em>Statistics and Computing, 25</em>, 1129-1141. <a href="https://doi.org/10.1007/s11222-014-9498-5">doi:10.1007/s11222-014-9498-5</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.cv.grpnet">plot.cv.grpnet</a></code> for plotting the cross-validation error curve
</p>
<p><code><a href="#topic+predict.cv.grpnet">predict.cv.grpnet</a></code> for predicting from <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> objects
</p>
<p><code><a href="#topic+grpnet">grpnet</a></code> for fitting group elastic net regularization paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   family = "gaussian"   ######***######

# load data
data(auto)

# 5-fold cv (formula method, response = mpg)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, nfolds = 5, alpha = 1)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)



######***######   family = "binomial"   ######***######

# load data
data(auto)

# define response (1 = American, 0 = other)
y &lt;- ifelse(auto$origin == "American", 1, 0)

# define predictors
x &lt;- rk.model.matrix(~ 0 + ., data = auto[,1:7])

# define group
g &lt;- attr(x, "assign")

# 10-fold cv (default method, response = y)
set.seed(1)
mod &lt;- cv.grpnet(x, y, g, family = "binomial", alpha = 1)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)



######***######   family = "poisson"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = horsepower)
set.seed(1)
mod &lt;- cv.grpnet(horsepower ~ ., data = auto, family = "poisson", alpha = 1)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)



######***######   family = "negative.binomial"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = horsepower)
set.seed(1)
mod &lt;- cv.grpnet(horsepower ~ ., data = auto, family = "negative.binomial", 
                 alpha = 1, theta = 100)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)



######***######   family = "multinomial"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = origin)
set.seed(1)
mod &lt;- cv.grpnet(origin ~ ., data = auto, family = "multinomial", alpha = 1)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)



######***######   family = "Gamma"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = origin)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, family = "Gamma", alpha = 1)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)



######***######   family = "inverse.gaussian"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = origin)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, family = "inverse.gaussian", alpha = 1)

# print min and 1se solution info
mod

# plot cv error curve
plot(mod)


</code></pre>

<hr>
<h2 id='grpnet'>
Fit a Group Elastic Net Regularized GLM/GAM
</h2><span id='topic+grpnet'></span><span id='topic+grpnet.default'></span><span id='topic+grpnet.formula'></span>

<h3>Description</h3>

<p>Fits generalized linear/additive models with a group elastic net penalty. Predictor groups can be manually input (default S3 method) or inferred from the model (S3 &quot;formula&quot; method). The regularization path is computed at a data-generated (default) or user-provided sequence of lambda values. </p>


<h3>Usage</h3>

<pre><code class='language-R'>grpnet(x, ...)

## Default S3 method:
grpnet(x, 
       y, 
       group, 
       family = c("gaussian", "binomial", "multinomial", "poisson", 
                  "negative.binomial", "Gamma", "inverse.gaussian"),
       weights = NULL, 
       offset = NULL, 
       alpha = 1, 
       nlambda = 100,
       lambda.min.ratio = ifelse(nobs &lt; nvars, 0.05, 0.0001), 
       lambda = NULL, 
       penalty.factor = NULL,
       penalty = c("LASSO", "MCP", "SCAD"),
       gamma = ifelse(penalty == "MCP", 3, 4),
       theta = 1,
       standardize = TRUE,
       orthogonalize = FALSE,
       intercept = TRUE, 
       thresh = 1e-04, 
       maxit = 1e05, 
       ...)
      
## S3 method for class 'formula'
grpnet(formula,
       data, 
       use.rk = TRUE,
       family = c("gaussian", "binomial", "multinomial", "poisson", 
                  "negative.binomial", "Gamma", "inverse.gaussian"),
       weights = NULL,
       offset = NULL,
       alpha = 1,
       nlambda = 100,
       lambda.min.ratio = ifelse(nobs &lt; nvars, 0.05, 0.0001),
       lambda = NULL,
       penalty.factor = NULL,
       penalty = c("LASSO", "MCP", "SCAD"),
       gamma = ifelse(penalty == "MCP", 3, 4),
       theta = 1,
       standardize = TRUE,
       orthogonalize = FALSE,
       thresh = 1e-04,
       maxit = 1e05,
       ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grpnet_+3A_x">x</code></td>
<td>

<p>Model (design) matrix of dimension <code>nobs</code> by <code>nvars</code> (<code class="reqn">n \times p</code>).
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_y">y</code></td>
<td>

<p>Response vector of length <code class="reqn">n</code>. Matrix inputs are allowed for binomial and multinomial families (see &quot;Binomial and multinomial&quot; section).
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_group">group</code></td>
<td>

<p>Group label vector (factor, character, or integer) of length <code class="reqn">p</code>. Predictors with the same label are grouped together for regularization.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_formula">formula</code></td>
<td>

<p>Model formula: a symbolic description of the model to be fitted. Uses the same syntax as <code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+glm">glm</a></code>. 
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_data">data</code></td>
<td>

<p>Optional data frame containing the variables referenced in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_use.rk">use.rk</code></td>
<td>

<p>If <code>TRUE</code> (default), the <code><a href="#topic+rk.model.matrix">rk.model.matrix</a></code> function is used to build the model matrix. Otherwise, the <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> function is used to build the model matrix. Additional arguments to the <code><a href="#topic+rk.model.matrix">rk.model.matrix</a></code> function can be passed via the <code>...</code> argument.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_family">family</code></td>
<td>

<p>Character specifying the assumed distribution for the response variable. Partial matching is allowed. Options include <code>"gaussian"</code> (real-valued response), <code>"binomial"</code> (binary response), <code>"multinomial"</code> (multi-class response), <code>"poisson"</code> (count response), <code>"negative.binomial"</code> (count response), <code>"Gamma"</code> (positive real-valued), or <code>"inverse.gaussian"</code> (positive real-valued). 
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_weights">weights</code></td>
<td>

<p>Optional vector of length <code class="reqn">n</code> with non-negative weights to use for weighted (penalized) likelihood estimation. Defaults to a vector of ones.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_offset">offset</code></td>
<td>

<p>Optional vector of length <code class="reqn">n</code> with an a priori known term to be included in the model's linear predictor. Defaults to a vector of zeros.  
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_alpha">alpha</code></td>
<td>

<p>Regularization hyperparameter satisfying <code class="reqn">0 \leq \alpha \leq 1</code> that gives the balance between the group L1 (lasso) and group L2 (ridge) penalty. Setting <code class="reqn">\alpha = 1</code> uses a group lasso penalty, setting <code class="reqn">\alpha = 0</code> uses a group ridge penalty, and setting <code class="reqn">0 &lt; \alpha &lt; 1</code> uses a group elastic net group penalty.  
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_nlambda">nlambda</code></td>
<td>

<p>Number of <code class="reqn">\lambda</code> values to use in the regularization path. Ignored if <code>lambda</code> is provided.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>

<p>The proportion <code class="reqn">0 &lt; \pi &lt; 1</code> that defines the minimum regularization parameter <code class="reqn">\lambda_{\mathrm{min}}</code> as a fraction of the maximum regularization parameter <code class="reqn">\lambda_{\mathrm{max}}</code> via the relationship <code class="reqn">\lambda_{\mathrm{min}} = \pi \lambda_{\mathrm{max}}</code>. Ignored if <code>lambda</code> is provided. Note that <code class="reqn">\lambda_{\mathrm{max}}</code> is defined such that all penalized effects are shrunk to zero.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_lambda">lambda</code></td>
<td>

<p>Optional vector of user-supplied regularization parameter values. 
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_penalty.factor">penalty.factor</code></td>
<td>

<p>Default S3 method: vector of length <code class="reqn">K</code> giving the non-negative penalty weight for each predictor group. The order of the weights should correspond to the order of <code>levels(as.factor(group))</code>. Defaults to <code class="reqn">\sqrt{p_k}</code> for all <code class="reqn">k = 1,\ldots,K</code>, where <code class="reqn">p_k</code> is the number of coefficients in the <code class="reqn">k</code>-th group. If <code>penalty.factor[k] = 0</code>, then the <code class="reqn">k</code>-th group is unpenalized, and the corresponding term is always included in the model. 
</p>
<p>S3 &quot;formula&quot; method: named list giving the non-negative penalty weight for terms specified in the formula. Incomplete lists are allowed. Any term that is specified in <code>formula</code> but not in <code>penalty.factor</code> will be assigned the default penalty weight of <code class="reqn">\sqrt{p_k}</code>. If <code>penalty.factor$z = 0</code>, then the variable <code>z</code> is unpenalized and always included in the model.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_penalty">penalty</code></td>
<td>

<p>Character specifying which (group) penalty to use: LASSO , MCP, or SCAD.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_gamma">gamma</code></td>
<td>

<p>Penalty hyperparameter that satisfies <code class="reqn">\gamma &gt; 1</code> for MCP and <code class="reqn">\gamma &gt; 2</code> for SCAD. Ignored for LASSO penalty.
</p>
</td></tr> 
<tr><td><code id="grpnet_+3A_theta">theta</code></td>
<td>

<p>Additional (&quot;size&quot;) parameter for negative binomial responses, where the variance function is defined as <code class="reqn">V(\mu) = \mu + \mu^2/ \theta</code>
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_standardize">standardize</code></td>
<td>

<p>Logical indicating whether the predictors should be groupwise standardized. If <code>TRUE</code> (default), each column of <code>x</code> is mean-centered and each predictor group's design matrix is scaled to have a mean-square of one before fitting the model. Regardless of whether standardization is used, the coefficients are always returned on the original data scale.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_orthogonalize">orthogonalize</code></td>
<td>

<p>Logical indicating whether the predictors should be groupwise orthogonalized. If <code>TRUE</code>, each predictor group's design matrix is orthonormalized (i.e., <code class="reqn">\mathbf{X}_k^\top \mathbf{X}_k = \mathbf{I}_k</code>) before fitting the model. Regardless of whether orthogonalization is used, the coefficients are always returned on the original data scale.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_intercept">intercept</code></td>
<td>

<p>Logical indicating whether an intercept term should be included in the model. Note that the intercept is always unpenalized.   
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_thresh">thresh</code></td>
<td>

<p>Convergence threshold (tolerance). The algorithm is determined to have converged once the maximum relative change in the coefficients is below this threshold. See &quot;Convergence&quot; section.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_maxit">maxit</code></td>
<td>

<p>Maximum number of iterations to allow.
</p>
</td></tr>
<tr><td><code id="grpnet_+3A_...">...</code></td>
<td>

<p>Additional arguments used by the default or formula method.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Consider a generalized linear model of the form
</p>
<p style="text-align: center;"><code class="reqn">
g(\mu) = \mathbf{X}^\top \boldsymbol\beta
</code>
</p>

<p>where <code class="reqn">\mu = E(Y | \mathbf{X})</code> is the conditional expectation of the response <code class="reqn">Y</code> given the predictor vector <code class="reqn">\mathbf{X}</code>, the function <code class="reqn">g(\cdot)</code> is a user-specified (invertible) link function, and <code class="reqn">\boldsymbol\beta</code> are the unknown regression coefficients. Furthermore, suppose that the predictors are grouped, such as
</p>
<p style="text-align: center;"><code class="reqn">
\mathbf{X}^\top \boldsymbol\beta = \sum_{k=1}^K \mathbf{X}_k^\top \boldsymbol\beta_k
</code>
</p>

<p>where <code class="reqn">\mathbf{X} = (\mathbf{X}_1, \ldots, \mathbf{X}_K)</code> is the grouped predictor vector, and <code class="reqn">\boldsymbol\beta = (\boldsymbol\beta_1, \ldots, \boldsymbol\beta_K)</code> is the grouped coefficient vector. 
</p>
<p>Given <code class="reqn">n</code> observations, this function finds the <code class="reqn">\boldsymbol\beta</code> that minimizes
</p>
<p style="text-align: center;"><code class="reqn">
L(\boldsymbol\beta | \mathbf{D}) + \lambda P_\alpha(\boldsymbol\beta)
</code>
</p>

<p>where <code class="reqn">L(\boldsymbol\beta | \mathbf{D})</code> is the loss function with <code class="reqn">\mathbf{D} = \{\mathbf{y}, \mathbf{X}\}</code> denoting the observed data, <code class="reqn">P_\alpha(\boldsymbol\beta)</code> is the group elastic net penalty, and <code class="reqn">\lambda \geq 0</code> is the regularization parameter. 
</p>
<p>The loss function has the form 
</p>
<p style="text-align: center;"><code class="reqn">
L(\boldsymbol\beta | \mathbf{D}) = \frac{1}{n} \sum_{i=1}^n w_i \ell_i(\boldsymbol\beta | \mathbf{D}_i)
</code>
</p>

<p>where <code class="reqn">w_i &gt; 0</code> are the user-supplied <code>weights</code>, and <code class="reqn">\ell_i(\boldsymbol\beta | \mathbf{D}_i)</code> is the <code class="reqn">i</code>-th observation's contribution to the loss function. Note that <code class="reqn">\ell(\cdot) = -\log(f_Y(\cdot))</code> denotes the negative log-likelihood function for the given <code>family</code>.
</p>
<p>The group elastic net penalty function has the form
</p>
<p style="text-align: center;"><code class="reqn">
P_\alpha(\boldsymbol\beta) = \alpha P_1(\boldsymbol\beta) + (1 - \alpha) P_2(\boldsymbol\beta)
</code>
</p>

<p>where <code class="reqn">\alpha \in [0,1]</code> is the user-specified <code>alpha</code> value, 
</p>
<p style="text-align: center;"><code class="reqn">
P_1(\boldsymbol\beta) = \sum_{k=1}^K \omega_k \| \boldsymbol\beta_k \|
</code>
</p>

<p>is the group lasso penalty with <code class="reqn">\omega_k \geq 0</code> denoting the <code class="reqn">k</code>-th group's <code>penalty.factor</code>, and 
</p>
<p style="text-align: center;"><code class="reqn">
P_2(\boldsymbol\beta) = \frac{1}{2} \sum_{k=1}^K \omega_k \| \boldsymbol\beta_k \|^2
</code>
</p>

<p>is the group ridge penalty. Note that <code class="reqn">\| \boldsymbol\beta_k \|^2 = \boldsymbol\beta_k^\top \boldsymbol\beta_k</code> denotes the squared Euclidean norm. When <code>penalty %in% c("MCP", "SCAD")</code>, the group L1 penalty <code class="reqn">P_1(\boldsymbol\beta)</code> is replaced by the group MCP or group SCAD penalty.
</p>


<h3>Value</h3>

<p>An object of class <code>"grpnet"</code> with the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>matched call</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>intercept sequence of length <code>nlambda</code></p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>coefficient matrix of dimension <code>nvars</code> by <code>nlambda</code></p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>balance between the group L1 (lasso) and group L2 (ridge) penalty</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>sequence of regularization parameter values</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>exponential family defining the loss function</p>
</td></tr>
<tr><td><code>dev.ratio</code></td>
<td>
<p>proportion of (null) deviance explained for each <code>lambda</code> (= 1 - dev / nulldev)</p>
</td></tr>
<tr><td><code>nulldev</code></td>
<td>
<p>null deviance for each <code>lambda</code></p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>effective degrees of freedom for each <code>lambda</code></p>
</td></tr>
<tr><td><code>nzgrp</code></td>
<td>
<p>number of non-zero groups for each <code>lambda</code></p>
</td></tr>
<tr><td><code>nzcoef</code></td>
<td>
<p>number of non-zero coefficients for each <code>lambda</code></p>
</td></tr>
<tr><td><code>xsd</code></td>
<td>
<p>standard deviation of x for each group</p>
</td></tr>
<tr><td><code>ylev</code></td>
<td>
<p>levels of response variable (only for binomial and multinomial families)</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>group label vector</p>
</td></tr>
<tr><td><code>ngroups</code></td>
<td>
<p>number of groups <code class="reqn">K</code></p>
</td></tr>
<tr><td><code>npasses</code></td>
<td>
<p>number of iterations for each <code>lambda</code></p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>logical indicating if an offset was included</p>
</td></tr>
<tr><td><code>args</code></td>
<td>
<p>list of input argument values</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>input formula (possibly after expansion)</p>
</td></tr>
<tr><td><code>term.labels</code></td>
<td>
<p>terms that appear in formula (if applicable)</p>
</td></tr>
<tr><td><code>rk.args</code></td>
<td>
<p>arguments for rk.model.matrix function (if applicable)</p>
</td></tr>
</table>


<h3>S3 &quot;formula&quot; method</h3>

<p><b>Important</b>: When using the S3 &quot;formula&quot; method, the S3 &quot;predict&quot; method forms the model matrix for the predictions by applying the model formula to the new data. As a result, to ensure that the corresponding S3 &quot;predict&quot; method works correctly, some formulaic features should be avoided. 
</p>
<p><b>Polynomials</b>: When including polynomial terms, the <code><a href="stats.html#topic+poly">poly</a></code> function should be used with option <code>raw = TRUE</code>. Default use of the <code><a href="stats.html#topic+poly">poly</a></code> function (with <code>raw = FALSE</code>) will work for fitting the model, but will result in invalid predictions for new data. Polynomials can also be included via the <code><a href="base.html#topic+I">I</a></code> function, but this isn't recommended because the polynomials terms wouldn't be grouped together, i.e., the terms <code>x</code> and <code>I(x^2)</code> would be treated as two separate groups of size one instead of a single group of size two.
</p>
<p><b>Splines</b>: B-splines (and other spline bases) can be included via the S3 &quot;formula&quot; method. However, to ensure reasonable predictions for new data, it is necessary to specify the knots directly. For example, if <code>x</code> is a vector with entries between zero and one, the code <code>bs(x, df = 5)</code> will *not* produce valid predictions for new data, but the code <code>bs(x, knots = c(0.25, 0.5, 0.75), Boundary.knots = c(0, 1))</code> will work as intended. Instead of attempting to integrate a call to <code>bs()</code> or <code>rk()</code> into the model formula, it is recommended that splines be included via the <code>use.rk = TRUE</code> argument.
</p>


<h3>Family argument and link functions</h3>

<p>Unlike the <code><a href="stats.html#topic+glm">glm</a></code> function, the <code>family</code> argument of the <code><a href="#topic+grpnet">grpnet</a></code> function <br />
* should be a character vector (not a <code><a href="stats.html#topic+family">family</a></code> object) <br />
* does not allow for specification of a link function 
</p>
<p>Currently, there is only one available link function for each <code>family</code>: <br />
* gaussian (identity): <code class="reqn">\mu = \mathbf{X}^\top \boldsymbol\beta</code> <br />
* binomial (logit): <code class="reqn">\log(\frac{\pi}{1 - \pi}) = \mathbf{X}^\top \boldsymbol\beta</code> <br />
* multinomial (symmetric): <code class="reqn">\pi_\ell = \frac{\exp(\mathbf{X}^\top \boldsymbol\beta_\ell)}{\sum_{l = 1}^m \exp(\mathbf{X}^\top \boldsymbol\beta_l)}</code> <br />
* poisson (log): <code class="reqn">\log(\mu) = \mathbf{X}^\top \boldsymbol\beta</code> <br />
* negative.binomial (log): <code class="reqn">\log(\mu) = \mathbf{X}^\top \boldsymbol\beta</code> <br />
* Gamma (log): <code class="reqn">\log(\mu) = \mathbf{X}^\top \boldsymbol\beta</code> <br />
* inverse.gaussian (log): <code class="reqn">\log(\mu) = \mathbf{X}^\top \boldsymbol\beta</code> <br />
</p>


<h3>Binomial and multinomial</h3>

<p>For <code>"binomial"</code> responses, three different possibilities exist for the input response: <br />
1. vector coercible into a factor with two levels <br />
2. matrix with two columns (# successes, # failures) <br />
3. numeric vector with entries between 0 and 1 <br />
In this case, the <code>weights</code> argument should be used specify the total number of trials.
</p>
<p>For <code>"multinomial"</code> responses, two different possibilities exist for the input reponse: <br />
1. vector coercible into a factor with more than two levels <br /> 
2. matrix of integers (counts) for each category level <br />
</p>


<h3>Convergence</h3>

<p>The algorithm is determined to have converged once
</p>
<p><code class="reqn">\max_j \frac{| \beta_j - \beta_j^{\mathrm{old}} |}{1 + |\beta_j^{\mathrm{old}}|}  &lt; \epsilon </code>
</p>
<p>where <code class="reqn">j \in \{1,\ldots,p\}</code> and <code class="reqn">\epsilon</code> is the <code>thresh</code> argument. 
</p>


<h3>Note</h3>

<p>The syntax of (the default S3 method for) this function closely mimics that of the <code>glmnet</code> function in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010). 
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Breheny, P., &amp; Huang, J. (2015). Group descent algorithms for nonconvex penalized linear and logistic regression models with grouped predictors. <em>Statistics and Computing, 25</em>, 173-187. <a href="https://doi.org/10.1007/s11222-013-9424-2">doi:10.1007/s11222-013-9424-2</a>
</p>
<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>
<p>Yang, Y., &amp; Zou, H. (2015). A fast unified algorithm for solving group-lasso penalize learning problems. <em>Statistics and Computing, 25</em>, 1129-1141. <a href="https://doi.org/10.1007/s11222-014-9498-5">doi:10.1007/s11222-014-9498-5</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.grpnet">plot.grpnet</a></code> for plotting the regularization path
</p>
<p><code><a href="#topic+predict.grpnet">predict.grpnet</a></code> for predicting from <code><a href="#topic+grpnet">grpnet</a></code> objects
</p>
<p><code><a href="#topic+cv.grpnet">cv.grpnet</a></code> for k-fold cross-validation of <code>lambda</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   family = "gaussian"   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto)

# print regularization path info
mod

# plot coefficient paths
plot(mod)



######***######   family = "binomial"   ######***######

# load data
data(auto)

# define response (1 = American, 0 = other)
y &lt;- ifelse(auto$origin == "American", 1, 0)

# define predictors
x &lt;- rk.model.matrix(~ 0 + ., data = auto[,1:7])

# define group
g &lt;- attr(x, "assign")

# fit model (default method, response = y)
mod &lt;- grpnet(x, y, g, family = "binomial")

# print regularization path info
mod

# plot coefficient paths
plot(mod)



######***######   family = "poisson"   ######***######

# load data
data(auto)

# fit model (formula method, response = horsepower)
mod &lt;- grpnet(horsepower ~ ., data = auto, family = "poisson")

# print regularization path info
mod

# plot coefficient paths
plot(mod)



######***######   family = "negative.binomial"   ######***######

# load data
data(auto)

# fit model (formula method, response = horsepower)
mod &lt;- grpnet(horsepower ~ ., data = auto, family = "negative.binomial", theta = 100)

# print regularization path info
mod

# plot coefficient paths
plot(mod)



######***######   family = "multinomial"   ######***######

# load data
data(auto)

# fit model (formula method, response = origin)
mod &lt;- grpnet(origin ~ ., data = auto, family = "multinomial")

# print regularization path info
mod

# plot coefficient paths
plot(mod)



######***######   family = "Gamma"   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto, family = "Gamma")

# print regularization path info
mod

# plot coefficient paths
plot(mod)



######***######   family = "inverse.gaussian"   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto, family = "inverse.gaussian")

# print regularization path info
mod

# plot coefficient paths
plot(mod)

</code></pre>

<hr>
<h2 id='plot.cv.grpnet'>
Plot Cross-Validation Curve for cv.grpnet Fits
</h2><span id='topic+plot.cv.grpnet'></span>

<h3>Description</h3>

<p>Plots the mean cross-validation error, along with lower and upper standard deviation curves, as a function of <code>log(lambda)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpnet'
plot(x, sign.lambda = 1, nzero = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cv.grpnet_+3A_x">x</code></td>
<td>

<p>Object of class &quot;cv.grpnet&quot;
</p>
</td></tr>
<tr><td><code id="plot.cv.grpnet_+3A_sign.lambda">sign.lambda</code></td>
<td>

<p>Default plots <code>log(lambda)</code> on the x-axis. Set to -1 to plot <code>-1*log(lambda)</code> on the x-axis instead.
</p>
</td></tr>
<tr><td><code id="plot.cv.grpnet_+3A_nzero">nzero</code></td>
<td>

<p>Should the number of non-zero groups be printed on the top of the x-axis?
</p>
</td></tr>
<tr><td><code id="plot.cv.grpnet_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to the <code><a href="base.html#topic+plot">plot</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces cross-validation plot only (i.e., nothing is returned).
</p>


<h3>Value</h3>

<p>No return value (produces a plot)
</p>


<h3>Note</h3>

<p>Syntax and functionality were modeled after the <code>plot.cv.glmnet</code> function in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.grpnet">cv.grpnet</a></code> for k-fold cross-validation of <code>lambda</code>
</p>
<p><code><a href="#topic+plot.grpnet">plot.grpnet</a></code> for plotting the regularization path
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see 'cv.grpnet' for plotting examples
?cv.grpnet
</code></pre>

<hr>
<h2 id='plot.grpnet'>
Plot Coefficients for grpnet Fits
</h2><span id='topic+plot.grpnet'></span>

<h3>Description</h3>

<p>Creates a profile plot of the coefficient paths for a fit group elastic net regularized GLM (grpnet) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpnet'
plot(x, type = c("coef", "imp", "norm", "znorm"),
     newx, newdata, intercept = FALSE,
     color.by.group = TRUE, col = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.grpnet_+3A_x">x</code></td>
<td>

<p>Object of class &quot;grpnet&quot;
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_type">type</code></td>
<td>

<p>What to plot on the Y-axis: &quot;coef&quot; for coefficient values, &quot;imp&quot; for importance of each group's contribution, &quot;norm&quot; for L2 norm of coefficients for each group, or &quot;znorm&quot; for L2 norm of standardized coefficients for each group. 
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_newx">newx</code></td>
<td>

<p>Matrix of new <code>x</code> scores for prediction (default S3 method). Ignored unless <code>type = "imp"</code>.
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_newdata">newdata</code></td>
<td>

<p>Data frame of new <code>data</code> scores for prediction (S3 &quot;formula&quot; method). Ignored unless <code>type = "imp"</code>.
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_intercept">intercept</code></td>
<td>

<p>Should the intercept be included in the plot?  
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_color.by.group">color.by.group</code></td>
<td>

<p>If <code>TRUE</code> (default), the coefficient paths are colored according to their group membership using the colors in <code>col</code>. If <code>FALSE</code>, all coefficient paths are plotted the same color.
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_col">col</code></td>
<td>

<p>If <code>color.by.group = TRUE</code>, this should be a vector of length <code class="reqn">K</code> giving a color label for each group. If <code>color.by.group = FASLE</code>, this should be a character specifying a single (common) color. Default of <code>col = NULL</code> is the same as <code>col = 1:K</code> or <code>col = "black"</code>.
</p>
</td></tr>
<tr><td><code id="plot.grpnet_+3A_...">...</code></td>
<td>

<p>Additional arguments passed to the <code><a href="base.html#topic+plot">plot</a></code> function.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Syntax and functionality were modeled after the <code>plot.glmnet</code> function in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010).
</p>


<h3>Value</h3>

<p>Produces a profile plot showing the requested type (y-axis) as a function of <code>log(lambda)</code> (x-axis). 
</p>


<h3>Note</h3>

<p>If <code>x</code> is a multinomial model, the coefficients for each response class are plotted in a separate plot.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpnet">grpnet</a></code> for fitting grpnet regularization paths
</p>
<p><code><a href="#topic+plot.cv.grpnet">plot.cv.grpnet</a></code> for plotting <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see 'grpnet' for plotting examples
?grpnet
</code></pre>

<hr>
<h2 id='predict.cv.grpnet'>
Predict Method for cv.grpnet Fits
</h2><span id='topic+predict.cv.grpnet'></span>

<h3>Description</h3>

<p>Obtain predictions from a cross-validated group elastic net regularized GLM (cv.grpnet) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.grpnet'
predict(object, 
        newx,
        newdata,
        s = c("lambda.min", "lambda.1se"),
        type = c("link", "response", "class", "terms", 
                 "importance", "coefficients", "nonzero", "groups", 
                 "ncoefs", "ngroups", "norm", "znorm"),
        ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cv.grpnet_+3A_object">object</code></td>
<td>

<p>Object of class &quot;cv.grpnet&quot;
</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_newx">newx</code></td>
<td>

<p>Matrix of new <code>x</code> scores for prediction (default S3 method). Must have <code class="reqn">p</code> columns arranged in the same order as the <code>x</code> matrix used to fit the model.
</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_newdata">newdata</code></td>
<td>

<p>Data frame of new <code>data</code> scores for prediction (S3 &quot;formula&quot; method). Must contain all variables in the <code>formula</code> used to fit the model.
</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_s">s</code></td>
<td>

<p>Lambda value(s) at which predictions should be obtained. Can input a character (&quot;lambda.min&quot; or &quot;lambda.1se&quot;) or a numeric vector. Default of &quot;lambda.min&quot; uses the <code>lambda</code> value that minimizes the mean cross-validated error. 
</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_type">type</code></td>
<td>

<p>Type of prediction to return. &quot;link&quot; gives predictions on the link scale (<code class="reqn">\eta</code>). &quot;response&quot; gives predictions on the mean scale (<code class="reqn">\mu</code>). &quot;terms&quot; gives the predictions for each term (group) in the model (<code class="reqn">\eta_k</code>). &quot;class&quot; gives predicted class labels (for &quot;binomial&quot; and &quot;multinomial&quot; families). &quot;coefficients&quot; returns the coefficients used for predictions. &quot;nonzero&quot; returns a list giving the indices of non-zero coefficients for each <code>s</code>. &quot;ncoefs&quot; returns the number of non-zero coefficients for each <code>s</code>. &quot;ngroups&quot; returns the number of non-zero groups for each <code>s</code>. &quot;norm&quot; returns the L2 norm of each group's (raw) coefficients for each <code>s</code>. &quot;znorm&quot; returns the L2 norm of each group's standardized coefficients for each <code>s</code>.
</p>
</td></tr>
<tr><td><code id="predict.cv.grpnet_+3A_...">...</code></td>
<td>

<p>Additional arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions are calculated from the <code><a href="#topic+grpnet">grpnet</a></code> object fit to the full sample of data, which is stored as <code>object$grpnet.fit</code> 
</p>
<p>See <code><a href="#topic+predict.grpnet">predict.grpnet</a></code> for further details on the calculation of the different types of predictions.
</p>


<h3>Value</h3>

<p>Depends on three factors... <br />
1. the exponential family distribution <br />
2. the length of the input <code>s</code> <br />
3. the <code>type</code> of prediction requested
</p>
<p>See <code><a href="#topic+predict.grpnet">predict.grpnet</a></code> for details
</p>


<h3>Note</h3>

<p>Syntax is inspired by the <code>predict.cv.glmnet</code> function in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010). 
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.grpnet">cv.grpnet</a></code> for k-fold cross-validation of <code>lambda</code>
</p>
<p><code><a href="#topic+predict.grpnet">predict.grpnet</a></code> for predicting from <code><a href="#topic+grpnet">grpnet</a></code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   family = "gaussian"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = mpg)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, alpha = 1)

# get fitted values at "lambda.min"
fit.min &lt;- predict(mod, newdata = auto)

# get fitted values at "lambda.1se"
fit.1se &lt;- predict(mod, newdata = auto, s = "lambda.1se")

# compare rmse for two solutions
sqrt(mean((auto$mpg - fit.min)^2))
sqrt(mean((auto$mpg - fit.1se)^2))




######***######   family = "binomial"   ######***######

# load data
data(auto)

# define response (1 = American, 0 = other)
y &lt;- ifelse(auto$origin == "American", 1, 0)

# define predictors
x &lt;- rk.model.matrix(~ 0 + ., data = auto[,1:7])

# define group
g &lt;- attr(x, "assign")

# 10-fold cv (default method, response = y)
set.seed(1)
mod &lt;- cv.grpnet(x, y, g, family = "binomial", alpha = 1)

# get fitted values at "lambda.min"
fit.min &lt;- predict(mod, newx = x, type = "response")

# get fitted values at "lambda.1se"
fit.1se &lt;- predict(mod, newx = x, type = "response", s = "lambda.1se")

# compare rmse for two solutions
sqrt(mean((y - fit.min)^2))
sqrt(mean((y - fit.1se)^2))

# get predicted classes at "lambda.min"
fit.min &lt;- predict(mod, newx = x, type = "class")

# get predicted classes at "lambda.1se"
fit.1se &lt;- predict(mod, newx = x, type = "class", s = "lambda.1se")

# compare misclassification rate for two solutions
1 - mean(y == fit.min)
1 - mean(y == fit.1se)



######***######   family = "poisson"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = horsepower)
set.seed(1)
mod &lt;- cv.grpnet(horsepower ~ ., data = auto, family = "poisson", alpha = 1)

# get fitted values at "lambda.min"
fit.min &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at "lambda.1se"
fit.1se &lt;- predict(mod, newdata = auto, type = "response", s = "lambda.1se")

# compare rmse for two solutions
sqrt(mean((auto$horsepower - fit.min)^2))
sqrt(mean((auto$horsepower - fit.1se)^2))



######***######   family = "negative.binomial"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = horsepower)
set.seed(1)
mod &lt;- cv.grpnet(horsepower ~ ., data = auto, family = "negative.binomial", 
                 alpha = 1, theta = 100)

# get fitted values at "lambda.min"
fit.min &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at "lambda.1se"
fit.1se &lt;- predict(mod, newdata = auto, type = "response", s = "lambda.1se")

# compare rmse for two solutions
sqrt(mean((auto$horsepower - fit.min)^2))
sqrt(mean((auto$horsepower - fit.1se)^2))



######***######   family = "multinomial"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = origin)
set.seed(1)
mod &lt;- cv.grpnet(origin ~ ., data = auto, family = "multinomial", alpha = 1)

# get predicted classes at "lambda.min"
fit.min &lt;- predict(mod, newdata = auto, type = "class")

# get predicted classes at "lambda.1se"
fit.1se &lt;- predict(mod, newdata = auto, type = "class", s = "lambda.1se")

# compare misclassification rate for two solutions
1 - mean(auto$origin == fit.min)
1 - mean(auto$origin == fit.1se)



######***######   family = "Gamma"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = origin)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, family = "Gamma", alpha = 1)

# get fitted values at "lambda.min"
fit.min &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at "lambda.1se"
fit.1se &lt;- predict(mod, newdata = auto, type = "response", s = "lambda.1se")

# compare rmse for two solutions
sqrt(mean((auto$mpg - fit.min)^2))
sqrt(mean((auto$mpg - fit.1se)^2))



######***######   family = "inverse.gaussian"   ######***######

# load data
data(auto)

# 10-fold cv (formula method, response = origin)
set.seed(1)
mod &lt;- cv.grpnet(mpg ~ ., data = auto, family = "inverse.gaussian", alpha = 1)

# get fitted values at "lambda.min"
fit.min &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at "lambda.1se"
fit.1se &lt;- predict(mod, newdata = auto, type = "response", s = "lambda.1se")

# compare rmse for two solutions
sqrt(mean((auto$mpg - fit.min)^2))
sqrt(mean((auto$mpg - fit.1se)^2))

</code></pre>

<hr>
<h2 id='predict.grpnet'>
Predict Method for grpnet Fits
</h2><span id='topic+predict.grpnet'></span>

<h3>Description</h3>

<p>Obtain predictions from a fit group elastic net regularized GLM (grpnet) object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'grpnet'
predict(object, 
        newx,
        newdata,
        s = NULL,
        type = c("link", "response", "class", "terms", 
                 "importance", "coefficients", "nonzero", "groups", 
                 "ncoefs", "ngroups", "norm", "znorm"),
        ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.grpnet_+3A_object">object</code></td>
<td>

<p>Object of class &quot;grpnet&quot;
</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_newx">newx</code></td>
<td>

<p>Matrix of new <code>x</code> scores for prediction (default S3 method). Must have <code class="reqn">p</code> columns arranged in the same order as the <code>x</code> matrix used to fit the model. Ignored for the last six types of predictions.
</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_newdata">newdata</code></td>
<td>

<p>Data frame of new <code>data</code> scores for prediction (S3 &quot;formula&quot; method). Must contain all variables in the <code>formula</code> used to fit the model. Ignored for the last six types of predictions.
</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_s">s</code></td>
<td>

<p>Lambda value(s) at which predictions should be obtained. Default uses <code>s = object$lambda</code>. Interpolation is used for <code>s</code> values that are not included in <code>object$lambda</code>.  
</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_type">type</code></td>
<td>

<p>Type of prediction to return. &quot;link&quot; gives predictions on the link scale (<code class="reqn">\eta</code>). &quot;response&quot; gives predictions on the mean scale (<code class="reqn">\mu</code>). &quot;class&quot; gives predicted class labels (for &quot;binomial&quot; and &quot;multinomial&quot; families). &quot;terms&quot; gives the predictions for each term (group) in the model (<code class="reqn">\eta_k</code>). &quot;importance&quot; gives the variable importance index for each term (group) in the model. &quot;coefficients&quot; returns the coefficients used for predictions. &quot;nonzero&quot; returns a list giving the indices of non-zero coefficients for each <code>s</code>. &quot;groups&quot; returns a list giving the labels of non-zero groups for each <code>s</code>. &quot;ncoefs&quot; returns the number of non-zero coefficients for each <code>s</code>. &quot;ngroups&quot; returns the number of non-zero groups for each <code>s</code>. &quot;norm&quot; returns the L2 norm of each group's (raw) coefficients for each <code>s</code>. &quot;znorm&quot; returns the L2 norm of each group's standardized coefficients for each <code>s</code>.
</p>
</td></tr>
<tr><td><code id="predict.grpnet_+3A_...">...</code></td>
<td>

<p>Additional arguments (ignored)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When <code>type == "link"</code>, the predictions for each <code class="reqn">\lambda</code> have the form
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol\eta_\lambda = \mathbf{X}_{\mathrm{new}} \boldsymbol\beta_\lambda</code>
</p>

<p>where <code class="reqn">\mathbf{X}_{\mathrm{new}}</code> is the argument <code>newx</code> (or the design matrix created from <code>newdata</code> by applying <code>object$formula</code>) and <code class="reqn">\boldsymbol\beta_\lambda</code> is the coefficient vector corresponding to <code class="reqn">\lambda</code>.
</p>
<p>When <code>type == "response"</code>, the predictions for each <code class="reqn">\lambda</code> have the form
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol\mu_\lambda = g^{-1}(\boldsymbol\eta_\lambda) </code>
</p>

<p>where <code class="reqn">g^{-1}(\cdot)</code> is the inverse link function stored in <code>object$family$linkinv</code>.
</p>
<p>When <code>type == "class"</code>, the predictions for each <code class="reqn">\lambda</code> have the form
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{y}_\lambda = \arg\max_l \boldsymbol\mu_\lambda(l) </code>
</p>

<p>where <code class="reqn">\boldsymbol\mu_\lambda(l)</code> gives the predicted probability that each observation belongs to the <code class="reqn">l</code>-th category (for <code class="reqn">l = 1,\ldots,m</code>) using the regularization parameter <code class="reqn">\lambda</code>. 
</p>
<p>When <code>type == "terms"</code>, the groupwise predictions for each <code class="reqn">\lambda</code> have the form
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol\eta_{k\lambda} = \mathbf{X}_k^{\mathrm{(new)}} \boldsymbol\beta_{k\lambda}</code>
</p>
<p> where <code class="reqn">\mathbf{X}_k^{\mathrm{(new)}}</code> is the portion of the argument <code>newx</code> (or the design matrix created from <code>newdata</code> by applying <code>object$formula</code>) that corresponds to the <code class="reqn">k</code>-th term/group, and <code class="reqn">\boldsymbol\beta_{k\lambda}</code> are the corresponding coefficients.
</p>
<p>When <code>type == "importance"</code>, the variable importance indices are defined as 
</p>
<p style="text-align: center;"><code class="reqn">\pi_k = \left( \boldsymbol\eta_{k\lambda}^\top \mathbf{C} \boldsymbol\eta_{0\lambda} \right) \left( \boldsymbol\eta_{0\lambda}^\top \mathbf{C} \boldsymbol\eta_{0\lambda} \right)^{-1}</code>
</p>

<p>where <code class="reqn">\mathbf{C} = (\mathbf{I}_n - \frac{1}{n} \mathbf{1}_n \mathbf{1}_n^\top)</code> denotes a centering matrix, and <code class="reqn">\boldsymbol\eta_{0\lambda} = \sum_{k=1}^K \boldsymbol\eta_{k\lambda}</code>. Note that <code class="reqn">\sum_{k=1}^K \pi_k = 1</code>, but some <code class="reqn">\pi_k</code> could be negative. When they are positive, <code class="reqn">\pi_k</code> gives the approximate proportion of model (explained) variation that is attributed to the <code class="reqn">k</code>-th term.
</p>


<h3>Value</h3>

<p>Depends on three factors... <br />
1. the exponential family distribution <br />
2. the length of the input <code>s</code> <br />
3. the <code>type</code> of prediction requested
</p>
<p>For most response variables, the typical output will be...
</p>
<table>
<tr><td><code>*</code></td>
<td>
<p>a matrix of dimension <code>c(newnobs, length(s))</code> if <code>length(s) &gt; 1</code></p>
</td></tr>
<tr><td><code>*</code></td>
<td>
<p>a vector of length <code>newnobs</code> if length(s) == 1</p>
</td></tr>
</table>
<p>For multinomial response variables, the typical output will be... 
</p>
<table>
<tr><td><code>*</code></td>
<td>
<p>an array of dimension <code>c(newnobs, length(object$ylev), length(s))</code> if <code>type %in% c("link", "response")</code></p>
</td></tr>
<tr><td><code>*</code></td>
<td>
<p>a matrix of dimension <code>c(newobs, length(s))</code> if <code>type == "class"</code></p>
</td></tr>
</table>
<p>Note: if <code>type == "class"</code>, then the output will be the same class as <code>object$ylev</code>. Otherwise, the output will be real-valued (or integer for the counts).
</p>
<p>If <code>type == "terms"</code> and <code>family != "multinomial"</code>, the output will be...
</p>
<table>
<tr><td><code>*</code></td>
<td>
<p>an array of dimension <code>c(newnobs, nterms, length(s))</code> if <code>length(s) &gt; 1</code></p>
</td></tr>
<tr><td><code>*</code></td>
<td>
<p>a matrix of dimension <code>c(newnobs, nterms)</code> if <code>length(s) == 1</code></p>
</td></tr>
</table>
<p>If <code>type == "terms"</code> and <code>family == "multinomial"</code>, the output will be a list of length <code>length(object$ylev)</code> where each element gives the terms for the corresponding response class.
</p>
<p>If <code>type == "importance"</code> and <code>family != "multinomial"</code>, the output will be...
</p>
<table>
<tr><td><code>*</code></td>
<td>
<p>a matrix of dimension <code>c(nterms, length(s))</code> if <code>length(s) &gt; 1</code></p>
</td></tr>
<tr><td><code>*</code></td>
<td>
<p>a vector of length <code>nterms</code> if <code>length(s) == 1</code></p>
</td></tr>
</table>
<p>If <code>type == "importance"</code> and <code>family == "multinomial"</code>, the output will be a list of length <code>length(object$ylev)</code> where each element gives the importance for the corresponding response class. If <code>length(s) == 1</code>, the output will be simplified to matrix.
</p>
<p>If <code>type == "coefficients"</code>, the output will be the same as that produced by <code><a href="#topic+coef.grpnet">coef.grpnet</a></code>.
</p>
<p>If <code>type == "nonzero"</code>, the output will be a list of length <code>length(s)</code> where each element is a vector of integers (indices).
</p>
<p>If <code>type == "groups"</code>, the output will be a list of length <code>length(s)</code> where each element is a vector of characters (<code>term.labels</code>).
</p>
<p>If <code>type %in% c("ncoefs", "ngroups")</code>, the output will be a vector of length <code>length(s)</code> where each element is an integer.
</p>
<p>If <code>type == "norm"</code>, the output will be a matrix of dimension <code>c(K, length(s))</code>, where each cell gives the L2 norm for the corresponding group and smoothing parameter. Note that <code>K</code> denotes the number of groups.
</p>


<h3>Note</h3>

<p>Some internal code (e.g., used for the interpolation) is borrowed from the <code>predict.glmnet</code> function in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+grpnet">grpnet</a></code> for fitting grpnet regularization paths
</p>
<p><code><a href="#topic+predict.cv.grpnet">predict.cv.grpnet</a></code> for predicting from <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######***######   family = "gaussian"   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto)

# get fitted values for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newdata = auto)

# get fitted values at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newdata = auto, s = c(1.5, 1, 0.5))

# compare rmse for solutions
rmse.path &lt;- sqrt(colMeans((auto$mpg - fit.path)^2))
rmse.some &lt;- sqrt(colMeans((auto$mpg - fit.some)^2))
plot(log(mod$lambda), rmse.path, cex = 0.5)
points(log(c(1.5, 1, 0.5)), rmse.some, pch = 0, col = "red")



######***######   family = "binomial"   ######***######

# load data
data(auto)

# define response (1 = American, 0 = other)
y &lt;- ifelse(auto$origin == "American", 1, 0)

# define predictors
x &lt;- model.matrix(~ ., data = auto[,1:7])[,-1]

# define group (according to colnames(x))
g &lt;- c(1, 2, 2, 2, 2, 3, 4, 5, 6, 7)

# fit model (default method, response = y)
mod &lt;- grpnet(x, y, g, family = "binomial")

# get predicted classes for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newx = x, type = "class")

# get predicted classes at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newx = x, type = "class", s = c(.15, .1, .05))

# compare misclassification rate for solutions
miss.path &lt;- 1 - colMeans(y == fit.path)
miss.some &lt;- 1 - colMeans(y == fit.some)
plot(log(mod$lambda), miss.path, cex = 0.5)
points(log(c(.15, .1, .05)), miss.some, pch = 0, col = "red")



######***######   family = "poisson"   ######***######

# load data
data(auto)

# fit model (formula method, response = horsepower)
mod &lt;- grpnet(horsepower ~ ., data = auto, family = "poisson")

# get fitted values for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newdata = auto, type = "response", s = c(15, 10, 5))

# compare rmse for solutions
rmse.path &lt;- sqrt(colMeans((auto$horsepower - fit.path)^2))
rmse.some &lt;- sqrt(colMeans((auto$horsepower - fit.some)^2))
plot(log(mod$lambda), rmse.path, cex = 0.5)
points(log(c(15, 10, 5)), rmse.some, pch = 0, col = "red")



######***######   family = "negative.binomial"   ######***######

# load data
data(auto)

# fit model (formula method, response = horsepower)
mod &lt;- grpnet(horsepower ~ ., data = auto, family = "negative.binomial", theta = 100)

# get fitted values for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newdata = auto, type = "response", s = c(15, 10, 5))

# compare rmse for solutions
rmse.path &lt;- sqrt(colMeans((auto$horsepower - fit.path)^2))
rmse.some &lt;- sqrt(colMeans((auto$horsepower - fit.some)^2))
plot(log(mod$lambda), rmse.path, cex = 0.5)
points(log(c(15, 10, 5)), rmse.some, pch = 0, col = "red")



######***######   family = "multinomial"   ######***######

# load data
data(auto)

# fit model (formula method, response = origin)
mod &lt;- grpnet(origin ~ ., data = auto, family = "multinomial")

# get predicted classes for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newdata = auto, type = "class")

# get predicted classes at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newdata = auto, type = "class", s = c(.1, .01, .001))

# compare misclassification rate for solutions
miss.path &lt;- 1 - colMeans(auto$origin == fit.path)
miss.some &lt;- 1 - colMeans(auto$origin == fit.some)
plot(log(mod$lambda), miss.path, cex = 0.5)
points(log(c(.1, .01, .001)), miss.some, pch = 0, col = "red")



######***######   family = "Gamma"   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto, family = "Gamma")

# get fitted values for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newdata = auto, type = "response", s = c(0.2, 0.1, 0.05))

# compare rmse for solutions
rmse.path &lt;- sqrt(colMeans((auto$mpg - fit.path)^2))
rmse.some &lt;- sqrt(colMeans((auto$mpg - fit.some)^2))
plot(log(mod$lambda), rmse.path, cex = 0.5)
points(log(c(0.2, 0.1, 0.05)), rmse.some, pch = 0, col = "red")



######***######   family = "inverse.gaussian"   ######***######

# load data
data(auto)

# fit model (formula method, response = mpg)
mod &lt;- grpnet(mpg ~ ., data = auto, family = "inverse.gaussian")

# get fitted values for regularization path (output = 392 x 100 matrix)
fit.path &lt;- predict(mod, newdata = auto, type = "response")

# get fitted values at 3 particular points (output = 392 x 3 matrix)
fit.some &lt;- predict(mod, newdata = auto, type = "response", s = c(0.2, 0.1, 0.05))

# compare rmse for solutions
rmse.path &lt;- sqrt(colMeans((auto$mpg - fit.path)^2))
rmse.some &lt;- sqrt(colMeans((auto$mpg - fit.some)^2))
plot(log(mod$lambda), rmse.path, cex = 0.5)
points(log(c(0.2, 0.1, 0.05)), rmse.some, pch = 0, col = "red")

</code></pre>

<hr>
<h2 id='print'>
S3 'print' Methods for grpnet
</h2><span id='topic+print.coef.grpnet'></span><span id='topic+print.cv.grpnet'></span><span id='topic+print.grpnet'></span>

<h3>Description</h3>

<p>Prints some basic information about the coefficients (for <code><a href="#topic+coef.grpnet">coef.grpnet</a></code> objects), observed cross-validation error (for <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> objects), or the computed regularization path (for <code><a href="#topic+grpnet">grpnet</a></code> objects). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'coef.grpnet'
print(x, ...)

## S3 method for class 'cv.grpnet'
print(x, digits = max(3, getOption("digits") - 3), ...)

## S3 method for class 'grpnet'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_+3A_x">x</code></td>
<td>

<p>an object of class <code><a href="#topic+coef.grpnet">coef.grpnet</a></code>, <code><a href="#topic+cv.grpnet">cv.grpnet</a></code>, or <code><a href="#topic+grpnet">grpnet</a></code>
</p>
</td></tr>
<tr><td><code id="print_+3A_digits">digits</code></td>
<td>

<p>the number of digits to print (must be a positive integer)  
</p>
</td></tr>
<tr><td><code id="print_+3A_...">...</code></td>
<td>

<p>additional arguments for <code><a href="base.html#topic+print">print</a></code> (currently ignored)  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code><a href="#topic+coef.grpnet">coef.grpnet</a></code> objects, prints the non-zero coefficients and uses &quot;.&quot; for coefficients shrunk to zero.
</p>
<p>For <code><a href="#topic+cv.grpnet">cv.grpnet</a></code> objects, prints the function <code>call</code>, the cross-validation <code>type.measure</code>, and a two-row table with information about the <code>min</code> and <code>1se</code> solutions.
</p>
<p>For <code><a href="#topic+grpnet">grpnet</a></code> objects, prints a data frame with columns <br />
* nGrp: number of non-zero groups for each <code>lambda</code> <br />
* Df: effective degrees of freedom for each <code>lambda</code> <br />
* %Dev: percentage of null deviance explained for each <code>lambda</code> <br />
* Lambda: the values of <code>lambda</code> <br />
</p>


<h3>Value</h3>

<p>No return value (produces a printout)
</p>


<h3>Note</h3>

<p>Some syntax and functionality were modeled after the <code>print</code> functions in the <b>glmnet</b> package (Friedman, Hastie, &amp; Tibshirani, 2010).
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Friedman, J.,  Hastie, T., &amp; Tibshirani, R. (2010). Regularization paths for generalized linear models via coordinate descent. <em>Journal of Statistical Software, 33</em>(1), 1-22. <a href="https://doi.org/10.18637/jss.v033.i01">doi:10.18637/jss.v033.i01</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.grpnet">coef.grpnet</a></code> for extracting coefficients
</p>
<p><code><a href="#topic+cv.grpnet">cv.grpnet</a></code> for k-fold cross-validation of <code>lambda</code>
</p>
<p><code><a href="#topic+grpnet">grpnet</a></code> for fitting grpnet regularization paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see 'coef.grpnet' for coefficient printing examples
?coef.grpnet

# see 'cv.grpnet' for cross-validation error printing examples
?cv.grpnet

# see 'grpnet' for regularization path printing examples
?grpnet
</code></pre>

<hr>
<h2 id='rk'>
Reproducing Kernel Basis
</h2><span id='topic+rk'></span>

<h3>Description</h3>

<p>Generate a reproducing kernel basis matrix for a nominal, ordinal, or polynomial smoothing spline.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rk(x, df = NULL, knots = NULL, m = NULL, intercept = FALSE, 
   Boundary.knots = NULL, warn.outside = TRUE, 
   periodic = FALSE, xlev = levels(x))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rk_+3A_x">x</code></td>
<td>

<p>the predictor vector of length <code>n</code>. Can be a factor, integer, or numeric, see Note.
</p>
</td></tr>
<tr><td><code id="rk_+3A_df">df</code></td>
<td>

<p>the degrees of freedom, i.e., number of knots to place at quantiles of <code>x</code>. Defaults to 5 but ignored if <code>knots</code> are provided.
</p>
</td></tr>
<tr><td><code id="rk_+3A_knots">knots</code></td>
<td>

<p>the breakpoints (knots) defining the spline. If <code>knots</code> are provided, the <code>df</code> is defined as <code>length(unique(c(knots, Boundary.knots)))</code>.
</p>
</td></tr>
<tr><td><code id="rk_+3A_m">m</code></td>
<td>

<p>the derivative penalty order: 0 = ordinal spline, 1 = linear spline, 2 = cubic spline, 3 = quintic spline
</p>
</td></tr>
<tr><td><code id="rk_+3A_intercept">intercept</code></td>
<td>

<p>should an intercept be included in the basis?  
</p>
</td></tr>
<tr><td><code id="rk_+3A_boundary.knots">Boundary.knots</code></td>
<td>

<p>the boundary points for spline basis. Defaults to <code>range(x)</code>.
</p>
</td></tr>
<tr><td><code id="rk_+3A_warn.outside">warn.outside</code></td>
<td>

<p>if <code>TRUE</code>, a warning is provided when <code>x</code> values are outside of the <code>Boundary.knots</code>
</p>
</td></tr>
<tr><td><code id="rk_+3A_periodic">periodic</code></td>
<td>

<p>should the spline basis functions be constrained to be periodic with respect to the <code>Boundary.knots</code>?
</p>
</td></tr>
<tr><td><code id="rk_+3A_xlev">xlev</code></td>
<td>

<p>levels of <code>x</code> (only applicable if <code>x</code> is a <code><a href="base.html#topic+factor">factor</a></code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a vector of function realizations <code class="reqn">f</code>, suppose that <code class="reqn">f = X \beta</code>, where <code class="reqn">X</code> is the (unregularized) spline basis and <code class="reqn">\beta</code> is the coefficient vector. Let <code class="reqn">Q</code> denote the postive semi-definite penalty matrix, such that <code class="reqn">\beta^\top Q \beta</code> defines the roughness penalty for the spline. See Helwig (2017) for the form of <code class="reqn">X</code> and <code class="reqn">Q</code> for the various types of splines.
</p>
<p>Consider the spectral parameterization of the form <code class="reqn">f = Z \alpha</code> where
</p>
<p style="text-align: center;"><code class="reqn">Z = X Q^{-1/2}</code>
</p>

<p>is the regularized spline basis (that is returned by this function), and <code class="reqn">\alpha = Q^{1/2} \beta</code> are the reparameterized coefficients. Note that <code class="reqn">X \beta = Z \alpha</code> and <code class="reqn">\beta^\top Q \beta = \alpha^\top \alpha</code>, so the spectral parameterization absorbs the penalty into the coefficients (see Helwig, 2021, 2024).
</p>
<p>Syntax of this function is designed to mimic the syntax of the <code><a href="splines.html#topic+bs">bs</a></code> function.
</p>


<h3>Value</h3>

<p>Returns a basis function matrix of dimension <code>n</code> by <code>df</code> (plus 1 if an <code>intercept</code> is included) with the following attributes:
</p>
<table>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>knots for spline basis</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>derivative penalty order</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>was an intercept included?</p>
</td></tr>
<tr><td><code>Boundary.knots</code></td>
<td>
<p>boundary points of <code>x</code></p>
</td></tr>
<tr><td><code>periodic</code></td>
<td>
<p>is the basis periodic?</p>
</td></tr>
<tr><td><code>xlev</code></td>
<td>
<p>factor levels (if applicable)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The (default) type of spline basis depends on the <code><a href="base.html#topic+class">class</a></code> of the input <code>x</code> object:
</p>
<p>* If <code>x</code> is an unordered factor, then a nominal spline basis is used
</p>
<p>* If <code>x</code> is an ordered factor (and <code>m = NULL</code>), then an ordinal spline basis is used
</p>
<p>* If <code>x</code> is an integer or numeric (and <code>m = NULL</code>), then a cubic spline basis is used
</p>
<p>Note that you can override the default behavior by specifying the <code>m</code> argument.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (2017). Regression with ordered predictors via ordinal smoothing splines. Frontiers in Applied Mathematics and Statistics, 3(15), 1-13. <a href="https://doi.org/10.3389/fams.2017.00015">doi:10.3389/fams.2017.00015</a>
</p>
<p>Helwig, N. E. (2021). Spectrally sparse nonparametric regression via elastic net regularized smoothers. Journal of Computational and Graphical Statistics, 30(1), 182-191. <a href="https://doi.org/10.1080/10618600.2020.1806855">doi:10.1080/10618600.2020.1806855</a>
</p>
<p>Helwig, N. E. (2024). Precise tensor product smoothing via spectral splines. Stats, 7(1), 34-53. <a href="https://doi.org/10.3390/stats7010003">doi:10.3390/stats7010003</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
######***######   NOMINAL SPLINE BASIS   ######***######

x &lt;- as.factor(LETTERS[1:5])
basis &lt;- rk(x)
plot(1:5, basis[,1], t = "l", ylim = extendrange(basis))
for(j in 2:ncol(basis)){
  lines(1:5, basis[,j], col = j)
}


######***######   ORDINAL SPLINE BASIS   ######***######

x &lt;- as.ordered(LETTERS[1:5])
basis &lt;- rk(x)
plot(1:5, basis[,1], t = "l", ylim = extendrange(basis))
for(j in 2:ncol(basis)){
  lines(1:5, basis[,j], col = j)
}


######***######   LINEAR SPLINE BASIS   ######***######

x &lt;- seq(0, 1, length.out = 101)
basis &lt;- rk(x, m = 1)
plot(x, basis[,1], t = "l", ylim = extendrange(basis))
for(j in 2:ncol(basis)){
  lines(x, basis[,j], col = j)
}


######***######   CUBIC SPLINE BASIS   ######***######

x &lt;- seq(0, 1, length.out = 101)
basis &lt;- rk(x)
basis &lt;- scale(basis)  # for visualization only!
plot(x, basis[,1], t = "l", ylim = extendrange(basis))
for(j in 2:ncol(basis)){
  lines(x, basis[,j], col = j)
}


######***######   QUINTIC SPLINE BASIS   ######***######

x &lt;- seq(0, 1, length.out = 101)
basis &lt;- rk(x, m = 3)
basis &lt;- scale(basis)  # for visualization only!
plot(x, basis[,1], t = "l", ylim = extendrange(basis))
for(j in 2:ncol(basis)){
  lines(x, basis[,j], col = j)
}

</code></pre>

<hr>
<h2 id='rk.model.matrix'>
Construct Design Matrices via Reproducing Kernels
</h2><span id='topic+rk.model.matrix'></span>

<h3>Description</h3>

<p>Creates a design (or model) matrix using the <code><a href="#topic+rk">rk</a></code> function to expand variables via a reproducing kernel basis. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rk.model.matrix(object, data = environment(object), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rk.model.matrix_+3A_object">object</code></td>
<td>

<p>a <code><a href="stats.html#topic+formula">formula</a></code> or <code><a href="stats.html#topic+terms">terms</a></code> object describing the fit model
</p>
</td></tr>
<tr><td><code id="rk.model.matrix_+3A_data">data</code></td>
<td>

<p>a data frame containing the variables referenced in <code>object</code>
</p>
</td></tr>
<tr><td><code id="rk.model.matrix_+3A_...">...</code></td>
<td>

<p>additional arguments passed to the <code><a href="#topic+rk">rk</a></code> function, e.g., <code>df</code>, <code>knots</code>, <code>m</code>, etc. Arguments must be passed as a named list, see Examples.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Designed to be a more flexible alternative to the <code><a href="stats.html#topic+model.matrix">model.matrix</a></code> function. The <code><a href="#topic+rk">rk</a></code> function is used to construct a marginal basis for each variable that appears in the input <code>object</code>. Tensor product interactions are formed by taking a <code><a href="#topic+row.kronecker">row.kronecker</a></code> product of marginal basis matrices. Interactions of any order are supported using standard formulaic conventions, see Note.
</p>


<h3>Value</h3>

<p>The design matrix corresponding to the input formula and data, which has the following attributes:
</p>
<table>
<tr><td><code>assign</code></td>
<td>
<p>an integer vector with an entry for each column in the matrix giving the term in the formula which gave rise to the column</p>
</td></tr>
<tr><td><code>term.labels</code></td>
<td>
<p>a character vector containing the labels for each of the terms in the model</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>a named list giving the knots used for each variable in the formula</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>a named list giving the penalty order used for each variable in the formula</p>
</td></tr>
<tr><td><code>periodic</code></td>
<td>
<p>a named list giving the periodicity used for each variable in the formula</p>
</td></tr>
<tr><td><code>xlev</code></td>
<td>
<p>a named list giving the factor levels used for each variable in the formula</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For formulas of the form <code>y ~ x + z</code>, the constructed model matrix has the form <code>cbind(rk(x), rk(z))</code>, which simply concatenates the two marginal basis matrices. For formulas of the form <code>y ~ x : z</code>, the constructed model matrix has the form <code>row.kronecker(rk(x), rk(z))</code>, where <code><a href="#topic+row.kronecker">row.kronecker</a></code> denotes the row-wise kronecker product. The formula <code>y ~ x * z</code> is a shorthand for <code>y ~ x + z + x : z</code>, which concatenates the two previous results. Unless it is suppressed (using <code>0+</code>), the first column of the basis will be a column of ones named <code>(Intercept)</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Helwig, N. E. (2017). Regression with ordered predictors via ordinal smoothing splines. Frontiers in Applied Mathematics and Statistics, 3(15), 1-13. <a href="https://doi.org/10.3389/fams.2017.00015">doi:10.3389/fams.2017.00015</a>
</p>
<p>Helwig, N. E. (2021). Spectrally sparse nonparametric regression via elastic net regularized smoothers. Journal of Computational and Graphical Statistics, 30(1), 182-191. <a href="https://doi.org/10.1080/10618600.2020.1806855">doi:10.1080/10618600.2020.1806855</a>
</p>
<p>Helwig, N. E. (2024). Precise tensor product smoothing via spectral splines. Stats, 7(1), 34-53. <a href="https://doi.org/10.3390/stats7010003">doi:10.3390/stats7010003</a>
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+rk">rk</a></code> for details on the reproducing kernel basis
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load auto data
data(auto)

# additive effects
x &lt;- rk.model.matrix(mpg ~ ., data = auto)
dim(x)                      # check dimensions
attr(x, "assign")           # check group assignments
attr(x, "term.labels")      # check term labels

# two-way interactions
x &lt;- rk.model.matrix(mpg ~ . * ., data = auto)
dim(x)                      # check dimensions
attr(x, "assign")           # check group assignments
attr(x, "term.labels")      # check term labels

# specify df for horsepower, weight, and acceleration
# note: default df = 5 is used for displacement and model.year
df &lt;- list(horsepower = 6, weight = 7, acceleration = 8)
x &lt;- rk.model.matrix(mpg ~ ., data = auto, df = df)
sapply(attr(x, "knots"), length)   # check df

# specify knots for model.year
# note: default knots are selected for other variables
knots &lt;- list(model.year = c(1970, 1974, 1978, 1982))
x &lt;- rk.model.matrix(mpg ~ ., data = auto, knots = knots)
sapply(attr(x, "knots"), length)   # check df

</code></pre>

<hr>
<h2 id='row.kronecker'>
Row-Wise Kronecker Product
</h2><span id='topic+row.kronecker'></span>

<h3>Description</h3>

<p>Calculates the row-wise Kronecker product between two matrices with the same number of rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>row.kronecker(X, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="row.kronecker_+3A_x">X</code></td>
<td>

<p>matrix of dimension <code class="reqn">n \times p</code>
</p>
</td></tr>
<tr><td><code id="row.kronecker_+3A_y">Y</code></td>
<td>

<p>matrix of dimension <code class="reqn">n \times q</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given <code>X</code> of dimension <code>c(n, p)</code> and <code>Y</code> of dimension <code>c(n, q)</code>, this function returns
</p>
<p><code>cbind(x[,1] * Y, x[,2] * Y, ..., x[,p] * Y)</code>
</p>
<p>which is a matrix of dimension <code>c(n, p*q)</code>
</p>


<h3>Value</h3>

<p>Matrix of dimension <code class="reqn">n \times pq</code> where each row contains the Kronecker product between the corresponding rows of <code>X</code> and <code>Y</code>.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>See Also</h3>

<p>Used by the <code><a href="#topic+rk.model.matrix">rk.model.matrix</a></code> to construct basis functions for interaction terms
</p>
<p>See <code><a href="base.html#topic+kronecker">kronecker</a></code> for the regular kronecker product
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(c(1, 1, 2, 2), nrow = 2, ncol = 2)
Y &lt;- matrix(1:6, nrow = 2, ncol = 3)
row.kronecker(X, Y)
</code></pre>

<hr>
<h2 id='StartupMessage'>Startup Message for grpnet</h2><span id='topic+StartupMessage'></span><span id='topic+grpnetStartupMessage'></span>

<h3>Description</h3>

<p>Prints the startup message when grpnet is loaded. Not intended to be called by the user.
</p>


<h3>Details</h3>

<p>The &lsquo;grpnet&rsquo; ascii start-up message was created using the taag software.
</p>


<h3>References</h3>

<p>https://patorjk.com/software/taag/
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
