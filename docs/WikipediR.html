<!DOCTYPE html><html><head><title>Help for package WikipediR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {WikipediR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#WikipediR'><p>A client library for MediaWiki's API</p></a></li>
<li><a href='#categories_in_page'><p>Retrieves categories associated with a page.</p></a></li>
<li><a href='#create_page'><p>wikimedia api page creation (single pages)</p>
</p>
<p>helper function to do the actual api requests for page</p>
and category-page creation</a></li>
<li><a href='#create_pages'><p>wikimedia api page creation</p>
</p>
<p>Create pages or category-pages on a wikimedia instance.</p></a></li>
<li><a href='#get_action_token'><p>request token for api action as signed in user</p></a></li>
<li><a href='#get_prelogin_token'><p>request token to start client login</p></a></li>
<li><a href='#login'><p>wikimedia api user login</p></a></li>
<li><a href='#page_backlinks'><p>Retrieve a page's backlinks</p></a></li>
<li><a href='#page_content'><p>Retrieves MediaWiki page content</p></a></li>
<li><a href='#page_external_links'><p>Retrieve a page's links</p></a></li>
<li><a href='#page_info'><p>Retrieve information about a particular page</p></a></li>
<li><a href='#page_links'><p>Retrieve a page's links</p></a></li>
<li><a href='#pages_in_category'><p>Retrieves a list of category members.</p></a></li>
<li><a href='#parse_response'><p>parse_response: Parse WikipediR responses internally</p></a></li>
<li><a href='#query'><p>base query function</p></a></li>
<li><a href='#random_page'><p>Retrieve the page content of a random MediaWiki page</p></a></li>
<li><a href='#recent_changes'><p>Retrieves entries from the RecentChanges feed</p></a></li>
<li><a href='#revision_content'><p>Retrieves MediaWiki revisions</p></a></li>
<li><a href='#revision_diff'><p>Generates a &quot;diff&quot; between a pair of revisions</p></a></li>
<li><a href='#user_contributions'><p>Retrieve user contributions</p></a></li>
<li><a href='#user_information'><p>Retrieve user information</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A MediaWiki API Wrapper</td>
</tr>
<tr>
<td>Version:</td>
<td>1.7.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-04-05</td>
</tr>
<tr>
<td>Author:</td>
<td>Os Keyes [aut, cre], Brock Tilbert [ctb], Clemens Schmid [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Os Keyes &lt;ironholds@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A wrapper for the MediaWiki API, aimed particularly at the
    Wikimedia 'production' wikis, such as Wikipedia. It can be used to retrieve
    page text, information about users or the history of pages, and elements of
    the category tree.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>httr, jsonlite, magrittr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, WikidataR, pageviews</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Ironholds/WikipediR/issues">https://github.com/Ironholds/WikipediR/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Ironholds/WikipediR/">https://github.com/Ironholds/WikipediR/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-05 17:43:38 UTC; ironholds</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-05 18:13:00 UTC</td>
</tr>
</table>
<hr>
<h2 id='WikipediR'>A client library for MediaWiki's API</h2><span id='topic+WikipediR'></span><span id='topic+WikipediR-package'></span>

<h3>Description</h3>

<p>This package provides functions for accessing the MediaWiki API, either for
Wikimedia projects or any other MediaWiki instance. For more information, see the
<a href="https://CRAN.R-project.org/package=WikipediR/vignettes/WikipediR.html">vignette</a>.
</p>


<h3>See Also</h3>

<p>The <a href="https://CRAN.R-project.org/package=WikipediR/vignettes/WikipediR.html">package vignette</a>.
</p>

<hr>
<h2 id='categories_in_page'>Retrieves categories associated with a page.</h2><span id='topic+categories_in_page'></span>

<h3>Description</h3>

<p>Retrieves categories associated with a page (or list of pages) on a MediaWiki instance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>categories_in_page(
  language = NULL,
  project = NULL,
  domain = NULL,
  pages,
  properties = c("sortkey", "timestamp", "hidden"),
  limit = 50,
  show_hidden = FALSE,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="categories_in_page_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_pages">pages</code></td>
<td>
<p>A vector of page titles, with or without spaces, that you want to retrieve
categories for.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_properties">properties</code></td>
<td>
<p>The properties you want to retrieve about the categories.
Options are &quot;sortkey&quot; (the key that sorts the way the page is stored in each category),
&quot;timestamp&quot; (when the category was added to that page) and &quot;hidden&quot; (tags those categories
in the returned list that are 'hidden' from readers).</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_limit">limit</code></td>
<td>
<p>The maximum number of categories you want to retrieve for each page. Set
to 50 by default.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_show_hidden">show_hidden</code></td>
<td>
<p>Whether or not to include 'hidden' categories in the categories
that are retrieved - these are usually associated with the maintenance of Wikipedia
and its internal processes. Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="categories_in_page_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+pages_in_category">pages_in_category</a></code> for pages in a specified category.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Retrieve the categories for the "New Age" article on en.wiki
cats &lt;- categories_in_page("en", "wikipedia", pages = "New Age")

#Retrieve the categories for the "New Age" article on rationalwiki.
rw_cats &lt;- categories_in_page(domain = "rationalwiki.org", pages = "New Age")

## End(Not run)
</code></pre>

<hr>
<h2 id='create_page'>wikimedia api page creation (single pages)
helper function to do the actual api requests for page 
and category-page creation</h2><span id='topic+create_page'></span>

<h3>Description</h3>

<p>wikimedia api page creation (single pages)
</p>
<p>helper function to do the actual api requests for page 
and category-page creation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_page(url, p_title, p_text, category, token)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_page_+3A_url">url</code></td>
<td>
<p>a URL body</p>
</td></tr>
<tr><td><code id="create_page_+3A_p_title">p_title</code></td>
<td>
<p>page title string of new page</p>
</td></tr>
<tr><td><code id="create_page_+3A_p_text">p_text</code></td>
<td>
<p>page content string of new page</p>
</td></tr>
<tr><td><code id="create_page_+3A_category">category</code></td>
<td>
<p>switch to decide, if the page should be
created as category-page</p>
</td></tr>
<tr><td><code id="create_page_+3A_token">token</code></td>
<td>
<p>action token to perform the request</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE
</p>

<hr>
<h2 id='create_pages'>wikimedia api page creation
Create pages or category-pages on a wikimedia instance.</h2><span id='topic+create_pages'></span>

<h3>Description</h3>

<p>wikimedia api page creation
</p>
<p>Create pages or category-pages on a wikimedia instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_pages(url, p_title, p_text, category = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_pages_+3A_url">url</code></td>
<td>
<p>a URL body</p>
</td></tr>
<tr><td><code id="create_pages_+3A_p_title">p_title</code></td>
<td>
<p>vector with page title strings of new pages</p>
</td></tr>
<tr><td><code id="create_pages_+3A_p_text">p_text</code></td>
<td>
<p>vector with page content strings of new pages</p>
</td></tr>
<tr><td><code id="create_pages_+3A_category">category</code></td>
<td>
<p>switch to decide, if the pages should be
created as category-pages</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE
</p>

<hr>
<h2 id='get_action_token'>request token for api action as signed in user</h2><span id='topic+get_action_token'></span>

<h3>Description</h3>

<p>helper function to request a user action token
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_action_token(url)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_action_token_+3A_url">url</code></td>
<td>
<p>a URL body</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a token string
</p>

<hr>
<h2 id='get_prelogin_token'>request token to start client login</h2><span id='topic+get_prelogin_token'></span>

<h3>Description</h3>

<p>helper function to request a user login token
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_prelogin_token(url, user)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_prelogin_token_+3A_url">url</code></td>
<td>
<p>a URL body</p>
</td></tr>
<tr><td><code id="get_prelogin_token_+3A_user">user</code></td>
<td>
<p>a username of a registered user</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a token string
</p>

<hr>
<h2 id='login'>wikimedia api user login</h2><span id='topic+login'></span>

<h3>Description</h3>

<p>Login to a wikimedia instance to trigger api requests
as a registered user. This function only allows the 
very basic login with username and password. Wikimedia
setups that require more sophisticated login methods 
are not supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>login(url, user, pw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="login_+3A_url">url</code></td>
<td>
<p>a URL body</p>
</td></tr>
<tr><td><code id="login_+3A_user">user</code></td>
<td>
<p>a username of a registered user</p>
</td></tr>
<tr><td><code id="login_+3A_pw">pw</code></td>
<td>
<p>the password of said user</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE
</p>

<hr>
<h2 id='page_backlinks'>Retrieve a page's backlinks</h2><span id='topic+page_backlinks'></span>

<h3>Description</h3>

<p>page_backlinks, when provided with a page title, retrieves backlinks to that
page. Output can be filtered to specific namespaces.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>page_backlinks(
  language = NULL,
  project = NULL,
  domain = NULL,
  page,
  limit = 50,
  direction = "ascending",
  namespaces = NULL,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="page_backlinks_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_page">page</code></td>
<td>
<p>the title of the page you want the backlinks of.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_limit">limit</code></td>
<td>
<p>the number of backlinks to return. Set to 50 (the maximum) by default.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_direction">direction</code></td>
<td>
<p>the direction to order the backlinks in, by linking page ID: &quot;ascending&quot;
or &quot;descending&quot;. Set to &quot;ascending&quot; by default.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_namespaces">namespaces</code></td>
<td>
<p>The namespaces to filter to. By default, backlinks from any namespace
are retrieved: alternately, a numeric vector of accepted namespaces (which are described
<a href="https://www.mediawiki.org/wiki/Manual:Namespace#Built-in_namespaces">here</a>) can be
provided, and only backlinks from pages within those namespaces will be returned.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="page_backlinks_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>Warnings</h3>

<p>as with <code><a href="#topic+pages_in_category">pages_in_category</a></code>, if the page
you are linking to does not exist, an empty list will be returned, without
any indication of an error.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Backlink
all_bls &lt;- page_backlinks("en","wikipedia", page = "Aaron Halfaker")

#Namespace-specific backlinks
mainspace_bls &lt;- page_backlinks("en","wikipedia", page = "Aaron Halfaker", namespaces = 0)

## End(Not run)
</code></pre>

<hr>
<h2 id='page_content'>Retrieves MediaWiki page content</h2><span id='topic+page_content'></span>

<h3>Description</h3>

<p>wiki_page retrieves the DOM of a particular MediaWiki page,
as a HTML blob inside a JSON object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>page_content(
  language = NULL,
  project = NULL,
  domain = NULL,
  page_name,
  page_id = NULL,
  as_wikitext = FALSE,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="page_content_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="page_content_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="page_content_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="page_content_+3A_page_name">page_name</code></td>
<td>
<p>The title of the page you want to retrieve</p>
</td></tr>
<tr><td><code id="page_content_+3A_page_id">page_id</code></td>
<td>
<p>the pageID of the page you want to retrieve. Set to NULL by default,
and an alternative to page_name; if both are provided, page_id will be used.</p>
</td></tr>
<tr><td><code id="page_content_+3A_as_wikitext">as_wikitext</code></td>
<td>
<p>whether to retrieve the wikimarkup (TRUE) or the HTML (FALSE).
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="page_content_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="page_content_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+revision_diff">revision_diff</a></code> for retrieving 'diffs' between revisions,
<code><a href="#topic+revision_content">revision_content</a></code> for retrieving the text of specified revisions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Content from a Wikimedia project
wp_content &lt;- page_content("en","wikipedia", page_name = "Aaron Halfaker")

#Content by ID
wp_content &lt;- page_content("en", "wikipedia", page_id = 12)

#Content from a non-Wikimedia project
rw_content &lt;- page_content(domain = "rationalwiki.org", page_name = "New Age")

## End(Not run)
</code></pre>

<hr>
<h2 id='page_external_links'>Retrieve a page's links</h2><span id='topic+page_external_links'></span>

<h3>Description</h3>

<p>page_external_links, when provided with a page title, retrieves external wikilinks from the
current revision of that page.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>page_external_links(
  language = NULL,
  project = NULL,
  domain = NULL,
  page,
  protocol = NULL,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="page_external_links_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="page_external_links_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="page_external_links_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="page_external_links_+3A_page">page</code></td>
<td>
<p>the title of the page you want the links of.</p>
</td></tr>
<tr><td><code id="page_external_links_+3A_protocol">protocol</code></td>
<td>
<p>limit links to those with certain link protocols. Options are listed
in Special:ApiSandbox's
<a href="https://en.wikipedia.org/wiki/Special:ApiSandbox#action=query&amp;prop=extlinks">elprotocol field</a>.</p>
</td></tr>
<tr><td><code id="page_external_links_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="page_external_links_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Links
external_links &lt;- page_external_links("en","wikipedia", page = "Aaron Halfaker")

#Protocol-specific links
external_http_links &lt;- page_external_links("en","wikipedia",
                                          page = "Aaron Halfaker", protocol = "http")

## End(Not run)
</code></pre>

<hr>
<h2 id='page_info'>Retrieve information about a particular page</h2><span id='topic+page_info'></span>

<h3>Description</h3>

<p>page_info, when provided with a page title, retrieves metadata about that page.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>page_info(
  language = NULL,
  project = NULL,
  domain = NULL,
  page,
  properties = c("protection", "talkid", "url", "displaytitle"),
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="page_info_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="page_info_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="page_info_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="page_info_+3A_page">page</code></td>
<td>
<p>the title of the page you want the metadata of.</p>
</td></tr>
<tr><td><code id="page_info_+3A_properties">properties</code></td>
<td>
<p>the properties you'd like to retrieve. Some properties (the pageID, namespace,
title, language, length and most recent revision ID, for example) are retrieved by default,
whatever is passed to <code>properties</code>: properties that can be explicitly retrieved include
the page's protection level (&quot;protection&quot;), the ID of the associated talk page, if applicable
(&quot;talkid&quot;), the full, canonical URL (&quot;url&quot;), and the displayed page title (&quot;displaytitle&quot;).</p>
</td></tr>
<tr><td><code id="page_info_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="page_info_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Metadata
page_metadata &lt;- page_info("en","wikipedia", page = "Aaron Halfaker")

## End(Not run)
</code></pre>

<hr>
<h2 id='page_links'>Retrieve a page's links</h2><span id='topic+page_links'></span>

<h3>Description</h3>

<p>page_links, when provided with a page title, retrieves internal wikilinks from the
current revision of that page.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>page_links(
  language = NULL,
  project = NULL,
  domain = NULL,
  page,
  limit = 50,
  direction = "ascending",
  namespaces = NULL,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="page_links_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="page_links_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="page_links_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="page_links_+3A_page">page</code></td>
<td>
<p>the title of the page you want the links of.</p>
</td></tr>
<tr><td><code id="page_links_+3A_limit">limit</code></td>
<td>
<p>the number of links to retrieve. 50 by default; a maximum of 500 is set server-side.</p>
</td></tr>
<tr><td><code id="page_links_+3A_direction">direction</code></td>
<td>
<p>the direction to order the links in, by destination page ID: &quot;ascending&quot;
or &quot;descending&quot;. Set to &quot;ascending&quot; by default.</p>
</td></tr>
<tr><td><code id="page_links_+3A_namespaces">namespaces</code></td>
<td>
<p>The namespaces to filter to. By default, links to any namespace
are retrieved: alternately, a numeric vector of accepted namespaces (which are described
<a href="https://www.mediawiki.org/wiki/Manual:Namespace#Built-in_namespaces">here</a>) can be
provided, and only backlinks from pages within those namespaces will be returned.</p>
</td></tr>
<tr><td><code id="page_links_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="page_links_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Links
links &lt;- page_links("en","wikipedia", page = "Aaron Halfaker")

#Namespace-specific links
mainspace_links &lt;- page_links("en","wikipedia", page = "Aaron Halfaker", namespaces = 0)

## End(Not run)
</code></pre>

<hr>
<h2 id='pages_in_category'>Retrieves a list of category members.</h2><span id='topic+pages_in_category'></span>

<h3>Description</h3>

<p>wiki_catpages retrieves a list of pages, subcategories, files or all of the above
in a specified category (or series of specified categories)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pages_in_category(
  language = NULL,
  project = NULL,
  domain = NULL,
  categories,
  properties = c("title", "ids", "sortkey", "sortkeyprefix", "type", "timestamp"),
  type = c("page", "subcat", "file"),
  clean_response = FALSE,
  limit = 50,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pages_in_category_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_categories">categories</code></td>
<td>
<p>The names of the categories you want to gather information for.</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_properties">properties</code></td>
<td>
<p>The properties you want to gather for each member of the category. 
Options are &quot;title&quot; (the name of the member, including namespace), 
&quot;id&quot; (the unique numeric identifier of the member), &quot;sortkey&quot; 
(the hexadecimal key used to sort that member within the category), 
&quot;sortkeyprefix&quot; (the human-readable sort key), &quot;type&quot;
(whether the member is a page, a subcategory or a file) and 
&quot;timestamp&quot; (when the member was added to the category)</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_type">type</code></td>
<td>
<p>The type of member you're interested in returning;
options are any permutation of &quot;page&quot; (pages), &quot;subcat&quot; (subcategories) and &quot;file&quot; (files).</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_limit">limit</code></td>
<td>
<p>The maximum number of members to retrieve for each category. Set
to 50 by default.</p>
</td></tr>
<tr><td><code id="pages_in_category_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET().</p>
</td></tr>
</table>


<h3>warnings</h3>

<p>Because of the way MediaWiki stores this data, both &quot;the category you asked for doesn't exist&quot;
and &quot;the category you asked for exists, but has no members&quot; return in the same way.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+categories_in_page">categories_in_page</a></code> for finding categories that a specified page is a member of.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Retrieve the pages in the "New Age" category on en.wiki
cats &lt;- pages_in_category("en", "wikipedia", categories = "New Age")

#Retrieve the pages in the "New Age" category on rationalwiki.
rw_cats &lt;- pages_in_category(domain = "rationalwiki.org", categories = "New Age")

## End(Not run)
</code></pre>

<hr>
<h2 id='parse_response'>parse_response: Parse WikipediR responses internally</h2><span id='topic+parse_response'></span>

<h3>Description</h3>

<p>Response parser
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_response(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse_response_+3A_x">x</code></td>
<td>
<p>result from a WikipediR query</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Should not be externally used
</p>

<hr>
<h2 id='query'>base query function</h2><span id='topic+query'></span>

<h3>Description</h3>

<p>not designed to be used by anyone except
a third-party reuser package, such as WikidataR
</p>


<h3>Usage</h3>

<pre><code class='language-R'>query(url, out_class, clean_response = FALSE, query_param = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="query_+3A_url">url</code></td>
<td>
<p>a URL body</p>
</td></tr>
<tr><td><code id="query_+3A_out_class">out_class</code></td>
<td>
<p>the class to set on the output object; used within
WikidataR to indicate what response-cleaning method should be applied.</p>
</td></tr>
<tr><td><code id="query_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to clean the response, using the method assigned
by out_class, or not.</p>
</td></tr>
<tr><td><code id="query_+3A_query_param">query_param</code></td>
<td>
<p>query parameters</p>
</td></tr>
<tr><td><code id="query_+3A_...">...</code></td>
<td>
<p>further arguments to httr's GET.</p>
</td></tr>
</table>

<hr>
<h2 id='random_page'>Retrieve the page content of a random MediaWiki page</h2><span id='topic+random_page'></span>

<h3>Description</h3>

<p>wiki_page retrieves the DOM of a particular MediaWiki page,
as a HTML blob inside a JSON object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_page(
  language = NULL,
  project = NULL,
  domain = NULL,
  namespaces = NULL,
  as_wikitext = FALSE,
  limit = 1,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_page_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="random_page_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="random_page_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="random_page_+3A_namespaces">namespaces</code></td>
<td>
<p>The namespaces to consider pages from. By default, pages from any namespace are
considered; alternately, a numeric vector of accepted namespaces (which are described
<a href="https://www.mediawiki.org/wiki/Manual:Namespace#Built-in_namespaces">here</a>) can be
provided, and only pages within those namespaces will be considered.</p>
</td></tr>
<tr><td><code id="random_page_+3A_as_wikitext">as_wikitext</code></td>
<td>
<p>whether to retrieve the wikimarkup (TRUE) or the HTML (FALSE).
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="random_page_+3A_limit">limit</code></td>
<td>
<p>the number of pages to return. 1 by default.</p>
</td></tr>
<tr><td><code id="random_page_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="random_page_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+page_content">page_content</a></code> for retrieving the content of a specific page,
<code><a href="#topic+revision_diff">revision_diff</a></code> for retrieving 'diffs' between revisions,
<code><a href="#topic+revision_content">revision_content</a></code> for retrieving the text of specified revisions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#A page from Wikipedia
wp_content &lt;- random_page("en","wikipedia")

#A page from the mainspace on Wikipedia
wp_article_content &lt;- random_page("en","wikipedia", namespaces = 0)

## End(Not run)
</code></pre>

<hr>
<h2 id='recent_changes'>Retrieves entries from the RecentChanges feed</h2><span id='topic+recent_changes'></span>

<h3>Description</h3>

<p>wiki_recentchanges retrieves a stream of entries from Special:RecentChanges, with a variety of
associated metadata and filtering (of both entries *and* that metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recent_changes(
  language = NULL,
  project = NULL,
  domain = NULL,
  properties = c("user", "userid", "comment", "parsedcomment", "flags", "timestamp",
    "title", "ids", "sizes", "redirect", "loginfo", "tags", "sha1"),
  type = c("edit", "external", "new", "log"),
  tag = NULL,
  dir = "newer",
  limit = 50,
  top = FALSE,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recent_changes_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_properties">properties</code></td>
<td>
<p>Properties you're trying to retrieve about each entry, Options include
&quot;user&quot; (the username of the person responsible for that entry), &quot;userid&quot; (the userID of said
person), &quot;comment&quot; (the edit summary associated with the entry), &quot;parsedcomment&quot; (the same,
but parsed, generating HTML from any wikitext in that comment), &quot;flags&quot; (whether the revision
was 'minor' or not), &quot;timestamp&quot;, &quot;title&quot; (the name of the page the entry affected), &quot;ids&quot;
(the page id, along with the old and new revision IDs when applicable) &quot;sizes&quot; (the size,
in uncompressed bytes, of the entry, and, in the case of revisions, the size of the edit
it displaced), &quot;tags&quot; (any tags associated with the revision) and &quot;loginfo&quot; (applicable only
to log entries, and consisting of log ID numbers, log types and actions, and so on) and &quot;sha1&quot;
(the SHA-1 hash of the revision text).</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_type">type</code></td>
<td>
<p>The type of entry you want to retrieve; can be any permutation of &quot;edit&quot; (edits to existing pages),
&quot;external&quot; (external actions that impact on the project - primarily wikidata changes),
&quot;new&quot; (the creation of new pages) and &quot;log&quot; (log entries). By default, all of these entry types
are included.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_tag">tag</code></td>
<td>
<p>Only return items with particular &quot;tags&quot;, such as &quot;mobile edit&quot;. NULL by
default.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_dir">dir</code></td>
<td>
<p>Should it go from newest to oldest (&quot;newer&quot;), or oldest to newest (&quot;older&quot;)?
By default, set to &quot;newer&quot;.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_limit">limit</code></td>
<td>
<p>The number of entries you'd like to return. By default, set to 50, which is
also the maximum number per-request for logged-out users.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_top">top</code></td>
<td>
<p>Should the request only return &quot;top&quot; entries - in other words, the most recent
entry on a page? Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="recent_changes_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>

<hr>
<h2 id='revision_content'>Retrieves MediaWiki revisions</h2><span id='topic+revision_content'></span>

<h3>Description</h3>

<p>Retrieves the content of a provided list of revisions from whichever MediaWiki instance you're
querying. Returns as wikimarkup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>revision_content(
  language = NULL,
  project = NULL,
  domain = NULL,
  revisions,
  properties = c("content", "ids", "flags", "timestamp", "user", "userid", "size",
    "sha1", "contentmodel", "comment", "parsedcomment", "tags"),
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="revision_content_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="revision_content_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="revision_content_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="revision_content_+3A_revisions">revisions</code></td>
<td>
<p>The revision IDs of each desired revision.</p>
</td></tr>
<tr><td><code id="revision_content_+3A_properties">properties</code></td>
<td>
<p>Properties you're trying to retrieve about that revision, should you want to;
options include &quot;ids&quot; (the revision ID of the revision...which is pointless),
&quot;flags&quot; (whether the revision was 'minor' or not), &quot;timestamp&quot; (the timestamp of the revision),
&quot;user&quot; (the username of the person who made that revision), &quot;userid&quot;
(the userID of the person who made the revision),
&quot;size&quot; (the size, in uncompressed bytes, of the revision), &quot;sha1&quot; (the SHA-1 hash of
the revision text), &quot;contentmodel&quot; (the content model of the page, usually &quot;wikitext&quot;),
&quot;comment&quot; (the revision summary associated with the revision), &quot;parsedcomment&quot; (the same,
but parsed, generating HTML from any wikitext in that comment), &quot;tags&quot; (any tags associated
with the revision) and &quot;flagged&quot; (the revision's status under Flagged Revisions).</p>
</td></tr>
<tr><td><code id="revision_content_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.</p>
</td></tr>
<tr><td><code id="revision_content_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+revision_diff">revision_diff</a></code> for diffs between revisions,
and <code><a href="#topic+page_content">page_content</a></code> for the content a specific page currently has.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Revision content from a Wikimedia project
wp_content &lt;- revision_content("en","wikipedia", revisions = 552373187)

#Revision content from a non-Wikimedia project
rw_content &lt;- revision_content(domain = "rationalwiki.org", revisions = 88616)

## End(Not run)
</code></pre>

<hr>
<h2 id='revision_diff'>Generates a &quot;diff&quot; between a pair of revisions</h2><span id='topic+revision_diff'></span>

<h3>Description</h3>

<p>revision_diff generates a diff between two revisions in a MediaWiki page.
This is provided as an XML-parsable blob inside the returned JSON object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>revision_diff(
  language = NULL,
  project = NULL,
  domain = NULL,
  revisions,
  properties = c("ids", "flags", "timestamp", "user", "userid", "size", "sha1",
    "contentmodel", "comment", "parsedcomment", "tags", "flagged"),
  direction,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="revision_diff_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_revisions">revisions</code></td>
<td>
<p>The revision IDs of each &quot;start&quot; revision.</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_properties">properties</code></td>
<td>
<p>Properties you're trying to retrieve about that revision, should you want to;
options include &quot;ids&quot; (the revision ID of the revision...which is pointless),
&quot;flags&quot; (whether the revision was 'minor' or not), &quot;timestamp&quot;,&quot;user&quot; (the username of the person
who made that revision), &quot;userid&quot; (the userID of the person who made the revision),
&quot;size&quot; (the size, in uncompressed bytes, of the revision), &quot;sha1&quot; (the SHA-1 hash of
the revision text), &quot;contentmodel&quot; (the content model of the page, usually &quot;wikitext&quot;),
&quot;comment&quot; (the revision summary associated with the revision), &quot;parsedcomment&quot; (the same,
but parsed, generating HTML from any wikitext in that comment), &quot;tags&quot; (any tags associated
with the revision) and &quot;flagged&quot; (the revision's status under Flagged Revisions).</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_direction">direction</code></td>
<td>
<p>The direction you want the diff to go in from the revisionID you have provided.
Options are &quot;prev&quot; (compare to the previous revision on that page), &quot;next&quot; (compare to the next
revision on that page) and &quot;cur&quot; (compare to the current, extant version of the page).</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.</p>
</td></tr>
<tr><td><code id="revision_diff_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>Warnings</h3>

<p>MediaWiki's API is deliberately designed to restrict users' ability to make computing-intense requests
- such as diff computation. As a result, the API only allows requests for one uncached diff in
each request. If you ask for multiple diffs, some uncached and some cached, you will be provided
with the cached diffs, one of the uncached diffs, and a warning.
</p>
<p>If you're going to be asking for a lot of diffs, some of which may not be cached, it may be more
sensible to retrieve the revisions themselves using <code><a href="#topic+revision_content">revision_content</a></code> and compute the
diffs yourself.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+page_content">page_content</a></code> for retrieving the current content of a specific page, and
<code><a href="#topic+revision_content">revision_content</a></code> for retrieving the text of specific revisions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Wikimedia diff
wp_diff &lt;- revision_diff("en","wikipedia", revisions = 552373187, direction = "next")

#Non-Wikimedia diff
rw_diff &lt;- revision_diff(domain = "rationalwiki.org", revisions = 88616, direction = "next")

## End(Not run)
</code></pre>

<hr>
<h2 id='user_contributions'>Retrieve user contributions</h2><span id='topic+user_contributions'></span>

<h3>Description</h3>

<p>Retrieves metadata associated with the most recent contributions by a
specified user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>user_contributions(
  language = NULL,
  project = NULL,
  domain = NULL,
  username,
  properties = c("ids", "title", "timestamp", "comment", "parsedcomment", "size",
    "sizediff", "flags", "tags"),
  mainspace = FALSE,
  limit = 50,
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="user_contributions_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_username">username</code></td>
<td>
<p>The username of the user whose contributions you want to retrieve.
Due to limitations at the API end, you can only retrieve edits for one user at a time.</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_properties">properties</code></td>
<td>
<p>The metadata you want associated with each edit. Potential metadata includes &quot;ids&quot;
(the revision ID of the revision, which can be passed into <code><a href="#topic+revision_content">revision_content</a></code>),
&quot;title&quot; (the name of the page that was edited), &quot;timestamp&quot;, &quot;comment&quot; (the edit summary associated
with the revision), &quot;parsedcomment&quot; (the same, but parsed, generating HTML from any wikitext
in that comment), &quot;size&quot; (the size, in uncompressed bytes, of the edit), &quot;sizediff&quot; (the size
delta between this edit, and the last edit to the page), &quot;flags&quot; (whether the revision was 
'minor' or not), and &quot;tags&quot; (any tags associated with the revision).</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_mainspace">mainspace</code></td>
<td>
<p>A boolean flag; FALSE retrieves all of the most recent contributions, while
TRUE limits the retrieved contributions to those in the 'mainspace' - in other words, edits to
actual articles. Set to FALSE by default</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_limit">limit</code></td>
<td>
<p>The number of edits to be retrieved. 50 is the maximum for logged-out API users,
and putting in more than 50 will generate a warning.</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="user_contributions_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+user_information">user_information</a></code> for information about a specific user (or group of users),
and <code>recent_changes</code> for non-user-specific recent actions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Retrieve the timestamps of a user's recent contributions to the English-language Wikipedia
contribs &lt;- user_contributions("en", "wikipedia", username = "Ironholds",
                              properties = "timestamp")

#Retrieve the timestamps of a user's recent contributions to a non-Wikimedia wiki.
rw_contribs &lt;- user_contributions(domain = "rationalwiki.org", username = "David Gerard",
                                 properties = "ids", limit = 1)

## End(Not run)                        
</code></pre>

<hr>
<h2 id='user_information'>Retrieve user information</h2><span id='topic+user_information'></span>

<h3>Description</h3>

<p>Retrieves information about a user, or set of users, from the MediaWiki API,
including registration date, gender and editcount.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>user_information(
  language = NULL,
  project = NULL,
  domain = NULL,
  user_names,
  properties = c("blockinfo", "groups", "implicitgroups", "rights", "editcount",
    "registration", "emailable", "gender"),
  clean_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="user_information_+3A_language">language</code></td>
<td>
<p>The language code of the project you wish to query,
if appropriate.</p>
</td></tr>
<tr><td><code id="user_information_+3A_project">project</code></td>
<td>
<p>The project you wish to query (&quot;wikiquote&quot;), if appropriate.
Should be provided in conjunction with <code>language</code>.</p>
</td></tr>
<tr><td><code id="user_information_+3A_domain">domain</code></td>
<td>
<p>as an alternative to a <code>language</code> and <code>project</code> combination,
you can also provide a domain (&quot;rationalwiki.org&quot;) to the URL constructor, allowing
for the querying of non-Wikimedia MediaWiki instances.</p>
</td></tr>
<tr><td><code id="user_information_+3A_user_names">user_names</code></td>
<td>
<p>The username(s) of the users you want information on - this should be provided
as a vector. There is a hard limit of 50 distinct users per query, set by MediaWiki's API;
in the event that you go over this, a warning will be issued and the query will only be
performed for the first 50 names in the vector.</p>
</td></tr>
<tr><td><code id="user_information_+3A_properties">properties</code></td>
<td>
<p>The user properties you're interested in. Applicable properties are
&quot;blockinfo&quot; (details about the user's block, if they are currently blocked), &quot;groups&quot;
(the user groups the user is a member of), &quot;implicitgroups&quot; (groups they are a member of
through inheritance, as a result of membership in other groups), &quot;rights&quot; (what permissions
their group membership grants them), &quot;editcount&quot; (how many non-deleted edits they have),
&quot;registration&quot; (the date when they registered), &quot;emailable&quot; (whether they are contactable
through Special:EmailUser) and &quot;gender&quot; (their provided gender).</p>
</td></tr>
<tr><td><code id="user_information_+3A_clean_response">clean_response</code></td>
<td>
<p>whether to do some basic sanitising of the resulting data structure.
Set to FALSE by default.</p>
</td></tr>
<tr><td><code id="user_information_+3A_...">...</code></td>
<td>
<p>further arguments to pass to httr's GET.</p>
</td></tr>
</table>


<h3>Warnings</h3>

<p>There are a few caveats with the data provided by <code>user_information</code>, mostly stemming from
historical inconsistencies and peculiarities in MediaWiki.
</p>
<p><code>groups</code> and <code>implicitgroups</code> gives you the user's permissions and group membership
on the project you are querying, not their membership on all projects - while you can find out
if &quot;Ironholds&quot; is not a sysop on, say, enwiki, that doesn't mean they aren't a sysop elsewhere
- there is no universal, API-accessible user groups listing.
</p>
<p>As an extension of the lack of centrality in Wikimedia's infrastructure, <code>registration</code>
tells you the date their account was created on the wiki you are querying. If they initially
registered on that wiki, this is accurate - if they registered on a different wiki,
this instead reflects the date and time that they first visited the wiki you're querying
while logged-in. For users registered before 2006, when registration logging was introduced,
the <code>registration</code> value represents not when they first registered, but when their first
edit was, since that was used as an estimator for existing accounts when the field was first
populated.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+user_contributions">user_contributions</a></code> for retrieving recent contributions made by
a particular user.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Retrieving information from a Wikimedia project
user_info &lt;- user_information("en", "wikipedia", user_names = "David Gerard",
                             properties = "registration")

#Non-Wikimedia projects
user_info &lt;- user_information(domain = "rationalwiki.org", user_names = "David Gerard",
                             properties = "registration")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
