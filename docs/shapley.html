<!DOCTYPE html><html lang="en"><head><title>Help for package shapley</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {shapley}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#feature.selection'><p>Selects the top features with highest weighted mean shap values based on the</p>
specified criteria</a></li>
<li><a href='#feature.test'><p>Weighted Permutation Test for Difference of Means</p></a></li>
<li><a href='#h2o.get_ids'><p>h2o.get_ids</p></a></li>
<li><a href='#normalize'><p>Normalize a vector based on specified minimum and maximum values</p></a></li>
<li><a href='#shapley'><p>Weighted Mean SHAP Ratio and Confidence Interval for a ML Grid</p>
of Fine-Tuned Models or Base-Learners of a Stacked Ensemble Model</a></li>
<li><a href='#shapley.domain'><p>compute and plot weighted mean SHAP contributions at group level (factors or domains)</p></a></li>
<li><a href='#shapley.feature.test'><p>Normalize a vector based on specified minimum and maximum values</p></a></li>
<li><a href='#shapley.plot'><p>Plot weighted SHAP contributions</p></a></li>
<li><a href='#shapley.row.plot'><p>Weighted mean SHAP values computed at subject level</p></a></li>
<li><a href='#shapley.table'><p>Create SHAP Summary Table Based on the Given Criterion</p></a></li>
<li><a href='#shapley.top'><p>Select top features in a model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Weighted Mean SHAP and CI for Robust Feature Assessment in ML
Grid</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>This R package introduces Weighted Mean SHapley Additive exPlanations (WMSHAP), an innovative method for calculating SHAP values for a grid of fine-tuned base-learner machine learning models as well as stacked ensembles, a method not previously available due to the common reliance on single best-performing models. By integrating the weighted mean SHAP values from individual base-learners comprising the ensemble or individual base-learners in a tuning grid search, the package weights SHAP contributions according to each model's performance, assessed by multiple either R squared (for both regression and classification models). alternatively, this software also offers weighting SHAP values based on the area under the precision-recall curve (AUCPR), the area under the curve (AUC), and F2 measures for binary classifiers. It further extends this framework to implement weighted confidence intervals for weighted mean SHAP values, offering a more comprehensive and robust feature importance evaluation over a grid of machine learning models, instead of solely computing SHAP values for the best model. This methodology is particularly beneficial for addressing the severe class imbalance (class rarity) problem by providing a transparent, generalized measure of feature importance that mitigates the risk of reporting SHAP values for an overfitted or biased model and maintains robustness under severe class imbalance, where there is no universal criteria of identifying the absolute best model. Furthermore, the package implements hypothesis testing to ascertain the statistical significance of SHAP values for individual features, as well as comparative significance testing of SHAP contributions between features. Additionally, it tackles a critical gap in feature selection literature by presenting criteria for the automatic feature selection of the most important features across a grid of models or stacked ensembles, eliminating the need for arbitrary determination of the number of top features to be extracted. This utility is invaluable for researchers analyzing feature significance, particularly within severely imbalanced outcomes where conventional methods fall short. Moreover, it is also expected to report democratic feature importance across a grid of models, resulting in a more comprehensive and generalizable feature selection. The package further implements a novel method for visualizing SHAP values both at subject level and feature level as well as a plot for feature selection based on the weighted mean SHAP ratios.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2 (&ge; 3.4.2), h2o (&ge; 3.34.0.0), curl (&ge; 4.3.0), waffle
(&ge; 1.0.2), pander (&ge; 0.6.5)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/haghish/shapley">https://github.com/haghish/shapley</a>,
<a href="https://www.sv.uio.no/psi/english/people/academic/haghish/">https://www.sv.uio.no/psi/english/people/academic/haghish/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/haghish/shapley/issues">https://github.com/haghish/shapley/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-18 22:38:24 UTC; haghish</td>
</tr>
<tr>
<td>Author:</td>
<td>E. F. Haghish [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>E. F. Haghish &lt;haghish@hotmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-18 23:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='feature.selection'>Selects the top features with highest weighted mean shap values based on the
specified criteria</h2><span id='topic+feature.selection'></span>

<h3>Description</h3>

<p>This function specifies the top features and prepares the data
for plotting SHAP contributions for each row, or summary of absolute
SHAP contributions for each feature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feature.selection(
  shapley,
  method = "mean",
  cutoff = 0,
  top_n_features = NULL,
  features = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="feature.selection_+3A_shapley">shapley</code></td>
<td>
<p>shapley object</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_method">method</code></td>
<td>
<p>Character. The column name in <code>summaryShaps</code> used
for feature selection. Default is <code>"mean"</code>, which
selects important features which have weighted mean shap
ratio (WMSHAP) higher than the specified cutoff. Other
alternative is &quot;lowerCI&quot;, which selects features which
their lower bound of confidence interval is higher than
the cutoff.</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric, specifying the cutoff for the method used for selecting
the top features. the default is zero, which means that all
features with the &quot;method&quot; criteria above zero will be selected.</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_top_n_features">top_n_features</code></td>
<td>
<p>integer. if specified, the top n features with the
highest weighted SHAP values will be selected, overrullung
the 'cutoff' and 'method' arguments.</p>
</td></tr>
<tr><td><code id="feature.selection_+3A_features">features</code></td>
<td>
<p>character vector, specifying the feature to be plotted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>normalized numeric vector
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>

<hr>
<h2 id='feature.test'>Weighted Permutation Test for Difference of Means</h2><span id='topic+feature.test'></span>

<h3>Description</h3>

<p>This function performs a weighted permutation test to determine if there is a significant
difference between the means of two weighted numeric vectors. It tests the null hypothesis
that the difference in means is zero against the alternative that it is not zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feature.test(var1, var2, weights, n = 2000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="feature.test_+3A_var1">var1</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="feature.test_+3A_var2">var2</code></td>
<td>
<p>A numeric vector of the same length as <code>var1</code>.</p>
</td></tr>
<tr><td><code id="feature.test_+3A_weights">weights</code></td>
<td>
<p>A numeric vector of weights, assumed to be the same for both <code>var1</code> and <code>var2</code>.</p>
</td></tr>
<tr><td><code id="feature.test_+3A_n">n</code></td>
<td>
<p>The number of permutations to perform (default is 2000).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the observed difference in means and the p-value of the test.
</p>

<hr>
<h2 id='h2o.get_ids'>h2o.get_ids</h2><span id='topic+h2o.get_ids'></span>

<h3>Description</h3>

<p>extracts the model IDs from H2O AutoML object or H2O grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h2o.get_ids(automl)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="h2o.get_ids_+3A_automl">automl</code></td>
<td>
<p>a h2o <code>"AutoML"</code> grid object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector of trained models' names (IDs)
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
library(h2o)
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 30)

# get the model IDs
ids &lt;- h2o.ids(aml)

## End(Not run)
</code></pre>

<hr>
<h2 id='normalize'>Normalize a vector based on specified minimum and maximum values</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p>This function normalizes a vector based on specified minimum
and maximum values. If the minimum and maximum values are not
specified, the function will use the minimum and maximum values
of the vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(x, min = NULL, max = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="normalize_+3A_min">min</code></td>
<td>
<p>minimum value</p>
</td></tr>
<tr><td><code id="normalize_+3A_max">max</code></td>
<td>
<p>maximum value</p>
</td></tr>
</table>


<h3>Value</h3>

<p>normalized numeric vector
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>

<hr>
<h2 id='shapley'>Weighted Mean SHAP Ratio and Confidence Interval for a ML Grid
of Fine-Tuned Models or Base-Learners of a Stacked Ensemble Model</h2><span id='topic+shapley'></span>

<h3>Description</h3>

<p>Calculates weighted mean SHAP ratios and confidence intervals to assess feature importance
across a collection of models (e.g., a grid of fine-tuned models or base-learners
in a stacked ensemble). Rather than reporting relative SHAP contributions for
only a single model, this function accounts for variability in feature importance
across multiple models. Each model's performance metric is used as a weight.
The function also provides a plot of weighted SHAP values with confidence intervals.
Currently, only models trained by the <code>h2o</code> machine learning platform,
<code>autoEnsemble</code>, and the <code>HMDA</code> R packages are supported.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley(
  models,
  newdata,
  plot = TRUE,
  performance_metric = "r2",
  standardize_performance_metric = FALSE,
  performance_type = "xval",
  minimum_performance = 0,
  method = "mean",
  cutoff = 0.01,
  top_n_features = NULL,
  n_models = 10,
  sample_size = nrow(newdata)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley_+3A_models">models</code></td>
<td>
<p>h2o search grid, autoML grid, or a character vector of H2O model IDs.</p>
</td></tr>
<tr><td><code id="shapley_+3A_newdata">newdata</code></td>
<td>
<p>An <code>h2o</code> frame (or <code>data.frame</code>) already uploaded to the
<code>h2o</code> server. This data will be used for computing SHAP
contributions for each model, alongside model's performance
weights.</p>
</td></tr>
<tr><td><code id="shapley_+3A_plot">plot</code></td>
<td>
<p>logical. if TRUE, the weighted mean and confidence intervals of
the SHAP values are plotted. The default is TRUE.</p>
</td></tr>
<tr><td><code id="shapley_+3A_performance_metric">performance_metric</code></td>
<td>
<p>Character specifying which performance metric to use
as weights. The default is <code>"r2"</code>, which can
be used for both regression and classification.
For binary classification, other options include:
<code>"aucpr"</code> (area under the precision-recall curve),
<code>"auc"</code> (area under the ROC curve),
and <code>"f2"</code> (F2 score).</p>
</td></tr>
<tr><td><code id="shapley_+3A_standardize_performance_metric">standardize_performance_metric</code></td>
<td>
<p>Logical, indicating whether to standardize
the performance metric used as weights so
their sum equals the number of models. The
default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="shapley_+3A_performance_type">performance_type</code></td>
<td>
<p>Character. Specify which performance metric should be
reported: <code>"train"</code> for training data, <code>"valid"</code>
for validation, or <code>"xval"</code> for cross-validation (default).</p>
</td></tr>
<tr><td><code id="shapley_+3A_minimum_performance">minimum_performance</code></td>
<td>
<p>Numeric. Specify the minimum performance metric
for a model to be included in calculating weighted
mean SHAP ratio Models below this threshold receive
zero weight. The default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="shapley_+3A_method">method</code></td>
<td>
<p>Character. Specify the method for selecting important features
based on their weighted mean SHAP ratios. The default is
<code>"mean"</code>, which selects features whose weighted mean shap ratio (WMSHAP)
exceeds the <code>cutoff</code>. The alternative is
<code>"lowerCI"</code>, which selects features whose lower bound of confidence
interval exceeds the <code>cutoff</code>.</p>
</td></tr>
<tr><td><code id="shapley_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric, specifying the cutoff for the method used for selecting
the top features.</p>
</td></tr>
<tr><td><code id="shapley_+3A_top_n_features">top_n_features</code></td>
<td>
<p>integer. if specified, the top n features with the
highest weighted SHAP values will be selected, overrullung
the 'cutoff' and 'method' arguments. specifying top_n_feature
is also a way to reduce computation time, if many features
are present in the data set. The default is NULL, which means
the shap values will be computed for all features.</p>
</td></tr>
<tr><td><code id="shapley_+3A_n_models">n_models</code></td>
<td>
<p>minimum number of models that should meet the 'minimum_performance'
criterion in order to compute WMSHAP and CI. If the intention
is to compute global summary SHAP values (at feature level) for
a single model, set n_models to 1. The default is 10.</p>
</td></tr>
<tr><td><code id="shapley_+3A_sample_size">sample_size</code></td>
<td>
<p>integer. number of rows in the <code>newdata</code> that should
be used for SHAP assessment. By default, all rows are used,
which is the recommended procedure for scientific analyses.
However, SHAP analysis is time consuming and in the process
of code development, lower values can be used for quicker
shapley analyses.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> SHAP contributions are computed at the individual level (row) for each model for the given &quot;newdata&quot;.
</p>
</li>
<li><p> Each model's feature-level SHAP ratios (i.e., share of total SHAP) are computed.
</p>
</li>
<li><p> The performance metrics of the models are used as weights.
</p>
</li>
<li><p> Using the weights vector and shap ratio of features for each model,
the weighted mean SHAP ratios and their confidence intervals are computed.
</p>
</li></ol>



<h3>Value</h3>

<p>a list including the GGPLOT2 object, the data frame of SHAP values,
and performance metric of all models, as well as the model IDs.
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

set.seed(10)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate, performance_metric = "aucpr", plot = TRUE)

#######################################################
### PREPARE H2O Grid (takes a couple of minutes)
#######################################################
# make sure equal number of "nfolds" is specified for different grids
grid &lt;- h2o.grid(algorithm = "gbm", y = y, training_frame = prostate,
                 hyper_params = list(ntrees = seq(1,50,1)),
                 grid_id = "ensemble_grid",

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, fold_assignment = "Modulo", nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

result2 &lt;- shapley(models = grid, newdata = prostate, performance_metric = "aucpr", plot = TRUE)

#######################################################
### PREPARE autoEnsemble STACKED ENSEMBLE MODEL
#######################################################

### get the models' IDs from the AutoML and grid searches.
### this is all that is needed before building the ensemble,
### i.e., to specify the model IDs that should be evaluated.
library(autoEnsemble)
ids    &lt;- c(h2o.get_ids(aml), h2o.get_ids(grid))
autoSearch &lt;- ensemble(models = ids, training_frame = prostate, strategy = "search")
result3 &lt;- shapley(models = autoSearch, newdata = prostate,
                   performance_metric = "aucpr", plot = TRUE)



## End(Not run)
</code></pre>

<hr>
<h2 id='shapley.domain'>compute and plot weighted mean SHAP contributions at group level (factors or domains)</h2><span id='topic+shapley.domain'></span>

<h3>Description</h3>

<p>This function applies different criteria to visualize SHAP contributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley.domain(
  shapley,
  domains,
  plot = "bar",
  legendstyle = "continuous",
  scale_colour_gradient = NULL,
  print = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley.domain_+3A_shapley">shapley</code></td>
<td>
<p>object of class 'shapley', as returned by the 'shapley' function</p>
</td></tr>
<tr><td><code id="shapley.domain_+3A_domains">domains</code></td>
<td>
<p>character list, specifying the domains for grouping the features'
contributions. Domains are clusters of features' names, that
can be used to compute WMSHAP at higher level, along with
their 95
better understand how a cluster of features influence the
outcome. Note that either of 'features' or 'domains' arguments
can be specified at the time.</p>
</td></tr>
<tr><td><code id="shapley.domain_+3A_plot">plot</code></td>
<td>
<p>character, specifying the type of the plot, which can be either
'bar', 'waffle', or 'shap'. The default is 'bar'.</p>
</td></tr>
<tr><td><code id="shapley.domain_+3A_legendstyle">legendstyle</code></td>
<td>
<p>character, specifying the style of the plot legend, which
can be either 'continuous' (default) or 'discrete'. the
continuous legend is only applicable to 'shap' plots and
other plots only use 'discrete' legend.</p>
</td></tr>
<tr><td><code id="shapley.domain_+3A_scale_colour_gradient">scale_colour_gradient</code></td>
<td>
<p>character vector for specifying the color gradients
for the plot.</p>
</td></tr>
<tr><td><code id="shapley.domain_+3A_print">print</code></td>
<td>
<p>logical. if TRUE, the WMSHAP summary table for the given row is printed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot object
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

set.seed(10)

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate, plot = TRUE)

#######################################################
### PLOT THE WEIGHTED MEAN SHAP VALUES
#######################################################

shapley.plot(result, plot = "bar")
shapley.plot(result, plot = "waffle")

#######################################################
### DEFINE DOMAINS (GROUPS OF FEATURES OR FACTORS)
#######################################################
shapley.domain(shapley = shapley, plot = "bar",
               domains = list(Demographic = c("RACE", "AGE"),
                              Cancer = c("VOL", "PSA", "GLEASON"),
                              Tests = c("DPROS", "DCAPS")),
                              print = TRUE

## End(Not run)
</code></pre>

<hr>
<h2 id='shapley.feature.test'>Normalize a vector based on specified minimum and maximum values</h2><span id='topic+shapley.feature.test'></span>

<h3>Description</h3>

<p>This function normalizes a vector based on specified minimum
and maximum values. If the minimum and maximum values are not
specified, the function will use the minimum and maximum values
of the vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley.feature.test(shapley, features, n = 5000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley.feature.test_+3A_shapley">shapley</code></td>
<td>
<p>object of class 'shapley', as returned by the 'shapley' function</p>
</td></tr>
<tr><td><code id="shapley.feature.test_+3A_features">features</code></td>
<td>
<p>character, name of two features to be compared with permutation test</p>
</td></tr>
<tr><td><code id="shapley.feature.test_+3A_n">n</code></td>
<td>
<p>integer, number of permutations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>normalized numeric vector
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(autoEnsemble)   #autoEnsemble models, particularly useful under severe class imbalance
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

set.seed(10)

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate, plot = TRUE)

#######################################################
### Significance testing of contributions of two features
#######################################################

shapley.test(result, features = c("GLEASON", "PSA"), n=5000)

## End(Not run)
</code></pre>

<hr>
<h2 id='shapley.plot'>Plot weighted SHAP contributions</h2><span id='topic+shapley.plot'></span>

<h3>Description</h3>

<p>This function applies different criteria to visualize SHAP contributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley.plot(
  shapley,
  plot = "bar",
  method = "mean",
  cutoff = 0.01,
  top_n_features = NULL,
  features = NULL,
  legendstyle = "continuous",
  scale_colour_gradient = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley.plot_+3A_shapley">shapley</code></td>
<td>
<p>object of class 'shapley', as returned by the 'shapley' function</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_plot">plot</code></td>
<td>
<p>character, specifying the type of the plot, which can be either
'bar', 'waffle', or 'shap'. The default is 'bar'.</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_method">method</code></td>
<td>
<p>Character. The column name in <code>summaryShaps</code> used
for feature selection. Default is <code>"mean"</code>, which
selects important features which have weighted mean shap
ratio (WMSHAP) higher than the specified cutoff. Other
alternative is &quot;lowerCI&quot;, which selects features which
their lower bound of confidence interval is higher than
the cutoff.</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric, specifying the cutoff for the method used for selecting
the top features.</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_top_n_features">top_n_features</code></td>
<td>
<p>Integer. If specified, the top n features with the
highest weighted SHAP values will be selected, overrullung
the 'cutoff' and 'method' arguments.</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_features">features</code></td>
<td>
<p>character vector, specifying the feature to be plotted.</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_legendstyle">legendstyle</code></td>
<td>
<p>character, specifying the style of the plot legend, which
can be either 'continuous' (default) or 'discrete'. the
continuous legend is only applicable to 'shap' plots and
other plots only use 'discrete' legend.</p>
</td></tr>
<tr><td><code id="shapley.plot_+3A_scale_colour_gradient">scale_colour_gradient</code></td>
<td>
<p>character vector for specifying the color gradients
for the plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot object
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

set.seed(10)

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate, plot = TRUE)

#######################################################
### PLOT THE WEIGHTED MEAN SHAP VALUES
#######################################################

shapley.plot(result, plot = "bar")
shapley.plot(result, plot = "waffle")

## End(Not run)
</code></pre>

<hr>
<h2 id='shapley.row.plot'>Weighted mean SHAP values computed at subject level</h2><span id='topic+shapley.row.plot'></span>

<h3>Description</h3>

<p>Weighted mean of SHAP values and weighted SHAP confidence intervals
provide a measure of feature importance for a grid of fine-tuned models
or base-learners of a stacked ensemble model at subject level,
showing that how each feature influences the prediction made for
a row in the dataset and to what extend different models agree
on that effect. If the 95
vertical line at 0.00, then it can be concluded that the feature
does not significantly influences the subject, when variability
across models is taken into consideration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley.row.plot(
  shapley,
  row_index,
  features = NULL,
  plot = TRUE,
  print = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley.row.plot_+3A_shapley">shapley</code></td>
<td>
<p>object of class 'shapley', as returned by the 'shapley' function</p>
</td></tr>
<tr><td><code id="shapley.row.plot_+3A_row_index">row_index</code></td>
<td>
<p>subject or row number in a wide-format dataset to be visualized</p>
</td></tr>
<tr><td><code id="shapley.row.plot_+3A_features">features</code></td>
<td>
<p>character vector, specifying the feature to be plotted.</p>
</td></tr>
<tr><td><code id="shapley.row.plot_+3A_plot">plot</code></td>
<td>
<p>logical. if TRUE, the plot is visualized.</p>
</td></tr>
<tr><td><code id="shapley.row.plot_+3A_print">print</code></td>
<td>
<p>logical. if TRUE, the WMSHAP summary table for the given row is printed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list including the GGPLOT2 object, the data frame of SHAP values,
and performance metric of all models, as well as the model IDs.
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE,
         insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

set.seed(10)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate,
                  performance_metric = "aucpr", plot = TRUE)

#######################################################
### PREPARE H2O Grid (takes a couple of minutes)
#######################################################
# make sure equal number of "nfolds" is specified for different grids
grid &lt;- h2o.grid(algorithm = "gbm", y = y, training_frame = prostate,
                 hyper_params = list(ntrees = seq(1,50,1)),
                 grid_id = "ensemble_grid",

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, fold_assignment = "Modulo", nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

result2 &lt;- shapley(models = grid, newdata = prostate,
                   performance_metric = "aucpr", plot = TRUE)

#######################################################
### PREPARE autoEnsemble STACKED ENSEMBLE MODEL
#######################################################

### get the models' IDs from the AutoML and grid searches.
### this is all that is needed before building the ensemble,
### i.e., to specify the model IDs that should be evaluated.
library(autoEnsemble)
ids    &lt;- c(h2o.get_ids(aml), h2o.get_ids(grid))
autoSearch &lt;- ensemble(models = ids, training_frame = prostate, strategy = "search")
result3 &lt;- shapley(models = autoSearch, newdata = prostate,
                   performance_metric = "aucpr", plot = TRUE)

#plot all important features
shapley.row.plot(shapley, row_index = 11)

#plot only the given features
shapPlot &lt;- shapley.row.plot(shapley, row_index = 11, features = c("PSA", "AGE"))

# inspect the computed data for the row 11
ptint(shapPlot$rowSummarySHAP)

## End(Not run)
</code></pre>

<hr>
<h2 id='shapley.table'>Create SHAP Summary Table Based on the Given Criterion</h2><span id='topic+shapley.table'></span>

<h3>Description</h3>

<p>Generates a summary table of weighted mean SHAP (WMSHAP) values
and confidence intervals for each feature based on a weighted SHAP analysis.
The function filters the SHAP summary table (from a <code>wmshap</code> object) by
selecting features that meet or exceed a specified cutoff using a selection
method (default &quot;mean&quot;, which is weighted mean shap ratio).
It then sorts the table by the mean SHAP value,
formats the SHAP values along with their 95% confidence intervals into a single
string, and optionally adds human-readable feature descriptions from a provided
dictionary. The output is returned as a markdown table using the <span class="pkg">pander</span>
package, or as a data frame if requested.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley.table(
  wmshap,
  method = "mean",
  cutoff = 0.01,
  round = 3,
  exclude_features = NULL,
  dict = NULL,
  markdown.table = TRUE,
  split.tables = 120,
  split.cells = 50
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley.table_+3A_wmshap">wmshap</code></td>
<td>
<p>A wmshap object, returned by the shapley function
containing a data frame <code>summaryShaps</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_method">method</code></td>
<td>
<p>Character. The column name in <code>summaryShaps</code> used
for feature selection. Default is <code>"mean"</code>, which
selects important features which have weighted mean shap
ratio (WMSHAP) higher than the specified cutoff. Other
alternative is &quot;lowerCI&quot;, which selects features which
their lower bound of confidence interval is higher than
the cutoff.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_cutoff">cutoff</code></td>
<td>
<p>Numeric. The threshold cutoff for the selection method;
only features with a value in the <code>method</code> column
greater than or equal to this value are retained.
Default is <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_round">round</code></td>
<td>
<p>Integer. The number of decimal places to round the
SHAP mean and confidence interval values. Default is
<code>3</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_exclude_features">exclude_features</code></td>
<td>
<p>Character vector. A vector of feature names to be
excluded from the summary table. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_dict">dict</code></td>
<td>
<p>A data frame containing at least two columns named
<code>"name"</code> and <code>"description"</code>. If provided, the
function uses this dictionary to add human-readable feature
descriptions. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_markdown.table">markdown.table</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the output is formatted as a
markdown table using the <span class="pkg">pander</span> package; otherwise, a
data frame is returned. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_split.tables">split.tables</code></td>
<td>
<p>Integer. Controls table splitting in <code>pander()</code>.
Default is <code>120</code>.</p>
</td></tr>
<tr><td><code id="shapley.table_+3A_split.cells">split.cells</code></td>
<td>
<p>Integer. Controls cell splitting in <code>pander()</code>.
Default is <code>50</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>markdown.table = TRUE</code>, returns a markdown table (invisibly)
showing two columns: <code>"Description"</code> and <code>"WMSHAP"</code>. If
<code>markdown.table = FALSE</code>, returns a data frame with these columns.
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

set.seed(10)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate, performance_metric = "aucpr", plot = TRUE)

#######################################################
### PREPARE H2O Grid (takes a couple of minutes)
#######################################################
# make sure equal number of "nfolds" is specified for different grids
grid &lt;- h2o.grid(algorithm = "gbm", y = y, training_frame = prostate,
                 hyper_params = list(ntrees = seq(1,50,1)),
                 grid_id = "ensemble_grid",

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, fold_assignment = "Modulo", nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

result2 &lt;- shapley(models = grid, newdata = prostate, performance_metric = "aucpr", plot = TRUE)

# get the output as a Markdown table:
md_table &lt;- shapley.table(wmshap = result2,
                          method = "mean",
                          cutoff = 0.01,
                          round = 3,
                          markdown.table = TRUE)
head(md_table)

## End(Not run)

</code></pre>

<hr>
<h2 id='shapley.top'>Select top features in a model</h2><span id='topic+shapley.top'></span>

<h3>Description</h3>

<p>This function applies different criteria simultaniously to identify
the most important features in a model. The criteria include:
1) minimum limit of lower weighted confidence intervals of SHAP values
relative to the feature with highest SHAP value.
2) minimum limit of percentage of weighted mean SHAP values relative to
over all SHAP values of all features. These are specified with two
different cutoff values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shapley.top(shapley, mean = 0.01, lowerCI = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shapley.top_+3A_shapley">shapley</code></td>
<td>
<p>object of class 'shapley', as returned by the 'shapley' function</p>
</td></tr>
<tr><td><code id="shapley.top_+3A_mean">mean</code></td>
<td>
<p>Numeric. specifying the cutoff of weighted mean
SHAP ratio (WMSHAP). The default is 0.01. Lower values will
be more generous in defining &quot;importance&quot;, while higher values
are more restrictive. However, these default values are not
generalizable to all situations and algorithms.</p>
</td></tr>
<tr><td><code id="shapley.top_+3A_lowerci">lowerCI</code></td>
<td>
<p>numeric. Specifying the limit of lower bound of 95% WMSHAP
The default is 0.01. Lower values will
be more generous in defining &quot;importance&quot;, while higher values
are more restrictive. However, these default values are not
generalizable to all situations and algorithms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame of selected features
</p>


<h3>Author(s)</h3>

<p>E. F. Haghish
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# load the required libraries for building the base-learners and the ensemble models
library(h2o)            #shapley supports h2o models
library(shapley)

# initiate the h2o server
h2o.init(ignore_config = TRUE, nthreads = 2, bind_to_localhost = FALSE, insecure = TRUE)

# upload data to h2o cloud
prostate_path &lt;- system.file("extdata", "prostate.csv", package = "h2o")
prostate &lt;- h2o.importFile(path = prostate_path, header = TRUE)

### H2O provides 2 types of grid search for tuning the models, which are
### AutoML and Grid. Below, I demonstrate how weighted mean shapley values
### can be computed for both types.

set.seed(10)

#######################################################
### PREPARE AutoML Grid (takes a couple of minutes)
#######################################################
# run AutoML to tune various models (GBM) for 60 seconds
y &lt;- "CAPSULE"
prostate[,y] &lt;- as.factor(prostate[,y])  #convert to factor for classification
aml &lt;- h2o.automl(y = y, training_frame = prostate, max_runtime_secs = 120,
                 include_algos=c("GBM"),

                 # this setting ensures the models are comparable for building a meta learner
                 seed = 2023, nfolds = 10,
                 keep_cross_validation_predictions = TRUE)

### call 'shapley' function to compute the weighted mean and weighted confidence intervals
### of SHAP values across all trained models.
### Note that the 'newdata' should be the testing dataset!
result &lt;- shapley(models = aml, newdata = prostate, plot = TRUE)

#######################################################
### Significance testing of contributions of two features
#######################################################


shapley.top(result, mean = 0.005, lowerCI = 0.01)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
