<!DOCTYPE html><html><head><title>Help for package eva</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {eva}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#eva'><p>eva: Extreme Value Analysis with Goodness-of-Fit Testing</p></a></li>
<li><a href='#fortmax'><p>Top Ten Annual Precipitation: Fort Collins, Colorado</p></a></li>
<li><a href='#gevr'><p>The GEVr Distribution</p></a></li>
<li><a href='#gevrDiag'><p>Diagnostic plots for a fit to the GEVr distribution.</p></a></li>
<li><a href='#gevrEd'><p>GEVr Entropy Difference Test</p></a></li>
<li><a href='#gevrFit'><p>Parameter estimation for the GEVr distribution model</p></a></li>
<li><a href='#gevrMultScore'><p>GEVr Multiplier Score Test</p></a></li>
<li><a href='#gevrPbScore'><p>GEVr Parametric Bootstrap Score Test</p></a></li>
<li><a href='#gevrProfShape'><p>GEVr Shape Parameter Profile Likelihood Estimation for Stationary Models</p></a></li>
<li><a href='#gevrRl'><p>GEVr Return Level Estimate and Confidence Interval for Stationary Models</p></a></li>
<li><a href='#gevrSeqTests'><p>Sequential Tests for the GEVr Model</p></a></li>
<li><a href='#gpd'><p>The Generalized Pareto Distribution (GPD)</p></a></li>
<li><a href='#gpdAd'><p>Generalized Pareto Distribution Anderson-Darling Test</p></a></li>
<li><a href='#gpdCvm'><p>Generalized Pareto Distribution Cramer-von Mises Test</p></a></li>
<li><a href='#gpdDiag'><p>Diagnostic plots for a fit to the Generalized Pareto distribution</p></a></li>
<li><a href='#gpdFit'><p>Parameter estimation for the Generalized Pareto Distribution (GPD)</p></a></li>
<li><a href='#gpdImAsym'><p>GPD Asymptotic Adjusted Information Matrix (IM) Test</p></a></li>
<li><a href='#gpdImPb'><p>GPD Bootstrapped Information Matrix (IM) Test</p></a></li>
<li><a href='#gpdMultScore'><p>GPD Multiplier Score Test</p></a></li>
<li><a href='#gpdPbScore'><p>GPD Parametric Bootstrap Score Test</p></a></li>
<li><a href='#gpdProfShape'><p>GPD Shape Parameter Profile Likelihood Estimation for Stationary Models</p></a></li>
<li><a href='#gpdRl'><p>GPD Return Level Estimate and Confidence Interval for Stationary Models</p></a></li>
<li><a href='#gpdSeqTests'><p>GPD Multiple Threshold Goodness-of-Fit Testing</p></a></li>
<li><a href='#lowestoft'><p>Top Ten Annual Sea Levels: Lowestoft, UK (1964 - 2014)</p></a></li>
<li><a href='#mrlPlot'><p>Mean Residual Life Plot for the Generalized Pareto Distribution</p></a></li>
<li><a href='#pSeqStop'><p>P-Value Sequential Adjustment</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Extreme Value Analysis with Goodness-of-Fit Testing</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-11-14</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Goodness-of-fit tests for selection of r in the r-largest order
    statistics (GEVr) model. Goodness-of-fit tests for threshold selection in the
    Generalized Pareto distribution (GPD). Random number generation and density functions
    for the GEVr distribution. Profile likelihood for return level estimation
    using the GEVr and Generalized Pareto distributions. P-value adjustments for
    sequential, multiple testing error control. Non-stationary fitting of GEVr and
    GPD.
    Bader, B., Yan, J. &amp; Zhang, X. (2016) &lt;<a href="https://doi.org/10.1007%2Fs11222-016-9697-3">doi:10.1007/s11222-016-9697-3</a>&gt;.
    Bader, B., Yan, J. &amp; Zhang, X. (2018) &lt;<a href="https://doi.org/10.1214%2F17-AOAS1092">doi:10.1214/17-AOAS1092</a>&gt;.</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, parallel, stats, graphics, utils, EnvStats</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 2.10.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, SpatialExtremes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/brianbader/eva_package">https://github.com/brianbader/eva_package</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/brianbader/eva_package/issues">https://github.com/brianbader/eva_package/issues</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Author:</td>
<td>Brian Bader [aut, cre],
  Jun Yan [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brian Bader &lt;bbader.stat@gmail.com&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-11-15 02:25:35 UTC; Brian</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-11-15 17:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='eva'>eva: Extreme Value Analysis with Goodness-of-Fit Testing</h2><span id='topic+eva'></span>

<h3>Description</h3>

<p>The focus of this package is to provide much needed automated diagnostic
tools (in the form of statistical hypothesis testing) to extreme value
models. Other useful functionality is efficient and user-friendly non-stationary
model fitting, profile likelihood confidence intervals, data generation
in the r-largest order statistics model (GEVr), and ordered p-value multiplicity
adjustments. Also, all routines are implemented to efficiently handle
the near-zero shape parameter, which may cause numerical issues in other
packages. Functions can be roughly assigned to the following topics:
</p>


<h3>Formal (Automated) Goodness-of-Fit Testing</h3>

<p><code><a href="#topic+gevrSeqTests">gevrSeqTests</a></code> is a wrapper function that performs sequential testing
for r in the GEVr distribution, with adjusted p-values. It can implement three
tests:
</p>

<dl>
<dt><code><a href="#topic+gevrEd">gevrEd</a></code></dt><dd><p>An entropy difference test, which uses an asymptotic normal central limit theorem result.</p>
</dd>
<dt><code><a href="#topic+gevrPbScore">gevrPbScore</a></code></dt><dd><p>A score test, implemented using parametric bootstrap and can be run in parallel.</p>
</dd>
<dt><code><a href="#topic+gevrMultScore">gevrMultScore</a></code></dt><dd><p>An asymptotic approximation to the score test (computationally efficient).</p>
</dd>
</dl>

<p><code><a href="#topic+gpdSeqTests">gpdSeqTests</a></code> is a wrapper function that performs sequential testing
for thresholds in the Generalized Pareto distribution (GPD), with adjusted
p-values. It can implement the following (six) tests:
</p>

<dl>
<dt><code><a href="#topic+gpdAd">gpdAd</a></code></dt><dd><p>The Anderson-Darling test, with log-linear interpolated p-values. Can also be bootstrapped
(with a parallel option).</p>
</dd>
<dt><code><a href="#topic+gpdCvm">gpdCvm</a></code></dt><dd><p>The Cramer-Von Mises test, with log-linear interpolated p-values. Can also be bootstrapped
(with a parallel option).</p>
</dd>
<dt><code><a href="#topic+gpdImAsym">gpdImAsym</a></code></dt><dd><p>An asymptotic information matrix test, with bootstrapped covariance estimates.</p>
</dd>
<dt><code><a href="#topic+gpdImPb">gpdImPb</a></code></dt><dd><p>A full bootstrap version of information matrix test, with bootstrapped covariance estimates and critical values.</p>
</dd>
<dt><code><a href="#topic+gpdPbScore">gpdPbScore</a></code></dt><dd><p>A score test, implemented using parametric bootstrap and can be run in parallel.</p>
</dd>
<dt><code><a href="#topic+gpdMultScore">gpdMultScore</a></code></dt><dd><p>An asymptotic approximation to the score test (computationally effciient).</p>
</dd>
</dl>

<p><code><a href="#topic+pSeqStop">pSeqStop</a></code> A simple function that reads in raw, ordered p-values and returns two sets that adjust
for the familywise error rate and false discovery rate.
</p>


<h3>Data generation and model fitting</h3>

<p>All the functions in this section (and package) efficiently handle a near-zero
value of the shape parameter, which can cause numerical instability in similar
functions from other packages. See the vignette for an example.
</p>
<p>Data generation, density, quantile, and distribution functions can handle
non-stationarity and vectorized inputs.
</p>
<p><code><a href="#topic+gevr">gevr</a></code> Data generation and density function for the GEVr distribution,
with distribution function and quantile functions available for GEV1 (block maxima).
</p>
<p><code><a href="#topic+gpd">gpd</a></code> Data generation, distribution, quantile, and density functions
for the GPD distribution.
</p>
<p><code><a href="#topic+gevrFit">gevrFit</a></code> Non-stationary fitting of the GEVr distribution, with the option
of maximum product spacings estimation when r=1. Uses formula statements for
user friendliness and automatically centers/scales covariates when appropriate
to speed up optimization.
</p>
<p><code><a href="#topic+gpdFit">gpdFit</a></code> Non-stationary fitting of the GP distribution, with same
options and implementation as &lsquo;gevrFit&rsquo;. Allows non-stationary
threshold to be used.
</p>
<p><code><a href="#topic+gevrProfShape">gevrProfShape</a></code> Profile likelihood estimation for the shape
parameter of the stationary GEVr distribution.
</p>
<p><code><a href="#topic+gpdProfShape">gpdProfShape</a></code> Profile likelihood estimation for the shape
parameter of the stationary GP distribution.
</p>
<p><code><a href="#topic+gevrRl">gevrRl</a></code> Profile likelihood estimation for return levels
of the stationary GEVr distribution.
</p>
<p><code><a href="#topic+gpdRl">gpdRl</a></code> Profile likelihood estimation for return levels
of the stationary GP distribution.
</p>


<h3>Visual Diagnostics</h3>

<p><code><a href="#topic+gevrDiag">gevrDiag</a></code>, <code><a href="#topic+gpdDiag">gpdDiag</a></code> Diagnostic plots for a fit to
the GEVr (GP) distribution. For stationary models, return level, density, quantile,
and probability plots are returned. For non-stationary models, residual quantile,
residual probability, and residuals versus covariate plots are returned.
</p>
<p><code><a href="#topic+mrlPlot">mrlPlot</a></code> Plots the empirical mean residual life, with
confidence intervals. Visual diagnostic tool to choose a threshold
for exceedances.
</p>


<h3>Data</h3>

<p><code><a href="#topic+fortmax">fortmax</a></code> Top ten annual precipitation events (inches) for
one rain gauge in Fort Collins, Colorado from 1900 through 1999.
</p>
<p><code><a href="#topic+lowestoft">lowestoft</a></code> Top ten annual sea levels at the LoweStoft station
tide gauge from 1964 - 2014.
</p>

<hr>
<h2 id='fortmax'>Top Ten Annual Precipitation: Fort Collins, Colorado</h2><span id='topic+fortmax'></span>

<h3>Description</h3>

<p>Top ten annual precipitation events (inches) for one rain gauge
in Fort Collins, Colorado from 1900 through 1999. See
Katz et al. (2002) Sec. 2.3.1 for more information and analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fortmax)
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 observations. Each year is considered an observation, with the top ten annual precipitation events.
</p>


<h3>Source</h3>

<p>Colorado Climate Center, Colorado State University. This is the original data source containing the daily precipitation data.
</p>


<h3>References</h3>

<p>Katz, R. W., Parlange, M. B. and Naveau, P. (2002) Statistics of extremes in hydrology. Advances in Water Resources, 25, 1287-1304.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fortmax)
y &lt;- fortmax[, -1]
gevrSeqTests(y, method = "ed")
</code></pre>

<hr>
<h2 id='gevr'>The GEVr Distribution</h2><span id='topic+gevr'></span><span id='topic+dgevr'></span><span id='topic+rgevr'></span><span id='topic+qgev'></span><span id='topic+pgev'></span>

<h3>Description</h3>

<p>Random number generation (rgevr) and density (dgevr) functions for the GEVr distribution with parameters loc, scale, and shape.
Also, quantile function (qgev) and cumulative distribution function (pgev) for the GEV1 distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgevr(x, loc = 0, scale = 1, shape = 0, log.d = FALSE)

rgevr(n, r, loc = 0, scale = 1, shape = 0)

qgev(p, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)

pgev(q, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevr_+3A_x">x</code></td>
<td>
<p>Vector or matrix of observations. If x is a matrix, each row is taken to be a new observation.</p>
</td></tr>
<tr><td><code id="gevr_+3A_loc">loc</code>, <code id="gevr_+3A_scale">scale</code>, <code id="gevr_+3A_shape">shape</code></td>
<td>
<p>Location, scale, and shape parameters. Can be vectors, but
the lengths must be appropriate.</p>
</td></tr>
<tr><td><code id="gevr_+3A_log.d">log.d</code></td>
<td>
<p>Logical: Whether or not to return the log density. (FALSE by default)</p>
</td></tr>
<tr><td><code id="gevr_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="gevr_+3A_r">r</code></td>
<td>
<p>Number of order statistics for each observation.</p>
</td></tr>
<tr><td><code id="gevr_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="gevr_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical: If TRUE (default), probabilities are P[X &lt;= x] otherwise, P[X &gt; x].</p>
</td></tr>
<tr><td><code id="gevr_+3A_log.p">log.p</code></td>
<td>
<p>Logical: If TRUE, probabilities p are given as log(p). (FALSE by default)</p>
</td></tr>
<tr><td><code id="gevr_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GEVr data (in matrix x) should be of the form <code class="reqn">x[i,1] &gt; x[i, 2] &gt; \cdots &gt; x[i, r]</code> for each observation
<code class="reqn">i = 1, \ldots, n</code>. Note that currently the quantile and cdf functions are only for the GEV1 distribution. The GEVr
distribution is also known as the r-largest order statistics model and is a generalization of the block maxima model (GEV1).
The density function is given by </p>
<p style="text-align: center;"><code class="reqn">f_r (x_1, x_2, ..., x_r | \mu, \sigma, \xi) = \sigma^{-r} \exp\Big\{-(1+\xi z_r)^{-\frac{1}{\xi}}
- \left(\frac{1}{\xi}+1\right)\sum_{j=1}^{r}\log(1+\xi z_j)\Big\}</code>
</p>
<p> for some location parameter <code class="reqn">\mu</code>,
scale parameter <code class="reqn">\sigma &gt; 0</code>, and shape parameter <code class="reqn">\xi</code>, where <code class="reqn">x_1 &gt; \cdots &gt; x_r</code>, <code class="reqn">z_j = (x_j - \mu) / \sigma</code>,
and <code class="reqn">1 + \xi z_j &gt; 0</code> for <code class="reqn">j=1, \ldots, r</code>. When <code class="reqn">r = 1</code>, this distribution is exactly the GEV distribution.
</p>


<h3>References</h3>

<p>Coles, S. (2001). An introduction to statistical modeling of extreme values (Vol. 208). London: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot the densities of the heavy and bounded upper tail forms of GEVr
set.seed(7)
dat1 &lt;- rgevr(1000, 1, loc = 0, scale = 1, shape = 0.25)
dat2 &lt;- rgevr(1000, 1, loc = 0, scale = 1, shape = -0.25)
hist(dat1, col = rgb(1, 0, 0, 0.5), xlim = c(-5, 10), ylim = c(0, 0.4),
     main = "Histogram of GEVr Densities", xlab = "Value", freq = FALSE)
hist(dat2, col = rgb(0, 0,1, 0.5), add = TRUE, freq = FALSE)
box()

# Generate sample with decreasing trend in location parameter
x &lt;- rgevr(10, 2, loc = 10:1, scale = 1, shape = 0.1)
dgevr(x, loc = 10:1, scale = 10:1, shape = 0.1)

# Incorrect parameter specifications
## Not run: 
rgevr(10, 2, loc = 5:8, scale = 1, shape = 0.1)
rgevr(1, 2, loc = 5:8, scale = 1:2, shape = 0.1)

## End(Not run)
</code></pre>

<hr>
<h2 id='gevrDiag'>Diagnostic plots for a fit to the GEVr distribution.</h2><span id='topic+gevrDiag'></span>

<h3>Description</h3>

<p>Diagnostic plots for a fit to the GEVr distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrDiag(z, conf = 0.95, method = c("delta", "profile"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrDiag_+3A_z">z</code></td>
<td>
<p>A class object returned from &lsquo;gevrFit&rsquo;.</p>
</td></tr>
<tr><td><code id="gevrDiag_+3A_conf">conf</code></td>
<td>
<p>Confidence level used in the return level plot.</p>
</td></tr>
<tr><td><code id="gevrDiag_+3A_method">method</code></td>
<td>
<p>The method to compute the return level confidence interval - either delta method (default) or profile
likelihood. Choosing profile likelihood may be quite slow.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In certain cases the quantile plot may fail, because it requires solving a root equation. See the references for details.
</p>


<h3>Value</h3>

<p>For stationary models, provides return level plot and density, probability,
and quantile plots for each marginal order statistic. The overlaid density is the &lsquo;true&rsquo; marginal
density for the estimated parameters. For nonstationary models, provides residual probability and quantile plots. In addition,
nonstationary models provide plots of the residuals vs. the parameter covariates.
</p>


<h3>References</h3>

<p>Tawn, J. A. (1988). An extreme-value theory model for dependent observations. Journal of Hydrology, 101(1), 227-250.
</p>
<p>Smith, R. L. (1986). Extreme value theory based on the r largest annual events. Journal of Hydrology, 86(1), 27-43.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- rgevr(500, 2, loc = 0.5, scale = 1, shape = 0.1)
z &lt;- gevrFit(x)
plot(z)

## End(Not run)
</code></pre>

<hr>
<h2 id='gevrEd'>GEVr Entropy Difference Test</h2><span id='topic+gevrEd'></span>

<h3>Description</h3>

<p>Goodness-of-fit test for GEVr using the difference in likelihood between GEVr and GEV(r-1).
This can be used sequentially to test for the choice of r.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrEd(data, theta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrEd_+3A_data">data</code></td>
<td>
<p>Data should be contain n rows, each a GEVr observation.</p>
</td></tr>
<tr><td><code id="gevrEd_+3A_theta">theta</code></td>
<td>
<p>Estimate for theta in the vector form (loc, scale, shape). If NULL, uses the MLE from the full data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GEVr data (in matrix x) should be of the form <code class="reqn">x[i,1] &gt; x[i, 2] &gt; \cdots &gt; x[i, r]</code> for each
observation <code class="reqn">i = 1, \ldots, n</code>. The test uses an asymptotic normality result based on the expected
entropy between the GEVr and GEV(r-1) likelihoods. See reference for detailed information. This test can be
used to sequentially test for the choice of r, implemented in the function &lsquo;gevrSeqTests&rsquo;.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimate of theta using the top r order statistics.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bader B., Yan J., &amp; Zhang X. (2015). Automated Selection of r for the r Largest Order Statistics Approach with Adjustment for Sequential Testing. Department of Statistics, University of Connecticut.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># This will test if the GEV2 distribution fits the data.
x &lt;- rgevr(100, 2, loc = 0.5, scale = 1, shape = 0.5)
result &lt;- gevrEd(x)
</code></pre>

<hr>
<h2 id='gevrFit'>Parameter estimation for the GEVr distribution model</h2><span id='topic+gevrFit'></span>

<h3>Description</h3>

<p>This function provides maximum likelihood estimation for the GEVr model, with the option of probability weighted moment and maximum product
spacing estimation for block maxima (GEV1) data. It also allows generalized linear modeling of the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrFit(
  data,
  method = c("mle", "mps", "pwm"),
  information = c("expected", "observed"),
  locvars = NULL,
  scalevars = NULL,
  shapevars = NULL,
  locform = ~1,
  scaleform = ~1,
  shapeform = ~1,
  loclink = identity,
  scalelink = identity,
  shapelink = identity,
  gumbel = FALSE,
  start = NULL,
  opt = "Nelder-Mead",
  maxit = 10000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrFit_+3A_data">data</code></td>
<td>
<p>Data should be a matrix from the GEVr distribution.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_method">method</code></td>
<td>
<p>Method of estimation - maximum likelihood (mle), maximum product spacings (mps), and probability weighted moments (pwm). Uses mle by default.
For <code class="reqn">r &gt; 1</code>, only mle can be used.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_information">information</code></td>
<td>
<p>Whether standard errors should be calculated via observed or expected (default) information. For probability weighted moments,
only expected information will be used if possible. In the case with covariates, only observed information is available.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_locvars">locvars</code>, <code id="gevrFit_+3A_scalevars">scalevars</code>, <code id="gevrFit_+3A_shapevars">shapevars</code></td>
<td>
<p>A dataframe of covariates to use for modeling of the each parameter. Parameter
intercepts are automatically handled by the function. Defaults to NULL for the stationary model.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_locform">locform</code>, <code id="gevrFit_+3A_scaleform">scaleform</code>, <code id="gevrFit_+3A_shapeform">shapeform</code></td>
<td>
<p>An object of class &lsquo;formula&rsquo; (or one that can be coerced into that class), specifying the model
of each parameter. By default, assumes stationary (intercept only) model. See details.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_loclink">loclink</code>, <code id="gevrFit_+3A_scalelink">scalelink</code>, <code id="gevrFit_+3A_shapelink">shapelink</code></td>
<td>
<p>A link function specifying the relationship between the covariates and each parameter. Defaults to the identity function. For
the stationary model, only the identity link should be used.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_gumbel">gumbel</code></td>
<td>
<p>Whether to fit the Gumbel (type I) extreme value distribution (i.e. shape parameter equals zero). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_start">start</code></td>
<td>
<p>Option to provide a set of starting parameters to optim; a vector of location, scale, and shape, in that order. Otherwise, the routine attempts
to find good starting parameters. See details.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_opt">opt</code></td>
<td>
<p>Optimization method to use with optim.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_maxit">maxit</code></td>
<td>
<p>Number of iterations to use in optimization, passed to optim. Defaults to 10,000.</p>
</td></tr>
<tr><td><code id="gevrFit_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to optim.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the stationary case (no covariates), starting parameters for mle and mps estimation are the probability weighted moment estimates.
In the case where covariates are used, the starting intercept parameters are the probability weighted moment estimates from the stationary case
and the parameters based on covariates are initially set to zero. For non-stationary parameters, the first reported estimate refers to the
intercept term. Covariates are centered and scaled automatically to speed up optimization, and then transformed back to original scale. <br />
Formulas for generalized linear modeling of the parameters should be given in the form '~ var1 + var2 + <code class="reqn">\cdots</code>'. Essentially, specification
here is the same as would be if using function &lsquo;lm&rsquo; for only the right hand side of the equation. Interactions, polynomials, etc. can be
handled as in the &lsquo;formula&rsquo; class. <br />
Intercept terms are automatically handled by the function. By default, the link functions are the identity function and the covariate dependent
scale parameter estimates are forced to be positive. For some link function <code class="reqn">f(\cdot)</code> and for example, scale
parameter <code class="reqn">\sigma</code>, the link is written as <code class="reqn">\sigma = f(\sigma_1 x_1 + \sigma_2 x_2 + \cdots + \sigma_k x_k)</code>. <br />
Maximum likelihood estimation can be used in all cases. Probability weighted moment estimation can only be used if <code class="reqn">r = 1</code> and data is
assumed to be stationary. Maximum product spacings estimation can be used in the non-stationary case, but only if <code class="reqn">r = 1</code>.
</p>


<h3>Value</h3>

<p>A list describing the fit, including parameter estimates and standard errors for the mle and mps methods. Returns as a class
object &lsquo;gevrFit&rsquo; to be used with diagnostic plots.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(7)
x1 &lt;- rgevr(500, 1, loc = 0.5, scale = 1, shape = 0.3)
result1 &lt;- gevrFit(x1, method = "mps")

# A linear trend in the location and scale parameter
n &lt;- 100
r &lt;- 10
x2 &lt;- rgevr(n, r, loc = 100 + 1:n / 50,  scale = 1 + 1:n / 300, shape = 0)

covs &lt;- as.data.frame(seq(1, n, 1))
names(covs) &lt;- c("Trend1")
# Create some unrelated covariates
covs$Trend2 &lt;- rnorm(n)
covs$Trend3 &lt;- 30 * runif(n)
result2 &lt;- gevrFit(data = x2, method = "mle", locvars = covs, locform = ~ Trend1 + Trend2*Trend3,
scalevars = covs, scaleform = ~ Trend1)

# Show summary of estimates
result2

</code></pre>

<hr>
<h2 id='gevrMultScore'>GEVr Multiplier Score Test</h2><span id='topic+gevrMultScore'></span>

<h3>Description</h3>

<p>Fast weighted bootstrap alternative to the parametric bootstrap procedure for the GEVr score test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrMultScore(data, bootnum, information = c("expected", "observed"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrMultScore_+3A_data">data</code></td>
<td>
<p>Data should be contain n rows, each a GEVr observation.</p>
</td></tr>
<tr><td><code id="gevrMultScore_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="gevrMultScore_+3A_information">information</code></td>
<td>
<p>To use expected (default) or observed information in the test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GEVr data (in matrix x) should be of the form <code class="reqn">x[i,1] &gt; x[i, 2] &gt; \cdots &gt; x[i, r]</code> for each observation <code class="reqn">i = 1, \ldots, n</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Value of theta used in the test.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bader B., Yan J., &amp; Zhang X. (2015). Automated Selection of r for the r Largest Order Statistics Approach with Adjustment for Sequential Testing. Department of Statistics, University of Connecticut.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgevr(500, 5, loc = 0.5, scale = 1, shape = 0.3)
result &lt;- gevrMultScore(x, bootnum = 1000)
</code></pre>

<hr>
<h2 id='gevrPbScore'>GEVr Parametric Bootstrap Score Test</h2><span id='topic+gevrPbScore'></span>

<h3>Description</h3>

<p>Parametric bootstrap score test procedure to assess goodness-of-fit to the GEVr distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrPbScore(
  data,
  bootnum,
  information = c("expected", "observed"),
  allowParallel = FALSE,
  numCores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrPbScore_+3A_data">data</code></td>
<td>
<p>Data should be contain n rows, each a GEVr observation.</p>
</td></tr>
<tr><td><code id="gevrPbScore_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="gevrPbScore_+3A_information">information</code></td>
<td>
<p>To use expected (default) or observed information in the test.</p>
</td></tr>
<tr><td><code id="gevrPbScore_+3A_allowparallel">allowParallel</code></td>
<td>
<p>Should the bootstrap procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gevrPbScore_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GEVr data (in matrix x) should be of the form <code class="reqn">x[i,1] &gt; x[i, 2] &gt; \cdots &gt; x[i, r]</code> for each observation <code class="reqn">i = 1, \ldots, n</code>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Initial value of theta used in the test.</p>
</td></tr>
<tr><td><code>effective_bootnum</code></td>
<td>
<p>Effective number of bootstrap replicates (only those that converged are used).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bader B., Yan J., &amp; Zhang X. (2015). Automated Selection of r for the r Largest Order Statistics Approach with Adjustment for Sequential Testing. Department of Statistics, University of Connecticut.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data from GEVr

x &lt;- rgevr(200, 5, loc = 0.5, scale = 1, shape = 0.25)
gevrPbScore(x, bootnum = 99)

</code></pre>

<hr>
<h2 id='gevrProfShape'>GEVr Shape Parameter Profile Likelihood Estimation for Stationary Models</h2><span id='topic+gevrProfShape'></span>

<h3>Description</h3>

<p>Computes the profile likelihood based confidence interval for the shape parameter of the stationary GEVr model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrProfShape(z, conf = 0.95, plot = TRUE, opt = c("Nelder-Mead"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrProfShape_+3A_z">z</code></td>
<td>
<p>A class object returned from gevrFit.</p>
</td></tr>
<tr><td><code id="gevrProfShape_+3A_conf">conf</code></td>
<td>
<p>Confidence level to use. Defaults to 95 percent.</p>
</td></tr>
<tr><td><code id="gevrProfShape_+3A_plot">plot</code></td>
<td>
<p>Plot the profile likelihood and estimate (vertical line)?</p>
</td></tr>
<tr><td><code id="gevrProfShape_+3A_opt">opt</code></td>
<td>
<p>Optimization method to maximize the profile likelihood, passed to optim. The default method is Nelder-Mead.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Estimate</code></td>
<td>
<p>Estimated shape parameter.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Profile likelihood based confidence interval for the shape parameter.</p>
</td></tr>
<tr><td><code>ConfLevel</code></td>
<td>
<p>The confidence level used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Compare the length of the shape confidence intervals using GEV1 vs. GEV10
set.seed(7)
x &lt;- rgevr(200, 10, loc = 0.5, scale = 1, shape = -0.3)
z1 &lt;- gevrFit(x[, 1])
z2 &lt;- gevrFit(x)
gevrProfShape(z1)
gevrProfShape(z2)
</code></pre>

<hr>
<h2 id='gevrRl'>GEVr Return Level Estimate and Confidence Interval for Stationary Models</h2><span id='topic+gevrRl'></span>

<h3>Description</h3>

<p>Computes stationary m-period return level estimate and interval, using either the delta method or profile likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrRl(
  z,
  period,
  conf = 0.95,
  method = c("delta", "profile"),
  plot = TRUE,
  opt = c("Nelder-Mead")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrRl_+3A_z">z</code></td>
<td>
<p>A class object returned from gevrFit. Must be a stationary fit.</p>
</td></tr>
<tr><td><code id="gevrRl_+3A_period">period</code></td>
<td>
<p>The number of periods to use for the return level.</p>
</td></tr>
<tr><td><code id="gevrRl_+3A_conf">conf</code></td>
<td>
<p>Confidence level. Defaults to 95 percent.</p>
</td></tr>
<tr><td><code id="gevrRl_+3A_method">method</code></td>
<td>
<p>The method to compute the confidence interval - either delta method (default) or profile likelihood.</p>
</td></tr>
<tr><td><code id="gevrRl_+3A_plot">plot</code></td>
<td>
<p>Plot the profile likelihood and estimate (vertical line)?</p>
</td></tr>
<tr><td><code id="gevrRl_+3A_opt">opt</code></td>
<td>
<p>Optimization method to maximize the profile likelihood if that is selected. The default method is Nelder-Mead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is generally accepted that profile likelihood confidence intervals provide greater accuracy than the delta
method, in particular for large return level periods. Also, by their nature, delta method confidence intervals must be symmetric
which may be undesirable for return level estimation. If the original fit was Gumbel, then return levels will be for the Gumbel
distribution.
</p>
<p>Caution: The profile likelihood optimization may be slow (on the order of minutes).
</p>


<h3>Value</h3>

<table>
<tr><td><code>Estimate</code></td>
<td>
<p>Estimated m-period return level.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Confidence interval for the m-period return level.</p>
</td></tr>
<tr><td><code>Period</code></td>
<td>
<p>The period length used.</p>
</td></tr>
<tr><td><code>ConfLevel</code></td>
<td>
<p>The confidence level used.</p>
</td></tr>
</table>


<h3>References</h3>

<p>http://www.mas.ncl.ac.uk/~nlf8/teaching/mas8391/background/chapter2.pdf
</p>
<p>Coles, S. (2001). An introduction to statistical modeling of extreme values (Vol. 208). London: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgevr(100, 2, loc = 0.5, scale = 1, shape = -0.3)
z &lt;- gevrFit(x)
# Compute 250-period return level.
gevrRl(z, 250, method = "delta")
</code></pre>

<hr>
<h2 id='gevrSeqTests'>Sequential Tests for the GEVr Model</h2><span id='topic+gevrSeqTests'></span>

<h3>Description</h3>

<p>Sequentially performs the entropy difference (ED) test or the multiplier or parametric bootstrap score tests for the GEVr model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevrSeqTests(
  data,
  bootnum = NULL,
  method = c("ed", "pbscore", "multscore"),
  information = c("expected", "observed"),
  allowParallel = FALSE,
  numCores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gevrSeqTests_+3A_data">data</code></td>
<td>
<p>Data should be contain n rows, each a GEVr observation.</p>
</td></tr>
<tr><td><code id="gevrSeqTests_+3A_bootnum">bootnum</code></td>
<td>
<p>If method equals 'pbscore' or 'multscore', the number of bootstrap simulations to use.</p>
</td></tr>
<tr><td><code id="gevrSeqTests_+3A_method">method</code></td>
<td>
<p>Which test to run: ED test (ed), multiplier (multscore) or parametric bootstrap (pbscore) score test.</p>
</td></tr>
<tr><td><code id="gevrSeqTests_+3A_information">information</code></td>
<td>
<p>To use expected (default) or observed information in the score tests.</p>
</td></tr>
<tr><td><code id="gevrSeqTests_+3A_allowparallel">allowParallel</code></td>
<td>
<p>If method equals 'pbscore', should the parametric boostrap procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gevrSeqTests_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GEVr data (in matrix x) should be of the form <code class="reqn">x[i,1] &gt; x[i, 2] &gt; \cdots &gt; x[i, r]</code> for each observation <code class="reqn">i = 1, \ldots, n</code>.
See function &lsquo;pSeqStop&rsquo; for details on transformed p-values.
</p>


<h3>Value</h3>

<p>Function returns a dataframe containing the test statistics, estimates, and p-value results of the sequential tests.
</p>
<table>
<tr><td><code>r</code></td>
<td>
<p>Value of r to be tested.</p>
</td></tr>
<tr><td><code>p.values</code></td>
<td>
<p>Raw p-values from the individual tests at each value of r.</p>
</td></tr>
<tr><td><code>ForwardStop</code></td>
<td>
<p>Transformed p-values according to the ForwardStop stopping rule.</p>
</td></tr>
<tr><td><code>StrongStop</code></td>
<td>
<p>Transformed p-values according to the StrongStop stopping rule.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Returned test statistics of each individual test.</p>
</td></tr>
<tr><td><code>est.loc</code></td>
<td>
<p>Estimated location parameter for the given r.</p>
</td></tr>
<tr><td><code>est.scale</code></td>
<td>
<p>Estimated scale parameter for the given r.</p>
</td></tr>
<tr><td><code>est.shape</code></td>
<td>
<p>Estimated shape parameter for the given r.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgevr(200, 5, loc = 0.5, scale = 1, shape = 0.25)
gevrSeqTests(x, method = "ed")
</code></pre>

<hr>
<h2 id='gpd'>The Generalized Pareto Distribution (GPD)</h2><span id='topic+gpd'></span><span id='topic+dgpd'></span><span id='topic+rgpd'></span><span id='topic+qgpd'></span><span id='topic+pgpd'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random number generation for the Generalized Pareto
distribution with location, scale, and shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgpd(x, loc = 0, scale = 1, shape = 0, log.d = FALSE)

rgpd(n, loc = 0, scale = 1, shape = 0)

qgpd(p, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)

pgpd(q, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpd_+3A_x">x</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="gpd_+3A_loc">loc</code>, <code id="gpd_+3A_scale">scale</code>, <code id="gpd_+3A_shape">shape</code></td>
<td>
<p>Location, scale, and shape parameters. Can be vectors, but
the lengths must be appropriate.</p>
</td></tr>
<tr><td><code id="gpd_+3A_log.d">log.d</code></td>
<td>
<p>Logical; if TRUE, the log density is returned.</p>
</td></tr>
<tr><td><code id="gpd_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="gpd_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="gpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if TRUE (default), probabilities are P[X &lt;= x], otherwise, P[X &gt; x].</p>
</td></tr>
<tr><td><code id="gpd_+3A_log.p">log.p</code></td>
<td>
<p>Logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="gpd_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Pareto distribution function is given (Pickands, 1975)
by </p>
<p style="text-align: center;"><code class="reqn">H(y) = 1 - \Big[1 + \frac{\xi (y - \mu)}{\sigma}\Big]^{-1/\xi}</code>
</p>
<p> defined
on <code class="reqn">\{y : y &gt; 0, (1 + \xi (y - \mu) / \sigma) &gt; 0 \}</code>, with location <code class="reqn">\mu</code>,
scale <code class="reqn">\sigma &gt; 0</code>, and shape parameter <code class="reqn">\xi</code>.
</p>


<h3>References</h3>

<p>Pickands III, J. (1975). Statistical inference using extreme order statistics. Annals of Statistics, 119-131.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dgpd(2:4, 1, 0.5, 0.01)
dgpd(2, -2:1, 0.5, 0.01)
pgpd(2:4, 1, 0.5, 0.01)
qgpd(seq(0.9, 0.6, -0.1), 2, 0.5, 0.01)
rgpd(6, 1, 0.5, 0.01)

# Generate sample with linear trend in location parameter
rgpd(6, 1:6, 0.5, 0.01)

# Generate sample with linear trend in location and scale parameter
rgpd(6, 1:6, seq(0.5, 3, 0.5), 0.01)

p &lt;- (1:9)/10
pgpd(qgpd(p, 1, 2, 0.8), 1, 2, 0.8)

# Incorrect syntax (parameter vectors are of different lengths other than 1)
## Not run: 
rgpd(1, 1:8, 1:5, 0)
rgpd(10, 1:8, 1, 0.01)

## End(Not run)
</code></pre>

<hr>
<h2 id='gpdAd'>Generalized Pareto Distribution Anderson-Darling Test</h2><span id='topic+gpdAd'></span>

<h3>Description</h3>

<p>Anderson-Darling goodness-of-fit test for the Generalized Pareto (GPD) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdAd(
  data,
  bootstrap = FALSE,
  bootnum = NULL,
  allowParallel = FALSE,
  numCores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdAd_+3A_data">data</code></td>
<td>
<p>Data should be in vector form, assumed to be from the GPD.</p>
</td></tr>
<tr><td><code id="gpdAd_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should bootstrap be used to obtain p-values for the test? By default, a table of critical values is used via interpolation. See details.</p>
</td></tr>
<tr><td><code id="gpdAd_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of replicates if bootstrap is used.</p>
</td></tr>
<tr><td><code id="gpdAd_+3A_allowparallel">allowParallel</code></td>
<td>
<p>Should the bootstrap procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gpdAd_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A table of critical values were generated via Monte Carlo simulation for shape
parameters -0.5 to 1.0 by 0.1, which provides p-values via log-linear interpolation from
.001 to .999. For p-values below .001, a linear equation exists by regressing -log(p-value)
on the critical values for the tail of the distribution (.950 to .999 upper percentiles). This
regression provides a method to extrapolate to arbitrarily small p-values.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated value of theta for the initial data.</p>
</td></tr>
<tr><td><code>effective_bootnum</code></td>
<td>
<p>Effective number of bootstrap replicates if bootstrap
based p-value is used (only those that converged are used).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Choulakian, V., &amp; Stephens, M. A. (2001). Goodness-of-fit tests for the Generalized Pareto distribution. Technometrics, 43(4), 478-484.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data from GPD
x &lt;- rgpd(200, loc = 0, scale = 1, shape = 0.2)
gpdAd(x)
</code></pre>

<hr>
<h2 id='gpdCvm'>Generalized Pareto Distribution Cramer-von Mises Test</h2><span id='topic+gpdCvm'></span>

<h3>Description</h3>

<p>Cramer-von Mises goodness-of-fit test for the Generalized Pareto (GPD) distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdCvm(
  data,
  bootstrap = FALSE,
  bootnum = NULL,
  allowParallel = FALSE,
  numCores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdCvm_+3A_data">data</code></td>
<td>
<p>Data should be in vector form, assumed to be from the GPD.</p>
</td></tr>
<tr><td><code id="gpdCvm_+3A_bootstrap">bootstrap</code></td>
<td>
<p>Should bootstrap be used to obtain p-values for the test? By default, a table of critical values is used via interpolation. See details.</p>
</td></tr>
<tr><td><code id="gpdCvm_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="gpdCvm_+3A_allowparallel">allowParallel</code></td>
<td>
<p>Should the bootstrap procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gpdCvm_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A table of critical values were generated via Monte Carlo simulation for shape
parameters -0.5 to 1.0 by 0.1, which provides p-values via log-linear interpolation from
.001 to .999. For p-values below .001, a linear equation exists by regressing -log(p-value)
on the critical values for the tail of the distribution (.950 to .999 upper percentiles). This
regression provides a method to extrapolate to arbitrarily small p-values.
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated value of theta for the initial data.</p>
</td></tr>
<tr><td><code>effective_bootnum</code></td>
<td>
<p>Effective number of bootstrap replicates if bootstrap
based p-value is used (only those that converged are used).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Choulakian, V., &amp; Stephens, M. A. (2001). Goodness-of-fit tests for the Generalized Pareto distribution. Technometrics, 43(4), 478-484.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data from GPD
x &lt;- rgpd(200, loc = 0, scale = 1, shape = 0.2)
gpdCvm(x)
</code></pre>

<hr>
<h2 id='gpdDiag'>Diagnostic plots for a fit to the Generalized Pareto distribution</h2><span id='topic+gpdDiag'></span>

<h3>Description</h3>

<p>Diagnostic plots for a fit to the Generalized Pareto distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdDiag(z, conf = 0.95, method = c("delta", "profile"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdDiag_+3A_z">z</code></td>
<td>
<p>A class object returned from &lsquo;gpdFit&rsquo;.</p>
</td></tr>
<tr><td><code id="gpdDiag_+3A_conf">conf</code></td>
<td>
<p>Confidence level used in the return level plot.</p>
</td></tr>
<tr><td><code id="gpdDiag_+3A_method">method</code></td>
<td>
<p>The method to compute the return level confidence interval - either delta method (default) or
profile likelihood. Choosing profile likelihood may be quite slow.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for details on how return levels are calculated.
</p>


<h3>Value</h3>

<p>For stationary models, provides return level, density, probability, and quantile plots for the GPD exceedances. The
overlaid density is the &lsquo;true&rsquo; density for the estimated parameters. For nonstationary models, provides
residual probability and quantile plots. In addition, nonstationary models provide plots of the residuals vs.
the parameter covariates.
</p>


<h3>References</h3>

<p>Coles, S. (2001). An introduction to statistical modeling of extreme values (Vol. 208). London: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- rgpd(10000, loc = 0.5, scale = 1, shape = 0.1)
z &lt;- gpdFit(x, nextremes = 500)
plot(z)

## End(Not run)
</code></pre>

<hr>
<h2 id='gpdFit'>Parameter estimation for the Generalized Pareto Distribution (GPD)</h2><span id='topic+gpdFit'></span>

<h3>Description</h3>

<p>Fits exceedances above a chosen threshold to the Generalized Pareto model. Various estimation procedures can be used,
including maximum likelihood, probability weighted moments, and maximum product spacing. It also allows
generalized linear modeling of the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdFit(
  data,
  threshold = NA,
  nextremes = NA,
  npp = 365,
  method = c("mle", "mps", "pwm"),
  information = c("expected", "observed"),
  scalevars = NULL,
  shapevars = NULL,
  scaleform = ~1,
  shapeform = ~1,
  scalelink = identity,
  shapelink = identity,
  start = NULL,
  opt = "Nelder-Mead",
  maxit = 10000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdFit_+3A_data">data</code></td>
<td>
<p>Data should be a numeric vector from the GPD.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_threshold">threshold</code></td>
<td>
<p>A threshold value or vector of the same length as the data.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_nextremes">nextremes</code></td>
<td>
<p>Number of upper extremes to be used (either this or the threshold must be given, but not both).</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_npp">npp</code></td>
<td>
<p>Length of each period (typically year). Is used in return level estimation. Defaults to 365.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_method">method</code></td>
<td>
<p>Method of estimation - maximum likelihood (mle), maximum product spacing (mps), and
probability weighted moments (pwm). Uses mle by default. For pwm, only the stationary model can be fit.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_information">information</code></td>
<td>
<p>Whether standard errors should be calculated via observed or expected (default) information. For probability
weighted moments, only expected information will be used if possible. For non-stationary models, only observed
information is used.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_scalevars">scalevars</code>, <code id="gpdFit_+3A_shapevars">shapevars</code></td>
<td>
<p>A dataframe of covariates to use for modeling of the each parameter. Parameter
intercepts are automatically handled by the function. Defaults to NULL for the stationary model.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_scaleform">scaleform</code>, <code id="gpdFit_+3A_shapeform">shapeform</code></td>
<td>
<p>An object of class &lsquo;formula&rsquo; (or one that can be coerced into that class), specifying the model
of each parameter. By default, assumes stationary (intercept only) model. See details.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_scalelink">scalelink</code>, <code id="gpdFit_+3A_shapelink">shapelink</code></td>
<td>
<p>A link function specifying the relationship between the covariates and each parameter. Defaults to
the identity function. For the stationary model, only the identity link should be used.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_start">start</code></td>
<td>
<p>Option to provide a set of starting parameters to optim; a vector of scale and shape, in that order. Otherwise,
the routine attempts to find good starting parameters. See details.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_opt">opt</code></td>
<td>
<p>Optimization method to use with optim.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_maxit">maxit</code></td>
<td>
<p>Number of iterations to use in optimization, passed to optim. Defaults to 10,000.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to optim.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The base code for finding probability weighted moments is taken from the R package evir. See citation.
In the stationary case (no covariates), starting parameters for mle and mps estimation are the probability weighted moment estimates.
In the case where covariates are used, the starting intercept parameters are the probability weighted moment estimates from the
stationary case and the parameters based on covariates are initially set to zero. For non-stationary parameters, the
first reported estimate refers to the intercept term. Covariates are centered and scaled automatically to speed up optimization,
and then transformed back to original scale. <br />
Formulas for generalized linear modeling of the parameters should be given in the form '~ var1 + var2 + <code class="reqn">\cdots</code>'. Essentially,
specification here is the same as would be if using function &lsquo;lm&rsquo; for only the right hand side of the equation. Interactions,
polynomials, etc. can be handled as in the &lsquo;formula&rsquo; class. <br />
Intercept terms are automatically handled by the function. By default, the link functions are the identity function and
the covariate dependent scale parameter estimates are forced to be positive. For some link function <code class="reqn">f(\cdot)</code> and for
example, scale parameter <code class="reqn">\sigma</code>, the link is written as <code class="reqn">\sigma = f(\sigma_1 x_1 + \sigma_2 x_2 + \cdots + \sigma_k x_k)</code>. <br />
Maximum likelihood estimation and maximum product spacing estimation can be used in all cases. Probability weighted moments
can only be used for stationary models.
</p>


<h3>Value</h3>

<p>A class object &lsquo;gpdFit&rsquo; describing the fit, including parameter estimates and standard errors.
</p>


<h3>References</h3>

<p>Pfaff, Bernhard, Alexander McNeil, and A. Stephenson. &quot;evir: Extreme Values in R.&quot; R package version (2012): 1-7.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit data using the three different estimation procedures
set.seed(7)
x &lt;- rgpd(2000, loc = 0, scale = 2, shape = 0.2)

# Set threshold at 4
mle_fit &lt;- gpdFit(x, threshold = 4, method = "mle")
pwm_fit &lt;- gpdFit(x, threshold = 4, method = "pwm")
mps_fit &lt;- gpdFit(x, threshold = 4, method = "mps")

# Look at the difference in parameter estimates and errors
mle_fit$par.ests
pwm_fit$par.ests
mps_fit$par.ests

mle_fit$par.ses
pwm_fit$par.ses
mps_fit$par.ses

# A linear trend in the scale parameter
set.seed(7)
n &lt;- 300
x2 &lt;- rgpd(n, loc = 0, scale = 1 + 1:n / 200, shape = 0)

covs &lt;- as.data.frame(seq(1, n, 1))
names(covs) &lt;- c("Trend1")

result1 &lt;- gpdFit(x2, threshold = 0, scalevars = covs, scaleform = ~ Trend1)

# Show summary of estimates
result1

</code></pre>

<hr>
<h2 id='gpdImAsym'>GPD Asymptotic Adjusted Information Matrix (IM) Test</h2><span id='topic+gpdImAsym'></span>

<h3>Description</h3>

<p>Runs the IM Test using bootstrap estimated covariance matrix. Asymptotically (in sample size) follows the F(3, bootnum - 3)
distribution (see reference for details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdImAsym(data, bootnum, theta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdImAsym_+3A_data">data</code></td>
<td>
<p>Data should be in vector form.</p>
</td></tr>
<tr><td><code id="gpdImAsym_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of bootstrap replicates for the covariance estimate.</p>
</td></tr>
<tr><td><code id="gpdImAsym_+3A_theta">theta</code></td>
<td>
<p>Estimate for theta in the vector form (scale, shape). If NULL, uses the MLE.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Value of theta used in the test.</p>
</td></tr>
<tr><td><code>effective_bootnum</code></td>
<td>
<p>Effective number of bootstrap replicates used for the covariance estimate. If a
replicate fails to converge, it will not be used in the estimation.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dhaene, G., &amp; Hoorelbeke, D. (2004). The information matrix test with bootstrap-based covariance matrix estimation. Economics Letters, 82(3), 341-347.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data from GPD
x &lt;- rgpd(200, loc = 0, scale = 1, shape = 0.2)
gpdImAsym(x, bootnum = 50)
</code></pre>

<hr>
<h2 id='gpdImPb'>GPD Bootstrapped Information Matrix (IM) Test</h2><span id='topic+gpdImPb'></span>

<h3>Description</h3>

<p>Runs the IM Test using a two-step iterative procedure, to boostrap the covariance estimate and critical values. See reference for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdImPb(data, inner, outer, allowParallel = FALSE, numCores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdImPb_+3A_data">data</code></td>
<td>
<p>Data should be in vector form.</p>
</td></tr>
<tr><td><code id="gpdImPb_+3A_inner">inner</code></td>
<td>
<p>Number of bootstrap replicates for the covariance estimate.</p>
</td></tr>
<tr><td><code id="gpdImPb_+3A_outer">outer</code></td>
<td>
<p>Number of bootstrap replicates for critical values.</p>
</td></tr>
<tr><td><code id="gpdImPb_+3A_allowparallel">allowParallel</code></td>
<td>
<p>Should the outer bootstrap procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gpdImPb_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Warning: This test can be very slow, since the covariance estimation is nested within the outer replicates. It would be
recommended to use a small number of replicates for the covariance estimate (at most 50).
</p>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimate of theta for the initial dataset.</p>
</td></tr>
<tr><td><code>effective_bootnum</code></td>
<td>
<p>Effective number of outer bootstrap replicates used (only those that converged are used).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Dhaene, G., &amp; Hoorelbeke, D. (2004). The information matrix test with bootstrap-based covariance matrix estimation. Economics Letters, 82(3), 341-347.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rgpd(200, loc = 0, scale = 1, shape = 0.2)
gpdImPb(x, inner = 20, outer = 99)

</code></pre>

<hr>
<h2 id='gpdMultScore'>GPD Multiplier Score Test</h2><span id='topic+gpdMultScore'></span>

<h3>Description</h3>

<p>Fast weighted bootstrap alternative to the parametric bootstrap procedure for the Generalized Pareto score test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdMultScore(data, bootnum, information = c("expected", "observed"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdMultScore_+3A_data">data</code></td>
<td>
<p>Data should be in vector form.</p>
</td></tr>
<tr><td><code id="gpdMultScore_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="gpdMultScore_+3A_information">information</code></td>
<td>
<p>To use expected (default) or observed information in the test.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Value of theta used in the test.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgpd(100, loc = 0, scale = 1, shape = 0.25)
gpdMultScore(x, bootnum = 1000)
</code></pre>

<hr>
<h2 id='gpdPbScore'>GPD Parametric Bootstrap Score Test</h2><span id='topic+gpdPbScore'></span>

<h3>Description</h3>

<p>Parametric bootstrap score test procedure to assess goodness-of-fit to the Generalized Pareto distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdPbScore(
  data,
  bootnum,
  information = c("expected", "observed"),
  allowParallel = FALSE,
  numCores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdPbScore_+3A_data">data</code></td>
<td>
<p>Data should be in vector form.</p>
</td></tr>
<tr><td><code id="gpdPbScore_+3A_bootnum">bootnum</code></td>
<td>
<p>Number of bootstrap replicates.</p>
</td></tr>
<tr><td><code id="gpdPbScore_+3A_information">information</code></td>
<td>
<p>To use expected (default) or observed information in the test.</p>
</td></tr>
<tr><td><code id="gpdPbScore_+3A_allowparallel">allowParallel</code></td>
<td>
<p>Should the bootstrap procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gpdPbScore_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>statistic</code></td>
<td>
<p>Test statistic.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>P-value for the test.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated value of theta for the initial data.</p>
</td></tr>
<tr><td><code>effective_bootnum</code></td>
<td>
<p>Effective number of bootstrap replicates (only those that converged are used).</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># Generate some data from GPD
x &lt;- rgpd(200, loc = 0, scale = 1, shape = 0.2)
gpdPbScore(x, bootnum = 100)
</code></pre>

<hr>
<h2 id='gpdProfShape'>GPD Shape Parameter Profile Likelihood Estimation for Stationary Models</h2><span id='topic+gpdProfShape'></span>

<h3>Description</h3>

<p>Computes the profile likelihood based confidence interval for the shape parameter of the stationary Generalized Pareto model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdProfShape(z, conf = 0.95, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdProfShape_+3A_z">z</code></td>
<td>
<p>A class object returned from gpdFit.</p>
</td></tr>
<tr><td><code id="gpdProfShape_+3A_conf">conf</code></td>
<td>
<p>Confidence level to use. Defaults to 95 percent.</p>
</td></tr>
<tr><td><code id="gpdProfShape_+3A_plot">plot</code></td>
<td>
<p>Plot the profile likelihood and estimate (vertical line)?</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Estimate</code></td>
<td>
<p>Estimated shape parameter.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Profile likelihood based confidence interval for the shape parameter.</p>
</td></tr>
<tr><td><code>ConfLevel</code></td>
<td>
<p>The confidence level used.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgpd(200, loc = 0, scale = 1, shape = 0.25)
z &lt;- gpdFit(x, threshold = 0)
gpdProfShape(z)
</code></pre>

<hr>
<h2 id='gpdRl'>GPD Return Level Estimate and Confidence Interval for Stationary Models</h2><span id='topic+gpdRl'></span>

<h3>Description</h3>

<p>Computes stationary m-period return level estimate and interval for the Generalized Pareto distribution,
using either the delta method or profile likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdRl(
  z,
  period,
  conf = 0.95,
  method = c("delta", "profile"),
  plot = TRUE,
  opt = c("Nelder-Mead")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdRl_+3A_z">z</code></td>
<td>
<p>An object of class &lsquo;gpdFit&rsquo;.</p>
</td></tr>
<tr><td><code id="gpdRl_+3A_period">period</code></td>
<td>
<p>The number of periods to use for the return level.</p>
</td></tr>
<tr><td><code id="gpdRl_+3A_conf">conf</code></td>
<td>
<p>Confidence level. Defaults to 95 percent.</p>
</td></tr>
<tr><td><code id="gpdRl_+3A_method">method</code></td>
<td>
<p>The method to compute the confidence interval - either delta method (default) or profile likelihood.</p>
</td></tr>
<tr><td><code id="gpdRl_+3A_plot">plot</code></td>
<td>
<p>Plot the profile likelihood and estimate (vertical line)?</p>
</td></tr>
<tr><td><code id="gpdRl_+3A_opt">opt</code></td>
<td>
<p>Optimization method to maximize the profile likelihood if that is selected. Argument passed to optim. The
default method is Nelder-Mead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Caution: The profile likelihood optimization may be slow for large datasets.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Estimate</code></td>
<td>
<p>Estimated m-period return level.</p>
</td></tr>
<tr><td><code>CI</code></td>
<td>
<p>Confidence interval for the m-period return level.</p>
</td></tr>
<tr><td><code>Period</code></td>
<td>
<p>The period length used.</p>
</td></tr>
<tr><td><code>ConfLevel</code></td>
<td>
<p>The confidence level used.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coles, S. (2001). An introduction to statistical modeling of extreme values (Vol. 208). London: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgpd(5000, loc = 0, scale = 1, shape = -0.1)
# Compute 50-period return level.
z &lt;- gpdFit(x, nextremes = 200)
gpdRl(z, period = 50, method = "delta")
gpdRl(z, period = 50, method = "profile")
</code></pre>

<hr>
<h2 id='gpdSeqTests'>GPD Multiple Threshold Goodness-of-Fit Testing</h2><span id='topic+gpdSeqTests'></span>

<h3>Description</h3>

<p>Wrapper function to test multiple thresholds for goodness-of-fit to the Generalized Pareto model. Can choose which test to
run from the available tests in this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdSeqTests(
  data,
  thresholds = NULL,
  nextremes = NULL,
  method = c("ad", "cvm", "pbscore", "multscore", "imasym", "impb"),
  nsim = NULL,
  inner = NULL,
  outer = NULL,
  information = c("expected", "observed"),
  allowParallel = FALSE,
  numCores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gpdSeqTests_+3A_data">data</code></td>
<td>
<p>Original, full dataset in vector form.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_thresholds">thresholds</code></td>
<td>
<p>A set of threshold values (either this or a set of the number of extremes must be given, but not both). Must be provided as a vector.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_nextremes">nextremes</code></td>
<td>
<p>A set of the number of upper extremes to be used, provided as a vector.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_method">method</code></td>
<td>
<p>Which test to run to sequentially test the thresholds. Must be one of &lsquo;ad&rsquo;, &lsquo;cvm&rsquo;, &lsquo;pbscore&rsquo;, &lsquo;multscore&rsquo;, &lsquo;imasym&rsquo;, or &lsquo;impb&rsquo;.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_nsim">nsim</code></td>
<td>
<p>Number of boostrap replicates for the &lsquo;ad&rsquo;, &lsquo;cvm&rsquo;, &lsquo;pbscore&rsquo;, &lsquo;multscore&rsquo;, and &lsquo;imasym&rsquo; tests.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_inner">inner</code></td>
<td>
<p>Number of inner boostrap replicates if &lsquo;impb&rsquo; test is chosen.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_outer">outer</code></td>
<td>
<p>Number of outer boostrap replicates if &lsquo;impb&rsquo; test is chosen.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_information">information</code></td>
<td>
<p>To use observed or expected (default) information for the &lsquo;pbscore&rsquo; and &lsquo;multscore&rsquo; tests.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_allowparallel">allowParallel</code></td>
<td>
<p>If selected, should the &lsquo;cvm&rsquo;, &lsquo;ad&rsquo;, &lsquo;pbscore&rsquo;, or &lsquo;impb&rsquo; procedure be run in parallel or not. Defaults to false.</p>
</td></tr>
<tr><td><code id="gpdSeqTests_+3A_numcores">numCores</code></td>
<td>
<p>If allowParallel is true, specify the number of cores to use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function returns a matrix containing the thresholds used, the number of observations above each threshold,
the corresponding test statistics, p-values (raw and transformed), and parameter estimates at each threshold. The user must provide
the data, a vector of thresholds or number of upper extremes to be used, and select the test.
</p>


<h3>Value</h3>

<table>
<tr><td><code>threshold</code></td>
<td>
<p>The threshold used for the test.</p>
</td></tr>
<tr><td><code>num.above</code></td>
<td>
<p>The number of observations above the given threshold.</p>
</td></tr>
<tr><td><code>p.values</code></td>
<td>
<p>Raw p-values for the thresholds tested.</p>
</td></tr>
<tr><td><code>ForwardStop</code></td>
<td>
<p>Transformed p-values according to the ForwardStop stopping rule.</p>
</td></tr>
<tr><td><code>StrongStop</code></td>
<td>
<p>Transformed p-values according to the StrongStop stopping rule.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>Returned test statistics of each individual test.</p>
</td></tr>
<tr><td><code>est.scale</code></td>
<td>
<p>Estimated scale parameter for the given threshold.</p>
</td></tr>
<tr><td><code>est.shape</code></td>
<td>
<p>Estimated shape parameter for the given threshold.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(7)
x &lt;- rgpd(10000, loc = 0, scale = 5, shape = 0.2)
## A vector of thresholds to test
threshes &lt;- c(1.5, 2.5, 3.5, 4.5, 5.5)
gpdSeqTests(x, thresholds = threshes, method = "ad")
</code></pre>

<hr>
<h2 id='lowestoft'>Top Ten Annual Sea Levels: Lowestoft, UK (1964 - 2014)</h2><span id='topic+lowestoft'></span>

<h3>Description</h3>

<p>Top ten annual sea levels at the LoweStoft Station tide gauge from 1964 - 2014.
From 1964 - 1992, raw data is collected in hour intervals; from 1993 - present,
raw data is collected in fifteen minute intervals. Data is pre-processed here to
account for storm length - see reference for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lowestoft)
</code></pre>


<h3>Format</h3>

<p>A data matrix with 51 observations. Each year is considered an observation, with the top ten annual sea level events.
</p>


<h3>Source</h3>

<p>UK Tide Gauge Network (Lowestoft Station): https://www.bodc.ac.uk/data/online_delivery/ntslf/processed/
</p>


<h3>References</h3>

<p>Bader B., Yan J., &amp; Zhang X. (2015). Automated Selection of r for the r Largest Order Statistics Approach with Adjustment for Sequential Testing. Department of Statistics, University of Connecticut.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lowestoft)
gevrSeqTests(lowestoft, method = "ed")
## Not run
## Look at the difference in confidence intervals between r = 1 and r = 10
# z1 &lt;- gevrFit(lowestoft[, 1])
# z2 &lt;- gevrFit(lowestoft)
# gevrRl(z1, 50, method = "profile")
# gevrRl(z2, 50, method = "profile")
</code></pre>

<hr>
<h2 id='mrlPlot'>Mean Residual Life Plot for the Generalized Pareto Distribution</h2><span id='topic+mrlPlot'></span>

<h3>Description</h3>

<p>Plots the empirical mean residual life, with confidence intervals. The mean residual life plot provides a
visual diagnostic tool to choose a threshold for exceedances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mrlPlot(data, thresholds = NULL, conf = 0.95, npoints = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mrlPlot_+3A_data">data</code></td>
<td>
<p>Vector of data.</p>
</td></tr>
<tr><td><code id="mrlPlot_+3A_thresholds">thresholds</code></td>
<td>
<p>A numeric vector of threshold(s) to plot vertically. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="mrlPlot_+3A_conf">conf</code></td>
<td>
<p>The level of the confidence bounds to use. Defaults to 0.95.</p>
</td></tr>
<tr><td><code id="mrlPlot_+3A_npoints">npoints</code></td>
<td>
<p>The number of points to interpolate with. Defaults to 100.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- rgpd(500, loc = 0, scale = 1, shape = 0.1)
mrlPlot(x, thresholds = c(2))

</code></pre>

<hr>
<h2 id='pSeqStop'>P-Value Sequential Adjustment</h2><span id='topic+pSeqStop'></span>

<h3>Description</h3>

<p>Given a set of (ordered) p-values, returns p-values adjusted according to the ForwardStop and StrongStop stopping rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pSeqStop(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pSeqStop_+3A_p">p</code></td>
<td>
<p>Vector of ordered p-values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Roughly speaking, under the assumption of independent but ordered p-values, the StrongStop adjusted p-values
control for the familywise error rate, while ForwardStop provides control for the false discovery rate.
</p>


<h3>Value</h3>

<table>
<tr><td><code>StrongStop</code></td>
<td>
<p>Vector of ordered p-values adjusted for the familywise error rate.</p>
</td></tr>
<tr><td><code>ForwardStop</code></td>
<td>
<p>Vector of ordered p-values adjusted for the false discovery rate.</p>
</td></tr>
<tr><td><code>UnAdjusted</code></td>
<td>
<p>Vector of non-transformed p-values.</p>
</td></tr>
</table>


<h3>References</h3>

<p>G'Sell, M. G., Wager, S., Chouldechova, A., &amp; Tibshirani, R. (2013). Sequential Selection Procedures and False Discovery Rate Control. arXiv preprint arXiv:1309.5352.
</p>
<p>Benjamini, Y., &amp; Hochberg, Y. (1995). Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Methodological), 289-300.
</p>
<p>Bader B., Yan J., &amp; Zhang X. (2015). Automated Selection of r for the r Largest Order Statistics Approach with Adjustment for Sequential Testing. Department of Statistics, University of Connecticut.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rgevr(500, 10, loc = 0.5, scale = 1, shape = 0.5)
y &lt;- gevrSeqTests(x, method = "ed")
pSeqStop(rev(y$p.values))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
