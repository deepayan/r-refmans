<!DOCTYPE html><html><head><title>Help for package s3fs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {s3fs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#s3fs-package'><p>s3fs: 'Amazon Web Service S3' File System</p></a></li>
<li><a href='#copy'><p>Copy files and directories</p></a></li>
<li><a href='#copy_async'><p>Copy files and directories</p></a></li>
<li><a href='#create'><p>Create files and directories</p></a></li>
<li><a href='#delete'><p>Delete files and directories</p></a></li>
<li><a href='#delete_async'><p>Delete files and directories</p></a></li>
<li><a href='#download'><p>Download files and directories</p></a></li>
<li><a href='#download_async'><p>Download files and directories</p></a></li>
<li><a href='#exists'><p>Download files and directories</p></a></li>
<li><a href='#file_type'><p>Functions to test for file types</p></a></li>
<li><a href='#info'><p>Get files and directories information</p></a></li>
<li><a href='#path'><p>Construct path for file or directory</p></a></li>
<li><a href='#path_manipulate'><p>Manipulate s3 uri paths</p></a></li>
<li><a href='#permission'><p>Change file permissions</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#s3_bucket_delete'><p>Delete bucket</p></a></li>
<li><a href='#s3_dir_ls_url'><p>Generate presigned url to list S3 directories</p></a></li>
<li><a href='#s3_dir_tree'><p>Print contents of directories in a tree-like format</p></a></li>
<li><a href='#s3_file_move'><p>Move or rename S3 files</p></a></li>
<li><a href='#s3_file_move_async'><p>Move or rename S3 files</p></a></li>
<li><a href='#s3_file_system'><p>Access AWS S3 as if it were a file system.</p></a></li>
<li><a href='#s3_file_temp'><p>Create name for temporary files</p></a></li>
<li><a href='#s3_file_url'><p>Generate presigned url for S3 object</p></a></li>
<li><a href='#s3_file_version_info'><p>Query file version metadata</p></a></li>
<li><a href='#s3_path_join'><p>Construct AWS S3 path</p></a></li>
<li><a href='#s3_path_split'><p>Split s3 path and uri</p></a></li>
<li><a href='#S3FileSystem'><p>Access AWS S3 as if it were a file system.</p></a></li>
<li><a href='#stream'><p>Streams data from R to AWS S3.</p></a></li>
<li><a href='#stream_async'><p>Streams data from R to AWS S3.</p></a></li>
<li><a href='#tag'><p>Modifying file tags</p></a></li>
<li><a href='#touch'><p>Change file modification time</p></a></li>
<li><a href='#upload'><p>Upload file and directory</p></a></li>
<li><a href='#upload_async'><p>Upload file and directory</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>'Amazon Web Service S3' File System</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Access 'Amazon Web Service Simple Storage Service' ('S3') <a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>
    as if it were a file system. Interface based on the R package 'fs'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/DyfanJones/s3fs">https://github.com/DyfanJones/s3fs</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/DyfanJones/s3fs/issues">https://github.com/DyfanJones/s3fs/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Collate:</td>
<td>'zzz.R' 'utils.R' 's3filesystem_class.R' 'file_system.R'
'file_system_async.R' 'reexport_fs.R'</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>curl, R6, data.table, fs, future, future.apply, lgr,
paws.storage (&ge; 0.2.0), utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, testthat (&ge; 3.1.4)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-15 11:11:27 UTC; dyfanjones</td>
</tr>
<tr>
<td>Author:</td>
<td>Dyfan Jones [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dyfan Jones &lt;dyfan.r.jones@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-15 11:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='s3fs-package'>s3fs: 'Amazon Web Service S3' File System</h2><span id='topic+s3fs'></span><span id='topic+s3fs-package'></span>

<h3>Description</h3>

<p>Access 'Amazon Web Service Simple Storage Service' ('S3') <a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a> as if it were a file system. Interface based on the R package 'fs'.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Dyfan Jones <a href="mailto:dyfan.r.jones@gmail.com">dyfan.r.jones@gmail.com</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/DyfanJones/s3fs">https://github.com/DyfanJones/s3fs</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/DyfanJones/s3fs/issues">https://github.com/DyfanJones/s3fs/issues</a>
</p>
</li></ul>


<hr>
<h2 id='copy'>Copy files and directories</h2><span id='topic+copy'></span><span id='topic+s3_file_copy'></span><span id='topic+s3_dir_copy'></span>

<h3>Description</h3>

<p><code>s3_file_copy</code> copies files
</p>
<p><code>s3_dir_copy</code> copies the directory recursively to the new location
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_copy(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)

s3_dir_copy(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="copy_+3A_path">path</code></td>
<td>
<p>(character): path to a local directory of file or a uri.</p>
</td></tr>
<tr><td><code id="copy_+3A_new_path">new_path</code></td>
<td>
<p>(character): path to a local directory of file or a uri.</p>
</td></tr>
<tr><td><code id="copy_+3A_max_batch">max_batch</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="copy_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="copy_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = "temp.txt"
file.create(temp_file)

s3_file_copy(
    temp_file,
    "s3://MyBucket/temp_file.txt"
 )

## End(Not run)
</code></pre>

<hr>
<h2 id='copy_async'>Copy files and directories</h2><span id='topic+copy_async'></span><span id='topic+s3_file_copy_async'></span><span id='topic+s3_dir_copy_async'></span>

<h3>Description</h3>

<p><code>s3_file_copy</code> copies files
</p>
<p><code>s3_dir_copy</code> copies the directory recursively to the new location
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_copy_async(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)

s3_dir_copy_async(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="copy_async_+3A_path">path</code></td>
<td>
<p>(character): path to a local directory of file or a uri.</p>
</td></tr>
<tr><td><code id="copy_async_+3A_new_path">new_path</code></td>
<td>
<p>(character): path to a local directory of file or a uri.</p>
</td></tr>
<tr><td><code id="copy_async_+3A_max_batch">max_batch</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="copy_async_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="copy_async_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return <code><a href="future.html#topic+future">future</a></code> object of <code><a href="#topic+s3_file_copy">s3_file_copy()</a></code>, <code><a href="#topic+s3_dir_copy">s3_dir_copy()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="future.html#topic+future">future</a></code> <code><a href="#topic+s3_file_copy">s3_file_copy()</a></code> <code><a href="#topic+s3_dir_copy">s3_dir_copy()</a></code>
</p>

<hr>
<h2 id='create'>Create files and directories</h2><span id='topic+create'></span><span id='topic+s3_file_create'></span><span id='topic+s3_bucket_create'></span><span id='topic+s3_dir_create'></span>

<h3>Description</h3>

<p><code>s3_file_create</code> create file on <code style="white-space: pre;">&#8288;AWS S3&#8288;</code>, if file already exists it will be left unchanged.
</p>
<p><code>s3_dir_create</code> create empty directory of <code style="white-space: pre;">&#8288;AWS S3&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_create(path, overwrite = FALSE, ...)

s3_bucket_create(
  path,
  region_name = NULL,
  mode = c("private", "public-read", "public-read-write", "authenticated-read"),
  versioning = FALSE,
  ...
)

s3_dir_create(path, overwrite = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_+3A_path">path</code></td>
<td>
<p>(character): A character vector of path or s3 uri.</p>
</td></tr>
<tr><td><code id="create_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="create_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code>,
<code><a href="paws.storage.html#topic+s3_create_bucket">s3_create_bucket</a></code></p>
</td></tr>
<tr><td><code id="create_+3A_region_name">region_name</code></td>
<td>
<p>(character): region for <code style="white-space: pre;">&#8288;AWS S3&#8288;</code> bucket, defaults
to <code><a href="#topic+s3_file_system">s3_file_system()</a></code> class region.</p>
</td></tr>
<tr><td><code id="create_+3A_mode">mode</code></td>
<td>
<p>(character): A character of the mode</p>
</td></tr>
<tr><td><code id="create_+3A_versioning">versioning</code></td>
<td>
<p>(logical)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir= "MyBucket")
s3_file_create(temp_file)

## End(Not run)
</code></pre>

<hr>
<h2 id='delete'>Delete files and directories</h2><span id='topic+delete'></span><span id='topic+s3_file_delete'></span><span id='topic+s3_dir_delete'></span>

<h3>Description</h3>

<p><code>s3_file_delete</code> delete files in AWS S3
</p>
<p><code>s3_dir_delete</code> delete directories in AWS S3 recursively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_delete(path, ...)

s3_dir_delete(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delete_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or s3 uris.</p>
</td></tr>
<tr><td><code id="delete_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_delete_objects">s3_delete_objects</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir= "MyBucket")
s3_file_create(temp_file)

s3_file_delete(temp_file)

## End(Not run)
</code></pre>

<hr>
<h2 id='delete_async'>Delete files and directories</h2><span id='topic+delete_async'></span><span id='topic+s3_file_delete_async'></span><span id='topic+s3_dir_delete_async'></span>

<h3>Description</h3>

<p><code>s3_file_delete</code> delete files in AWS S3
</p>
<p><code>s3_dir_delete</code> delete directories in AWS S3 recursively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_delete_async(path, ...)

s3_dir_delete_async(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delete_async_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or s3 uris.</p>
</td></tr>
<tr><td><code id="delete_async_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_delete_objects">s3_delete_objects</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return <code><a href="future.html#topic+future">future</a></code> object of <code><a href="#topic+s3_file_delete">s3_file_delete()</a></code> <code><a href="#topic+s3_dir_delete">s3_dir_delete()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="future.html#topic+future">future</a></code> <code><a href="#topic+s3_file_delete">s3_file_delete()</a></code> <code><a href="#topic+s3_dir_delete">s3_dir_delete()</a></code>
</p>

<hr>
<h2 id='download'>Download files and directories</h2><span id='topic+download'></span><span id='topic+s3_file_download'></span><span id='topic+s3_dir_download'></span>

<h3>Description</h3>

<p><code>s3_file_download</code> downloads <code style="white-space: pre;">&#8288;AWS S3&#8288;</code> files to local
</p>
<p><code>s3_file_download</code> downloads <code style="white-space: pre;">&#8288;AWS s3&#8288;</code> directory to local
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_download(path, new_path, overwrite = FALSE, ...)

s3_dir_download(path, new_path, overwrite = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or uris</p>
</td></tr>
<tr><td><code id="download_+3A_new_path">new_path</code></td>
<td>
<p>(character): A character vector of paths to the new locations.</p>
</td></tr>
<tr><td><code id="download_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="download_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir= "MyBucket")
s3_file_create(temp_file)

s3_file_download(temp_file, "temp_file.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='download_async'>Download files and directories</h2><span id='topic+download_async'></span><span id='topic+s3_file_download_async'></span><span id='topic+s3_dir_download_async'></span>

<h3>Description</h3>

<p><code>s3_file_download</code> downloads <code style="white-space: pre;">&#8288;AWS S3&#8288;</code> files to local
</p>
<p><code>s3_file_download</code> downloads <code style="white-space: pre;">&#8288;AWS s3&#8288;</code> directory to local
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_download_async(path, new_path, overwrite = FALSE, ...)

s3_dir_download_async(path, new_path, overwrite = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_async_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or uris</p>
</td></tr>
<tr><td><code id="download_async_+3A_new_path">new_path</code></td>
<td>
<p>(character): A character vector of paths to the new locations.</p>
</td></tr>
<tr><td><code id="download_async_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="download_async_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return <code><a href="future.html#topic+future">future</a></code> object of <code><a href="#topic+s3_file_download">s3_file_download()</a></code> <code><a href="#topic+s3_dir_download">s3_dir_download()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="future.html#topic+future">future</a></code> <code><a href="#topic+s3_file_download">s3_file_download()</a></code> <code><a href="#topic+s3_dir_download">s3_dir_download()</a></code>
</p>

<hr>
<h2 id='exists'>Download files and directories</h2><span id='topic+exists'></span><span id='topic+s3_file_exists'></span><span id='topic+s3_dir_exists'></span>

<h3>Description</h3>

<p><code>s3_file_exists</code> check if file exists in AWS S3
</p>
<p><code>s3_dir_exists</code> check if path is a directory in AWS S3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_exists(path)

s3_dir_exists(path = ".")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exists_+3A_path">path</code></td>
<td>
<p>(character) s3 path to check</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical vector if file exists
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir= "MyBucket")
s3_file_create(temp_file)

s3_file_exists(temp_file)

## End(Not run)
</code></pre>

<hr>
<h2 id='file_type'>Functions to test for file types</h2><span id='topic+file_type'></span><span id='topic+s3_is_file'></span><span id='topic+s3_is_dir'></span><span id='topic+s3_is_bucket'></span><span id='topic+s3_is_file_empty'></span>

<h3>Description</h3>

<p>Test for file types
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_is_file(path)

s3_is_dir(path)

s3_is_bucket(path, ...)

s3_is_file_empty(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="file_type_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or uris</p>
</td></tr>
<tr><td><code id="file_type_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='info'>Get files and directories information</h2><span id='topic+info'></span><span id='topic+s3_file_info'></span><span id='topic+s3_file_size'></span><span id='topic+s3_dir_info'></span><span id='topic+s3_dir_ls'></span>

<h3>Description</h3>

<p><code>s3_file_info</code> returns file information within AWS S3 directory
</p>
<p><code>s3_file_size</code> returns file size in bytes
</p>
<p><code>s3_dir_info</code> returns file name information within AWS S3 directory
</p>
<p><code>s3_dir_ls</code> returns file name within AWS S3 directory
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_info(path)

s3_file_size(path)

s3_dir_info(
  path = ".",
  type = c("any", "bucket", "directory", "file"),
  glob = NULL,
  regexp = NULL,
  invert = FALSE,
  recurse = FALSE,
  refresh = FALSE,
  ...
)

s3_dir_ls(
  path = ".",
  type = c("any", "bucket", "directory", "file"),
  glob = NULL,
  regexp = NULL,
  invert = FALSE,
  recurse = FALSE,
  refresh = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="info_+3A_path">path</code></td>
<td>
<p>(character):A character vector of one or more paths. Can be path
or s3 uri.</p>
</td></tr>
<tr><td><code id="info_+3A_type">type</code></td>
<td>
<p>(character): File type(s) to return. Default (&quot;any&quot;) returns all
AWS S3 object types.</p>
</td></tr>
<tr><td><code id="info_+3A_glob">glob</code></td>
<td>
<p>(character): A wildcard pattern (e.g. <code>*.csv</code>), passed onto
<code>grep()</code> to filter paths.</p>
</td></tr>
<tr><td><code id="info_+3A_regexp">regexp</code></td>
<td>
<p>(character): A regular expression (e.g. <code>[.]csv$</code>),
passed onto <code>grep()</code> to filter paths.</p>
</td></tr>
<tr><td><code id="info_+3A_invert">invert</code></td>
<td>
<p>(logical): If <code>code</code> return files which do not match.</p>
</td></tr>
<tr><td><code id="info_+3A_recurse">recurse</code></td>
<td>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</td></tr>
<tr><td><code id="info_+3A_refresh">refresh</code></td>
<td>
<p>(logical): Refresh cached in <code>s3_cache</code>.</p>
</td></tr>
<tr><td><code id="info_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>s3_file_info</code> A data.table with metadata for each file. Columns returned are as follows.
</p>

<ul>
<li><p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li><p>key (character): AWS S3 path key of file
</p>
</li>
<li><p>uri (character): S3 uri of file
</p>
</li>
<li><p>size (numeric): file size in bytes
</p>
</li>
<li><p>type (character): file type (file or directory)
</p>
</li>
<li><p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li><p>last_modified (POSIXct): Created date of file.
</p>
</li>
<li><p>delete_marker (logical): Specifies retrieved a logical marker
</p>
</li>
<li><p>accept_ranges (character): Indicates that a range of bytes was specified.
</p>
</li>
<li><p>expiration (character): File expiration
</p>
</li>
<li><p>restore (character): If file is archived
</p>
</li>
<li><p>archive_status (character): Archive status
</p>
</li>
<li><p>missing_meta (integer): Number of metadata entries not returned in &quot;x-amz-meta&quot; headers
</p>
</li>
<li><p>version_id (character): version id of file
</p>
</li>
<li><p>cache_control (character): caching behaviour for the request/reply chain
</p>
</li>
<li><p>content_disposition (character): presentational information of file
</p>
</li>
<li><p>content_encoding (character): file content encodings
</p>
</li>
<li><p>content_language (character): what language the content is in
</p>
</li>
<li><p>content_type (character): file MIME type
</p>
</li>
<li><p>expires (POSIXct): date and time the file is no longer cacheable
</p>
</li>
<li><p>website_redirect_location (character): redirects request for file to another
</p>
</li>
<li><p>server_side_encryption (character): File server side encryption
</p>
</li>
<li><p>metadata (list): metadata of file
</p>
</li>
<li><p>sse_customer_algorithm (character): server-side encryption with a customer-provided encryption key
</p>
</li>
<li><p>sse_customer_key_md5 (character): server-side encryption with a customer-provided encryption key
</p>
</li>
<li><p>ssekms_key_id (character): ID of the Amazon Web Services Key Management Service
</p>
</li>
<li><p>bucket_key_enabled (logical): s3 bucket key for server-side encryption with
</p>
</li>
<li><p>storage_class (character): file storage class information
</p>
</li>
<li><p>request_charged (character): indicates successfully charged for request
</p>
</li>
<li><p>replication_status (character): return specific header if request
involves a bucket that is either a source or a destination in a replication rule
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object</a>
</p>
</li>
<li><p>parts_count (integer): number of count parts the file has
</p>
</li>
<li><p>object_lock_mode (character): the file lock mode
</p>
</li>
<li><p>object_lock_retain_until_date (POSIXct): date and time of when object_lock_mode expires
</p>
</li>
<li><p>object_lock_legal_hold_status (character): file legal holding
</p>
</li></ul>

<p><code>s3_dir_info</code> data.table with directory metadata
</p>

<ul>
<li><p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li><p>key (character): AWS S3 path key of file
</p>
</li>
<li><p>uri (character): S3 uri of file
</p>
</li>
<li><p>size (numeric): file size in bytes
</p>
</li>
<li><p>version_id (character): version id of file
</p>
</li>
<li><p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li><p>last_modified (POSIXct): Created date of file
</p>
</li></ul>

<p><code>s3_dir_ls</code> character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir= "MyBucket")
s3_file_create(temp_file)

s3_file_info(temp_file)

## End(Not run)
</code></pre>

<hr>
<h2 id='path'>Construct path for file or directory</h2><span id='topic+path'></span><span id='topic+s3_path'></span>

<h3>Description</h3>

<p>Constructs a s3 uri path
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_path(..., ext = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="path_+3A_...">...</code></td>
<td>
<p>(character): Character vectors</p>
</td></tr>
<tr><td><code id="path_+3A_ext">ext</code></td>
<td>
<p>(character): An optional extension to append to the generated path</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

s3_path("my_bucket1", "my_bucket2")

## End(Not run)
</code></pre>

<hr>
<h2 id='path_manipulate'>Manipulate s3 uri paths</h2><span id='topic+path_manipulate'></span><span id='topic+s3_path_dir'></span><span id='topic+s3_path_file'></span><span id='topic+s3_path_ext'></span><span id='topic+s3_path_ext_remove'></span><span id='topic+s3_path_ext_set'></span>

<h3>Description</h3>

<p><code>s3_path_dir</code> returns the directory portion of s3 uri
</p>
<p><code>s3_path_file</code> returns the file name portion of the s3 uri path
</p>
<p><code>s3_path_ext</code> returns the last extension for a path.
</p>
<p><code>s3_path_ext_remove</code> removes the last extension and return the rest of the s3 uri.
</p>
<p><code>s3_path_ext_set</code> replace the extension with a new extension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_path_dir(path)

s3_path_file(path)

s3_path_ext(path)

s3_path_ext_remove(path)

s3_path_ext_set(path, ext)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="path_manipulate_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths</p>
</td></tr>
<tr><td><code id="path_manipulate_+3A_ext">ext</code></td>
<td>
<p>(character): New file extension</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

s3_path_dir("s3://my_bucket1/hi.txt")

s3_path_file("s3://my_bucket1/hi.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='permission'>Change file permissions</h2><span id='topic+permission'></span><span id='topic+s3_file_chmod'></span><span id='topic+s3_bucket_chmod'></span>

<h3>Description</h3>

<p>Change file permissions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_chmod(
  path,
  mode = c("private", "public-read", "public-read-write", "authenticated-read",
    "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control")
)

s3_bucket_chmod(
  path,
  mode = c("private", "public-read", "public-read-write", "authenticated-read")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="permission_+3A_path">path</code></td>
<td>
<p>(character): A character vector of path or s3 uri.</p>
</td></tr>
<tr><td><code id="permission_+3A_mode">mode</code></td>
<td>
<p>(character): A character of the mode</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir = "MyBucket")
s3_file_create(temp_file)

# Reset connection to connect to a different region
s3_file_chmod(
    profile_name = "s3fs_example",
    region_name = "us-east-1",
    refresh = TRUE
 )

## End(Not run)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+fs_bytes'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>fs</dt><dd><p><code><a href="fs.html#topic+fs_bytes">fs_bytes</a></code></p>
</dd>
</dl>

<hr>
<h2 id='s3_bucket_delete'>Delete bucket</h2><span id='topic+s3_bucket_delete'></span>

<h3>Description</h3>

<p>Delete <code style="white-space: pre;">&#8288;AWS S3&#8288;</code> bucket including all objects in the bucket itself.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_bucket_delete(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_bucket_delete_+3A_path">path</code></td>
<td>
<p>(character): A character vector of path or s3 uri.</p>
</td></tr>
</table>

<hr>
<h2 id='s3_dir_ls_url'>Generate presigned url to list S3 directories</h2><span id='topic+s3_dir_ls_url'></span>

<h3>Description</h3>

<p>Generate presigned url to list S3 directories
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_dir_ls_url(path, expiration = 3600L, recurse = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_dir_ls_url_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or uris</p>
</td></tr>
<tr><td><code id="s3_dir_ls_url_+3A_expiration">expiration</code></td>
<td>
<p>(numeric): The number of seconds the presigned url is
valid for. By default it expires in an hour (3600 seconds)</p>
</td></tr>
<tr><td><code id="s3_dir_ls_url_+3A_recurse">recurse</code></td>
<td>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</td></tr>
<tr><td><code id="s3_dir_ls_url_+3A_...">...</code></td>
<td>
<p>parameters passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return character of urls
</p>

<hr>
<h2 id='s3_dir_tree'>Print contents of directories in a tree-like format</h2><span id='topic+s3_dir_tree'></span>

<h3>Description</h3>

<p>Print contents of directories in a tree-like format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_dir_tree(path, recurse = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_dir_tree_+3A_path">path</code></td>
<td>
<p>(character): path A path to print the tree from</p>
</td></tr>
<tr><td><code id="s3_dir_tree_+3A_recurse">recurse</code></td>
<td>
<p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</td></tr>
<tr><td><code id="s3_dir_tree_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <a href="#topic+s3_dir_ls">s3_dir_ls</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>

<hr>
<h2 id='s3_file_move'>Move or rename S3 files</h2><span id='topic+s3_file_move'></span>

<h3>Description</h3>

<p>Move files to another location on AWS S3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_move(path, new_path, max_batch = 100 * MB, overwrite = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_file_move_+3A_path">path</code></td>
<td>
<p>(character): A character vector of s3 uri</p>
</td></tr>
<tr><td><code id="s3_file_move_+3A_new_path">new_path</code></td>
<td>
<p>(character): A character vector of s3 uri.</p>
</td></tr>
<tr><td><code id="s3_file_move_+3A_max_batch">max_batch</code></td>
<td>
<p>(numeric): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="s3_file_move_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="s3_file_move_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_copy_object">s3_copy_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

temp_file = s3_file_temp(tmp_dir= "MyBucket")
s3_file_create(temp_file)

s3_file_move(temp_file, "s3://MyBucket/new_file.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='s3_file_move_async'>Move or rename S3 files</h2><span id='topic+s3_file_move_async'></span>

<h3>Description</h3>

<p>Move files to another location on AWS S3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_move_async(
  path,
  new_path,
  max_batch = 100 * MB,
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_file_move_async_+3A_path">path</code></td>
<td>
<p>(character): A character vector of s3 uri</p>
</td></tr>
<tr><td><code id="s3_file_move_async_+3A_new_path">new_path</code></td>
<td>
<p>(character): A character vector of s3 uri.</p>
</td></tr>
<tr><td><code id="s3_file_move_async_+3A_max_batch">max_batch</code></td>
<td>
<p>(numeric): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="s3_file_move_async_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="s3_file_move_async_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_copy_object">s3_copy_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return <code><a href="future.html#topic+future">future</a></code> object of <code><a href="#topic+s3_file_move">s3_file_move()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="future.html#topic+future">future</a></code> <code><a href="#topic+s3_file_move">s3_file_move()</a></code>
</p>

<hr>
<h2 id='s3_file_system'>Access AWS S3 as if it were a file system.</h2><span id='topic+s3_file_system'></span>

<h3>Description</h3>

<p>This creates a file system &quot;like&quot; API based off <code>fs</code>
(e.g. dir_ls, file_copy, etc.) for AWS S3 storage. To set up <code>AWS</code>
credentials please look at
<a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_system(
  aws_access_key_id = NULL,
  aws_secret_access_key = NULL,
  aws_session_token = NULL,
  region_name = NULL,
  profile_name = NULL,
  endpoint = NULL,
  disable_ssl = FALSE,
  multipart_threshold = fs_bytes("2GB"),
  request_payer = FALSE,
  anonymous = FALSE,
  retries = 5,
  refresh = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_file_system_+3A_aws_access_key_id">aws_access_key_id</code></td>
<td>
<p>(character): AWS access key ID</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_aws_secret_access_key">aws_secret_access_key</code></td>
<td>
<p>(character): AWS secret access key</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_aws_session_token">aws_session_token</code></td>
<td>
<p>(character): AWS temporary session token</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_region_name">region_name</code></td>
<td>
<p>(character): Default region when creating new connections</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_profile_name">profile_name</code></td>
<td>
<p>(character): The name of a profile to use. If not given,
then the default profile is used.</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_endpoint">endpoint</code></td>
<td>
<p>(character): The complete URL to use for the constructed client.</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_disable_ssl">disable_ssl</code></td>
<td>
<p>(logical): Whether or not to use SSL. By default, SSL is used.</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_multipart_threshold">multipart_threshold</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Threshold to use multipart instead of standard
copy and upload methods.</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_request_payer">request_payer</code></td>
<td>
<p>(logical): Confirms that the requester knows that they
will be charged for the request.</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_anonymous">anonymous</code></td>
<td>
<p>(logical): Set up anonymous credentials when connecting to AWS S3.</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_retries">retries</code></td>
<td>
<p>(numeric): max number of retry attempts</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_refresh">refresh</code></td>
<td>
<p>(logical): Refresh cached S3FileSystem class</p>
</td></tr>
<tr><td><code id="s3_file_system_+3A_...">...</code></td>
<td>
<p>Other parameters within <code>paws</code> client.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S3FileSystem class invisible
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

# Set up connection using profile
s3_file_system(profile_name = "s3fs_example")

# Reset connection to connect to a different region
s3_file_system(
    profile_name = "s3fs_example",
    region_name = "us-east-1",
    refresh = TRUE
 )

## End(Not run)
</code></pre>

<hr>
<h2 id='s3_file_temp'>Create name for temporary files</h2><span id='topic+s3_file_temp'></span>

<h3>Description</h3>

<p>return the name which can be used as a temporary file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_temp(pattern = "file", tmp_dir = "", ext = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_file_temp_+3A_pattern">pattern</code></td>
<td>
<p>(character): A character vector with the non-random portion of the name.</p>
</td></tr>
<tr><td><code id="s3_file_temp_+3A_tmp_dir">tmp_dir</code></td>
<td>
<p>(character): The directory the file will be created in. By default
the cached s3 bucket will be applied otherwise <code>""</code> will be used.</p>
</td></tr>
<tr><td><code id="s3_file_temp_+3A_ext">ext</code></td>
<td>
<p>(character): A character vector of one or more paths.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

s3_file_temp(tmp_dir = "MyBucket")

## End(Not run)
</code></pre>

<hr>
<h2 id='s3_file_url'>Generate presigned url for S3 object</h2><span id='topic+s3_file_url'></span>

<h3>Description</h3>

<p>Generate presigned url for S3 object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_url(path, expiration = 3600L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_file_url_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or uris</p>
</td></tr>
<tr><td><code id="s3_file_url_+3A_expiration">expiration</code></td>
<td>
<p>(numeric): The number of seconds the presigned url is
valid for. By default it expires in an hour (3600 seconds)</p>
</td></tr>
<tr><td><code id="s3_file_url_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code>params</code> parameter of
<code><a href="paws.storage.html#topic+s3_generate_presigned_url">s3_generate_presigned_url</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return character of urls
</p>

<hr>
<h2 id='s3_file_version_info'>Query file version metadata</h2><span id='topic+s3_file_version_info'></span>

<h3>Description</h3>

<p>Get file versions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_version_info(path, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_file_version_info_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or uris</p>
</td></tr>
<tr><td><code id="s3_file_version_info_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_object_versions">s3_list_object_versions</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='s3_path_join'>Construct AWS S3 path</h2><span id='topic+s3_path_join'></span>

<h3>Description</h3>

<p>Construct an s3 uri path from path vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_path_join(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_path_join_+3A_path">path</code></td>
<td>
<p>(character): A character vector of one or more paths</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

s3_path_dir(c("s3://my_bucket1/hi.txt", "s3://my_bucket/bye.txt"))

## End(Not run)
</code></pre>

<hr>
<h2 id='s3_path_split'>Split s3 path and uri</h2><span id='topic+s3_path_split'></span>

<h3>Description</h3>

<p>Split s3 uri path to core components bucket, key and version id
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_path_split(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="s3_path_split_+3A_path">path</code></td>
<td>
<p>(character): A character vector of one or more paths or s3 uri</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list character vectors splitting the s3 uri path in &quot;Bucket&quot;, &quot;Key&quot; and &quot;VersionId&quot;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

s3_path_dir("s3://my_bucket1/hi.txt")

## End(Not run)
</code></pre>

<hr>
<h2 id='S3FileSystem'>Access AWS S3 as if it were a file system.</h2><span id='topic+S3FileSystem'></span>

<h3>Description</h3>

<p>This creates a file system &quot;like&quot; API based off <code>fs</code>
(e.g. dir_ls, file_copy, etc.) for AWS S3 storage.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>s3_cache</code></dt><dd><p>Cache AWS S3</p>
</dd>
<dt><code>s3_cache_bucket</code></dt><dd><p>Cached s3 bucket</p>
</dd>
<dt><code>s3_client</code></dt><dd><p>paws s3 client</p>
</dd>
<dt><code>region_name</code></dt><dd><p>AWS region when creating new connections</p>
</dd>
<dt><code>profile_name</code></dt><dd><p>The name of a profile to use</p>
</dd>
<dt><code>multipart_threshold</code></dt><dd><p>Threshold to use multipart</p>
</dd>
<dt><code>request_payer</code></dt><dd><p>Threshold to use multipart</p>
</dd>
<dt><code>pid</code></dt><dd><p>Get the process ID of the R Session</p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>retries</code></dt><dd><p>number of retries</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-S3FileSystem-new"><code>S3FileSystem$new()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_chmod"><code>S3FileSystem$file_chmod()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_copy"><code>S3FileSystem$file_copy()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_create"><code>S3FileSystem$file_create()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_delete"><code>S3FileSystem$file_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_download"><code>S3FileSystem$file_download()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_exists"><code>S3FileSystem$file_exists()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_info"><code>S3FileSystem$file_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_move"><code>S3FileSystem$file_move()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_size"><code>S3FileSystem$file_size()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_stream_in"><code>S3FileSystem$file_stream_in()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_stream_out"><code>S3FileSystem$file_stream_out()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_temp"><code>S3FileSystem$file_temp()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_tag_delete"><code>S3FileSystem$file_tag_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_tag_info"><code>S3FileSystem$file_tag_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_tag_update"><code>S3FileSystem$file_tag_update()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_touch"><code>S3FileSystem$file_touch()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_upload"><code>S3FileSystem$file_upload()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_url"><code>S3FileSystem$file_url()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-file_version_info"><code>S3FileSystem$file_version_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_file"><code>S3FileSystem$is_file()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_dir"><code>S3FileSystem$is_dir()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_bucket"><code>S3FileSystem$is_bucket()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-is_file_empty"><code>S3FileSystem$is_file_empty()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-bucket_chmod"><code>S3FileSystem$bucket_chmod()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-bucket_create"><code>S3FileSystem$bucket_create()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-bucket_delete"><code>S3FileSystem$bucket_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_copy"><code>S3FileSystem$dir_copy()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_create"><code>S3FileSystem$dir_create()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_delete"><code>S3FileSystem$dir_delete()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_exists"><code>S3FileSystem$dir_exists()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_download"><code>S3FileSystem$dir_download()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_info"><code>S3FileSystem$dir_info()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_ls"><code>S3FileSystem$dir_ls()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_ls_url"><code>S3FileSystem$dir_ls_url()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_tree"><code>S3FileSystem$dir_tree()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-dir_upload"><code>S3FileSystem$dir_upload()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path"><code>S3FileSystem$path()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_dir"><code>S3FileSystem$path_dir()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_ext"><code>S3FileSystem$path_ext()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_ext_remove"><code>S3FileSystem$path_ext_remove()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_ext_set"><code>S3FileSystem$path_ext_set()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_file"><code>S3FileSystem$path_file()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_join"><code>S3FileSystem$path_join()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-path_split"><code>S3FileSystem$path_split()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-clear_cache"><code>S3FileSystem$clear_cache()</code></a>
</p>
</li>
<li> <p><a href="#method-S3FileSystem-clone"><code>S3FileSystem$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-S3FileSystem-new"></a>



<h4>Method <code>new()</code></h4>

<p>Initialize S3FileSystem class
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$new(
  aws_access_key_id = NULL,
  aws_secret_access_key = NULL,
  aws_session_token = NULL,
  region_name = NULL,
  profile_name = NULL,
  endpoint = NULL,
  disable_ssl = FALSE,
  multipart_threshold = fs_bytes("2GB"),
  request_payer = FALSE,
  anonymous = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>aws_access_key_id</code></dt><dd><p>(character): AWS access key ID</p>
</dd>
<dt><code>aws_secret_access_key</code></dt><dd><p>(character): AWS secret access key</p>
</dd>
<dt><code>aws_session_token</code></dt><dd><p>(character): AWS temporary session token</p>
</dd>
<dt><code>region_name</code></dt><dd><p>(character): Default region when creating new connections</p>
</dd>
<dt><code>profile_name</code></dt><dd><p>(character): The name of a profile to use. If not given,
then the default profile is used.</p>
</dd>
<dt><code>endpoint</code></dt><dd><p>(character): The complete URL to use for the constructed client.</p>
</dd>
<dt><code>disable_ssl</code></dt><dd><p>(logical): Whether or not to use SSL. By default, SSL is used.</p>
</dd>
<dt><code>multipart_threshold</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Threshold to use multipart instead of standard
copy and upload methods.</p>
</dd>
<dt><code>request_payer</code></dt><dd><p>(logical): Confirms that the requester knows that they
will be charged for the request.</p>
</dd>
<dt><code>anonymous</code></dt><dd><p>(logical): Set up anonymous credentials when connecting to AWS S3.</p>
</dd>
<dt><code>...</code></dt><dd><p>Other parameters within <code>paws</code> client.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-S3FileSystem-file_chmod"></a>



<h4>Method <code>file_chmod()</code></h4>

<p>Change file permissions
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_chmod(
  path,
  mode = c("private", "public-read", "public-read-write", "authenticated-read",
    "aws-exec-read", "bucket-owner-read", "bucket-owner-full-control")
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>mode</code></dt><dd><p>(character): A character of the mode</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_copy"></a>



<h4>Method <code>file_copy()</code></h4>

<p>copy files
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_copy(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>max_batch</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_create"></a>



<h4>Method <code>file_create()</code></h4>

<p>Create file on AWS S3, if file already
exists it will be left unchanged.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_create(path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_delete"></a>



<h4>Method <code>file_delete()</code></h4>

<p>Delete files in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_delete(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uris.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_delete_objects">s3_delete_objects</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_download"></a>



<h4>Method <code>file_download()</code></h4>

<p>Downloads AWS S3 files to local
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_download(path, new_path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): A character vector of paths to the new locations.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_exists"></a>



<h4>Method <code>file_exists()</code></h4>

<p>Check if file exists in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_exists(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character) s3 path to check</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>logical vector if file exists
</p>


<hr>
<a id="method-S3FileSystem-file_info"></a>



<h4>Method <code>file_info()</code></h4>

<p>Returns file information within AWS S3 directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_info(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A data.table with metadata for each file. Columns returned are as follows.
</p>

<ul>
<li><p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li><p>key (character): AWS S3 path key of file
</p>
</li>
<li><p>uri (character): S3 uri of file
</p>
</li>
<li><p>size (numeric): file size in bytes
</p>
</li>
<li><p>type (character): file type (file or directory)
</p>
</li>
<li><p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li><p>last_modified (POSIXct): Created date of file.
</p>
</li>
<li><p>delete_marker (logical): Specifies retrieved a logical marker
</p>
</li>
<li><p>accept_ranges (character): Indicates that a range of bytes was specified.
</p>
</li>
<li><p>expiration (character): File expiration
</p>
</li>
<li><p>restore (character): If file is archived
</p>
</li>
<li><p>archive_status (character): Archive status
</p>
</li>
<li><p>missing_meta (integer): Number of metadata entries not returned in &quot;x-amz-meta&quot; headers
</p>
</li>
<li><p>version_id (character): version id of file
</p>
</li>
<li><p>cache_control (character): caching behaviour for the request/reply chain
</p>
</li>
<li><p>content_disposition (character): presentational information of file
</p>
</li>
<li><p>content_encoding (character): file content encodings
</p>
</li>
<li><p>content_language (character): what language the content is in
</p>
</li>
<li><p>content_type (character): file MIME type
</p>
</li>
<li><p>expires (POSIXct): date and time the file is no longer cacheable
</p>
</li>
<li><p>website_redirect_location (character): redirects request for file to another
</p>
</li>
<li><p>server_side_encryption (character): File server side encryption
</p>
</li>
<li><p>metadata (list): metadata of file
</p>
</li>
<li><p>sse_customer_algorithm (character): server-side encryption with a customer-provided encryption key
</p>
</li>
<li><p>sse_customer_key_md5 (character): server-side encryption with a customer-provided encryption key
</p>
</li>
<li><p>ssekms_key_id (character): ID of the Amazon Web Services Key Management Service
</p>
</li>
<li><p>bucket_key_enabled (logical): s3 bucket key for server-side encryption with
</p>
</li>
<li><p>storage_class (character): file storage class information
</p>
</li>
<li><p>request_charged (character): indicates successfully charged for request
</p>
</li>
<li><p>replication_status (character): return specific header if request
involves a bucket that is either a source or a destination in a replication rule
<a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object">https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.head_object</a>
</p>
</li>
<li><p>parts_count (integer): number of count parts the file has
</p>
</li>
<li><p>object_lock_mode (character): the file lock mode
</p>
</li>
<li><p>object_lock_retain_until_date (POSIXct): date and time of when object_lock_mode expires
</p>
</li>
<li><p>object_lock_legal_hold_status (character): file legal holding
</p>
</li></ul>



<hr>
<a id="method-S3FileSystem-file_move"></a>



<h4>Method <code>file_move()</code></h4>

<p>Move files to another location on AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_move(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of s3 uri</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): A character vector of s3 uri.</p>
</dd>
<dt><code>max_batch</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_copy_object">s3_copy_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_size"></a>



<h4>Method <code>file_size()</code></h4>

<p>Return file size in bytes
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_size(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of s3 uri</p>
</dd>
</dl>

</div>


<hr>
<a id="method-S3FileSystem-file_stream_in"></a>



<h4>Method <code>file_stream_in()</code></h4>

<p>Streams in AWS S3 file as a raw vector
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_stream_in(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>list of raw vectors containing the contents of the file
</p>


<hr>
<a id="method-S3FileSystem-file_stream_out"></a>



<h4>Method <code>file_stream_out()</code></h4>

<p>Streams out raw vector to AWS S3 file
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_stream_out(
  obj,
  path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>obj</code></dt><dd><p>(raw|character): A raw vector, rawConnection, url to be streamed up to AWS S3.</p>
</dd>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>max_batch</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_temp"></a>



<h4>Method <code>file_temp()</code></h4>

<p>return the name which can be used as a temporary file
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_temp(pattern = "file", tmp_dir = "", ext = "")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>pattern</code></dt><dd><p>(character): A character vector with the non-random portion of the name.</p>
</dd>
<dt><code>tmp_dir</code></dt><dd><p>(character): The directory the file will be created in.</p>
</dd>
<dt><code>ext</code></dt><dd><p>(character): A character vector of one or more paths.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_tag_delete"></a>



<h4>Method <code>file_tag_delete()</code></h4>

<p>Delete file tags
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_tag_delete(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_tag_info"></a>



<h4>Method <code>file_tag_info()</code></h4>

<p>Get file tags
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_tag_info(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uri</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>data.table of file version metadata
</p>

<ul>
<li><p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li><p>key (character): AWS S3 path key of file
</p>
</li>
<li><p>uri (character): S3 uri of file
</p>
</li>
<li><p>size (numeric): file size in bytes
</p>
</li>
<li><p>version_id (character): version id of file
</p>
</li>
<li><p>tag_key (character): name of tag
</p>
</li>
<li><p>tag_value (character): tag value
</p>
</li></ul>



<hr>
<a id="method-S3FileSystem-file_tag_update"></a>



<h4>Method <code>file_tag_update()</code></h4>

<p>Update file tags
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_tag_update(path, tags, overwrite = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>tags</code></dt><dd><p>(list): Tags to be applied</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): To overwrite tagging or to modify inplace. Default will
modify inplace.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_touch"></a>



<h4>Method <code>file_touch()</code></h4>

<p>Similar to <code>fs::file_touch</code> this does not create the file if
it does not exist. Use <code>s3fs$file_create()</code> to do this if needed.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_touch(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or s3 uri</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_copy_object">s3_copy_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_upload"></a>



<h4>Method <code>file_upload()</code></h4>

<p>Uploads files to AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_upload(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of local file paths to upload to AWS S3</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): A character vector of AWS S3 paths or uri's of the new locations.</p>
</dd>
<dt><code>max_batch</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code>
and <code><a href="paws.storage.html#topic+s3_create_multipart_upload">s3_create_multipart_upload</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-file_url"></a>



<h4>Method <code>file_url()</code></h4>

<p>Generate presigned url for S3 object
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_url(path, expiration = 3600L, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>expiration</code></dt><dd><p>(numeric): The number of seconds the presigned url is
valid for. By default it expires in an hour (3600 seconds)</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>return character of urls
</p>


<hr>
<a id="method-S3FileSystem-file_version_info"></a>



<h4>Method <code>file_version_info()</code></h4>

<p>Get file versions
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$file_version_info(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_object_versions">s3_list_object_versions</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>return data.table with file version info, columns below:
</p>

<ul>
<li><p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li><p>key (character): AWS S3 path key of file
</p>
</li>
<li><p>uri (character): S3 uri of file
</p>
</li>
<li><p>size (numeric): file size in bytes
</p>
</li>
<li><p>version_id (character): version id of file
</p>
</li>
<li><p>owner (character): file owner
</p>
</li>
<li><p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li><p>last_modified (POSIXct): Created date of file.
</p>
</li></ul>



<hr>
<a id="method-S3FileSystem-is_file"></a>



<h4>Method <code>is_file()</code></h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_file(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>logical vector if object is a file
</p>


<hr>
<a id="method-S3FileSystem-is_dir"></a>



<h4>Method <code>is_dir()</code></h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_dir(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>logical vector if object is a directory
</p>


<hr>
<a id="method-S3FileSystem-is_bucket"></a>



<h4>Method <code>is_bucket()</code></h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_bucket(path, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>logical vector if object is a <code style="white-space: pre;">&#8288;AWS S3&#8288;</code> bucket
</p>


<hr>
<a id="method-S3FileSystem-is_file_empty"></a>



<h4>Method <code>is_file_empty()</code></h4>

<p>Test for file types
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$is_file_empty(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>logical vector if file is empty
</p>


<hr>
<a id="method-S3FileSystem-bucket_chmod"></a>



<h4>Method <code>bucket_chmod()</code></h4>

<p>Change bucket permissions
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$bucket_chmod(
  path,
  mode = c("private", "public-read", "public-read-write", "authenticated-read")
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>mode</code></dt><dd><p>(character): A character of the mode</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-bucket_create"></a>



<h4>Method <code>bucket_create()</code></h4>

<p>Create bucket
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$bucket_create(
  path,
  region_name = NULL,
  mode = c("private", "public-read", "public-read-write", "authenticated-read"),
  versioning = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of path or s3 uri.</p>
</dd>
<dt><code>region_name</code></dt><dd><p>(character): aws region</p>
</dd>
<dt><code>mode</code></dt><dd><p>(character): A character of the mode</p>
</dd>
<dt><code>versioning</code></dt><dd><p>(logical): Whether to set the bucket to versioning or not.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_create_bucket">s3_create_bucket</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-bucket_delete"></a>



<h4>Method <code>bucket_delete()</code></h4>

<p>Delete bucket
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$bucket_delete(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of path or s3 uri.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-S3FileSystem-dir_copy"></a>



<h4>Method <code>dir_copy()</code></h4>

<p>Copies the directory recursively to the new location.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_copy(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): path to a local directory of file or a uri.</p>
</dd>
<dt><code>max_batch</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code>
and <code><a href="paws.storage.html#topic+s3_create_multipart_upload">s3_create_multipart_upload</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_create"></a>



<h4>Method <code>dir_create()</code></h4>

<p>Create empty directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_create(path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A vector of directory or uri to be created in AWS S3</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_delete"></a>



<h4>Method <code>dir_delete()</code></h4>

<p>Delete contents and directory in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_delete(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A vector of paths or uris to directories to be deleted.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_exists"></a>



<h4>Method <code>dir_exists()</code></h4>

<p>Check if path exists in AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_exists(path = ".")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character) aws s3 path to be checked</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_download"></a>



<h4>Method <code>dir_download()</code></h4>

<p>Downloads AWS S3 files to local
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_download(path, new_path, overwrite = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): A character vector of paths to the new locations.
Please ensure directories end with a <code>/</code>.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_info"></a>



<h4>Method <code>dir_info()</code></h4>

<p>Returns file information within AWS S3 directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_info(
  path = ".",
  type = c("any", "bucket", "directory", "file"),
  glob = NULL,
  regexp = NULL,
  invert = FALSE,
  recurse = FALSE,
  refresh = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character):A character vector of one or more paths. Can be path
or s3 uri.</p>
</dd>
<dt><code>type</code></dt><dd><p>(character): File type(s) to return. Default (&quot;any&quot;) returns all
AWS S3 object types.</p>
</dd>
<dt><code>glob</code></dt><dd><p>(character): A wildcard pattern (e.g. <code>*.csv</code>), passed onto
<code>grep()</code> to filter paths.</p>
</dd>
<dt><code>regexp</code></dt><dd><p>(character): A regular expression (e.g. <code>[.]csv$</code>),
passed onto <code>grep()</code> to filter paths.</p>
</dd>
<dt><code>invert</code></dt><dd><p>(logical): If <code>code</code> return files which do not match.</p>
</dd>
<dt><code>recurse</code></dt><dd><p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>refresh</code></dt><dd><p>(logical): Refresh cached in <code>s3_cache</code>.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>data.table with directory metadata
</p>

<ul>
<li><p>bucket_name (character): AWS S3 bucket of file
</p>
</li>
<li><p>key (character): AWS S3 path key of file
</p>
</li>
<li><p>uri (character): S3 uri of file
</p>
</li>
<li><p>size (numeric): file size in bytes
</p>
</li>
<li><p>version_id (character): version id of file
</p>
</li>
<li><p>etag (character): An entity tag is an opague identifier
</p>
</li>
<li><p>last_modified (POSIXct): Created date of file
</p>
</li></ul>



<hr>
<a id="method-S3FileSystem-dir_ls"></a>



<h4>Method <code>dir_ls()</code></h4>

<p>Returns file name within AWS S3 directory
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_ls(
  path = ".",
  type = c("any", "bucket", "directory", "file"),
  glob = NULL,
  regexp = NULL,
  invert = FALSE,
  recurse = FALSE,
  refresh = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character):A character vector of one or more paths. Can be path
or s3 uri.</p>
</dd>
<dt><code>type</code></dt><dd><p>(character): File type(s) to return. Default (&quot;any&quot;) returns all
AWS S3 object types.</p>
</dd>
<dt><code>glob</code></dt><dd><p>(character): A wildcard pattern (e.g. <code>*.csv</code>), passed onto
<code>grep()</code> to filter paths.</p>
</dd>
<dt><code>regexp</code></dt><dd><p>(character): A regular expression (e.g. <code>[.]csv$</code>),
passed onto <code>grep()</code> to filter paths.</p>
</dd>
<dt><code>invert</code></dt><dd><p>(logical): If <code>code</code> return files which do not match.</p>
</dd>
<dt><code>recurse</code></dt><dd><p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>refresh</code></dt><dd><p>(logical): Refresh cached in <code>s3_cache</code>.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_ls_url"></a>



<h4>Method <code>dir_ls_url()</code></h4>

<p>Generate presigned url to list S3 directories
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_ls_url(path, expiration = 3600L, recurse = FALSE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths or uris</p>
</dd>
<dt><code>expiration</code></dt><dd><p>(numeric): The number of seconds the presigned url is
valid for. By default it expires in an hour (3600 seconds)</p>
</dd>
<dt><code>recurse</code></dt><dd><p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters passed to <code><a href="paws.storage.html#topic+s3_list_objects_v2">s3_list_objects_v2</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>return character of urls
</p>


<hr>
<a id="method-S3FileSystem-dir_tree"></a>



<h4>Method <code>dir_tree()</code></h4>

<p>Print contents of directories in a tree-like format
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_tree(path, recurse = TRUE, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): path A path to print the tree from</p>
</dd>
<dt><code>recurse</code></dt><dd><p>(logical): Returns all AWS S3 objects in lower sub directories</p>
</dd>
<dt><code>...</code></dt><dd><p>Additional arguments passed to <a href="#topic+s3_dir_ls">s3_dir_ls</a>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-dir_upload"></a>



<h4>Method <code>dir_upload()</code></h4>

<p>Uploads local directory to AWS S3
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$dir_upload(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of local file paths to upload to AWS S3</p>
</dd>
<dt><code>new_path</code></dt><dd><p>(character): A character vector of AWS S3 paths or uri's of the new locations.</p>
</dd>
<dt><code>max_batch</code></dt><dd><p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</dd>
<dt><code>overwrite</code></dt><dd><p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</dd>
<dt><code>...</code></dt><dd><p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code>
and <code><a href="paws.storage.html#topic+s3_create_multipart_upload">s3_create_multipart_upload</a></code></p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path"></a>



<h4>Method <code>path()</code></h4>

<p>Constructs a s3 uri path
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path(..., ext = "")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(character): Character vectors</p>
</dd>
<dt><code>ext</code></dt><dd><p>(character): An optional extension to append to the generated path</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_dir"></a>



<h4>Method <code>path_dir()</code></h4>

<p>Returns the directory portion of s3 uri
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_dir(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_ext"></a>



<h4>Method <code>path_ext()</code></h4>

<p>Returns the last extension for a path.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_ext(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character s3 uri file extension
</p>


<hr>
<a id="method-S3FileSystem-path_ext_remove"></a>



<h4>Method <code>path_ext_remove()</code></h4>

<p>Removes the last extension and return the rest of the s3 uri.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_ext_remove(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_ext_set"></a>



<h4>Method <code>path_ext_set()</code></h4>

<p>Replace the extension with a new extension.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_ext_set(path, ext)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths</p>
</dd>
<dt><code>ext</code></dt><dd><p>(character): New file extension</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_file"></a>



<h4>Method <code>path_file()</code></h4>

<p>Returns the file name portion of the s3 uri path
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_file(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of paths</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of file names
</p>


<hr>
<a id="method-S3FileSystem-path_join"></a>



<h4>Method <code>path_join()</code></h4>

<p>Construct an s3 uri path from path vector
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_join(parts)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>parts</code></dt><dd><p>(character): A character vector of one or more paths</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>character vector of s3 uri paths
</p>


<hr>
<a id="method-S3FileSystem-path_split"></a>



<h4>Method <code>path_split()</code></h4>

<p>Split s3 uri path to core components bucket, key and version id
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$path_split(path)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): A character vector of one or more paths or s3 uri</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>list character vectors splitting the s3 uri path in &quot;Bucket&quot;, &quot;Key&quot; and &quot;VersionId&quot;
</p>


<hr>
<a id="method-S3FileSystem-clear_cache"></a>



<h4>Method <code>clear_cache()</code></h4>

<p>Clear S3 Cache
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$clear_cache(path = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(character): s3 path to be cl</p>
</dd>
</dl>

</div>


<hr>
<a id="method-S3FileSystem-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>S3FileSystem$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Note</h3>

<p>This method will only update the modification time of the AWS S3 object.
</p>

<hr>
<h2 id='stream'>Streams data from R to AWS S3.</h2><span id='topic+stream'></span><span id='topic+s3_file_stream_in'></span><span id='topic+s3_file_stream_out'></span>

<h3>Description</h3>

<p><code>s3_file_stream_in</code> streams in AWS S3 file as a raw vector
</p>
<p><code>s3_file_stream_out</code> streams raw vector out to AWS S3 file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_stream_in(path, ...)

s3_file_stream_out(
  obj,
  path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stream_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or s3 uri</p>
</td></tr>
<tr><td><code id="stream_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code> and
<code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</td></tr>
<tr><td><code id="stream_+3A_obj">obj</code></td>
<td>
<p>(raw|character): A raw vector, rawConnection, url to be streamed up to AWS S3.</p>
</td></tr>
<tr><td><code id="stream_+3A_max_batch">max_batch</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="stream_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of raw vectors containing the contents of the file
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

obj = list(charToRaw("contents1"), charToRaw("contents2"))

dir = s3_file_temp(tmp_dir = "MyBucket")
path = s3_path(dir, letters[1:2], ext = "txt")

s3_file_stream_out(obj, path)
s3_file_stream_in(path)

## End(Not run)
</code></pre>

<hr>
<h2 id='stream_async'>Streams data from R to AWS S3.</h2><span id='topic+stream_async'></span><span id='topic+s3_file_stream_in_async'></span><span id='topic+s3_file_stream_out_async'></span>

<h3>Description</h3>

<p><code>s3_file_stream_in</code> streams in AWS S3 file as a raw vector
</p>
<p><code>s3_file_stream_out</code> streams raw vector out to AWS S3 file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_stream_in_async(path, ...)

s3_file_stream_out_async(
  obj,
  path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stream_async_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or s3 uri</p>
</td></tr>
<tr><td><code id="stream_async_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_get_object">s3_get_object</a></code> and
<code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code></p>
</td></tr>
<tr><td><code id="stream_async_+3A_obj">obj</code></td>
<td>
<p>(raw|character): A raw vector, rawConnection, url to be streamed up to AWS S3.</p>
</td></tr>
<tr><td><code id="stream_async_+3A_max_batch">max_batch</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="stream_async_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return <code><a href="future.html#topic+future">future</a></code> object of <code><a href="#topic+s3_file_stream_in">s3_file_stream_in()</a></code> <code><a href="#topic+s3_file_stream_out">s3_file_stream_out()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="future.html#topic+future">future</a></code> <code><a href="#topic+s3_file_move">s3_file_move()</a></code> <code><a href="#topic+s3_file_stream_in">s3_file_stream_in()</a></code> <code><a href="#topic+s3_file_stream_out">s3_file_stream_out()</a></code>
</p>

<hr>
<h2 id='tag'>Modifying file tags</h2><span id='topic+tag'></span><span id='topic+s3_file_tag_delete'></span><span id='topic+s3_file_tag_info'></span><span id='topic+s3_file_tag_update'></span>

<h3>Description</h3>

<p><code>s3_file_tag_delete</code> delete file tags
</p>
<p><code>s3_file_tag_info</code> get file tags
</p>
<p><code>s3_file_tag_info</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_tag_delete(path)

s3_file_tag_info(path)

s3_file_tag_update(path, tags, overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tag_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or s3 uri</p>
</td></tr>
<tr><td><code id="tag_+3A_tags">tags</code></td>
<td>
<p>(list): Tags to be applied</p>
</td></tr>
<tr><td><code id="tag_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): To overwrite tagging or to modify inplace. Default will
modify inplace.</p>
</td></tr>
</table>

<hr>
<h2 id='touch'>Change file modification time</h2><span id='topic+touch'></span><span id='topic+s3_file_touch'></span>

<h3>Description</h3>

<p>Similar to <code>fs::file_touch</code> this does not create the file if
it does not exist. Use <code><a href="#topic+s3_file_create">s3_file_create</a></code> to do this if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_touch(path, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="touch_+3A_path">path</code></td>
<td>
<p>(character): A character vector of paths or s3 uri</p>
</td></tr>
<tr><td><code id="touch_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_copy_object">s3_copy_object</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>


<h3>Note</h3>

<p>This method will only update the modification time of the AWS S3 object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Require AWS S3 credentials

dir = s3_file_temp(tmp_dir = "MyBucket")
path = s3_path(dir, letters[1:2], ext = "txt")

s3_file_touch(path)

## End(Not run)
</code></pre>

<hr>
<h2 id='upload'>Upload file and directory</h2><span id='topic+upload'></span><span id='topic+s3_file_upload'></span><span id='topic+s3_dir_upload'></span>

<h3>Description</h3>

<p><code>s3_file_upload</code> upload files to AWS S3
</p>
<p><code>s3_dir_upload</code> upload directory to AWS S3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_upload(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)

s3_dir_upload(path, new_path, max_batch, overwrite = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="upload_+3A_path">path</code></td>
<td>
<p>(character): A character vector of local file paths to upload to AWS S3</p>
</td></tr>
<tr><td><code id="upload_+3A_new_path">new_path</code></td>
<td>
<p>(character): A character vector of AWS S3 paths or uri's of the new locations.</p>
</td></tr>
<tr><td><code id="upload_+3A_max_batch">max_batch</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="upload_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="upload_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code>
and <code><a href="paws.storage.html#topic+s3_create_multipart_upload">s3_create_multipart_upload</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector of s3 uri paths
</p>

<hr>
<h2 id='upload_async'>Upload file and directory</h2><span id='topic+upload_async'></span><span id='topic+s3_file_upload_async'></span><span id='topic+s3_dir_upload_async'></span>

<h3>Description</h3>

<p><code>s3_file_upload</code> upload files to AWS S3
</p>
<p><code>s3_dir_upload</code> upload directory to AWS S3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>s3_file_upload_async(
  path,
  new_path,
  max_batch = fs_bytes("100MB"),
  overwrite = FALSE,
  ...
)

s3_dir_upload_async(path, new_path, max_batch, overwrite = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="upload_async_+3A_path">path</code></td>
<td>
<p>(character): A character vector of local file paths to upload to AWS S3</p>
</td></tr>
<tr><td><code id="upload_async_+3A_new_path">new_path</code></td>
<td>
<p>(character): A character vector of AWS S3 paths or uri's of the new locations.</p>
</td></tr>
<tr><td><code id="upload_async_+3A_max_batch">max_batch</code></td>
<td>
<p>(<a href="fs.html#topic+fs_bytes">fs_bytes</a>): Maximum batch size being uploaded with each multipart.</p>
</td></tr>
<tr><td><code id="upload_async_+3A_overwrite">overwrite</code></td>
<td>
<p>(logical): Overwrite files if the exist. If this is <code>FALSE</code>
and the file exists an error will be thrown.</p>
</td></tr>
<tr><td><code id="upload_async_+3A_...">...</code></td>
<td>
<p>parameters to be passed to <code><a href="paws.storage.html#topic+s3_put_object">s3_put_object</a></code>
and <code><a href="paws.storage.html#topic+s3_create_multipart_upload">s3_create_multipart_upload</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>return <code><a href="future.html#topic+future">future</a></code> object of <code><a href="#topic+s3_file_upload">s3_file_upload()</a></code> <code><a href="#topic+s3_dir_upload">s3_dir_upload()</a></code>
</p>


<h3>See Also</h3>

<p><code><a href="future.html#topic+future">future</a></code> <code><a href="#topic+s3_file_move">s3_file_move()</a></code> <code><a href="#topic+s3_file_upload">s3_file_upload()</a></code> <code><a href="#topic+s3_dir_upload">s3_dir_upload()</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
