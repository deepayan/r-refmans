<!DOCTYPE html><html><head><title>Help for package aum</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {aum}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aum'><p>aum</p></a></li>
<li><a href='#aum_diffs'><p>aum diffs</p></a></li>
<li><a href='#aum_diffs_binary'><p>aum diffs binary</p></a></li>
<li><a href='#aum_diffs_penalty'><p>aum diffs penalty</p></a></li>
<li><a href='#aum_errors'><p>aum errors</p></a></li>
<li><a href='#aum_line_search'><p>aum line search</p></a></li>
<li><a href='#aum_line_search_grid'><p>aum line search grid</p></a></li>
<li><a href='#aum_linear_model'><p>aum linear model</p></a></li>
<li><a href='#aum_linear_model_cv'><p>aum linear model cv</p></a></li>
<li><a href='#aum_linear_model_ls'><p>aum linear model ls</p></a></li>
<li><a href='#fn.not.zero'>
<p>Penalized models with non-zero fn at penalty=0</p></a></li>
<li><a href='#neg.zero.fp'>
<p>Negative zero FP</p></a></li>
<li><a href='#plot.aum_diffs'><p>plot aum diffs</p></a></li>
<li><a href='#plot.aum_line_search'><p>plot aum line search</p></a></li>
<li><a href='#plot.aum_line_search_grid'><p>plot aum line search grid</p></a></li>
<li><a href='#set_loss_plot'><p>set loss plot</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Area Under Minimum of False Positives and Negatives</td>
</tr>
<tr>
<td>Version:</td>
<td>2024.6.19</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient algorithms
 <a href="https://jmlr.org/papers/v24/21-0751.html">https://jmlr.org/papers/v24/21-0751.html</a>
 for computing Area Under Minimum,
 directional derivatives, and
 line search optimization of a linear model,
 with objective defined as either
 max Area Under the Curve or
 min Area Under Minimum.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tdhock/aum">https://github.com/tdhock/aum</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tdhock/aum/issues">https://github.com/tdhock/aum/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, data.table</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, kernlab, nc, ggplot2, WeightedROC, penaltyLearning,
knitr, markdown, mlbench, directlabels, microbenchmark, covr,
atime, ggrepel</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-20 13:21:27 UTC; tdhock</td>
</tr>
<tr>
<td>Author:</td>
<td>Toby Dylan Hocking [aut, cre],
  Jadon Fowler [aut] (Contributed exact line search C++ code)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-20 21:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aum'>aum</h2><span id='topic+aum'></span>

<h3>Description</h3>

<p>Compute the Area Under Minimum of False Positives and False
Negatives, and its directional derivatives.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum(error.diff.df, pred.vec)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_+3A_error.diff.df">error.diff.df</code></td>
<td>
<p>data frame of error differences, typically computed via
<code><a href="#topic+aum_diffs_binary">aum_diffs_binary</a></code> or <code><a href="#topic+aum_diffs_penalty">aum_diffs_penalty</a></code>. There should be one row for
each change in error functions. &quot;example&quot; column indicates example
ID (int from 1 to N), &quot;pred&quot; column indicates predicted value
where there is a change in the error function(s), &quot;fp_diff&quot; and
&quot;fn_diff&quot; columns indicate differences in false positives and
false negatives at that predicted value. Note that this
representation assumes that each error function has fp=0 at
pred=-Inf and fn=0 at pred=Inf.</p>
</td></tr>
<tr><td><code id="aum_+3A_pred.vec">pred.vec</code></td>
<td>
<p>numeric vector of N predicted values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list of two items: aum is numeric scalar loss value,
derivative_mat is N x 2 matrix of directional derivatives (first
column is derivative from left, second column is derivative from
right). If</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
(bin.diffs &lt;- aum::aum_diffs_binary(c(0,1)))
aum::aum(bin.diffs, c(-10,10))
aum::aum(bin.diffs, c(0,0))
aum::aum(bin.diffs, c(10,-10))

</code></pre>

<hr>
<h2 id='aum_diffs'>aum diffs</h2><span id='topic+aum_diffs'></span>

<h3>Description</h3>

<p>Create error differences data table which can be used as input to
<code><a href="#topic+aum">aum</a></code> function. Typical users should not use this function directly,
and instead use <code><a href="#topic+aum_diffs_binary">aum_diffs_binary</a></code> for binary classification, and
<code><a href="#topic+aum_diffs_penalty">aum_diffs_penalty</a></code> for error defined as a function of non-negative
penalty.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_diffs(example, pred, 
    fp_diff, fn_diff, 
    pred.name.vec)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_diffs_+3A_example">example</code></td>
<td>
<p>Integer or character vector identifying different examples.</p>
</td></tr>
<tr><td><code id="aum_diffs_+3A_pred">pred</code></td>
<td>
<p>Numeric vector of predicted values at which the error changes.</p>
</td></tr>
<tr><td><code id="aum_diffs_+3A_fp_diff">fp_diff</code></td>
<td>
<p>Numeric vector of difference in fp at <code>pred</code>.</p>
</td></tr>
<tr><td><code id="aum_diffs_+3A_fn_diff">fn_diff</code></td>
<td>
<p>Numeric vector of difference in fn at <code>pred</code>.</p>
</td></tr>
<tr><td><code id="aum_diffs_+3A_pred.name.vec">pred.name.vec</code></td>
<td>
<p>Character vector of <code>example</code> names for predictions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data table of class &quot;aum_diffs&quot; in which each rows represents a
breakpoint in an error function. Columns are interpreted as
follows: there is a change of &quot;fp_diff&quot;,&quot;fn_diff&quot; at predicted
value &quot;pred&quot; for example/observation &quot;example&quot;. This can be used
for computing Area Under Minimum via <code><a href="#topic+aum">aum</a></code> function, and plotted via
<code><a href="#topic+plot.aum_diffs">plot.aum_diffs</a></code>.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
aum::aum_diffs_binary(c(0,1))
aum::aum_diffs(c("positive", "negative"), 0, c(0,1), c(-1,1), c("negative", "positive"))
rbind(aum::aum_diffs(0L, 0, 1, 0), aum_diffs(1L, 0, 0, -1))

</code></pre>

<hr>
<h2 id='aum_diffs_binary'>aum diffs binary</h2><span id='topic+aum_diffs_binary'></span>

<h3>Description</h3>

<p>Convert binary labels to error differences.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_diffs_binary(label.vec, 
    pred.name.vec, denominator = "count")</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_diffs_binary_+3A_label.vec">label.vec</code></td>
<td>
<p>Numeric vector representing binary labels (either all 0,1 or all
-1,1). If named, names are used to identify each example.</p>
</td></tr>
<tr><td><code id="aum_diffs_binary_+3A_pred.name.vec">pred.name.vec</code></td>
<td>
<p>Character vector of prediction example names, used to convert
names of <code>label.vec</code> to integers.</p>
</td></tr>
<tr><td><code id="aum_diffs_binary_+3A_denominator">denominator</code></td>
<td>
<p>Type of diffs, either &quot;count&quot; or &quot;rate&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data table of class &quot;aum_diffs&quot; in which each rows represents a
breakpoint in an error function. Columns are interpreted as
follows: there is a change of &quot;fp_diff&quot;,&quot;fn_diff&quot; at predicted
value &quot;pred&quot; for example/observation &quot;example&quot;. This can be used
for computing Area Under Minimum via <code><a href="#topic+aum">aum</a></code> function, and plotted via
<code><a href="#topic+plot.aum_diffs">plot.aum_diffs</a></code>.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
aum_diffs_binary(c(0,1))
aum_diffs_binary(c(-1,1))
aum_diffs_binary(c(a=0,b=1,c=0), pred.name.vec=c("c","b"))
aum_diffs_binary(c(0,0,1,1,1), denominator="rate")

</code></pre>

<hr>
<h2 id='aum_diffs_penalty'>aum diffs penalty</h2><span id='topic+aum_diffs_penalty'></span>

<h3>Description</h3>

<p>Convert penalized errors to error differences. A typical use case
is for penalized optimal changepoint models, for which small
penalty values result in large fp/fn, and large penalty values
result in small fp/fn.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_diffs_penalty(errors.df, 
    pred.name.vec, denominator = "count")</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_diffs_penalty_+3A_errors.df">errors.df</code></td>
<td>
<p>data.frame which describes error as a function of penalty/lambda,
with at least columns example, min.lambda, fp, fn. Interpreted as
follows: fp/fn occur from all penalties from min.lambda to the
next value of min.lambda within the current value of example.</p>
</td></tr>
<tr><td><code id="aum_diffs_penalty_+3A_pred.name.vec">pred.name.vec</code></td>
<td>
<p>Character vector of prediction example names, used to convert
names of label.vec to integers.</p>
</td></tr>
<tr><td><code id="aum_diffs_penalty_+3A_denominator">denominator</code></td>
<td>
<p>Type of diffs, either &quot;count&quot; or &quot;rate&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data table of class &quot;aum_diffs&quot; in which each rows represents a
breakpoint in an error function. Columns are interpreted as
follows: there is a change of &quot;fp_diff&quot;,&quot;fn_diff&quot; at predicted
value &quot;pred&quot; for example/observation &quot;example&quot;. This can be used
for computing Area Under Minimum via <code><a href="#topic+aum">aum</a></code> function, and plotted via
<code><a href="#topic+plot.aum_diffs">plot.aum_diffs</a></code>.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(require("data.table"))setDTthreads(1L)#for CRAN check.

## Simple synthetic example with two changes in error function.
simple.df &lt;- data.frame(
  example=1L,
  min.lambda=c(0, exp(1), exp(2), exp(3)),
  fp=c(6,2,2,0),
  fn=c(0,1,1,5))
(simple.diffs &lt;- aum::aum_diffs_penalty(simple.df))
if(requireNamespace("ggplot2"))plot(simple.diffs)
(simple.rates &lt;- aum::aum_diffs_penalty(simple.df, denominator="rate"))
if(requireNamespace("ggplot2"))plot(simple.rates)

## Simple real data with four example, one has non-monotonic fn.
if(requireNamespace("penaltyLearning")){
  data(neuroblastomaProcessed, package="penaltyLearning", envir=environment())
  ## assume min.lambda, max.lambda columns only? use names?
  nb.err &lt;- with(neuroblastomaProcessed$errors, data.frame(
    example=paste0(profile.id, ".", chromosome),
    min.lambda,
    max.lambda,
    fp, fn))
  (nb.diffs &lt;- aum::aum_diffs_penalty(nb.err, c("1.2", "1.1", "4.1", "4.2")))
  if(requireNamespace("ggplot2"))plot(nb.diffs)
}

## More complex real data example
data(fn.not.zero, package="aum", envir=environment())
pred.names &lt;- unique(fn.not.zero$example)
(fn.not.zero.diffs &lt;- aum::aum_diffs_penalty(fn.not.zero, pred.names))
if(requireNamespace("ggplot2"))plot(fn.not.zero.diffs)

if(require("ggplot2")){
  name2id &lt;- structure(seq(0, length(pred.names)-1L), names=pred.names)
  fn.not.zero.wide &lt;- fn.not.zero[, .(example=name2id[example], min.lambda, max.lambda, fp, fn)]
  fn.not.zero.tall &lt;- data.table::melt(fn.not.zero.wide, measure=c("fp", "fn"))
  ggplot()+
    geom_segment(aes(
      -log(min.lambda), value,
      xend=-log(max.lambda), yend=value,
      color=variable, linewidth=variable),
      data=fn.not.zero.tall)+
    geom_point(aes(
      -log(min.lambda), value,
      fill=variable),
      color="black",
      shape=21,
      data=fn.not.zero.tall)+
    geom_vline(aes(
      xintercept=pred),
      data=fn.not.zero.diffs)+
    scale_size_manual(values=c(fp=2, fn=1))+
    facet_grid(example ~ ., labeller=label_both)
}

</code></pre>

<hr>
<h2 id='aum_errors'>aum errors</h2><span id='topic+aum_errors'></span>

<h3>Description</h3>

<p>Convert diffs to canonical errors, used internally in
<code><a href="#topic+plot.aum_diffs">plot.aum_diffs</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_errors(diffs.df)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_errors_+3A_diffs.df">diffs.df</code></td>
<td>
<p>data.table of diffs from <code><a href="#topic+aum_diffs">aum_diffs</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.table suitable for plotting piecewise constant error
functions, with columns example, min.pred, max.pred, fp, fn.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
(bin.diffs &lt;- aum::aum_diffs_binary(c(0,1)))
if(requireNamespace("ggplot2"))plot(bin.diffs)
aum::aum_errors(bin.diffs)

</code></pre>

<hr>
<h2 id='aum_line_search'>aum line search</h2><span id='topic+aum_line_search'></span>

<h3>Description</h3>

<p>Exact line search using a C++ STL map (red-black tree) to
implement a queue of line intersection events. If number of rows
of <code>error.diff.df</code> is B, and number of iterations is I, then space
complexity is O(B) and time complexity is O( (I+B)log B ).</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_line_search(error.diff.df, 
    feature.mat, weight.vec, 
    pred.vec = NULL, 
    maxIterations = nrow(error.diff.df), 
    feature.mat.search = feature.mat, 
    error.diff.search = error.diff.df, 
    maxStepSize = -1)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_line_search_+3A_error.diff.df">error.diff.df</code></td>
<td>
<p><code><a href="#topic+aum_diffs">aum_diffs</a></code> data frame with B rows, one for each breakpoint in
example-specific error functions.</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_feature.mat">feature.mat</code></td>
<td>
<p>N x p matrix of numeric features.</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_weight.vec">weight.vec</code></td>
<td>
<p>p-vector of numeric linear model coefficients.</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_pred.vec">pred.vec</code></td>
<td>
<p>N-vector of numeric predicted values. If NULL, <code>feature.mat</code> and
<code>weight.vec</code> will be used to compute predicted values.</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_maxiterations">maxIterations</code></td>
<td>
<p>max number of line search iterations, either a positive integer or
&quot;max.auc&quot; or &quot;min.aum&quot; indicating to keep going until AUC
decreases or AUM increases.</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_feature.mat.search">feature.mat.search</code></td>
<td>
<p>feature matrix to use in line search, default is subtrain, can be validation</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_error.diff.search">error.diff.search</code></td>
<td>
<p><code><a href="#topic+aum_diffs">aum_diffs</a></code> data frame to use in line search, default is subtrain, can be validation</p>
</td></tr>
<tr><td><code id="aum_line_search_+3A_maxstepsize">maxStepSize</code></td>
<td>
<p>max step size to explore.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of class aum_line_search. Element named &quot;line_search_result&quot;
is a data table with number of rows equal to <code>maxIterations</code> (if it
is positive integer, info for all steps, q.size column is number
of items in queue at each iteration), otherwise 1 (info for the
best step, q.size column is the total number of items popped off
the queue).</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(require("data.table"))setDTthreads(1L)#for CRAN check.

## Example 1: two binary data.
(bin.diffs &lt;- aum::aum_diffs_binary(c(0,1)))
if(requireNamespace("ggplot2"))plot(bin.diffs)
bin.line.search &lt;- aum::aum_line_search(bin.diffs, pred.vec=c(10,-10))
if(requireNamespace("ggplot2"))plot(bin.line.search)

if(requireNamespace("penaltyLearning")){

  ## Example 2: two changepoint examples, one with three breakpoints.
  data(neuroblastomaProcessed, package="penaltyLearning", envir=environment())
  nb.err &lt;- with(neuroblastomaProcessed$errors, data.frame(
    example=paste0(profile.id, ".", chromosome),
    min.lambda,
    max.lambda,
    fp, fn))
  (nb.diffs &lt;- aum::aum_diffs_penalty(nb.err, c("1.1", "4.2")))
  if(requireNamespace("ggplot2"))plot(nb.diffs)
  nb.line.search &lt;- aum::aum_line_search(nb.diffs, pred.vec=c(1,-1))
  if(requireNamespace("ggplot2"))plot(nb.line.search)
  aum::aum_line_search(nb.diffs, pred.vec=c(1,-1)-c(1,-1)*0.5)

  ## Example 3: all changepoint examples, with linear model.
  X.sc &lt;- scale(neuroblastomaProcessed$feature.mat)
  keep &lt;- apply(is.finite(X.sc), 2, all)
  X.subtrain &lt;- X.sc[1:50,keep]
  weight.vec &lt;- rep(0, ncol(X.subtrain))
  (diffs.subtrain &lt;- aum::aum_diffs_penalty(nb.err, rownames(X.subtrain)))
  nb.weight.search &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec, 
    maxIterations = 200)
  if(requireNamespace("ggplot2"))plot(nb.weight.search)

  ## Stop line search after finding a (local) max AUC or min AUM.
  max.auc.search &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec,
    maxIterations="max.auc")
  min.aum.search &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec,
    maxIterations="min.aum")
  if(require("ggplot2")){
    plot(nb.weight.search)+
      geom_point(aes(
        step.size, auc),
        data=data.table(max.auc.search[["line_search_result"]], panel="auc"),
        color="red")+
      geom_point(aes(
        step.size, aum),
        data=data.table(min.aum.search[["line_search_result"]], panel="aum"),
        color="red")
  }

  ## Alternate viz with x=iteration instead of step size.
  nb.weight.full &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec, 
    maxIterations = 1000)
  library(data.table)
  weight.result.tall &lt;- suppressWarnings(melt(
    nb.weight.full$line_search_result[, iteration:=1:.N][, .(
      iteration, auc, q.size,
      log10.step.size=log10(step.size),
      log10.aum=log10(aum))],
    id.vars="iteration"))
  if(require(ggplot2)){
    ggplot()+
      geom_point(aes(
        iteration, value),
        shape=1,
        data=weight.result.tall)+
      facet_grid(variable ~ ., scales="free")+
      scale_y_continuous("")
  }

  ## Example 4: line search on validation set.
  X.validation &lt;- X.sc[101:300,keep]
  diffs.validation &lt;- aum::aum_diffs_penalty(nb.err, rownames(X.validation))
  valid.search &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec, 
    maxIterations = 2000,
    feature.mat.search=X.validation,
    error.diff.search=diffs.validation)
  if(requireNamespace("ggplot2"))plot(valid.search)

  ## validation set max auc, min aum.
  max.auc.valid &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec,
    maxIterations="max.auc",
    feature.mat.search=X.validation,
    error.diff.search=diffs.validation)
  min.aum.valid &lt;- aum::aum_line_search(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec,
    maxIterations="min.aum",
    feature.mat.search=X.validation,
    error.diff.search=diffs.validation)
  if(require("ggplot2")){
    plot(valid.search)+
      geom_point(aes(
        step.size, auc),
        data=data.table(max.auc.valid[["line_search_result"]], panel="auc"),
        color="red")+
      geom_point(aes(
        step.size, aum),
        data=data.table(min.aum.valid[["line_search_result"]], panel="aum"),
        color="red")
  }

  ## compare subtrain and validation
  both.results &lt;- rbind(
    data.table(valid.search$line_search_result, set="validation"),
    data.table(nb.weight.search$line_search_result, set="subtrain"))
  both.max &lt;- rbind(
    data.table(max.auc.valid$line_search_result, set="validation"),
    data.table(max.auc.search$line_search_result, set="subtrain"))
  ggplot()+
    geom_vline(aes(
      xintercept=step.size, color=set),
      data=both.max)+
    geom_point(aes(
      step.size, auc, color=set),
      shape=1,
      data=both.results)

}

</code></pre>

<hr>
<h2 id='aum_line_search_grid'>aum line search grid</h2><span id='topic+aum_line_search_grid'></span>

<h3>Description</h3>

<p>Line search for predicted values, with grid search to check.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_line_search_grid(error.diff.df, 
    feature.mat, weight.vec, 
    pred.vec = NULL, 
    maxIterations = nrow(error.diff.df), 
    n.grid = 10L, add.breakpoints = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_line_search_grid_+3A_error.diff.df">error.diff.df</code></td>
<td>
<p><code><a href="#topic+aum_diffs">aum_diffs</a></code> data frame with B rows, one for each breakpoint in
example-specific error functions.</p>
</td></tr>
<tr><td><code id="aum_line_search_grid_+3A_feature.mat">feature.mat</code></td>
<td>
<p>N x p matrix of numeric features.</p>
</td></tr>
<tr><td><code id="aum_line_search_grid_+3A_weight.vec">weight.vec</code></td>
<td>
<p>p-vector of numeric linear model coefficients.</p>
</td></tr>
<tr><td><code id="aum_line_search_grid_+3A_pred.vec">pred.vec</code></td>
<td>
<p>N-vector of numeric predicted values. If missing, <code>feature.mat</code> and
<code>weight.vec</code> will be used to compute predicted values.</p>
</td></tr>
<tr><td><code id="aum_line_search_grid_+3A_maxiterations">maxIterations</code></td>
<td>
<p>positive int: max number of line search iterations.</p>
</td></tr>
<tr><td><code id="aum_line_search_grid_+3A_n.grid">n.grid</code></td>
<td>
<p>positive int: number of grid points for checking.</p>
</td></tr>
<tr><td><code id="aum_line_search_grid_+3A_add.breakpoints">add.breakpoints</code></td>
<td>
<p>add breakpoints from exact search to grid search.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of class aum_line_search_grid.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(require("data.table"))setDTthreads(1L)#for CRAN check.

## Example 1: two binary data.
(bin.diffs &lt;- aum::aum_diffs_binary(c(1,0)))
if(requireNamespace("ggplot2"))plot(bin.diffs)
bin.line.search &lt;- aum::aum_line_search_grid(bin.diffs, pred.vec=c(-10,10))
if(requireNamespace("ggplot2"))plot(bin.line.search)

if(requireNamespace("penaltyLearning")){

  ## Example 2: two changepoint examples, one with three breakpoints.
  data(neuroblastomaProcessed, package="penaltyLearning", envir=environment())
  nb.err &lt;- with(neuroblastomaProcessed$errors, data.frame(
    example=paste0(profile.id, ".", chromosome),
    min.lambda,
    max.lambda,
    fp, fn))
  (diffs.subtrain &lt;- aum::aum_diffs_penalty(nb.err, c("4.2", "1.1")))
  if(requireNamespace("ggplot2"))plot(diffs.subtrain)
  (nb.line.search &lt;- aum::aum_line_search_grid(diffs.subtrain, pred.vec=c(-1,1)))
  if(requireNamespace("ggplot2"))plot(nb.line.search)

  ## Example 3: 50 changepoint examples, with linear model.
  X.sc &lt;- scale(neuroblastomaProcessed$feature.mat[1:50,])
  keep &lt;- apply(is.finite(X.sc), 2, all)
  X.subtrain &lt;- X.sc[,keep]
  weight.vec &lt;- rep(0, ncol(X.subtrain))
  diffs.subtrain &lt;- aum::aum_diffs_penalty(nb.err, rownames(X.subtrain))
  nb.weight.search &lt;- aum::aum_line_search_grid(
    diffs.subtrain,
    feature.mat=X.subtrain,
    weight.vec=weight.vec,
    maxIterations = 200)
  if(requireNamespace("ggplot2"))plot(nb.weight.search)

}

## Example 4: counting intersections and intervals at each
## iteration/step size, when there are ties.
(bin.diffs &lt;- aum::aum_diffs_binary(c(0,0,0,1,1,1)))
bin.line.search &lt;- aum::aum_line_search_grid(
  bin.diffs, pred.vec=c(2,3,-1,1,-2,0), n.grid=21) 
if(require("ggplot2")){
  plot(bin.line.search)+
    geom_text(aes(
      step.size, Inf, label=sprintf(
        "%d,%d", intersections, intervals)),
      vjust=1.1,
      data=data.frame(
        panel="threshold", bin.line.search$line_search_result))
}

</code></pre>

<hr>
<h2 id='aum_linear_model'>aum linear model</h2><span id='topic+aum_linear_model'></span>

<h3>Description</h3>

<p>Learn a linear model with weights that minimize AUM. Weights are
initialized as a vector of zeros, then optimized using gradient
descent with exact line search.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_linear_model(feature.list, 
    diff.list, max.steps = NULL, 
    improvement.thresh = NULL, 
    maxIterations = "min.aum", 
    initial.weight.fun = NULL, 
    line.search.set = "subtrain")</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_linear_model_+3A_feature.list">feature.list</code></td>
<td>
<p>List with named elements subtrain and optionally validation, each
should be a scaled feature matrix.</p>
</td></tr>
<tr><td><code id="aum_linear_model_+3A_diff.list">diff.list</code></td>
<td>
<p>List with named elements subtrain and optionally validation, each
should be a data table of differences in error functions.</p>
</td></tr>
<tr><td><code id="aum_linear_model_+3A_max.steps">max.steps</code></td>
<td>
<p>positive integer: max number of steps of gradient descent with
exact line search (specify either this or <code>improvement.thresh</code>, not
both).</p>
</td></tr>
<tr><td><code id="aum_linear_model_+3A_improvement.thresh">improvement.thresh</code></td>
<td>
<p>non-negative real number: keep doing gradient descent while the
improvement in objective is greater than this number (specify either
this or <code>max.steps</code>, not both).</p>
</td></tr>
<tr><td><code id="aum_linear_model_+3A_maxiterations">maxIterations</code></td>
<td>
<p>max number of iterations of exact line search. If &quot;max.auc&quot; then
the objective for <code>improvement.thresh</code> is max AUC, otherwise
objective is min AUM. Default is &quot;min.aum&quot; </p>
</td></tr>
<tr><td><code id="aum_linear_model_+3A_initial.weight.fun">initial.weight.fun</code></td>
<td>
<p>Function for computing initial weights, default NULL means use a
random standard normal vector.</p>
</td></tr>
<tr><td><code id="aum_linear_model_+3A_line.search.set">line.search.set</code></td>
<td>
<p>set to use for line search, subtrain or validation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Linear model represented as a list of class aum_linear_model with
named elements: loss is a data table of values for subtrain and
optionally validation at each step, weight.vec is the final vector
of weights learned via gradient descent, intercept is the value
which results in minimal total error (FP+FN), learned via a linear
scan over all possible values given the final weight vector, and
search is a data table with one row for each step (best step size
and number of iterations of line search).</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>

<hr>
<h2 id='aum_linear_model_cv'>aum linear model cv</h2><span id='topic+aum_linear_model_cv'></span>

<h3>Description</h3>

<p>Cross-validation for learning number of early stopping gradient
descent steps with exact line search, in linear model for
minimizing AUM.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_linear_model_cv(feature.mat, 
    diff.dt, maxIterations = "min.aum", 
    improvement.thresh = NULL, 
    n.folds = 3, initial.weight.fun = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_linear_model_cv_+3A_feature.mat">feature.mat</code></td>
<td>
<p>N x P matrix of features, which will be scaled before gradient descent.</p>
</td></tr>
<tr><td><code id="aum_linear_model_cv_+3A_diff.dt">diff.dt</code></td>
<td>
<p>data table of differences in error functions, from
<code><a href="#topic+aum_diffs_penalty">aum_diffs_penalty</a></code> or <code><a href="#topic+aum_diffs_binary">aum_diffs_binary</a></code>. There should be an example
column with values from 0 to N-1.</p>
</td></tr>
<tr><td><code id="aum_linear_model_cv_+3A_maxiterations">maxIterations</code></td>
<td>
<p>max iterations of the exact line search, default is number of examples.</p>
</td></tr>
<tr><td><code id="aum_linear_model_cv_+3A_improvement.thresh">improvement.thresh</code></td>
<td>
<p>before doing cross-validation to learn the number of gradient
descent steps, we do gradient descent on the full data set in
order to determine a max number of steps, by continuing to do
exact line search steps while the decrease in AUM is greater than
this value (positive real number). Default NULL means to use the
value which is ten times smaller than the min non-zero absolute
value of FP and FN diffs in <code>diff.dt</code>.</p>
</td></tr>
<tr><td><code id="aum_linear_model_cv_+3A_n.folds">n.folds</code></td>
<td>
<p>Number of cross-validation folds to average over to determine the
best number of steps of gradient descent.</p>
</td></tr>
<tr><td><code id="aum_linear_model_cv_+3A_initial.weight.fun">initial.weight.fun</code></td>
<td>
<p>Function for computing initial weight vector in gradient descent.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Model trained with best number of iterations, represented as a
list of class aum_linear_model_cv with named elements: keep is a
logical vector telling which features should be kept before doing
matrix multiply of learned weight vector, weight.orig/weight.vec
and intercept.orig/intercept are the learned weights/intercepts
for the original/scaled feature space, fold.loss/set.loss are data
tables of loss values for the subtrain/validation sets, used for
selecting the best number of gradient descent steps.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(require("data.table"))setDTthreads(1L)#for CRAN check.

## simulated binary classification problem.
N.rows &lt;- 60
N.cols &lt;- 2
set.seed(1)
feature.mat &lt;- matrix(rnorm(N.rows*N.cols), N.rows, N.cols)
unknown.score &lt;- feature.mat[,1]*2.1 + rnorm(N.rows)
label.vec &lt;- ifelse(unknown.score &gt; 0, 1, 0)
diffs.dt &lt;- aum::aum_diffs_binary(label.vec)

## Default line search keeps doing iterations until increase in AUM.
(default.time &lt;- system.time({
  default.model &lt;- aum::aum_linear_model_cv(feature.mat, diffs.dt)
}))
plot(default.model)
print(default.valid &lt;- default.model[["set.loss"]][set=="validation"])
print(default.model[["search"]][, .(step.size, aum, iterations=q.size)])

## Can specify max number of iterations of line search.
(small.step.time &lt;- system.time({
  small.step.model &lt;- aum::aum_linear_model_cv(feature.mat, diffs.dt, maxIterations = N.rows)
}))
plot(small.step.model)
print(small.step.valid &lt;- small.step.model[["set.loss"]][set=="validation"])
small.step.model[["search"]][, .(step.size, aum, iterations=q.size)]

## Compare number of steps, iterations and time. On my machine small
## step model takes more time/steps, but less iterations in the C++
## line search code.
cbind(
  iterations=c(
    default=default.model[["search"]][, sum(q.size)],
    small.step=small.step.model[["search"]][, sum(q.size)]),
  seconds=c(
    default.time[["elapsed"]],
    small.step.time[["elapsed"]]),
  steps=c(
    default.model[["min.valid.aum"]][["step.number"]],
    small.step.model[["min.valid.aum"]][["step.number"]]),
  min.valid.aum=c(
    default.model[["min.valid.aum"]][["aum_mean"]],
    small.step.model[["min.valid.aum"]][["aum_mean"]]))

</code></pre>

<hr>
<h2 id='aum_linear_model_ls'>aum linear model ls</h2><span id='topic+aum_linear_model_ls'></span>

<h3>Description</h3>

<p>Learn a linear model with weights that minimize AUM. Weights are
initialized as a vector of zeros, then optimized using gradient
descent with exact line search.</p>


<h3>Usage</h3>

<pre><code class='language-R'>aum_linear_model_ls(feature.list, 
    diff.list, max.steps = NULL, 
    improvement.thresh = NULL, 
    maxIterations = "min.aum", 
    initial.weight.fun = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aum_linear_model_ls_+3A_feature.list">feature.list</code></td>
<td>
<p>List with named elements subtrain and validation, each
should be a scaled feature matrix.</p>
</td></tr>
<tr><td><code id="aum_linear_model_ls_+3A_diff.list">diff.list</code></td>
<td>
<p>List with named elements subtrain and validation, each
should be a data table of differences in error functions.</p>
</td></tr>
<tr><td><code id="aum_linear_model_ls_+3A_max.steps">max.steps</code></td>
<td>
<p>positive integer: max number of steps of gradient descent with
exact line search (specify either this or <code>improvement.thresh</code>, not
both).</p>
</td></tr>
<tr><td><code id="aum_linear_model_ls_+3A_improvement.thresh">improvement.thresh</code></td>
<td>
<p>non-negative real number: keep doing gradient descent while the
improvement in objective is greater than this number (specify either
this or <code>max.steps</code>, not both).</p>
</td></tr>
<tr><td><code id="aum_linear_model_ls_+3A_maxiterations">maxIterations</code></td>
<td>
<p>max number of iterations of exact line search. If &quot;max.auc&quot; then
the objective for <code>improvement.thresh</code> is max AUC, otherwise
objective is min AUM. Default is &quot;min.aum&quot; </p>
</td></tr>
<tr><td><code id="aum_linear_model_ls_+3A_initial.weight.fun">initial.weight.fun</code></td>
<td>
<p>Function for computing initial weights, default NULL means use a
random standard normal vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Linear model represented as a list of class <code><a href="#topic+aum_linear_model">aum_linear_model</a></code> with
named elements: loss is a data table of values for subtrain and
optionally validation at each step, weight.vec is the final vector
of weights learned via gradient descent, intercept is the value
which results in minimal total error (FP+FN), learned via a linear
scan over all possible values given the final weight vector, and
search is a data table with one row for each step (best step size
and number of iterations of line search).</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>

<hr>
<h2 id='fn.not.zero'>
Penalized models with non-zero fn at penalty=0
</h2><span id='topic+fn.not.zero'></span>

<h3>Description</h3>

<p>Usually we assume that fn must be zero at penalty=0, but this is not
always the case in real data/labels. For example in the PeakSegDisk
model with penalty=0, there are peaks almost everywhere but if a positive
label is too small or misplaced with respect to the detected peaks,
then there can be false negatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("fn.not.zero")</code></pre>


<h3>Format</h3>

<p>A data frame with 156 observations on the following 5 variables.
</p>

<dl>
<dt><code>example</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>min.lambda</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>max.lambda</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>fp</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>fn</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://github.com/tdhock/feature-learning-benchmark
</p>

<hr>
<h2 id='neg.zero.fp'>
Negative zero FP
</h2><span id='topic+neg.zero.fp'></span>

<h3>Description</h3>

<p>A data set that resulted in an error, negative FP, but actually
numerically zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("neg.zero.fp")</code></pre>


<h3>Format</h3>

<p>Named list. diffs is a data table, output of aum_diffs, pred is a
numeric vector of predictions.
</p>

<hr>
<h2 id='plot.aum_diffs'>plot aum diffs</h2><span id='topic+plot.aum_diffs'></span>

<h3>Description</h3>

<p>Plot method for <code><a href="#topic+aum_diffs">aum_diffs</a></code> which shows piecewise constant error
functions. Uses <code><a href="#topic+aum_errors">aum_errors</a></code> internally to compute error functions
which are plotted. Not recommended for large number of examples
(&gt;20).</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'aum_diffs'
plot(x, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.aum_diffs_+3A_x">x</code></td>
<td>
<p>data table with class &quot;aum_diffs&quot;.</p>
</td></tr>
<tr><td><code id="plot.aum_diffs_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot of error functions, each example in a different panel.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>

<hr>
<h2 id='plot.aum_line_search'>plot aum line search</h2><span id='topic+plot.aum_line_search'></span>

<h3>Description</h3>

<p>Plot method for <code><a href="#topic+aum_line_search">aum_line_search</a></code> which shows AUM and threshold functions. </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'aum_line_search'
plot(x, 
    ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.aum_line_search_+3A_x">x</code></td>
<td>
<p>list with class &quot;aum_line_search&quot;.</p>
</td></tr>
<tr><td><code id="plot.aum_line_search_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>

<hr>
<h2 id='plot.aum_line_search_grid'>plot aum line search grid</h2><span id='topic+plot.aum_line_search_grid'></span>

<h3>Description</h3>

<p>Plot method for <code><a href="#topic+aum_line_search_grid">aum_line_search_grid</a></code> which shows AUM and threshold
functions, along with grid points for checking.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'aum_line_search_grid'
plot(x, 
    ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.aum_line_search_grid_+3A_x">x</code></td>
<td>
<p>list with class &quot;aum_line_search_grid&quot;.</p>
</td></tr>
<tr><td><code id="plot.aum_line_search_grid_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>

<hr>
<h2 id='set_loss_plot'>set loss plot</h2><span id='topic+set_loss_plot'></span>

<h3>Description</h3>

<p>plot subtrain/validation loss.</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_loss_plot(loss.dt, 
    set.colors = c(subtrain = "black", 
        validation = "red"))</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_loss_plot_+3A_loss.dt">loss.dt</code></td>
<td>
<p>loss.dt </p>
</td></tr>
<tr><td><code id="set_loss_plot_+3A_set.colors">set.colors</code></td>
<td>
<p>set.colors </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt; [aut, cre], Jadon Fowler [aut] (Contributed exact line search C++ code)</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
