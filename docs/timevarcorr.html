<!DOCTYPE html><html lang="en-US"><head><title>Help for package timevarcorr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {timevarcorr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.onAttach'><p>Display welcome message</p></a></li>
<li><a href='#CI'><p>Internal functions for the computation of confidence intervals</p></a></li>
<li><a href='#in_pkgdown'><p>Determine if the package is being used by pkgdown</p></a></li>
<li><a href='#kern_smooth'><p>Smoothing by kernel regression</p></a></li>
<li><a href='#stockprice'><p>Daily Closing Prices of Major European Stock Indices, April 2000&ndash;December 2017</p></a></li>
<li><a href='#tcor'><p>Compute time varying correlation coefficients</p></a></li>
<li><a href='#test_equality'><p>Compute equality test between correlation coefficient estimates at two time points</p></a></li>
<li><a href='#test_ref'><p>Test difference between correlation coefficient estimates and a value of reference</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Time Varying Correlation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>
    Computes how the correlation between 2 time-series changes over time.
    To do so, the package follows the method from Choi &amp; Shin (2021) &lt;<a href="https://doi.org/10.1007%2Fs42952-020-00073-6">doi:10.1007/s42952-020-00073-6</a>&gt;.
    It performs a non-parametric kernel smoothing (using a common bandwidth) of all underlying components required for the computation of a correlation coefficient (i.e., x, y, x^2, y^2, xy).
    An automatic selection procedure for the bandwidth parameter is implemented.
    Alternative kernels can be used (Epanechnikov, box and normal).
    Both Pearson and Spearman correlation coefficients can be estimated and change in correlation over time can be tested.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lpridge</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dplyr, ggplot2, spelling, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://courtiol.github.io/timevarcorr/">https://courtiol.github.io/timevarcorr/</a>,
<a href="https://github.com/courtiol/timevarcorr">https://github.com/courtiol/timevarcorr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/courtiol/timevarcorr/issues">https://github.com/courtiol/timevarcorr/issues</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-06 21:19:27 UTC; courtiol</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexandre Courtiol
    <a href="https://orcid.org/0000-0003-0637-2959"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre,
    cph],
  François Rousset <a href="https://orcid.org/0000-0003-4670-0371"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexandre Courtiol &lt;alexandre.courtiol@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-07 18:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.onAttach'>Display welcome message</h2><span id='topic+.onAttach'></span>

<h3>Description</h3>

<p>This function should not be called by the user.
It displays a message when the package is being loaded.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.onAttach(libname, pkgname)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".onAttach_+3A_libname">libname</code></td>
<td>
<p>argument needed but automatically defined.</p>
</td></tr>
<tr><td><code id=".onAttach_+3A_pkgname">pkgname</code></td>
<td>
<p>argument needed but automatically defined.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>nothing (invisible NULL).
</p>

<hr>
<h2 id='CI'>Internal functions for the computation of confidence intervals</h2><span id='topic+CI'></span><span id='topic+calc_H'></span><span id='topic+calc_e'></span><span id='topic+calc_Gamma'></span><span id='topic+calc_GammaINF'></span><span id='topic+calc_L_And'></span><span id='topic+calc_D'></span><span id='topic+calc_SE'></span>

<h3>Description</h3>

<p>These functions compute the different terms required for <code><a href="#topic+tcor">tcor()</a></code> to compute the confidence
interval around the time-varying correlation coefficient. These terms are defined in Choi &amp; Shin (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_H(smoothed_obj)

calc_e(smoothed_obj, H)

calc_Gamma(e, l)

calc_GammaINF(e, L)

calc_L_And(e, AR.method = c("yule-walker", "burg", "ols", "mle", "yw"))

calc_D(smoothed_obj)

calc_SE(
  smoothed_obj,
  h,
  AR.method = c("yule-walker", "burg", "ols", "mle", "yw")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CI_+3A_smoothed_obj">smoothed_obj</code></td>
<td>
<p>an object created with <code><a href="#topic+calc_rho">calc_rho</a></code>.</p>
</td></tr>
<tr><td><code id="CI_+3A_h">H</code></td>
<td>
<p>an object created with <code>calc_H</code>.</p>
</td></tr>
<tr><td><code id="CI_+3A_e">e</code></td>
<td>
<p>an object created with <code>calc_e</code>.</p>
</td></tr>
<tr><td><code id="CI_+3A_l">l</code></td>
<td>
<p>a scalar indicating a number of time points.</p>
</td></tr>
<tr><td><code id="CI_+3A_l">L</code></td>
<td>
<p>a scalar indicating a bandwidth parameter.</p>
</td></tr>
<tr><td><code id="CI_+3A_ar.method">AR.method</code></td>
<td>
<p>character string specifying the method to fit the autoregressive model used to compute <code class="reqn">\hat{\gamma}_1</code> in <code class="reqn">L_{And}</code> (see <code><a href="stats.html#topic+ar">stats::ar</a></code> for details).</p>
</td></tr>
<tr><td><code id="CI_+3A_h">h</code></td>
<td>
<p>a scalar indicating the bandwidth used by the smoothing function.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>calc_H()</code> returns a 5 x 5 x <code class="reqn">t</code> array of elements of class numeric, which corresponds to <code class="reqn">\hat{H_t}</code> in Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_e()</code> returns a <code class="reqn">t</code> x 5 matrix of elements of class numeric storing the residuals, which corresponds to <code class="reqn">\hat{e}_t</code> in Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_Gamma()</code> returns a 5 x 5 matrix of elements of class numeric, which corresponds to <code class="reqn">\hat{\Gamma}_l</code> in Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_GammaINF()</code> returns a 5 x 5 matrix of elements of class numeric, which corresponds to <code class="reqn">\hat{\Gamma}^\infty</code> in Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_L_And()</code> returns a scalar of class numeric, which corresponds to <code class="reqn">L_{And}</code> in Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_D()</code> returns a <code class="reqn">t</code> x 5 matrix of elements of class numeric storing the residuals, which corresponds to <code class="reqn">D_t</code> in Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_SE()</code> returns a vector of length <code class="reqn">t</code> of elements of class numeric, which corresponds to <code class="reqn">se(\hat{\rho}_t(h))</code> in Choi &amp; Shin (2021).
</p>
</li></ul>



<h3>Functions</h3>


<ul>
<li> <p><code>calc_H()</code>: computes the <code class="reqn">\hat{H_t}</code> array.
</p>
<p><code class="reqn">\hat{H_t}</code> is a component needed to compute confidence intervals;
<code class="reqn">H_t</code> is defined in eq. 6 from Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_e()</code>: computes <code class="reqn">\hat{e}_t</code>.
</p>
<p><code class="reqn">\hat{e}_t</code> is defined in eq. 9 from Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_Gamma()</code>: computes <code class="reqn">\hat{\Gamma}_l</code>.
</p>
<p><code class="reqn">\hat{\Gamma}_l</code> is defined in eq. 9 from Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_GammaINF()</code>: computes <code class="reqn">\hat{\Gamma}^\infty</code>.
</p>
<p><code class="reqn">\hat{\Gamma}^\infty</code> is the long run variance estimator, defined in eq. 9 from Choi &amp; Shin (2021).
</p>
</li>
<li> <p><code>calc_L_And()</code>: computes <code class="reqn">L_{And}</code>.
</p>
<p><code class="reqn">L_{And}</code> is defined in Choi &amp; Shin (2021, p 342).
It also corresponds to <code class="reqn">S_T^*</code>, eq 5.3 in Andrews (1991).
</p>
</li>
<li> <p><code>calc_D()</code>: computes <code class="reqn">D_t</code>.
</p>
<p><code class="reqn">D_t</code> is defined in Choi &amp; Shin (2021, p 338).
</p>
</li>
<li> <p><code>calc_SE()</code>: computes <code class="reqn">se(\hat{\rho}_t(h))</code>.
</p>
<p>The standard deviation of the time-varying correlation (<code class="reqn">se(\hat{\rho}_t(h))</code>) is defined in eq. 8 from Choi &amp; Shin (2021).
It depends on <code class="reqn">D_{Lt}</code>, <code class="reqn">D_{Mt}</code> &amp; <code class="reqn">D_{Ut}</code>, themselves defined in Choi &amp; Shin (2021, p 337 &amp; 339).
The <code class="reqn">D_{Xt}</code> terms are all computed within the function since they all rely on the same components.
</p>
</li></ul>


<h3>References</h3>

<p>Choi, JE., Shin, D.W. Nonparametric estimation of time varying correlation coefficient.
J. Korean Stat. Soc. 50, 333–353 (2021). <a href="https://doi.org/10.1007/s42952-020-00073-6">doi:10.1007/s42952-020-00073-6</a>
</p>
<p>Andrews, D. W. K. Heteroskedasticity and autocorrelation consistent covariance matrix estimation.
Econometrica: Journal of the Econometric Society, 817-858 (1991).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tcor">tcor()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rho_obj &lt;- with(na.omit(stockprice),
                calc_rho(x = SP500, y = FTSE100, t = DateID, h = 20, kernel = "box"))
head(rho_obj)

## Computing \eqn{\hat{H_t}}

H &lt;- calc_H(smoothed_obj = rho_obj)
H[, , 1:2] # H array for the first two time points

## Computing \eqn{\hat{e}_t}

e &lt;- calc_e(smoothed_obj = rho_obj, H = H)
head(e) # e matrix for the first six time points

## Computing \eqn{\hat{\Gamma}_l}

calc_Gamma(e = e, l = 3)

## Computing \eqn{\hat{\Gamma}^\infty}

calc_GammaINF(e = e, L = 2)

## Computing \eqn{L_{And}}

calc_L_And(e = e)
sapply(c("yule-walker", "burg", "ols", "mle", "yw"),
       function(m) calc_L_And(e = e, AR.method = m)) ## comparing AR.methods

## Computing \eqn{D_t}

D &lt;- calc_D(smoothed_obj = rho_obj)
head(D) # D matrix for the first six time points

## Computing \eqn{se(\hat{\rho}_t(h))}
# nb: takes a few seconds to run

run &lt;- FALSE ## change to TRUE to run the example
if (in_pkgdown() || run) {

SE &lt;- calc_SE(smoothed_obj = rho_obj, h = 50)
head(SE) # SE vector for the first six time points

}


</code></pre>

<hr>
<h2 id='in_pkgdown'>Determine if the package is being used by pkgdown</h2><span id='topic+in_pkgdown'></span>

<h3>Description</h3>

<p>This function should not be called by the user.
It allows to run some examples conditionally to being used by pkgdown.
Code copied from <code><a href="pkgdown.html#topic+in_pkgdown">pkgdown::in_pkgdown()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>in_pkgdown()
</code></pre>


<h3>Value</h3>

<p>a logical value (<code>TRUE</code> or <code>FALSE</code>).
</p>

<hr>
<h2 id='kern_smooth'>Smoothing by kernel regression</h2><span id='topic+kern_smooth'></span>

<h3>Description</h3>

<p>The function perform the smoothing of a time-series by non-parametric kernel regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kern_smooth(
  x,
  t = seq_along(x),
  h,
  t.for.pred = t,
  kernel = c("epanechnikov", "box", "normal"),
  param_smoother = list(),
  output = c("dataframe", "list")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kern_smooth_+3A_x">x</code></td>
<td>
<p>a numeric vector of the series to be smoothed.</p>
</td></tr>
<tr><td><code id="kern_smooth_+3A_t">t</code></td>
<td>
<p>a (numeric or Date) vector of time points. If missing, observations
are considered to correspond to sequential time steps (i.e., 1, 2 ...).</p>
</td></tr>
<tr><td><code id="kern_smooth_+3A_h">h</code></td>
<td>
<p>a scalar indicating the bandwidth used by the smoothing function.</p>
</td></tr>
<tr><td><code id="kern_smooth_+3A_t.for.pred">t.for.pred</code></td>
<td>
<p>a (numeric or Date) vector of time points at which to
evaluate the smoothed fit. If missing, <code>t</code> is used.</p>
</td></tr>
<tr><td><code id="kern_smooth_+3A_kernel">kernel</code></td>
<td>
<p>a character string indicating which kernel to use: &quot;epanechnikov&quot;
(the default), &quot;box&quot;, or &quot;normal&quot; (abbreviations also work).</p>
</td></tr>
<tr><td><code id="kern_smooth_+3A_param_smoother">param_smoother</code></td>
<td>
<p>a list of additional parameters to provide to the
internal smoothing function (see <strong>Details</strong>).</p>
</td></tr>
<tr><td><code id="kern_smooth_+3A_output">output</code></td>
<td>
<p>a character string indicating if the output should be a &quot;dataframe&quot;
(default) or a list (for faster computation when the function is called repeatedly).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is essentially a wrapper that calls different underlying
functions depending on the kernel that is selected:
</p>

<ul>
<li> <p><code><a href="lpridge.html#topic+lpepa">lpridge::lpepa()</a></code> for &quot;epanechnikov&quot;.
</p>
</li>
<li> <p><code><a href="stats.html#topic+ksmooth">stats::ksmooth()</a></code> for &quot;normal&quot; and &quot;box&quot;.
The argument <code>param_smoother</code> can be used to pass additional arguments to
these functions.
</p>
</li></ul>



<h3>Value</h3>

<p>a dataframe of time points (<code>t.for.pred</code>) and corresponding fitted
values.
</p>


<h3>References</h3>

<p>A short post we found useful: <a href="http://users.stat.umn.edu/~helwig/notes/smooth-notes.html">http://users.stat.umn.edu/~helwig/notes/smooth-notes.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tcor">tcor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Smooth 10 first values of a vector

kern_smooth(stockprice$DAX[1:20], h = 5)


## Prediction at time step 2 and 3

kern_smooth(stockprice$DAX, h = 1, t.for.pred = c(2, 3))


## Smoothing using a vector of dates for time

kern_smooth(x = stockprice$DAX[1:10], t = stockprice$DateID[1:10], h = 5)


## Smoothing conserves original order

kern_smooth(x = stockprice$DAX[10:1], t = stockprice$DateID[10:1], h = 5)


## Effect of the bandwidth

plot(stockprice$DAX[1:100] ~ stockprice$DateID[1:100],
     las = 1, ylab = "DAX index", xlab = "Date")
points(kern_smooth(stockprice$DAX[1:100], stockprice$DateID[1:100], h = 1),
       type = "l", col = "grey")
points(kern_smooth(stockprice$DAX[1:100], stockprice$DateID[1:100], h = 3),
       type = "l", col = "blue")
points(kern_smooth(stockprice$DAX[1:100], stockprice$DateID[1:100], h = 10),
       type = "l", col = "red")
legend("topright", fill = c("grey", "blue", "red"),
       legend = c("1", "3", "10"), bty = "n", title = "Bandwidth (h)")


## Effect of the kernel

plot(stockprice$DAX[1:100] ~ stockprice$DateID[1:100],
     las = 1, ylab = "DAX index", xlab = "Date")
points(kern_smooth(stockprice$DAX[1:100], stockprice$DateID[1:100], h = 10),
       type = "l", col = "orange")
points(kern_smooth(stockprice$DAX[1:100], stockprice$DateID[1:100], h = 10, kernel = "box"),
       type = "l", col = "blue")
points(kern_smooth(stockprice$DAX[1:100], stockprice$DateID[1:100], h = 10, kernel = "norm"),
       type = "l", col = "red")
legend("topright", fill = c("orange", "blue", "red"),
       legend = c("epanechnikov", "box", "normal"), bty = "n", title = "Kernel method")

</code></pre>

<hr>
<h2 id='stockprice'>Daily Closing Prices of Major European Stock Indices, April 2000&ndash;December 2017</h2><span id='topic+stockprice'></span>

<h3>Description</h3>

<p>A dataset containing the stockmarket returns between 2000-04-03 and 2017-12-05.
This dataset is very close to the one used by Choi &amp; Shin (2021), although not
strictly identical. It has been produced by the Oxford-Man Institute of Quantitative Finance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stockprice
</code></pre>


<h3>Format</h3>

<p>A data frame with 4618 rows and 7 variables:
</p>

<dl>
<dt>DateID</dt><dd><p>a vector of <code>Date</code>.</p>
</dd>
<dt>SP500</dt><dd><p>a numeric vector of the stockmarket return for the S&amp;P 500 Index.</p>
</dd>
<dt>FTSE100</dt><dd><p>a numeric vector of the stockmarket return for the FTSE 100.</p>
</dd>
<dt>Nikkei</dt><dd><p>a numeric vector of the stockmarket return for the Nikkei 225.</p>
</dd>
<dt>DAX</dt><dd><p>a numeric vector of the stockmarket return for the German stock index.</p>
</dd>
<dt>NASDAQ</dt><dd><p>a numeric vector of the stockmarket return for the Nasdaq Stock Market.</p>
</dd>
<dt>Event</dt><dd><p>a character string of particular events that have impacted the stockmarket, as in Choi &amp; Shin (2021).</p>
</dd>
</dl>



<h3>Source</h3>

<p>The file was downloaded from the &quot;Oxford-Man Institute's realized library&quot;, which no longer exists.
At the time, the raw data file was named &quot;oxfordmanrealizedvolatilityindices-0.2-final.zip&quot;.
</p>


<h3>References</h3>

<p>Heber, Gerd, Asger Lunde, Neil Shephard and Kevin Sheppard (2009)
&quot;Oxford-Man Institute's realized library&quot;, Oxford-Man Institute, University of Oxford.
</p>
<p>Choi, JE., Shin, D.W. Nonparametric estimation of time varying correlation coefficient.
J. Korean Stat. Soc. 50, 333–353 (2021). <a href="https://doi.org/10.1007/s42952-020-00073-6">doi:10.1007/s42952-020-00073-6</a>
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+EuStockMarkets">datasets::EuStockMarkets</a></code> for a similar dataset, albeit formatted differently.
</p>

<hr>
<h2 id='tcor'>Compute time varying correlation coefficients</h2><span id='topic+tcor'></span><span id='topic+calc_rho'></span><span id='topic+calc_RMSE'></span><span id='topic+select_h'></span>

<h3>Description</h3>

<p>The function <code>tcor()</code> implements (together with its helper function
<code>calc_rho()</code>) the nonparametric estimation of the time varying correlation
coefficient proposed by Choi &amp; Shin (2021). The general idea is to compute a
(Pearson) correlation coefficient (<code class="reqn">r(x,y) = \frac{\hat{xy} - \hat{x}\times\hat{y}}{
\sqrt{\hat{x^2}-\hat{x}^2} \times \sqrt{\hat{y^2}-\hat{y}^2}}</code>), but instead of
using the means required for such a computation, each component (i.e.,
<code class="reqn">x</code>, <code class="reqn">y</code>, <code class="reqn">x^2</code>, <code class="reqn">y^2</code>, <code class="reqn">x \times y</code>) is smoothed and the
smoothed terms are considered in place the original means. The intensity of
the smoothing depends on a unique parameter: the bandwidth (<code>h</code>). If <code>h = Inf</code>, the method produces the original (i.e., time-invariant) correlation
value. The smaller the parameter <code>h</code>, the more variation in time is being
captured. The parameter <code>h</code> can be provided by the user; otherwise it is
automatically estimated by the internal helper functions <code>select_h()</code> and
<code>calc_RMSE()</code> (see <strong>Details</strong>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tcor(
  x,
  y,
  t = seq_along(x),
  h = NULL,
  cor.method = c("pearson", "spearman"),
  kernel = c("epanechnikov", "box", "normal"),
  CI = FALSE,
  CI.level = 0.95,
  param_smoother = list(),
  keep.missing = FALSE,
  verbose = FALSE
)

calc_rho(
  x,
  y,
  t = seq_along(x),
  t.for.pred = t,
  h,
  cor.method = c("pearson", "spearman"),
  kernel = c("epanechnikov", "box", "normal"),
  param_smoother = list()
)

calc_RMSE(
  h,
  x,
  y,
  t = seq_along(x),
  cor.method = c("pearson", "spearman"),
  kernel = c("epanechnikov", "box", "normal"),
  param_smoother = list(),
  verbose = FALSE
)

select_h(
  x,
  y,
  t = seq_along(x),
  cor.method = c("pearson", "spearman"),
  kernel = c("epanechnikov", "box", "normal"),
  param_smoother = list(),
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tcor_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="tcor_+3A_y">y</code></td>
<td>
<p>a numeric vector of to be correlated with <code>x</code>.</p>
</td></tr>
<tr><td><code id="tcor_+3A_t">t</code></td>
<td>
<p>a (numeric or Date) vector of time points. If missing, observations
are considered to correspond to sequential time steps (i.e., 1, 2 ...).</p>
</td></tr>
<tr><td><code id="tcor_+3A_h">h</code></td>
<td>
<p>a scalar indicating the bandwidth used by the smoothing function.</p>
</td></tr>
<tr><td><code id="tcor_+3A_cor.method">cor.method</code></td>
<td>
<p>a character string indicating which correlation coefficient
is to be computed (&quot;pearson&quot;, the default; or &quot;spearman&quot;).</p>
</td></tr>
<tr><td><code id="tcor_+3A_kernel">kernel</code></td>
<td>
<p>a character string indicating which kernel to use: &quot;epanechnikov&quot;
(the default), &quot;box&quot;, or &quot;normal&quot; (abbreviations also work).</p>
</td></tr>
<tr><td><code id="tcor_+3A_ci">CI</code></td>
<td>
<p>a logical specifying if a confidence interval should be computed or not (default = <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="tcor_+3A_ci.level">CI.level</code></td>
<td>
<p>a scalar defining the level for <code>CI</code> (default = 0.95 for 95% CI).</p>
</td></tr>
<tr><td><code id="tcor_+3A_param_smoother">param_smoother</code></td>
<td>
<p>a list of additional parameters to provide to the
internal smoothing function (see <strong>Details</strong>).</p>
</td></tr>
<tr><td><code id="tcor_+3A_keep.missing">keep.missing</code></td>
<td>
<p>a logical specifying if time points associated with missing
information should be kept in the output (default = <code>FALSE</code> to facilitate plotting).</p>
</td></tr>
<tr><td><code id="tcor_+3A_verbose">verbose</code></td>
<td>
<p>a logical specifying if information should be displayed to
monitor the progress of the cross validation (default = <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="tcor_+3A_t.for.pred">t.for.pred</code></td>
<td>
<p>a (numeric or Date) vector of time points at which to
evaluate the smoothed fit. If missing, <code>t</code> is used.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Smoothing</strong>: the smoothing of each component is performed by kernel
regression. The default is to use the Epanechnikov kernel following Choi &amp;
Shin (2021), but other kernels have also been implemented and can thus
alternatively be used (see <code><a href="#topic+kern_smooth">kern_smooth()</a></code> for details). The normal kernel
seems to sometimes lead to very small bandwidth being selected, but the
default kernel can lead to numerical issues (see next point). We thus
recommend always comparing the results from different kernel methods.
</p>
</li>
<li> <p><strong>Numerical issues</strong>: some numerical issues can happen because the smoothing
is performed independently on each component of the correlation coefficient.
As a consequence, some relationship between components may become violated
for some time points. For instance, if the square of the smoothed <code class="reqn">x</code> term
gets larger than the smoothed <code class="reqn">x^2</code> term, the variance of <code class="reqn">x</code> would become
negative. In such cases, coefficient values returned are <code>NA</code>.
</p>
</li>
<li> <p><strong>Bandwidth selection</strong>: when the value used to define the bandwidth (<code>h</code>)
in <code>tcor()</code> is set to <code>NULL</code> (the default), the internal function <code>select_h()</code>
is used to to select the optimal value for <code>h</code>. It is first estimated by
leave-one-out cross validation (using internally <code>calc_RMSE()</code>). If the cross
validation error (RMSE) is minimal for the maximal value of <code>h</code> considered
(<code class="reqn">8\sqrt{N}</code>), rather than taking this as the optimal <code>h</code> value, the
bandwidth becomes estimated using the so-called elbow criterion. This latter
method identifies the value <code>h</code> after which the cross validation error
decreasing very little. The procedure is detailed in section 2.1 in Choi &amp;
Shin (2021).
</p>
</li>
<li> <p><strong>Parallel computation</strong>: if <code>h</code> is not provided, an automatic bandwidth
selection occurs (see above). For large datasets, this step can be
computationally demanding. The current implementation thus relies on
<code><a href="parallel.html#topic+mclapply">parallel::mclapply()</a></code> and is thus only effective for Linux and MacOS.
Relying on parallel processing also implies that you call <code>options("mc.cores" = XX)</code> beforehand, replacing <code>XX</code> by the relevant number of CPU cores you
want to use (see <strong>Examples</strong>). For debugging, do use <code>options("mc.cores" = 1)</code>, otherwise you may not be able to see the error messages generated in
child nodes.
</p>
</li>
<li> <p><strong>Confidence interval</strong>: if <code>CI</code> is set to <code>TRUE</code>, a confidence interval is
calculated as described in Choi &amp; Shin (2021). This is also necessary for using
<code><a href="#topic+test_equality">test_equality()</a></code> to test differences between correlations at two time points.
The computation of the confidence intervals involves multiple internal
functions (see <code><a href="#topic+CI">CI</a></code> for details).
</p>
</li></ul>



<h3>Value</h3>

<p><strong>&mdash;Output for <code>tcor()</code>&mdash;</strong>
</p>
<p>A 2 x <code class="reqn">t</code> dataframe containing:
</p>

<ul>
<li><p> the time points (<code>t</code>).
</p>
</li>
<li><p> the estimates of the correlation value (<code>r</code>).
</p>
</li></ul>

<p>Or, if <code>CI = TRUE</code>, a 5 x <code class="reqn">t</code> dataframe containing:
</p>

<ul>
<li><p> the time points (<code>t</code>).
</p>
</li>
<li><p> the estimates of the correlation value (<code>r</code>).
</p>
</li>
<li><p> the Standard Error (<code>SE</code>).
</p>
</li>
<li><p> the lower boundary of the confidence intervals (<code>lwr</code>).
</p>
</li>
<li><p> the upper boundary of the confidence intervals (<code>upr</code>).
</p>
</li></ul>

<p>Some metadata are also attached to the dataframe (as attributes):
</p>

<ul>
<li><p> the call to the function (<code>call</code>).
</p>
</li>
<li><p> the argument <code>CI</code>.
</p>
</li>
<li><p> the bandwidth parameter (<code>h</code>).
</p>
</li>
<li><p> the method used to select <code>h</code> (<code>h_selection</code>).
</p>
</li>
<li><p> the minimal root mean square error when <code>h</code> is selected (<code>RMSE</code>).
</p>
</li>
<li><p> the computing time (in seconds) spent to select the bandwidth parameter (<code>h_selection_duration</code>) if <code>h</code> automatically selected.
</p>
</li></ul>

<p><strong>&mdash;Output for <code>calc_rho()</code>&mdash;</strong>
</p>
<p>A 14 x <code class="reqn">t</code> dataframe with:
</p>

<ul>
<li><p> the six raw components of correlation (<code>x</code>, <code>y</code>, <code>x2</code>, <code>y2</code>, <code>xy</code>).
</p>
</li>
<li><p> the time points (<code>t</code>).
</p>
</li>
<li><p> the six raw components of correlation after smoothing (<code>x_smoothed</code>, <code>y_smoothed</code>, <code>x2_smoothed</code>, <code>y2_smoothed</code>, <code>xy_smoothed</code>).
</p>
</li>
<li><p> the standard deviation around <code class="reqn">x</code> and <code class="reqn">y</code> (<code>sd_x_smoothed</code>, <code>sd_y_smoothed</code>).
</p>
</li>
<li><p> the smoothed correlation coefficient (<code>rho_smoothed</code>).
</p>
</li></ul>

<p><strong>&mdash;Output for <code>calc_RMSE()</code>&mdash;</strong>
</p>
<p>A scalar of class numeric corresponding to the RMSE.
</p>
<p><strong>&mdash;Output for <code>select_h()</code>&mdash;</strong>
</p>
<p>A list with the following components:
</p>

<ul>
<li><p> the selected bandwidth parameter (<code>h</code>).
</p>
</li>
<li><p> the method used to select <code>h</code> (<code>h_selection</code>).
</p>
</li>
<li><p> the minimal root mean square error when <code>h</code> is selected (<code>RMSE</code>).
</p>
</li>
<li><p> the computing time (in seconds) spent to select the bandwidth parameter (<code>time</code>).
</p>
</li></ul>



<h3>Functions</h3>


<ul>
<li> <p><code>tcor()</code>: <strong>the user-level function to be used</strong>.
</p>
</li>
<li> <p><code>calc_rho()</code>: computes the correlation for a given bandwidth.
</p>
<p>The function calls the kernel smoothing procedure on each component required
to compute the time-varying correlation.
</p>
</li>
<li> <p><code>calc_RMSE()</code>: Internal function computing the root mean square error (RMSE) for a given bandwidth.
</p>
<p>The function removes each time point one by one and predicts the correlation
at the missing time point based on the other time points. It then computes
and returns the RMSE between this predicted correlation and the one predicted
using the full dataset. See also <em>Bandwidth selection</em> and <em>Parallel
computation</em> in <strong>Details</strong>.
</p>
</li>
<li> <p><code>select_h()</code>: Internal function selecting the optimal bandwidth parameter <code>h</code>.
</p>
<p>The function selects and returns the optimal bandwidth parameter <code>h</code> using an
optimizer (<code><a href="stats.html#topic+optimize">stats::optimize()</a></code>) which searches the <code>h</code> value associated with
the smallest RMSE returned by <code><a href="#topic+calc_RMSE">calc_RMSE()</a></code>. See also <em>Bandwidth selection</em>
in <strong>Details</strong>.
</p>
</li></ul>


<h3>References</h3>

<p>Choi, JE., Shin, D.W. Nonparametric estimation of time varying correlation coefficient.
J. Korean Stat. Soc. 50, 333–353 (2021). <a href="https://doi.org/10.1007/s42952-020-00073-6">doi:10.1007/s42952-020-00073-6</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test_equality">test_equality</a></code>, <code><a href="#topic+kern_smooth">kern_smooth</a></code>, <code><a href="#topic+CI">CI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#####################################################
## Examples for the user-level function to be used ##
#####################################################

## Effect of the bandwidth

res_h50   &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 50))
res_h100  &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 100))
res_h200  &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 200))
plot(res_h50, type = "l", ylab = "Cor", xlab = "Time", las = 1, col = "grey")
points(res_h100, type = "l", col = "blue")
points(res_h200, type = "l", col = "red")
legend("bottom", horiz = TRUE, fill = c("grey", "blue", "red"),
       legend = c("50", "100", "200"), bty = "n", title = "Bandwidth (h)")


## Effect of the correlation method

res_pearson  &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 150))
res_spearman &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 150,
                                      cor.method = "spearman"))
plot(res_pearson, type = "l", ylab = "Cor", xlab = "Time", las = 1)
points(res_spearman, type = "l", col = "blue")
legend("bottom", horiz = TRUE, fill = c("black", "blue"),
       legend = c("pearson", "spearman"), bty = "n", title = "cor.method")


## Infinite bandwidth should match fixed correlation coefficients
## nb: `h = Inf` is not supported by default kernel (`kernel = 'epanechnikov'`)

res_pearson_hInf  &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = Inf,
                                           kernel = "normal"))
res_spearman_hInf &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = Inf,
                                           kernel = "normal", cor.method = "spearman"))
r &lt;- cor(stockprice$SP500, stockprice$FTSE100, use = "pairwise.complete.obs")
rho &lt;- cor(stockprice$SP500, stockprice$FTSE100, method = "spearman", use = "pairwise.complete.obs")
round(unique(res_pearson_hInf$r) - r, digits = 3) ## 0 indicates near equality
round(unique(res_spearman_hInf$r) - rho, digits = 3) ## 0 indicates near equality


## Computing and plotting the confidence interval

res_withCI &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 200, CI = TRUE))
with(res_withCI, {
     plot(r ~ t, type = "l", ylab = "Cor", xlab = "Time", las = 1, ylim = c(0, 1))
     points(lwr ~ t, type = "l", lty = 2)
     points(upr ~ t, type = "l", lty = 2)})


## Same using tidyverse packages (dplyr and ggplot2 must be installed)
## see https://github.com/courtiol/timevarcorr for more examples of this kind

if (require("dplyr", warn.conflicts = FALSE)) {

  stockprice |&gt;
    reframe(tcor(x = SP500, y = FTSE100, t = DateID,
                 h = 200, CI = TRUE)) -&gt; res_tidy
  res_tidy
}

if (require("ggplot2")) {

  ggplot(res_tidy) +
     aes(x = t, y = r, ymin = lwr, ymax = upr) +
     geom_ribbon(fill = "grey") +
     geom_line() +
     labs(title = "SP500 vs FTSE100", x = "Time", y = "Correlation") +
     theme_classic()

}


## Automatic selection of the bandwidth using parallel processing and comparison
## of the 3 alternative kernels on the first 500 time points of the dataset
# nb: takes a few seconds to run, so not run by default

run &lt;- in_pkgdown() || FALSE ## change to TRUE to run the example
if (run) {

options("mc.cores" = 2L) ## CPU cores to be used for parallel processing

res_hauto_epanech &lt;- with(stockprice[1:500, ],
         tcor(x = SP500, y = FTSE100, t = DateID, kernel = "epanechnikov")
         )

res_hauto_box &lt;- with(stockprice[1:500, ],
          tcor(x = SP500, y = FTSE100, t = DateID, kernel = "box")
          )

res_hauto_norm &lt;- with(stockprice[1:500, ],
          tcor(x = SP500, y = FTSE100, t = DateID, kernel = "norm")
          )

plot(res_hauto_epanech, type = "l", col = "red",
     ylab = "Cor", xlab = "Time", las = 1, ylim = c(0, 1))
points(res_hauto_box, type = "l", col = "grey")
points(res_hauto_norm, type = "l", col = "orange")
legend("top", horiz = TRUE, fill = c("red", "grey", "orange"),
       legend = c("epanechnikov", "box", "normal"), bty = "n",
       title = "Kernel")

}


## Comparison of the 3 alternative kernels under same bandwidth
## nb: it requires to have run the previous example

if (run) {

res_epanech &lt;- with(stockprice[1:500, ],
          tcor(x = SP500, y = FTSE100, t = DateID,
          kernel = "epanechnikov", h = attr(res_hauto_epanech, "h"))
          )

res_box &lt;- with(stockprice[1:500, ],
           tcor(x = SP500, y = FTSE100, t = DateID,
           kernel = "box", h = attr(res_hauto_epanech, "h"))
           )

res_norm &lt;- with(stockprice[1:500, ],
          tcor(x = SP500, y = FTSE100, t = DateID,
          kernel = "norm", h = attr(res_hauto_epanech, "h"))
          )

plot(res_epanech, type = "l", col = "red", ylab = "Cor", xlab = "Time",
     las = 1, ylim = c(0, 1))
points(res_box, type = "l", col = "grey")
points(res_norm, type = "l", col = "orange")
legend("top", horiz = TRUE, fill = c("red", "grey", "orange"),
       legend = c("epanechnikov", "box", "normal"), bty = "n",
       title = "Kernel")

}

## Automatic selection of the bandwidth using parallel processing with CI
# nb: takes a few seconds to run, so not run by default

run &lt;- in_pkgdown() || FALSE ## change to TRUE to run the example
if (run) {

res_hauto_epanechCI &lt;- with(stockprice[1:500, ],
          tcor(x = SP500, y = FTSE100, t = DateID, CI = TRUE)
          )

plot(res_hauto_epanechCI[, c("t", "r")], type = "l", col = "red",
     ylab = "Cor", xlab = "Time", las = 1, ylim = c(0, 1))
points(res_hauto_epanechCI[, c("t", "lwr")], type = "l", col = "red", lty = 2)
points(res_hauto_epanechCI[, c("t", "upr")], type = "l", col = "red", lty = 2)

}


## Not all kernels work well in all situations
## Here the default kernell estimation leads to issues for last time points
## nb1: EuStockMarkets is a time-series object provided with R
## nb2: takes a few minutes to run, so not run by default

run &lt;- in_pkgdown() || FALSE ## change to TRUE to run the example
if (run) {

EuStock_epanech &lt;- tcor(EuStockMarkets[1:500, "DAX"], EuStockMarkets[1:500, "SMI"])
EuStock_norm &lt;- tcor(EuStockMarkets[1:500, "DAX"], EuStockMarkets[1:500, "SMI"], kernel = "normal")

plot(EuStock_epanech, type = "l", col = "red", las = 1, ylim = c(-1, 1))
points(EuStock_norm, type = "l", col = "orange", lty = 2)
legend("bottom", horiz = TRUE, fill = c("red", "orange"),
       legend = c("epanechnikov", "normal"), bty = "n",
       title = "Kernel")
}




##################################################################
## Examples for the internal function computing the correlation ##
##################################################################

## Computing the correlation and its component for the first six time points

with(head(stockprice), calc_rho(x = SP500, y = FTSE100, t = DateID, h = 20))


## Predicting the correlation and its component at a specific time point

with(head(stockprice), calc_rho(x = SP500, y = FTSE100, t = DateID, h = 20,
     t.for.pred = DateID[1]))


## The function can handle non consecutive time points

set.seed(1)
calc_rho(x = rnorm(10), y = rnorm(10), t = c(1:5, 26:30), h = 3, kernel = "box")


## The function can handle non-ordered time series

with(head(stockprice)[c(1, 3, 6, 2, 4, 5), ], calc_rho(x = SP500, y = FTSE100, t = DateID, h = 20))


## Note: the function does not handle missing data (by design)

# calc_rho(x = c(NA, rnorm(9)), y = rnorm(10), t = c(1:2, 23:30), h = 2) ## should err (if ran)



###########################################################
## Examples for the internal function computing the RMSE ##
###########################################################

## Compute the RMSE on the correlation estimate
# nb: takes a few seconds to run, so not run by default

run &lt;- in_pkgdown() || FALSE ## change to TRUE to run the example
if (run) {

small_clean_dataset &lt;- head(na.omit(stockprice), n = 200)
with(small_clean_dataset, calc_RMSE(x = SP500, y = FTSE100, t = DateID, h = 10))

}




################################################################
## Examples for the internal function selecting the bandwidth ##
################################################################

## Automatic selection of the bandwidth using parallel processing
# nb: takes a few seconds to run, so not run by default

run &lt;- in_pkgdown() || FALSE ## change to TRUE to run the example
if (run) {

small_clean_dataset &lt;- head(na.omit(stockprice), n = 200)
with(small_clean_dataset, select_h(x = SP500, y = FTSE100, t = DateID))

}

</code></pre>

<hr>
<h2 id='test_equality'>Compute equality test between correlation coefficient estimates at two time points</h2><span id='topic+test_equality'></span>

<h3>Description</h3>

<p>This function tests whether smoothed correlation values at two time points are equal (H0) or not.
The test is described page 341 in Choi &amp; Shin (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_equality(
  tcor_obj,
  t1 = 1,
  t2 = nrow(tcor_obj),
  test = c("student", "chi2")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_equality_+3A_tcor_obj">tcor_obj</code></td>
<td>
<p>the output of a call to <code><a href="#topic+tcor">tcor()</a></code> with <code>CI = TRUE</code>.</p>
</td></tr>
<tr><td><code id="test_equality_+3A_t1">t1</code></td>
<td>
<p>the first time point used by the test (by default, the first time point in the time series).</p>
</td></tr>
<tr><td><code id="test_equality_+3A_t2">t2</code></td>
<td>
<p>the second time point used by the test (by default, the last time point in the time series).</p>
</td></tr>
<tr><td><code id="test_equality_+3A_test">test</code></td>
<td>
<p>a character string indicating which test to use (&quot;student&quot;, the default; or &quot;chi2&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two different test statistics can be used, one is asymptotically Student-t distributed under H0 and one is chi-square distributed.
In practice, it seems to give very similar results.
</p>


<h3>Value</h3>

<p>a data.frame with the result of the test, including the effect size (<code>delta_r = r[t2] - r[t1]</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test_ref">test_ref()</a></code>, <code><a href="#topic+tcor">tcor()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simple example

res &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 50, CI = TRUE))
test_equality(res)

## Chi2 instead of Student's t-test

test_equality(res, test = "chi2")


## Time point can be dates or indices (mixing possible) but output as in input data

test_equality(res, t1 = "2000-04-04", t2 = 1000)
res[1000, "t"] ## t2 matches with date in `res`
stockprice[1000, "DateID"] ## t2 does not match with date `stockprice` due to missing values


## It could be useful to use `keep.missing = TRUE` for index to match original data despite NAs

res2 &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID,
                              h = 50, CI = TRUE, keep.missing = TRUE))
test_equality(res2, t1 = "2000-04-04", t2 = 1000)
res[1000, "t"] ## t2 matches with date in `res`
stockprice[1000, "DateID"] ## t2 does match with date `stockprice` despite missing values

</code></pre>

<hr>
<h2 id='test_ref'>Test difference between correlation coefficient estimates and a value of reference</h2><span id='topic+test_ref'></span>

<h3>Description</h3>

<p>This function tests whether smoothed correlation values are equal (H0) or not to a reference value (default = <code>0</code>).
The test is not described in Choi &amp; Shin, 2021, but it is based on the idea behind <code><a href="#topic+test_equality">test_equality()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test_ref(
  tcor_obj,
  t = tcor_obj$t,
  r_ref = 0,
  test = c("student", "chi2"),
  p.adjust.methods = c("none", "bonferroni", "holm", "hochberg", "hommel", "BH", "BY",
    "fdr")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test_ref_+3A_tcor_obj">tcor_obj</code></td>
<td>
<p>the output of a call to <code><a href="#topic+tcor">tcor()</a></code> with <code>CI = TRUE</code>.</p>
</td></tr>
<tr><td><code id="test_ref_+3A_t">t</code></td>
<td>
<p>a vector of time point(s) used by the test (by default, all time points are considered).</p>
</td></tr>
<tr><td><code id="test_ref_+3A_r_ref">r_ref</code></td>
<td>
<p>a scalar indicating the reference value for the correlation coefficient to be used in the test (default = <code>0</code>).</p>
</td></tr>
<tr><td><code id="test_ref_+3A_test">test</code></td>
<td>
<p>a character string indicating which test to use (&quot;student&quot;, the default; or &quot;chi2&quot;).</p>
</td></tr>
<tr><td><code id="test_ref_+3A_p.adjust.methods">p.adjust.methods</code></td>
<td>
<p>a character string indicating the method used to adjust p-values for multiple testing (see <code><a href="stats.html#topic+p.adjust">p.adjust()</a></code>; default = &quot;none&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two different test statistics can be used, one is asymptotically Student-t distributed under H0 and one is chi-square distributed.
In practice, it seems to give very similar results.
</p>


<h3>Value</h3>

<p>a data.frame with the result of the test, including the effect size (<code>delta_r = r[t] - r_ref</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+test_equality">test_equality()</a></code>, <code><a href="#topic+tcor">tcor()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Comparison of all correlation values to reference of 0.5

res &lt;- with(stockprice, tcor(x = SP500, y = FTSE100, t = DateID, h = 300, CI = TRUE))
ref &lt;- 0.5
test_against_ref &lt;- test_ref(res, r_ref = ref)
head(test_against_ref)


## Plot to illustrate the correspondance with confidence intervals

plot(res$r ~ res$t, type = "l", ylim = c(0, 1), col = NULL)
abline(v = test_against_ref$t[test_against_ref$p &gt; 0.05], col = "lightgreen")
abline(v = test_against_ref$t[test_against_ref$p &lt; 0.05], col = "red")
points(res$r ~ res$t, type = "l")
points(res$upr ~ res$t, type = "l", lty = 2)
points(res$lwr ~ res$t, type = "l", lty = 2)
abline(h = ref, col = "blue")


## Test correlation of 0 a specific time points (using index or dates)

test_ref(res, t = c(100, 150))
test_ref(res, t = c("2000-08-18", "2000-10-27"))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
