<!DOCTYPE html><html lang="en-US"><head><title>Help for package mlearning</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlearning}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mlearning-package'><p>Machine Learning Algorithms with Unified Interface and Confusion Matrices</p></a></li>
<li><a href='#confusion'><p>Construct and analyze confusion matrices</p></a></li>
<li><a href='#mlearning'><p>Machine learning model for (un)supervised classification or regression</p></a></li>
<li><a href='#mlKnn'><p>Supervised classification using k-nearest neighbor</p></a></li>
<li><a href='#mlLda'><p>Supervised classification using linear discriminant analysis</p></a></li>
<li><a href='#mlLvq'><p>Supervised classification using learning vector quantization</p></a></li>
<li><a href='#mlNaiveBayes'><p>Supervised classification using naive Bayes</p></a></li>
<li><a href='#mlNnet'><p>Supervised classification and regression using neural network</p></a></li>
<li><a href='#mlQda'><p>Supervised classification using quadratic discriminant analysis</p></a></li>
<li><a href='#mlRforest'><p>Supervised classification and regression using random forest</p></a></li>
<li><a href='#mlRpart'><p>Supervised classification and regression using recursive partitioning</p></a></li>
<li><a href='#mlSvm'><p>Supervised classification and regression using support vector machine</p></a></li>
<li><a href='#plot.confusion'><p>Plot a confusion matrix</p></a></li>
<li><a href='#prior'><p>Get or set priors on a confusion matrix</p></a></li>
<li><a href='#response'><p>Get the response variable for a mlearning object</p></a></li>
<li><a href='#train'><p>Get the training variable for a mlearning object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Machine Learning Algorithms with Unified Interface and Confusion
Matrices</td>
</tr>
<tr>
<td>Description:</td>
<td>A unified interface is provided to various machine learning
  algorithms like linear or quadratic discriminant analysis, k-nearest
  neighbors, random forest, support vector machine, ... It allows to train,
  test, and apply cross-validation using similar functions and function
  arguments with a minimalist and clean, formula-based interface. Missing data
  are processed the same way as base and stats R functions for all algorithms,
  both in training and testing. Confusion matrices are also provided with a rich
  set of metrics calculated and a few specific plots.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Philippe Grosjean &lt;phgrosjean@sciviews.org&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, grDevices, class, nnet, MASS, e1071, randomForest,
ipred, rpart</td>
</tr>
<tr>
<td>Suggests:</td>
<td>mlbench, datasets, RColorBrewer, spelling, knitr, rmarkdown,
covr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.sciviews.org/mlearning/">https://www.sciviews.org/mlearning/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/SciViews/mlearning/issues">https://github.com/SciViews/mlearning/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-30 18:46:17 UTC; phgrosjean</td>
</tr>
<tr>
<td>Author:</td>
<td>Philippe Grosjean <a href="https://orcid.org/0000-0002-2694-9471"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Kevin Denis [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-30 19:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mlearning-package'>Machine Learning Algorithms with Unified Interface and Confusion Matrices</h2><span id='topic+mlearning-package'></span>

<h3>Description</h3>

<p>This package provides wrappers around several existing machine learning
algorithms in R, under a unified user interface. Confusion matrices can also
be calculated and viewed as tables or plots. Key features are:
</p>

<ul>
<li><p> Unified, formula-based interface for all algorithms, similar to
<code><a href="stats.html#topic+lm">stats::lm()</a></code>.
</p>
</li>
<li><p> Optimized code when a simplified formula <code>y ~ .</code> is used, meaning all
variables in data are used (one of them (<code>y</code> here) is the class to be
predicted (classification problem, a factor variable), or the dependent
variable of the model (regression problem, a numeric variable).
</p>
</li>
<li><p> Similar way of dealing with missing data, both in the training set and in
predictions. Underlying algorithms deal differently with missing data. Some
accept them, other not.
</p>
</li>
<li><p> Unified way of dealing with factor levels that have no cases in the
training set. The training succeeds, but the classifier is, of course, unable
to classify items in the missing class.
</p>
</li>
<li><p> The <code><a href="stats.html#topic+predict">predict()</a></code> methods have similar arguments. They return the class,
membership to the classes, both, or something else (probabilities,
raw predictions, ...) depending on the algorithm or the problem
(classification or regression).
</p>
</li>
<li><p> The <code><a href="#topic+cvpredict">cvpredict()</a></code> method is available for all algorithms and it performs
very easily a cross-validation, or even a leave_one_out validation (when
<code>cv.k</code> = number of cases). It operates transparently for the end-user.
</p>
</li>
<li><p> The <code><a href="#topic+confusion">confusion()</a></code> method creates a confusion matrix and the object can be
printed, summarized, plotted. Various metrics are easily derived from the
confusion matrix. Also, it allows to adjust prior probabilities of the
classes in a classification problem, in order to obtain more representative
estimates of the metrics when priors are adjusted to values closes to real
proportions of classes in the data.
</p>
</li></ul>

<p>See <code><a href="#topic+mlearning">mlearning()</a></code> for further explanations and an example analysis. See
<code><a href="#topic+mlLda">mlLda()</a></code> for examples of the different forms of the formula that can be
used. See <code><a href="#topic+plot.confusion">plot.confusion()</a></code> for the different ways to explore the confusion
matrix.
</p>


<h3>Important functions</h3>


<ul>
<li> <p><code><a href="#topic+ml_lda">ml_lda()</a></code>, <code><a href="#topic+ml_qda">ml_qda()</a></code>, <code><a href="#topic+ml_naive_bayes">ml_naive_bayes()</a></code>, <code><a href="#topic+ml_knn">ml_knn()</a></code>, <code><a href="#topic+ml_lvq">ml_lvq()</a></code>,
<code><a href="#topic+ml_nnet">ml_nnet()</a></code>, <code><a href="#topic+ml_rpart">ml_rpart()</a></code>, <code><a href="#topic+ml_rforest">ml_rforest()</a></code> and <code><a href="#topic+ml_svm">ml_svm()</a></code> to train classifiers
or regressors with the different algorithms that are supported in the
package,
</p>
</li>
<li> <p><code><a href="stats.html#topic+predict">predict()</a></code> and <code><a href="#topic+cvpredict">cvpredict()</a></code> for predictions, including using
cross-validation,
</p>
</li>
<li> <p><code><a href="#topic+confusion">confusion()</a></code> to calculate the confusion matrix (with various methods to
analyze it and to calculate derived metrics like recall, precision, F-score,
...)
</p>
</li>
<li> <p><code><a href="#topic+prior">prior()</a></code> to adjust prior probabilities,
</p>
</li>
<li> <p><code><a href="#topic+response">response()</a></code> and <code><a href="#topic+train">train()</a></code> to extract response and training variables from
an <strong>mlearning</strong> object.
</p>
</li></ul>


<hr>
<h2 id='confusion'>Construct and analyze confusion matrices</h2><span id='topic+confusion'></span><span id='topic+confusion.default'></span><span id='topic+confusion.mlearning'></span><span id='topic+print.confusion'></span><span id='topic+summary.confusion'></span><span id='topic+print.summary.confusion'></span>

<h3>Description</h3>

<p>Confusion matrices compare two classifications (usually one done
automatically using a machine learning algorithm versus the true
classification done by a specialist... but one can also compare two automatic
or two manual classifications against each other).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion(x, ...)

## Default S3 method:
confusion(
  x,
  y = NULL,
  vars = c("Actual", "Predicted"),
  labels = vars,
  merge.by = "Id",
  useNA = "ifany",
  prior,
  ...
)

## S3 method for class 'mlearning'
confusion(
  x,
  y = response(x),
  labels = c("Actual", "Predicted"),
  useNA = "ifany",
  prior,
  ...
)

## S3 method for class 'confusion'
print(x, sums = TRUE, error.col = sums, digits = 0, sort = "ward.D2", ...)

## S3 method for class 'confusion'
summary(object, type = "all", sort.by = "Fscore", decreasing = TRUE, ...)

## S3 method for class 'summary.confusion'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confusion_+3A_x">x</code></td>
<td>
<p>an object with a <code>confusion()</code> method implemented.</p>
</td></tr>
<tr><td><code id="confusion_+3A_...">...</code></td>
<td>
<p>further arguments passed to the method.</p>
</td></tr>
<tr><td><code id="confusion_+3A_y">y</code></td>
<td>
<p>another object, from which to extract the second classification, or
<code>NULL</code> if not used.</p>
</td></tr>
<tr><td><code id="confusion_+3A_vars">vars</code></td>
<td>
<p>the variables of interest in the first and second classification
in the case the objects are lists or data frames. Otherwise, this argument
is ignored and <code>x</code> and <code>y</code> must be factors with same length and same levels.</p>
</td></tr>
<tr><td><code id="confusion_+3A_labels">labels</code></td>
<td>
<p>labels to use for the two classifications. By default, they are
the same as <code>vars</code>, or the one in the confusion matrix.</p>
</td></tr>
<tr><td><code id="confusion_+3A_merge.by">merge.by</code></td>
<td>
<p>a character string with the name of variables to use to merge
the two data frames, or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="confusion_+3A_usena">useNA</code></td>
<td>
<p>do we keep <code>NA</code>s as a separate category? The default <code>"ifany"</code>
creates this category only if there are missing values. Other possibilities
are <code>"no"</code>, or <code>"always"</code>.</p>
</td></tr>
<tr><td><code id="confusion_+3A_prior">prior</code></td>
<td>
<p>class frequencies to use for first classifier that is tabulated
in the rows of the confusion matrix. For its value, see here under, the
<code style="white-space: pre;">&#8288;value=&#8288;</code> argument.</p>
</td></tr>
<tr><td><code id="confusion_+3A_sums">sums</code></td>
<td>
<p>is the confusion matrix printed with rows and columns sums?</p>
</td></tr>
<tr><td><code id="confusion_+3A_error.col">error.col</code></td>
<td>
<p>is a column with class error for first classifier added
(equivalent to false negative rate of FNR)?</p>
</td></tr>
<tr><td><code id="confusion_+3A_digits">digits</code></td>
<td>
<p>the number of digits after the decimal point to print in the
confusion matrix. The default or zero leads to most compact presentation
and is suitable for frequencies, but not for relative frequencies.</p>
</td></tr>
<tr><td><code id="confusion_+3A_sort">sort</code></td>
<td>
<p>are rows and columns of the confusion matrix sorted so that
classes with larger confusion are closer together? Sorting is done
using a hierarchical clustering with <code><a href="stats.html#topic+hclust">hclust()</a></code>. The clustering method
is <code>"ward.D2"</code> by default, but see the <code><a href="stats.html#topic+hclust">hclust()</a></code> help for other options).
If <code>FALSE</code> or <code>NULL</code>, no sorting is done.</p>
</td></tr>
<tr><td><code id="confusion_+3A_object">object</code></td>
<td>
<p>a <strong>confusion</strong> object</p>
</td></tr>
<tr><td><code id="confusion_+3A_type">type</code></td>
<td>
<p>either <code>"all"</code> (by default), or considering <code>TP</code> is the true
positives, <code>FP</code> is the false positives, <code>TN</code> is the true negatives and <code>FN</code>
is the false negatives, one can also specify: <code>"Fscore"</code> (F-score = F-measure
= F1 score = harmonic mean of Precision and recall), <code>"Recall"</code>
(TP / (TP + FN) = 1 - FNR), <code>"Precision"</code> (TP / (TP + FP) = 1 - FDR),
<code>"Specificity"</code> (TN / (TN + FP) = 1 - FPR), <code>"NPV"</code> (Negative predicted value
= TN / (TN + FN) = 1 - FOR), <code>"FPR"</code> (False positive rate = 1 - Specificity
= FP / (FP + TN)), <code>"FNR"</code> (False negative rate = 1 - Recall = FN / (TP + FN)),
<code>"FDR"</code> (False Discovery Rate = 1 - Precision = FP / (TP + FP)), <code>"FOR"</code>
(False omission rate = 1 - NPV = FN / (FN + TN)), <code>"LRPT"</code> (Likelihood Ratio
for Positive Tests = Recall / FPR = Recall / (1 - Specificity)), <code>"LRNT"</code>
Likelihood Ratio for Negative Tests = FNR / Specificity = (1 - Recall) /
Specificity, <code>"LRPS"</code> (Likelihood Ratio for Positive Subjects = Precision /
FOR = Precision / (1 - NPV)), <code>"LRNS"</code> (Likelihood Ratio Negative Subjects =
FDR / NPV = (1 - Precision) / (1 - FOR)), <code>"BalAcc"</code> (Balanced accuracy
= (Sensitivity + Specificity) / 2), <code>"MCC"</code> (Matthews correlation coefficient),
<code>"Chisq"</code> (Chisq metric), or <code>"Bray"</code> (Bray-Curtis metric)</p>
</td></tr>
<tr><td><code id="confusion_+3A_sort.by">sort.by</code></td>
<td>
<p>the statistics to use to sort the table (by default, Fmeasure,
the F1 score for each class = 2 * recall * precision / (recall + precision)).</p>
</td></tr>
<tr><td><code id="confusion_+3A_decreasing">decreasing</code></td>
<td>
<p>do we sort in increasing or decreasing order?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A confusion matrix in a <strong>confusion</strong> object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+plot.confusion">plot.confusion()</a></code>, <code><a href="#topic+prior">prior()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Glass", package = "mlbench")
# Use a little bit more informative labels for Type
Glass$Type &lt;- as.factor(paste("Glass", Glass$Type))

# Use learning vector quantization to classify the glass types
# (using default parameters)
summary(glass_lvq &lt;- ml_lvq(Type ~ ., data = Glass))

# Calculate cross-validated confusion matrix
(glass_conf &lt;- confusion(cvpredict(glass_lvq), Glass$Type))
# Raw confusion matrix: no sort and no margins
print(glass_conf, sums = FALSE, sort = FALSE)

summary(glass_conf)
summary(glass_conf, type = "Fscore")
</code></pre>

<hr>
<h2 id='mlearning'>Machine learning model for (un)supervised classification or regression</h2><span id='topic+mlearning'></span><span id='topic+print.mlearning'></span><span id='topic+summary.mlearning'></span><span id='topic+print.summary.mlearning'></span><span id='topic+plot.mlearning'></span><span id='topic+predict.mlearning'></span><span id='topic+cvpredict'></span><span id='topic+cvpredict.mlearning'></span>

<h3>Description</h3>

<p>An <strong>mlearning</strong> object provides an unified (formula-based) interface to
several machine learning algorithms. They share the same interface and very
similar arguments. They conform to the formula-based approach, of say,
<code><a href="stats.html#topic+lm">stats::lm()</a></code> in base R, but with a coherent handling of missing data and
missing class levels. An optimized version exists for the simplified <code>y ~ .</code>
formula. Finally, cross-validation is also built-in.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlearning(
  formula,
  data,
  method,
  model.args,
  call = match.call(),
  ...,
  subset,
  na.action = na.fail
)

## S3 method for class 'mlearning'
print(x, ...)

## S3 method for class 'mlearning'
summary(object, ...)

## S3 method for class 'summary.mlearning'
print(x, ...)

## S3 method for class 'mlearning'
plot(x, y, ...)

## S3 method for class 'mlearning'
predict(
  object,
  newdata,
  type = c("class", "membership", "both"),
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)

cvpredict(object, ...)

## S3 method for class 'mlearning'
cvpredict(
  object,
  type = c("class", "membership", "both"),
  cv.k = 10,
  cv.strat = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlearning_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
(for supervised classification), a vector of numbers (for regression) or
nothing (for unsupervised classification) and the right term with the list
of independent, predictive variables, separated with a plus sign. If the
data frame provided contains only the dependent and independent variables,
one can use the <code>class ~ .</code> short version (that one is strongly encouraged).
Variables with minus sign are eliminated. Calculations on variables are
possible according to usual formula convention (possibly protected by using
<code>I()</code>). Supervised classification, regression or unsupervised classification
are not available for all algorithms. Check respective help pages.</p>
</td></tr>
<tr><td><code id="mlearning_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlearning_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases
in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training
set if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different dataset in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case. Other
methods may be provided by the various algorithms (check their help pages)</p>
</td></tr>
<tr><td><code id="mlearning_+3A_model.args">model.args</code></td>
<td>
<p>arguments for formula modeling with substituted data and
subset... Not to be used by the end-user.</p>
</td></tr>
<tr><td><code id="mlearning_+3A_call">call</code></td>
<td>
<p>the function call. Not to be used by the end-user.</p>
</td></tr>
<tr><td><code id="mlearning_+3A_...">...</code></td>
<td>
<p>further arguments (depends on the method).</p>
</td></tr>
<tr><td><code id="mlearning_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlearning_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_qda">ml_qda()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlearning_+3A_x">x</code>, <code id="mlearning_+3A_object">object</code></td>
<td>
<p>an <strong>mlearning</strong> object</p>
</td></tr>
<tr><td><code id="mlearning_+3A_y">y</code></td>
<td>
<p>a second <strong>mlearning</strong> object or nothing (not used in several plots)</p>
</td></tr>
<tr><td><code id="mlearning_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlearning_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (a
number between 0 and 1) to the different classes, or <code>"both"</code> to return
classes and memberships. Other types may be provided for some algorithms
(read respective help pages).</p>
</td></tr>
<tr><td><code id="mlearning_+3A_cv.k">cv.k</code></td>
<td>
<p>k for k-fold cross-validation, cf <code><a href="ipred.html#topic+errorest">ipred::errorest()</a></code>.
By default, 10.</p>
</td></tr>
<tr><td><code id="mlearning_+3A_cv.strat">cv.strat</code></td>
<td>
<p>is the subsampling stratified or not in cross-validation,
cf <code><a href="ipred.html#topic+errorest">ipred::errorest()</a></code>. <code>TRUE</code> by default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <strong>mlearning</strong> object for <code><a href="#topic+mlearning">mlearning()</a></code>. Methods return their own
results that can be a <strong>mlearning</strong>, <strong>data.frame</strong>, <strong>vector</strong>, etc.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ml_lda">ml_lda()</a></code>, <code><a href="#topic+ml_qda">ml_qda()</a></code>, <code><a href="#topic+ml_naive_bayes">ml_naive_bayes()</a></code>, <code><a href="#topic+ml_nnet">ml_nnet()</a></code>,
<code><a href="#topic+ml_rpart">ml_rpart()</a></code>, <code><a href="#topic+ml_rforest">ml_rforest()</a></code>, <code><a href="#topic+ml_svm">ml_svm()</a></code>, <code><a href="#topic+confusion">confusion()</a></code> and <code><a href="#topic+prior">prior()</a></code>. Also
<code><a href="ipred.html#topic+errorest">ipred::errorest()</a></code> that internally computes the cross-validation
in <code>cvpredict()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># mlearning() should not be calle directly. Use the mlXXX() functions instead
# for instance, for Random Forest, use ml_rforest()/mlRforest()
# A typical classification involves several steps:
#
# 1) Prepare data: split into training set (2/3) and test set (1/3)
#    Data cleaning (elimination of unwanted variables), transformation of
#    others (scaling, log, ratios, numeric to factor, ...) may be necessary
#    here. Apply the same treatments on the training and test sets
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133) # Also random or stratified sampling
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]

# 2) Train the classifier, use of the simplified formula class ~ . encouraged
#    so, you may have to prepare the train/test sets to keep only relevant
#    variables and to possibly transform them before use
iris_rf &lt;- ml_rforest(data = iris_train, Species ~ .)
iris_rf
summary(iris_rf)
train(iris_rf)
response(iris_rf)

# 3) Find optimal values for the parameters of the model
#    This is usally done iteratively. Just an example with ntree where a plot
#    exists to help finding optimal value
plot(iris_rf)
# For such a relatively simple case, 50 trees are enough, retrain with it
iris_rf &lt;- ml_rforest(data = iris_train, Species ~ ., ntree = 50)
summary(iris_rf)

# 4) Study the classifier performances. Several metrics and tools exists
#    like ROC curves, AUC, etc. Tools provided here are the confusion matrix
#    and the metrics that are calculated on it.
predict(iris_rf) # Default type is class
predict(iris_rf, type = "membership")
predict(iris_rf, type = "both")
# Confusion matrice and metrics using 10-fols cross-validation
iris_rf_conf &lt;- confusion(iris_rf, method = "cv")
iris_rf_conf
summary(iris_rf_conf)
# Note you may want to manipulate priors too, see ?prior

# 5) Go back to step #1 and refine the process until you are happy with the
#    results. Then, you can use the classifier to predict unknown items.
</code></pre>

<hr>
<h2 id='mlKnn'>Supervised classification using k-nearest neighbor</h2><span id='topic+mlKnn'></span><span id='topic+ml_knn'></span><span id='topic+mlKnn.formula'></span><span id='topic+mlKnn.default'></span><span id='topic+summary.mlKnn'></span><span id='topic+print.summary.mlKnn'></span><span id='topic+predict.mlKnn'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the k-nearest neighbor
algorithm provided by <code><a href="class.html#topic+knn">class::knn()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlKnn(train, ...)

ml_knn(train, ...)

## S3 method for class 'formula'
mlKnn(formula, data, k.nn = 5, ..., subset, na.action)

## Default S3 method:
mlKnn(train, response, k.nn = 5, ...)

## S3 method for class 'mlKnn'
summary(object, ...)

## S3 method for class 'summary.mlKnn'
print(x, ...)

## S3 method for class 'mlKnn'
predict(
  object,
  newdata,
  type = c("class", "prob", "both"),
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlKnn_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_...">...</code></td>
<td>
<p>further arguments passed to the classification method or its
<code><a href="stats.html#topic+predict">predict()</a></code> method (not used here for now).</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual formula
convention (possibly protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_k.nn">k.nn</code></td>
<td>
<p>k used for k-NN number of neighbor considered. Default is 5.</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_knn">ml_knn()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_response">response</code></td>
<td>
<p>a vector of factor for the classification.</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_x">x</code>, <code id="mlKnn_+3A_object">object</code></td>
<td>
<p>an <strong>mlKnn</strong> object</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"prob"</code> the &quot;probability&quot; for the
different classes as assessed by the number of neighbors of these classes,
or <code>"both"</code> to return classes and &quot;probabilities&quot;,</p>
</td></tr>
<tr><td><code id="mlKnn_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases in
<code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training set
if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different data set in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_knn">ml_knn()</a></code>/<code><a href="#topic+mlKnn">mlKnn()</a></code> creates an <strong>mlKnn</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="class.html#topic+knn">class::knn()</a></code> and
<code><a href="ipred.html#topic+predict.ipredknn">ipred::predict.ipredknn()</a></code> that actually do the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_knn &lt;- ml_knn(data = iris_train, Species ~ .)
summary(iris_knn)
predict(iris_knn) # This object only returns classes
# Self-consistency, do not use for assessing classifier performances!
confusion(iris_knn)
# Use an independent test set instead
confusion(predict(iris_knn, newdata = iris_test), iris_test$Species)
</code></pre>

<hr>
<h2 id='mlLda'>Supervised classification using linear discriminant analysis</h2><span id='topic+mlLda'></span><span id='topic+ml_lda'></span><span id='topic+mlLda.formula'></span><span id='topic+mlLda.default'></span><span id='topic+predict.mlLda'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the linear discriminant
analysis algorithm provided by <code><a href="MASS.html#topic+lda">MASS::lda()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlLda(train, ...)

ml_lda(train, ...)

## S3 method for class 'formula'
mlLda(formula, data, ..., subset, na.action)

## Default S3 method:
mlLda(train, response, ...)

## S3 method for class 'mlLda'
predict(
  object,
  newdata,
  type = c("class", "membership", "both", "projection"),
  prior = object$prior,
  dimension = NULL,
  method = c("plug-in", "predictive", "debiased", "cv"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlLda_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="MASS.html#topic+lda">MASS::lda()</a></code> or its  <code><a href="stats.html#topic+predict">predict()</a></code>
method (see the corresponding help page).</p>
</td></tr>
<tr><td><code id="mlLda_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual
formula convention (possibly protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlLda_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlLda_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_lda">ml_lda()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlLda_+3A_response">response</code></td>
<td>
<p>a vector of factor for the classification.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_object">object</code></td>
<td>
<p>an <strong>mlLda</strong> object</p>
</td></tr>
<tr><td><code id="mlLda_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (a
number between 0 and 1) to the different classes, or <code>"both"</code> to return
classes and memberships. The <code>type = "projection"</code> returns a projection
of the individuals in the plane represented by the <code style="white-space: pre;">&#8288;dimension= &#8288;</code>
discriminant components.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_prior">prior</code></td>
<td>
<p>the prior probabilities of class membership. By default, the
prior are obtained from the object and, if they where not changed,
correspond to the proportions observed in the training set.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_dimension">dimension</code></td>
<td>
<p>the number of the predictive space to use. If <code>NULL</code> (the
default) a reasonable value is used. If this is less than min(p, ng-1),
only the first <code>dimension</code> discriminant components are used (except for
<code>method = "predictive"</code>), and only those dimensions are returned in x.</p>
</td></tr>
<tr><td><code id="mlLda_+3A_method">method</code></td>
<td>
<p><code>"plug-in"</code>, <code>"predictive"</code>, <code>"debiased"</code>, or <code>"cv"</code>.
<code>"plug-in"</code> (default) the usual unbiased parameter estimates are used.
With <code>"predictive"</code>, the parameters are integrated out using a vague prior.
With <code>"debiased"</code>, an unbiased estimator of the log posterior probabilities
is used. With <code>"cv"</code>, cross-validation is used instead. If you specify
<code>method = "cv"</code> then <code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide
<code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_lda">ml_lda()</a></code>/<code><a href="#topic+mlLda">mlLda()</a></code> creates an <strong>mlLda</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="MASS.html#topic+lda">MASS::lda()</a></code> that
actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_lda &lt;- ml_lda(data = iris_train, Species ~ .)
iris_lda
summary(iris_lda)
plot(iris_lda, col = as.numeric(response(iris_lda)) + 1)
# Prediction using a test set
predict(iris_lda, newdata = iris_test) # class (default type)
predict(iris_lda, type = "membership") # posterior probability
predict(iris_lda, type = "both") # both class and membership in a list
# Type projection
predict(iris_lda, type = "projection") # Projection on the LD axes
# Add test set items to the previous plot
points(predict(iris_lda, newdata = iris_test, type = "projection"),
  col = as.numeric(predict(iris_lda, newdata = iris_test)) + 1, pch = 19)
# predict() and confusion() should be used on a separate test set
# for unbiased estimation (or using cross-validation, bootstrap, ...)
# Wrong, cf. biased estimation (so-called, self-consistency)
confusion(iris_lda)
# Estimation using a separate test set
confusion(predict(iris_lda, newdata = iris_test), iris_test$Species)

# Another dataset (binary predictor... not optimal for lda, just for test)
data("HouseVotes84", package = "mlbench")
house_lda &lt;- ml_lda(data = HouseVotes84, na.action = na.omit, Class ~ .)
summary(house_lda)
confusion(house_lda) # Self-consistency (biased metrics)
print(confusion(house_lda), error.col = FALSE) # Without error column

# More complex formulas
# Exclude one or more variables
iris_lda2 &lt;- ml_lda(data = iris, Species ~ . - Sepal.Width)
summary(iris_lda2)
# With calculation
iris_lda3 &lt;- ml_lda(data = iris, Species ~ log(Petal.Length) +
  log(Petal.Width) + I(Petal.Length/Sepal.Length))
summary(iris_lda3)

# Factor levels with missing items are allowed
ir2 &lt;- iris[-(51:100), ] # No Iris versicolor in the training set
iris_lda4 &lt;- ml_lda(data = ir2, Species ~ .)
summary(iris_lda4) # missing class
# Missing levels are reinjected in class or membership by predict()
predict(iris_lda4, type = "both")
# ... but, of course, the classifier is wrong for Iris versicolor
confusion(predict(iris_lda4, newdata = iris), iris$Species)

# Simpler interface, but more memory-effective
iris_lda5 &lt;- ml_lda(train = iris[, -5], response = iris$Species)
summary(iris_lda5)
</code></pre>

<hr>
<h2 id='mlLvq'>Supervised classification using learning vector quantization</h2><span id='topic+mlLvq'></span><span id='topic+ml_lvq'></span><span id='topic+mlLvq.formula'></span><span id='topic+mlLvq.default'></span><span id='topic+summary.mlLvq'></span><span id='topic+print.summary.mlLvq'></span><span id='topic+predict.mlLvq'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the learning vector quantization
algorithms provided by <code><a href="class.html#topic+olvq1">class::olvq1()</a></code>, <code><a href="class.html#topic+lvq1">class::lvq1()</a></code>, <code><a href="class.html#topic+lvq2">class::lvq2()</a></code>,
and <code><a href="class.html#topic+lvq3">class::lvq3()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlLvq(train, ...)

ml_lvq(train, ...)

## S3 method for class 'formula'
mlLvq(
  formula,
  data,
  k.nn = 5,
  size,
  prior,
  algorithm = "olvq1",
  ...,
  subset,
  na.action
)

## Default S3 method:
mlLvq(train, response, k.nn = 5, size, prior, algorithm = "olvq1", ...)

## S3 method for class 'mlLvq'
summary(object, ...)

## S3 method for class 'summary.mlLvq'
print(x, ...)

## S3 method for class 'mlLvq'
predict(
  object,
  newdata,
  type = "class",
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlLvq_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_...">...</code></td>
<td>
<p>further arguments passed to the classification method or its
<code><a href="stats.html#topic+predict">predict()</a></code> method (not used here for now).</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual formula
convention (possibly protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_k.nn">k.nn</code></td>
<td>
<p>k used for k-NN number of neighbor considered. Default is 5.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_size">size</code></td>
<td>
<p>the size of the codebook. Defaults to
min(round(0.4 \* nc \* (nc - 1 + p/2),0), n) where nc is the number of
classes.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_prior">prior</code></td>
<td>
<p>probabilities to represent classes in the codebook (default
values are the proportions in the training set).</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_algorithm">algorithm</code></td>
<td>
<p><code>"olvq1"</code> (by default, the optimized 'lvq1' version), or
<code>"lvq1"</code>, <code>"lvq2"</code>, <code>"lvq3"</code>.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For [ml_lvq)] <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).
</p>
<p>[ml_lvq)]: R:ml_lvq)</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_response">response</code></td>
<td>
<p>a vector of factor of the classes.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_x">x</code>, <code id="mlLvq_+3A_object">object</code></td>
<td>
<p>an <strong>mlLvq</strong> object</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. For this method, only <code>"class"</code>
is accepted, and it is the default. It returns the predicted classes.</p>
</td></tr>
<tr><td><code id="mlLvq_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases in
<code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training set
if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different dataset in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_lvq">ml_lvq()</a></code>/<code><a href="#topic+mlLvq">mlLvq()</a></code> creates an <strong>mlLvq</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="class.html#topic+olvq1">class::olvq1()</a></code>,
<code><a href="class.html#topic+lvq1">class::lvq1()</a></code>, <code><a href="class.html#topic+lvq2">class::lvq2()</a></code>, and <code><a href="class.html#topic+lvq3">class::lvq3()</a></code> that actually do the
classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_lvq &lt;- ml_lvq(data = iris_train, Species ~ .)
summary(iris_lvq)
predict(iris_lvq) # This object only returns classes
#' # Self-consistency, do not use for assessing classifier performances!
confusion(iris_lvq)
# Use an independent test set instead
confusion(predict(iris_lvq, newdata = iris_test), iris_test$Species)
</code></pre>

<hr>
<h2 id='mlNaiveBayes'>Supervised classification using naive Bayes</h2><span id='topic+mlNaiveBayes'></span><span id='topic+ml_naive_bayes'></span><span id='topic+mlNaiveBayes.formula'></span><span id='topic+mlNaiveBayes.default'></span><span id='topic+predict.mlNaiveBayes'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the naive Bayes algorithm
provided by <code><a href="e1071.html#topic+naiveBayes">e1071::naiveBayes()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlNaiveBayes(train, ...)

ml_naive_bayes(train, ...)

## S3 method for class 'formula'
mlNaiveBayes(formula, data, laplace = 0, ..., subset, na.action)

## Default S3 method:
mlNaiveBayes(train, response, laplace = 0, ...)

## S3 method for class 'mlNaiveBayes'
predict(
  object,
  newdata,
  type = c("class", "membership", "both"),
  method = c("direct", "cv"),
  na.action = na.exclude,
  threshold = 0.001,
  eps = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlNaiveBayes_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_...">...</code></td>
<td>
<p>further arguments passed to the classification method or its
<code><a href="stats.html#topic+predict">predict()</a></code> method (not used here for now).</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual formula
convention (possibly protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_laplace">laplace</code></td>
<td>
<p>positive number controlling Laplace smoothing for the naive
Bayes classifier. The default (0) disables Laplace smoothing.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_naive_bayes">ml_naive_bayes()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_response">response</code></td>
<td>
<p>a vector of factor with the classes.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_object">object</code></td>
<td>
<p>an <strong>mlNaiveBayes</strong> object</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code>, the posterior
probability or <code>"both"</code> to return classes and memberships,</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases in
<code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training set
if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different dataset in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_threshold">threshold</code></td>
<td>
<p>value replacing cells with probabilities within 'eps' range.</p>
</td></tr>
<tr><td><code id="mlNaiveBayes_+3A_eps">eps</code></td>
<td>
<p>number for specifying an epsilon-range to apply Laplace smoothing
(to replace zero or close-zero probabilities by 'threshold').</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_naive_bayes">ml_naive_bayes()</a></code>/<code><a href="#topic+mlNaiveBayes">mlNaiveBayes()</a></code> creates an <strong>mlNaiveBayes</strong>,
<strong>mlearning</strong> object containing the classifier and a lot of additional
metadata used by the functions and methods you can apply to it like
<code><a href="stats.html#topic+predict">predict()</a></code> or <code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or
extract specific components, inspect the &quot;unclassed&quot; object using
<code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also
<code><a href="e1071.html#topic+naiveBayes">e1071::naiveBayes()</a></code> that actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_nb &lt;- ml_naive_bayes(data = iris_train, Species ~ .)
summary(iris_nb)
predict(iris_nb) # Default type is class
predict(iris_nb, type = "membership")
predict(iris_nb, type = "both")
# Self-consistency, do not use for assessing classifier performances!
confusion(iris_nb)
# Use an independent test set instead
confusion(predict(iris_nb, newdata = iris_test), iris_test$Species)

# Another dataset
data("HouseVotes84", package = "mlbench")
house_nb &lt;- ml_naive_bayes(data = HouseVotes84, Class ~ .,
  na.action = na.omit)
summary(house_nb)
confusion(house_nb) # Self-consistency
confusion(cvpredict(house_nb), na.omit(HouseVotes84)$Class)
</code></pre>

<hr>
<h2 id='mlNnet'>Supervised classification and regression using neural network</h2><span id='topic+mlNnet'></span><span id='topic+ml_nnet'></span><span id='topic+mlNnet.formula'></span><span id='topic+mlNnet.default'></span><span id='topic+predict.mlNnet'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the single-hidden-layer neural
network algorithm, possibly with skip-layer connections provided by
<code><a href="nnet.html#topic+nnet">nnet::nnet()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlNnet(train, ...)

ml_nnet(train, ...)

## S3 method for class 'formula'
mlNnet(
  formula,
  data,
  size = NULL,
  rang = NULL,
  decay = 0,
  maxit = 1000,
  ...,
  subset,
  na.action
)

## Default S3 method:
mlNnet(train, response, size = NULL, rang = NULL, decay = 0, maxit = 1000, ...)

## S3 method for class 'mlNnet'
predict(
  object,
  newdata,
  type = c("class", "membership", "both", "raw"),
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlNnet_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="nnet.html#topic+nnet">nnet::nnet()</a></code> that has many more
parameters (see its help page).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
(for supervised classification), a vector of numbers (for regression) and the
right term with the list of independent, predictive variables, separated with
a plus sign. If the data frame provided contains only the dependent and
independent variables, one can use the <code>class ~ .</code> short version (that one is
strongly encouraged). Variables with minus sign are eliminated. Calculations
on variables are possible according to usual formula convention (possibly
protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_size">size</code></td>
<td>
<p>number of units in the hidden layer. Can be zero if there are
skip-layer units. If <code>NULL</code> (the default), a reasonable value is computed.</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_rang">rang</code></td>
<td>
<p>initial random weights on [-rang, rang]. Value about 0.5 unless
the inputs are large, in which case it should be chosen so that
rang * max(|x|) is about 1. If <code>NULL</code>, a reasonable default is computed.</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_decay">decay</code></td>
<td>
<p>parameter for weight decay. Default to 0.</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations. Default 1000 (it is 100 in
<code><a href="nnet.html#topic+nnet">nnet::nnet()</a></code>).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_nnet">ml_nnet()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_response">response</code></td>
<td>
<p>a vector of factor (classification) or numeric (regression).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_object">object</code></td>
<td>
<p>an <strong>mlNnet</strong> object</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (number
between 0 and 1) to the different classes, or <code>"both"</code> to return classes
and memberships. Also type <code>"raw"</code> as non normalized result as returned by
<code><a href="nnet.html#topic+nnet">nnet::nnet()</a></code> (useful for regression, see examples).</p>
</td></tr>
<tr><td><code id="mlNnet_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases
in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training
set if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different data set in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_nnet">ml_nnet()</a></code>/<code><a href="#topic+mlNnet">mlNnet()</a></code> creates an <strong>mlNnet</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="nnet.html#topic+nnet">nnet::nnet()</a></code>
that actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

set.seed(689) # Useful for reproductibility, use a different value each time!
iris_nnet &lt;- ml_nnet(data = iris_train, Species ~ .)
summary(iris_nnet)
predict(iris_nnet) # Default type is class
predict(iris_nnet, type = "membership")
predict(iris_nnet, type = "both")
# Self-consistency, do not use for assessing classifier performances!
confusion(iris_nnet)
# Use an independent test set instead
confusion(predict(iris_nnet, newdata = iris_test), iris_test$Species)

# Idem, but two classes prediction
data("HouseVotes84", package = "mlbench")
set.seed(325)
house_nnet &lt;- ml_nnet(data = HouseVotes84, Class ~ ., na.action = na.omit)
summary(house_nnet)
# Cross-validated confusion matrix
confusion(cvpredict(house_nnet), na.omit(HouseVotes84)$Class)

# Regression
data(airquality, package = "datasets")
set.seed(74)
ozone_nnet &lt;- ml_nnet(data = airquality, Ozone ~ ., na.action = na.omit,
  skip = TRUE, decay = 1e-3, size = 20, linout = TRUE)
summary(ozone_nnet)
plot(na.omit(airquality)$Ozone, predict(ozone_nnet, type = "raw"))
abline(a = 0, b = 1)
</code></pre>

<hr>
<h2 id='mlQda'>Supervised classification using quadratic discriminant analysis</h2><span id='topic+mlQda'></span><span id='topic+ml_qda'></span><span id='topic+mlQda.formula'></span><span id='topic+mlQda.default'></span><span id='topic+predict.mlQda'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the quadratic discriminant
analysis algorithm provided by <code><a href="MASS.html#topic+qda">MASS::qda()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlQda(train, ...)

ml_qda(train, ...)

## S3 method for class 'formula'
mlQda(formula, data, ..., subset, na.action)

## Default S3 method:
mlQda(train, response, ...)

## S3 method for class 'mlQda'
predict(
  object,
  newdata,
  type = c("class", "membership", "both"),
  prior = object$prior,
  method = c("plug-in", "predictive", "debiased", "looCV", "cv"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlQda_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlQda_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="MASS.html#topic+qda">MASS::qda()</a></code> or its  <code><a href="stats.html#topic+predict">predict()</a></code>
method (see the corresponding help page).</p>
</td></tr>
<tr><td><code id="mlQda_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
and the right term with the list of independent, predictive variables,
separated with a plus sign. If the data frame provided contains only the
dependent and independent variables, one can use the <code>class ~ .</code> short
version (that one is strongly encouraged). Variables with minus sign are
eliminated. Calculations on variables are possible according to usual
formula convention (possibly protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlQda_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlQda_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlQda_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_qda">ml_qda()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlQda_+3A_response">response</code></td>
<td>
<p>a vector of factor for the classification.</p>
</td></tr>
<tr><td><code id="mlQda_+3A_object">object</code></td>
<td>
<p>an <strong>mlQda</strong> object</p>
</td></tr>
<tr><td><code id="mlQda_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlQda_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (a
number between 0 and 1) to the different classes, or <code>"both"</code> to return
classes and memberships.</p>
</td></tr>
<tr><td><code id="mlQda_+3A_prior">prior</code></td>
<td>
<p>the prior probabilities of class membership. By default, the
prior are obtained from the object and, if they where not changed,
correspond to the proportions observed in the training set.</p>
</td></tr>
<tr><td><code id="mlQda_+3A_method">method</code></td>
<td>
<p><code>"plug-in"</code>, <code>"predictive"</code>, <code>"debiased"</code>, <code>"looCV"</code>, or
<code>"cv"</code>. <code>"plug-in"</code> (default) the usual unbiased parameter estimates are
used. With <code>"predictive"</code>, the parameters are integrated out using a vague
prior. With <code>"debiased"</code>, an unbiased estimator of the log posterior
probabilities is used. With <code>"looCV"</code>, the leave-one-out cross-validation
fits to the original data set are computed and returned. With <code>"cv"</code>,
cross-validation is used instead. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_qda">ml_qda()</a></code>/<code><a href="#topic+mlQda">mlQda()</a></code> creates an <strong>mlQda</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="MASS.html#topic+qda">MASS::qda()</a></code> that
actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_qda &lt;- ml_qda(data = iris_train, Species ~ .)
summary(iris_qda)
confusion(iris_qda)
confusion(predict(iris_qda, newdata = iris_test), iris_test$Species)

# Another dataset (binary predictor... not optimal for qda, just for test)
data("HouseVotes84", package = "mlbench")
house_qda &lt;- ml_qda(data = HouseVotes84, Class ~ ., na.action = na.omit)
summary(house_qda)
</code></pre>

<hr>
<h2 id='mlRforest'>Supervised classification and regression using random forest</h2><span id='topic+mlRforest'></span><span id='topic+ml_rforest'></span><span id='topic+mlRforest.formula'></span><span id='topic+mlRforest.default'></span><span id='topic+predict.mlRforest'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the random forest algorithm
provided by <code><a href="randomForest.html#topic+randomForest">randomForest::randomForest()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlRforest(train, ...)

ml_rforest(train, ...)

## S3 method for class 'formula'
mlRforest(
  formula,
  data,
  ntree = 500,
  mtry,
  replace = TRUE,
  classwt = NULL,
  ...,
  subset,
  na.action
)

## Default S3 method:
mlRforest(
  train,
  response,
  ntree = 500,
  mtry,
  replace = TRUE,
  classwt = NULL,
  ...
)

## S3 method for class 'mlRforest'
predict(
  object,
  newdata,
  type = c("class", "membership", "both", "vote"),
  method = c("direct", "oob", "cv"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlRforest_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="randomForest.html#topic+randomForest">randomForest::randomForest()</a></code> or its
<code><a href="stats.html#topic+predict">predict()</a></code> method. There are many more arguments, see the corresponding
help page.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
(for supervised classification), a vector of numbers (for regression) or
nothing (for unsupervised classification) and the right term with the list
of independent, predictive variables, separated with a plus sign. If the
data frame provided contains only the dependent and independent variables,
one can use the <code>class ~ .</code> short version (that one is strongly encouraged).
Variables with minus sign are eliminated. Calculations on variables are
possible according to usual formula convention (possibly protected by using
<code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_ntree">ntree</code></td>
<td>
<p>the number of trees to generate (use a value large enough to get
at least a few predictions for each input row). Default is 500 trees.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_mtry">mtry</code></td>
<td>
<p>number of variables randomly sampled as candidates at each split.
Note that the default values are different for classification (sqrt(p)
where p is number of variables in x) and regression (p/3)?</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_replace">replace</code></td>
<td>
<p>sample cases with or without replacement (<code>TRUE</code> by default)?</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_classwt">classwt</code></td>
<td>
<p>priors of the classes. Need not add up to one. Ignored for
regression.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_rforest">ml_rforest()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_response">response</code></td>
<td>
<p>a vector of factor (classification) or numeric (regression),
or <code>NULL</code> (unsupervised classification).</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_object">object</code></td>
<td>
<p>an <strong>mlRforest</strong> object</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (number
between 0 and 1) to the different classes as assessed by the number of
neighbors of these classes, or <code>"both"</code> to return classes and memberships.
One can also use <code>"vote"</code>, which returns the number of trees that voted
for each class.</p>
</td></tr>
<tr><td><code id="mlRforest_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default), <code>"oob"</code> or <code>"cv"</code>. <code>"direct"</code> predicts
new cases in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the
training set if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you
just calculate the <strong>self-consistency</strong> of the classifier but cannot use
the metrics derived from these results for the assessment of its
performances (in the case of Random Forest, these metrics would most
certainly falsely indicate a perfect classifier). Either use a different
data set in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate approaches: out-of-bag
(<code>"oob"</code>) or cross-validation (&quot;cv&quot;). The out-of-bag approach uses
individuals that are not used to build the trees to assess performances. It
is an unbiased estimates. If you specify <code>method = "cv"</code> then <code><a href="#topic+cvpredict">cvpredict()</a></code>
is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_rforest">ml_rforest()</a></code>/<code><a href="#topic+mlRforest">mlRforest()</a></code> creates an <strong>mlRforest</strong>, <strong>mlearning</strong>
object containing the classifier and a lot of additional metadata used by
the functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also
<code><a href="randomForest.html#topic+randomForest">randomForest::randomForest()</a></code> that actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_rf &lt;- ml_rforest(data = iris_train, Species ~ .)
summary(iris_rf)
plot(iris_rf) # Useful to look at the effect of ntree=
# For such a relatively simple case, 50 trees are enough
iris_rf &lt;- ml_rforest(data = iris_train, Species ~ ., ntree = 50)
summary(iris_rf)
predict(iris_rf) # Default type is class
predict(iris_rf, type = "membership")
predict(iris_rf, type = "both")
predict(iris_rf, type = "vote")
# Out-of-bag prediction (unbiased)
predict(iris_rf, method = "oob")
# Self-consistency (always very high for random forest, biased, do not use!)
confusion(iris_rf)
# This one is better
confusion(iris_rf, method = "oob") # Out-of-bag performances
# Cross-validation prediction is also a good choice when there is no test set
predict(iris_rf, method = "cv")  # Idem: cvpredict(res)
# Cross-validation for performances estimation
confusion(iris_rf, method = "cv")
# Evaluation of performances using a separate test set
confusion(predict(iris_rf, newdata = iris_test), iris_test$Species)

# Regression using random forest (from ?randomForest)
set.seed(131) # Useful for reproducibility (use a different number each time)
ozone_rf &lt;- ml_rforest(data = airquality, Ozone ~ ., mtry = 3,
  importance = TRUE, na.action = na.omit)
summary(ozone_rf)
# Show "importance" of variables: higher value mean more important variables
round(randomForest::importance(ozone_rf), 2)
plot(na.omit(airquality)$Ozone, predict(ozone_rf))
abline(a = 0, b = 1)

# Unsupervised classification using random forest (from ?randomForest)
set.seed(17)
iris_urf &lt;- ml_rforest(train = iris[, -5]) # Use only quantitative data
summary(iris_urf)
randomForest::MDSplot(iris_urf, iris$Species)
plot(stats::hclust(stats::as.dist(1 - iris_urf$proximity),
  method = "average"), labels = iris$Species)
</code></pre>

<hr>
<h2 id='mlRpart'>Supervised classification and regression using recursive partitioning</h2><span id='topic+mlRpart'></span><span id='topic+ml_rpart'></span><span id='topic+mlRpart.formula'></span><span id='topic+mlRpart.default'></span><span id='topic+predict.mlRpart'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the recursive partitioning
algorithm as implemented in <code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlRpart(train, ...)

ml_rpart(train, ...)

## S3 method for class 'formula'
mlRpart(formula, data, ..., subset, na.action)

## Default S3 method:
mlRpart(train, response, ..., .args. = NULL)

## S3 method for class 'mlRpart'
predict(
  object,
  newdata,
  type = c("class", "membership", "both"),
  method = c("direct", "cv"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlRpart_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code> or its <code><a href="stats.html#topic+predict">predict()</a></code>
method (see the corresponding help page.</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
(for supervised classification), a vector of numbers (for regression) and the
right term with the list of independent, predictive variables, separated with
a plus sign. If the data frame provided contains only the dependent and
independent variables, one can use the <code>class ~ .</code> short version (that one is
strongly encouraged). Variables with minus sign are eliminated. Calculations
on variables are possible according to usual formula convention (possibly
protected by using <code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_rpart">ml_rpart()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_response">response</code></td>
<td>
<p>a vector of factor (classification) or numeric (regression).</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_.args.">.args.</code></td>
<td>
<p>used internally, do not provide anything here.</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_object">object</code></td>
<td>
<p>an <strong>mlRpart</strong> object</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_type">type</code></td>
<td>
<p>the type of prediction to return. <code>"class"</code> by default, the
predicted classes. Other options are <code>"membership"</code> the membership (number
between 0 and 1) to the different classes, or <code>"both"</code> to return classes
and memberships,</p>
</td></tr>
<tr><td><code id="mlRpart_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases in
<code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training set
if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different data set in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_rpart">ml_rpart()</a></code>/<code><a href="#topic+mlRpart">mlRpart()</a></code> creates an <strong>mlRpart</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="rpart.html#topic+rpart">rpart::rpart()</a></code>
that actually does the classification.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_rpart &lt;- ml_rpart(data = iris_train, Species ~ .)
summary(iris_rpart)
# Plot the decision tree for this classifier
plot(iris_rpart, margin = 0.03, uniform = TRUE)
text(iris_rpart, use.n = FALSE)
# Predictions
predict(iris_rpart) # Default type is class
predict(iris_rpart, type = "membership")
predict(iris_rpart, type = "both")
# Self-consistency, do not use for assessing classifier performances!
confusion(iris_rpart)
# Cross-validation prediction is a good choice when there is no test set
predict(iris_rpart, method = "cv")  # Idem: cvpredict(res)
confusion(iris_rpart, method = "cv")
# Evaluation of performances using a separate test set
confusion(predict(iris_rpart, newdata = iris_test), iris_test$Species)
</code></pre>

<hr>
<h2 id='mlSvm'>Supervised classification and regression using support vector machine</h2><span id='topic+mlSvm'></span><span id='topic+ml_svm'></span><span id='topic+mlSvm.formula'></span><span id='topic+mlSvm.default'></span><span id='topic+predict.mlSvm'></span>

<h3>Description</h3>

<p>Unified (formula-based) interface version of the support vector machine
algorithm provided by <code><a href="e1071.html#topic+svm">e1071::svm()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlSvm(train, ...)

ml_svm(train, ...)

## S3 method for class 'formula'
mlSvm(
  formula,
  data,
  scale = TRUE,
  type = NULL,
  kernel = "radial",
  classwt = NULL,
  ...,
  subset,
  na.action
)

## Default S3 method:
mlSvm(
  train,
  response,
  scale = TRUE,
  type = NULL,
  kernel = "radial",
  classwt = NULL,
  ...
)

## S3 method for class 'mlSvm'
predict(
  object,
  newdata,
  type = c("class", "membership", "both"),
  method = c("direct", "cv"),
  na.action = na.exclude,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlSvm_+3A_train">train</code></td>
<td>
<p>a matrix or data frame with predictors.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_...">...</code></td>
<td>
<p>further arguments passed to the classification or regression
method. See <code><a href="e1071.html#topic+svm">e1071::svm()</a></code>.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_formula">formula</code></td>
<td>
<p>a formula with left term being the factor variable to predict
(for supervised classification), a vector of numbers (for regression) or
nothing (for unsupervised classification) and the right term with the list
of independent, predictive variables, separated with a plus sign. If the
data frame provided contains only the dependent and independent variables,
one can use the <code>class ~ .</code> short version (that one is strongly encouraged).
Variables with minus sign are eliminated. Calculations on variables are
possible according to usual formula convention (possibly protected by using
<code>I()</code>).</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_data">data</code></td>
<td>
<p>a data.frame to use as a training set.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_scale">scale</code></td>
<td>
<p>are the variables scaled (so that mean = 0 and standard
deviation = 1)? <code>TRUE</code> by default. If a vector is provided, it is applied
to variables with recycling.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_type">type</code></td>
<td>
<p>For <code><a href="#topic+ml_svm">ml_svm()</a></code>/<code><a href="#topic+mlSvm">mlSvm()</a></code>, the type of classification or
regression machine to use. The default value of <code>NULL</code> uses
<code>"C-classification"</code> if response variable is factor and  <code>eps-regression</code>
if it is numeric. It can also be <code>"nu-classification"</code> or
<code>"nu-regression"</code>. The &quot;C&quot; and &quot;nu&quot; versions are basically the same but
with a different parameterisation. The range of C is from zero to infinity,
while the range for nu is from zero to one. A fifth option is
<code>"one_classification"</code> that is specific to novelty detection (find the
items that are different from the rest).
For <code><a href="stats.html#topic+predict">predict()</a></code>, the type of prediction to return. <code>"class"</code> by default,
the predicted classes. Other options are <code>"membership"</code> the membership
(number between 0 and 1) to the different classes, or  <code>"both"</code> to return
classes and memberships.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_kernel">kernel</code></td>
<td>
<p>the kernel used by svm, see <code><a href="e1071.html#topic+svm">e1071::svm()</a></code> for further
explanations. Can be <code>"radial"</code>, <code>"linear"</code>, <code>"polynomial"</code> or <code>"sigmoid"</code>.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_classwt">classwt</code></td>
<td>
<p>priors of the classes. Need not add up to one.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_subset">subset</code></td>
<td>
<p>index vector with the cases to define the training set in use
(this argument must be named, if provided).</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_na.action">na.action</code></td>
<td>
<p>function to specify the action to be taken if <code>NA</code>s are
found. For <code><a href="#topic+ml_svm">ml_svm()</a></code> <code>na.fail</code> is used by default. The calculation is
stopped if there is any <code>NA</code> in the data. Another option is <code>na.omit</code>,
where cases with missing values on any required variable are dropped (this
argument must be named, if provided). For the <code>predict()</code> method, the
default, and most suitable option, is <code>na.exclude</code>. In that case, rows with
<code>NA</code>s in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> are excluded from prediction, but reinjected in the
final results so that the number of items is still the same (and in the
same order as <code style="white-space: pre;">&#8288;newdata=&#8288;</code>).</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_response">response</code></td>
<td>
<p>a vector of factor (classification) or numeric (regression).</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_object">object</code></td>
<td>
<p>an <strong>mlSvm</strong> object</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_newdata">newdata</code></td>
<td>
<p>a new dataset with same conformation as the training set (same
variables, except may by the class for classification or dependent variable
for regression). Usually a test set, or a new dataset to be predicted.</p>
</td></tr>
<tr><td><code id="mlSvm_+3A_method">method</code></td>
<td>
<p><code>"direct"</code> (default) or <code>"cv"</code>. <code>"direct"</code> predicts new cases in
<code style="white-space: pre;">&#8288;newdata=&#8288;</code> if this argument is provided, or the cases in the training set
if not. Take care that not providing <code style="white-space: pre;">&#8288;newdata=&#8288;</code> means that you just
calculate the <strong>self-consistency</strong> of the classifier but cannot use the
metrics derived from these results for the assessment of its performances.
Either use a different data set in <code style="white-space: pre;">&#8288;newdata=&#8288;</code> or use the alternate
cross-validation (&quot;cv&quot;) technique. If you specify <code>method = "cv"</code> then
<code><a href="#topic+cvpredict">cvpredict()</a></code> is used and you cannot provide <code style="white-space: pre;">&#8288;newdata=&#8288;</code> in that case.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+ml_svm">ml_svm()</a></code>/<code><a href="#topic+mlSvm">mlSvm()</a></code> creates an <strong>mlSvm</strong>, <strong>mlearning</strong> object
containing the classifier and a lot of additional metadata used by the
functions and methods you can apply to it like <code><a href="stats.html#topic+predict">predict()</a></code> or
<code><a href="#topic+cvpredict">cvpredict()</a></code>. In case you want to program new functions or extract
specific components, inspect the &quot;unclassed&quot; object using <code><a href="base.html#topic+unclass">unclass()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+cvpredict">cvpredict()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>, also <code><a href="e1071.html#topic+svm">e1071::svm()</a></code>
that actually does the calculation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Prepare data: split into training set (2/3) and test set (1/3)
data("iris", package = "datasets")
train &lt;- c(1:34, 51:83, 101:133)
iris_train &lt;- iris[train, ]
iris_test &lt;- iris[-train, ]
# One case with missing data in train set, and another case in test set
iris_train[1, 1] &lt;- NA
iris_test[25, 2] &lt;- NA

iris_svm &lt;- ml_svm(data = iris_train, Species ~ .)
summary(iris_svm)
predict(iris_svm) # Default type is class
predict(iris_svm, type = "membership")
predict(iris_svm, type = "both")
# Self-consistency, do not use for assessing classifier performances!
confusion(iris_svm)
# Use an independent test set instead
confusion(predict(iris_svm, newdata = iris_test), iris_test$Species)

# Another dataset
data("HouseVotes84", package = "mlbench")
house_svm &lt;- ml_svm(data = HouseVotes84, Class ~ ., na.action = na.omit)
summary(house_svm)
# Cross-validated confusion matrix
confusion(cvpredict(house_svm), na.omit(HouseVotes84)$Class)

# Regression using support vector machine
data(airquality, package = "datasets")
ozone_svm &lt;- ml_svm(data = airquality, Ozone ~ ., na.action = na.omit)
summary(ozone_svm)
plot(na.omit(airquality)$Ozone, predict(ozone_svm))
abline(a = 0, b = 1)
</code></pre>

<hr>
<h2 id='plot.confusion'>Plot a confusion matrix</h2><span id='topic+plot.confusion'></span><span id='topic+confusion_image'></span><span id='topic+confusionImage'></span><span id='topic+confusion_barplot'></span><span id='topic+confusionBarplot'></span><span id='topic+confusion_stars'></span><span id='topic+confusionStars'></span><span id='topic+confusion_dendrogram'></span><span id='topic+confusionDendrogram'></span>

<h3>Description</h3>

<p>Several graphical representations of <strong>confusion</strong> objects are possible: an
image of the matrix with colored squares, a barplot comparing recall and
precision, a stars plot also comparing two metrics, possibly also comparing
two different classifiers of the same dataset, or a dendrogram grouping the
classes relative to the errors observed in the confusion matrix (classes
with more errors are pooled together more rapidly).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'confusion'
plot(
  x,
  y = NULL,
  type = c("image", "barplot", "stars", "dendrogram"),
  stat1 = "Recall",
  stat2 = "Precision",
  names,
  ...
)

confusion_image(
  x,
  y = NULL,
  labels = names(dimnames(x)),
  sort = "ward.D2",
  numbers = TRUE,
  digits = 0,
  mar = c(3.1, 10.1, 3.1, 3.1),
  cex = 1,
  asp = 1,
  colfun,
  ncols = 41,
  col0 = FALSE,
  grid.col = "gray",
  ...
)

confusionImage(
  x,
  y = NULL,
  labels = names(dimnames(x)),
  sort = "ward.D2",
  numbers = TRUE,
  digits = 0,
  mar = c(3.1, 10.1, 3.1, 3.1),
  cex = 1,
  asp = 1,
  colfun,
  ncols = 41,
  col0 = FALSE,
  grid.col = "gray",
  ...
)

confusion_barplot(
  x,
  y = NULL,
  col = c("PeachPuff2", "green3", "lemonChiffon2"),
  mar = c(1.1, 8.1, 4.1, 2.1),
  cex = 1,
  cex.axis = cex,
  cex.legend = cex,
  main = "F-score (precision versus recall)",
  numbers = TRUE,
  min.width = 17,
  ...
)

confusionBarplot(
  x,
  y = NULL,
  col = c("PeachPuff2", "green3", "lemonChiffon2"),
  mar = c(1.1, 8.1, 4.1, 2.1),
  cex = 1,
  cex.axis = cex,
  cex.legend = cex,
  main = "F-score (precision versus recall)",
  numbers = TRUE,
  min.width = 17,
  ...
)

confusion_stars(
  x,
  y = NULL,
  stat1 = "Recall",
  stat2 = "Precision",
  names,
  main,
  col = c("green2", "blue2", "green4", "blue4"),
  ...
)

confusionStars(
  x,
  y = NULL,
  stat1 = "Recall",
  stat2 = "Precision",
  names,
  main,
  col = c("green2", "blue2", "green4", "blue4"),
  ...
)

confusion_dendrogram(
  x,
  y = NULL,
  labels = rownames(x),
  sort = "ward.D2",
  main = "Groups clustering",
  ...
)

confusionDendrogram(
  x,
  y = NULL,
  labels = rownames(x),
  sort = "ward.D2",
  main = "Groups clustering",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.confusion_+3A_x">x</code></td>
<td>
<p>a <strong>confusion</strong> object</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_y">y</code></td>
<td>
<p><code>NULL</code> (not used), or a second <strong>confusion</strong> object when two
different classifications are compared in the plot (<code>"stars"</code> type).</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_type">type</code></td>
<td>
<p>the kind of plot to produce (<code>"image"</code>, the default, or
<code>"barplot"</code>, <code>"stars"</code>, <code>"dendrogram"</code>).</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_stat1">stat1</code></td>
<td>
<p>the first metric to plot for the <code>"stars"</code> type (Recall by
default).</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_stat2">stat2</code></td>
<td>
<p>the second metric to plot for the <code>"stars"</code> type (Precision by
default).</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_names">names</code></td>
<td>
<p>names of the two classifiers to compare</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_...">...</code></td>
<td>
<p>further arguments passed to the function. It can be all arguments
or the corresponding plot.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_labels">labels</code></td>
<td>
<p>labels to use for the two classifications. By default, they are
the same as <code>vars</code>, or the one in the confusion matrix.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_sort">sort</code></td>
<td>
<p>are rows and columns of the confusion matrix sorted so that
classes with larger confusion are closer together? Sorting is done
using a hierarchical clustering with <code><a href="stats.html#topic+hclust">hclust()</a></code>. The clustering method
is <code>"ward.D2"</code> by default, but see the <code><a href="stats.html#topic+hclust">hclust()</a></code> help for other options).
If <code>FALSE</code> or <code>NULL</code>, no sorting is done.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_numbers">numbers</code></td>
<td>
<p>are actual numbers indicated in the confusion matrix image?</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_digits">digits</code></td>
<td>
<p>the number of digits after the decimal point to print in the
confusion matrix. The default or zero leads to most compact presentation
and is suitable for frequencies, but not for relative frequencies.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_mar">mar</code></td>
<td>
<p>graph margins.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_cex">cex</code></td>
<td>
<p>text magnification factor.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_asp">asp</code></td>
<td>
<p>graph aspect ratio. There is little reasons to change the default
value of 1.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_colfun">colfun</code></td>
<td>
<p>a function that calculates a series of colors, like e.g.,
<code><a href="grDevices.html#topic+cm.colors">cm.colors()</a></code> that accepts one argument being the number of colors
to be generated.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_ncols">ncols</code></td>
<td>
<p>the number of colors to generate. It should preferably be
2 * number of levels + 1, where levels is the number of frequencies you
want to evidence in the plot. Default to 41.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_col0">col0</code></td>
<td>
<p>should null values be colored or not (no, by default)?</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_grid.col">grid.col</code></td>
<td>
<p>color to use for grid lines, or <code>NULL</code> for not drawing grid
lines.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_col">col</code></td>
<td>
<p>color(s) to use for the plot.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_cex.axis">cex.axis</code></td>
<td>
<p>idem for axes. If <code>NULL</code>, the axis is not drawn.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_cex.legend">cex.legend</code></td>
<td>
<p>idem for legend text. If <code>NULL</code>, no legend is added.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_main">main</code></td>
<td>
<p>main title of the plot.</p>
</td></tr>
<tr><td><code id="plot.confusion_+3A_min.width">min.width</code></td>
<td>
<p>minimum bar width required to add numbers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data calculate to create the plots are returned invisibly. These
functions are mostly used for their side-effect of producing a plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Glass", package = "mlbench")
# Use a little bit more informative labels for Type
Glass$Type &lt;- as.factor(paste("Glass", Glass$Type))

# Use learning vector quantization to classify the glass types
# (using default parameters)
summary(glass_lvq &lt;- ml_lvq(Type ~ ., data = Glass))

# Calculate cross-validated confusion matrix and plot it in different ways
(glass_conf &lt;- confusion(cvpredict(glass_lvq), Glass$Type))
# Raw confusion matrix: no sort and no margins
print(glass_conf, sums = FALSE, sort = FALSE)
# Plots
plot(glass_conf) # Image by default
plot(glass_conf, sort = FALSE) # No sorting
plot(glass_conf, type = "barplot")
plot(glass_conf, type = "stars")
plot(glass_conf, type = "dendrogram")

# Build another classifier and make a comparison
summary(glass_naive_bayes &lt;- ml_naive_bayes(Type ~ ., data = Glass))
(glass_conf2 &lt;- confusion(cvpredict(glass_naive_bayes), Glass$Type))

# Comparison plot for two classifiers
plot(glass_conf, glass_conf2)
</code></pre>

<hr>
<h2 id='prior'>Get or set priors on a confusion matrix</h2><span id='topic+prior'></span><span id='topic+prior.confusion'></span><span id='topic+prior+3C-'></span><span id='topic+prior+3C-.confusion'></span>

<h3>Description</h3>

<p>Most metrics in supervised classifications are sensitive to the relative
proportion of the items in the different classes. When a confusion matrix is
calculated on a test set, it uses the proportions observed on that test set.
If they are representative of the proportions in the population, metrics are
not biased. When it is not the case, priors of a <strong>confusion</strong> object can be
adjusted to better reflect proportions that are supposed to be observed in
the different classes in order to get more accurate metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prior(object, ...)

## S3 method for class 'confusion'
prior(object, ...)

prior(object, ...) &lt;- value

## S3 replacement method for class 'confusion'
prior(object, ...) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="prior_+3A_object">object</code></td>
<td>
<p>a <strong>confusion</strong> object (or another class if a method is
implemented)</p>
</td></tr>
<tr><td><code id="prior_+3A_...">...</code></td>
<td>
<p>further arguments passed to methods</p>
</td></tr>
<tr><td><code id="prior_+3A_value">value</code></td>
<td>
<p>a (named) vector of positive numbers of zeros of
the same length as the number of classes in the <strong>confusion</strong> object. It
can also be a single &gt;= 0 number and in this case, equal probabilities are
applied to all the classes (use 1 for relative frequencies and 100 for
relative frequencies in percent). If the value has zero length or is
<code>NULL</code>, original prior probabilities (from the test set) are used. If the
vector is named, names must correspond to existing class names in the
<strong>confusion</strong> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+prior">prior()</a></code> returns the current class frequencies associated with
the first classification tabulated in the <strong>confusion</strong> object, i.e., for
rows in the confusion matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Glass", package = "mlbench")
# Use a little bit more informative labels for Type
Glass$Type &lt;- as.factor(paste("Glass", Glass$Type))
# Use learning vector quantization to classify the glass types
# (using default parameters)
summary(glass_lvq &lt;- ml_lvq(Type ~ ., data = Glass))

# Calculate cross-validated confusion matrix
(glass_conf &lt;- confusion(cvpredict(glass_lvq), Glass$Type))

# When the probabilities in each class do not match the proportions in the
# training set, all these calculations are useless. Having an idea of
# the real proportions (so-called, priors), one should first reweight the
# confusion matrix before calculating statistics, for instance:
prior1 &lt;- c(10, 10, 10, 100, 100, 100) # Glass types 1-3 are rare
prior(glass_conf) &lt;- prior1
glass_conf
summary(glass_conf, type = c("Fscore", "Recall", "Precision"))

# This is very different than if glass types 1-3 are abundants!
prior2 &lt;- c(100, 100, 100, 10, 10, 10) # Glass types 1-3 are abundants
prior(glass_conf) &lt;- prior2
glass_conf
summary(glass_conf, type = c("Fscore", "Recall", "Precision"))

# Weight can also be used to construct a matrix of relative frequencies
# In this case, all rows sum to one
prior(glass_conf) &lt;- 1
print(glass_conf, digits = 2)
# However, it is easier to work with relative frequencies in percent
# and one gets a more compact presentation
prior(glass_conf) &lt;- 100
glass_conf

# To reset row class frequencies to original propotions, just assign NULL
prior(glass_conf) &lt;- NULL
glass_conf
prior(glass_conf)
</code></pre>

<hr>
<h2 id='response'>Get the response variable for a mlearning object</h2><span id='topic+response'></span><span id='topic+response.default'></span>

<h3>Description</h3>

<p>The response is either the class to be predicted for a classification problem
(and it is a factor), or the dependent variable in a regression model (and
it is numeric in that case). For unsupervised classification, response is not
provided and should return <code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>response(object, ...)

## Default S3 method:
response(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="response_+3A_object">object</code></td>
<td>
<p>an object having a response variable.</p>
</td></tr>
<tr><td><code id="response_+3A_...">...</code></td>
<td>
<p>further parameter (depends on the method).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The response variable of the training set, or <code>NULL</code> for unsupervised
classification.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+train">train()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("HouseVotes84", package = "mlbench")
house_rf &lt;- ml_rforest(data = HouseVotes84, Class ~ .)
house_rf
response(house_rf)
</code></pre>

<hr>
<h2 id='train'>Get the training variable for a mlearning object</h2><span id='topic+train'></span><span id='topic+train.default'></span>

<h3>Description</h3>

<p>The training variables (train) are the variables used to train a classifier,
excepted the prediction (class or dependent variable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>train(object, ...)

## Default S3 method:
train(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="train_+3A_object">object</code></td>
<td>
<p>an object having a train attribute.</p>
</td></tr>
<tr><td><code id="train_+3A_...">...</code></td>
<td>
<p>further parameter (depends on the method).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing the training variables of the model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlearning">mlearning()</a></code>, <code><a href="#topic+response">response()</a></code>, <code><a href="#topic+confusion">confusion()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("HouseVotes84", package = "mlbench")
house_rf &lt;- ml_rforest(data = HouseVotes84, Class ~ .)
house_rf
train(house_rf)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
