<!DOCTYPE html><html><head><title>Help for package strucchangeRcpp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {strucchangeRcpp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BostonHomicide'><p>Youth Homicides in Boston</p></a></li>
<li><a href='#boundary'><p>Boundary Function for Structural Change Tests</p></a></li>
<li><a href='#boundary.efp'><p>Boundary for Empirical Fluctuation Processes</p></a></li>
<li><a href='#boundary.Fstats'><p>Boundary for F Statistics</p></a></li>
<li><a href='#boundary.mefp'><p>Boundary Function for Monitoring of Structural Changes</p></a></li>
<li><a href='#breakdates'><p>Breakdates Corresponding to Breakpoints</p></a></li>
<li><a href='#breakfactor'><p>Factor Coding of Segmentations</p></a></li>
<li><a href='#breakpoints'><p>Dating Breaks</p></a></li>
<li><a href='#catL2BB'><p>Generators for efpFunctionals along Categorical Variables</p></a></li>
<li><a href='#confint.breakpointsfull'><p>Confidence Intervals for Breakpoints</p></a></li>
<li><a href='#DJIA'><p>Dow Jones Industrial Average</p></a></li>
<li><a href='#durab'><p>US Labor Productivity</p></a></li>
<li><a href='#efp'><p>Empirical Fluctuation Processes</p></a></li>
<li><a href='#efpFunctional'><p>Functionals for Fluctuation Processes</p></a></li>
<li><a href='#Fstats'><p>F Statistics</p></a></li>
<li><a href='#gefp'><p>Generalized Empirical M-Fluctuation Processes</p></a></li>
<li><a href='#GermanM1'><p>German M1 Money Demand</p></a></li>
<li><a href='#Grossarl'><p>Marriages, Births and Deaths in Grossarl</p></a></li>
<li><a href='#logLik.breakpoints'><p>Log Likelihood and Information Criteria for Breakpoints</p></a></li>
<li><a href='#magnitude'><p>Magnitudes of Breakpoints</p></a></li>
<li><a href='#mefp'><p>Monitoring of Empirical Fluctuation Processes</p></a></li>
<li><a href='#PhillipsCurve'><p>UK Phillips Curve Equation Data</p></a></li>
<li><a href='#plot.efp'><p>Plot Empirical Fluctuation Process</p></a></li>
<li><a href='#plot.Fstats'><p>Plot F Statistics</p></a></li>
<li><a href='#plot.mefp'><p>Plot Methods for mefp Objects</p></a></li>
<li><a href='#RealInt'><p>US Ex-post Real Interest Rate</p></a></li>
<li><a href='#recresid'><p>Recursive Residuals</p></a></li>
<li><a href='#root.matrix'><p>Root of a Matrix</p></a></li>
<li><a href='#root.matrix.crossprod'><p>Root of X^TX</p></a></li>
<li><a href='#scPublications'><p>Structural Change Publications</p></a></li>
<li><a href='#sctest'><p>Structural Change Tests</p></a></li>
<li><a href='#sctest.default'><p>Structural Change Tests in Parametric Models</p></a></li>
<li><a href='#sctest.efp'><p>Generalized Fluctuation Tests</p></a></li>
<li><a href='#sctest.formula'><p>Structural Change Tests in Linear Regression Models</p></a></li>
<li><a href='#sctest.Fstats'><p>supF-, aveF- and expF-Test</p></a></li>
<li><a href='#solveCrossprod'><p>Inversion of X'X</p></a></li>
<li><a href='#SP2001'><p>S\&amp;P 500 Stock Prices</p></a></li>
<li><a href='#strucchange.internal'><p>Internal strucchange objects</p></a></li>
<li><a href='#supLM'><p>Generators for efpFunctionals along Continuous Variables</p></a></li>
<li><a href='#USIncExp'><p>Income and Expenditures in the US</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.5-3-1.0.4</td>
</tr>
<tr>
<td>Title:</td>
<td>Testing, Monitoring, and Dating Structural Changes: C++ Version</td>
</tr>
<tr>
<td>Description:</td>
<td>A fast implementation with additional experimental features for
             testing, monitoring and dating structural changes in (linear)
             regression models. 'strucchangeRcpp' features tests/methods from
	     the generalized fluctuation test framework as well as from
	     the F test (Chow test) framework. This includes methods to
             fit, plot and test fluctuation processes (e.g. cumulative/moving
             sum, recursive/moving estimates) and F statistics, respectively.
             These methods are described in Zeileis et al. (2002)
             &lt;<a href="https://doi.org/10.18637%2Fjss.v007.i02">doi:10.18637/jss.v007.i02</a>&gt;.
             Finally, the breakpoints in regression models with structural
             changes can be estimated together with confidence intervals,
             and their magnitude as well as the model fit can be evaluated
             using a variety of statistical measures.</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10.0), zoo, sandwich</td>
</tr>
<tr>
<td>Suggests:</td>
<td>stats4, car, dynlm, e1071, foreach, lmtest, mvtnorm, tseries,
bfast</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, stats, Rcpp (&ge; 0.12.7), utils</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bfast2/strucchangeRcpp/">https://github.com/bfast2/strucchangeRcpp/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bfast2/strucchangeRcpp/issues">https://github.com/bfast2/strucchangeRcpp/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-11-25 15:45:25 UTC; dainius</td>
</tr>
<tr>
<td>Author:</td>
<td>Dainius Masiliunas
    <a href="https://orcid.org/0000-0001-5654-1277"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Achim Zeileis <a href="https://orcid.org/0000-0003-0918-3766"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Marius Appel [aut],
  Friedrich Leisch [aut],
  Kurt Hornik [aut],
  Christian Kleiber [aut],
  Andrei Mirt <a href="https://orcid.org/0000-0003-3654-2090"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Bruce Hansen [ctb],
  Edgar C. Merkle [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dainius Masiliunas &lt;pastas4@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-11-26 16:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BostonHomicide'>Youth Homicides in Boston</h2><span id='topic+BostonHomicide'></span>

<h3>Description</h3>

<p>Data about the number of youth homicides in Boston during the
&lsquo;Boston Gun Project&rsquo;&mdash;a policing initiative aiming at lowering
homicide victimization among young people in Boston.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("BostonHomicide")</code></pre>


<h3>Format</h3>

<p>A data frame containing 6 monthly time series
and two factors coding seasonality and year, respectively.
</p>

<dl>
<dt>homicides</dt><dd><p>time series. Number of youth homicides.</p>
</dd>
<dt>population</dt><dd><p>time series. Boston population (aged 25-44),
linearly interpolated from annual data.</p>
</dd>
<dt>populationBM</dt><dd><p>time series. Population of black males (aged 15-24),
linearly interpolated from annual data.</p>
</dd>
<dt>ahomicides25</dt><dd><p>time series. Number of adult homicides (aged 25 and older).</p>
</dd>
<dt>ahomicides35</dt><dd><p>time series. Number of adult homicides (aged 35-44).</p>
</dd>
<dt>unemploy</dt><dd><p>time series. Teen unemployment rate (in percent).</p>
</dd>
<dt>season</dt><dd><p>factor coding the month.</p>
</dd>
<dt>year</dt><dd><p>factor coding the year.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The &lsquo;Boston Gun Project&rsquo; is a policing initiative aiming at lowering
youth homicides in Boston. The project began in early 1995 and implemented the
so-called &lsquo;Operation Ceasefire&rsquo; intervention which began in the late spring of 1996.
</p>


<h3>Source</h3>

<p>Piehl et al. (2004), Figure 1, Figure 3, and Table 1.
</p>
<p>From the table it is not clear how the data should be linearly interpolated.
Here, it was chosen to use the given observations for July of the corresponding
year and then use <code><a href="stats.html#topic+approx">approx</a></code> with <code>rule = 2</code>.
</p>


<h3>References</h3>

<p>Piehl A.M., Cooper S.J., Braga A.A., Kennedy D.M. (2003), Testing for Structural
Breaks in the Evaluation of Programs, <em>The Review of Economics and Statistics</em>,
<b>85</b>(3), 550-558.
</p>
<p>Kennedy D.M., Piehl A.M., Braga A.A. (1996), Youth Violence in Boston: Gun Markets,
Serious Youth Offenders, and a Use-Reduction Strategy, <em>Law and Contemporary Problems</em>,
<b>59</b>, 147-183.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("BostonHomicide")
attach(BostonHomicide)

## data from Table 1
tapply(homicides, year, mean)
populationBM[0:6*12 + 7]
tapply(ahomicides25, year, mean)
tapply(ahomicides35, year, mean)
population[0:6*12 + 7]
unemploy[0:6*12 + 7]

## model A
## via OLS
fmA &lt;- lm(homicides ~ populationBM + season)
anova(fmA)
## as GLM
fmA1 &lt;- glm(homicides ~ populationBM + season, family = poisson)
anova(fmA1, test = "Chisq")

## model B &amp; C
fmB &lt;- lm(homicides ~ populationBM + season + ahomicides25)
fmC &lt;- lm(homicides ~ populationBM + season + ahomicides25 + unemploy)

detach(BostonHomicide)
</code></pre>

<hr>
<h2 id='boundary'>Boundary Function for Structural Change Tests</h2><span id='topic+boundary'></span>

<h3>Description</h3>

<p>A generic function computing boundaries for structural change
tests</p>


<h3>Usage</h3>

<pre><code class='language-R'>boundary(x, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boundary_+3A_x">x</code></td>
<td>
<p>an object. Use <code><a href="utils.html#topic+methods">methods</a></code> to see which
<code><a href="base.html#topic+class">class</a></code> has a method for boundary.</p>
</td></tr>
<tr><td><code id="boundary_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the boundary.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"ts"</code> with the same time properties as
the time series in <code>x</code></p>


<h3>See Also</h3>

<p><code><a href="#topic+boundary.efp">boundary.efp</a></code>, <code><a href="#topic+boundary.mefp">boundary.mefp</a></code>,
<code><a href="#topic+boundary.Fstats">boundary.Fstats</a></code></p>

<hr>
<h2 id='boundary.efp'>Boundary for Empirical Fluctuation Processes</h2><span id='topic+boundary.efp'></span>

<h3>Description</h3>

<p>Computes boundary for an object of class <code>"efp"</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'efp'
boundary(x, alpha = 0.05, alt.boundary = FALSE,
   functional = "max", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boundary.efp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"efp"</code>.</p>
</td></tr>
<tr><td><code id="boundary.efp_+3A_alpha">alpha</code></td>
<td>
<p>numeric from interval (0,1) indicating the confidence level for
which the boundary of the corresponding test will be computed.</p>
</td></tr>
<tr><td><code id="boundary.efp_+3A_alt.boundary">alt.boundary</code></td>
<td>
<p>logical. If set to <code>TRUE</code> alternative boundaries
(instead of the standard linear boundaries) will be computed (for Brownian
bridge type processes only).</p>
</td></tr>
<tr><td><code id="boundary.efp_+3A_functional">functional</code></td>
<td>
<p>indicates which functional should be applied to the
empirical fluctuation process. See also <code><a href="#topic+plot.efp">plot.efp</a></code>.</p>
</td></tr>
<tr><td><code id="boundary.efp_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"ts"</code> with the same time properties as
the process in <code>x</code></p>


<h3>See Also</h3>

<p><code><a href="#topic+efp">efp</a></code>, <code><a href="#topic+plot.efp">plot.efp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load dataset "nhtemp" with average yearly temperatures in New Haven
data("nhtemp")
## plot the data
plot(nhtemp)

## test the model null hypothesis that the average temperature remains constant
## over the years
## compute OLS-CUSUM fluctuation process
temp.cus &lt;- efp(nhtemp ~ 1, type = "OLS-CUSUM")
## plot the process without boundaries
plot(temp.cus, alpha = 0.01, boundary = FALSE)
## add the boundaries in another colour
bound &lt;- boundary(temp.cus, alpha = 0.01)
lines(bound, col=4)
lines(-bound, col=4)
</code></pre>

<hr>
<h2 id='boundary.Fstats'>Boundary for F Statistics</h2><span id='topic+boundary.Fstats'></span>

<h3>Description</h3>

<p>Computes boundary for an object of class <code>"Fstats"</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Fstats'
boundary(x, alpha = 0.05, pval = FALSE, aveF = FALSE,
    asymptotic = FALSE, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boundary.Fstats_+3A_x">x</code></td>
<td>
<p>an object of class <code>"Fstats"</code>.</p>
</td></tr>
<tr><td><code id="boundary.Fstats_+3A_alpha">alpha</code></td>
<td>
<p>numeric from interval (0,1) indicating the confidence level for
which the boundary of the supF test will be computed.</p>
</td></tr>
<tr><td><code id="boundary.Fstats_+3A_pval">pval</code></td>
<td>
<p>logical. If set to <code>TRUE</code> a boundary for the corresponding p
values will be computed.</p>
</td></tr>
<tr><td><code id="boundary.Fstats_+3A_avef">aveF</code></td>
<td>
<p>logical. If set to <code>TRUE</code> the boundary of the aveF (instead of
the supF) test will be computed. The resulting boundary then is a boundary
for the mean of the F statistics rather than for the F statistics
themselves.</p>
</td></tr>
<tr><td><code id="boundary.Fstats_+3A_asymptotic">asymptotic</code></td>
<td>
<p>logical. If set to <code>TRUE</code> the asymptotic (chi-square)
distribution instead of the exact (F) distribution will be used to compute
the p values (only if <code>pval</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="boundary.Fstats_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"ts"</code> with the same time properties as
the time series in <code>x</code></p>


<h3>See Also</h3>

<p><code><a href="#topic+Fstats">Fstats</a></code>, <code><a href="#topic+plot.Fstats">plot.Fstats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load dataset "nhtemp" with average yearly temperatures in New Haven
data("nhtemp")
## plot the data
plot(nhtemp)

## test the model null hypothesis that the average temperature remains
## constant over the years for potential break points between 1941
## (corresponds to from = 0.5) and 1962 (corresponds to to = 0.85)
## compute F statistics
fs &lt;- Fstats(nhtemp ~ 1, from = 0.5, to = 0.85)
## plot the p values without boundary
plot(fs, pval = TRUE, alpha = 0.01)
## add the boundary in another colour
lines(boundary(fs, pval = TRUE, alpha = 0.01), col = 2)
</code></pre>

<hr>
<h2 id='boundary.mefp'>Boundary Function for Monitoring of Structural Changes</h2><span id='topic+boundary.mefp'></span>

<h3>Description</h3>

<p>Computes boundary for an object of class <code>"mefp"</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mefp'
boundary(x, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boundary.mefp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"mefp"</code>.</p>
</td></tr>
<tr><td><code id="boundary.mefp_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>"ts"</code> with the same time properties as
the monitored process</p>


<h3>See Also</h3>

<p><code><a href="#topic+mefp">mefp</a></code>, <code><a href="#topic+plot.mefp">plot.mefp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>df1 &lt;- data.frame(y=rnorm(300))
df1[150:300,"y"] &lt;- df1[150:300,"y"]+1
me1 &lt;- mefp(y~1, data=df1[1:50,,drop=FALSE], type="ME", h=1,
              alpha=0.05)
me2 &lt;- monitor(me1, data=df1)

plot(me2, boundary=FALSE)
lines(boundary(me2), col="green", lty="44")
</code></pre>

<hr>
<h2 id='breakdates'>Breakdates Corresponding to Breakpoints</h2><span id='topic+breakdates'></span><span id='topic+breakdates.breakpoints'></span><span id='topic+breakdates.confint.breakpoints'></span>

<h3>Description</h3>

<p>A generic function for computing the breakdates corresponding
to breakpoints (and their confidence intervals).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breakdates(obj, format.times = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="breakdates_+3A_obj">obj</code></td>
<td>
<p>An object of class <code>"breakpoints"</code>, <code>"breakpointsfull"</code> or their
confidence intervals as returned by <code><a href="stats.html#topic+confint">confint</a></code>.</p>
</td></tr>
<tr><td><code id="breakdates_+3A_format.times">format.times</code></td>
<td>
<p>logical. If set to <code>TRUE</code> a vector of
strings with the formatted breakdates. See details for more
information.</p>
</td></tr>
<tr><td><code id="breakdates_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Breakpoints are the number of observations that are the last in one
segment and breakdates are the corresponding points on the underlying
time scale. The breakdates can be formatted which enhances readability
in particular for quarterly or monthly time series. For example the
breakdate <code>2002.75</code> of a monthly time series will be formatted to
<code>"2002(10)"</code>.
</p>


<h3>Value</h3>

<p>A vector or matrix containing the breakdates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+breakpoints">breakpoints</a></code>, <code><a href="stats.html#topic+confint">confint</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

bp.nile &lt;- breakpoints(Nile ~ 1)
summary(bp.nile)
plot(bp.nile)

## compute breakdates corresponding to the
## breakpoints of minimum BIC segmentation
breakdates(bp.nile)

## confidence intervals
ci.nile &lt;- confint(bp.nile)
breakdates(ci.nile)
ci.nile

plot(Nile)
lines(ci.nile)
</code></pre>

<hr>
<h2 id='breakfactor'>Factor Coding of Segmentations</h2><span id='topic+breakfactor'></span>

<h3>Description</h3>

<p>Generates a factor encoding the segmentation given by
a set of breakpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>breakfactor(obj, breaks = NULL, labels = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="breakfactor_+3A_obj">obj</code></td>
<td>
<p>An object of class <code>"breakpoints"</code> or
<code>"breakpointsfull"</code> respectively.</p>
</td></tr>
<tr><td><code id="breakfactor_+3A_breaks">breaks</code></td>
<td>
<p>an integer specifying the number of breaks
to extract (only if <code>obj</code> is of class <code>"breakpointsfull"</code>),
by default the minimum BIC partition is used.</p>
</td></tr>
<tr><td><code id="breakfactor_+3A_labels">labels</code></td>
<td>
<p>a vector of labels for the returned factor,
by default the segments are numbered starting from
<code>"segment1"</code>.</p>
</td></tr>
<tr><td><code id="breakfactor_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>factor</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A factor encoding the segmentation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+breakpoints">breakpoints</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

## compute breakpoints
bp.nile &lt;- breakpoints(Nile ~ 1)

## fit and visualize segmented and unsegmented model
fm0 &lt;- lm(Nile ~ 1)
fm1 &lt;- lm(Nile ~ breakfactor(bp.nile, breaks = 1))

lines(fitted(fm0), col = 3)
lines(fitted(fm1), col = 4)
lines(bp.nile, breaks = 1)
</code></pre>

<hr>
<h2 id='breakpoints'>Dating Breaks</h2><span id='topic+breakpoints'></span><span id='topic+breakpoints.formula'></span><span id='topic+breakpoints.matrix'></span><span id='topic+breakpoints.breakpointsfull'></span><span id='topic+breakpoints.Fstats'></span><span id='topic+summary.breakpoints'></span><span id='topic+summary.breakpointsfull'></span><span id='topic+plot.breakpointsfull'></span><span id='topic+plot.summary.breakpointsfull'></span><span id='topic+print.breakpoints'></span><span id='topic+print.summary.breakpointsfull'></span><span id='topic+lines.breakpoints'></span><span id='topic+coef.breakpointsfull'></span><span id='topic+vcov.breakpointsfull'></span><span id='topic+fitted.breakpointsfull'></span><span id='topic+residuals.breakpointsfull'></span><span id='topic+df.residual.breakpointsfull'></span>

<h3>Description</h3>

<p>Computation of breakpoints in regression relationships. Given a number
of breaks the function computes the optimal breakpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
breakpoints(formula, h = 0.15, breaks = c("BIC", "LWZ", "RSS", "all"),
    data = list(), hpc = c("none", "foreach"), ...)
## S3 method for class 'matrix'
breakpoints(obj, y, h = 0.15, breaks = c("BIC", "LWZ", "RSS", "all"), 
    hpc = c("none", "foreach"), ...)
## S3 method for class 'breakpointsfull'
breakpoints(obj, breaks = c("BIC", "LWZ", "RSS", "all"), ...)
## S3 method for class 'breakpointsfull'
summary(object, breaks = NULL, sort = TRUE,
    format.times = NULL, ...)
## S3 method for class 'breakpoints'
lines(x, breaks = NULL, lty = 2, ...)

## S3 method for class 'breakpointsfull'
coef(object, breaks = NULL, names = NULL, ...)
## S3 method for class 'breakpointsfull'
fitted(object, breaks = NULL, bp = NULL, ...)
## S3 method for class 'breakpointsfull'
residuals(object, breaks = NULL, ...)
## S3 method for class 'breakpointsfull'
vcov(object, breaks = NULL, names = NULL,
    het.reg = TRUE, het.err = TRUE, vcov. = NULL, sandwich = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="breakpoints_+3A_obj">obj</code>, <code id="breakpoints_+3A_object">object</code></td>
<td>
<p>an object of class <code>"breakpointsfull"</code>,
or (only in <code>breakpoints.matrix</code>) regression matrix <em>X</em>.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_y">y</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model in which breakpoints
will be estimated.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_h">h</code></td>
<td>
<p>minimal segment size either given as fraction relative to the
sample size or as an integer giving the minimal number of observations
in each segment.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_breaks">breaks</code></td>
<td>
<p>either a positive integer specifying the maximal number of breaks to be calculated,
or a string specifying the information criterion to use to automatically determine
the optimal number of breaks (see also <code><a href="stats.html#topic+logLik">logLik</a></code>).
<code>"all"</code> means the maximal number allowed by <code>h</code> is used.
<code>NULL</code> is treated as the default of the <code>breakpoints</code> function (i.e. BIC).</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By
default the variables are taken from the environment which <code>breakpoints</code> is
called from.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_hpc">hpc</code></td>
<td>
<p>a character specifying the high performance computing support.
Default is <code>"none"</code>, can be set to <code>"foreach"</code>.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="#topic+recresid">recresid</a></code>.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_sort">sort</code></td>
<td>
<p>logical. If set to <code>TRUE</code> <code>summary</code> tries to match
the breakpoints from partitions with different numbers of breaks.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_format.times">format.times</code></td>
<td>
<p>logical. If set to <code>TRUE</code> a vector of
strings with the formatted breakdates is printed. See <code><a href="#topic+breakdates">breakdates</a></code>
for more information.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_x">x</code></td>
<td>
<p>an object of class <code>"breakpoints"</code>.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_lty">lty</code></td>
<td>
<p>line type.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_names">names</code></td>
<td>
<p>a character vector giving the names of the segments. If of length
1 it is taken to be a generic prefix, e.g. <code>"segment"</code>.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_bp">bp</code></td>
<td>
<p>integer vector denoting the breakpoint indices for which to get the fitted values.
Default is to choose according to <code>breaks</code>. If both are given, <code>bp</code> takes precedence.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_het.reg">het.reg</code></td>
<td>
<p>logical. Should heterogeneous regressors be assumed? If set
to <code>FALSE</code> the distribution of the regressors is assumed to be
homogeneous over the segments.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_het.err">het.err</code></td>
<td>
<p>logical. Should heterogeneous errors be assumed? If set
to <code>FALSE</code> the distribution of the errors is assumed to be
homogeneous over the segments.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_vcov.">vcov.</code></td>
<td>
<p>a function to extract the covariance matrix
for the coefficients of a fitted model of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="breakpoints_+3A_sandwich">sandwich</code></td>
<td>
<p>logical. Is the function <code>vcov.</code> the sandwich
estimator or only the middle part?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All procedures in this package are concerned with testing or assessing
deviations from stability in the classical linear regression model
</p>
<p style="text-align: center;"><code class="reqn">y_i = x_i^\top \beta + u_i</code>
</p>

<p>In many applications it is reasonable to assume
that there are <code class="reqn">m</code> breakpoints, where the coefficients shift from
one stable regression relationship to a different one. Thus,
there are <code class="reqn">m+1</code> segments in which the regression coefficients are
constant, and the model can be rewritten as
</p>
<p style="text-align: center;"><code class="reqn">y_i = x_i^\top \beta_j + u_i
  \qquad (i = i_{j-1} + 1, \dots, i_j, \quad j = 1, \dots, m+1)</code>
</p>

<p>where <code class="reqn">j</code> denotes the segment index. In practice the breakpoints <code class="reqn">i_j</code>
are rarely given exogenously, but have to be estimated.
<code>breakpoints</code> estimates these breakpoints by minimizing the residual sum of
squares (RSS) of the equation above.
</p>
<p>The foundation for estimating breaks in time series regression models
was given by Bai (1994) and was extended to multiple breaks by Bai (1997ab)
and Bai &amp; Perron (1998). <code>breakpoints</code> implements the algorithm
described in Bai &amp; Perron (2003) for simultaneous estimation of
multiple breakpoints. The distribution function used for the confidence
intervals for the breakpoints is given in Bai (1997b). The ideas behind
this implementation are described in Zeileis et al. (2003).
</p>
<p>The algorithm for computing the optimal breakpoints given the number
of breaks is based on a dynamic programming approach. The underlying
idea is that of the Bellman principle. The main computational effort
is to compute a triangular RSS matrix, which gives the residual
sum of squares for a segment starting at observation <code class="reqn">i</code> and
ending at <code class="reqn">i'</code> with <code class="reqn">i</code> &lt; <code class="reqn">i'</code>.
</p>
<p>Given a <code>formula</code> as the first argument, <code>breakpoints</code> computes
an object of class <code>"breakpointsfull"</code> which inherits from <code>"breakpoints"</code>.
This contains in particular the triangular RSS
matrix and functions to extract an optimal segmentation. A <code>summary</code>
of this object will give the breakpoints (and associated) breakdates
for all segmentations up to the maximal number of breaks together
with the associated RSS, BIC and LWZ. These will be plotted if <code>plot</code>
is applied and thus visualize the minimum BIC and LWZ estimators of the number
of breakpoints. From an object of class <code>"breakpointsfull"</code> an
arbitrary number of <code>breaks</code> (admissible by the minimum segment
size <code>h</code>) can be extracted by another application of
<code>breakpoints</code>, returning an object of class <code>"breakpoints"</code>.
This contains only the breakpoints for the specified number of breaks
and some model properties (number of observations, regressors, time
series properties and the associated RSS) but not the triangular RSS
matrix and related extractor functions. The set of breakpoints which
is associated by default with a <code>"breakpointsfull"</code> object is
the minimum BIC partition.
</p>
<p>Breakpoints are the number of observations that are the last in one
segment, it is also possible to compute the corresponding <code>breakdates</code>
which are the breakpoints on the underlying time scale. The breakdates
can be formatted which enhances readability in particular for quarterly
or monthly time series. For example the breakdate <code>2002.75</code> of a monthly
time series will be formatted to <code>"2002(10)"</code>. See <code><a href="#topic+breakdates">breakdates</a></code>
for more details.
</p>
<p>From a <code>"breakpointsfull"</code> object confidence intervals for the breakpoints
can be computed using the method of <code><a href="stats.html#topic+confint">confint</a></code>.
The breakdates corresponding to the breakpoints can again be computed
by <code><a href="#topic+breakdates">breakdates</a></code>. The breakpoints and their confidence
intervals can be visualized by <code>lines</code>. Convenience functions are
provided for extracting the coefficients and covariance matrix, fitted 
values and residuals of segmented models.
</p>
<p>The log likelihood as well as some information criteria can be computed
using the methods for the <code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="stats.html#topic+AIC">AIC</a></code> and <code>LWZ</code>. As
for linear models the log likelihood is computed on a normal model and
the degrees of freedom are the number of regression coefficients multiplied
by the number of segments plus the number of estimated breakpoints plus
1 for the error variance. More details can be found on the help page of
the method <code><a href="#topic+logLik.breakpoints">logLik.breakpoints</a></code>.
</p>
<p>As the maximum of a sequence of F statistics is equivalent to the minimum
OLS estimator of the breakpoint in a 2-segment partition it can be
extracted by <code>breakpoints</code> from an object of class <code>"Fstats"</code>
as computed by <code><a href="#topic+Fstats">Fstats</a></code>. However, this cannot be used to extract
a larger number of breakpoints.
</p>
<p>For illustration see the commented examples below and Zeileis et al. (2003).
</p>
<p>Optional support for high performance computing is available, currently using
<code><a href="foreach.html#topic+foreach">foreach</a></code> for the dynamic programming algorithm.
If <code>hpc = "foreach"</code> is to be used, a parallel backend should be registered
before. See <code><a href="foreach.html#topic+foreach">foreach</a></code> for more information.
</p>


<h3>Value</h3>

<p>An object of class <code>"breakpoints"</code> is a list with the following
elements:
</p>

<dl>
<dt>breakpoints</dt><dd><p>the breakpoints of the optimal partition with the
number of breaks specified (set to <code>NA</code> if the optimal 1-segment
solution is reported),</p>
</dd>
<dt>RSS</dt><dd><p>the associated RSS,</p>
</dd>
<dt>nobs</dt><dd><p>the number of observations,</p>
</dd>
<dt>nreg</dt><dd><p>the number of regressors,</p>
</dd>
<dt>call</dt><dd><p>the function call,</p>
</dd>
<dt>datatsp</dt><dd><p>the time series properties <code>tsp</code> of the data,
if any, <code>c(1/nobs, 1, nobs)</code> otherwise.</p>
</dd>
</dl>

<p>If applied to a <code>formula</code> as first argument, <code>breakpoints</code> returns an object of class
<code>"breakpointsfull"</code> (which inherits from <code>"breakpoints"</code>), that
contains some additional (or slightly different) elements such as:
</p>

<dl>
<dt>breakpoints</dt><dd><p>the breakpoints of the minimum BIC partition,</p>
</dd>
<dt>RSS</dt><dd><p>a function which takes two arguments <code>i,j</code> and computes
the residual sum of squares for a segment starting at observation <code>i</code> and
ending at <code>j</code> by looking up the corresponding element in the triangular
RSS matrix <code>RSS.triang</code>,</p>
</dd>
<dt>RSS.triang</dt><dd><p>a list encoding the triangular RSS matrix.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bai J. (1994), Least Squares Estimation of a Shift in Linear Processes,
<em>Journal of Time Series Analysis</em>, <b>15</b>, 453-472.
</p>
<p>Bai J. (1997a), Estimating Multiple Breaks One at a Time,
<em>Econometric Theory</em>, <b>13</b>, 315-352.
</p>
<p>Bai J. (1997b), Estimation of a Change Point in Multiple Regression Models,
<em>Review of Economics and Statistics</em>, <b>79</b>, 551-563.
</p>
<p>Bai J., Perron P. (1998), Estimating and Testing Linear Models With Multiple Structural
Changes, <em>Econometrica</em>, <b>66</b>, 47-78.
</p>
<p>Bai J., Perron P. (2003), Computation and Analysis of Multiple Structural Change
Models, <em>Journal of Applied Econometrics</em>, <b>18</b>, 1-22.
</p>
<p>Zeileis A., Kleiber C., Kr\&quot;amer W., Hornik K. (2003), Testing and Dating of
Structural Changes in Practice, <em>Computational Statistics and Data Analysis</em>,
<b>44</b>, 109-123. doi:10.1016/S0167-9473(03)00030-6.
</p>
<p>Zeileis A., Shah A., Patnaik I. (2010), Testing, Monitoring, and Dating Structural
Changes in Exchange Rate Regimes, <em>Computational Statistics and Data Analysis</em>,
<b>54</b>(6), 1696&ndash;1706. doi:10.1016/j.csda.2009.12.005.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

## F statistics indicate one breakpoint
fs.nile &lt;- Fstats(Nile ~ 1)
plot(fs.nile)
breakpoints(fs.nile)
lines(breakpoints(fs.nile))

## or
bp.nile &lt;- breakpoints(Nile ~ 1)
summary(bp.nile)

## the BIC and LWZ also choose one breakpoint
plot(bp.nile)
breakpoints(bp.nile)
breakpoints(bp.nile, breaks = "LWZ")

## fit null hypothesis model and model with 1 breakpoint
fm0 &lt;- lm(Nile ~ 1)
fm1 &lt;- lm(Nile ~ breakfactor(bp.nile, breaks = 1))
plot(Nile)
lines(ts(fitted(fm0), start = 1871), col = 3)
lines(ts(fitted(fm1), start = 1871), col = 4)
lines(bp.nile)

## confidence interval
ci.nile &lt;- confint(bp.nile)
ci.nile
lines(ci.nile)


## UK Seatbelt data: a SARIMA(1,0,0)(1,0,0)_12 model
## (fitted by OLS) is used and reveals (at least) two
## breakpoints - one in 1973 associated with the oil crisis and
## one in 1983 due to the introduction of compulsory
## wearing of seatbelts in the UK.
data("UKDriverDeaths")
seatbelt &lt;- log10(UKDriverDeaths)
seatbelt &lt;- cbind(seatbelt, lag(seatbelt, k = -1), lag(seatbelt, k = -12))
colnames(seatbelt) &lt;- c("y", "ylag1", "ylag12")
seatbelt &lt;- window(seatbelt, start = c(1970, 1), end = c(1984,12))
plot(seatbelt[,"y"], ylab = expression(log[10](casualties)))

## testing
re.seat &lt;- efp(y ~ ylag1 + ylag12, data = seatbelt, type = "RE")
plot(re.seat)

## dating
bp.seat &lt;- breakpoints(y ~ ylag1 + ylag12, data = seatbelt, h = 0.1)
summary(bp.seat)
lines(bp.seat, breaks = 2)

## minimum BIC partition
plot(bp.seat)
breakpoints(bp.seat)
## the BIC would choose 0 breakpoints although the RE and supF test
## clearly reject the hypothesis of structural stability. Bai &amp;
## Perron (2003) report that the BIC has problems in dynamic regressions.
## due to the shape of the RE process of the F statistics choose two
## breakpoints and fit corresponding models
bp.seat2 &lt;- breakpoints(bp.seat, breaks = 2)
fm0 &lt;- lm(y ~ ylag1 + ylag12, data = seatbelt)
fm1 &lt;- lm(y ~ breakfactor(bp.seat2)/(ylag1 + ylag12) - 1, data = seatbelt)

## plot
plot(seatbelt[,"y"], ylab = expression(log[10](casualties)))
time.seat &lt;- as.vector(time(seatbelt))
lines(time.seat, fitted(fm0), col = 3)
lines(time.seat, fitted(fm1), col = 4)
lines(bp.seat2)

## confidence intervals
ci.seat2 &lt;- confint(bp.seat, breaks = 2)
ci.seat2
lines(ci.seat2)
</code></pre>

<hr>
<h2 id='catL2BB'>Generators for efpFunctionals along Categorical Variables</h2><span id='topic+catL2BB'></span><span id='topic+ordL2BB'></span><span id='topic+ordwmax'></span>

<h3>Description</h3>

<p>Generators for <code>efpFunctional</code> objects suitable for aggregating
empirical fluctuation processes to test statistics along (ordinal)
categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catL2BB(freq)
ordL2BB(freq, nproc = NULL, nrep = 1e5, probs = c(0:84/100, 850:1000/1000), ...)
ordwmax(freq, algorithm = mvtnorm::GenzBretz(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catL2BB_+3A_freq">freq</code></td>
<td>
<p>object specifying the category frequencies for the
categorical variable to be used for aggregation: either a
<code><a href="#topic+gefp">gefp</a></code> object, a <code><a href="base.html#topic+factor">factor</a></code>, or a numeric
vector with either absolute or relative category frequencies.</p>
</td></tr>
<tr><td><code id="catL2BB_+3A_nproc">nproc</code></td>
<td>
<p>numeric. Number of processes used for simulating
from the asymptotic distribution (passed to <code><a href="#topic+efpFunctional">efpFunctional</a></code>).
If <code>feq</code> is a <code><a href="#topic+gefp">gefp</a></code> object, then its number of
processes is used by default.</p>
</td></tr>
<tr><td><code id="catL2BB_+3A_nrep">nrep</code></td>
<td>
<p>numeric. Number of replications used for simulating
from the asymptotic distribution (passed to <code><a href="#topic+efpFunctional">efpFunctional</a></code>).</p>
</td></tr>
<tr><td><code id="catL2BB_+3A_probs">probs</code></td>
<td>
<p>numeric vector specifying for which probabilities 
critical values should be tabulated.</p>
</td></tr>
<tr><td><code id="catL2BB_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+efpFunctional">efpFunctional</a></code>.</p>
</td></tr>
<tr><td><code id="catL2BB_+3A_algorithm">algorithm</code></td>
<td>
<p>algorithm specification passed to <code><a href="mvtnorm.html#topic+pmvnorm">pmvnorm</a></code>
for computing the asymptotic distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Merkle, Fan, and Zeileis (2014) discuss three functionals that are 
suitable for aggregating empirical fluctuation processes along categorical
variables, especially ordinal variables. The functions <code>catL2BB</code>,
<code>ordL2BB</code>, and <code>ordwmax</code> all require a specification of the
relative frequencies within each category (which can be computed from
various specifications, see arguments). All of them employ
<code><a href="#topic+efpFunctional">efpFunctional</a></code> (Zeileis 2006) internally to set up an
object that can be employed with <code><a href="#topic+gefp">gefp</a></code> fluctuation
processes.
</p>
<p><code>catL2BB</code> results in a chi-squared test. This is essentially
the LM test counterpart to the likelihood ratio test that assesses
a split into unordered categories.
</p>
<p><code>ordL2BB</code> is the ordinal counterpart to <code><a href="#topic+supLM">supLM</a></code>
where aggregation is done along the ordered categories (rather than
continuously). The asymptotic distribution is non-standard and needs
to be simulated for every combination of frequencies and number of
processes. Hence, this is somewhat more time-consuming compared to
the closed-form solution employed in <code>catL2BB</code>. It is also
possible to store the result of <code>ordL2BB</code> in case it needs to
be applied several <code><a href="#topic+gefp">gefp</a></code> fluctuation processes.
</p>
<p><code>ordwmax</code> is a weighted double maximum test based on ideas
previously suggested by Hothorn and Zeileis (2008) in the context of
maximally selected statistics. The asymptotic distribution is
(multivariate) normal and computed by means of <code><a href="mvtnorm.html#topic+pmvnorm">pmvnorm</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>efpFunctional</code>.
</p>


<h3>References</h3>

<p>Hothorn T., Zeileis A. (2008), Generalized Maximally Selected Statistics.
<em>Biometrics</em>, <b>64</b>, 1263&ndash;1269.
</p>
<p>Merkle E.C., Fan J., Zeileis A. (2014), Testing for Measurement Invariance with
Respect to an Ordinal Variable. <em>Psychometrika</em>, <b>79</b>(4), 569&ndash;584.
doi:10.1007/S11336-013-9376-7.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi:10.1016/j.csda.2005.07.001.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efpFunctional">efpFunctional</a></code>, <code><a href="#topic+gefp">gefp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## artificial data
set.seed(1)
d &lt;- data.frame(
  x = runif(200, -1, 1),
  z = factor(rep(1:4, each = 50)),
  err = rnorm(200)
)
d$y &lt;- rep(c(0.5, -0.5), c(150, 50)) * d$x + d$err

## empirical fluctuation process
scus &lt;- gefp(y ~ x, data = d, fit = lm, order.by = ~ z)

## chi-squared-type test (unordered LM-type test)
LMuo &lt;- catL2BB(scus)
plot(scus, functional = LMuo)
sctest(scus, functional = LMuo)

## ordinal maxLM test (with few replications only to save time)
maxLMo &lt;- ordL2BB(scus, nrep = 10000)
plot(scus, functional = maxLMo)
sctest(scus, functional = maxLMo)

## ordinal weighted double maximum test
WDM &lt;- ordwmax(scus)
plot(scus, functional = WDM)
sctest(scus, functional = WDM)
</code></pre>

<hr>
<h2 id='confint.breakpointsfull'>Confidence Intervals for Breakpoints</h2><span id='topic+confint.breakpointsfull'></span><span id='topic+lines.confint.breakpoints'></span><span id='topic+print.confint.breakpoints'></span>

<h3>Description</h3>

<p>Computes confidence intervals for breakpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'breakpointsfull'
confint(object, parm = NULL, level = 0.95,
    breaks = NULL, het.reg = TRUE, het.err = TRUE, vcov. = NULL, sandwich = TRUE, ...)
## S3 method for class 'confint.breakpoints'
lines(x, col = 2, angle = 90, length = 0.05,
    code = 3, at = NULL, breakpoints = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confint.breakpointsfull_+3A_object">object</code></td>
<td>
<p>an object of class <code>"breakpointsfull"</code> as computed by
<code><a href="#topic+breakpoints">breakpoints</a></code> from a <code>formula</code>.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_parm">parm</code></td>
<td>
<p>the same as <code>breaks</code>, only one of the two should be
specified.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_level">level</code></td>
<td>
<p>the confidence level required.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_breaks">breaks</code></td>
<td>
<p>an integer specifying the number of breaks to be used.
By default the breaks of the minimum BIC partition are used.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_het.reg">het.reg</code></td>
<td>
<p>logical. Should heterogeneous regressors be assumed? If set
to <code>FALSE</code> the distribution of the regressors is assumed to be
homogeneous over the segments.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_het.err">het.err</code></td>
<td>
<p>logical. Should heterogeneous errors be assumed? If set
to <code>FALSE</code> the distribution of the errors is assumed to be
homogeneous over the segments.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_vcov.">vcov.</code></td>
<td>
<p>a function to extract the covariance matrix
for the coefficients of a fitted model of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_sandwich">sandwich</code></td>
<td>
<p>logical. Is the function <code>vcov.</code> the sandwich
estimator or only the middle part?</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_x">x</code></td>
<td>
<p>an object of class <code>"confint.breakpoints"</code> as returned by
<code>confint</code>.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_col">col</code>, <code id="confint.breakpointsfull_+3A_angle">angle</code>, <code id="confint.breakpointsfull_+3A_length">length</code>, <code id="confint.breakpointsfull_+3A_code">code</code></td>
<td>
<p>arguments passed to <code><a href="graphics.html#topic+arrows">arrows</a></code>.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_at">at</code></td>
<td>
<p>position on the y axis, where the confidence arrows should be
drawn. By default they are drawn at the bottom of the plot.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_breakpoints">breakpoints</code></td>
<td>
<p>logical. If <code>TRUE</code> vertical lines for the breakpoints
are drawn.</p>
</td></tr>
<tr><td><code id="confint.breakpointsfull_+3A_...">...</code></td>
<td>
<p><em>currently not used</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As the breakpoints are integers (observation numbers) the corresponding
confidence intervals are also rounded to integers.
</p>
<p>The distribution function used for the computation of confidence
intervals of breakpoints is given in Bai (1997). The procedure, in
particular the usage of heterogeneous regressors and/or errors, is
described in more detail in Bai &amp; Perron (2003).
</p>
<p>The breakpoints should be computed from a formula with <code>breakpoints</code>,
then the confidence intervals for the breakpoints can be derived by
<code>confint</code> and these can be visualized by <code>lines</code>. For an
example see below.
</p>


<h3>Value</h3>

<p>A matrix containing the breakpoints and their lower and upper
confidence boundary for the given level.
</p>


<h3>References</h3>

<p>Bai J. (1997), Estimation of a Change Point in Multiple Regression Models,
<em>Review of Economics and Statistics</em>, <b>79</b>, 551-563.
</p>
<p>Bai J., Perron P. (2003), Computation and Analysis of Multiple Structural Change
Models, <em>Journal of Applied Econometrics</em>, <b>18</b>, 1-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+breakpoints">breakpoints</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

## dating breaks
bp.nile &lt;- breakpoints(Nile ~ 1)
ci.nile &lt;- confint(bp.nile, breaks = 1)
lines(ci.nile)
</code></pre>

<hr>
<h2 id='DJIA'>Dow Jones Industrial Average</h2><span id='topic+DJIA'></span>

<h3>Description</h3>

<p>Weekly closing values of the Dow Jones Industrial Average.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("DJIA")</code></pre>


<h3>Format</h3>

<p>A weekly univariate time series of class <code>"zoo"</code>
from 1971-07-01 to 1974-08-02.
</p>


<h3>Source</h3>

<p>Appendix A in Hsu (1979).
</p>


<h3>References</h3>

<p>Hsu D. A. (1979), Detecting Shifts of Parameter in Gamma Sequences with 
Applications to Stock Price and Air Traffic Flow Analysis,
<em>Journal of the American Statistical Association</em>, <b>74</b>, 31&ndash;40.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("DJIA")
## look at log-difference returns
djia &lt;- diff(log(DJIA))
plot(djia)

## convenience functions
## set up a normal regression model which
## explicitely also models the variance
normlm &lt;- function(formula, data = list()) {
  rval &lt;- lm(formula, data = data)
  class(rval) &lt;- c("normlm", "lm")
  return(rval)
}
estfun.normlm &lt;- function(obj) {
  res &lt;- residuals(obj)
  ef &lt;- NextMethod(obj)
  sigma2 &lt;- mean(res^2)
  rval &lt;- cbind(ef, res^2 - sigma2)
  colnames(rval) &lt;- c(colnames(ef), "(Variance)")
  return(rval)
}

## normal model (with constant mean and variance) for log returns
m1 &lt;- gefp(djia ~ 1, fit = normlm, vcov = meatHAC, sandwich = FALSE)
plot(m1, aggregate = FALSE)
## suggests a clear break in the variance (but not the mean)

## dating
bp &lt;- breakpoints(I(djia^2) ~ 1)
plot(bp)
## -&gt; clearly one break
bp
time(djia)[bp$breakpoints]

## visualization
plot(djia)
abline(v = time(djia)[bp$breakpoints], lty = 2)
lines(time(djia)[confint(bp)$confint[c(1,3)]], rep(min(djia), 2), col = 2, type = "b", pch = 3)
</code></pre>

<hr>
<h2 id='durab'>US Labor Productivity</h2><span id='topic+durab'></span>

<h3>Description</h3>

<p>US labor productivity in the manufacturing/durables sector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("durab")</code></pre>


<h3>Format</h3>

<p><code>durab</code> is a multivariate monthly time series from 1947(3)
to 2001(4) with variables
</p>

<dl>
<dt>y</dt><dd><p>growth rate of the Industrial Production Index to
average weekly labor hours in the manufacturing/durables sector,</p>
</dd>
<dt>lag</dt><dd><p>lag 1 of the series <code>y</code>,</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data set is available from Bruce Hansen's homepage
<a href="http://www.ssc.wisc.edu/~bhansen/">http://www.ssc.wisc.edu/~bhansen/</a>. For more information
see Hansen (2001).</p>


<h3>References</h3>

<p>Hansen B. (2001), The New Econometrics of Structural Change:
Dating Breaks in U.S. Labor Productivity,
<em>Journal of Economic Perspectives</em>, <b>15</b>, 117&ndash;128.
</p>
<p>Zeileis A., Leisch F., Kleiber C., Hornik K. (2005), Monitoring
Structural Change in Dynamic Econometric Models,
<em>Journal of Applied Econometrics</em>, <b>20</b>, 99&ndash;121.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Enable fast options
options(strucchange.use_armadillo = TRUE)
data("durab")
## use AR(1) model as in Hansen (2001) and Zeileis et al. (2005)
durab.model &lt;- y ~ lag

## historical tests
## OLS-based CUSUM process
ols &lt;- efp(durab.model, data = durab, type = "OLS-CUSUM")
plot(ols)
## F statistics
fs &lt;- Fstats(durab.model, data = durab, from = 0.1)
plot(fs)

## F statistics based on heteroskadisticy-consistent covariance matrix
fsHC &lt;- Fstats(durab.model, data = durab, from = 0.1,
	       vcov = function(x, ...) vcovHC(x, type = "HC", ...))
plot(fsHC)

## monitoring
Durab &lt;- window(durab, start=1964, end = c(1979, 12))
ols.efp &lt;- efp(durab.model, type = "OLS-CUSUM", data = Durab)
newborder &lt;- function(k) 1.723 * k/192
ols.mefp &lt;- mefp(ols.efp, period=2)
ols.mefp2 &lt;- mefp(ols.efp, border=newborder)
Durab &lt;- window(durab, start=1964)
ols.mon &lt;- monitor(ols.mefp)
ols.mon2 &lt;- monitor(ols.mefp2)
plot(ols.mon)
lines(boundary(ols.mon2), col = 2)
## Note: critical value for linear boundary taken from Table III
## in Zeileis et al. 2005: (1.568 + 1.896)/2 = 1.732 is a linear
## interpolation between the values for T = 2 and T = 3 at
## alpha = 0.05. A typo switched 1.732 to 1.723.

## dating
bp &lt;- breakpoints(durab.model, data = durab)
summary(bp)
plot(summary(bp))

plot(ols)
lines(breakpoints(bp, breaks = 1), col = 3)
lines(breakpoints(bp, breaks = 2), col = 4)
plot(fs)
lines(breakpoints(bp, breaks = 1), col = 3)
lines(breakpoints(bp, breaks = 2), col = 4)
</code></pre>

<hr>
<h2 id='efp'>Empirical Fluctuation Processes</h2><span id='topic+efp'></span><span id='topic+efp.formula'></span><span id='topic+efp.matrix'></span><span id='topic+print.efp'></span>

<h3>Description</h3>

<p>Computes an empirical fluctuation process according
to a specified method from the generalized fluctuation test
framework, which includes CUSUM and MOSUM tests based on recursive
or OLS residuals, parameter estimates or ML scores (OLS first order
conditions).</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
efp(formula, data, type = , h = 0.15,
    dynamic = FALSE, rescale = TRUE, lrvar = FALSE, vcov = NULL, ...)
## S3 method for class 'matrix'
efp(X, y, type = , h = 0.15,
    dynamic = FALSE, rescale = TRUE, ...)   
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efp_+3A_x">X</code>, <code id="efp_+3A_y">y</code>, <code id="efp_+3A_formula">formula</code></td>
<td>
<p>specification of the linear regression model:
either by a regressor matrix <code>X</code> and a response variable <code>y</code>,
or by a <code>formula</code>.</p>
</td></tr>
<tr><td><code id="efp_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By
default the variables are taken from the environment which <code>efp</code> is
called from.</p>
</td></tr>
<tr><td><code id="efp_+3A_type">type</code></td>
<td>
<p>specifies which type of fluctuation process will be
computed, the default is <code>"Rec-CUSUM"</code>. For details see below.</p>
</td></tr>
<tr><td><code id="efp_+3A_h">h</code></td>
<td>
<p>bandwidth (for MOSUM and ME processes
only), either specified relative to the sample size as a numeric from interval (0,1),      or as an integer &gt;= 1 determining the absolute bandwidth size (number of samples). </p>
</td></tr>
<tr><td><code id="efp_+3A_dynamic">dynamic</code></td>
<td>
<p>logical. If <code>TRUE</code> the lagged observations are included as
a regressor.</p>
</td></tr>
<tr><td><code id="efp_+3A_rescale">rescale</code></td>
<td>
<p>logical. If <code>TRUE</code> the estimates will be standardized by
the regressor matrix of the corresponding subsample according to Kuan &amp; Chen
(1994); if <code>FALSE</code> the whole regressor matrix will be used.
(only if <code>type</code> is either <code>"RE"</code> or <code>"ME"</code>)</p>
</td></tr>
<tr><td><code id="efp_+3A_lrvar">lrvar</code></td>
<td>
<p>logical or character. Should a long-run variance estimator
be used for the residuals? By default, the standard OLS variance is employed.
Alternatively, <code><a href="sandwich.html#topic+lrvar">lrvar</a></code> can be used. If <code>lrvar</code>
is character (<code>"Andrews"</code> or <code>"Newey-West"</code>), then the corresponding
<code>type</code> of long-run variance is used. (The argument is ignored for the
score-based tests where <code><a href="#topic+gefp">gefp</a></code> should be used instead.)</p>
</td></tr>
<tr><td><code id="efp_+3A_vcov">vcov</code></td>
<td>
<p>a function to extract the covariance matrix for the coefficients
of the fitted model (only for <code>"RE"</code> and <code>"ME"</code>).</p>
</td></tr>
<tr><td><code id="efp_+3A_...">...</code></td>
<td>
<p><em>currently not used</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>type</code> is one of <code>"Rec-CUSUM"</code>, <code>"OLS-CUSUM"</code>,
<code>"Rec-MOSUM"</code> or <code>"OLS-MOSUM"</code> the function <code>efp</code> will return a
one-dimensional empirical process of sums of residuals. Either it will be based
on recursive residuals or on OLS residuals and the process will contain
CUmulative SUMs or MOving SUMs of residuals in a certain data window.
For the MOSUM and ME processes all estimations are done for the
observations in a moving data window, whose size is determined by <code>h</code> and
which is shifted over the whole sample.
</p>
<p>If <code>type</code> is either <code>"RE"</code> or <code>"ME"</code> a
<em>k</em>-dimensional process will be returned, if <em>k</em> is the number of
regressors in the model, as it is based on recursive OLS estimates of the
regression coefficients or moving OLS estimates respectively. The recursive
estimates test is also called fluctuation test, therefore setting <code>type</code>
to <code>"fluctuation"</code> was used to specify it in earlier versions of
strucchange. It still can be used now, but will be forced to <code>"RE"</code>.
</p>
<p>If <code>type</code> is <code>"Score-CUSUM"</code> or <code>"Score-MOSUM"</code> a <em>k+1</em>-dimensional
process will be returned, one for each score of the regression coefficients and one for
the scores of the variance. The process gives the decorrelated cumulative sums of the ML
scores (in a Gaussian model) or first order conditions respectively (in an OLS framework).
</p>
<p>If there is a single structural change point <code class="reqn">t^*</code>, the recursive CUSUM path
starts to depart from its mean 0 at <code class="reqn">t^*</code>. The Brownian bridge type paths
will have their respective peaks around <code class="reqn">t^*</code>.
The Brownian bridge increments type paths should have a strong change at <code class="reqn">t^*</code>.
</p>
<p>The function <code><a href="base.html#topic+plot">plot</a></code>
has a method to plot the empirical fluctuation process; with
<code>sctest</code> the corresponding test on structural change can be
performed.
</p>


<h3>Value</h3>

<p><code>efp</code> returns a list of class <code>"efp"</code> with components including:
</p>
<table>
<tr><td><code>process</code></td>
<td>
<p>the fitted empirical fluctuation process of class
<code>"ts"</code> or <code>"mts"</code> respectively,</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a string with the <code>type</code> of the process fitted,</p>
</td></tr>
<tr><td><code>nreg</code></td>
<td>
<p>the number of regressors,</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>the number of observations,</p>
</td></tr>
<tr><td><code>par</code></td>
<td>
<p>the bandwidth <code>h</code> used.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brown R.L., Durbin J., Evans J.M. (1975), Techniques for
testing constancy of regression relationships over time, <em>Journal of the
Royal Statistical Society</em>, B, <b>37</b>, 149-163.
</p>
<p>Chu C.-S., Hornik K., Kuan C.-M. (1995), MOSUM tests for parameter
constancy, <em>Biometrika</em>, <b>82</b>, 603-617.
</p>
<p>Chu C.-S., Hornik K., Kuan C.-M. (1995), The moving-estimates test for
parameter stability, <em>Econometric Theory</em>, <b>11</b>, 669-720.
</p>
<p>Hansen B. (1992), Testing for Parameter Instability in Linear Models,
<em>Journal of Policy Modeling</em>, <b>14</b>, 517-533.
</p>
<p>Hjort N.L., Koning A. (2002), Tests for Constancy of Model Parameters
Over Time, <em>Nonparametric Statistics</em>, <b>14</b>, 113-132.
</p>
<p>Kr\&quot;amer W., Ploberger W., Alt R. (1988), Testing for structural change in
dynamic models, <em>Econometrica</em>, <b>56</b>, 1355-1369.
</p>
<p>Kuan C.-M., Hornik K. (1995), The generalized fluctuation test: A
unifying view, <em>Econometric Reviews</em>, <b>14</b>, 135 - 161.
</p>
<p>Kuan C.-M., Chen (1994), Implementing the fluctuation and moving estimates
tests in dynamic econometric models, <em>Economics Letters</em>, <b>44</b>,
235-239.
</p>
<p>Ploberger W., Kr\&quot;amer W. (1992), The CUSUM test with OLS residuals,
<em>Econometrica</em>, <b>60</b>, 271-285.
</p>
<p>Zeileis A., Leisch F., Hornik K., Kleiber C. (2002), <code>strucchange</code>:
An R Package for Testing for Structural Change in Linear Regression Models,
<em>Journal of Statistical Software</em>, <b>7</b>(2), 1-38.
doi: <a href="https://doi.org/10.18637/jss.v007.i02">10.18637/jss.v007.i02</a>.
</p>
<p>Zeileis A. (2005), A Unified Approach to Structural Change Tests Based on
ML Scores, F Statistics, and OLS Residuals. <em>Econometric Reviews</em>, <b>24</b>,
445&ndash;466. doi: <a href="https://doi.org/10.1080/07474930500406053">10.1080/07474930500406053</a>.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi: <a href="https://doi.org/10.1016/j.csda.2005.07.001">10.1016/j.csda.2005.07.001</a>.
</p>
<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for Parameter
Instability, <em>Statistica Neerlandica</em>, <b>61</b>, 488&ndash;508.
doi: <a href="https://doi.org/10.1111/j.1467-9574.2007.00371.x">10.1111/j.1467-9574.2007.00371.x</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gefp">gefp</a></code>, <code><a href="#topic+plot.efp">plot.efp</a></code>, <code><a href="#topic+print.efp">print.efp</a></code>,
<code><a href="#topic+sctest.efp">sctest.efp</a></code>, <code><a href="#topic+boundary.efp">boundary.efp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

## test the null hypothesis that the annual flow remains constant
## over the years
## compute OLS-based CUSUM process and plot
## with standard and alternative boundaries
ocus.nile &lt;- efp(Nile ~ 1, type = "OLS-CUSUM")
plot(ocus.nile)
plot(ocus.nile, alpha = 0.01, alt.boundary = TRUE)
## calculate corresponding test statistic
sctest(ocus.nile)

## UK Seatbelt data: a SARIMA(1,0,0)(1,0,0)_12 model
## (fitted by OLS) is used and reveals (at least) two
## breakpoints - one in 1973 associated with the oil crisis and
## one in 1983 due to the introduction of compulsory
## wearing of seatbelts in the UK.
data("UKDriverDeaths")
seatbelt &lt;- log10(UKDriverDeaths)
seatbelt &lt;- cbind(seatbelt, lag(seatbelt, k = -1), lag(seatbelt, k = -12))
colnames(seatbelt) &lt;- c("y", "ylag1", "ylag12")
seatbelt &lt;- window(seatbelt, start = c(1970, 1), end = c(1984,12))
plot(seatbelt[,"y"], ylab = expression(log[10](casualties)))

## use RE process
re.seat &lt;- efp(y ~ ylag1 + ylag12, data = seatbelt, type = "RE")
plot(re.seat)
plot(re.seat, functional = NULL)
sctest(re.seat)
</code></pre>

<hr>
<h2 id='efpFunctional'>Functionals for Fluctuation Processes</h2><span id='topic+efpFunctional'></span><span id='topic+simulateBMDist'></span><span id='topic+maxBM'></span><span id='topic+maxBB'></span><span id='topic+maxBMI'></span><span id='topic+maxBBI'></span><span id='topic+maxL2BB'></span><span id='topic+meanL2BB'></span><span id='topic+rangeBM'></span><span id='topic+rangeBB'></span><span id='topic+rangeBMI'></span><span id='topic+rangeBBI'></span>

<h3>Description</h3>

<p>Computes an object for aggregating, plotting and testing
empirical fluctuation processes.</p>


<h3>Usage</h3>

<pre><code class='language-R'>efpFunctional(functional = list(comp = function(x) max(abs(x)), time = max),
  boundary = function(x) rep(1, length(x)),
  computePval = NULL, computeCritval = NULL,
  plotProcess = NULL, lim.process = "Brownian bridge",
  nobs = 10000, nrep = 50000, nproc = 1:20, h = 0.5,
  probs = c(0:84/100, 850:1000/1000))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efpFunctional_+3A_functional">functional</code></td>
<td>
<p>either a function for aggregating fluctuation processes
or a list with two functions names <code>"comp"</code> and <code>"time"</code>.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_boundary">boundary</code></td>
<td>
<p>a boundary function.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_computepval">computePval</code></td>
<td>
<p>a function for computing p values. If neither
<code>computePval</code> nor <code>computeCritval</code> are specified
critical values are simulated with settings as specified below.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_computecritval">computeCritval</code></td>
<td>
<p>a function for computing critical values. If neither
<code>computePval</code> nor <code>computeCritval</code> are specified
critical values are simulated with settings as specified below.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_plotprocess">plotProcess</code></td>
<td>
<p>a function for plotting the empirical process,
if set to <code>NULL</code> a suitable function is set up.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_lim.process">lim.process</code></td>
<td>
<p>a string specifying the limiting process.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_nobs">nobs</code></td>
<td>
<p>integer specifying the number of observations of each
Brownian motion simulated.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_nrep">nrep</code></td>
<td>
<p>integer specifying the number of replications.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_nproc">nproc</code></td>
<td>
<p>integer specifying for which number of processes
Brownian motions should be simulated. If set to <code>NULL</code> only
<code>nproc = 1</code> is used and all other values are derived from
a Bonferroni correction.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_h">h</code></td>
<td>
<p>bandwidth parameter for increment processes.</p>
</td></tr>
<tr><td><code id="efpFunctional_+3A_probs">probs</code></td>
<td>
<p>numeric vector specifying for which probabilities 
critical values should be tabulated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>efpFunctional</code> computes an object of class <code>"efpFunctional"</code>
which then knows how to do inference based on empirical fluctuation processes
(currently only for <code><a href="#topic+gefp">gefp</a></code> objects and not yet for <code><a href="#topic+efp">efp</a></code>
objects) and how to visualize the corresponding processes.   
</p>
<p><code>efpFunctional</code>s for many frequently used test statistics are provided:
<code><a href="#topic+maxBB">maxBB</a></code> for the double maximum statistic, <code><a href="#topic+meanL2BB">meanL2BB</a></code> for the Cramer-von Mises
statistic, or <code>rangeBB</code> for the range statistic. Furthermore, <code><a href="#topic+supLM">supLM</a></code>
generates an object of class <code>"efpFunctional"</code> for a certain trimming parameter,
see the examples. More details can be found in Zeileis (2006). Based on
Merkle, Fan, and Zeileis (2014), further <code>efpFunctional</code> generators for
aggregating along (ordered) categorical variables have been added:
<code><a href="#topic+catL2BB">catL2BB</a></code>, <code><a href="#topic+ordL2BB">ordL2BB</a></code>, <code><a href="#topic+ordwmax">ordwmax</a></code>.
</p>
<p>For setting up an <code>efpFunctional</code>, the functions
<code>computeStatistic</code>, <code>computePval</code>, and <code>plotProcess</code> need to be
supplied. These should have the following interfaces:
<code>computeStatistic</code> should take a single argument which is the process
itself, i.e., essentially a n x k matrix where n is the number of
observations and k the number of processes (regressors).
<code>computePval</code> should take two arguments: a scalar test statistic and the
number of processes k.
<code>plotProcess</code> should take two arguments: an object of class <code>"gefp"</code>
and <code>alpha</code> the level of significance for any boundaries or critical
values to be visualized.
</p>


<h3>Value</h3>

<p><code>efpFunctional</code> returns a list of class <code>"efpFunctional"</code> with components including:
</p>
<table>
<tr><td><code>plotProcess</code></td>
<td>
<p>a function for plotting empirical fluctuation processes,</p>
</td></tr>
<tr><td><code>computeStatistic</code></td>
<td>
<p>a function for computing a test statistic from an empirical fluctuation process,</p>
</td></tr>
<tr><td><code>computePval</code></td>
<td>
<p>a function for computing the corresponding p value,</p>
</td></tr>
<tr><td><code>computeCritval</code></td>
<td>
<p>a function for computing critical values.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Merkle E.C., Zeileis A. (2013), Tests of Measurement Invariance without Subgroups:
A Generalization of Classical Methods. <em>Psychometrika</em>, <b>78</b>(1), 59&ndash;82.
doi:10.1007/S11336-012-9302-4
</p>
<p>Merkle E.C., Fan J., Zeileis A. (2014), Testing for Measurement Invariance with
Respect to an Ordinal Variable. <em>Psychometrika</em>, <b>79</b>(4), 569&ndash;584.
doi:10.1007/S11336-013-9376-7.
</p>
<p>Zeileis A. (2005), A Unified Approach to Structural Change Tests Based on
ML Scores, F Statistics, and OLS Residuals. <em>Econometric Reviews</em>, <b>24</b>,
445&ndash;466. doi:10.1080/07474930500406053.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi:10.1016/j.csda.2005.07.001.
</p>
<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for Parameter
Instability, <em>Statistica Neerlandica</em>, <b>61</b>, 488&ndash;508.
doi:10.1111/j.1467-9574.2007.00371.x.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gefp">gefp</a></code>, <code><a href="#topic+supLM">supLM</a></code>, <code><a href="#topic+catL2BB">catL2BB</a></code>, <code><a href="#topic+sctest.default">sctest.default</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("BostonHomicide")
gcus &lt;- gefp(homicides ~ 1, family = poisson, vcov = kernHAC,
  data = BostonHomicide)
plot(gcus, functional = meanL2BB)	 
gcus
sctest(gcus, functional = meanL2BB)

y &lt;- rnorm(1000)
x1 &lt;- runif(1000)
x2 &lt;- runif(1000)

## supWald statistic computed by Fstats()
fs &lt;- Fstats(y ~ x1 + x2, from = 0.1)
plot(fs)
sctest(fs)

## compare with supLM statistic
scus &lt;- gefp(y ~ x1 + x2, fit = lm)
plot(scus, functional = supLM(0.1))
sctest(scus, functional = supLM(0.1))

## seatbelt data
data("UKDriverDeaths")
seatbelt &lt;- log10(UKDriverDeaths)
seatbelt &lt;- cbind(seatbelt, lag(seatbelt, k = -1), lag(seatbelt, k = -12))
colnames(seatbelt) &lt;- c("y", "ylag1", "ylag12")
seatbelt &lt;- window(seatbelt, start = c(1970, 1), end = c(1984,12))

scus.seat &lt;- gefp(y ~ ylag1 + ylag12, data = seatbelt)

## double maximum test
plot(scus.seat)
## range test
plot(scus.seat, functional = rangeBB)
## Cramer-von Mises statistic (Nyblom-Hansen test)
plot(scus.seat, functional = meanL2BB)
## supLM test
plot(scus.seat, functional = supLM(0.1))
</code></pre>

<hr>
<h2 id='Fstats'>F Statistics</h2><span id='topic+Fstats'></span><span id='topic+print.Fstats'></span>

<h3>Description</h3>

<p>Computes a series of F statistics for a specified data window.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Fstats(formula, from = 0.15, to = NULL, data = list(), vcov. = NULL)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Fstats_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be tested</p>
</td></tr>
<tr><td><code id="Fstats_+3A_from">from</code>, <code id="Fstats_+3A_to">to</code></td>
<td>
<p>numeric. If <code>from</code> is smaller than 1 they are
interpreted as percentages of data and by default <code>to</code> is taken to be
1 - <code>from</code>. F statistics will be calculated for the observations
<code>(n*from):(n*to)</code>, when <code>n</code> is the number of observations in the
model. If <code>from</code> is greater than 1 it is interpreted to be the index
and <code>to</code> defaults to <code>n - from</code>. If <code>from</code> is a vector with
two elements, then <code>from</code> and <code>to</code> are interpreted as time
specifications like in <code><a href="stats.html#topic+ts">ts</a></code>, see also the examples.</p>
</td></tr>
<tr><td><code id="Fstats_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By
default the variables are taken from the environment which <code>Fstats</code> is
called from.</p>
</td></tr>
<tr><td><code id="Fstats_+3A_vcov.">vcov.</code></td>
<td>
<p>a function to extract the covariance matrix
for the coefficients of a fitted model of class <code>"lm"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For every potential change point in <code>from:to</code> a F statistic (Chow
test statistic) is computed. For this an OLS model is fitted for the
observations before and after the potential change point, i.e. <code>2k</code>
parameters have to be estimated, and the error sum of squares is computed (ESS).
Another OLS model for all observations with a restricted sum of squares (RSS) is
computed, hence <code>k</code> parameters have to be estimated here. If <code>n</code> is 
the number of observations and <code>k</code> the number of regressors in the model,
the formula is:
</p>
<p style="text-align: center;"><code class="reqn">F = \frac{(RSS - ESS)}{ESS/(n - 2 k)}</code>
</p>

<p>Note that this statistic has an asymptotic chi-squared distribution with k degrees of
freedom and (under the assumption of normality) F/k has an exact F distribution
with k and n - 2k degrees of freedom.
</p>


<h3>Value</h3>

<p><code>Fstats</code> returns an object of class <code>"Fstats"</code>, which contains
mainly a time series of F statistics. The function <code><a href="base.html#topic+plot">plot</a></code> has a
method to plot the F statistics or the
corresponding p values; with <code>sctest</code> a
supF-, aveF- or expF-test on structural change can be performed.</p>


<h3>References</h3>

<p>Andrews D.W.K. (1993), Tests for parameter instability and structural
change with unknown change point, <em>Econometrica</em>, <b>61</b>, 821-856.
</p>
<p>Hansen B. (1992), Tests for parameter instability in regressions with I(1)
processes, <em>Journal of Business &amp; Economic Statistics</em>, <b>10</b>, 321-335.
</p>
<p>Hansen B. (1997), Approximate asymptotic p values for structural-change
tests, <em>Journal of Business &amp; Economic Statistics</em>, <b>15</b>, 60-67. </p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.Fstats">plot.Fstats</a></code>, <code><a href="#topic+sctest.Fstats">sctest.Fstats</a></code>,
<code><a href="#topic+boundary.Fstats">boundary.Fstats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

## test the null hypothesis that the annual flow remains constant
## over the years
fs.nile &lt;- Fstats(Nile ~ 1)
plot(fs.nile)
sctest(fs.nile)
## visualize the breakpoint implied by the argmax of the F statistics
plot(Nile)
lines(breakpoints(fs.nile))

## UK Seatbelt data: a SARIMA(1,0,0)(1,0,0)_12 model
## (fitted by OLS) is used and reveals (at least) two
## breakpoints - one in 1973 associated with the oil crisis and
## one in 1983 due to the introduction of compulsory
## wearing of seatbelts in the UK.
data("UKDriverDeaths")
seatbelt &lt;- log10(UKDriverDeaths)
seatbelt &lt;- cbind(seatbelt, lag(seatbelt, k = -1), lag(seatbelt, k = -12))
colnames(seatbelt) &lt;- c("y", "ylag1", "ylag12")
seatbelt &lt;- window(seatbelt, start = c(1970, 1), end = c(1984,12))
plot(seatbelt[,"y"], ylab = expression(log[10](casualties)))

## compute F statistics for potential breakpoints between
## 1971(6) (corresponds to from = 0.1) and 1983(6) (corresponds to
## to = 0.9 = 1 - from, the default)
## compute F statistics
fs &lt;- Fstats(y ~ ylag1 + ylag12, data = seatbelt, from = 0.1)
## this gives the same result
fs &lt;- Fstats(y ~ ylag1 + ylag12, data = seatbelt, from = c(1971, 6),
             to = c(1983, 6))
## plot the F statistics
plot(fs, alpha = 0.01)
## plot F statistics with aveF boundary
plot(fs, aveF = TRUE)
## perform the expF test
sctest(fs, type = "expF")
</code></pre>

<hr>
<h2 id='gefp'>Generalized Empirical M-Fluctuation Processes</h2><span id='topic+gefp'></span><span id='topic+print.gefp'></span><span id='topic+sctest.gefp'></span><span id='topic+plot.gefp'></span><span id='topic+time.gefp'></span><span id='topic+print.gefp'></span>

<h3>Description</h3>

<p>Computes an empirical M-fluctuation process 
from the scores of a fitted model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gefp(..., fit = glm, scores = estfun, vcov = NULL,
  decorrelate = TRUE, sandwich = TRUE, order.by = NULL,
  fitArgs = NULL, parm = NULL, data = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gefp_+3A_...">...</code></td>
<td>
<p>specification of some model which is passed together
with <code>data</code> to the <code>fit</code> function: <code>fm &lt;- fit(..., data = data)</code>.
If <code>fit</code> is set to <code>NULL</code> the first argument <code>...</code>
is assumed to be already the fitted model <code>fm</code>
(all other arguments in <code>...</code> are ignored and a warning
is issued in this case).</p>
</td></tr>
<tr><td><code id="gefp_+3A_fit">fit</code></td>
<td>
<p>a model fitting function, typically <code><a href="stats.html#topic+lm">lm</a></code>,
<code><a href="stats.html#topic+glm">glm</a></code> or <code><a href="MASS.html#topic+rlm">rlm</a></code>.</p>
</td></tr>
<tr><td><code id="gefp_+3A_scores">scores</code></td>
<td>
<p>a function which extracts the scores or estimating
function from the fitted object: <code>scores(fm)</code>.</p>
</td></tr>
<tr><td><code id="gefp_+3A_vcov">vcov</code></td>
<td>
<p>a function to extract the covariance matrix
for the coefficients of the fitted model:
<code>vcov(fm, order.by = order.by, data = data)</code>.</p>
</td></tr>
<tr><td><code id="gefp_+3A_decorrelate">decorrelate</code></td>
<td>
<p>logical. Should the process be decorrelated?</p>
</td></tr>
<tr><td><code id="gefp_+3A_sandwich">sandwich</code></td>
<td>
<p>logical. Is the function <code>vcov</code> the full sandwich
estimator or only the meat?</p>
</td></tr>
<tr><td><code id="gefp_+3A_order.by">order.by</code></td>
<td>
<p>Either a vector <code>z</code> or a formula with a single explanatory
variable like <code>~ z</code>. The observations in the model
are ordered by the size of <code>z</code>. If set to <code>NULL</code> (the
default) the observations are assumed to be ordered (e.g., a
time series).</p>
</td></tr>
<tr><td><code id="gefp_+3A_fitargs">fitArgs</code></td>
<td>
<p>List of additional arguments which could be passed to
the <code>fit</code> function. Usually, this is not needed and <code>...</code>
will be sufficient to pass arguments to <code>fit</code>.</p>
</td></tr>
<tr><td><code id="gefp_+3A_parm">parm</code></td>
<td>
<p>integer or character specifying the component of the estimating
functions which should be used (by default all components are used).</p>
</td></tr>
<tr><td><code id="gefp_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the <code>...</code>
specification and the <code>order.by</code> model. By default the variables are
taken from the environment which <code>gefp</code> is called from.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>gefp</code> returns a list of class <code>"gefp"</code> with components including:
</p>
<table>
<tr><td><code>process</code></td>
<td>
<p>the fitted empirical fluctuation process of class
<code>"zoo"</code>,</p>
</td></tr>
<tr><td><code>nreg</code></td>
<td>
<p>the number of regressors,</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p>the number of observations,</p>
</td></tr>
<tr><td><code>fit</code></td>
<td>
<p>the fit function used,</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the scores function used,</p>
</td></tr>
<tr><td><code>fitted.model</code></td>
<td>
<p>the fitted model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zeileis A. (2005), A Unified Approach to Structural Change Tests Based on
ML Scores, F Statistics, and OLS Residuals. <em>Econometric Reviews</em>, <b>24</b>,
445&ndash;466. doi:10.1080/07474930500406053.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi:10.1016/j.csda.2005.07.001.
</p>
<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for Parameter
Instability, <em>Statistica Neerlandica</em>, <b>61</b>, 488&ndash;508.
doi:10.1111/j.1467-9574.2007.00371.x.
</p>
<p>Zeileis A., Shah A., Patnaik I. (2010), Testing, Monitoring, and Dating Structural
Changes in Exchange Rate Regimes, <em>Computational Statistics and Data Analysis</em>,
<b>54</b>(6), 1696&ndash;1706. doi:10.1016/j.csda.2009.12.005.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efp">efp</a></code>, <code><a href="#topic+efpFunctional">efpFunctional</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("BostonHomicide")
gcus &lt;- gefp(homicides ~ 1, family = poisson, vcov = kernHAC,
	     data = BostonHomicide)
plot(gcus, aggregate = FALSE)	 
gcus
sctest(gcus)
</code></pre>

<hr>
<h2 id='GermanM1'>German M1 Money Demand</h2><span id='topic+GermanM1'></span><span id='topic+historyM1'></span><span id='topic+monitorM1'></span>

<h3>Description</h3>

<p>German M1 money demand.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("GermanM1")</code></pre>


<h3>Format</h3>

<p><code>GermanM1</code> is a data frame containing 12 quarterly time series
from 1961(1) to 1995(4) and two further variables. <code>historyM1</code>
is the subset of <code>GermanM1</code> up to 1990(2), i.e., the data before
the German monetary unification on 1990-06-01. <code>monitorM1</code>
is the complement of <code>historyM1</code>, i.e., the data after
the unification. All three data frames contain the variables
</p>

<dl>
<dt>m</dt><dd><p>time series. Logarithm of real M1 per capita,</p>
</dd>
<dt>p</dt><dd><p>time series. Logarithm of a price index,</p>
</dd>
<dt>y</dt><dd><p>time series. Logarithm of real per capita gross
national product,</p>
</dd>
<dt>R</dt><dd><p>time series. Long-run interest rate,</p>
</dd>
<dt>dm</dt><dd><p>time series. First differences of <code>m</code>,</p>
</dd>
<dt>dy2</dt><dd><p>time series. First differences of lag 2 of <code>y</code>,</p>
</dd>
<dt>dR</dt><dd><p>time series. First differences of <code>R</code>,</p>
</dd>
<dt>dR1</dt><dd><p>time series. First differences of lag 1 of <code>R</code>,</p>
</dd>
<dt>dp</dt><dd><p>time series. First differences of <code>p</code>,</p>
</dd>
<dt>m1</dt><dd><p>time series. Lag 1 of <code>m</code>,</p>
</dd>
<dt>y1</dt><dd><p>time series. Lag 1 of <code>y</code>,</p>
</dd>
<dt>R1</dt><dd><p>time series. Lag 1 of <code>R</code>,</p>
</dd>
<dt>season</dt><dd><p>factor coding the seasonality,</p>
</dd>
<dt>ecm.res</dt><dd><p>vector containing the OLS residuals of
the Lütkepohl et al. (1999) model fitted in the history
period.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Lütkepohl et al. (1999) investigate the linearity and
stability of German M1 money demand: they find a stable regression relation
for the time before the monetary union on 1990-06-01 but a clear structural
instability afterwards.
</p>
<p>Zeileis et al. (2005) use a model with
<code>ecm.res</code> instead of <code>m1</code>, <code>y1</code> and <code>R1</code>, which
leads to equivalent results in the history period but slightly
different results in the monitoring period. The reason for the
replacement is that stationary regressors are needed for the
structural change tests. See references and the examples below for
more details.
</p>


<h3>Source</h3>

<p>The data is provided by the German central bank and is
available online in the data archive of the Journal of Applied
Econometrics
<a href="http://qed.econ.queensu.ca/jae/1999-v14.5/lutkepohl-terasvirta-wolters/">http://qed.econ.queensu.ca/jae/1999-v14.5/lutkepohl-terasvirta-wolters/</a>.</p>


<h3>References</h3>

<p>Lütkepohl H., Teräsvirta T., Wolters J. (1999), Investigating
Stability and Linearity of a German M1 Money Demand Function,
<em>Journal of Applied Econometrics</em>, <b>14</b>, 511-525.
</p>
<p>Zeileis A., Leisch F., Kleiber C., Hornik K. (2005), Monitoring
Structural Change in Dynamic Econometric Models,
<em>Journal of Applied Econometrics</em>, <b>20</b>, 99&ndash;121.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("GermanM1")
## Lütkepohl et al. (1999) use the following model
LTW.model &lt;- dm ~ dy2 + dR + dR1 + dp + m1 + y1 + R1 + season
## Zeileis et al. (2005) use
M1.model &lt;- dm ~ dy2 + dR + dR1 + dp + ecm.res + season


## historical tests
ols &lt;- efp(LTW.model, data = GermanM1, type = "OLS-CUSUM")
plot(ols)
re &lt;- efp(LTW.model, data = GermanM1, type = "fluctuation")
plot(re)
fs &lt;- Fstats(LTW.model, data = GermanM1, from = 0.1)
plot(fs)

## monitoring
M1 &lt;- historyM1
ols.efp &lt;- efp(M1.model, type = "OLS-CUSUM", data = M1)
newborder &lt;- function(k) 1.5778*k/118
ols.mefp &lt;- mefp(ols.efp, period = 2)
ols.mefp2 &lt;- mefp(ols.efp, border = newborder)
M1 &lt;- GermanM1
ols.mon &lt;- monitor(ols.mefp)
ols.mon2 &lt;- monitor(ols.mefp2)
plot(ols.mon)
lines(boundary(ols.mon2), col = 2)

## dating
bp &lt;- breakpoints(LTW.model, data = GermanM1)
summary(bp)
plot(bp)

plot(fs)
lines(confint(bp))
</code></pre>

<hr>
<h2 id='Grossarl'>Marriages, Births and Deaths in Grossarl</h2><span id='topic+Grossarl'></span>

<h3>Description</h3>

<p>Data about the number of marriages, illegitimate and legitimate
births, and deaths in the Austrian Alpine village Grossarl during the
18th and 19th century.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Grossarl")</code></pre>


<h3>Format</h3>

<p><code>Grossarl</code> is a data frame containing 6 annual time series
(1700 - 1899), 3 factors coding policy interventions and 1 vector
with the year (plain numeric).
</p>

<dl>
<dt>marriages</dt><dd><p>time series. Number of marriages,</p>
</dd>
<dt>illegitimate</dt><dd><p>time series. Number of illegitimate births,</p>
</dd>
<dt>legitimate</dt><dd><p>time series. Number of legitimate births,</p>
</dd>
<dt>legitimate</dt><dd><p>time series. Number of deaths,</p>
</dd>
<dt>fraction</dt><dd><p>time series. Fraction of illegitimate births,</p>
</dd>
<dt>lag.marriages</dt><dd><p>time series. Number of marriages in the previous year,</p>
</dd>
<dt>politics</dt><dd><p>ordered factor coding 4 different political regimes,</p>
</dd>
<dt>morals</dt><dd><p>ordered factor coding 5 different moral regulations,</p>
</dd>
<dt>nuptiality</dt><dd><p>ordered factor coding 5 different marriage restrictions,</p>
</dd>
<dt>year</dt><dd><p>numeric. Year of observation.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data frame contains historical demographic data from
Grossarl, a village in the Alpine region of Salzburg, Austria,
during the 18th and 19th century.
During this period, the total population of Grossarl did not vary much on the whole,
with the very exception of the period of the protestant emigrations
in 1731/32.
</p>
<p>Especially
during the archbishopric, moral interventions aimed at lowering
the proportion of illegitimate baptisms. For details see the references.</p>


<h3>Source</h3>

<p>Parish registers provide the basic demographic series of baptisms 
and burials (which is almost equivalent to births and deaths in the study
area) and marriages. For more information see Veichtlbauer et al. (2006).</p>


<h3>References</h3>

<p>Veichtlbauer O., Zeileis A., Leisch F. (2006),
The Impact Of Policy Interventions on a Pre-Industrial
Population System in the Austrian Alps, forthcoming.
</p>
<p>Zeileis A., Veichtlbauer O. (2002), Policy Interventions
Affecting Illegitimacy in Preindustrial Austria:
A Structural Change Analysis, In R. Dutter (ed.),
<em>Festschrift 50 Jahre \&quot;Osterreichische Statistische Gesellschaft</em>, 133-146,
\&quot;Osterreichische Statistische Gesellschaft.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Grossarl")

## time series of births, deaths, marriages
###########################################

with(Grossarl, plot(cbind(deaths, illegitimate + legitimate, marriages),
  plot.type = "single", col = grey(c(0.7, 0, 0)), lty = c(1, 1, 3),
  lwd = 1.5, ylab = "annual Grossarl series"))
legend("topright", c("deaths", "births", "marriages"), col = grey(c(0.7, 0, 0)),
  lty = c(1, 1, 3), bty = "n")

## illegitimate births
######################
## lm + MOSUM
plot(Grossarl$fraction)
fm.min &lt;- lm(fraction ~ politics, data = Grossarl)
fm.ext &lt;- lm(fraction ~ politics + morals + nuptiality + marriages,
  data = Grossarl)
lines(ts(fitted(fm.min), start = 1700), col = 2)
lines(ts(fitted(fm.ext), start = 1700), col = 4)
mos.min &lt;- efp(fraction ~ politics, data = Grossarl, type = "OLS-MOSUM")
mos.ext &lt;- efp(fraction ~ politics + morals + nuptiality + marriages,
  data = Grossarl, type = "OLS-MOSUM")
plot(mos.min)
lines(mos.ext, lty = 2)

## dating
bp &lt;- breakpoints(fraction ~ 1, data = Grossarl, h = 0.1)
summary(bp)
## RSS, BIC, AIC
plot(bp)
plot(0:8, AIC(bp), type = "b")

## probably use 5 or 6 breakpoints and compare with
## coding of the factors as used by us
##
## politics                   1803      1816 1850
## morals      1736 1753 1771 1803
## nuptiality                 1803 1810 1816      1883
##
## m = 5            1753 1785           1821 1856 1878
## m = 6       1734 1754 1785           1821 1856 1878
##              6    2    5              1    4    3

## fitted models
coef(bp, breaks = 6)
plot(Grossarl$fraction)
lines(fitted(bp, breaks = 6), col = 2)
lines(ts(fitted(fm.ext), start = 1700), col = 4)


## marriages
############
## lm + MOSUM
plot(Grossarl$marriages)
fm.min &lt;- lm(marriages ~ politics, data = Grossarl)
fm.ext &lt;- lm(marriages ~ politics + morals + nuptiality, data = Grossarl)
lines(ts(fitted(fm.min), start = 1700), col = 2)
lines(ts(fitted(fm.ext), start = 1700), col = 4)
mos.min &lt;- efp(marriages ~ politics, data = Grossarl, type = "OLS-MOSUM")
mos.ext &lt;- efp(marriages ~ politics + morals + nuptiality, data = Grossarl,
  type = "OLS-MOSUM")
plot(mos.min)
lines(mos.ext, lty = 2)

## dating
bp &lt;- breakpoints(marriages ~ 1, data = Grossarl, h = 0.1)
summary(bp)
## RSS, BIC, AIC
plot(bp)
plot(0:8, AIC(bp), type = "b")

## probably use 3 or 4 breakpoints and compare with
## coding of the factors as used by us
##
## politics                   1803      1816 1850
## morals      1736 1753 1771 1803
## nuptiality                 1803 1810 1816      1883
##
## m = 3       1738                     1813      1875
## m = 4       1738      1794           1814      1875
##              2         4              1         3

## fitted models
coef(bp, breaks = 4)
plot(Grossarl$marriages)
lines(fitted(bp, breaks = 4), col = 2)
lines(ts(fitted(fm.ext), start = 1700), col = 4)
</code></pre>

<hr>
<h2 id='logLik.breakpoints'>Log Likelihood and Information Criteria for Breakpoints</h2><span id='topic+logLik.breakpoints'></span><span id='topic+logLik.breakpointsfull'></span><span id='topic+AIC.breakpointsfull'></span><span id='topic+LWZ'></span><span id='topic+LWZ.breakpointsfull'></span><span id='topic+LWZ.breakpoints'></span>

<h3>Description</h3>

<p>Computation of log likelihood and AIC type information criteria
for partitions given by breakpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'breakpointsfull'
logLik(object, breaks = NULL, ...)
## S3 method for class 'breakpointsfull'
AIC(object, breaks = NULL, ..., k = 2)
## S3 method for class 'breakpointsfull'
LWZ(object, ...)
## S3 method for class 'breakpoints'
LWZ(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik.breakpoints_+3A_object">object</code></td>
<td>
<p>an object of class <code>"breakpoints"</code> or <code>"breakpointsfull"</code>.</p>
</td></tr>
<tr><td><code id="logLik.breakpoints_+3A_breaks">breaks</code></td>
<td>
<p>if <code>object</code> is of class <code>"breakpointsfull"</code> the
number of breaks can be specified.</p>
</td></tr>
<tr><td><code id="logLik.breakpoints_+3A_...">...</code></td>
<td>
<p>for <code>LWZ</code>, parameters passed to <code>AIC.breakpointsfull</code>. Unused in <code>logLik</code> and <code>AIC</code>.</p>
</td></tr>
<tr><td><code id="logLik.breakpoints_+3A_k">k</code></td>
<td>
<p>the penalty parameter to be used, the default <code>k = 2</code>
is the classical AIC, <code>k = log(n)</code> gives the BIC, <code>k = 0.299 * log(n)^2.1</code> gives the LWZ,
if <code>n</code> is the number of observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As for linear models the log likelihood is computed on a normal model and
the degrees of freedom are the number of regression coefficients multiplied
by the number of segments plus the number of estimated breakpoints plus
1 for the error variance.
</p>
<p>If <code>AIC</code> or <code>LWZ</code> is applied to an object of class <code>"breakpointsfull"</code>
<code>breaks</code> can be a vector of integers and the AIC or LWZ for each corresponding
partition will be returned. By default the maximal number of breaks stored
in the <code>object</code> is used. See below for an example.
</p>


<h3>Value</h3>

<p>An object of class <code>"logLik"</code> or a simple vector containing
the AIC respectively.
</p>


<h3>References</h3>

<p>Liu, J., Wu, S., &amp; Zidek, J. V. (1997). On segmented multivariate regression. <em>Statistica Sinica</em>, 497-525.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+breakpoints">breakpoints</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Nile data with one breakpoint: the annual flows drop in 1898
## because the first Ashwan dam was built
data("Nile")
plot(Nile)

bp.nile &lt;- breakpoints(Nile ~ 1)
summary(bp.nile)
plot(bp.nile)

## BIC of partitions with 0 to 5 breakpoints
plot(0:5, AIC(bp.nile, k = log(bp.nile$nobs)), type = "b")
## AIC
plot(0:5, AIC(bp.nile), type = "b")
## LWZ
plot(0:5, LWZ(bp.nile), type = "b")

## BIC, AIC, LWZ, log likelihood of a single partition
bp.nile1 &lt;- breakpoints(bp.nile, breaks = 1)
AIC(bp.nile1, k = log(bp.nile1$nobs))
AIC(bp.nile1)
LWZ(bp.nile1)
logLik(bp.nile1)
</code></pre>

<hr>
<h2 id='magnitude'>Magnitudes of Breakpoints</h2><span id='topic+magnitude'></span><span id='topic+magnitude.breakpointsfull'></span>

<h3>Description</h3>

<p>Computes magnitude statistics for breakpoints.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'breakpointsfull'
magnitude(object,
  interval = 0.1, breaks = NULL, component = "trend", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="magnitude_+3A_object">object</code></td>
<td>
<p>an object of class <code>"breakpointsfull"</code> as computed by
<code><a href="#topic+breakpoints">breakpoints</a></code>.</p>
</td></tr>
<tr><td><code id="magnitude_+3A_interval">interval</code></td>
<td>
<p>the (one-side) interval over which to compute the magnitude for the columns
<code>RMSD</code> and <code>MAD</code>. If below 1, fraction of the time series length,
otherwise number of observations.</p>
</td></tr>
<tr><td><code id="magnitude_+3A_breaks">breaks</code></td>
<td>
<p>how many breaks to use or which statistic to use for estimating it,
see <code><a href="#topic+breakpoints">breakpoints</a></code> for details. If <code>NULL</code>, uses the defaults.</p>
</td></tr>
<tr><td><code id="magnitude_+3A_component">component</code></td>
<td>
<p>which covariate(s) used for fitting the <code>breakpointsfull</code>
object to use for magnitude estimation. The components are additive.</p>
</td></tr>
<tr><td><code id="magnitude_+3A_...">...</code></td>
<td>
<p><em>ignored</em></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The breakpoint magnitude is estimated using several statistics:
the difference (<em>diff</em>) in the fitted value immediately <em>before</em>
and <em>after</em> the break, and the root mean squared deviation (<em>RMSD</em>),
mean absolute deviation (<em>MAD</em>) and mean deviation (<em>MD</em>) between the
fitted values of the model preceding the break extrapolated over <em>interval</em>
samples after the break, and vice versa. RMSD and MAD should be more robust
estimators of magnitude compared to <em>diff</em>.
</p>


<h3>Value</h3>

<p>A list with the following elements, compatible with the magnitude format as output by <code><a href="bfast.html#topic+bfast">bfast</a></code>:
</p>

<dl>
<dt>Mag</dt><dd><p>a matrix containing the magnitude estimates (in columns) for each breakpoint (in rows),</p>
</dd>
<dt>m.x</dt><dd><p>sample number at which the largest break was detected, twice</p>
</dd>
<dt>y.x</dt><dd><p>fitted values <em>before</em> and <em>after</em> the largest break</p>
</dd>
<dt>Magnitude</dt><dd><p>the maximum <em>diff</em> magnitude of the largest break</p>
</dd>
<dt>Time</dt><dd><p>time of the largest break (same as <code>m.x</code>, but single value)</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+breakpoints">breakpoints</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Nile)

trend &lt;- 1:length(Nile)
bp.nile &lt;- breakpoints(Nile ~ trend)

# The trend component is default, set "component" to the
# name of your coviariate(s), if it is different.
magnitude(bp.nile)
</code></pre>

<hr>
<h2 id='mefp'>Monitoring of Empirical Fluctuation Processes</h2><span id='topic+mefp'></span><span id='topic+mefp.formula'></span><span id='topic+mefp.matrix'></span><span id='topic+mefp.efp'></span><span id='topic+print.mefp'></span><span id='topic+monitor'></span><span id='topic+monitor.matrix'></span>

<h3>Description</h3>

<p>Online monitoring of structural breaks in a linear regression model. A
sequential fluctuation test based on parameter estimates or OLS residuals
signals structural breaks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
mefp(formula, type = c("OLS-CUSUM", "OLS-MOSUM", "RE", "ME",
    "fluctuation"), data, h = 1, alpha = 0.05,
    functional = c("max", "range"), period = 10,
    tolerance = .Machine$double.eps^0.5, CritvalTable = NULL,
    rescale = NULL, border = NULL, ...)
    
## S3 method for class 'matrix'
mefp(obj, y, type = c("OLS-CUSUM", "OLS-MOSUM", "RE", "ME",
    "fluctuation"), h = 1, alpha = 0.05,
    functional = c("max", "range"), period = 10,
    tolerance = .Machine$double.eps^0.5, CritvalTable = NULL,
    rescale = NULL, border = NULL, ...)
    
## S3 method for class 'efp'
mefp(obj, alpha=0.05, functional = c("max", "range"),
    period = 10, tolerance = .Machine$double.eps^0.5,
    CritvalTable = NULL, rescale = NULL, border = NULL, ...)

monitor(obj, data = NULL, verbose = TRUE)
monitor.matrix(obj, X, y, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mefp_+3A_formula">formula</code></td>
<td>
<p>specification of the linear regression model by a <code>formula</code>.</p>
</td></tr>
<tr><td><code id="mefp_+3A_obj">obj</code></td>
<td>
<p>object of class <code>"efp"</code> (for <code>mefp</code>),
<code>"mefp"</code> (for <code>monitor</code>),
or the regression matrix <em>X</em> (for <code>mefp.matrix</code>.</p>
</td></tr>
<tr><td><code id="mefp_+3A_x">X</code></td>
<td>
<p>regression matrix <em>X</em>.</p>
</td></tr>
<tr><td><code id="mefp_+3A_y">y</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code id="mefp_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By
default the variables are taken from the environment which <code>efp</code> is
called from.</p>
</td></tr>
<tr><td><code id="mefp_+3A_type">type</code></td>
<td>
<p>specifies which type of fluctuation process will be
computed.</p>
</td></tr>
<tr><td><code id="mefp_+3A_h">h</code></td>
<td>
<p>(only used for MOSUM/ME processes). A numeric scalar from interval
(0,1) specifying the size of the data window relative to the sample
size.</p>
</td></tr>
<tr><td><code id="mefp_+3A_alpha">alpha</code></td>
<td>
<p>Significance level of the test, i.e., probability of
type I error.</p>
</td></tr>
<tr><td><code id="mefp_+3A_functional">functional</code></td>
<td>
<p>Determines if maximum or range of parameter
differences is used as statistic.</p>
</td></tr>
<tr><td><code id="mefp_+3A_period">period</code></td>
<td>
<p>(only used for MOSUM/ME processes). Maximum time (relative
to the history period) that will be monitored. Default is 10 times
the history period.</p>
</td></tr>
<tr><td><code id="mefp_+3A_tolerance">tolerance</code></td>
<td>
<p>Tolerance for numeric <code>==</code> comparisons.</p>
</td></tr>
<tr><td><code id="mefp_+3A_critvaltable">CritvalTable</code></td>
<td>
<p>Table of critical values, this table is
interpolated to get critical values
for arbitrary <code>alpha</code>s. The default depends on the <code>type</code>
of fluctuation process (pre-computed tables are available for all
types). <em>This argument is under development.</em></p>
</td></tr>
<tr><td><code id="mefp_+3A_rescale">rescale</code></td>
<td>
<p>If <code>TRUE</code> the estimates will be standardized by
the regressor matrix of the corresponding subsample similar to
Kuan &amp; Chen (1994); if <code>FALSE</code> the historic regressor matrix will
be used. The default is to rescale the monitoring processes of type
<code>"ME"</code> but not of <code>"RE"</code>.</p>
</td></tr>
<tr><td><code id="mefp_+3A_border">border</code></td>
<td>
<p>An optional user-specified border function for the
empirical process. <em>This argument is under development.</em></p>
</td></tr>
<tr><td><code id="mefp_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, signal breaks by text output.</p>
</td></tr>
<tr><td><code id="mefp_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+mefp">mefp</a></code> creates an object of class <code>"mefp"</code> either
from a model formula or from an object of class <code>"efp"</code>. In
addition to the arguments of <code><a href="#topic+efp">efp</a></code>, the type of statistic
and a significance level for the monitoring must be specified. The
monitoring itself is performed by <code>monitor</code>, which can be
called arbitrarily often on objects of class <code>"mefp"</code>. If new
data have arrived, then the empirical fluctuation process is computed
for the new data. If the process crosses the boundaries corresponding
to the significance level <code>alpha</code>, a structural break is detected
(and signaled).
</p>
<p>The typical usage is to initialize the monitoring by creation of an
object of class <code>"mefp"</code> either using a formula or an
<code>"efp"</code> object. Data available at this stage are considered the
<em>history sample</em>, which is kept fixed during the complete
monitoring process, and may not contain any structural changes.
</p>
<p>Subsequent calls to <code>monitor</code> perform a sequential test of the
null hypothesis of no structural change in new data against the
general alternative of changes in one or more of the coefficients of
the regression model.
</p>
<p>The recursive
estimates test is also called fluctuation test, therefore setting <code>type</code>
to <code>"fluctuation"</code> was used to specify it in earlier versions of
strucchange. It still can be used now, but will be forced to <code>"RE"</code>
</p>


<h3>Value</h3>

<p>An object of class <code>mefp</code> that includes components such as:
</p>
<table>
<tr><td><code>breakpoint</code></td>
<td>
<p>index of the detected breakpoint, <code>NA</code> otherwise,</p>
</td></tr>
<tr><td><code>process</code></td>
<td>
<p>a matrix denoting the coefficients of the empirical fluctuation process,</p>
</td></tr>
<tr><td><code>computeEmpProc</code></td>
<td>
<p>a function to compute the empirical process
based on <code>newcoef</code>, <code>Q</code> and <code>k</code> for ME/RE and
<code>X</code> and <code>y</code> for OLS-MOSUM/OLS-CUSUM.</p>
</td></tr>
<tr><td><code>last</code></td>
<td>
<p>number of observations,</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a string with the <code>type</code> of the process fitted,</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the significance level.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Leisch F., Hornik K., Kuan C.-M. (2000), Monitoring
Structural Changes with the Generalized Fluctuation Test,
<em>Econometric Theory</em>, <b>16</b>, 835&ndash;854.
</p>
<p>Zeileis A., Leisch F., Kleiber C., Hornik K. (2005), Monitoring
Structural Change in Dynamic Econometric Models,
<em>Journal of Applied Econometrics</em>, <b>20</b>, 99&ndash;121.
doi:10.1002/jae.776.
</p>
<p>Zeileis A. (2005), A Unified Approach to Structural Change Tests Based on
ML Scores, F Statistics, and OLS Residuals. <em>Econometric Reviews</em>, <b>24</b>,
445&ndash;466. doi:10.1080/07474930500406053.
</p>
<p>Zeileis A., Shah A., Patnaik I. (2010), Testing, Monitoring, and Dating Structural
Changes in Exchange Rate Regimes, <em>Computational Statistics and Data Analysis</em>,
<b>54</b>(6), 1696&ndash;1706. doi:10.1016/j.csda.2009.12.005.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.mefp">plot.mefp</a></code>, <code><a href="#topic+boundary.mefp">boundary.mefp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>df1 &lt;- data.frame(y=rnorm(300))
df1[150:300,"y"] &lt;- df1[150:300,"y"]+1

## use the first 50 observations as history period
e1 &lt;- efp(y~1, data=df1[1:50,,drop=FALSE], type="ME", h=1)
me1 &lt;- mefp(e1, alpha=0.05)

## the same in one function call
me1 &lt;- mefp(y~1, data=df1[1:50,,drop=FALSE], type="ME", h=1,
              alpha=0.05)

## monitor the 50 next observations
me2 &lt;- monitor(me1, data=df1[1:100,,drop=FALSE])
plot(me2)

# and now monitor on all data
me3 &lt;- monitor(me2, data=df1)
plot(me3)


## Load dataset "USIncExp" with income and expenditure in the US
## and choose a suitable subset for the history period
data("USIncExp")
USIncExp3 &lt;- window(USIncExp, start=c(1969,1), end=c(1971,12))
## initialize the monitoring with the formula interface
me.mefp &lt;- mefp(expenditure~income, type="ME", rescale=TRUE,
                   data=USIncExp3, alpha=0.05)

## monitor the new observations for the year 1972
USIncExp3 &lt;- window(USIncExp, start=c(1969,1), end=c(1972,12))
me.mefp &lt;- monitor(me.mefp)

## monitor the new data for the years 1973-1976
USIncExp3 &lt;- window(USIncExp, start=c(1969,1), end=c(1976,12))
me.mefp &lt;- monitor(me.mefp)
plot(me.mefp, functional = NULL)
</code></pre>

<hr>
<h2 id='PhillipsCurve'>UK Phillips Curve Equation Data</h2><span id='topic+PhillipsCurve'></span>

<h3>Description</h3>

<p>Macroeconomic time series from the United Kingdom with variables
for estimating the Phillips curve equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("PhillipsCurve")</code></pre>


<h3>Format</h3>

<p>A multivariate annual time series from 1857 to 1987 with the columns
</p>

<dl>
<dt>p</dt><dd><p>Logarithm of the consumer price index,</p>
</dd>
<dt>w</dt><dd><p>Logarithm of nominal wages,</p>
</dd>
<dt>u</dt><dd><p>Unemployment rate,</p>
</dd>
<dt>dp</dt><dd><p>First differences of <code>p</code>,</p>
</dd>
<dt>dw</dt><dd><p>First differences of <code>w</code>,</p>
</dd>
<dt>du</dt><dd><p>First differences of <code>u</code></p>
</dd>
<dt>u1</dt><dd><p>Lag 1 of <code>u</code>,</p>
</dd>
<dt>dp1</dt><dd><p>Lag 1 of <code>dp</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The data is available online in the data archive of the
Journal of Applied Econometrics
<a href="http://qed.econ.queensu.ca/jae/2003-v18.1/bai-perron/">http://qed.econ.queensu.ca/jae/2003-v18.1/bai-perron/</a>.</p>


<h3>References</h3>

<p>Alogoskoufis G.S., Smith R. (1991), The Phillips Curve, the Persistence of
Inflation, and the Lucas Critique: Evidence from Exchange Rate Regimes,
<em>American Economic Review</em>, <b>81</b>, 1254-1275.
</p>
<p>Bai J., Perron P. (2003), Computation and Analysis of Multiple Structural Change
Models, <em>Journal of Applied Econometrics</em>, <b>18</b>, 1-22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load and plot data
data("PhillipsCurve")
uk &lt;- window(PhillipsCurve, start = 1948)
plot(uk[, "dp"])

## AR(1) inflation model
## estimate breakpoints
bp.inf &lt;- breakpoints(dp ~ dp1, data = uk, h = 8)
plot(bp.inf)
summary(bp.inf)

## fit segmented model with three breaks
fac.inf &lt;- breakfactor(bp.inf, breaks = 2, label = "seg")
fm.inf &lt;- lm(dp ~ 0 + fac.inf/dp1, data = uk)
summary(fm.inf)

## Results from Table 2 in Bai &amp; Perron (2003):
## coefficient estimates
coef(bp.inf, breaks = 2)
## corresponding standard errors
sqrt(sapply(vcov(bp.inf, breaks = 2), diag))
## breakpoints and confidence intervals
confint(bp.inf, breaks = 2)

## Phillips curve equation
## estimate breakpoints
bp.pc &lt;- breakpoints(dw ~ dp1 + du + u1, data = uk, h = 5, breaks = 5)
## look at RSS and BIC
plot(bp.pc)
summary(bp.pc)

## fit segmented model with three breaks
fac.pc &lt;- breakfactor(bp.pc, breaks = 2, label = "seg")
fm.pc &lt;- lm(dw ~ 0 + fac.pc/dp1 + du + u1, data = uk)
summary(fm.pc)

## Results from Table 3 in Bai &amp; Perron (2003):
## coefficient estimates
coef(fm.pc)
## corresponding standard errors
sqrt(diag(vcov(fm.pc)))
## breakpoints and confidence intervals
confint(bp.pc, breaks = 2, het.err = FALSE)
</code></pre>

<hr>
<h2 id='plot.efp'>Plot Empirical Fluctuation Process</h2><span id='topic+plot.efp'></span><span id='topic+lines.efp'></span>

<h3>Description</h3>

<p>Plot and lines method for objects of class <code>"efp"</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'efp'
plot(x, alpha = 0.05, alt.boundary = FALSE, boundary = TRUE,
    functional = "max", main = NULL,  ylim = NULL,
    ylab = "Empirical fluctuation process", ...)
## S3 method for class 'efp'
lines(x, functional = "max", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.efp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"efp"</code>.</p>
</td></tr>
<tr><td><code id="plot.efp_+3A_alpha">alpha</code></td>
<td>
<p>numeric from interval (0,1) indicating the confidence level for
which the boundary of the corresponding test will be computed.</p>
</td></tr>
<tr><td><code id="plot.efp_+3A_alt.boundary">alt.boundary</code></td>
<td>
<p>logical. If set to <code>TRUE</code> alternative boundaries
(instead of the standard linear boundaries) will be plotted (for CUSUM
processes only).</p>
</td></tr>
<tr><td><code id="plot.efp_+3A_boundary">boundary</code></td>
<td>
<p>logical. If set to <code>FALSE</code> the boundary will be computed
but not plotted.</p>
</td></tr>
<tr><td><code id="plot.efp_+3A_functional">functional</code></td>
<td>
<p>indicates which functional should be applied to the
process before plotting and which boundaries should be used. If set to <code>NULL</code>
a multiple process with boundaries for the <code>"max"</code> functional is plotted.
For more details see below.</p>
</td></tr>
<tr><td><code id="plot.efp_+3A_main">main</code>, <code id="plot.efp_+3A_ylim">ylim</code>, <code id="plot.efp_+3A_ylab">ylab</code>, <code id="plot.efp_+3A_...">...</code></td>
<td>
<p>high-level <code><a href="base.html#topic+plot">plot</a></code> function
parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots are available for the <code>"max"</code> functional for all process types.
For Brownian bridge type processes the maximum or mean squared Euclidean norm
(<code>"maxL2"</code> and <code>"meanL2"</code>) can be used for aggregating before plotting.
No plots are available for the <code>"range"</code> functional.
</p>
<p>Alternative boundaries that are proportional to the standard deviation
of the corresponding limiting process are available for processes with Brownian
motion or Brownian bridge limiting processes.
</p>


<h3>Value</h3>

<p><code><a href="#topic+efp">efp</a></code> returns an object of class <code>"efp"</code> which inherits
from the class <code>"ts"</code> or <code>"mts"</code> respectively. The function
<code><a href="base.html#topic+plot">plot</a></code> has a method to plot the
empirical fluctuation process; with <code>sctest</code> the corresponding test for
structural change can be performed.</p>


<h3>References</h3>

<p>Brown R.L., Durbin J., Evans J.M. (1975), Techniques for
testing constancy of regression relationships over time, <em>Journal of the
Royal Statistical Society</em>, B, <b>37</b>, 149-163.
</p>
<p>Chu C.-S., Hornik K., Kuan C.-M. (1995), MOSUM tests for parameter
constancy, <em>Biometrika</em>, <b>82</b>, 603-617.
</p>
<p>Chu C.-S., Hornik K., Kuan C.-M. (1995), The moving-estimates test for
parameter stability, <em>Econometric Theory</em>, <b>11</b>, 669-720.
</p>
<p>Krämer W., Ploberger W., Alt R. (1988), Testing for structural change in
dynamic models, <em>Econometrica</em>, <b>56</b>, 1355-1369.
</p>
<p>Kuan C.-M., Hornik K. (1995), The generalized fluctuation test: A
unifying view, <em>Econometric Reviews</em>, <b>14</b>, 135 - 161.
</p>
<p>Kuan C.-M., Chen (1994), Implementing the fluctuation and moving estimates
tests in dynamic econometric models, <em>Economics Letters</em>, <b>44</b>,
235-239.
</p>
<p>Ploberger W., Krämer W. (1992), The CUSUM test with OLS residuals,
<em>Econometrica</em>, <b>60</b>, 271-285.
</p>
<p>Zeileis A., Leisch F., Hornik K., Kleiber C. (2002), <code>strucchange</code>:
An R Package for Testing for Structural Change in Linear Regression Models,
<em>Journal of Statistical Software</em>, <b>7</b>(2), 1-38.
doi: <a href="https://doi.org/10.18637/jss.v007.i02">10.18637/jss.v007.i02</a>.
</p>
<p>Zeileis A. (2004), Alternative Boundaries for CUSUM Tests,
<em>Statistical Papers</em>, <b>45</b>, 123&ndash;131.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efp">efp</a></code>, <code><a href="#topic+boundary.efp">boundary.efp</a></code>,
<code><a href="#topic+sctest.efp">sctest.efp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load dataset "nhtemp" with average yearly temperatures in New Haven
data("nhtemp")
## plot the data
plot(nhtemp)

## test the model null hypothesis that the average temperature remains
## constant over the years
## compute Rec-CUSUM fluctuation process
temp.cus &lt;- efp(nhtemp ~ 1)
## plot the process
plot(temp.cus, alpha = 0.01)
## and calculate the test statistic
sctest(temp.cus)

## compute (recursive estimates) fluctuation process
## with an additional linear trend regressor
lin.trend &lt;- 1:60
temp.me &lt;- efp(nhtemp ~ lin.trend, type = "fluctuation")
## plot the bivariate process
plot(temp.me, functional = NULL)
## and perform the corresponding test
sctest(temp.me)
</code></pre>

<hr>
<h2 id='plot.Fstats'>Plot F Statistics</h2><span id='topic+plot.Fstats'></span><span id='topic+lines.Fstats'></span>

<h3>Description</h3>

<p>Plotting method for objects of class <code>"Fstats"</code></p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Fstats'
plot(x, pval = FALSE, asymptotic = FALSE, alpha = 0.05,
    boundary = TRUE, aveF = FALSE, xlab = "Time", ylab = NULL,
    ylim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.Fstats_+3A_x">x</code></td>
<td>
<p>an object of class <code>"Fstats"</code>.</p>
</td></tr>
<tr><td><code id="plot.Fstats_+3A_pval">pval</code></td>
<td>
<p>logical. If set to <code>TRUE</code> the corresponding p values instead
of the original F statistics will be plotted.</p>
</td></tr>
<tr><td><code id="plot.Fstats_+3A_asymptotic">asymptotic</code></td>
<td>
<p>logical. If set to <code>TRUE</code> the asymptotic (chi-square)
distribution instead of the exact (F) distribution will be used to compute
the p values (only if <code>pval</code> is <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="plot.Fstats_+3A_alpha">alpha</code></td>
<td>
<p>numeric from interval (0,1) indicating the confidence level for
which the boundary of the supF test will be computed.</p>
</td></tr>
<tr><td><code id="plot.Fstats_+3A_boundary">boundary</code></td>
<td>
<p>logical. If set to <code>FALSE</code> the boundary will be computed
but not plotted.</p>
</td></tr>
<tr><td><code id="plot.Fstats_+3A_avef">aveF</code></td>
<td>
<p>logical. If set to <code>TRUE</code> the boundary of the aveF test will
be plotted. As this is a boundary for the mean of the F statistics rather
than for the F statistics themselves a dashed line for the mean of the F
statistics will also be plotted.</p>
</td></tr>
<tr><td><code id="plot.Fstats_+3A_xlab">xlab</code>, <code id="plot.Fstats_+3A_ylab">ylab</code>, <code id="plot.Fstats_+3A_ylim">ylim</code>, <code id="plot.Fstats_+3A_...">...</code></td>
<td>
<p>high-level <code><a href="base.html#topic+plot">plot</a></code> function parameters.</p>
</td></tr></table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>References</h3>

<p>Andrews D.W.K. (1993), Tests for parameter instability and structural
change with unknown change point, <em>Econometrica</em>, <b>61</b>, 821-856.
</p>
<p>Hansen B. (1992), Tests for parameter instability in regressions with I(1)
processes, <em>Journal of Business &amp; Economic Statistics</em>, <b>10</b>, 321-335.
</p>
<p>Hansen B. (1997), Approximate asymptotic p values for structural-change
tests, <em>Journal of Business &amp; Economic Statistics</em>, <b>15</b>, 60-67. </p>


<h3>See Also</h3>

<p><code><a href="#topic+Fstats">Fstats</a></code>, <code><a href="#topic+boundary.Fstats">boundary.Fstats</a></code>,
<code><a href="#topic+sctest.Fstats">sctest.Fstats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load dataset "nhtemp" with average yearly temperatures in New Haven
data("nhtemp")
## plot the data
plot(nhtemp)

## test the model null hypothesis that the average temperature remains
## constant over the years for potential break points between 1941
## (corresponds to from = 0.5) and 1962 (corresponds to to = 0.85)
## compute F statistics
fs &lt;- Fstats(nhtemp ~ 1, from = 0.5, to = 0.85)
## plot the F statistics
plot(fs, alpha = 0.01)
## and the corresponding p values
plot(fs, pval = TRUE, alpha = 0.01)
## perform the aveF test
sctest(fs, type = "aveF")
</code></pre>

<hr>
<h2 id='plot.mefp'>Plot Methods for mefp Objects</h2><span id='topic+plot.mefp'></span><span id='topic+lines.mefp'></span>

<h3>Description</h3>

<p>This is a method of the generic <code><a href="base.html#topic+plot">plot</a></code> function for
for <code>"mefp"</code> objects as returned by <code><a href="#topic+mefp">mefp</a></code> or
<code><a href="#topic+monitor">monitor</a></code>. It plots the empirical fluctuation process (or a
functional thereof) as a time series plot, and includes boundaries
corresponding to the significance level of the monitoring procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mefp'
plot(x, boundary = TRUE, functional = "max", main = NULL,
    ylab = "Empirical fluctuation process", ylim = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mefp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"mefp"</code>.</p>
</td></tr>
<tr><td><code id="plot.mefp_+3A_boundary">boundary</code></td>
<td>
<p>if <code>FALSE</code>, plotting of boundaries is suppressed.</p>
</td></tr>
<tr><td><code id="plot.mefp_+3A_functional">functional</code></td>
<td>
<p>indicates which functional should be applied to a
multivariate empirical process. If set to <code>NULL</code> all dimensions
of the process (one process per coefficient in the linear model) are
plotted. </p>
</td></tr>
<tr><td><code id="plot.mefp_+3A_main">main</code>, <code id="plot.mefp_+3A_ylab">ylab</code>, <code id="plot.mefp_+3A_ylim">ylim</code>, <code id="plot.mefp_+3A_...">...</code></td>
<td>
<p>high-level <code><a href="base.html#topic+plot">plot</a></code> function parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for side effects.</p>


<h3>See Also</h3>

<p><code><a href="#topic+mefp">mefp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>df1 &lt;- data.frame(y=rnorm(300))
df1[150:300,"y"] &lt;- df1[150:300,"y"]+1
me1 &lt;- mefp(y~1, data=df1[1:50,,drop=FALSE], type="ME", h=1,
              alpha=0.05)
me2 &lt;- monitor(me1, data=df1)

plot(me2)
</code></pre>

<hr>
<h2 id='RealInt'>US Ex-post Real Interest Rate</h2><span id='topic+RealInt'></span>

<h3>Description</h3>

<p>US ex-post real interest rate: the three-month treasury bill
deflated by the CPI inflation rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("RealInt")</code></pre>


<h3>Format</h3>

<p>A quarterly time series from 1961(1) to 1986(3).
</p>


<h3>Source</h3>

<p>The data is available online in the data archive of the
Journal of Applied Econometrics
<a href="http://qed.econ.queensu.ca/jae/2003-v18.1/bai-perron/">http://qed.econ.queensu.ca/jae/2003-v18.1/bai-perron/</a>.</p>


<h3>References</h3>

<p>Bai J., Perron P. (2003), Computation and Analysis of Multiple Structural Change
Models, <em>Journal of Applied Econometrics</em>, <b>18</b>, 1-22.
</p>
<p>Zeileis A., Kleiber C. (2005), Validating Multiple Structural Change Models -
A Case Study. Journal of Applied Econometrics, <b>20</b>, 685-690.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## load and plot data
data("RealInt")
plot(RealInt)

## estimate breakpoints
bp.ri &lt;- breakpoints(RealInt ~ 1, h = 15)
plot(bp.ri)
summary(bp.ri)

## fit segmented model with three breaks
fac.ri &lt;- breakfactor(bp.ri, breaks = 3, label = "seg")
fm.ri &lt;- lm(RealInt ~ 0 + fac.ri)
summary(fm.ri)

## setup kernel HAC estimator
vcov.ri &lt;- function(x, ...) kernHAC(x, kernel = "Quadratic Spectral",
  prewhite = 1, approx = "AR(1)", ...)

## Results from Table 1 in Bai &amp; Perron (2003):
## coefficient estimates
coef(bp.ri, breaks = 3)
## corresponding standard errors
sapply(vcov(bp.ri, breaks = 3, vcov = vcov.ri), sqrt)
## breakpoints and confidence intervals
confint(bp.ri, breaks = 3, vcov = vcov.ri)

## Visualization
plot(RealInt)
lines(as.vector(time(RealInt)), fitted(fm.ri), col = 4)
lines(confint(bp.ri, breaks = 3, vcov = vcov.ri))
</code></pre>

<hr>
<h2 id='recresid'>Recursive Residuals</h2><span id='topic+recresid'></span><span id='topic+recresid.default'></span><span id='topic+recresid.formula'></span><span id='topic+recresid.lm'></span>

<h3>Description</h3>

<p>A generic function for computing the recursive residuals
(standardized one step prediction errors) of a linear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
recresid(x, y, start = ncol(x) + 1, end = nrow(x),
  tol = sqrt(.Machine$double.eps)/ncol(x), qr.tol = 1e-7, ...)
## S3 method for class 'formula'
recresid(formula, data = list(), ...)
## S3 method for class 'lm'
recresid(x, data = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recresid_+3A_x">x</code>, <code id="recresid_+3A_y">y</code>, <code id="recresid_+3A_formula">formula</code></td>
<td>
<p>specification of the linear regression model:
either by a regressor matrix <code>x</code> and a response variable <code>y</code>,
or by a <code>formula</code> or by a fitted object <code>x</code> of class <code>"lm"</code>.</p>
</td></tr>
<tr><td><code id="recresid_+3A_start">start</code>, <code id="recresid_+3A_end">end</code></td>
<td>
<p>integer. Index of the first and last observation, respectively,
for which recursive residuals should be computed. By default, the maximal
range is selected.</p>
</td></tr>
<tr><td><code id="recresid_+3A_tol">tol</code></td>
<td>
<p>numeric. A relative tolerance for precision of recursive
coefficient estimates, see details.</p>
</td></tr>
<tr><td><code id="recresid_+3A_qr.tol">qr.tol</code></td>
<td>
<p>numeric. The <code>tol</code>erance passed to <code><a href="stats.html#topic+lm.fit">lm.fit</a></code>
for detecting linear dependencies.</p>
</td></tr>
<tr><td><code id="recresid_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By
default the variables are taken from the environment which <code>recresid</code> is
called from. Specifying <code>data</code> might also be necessary when applying
<code>recresid</code> to a fitted model of class <code>"lm"</code> if this does not
contain the regressor matrix and the response.</p>
</td></tr>
<tr><td><code id="recresid_+3A_...">...</code></td>
<td>
<p><em>currently not used.</em></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Recursive residuals are standardized one-step-ahead prediction errors.
Under the usual assumptions for the linear regression model they
are (asymptotically) normal and i.i.d. (see Brown, Durbin, Evans, 1975,
for details).
</p>
<p>The default method computes the initial coefficient estimates via QR
decomposition, using <code><a href="stats.html#topic+lm.fit">lm.fit</a></code>. In subsequent steps, the
updating formula provided by Brown, Durbin, Evans (1975) is employed.
To avoid numerical instabilities in the first steps (with typically
small sample sizes), the QR solution is computed for comparison.
When the relative difference (assessed bey <code><a href="base.html#topic+all.equal">all.equal</a></code>)
between the two solutions falls below <code>tol</code>, only the updating
formula is used in subsequent steps.
</p>


<h3>Value</h3>

<p>A vector containing the recursive residuals.
</p>


<h3>References</h3>

<p>Brown R.L., Durbin J., Evans J.M. (1975), Techniques for
testing constancy of regression relationships over time, <em>Journal of the
Royal Statistical Society</em>, B, <b>37</b>, 149-163.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efp">efp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rnorm(100) + rep(c(0, 2), each = 50)
rr &lt;- recresid(x ~ 1)
plot(cumsum(rr), type = "l")

plot(efp(x ~ 1, type = "Rec-CUSUM"))
</code></pre>

<hr>
<h2 id='root.matrix'>Root of a Matrix</h2><span id='topic+root.matrix'></span>

<h3>Description</h3>

<p>Computes the root of a symmetric and positive semidefinite matrix.</p>


<h3>Usage</h3>

<pre><code class='language-R'>root.matrix(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="root.matrix_+3A_x">X</code></td>
<td>
<p>a symmetric and positive semidefinite matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a symmetric matrix of same dimensions as <code>X</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(c(1,2,2,8), ncol=2)
test &lt;- root.matrix(X)
## control results
X
test %*% test
</code></pre>

<hr>
<h2 id='root.matrix.crossprod'>Root of X^TX</h2><span id='topic+root.matrix.crossprod'></span>

<h3>Description</h3>

<p>Computes the root of the Gramian X^TX.</p>


<h3>Usage</h3>

<pre><code class='language-R'>root.matrix.crossprod(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="root.matrix.crossprod_+3A_x">X</code></td>
<td>
<p>a matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a symmetric matrix <code>V</code> where <code>V^2</code> equals <code>X^TX</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100
p &lt;- 3
X &lt;- matrix(rnorm(n*p),nrow=n, ncol=p)
test &lt;- root.matrix.crossprod(X)
## control results
t(X) %*% X
test %*% test
</code></pre>

<hr>
<h2 id='scPublications'>Structural Change Publications</h2><span id='topic+scPublications'></span>

<h3>Description</h3>

<p>Bibliographic information about papers related to structural change and
changepoints published in 27 different econometrics and statistics 
journals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("scPublications")</code></pre>


<h3>Format</h3>

<p>A data frame containing information on 835 structural change papers in 9 variables.
</p>

<dl>
<dt>author</dt><dd><p>character. Author(s) of the paper.</p>
</dd>
<dt>title</dt><dd><p>character. Title of the paper.</p>
</dd>
<dt>journal</dt><dd><p>factor. In which journal was the paper published?</p>
</dd>
<dt>year</dt><dd><p>numeric. Year of publication.</p>
</dd>
<dt>volume</dt><dd><p>numeric. Journal volume.</p>
</dd>
<dt>issue</dt><dd><p>character. Issue within the journal volume.</p>
</dd>
<dt>bpage</dt><dd><p>numeric. Page on which the paper begins.</p>
</dd>
<dt>epage</dt><dd><p>numeric. Page on which the paper ends.</p>
</dd>
<dt>type</dt><dd><p>factor. Is the journal an econometrics or statistics journal?</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data set <code>scPublications</code> includes
bibliographic information about publications related to structural change and obtained
from the &lsquo;ISI Web of Science&rsquo;. The query was based on the &lsquo;Science Citation Index Expanded&rsquo;
and &lsquo;Social Sciences Citation Index&rsquo; (for the full range of years available: 1900-2006 and
1956-2006, respectively). The &lsquo;Source Title&rsquo; was restricted to the 27 journals
in the data frame and the &lsquo;Topic&rsquo; to be one of the following:
structural change, structural break, structural stability, structural instability,
parameter instability, parameter stability, parameter constancy, change point,
changepoint, change-point, breakpoint, break-point, break point, CUSUM, MOSUM.
Additionally, the famous CUSUM paper of Brown, Durbin and Evans (1975) was added
manually to <code>scPublications</code> (because it did not match the query above).
</p>


<h3>Source</h3>

<p>ISI Web of Science at <a href="http://www.webofknowledge.com/">http://www.webofknowledge.com/</a>.
Queried by James Bullard.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## construct time series:
## number of sc publications in econometrics/statistics
data("scPublications")

## select years from 1987 and
## `most important' journals
pub &lt;- scPublications
pub &lt;- subset(pub, year &gt; 1986)
tab1 &lt;- table(pub$journal)
nam1 &lt;- names(tab1)[as.vector(tab1) &gt; 9] ## at least 10 papers
tab2 &lt;- sapply(levels(pub$journal), function(x) min(subset(pub, journal == x)$year))
nam2 &lt;- names(tab2)[as.vector(tab2) &lt; 1991] ## started at least in 1990
nam &lt;- nam1[nam1 %in% nam2]
pub &lt;- subset(pub, as.character(journal) %in% nam)
pub$journal &lt;- factor(pub$journal)
pub_data &lt;- pub

## generate time series
pub &lt;- with(pub, tapply(type, year, table))
pub &lt;- zoo(t(sapply(pub, cbind)), 1987:2006)
colnames(pub) &lt;- levels(pub_data$type)

## visualize
plot(pub, ylim = c(0, 35))
</code></pre>

<hr>
<h2 id='sctest'>Structural Change Tests</h2><span id='topic+sctest'></span>

<h3>Description</h3>

<p>Generic function for performing structural change tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sctest(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sctest_+3A_x">x</code></td>
<td>
<p>an object.</p>
</td></tr>
<tr><td><code id="sctest_+3A_...">...</code></td>
<td>
<p>arguments passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sctest</code> is a generic function for performing/extracting structural
change tests based on various types of objects. The <code>strucchange</code> package
provides various types of methods.
</p>
<p>First, structural change tests based on
F statistics in linear regression models (<code><a href="#topic+Fstats">Fstats</a></code>),
empirical fluctuation processes in linear regression models (<code><a href="#topic+efp">efp</a></code>),
and generalized empirical fluctuation processes in parametric models (<code><a href="#topic+gefp">gefp</a></code>)
are available in the corresponding <code>sctest</code> methods.
</p>
<p>Second, convenience interfaces for carrying out structural change tests
in linear regression models and general parametric models are provided in
<code><a href="#topic+sctest.formula">sctest.formula</a></code> and <code><a href="#topic+sctest.default">sctest.default</a></code>, respectively.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> containing:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the test statistic,</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the corresponding p value,</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string with the method used,</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string with the data name.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zeileis A., Leisch F., Hornik K., Kleiber C. (2002), <code>strucchange</code>:
An R Package for Testing for Structural Change in Linear Regression Models,
<em>Journal of Statistical Software</em>, <b>7</b>(2), 1-38.
doi: <a href="https://doi.org/10.18637/jss.v007.i02">10.18637/jss.v007.i02</a>.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi: <a href="https://doi.org/10.1016/j.csda.2005.07.001">10.1016/j.csda.2005.07.001</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sctest.formula">sctest.formula</a></code>, <code><a href="#topic+sctest.default">sctest.default</a></code>,
<code><a href="#topic+sctest.Fstats">sctest.Fstats</a></code>, <code><a href="#topic+sctest.efp">sctest.efp</a></code>, <code><a href="#topic+sctest.gefp">sctest.gefp</a></code></p>

<hr>
<h2 id='sctest.default'>Structural Change Tests in Parametric Models</h2><span id='topic+sctest.default'></span>

<h3>Description</h3>

<p>Performs model-based tests for structural change (or parameter instability)
in parametric models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sctest(x, order.by = NULL, functional = maxBB,
  vcov = NULL, scores = estfun, decorrelate = TRUE, sandwich = TRUE,
  parm = NULL, plot = FALSE, from = 0.1, to = NULL, nobs = NULL,
  nrep = 50000, width = 0.15, xlab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sctest.default_+3A_x">x</code></td>
<td>
<p>a model object. The model class can in principle be arbitrary
but needs to provide suitable methods for extracting the <code>scores</code>
and associated variance-covariance matrix <code>vcov</code>.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_order.by">order.by</code></td>
<td>
<p>either a vector <code>z</code> or a formula with a single explanatory
variable like <code>~ z</code>. The observations in the model
are ordered by the size of <code>z</code>. If set to <code>NULL</code> (the
default) the observations are assumed to be ordered (e.g., a
time series).</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_functional">functional</code></td>
<td>
<p>either a character specification of the functional
to be used or an <code><a href="#topic+efpFunctional">efpFunctional</a></code> object. For a list
of functionals see the details.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_vcov">vcov</code></td>
<td>
<p>a function to extract the covariance matrix
for the coefficients of the fitted model:
<code>vcov(x, order.by = order.by, data = data)</code>.
Alternatively, the character string <code>"info"</code>, for details see
below.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_scores">scores</code></td>
<td>
<p>a function which extracts the scores or estimating
function from the fitted object: <code>scores(x)</code>, by default
this is <code><a href="sandwich.html#topic+estfun">estfun</a></code>.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_decorrelate">decorrelate</code></td>
<td>
<p>logical. Should the process be decorrelated?</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_sandwich">sandwich</code></td>
<td>
<p>logical. Is the function <code>vcov</code> the full sandwich
estimator or only the meat?</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_parm">parm</code></td>
<td>
<p>integer or character specifying the component of the estimating
functions which should be used (by default all components are used).</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_plot">plot</code></td>
<td>
<p>logical. Should the result of the test also be visualized?</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_from">from</code>, <code id="sctest.default_+3A_to">to</code></td>
<td>
<p>numeric. In case the <code>functional</code> is <code>"supLM"</code>
(or equivalently <code>"maxLM"</code>), <code>from</code> and <code>to</code> can be
passed to the <code><a href="#topic+supLM">supLM</a></code> functional.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_nobs">nobs</code>, <code id="sctest.default_+3A_nrep">nrep</code></td>
<td>
<p>numeric. In case the <code>functional</code> is <code>"maxLMo"</code>,
<code>nobs</code> and <code>nrep</code> are passed to the <code><a href="#topic+catL2BB">catL2BB</a></code> functional.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_width">width</code></td>
<td>
<p>numeric. In case the <code>functional</code> is <code>"MOSUM"</code>,
the bandwidth <code>width</code> is passed to the <code><a href="#topic+maxMOSUM">maxMOSUM</a></code>
functional.</p>
</td></tr>
<tr><td><code id="sctest.default_+3A_xlab">xlab</code>, <code id="sctest.default_+3A_...">...</code></td>
<td>
<p>graphical parameters passed to the plot method (in case
<code>plot = TRUE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>sctest.default</code> is a convenience interface to <code><a href="#topic+gefp">gefp</a></code> for
structural change tests (or parameter instability tests) in general
parametric models. It proceeds in the following steps:
</p>

<ol>
<li><p> The generalized empirical fluctuation process (or score-based CUSUM process)
is computed via <code>scus &lt;- gefp(x, fit = NULL, ...)</code> where <code>...</code>
comprises the arguments <code>order.by</code>, <code>vcov</code>, <code>scores</code>, <code>decorrelate</code>,
<code>sandwich</code>, <code>parm</code> that are simply passed on to <code><a href="#topic+gefp">gefp</a></code>.
</p>
</li>
<li><p> The empirical fluctuation process is visualized (if <code>plot = TRUE</code>) via
<code>plot(scus, functional = functional, ...)</code>.
</p>
</li>
<li><p> The empirical fluctuation is assessed by the corresponding significance test
via <code>sctest(scus, functional = functional)</code>.
</p>
</li></ol>

<p>The main motivation for prociding the convenience interface is that these three
steps can be easily carried out in one go along with a two convenience options:
</p>

<ol>
<li><p> By default, the covariance is computed by an outer-product of gradients
estimator just as in <code>gefp</code>. This is always available based on the <code>scores</code>.
Additionally, by setting <code>vcov = "info"</code>, the corresponding information
matrix can be used. Then the average information is assumed to be provided by
the <code>vcov</code> method for the model class. (Note that this is only sensible
for models estimated by maximum likelihood.)
</p>
</li>
<li><p> Instead of providing the <code>functional</code> by an <code><a href="#topic+efpFunctional">efpFunctional</a></code>
object, the test labels employed by Merkle and Zeileis (2013) and Merkle, Fan,
and Zeileis (2013) can be used for convenience. Namely, for continuous numeric
orderings, the following functionals are available:
<code>functional = "DM"</code> or <code>"dmax"</code> provides the double-maximum test (<code><a href="#topic+maxBB">maxBB</a></code>).
<code>"CvM"</code> is the Cramer-von Mises functional <code><a href="#topic+meanL2BB">meanL2BB</a></code>.
<code>"supLM"</code> or equivalently <code>"maxLM"</code> is Andrews' supLM test
(<code><a href="#topic+supLM">supLM</a></code>). <code>"MOSUM"</code> or <code>"maxMOSUM"</code> is the MOSUM
functional (<code><a href="#topic+maxMOSUM">maxMOSUM</a></code>), and <code>"range"</code> is the range
functional <code><a href="#topic+rangeBB">rangeBB</a></code>. Furthermore, several functionals suitable
for (ordered) categorical <code>order.by</code> variables are provided:
<code>"LMuo"</code> is the unordered LM test (<code><a href="#topic+catL2BB">catL2BB</a></code>),
<code>"WDMo"</code> is the weighted double-maximum test for ordered variables
(<code><a href="#topic+ordwmax">ordwmax</a></code>), and <code>"maxLMo"</code> is the maxLM test for
ordered variables (<code><a href="#topic+ordL2BB">ordL2BB</a></code>).
</p>
</li></ol>

<p>The theoretical model class is introduced in Zeileis and Hornik (2007) with a
unifying view in Zeileis (2005), especially from an econometric perspective.
Zeileis (2006) introduces the underling computational tools <code>gefp</code> and
<code>efpFunctional</code>.
</p>
<p>Merkle and Zeileis (2013) discuss the methods in the context of measurement
invariance which is particularly relevant to psychometric models for cross section
data. Merkle, Fan, and Zeileis (2014) extend the results to ordered categorical
variables.
</p>
<p>Zeileis, Shah, and Patnaik (2013) provide a unifying discussion in the context
of time series methods, specifically in financial econometrics.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> containing:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the test statistic,</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the corresponding p value,</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string with the method used,</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string with the data name.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Merkle E.C., Zeileis A. (2013), Tests of Measurement Invariance without Subgroups:
A Generalization of Classical Methods. <em>Psychometrika</em>, <b>78</b>(1), 59&ndash;82.
doi:10.1007/S11336-012-9302-4
</p>
<p>Merkle E.C., Fan J., Zeileis A. (2014), Testing for Measurement Invariance with
Respect to an Ordinal Variable. <em>Psychometrika</em>, <b>79</b>(4), 569&ndash;584.
doi:10.1007/S11336-013-9376-7.
</p>
<p>Zeileis A. (2005), A Unified Approach to Structural Change Tests Based on
ML Scores, F Statistics, and OLS Residuals. <em>Econometric Reviews</em>, <b>24</b>,
445&ndash;466. doi:10.1080/07474930500406053.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi:10.1016/j.csda.2005.07.001.
</p>
<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for Parameter
Instability, <em>Statistica Neerlandica</em>, <b>61</b>, 488&ndash;508.
doi:10.1111/j.1467-9574.2007.00371.x.
</p>
<p>Zeileis A., Shah A., Patnaik I. (2010), Testing, Monitoring, and Dating Structural
Changes in Exchange Rate Regimes, <em>Computational Statistics and Data Analysis</em>,
<b>54</b>(6), 1696&ndash;1706. doi:10.1016/j.csda.2009.12.005.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gefp">gefp</a></code>, <code><a href="#topic+efpFunctional">efpFunctional</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Zeileis and Hornik (2007), Section 5.3, Figure 6
data("Grossarl")
m &lt;- glm(cbind(illegitimate, legitimate) ~ 1, family = binomial, data = Grossarl,
  subset = time(fraction) &lt;= 1800)
sctest(m, order.by = 1700:1800, functional = "CvM")
</code></pre>

<hr>
<h2 id='sctest.efp'>Generalized Fluctuation Tests</h2><span id='topic+sctest.efp'></span>

<h3>Description</h3>

<p>Performs a generalized fluctuation test.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'efp'
sctest(x, alt.boundary = FALSE,
    functional = c("max", "range", "maxL2", "meanL2"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sctest.efp_+3A_x">x</code></td>
<td>
<p>an object of class <code>"efp"</code>.</p>
</td></tr>
<tr><td><code id="sctest.efp_+3A_alt.boundary">alt.boundary</code></td>
<td>
<p>logical. If set to <code>TRUE</code> alternative boundaries
(instead of
the standard linear boundaries) will be used (for CUSUM
processes only).</p>
</td></tr>
<tr><td><code id="sctest.efp_+3A_functional">functional</code></td>
<td>
<p>indicates which functional should be applied to the
empirical fluctuation process.</p>
</td></tr>
<tr><td><code id="sctest.efp_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The critical values for the MOSUM tests and the ME test are just
tabulated for confidence levels between 0.1 and 0.01, thus the p
value approximations will be poor for other p values. Similarly the
critical values for the maximum and mean squared Euclidean norm (<code>"maxL2"</code>
and <code>"meanL2"</code>) are tabulated for confidence levels between 0.2 and 0.005.</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> containing:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the test statistic,</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the corresponding p value,</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string with the method used,</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string with the data name.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brown R.L., Durbin J., Evans J.M. (1975), Techniques for
testing constancy of regression relationships over time, <em>Journal of the
Royal Statistical Society</em>, B, <b>37</b>, 149-163.
</p>
<p>Chu C.-S., Hornik K., Kuan C.-M. (1995), MOSUM tests for parameter
constancy, <em>Biometrika</em>, <b>82</b>, 603-617.
</p>
<p>Chu C.-S., Hornik K., Kuan C.-M. (1995), The moving-estimates test for
parameter stability, <em>Econometric Theory</em>, <b>11</b>, 669-720.
</p>
<p>Krämer W., Ploberger W., Alt R. (1988), Testing for structural change in
dynamic models, <em>Econometrica</em>, <b>56</b>, 1355-1369.
</p>
<p>Kuan C.-M., Hornik K. (1995), The generalized fluctuation test: A
unifying view, <em>Econometric Reviews</em>, <b>14</b>, 135 - 161.
</p>
<p>Kuan C.-M., Chen (1994), Implementing the fluctuation and moving estimates
tests in dynamic econometric models, <em>Economics Letters</em>, <b>44</b>,
235-239.
</p>
<p>Ploberger W., Krämer W. (1992), The CUSUM Test with OLS Residuals,
<em>Econometrica</em>, <b>60</b>, 271-285.
</p>
<p>Zeileis A., Leisch F., Hornik K., Kleiber C. (2002), <code>strucchange</code>:
An R Package for Testing for Structural Change in Linear Regression Models,
<em>Journal of Statistical Software</em>, <b>7</b>(2), 1-38.
doi: <a href="https://doi.org/10.18637/jss.v007.i02">10.18637/jss.v007.i02</a>.
</p>
<p>Zeileis A. (2004), Alternative Boundaries for CUSUM Tests,
<em>Statistical Papers</em>, <b>45</b>, 123&ndash;131.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efp">efp</a></code>, <code><a href="#topic+plot.efp">plot.efp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load dataset "nhtemp" with average yearly temperatures in New Haven
data("nhtemp")
## plot the data
plot(nhtemp)

## test the model null hypothesis that the average temperature remains
## constant over the years compute OLS-CUSUM fluctuation process
temp.cus &lt;- efp(nhtemp ~ 1, type = "OLS-CUSUM")
## plot the process with alternative boundaries
plot(temp.cus, alpha = 0.01, alt.boundary = TRUE)
## and calculate the test statistic
sctest(temp.cus)

## compute moving estimates fluctuation process
temp.me &lt;- efp(nhtemp ~ 1, type = "ME", h = 0.2)
## plot the process with functional = "max"
plot(temp.me)
## and perform the corresponding test
sctest(temp.me)
</code></pre>

<hr>
<h2 id='sctest.formula'>Structural Change Tests in Linear Regression Models</h2><span id='topic+sctest.formula'></span>

<h3>Description</h3>

<p>Performs tests for structural change in linear regression models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'formula'
sctest(formula, type = , h = 0.15,
    alt.boundary = FALSE, functional = c("max", "range",
    "maxL2", "meanL2"), from = 0.15, to = NULL, point = 0.5,
    asymptotic = FALSE, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sctest.formula_+3A_formula">formula</code></td>
<td>
<p>a formula describing the model to be tested.</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_type">type</code></td>
<td>
<p>a character string specifying the structural change test that is
to be performed, the default is <code>"Rec-CUSUM"</code>. Besides the test
types described in <code><a href="#topic+efp">efp</a></code>
and <code><a href="#topic+sctest.Fstats">sctest.Fstats</a></code> the Chow test and the Nyblom-Hansen test
can be performed by setting type to <code>"Chow"</code> or <code>"Nyblom-Hansen"</code>,
respectively.</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_h">h</code></td>
<td>
<p>numeric from interval (0,1) specifying the bandwidth. Determines the
size of the data window relative to the sample size (for MOSUM and ME tests
only).</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_alt.boundary">alt.boundary</code></td>
<td>
<p>logical. If set to <code>TRUE</code> alternative boundaries
(instead of the standard linear boundaries) will be used (for CUSUM
processes only).</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_functional">functional</code></td>
<td>
<p>indicates which functional should be used to aggregate
the empirical fluctuation processes to a test statistic.</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_from">from</code>, <code id="sctest.formula_+3A_to">to</code></td>
<td>
<p>numeric. If <code>from</code> is smaller than 1 they are
interpreted as percentages of data and by default <code>to</code> is taken to be
the 1 - <code>from</code>. F statistics will be calculated for the observations
<code>(n*from):(n*to)</code>, when <code>n</code> is the number of observations in the
model. If <code>from</code> is greater than 1 it is interpreted to be the index
and <code>to</code> defaults to <code>n - from</code>. (for F tests only)</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_point">point</code></td>
<td>
<p>parameter of the Chow test for the potential change point.
Interpreted analogous to the <code>from</code> parameter. By
default taken to be <code>floor(n*0.5)</code> if <code>n</code> is the  number of
observations in the model.</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_asymptotic">asymptotic</code></td>
<td>
<p>logical. If <code>TRUE</code> the asymptotic (chi-square)
distribution instead of the exact (F) distribution will be used to compute
the p value (for Chow test only).</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. By
default the variables are taken from the environment which
<code>sctest</code> is called from.</p>
</td></tr>
<tr><td><code id="sctest.formula_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="#topic+efp">efp</a></code> or
<code><a href="#topic+Fstats">Fstats</a></code>.</p>
</td></tr> </table>


<h3>Details</h3>

<p><code>sctest.formula</code> is a convenience interface for performing structural change
tests in linear regression models based on <code><a href="#topic+efp">efp</a></code> and <code><a href="#topic+Fstats">Fstats</a></code>.
It is mainly a wrapper for <code><a href="#topic+sctest.efp">sctest.efp</a></code>
and <code><a href="#topic+sctest.Fstats">sctest.Fstats</a></code> as it fits an empirical fluctuation process
first or computes the F statistics respectively and subsequently performs the
corresponding test. The Chow test and the Nyblom-Hansen test are available explicitly here.
</p>
<p>An alternative convenience interface for performing structural change tests in general
parametric models (based on <code><a href="#topic+gefp">gefp</a></code>) is available in <code><a href="#topic+sctest.default">sctest.default</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> containing:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the test statistic,</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the corresponding p value,</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string with the method used,</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string with the data name.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+sctest.efp">sctest.efp</a></code>, <code><a href="#topic+sctest.Fstats">sctest.Fstats</a></code>, <code><a href="#topic+sctest.default">sctest.default</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example 7.4 from Greene (1993), "Econometric Analysis"
## Chow test on Longley data
data("longley")
sctest(Employed ~ Year + GNP.deflator + GNP + Armed.Forces, data = longley,
  type = "Chow", point = 7)

## which is equivalent to segmenting the regression via
fac &lt;- factor(c(rep(1, 7), rep(2, 9)))
fm0 &lt;- lm(Employed ~ Year + GNP.deflator + GNP + Armed.Forces, data = longley)
fm1 &lt;- lm(Employed ~ fac/(Year + GNP.deflator + GNP + Armed.Forces), data = longley)
anova(fm0, fm1)

## estimates from Table 7.5 in Greene (1993)
summary(fm0)
summary(fm1)
</code></pre>

<hr>
<h2 id='sctest.Fstats'>supF-, aveF- and expF-Test</h2><span id='topic+sctest.Fstats'></span>

<h3>Description</h3>

<p>Performs the supF-, aveF- or expF-test</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Fstats'
sctest(x, type = c("supF", "aveF", "expF"),
    asymptotic = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sctest.Fstats_+3A_x">x</code></td>
<td>
<p>an object of class <code>"Fstats"</code>.</p>
</td></tr>
<tr><td><code id="sctest.Fstats_+3A_type">type</code></td>
<td>
<p>a character string specifying which test will be performed.</p>
</td></tr>
<tr><td><code id="sctest.Fstats_+3A_asymptotic">asymptotic</code></td>
<td>
<p>logical. Only necessary if <code>x</code> contains just a single F
statistic and type is <code>"supF"</code> or <code>"aveF"</code>. If then set to
<code>TRUE</code> the asymptotic (chi-square) distribution instead of the exact
(F) distribution will be used to compute the p value.</p>
</td></tr>
<tr><td><code id="sctest.Fstats_+3A_...">...</code></td>
<td>
<p>currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> contains just a single F statistic and type is
<code>"supF"</code> or <code>"aveF"</code> the Chow test will be performed.
</p>
<p>The original GAUSS code for computing the p values of the supF-, aveF- and
expF-test was written by Bruce Hansen and is available from
<a href="http://www.ssc.wisc.edu/~bhansen/">http://www.ssc.wisc.edu/~bhansen/</a>. R port by Achim Zeileis.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code> containing:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>the test statistic,</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the corresponding p value,</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>a character string with the method used,</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>a character string with the data name.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Andrews D.W.K. (1993), Tests for parameter instability and structural
change with unknown change point, <em>Econometrica</em>, <b>61</b>, 821-856.
</p>
<p>Andrews D.W.K., Ploberger W. (1994), Optimal tests when a nuisance parameter
is present only under the alternative, <em>Econometrica</em>, <b>62</b>, 1383-1414.
</p>
<p>Hansen B. (1992), Tests for parameter instability in regressions with I(1)
processes, <em>Journal of Business &amp; Economic Statistics</em>, <b>10</b>, 321-335.
</p>
<p>Hansen B. (1997), Approximate asymptotic p values for structural-change
tests, <em>Journal of Business &amp; Economic Statistics</em>, <b>15</b>, 60-67. </p>


<h3>See Also</h3>

<p><code><a href="#topic+Fstats">Fstats</a></code>, <code><a href="#topic+plot.Fstats">plot.Fstats</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load dataset "nhtemp" with average yearly temperatures in New Haven
data(nhtemp)
## plot the data
plot(nhtemp)

## test the model null hypothesis that the average temperature remains
## constant over the years for potential break points between 1941
## (corresponds to from = 0.5) and 1962 (corresponds to to = 0.85)
## compute F statistics
fs &lt;- Fstats(nhtemp ~ 1, from = 0.5, to = 0.85)
## plot the F statistics
plot(fs, alpha = 0.01)
## and the corresponding p values
plot(fs, pval = TRUE, alpha = 0.01)
## perform the aveF test
sctest(fs, type = "aveF")
</code></pre>

<hr>
<h2 id='solveCrossprod'>Inversion of X'X</h2><span id='topic+solveCrossprod'></span>

<h3>Description</h3>

<p>Computes the inverse of the cross-product of a matrix X.</p>


<h3>Usage</h3>

<pre><code class='language-R'>solveCrossprod(X, method = c("qr", "chol", "solve"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="solveCrossprod_+3A_x">X</code></td>
<td>
<p>a matrix, typically a regressor matrix.</p>
</td></tr>
<tr><td><code id="solveCrossprod_+3A_method">method</code></td>
<td>
<p>a string indicating whether the QR decomposition,
the Cholesky decomposition or <code>solve</code> should be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the Cholesky decomposition of X'X (as computed by <code>crossprod(X)</code>)
is computationally faster and preferred to <code>solve(crossprod(X))</code>. Using the
QR decomposition of X is slower but should be more accurate.</p>


<h3>Value</h3>

<p>a matrix containing the inverse of <code>crossprod(X)</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- cbind(1, rnorm(100))
solveCrossprod(X)
solve(crossprod(X))
</code></pre>

<hr>
<h2 id='SP2001'>S\&amp;P 500 Stock Prices</h2><span id='topic+SP2001'></span>

<h3>Description</h3>

<p>A multivariate series of all S\&amp;P 500 stock prices in the
second half of the year 2001, i.e., before and after the
terrorist attacks of 2001-09-11. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("SP2001")</code></pre>


<h3>Format</h3>

<p>A multivariate daily <code>"zoo"</code> series with <code>"Date"</code> index 
from 2001-07-31 to 2001-12-31 (103 observations) of all 500 S\&amp;P
stock prices. 
</p>


<h3>Source</h3>

<p>Yahoo! Finance: <a href="https://finance.yahoo.com/">https://finance.yahoo.com/</a>.</p>


<h3>References</h3>

<p>Zeileis A., Leisch F., Kleiber C., Hornik K. (2005), Monitoring
Structural Change in Dynamic Econometric Models,
<em>Journal of Applied Econometrics</em>, <b>20</b>, 99&ndash;121.
</p>


<h3>See Also</h3>

<p><code><a href="tseries.html#topic+get.hist.quote">get.hist.quote</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## load and transform data
## (DAL: Delta Air Lines, LU: Lucent Technologies)
data("SP2001")
stock.prices &lt;- SP2001[, c("DAL", "LU")]
stock.returns &lt;- diff(log(stock.prices))

## price and return series
plot(stock.prices, ylab = c("Delta Air Lines", "Lucent Technologies"), main = "")
plot(stock.returns, ylab = c("Delta Air Lines", "Lucent Technologies"), main = "")

## monitoring of DAL series
myborder &lt;- function(k) 1.939*k/28
x &lt;- as.vector(stock.returns[, "DAL"][1:28])
dal.cusum &lt;- mefp(x ~ 1, type = "OLS-CUSUM", border = myborder)
dal.mosum &lt;- mefp(x ~ 1, type = "OLS-MOSUM", h = 0.5, period = 4)
x &lt;- as.vector(stock.returns[, "DAL"])
dal.cusum &lt;- monitor(dal.cusum)
dal.mosum &lt;- monitor(dal.mosum)

## monitoring of LU series
x &lt;- as.vector(stock.returns[, "LU"][1:28])
lu.cusum &lt;- mefp(x ~ 1, type = "OLS-CUSUM", border = myborder)
lu.mosum &lt;- mefp(x ~ 1, type = "OLS-MOSUM", h = 0.5, period = 4)
x &lt;- as.vector(stock.returns[, "LU"])
lu.cusum &lt;- monitor(lu.cusum)
lu.mosum &lt;- monitor(lu.mosum)

## pretty plotting
## (needs some work because lm() does not keep "zoo" attributes)
cus.bound &lt;- zoo(c(rep(NA, 27), myborder(28:102)), index(stock.returns))
mos.bound &lt;- as.vector(boundary(dal.mosum))
mos.bound &lt;- zoo(c(rep(NA, 27), mos.bound[1], mos.bound), index(stock.returns))

## Lucent Technologies: CUSUM test
plot(zoo(c(lu.cusum$efpprocess, lu.cusum$process), index(stock.prices)),
  ylim = c(-1, 1) * coredata(cus.bound)[102], xlab = "Time", ylab = "empirical fluctuation process")
abline(0, 0)
abline(v = as.Date("2001-09-10"), lty = 2)
lines(cus.bound, col = 2)
lines(-cus.bound, col = 2)

## Lucent Technologies: MOSUM test
plot(zoo(c(lu.mosum$efpprocess, lu.mosum$process), index(stock.prices)[-(1:14)]),
  ylim = c(-1, 1) * coredata(mos.bound)[102], xlab = "Time", ylab = "empirical fluctuation process")
abline(0, 0)
abline(v = as.Date("2001-09-10"), lty = 2)
lines(mos.bound, col = 2)
lines(-mos.bound, col = 2)

## Delta Air Lines: CUSUM test
plot(zoo(c(dal.cusum$efpprocess, dal.cusum$process), index(stock.prices)),
  ylim = c(-1, 1) * coredata(cus.bound)[102], xlab = "Time", ylab = "empirical fluctuation process")
abline(0, 0)
abline(v = as.Date("2001-09-10"), lty = 2)
lines(cus.bound, col = 2)
lines(-cus.bound, col = 2)

## Delta Air Lines: MOSUM test
plot(zoo(c(dal.mosum$efpprocess, dal.mosum$process), index(stock.prices)[-(1:14)]),
  ylim = range(dal.mosum$process), xlab = "Time", ylab = "empirical fluctuation process")
abline(0, 0)
abline(v = as.Date("2001-09-10"), lty = 2)
lines(mos.bound, col = 2)
lines(-mos.bound, col = 2)
</code></pre>

<hr>
<h2 id='strucchange.internal'>Internal strucchange objects</h2><span id='topic+sc.beta.sup'></span><span id='topic+sc.beta.ave'></span><span id='topic+sc.beta.exp'></span><span id='topic+sc.me'></span><span id='topic+sc.meanL2'></span><span id='topic+sc.maxL2'></span><span id='topic+pvalue.efp'></span><span id='topic+pvalue.Fstats'></span><span id='topic+monitorMECritval'></span><span id='topic+monitorMECritvalData'></span><span id='topic+monitorMECritvalTable'></span><span id='topic+monitorRECritval'></span><span id='topic+monitorRECritvalData'></span><span id='topic+monitorRECritvalTable'></span><span id='topic+pargmaxV'></span>

<h3>Description</h3>

<p>These are not to be called by the user.
</p>


<h3>Value</h3>

<p>Various, used internally and subject to change.
</p>

<hr>
<h2 id='supLM'>Generators for efpFunctionals along Continuous Variables</h2><span id='topic+supLM'></span><span id='topic+maxMOSUM'></span>

<h3>Description</h3>

<p>Generators for <code>efpFunctional</code> objects suitable for aggregating
empirical fluctuation processes to test statistics along continuous
variables (i.e., along time in time series applications).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>supLM(from = 0.15, to = NULL) 

maxMOSUM(width = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="supLM_+3A_from">from</code>, <code id="supLM_+3A_to">to</code></td>
<td>
<p>numeric from interval (0, 1) specifying start and end
of trimmed sample period. By default, <code>to</code> is <code>1 - from</code>, i.e.,
with the default <code>from = 0.15</code> the first and last 15 percent of
observations are trimmed.</p>
</td></tr>
<tr><td><code id="supLM_+3A_width">width</code></td>
<td>
<p>a numeric from interval (0,1) specifying the bandwidth.
Determines the size of the moving data window relative to sample size.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>supLM</code> and <code>maxMOSUM</code> generate <code><a href="#topic+efpFunctional">efpFunctional</a></code>
objects for Andrews' supLM test and a (maximum) MOSUM test, respectively,
with the specified optional parameters (<code>from</code> and <code>to</code>,
and <code>width</code>, respectively). The resulting objects can be used in
combination with empirical fluctuation processes of class <code><a href="#topic+gefp">gefp</a></code>
for significance testing and visualization. The corresponding statistics
are useful for carrying out structural change tests along a continuous
variable (i.e., along time in time series applications). Further typical
<code><a href="#topic+efpFunctional">efpFunctional</a></code>s for this setting are the double-maximum
functional <code><a href="#topic+maxBB">maxBB</a></code> and the Cramer-von Mises functional
<code><a href="#topic+meanL2BB">meanL2BB</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>efpFunctional</code>.
</p>


<h3>References</h3>

<p>Merkle E.C., Zeileis A. (2013), Tests of Measurement Invariance without Subgroups:
A Generalization of Classical Methods. <em>Psychometrika</em>, <b>78</b>(1), 59&ndash;82.
doi:10.1007/S11336-012-9302-4
</p>
<p>Zeileis A. (2005), A Unified Approach to Structural Change Tests Based on
ML Scores, F Statistics, and OLS Residuals. <em>Econometric Reviews</em>, <b>24</b>,
445&ndash;466. doi:10.1080/07474930500406053.
</p>
<p>Zeileis A. (2006), Implementing a Class of Structural Change Tests: An
Econometric Computing Approach. <em>Computational Statistics &amp; Data Analysis</em>, 
<b>50</b>, 2987&ndash;3008. doi:10.1016/j.csda.2005.07.001.
</p>
<p>Zeileis A., Hornik K. (2007), Generalized M-Fluctuation Tests for Parameter
Instability, <em>Statistica Neerlandica</em>, <b>61</b>, 488&ndash;508.
doi:10.1111/j.1467-9574.2007.00371.x.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efpFunctional">efpFunctional</a></code>, <code><a href="#topic+gefp">gefp</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## seatbelt data
data("UKDriverDeaths")
seatbelt &lt;- log10(UKDriverDeaths)
seatbelt &lt;- cbind(seatbelt, lag(seatbelt, k = -1), lag(seatbelt, k = -12))
colnames(seatbelt) &lt;- c("y", "ylag1", "ylag12")
seatbelt &lt;- window(seatbelt, start = c(1970, 1), end = c(1984,12))

## empirical fluctuation process
scus.seat &lt;- gefp(y ~ ylag1 + ylag12, data = seatbelt)

## supLM test
plot(scus.seat, functional = supLM(0.1))
## MOSUM test
plot(scus.seat, functional = maxMOSUM(0.25))
## double maximum test
plot(scus.seat)
## range test
plot(scus.seat, functional = rangeBB)
## Cramer-von Mises statistic (Nyblom-Hansen test)
plot(scus.seat, functional = meanL2BB)
</code></pre>

<hr>
<h2 id='USIncExp'>Income and Expenditures in the US</h2><span id='topic+USIncExp'></span>

<h3>Description</h3>

<p>Personal income and personal
consumption expenditures in the US between January 1959 and
February 2001 (seasonally adjusted at annual rates).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("USIncExp")</code></pre>


<h3>Format</h3>

<p>A multivariate monthly time series from 1959(1) to 2001(2) with variables
</p>

<dl>
<dt>income</dt><dd><p>monthly personal income (in billion US dollars),</p>
</dd>
<dt>expenditure</dt><dd><p>monthly personal consumption expenditures
(in billion US Dollars).</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://web.archive.org/web/20201205041942/http://www.economagic.com/">https://web.archive.org/web/20201205041942/http://www.economagic.com/</a> </p>


<h3>References</h3>

<p>A. Zeileis, F. Leisch, K. Hornik, C. Kleiber (2002),
strucchange: An R Package for Testing for Structural Change in Linear
Regression Models.
<em>Journal of Statistical Software</em> <b>7</b>(2), 1&ndash;38.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## These example are presented in the vignette distributed with this
## package, the code was generated by Stangle("strucchange-intro.Rnw")

###################################################
### chunk number 1: data
###################################################
data("USIncExp")
plot(USIncExp, plot.type = "single", col = 1:2, ylab = "billion US$")
legend(1960, max(USIncExp), c("income", "expenditures"),
       lty = c(1,1), col = 1:2, bty = "n")


###################################################
### chunk number 2: subset
###################################################
data("USIncExp")
USIncExp2 &lt;- window(USIncExp, start = c(1985,12))


###################################################
### chunk number 3: ecm-setup
###################################################
coint.res &lt;- residuals(lm(expenditure ~ income, data = USIncExp2))
coint.res &lt;- lag(ts(coint.res, start = c(1985,12), freq = 12), k = -1)
USIncExp2 &lt;- cbind(USIncExp2, diff(USIncExp2), coint.res)
USIncExp2 &lt;- window(USIncExp2, start = c(1986,1), end = c(2001,2))
colnames(USIncExp2) &lt;- c("income", "expenditure", "diff.income",
                         "diff.expenditure", "coint.res")
ecm.model &lt;- diff.expenditure ~ coint.res + diff.income


###################################################
### chunk number 4: ts-used
###################################################
plot(USIncExp2[,3:5], main = "")


###################################################
### chunk number 5: efp
###################################################
ocus &lt;- efp(ecm.model, type="OLS-CUSUM", data=USIncExp2)
me &lt;- efp(ecm.model, type="ME", data=USIncExp2, h=0.2)


###################################################
### chunk number 6: efp-boundary
###################################################
bound.ocus &lt;- boundary(ocus, alpha=0.05)


###################################################
### chunk number 7: OLS-CUSUM
###################################################
plot(ocus)


###################################################
### chunk number 8: efp-boundary2
###################################################
plot(ocus, boundary = FALSE)
lines(bound.ocus, col = 4)
lines(-bound.ocus, col = 4)


###################################################
### chunk number 9: ME-null
###################################################
plot(me, functional = NULL)


###################################################
### chunk number 10: efp-sctest
###################################################
sctest(ocus)


###################################################
### chunk number 11: efp-sctest2
###################################################
sctest(ecm.model, type="OLS-CUSUM", data=USIncExp2)


###################################################
### chunk number 12: Fstats
###################################################
fs &lt;- Fstats(ecm.model, from = c(1990, 1), to = c(1999,6), data = USIncExp2)


###################################################
### chunk number 13: Fstats-plot
###################################################
plot(fs)


###################################################
### chunk number 14: pval-plot
###################################################
plot(fs, pval=TRUE)


###################################################
### chunk number 15: aveF-plot
###################################################
plot(fs, aveF=TRUE)


###################################################
### chunk number 16: Fstats-sctest
###################################################
sctest(fs, type="expF")


###################################################
### chunk number 17: Fstats-sctest2
###################################################
sctest(ecm.model, type = "expF", from = 49, to = 162, data = USIncExp2)


###################################################
### chunk number 18: mefp
###################################################
USIncExp3 &lt;- window(USIncExp2, start = c(1986, 1), end = c(1989,12))
me.mefp &lt;- mefp(ecm.model, type = "ME", data = USIncExp3, alpha = 0.05)


###################################################
### chunk number 19: monitor1
###################################################
USIncExp3 &lt;- window(USIncExp2, start = c(1986, 1), end = c(1990,12))
me.mefp &lt;- monitor(me.mefp)


###################################################
### chunk number 20: monitor2
###################################################
USIncExp3 &lt;- window(USIncExp2, start = c(1986, 1))
me.mefp &lt;- monitor(me.mefp)
me.mefp


###################################################
### chunk number 21: monitor-plot
###################################################
plot(me.mefp)


###################################################
### chunk number 22: mefp2
###################################################
USIncExp3 &lt;- window(USIncExp2, start = c(1986, 1), end = c(1989,12))
me.efp &lt;- efp(ecm.model, type = "ME", data = USIncExp3, h = 0.5)
me.mefp &lt;- mefp(me.efp, alpha=0.05)


###################################################
### chunk number 23: monitor3
###################################################
USIncExp3 &lt;- window(USIncExp2, start = c(1986, 1))
me.mefp &lt;- monitor(me.mefp)


###################################################
### chunk number 24: monitor-plot2
###################################################
plot(me.mefp)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
