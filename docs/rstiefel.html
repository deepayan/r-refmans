<!DOCTYPE html><html lang="en"><head><title>Help for package rstiefel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rstiefel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#rstiefel-package'><p>Random Orthonormal Matrix Generation on the Stiefel Manifold #'</p>
Simulation of random orthonormal matrices from linear and quadratic exponential family distributions on the Stiefel manifold. The most general type of distribution covered is the matrix-variate  Bingham-von Mises-Fisher distribution. Most of the simulation methods are presented in Hoff(2009) &quot;Simulation of the Matrix Bingham-von Mises-Fisher Distribution, With Applications to Multivariate and Relational Data&quot; &lt;doi:10.1198/jcgs.2009.07177&gt;. The package also includes functions for optimzation on the Stiefel manifold based on algoirthms described in Wen and Yin (2013) &quot;A feasible method for optimization with orthogonality constraints&quot; &lt;doi:10.1007/s10107-012-0584-1&gt;.</a></li>
<li><a href='#lineSearch'><p>A curvilinear search on the Stiefel manifold (Wen and Yin 2013, Algo 1)</p></a></li>
<li><a href='#lineSearchBB'><p>A curvilinear search on the Stiefel manifold with BB steps (Wen and Yin 2013, Algo 2)</p>
This is based on the line search algorithm described in (Zhang and Hager, 2004)</a></li>
<li><a href='#NullC'><p>Null Space of a Matrix</p></a></li>
<li><a href='#optStiefel'><p>Optimize a function on the Stiefel manifold</p></a></li>
<li><a href='#rbing.matrix.gibbs'><p>Gibbs Sampling for the Matrix-variate Bingham Distribution</p></a></li>
<li><a href='#rbing.O2'><p>Simulate a 2*2 Orthogonal Random Matrix</p></a></li>
<li><a href='#rbing.Op'><p>Simulate a <code>p*p</code> Orthogonal Random Matrix</p></a></li>
<li><a href='#rbing.vector.gibbs'><p>Gibbs Sampling for the Vector-variate Bingham Distribution</p></a></li>
<li><a href='#rbmf.matrix.gibbs'><p>Gibbs Sampling for the Matrix-variate Bingham-von Mises-Fisher Distribution.</p></a></li>
<li><a href='#rbmf.O2'><p>Simulate a <code>2*2</code> Orthogonal Random Matrix</p></a></li>
<li><a href='#rbmf.vector.gibbs'><p>Gibbs Sampling for the Vector-variate Bingham-von Mises-Fisher Distribution</p></a></li>
<li><a href='#rmf.matrix'><p>Simulate a Random Orthonormal Matrix</p></a></li>
<li><a href='#rmf.matrix.gibbs'><p>Gibbs Sampling for the Matrix-variate von Mises-Fisher Distribution</p></a></li>
<li><a href='#rmf.vector'><p>Simulate a Random Normal Vector</p></a></li>
<li><a href='#rustiefel'><p>Siumlate a Uniformly Distributed Random Orthonormal Matrix</p></a></li>
<li><a href='#rW'><p>Simulate <code>W</code> as Described in Wood(1994)</p></a></li>
<li><a href='#ry_bing'><p>Helper Function for Sampling a Bingham-distributed Vector</p></a></li>
<li><a href='#ry_bmf'><p>Helper Function for Sampling a Bingham-von Mises-Fisher-distributed Vector</p></a></li>
<li><a href='#tr'><p>Compute the trace of a matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Random Orthonormal Matrix Generation and Optimization on the
Stiefel Manifold</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-06-14</td>
</tr>
<tr>
<td>Author:</td>
<td>Peter Hoff and Alexander Franks</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Hoff &lt;peter.hoff@duke.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Simulation of random orthonormal matrices from linear and quadratic exponential family distributions on the Stiefel manifold. The most general type of distribution covered is the matrix-variate  Bingham-von Mises-Fisher distribution. Most of the simulation methods are presented in Hoff(2009) "Simulation of the Matrix Bingham-von Mises-Fisher Distribution, With Applications to Multivariate and Relational Data" &lt;<a href="https://doi.org/10.1198%2Fjcgs.2009.07177">doi:10.1198/jcgs.2009.07177</a>&gt;. The package also includes functions for optimization on the Stiefel manifold based on algorithms described in Wen and Yin (2013) "A feasible method for optimization with orthogonality constraints" &lt;<a href="https://doi.org/10.1007%2Fs10107-012-0584-1">doi:10.1007/s10107-012-0584-1</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-06-15 13:57:46 UTC; pdhoff</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-06-15 15:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='rstiefel-package'>Random Orthonormal Matrix Generation on the Stiefel Manifold #' 
Simulation of random orthonormal matrices from linear and quadratic exponential family distributions on the Stiefel manifold. The most general type of distribution covered is the matrix-variate  Bingham-von Mises-Fisher distribution. Most of the simulation methods are presented in Hoff(2009) &quot;Simulation of the Matrix Bingham-von Mises-Fisher Distribution, With Applications to Multivariate and Relational Data&quot; &lt;doi:10.1198/jcgs.2009.07177&gt;. The package also includes functions for optimzation on the Stiefel manifold based on algoirthms described in Wen and Yin (2013) &quot;A feasible method for optimization with orthogonality constraints&quot; &lt;doi:10.1007/s10107-012-0584-1&gt;.</h2><span id='topic+rstiefel-package'></span><span id='topic+rstiefel'></span>

<h3>Description</h3>


<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> rstiefel</td>
</tr>
<tr>
 <td style="text-align: left;"> Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> Version: </td><td style="text-align: left;">
1.0.0</td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;"> 2019-02-18</td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Peter Hoff
</p>
<p>Alex Franks
</p>
<p>Maintainer: Peter Hoff &lt;peter.hoff@duke.edu&gt;
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Z&lt;-matrix(rnorm(10*5),10,5) ; A&lt;-t(Z)%*%Z 
B&lt;-diag(sort(rexp(5),decreasing=TRUE))
U&lt;-rbing.Op(A,B)
U&lt;-rbing.matrix.gibbs(A,B,U)

U&lt;-rmf.matrix(Z)
U&lt;-rmf.matrix.gibbs(Z,U)

</code></pre>

<hr>
<h2 id='lineSearch'>A curvilinear search on the Stiefel manifold (Wen and Yin 2013, Algo 1)</h2><span id='topic+lineSearch'></span>

<h3>Description</h3>

<p>A curvilinear search on the Stiefel manifold (Wen and Yin 2013, Algo 1)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lineSearch(F, dF, X, rho1, rho2, tauStart, maxIters = 20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lineSearch_+3A_f">F</code></td>
<td>
<p>A function V(n, p) -&gt; <code>R^1</code></p>
</td></tr>
<tr><td><code id="lineSearch_+3A_df">dF</code></td>
<td>
<p>A function V(n, p) -&gt; <code>R^1</code></p>
</td></tr>
<tr><td><code id="lineSearch_+3A_x">X</code></td>
<td>
<p>an n x p semi-orthogonal matrix (starting point)</p>
</td></tr>
<tr><td><code id="lineSearch_+3A_rho1">rho1</code></td>
<td>
<p>Parameter for Armijo condition.  Between 0 and 1 and usually small, e.g &lt; 0.1</p>
</td></tr>
<tr><td><code id="lineSearch_+3A_rho2">rho2</code></td>
<td>
<p>Parameter for Wolfe condition Between 0 and 1 usually large, &gt; 0.9</p>
</td></tr>
<tr><td><code id="lineSearch_+3A_taustart">tauStart</code></td>
<td>
<p>Initial step size</p>
</td></tr>
<tr><td><code id="lineSearch_+3A_maxiters">maxIters</code></td>
<td>
<p>Maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing: Y, the semi-orthogonal matrix satisfying the Armijo-Wolfe conditions and tau: the stepsize satisfying these conditions
</p>


<h3>Author(s)</h3>

<p>Alexander Franks
</p>


<h3>References</h3>

<p>(Wen and Yin, 2013)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 10
P &lt;- 2
M &lt;- diag(10:1)
F &lt;- function(V) { - sum(diag(t(V) %*% M %*% V)) }
dF &lt;- function(V) { - 2*M %*% V }
X &lt;- rustiefel(N, P)
res &lt;- lineSearch(F, dF, X, rho1=0.1, rho2=0.9, tauStart=1)

</code></pre>

<hr>
<h2 id='lineSearchBB'>A curvilinear search on the Stiefel manifold with BB steps (Wen and Yin 2013, Algo 2)
This is based on the line search algorithm described in (Zhang and Hager, 2004)</h2><span id='topic+lineSearchBB'></span>

<h3>Description</h3>

<p>A curvilinear search on the Stiefel manifold with BB steps (Wen and Yin 2013, Algo 2)
This is based on the line search algorithm described in (Zhang and Hager, 2004)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lineSearchBB(F, X, Xprev, G_x, G_xprev, rho, C, maxIters = 20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lineSearchBB_+3A_f">F</code></td>
<td>
<p>A function V(n, p) -&gt; R</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_x">X</code></td>
<td>
<p>an n x p semi-orthogonal matrix (the current )</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_xprev">Xprev</code></td>
<td>
<p>an n x p semi-orthogonal matrix (the previous)</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_g_x">G_x</code></td>
<td>
<p>an n x p matrix with (G_x)_ij = dF(X)/dX_ij</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_g_xprev">G_xprev</code></td>
<td>
<p>an n x p matrix with (G_xprev)_ij = dF(X_prev)/dX_prev_ij</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_rho">rho</code></td>
<td>
<p>Convergence parameter, usually small (e.g. 0.1)</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_c">C</code></td>
<td>
<p>C_t+1 = (etaQ_t + F(X_t+1))/Q_t+1 See section 3.2 in Wen and Yin, 2013</p>
</td></tr>
<tr><td><code id="lineSearchBB_+3A_maxiters">maxIters</code></td>
<td>
<p>Maximum number of iterations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing Y: a semi-orthogonal matrix Ytau which satisfies convergence criteria (Eqn 29 in Wen &amp; Yin '13), and tau: the stepsize satisfying these criteria
</p>


<h3>Author(s)</h3>

<p>Alexander Franks
</p>


<h3>References</h3>

<p>(Wen and Yin, 2013) and (Zhang and Hager, 2004)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 10
P &lt;- 2
M &lt;- diag(10:1)
F &lt;- function(V) { - sum(diag(t(V) %*% M %*% V)) }
dF &lt;- function(V) { - 2*M %*% V }
Xprev &lt;- rustiefel(N, P)
G_xprev &lt;- dF(Xprev)
X &lt;- rustiefel(N, P)
G_x &lt;- dF(X)
Xprev &lt;- dF(X)
res &lt;- lineSearchBB(F, X, Xprev, G_x, G_xprev, rho=0.1, C=F(X))

</code></pre>

<hr>
<h2 id='NullC'>Null Space of a Matrix</h2><span id='topic+NullC'></span>

<h3>Description</h3>

<p>Given a matrix <code>M</code>, find a matrix <code>N</code> giving a basis for the null
space. This is a modified version of Null from the package MASS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NullC(M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NullC_+3A_m">M</code></td>
<td>
<p>input matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an orthonormal matrix such that <code>t(N)%*%M</code> is a matrix of
zeros.
</p>


<h3>Note</h3>

<p>The MASS function <code>Null(matrix(0,4,2))</code> returns a 4*2 matrix,
whereas <code>NullC(matrix(0,4,2))</code> returns <code>diag(4)</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
NullC(matrix(0,4,2))

## The function is currently defined as
function (M) 
{
    tmp &lt;- qr(M)
    set &lt;- if (tmp$rank == 0L) 
        1L:nrow(M)
    else -(1L:tmp$rank)
    qr.Q(tmp, complete = TRUE)[, set, drop = FALSE]
  }

</code></pre>

<hr>
<h2 id='optStiefel'>Optimize a function on the Stiefel manifold</h2><span id='topic+optStiefel'></span>

<h3>Description</h3>

<p>Find a local minimum of a function defined on the stiefel manifold using algorithms described in Wen and Yin (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optStiefel(F, dF, Vinit, method = "bb", searchParams = NULL, tol = 1e-08,
  maxIters = 100, verbose = FALSE, maxLineSearchIters = 20)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optStiefel_+3A_f">F</code></td>
<td>
<p>A function V(P, S) -&gt; <code>R^1</code></p>
</td></tr>
<tr><td><code id="optStiefel_+3A_df">dF</code></td>
<td>
<p>A function to compute the gradient of F.  Returns a <code>P x S</code> matrix with <code>dF(X)_ij  = d(F(X))/dX_ij</code></p>
</td></tr>
<tr><td><code id="optStiefel_+3A_vinit">Vinit</code></td>
<td>
<p>The starting point on the stiefel manifold for the optimization</p>
</td></tr>
<tr><td><code id="optStiefel_+3A_method">method</code></td>
<td>
<p>Line search type: &quot;bb&quot; or curvilinear</p>
</td></tr>
<tr><td><code id="optStiefel_+3A_searchparams">searchParams</code></td>
<td>
<p>List of parameters for the line search algorithm.  If the line search algorithm is the standard curvilinear search than the search parameters are rho1 and rho2.  If the line search algorithm is &quot;bb&quot; then the parameters are rho and eta.</p>
</td></tr>
<tr><td><code id="optStiefel_+3A_tol">tol</code></td>
<td>
<p>Convergence tolerance.  Optimization stops when Fprime &lt; abs(tol), an approximate stationary point.</p>
</td></tr>
<tr><td><code id="optStiefel_+3A_maxiters">maxIters</code></td>
<td>
<p>Maximum iterations for each gradient step</p>
</td></tr>
<tr><td><code id="optStiefel_+3A_verbose">verbose</code></td>
<td>
<p>Boolean indicating whether to print function value and iteration number at each step.</p>
</td></tr>
<tr><td><code id="optStiefel_+3A_maxlinesearchiters">maxLineSearchIters</code></td>
<td>
<p>Maximum iterations for for each line search (one step in the gradient descent algorithm)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A stationary point of F on the Stiefel manifold.
</p>


<h3>Author(s)</h3>

<p>Alexander Franks
</p>


<h3>References</h3>

<p>(Wen and Yin, 2013)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Find the first eigenspace spanned by the first P eigenvectors for a 
## matrix M. The size of the matrix has been kept small and the tolerance 
## has been raised to keep the runtime 
## of this example below the CRAN submission threshold. 

N &lt;- 500
P &lt;- 3
Lam &lt;- diag(c(10, 5, 3, rep(1, N-P)))
U &lt;- rustiefel(N, N)
M &lt;- U %*% Lam %*% t(U)

F &lt;- function(V) { - sum(diag(t(V) %*% M %*% V)) }
dF &lt;- function(V) { - 2*M %*% V }
V = optStiefel(F, dF, Vinit=rustiefel(N, P),
               method="curvilinear",
               searchParams=list(rho1=0.1, rho2=0.9, tau=1),tol=1e-4)
               
print(sprintf("Sum of first %d eigenvalues is %f", P, -F(V)))

</code></pre>

<hr>
<h2 id='rbing.matrix.gibbs'>Gibbs Sampling for the Matrix-variate Bingham Distribution</h2><span id='topic+rbing.matrix.gibbs'></span>

<h3>Description</h3>

<p>Simulate a random orthonormal matrix from the Bingham distribution using
Gibbs sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbing.matrix.gibbs(A, B, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbing.matrix.gibbs_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbing.matrix.gibbs_+3A_b">B</code></td>
<td>
<p>a diagonal matrix with decreasing entries.</p>
</td></tr>
<tr><td><code id="rbing.matrix.gibbs_+3A_x">X</code></td>
<td>
<p>the current value of the random orthonormal matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new value of the matrix <code>X</code> obtained by Gibbs sampling.
</p>


<h3>Note</h3>

<p>This provides one Gibbs scan. The function should be used iteratively.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Z&lt;-matrix(rnorm(10*5),10,5) ; A&lt;-t(Z)%*%Z
B&lt;-diag(sort(rexp(5),decreasing=TRUE))
U&lt;-rbing.Op(A,B)
U&lt;-rbing.matrix.gibbs(A,B,U)

## The function is currently defined as
function (A, B, X) 
{
    m &lt;- dim(X)[1]
    R &lt;- dim(X)[2]
    if (m &gt; R) {
        for (r in sample(seq(1, R, length = R))) {
            N &lt;- NullC(X[, -r])
            An &lt;- B[r, r] * t(N) %*% (A) %*% N
            X[, r] &lt;- N %*% rbing.vector.gibbs(An, t(N) %*% X[, 
                r])
        }
    }
    if (m == R) {
        for (s in seq(1, R, length = R)) {
            r &lt;- sort(sample(seq(1, R, length = R), 2))
            N &lt;- NullC(X[, -r])
            An &lt;- t(N) %*% A %*% N
            X[, r] &lt;- N %*% rbing.Op(An, B[r, r])
        }
    }
    X
  }

</code></pre>

<hr>
<h2 id='rbing.O2'>Simulate a 2*2 Orthogonal Random Matrix</h2><span id='topic+rbing.O2'></span>

<h3>Description</h3>

<p>Simulate a 2*2 random orthogonal matrix from the Bingham distribution using
a rejection sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbing.O2(A, B, a = NULL, E = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbing.O2_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbing.O2_+3A_b">B</code></td>
<td>
<p>a diagonal matrix with decreasing entries.</p>
</td></tr>
<tr><td><code id="rbing.O2_+3A_a">a</code></td>
<td>
<p>sum of the eigenvalues of A, multiplied by the difference in
B-values.</p>
</td></tr>
<tr><td><code id="rbing.O2_+3A_e">E</code></td>
<td>
<p>eigenvectors of A.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A random 2x2 orthogonal matrix simulated from the Bingham
distribution.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (A, B, a = NULL, E = NULL) 
{
    if (is.null(a)) {
        trA &lt;- A[1, 1] + A[2, 2]
        lA &lt;- 2 * sqrt(trA^2/4 - A[1, 1] * A[2, 2] + A[1, 2]^2)
        a &lt;- lA * (B[1, 1] - B[2, 2])
        E &lt;- diag(2)
        if (A[1, 2] != 0) {
            E &lt;- cbind(c(0.5 * (trA + lA) - A[2, 2], A[1, 2]), 
                c(0.5 * (trA - lA) - A[2, 2], A[1, 2]))
            E[, 1] &lt;- E[, 1]/sqrt(sum(E[, 1]^2))
            E[, 2] &lt;- E[, 2]/sqrt(sum(E[, 2]^2))
        }
    }
    b &lt;- min(1/a^2, 0.5)
    beta &lt;- 0.5 - b
    lrmx &lt;- a
    if (beta &gt; 0) {
        lrmx &lt;- lrmx + beta * (log(beta/a) - 1)
    }
    lr &lt;- -Inf
    while (lr &lt; log(runif(1))) {
        w &lt;- rbeta(1, 0.5, b)
        lr &lt;- a * w + beta * log(1 - w) - lrmx
    }
    u &lt;- c(sqrt(w), sqrt(1 - w)) * (-1)^rbinom(2, 1, 0.5)
    x1 &lt;- E %*% u
    x2 &lt;- (x1[2:1] * c(-1, 1) * (-1)^rbinom(1, 1, 0.5))
    cbind(x1, x2)
  }

</code></pre>

<hr>
<h2 id='rbing.Op'>Simulate a <code>p*p</code> Orthogonal Random Matrix</h2><span id='topic+rbing.Op'></span>

<h3>Description</h3>

<p>Simulate a <code>p*p</code> random orthogonal matrix from the Bingham distribution
using a rejection sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbing.Op(A, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbing.Op_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbing.Op_+3A_b">B</code></td>
<td>
<p>a diagonal matrix with decreasing entries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A random pxp orthogonal matrix simulated from the Bingham
distribution.
</p>


<h3>Note</h3>

<p>This only works for small matrices, otherwise the sampler will reject
too frequently to be useful.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Z&lt;-matrix(rnorm(10*5),10,5) ; A&lt;-t(Z)%*%Z
B&lt;-diag(sort(rexp(5),decreasing=TRUE))
U&lt;-rbing.Op(A,B)
U&lt;-rbing.matrix.gibbs(A,B,U)


## The function is currently defined as
function (A, B) 
{
    b &lt;- diag(B)
    bmx &lt;- max(b)
    bmn &lt;- min(b)
    if(bmx&gt;bmn)
    {
    A &lt;- A * (bmx - bmn)
    b &lt;- (b - bmn)/(bmx - bmn)
    vlA &lt;- eigen(A)$val
    diag(A) &lt;- diag(A) - vlA[1]
    vlA &lt;- eigen(A)$val
    nu &lt;- max(dim(A)[1] + 1, round(-vlA[length(vlA)]))
    del &lt;- nu/2
    M &lt;- solve(diag(del, nrow = dim(A)[1]) - A)/2
    rej &lt;- TRUE
    cholM &lt;- chol(M)
    nrej &lt;- 0
    while (rej) {
        Z &lt;- matrix(rnorm(nu * dim(M)[1]), nrow = nu, ncol = dim(M)[1])
        Y &lt;- Z %*% cholM
        tmp &lt;- eigen(t(Y) %*% Y)
        U &lt;- tmp$vec %*% diag((-1)^rbinom(dim(A)[1], 1, 0.5))
        L &lt;- diag(tmp$val)
        D &lt;- diag(b) - L
        lrr &lt;- sum(diag((D %*% t(U) %*% A %*% U))) - sum(-sort(diag(-D)) * 
            vlA)
        rej &lt;- (log(runif(1)) &gt; lrr)
        nrej &lt;- nrej + 1
    }
    }
    if(bmx==bmn) { U&lt;-rustiefel(dim(A)[1],dim(A)[1]) } 
    U
  }

</code></pre>

<hr>
<h2 id='rbing.vector.gibbs'>Gibbs Sampling for the Vector-variate Bingham Distribution</h2><span id='topic+rbing.vector.gibbs'></span>

<h3>Description</h3>

<p>Simulate a random normal vector from the Bingham distribution using Gibbs
sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbing.vector.gibbs(A, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbing.vector.gibbs_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbing.vector.gibbs_+3A_x">x</code></td>
<td>
<p>the current value of the random normal vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new value of the vector <code>x</code> obtained by Gibbs sampling.
</p>


<h3>Note</h3>

<p>This provides one Gibbs scan. The function should be used iteratively.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
rbing.vector.gibbs &lt;-
function(A,x)
{
  #simulate from the vector bmf distribution as described in Hoff(2009) 
  #this is one Gibbs step, and must be used iteratively
  evdA&lt;-eigen(A,symmetric=TRUE)
  E&lt;-evdA$vec
  l&lt;-evdA$val

  y&lt;-t(E)%*%x
  x&lt;-E%*%ry_bing(y,l)
  x/sqrt(sum(x^2))
  #One improvement might be a rejection sampler 
  #based on a mixture of vector mf distributions. 
  #The difficulty is finding the max of the ratio.
}


</code></pre>

<hr>
<h2 id='rbmf.matrix.gibbs'>Gibbs Sampling for the Matrix-variate Bingham-von Mises-Fisher Distribution.</h2><span id='topic+rbmf.matrix.gibbs'></span>

<h3>Description</h3>

<p>Simulate a random orthonormal matrix from the Bingham distribution using
Gibbs sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbmf.matrix.gibbs(A, B, C, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbmf.matrix.gibbs_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbmf.matrix.gibbs_+3A_b">B</code></td>
<td>
<p>a diagonal matrix with decreasing entries.</p>
</td></tr>
<tr><td><code id="rbmf.matrix.gibbs_+3A_c">C</code></td>
<td>
<p>a matrix with the same dimension as X.</p>
</td></tr>
<tr><td><code id="rbmf.matrix.gibbs_+3A_x">X</code></td>
<td>
<p>the current value of the random orthonormal matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new value of the matrix <code>X</code> obtained by Gibbs sampling.
</p>


<h3>Note</h3>

<p>This provides one Gibbs scan. The function should be used iteratively.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (A, B, C, X) 
{
    m &lt;- dim(X)[1]
    R &lt;- dim(X)[2]
    if (m &gt; R) {
        for (r in sample(seq(1, R, length = R))) {
            N &lt;- NullC(X[, -r])
            An &lt;- B[r, r] * t(N) %*% (A) %*% N
            cn &lt;- t(N) %*% C[, r]
            X[, r] &lt;- N %*% rbmf.vector.gibbs(An, cn, t(N) %*% 
                X[, r])
        }
    }
    if (m == R) {
        for (s in seq(1, R, length = R)) {
            r &lt;- sort(sample(seq(1, R, length = R), 2))
            N &lt;- NullC(X[, -r])
            An &lt;- t(N) %*% A %*% N
            Cn &lt;- t(N) %*% C[, r]
            X[, r] &lt;- N %*% rbmf.O2(An, B[r, r], Cn)
        }
    }
    X
  }

</code></pre>

<hr>
<h2 id='rbmf.O2'>Simulate a <code>2*2</code> Orthogonal Random Matrix</h2><span id='topic+rbmf.O2'></span>

<h3>Description</h3>

<p>Simulate a <code>2*2</code> random orthogonal matrix from the Bingham-von
Mises-Fisher distribution using a rejection sampler.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbmf.O2(A, B, C, env = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbmf.O2_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbmf.O2_+3A_b">B</code></td>
<td>
<p>a diagonal matrix with decreasing entries.</p>
</td></tr>
<tr><td><code id="rbmf.O2_+3A_c">C</code></td>
<td>
<p>a 2x2 matrix.</p>
</td></tr>
<tr><td><code id="rbmf.O2_+3A_env">env</code></td>
<td>
<p>which rejection envelope to use, Bingham (<code>bingham</code>) or von
Mises-Fisher (<code>mf</code>)?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A random 2x2 orthogonal matrix simulated from the Bingham-von
Mises-Fisher distribution.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (A, B, C, env = FALSE) 
{
    sC &lt;- svd(C)
    d1 &lt;- sum(sC$d)
    eA &lt;- eigen(A)
    ab &lt;- sum(eA$val * diag(B))
    if (d1 &lt;= ab | env == "bingham") {
        lrmx &lt;- sum(sC$d)
        lr &lt;- -Inf
        while (lr &lt; log(runif(1))) {
            X &lt;- rbing.O2(A, B, a = (eA$val[1] - eA$val[2]) * 
                (B[1, 1] - B[2, 2]), E = eA$vec)
            lr &lt;- sum(diag(t(X) %*% C)) - lrmx
        }
    }
    if (d1 &gt; ab | env == "mf") {
        lrmx &lt;- sum(eA$val * sort(diag(B), decreasing = TRUE))
        lr &lt;- -Inf
        while (lr &lt; log(runif(1))) {
            X &lt;- rmf.matrix(C)
            lr &lt;- sum(diag(B %*% t(X) %*% A %*% X)) - lrmx
        }
    }
    X
  }

</code></pre>

<hr>
<h2 id='rbmf.vector.gibbs'>Gibbs Sampling for the Vector-variate Bingham-von Mises-Fisher Distribution</h2><span id='topic+rbmf.vector.gibbs'></span>

<h3>Description</h3>

<p>Simulate a random normal vector from the Bingham-von Mises-Fisher
distribution using Gibbs sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rbmf.vector.gibbs(A, c, x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rbmf.vector.gibbs_+3A_a">A</code></td>
<td>
<p>a symmetric matrix.</p>
</td></tr>
<tr><td><code id="rbmf.vector.gibbs_+3A_c">c</code></td>
<td>
<p>a vector with the same length as <code>x</code>.</p>
</td></tr>
<tr><td><code id="rbmf.vector.gibbs_+3A_x">x</code></td>
<td>
<p>the current value of the random normal vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new value of the vector <code>x</code> obtained by Gibbs sampling.
</p>


<h3>Note</h3>

<p>This provides one Gibbs scan. The function should be used iteratively.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (A, c, x) 
{
    evdA &lt;- eigen(A)
    E &lt;- evdA$vec
    l &lt;- evdA$val
    y &lt;- t(E) %*% x
    d &lt;- t(E) %*% c
    x &lt;- E %*% ry_bmf(y, l, d)
    x/sqrt(sum(x^2))
  }

</code></pre>

<hr>
<h2 id='rmf.matrix'>Simulate a Random Orthonormal Matrix</h2><span id='topic+rmf.matrix'></span>

<h3>Description</h3>

<p>Simulate a random orthonormal matrix from the von Mises-Fisher distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmf.matrix(M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmf.matrix_+3A_m">M</code></td>
<td>
<p>a matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an orthonormal matrix of the same dimension as <code>M</code>.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
Z&lt;-matrix(rnorm(10*5),10,5) 

U&lt;-rmf.matrix(Z)
U&lt;-rmf.matrix.gibbs(Z,U)


function (M) 
{
    if (dim(M)[2] == 1) {
        X &lt;- rmf.vector(M)
    }
    if (dim(M)[2] &gt; 1) {
        svdM &lt;- svd(M)
        H &lt;- svdM$u %*% diag(svdM$d)
        m &lt;- dim(H)[1]
        R &lt;- dim(H)[2]
        cmet &lt;- FALSE
        rej &lt;- 0
        while (!cmet) {
            U &lt;- matrix(0, m, R)
            U[, 1] &lt;- rmf.vector(H[, 1])
            lr &lt;- 0
            for (j in seq(2, R, length = R - 1)) {
                N &lt;- NullC(U[, seq(1, j - 1, length = j - 1)])
                x &lt;- rmf.vector(t(N) %*% H[, j])
                U[, j] &lt;- N %*% x
                if (svdM$d[j] &gt; 0) {
                  xn &lt;- sqrt(sum((t(N) %*% H[, j])^2))
                  xd &lt;- sqrt(sum(H[, j]^2))
                  lbr &lt;- log(besselI(xn, 0.5 * (m - j - 1), expon.scaled = TRUE)) - 
                    log(besselI(xd, 0.5 * (m - j - 1), expon.scaled = TRUE))
                  if (is.na(lbr)) {
                    lbr &lt;- 0.5 * (log(xd) - log(xn))
                  }
                  lr &lt;- lr + lbr + (xn - xd) + 0.5 * (m - j - 
                    1) * (log(xd) - log(xn))
                }
            }
            cmet &lt;- (log(runif(1)) &lt; lr)
            rej &lt;- rej + (1 - 1 * cmet)
        }
        X &lt;- U %*% t(svd(M)$v)
    }
    X
  }

</code></pre>

<hr>
<h2 id='rmf.matrix.gibbs'>Gibbs Sampling for the Matrix-variate von Mises-Fisher Distribution</h2><span id='topic+rmf.matrix.gibbs'></span>

<h3>Description</h3>

<p>Simulate a random orthonormal matrix from the matrix von Mises-Fisher
distribution using Gibbs sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmf.matrix.gibbs(M, X, rscol = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmf.matrix.gibbs_+3A_m">M</code></td>
<td>
<p>a matrix.</p>
</td></tr>
<tr><td><code id="rmf.matrix.gibbs_+3A_x">X</code></td>
<td>
<p>the current value of the random orthonormal matrix.</p>
</td></tr>
<tr><td><code id="rmf.matrix.gibbs_+3A_rscol">rscol</code></td>
<td>
<p>the number of columns to update simultaneously.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new value of the matrix <code>X</code> obtained by Gibbs sampling.
</p>


<h3>Note</h3>

<p>This provides one Gibbs scan. The function should be used iteratively.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
Z&lt;-matrix(rnorm(10*5),10,5) 

U&lt;-rmf.matrix(Z)
U&lt;-rmf.matrix.gibbs(Z,U)


## The function is currently defined as
function (M, X, rscol = NULL) 
{
    if (is.null(rscol)) {
        rscol &lt;- max(2, min(round(log(dim(M)[1])), dim(M)[2]))
    }
    sM &lt;- svd(M)
    H &lt;- sM$u %*% diag(sM$d)
    Y &lt;- X %*% sM$v
    m &lt;- dim(H)[1]
    R &lt;- dim(H)[2]
    for (iter in 1:round(R/rscol)) {
        r &lt;- sample(seq(1, R, length = R), rscol)
        N &lt;- NullC(Y[, -r])
        y &lt;- rmf.matrix(t(N) %*% H[, r])
        Y[, r] &lt;- N %*% y
    }
    Y %*% t(sM$v)
  }

</code></pre>

<hr>
<h2 id='rmf.vector'>Simulate a Random Normal Vector</h2><span id='topic+rmf.vector'></span>

<h3>Description</h3>

<p>Simulate a random normal vector from the von Mises-Fisher distribution as
described in Wood(1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmf.vector(kmu)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmf.vector_+3A_kmu">kmu</code></td>
<td>
<p>a vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Wood(1994), Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (kmu) 
{
    kap &lt;- sqrt(sum(kmu^2))
    mu &lt;- kmu/kap
    m &lt;- length(mu)
    if (kap == 0) {
        u &lt;- rnorm(length(kmu))
        u&lt;-matrix(u/sqrt(sum(u^2)),m,1) 
    }
    if (kap &gt; 0) {
        if (m == 1) {
            u &lt;- (-1)^rbinom(1, 1, 1/(1 + exp(2 * kap * mu)))
        }
        if (m &gt; 1) {
            W &lt;- rW(kap, m)
            V &lt;- rnorm(m - 1)
            V &lt;- V/sqrt(sum(V^2))
            x &lt;- c((1 - W^2)^0.5 * t(V), W)
            u &lt;- cbind(NullC(mu), mu) %*% x
        }
    }
    u
  }

</code></pre>

<hr>
<h2 id='rustiefel'>Siumlate a Uniformly Distributed Random Orthonormal Matrix</h2><span id='topic+rustiefel'></span>

<h3>Description</h3>

<p>Siumlate a random orthonormal matrix from the uniform distribution on the
Stiefel manifold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rustiefel(m, R)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rustiefel_+3A_m">m</code></td>
<td>
<p>the length of each column vector.</p>
</td></tr>
<tr><td><code id="rustiefel_+3A_r">R</code></td>
<td>
<p>the number of column vectors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>m*R</code> orthonormal matrix.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2007)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (m, R) 
{
    X &lt;- matrix(rnorm(m * R), m, R)
    tmp &lt;- eigen(t(X) %*% X)
    X %*% (tmp$vec %*% sqrt(diag(1/tmp$val, nrow = R)) %*% t(tmp$vec))
  }

</code></pre>

<hr>
<h2 id='rW'>Simulate <code>W</code> as Described in Wood(1994)</h2><span id='topic+rW'></span>

<h3>Description</h3>

<p>Auxilliary variable simulation for rejection sampling of <code>rmf.vector</code>,
as described in Wood(1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rW(kap, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rW_+3A_kap">kap</code></td>
<td>
<p>a positive scalar.</p>
</td></tr>
<tr><td><code id="rW_+3A_m">m</code></td>
<td>
<p>a positive integer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number between zero and one.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
rW(pi,4)

## The function is currently defined as
function (kap, m) 
{
    .C("rW", kap = as.double(kap), m = as.integer(m), w = double(1))$w
  }

</code></pre>

<hr>
<h2 id='ry_bing'>Helper Function for Sampling a Bingham-distributed Vector</h2><span id='topic+ry_bing'></span>

<h3>Description</h3>

<p>C interface to perform a Gibbs update of <code>y</code> with invariant
distribution proportional to <code>exp( sum(l*y^2) </code> with respect to the
uniform measure on the sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ry_bing(y, l)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ry_bing_+3A_y">y</code></td>
<td>
<p>a normal vector.</p>
</td></tr>
<tr><td><code id="ry_bing_+3A_l">l</code></td>
<td>
<p>a vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a normal vector.
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (y, l) 
{
    .C("ry_bing", y = as.double(y), l = as.double(l), n = as.integer(length(y)))$y
  }

</code></pre>

<hr>
<h2 id='ry_bmf'>Helper Function for Sampling a Bingham-von Mises-Fisher-distributed Vector</h2><span id='topic+ry_bmf'></span>

<h3>Description</h3>

<p>C interface to perform a Gibbs update of <code>y</code> with invariant
distribution proportional to <code>exp( sum(l*y^2+y*d) </code> with respect to the
uniform measure on the sphere.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ry_bmf(y, l, d)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ry_bmf_+3A_y">y</code></td>
<td>
<p>a normal vector.</p>
</td></tr>
<tr><td><code id="ry_bmf_+3A_l">l</code></td>
<td>
<p>a vector.</p>
</td></tr>
<tr><td><code id="ry_bmf_+3A_d">d</code></td>
<td>
<p>a vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a normal vector
</p>


<h3>Author(s)</h3>

<p>Peter Hoff
</p>


<h3>References</h3>

<p>Hoff(2009)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The function is currently defined as
function (y, l, d) 
{
    .C("ry_bmf", y = as.double(y), l = as.double(l), d = as.double(d), 
        n = as.integer(length(y)))$y
  }

</code></pre>

<hr>
<h2 id='tr'>Compute the trace of a matrix</h2><span id='topic+tr'></span>

<h3>Description</h3>

<p>compute the trace of a square matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tr(X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tr_+3A_x">X</code></td>
<td>
<p>Square matrix</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
