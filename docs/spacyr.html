<!DOCTYPE html><html lang="en-GB"><head><title>Help for package spacyr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {spacyr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#spacyr-package'><p>An R wrapper to the spaCy NLP system</p></a></li>
<li><a href='#data_char_paragraph'><p>A short paragraph of text for testing</p></a></li>
<li><a href='#data_char_sentences'><p>Sample short documents for testing</p></a></li>
<li><a href='#entity_extract'><p>Extract or consolidate entities from parsed documents</p></a></li>
<li><a href='#find_spacy'><p>Find spaCy</p></a></li>
<li><a href='#get-functions'><p>get functions for spaCy</p></a></li>
<li><a href='#nounphrase_extract'><p>Extract or consolidate noun phrases from parsed documents</p></a></li>
<li><a href='#process_document'><p>Tokenize text using spaCy</p></a></li>
<li><a href='#spacy_download_langmodel'><p>Download spaCy language models</p></a></li>
<li><a href='#spacy_download_langmodel_virtualenv'><p>Install a language model in a conda or virtual environment</p></a></li>
<li><a href='#spacy_extract_entity'><p>Extract named entities from texts using spaCy</p></a></li>
<li><a href='#spacy_extract_nounphrases'><p>Extract noun phrases from texts using spaCy</p></a></li>
<li><a href='#spacy_finalize'><p>Finalize spaCy</p></a></li>
<li><a href='#spacy_initialize'><p>Initialize spaCy</p></a></li>
<li><a href='#spacy_install'><p>Install spaCy in conda or virtualenv environment</p></a></li>
<li><a href='#spacy_install_virtualenv'><p>Install spaCy to a virtual environment</p></a></li>
<li><a href='#spacy_parse'><p>Parse a text using spaCy</p></a></li>
<li><a href='#spacy_tokenize'><p>Tokenize text with spaCy</p></a></li>
<li><a href='#spacy_uninstall'><p>Uninstall the spaCy environment</p></a></li>
<li><a href='#spacy_upgrade'><p>Shorthand function to upgrade spaCy</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Wrapper to the 'spaCy' 'NLP' Library</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.0</td>
</tr>
<tr>
<td>Description:</td>
<td>An R wrapper to the 'Python' 'spaCy' 'NLP' library,
    from <a href="https://spacy.io">https://spacy.io</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table, reticulate (&ge; 1.6)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dplyr, knitr, quanteda, R.rsp, rmarkdown, spelling, testthat,
tidytext, tibble</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://spacyr.quanteda.io">https://spacyr.quanteda.io</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/quanteda/spacyr/issues">https://github.com/quanteda/spacyr/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-07 16:16:42 UTC; kbenoit</td>
</tr>
<tr>
<td>Author:</td>
<td>Kenneth Benoit <a href="https://orcid.org/0000-0002-0797-564X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut, cph],
  Akitaka Matsuo <a href="https://orcid.org/0000-0002-3323-6330"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Johannes Gruber <a href="https://orcid.org/0000-0001-9177-1772"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  European Research Council [fnd] (ERC-2011-StG 283794-QUANTESS)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kenneth Benoit &lt;kbenoit@lse.ac.uk&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-08 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='spacyr-package'>An R wrapper to the spaCy NLP system</h2><span id='topic+spacyr'></span><span id='topic+spacyr-package'></span>

<h3>Description</h3>

<p>An R wrapper to the Python (Cython) spaCy NLP system, from
<a href="https://spacy.io">https://spacy.io</a>. Nicely integrated with <span class="pkg">quanteda</span>.  <span class="pkg">spacyr</span>
is designed to provide easy access to the powerful functionality of spaCy, in
a simple format.
</p>


<h3>Author(s)</h3>

<p>Ken Benoit and Akitaka Matsuo
</p>


<h3>References</h3>

<p><a href="https://spacy.io">https://spacy.io</a>, <a href="https://spacyr.quanteda.io">https://spacyr.quanteda.io</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://spacyr.quanteda.io">https://spacyr.quanteda.io</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/quanteda/spacyr/issues">https://github.com/quanteda/spacyr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='data_char_paragraph'>A short paragraph of text for testing</h2><span id='topic+data_char_paragraph'></span>

<h3>Description</h3>

<p>A sample of text from the Irish budget debate of 2010 (531 tokens long).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_char_paragraph
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='data_char_sentences'>Sample short documents for testing</h2><span id='topic+data_char_sentences'></span>

<h3>Description</h3>

<p>A character object consisting of 30 short documents in plain text format for
testing.  Each document is one or two brief sentences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data_char_sentences
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 30.
</p>

<hr>
<h2 id='entity_extract'>Extract or consolidate entities from parsed documents</h2><span id='topic+entity_extract'></span><span id='topic+entity_consolidate'></span>

<h3>Description</h3>

<p>From an object parsed by <code><a href="#topic+spacy_parse">spacy_parse()</a></code>, extract the entities as a
separate object, or convert the multi-word entities into single &quot;token&quot;
consisting of the concatenated elements of the multi-word entities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>entity_extract(x, type = c("named", "extended", "all"), concatenator = "_")

entity_consolidate(x, concatenator = "_")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="entity_extract_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+spacy_parse">spacy_parse()</a></code>.</p>
</td></tr>
<tr><td><code id="entity_extract_+3A_type">type</code></td>
<td>
<p>type of named entities, either <code>named</code>, <code>extended</code>, or
<code>all</code>.  See
<a href="https://spacy.io/docs/usage/entity-recognition#entity-types">https://spacy.io/docs/usage/entity-recognition#entity-types</a> for
details.</p>
</td></tr>
<tr><td><code id="entity_extract_+3A_concatenator">concatenator</code></td>
<td>
<p>the character(s) used to join the elements of multi-word
named entities</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>entity_extract()</code> returns a data.frame of all named
entities, containing the following fields:
</p>

<ul>
<li> <p><code>doc_id</code> name of the document containing the entity
</p>
</li>
<li> <p><code>sentence_id</code> the sentence ID containing the entity, within the document
</p>
</li>
<li> <p><code>entity</code> the named entity
</p>
</li>
<li> <p><code>entity_type</code> the type of named entities (e.g. PERSON, ORG, PERCENT, etc.)
</p>
</li></ul>

<p><code>entity_consolidate</code> returns a modified <code>data.frame</code> of
parsed results, where the named entities have been combined into a single
&quot;token&quot;.  Currently, dependency parsing is removed when this consolidation
occurs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()

# entity extraction
txt &lt;- "Mr. Smith of moved to San Francisco in December."
parsed &lt;- spacy_parse(txt, entity = TRUE)
entity_extract(parsed)
entity_extract(parsed, type = "all")

## End(Not run)
## Not run: 
# consolidating multi-word entities 
txt &lt;- "The House of Representatives voted to suspend aid to South Dakota."
parsed &lt;- spacy_parse(txt, entity = TRUE)
entity_consolidate(parsed)

## End(Not run)
</code></pre>

<hr>
<h2 id='find_spacy'>Find spaCy</h2><span id='topic+find_spacy'></span>

<h3>Description</h3>

<p>Locate the user's version of Python for which spaCy installed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_spacy(model = "en_core_web_sm", ask)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="find_spacy_+3A_model">model</code></td>
<td>
<p>name of the language model</p>
</td></tr>
<tr><td><code id="find_spacy_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>FALSE</code>, use the first spaCy installation found;
if <code>TRUE</code>, list available spaCy installations and prompt the user
for which to use. If another (e.g. <code>python_executable</code>) is set, then
this value will always be treated as <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spacy_python
</p>

<hr>
<h2 id='get-functions'>get functions for spaCy</h2><span id='topic+get-functions'></span><span id='topic+get_tokens'></span><span id='topic+get_tags'></span><span id='topic+get_attrs'></span><span id='topic+get_named_entities'></span><span id='topic+get_dependency'></span><span id='topic+get_noun_phrases'></span><span id='topic+get_ntokens'></span><span id='topic+get_ntokens_by_sent'></span>

<h3>Description</h3>

<p>A collection of get methods for spacyr return objects (of <code>spacy_out</code> class).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_tokens(spacy_out)

get_tags(spacy_out, tagset = c("google", "detailed"))

get_attrs(spacy_out, attr_name, deal_utf8 = FALSE)

get_named_entities(spacy_out)

get_dependency(spacy_out)

get_noun_phrases(spacy_out)

get_ntokens(spacy_out)

get_ntokens_by_sent(spacy_out)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get-functions_+3A_spacy_out">spacy_out</code></td>
<td>
<p>a spacy_out object</p>
</td></tr>
<tr><td><code id="get-functions_+3A_tagset">tagset</code></td>
<td>
<p>character label for the tagset to use, either <code>"google"</code>
or <code>"detailed"</code> to use the simplified Google tagset, or the more detailed
scheme from the Penn Treebank (or the German Text Archive in case of German language model).</p>
</td></tr>
<tr><td><code id="get-functions_+3A_attr_name">attr_name</code></td>
<td>
<p>name of spaCy token attributes to extract</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_tokens</code> returns a data.frame of tokens from spaCy.
</p>
<p><code>get_tags</code> returns a tokenized text object with part-of-speech tags.
Options exist for using either the Google or Detailed tagsets. See
<a href="https://spacy.io">https://spacy.io</a>.
</p>
<p><code>get_attrs</code> returns a list of attributes from spaCy output
</p>
<p><code>get_named_entities</code> returns a list of named entities in texts
</p>
<p><code>get_dependency</code> returns a data.frame of dependency relations.
</p>
<p><code>get_noun_phrases</code> returns a data.frame of noun phrases.
</p>
<p><code>get_ntokens</code> returns a data.frame of dependency relations
</p>
<p><code>get_ntokens_by_sent</code> returns a data.frame of dependency
relations, by sentence
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# get_tags examples
txt &lt;- c(text1 = "This is the first sentence.\nHere is the second sentence.", 
         text2 = "This is the second document.")
results &lt;- spacy_parse(txt)
tokens &lt;- tokens(results)
tokens_with_tag &lt;- tokens_tag(tokens)


## End(Not run)
</code></pre>

<hr>
<h2 id='nounphrase_extract'>Extract or consolidate noun phrases from parsed documents</h2><span id='topic+nounphrase_extract'></span><span id='topic+nounphrase_consolidate'></span>

<h3>Description</h3>

<p>From an object parsed by <code><a href="#topic+spacy_parse">spacy_parse()</a></code>, extract the multi-word
noun phrases as a separate object, or convert the multi-word noun phrases
into single &quot;token&quot; consisting of the concatenated elements of the multi-word
noun phrases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nounphrase_extract(x, concatenator = "_")

nounphrase_consolidate(x, concatenator = "_")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nounphrase_extract_+3A_x">x</code></td>
<td>
<p>output from <code><a href="#topic+spacy_parse">spacy_parse()</a></code></p>
</td></tr>
<tr><td><code id="nounphrase_extract_+3A_concatenator">concatenator</code></td>
<td>
<p>the character(s) used to join elements of multi-word
noun phrases</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>noun</code> returns a <code>data.frame</code> of all named
entities, containing the following fields:
</p>

<ul>
<li> <p><code>doc_id</code> name of the document containing the noun phrase
</p>
</li>
<li> <p><code>sentence_id</code> the sentence ID containing the noun phrase, within the document
</p>
</li>
<li> <p><code>nounphrase</code> the noun phrase
</p>
</li>
<li> <p><code>root</code> the root token of the noun phrase
</p>
</li></ul>

<p><code>nounphrase_consolidate</code> returns a modified <code>data.frame</code> of
parsed results, where the noun phrases have been combined into a single
&quot;token&quot;.  Currently, dependency parsing is removed when this consolidation
occurs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()

# entity extraction
txt &lt;- "Mr. Smith of moved to San Francisco in December."
parsed &lt;- spacy_parse(txt, nounphrase = TRUE)
entity_extract(parsed)

## End(Not run)
## Not run: 
# consolidating multi-word noun phrases
txt &lt;- "The House of Representatives voted to suspend aid to South Dakota."
parsed &lt;- spacy_parse(txt, nounphrase = TRUE)
nounphrase_consolidate(parsed)

## End(Not run)
</code></pre>

<hr>
<h2 id='process_document'>Tokenize text using spaCy</h2><span id='topic+process_document'></span>

<h3>Description</h3>

<p>Tokenize text using spaCy. The results of tokenization is stored as a Python
object. To obtain the tokens results in R, use <code>get_tokens()</code>.
<a href="https://spacy.io">https://spacy.io</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>process_document(x, multithread, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="process_document_+3A_x">x</code></td>
<td>
<p>input text
functionalities including the tagging, named entity recognition, dependency
analysis.
This slows down <code>spacy_parse()</code> but speeds up the later parsing.
If FALSE, tagging, entity recognition, and dependency analysis when
relevant functions are called.</p>
</td></tr>
<tr><td><code id="process_document_+3A_multithread">multithread</code></td>
<td>
<p>logical;</p>
</td></tr>
<tr><td><code id="process_document_+3A_...">...</code></td>
<td>
<p>arguments passed to specific methods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>result marker object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()
# the result has to be "tag() is ready to run" to run the following
txt &lt;- c(text1 = "This is the first sentence.\nHere is the second sentence.", 
         text2 = "This is the second document.")
results &lt;- spacy_parse(txt)

## End(Not run)
</code></pre>

<hr>
<h2 id='spacy_download_langmodel'>Download spaCy language models</h2><span id='topic+spacy_download_langmodel'></span>

<h3>Description</h3>

<p>Download spaCy language models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_download_langmodel(lang_models = "en_core_web_sm", force = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_download_langmodel_+3A_lang_models">lang_models</code></td>
<td>
<p>character; language models to be installed. Defaults
<code>en_core_web_sm</code> (English model). A vector of multiple model names can
be used (e.g. <code>c("en_core_web_sm", "de_core_news_sm")</code>). A list of
available language models and their
names is available from the <a href="https://spacy.io/usage/models">spaCy language models</a> page.</p>
</td></tr>
<tr><td><code id="spacy_download_langmodel_+3A_force">force</code></td>
<td>
<p>ignore if spaCy/the lang_models is already present and install
it anyway.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly returns the installation log.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# install medium sized model
spacy_download_langmodel("en_core_web_md")

#' # install several models with spaCy
spacy_install(lang_models = c("en_core_web_sm", "de_core_news_sm"))

# install transformer based model
spacy_download_langmodel("en_core_web_trf")

## End(Not run)
</code></pre>

<hr>
<h2 id='spacy_download_langmodel_virtualenv'>Install a language model in a conda or virtual environment</h2><span id='topic+spacy_download_langmodel_virtualenv'></span>

<h3>Description</h3>

<p>Deprecated. <code>spacyr</code> now always uses a virtual environment,
making this function redundant.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_download_langmodel_virtualenv(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_download_langmodel_virtualenv_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>

<hr>
<h2 id='spacy_extract_entity'>Extract named entities from texts using spaCy</h2><span id='topic+spacy_extract_entity'></span>

<h3>Description</h3>

<p>This function extracts named entities from texts, based on the entity tag
<code>ent</code> attributes of documents objects parsed by spaCy (see
<a href="https://spacy.io/usage/linguistic-features#section-named-entities">https://spacy.io/usage/linguistic-features#section-named-entities</a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_extract_entity(
  x,
  output = c("data.frame", "list"),
  type = c("all", "named", "extended"),
  multithread = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_extract_entity_+3A_x">x</code></td>
<td>
<p>a character object or a TIF-compliant
corpus data.frame (see <a href="https://github.com/ropenscilabs/tif">https://github.com/ropenscilabs/tif</a>)</p>
</td></tr>
<tr><td><code id="spacy_extract_entity_+3A_output">output</code></td>
<td>
<p>type of returned object, either <code>"list"</code> or
<code>"data.frame"</code>.</p>
</td></tr>
<tr><td><code id="spacy_extract_entity_+3A_type">type</code></td>
<td>
<p>type of named entities, either <code>named</code>, <code>extended</code>, or
<code>all</code>.  See
<a href="https://spacy.io/docs/usage/entity-recognition#entity-types">https://spacy.io/docs/usage/entity-recognition#entity-types</a> for
details.</p>
</td></tr>
<tr><td><code id="spacy_extract_entity_+3A_multithread">multithread</code></td>
<td>
<p>logical; If <code>TRUE</code>, the processing is parallelized
using spaCy's architecture (<a href="https://spacy.io/api">https://spacy.io/api</a>)</p>
</td></tr>
<tr><td><code id="spacy_extract_entity_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the option <code>output = "data.frame"</code> is selected, the
function returns a <code>data.frame</code> with the following fields.
</p>
<dl>
<dt><code>text</code></dt><dd><p>contents of entity</p>
</dd>
<dt><code>entity_type</code></dt><dd><p>type of entity (e.g. <code>ORG</code> for
organizations)</p>
</dd> <dt><code>start_id</code></dt><dd><p>serial number ID of starting token.
This number corresponds with the number of <code>data.frame</code> returned from
<code>spacy_tokenize(x)</code> with default options.</p>
</dd> <dt><code>length</code></dt><dd><p>number
of words (tokens) included in a named entity (e.g. for an entity, &quot;New York
Stock Exchange&quot;&quot;, <code>length = 4</code>)</p>
</dd></dl>



<h3>Value</h3>

<p>either a <code>list</code> or <code>data.frame</code> of tokens
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()

txt &lt;- c(doc1 = "The Supreme Court is located in Washington D.C.",
         doc2 = "Paul earned a postgraduate degree from MIT.")
spacy_extract_entity(txt)
spacy_extract_entity(txt, output = "list")

## End(Not run)
</code></pre>

<hr>
<h2 id='spacy_extract_nounphrases'>Extract noun phrases from texts using spaCy</h2><span id='topic+spacy_extract_nounphrases'></span>

<h3>Description</h3>

<p>This function extracts noun phrases from documents, based on the
<code>noun_chunks</code> attributes of documents objects parsed by spaCy (see
<a href="https://spacy.io/usage/linguistic-features#noun-chunks">https://spacy.io/usage/linguistic-features#noun-chunks</a>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_extract_nounphrases(
  x,
  output = c("data.frame", "list"),
  multithread = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_extract_nounphrases_+3A_x">x</code></td>
<td>
<p>a character object or a TIF-compliant corpus data.frame (see
<a href="https://github.com/ropenscilabs/tif">https://github.com/ropenscilabs/tif</a>)</p>
</td></tr>
<tr><td><code id="spacy_extract_nounphrases_+3A_output">output</code></td>
<td>
<p>type of returned object, either <code>"data.frame"</code> or
<code>"list"</code></p>
</td></tr>
<tr><td><code id="spacy_extract_nounphrases_+3A_multithread">multithread</code></td>
<td>
<p>logical; If <code>TRUE</code>, the processing is parallelized
using spaCy's architecture (<a href="https://spacy.io/api">https://spacy.io/api</a>)</p>
</td></tr>
<tr><td><code id="spacy_extract_nounphrases_+3A_...">...</code></td>
<td>
<p>unused</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the option <code>output = "data.frame"</code> is selected, the
function returns a <code>data.frame</code> with the following fields.
</p>
<dl>
<dt><code>text</code></dt><dd><p>contents of noun-phrase</p>
</dd>
<dt><code>root_text</code></dt><dd><p>contents of root token</p>
</dd>
<dt><code>start_id</code></dt><dd><p>serial number ID of starting token. This number
corresponds with the number of <code>data.frame</code> returned from
<code>spacy_tokenize(x)</code> with default options.</p>
</dd>
<dt><code>root_id</code></dt><dd><p>serial number ID of root token</p>
</dd>
<dt><code>length</code></dt><dd><p>number of words (tokens) included in a noun-phrase (e.g.
for a noun-phrase, &quot;individual car owners&quot;, <code>length = 3</code>)</p>
</dd></dl>



<h3>Value</h3>

<p>either a <code>list</code> or <code>data.frame</code> of tokens
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()

txt &lt;- c(doc1 = "Natural language processing is a branch of computer science.",
         doc2 = "Paul earned a postgraduate degree from MIT.")
spacy_extract_nounphrases(txt)
spacy_extract_nounphrases(txt, output = "list")

## End(Not run)
</code></pre>

<hr>
<h2 id='spacy_finalize'>Finalize spaCy</h2><span id='topic+spacy_finalize'></span>

<h3>Description</h3>

<p>While running spaCy on Python through R, a Python process is always running
in the background and Rsession will take up a lot of memory (typically over
1.5GB). <code>spacy_finalize()</code> terminates the Python process and frees up
the memory it was using.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_finalize()
</code></pre>


<h3>Author(s)</h3>

<p>Akitaka Matsuo
</p>

<hr>
<h2 id='spacy_initialize'>Initialize spaCy</h2><span id='topic+spacy_initialize'></span>

<h3>Description</h3>

<p>Initialize spaCy to call from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_initialize(model = "en_core_web_sm", entity = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_initialize_+3A_model">model</code></td>
<td>
<p>Language package for loading spaCy. Example: <code>en_core_web_sm</code> (English) and
<code>de_core_web_sm</code> (German). Default is <code>en_core_web_sm</code>.</p>
</td></tr>
<tr><td><code id="spacy_initialize_+3A_entity">entity</code></td>
<td>
<p>logical; if <code>FALSE</code> is selected, named entity recognition
is turned off in spaCy. This will speed up the parsing as it will exclude
<code>ner</code> from the pipeline. For details of spaCy pipeline, see
<a href="https://spacy.io/usage/processing-pipelines">https://spacy.io/usage/processing-pipelines</a>. The option <code>FALSE</code>
is available only for spaCy version 2.0.0 or higher.</p>
</td></tr>
<tr><td><code id="spacy_initialize_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Akitaka Matsuo, Johannes B. Gruber
</p>

<hr>
<h2 id='spacy_install'>Install spaCy in conda or virtualenv environment</h2><span id='topic+spacy_install'></span>

<h3>Description</h3>

<p>Install spaCy in a self-contained environment, including
specified language models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_install(
  version = "latest",
  lang_models = "en_core_web_sm",
  ask = interactive(),
  force = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_install_+3A_version">version</code></td>
<td>
<p>character; spaCy version to install (see details).</p>
</td></tr>
<tr><td><code id="spacy_install_+3A_lang_models">lang_models</code></td>
<td>
<p>character; language models to be installed. Defaults
<code>en_core_web_sm</code> (English model). A vector of multiple model names can
be used (e.g. <code>c("en_core_web_sm", "de_core_news_sm")</code>). A list of
available language models and their
names is available from the <a href="https://spacy.io/usage/models">spaCy language models</a> page.</p>
</td></tr>
<tr><td><code id="spacy_install_+3A_ask">ask</code></td>
<td>
<p>logical; ask whether to proceed during the installation. By
default, questions are only asked in interactive sessions.</p>
</td></tr>
<tr><td><code id="spacy_install_+3A_force">force</code></td>
<td>
<p>ignore if spaCy/the lang_models is already present and install
it anyway.</p>
</td></tr>
<tr><td><code id="spacy_install_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function checks whether a suitable installation of Python is
present on the system and installs one via
<code><a href="reticulate.html#topic+install_python">reticulate::install_python()</a></code> otherwise. It then creates a
virtual environment with the necessary packages in the default location
chosen by <code><a href="reticulate.html#topic+virtualenv-tools">reticulate::virtualenv_root()</a></code>.
</p>
<p>If you want to install a different version of Python than the default, you
should call <code><a href="reticulate.html#topic+install_python">reticulate::install_python()</a></code> directly. If you want
to create or use a different virtual environment, you can use, e.g.,
<code>Sys.setenv(SPACY_PYTHON = "path/to/directory")</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spacy_download_langmodel">spacy_download_langmodel()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# install the latest version of spaCy
spacy_install()

# update spaCy
spacy_install(force = TRUE)

# install an older version
spacy_install(version = "3.1.0")

# install with GPU enabled
spacy_install(version = "cuda-autodetect")

# install on Apple ARM processors
spacy_install(version = "apple")

# install an old custom version
spacy_install(version = "[cuda-autodetect]==3.2.0")

# install several models with spaCy
spacy_install(lang_models = c("en_core_web_sm", "de_core_news_sm"))


# install spaCy to an existing virtual environment
Sys.setenv(RETICULATE_PYTHON = "path/to/python")
spacy_install()

## End(Not run)

</code></pre>

<hr>
<h2 id='spacy_install_virtualenv'>Install spaCy to a virtual environment</h2><span id='topic+spacy_install_virtualenv'></span>

<h3>Description</h3>

<p>Deprecated. <code>spacy_install</code> now installs to a virtual environment by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_install_virtualenv(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_install_virtualenv_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>

<hr>
<h2 id='spacy_parse'>Parse a text using spaCy</h2><span id='topic+spacy_parse'></span>

<h3>Description</h3>

<p>The <code>spacy_parse()</code> function calls spaCy to both tokenize and tag the
texts, and returns a data.table of the results. The function provides options
on the types of tagsets (<code>tagset_</code> options) either  <code>"google"</code> or
<code>"detailed"</code>, as well as lemmatization (<code>lemma</code>). It provides a
functionalities of dependency parsing and named entity recognition as an
option. If <code>"full_parse = TRUE"</code> is provided, the function returns the
most extensive list of the parsing results from spaCy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_parse(
  x,
  pos = TRUE,
  tag = FALSE,
  lemma = TRUE,
  entity = TRUE,
  dependency = FALSE,
  nounphrase = FALSE,
  multithread = TRUE,
  additional_attributes = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_parse_+3A_x">x</code></td>
<td>
<p>a character object, a <span class="pkg">quanteda</span> corpus, or a TIF-compliant
corpus data.frame (see <a href="https://github.com/ropenscilabs/tif">https://github.com/ropenscilabs/tif</a>)</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_pos">pos</code></td>
<td>
<p>logical whether to return universal dependency POS tagset
<a href="https://universaldependencies.org/u/pos/">https://universaldependencies.org/u/pos/</a>)</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_tag">tag</code></td>
<td>
<p>logical whether to return detailed part-of-speech tags, for the
language model <code>en</code>, it uses the OntoNotes 5 version of the Penn
Treebank tag set
(<a href="https://spacy.io/docs/usage/pos-tagging#pos-schemes">https://spacy.io/docs/usage/pos-tagging#pos-schemes</a>). Annotation
specifications for other available languages are available on the spaCy
website (<a href="https://spacy.io/api/annotation">https://spacy.io/api/annotation</a>).</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_lemma">lemma</code></td>
<td>
<p>logical; include lemmatized tokens in the output (lemmatization
may not work properly for non-English models)</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_entity">entity</code></td>
<td>
<p>logical; if <code>TRUE</code>, report named entities</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_dependency">dependency</code></td>
<td>
<p>logical; if <code>TRUE</code>, analyse and tag dependencies</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_nounphrase">nounphrase</code></td>
<td>
<p>logical; if <code>TRUE</code>, analyse and tag noun phrases
tags</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_multithread">multithread</code></td>
<td>
<p>logical; If <code>TRUE</code>, the processing is parallelized
using spaCy's architecture (<a href="https://spacy.io/api">https://spacy.io/api</a>)</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_additional_attributes">additional_attributes</code></td>
<td>
<p>a character vector; this option is for
extracting additional attributes of tokens from spaCy. When the names of
attributes are supplied, the output data.frame will contain additional
variables corresponding to the names of the attributes. For instance, when
<code>additional_attributes = c("is_punct")</code>, the output will include an
additional variable named <code>is_punct</code>, which is a Boolean (in R,
logical) variable indicating whether  the token is a punctuation. A full
list of available attributes is available from
<a href="https://spacy.io/api/token#attributes">https://spacy.io/api/token#attributes</a>.</p>
</td></tr>
<tr><td><code id="spacy_parse_+3A_...">...</code></td>
<td>
<p>not used directly</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> of tokenized, parsed, and annotated tokens
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()
# See Chap 5.1 of the NLTK book, http://www.nltk.org/book/ch05.html
txt &lt;- "And now for something completely different."
spacy_parse(txt)
spacy_parse(txt, pos = TRUE, tag = TRUE)
spacy_parse(txt, dependency = TRUE)

txt2 &lt;- c(doc1 = "The fast cat catches mice.\\nThe quick brown dog jumped.", 
          doc2 = "This is the second document.",
          doc3 = "This is a \\\"quoted\\\" text." )
spacy_parse(txt2, entity = TRUE, dependency = TRUE)

txt3 &lt;- "We analyzed the Supreme Court with three natural language processing tools." 
spacy_parse(txt3, entity = TRUE, nounphrase = TRUE)
spacy_parse(txt3, additional_attributes = c("like_num", "is_punct"))

## End(Not run)
</code></pre>

<hr>
<h2 id='spacy_tokenize'>Tokenize text with spaCy</h2><span id='topic+spacy_tokenize'></span>

<h3>Description</h3>

<p>Efficient tokenization (without POS tagging, dependency parsing,
lemmatization, or named entity recognition) of texts using spaCy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_tokenize(
  x,
  what = c("word", "sentence"),
  remove_punct = FALSE,
  remove_url = FALSE,
  remove_numbers = FALSE,
  remove_separators = TRUE,
  remove_symbols = FALSE,
  padding = FALSE,
  multithread = TRUE,
  output = c("list", "data.frame"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_tokenize_+3A_x">x</code></td>
<td>
<p>a character object, a <span class="pkg">quanteda</span> corpus, or a TIF-compliant
corpus data.frame (see <a href="https://github.com/ropenscilabs/tif">https://github.com/ropenscilabs/tif</a>)</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_what">what</code></td>
<td>
<p>the unit for splitting the text, available alternatives are:
</p>
 <dl>
<dt><code>"word"</code></dt><dd><p>word segmenter</p>
</dd>
<dt><code>"sentence"</code></dt><dd><p>sentence segmenter </p>
</dd></dl>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_remove_punct">remove_punct</code></td>
<td>
<p>remove punctuation tokens.</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_remove_url">remove_url</code></td>
<td>
<p>remove tokens that look like a url or email address.</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_remove_numbers">remove_numbers</code></td>
<td>
<p>remove tokens that look like a number (e.g. &quot;334&quot;, &quot;3.1415&quot;, &quot;fifty&quot;).</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_remove_separators">remove_separators</code></td>
<td>
<p>remove spaces as separators when
all other remove functionalities (e.g. <code>remove_punct</code>) have to be set to <code>FALSE</code>.
When <code>what = "sentence"</code>, this option will remove trailing spaces if <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_remove_symbols">remove_symbols</code></td>
<td>
<p>remove symbols. The symbols are either <code>SYM</code> in <code>pos</code>
field, or currency symbols.</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_padding">padding</code></td>
<td>
<p>if <code>TRUE</code>, leave an empty string where the removed tokens
previously existed. This is useful if a positional match is needed between
the pre- and post-selected tokens, for instance if a window of adjacency
needs to be computed.</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_multithread">multithread</code></td>
<td>
<p>logical; If <code>TRUE</code>, the processing is parallelized
using spaCy's architecture (<a href="https://spacy.io/api">https://spacy.io/api</a>)</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_output">output</code></td>
<td>
<p>type of returning object. Either <code>list</code> or <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="spacy_tokenize_+3A_...">...</code></td>
<td>
<p>not used directly</p>
</td></tr>
</table>


<h3>Value</h3>

<p>either <code>list</code> or <code>data.frame</code> of tokens
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
spacy_initialize()
txt &lt;- "And now for something completely different."
spacy_tokenize(txt)

txt2 &lt;- c(doc1 = "The fast cat catches mice.\\nThe quick brown dog jumped.", 
          doc2 = "This is the second document.",
          doc3 = "This is a \\\"quoted\\\" text." )
spacy_tokenize(txt2)

## End(Not run)
</code></pre>

<hr>
<h2 id='spacy_uninstall'>Uninstall the spaCy environment</h2><span id='topic+spacy_uninstall'></span>

<h3>Description</h3>

<p>Removes the virtual environment created by spacy_install()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_uninstall(confirm = interactive())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_uninstall_+3A_confirm">confirm</code></td>
<td>
<p>logical; confirm before uninstalling spaCy?</p>
</td></tr>
</table>

<hr>
<h2 id='spacy_upgrade'>Shorthand function to upgrade spaCy</h2><span id='topic+spacy_upgrade'></span>

<h3>Description</h3>

<p>Upgrade spaCy (to a specific version).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spacy_upgrade(
  version = "latest",
  lang_models = NULL,
  ask = interactive(),
  force = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spacy_upgrade_+3A_version">version</code></td>
<td>
<p>character; spaCy version to install (see details).</p>
</td></tr>
<tr><td><code id="spacy_upgrade_+3A_lang_models">lang_models</code></td>
<td>
<p>character; language models to be installed. Defaults
<code>en_core_web_sm</code> (English model). A vector of multiple model names can
be used (e.g. <code>c("en_core_web_sm", "de_core_news_sm")</code>). A list of
available language models and their
names is available from the <a href="https://spacy.io/usage/models">spaCy language models</a> page.</p>
</td></tr>
<tr><td><code id="spacy_upgrade_+3A_ask">ask</code></td>
<td>
<p>logical; ask whether to proceed during the installation. By
default, questions are only asked in interactive sessions.</p>
</td></tr>
<tr><td><code id="spacy_upgrade_+3A_force">force</code></td>
<td>
<p>ignore if spaCy/the lang_models is already present and install
it anyway.</p>
</td></tr>
<tr><td><code id="spacy_upgrade_+3A_...">...</code></td>
<td>
<p>passed on to <code><a href="#topic+spacy_install">spacy_install()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function checks whether a suitable installation of Python is
present on the system and installs one via
<code><a href="reticulate.html#topic+install_python">reticulate::install_python()</a></code> otherwise. It then creates a
virtual environment with the necessary packages in the default location
chosen by <code><a href="reticulate.html#topic+virtualenv-tools">reticulate::virtualenv_root()</a></code>.
</p>
<p>If you want to install a different version of Python than the default, you
should call <code><a href="reticulate.html#topic+install_python">reticulate::install_python()</a></code> directly. If you want
to create or use a different virtual environment, you can use, e.g.,
<code>Sys.setenv(SPACY_PYTHON = "path/to/directory")</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spacy_download_langmodel">spacy_download_langmodel()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# install the latest version of spaCy
spacy_install()

# update spaCy
spacy_install(force = TRUE)

# install an older version
spacy_install(version = "3.1.0")

# install with GPU enabled
spacy_install(version = "cuda-autodetect")

# install on Apple ARM processors
spacy_install(version = "apple")

# install an old custom version
spacy_install(version = "[cuda-autodetect]==3.2.0")

# install several models with spaCy
spacy_install(lang_models = c("en_core_web_sm", "de_core_news_sm"))


# install spaCy to an existing virtual environment
Sys.setenv(RETICULATE_PYTHON = "path/to/python")
spacy_install()

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
