<!DOCTYPE html><html><head><title>Help for package EEMDelm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EEMDelm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CEEMDANelm'>
<p>Complementary Ensemble Empirical Mode Decomposition with Adaptive Noise Based ELM Model</p></a></li>
<li><a href='#Data_Soybean'>
<p>Monthly International Soybean Oil Price</p></a></li>
<li><a href='#EEMDELM'>
<p>Ensemble Empirical Mode Decomposition Based ELM Model</p></a></li>
<li><a href='#EMDelm'>
<p>Empirical Mode Decomposition Based ELM Model</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Ensemble Empirical Mode Decomposition and Its Variant Based ELM
Model</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Girish Kumar Jha &lt;girish.stat@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Forecasting univariate time series with different decomposition based Extreme Learning Machine models. For method details see Yu L, Wang S, Lai KK (2008). &lt;<a href="https://doi.org/10.1016%2Fj.eneco.2008.05.003">doi:10.1016/j.eneco.2008.05.003</a>&gt;, Parida M, Behera MK, Nayak N (2018). &lt;<a href="https://doi.org/10.1109%2FICSESP.2018.8376723">doi:10.1109/ICSESP.2018.8376723</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>forecast, nnfor, Rlibeemd</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-08-09 04:18:18 UTC; kapil</td>
</tr>
<tr>
<td>Author:</td>
<td>Girish Kumar Jha [aut, cre],
  Kapil Choudhary [aut, ctb],
  Rajeev Ranjan Kumar [ctb],
  Ronit Jaiswal [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-08-09 06:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='CEEMDANelm'>
Complementary Ensemble Empirical Mode Decomposition with Adaptive Noise Based ELM Model
</h2><span id='topic+CEEMDANelm'></span>

<h3>Description</h3>

<p>The CEEMDANelm function computes forecasted value with different forecasting evaluation criteria for Complementary Ensemble Empirical Mode Decomposition with Adaptive Noise based Extreme Learning Machine model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CEEMDANelm(data, stepahead=10,
num.IMFs=emd_num_imfs(length(data)),
s.num=4L, num.sift=50L, ensem.size=250L, noise.st=0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CEEMDANelm_+3A_data">data</code></td>
<td>

<p>Input univariate time series (ts) data.
</p>
</td></tr>
<tr><td><code id="CEEMDANelm_+3A_stepahead">stepahead</code></td>
<td>

<p>The forecast horizon.
</p>
</td></tr>
<tr><td><code id="CEEMDANelm_+3A_num.imfs">num.IMFs</code></td>
<td>

<p>Number of Intrinsic Mode Function (IMF) for input series.
</p>
</td></tr>
<tr><td><code id="CEEMDANelm_+3A_s.num">s.num</code></td>
<td>

<p>Integer. Use the S number stopping criterion for the EMD procedure with the given values of S. That is, iterate until the number of extrema and zero crossings in the signal differ at most by one, and stay the same for S consecutive iterations.
</p>
</td></tr>
<tr><td><code id="CEEMDANelm_+3A_num.sift">num.sift</code></td>
<td>

<p>Number of siftings to find out IMFs.
</p>
</td></tr>
<tr><td><code id="CEEMDANelm_+3A_ensem.size">ensem.size</code></td>
<td>

<p>Number of copies of the input signal to use as the ensemble.
</p>
</td></tr>
<tr><td><code id="CEEMDANelm_+3A_noise.st">noise.st</code></td>
<td>

<p>Standard deviation of the Gaussian random numbers used as additional noise. This value is relative to the standard deviation of the input series.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Some useless IMFs are generated in EMD and EEMD, which degrades performance of these algorithms. Therefore, reducing the number of these useless IMFs is advantageous for improving the computation efficiency of these techniques, Torres et al.(2011) proposed CEEMDAN. Fewer IMFs may be generated on the premise of successfully separating different components of a series by using this algorithm, which can reduce the computational cost.
</p>


<h3>Value</h3>

<table>
<tr><td><code>TotalIMF</code></td>
<td>
<p>Total number of IMFs.</p>
</td></tr>
<tr><td><code>AllIMF</code></td>
<td>
<p>List of all IMFs with residual for input series.</p>
</td></tr>       <tr><td><code>data_test</code></td>
<td>
<p>Testing set is used to measure the out of sample performance.</p>
</td></tr>
<tr><td><code>AllIMF_forecast</code></td>
<td>
<p>Forecasted value of all individual IMF</p>
</td></tr>
<tr><td><code>FinalCEEMDANELM_forecast</code></td>
<td>
<p>Final forecasted value of the CEEMDANELM model.It is obtained by combining the forecasted value of all individual IMF.</p>
</td></tr>
<tr><td><code>MAE_CEEMDANELM</code></td>
<td>
<p>Mean Absolute Error (MAE) for CEEMDANELM model.</p>
</td></tr>
<tr><td><code>MAPE_CEEMDANELM</code></td>
<td>
<p>Mean Absolute Percentage Error (MAPE) for CEEMDANELM  model.</p>
</td></tr>
<tr><td><code>rmse_CEEMDANELM</code></td>
<td>
<p>Root Mean Square Error (RMSE) for CEEMDANELM model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Huang, G.B., Zhu, Q.Y. and Siew, C.K. (2006). Extreme learning machine: theory and applications. Neurocomputing, 70, 489&ndash;501.
</p>
<p>Torres, M.E., Colominas, M.A., Schlotthauer, G. and Flandrin, P. (2011) A complete ensemble empirical mode decomposition with adaptive noise. In 2011 IEEE international conference on acoustics, speech and signal processing (ICASSP) (pp. 4144&ndash;4147). IEEE.
</p>
<p>Wu, Z. and Huang, N.E. (2009) Ensemble empirical mode decomposition: a noise assisted data analysis method. Advances in adaptive data analysis, 1(1), 1&ndash;41.
</p>


<h3>See Also</h3>

<p>EMDelm, EEMDELM
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Data_Soybean")
CEEMDANelm(Data_Soybean)

</code></pre>

<hr>
<h2 id='Data_Soybean'>
Monthly International Soybean Oil Price
</h2><span id='topic+Data_Soybean'></span>

<h3>Description</h3>

<p>Monthly international Soyabean oil price from August 2001 to June 2020.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Data_Soybean")</code></pre>


<h3>Format</h3>

<p>A time series data with 227 observations.
</p>

<dl>
<dt><code>price</code></dt><dd><p>a time series</p>
</dd>
</dl>



<h3>Details</h3>

<p>Dataset contains 227 observations of monthly international Soyabean oil price. It is obtained from World Bank &quot;Pink sheet&quot;.
</p>


<h3>Source</h3>

<p>https://www.worldbank.org/en/research/commodity-markets
</p>


<h3>References</h3>

<p>https://www.worldbank.org/en/research/commodity-markets
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Data_Soybean)
</code></pre>

<hr>
<h2 id='EEMDELM'>
Ensemble Empirical Mode Decomposition Based ELM Model
</h2><span id='topic+EEMDELM'></span>

<h3>Description</h3>

<p>The EEMDelm function computes forecasted value with different forecasting evaluation criteria for Ensemble Empirical Mode Decomposition based Extreme Learning Machine model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EEMDELM(data, stepahead=10,
num.IMFs=emd_num_imfs(length(data)), s.num=4L,
num.sift=50L, ensem.size=250L, noise.st=0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EEMDELM_+3A_data">data</code></td>
<td>

<p>Input univariate time series (ts) data.
</p>
</td></tr>
<tr><td><code id="EEMDELM_+3A_stepahead">stepahead</code></td>
<td>

<p>The forecast horizon.
</p>
</td></tr>
<tr><td><code id="EEMDELM_+3A_num.imfs">num.IMFs</code></td>
<td>

<p>Number of Intrinsic Mode Function (IMF) for input series.
</p>
</td></tr>
<tr><td><code id="EEMDELM_+3A_s.num">s.num</code></td>
<td>

<p>Integer. Use the S number stopping criterion for the EMD procedure with the given values of S. That is, iterate until the number of extrema and zero crossings in the signal differ at most by one, and stay the same for S consecutive iterations.
</p>
</td></tr>
<tr><td><code id="EEMDELM_+3A_num.sift">num.sift</code></td>
<td>

<p>Number of siftings to find out IMFs.
</p>
</td></tr>
<tr><td><code id="EEMDELM_+3A_ensem.size">ensem.size</code></td>
<td>

<p>Number of copies of the input signal to use as the ensemble.
</p>
</td></tr>
<tr><td><code id="EEMDELM_+3A_noise.st">noise.st</code></td>
<td>

<p>Standard deviation of the Gaussian random numbers used as additional noise. This value is relative to the standard deviation of the input series.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To overcome the problem of EMD (i.e. mode mixing), Ensemble Empirical Mode Decomposition (EEMD) method was developed by Wu and Huang (2009), which significantly reduces the chance of mode mixing and represents a substantial improvement over the original EMD.
</p>


<h3>Value</h3>

<table>
<tr><td><code>TotalIMF</code></td>
<td>
<p>Total number of IMFs.</p>
</td></tr>
<tr><td><code>AllIMF</code></td>
<td>
<p>List of all IMFs with residual for input series.</p>
</td></tr>
<tr><td><code>data_test</code></td>
<td>
<p>Testing set is used to measure the out of sample performance.</p>
</td></tr>
<tr><td><code>AllIMF_forecast</code></td>
<td>
<p>Forecasted value of all individual IMF.</p>
</td></tr>
<tr><td><code>FinalEEMDELM_forecast</code></td>
<td>
<p>Final forecasted value of the EEMDELM model. It is obtained by combining the forecasted value of all individual IMF.</p>
</td></tr>
<tr><td><code>MAE_EEMDELM</code></td>
<td>
<p>Mean Absolute Error (MAE) for EEMDELM model.</p>
</td></tr>
<tr><td><code>MAPE_EEMDELM</code></td>
<td>
<p>Mean Absolute Percentage Error (MAPE) for EEMDELM model.</p>
</td></tr>
<tr><td><code>rmse_EEMDELM</code></td>
<td>
<p>Root Mean Square Error (RMSE) for EEMDELM model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Choudhary, K., Jha, G.K., Kumar, R.R. and Mishra, D.C. (2019) Agricultural commodity price analysis using ensemble empirical mode decomposition: A case study of daily potato price series. Indian journal of agricultural sciences, 89(5), 882&ndash;886.
</p>
<p>Huang, N.E., Shen, Z., Long, S.R., Wu, M.C., Shih, H.H., Zheng, Q. and Liu, H.H. (1998) The empirical mode decomposition and the Hilbert spectrum for nonlinear and non stationary time series analysis. In Proceedings of the Royal Society of London A: mathematical, physical and engineering sciences. 454, 903&ndash;995.
</p>
<p>Huang, G.B., Zhu, Q.Y. and Siew, C.K. (2006) Extreme learning machine: theory and applications. Neurocomputing, 70, 489&ndash;501.
</p>
<p>Wu, Z. and Huang, N.E. (2009) Ensemble empirical mode decomposition: a noise assisted data analysis method. Advances in adaptive data analysis, 1(1), 1&ndash;41.
</p>


<h3>See Also</h3>

<p>EMDelm, CEEMDANelm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Data_Soybean")
EEMDELM(Data_Soybean)

</code></pre>

<hr>
<h2 id='EMDelm'>
Empirical Mode Decomposition Based ELM Model
</h2><span id='topic+EMDelm'></span>

<h3>Description</h3>

<p>The EMDelm function computes forecasted value with different forecasting evaluation criteria for Empirical Mode Decomposition based Extreme Learning Machine model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EMDelm(xt, stepahead = 10, s.num = 4L, num.sift = 50L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EMDelm_+3A_xt">xt</code></td>
<td>

<p>Input univariate time series (ts) data.
</p>
</td></tr>
<tr><td><code id="EMDelm_+3A_stepahead">stepahead</code></td>
<td>

<p>The forecast horizon.
</p>
</td></tr>
<tr><td><code id="EMDelm_+3A_s.num">s.num</code></td>
<td>

<p>Integer. Use the S number stopping criterion for the EMD procedure with the given values of S. That is, iterate until the number of extrema and zero crossings in the signal differ at most by one, and stay the same for S consecutive iterations.
</p>
</td></tr>
<tr><td><code id="EMDelm_+3A_num.sift">num.sift</code></td>
<td>

<p>Number of siftings to find out IMFs.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function decomposes the original time series into several independent intrinsic mode functions (IMFs) and one residual component (Huang et al., 1998). Then extreme learning machine, a class of feedforward neural network is used to forecast these IMFs and residual component individually (Huang et al., 2006). Finally, the prediction results of all IMFs including residual are aggregated to formulate an ensemble output for the original time series.
</p>


<h3>Value</h3>

<table>
<tr><td><code>TotalIMF</code></td>
<td>
<p>Total number of IMFs.</p>
</td></tr>
<tr><td><code>AllIMF</code></td>
<td>
<p>List of all IMFs with residual for input series.</p>
</td></tr>
<tr><td><code>data_test</code></td>
<td>
<p>Testing set is used to measure the out of sample performance.</p>
</td></tr>
<tr><td><code>AllIMF_forecast</code></td>
<td>
<p>Forecasted value of all individual IMF.</p>
</td></tr>
<tr><td><code>FinalEMDELM_forecast</code></td>
<td>
<p>Final forecasted value of the EMDELM model.It is obtained by combining the forecasted value of all individual IMF.</p>
</td></tr>
<tr><td><code>MAE_EMDELM</code></td>
<td>
<p>Mean Absolute Error (MAE) for EMDELM model.</p>
</td></tr>
<tr><td><code>MAPE_EMDELM</code></td>
<td>
<p>Mean Absolute Percentage Error (MAPE) for EMDELM  model.</p>
</td></tr>
<tr><td><code>rmse_EMDELM</code></td>
<td>
<p>Root Mean Square Error (RMSE) for EMDELM model.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Choudhary, K., Jha, G.K., Kumar, R.R. and Mishra, D.C. (2019) Agricultural commodity price analysis using ensemble empirical mode decomposition: A case study of daily potato price series. Indian journal of agricultural sciences, 89(5), 882&ndash;886.
</p>
<p>Dong, J., Dai, W., Tang, L. and Yu, L. (2019) Why do EMD based methods improve prediction. A multiscale complexity perspective. Journal of Forecasting, 38(7), 714&ndash;731.
</p>
<p>Huang, N.E., Shen, Z., Long, S.R., Wu, M.C., Shih, H.H., Zheng, Q. and Liu, H.H. (1998). The empirical mode decomposition and the Hilbert spectrum for nonlinear and non stationary time series analysis. In Proceedings of the Royal Society of London A: mathematical, physical and engineering sciences. 454, 903&ndash;995.
</p>
<p>Huang, G.B., Zhu, Q.Y. and Siew, C.K. (2006). Extreme learning machine: theory and applications. Neurocomputing, 70, 489&ndash;501.
</p>


<h3>See Also</h3>

<p>EEMDELM, CEEMDANelm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Data_Soybean")
EMDelm(Data_Soybean)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
