<!DOCTYPE html><html lang="en"><head><title>Help for package EMJMCMC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {EMJMCMC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#do.call.emjmcmc'><p>A help function used by parall.gmj to run parallel chains of (R)(G)MJMCMC algorithms</p></a></li>
<li><a href='#erf'><p>erf activation function</p></a></li>
<li><a href='#estimate.bas.glm'><p>Obtaining Bayesian estimators of interest from a GLM model</p></a></li>
<li><a href='#estimate.bas.lm'><p>Obtaining Bayesian estimators of interest from a LM model</p></a></li>
<li><a href='#estimate.bigm'><p>Obtaining Bayesian estimators of interest from a GLM model</p></a></li>
<li><a href='#estimate.elnet'><p>A test function to work with elastic networks in future, be omitted so far</p></a></li>
<li><a href='#estimate.gamma.cpen'><p>Estimate marginal log posterior of a single BGNLM model</p></a></li>
<li><a href='#estimate.gamma.cpen_2'><p>Estimate marginal log posterior of a single BGNLM model with alternative defaults</p></a></li>
<li><a href='#estimate.glm'><p>Obtaining Bayesian estimators of interest from a GLM model</p></a></li>
<li><a href='#estimate.logic.glm'><p>Obtaining Bayesian estimators of interest from a GLM model in a</p>
logic regression context</a></li>
<li><a href='#estimate.logic.lm'><p>Obtaining Bayesian estimators of interest from an LM model for the</p>
logic regression case</a></li>
<li><a href='#estimate.speedglm'><p>Obtaining Bayesian estimators of interest from a GLM model</p></a></li>
<li><a href='#LogicRegr'><p>A wrapper for running the Bayesian logic regression based inference</p>
in a easy to use way</a></li>
<li><a href='#m'><p>Product function used in the deep regression context</p></a></li>
<li><a href='#parall.gmj'><p>A function to run parallel chains of (R)(G)MJMCMC algorithms</p></a></li>
<li><a href='#parallelize'><p>An example of user defined parallelization (cluster based) function</p>
for within an MJMCMC chain calculations (mclapply or lapply are used by
default depending on specification and OS).</a></li>
<li><a href='#pinferunemjmcmc'><p>A wrapper for running the GLMM, BLR, or DBRM based inference</p>
and predictions in an expert but rather easy to use way</a></li>
<li><a href='#runemjmcmc'><p>Mode jumping MJMCMC or Genetically Modified Mode jumping MCMC or Reversible Genetically Modified Mode jumping MCMC</p>
for variable selection, Bayesian model averaging and feature engineering</a></li>
<li><a href='#sigmoid'><p>sigmoid activation function</p></a></li>
<li><a href='#simplify.formula'><p>A function parsing the formula into the vectors of character arrays</p>
of responses and covariates</a></li>
<li><a href='#simplifyposteriors'><p>A function that ads up posteriors for the same expression written</p>
in different character form in different parallel runs of the algorithm
(mainly for Logic Regression and Deep Regression contexts)</a></li>
<li><a href='#truncfactorial'><p>Truncated factorial to avoid stack overflow for huge values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Evolutionary Mode Jumping Markov Chain Monte Carlo Expert
Toolbox</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-02</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Waldir Leoncio &lt;w.l.netto@medisin.uio.no&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the Mode Jumping Markov Chain Monte Carlo algorithm from Hubin, A., Storvik, G. (2018) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2018.05.020">doi:10.1016/j.csda.2018.05.020</a>&gt;, Genetically Modified Mode Jumping Markov Chain Monte Carlo from Hubin, A., Storvik, G., &amp; Frommlet, F. (2020) &lt;<a href="https://doi.org/10.1214%2F18-BA1141">doi:10.1214/18-BA1141</a>&gt;, Hubin, A., Storvik, G., &amp; Frommlet, F. (2021) &lt;<a href="https://doi.org/10.1613%2Fjair.1.13047">doi:10.1613/jair.1.13047</a>&gt;, and Hubin, A., Heinze, G., &amp; De Bin, R. (2023) &lt;<a href="https://doi.org/10.3390%2Ffractalfract7090641">doi:10.3390/fractalfract7090641</a>&gt;, and Reversible Genetically Modified Mode Jumping Markov Chain Monte Carlo from Hubin, A., Frommlet, F., &amp; Storvik, G. (2021) &lt;<a href="https://doi.org/10.48550%2FarXiv.2110.05316">doi:10.48550/arXiv.2110.05316</a>&gt;, which allow for estimating posterior model probabilities and Bayesian model averaging across a wide set of Bayesian models including linear, generalized linear, generalized linear mixed, generalized nonlinear, generalized nonlinear mixed, and logic regression models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.1), bigmemory</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, biglm, hash, BAS, stringi, parallel, methods,
speedglm, stats, withr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), bindata, clusterGeneration, reshape2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-02 07:33:43 UTC; waldir</td>
</tr>
<tr>
<td>Author:</td>
<td>Aliaksandr Hubin [aut],
  Waldir Leoncio [cre, aut],
  Geir Storvik [ctb],
  Florian Frommlet [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-03 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='do.call.emjmcmc'>A help function used by parall.gmj to run parallel chains of (R)(G)MJMCMC algorithms</h2><span id='topic+do.call.emjmcmc'></span>

<h3>Description</h3>

<p>A help function used by parall.gmj to run parallel chains of (R)(G)MJMCMC algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.call.emjmcmc(vect)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="do.call.emjmcmc_+3A_vect">vect</code></td>
<td>
<p>a vector of parameters of runemjmcmc as well as several
additional fields that must come after runemjmcmc parameters such as:
</p>

<dl>
<dt>vect$simlen</dt><dd><p>the number of parameters of runemjmcmc in vect</p>
</dd>
<dt>vect$cpu</dt><dd><p>the CPU id for to set the unique seed</p>
</dd>
<dt>vect$NM</dt><dd><p>the number of unique best models from runemjmcmc to
base the output report upon</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>post.populi</dt><dd><p>the total mass (sum of the marginal likelihoods times
the priors of the visited models) from the addressed run of runemjmcmc</p>
</dd>
<dt>p.post</dt><dd><p>posterior probabilities of the covariates approximated by the
addressed run of runemjmcmc</p>
</dd>
<dt>cterm</dt><dd><p>the best value of marginal likelihood times the prior from
the addressed run of runemjmcmc</p>
</dd>
<dt>fparam</dt><dd><p>the final set of covariates returned by the addressed
run of runemjmcmc</p>
</dd>
</dl>



<h3>See Also</h3>

<p>runemjmcmc, parall.gmj
</p>

<hr>
<h2 id='erf'>erf activation function</h2><span id='topic+erf'></span>

<h3>Description</h3>

<p>erf activation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>erf(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="erf_+3A_x">x</code></td>
<td>
<p>a real number</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>erf(x)</code>, erf value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>erf(10)
</code></pre>

<hr>
<h2 id='estimate.bas.glm'>Obtaining Bayesian estimators of interest from a GLM model</h2><span id='topic+estimate.bas.glm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from a GLM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.bas.glm(formula, data, family, prior, logn)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.bas.glm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.bas.glm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations
corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.bas.glm_+3A_family">family</code></td>
<td>
<p>either poisson() or binomial(), that are currently adopted
within this function</p>
</td></tr>
<tr><td><code id="estimate.bas.glm_+3A_prior">prior</code></td>
<td>
<p>BAS::aic.prior(), bic.prior() or ic.prior() are allowed</p>
</td></tr>
<tr><td><code id="estimate.bas.glm_+3A_logn">logn</code></td>
<td>
<p>log sample size</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>BAS::bayesglm.fit
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (((X4$V50 * X4$V19 * X4$V13 * X4$V11) &gt; 0)) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8,
  sd = 1
)
X4$Y4 &lt;- Y4
data.example &lt;- as.data.frame(X4)
data.example$Y4 &lt;- as.integer(data.example$Y &gt; mean(data.example$Y))
formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)

estimate.bas.glm(
  formula = formula1,
  data = data.example,
  prior = BAS::aic.prior(),
  logn = 47,
  family = binomial()
)
</code></pre>

<hr>
<h2 id='estimate.bas.lm'>Obtaining Bayesian estimators of interest from a LM model</h2><span id='topic+estimate.bas.lm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from a LM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.bas.lm(formula, data, prior, n, g = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.bas.lm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.bas.lm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.bas.lm_+3A_prior">prior</code></td>
<td>
<p>integers 1, 2 or 3 are allowed corresponding to AIC, BIC or Zellner's g-prior</p>
</td></tr>
<tr><td><code id="estimate.bas.lm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="estimate.bas.lm_+3A_g">g</code></td>
<td>
<p>g</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>BAS::bayesglm.fit
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (((X4$V50 * X4$V19 * X4$V13 * X4$V11) &gt; 0)) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8,
  sd = 1
)
X4$Y4 &lt;- Y4
data.example &lt;- as.data.frame(X4)
formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)

estimate.bas.lm(formula = formula1, data = data.example, prior = 2, n = 47)
</code></pre>

<hr>
<h2 id='estimate.bigm'>Obtaining Bayesian estimators of interest from a GLM model</h2><span id='topic+estimate.bigm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from a GLM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.bigm(formula, data, family, prior, n, maxit = 2, chunksize = 1e+06)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.bigm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.bigm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.bigm_+3A_family">family</code></td>
<td>
<p>distribution family foe the responses</p>
</td></tr>
<tr><td><code id="estimate.bigm_+3A_prior">prior</code></td>
<td>
<p>either &quot;AIC&quot; or &quot;BIC&quot;</p>
</td></tr>
<tr><td><code id="estimate.bigm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="estimate.bigm_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of Fisher scoring iterations</p>
</td></tr>
<tr><td><code id="estimate.bigm_+3A_chunksize">chunksize</code></td>
<td>
<p>size of chunks for processing the data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
<dt>n</dt><dd><p>sample size</p>
</dd>
</dl>



<h3>See Also</h3>

<p>biglm::bigglm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (((X4$V50 * X4$V19 * X4$V13 * X4$V11) &gt; 0)) +
    9 * (X4$V37 * X4$V20 * X4$V12) + 7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8,
  sd = 1
)
X4$Y4 &lt;- Y4
data.example &lt;- as.data.frame(X4)
formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)
formula1 &lt;- as.formula(
  paste(
    colnames(data.example)[1], "~ 1 +", paste0(colnames(data.example)[-1],
    collapse = "+")
  )
)
estimate.bigm(
  formula = formula1, data = data.example, n = 47, prior = "BIC", maxit = 20,
  chunksize = 1000000, family = gaussian()
)
</code></pre>

<hr>
<h2 id='estimate.elnet'>A test function to work with elastic networks in future, be omitted so far</h2><span id='topic+estimate.elnet'></span>

<h3>Description</h3>

<p>A test function to work with elastic networks in future, be omitted so far
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.elnet(formula, response, data, family, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.elnet_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.elnet_+3A_response">response</code></td>
<td>
<p>response in a formula</p>
</td></tr>
<tr><td><code id="estimate.elnet_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.elnet_+3A_family">family</code></td>
<td>
<p>distribution of the response family object</p>
</td></tr>
<tr><td><code id="estimate.elnet_+3A_alpha">alpha</code></td>
<td>
<p>regularization parameter in [0,1]</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>glmnet::glmnet
</p>

<hr>
<h2 id='estimate.gamma.cpen'>Estimate marginal log posterior of a single BGNLM model</h2><span id='topic+estimate.gamma.cpen'></span>

<h3>Description</h3>

<p>Estimate marginal log posterior of a single BGNLM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.gamma.cpen(
  formula,
  data,
  r = 1/1000,
  logn = log(1000),
  relat = c("cos", "sigmoid", "tanh", "atan", "sin", "erf")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.gamma.cpen_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_+3A_data">data</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_+3A_r">r</code></td>
<td>
<p>prior inclusion penalty parameter</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_+3A_logn">logn</code></td>
<td>
<p>logn</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_+3A_relat">relat</code></td>
<td>
<p>a set of nonlinear transformations in the class of BGNLMs of interest</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>


<hr>
<h2 id='estimate.gamma.cpen_2'>Estimate marginal log posterior of a single BGNLM model with alternative defaults</h2><span id='topic+estimate.gamma.cpen_2'></span>

<h3>Description</h3>

<p>Estimate marginal log posterior of a single BGNLM model with alternative defaults
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.gamma.cpen_2(
  formula,
  data,
  r = 1/223,
  logn = log(223),
  relat = c("to23", "expi", "logi", "to35", "sini", "troot", "sigmoid")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.gamma.cpen_2_+3A_formula">formula</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_2_+3A_data">data</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_2_+3A_r">r</code></td>
<td>
<p>prior inclusion penalty parameter</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_2_+3A_logn">logn</code></td>
<td>
<p>logn</p>
</td></tr>
<tr><td><code id="estimate.gamma.cpen_2_+3A_relat">relat</code></td>
<td>
<p>a set of nonlinear transformations in the class of BGNLMs of interest</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>


<hr>
<h2 id='estimate.glm'>Obtaining Bayesian estimators of interest from a GLM model</h2><span id='topic+estimate.glm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from a GLM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.glm(formula, data, family, prior, n = 1, g = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.glm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.glm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations
corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.glm_+3A_family">family</code></td>
<td>
<p>distribution family for the responses</p>
</td></tr>
<tr><td><code id="estimate.glm_+3A_prior">prior</code></td>
<td>
<p>integers 1,2 or 3 corresponding to AIC, BIC or Zellner's g-prior</p>
</td></tr>
<tr><td><code id="estimate.glm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="estimate.glm_+3A_g">g</code></td>
<td>
<p>g parameter of Zellner's g prior</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>glm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (((X4$V50 * X4$V19 * X4$V13 * X4$V11) &gt; 0)) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8,
  sd = 1
)
X4$Y4 &lt;- Y4
data.example &lt;- as.data.frame(X4)
formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)

formula1 &lt;- as.formula(
  paste(
    colnames(data.example)[1], "~ 1 +", paste0(colnames(data.example)[-1],
    collapse = "+")
  )
)
estimate.glm(
  formula = formula1, data = data.example, prior = 2, family = gaussian()
)
</code></pre>

<hr>
<h2 id='estimate.logic.glm'>Obtaining Bayesian estimators of interest from a GLM model in a
logic regression context</h2><span id='topic+estimate.logic.glm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from a GLM model in a
logic regression context
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.logic.glm(formula, data, family, n, m, r = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.logic.glm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.logic.glm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.logic.glm_+3A_family">family</code></td>
<td>
<p>either poisson() or binomial(), that are currently adopted within this function</p>
</td></tr>
<tr><td><code id="estimate.logic.glm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="estimate.logic.glm_+3A_m">m</code></td>
<td>
<p>total number of input binary leaves</p>
</td></tr>
<tr><td><code id="estimate.logic.glm_+3A_r">r</code></td>
<td>
<p>omitted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>BAS::bayesglm.fit estimate.logic.lm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- as.data.frame(
  array(data = rbinom(n = 50 * 1000, size = 1, prob = 0.3), dim = c(1000, 50))
)
Y1 &lt;- -0.7 + 1 * ((1 - X1$V1) * (X1$V4)) + 1 * (X1$V8 * X1$V11) + 1 * (X1$V5 * X1$V9)
X1$Y1 &lt;- round(1.0 / (1.0 + exp(-Y1)))

formula1 &lt;- as.formula(
  paste(colnames(X1)[51], "~ 1 +", paste0(colnames(X1)[-c(51)], collapse = "+"))
)

estimate.logic.glm(
  formula = formula1, data = X1, family = binomial(), n = 1000, m = 50
)
</code></pre>

<hr>
<h2 id='estimate.logic.lm'>Obtaining Bayesian estimators of interest from an LM model for the
logic regression case</h2><span id='topic+estimate.logic.lm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from an LM model for the
logic regression case
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.logic.lm(formula, data, n, m, r = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.logic.lm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.logic.lm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations
corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.logic.lm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="estimate.logic.lm_+3A_m">m</code></td>
<td>
<p>total number of input binary leaves</p>
</td></tr>
<tr><td><code id="estimate.logic.lm_+3A_r">r</code></td>
<td>
<p>omitted</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>BAS::bayesglm.fit, estimate.logic.glm
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (X4$V50 * X4$V19 * X4$V13 * X4$V11) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8
  , sd = 1
)
X4$Y4 &lt;- Y4

formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)

estimate.logic.lm(formula = formula1, data = X4, n = 1000, m = 50)
</code></pre>

<hr>
<h2 id='estimate.speedglm'>Obtaining Bayesian estimators of interest from a GLM model</h2><span id='topic+estimate.speedglm'></span>

<h3>Description</h3>

<p>Obtaining Bayesian estimators of interest from a GLM model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.speedglm(formula, data, family, prior, logn)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.speedglm_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="estimate.speedglm_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations
corresponding to the formula used</p>
</td></tr>
<tr><td><code id="estimate.speedglm_+3A_family">family</code></td>
<td>
<p>distribution family foe the responses</p>
</td></tr>
<tr><td><code id="estimate.speedglm_+3A_prior">prior</code></td>
<td>
<p>either &quot;AIC&quot; or &quot;BIC&quot;</p>
</td></tr>
<tr><td><code id="estimate.speedglm_+3A_logn">logn</code></td>
<td>
<p>log sample size</p>
</td></tr>
</table>


<h3>Value</h3>


<dl>
<dt>mlik</dt><dd><p>marginal likelihood of the model</p>
</dd>
<dt>waic</dt><dd><p>AIC model selection criterion</p>
</dd>
<dt>dic</dt><dd><p>BIC model selection criterion</p>
</dd>
<dt>summary.fixed$mean</dt><dd><p>a vector of posterior modes of the parameters</p>
</dd>
</dl>



<h3>See Also</h3>

<p>speedglm::speedglm.wfit
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (X4$V50 * X4$V19 * X4$V13 * X4$V11) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8
  , sd = 1
)
X4$Y4 &lt;- Y4

formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)

estimate.logic.lm(formula = formula1, data = X4, n = 1000, m = 50)
</code></pre>

<hr>
<h2 id='LogicRegr'>A wrapper for running the Bayesian logic regression based inference
in a easy to use way</h2><span id='topic+LogicRegr'></span>

<h3>Description</h3>

<p>A wrapper for running the Bayesian logic regression based
inference in a easy to use way
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LogicRegr(
  formula,
  data,
  family = "Gaussian",
  prior = "J",
  report.level = 0.5,
  d = 20,
  cmax = 5,
  kmax = 20,
  p.and = 0.9,
  p.not = 0.05,
  p.surv = 0.1,
  ncores = -1,
  n.mods = 1000,
  print.freq = 1000L,
  advanced = list(presearch = TRUE, locstop = FALSE, estimator =
    estimate.logic.bern.tCCH, estimator.args = list(data = data.example, n = 1000, m =
    50, r = 1), recalc_margin = 250, save.beta = FALSE, interact = TRUE, relations =
    c("", "lgx2", "cos", "sigmoid", "tanh", "atan", "erf"), relations.prob = c(0.4, 0, 0,
    0, 0, 0, 0), interact.param = list(allow_offsprings = 1, mutation_rate = 300,
    last.mutation = 5000, max.tree.size = 1, Nvars.max = 100, p.allow.replace = 0.9,
    p.allow.tree = 0.2, p.nor = 0.2, p.and = 1), 
     n.models = 10000, unique = TRUE,
    max.cpu = ncores, max.cpu.glob = ncores, create.table = FALSE, create.hash = TRUE,
    pseudo.paral = TRUE, burn.in = 50, outgraphs = FALSE, print.freq = print.freq,
    advanced.param = list(max.N.glob = as.integer(10), min.N.glob = as.integer(5), max.N
    = as.integer(3), min.N = as.integer(1), printable = FALSE))
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LogicRegr_+3A_formula">formula</code></td>
<td>
<p>a formula object for the model to be addressed</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_data">data</code></td>
<td>
<p>a data frame object containing variables and observations
corresponding to the formula used</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_family">family</code></td>
<td>
<p>a string taking values of either &quot;Gaussian&quot; or &quot;Bernoulli&quot;
corresponding to the linear or logistic Bayesian logic regression contexts</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_prior">prior</code></td>
<td>
<p>character values &quot;J&quot; or &quot;G&quot; corresponding either to Jeffey's
or robust g prior</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_report.level">report.level</code></td>
<td>
<p>a numeric value in (0,1) specifying the threshold for
detections based on the marginal inclusion probabilities</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_d">d</code></td>
<td>
<p>population size for the GMJMCMC algorithm</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_cmax">cmax</code></td>
<td>
<p>the maximal allowed depth of logical expressions to be considered</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_kmax">kmax</code></td>
<td>
<p>the maximal number of logical expressions per model</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_p.and">p.and</code></td>
<td>
<p>probability of AND parameter of GMJMCMC algorithm</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_p.not">p.not</code></td>
<td>
<p>probability of applying logical NOT in GMJMCMC algorithm</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_p.surv">p.surv</code></td>
<td>
<p>minimal survival probabilities for the features to be allowed to enter the next population</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_ncores">ncores</code></td>
<td>
<p>the maximal number of cores (and GMJMCMC threads) to be
addressed in the analysis</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_n.mods">n.mods</code></td>
<td>
<p>the number of the best models in the thread to calculate
marginal inclusion probabilities</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_print.freq">print.freq</code></td>
<td>
<p>printing frequency of the intermediate results</p>
</td></tr>
<tr><td><code id="LogicRegr_+3A_advanced">advanced</code></td>
<td>
<p>should only be addressed by experienced users to tune advanced
parameters of GMJMCMC, advanced corresponds to the vector of tuning
parameters of runemjmcmc function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>feat.stat</dt><dd><p>detected logical expressions and their marginal inclusion
probabilities</p>
</dd>
<dt>predictions</dt><dd><p>NULL currently, since LogrRegr function is not designed
for predictions at the moment, which is still possible in its expert
mother function pinferunemjmcmc</p>
</dd>
<dt>allposteriors</dt><dd><p>all visited by GMJMCMC logical expressions and their
marginal inclusion probabilities</p>
</dd>
<dt>threads.stats</dt><dd><p>a vector of detailed outputs of individual ncores
threads of GMJMCMC run</p>
</dd>
</dl>



<h3>See Also</h3>

<p>runemjmcmc pinferunemjmcmc
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(040590)
X1 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1,
    prob = runif(n = 50 * 1000, 0, 1)), dim = c(1000, 50)
  )
)
Y1 &lt;- rnorm(
  n = 1000,
  mean = 1 + 0.7 * (X1$V1 * X1$V4) + 0.8896846 * (X1$V8 * X1$V11) + 1.434573 * (X1$V5 * X1$V9),
  sd = 1
)
X1$Y1 &lt;- Y1

# specify the initial formula
formula1 &lt;- as.formula(
  paste(colnames(X1)[51], "~ 1 +", paste0(colnames(X1)[-c(51)], collapse = "+"))
)
data.example &lt;- as.data.frame(X1)


# run the inference with robust g prior
n_cores &lt;- 1L


  res4G &lt;- LogicRegr(
    formula = formula1, data = data.example, family = "Gaussian", prior = "G",
    report.level = 0.5, d = 15, cmax = 2, kmax = 15, p.and = 0.9, p.not = 0.01,
    p.surv = 0.2, ncores = n_cores
  )
  print(res4G$feat.stat)

  # run the inference with Jeffrey's prior
  res4J &lt;- LogicRegr(
    formula = formula1, data = data.example, family = "Gaussian", prior = "J",
    report.level = 0.5, d = 15, cmax = 2, kmax = 15, p.and = 0.9, p.not = 0.01,
    p.surv = 0.2, ncores = n_cores
  )
  print(res4J$feat.stat)

</code></pre>

<hr>
<h2 id='m'>Product function used in the deep regression context</h2><span id='topic+m'></span>

<h3>Description</h3>

<p>Product function used in the deep regression context
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m(a, b)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m_+3A_a">a</code></td>
<td>
<p>the first argument</p>
</td></tr>
<tr><td><code id="m_+3A_b">b</code></td>
<td>
<p>the second argument</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>m(a,b)</code>, product of the arguments a*b
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m(10,2)
</code></pre>

<hr>
<h2 id='parall.gmj'>A function to run parallel chains of (R)(G)MJMCMC algorithms</h2><span id='topic+parall.gmj'></span>

<h3>Description</h3>

<p>A function to run parallel chains of (R)(G)MJMCMC algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parall.gmj(X, M = 16, preschedule = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parall.gmj_+3A_x">X</code></td>
<td>
<p>a vector of lists of parameters of runemjmcmc as well as
several additional fields that must come after runemjmcmc parameters
such as:
</p>

<dl>
<dt>vect$simlen</dt><dd><p>the number of parameters of runemjmcmc in vect</p>
</dd>
<dt>vect$cpu</dt><dd><p>the CPU id for to set the unique seed</p>
</dd>
<dt>vect$NM</dt><dd><p>the number of unique best models from runemjmcmc to
base the output report upon</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="parall.gmj_+3A_m">M</code></td>
<td>
<p>a number of CPUs to be used (can only be equal to 1 on
Windows OS currently, up to a maximal number of cores can be used on
Linux-based systems)</p>
</td></tr>
<tr><td><code id="parall.gmj_+3A_preschedule">preschedule</code></td>
<td>
<p>if pseudoscheduling should be used for the jobs if
their number exceeds M (if TRUE) otherwise the jobs are performed
sequentially w.r.t. their order</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of lists of
</p>

<dl>
<dt>post.populi</dt><dd><p>the total mass (sum of the marginal likelihoods times
the priors of the visited models) from the addressed run of runemjmcmc</p>
</dd>
<dt>p.post</dt><dd><p>posterior probabilities of the covariates approximated by the
addressed run of runemjmcmc</p>
</dd>
<dt>cterm</dt><dd><p>the best value of marginal likelihood times the prior from
the addressed run of runemjmcmc</p>
</dd>
<dt>fparam</dt><dd><p>the final set of covariates returned by the addressed
run of runemjmcmc</p>
</dd>
</dl>



<h3>See Also</h3>

<p>runemjmcmc parall.gmj
</p>


<h3>Examples</h3>

<pre><code class='language-R'>j &lt;- 1
M &lt;- 4
X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (X4$V50 * X4$V19 * X4$V13 * X4$V11) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8,
  sd = 1
)
X4$Y4 &lt;- Y4

formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)
data.example &lt;- as.data.frame(X4)

vect &lt;- list(
  formula = formula1, outgraphs = FALSE, data = X4,
  estimator = estimate.logic.lm,
  estimator.args = list(data = data.example, n = 100, m = 50),
  recalc_margin = 249, save.beta = FALSE, interact = TRUE,
  relations = c("", "lgx2", "cos", "sigmoid", "tanh", "atan", "erf"),
  relations.prob = c(0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0),
  interact.param = list(
    allow_offsprings = 1, mutation_rate = 250, last.mutation = 15000,
    max.tree.size = 4, Nvars.max = 40, p.allow.replace = 0.7,
    p.allow.tree = 0.2, p.nor = 0, p.and = 0.9
  ), n.models = 20000, unique = TRUE, max.cpu = 4, max.cpu.glob = 4,
  create.table = FALSE, create.hash = TRUE, pseudo.paral = TRUE,
  burn.in = 50, print.freq = 1000,
  advanced.param = list(
    max.N.glob = as.integer(10),
    min.N.glob = as.integer(5),
    max.N = as.integer(3),
    min.N = as.integer(1),
    printable = FALSE
  )
)

params &lt;- list(vect)[rep(1, M)]

for (i in 1:M) {
  params[[i]]$cpu &lt;- i
  params[[i]]$NM &lt;- 1000
  params[[i]]$simlen &lt;- 21
}

  message("begin simulation ", j)
  set.seed(363571)
  results &lt;- parall.gmj(X = params, M = 1)

</code></pre>

<hr>
<h2 id='parallelize'>An example of user defined parallelization (cluster based) function
for within an MJMCMC chain calculations (mclapply or lapply are used by
default depending on specification and OS).</h2><span id='topic+parallelize'></span>

<h3>Description</h3>

<p>An example of user defined parallelization (cluster based) function
for within an MJMCMC chain calculations (mclapply or lapply are used by
default depending on specification and OS).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parallelize(X, FUN)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parallelize_+3A_x">X</code></td>
<td>
<p>a vector (atomic or list) or an expressions vector. Other objects
(including classed objects) will be coerced by as.list</p>
</td></tr>
<tr><td><code id="parallelize_+3A_fun">FUN</code></td>
<td>
<p>the function to be applied to each element of X or v, or in
parallel to X</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only allowed when working with big.memory based hash table within
MJMCMC (see runemjmcmc for more details)
</p>


<h3>Value</h3>

<p><code>parallelize(X,FUN)</code>, a list of the same length as X and named by X
</p>


<h3>See Also</h3>

<p>parLapply clusterMap mclapply lapply
</p>

<hr>
<h2 id='pinferunemjmcmc'>A wrapper for running the GLMM, BLR, or DBRM based inference
and predictions in an expert but rather easy to use way</h2><span id='topic+pinferunemjmcmc'></span>

<h3>Description</h3>

<p>A wrapper for running the GLMM, BLR, or DBRM based inference
and predictions in an expert but rather easy to use way
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pinferunemjmcmc(
  n.cores = 4,
  mcgmj = mcgmjpse,
  report.level = 0.5,
  simplify = FALSE,
  num.mod.best = 1000,
  predict = FALSE,
  test.data = 1,
  link.function = function(z) z,
  runemjmcmc.params
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pinferunemjmcmc_+3A_n.cores">n.cores</code></td>
<td>
<p>the maximal number of cores (and (R)(G)MJMCMC threads) to
be addressed in the analysis</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_mcgmj">mcgmj</code></td>
<td>
<p>an mclapply like function for performing for performing
parallel computing, do not change the default unless you are using Windows</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_report.level">report.level</code></td>
<td>
<p>a numeric value in (0,1) specifying the threshold for
detections based on the marginal inclusion probabilities</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_simplify">simplify</code></td>
<td>
<p>a logical value specifying in simplification of the features
is to be done after the search is completed</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_num.mod.best">num.mod.best</code></td>
<td>
<p>the number of the best models in the thread to
calculate marginal inclusion probabilities</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_predict">predict</code></td>
<td>
<p>a logical value specifying if predictions should be done by
the run of pinferunemjmcmc</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_test.data">test.data</code></td>
<td>
<p>covariates data.frame to be used for predictions</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_link.function">link.function</code></td>
<td>
<p>the link functions to be used to make predictions</p>
</td></tr>
<tr><td><code id="pinferunemjmcmc_+3A_runemjmcmc.params">runemjmcmc.params</code></td>
<td>
<p>a vector of parameters of runemjmcmc function,
see the help of runemjmcmc for details</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>feat.stat</dt><dd><p>detected features or logical expressions and their
marginal inclusion probabilities</p>
</dd>
<dt>predictions</dt><dd><p>predicted values if they are required, NULL otherwise</p>
</dd>
<dt>allposteriors</dt><dd><p>all visited by (R)(G)MJMCMC features and logical
expressions and their marginal inclusion probabilities</p>
</dd>
<dt>threads.stats</dt><dd><p>a vector of detailed outputs of individual n.cores
threads of (R)(G)MJMCMC run</p>
</dd>
</dl>



<h3>See Also</h3>

<p>runemjmcmc LogrRegr DeepRegr LinRegr
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# inference

X &lt;- read.csv(system.file("extdata", "exa1.csv", package="EMJMCMC"))
data.example &lt;- as.data.frame(X)

# specify the initial formula
formula1 &lt;- as.formula(
  paste(colnames(X)[5], "~ 1 +", paste0(colnames(X)[-5], collapse = "+"))
)

# define the number or cpus
M &lt;- 1L
# define the size of the simulated samples
NM &lt;- 1000
# define \k_{max} + 1 from the paper
compmax &lt;- 16
# define treshold for preinclusion of the tree into the analysis
th &lt;- (10)^(-5)
# define a final treshold on the posterior marginal probability for reporting a
# tree
thf &lt;- 0.05
# specify tuning parameters of the algorithm for exploring DBRM of interest
# notice that allow_offsprings=3 corresponds to the GMJMCMC runs and
# allow_offsprings=4 -to the RGMJMCMC runs

  res1 &lt;- pinferunemjmcmc(
    n.cores = M, report.level = 0.5, num.mod.best = NM, simplify = TRUE,
    runemjmcmc.params = list(
      formula = formula1, data = data.example, estimator = estimate.gamma.cpen_2,
      estimator.args = list(data = data.example), recalc_margin = 249,
      save.beta = FALSE, interact = TRUE, outgraphs = FALSE,
      relations = c("to23", "expi", "logi", "to35", "sini", "troot", "sigmoid"),
      relations.prob = c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1),
      interact.param = list(allow_offsprings = 3, mutation_rate = 250,
      last.mutation = 10000, max.tree.size = 5, Nvars.max = 15,
      p.allow.replace = 0.9, p.allow.tree = 0.01, p.nor = 0.9, p.and = 0.9),
      n.models = 10000, unique = TRUE, max.cpu = M, max.cpu.glob = M,
      create.table = FALSE, create.hash = TRUE, pseudo.paral = TRUE,
      burn.in = 100, print.freq = 1000,
      advanced.param = list(
        max.N.glob = as.integer(10),
        min.N.glob = as.integer(5),
        max.N = as.integer(3),
        min.N = as.integer(1),
        printable = FALSE
      )
    )
  )
  print(res1$feat.stat)


# prediction

compmax &lt;- 21

# read in the train and test data sets
test &lt;- read.csv(
  system.file("extdata", "breast_cancer_test.csv", package="EMJMCMC"),
  header = TRUE, sep = ","
)[, -1]
train &lt;- read.csv(
  system.file("extdata", "breast_cancer_train.csv", package="EMJMCMC"),
  header = TRUE, sep = ","
)[, -1]

# transform the train data set to a data.example data.frame that EMJMCMC class
# will internally use
data.example &lt;- as.data.frame(train)

# specify the link function that will be used in the prediction phase
g &lt;- function(x) {
  return((x &lt;- 1 / (1 + exp(-x))))
}

formula1 &lt;- as.formula(
  paste(
    colnames(data.example)[31], "~ 1 +",
    paste0(colnames(data.example)[-31], collapse = "+")
  )
)


  # Defining a custom estimator function
  estimate.bas.glm.cpen &lt;- function(
    formula, data, family, prior, logn, r = 0.1, yid=1,
    relat =c("cosi","sigmoid","tanh","atan","erf","m(")
  ) {
    #only poisson and binomial families are currently adopted
    X &lt;- model.matrix(object = formula,data = data)
    capture.output({out &lt;- BAS::bayesglm.fit(x = X, y = data[,yid], family=family,coefprior=prior)})
    fmla.proc&lt;-as.character(formula)[2:3]
    fobserved &lt;- fmla.proc[1]
    fmla.proc[2]&lt;- stringi::stri_replace_all(str = fmla.proc[2],fixed = " ",replacement = "")
    fmla.proc[2]&lt;- stringi::stri_replace_all(str = fmla.proc[2],fixed = "\n",replacement = "")
    sj&lt;-2*(stringi::stri_count_fixed(str = fmla.proc[2], pattern = "*"))
    sj&lt;-sj+1*(stringi::stri_count_fixed(str = fmla.proc[2], pattern = "+"))
    for(rel in relat) {
      sj&lt;-sj+2*(stringi::stri_count_fixed(str = fmla.proc[2], pattern = rel))
    }
    mlik = ((-out$deviance +2*log(r)*sum(sj)))/2
    return(
      list(
        mlik = mlik, waic = -(out$deviance + 2*out$rank),
        dic = -(out$deviance + logn*out$rank),
        summary.fixed = list(mean = coefficients(out))
      )
    )
  }
  res &lt;- pinferunemjmcmc(
    n.cores = M, report.level = 0.5, num.mod.best = NM, simplify = TRUE,
    predict = TRUE, test.data = as.data.frame(test), link.function = g,
    runemjmcmc.params = list(
      formula = formula1, data = data.example, gen.prob = c(1, 1, 1, 1, 0),
      estimator = estimate.bas.glm.cpen,
      estimator.args = list(
        data = data.example, prior = BAS::aic.prior(), family = binomial(),
        yid = 31, logn = log(143), r = exp(-0.5)
      ), recalc_margin = 95, save.beta = TRUE, interact = TRUE,
      relations = c("gauss", "tanh", "atan", "sin"),
      relations.prob = c(0.1, 0.1, 0.1, 0.1),
      interact.param = list(
        allow_offsprings = 4, mutation_rate = 100, last.mutation = 1000,
        max.tree.size = 6, Nvars.max = 20, p.allow.replace = 0.5,
        p.allow.tree = 0.4, p.nor = 0.3, p.and = 0.9
      ), n.models = 7000, unique = TRUE, max.cpu = M, max.cpu.glob = M,
      create.table = FALSE, create.hash = TRUE, pseudo.paral = TRUE,
      burn.in = 100, print.freq = 1000,
      advanced.param = list(
        max.N.glob = as.integer(10), min.N.glob = as.integer(5),
        max.N = as.integer(3), min.N = as.integer(1), printable = FALSE
      )
    )
  )

  for (jjjj in 1:10)
  {
    resw &lt;- as.integer(res$predictions &gt;= 0.1 * jjjj)
    prec &lt;- (1 - sum(abs(resw - test$X), na.rm = TRUE) / length(resw))
    print(prec)
    # FNR
    ps &lt;- which(test$X == 1)
    fnr &lt;- sum(abs(resw[ps] - test$X[ps])) / (sum(abs(resw[ps] - test$X[ps])) + length(ps))

    # FPR
    ns &lt;- which(test$X == 0)
    fpr &lt;- sum(abs(resw[ns] - test$X[ns])) / (sum(abs(resw[ns] - test$X[ns])) + length(ns))
  }

</code></pre>

<hr>
<h2 id='runemjmcmc'>Mode jumping MJMCMC or Genetically Modified Mode jumping MCMC or Reversible Genetically Modified Mode jumping MCMC
for variable selection, Bayesian model averaging and feature engineering</h2><span id='topic+runemjmcmc'></span>

<h3>Description</h3>

<p>A function that creates an EMJMCMC2016 object with
specified values of some parameters and default values of other parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runemjmcmc(
  formula,
  data,
  secondary = vector(mode = "character", length = 0),
  latnames = "",
  estimator,
  estimator.args = "list",
  n.models,
  p.add.default = 1,
  p.add = 0.5,
  unique = FALSE,
  save.beta = FALSE,
  locstop.nd = FALSE,
  latent = "",
  max.cpu = 4,
  max.cpu.glob = 2,
  create.table = TRUE,
  hash.length = 20,
  presearch = TRUE,
  locstop = FALSE,
  pseudo.paral = FALSE,
  interact = FALSE,
  deep.method = 1,
  relations = c("", "sin", "cos", "sigmoid", "tanh", "atan", "erf"),
  relations.prob = c(0.4, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1),
  gen.prob = c(1, 10, 5, 1, 0),
  pool.cross = 0.9,
  p.epsilon = 1e-04,
  del.sigma = 0.5,
  pool.cor.prob = FALSE,
  interact.param = list(allow_offsprings = 2, mutation_rate = 100, last.mutation = 2000,
    max.tree.size = 10000, Nvars.max = 100, p.allow.replace = 0.7, p.allow.tree = 0.1,
    p.nor = 0.3, p.and = 0.7),
  prand = 0.01,
  keep.origin = TRUE,
  sup.large.n = 5000,
  recalc_margin = 2^10,
  create.hash = FALSE,
  interact.order = 1,
  burn.in = 1,
  eps = 10^6,
  max.time = 120,
  max.it = 25000,
  print.freq = 100,
  outgraphs = FALSE,
  advanced.param = NULL,
  distrib_of_neighbourhoods = t(array(data = c(7.6651604, 16.773326, 14.541629,
    12.839445, 2.964227, 13.048343, 7.165434, 0.9936905, 15.94249, 11.040131, 3.200394,
    15.349051, 5.466632, 14.676458, 1.5184551, 9.285762, 6.125034, 3.627547, 13.343413,
    2.923767, 15.318774, 14.529538, 1.52196, 11.804457, 5.070282, 6.93438, 10.578945,
    12.455602, 6.0826035, 2.453729, 14.340435, 14.863495, 1.028312, 12.685017,
    13.806295), dim = c(7, 5))),
  distrib_of_proposals = c(76.9187, 71.25264, 87.68184, 60.55921, 15812.39852),
  quiet = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runemjmcmc_+3A_formula">formula</code></td>
<td>
<p>a typical formula for specifying a model with all potential covariates included</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_data">data</code></td>
<td>
<p>a data frame containing both covariates and response</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_secondary">secondary</code></td>
<td>
<p>a character vector of names other covariates excluded from those defined in formula (relevant for GMJMCMC only)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_latnames">latnames</code></td>
<td>
<p>a character vector of names other covariates excluded from populations of GMJMCMC, for example for continuous covariates to be combined with BLR (relevant for GMJMCMC only) or the names of latent Gaussian variables to be selected in BGNLMM</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_estimator">estimator</code></td>
<td>
<p>a function returning a list with marginal likelihood, waic, dic and coefficients of the addressed model. The list should be of a format: list(mlik = mlik,waic = waic , dic = dic,summary.fixed =list(mean = coefficients))</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_estimator.args">estimator.args</code></td>
<td>
<p>a list of arguments of estimator functions to be used (formula parameter has to be omitted, see the example)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_n.models">n.models</code></td>
<td>
<p>maximal number of models to be estimated during the search</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_p.add.default">p.add.default</code></td>
<td>
<p>a parameter defining sparsity after filtrations in GMJMCMC as initial marginal inclusion probabilities vector for parameters in the current pool</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_p.add">p.add</code></td>
<td>
<p>a default marginal inclusion probability parameter to be changed during the search to the true value</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_unique">unique</code></td>
<td>
<p>defines whether n.models allows repetitions of the same models (unique=FALSE) or not (unique=TRUE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_save.beta">save.beta</code></td>
<td>
<p>a boolean parameter defining if beta coefficients for the models should be stored (must be set to TRUE if one is interested in predictions)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_locstop.nd">locstop.nd</code></td>
<td>
<p>Defines whether local greedy optimizers stop at the first local optima found (locstop.nd=TRUE) or not (locstop.nd=FALSE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_latent">latent</code></td>
<td>
<p>a latent random field to be addressed (to be specifically used when estimator = INLA, currently unsupported)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_max.cpu">max.cpu</code></td>
<td>
<p>maximal number of CPUs in MJMCMC when within chain parallelization is allowed pseudo.paral = FALSE</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_max.cpu.glob">max.cpu.glob</code></td>
<td>
<p>maximal number of CPUs in global moves in MJMCMC when within chain parallelization is allowed pseudo.paral = FALSE</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_create.table">create.table</code></td>
<td>
<p>a Boolean variable defining if a big.memory based hash table (only available for MJMCMC with no feature engineering, allows data sharing between CPUs) or the original R hash data structure (available for all algorithm, does not allow data sharing between CPUs) is used for storing of the results</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_hash.length">hash.length</code></td>
<td>
<p>a parameter defining hash size for the big.memory based hash table as 2^hash.length (only relevant when create.table = TRUE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_presearch">presearch</code></td>
<td>
<p>a boolean parameter defining if greedy forward and backward regression steps are used for initialization of initial approximations of marginal inclusion probabilities</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_locstop">locstop</code></td>
<td>
<p>a boolean parameter defining if the presearch is stopped at the first local extremum visited</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_pseudo.paral">pseudo.paral</code></td>
<td>
<p>defines if lapply or mclapply is used for local vectorized computations within the chain (can only be TRUE if create.table= TRUE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_interact">interact</code></td>
<td>
<p>a boolean parameter defining if feature engineering is allowed in the search</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_deep.method">deep.method</code></td>
<td>
<p>an integer in {1, 2, 3, 4} defining the method of estimating the alpha parameters of BGNLM, details to be found in https://www.jair.org/index.php/jair/article/view/13047</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_relations">relations</code></td>
<td>
<p>a vector of allowed modification functions (only relevant when feature engineering is enabled by means of interact = TRUE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_relations.prob">relations.prob</code></td>
<td>
<p>probability distribution of addressing modifications defined in relations parameter (both vectors must be of the same length)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_gen.prob">gen.prob</code></td>
<td>
<p>a vector of probabilities for different operators in GMJMCMC or RGMJMCMC in the deep regression context (hence only relevant if <code>interact.param$allow_offsprings</code> is either 3 or 4)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_pool.cross">pool.cross</code></td>
<td>
<p>a parameter defining the probability of addressing covariates from the current pool of covariates in GMJMCMC (covariates from the set of filtered covariates can be addressed with probability 1-pool.cross) (only relevant when interact = TRUE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_p.epsilon">p.epsilon</code></td>
<td>
<p>a parameter to define minimal deviations from 0 and 1 probabilities when allowing adaptive MCMC based on marginal inclusion probabilities</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_del.sigma">del.sigma</code></td>
<td>
<p>a parameter describing probability of deleting each of the function from the selected feature in the reduction operator(only relevant for the deep regression models context)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_pool.cor.prob">pool.cor.prob</code></td>
<td>
<p>a boolean parameter indicating if inclusion of the filtered covariates during mutations are based on probabilities proportional to the absolute values of correlations of these parameters and the observations (should not be addressed for multivariate observations, e.g. survival studies with Cox regression)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_interact.param">interact.param</code></td>
<td>
<p>a list of parameters for GMJMCMC, where allow_offsprings is 1 for logic regression context, 2 for the old version of GMJMCMC for deep regressions, 3 for the new version of GMJMCMC for deep regressions and 4 for the RGMJMCMC for the deep regressions; mutation_rate defines how often changes of the search space are allowed in terms of the number of MJMCMC iterations per search space; last.mutation defines the iteration after which changes of search space are no longer allowed; max.tree.size is a parameter defining maximal depth of features; Nvars.max is a parameter defining maximal number of covariates in the search space after the first filtration; p.allow.replace is a parameter defining the upper bound on the probability allowing the replacement of corresponding features with marginal inclusion probabilities below it; p.allow.tree is a lower bound for the probability of not being filtered out after initializing steps of MJMCMC in GMJMCMC; p.nor is a parameter for not operator in the logic regression context (allow_offsprings==1); p.and = is the probability of &amp; crossover in the logic regression context (allow_offsprings==1)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_prand">prand</code></td>
<td>
<p>probability of changes of components in randomization kernels of RGMJMCMC</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_keep.origin">keep.origin</code></td>
<td>
<p>a boolean parameter defining if the initially unfiltered covariates can leave the search space afterwards (TRUE) or not (FALSE)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_sup.large.n">sup.large.n</code></td>
<td>
<p>omitted currently</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_recalc_margin">recalc_margin</code></td>
<td>
<p>a parameter defining how often marginal inclusion probabilities would be recalculated</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_create.hash">create.hash</code></td>
<td>
<p>a parameter defining if by default the results are stored in a hash table</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_interact.order">interact.order</code></td>
<td>
<p>omitted currently</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_burn.in">burn.in</code></td>
<td>
<p>number of burn-in steps for (R)(G)MJMCMC</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_eps">eps</code></td>
<td>
<p>omitted, not to be changed</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_max.time">max.time</code></td>
<td>
<p>maximal time for the run of (R)(G)MJMCMC algorithm in minutes</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_max.it">max.it</code></td>
<td>
<p>maximal number of (R)(G)MJMCMC iterations</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_print.freq">print.freq</code></td>
<td>
<p>printing frequency of the intermediate results</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_outgraphs">outgraphs</code></td>
<td>
<p>a boolean variable defining if the graphics on the marginal inclusion probabilities should be drawn (must not be used inside mclapply wrapper of runemjmcmc since otherwise errors can occur)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_advanced.param">advanced.param</code></td>
<td>
<p>omitted currently</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_distrib_of_neighbourhoods">distrib_of_neighbourhoods</code></td>
<td>
<p>a matrix defining probability distribution on 7 types of neighbourhoods within 4 possible local search strategies as well as within global moves</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_distrib_of_proposals">distrib_of_proposals</code></td>
<td>
<p>probability distribution up to a constant of proportionality for addressing different local search strategies after large jumps or no large jumps (5th component)</p>
</td></tr>
<tr><td><code id="runemjmcmc_+3A_quiet">quiet</code></td>
<td>
<p>defaults to <code>FALSE</code>. If <code>TRUE</code>, prints intermediate
messages</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is an extended Metropolis-Hastings algorithm
(or its Genetically modified version) mixing single site changes with
occasionally large jumps. The models are described through the gamma vector,
a binary vector indicating which variables that are included in the model.
</p>
<p>See Hubin &amp; Storvik (2016),Hubin, Storvik &amp; Frommlet (2017),
Hubin &amp; Storvik (2017) details. The local optimization is performed through
stepwise search within a neighborhood in the current gamma vector, allowing
one component to be changed at a time.
</p>


<h3>Value</h3>

<p>a list containing
</p>

<dl>
<dt>p.post</dt><dd><p>a vector of posterior probabilities of the final vector of active covariates (features)</p>
</dd>
<dt>m.post</dt><dd><p>a vector of posterior probabilities of the models from the search space induced by the final vector of active covariates (features)</p>
</dd>
<dt>s.mass</dt><dd><p>sum of marginal likelihoods times the priors from the explored part of the search space induced by the final vector of active covariates (features)</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Aliaksandr Hubin
</p>


<h3>References</h3>

<p>Hubin &amp; Storvik (2016),Hubin, Storvik &amp; Frommlet (2017), Hubin &amp; Storvik (2017)
</p>


<h3>See Also</h3>

<p>global objects statistics1 (if create.table== TRUE) or hashStat (if create.table== FALSE) contain all marginal likelihoods and two other model selection criteria as well as all of the beta coefficients for the models (if save.beta== TRUE)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X4 &lt;- as.data.frame(
  array(
    data = rbinom(n = 50 * 1000, size = 1, prob = runif(n = 50 * 1000, 0, 1)),
    dim = c(1000, 50)
  )
)
Y4 &lt;- rnorm(
  n = 1000,
  mean = 1 +
    7 * (X4$V4 * X4$V17 * X4$V30 * X4$V10) +
    7 * (((X4$V50 * X4$V19 * X4$V13 * X4$V11) &gt; 0)) +
    9 * (X4$V37 * X4$V20 * X4$V12) +
    7 * (X4$V1 * X4$V27 * X4$V3) +
    3.5 * (X4$V9 * X4$V2) +
    6.6 * (X4$V21 * X4$V18) +
    1.5 * X4$V7 +
    1.5 * X4$V8,
  sd = 1
)
X4$Y4 &lt;- Y4
data.example &lt;- as.data.frame(X4)

# specify the initial formula
formula1 &lt;- as.formula(
  paste(colnames(X4)[51], "~ 1 +", paste0(colnames(X4)[-c(51)], collapse = "+"))
)


# specify tuning parameters of the algorithm for exploring DBRM of interest
# notice that allow_offsprings=3 corresponds to the GMJMCMC runs and
# allow_offsprings=4 -to the RGMJMCMC runs

  res &lt;- runemjmcmc(
    formula = formula1, outgraphs = FALSE, data = X4,
    estimator = estimate.gamma.cpen, estimator.args = list(data = data.example),
    recalc_margin = 249, save.beta = FALSE, interact = TRUE,
    relations = c("cos", "sigmoid", "tanh", "atan", "sin", "erf"),
    relations.prob = c(0.1, 0.1, 0.1, 0.1, 0.1, 0.1),
    interact.param = list(
      allow_offsprings = 4, mutation_rate = 250, last.mutation = 15000,
      max.tree.size = 4, Nvars.max = 40, p.allow.replace = 0.7,
      p.allow.tree = 0.2, p.nor = 0, p.and = 0.9
    ), n.models = 20000, unique = TRUE, max.cpu = 4, max.cpu.glob = 4,
    create.table = FALSE, create.hash = TRUE, pseudo.paral = TRUE, burn.in = 50,
    print.freq = 1000,
    advanced.param = list(
      max.N.glob = as.integer(10),
      min.N.glob = as.integer(5),
      max.N = as.integer(3),
      min.N = as.integer(1),
      printable = FALSE
    )
  )

</code></pre>

<hr>
<h2 id='sigmoid'>sigmoid activation function</h2><span id='topic+sigmoid'></span>

<h3>Description</h3>

<p>sigmoid activation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sigmoid(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sigmoid_+3A_x">x</code></td>
<td>
<p>a real number</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sigmoid value
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sigmoid(10)
</code></pre>

<hr>
<h2 id='simplify.formula'>A function parsing the formula into the vectors of character arrays
of responses and covariates</h2><span id='topic+simplify.formula'></span>

<h3>Description</h3>

<p>A function parsing the formula into the vectors of character arrays
of responses and covariates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplify.formula(fmla, names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simplify.formula_+3A_fmla">fmla</code></td>
<td>
<p>an R formula object</p>
</td></tr>
<tr><td><code id="simplify.formula_+3A_names">names</code></td>
<td>
<p>all column names from the data.frame to be used with the formula</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of
</p>

<dl>
<dt>fobserved</dt><dd><p>a vector of character arrays corresponding to the observations</p>
</dd>
<dt>fparam</dt><dd><p>a vector of character arrays corresponding to the covariates</p>
</dd>
</dl>



<h3>See Also</h3>

<p>formula data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X1 &lt;- as.data.frame(
  array(data = rbinom(n = 50 * 1000, size = 1, prob = 0.3), dim = c(1000, 50))
)
Y1 &lt;- -0.7 + 1 * ((1 - X1$V1) * (X1$V4)) + 1 * (X1$V8 * X1$V11) + 1 * (X1$V5 * X1$V9)
X1$Y1 &lt;- round(1.0 / (1.0 + exp(-Y1)))

formula1 &lt;- as.formula(
  paste(colnames(X1)[51], "~ 1 +", paste0(colnames(X1)[-c(51)], collapse = "+"))
)
names &lt;- colnames(X1)
simplify.formula(fmla = formula1, names = names)
</code></pre>

<hr>
<h2 id='simplifyposteriors'>A function that ads up posteriors for the same expression written
in different character form in different parallel runs of the algorithm
(mainly for Logic Regression and Deep Regression contexts)</h2><span id='topic+simplifyposteriors'></span>

<h3>Description</h3>

<p>A function that ads up posteriors for the same expression written
in different character form in different parallel runs of the algorithm
(mainly for Logic Regression and Deep Regression contexts)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simplifyposteriors(X, posteriors, th = 1e-04, thf = 0.2, resp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simplifyposteriors_+3A_x">X</code></td>
<td>
<p>a data.frame containing the data on the covariates</p>
</td></tr>
<tr><td><code id="simplifyposteriors_+3A_posteriors">posteriors</code></td>
<td>
<p>a data.frame with expressions in the first column and their posteriors in the second column from all of the runs</p>
</td></tr>
<tr><td><code id="simplifyposteriors_+3A_th">th</code></td>
<td>
<p>initial filtering before summary threshold</p>
</td></tr>
<tr><td><code id="simplifyposteriors_+3A_thf">thf</code></td>
<td>
<p>threshold for final filtering after summary</p>
</td></tr>
<tr><td><code id="simplifyposteriors_+3A_resp">resp</code></td>
<td>
<p>the response to be addressed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>res, a data.frame with the summarized across runs expressions and
their posteriors
</p>


<h3>See Also</h3>

<p>runemjmcmc
</p>

<hr>
<h2 id='truncfactorial'>Truncated factorial to avoid stack overflow for huge values</h2><span id='topic+truncfactorial'></span>

<h3>Description</h3>

<p>truncated factorial to avoid stack overflow for huge values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>truncfactorial(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="truncfactorial_+3A_x">x</code></td>
<td>
<p>a non-negative integer number</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>truncfactorial(x)</code>, truncated factorial as min(x!,171!)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>truncfactorial(10)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
