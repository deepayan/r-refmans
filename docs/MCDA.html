<!DOCTYPE html><html><head><title>Help for package MCDA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MCDA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#additiveValueFunctionElicitation'><p>Elicitation of a general additive value function.</p></a></li>
<li><a href='#AHP'><p>Analytic Hierarchy Process (AHP) method</p></a></li>
<li><a href='#applyPiecewiseLinearValueFunctionsOnPerformanceTable'><p>Applies value functions on a performance table.</p></a></li>
<li><a href='#assignAlternativesToCategoriesByThresholds'><p>Assign alternatives to categories according to thresholds.</p></a></li>
<li><a href='#ELECTRE3'><p>ELimination Et Choice Translating REality - ELECTRE-III</p></a></li>
<li><a href='#ELECTREIIIDistillation'><p>ELECTRE III ranking</p></a></li>
<li><a href='#LPDMRSort'><p>MRSort that takes into account large performance differences.</p></a></li>
<li><a href='#LPDMRSortIdentifyIncompatibleAssignments'><p>Identifies all sets of assignment examples which are incompatible with the</p>
MRSort sorting method extended to handle large performance differences.</a></li>
<li><a href='#LPDMRSortIdentifyUsedDictatorProfiles'><p>Identify dictator profiles evaluations that have an impact on the final</p>
assignments of MRSort with large performance differences</a></li>
<li><a href='#LPDMRSortIdentifyUsedVetoProfiles'><p>Identify veto profiles evaluations that have an impact on the final</p>
assignments of MRSort with large performance differences</a></li>
<li><a href='#LPDMRSortInferenceApprox'><p>Identification of profiles, weights, majority threshold, veto and dictator</p>
thresholds for LPDMRSort using a genetic algorithm.</a></li>
<li><a href='#LPDMRSortInferenceExact'><p>Identification of profiles, weights, majority threshold and veto and</p>
dictator thresholds for the MRSort sorting approach extended to handle large
performance differences.</a></li>
<li><a href='#MARE'><p>Multi-Attribute Range Evaluations (MARE)</p></a></li>
<li><a href='#MRSort'><p>Electre TRI-like sorting method axiomatized by Bouyssou and Marchant.</p></a></li>
<li><a href='#MRSortIdentifyIncompatibleAssignments'><p>Identifies all sets of assignment examples which are incompatible with the</p>
MRSort method.</a></li>
<li><a href='#MRSortIdentifyUsedVetoProfiles'><p>Identify veto profiles evaluations that have an impact on the final</p>
assignments of MRSort</a></li>
<li><a href='#MRSortInferenceApprox'><p>Identification of profiles, weights, majority threshold and veto thresholds</p>
for MRSort using a genetic algorithm.</a></li>
<li><a href='#MRSortInferenceExact'><p>Identification of profiles, weights and majority threshold for the MRSort</p>
sorting method using an exact approach.</a></li>
<li><a href='#MRSortInterval'><p>MRSort with imprecise evaluations</p></a></li>
<li><a href='#normalizePerformanceTable'><p>Function to normalize (or rescale) the columns (or criteria) of a</p>
performance table.</a></li>
<li><a href='#pairwiseConsistencyMeasures'><p>Consistency Measures for Pairwise Comparison Matrices</p></a></li>
<li><a href='#plotAlternativesValuesPreorder'><p>Function to plot a preorder of alternatives, based on some score or ranking.</p></a></li>
<li><a href='#plotMARE'><p>Plot Multi-Attribute Range Evaluations (MARE)</p></a></li>
<li><a href='#plotMRSortSortingProblem'><p>Plot the categories and assignments of an Electre TRI-like sorting problem</p>
(via separation profiles).</a></li>
<li><a href='#plotPiecewiseLinearValueFunctions'><p>Function to plot piecewise linear value functions.</p></a></li>
<li><a href='#plotRadarPerformanceTable'><p>Function to plot radar plots of alternatives of a performance table.</p></a></li>
<li><a href='#plotSURE'><p>Plot SURE kernel density plots.</p></a></li>
<li><a href='#PROMETHEEI'><p>PROMETHEE I</p></a></li>
<li><a href='#PROMETHEEII'><p>PROMETHEE II</p></a></li>
<li><a href='#PROMETHEEOutrankingFlows'><p>Outranking flows for the PROMETHEE methods</p></a></li>
<li><a href='#PROMETHEEPreferenceIndices'><p>Preference indices for the PROMETHEE methods</p></a></li>
<li><a href='#SRMP'><p>SRMP: a simple ranking method using reference profiles</p></a></li>
<li><a href='#SRMPInference'><p>Exact inference of an SRMP model given a maximum number of reference</p>
profiles</a></li>
<li><a href='#SRMPInferenceApprox'><p>Approximative inference of an SRMP model</p></a></li>
<li><a href='#SRMPInferenceApproxFixedLexicographicOrder'><p>Approximative inference of an SRMP model given the lexicographic order of</p>
the profiles</a></li>
<li><a href='#SRMPInferenceApproxFixedProfilesNumber'><p>Approximative inference of an SRMP model given the number of reference</p>
profiles</a></li>
<li><a href='#SRMPInferenceFixedLexicographicOrder'><p>Exact inference of an SRMP model given the lexicographic order of the</p>
profiles</a></li>
<li><a href='#SRMPInferenceFixedProfilesNumber'><p>Exact inference of an SRMP model given the number of reference profiles</p></a></li>
<li><a href='#SRMPInferenceNoInconsist'><p>Exact inference of an SRMP model given a maximum number of reference</p>
profiles - no inconsistencies</a></li>
<li><a href='#SRMPInferenceNoInconsistFixedLexicographicOrder'><p>Exact inference of an SRMP model given the lexicographic order of the</p>
profiles - no inconsistencies</a></li>
<li><a href='#SRMPInferenceNoInconsistFixedProfilesNumber'><p>Exact inference of an SRMP model given the number of reference profiles - no</p>
inconsistencies</a></li>
<li><a href='#SURE'><p>Simulated Uncertainty Range Evaluations (SURE)</p></a></li>
<li><a href='#TOPSIS'><p>Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS)</p>
method</a></li>
<li><a href='#UTA'><p>UTA method to elicit value functions.</p></a></li>
<li><a href='#UTADIS'><p>UTADIS method to elicit value functions in view of sorting alternatives in</p>
ordered categories</a></li>
<li><a href='#UTASTAR'><p>UTASTAR method to elicit value functions.</p></a></li>
<li><a href='#VIKOR'><p>VIKOR method</p></a></li>
<li><a href='#weightedSum'><p>Weighted sum of evaluations of alternatives.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Title:</td>
<td>Support for the Multicriteria Decision Aiding Process</td>
</tr>
<tr>
<td>Author:</td>
<td>Patrick Meyer, Sébastien Bigaret, Richard Hodgett, Alexandru-Liviu Olteanu, David Palma, Aritad Alan Choicharoon</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Palma &lt;d.palma@leeds.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Support for the analyst in a Multicriteria Decision Aiding (MCDA) process with algorithms, 
    preference elicitation and data visualisation functions. Sébastien Bigaret, Richard Hodgett, Patrick Meyer, 
    Tatyana Mironova, Alexandru Olteanu (2017) Supporting the multi-criteria decision aiding process : 
    R and the MCDA package, Euro Journal On Decision Processes, Volume 5, Issue 1 - 4, 
    pages 169 - 194 &lt;<a href="https://doi.org/10.1007%2Fs40070-017-0064-1">doi:10.1007/s40070-017-0064-1</a>&gt;.</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rglpk, glpkAPI, RColorBrewer, combinat, triangle, plyr,
ggplot2</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://joinup.ec.europa.eu/software/page/eupl">EUPL (&ge; 1.1)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/paterijk/MCDA">https://github.com/paterijk/MCDA</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-22 17:59:32 UTC; david</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-24 09:20:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='additiveValueFunctionElicitation'>Elicitation of a general additive value function.</h2><span id='topic+additiveValueFunctionElicitation'></span>

<h3>Description</h3>

<p>Elicits a general additive value function from a ranking of alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>additiveValueFunctionElicitation(
  performanceTable,
  criteriaMinMax,
  epsilon,
  alternativesRanks = NULL,
  alternativesPreferences = NULL,
  alternativesIndifferences = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="additiveValueFunctionElicitation_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_epsilon">epsilon</code></td>
<td>
<p>Numeric value containing the minimal difference in value
between two consecutive alternatives in the final ranking.</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_alternativesranks">alternativesRanks</code></td>
<td>
<p>Optional vector containing the ranks of the
alternatives. The elements are named according to the IDs of the
alternatives. If not present, then at least one of alternativesPreferences
or alternativesIndifferences should be given.</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_alternativespreferences">alternativesPreferences</code></td>
<td>
<p>Optional matrix containing the preference
constraints on the alternatives. Each line of the matrix corresponds to a
constraint of the type alternative a is strictly preferred to alternative b.
If not present, then either alternativesRanks or alternativesIndifferences
should be given.</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_alternativesindifferences">alternativesIndifferences</code></td>
<td>
<p>Optional matrix containing the indifference
constraints on the alternatives. Each line of the matrix corresponds to a
constraint of the type alternative a is indifferent to alternative b. If not
present, then either alternativesRanks or alternativesPreferences should be
given.</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="additiveValueFunctionElicitation_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list structured as follows :
</p>
<table>
<tr><td><code>optimum</code></td>
<td>
<p>The value of the objective function.</p>
</td></tr> <tr><td><code>valueFunctions</code></td>
<td>
<p>A
list containing the value functions which have been determined. Each value
function is defined by a matrix of breakpoints, where the first row
corresponds to the abscissa (row labelled &quot;x&quot;) and where the second row
corresponds to the ordinate (row labelled &quot;y&quot;).</p>
</td></tr> <tr><td><code>overallValues</code></td>
<td>
<p>A
vector containing the overall values of the input alternatives.</p>
</td></tr>
<tr><td><code>ranks</code></td>
<td>
<p>A vector containing the ranks of the alternatives obtained via
the elicited value functions. Ties method = &quot;min&quot;.</p>
</td></tr> <tr><td><code>Kendall</code></td>
<td>
<p>Kendall's
tau between the input ranking and the one obtained via the elicited value
functions.</p>
</td></tr> <tr><td><code>errors</code></td>
<td>
<p>The errors (sigma) which have to be added to the
overall values of the alternatives in order to respect the input ranking.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Based on the UTA algorithm (E. Jacquet-Lagreze, J. Siskos,
Assessing a set of additive utility functions for multicriteria
decision-making, the UTA method, European Journal of Operational Research,
Volume 10, Issue 2, 151&ndash;164, June 1982) except that the breakpoints of the
value functions are the actual performances of the alternatives on the
criteria.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# ----------------------------------------
# ranking some cars (from original article on UTA by Siskos and Lagreze, 1982)

# the separation threshold

epsilon &lt;-0.01

# the performance table

performanceTable &lt;- rbind(      
c(173, 11.4, 10.01, 10, 7.88, 49500),
c(176, 12.3, 10.48, 11, 7.96, 46700),
c(142, 8.2, 7.30, 5, 5.65, 32100),
c(148, 10.5, 9.61, 7, 6.15, 39150), 
c(178, 14.5, 11.05, 13, 8.06, 64700), 
c(180, 13.6, 10.40, 13, 8.47, 75700),
c(182, 12.7, 12.26, 11, 7.81, 68593), 
c(145, 14.3, 12.95, 11, 8.38, 55000),
c(161, 8.6, 8.42, 7, 5.11, 35200), 
c(117, 7.2, 6.75, 3, 5.81, 24800)
)

rownames(performanceTable) &lt;- c(
  "Peugeot 505 GR",
  "Opel Record 2000 LS",
  "Citroen Visa Super E",
  "VW Golf 1300 GLS",
  "Citroen CX 2400 Pallas",
  "Mercedes 230",
  "BMW 520",
  "Volvo 244 DL",
  "Peugeot 104 ZS",
  "Citroen Dyane")

colnames(performanceTable) &lt;- c(
  "MaximalSpeed",
  "ConsumptionTown",
  "Consumption120kmh",
  "HP",
  "Space",
  "Price")

# ranks of the alternatives

alternativesRanks &lt;- c(1,2,3,4,5,6,7,8,9,10)

names(alternativesRanks) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("max","min","min","max","max","min")

names(criteriaMinMax) &lt;- colnames(performanceTable)

x&lt;-additiveValueFunctionElicitation(performanceTable,  
                                      criteriaMinMax, epsilon,
                                      alternativesRanks = alternativesRanks)


</code></pre>

<hr>
<h2 id='AHP'>Analytic Hierarchy Process (AHP) method</h2><span id='topic+AHP'></span>

<h3>Description</h3>

<p>AHP is a multi-criteria decision analysis method which was originally
developed by Thomas L. Saaty in 1970s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AHP(criteriaWeightsPairwiseComparisons, alternativesPairwiseComparisonsList)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AHP_+3A_criteriaweightspairwisecomparisons">criteriaWeightsPairwiseComparisons</code></td>
<td>
<p>Matrix or data frame containing
the pairwise comparison matrix for the criteria weights. Lines and columns
are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="AHP_+3A_alternativespairwisecomparisonslist">alternativesPairwiseComparisonsList</code></td>
<td>
<p>A list containing a matrix or
data frame of pairwise comparisons (comparing alternatives) for each
criterion. The elements of the list are named according to the IDs of the
criteria. In each matrix, the lines and the columns are named according to
the IDs of the alternatives. If one criteria is already a score (i.e. it 
is a numeric value between 0 and 1 where higher values indicate better 
performance), then providing a nAlt-length vector, or a nAlt x 1 matrix
containing the score associated with each alternative will be enough, but
the vector or rows of the matrix must be named as the alternatives.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the AHP score for each
alternative.
</p>


<h3>References</h3>

<p>The Analytic Hierarchy Process: Planning, Priority Setting
(1980), ISBN 0-07-054371-2, McGraw-Hill
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alts &lt;- c("Corsa","Clio","Fiesta","Sandero")
style &lt;- matrix(c(1.0, 1/4, 4.0, 1/6,
                  4.0, 1.0, 4.0, 1/4,
                  1/4, 1/4, 1.0, 1/5,
                  6.0, 4.0, 5.0, 1.0), 
                nrow=length(alts), ncol=length(alts), byrow=TRUE, 
                dimnames=list(alts,alts))
reliability &lt;- matrix(c(1.0, 2.0, 5.0, 1.0,
                        1/2, 1.0, 3.0, 2.0,
                        1/5, 1/3, 1.0, 1/4,
                        1.0, 1/2, 4.0, 1.0), 
                      nrow=length(alts), ncol=length(alts), byrow=TRUE, 
                      dimnames=list(alts,alts))
fuel &lt;- matrix(c(1.0, 2.0, 4.0, 1.0,
                 0.5, 1.0, 3.0, 2.0,
                 1/4, 1/3, 1.0, 1/5,
                 1.0, 1/2, 5.0, 1.0), 
               nrow=length(alts), ncol=length(alts), byrow=TRUE, 
               dimnames=list(alts,alts))
alternativesPairwiseComparisonsList &lt;- list(style       = style, 
                                            reliability = reliability, 
                                            fuel        = fuel)
crit &lt;- c("style","reliability","fuel")
criteriaWeightsPairwiseComparisons &lt;- matrix(c(1.0, 1/2, 3.0,
                                               2.0, 1.0, 4.0,
                                               1/3, 1/4, 1.0), 
                                             nrow=length(crit), 
                                             ncol=length(crit), 
                                             dimnames=list(crit,crit))
# All attributes have pairwise comparisons
AHP(criteriaWeightsPairwiseComparisons, alternativesPairwiseComparisonsList)
# Fuel is a score
newFuel &lt;- c(Corsa=34, Clio=27, Fiest=24, Sandero=28)
newFuel &lt;- newFuel/sum(newFuel)
alternativesPairwiseComparisonsList$fuel &lt;- newFuel
AHP(criteriaWeightsPairwiseComparisons, alternativesPairwiseComparisonsList)

</code></pre>

<hr>
<h2 id='applyPiecewiseLinearValueFunctionsOnPerformanceTable'>Applies value functions on a performance table.</h2><span id='topic+applyPiecewiseLinearValueFunctionsOnPerformanceTable'></span>

<h3>Description</h3>

<p>Transforms a performance table via given piecewise linear value functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>applyPiecewiseLinearValueFunctionsOnPerformanceTable(
  valueFunctions,
  performanceTable,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="applyPiecewiseLinearValueFunctionsOnPerformanceTable_+3A_valuefunctions">valueFunctions</code></td>
<td>
<p>A list containing, for each criterion, the piecewise
linear value functions defined by the coordinates of the break points. Each
value function is defined by a matrix of breakpoints, where the first row
corresponds to the abscissa (row labelled &quot;x&quot;) and where the second row
corresponds to the ordinate (row labelled &quot;y&quot;).</p>
</td></tr>
<tr><td><code id="applyPiecewiseLinearValueFunctionsOnPerformanceTable_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="applyPiecewiseLinearValueFunctionsOnPerformanceTable_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="applyPiecewiseLinearValueFunctionsOnPerformanceTable_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a performance table which has been transformed
through the given value functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# the value functions

v&lt;-list(
  Price = array(c(30, 0, 16, 0, 2, 0.0875), 
    dim=c(2,3), dimnames = list(c("x", "y"), NULL)), 
  Time = array(c(40, 0, 30, 0, 20, 0.025, 10, 0.9), 
    dim = c(2, 4), dimnames = list(c("x", "y"), NULL)), 
  Comfort = array(c(0, 0, 1, 0, 2, 0.0125, 3, 0.0125), 
    dim = c(2, 4), dimnames = list(c("x", "y"), NULL)))

# the performance table

performanceTable &lt;- rbind(
    	c(3,10,1),
			c(4,20,2),
			c(2,20,0),
			c(6,40,0),
			c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# the transformed performance table

applyPiecewiseLinearValueFunctionsOnPerformanceTable(v,performanceTable)

</code></pre>

<hr>
<h2 id='assignAlternativesToCategoriesByThresholds'>Assign alternatives to categories according to thresholds.</h2><span id='topic+assignAlternativesToCategoriesByThresholds'></span>

<h3>Description</h3>

<p>Assign alternatives to categories according to thresholds representing the
lower bounds of the categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assignAlternativesToCategoriesByThresholds(
  alternativesScores,
  categoriesLowerBounds,
  alternativesIDs = NULL,
  categoriesIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assignAlternativesToCategoriesByThresholds_+3A_alternativesscores">alternativesScores</code></td>
<td>
<p>Vector representing the overall scores of the
alternatives. The elements are named according to the IDs of the
alternatives.</p>
</td></tr>
<tr><td><code id="assignAlternativesToCategoriesByThresholds_+3A_categorieslowerbounds">categoriesLowerBounds</code></td>
<td>
<p>Vector containing the lower bounds of the
categories. An alternative is assigned to a category if it's score is higher
or equal to the lower bound of the category, and strictly lower to the lower
bound of the category above.</p>
</td></tr>
<tr><td><code id="assignAlternativesToCategoriesByThresholds_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="assignAlternativesToCategoriesByThresholds_+3A_categoriesids">categoriesIDs</code></td>
<td>
<p>Vector containing IDs of categories, according to which
the data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the assignments of the
alternatives to the categories.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the separation threshold

epsilon &lt;-0.05

# the performance table

performanceTable &lt;- rbind(
  c(3,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# ranks of the alternatives

alternativesAssignments &lt;- c("good","medium","medium","bad","bad")

names(alternativesAssignments) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# number of break points for each criterion

criteriaNumberOfBreakPoints &lt;- c(3,4,4)

names(criteriaNumberOfBreakPoints) &lt;- colnames(performanceTable)

# ranks of the categories

categoriesRanks &lt;- c(1,2,3)

names(categoriesRanks) &lt;- c("good","medium","bad")

x&lt;-UTADIS(performanceTable, criteriaMinMax, criteriaNumberOfBreakPoints, 
            alternativesAssignments, categoriesRanks,0.1)

npt &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(x$valueFunctions, 
                                                             performanceTable)

scores &lt;- weightedSum(npt, c(1,1,1))

# add a lower bound for the "bad" category

lbs &lt;- c(x$categoriesLBs,0)

names(lbs) &lt;- c(names(x$categoriesLBs),"bad")

assignments&lt;-assignAlternativesToCategoriesByThresholds(scores,lbs)



</code></pre>

<hr>
<h2 id='ELECTRE3'>ELimination Et Choice Translating REality - ELECTRE-III</h2><span id='topic+ELECTRE3'></span>

<h3>Description</h3>

<p>ELECTRE (ELimination Et Choice Translating REality) is an outranking method
proposed by Bernard Roy and his colleagues at SEMA consultancy company. This
is the implementation of ELECTRE-III.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ELECTRE3(scores, q, p, v, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ELECTRE3_+3A_scores">scores</code></td>
<td>
<p>Matrix or data frame containing the performance table. Each
column corresponds to a criterion, and each row to an alternative.</p>
</td></tr>
<tr><td><code id="ELECTRE3_+3A_q">q</code></td>
<td>
<p>Vector containing the indifference thresholds. The elements are
named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="ELECTRE3_+3A_p">p</code></td>
<td>
<p>Vector containing the preference threshold on each of the criteria.
The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="ELECTRE3_+3A_v">v</code></td>
<td>
<p>Vector containing the veto thresholds for each criterion. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="ELECTRE3_+3A_w">w</code></td>
<td>
<p>Vector containing the weights of criteria. The elements are named
according to the IDs of the criteria.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns the Concordance, Discordance, Credibility,
Dominance, and Scoring tables.
</p>


<h3>References</h3>

<p>Roy, Bernard (1968). &quot;Classement et choix en présence de points
de vue multiples (la méthode ELECTRE)&quot;. La Revue d'Informatique et de
Recherche Opérationelle (RIRO) (8): 57–75.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MCDA)
scores &lt;- matrix( c(-0.2,-2.3,-2.4,-1,3,9,10,7), 
                  nrow = 4, 
                  dimnames = list(
                    c("School-A","School-B","School-C", "School-D"), 
                    c("Location","Quality")) )

q &lt;- c( 0.2, 1)
p &lt;- c(   1, 2)
v &lt;- c( 3.5, 4)
w &lt;- c(0.25, 0.75)

res &lt;- ELECTRE3(scores, q, p, v, w)
print(res)


</code></pre>

<hr>
<h2 id='ELECTREIIIDistillation'>ELECTRE III ranking</h2><span id='topic+ELECTREIIIDistillation'></span>

<h3>Description</h3>

<p>This function computes the two ELECTRE III distillations, or rankings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ELECTREIIIDistillation(
  performanceTable,
  criteriaWeights,
  minMaxcriteria,
  preferenceThresholds,
  indifferenceThresholds,
  vetoThresholds
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ELECTREIIIDistillation_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="ELECTREIIIDistillation_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="ELECTREIIIDistillation_+3A_minmaxcriteria">minMaxcriteria</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="ELECTREIIIDistillation_+3A_preferencethresholds">preferenceThresholds</code></td>
<td>
<p>Vector containing preference thresholds for each
criterion.</p>
</td></tr>
<tr><td><code id="ELECTREIIIDistillation_+3A_indifferencethresholds">indifferenceThresholds</code></td>
<td>
<p>Vector containing indifferences thresholds for
each criterion.</p>
</td></tr>
<tr><td><code id="ELECTREIIIDistillation_+3A_vetothresholds">vetoThresholds</code></td>
<td>
<p>Vector containing veto thresholds for each criterion.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns two lists, one for each distillation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTable &lt;- rbind(
c(10,20,5,10,16),
c(0,5,5,16,10),
c(0,10,0,16,7),
c(20,5,10,10,13),
c(20,10,15,10,13),
c(20,10,20,13,13))
rownames(performanceTable) &lt;-c("P1","P2","P3","P4","P5","P6")
colnames(performanceTable) &lt;-c("CRIT1","CRIT2","CRIT3","CRIT4","CRIT5")
## vector indicating the direction of the criteria evaluation .
minMaxcriteria &lt;-c("max","max","max","max","max")
names(minMaxcriteria) &lt;- colnames(performanceTable)
## criteriaWeights vector
criteriaWeights &lt;- c(3,2,3,1,1)
names(criteriaWeights) &lt;- colnames(performanceTable)

indifferenceThresholds&lt;-c(3,3,3,3,3)
names(indifferenceThresholds) &lt;- colnames(performanceTable)
preferenceThresholds&lt;-c(5,5,5,5,5)
names(preferenceThresholds) &lt;- colnames(performanceTable)
vetoThresholds&lt;-c(11,11,11,11,11)
names(vetoThresholds) &lt;- colnames(performanceTable)

ELECTREIIIDistillation(performanceTable,criteriaWeights,minMaxcriteria,
                       preferenceThresholds,indifferenceThresholds,
                       vetoThresholds)

</code></pre>

<hr>
<h2 id='LPDMRSort'>MRSort that takes into account large performance differences.</h2><span id='topic+LPDMRSort'></span>

<h3>Description</h3>

<p>MRSort is a simplified ElectreTRI method that uses the pessimistic
assignment rule, without indifference or preference thresholds attached to
criteria. LPDMRSort considers both a binary discordance and a binary
concordance conditions including several interactions between them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPDMRSort(
  performanceTable,
  categoriesLowerProfiles,
  categoriesRanks,
  criteriaWeights,
  criteriaMinMax,
  majorityThreshold,
  criteriaVetos = NULL,
  criteriaDictators = NULL,
  majorityRule = "M",
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  categoriesIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPDMRSort_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_categorieslowerprofiles">categoriesLowerProfiles</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories. The columns are named according to the criteria,
and the rows are named according to the categories. The index of the row in
the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_majoritythreshold">majorityThreshold</code></td>
<td>
<p>The cut threshold for the concordance condition.
Should be at least half of the sum of the weights.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_criteriavetos">criteriaVetos</code></td>
<td>
<p>Matrix containing in each row a vector defining the
veto values for the lower profile of the category. NA values mean that no
veto is defined. A veto threshold for criterion i and category k represents
the performance below which an alternative is forbidden to outrank the lower
profile of category k, and thus is forbidden to be assigned to the category
k. The rows are named according to the categories, whereas the columns are
named according to the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_criteriadictators">criteriaDictators</code></td>
<td>
<p>Matrix containing in each row a vector defining the
dictator values for the lower profile of the category. NA values mean that
no veto is defined.  A dictator threshold for criterion i and category k
represents the performance above which an alternative is guaranteed to
outrank the lower profile of category k, and thus may no be assigned below
category k. The rows are named according to the categories, whereas the
columns are named according to the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_majorityrule">majorityRule</code></td>
<td>
<p>String denoting how the vetoes and dictators are
combined in order to form the assignment rule.  The values to choose from
are &quot;M&quot;, &quot;V&quot;, &quot;D&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;.  &quot;M&quot; corresponds to using
only the majority rule without vetoes or dictators, &quot;V&quot; considers only the
vetoes, &quot;D&quot; only the dictators, &quot;v&quot; is like &quot;V&quot; only that a dictator may
invalidate a veto, &quot;d&quot; is like &quot;D&quot; only that a veto may invalidate a
dictator, &quot;dV&quot; is like &quot;V&quot; only that if there is no veto we may then
consider the dictator, &quot;Dv&quot; is like &quot;D&quot; only that when there is no dictator
we may consider the vetoes, while finally &quot;dv&quot; is identical to using both
dictator and vetoes only that when both are active they invalidate each
other, so the majority rule is considered in that case.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSort_+3A_categoriesids">categoriesIDs</code></td>
<td>
<p>Vector containing IDs of categories, according to which
the data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the assignments of the
alternatives to the categories.
</p>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompensatory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>
<p>Meyer, P. and Olteanu, A-L. Integrating large positive and negative
performance differences in majority-rule sorting models. European Journal of
Operational Research, submitted, 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(c(10,10,9), c(10,9,10), c(9,10,10), c(9,9,10), 
                          c(9,10,9), c(10,9,9), c(10,10,7), c(10,7,10), 
                          c(7,10,10), c(9,9,17), c(9,17,9), c(17,9,9), 
                          c(7,10,17), c(10,17,7), c(17,7,10), c(7,17,10), 
                          c(17,10,7), c(10,7,17), c(7,9,17), c(9,17,7), 
                          c(17,7,9), c(7,17,9), c(17,9,7), c(9,7,17))

profilesPerformances &lt;- rbind(c(10,10,10),c(0,0,0))

vetoPerformances &lt;- rbind(c(7,7,7),c(0,0,0))

dictatorPerformances &lt;- rbind(c(17,17,17),c(0,0,0))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", 
                                "a8", "a9", "a10", "a11", "a12",  "a13", 
                                "a14", "a15", "a16", "a17", "a18", "a19", 
                                "a20", "a21", "a22", "a23", "a24")

rownames(profilesPerformances) &lt;- c("P","F")

rownames(vetoPerformances) &lt;- c("P","F")

rownames(dictatorPerformances) &lt;- c("P","F")

colnames(performanceTable) &lt;- c("c1","c2","c3")

colnames(profilesPerformances) &lt;- c("c1","c2","c3")

colnames(vetoPerformances) &lt;- c("c1","c2","c3")

colnames(dictatorPerformances) &lt;- c("c1","c2","c3")

lambda &lt;- 0.5

weights &lt;- c(1/3,1/3,1/3)

names(weights) &lt;- c("c1","c2","c3")

categoriesRanks &lt;-c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

assignments &lt;-rbind(c("P","P","P","F","F","F","F","F","F","F","F","F",
                    "F","F","F","F","F","F","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","P","P","P","P","P","P",
                    "P","P","P","P","P","P","P","P","P","P","P","P"), 
                    c("P","P","P","F","F","F","F","F","F","F","F","F",
                    "P","P","P","P","P","P","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","P","P","P","P","P","P",
                    "P","P","P","P","P","P","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "F","F","F","F","F","F","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "P","P","P","P","P","P","P","P","P","P","P","P"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "P","P","P","P","P","P","F","F","F","F","F","F"))

colnames(assignments) &lt;- rownames(performanceTable)

majorityRules &lt;- c("V","D","v","d","dV","Dv","dv")

for(i in 1:7)
{
  ElectreAssignments&lt;-LPDMRSort(performanceTable, profilesPerformances, 
                                categoriesRanks,
                                weights, criteriaMinMax, lambda, 
                                criteriaVetos=vetoPerformances,
                                criteriaDictators=dictatorPerformances,
                                majorityRule = majorityRules[i])

  print(all(ElectreAssignments == assignments[i,]))
}

</code></pre>

<hr>
<h2 id='LPDMRSortIdentifyIncompatibleAssignments'>Identifies all sets of assignment examples which are incompatible with the
MRSort sorting method extended to handle large performance differences.</h2><span id='topic+LPDMRSortIdentifyIncompatibleAssignments'></span>

<h3>Description</h3>

<p>MRSort is a simplified ElectreTRI method that uses the pessimistic
assignment rule, without indifference or preference thresholds attached to
criteria. LPDMRSort considers both a binary discordance and a binary
concordance conditions including several interactions between them. This
function outputs all (or a fixed number of) sets of incompatible assignment
examples ranging in size from the minimal size and up to a given threshold.
The retrieved sets are also not contained in each other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPDMRSortIdentifyIncompatibleAssignments(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  majorityRule = "M",
  incompatibleSetsLimit = 100,
  largerIncompatibleSetsMargin = 0,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories.  The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories.  The
elements are named according to the IDs of the categories.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_majorityrule">majorityRule</code></td>
<td>
<p>String denoting how the vetoes and dictators are
combined in order to form the assignment rule.  The values to choose from
are &quot;M&quot;, &quot;V&quot;, &quot;D&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;.  &quot;M&quot; corresponds to using
only the majority rule without vetoes or dictators, &quot;V&quot; considers only the
vetoes, &quot;D&quot; only the dictators, &quot;v&quot; is like &quot;V&quot; only that a dictator may
invalidate a veto, &quot;d&quot; is like &quot;D&quot; only that a veto may invalidate a
dictator, &quot;dV&quot; is like &quot;V&quot; only that if there is no veto we may then
consider the dictator, &quot;Dv&quot; is like &quot;D&quot; only that when there is no dictator
we may consider the vetoes, while finally &quot;dv&quot; is identical to using both
dictator and vetoes only that when both are active they invalidate each
other, so the majority rule is considered in that case.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_incompatiblesetslimit">incompatibleSetsLimit</code></td>
<td>
<p>Pozitive integer denoting the upper limit of
the number of sets to be retrieved.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_largerincompatiblesetsmargin">largerIncompatibleSetsMargin</code></td>
<td>
<p>Pozitive integer denoting whether sets
larger than the minimal size should be retrieved, and by what margin. For
example, if this is 0 then only sets of the minimal size will be retrieved,
if this is 1 then sets also larger by 1 element will be retrieved.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyIncompatibleAssignments_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns NULL if there is a problem, or a list
containing a list of incompatible sets of alternatives as vectors and the
status of the execution.
</p>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen-satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>
<p>Meyer, P. and Olteanu, A-L. Integrating large positive and negative
performance differences in majority-rule sorting models. European Journal of
Operational Research, submitted , 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(c(10,10,9), c(10,9,10), c(9,10,10), c(9,9,10), 
                          c(9,10,9), c(10,9,9), c(10,10,7), c(10,7,10), 
                          c(7,10,10), c(9,9,17), c(9,17,9), c(17,9,9), 
                          c(7,10,17), c(10,17,7), c(17,7,10), c(7,17,10), 
                          c(17,10,7), c(10,7,17), c(7,9,17), c(9,17,7), 
                          c(17,7,9), c(7,17,9), c(17,9,7), c(9,7,17), 
                          c(7,7,7))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", 
                                "a8", "a9", "a10", "a11", "a12", "a13", 
                                "a14", "a15", "a16", "a17", "a18", "a19", 
                                "a20", "a21", "a22", "a23", "a24", "a25")

colnames(performanceTable) &lt;- c("c1","c2","c3")

assignments &lt;-rbind(c("P","P","P","F","F","F","F","F","F","F","F","F",
                    "F","F","F","F","F","F","F","F","F","F","F","F","P"), 
                    c("P","P","P","F","F","F","P","P","P","P","P","P",
                    "P","P","P","P","P","P","P","P","P","P","P","P","P"), 
                    c("P","P","P","F","F","F","F","F","F","F","F","F",
                    "P","P","P","P","P","P","F","F","F","F","F","F","P"), 
                    c("P","P","P","F","F","F","P","P","P","P","P","P",
                    "P","P","P","P","P","P","F","F","F","F","F","F","P"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "F","F","F","F","F","F","F","F","F","F","F","F","P"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "P","P","P","P","P","P","P","P","P","P","P","P","P"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "P","P","P","P","P","P","F","F","F","F","F","F","P"))

colnames(assignments) &lt;- rownames(performanceTable)

categoriesRanks &lt;-c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

majorityRules &lt;- c("V","D","v","d","dV","Dv","dv")

for(i in 1:1)# change to 7 in order to perform all tests
{
  incompatibleAssignmentsSets&lt;-LPDMRSortIdentifyIncompatibleAssignments(
                                 performanceTable, assignments[i,], 
                                 categoriesRanks, criteriaMinMax,
                                 majorityRule = majorityRules[i])
  
  filteredAlternativesIDs &lt;- setdiff(rownames(performanceTable),
                                     incompatibleAssignmentsSets[[1]][1])
  
  x&lt;-LPDMRSortInferenceExact(performanceTable, assignments[i,], 
                             categoriesRanks, criteriaMinMax, 
                             majorityRule = majorityRules[i], 
                             readableWeights = TRUE, 
                             readableProfiles = TRUE, 
                             minmaxLPD =  TRUE, 
                             alternativesIDs = filteredAlternativesIDs)
  
  ElectreAssignments&lt;-LPDMRSort(performanceTable, x$profilesPerformances, 
                                categoriesRanks,
                                x$weights, criteriaMinMax, x$lambda, 
                                criteriaVetos=x$vetoPerformances,
                                criteriaDictators=x$dictatorPerformances, 
                                majorityRule = majorityRules[i],
                                alternativesIDs = filteredAlternativesIDs)
  
  print(all(ElectreAssignments == assignments[i,filteredAlternativesIDs]))
}

</code></pre>

<hr>
<h2 id='LPDMRSortIdentifyUsedDictatorProfiles'>Identify dictator profiles evaluations that have an impact on the final
assignments of MRSort with large performance differences</h2><span id='topic+LPDMRSortIdentifyUsedDictatorProfiles'></span>

<h3>Description</h3>

<p>MRSort is a simplified ELECTRE-TRI approach which assigns alternatives to a
set of ordered categories using delimiting profiles evaluations. In this
case, we also take into account large performance differences. This method
is used to identify which dictator profiles evaluations have an impact on
the final assignment of at least one of the input alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPDMRSortIdentifyUsedDictatorProfiles(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  majorityThreshold,
  criteriaWeights,
  profilesPerformances,
  dictatorPerformances,
  vetoPerformances = NULL,
  majorityRule = "D",
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_assignments">assignments</code></td>
<td>
<p>A vector containing the category to which each
alternative is assigned. The vector needs to be named using the alternatives
IDs.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_majoritythreshold">majorityThreshold</code></td>
<td>
<p>The majority threshold needed to determine when a
coalition of criteria is sufficient in order to validate an outranking
relation.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_profilesperformances">profilesPerformances</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories. The columns are named according to the criteria,
and the rows are named according to the categories. The index of the row in
the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_dictatorperformances">dictatorPerformances</code></td>
<td>
<p>Matrix containing in each row a vector defining
the dictator values for the lower profile of the category. NA values mean
that no dictator is defined.  A dictator threshold for criterion i and
category k represents the performance above which an alternative outranks
the lower profile of category k regardless of the size of the coalition of
criteria in favor of this statement.  The rows are named according to the
categories, whereas the columns are named according to the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_vetoperformances">vetoPerformances</code></td>
<td>
<p>Matrix containing in each row a vector defining the
veto values for the lower profile of the category. NA values mean that no
veto is defined.  A veto threshold for criterion i and category k represents
the performance below which an alternative is forbidden to outrank the lower
profile of category k, and thus is forbidden to be assigned to the category
k.  The rows are named according to the categories, whereas the columns are
named according to the criteria. By default no veto profiles are needed.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_majorityrule">majorityRule</code></td>
<td>
<p>String denoting how the vetoes and dictators are
combined in order to form the assignment rule.  The values to choose from
are &quot;D&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;.  &quot;D&quot; considers only the dictators, &quot;v&quot;
is like &quot;V&quot; only that a dictator may invalidate a veto, &quot;d&quot; is like &quot;D&quot; only
that a veto may invalidate a dictator, &quot;dV&quot; is like &quot;V&quot; only that if there
is no veto we may then consider the dictator, &quot;Dv&quot; is like &quot;D&quot; only that
when there is no dictator we may consider the vetoes, while finally &quot;dv&quot; is
identical to using both dictator and vetoes only that when both are active
they invalidate each other, so the majority rule is considered in that case.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedDictatorProfiles_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a matrix containing TRUE/FALSE inficators for
each evaluation of the veto profiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(
  c(1,27,1),
  c(6,20,1),
  c(2,20,0),
  c(6,40,0),
  c(30,10,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# lower profiles of the categories (best category in the first position of the list)

categoriesLowerProfiles &lt;- rbind(c(3, 11, 3),c(7, 25, 2),c(NA,NA,NA))

colnames(categoriesLowerProfiles) &lt;- colnames(performanceTable)

rownames(categoriesLowerProfiles)&lt;-c("Good","Medium","Bad")

# the order of the categories, 1 being the best

categoriesRanks &lt;-c(1,2,3)

names(categoriesRanks) &lt;- c("Good","Medium","Bad")

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# dictators

criteriaDictators &lt;- rbind(c(1, 1, -1),c(1, 20, 0),c(NA,NA,NA))

colnames(criteriaDictators) &lt;- colnames(performanceTable)
rownames(criteriaDictators) &lt;- c("Good","Medium","Bad")

# vetos

criteriaVetos &lt;- rbind(c(9, 50, 5),c(50, 50, 5),c(NA,NA,NA))

colnames(criteriaVetos) &lt;- colnames(performanceTable)
rownames(criteriaVetos) &lt;- c("Good","Medium","Bad")

# weights

criteriaWeights &lt;- c(1/6,3/6,2/6)

names(criteriaWeights) &lt;- colnames(performanceTable)

# assignments

assignments &lt;- c("Good","Medium","Bad","Bad","Bad")


# LPDMRSortIndetifyUsedVetoProfiles

used&lt;-LPDMRSortIdentifyUsedDictatorProfiles(performanceTable, assignments,
                                        categoriesRanks, criteriaMinMax,
                                        0.5, criteriaWeights,
                                        categoriesLowerProfiles,
                                        criteriaDictators,
                                        criteriaVetos,
                                        "dv")

</code></pre>

<hr>
<h2 id='LPDMRSortIdentifyUsedVetoProfiles'>Identify veto profiles evaluations that have an impact on the final
assignments of MRSort with large performance differences</h2><span id='topic+LPDMRSortIdentifyUsedVetoProfiles'></span>

<h3>Description</h3>

<p>MRSort is a simplified ELECTRE-TRI approach which assigns alternatives to a
set of ordered categories using delimiting profiles evaluations. In this
case, we also take into account large performance differences. This method
is used to identify which veto profiles evaluations have an impact on the
final assignment of at least one of the input alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPDMRSortIdentifyUsedVetoProfiles(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  majorityThreshold,
  criteriaWeights,
  profilesPerformances,
  vetoPerformances,
  dictatorPerformances = NULL,
  majorityRule = "V",
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_assignments">assignments</code></td>
<td>
<p>A vector containing the category to which each
alternative is assigned. The vector needs to be named using the alternatives
IDs.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_majoritythreshold">majorityThreshold</code></td>
<td>
<p>The majority threshold needed to determine when a
coalition of criteria is sufficient in order to validate an outranking
relation.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_profilesperformances">profilesPerformances</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories. The columns are named according to the criteria,
and the rows are named according to the categories. The index of the row in
the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_vetoperformances">vetoPerformances</code></td>
<td>
<p>Matrix containing in each row a vector defining the
veto values for the lower profile of the category. NA values mean that no
veto is defined.  A veto threshold for criterion i and category k represents
the performance below which an alternative is forbidden to outrank the lower
profile of category k, and thus is forbidden to be assigned to the category
k.  The rows are named according to the categories, whereas the columns are
named according to the criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_dictatorperformances">dictatorPerformances</code></td>
<td>
<p>Matrix containing in each row a vector defining
the dictator values for the lower profile of the category. NA values mean
that no dictator is defined.  A dictator threshold for criterion i and
category k represents the performance above which an alternative outranks
the lower profile of category k regardless of the size of the coalition of
criteria in favor of this statement.  The rows are named according to the
categories, whereas the columns are named according to the criteria. By
default no dictator profiles are needed for this method.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_majorityrule">majorityRule</code></td>
<td>
<p>String denoting how the vetoes and dictators are
combined in order to form the assignment rule.  The values to choose from
are &quot;V&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;.  &quot;V&quot; considers only the vetoes, &quot;v&quot; is
like &quot;V&quot; only that a dictator may invalidate a veto, &quot;d&quot; is like &quot;D&quot; only
that a veto may invalidate a dictator, &quot;dV&quot; is like &quot;V&quot; only that if there
is no veto we may then consider the dictator, &quot;Dv&quot; is like &quot;D&quot; only that
when there is no dictator we may consider the vetoes, while finally &quot;dv&quot; is
identical to using both dictator and vetoes only that when both are active
they invalidate each other, so the majority rule is considered in that case.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSortIdentifyUsedVetoProfiles_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a matrix containing TRUE/FALSE inficators for
each evaluation of the veto profiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(
  c(1,27,1),
  c(6,20,1),
  c(2,20,0),
  c(6,40,0),
  c(30,10,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# lower profiles of the categories (best category in the first position of the list)

categoriesLowerProfiles &lt;- rbind(c(3, 11, 3),c(7, 25, 2),c(NA,NA,NA))

colnames(categoriesLowerProfiles) &lt;- colnames(performanceTable)

rownames(categoriesLowerProfiles)&lt;-c("Good","Medium","Bad")

# the order of the categories, 1 being the best

categoriesRanks &lt;-c(1,2,3)

names(categoriesRanks) &lt;- c("Good","Medium","Bad")

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# dictators

criteriaDictators &lt;- rbind(c(1, 1, -1),c(1, 20, 0),c(NA,NA,NA))

colnames(criteriaDictators) &lt;- colnames(performanceTable)
rownames(criteriaDictators) &lt;- c("Good","Medium","Bad")

# vetos

criteriaVetos &lt;- rbind(c(9, 50, 5),c(50, 50, 5),c(NA,NA,NA))

colnames(criteriaVetos) &lt;- colnames(performanceTable)
rownames(criteriaVetos) &lt;- c("Good","Medium","Bad")

# weights

criteriaWeights &lt;- c(1/6,3/6,2/6)

names(criteriaWeights) &lt;- colnames(performanceTable)

# assignments

assignments &lt;- c("Good","Medium","Bad","Bad","Bad")


# LPDMRSortIndetifyUsedVetoProfiles

used&lt;-LPDMRSortIdentifyUsedVetoProfiles(performanceTable, assignments,
                                        categoriesRanks, criteriaMinMax,
                                        0.5, criteriaWeights,
                                        categoriesLowerProfiles,
                                        criteriaVetos,
                                        criteriaDictators,
                                        "dv")

</code></pre>

<hr>
<h2 id='LPDMRSortInferenceApprox'>Identification of profiles, weights, majority threshold, veto and dictator
thresholds for LPDMRSort using a genetic algorithm.</h2><span id='topic+LPDMRSortInferenceApprox'></span>

<h3>Description</h3>

<p>MRSort is a simplified ElectreTRI method that uses the pessimistic
assignment rule, without indifference or preference thresholds attached to
criteria. LPDMRSort considers both a binary discordance and a binary
concordance conditions including several interactions between them. The
identification of the profiles, weights, majority threshold and veto
thresholds is done by taking into account assignment examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPDMRSortInferenceApprox(
  performanceTable,
  criteriaMinMax,
  categoriesRanks,
  assignments,
  majorityRules = c("M", "V", "D", "v", "d", "dV", "Dv", "dv"),
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = 60,
  populationSize = 20,
  mutationProb = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories. The
elements are named according to the IDs of the categories.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories. The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_majorityrules">majorityRules</code></td>
<td>
<p>A vector containing the different type of majority
rules to be considered (&quot;M&quot;, &quot;V&quot;, &quot;D&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;).  &quot;M&quot;
corresponds to using only the majority rule without vetoes or dictators, &quot;V&quot;
considers only the vetoes, &quot;D&quot; only the dictators, &quot;v&quot; is like &quot;V&quot; only that
a dictator may invalidate a veto, &quot;d&quot; is like &quot;D&quot; only that a veto may
invalidate a dictator, &quot;dV&quot; is like &quot;V&quot; only that if there is no veto we may
then consider the dictator, &quot;Dv&quot; is like &quot;D&quot; only that when there is no
dictator we may consider the vetoes, while finally &quot;dv&quot; is identical to
using both dictator and vetoes only that when both are active they
invalidate each other, so the majority rule is considered in that case.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds
(default 60).</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_populationsize">populationSize</code></td>
<td>
<p>Allows to change the size of the population used by
the genetic algorithm (default 20).</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceApprox_+3A_mutationprob">mutationProb</code></td>
<td>
<p>Allows to change the mutation probability used by the
genetic algorithm (default 0.1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>majorityThreshold</code></td>
<td>
<p>The
inferred majority threshold (single numeric value).</p>
</td></tr>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The inferred criteria weights (a vector named with
the criteria IDs).</p>
</td></tr> <tr><td><code>majorityRule</code></td>
<td>
<p>A string corresponding to the
inferred majority rule (one of &quot;M&quot;, &quot;V&quot;, &quot;D&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;).</p>
</td></tr>
<tr><td><code>profilesPerformances</code></td>
<td>
<p>The inferred category limits (a matrix with the
column names given by the criteria IDs and the rownames given by the upper
categories each profile delimits).</p>
</td></tr> <tr><td><code>vetoPerformances</code></td>
<td>
<p>The inferred
vetoes (a matrix with the column names given by the criteria IDs and the
rownames given by the categories to which each profile applies).</p>
</td></tr>
<tr><td><code>dictatorPerformances</code></td>
<td>
<p>The inferred dictators (a matrix with the column
names given by the criteria IDs and the rownames given by the categories to
which each profile applies).</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The classification accuracy of
the inferred model (from 0 to 1).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen- satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>
<p>no reference yet for the algorithmic approach; one should become available
in 2018
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", "a8", "a9", "a10", "a11",
                                "a12", "a13", "a14", "a15", "a16", "a17", "a18", "a19", "a20",
                                "a21", "a22", "a23", "a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

assignments &lt;-c("P","P","P","F","F","F","F","F","F","P","P","P","P","P","P","P","P","P","F","F",
                "F","F","F","F")

names(assignments) &lt;- rownames(performanceTable)

categoriesRanks &lt;- c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

set.seed(1)

x&lt;-LPDMRSortInferenceApprox(performanceTable, criteriaMinMax, categoriesRanks, assignments,
                            majorityRules = c("dV","Dv","dv"),
                            timeLimit = 180, populationSize = 30,
                            alternativesIDs = c("a1","a2","a3","a4","a5","a6","a7"))

</code></pre>

<hr>
<h2 id='LPDMRSortInferenceExact'>Identification of profiles, weights, majority threshold and veto and
dictator thresholds for the MRSort sorting approach extended to handle large
performance differences.</h2><span id='topic+LPDMRSortInferenceExact'></span>

<h3>Description</h3>

<p>MRSort is a simplified ElectreTRI method that uses the pessimistic
assignment rule, without indifference or preference thresholds attached to
criteria.  LPDMRSort considers both a binary discordance and a binary
concordance conditions including several interactions between them.  The
identification of the profiles, weights, majority threshold and veto and
dictator thresholds are done by taking into account assignment examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPDMRSortInferenceExact(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  majorityRule = "M",
  readableWeights = FALSE,
  readableProfiles = FALSE,
  minmaxLPD = FALSE,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPDMRSortInferenceExact_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories.  The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories.  The
elements are named according to the IDs of the categories.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_majorityrule">majorityRule</code></td>
<td>
<p>String denoting how the vetoes and dictators are
combined in order to form the assignment rule.  The values to choose from
are &quot;M&quot;, &quot;V&quot;, &quot;D&quot;, &quot;v&quot;, &quot;d&quot;, &quot;dV&quot;, &quot;Dv&quot;, &quot;dv&quot;.  &quot;M&quot; corresponds to using
only the majority rule without vetoes or dictators, &quot;V&quot; considers only the
vetoes, &quot;D&quot; only the dictators, &quot;v&quot; is like &quot;V&quot; only that a dictator may
invalidate a veto, &quot;d&quot; is like &quot;D&quot; only that a veto may invalidate a
dictator, &quot;dV&quot; is like &quot;V&quot; only that if there is no veto we may then
consider the dictator, &quot;Dv&quot; is like &quot;D&quot; only that when there is no dictator
we may consider the vetoes, while finally &quot;dv&quot; is identical to using both
dictator and vetoes only that when both are active they invalidate each
other, so the majority rule is considered in that case.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_readableweights">readableWeights</code></td>
<td>
<p>Boolean parameter indicating whether the weights are
to be spaced more evenly or not.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_readableprofiles">readableProfiles</code></td>
<td>
<p>Boolean parameter indicating whether the profiles
are to be spaced more evenly or not.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_minmaxlpd">minmaxLPD</code></td>
<td>
<p>Boolean parameter indicating whether the veto thresholds
are to be minimized (or maximized if lower criteria values are preferred)
while the dictator thresholds are to be maximized (or minimized if lower
criteria values are preferred).</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="LPDMRSortInferenceExact_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list structured as follows :
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The majority threshold.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>A vector containing
the weights of the criteria.  The elements are named according to the
criteria IDs.</p>
</td></tr> <tr><td><code>profilesPerformances</code></td>
<td>
<p>A matrix containing the lower
profiles of the categories.  The columns are named according to the
criteria, whereas the rows are named according to the categories. The lower
profile of the lower category can be considered as a dummy profile.</p>
</td></tr>
<tr><td><code>vetoPerformances</code></td>
<td>
<p>A matrix containing the veto profiles of the
categories.  The columns are named according to the criteria, whereas the
rows are named according to the categories. The veto profile of the lower
category can be considered as a dummy profile.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The
solver status as given by glpk.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen- satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>
<p>Meyer, P. and Olteanu, A-L. Integrating large positive and negative
performance differences in majority-rule sorting models.  European Journal
of Operational Research, submitted, 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(c(10,10,9), c(10,9,10), c(9,10,10), c(9,9,10), 
                          c(9,10,9), c(10,9,9), c(10,10,7), c(10,7,10), 
                          c(7,10,10), c(9,9,17), c(9,17,9), c(17,9,9), 
                          c(7,10,17), c(10,17,7), c(17,7,10), c(7,17,10), 
                          c(17,10,7), c(10,7,17), c(7,9,17), c(9,17,7), 
                          c(17,7,9), c(7,17,9), c(17,9,7), c(9,7,17))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", 
                                "a8", "a9", "a10", "a11", "a12", "a13", 
                                "a14", "a15", "a16", "a17", "a18", "a19", 
                                "a20", "a21", "a22", "a23", "a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

categoriesRanks &lt;-c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

assignments &lt;-rbind(c("P","P","P","F","F","F","F","F","F","F","F","F",
                    "F","F","F","F","F","F","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","P","P","P","P","P","P",
                    "P","P","P","P","P","P","P","P","P","P","P","P"), 
                    c("P","P","P","F","F","F","F","F","F","F","F","F",
                    "P","P","P","P","P","P","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","P","P","P","P","P","P",
                    "P","P","P","P","P","P","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "F","F","F","F","F","F","F","F","F","F","F","F"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "P","P","P","P","P","P","P","P","P","P","P","P"), 
                    c("P","P","P","F","F","F","F","F","F","P","P","P",
                    "P","P","P","P","P","P","F","F","F","F","F","F"))

colnames(assignments) &lt;- rownames(performanceTable)

majorityRules &lt;- c("V","D","v","d","dV","Dv","dv")

for(i in 1:1)# change to 7 in order to perform all tests
{
  x&lt;-LPDMRSortInferenceExact(performanceTable, assignments[i,],
                             categoriesRanks, criteriaMinMax, 
                             majorityRule = majorityRules[i], 
                             readableWeights = TRUE,
                             readableProfiles = TRUE,
                             minmaxLPD = TRUE)
  
  ElectreAssignments&lt;-LPDMRSort(performanceTable, x$profilesPerformances, 
                                categoriesRanks,
                                x$weights, criteriaMinMax, x$lambda, 
                                criteriaVetos=x$vetoPerformances, 
                                criteriaDictators=x$dictatorPerformances, 
                                majorityRule = majorityRules[i])
  
  print(x)
  
  print(all(ElectreAssignments == assignments[i,]))
}

</code></pre>

<hr>
<h2 id='MARE'>Multi-Attribute Range Evaluations (MARE)</h2><span id='topic+MARE'></span>

<h3>Description</h3>

<p>MARE is a multi-criteria decision analysis method which was originally
developed by Hodgett et al. in 2014.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MARE(
  performanceTableMin,
  performanceTable,
  performanceTableMax,
  criteriaWeights,
  criteriaMinMax,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MARE_+3A_performancetablemin">performanceTableMin</code></td>
<td>
<p>Matrix or data frame containing the minimum
performance table. Each column corresponds to an alternative, and each row
to a criterion. Columns (resp. rows) must be named according to the IDs of
the alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MARE_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the most likely
performance table. Each column corresponds to an alternative, and each row
to a criterion. Columns (resp. rows) must be named according to the IDs of
the alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MARE_+3A_performancetablemax">performanceTableMax</code></td>
<td>
<p>Matrix or data frame containing the maximum
performance table. Each column corresponds to an alternative, and each row
to a criterion. Columns (resp. rows) must be named according to the IDs of
the alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MARE_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="MARE_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="MARE_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="MARE_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an element of type mare which contains the MARE
scores for each alternative.
</p>


<h3>References</h3>

<p>Richard E. Hodgett, Elaine B. Martin, Gary Montague, Mark
Talford (2014). Handling uncertain decisions in whole process design.
Production Planning &amp; Control, Volume 25, Issue 12, 1028-1038.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTableMin &lt;- t(matrix(c(78,87,79,19,8,68,74,8,90,89,74.5,9,20,81,30),
                  nrow=3,ncol=5, byrow=TRUE)) 
performanceTable &lt;- t(matrix(c(80,87,86,19,8,70,74,10,90,89,75,9,33,82,30),
                              nrow=3,ncol=5, byrow=TRUE))
performanceTableMax &lt;- t(matrix(c(81,87,95,19,8,72,74,15,90,89,75.5,9,36,84,30),
                                 nrow=3,ncol=5, byrow=TRUE))  

row.names(performanceTable) &lt;- c("Yield","Toxicity","Cost","Separation","Odour")
colnames(performanceTable) &lt;- c("Route One","Route Two","Route Three")
row.names(performanceTableMin) &lt;- row.names(performanceTable)
colnames(performanceTableMin) &lt;- colnames(performanceTable)
row.names(performanceTableMax) &lt;- row.names(performanceTable)
colnames(performanceTableMax) &lt;- colnames(performanceTable)

weights &lt;- c(0.339,0.077,0.434,0.127,0.023) 
names(weights) &lt;- row.names(performanceTable)

criteriaMinMax &lt;- c("max", "max", "max", "max", "max")
names(criteriaMinMax) &lt;- row.names(performanceTable)

overall1 &lt;- MARE(performanceTableMin, 
                   performanceTable, 
                   performanceTableMax, 
                   weights, 
                   criteriaMinMax)

overall2 &lt;- MARE(performanceTableMin, 
                    performanceTable,
                    performanceTableMax,
                    weights,
                    criteriaMinMax,
                    alternativesIDs = c("Route Two","Route Three"),
                    criteriaIDs = c("Yield","Toxicity","Cost","Separation"))

</code></pre>

<hr>
<h2 id='MRSort'>Electre TRI-like sorting method axiomatized by Bouyssou and Marchant.</h2><span id='topic+MRSort'></span>

<h3>Description</h3>

<p>This simplification of the Electre TRI method uses the pessimistic
assignment rule, without indifference or preference thresholds attached to
criteria.  Only a binary discordance condition is considered, i.e. a veto
forbids an outranking in any possible concordance situation, or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MRSort(
  performanceTable,
  categoriesLowerProfiles,
  categoriesRanks,
  criteriaWeights,
  criteriaMinMax,
  majorityThreshold,
  criteriaVetos = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  categoriesIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MRSort_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MRSort_+3A_categorieslowerprofiles">categoriesLowerProfiles</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories.  The columns are named according to the
criteria, and the rows are named according to the categories.  The index of
the row in the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_majoritythreshold">majorityThreshold</code></td>
<td>
<p>The cut threshold for the concordance condition.
Should be at least half of the sum of the weights.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_criteriavetos">criteriaVetos</code></td>
<td>
<p>Matrix containing in each row a vector defining the
veto values for the lower profile of the category. NA values mean that no
veto is defined.  A veto threshold for criterion i and category k represents
the performance below which an alternative is forbidden to outrank the lower
profile of category k, and thus is forbidden to be assigned to the category
k.  The rows are named according to the categories, whereas the columns are
named according to the criteria.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="MRSort_+3A_categoriesids">categoriesIDs</code></td>
<td>
<p>Vector containing IDs of categories, according to which
the data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the assignments of the
alternatives to the categories.
</p>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen- satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# lower profiles of the categories 
# (best category in the first position of the list)

categoriesLowerProfiles &lt;- rbind(c(3, 11, 3),c(7, 25, 2),c(NA,NA,NA))

colnames(categoriesLowerProfiles) &lt;- colnames(performanceTable)

rownames(categoriesLowerProfiles)&lt;-c("Good","Medium","Bad")

# the order of the categories, 1 being the best

categoriesRanks &lt;-c(1,2,3)

names(categoriesRanks) &lt;- c("Good","Medium","Bad")

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# vetos

criteriaVetos &lt;- rbind(c(10, NA, NA),c(NA, NA, 1),c(NA,NA,NA))

colnames(criteriaVetos) &lt;- colnames(performanceTable)
rownames(criteriaVetos) &lt;- c("Good","Medium","Bad")

# weights

criteriaWeights &lt;- c(1,3,2)

names(criteriaWeights) &lt;- colnames(performanceTable)


# MRSort

assignments&lt;-MRSort(performanceTable, categoriesLowerProfiles,
                    categoriesRanks,criteriaWeights,
                    criteriaMinMax, 3, 
                    criteriaVetos = criteriaVetos)
 
print(assignments)

# un peu de filtrage

assignments&lt;-MRSort(performanceTable, categoriesLowerProfiles, 
                    categoriesRanks, criteriaWeights,
                    criteriaMinMax, 2,
                    categoriesIDs = c("Medium","Bad"), 
                    criteriaIDs = c("Price","Time"), 
                    alternativesIDs = c("RER", "BUS"))

print(assignments)


</code></pre>

<hr>
<h2 id='MRSortIdentifyIncompatibleAssignments'>Identifies all sets of assignment examples which are incompatible with the
MRSort method.</h2><span id='topic+MRSortIdentifyIncompatibleAssignments'></span>

<h3>Description</h3>

<p>This MRSort method, which is a simplification of the Electre TRI method,
uses the pessimistic assignment rule, without indifference or preference
thresholds attached to criteria.  Only a binary discordance condition is
considered, i.e. a veto forbids an outranking in any possible concordance
situation, or not.  This function outputs for all (or a fixed number of)
sets of incompatible assignment examples ranging in size from the minimal
size and up to a given threshold.  The retrieved sets are also not contained
in each other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MRSortIdentifyIncompatibleAssignments(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  veto = FALSE,
  incompatibleSetsLimit = 100,
  largerIncompatibleSetsMargin = 0,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories.  The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories.  The
elements are named according to the IDs of the categories.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_veto">veto</code></td>
<td>
<p>Boolean parameter indicating whether veto profiles are being
used by the model or not.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_incompatiblesetslimit">incompatibleSetsLimit</code></td>
<td>
<p>Pozitive integer denoting the upper limit of
the number of sets to be retrieved.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_largerincompatiblesetsmargin">largerIncompatibleSetsMargin</code></td>
<td>
<p>Pozitive integer denoting whether sets
larger than the minimal size should be retrieved, and by what margin. For
example, if this is 0 then only sets of the minimal size will be retrieved,
if this is 1 then sets also larger by 1 element will be retrieved.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyIncompatibleAssignments_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns NULL if there is a problem, or a list
containing a list of incompatible sets of alternatives as vectors and the
status of the execution.
</p>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen- satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9), c(10,9,10), c(9,10,10), c(9,9,10), 
                          c(9,10,9), c(10,9,9), c(10,10,7), c(10,7,10), 
                          c(7,10,10), c(9,9,17), c(9,17,9), c(17,9,9), 
                          c(7,10,17), c(10,17,7), c(17,7,10), c(7,17,10), 
                          c(17,10,7), c(10,7,17), c(7,9,17), c(9,17,7), 
                          c(17,7,9), c(7,17,9), c(17,9,7), c(9,7,17))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", 
                                "a8", "a9", "a10", "a11", "a12", "a13", 
                                "a14", "a15", "a16", "a17", "a18", "a19", 
                                "a20", "a21", "a22", "a23", "a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

assignments &lt;-c("P", "P", "P", "F", "F", "F", "F", "F", "F", "P", "F", 
                "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", 
                "F", "F")

names(assignments) &lt;- rownames(performanceTable)

categoriesRanks &lt;-c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

incompatibleAssignmentsSets&lt;-MRSortIdentifyIncompatibleAssignments(
                               performanceTable, assignments, 
                               categoriesRanks, criteriaMinMax, 
                               veto = TRUE, 
                               alternativesIDs = c("a1","a2","a3","a4",
                               "a5","a6","a7","a8","a9","a10"))

print(incompatibleAssignmentsSets)

filteredAlternativesIDs &lt;- setdiff(c("a1","a2","a3","a4","a5","a6","a7","a8","a9"),
                                   incompatibleAssignmentsSets[[1]][1])

print(filteredAlternativesIDs)

x&lt;-MRSortInferenceExact(performanceTable, assignments, categoriesRanks, 
                        criteriaMinMax, veto = TRUE, 
                        readableWeights = TRUE, readableProfiles = TRUE,
                        alternativesIDs = filteredAlternativesIDs)

ElectreAssignments&lt;-MRSort(performanceTable, x$profilesPerformances,
                           categoriesRanks, x$weights,
                           criteriaMinMax, x$lambda, 
                           criteriaVetos=x$vetoPerformances,
                           alternativesIDs = filteredAlternativesIDs)

</code></pre>

<hr>
<h2 id='MRSortIdentifyUsedVetoProfiles'>Identify veto profiles evaluations that have an impact on the final
assignments of MRSort</h2><span id='topic+MRSortIdentifyUsedVetoProfiles'></span>

<h3>Description</h3>

<p>MRSort is a simplified ELECTRE-TRI approach which assigns alternatives to a
set of ordered categories using delimiting profiles evaluations. In
addition, veto profiles may also be used in order to circumvent a sufficient
majority coalition in favor of an alternative being assigned to a certain
category. This method is used to identify which veto profiles evaluations
have an impact on the final assignment of at least one of the input
alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MRSortIdentifyUsedVetoProfiles(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  majorityThreshold,
  criteriaWeights,
  profilesPerformances,
  vetoPerformances,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_assignments">assignments</code></td>
<td>
<p>A vector containing the category to which each
alternative is assigned. The vector needs to be named using the alternatives
IDs.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_majoritythreshold">majorityThreshold</code></td>
<td>
<p>The majority threshold needed to determine when a
coalition of criteria is sufficient in order to validate an outranking
relation.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_profilesperformances">profilesPerformances</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories. The columns are named according to the criteria,
and the rows are named according to the categories. The index of the row in
the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_vetoperformances">vetoPerformances</code></td>
<td>
<p>Matrix containing in each row a vector defining the
veto values for the lower profile of the category. NA values mean that no
veto is defined.  A veto threshold for criterion i and category k represents
the performance below which an alternative is forbidden to outrank the lower
profile of category k, and thus is forbidden to be assigned to the category
k.  The rows are named according to the categories, whereas the columns are
named according to the criteria.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="MRSortIdentifyUsedVetoProfiles_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a matrix containing TRUE/FALSE inficators for
each evaluation of the veto profiles.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,10,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# lower profiles of the categories (best category in the first position of the list)

categoriesLowerProfiles &lt;- rbind(c(3, 11, 3),c(7, 25, 2),c(NA,NA,NA))

colnames(categoriesLowerProfiles) &lt;- colnames(performanceTable)

rownames(categoriesLowerProfiles)&lt;-c("Good","Medium","Bad")

# the order of the categories, 1 being the best

categoriesRanks &lt;-c(1,2,3)

names(categoriesRanks) &lt;- c("Good","Medium","Bad")

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# vetos

criteriaVetos &lt;- rbind(c(9, 50, -1),c(50, 50, 0),c(NA,NA,NA))

colnames(criteriaVetos) &lt;- colnames(performanceTable)
rownames(criteriaVetos) &lt;- c("Good","Medium","Bad")

# weights

criteriaWeights &lt;- c(1/6,3/6,2/6)

names(criteriaWeights) &lt;- colnames(performanceTable)

# assignments

assignments &lt;- c("Good","Medium","Bad","Bad","Bad")

# MRSortIndetifyUsedVetoProfiles

used&lt;-MRSortIdentifyUsedVetoProfiles(performanceTable, assignments,
                                     categoriesRanks, criteriaMinMax,
                                     0.5, criteriaWeights,
                                     categoriesLowerProfiles,
                                     criteriaVetos)

</code></pre>

<hr>
<h2 id='MRSortInferenceApprox'>Identification of profiles, weights, majority threshold and veto thresholds
for MRSort using a genetic algorithm.</h2><span id='topic+MRSortInferenceApprox'></span>

<h3>Description</h3>

<p>MRSort is a simplification of the Electre TRI method that uses the
pessimistic assignment rule, without indifference or preference thresholds
attached to criteria. Only a binary discordance condition is considered,
i.e. a veto forbids an outranking in any possible concordance situation, or
not. The identification of the profiles, weights, majority threshold and
veto thresholds are done by taking into account assignment examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MRSortInferenceApprox(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  veto = FALSE,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = 60,
  populationSize = 20,
  mutationProb = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MRSortInferenceApprox_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories. The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories. The
elements are named according to the IDs of the categories.</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_veto">veto</code></td>
<td>
<p>Boolean parameter indicating whether veto profiles are to be
used or not.</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds
(default 60).</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_populationsize">populationSize</code></td>
<td>
<p>Allows to change the size of the population used by
the genetic algorithm (default 20).</p>
</td></tr>
<tr><td><code id="MRSortInferenceApprox_+3A_mutationprob">mutationProb</code></td>
<td>
<p>Allows to change the mutation probability used by the
genetic algorithm (default 0.1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>majorityThreshold</code></td>
<td>
<p>The
inferred majority threshold (single numeric value).</p>
</td></tr>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The inferred criteria weights (a vector named with
the criteria IDs).</p>
</td></tr> <tr><td><code>profilesPerformances</code></td>
<td>
<p>The inferred category limits
(a matrix with the column names given by the criteria IDs and the rownames
given by the upper categories each profile delimits).</p>
</td></tr>
<tr><td><code>vetoPerformances</code></td>
<td>
<p>The inferred vetoes (a matrix with the column names
given by the criteria IDs and the rownames given by the categories to which
each profile applies).</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The classification accuracy of the
inferred model (from 0 to 1).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen- satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>
<p>no reference yet for the algorithmic approach; one should become available
in 2018
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9), c(10,9,10), c(9,10,10), c(9,9,10), c(9,10,9), c(10,9,9),
                          c(10,10,7), c(10,7,10), c(7,10,10), c(9,9,17), c(9,17,9), c(17,9,9),
                          c(7,10,17), c(10,17,7), c(17,7,10), c(7,17,10), c(17,10,7), c(10,7,17),
                          c(7,9,17), c(9,17,7), c(17,7,9), c(7,17,9), c(17,9,7), c(9,7,17))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", "a8", "a9", "a10", "a11",
                                "a12", "a13", "a14", "a15", "a16", "a17", "a18", "a19", "a20",
                                "a21", "a22", "a23", "a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

assignments &lt;-c("P", "P", "P", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F",
                "F", "F", "F", "F", "F", "F", "F")

names(assignments) &lt;- rownames(performanceTable)

categoriesRanks &lt;- c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

set.seed(1)

x&lt;-MRSortInferenceApprox(performanceTable, assignments, categoriesRanks, 
                         criteriaMinMax, veto = TRUE,
                         alternativesIDs = c("a1","a2","a3","a4","a5","a6","a7"))


</code></pre>

<hr>
<h2 id='MRSortInferenceExact'>Identification of profiles, weights and majority threshold for the MRSort
sorting method using an exact approach.</h2><span id='topic+MRSortInferenceExact'></span>

<h3>Description</h3>

<p>The MRSort method, a simplification of the Electre TRI method, uses the
pessimistic assignment rule, without indifference or preference thresholds
attached to criteria.  Only a binary discordance condition is considered,
i.e. a veto forbids an outranking in any possible concordance situation, or
not.  The identification of the profiles, weights and majority threshold are
done by taking into account assignment examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MRSortInferenceExact(
  performanceTable,
  assignments,
  categoriesRanks,
  criteriaMinMax,
  veto = FALSE,
  readableWeights = FALSE,
  readableProfiles = FALSE,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MRSortInferenceExact_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories. The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories.  The
elements are named according to the IDs of the categories.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_veto">veto</code></td>
<td>
<p>Boolean parameter indicating whether veto profiles are being
used or not.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_readableweights">readableWeights</code></td>
<td>
<p>Boolean parameter indicating whether the weights are
to be spaced more evenly or not.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_readableprofiles">readableProfiles</code></td>
<td>
<p>Boolean parameter indicating whether the profiles
are to be spaced more evenly or not.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="MRSortInferenceExact_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list structured as follows :
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>The majority threshold.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>A vector containing
the weights of the criteria.  The elements are named according to the
criteria IDs.</p>
</td></tr> <tr><td><code>profilesPerformances</code></td>
<td>
<p>A matrix containing the lower
profiles of the categories.  The columns are named according to the
criteria, whereas the rows are named according to the categories. The lower
profile of the lower category can be considered as a dummy profile.</p>
</td></tr>
<tr><td><code>vetoPerformances</code></td>
<td>
<p>A matrix containing the veto profiles of the
categories.  The columns are named according to the criteria, whereas the
rows are named according to the categories. The veto profile of the lower
category can be considered as a dummy profile.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The
solver status as given by glpk.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bouyssou, D. and Marchant, T. An axiomatic approach to
noncompen- satory sorting methods in MCDM, II: more than two categories.
European Journal of Operational Research, 178(1): 246&ndash;276, 2007.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTable &lt;- rbind(c(10,10,9), c(10,9,10), c(9,10,10), c(9,9,10), 
                          c(9,10,9), c(10,9,9), c(10,10,7), c(10,7,10), 
                          c(7,10,10), c(9,9,17), c(9,17,9), c(17,9,9), 
                          c(7,10,17), c(10,17,7), c(17,7,10), c(7,17,10), 
                          c(17,10,7), c(10,7,17), c(7,9,17), c(9,17,7), 
                          c(17,7,9), c(7,17,9), c(17,9,7), c(9,7,17))

rownames(performanceTable) &lt;- c("a1", "a2", "a3", "a4", "a5", "a6", "a7", 
                                "a8", "a9", "a10", "a11", "a12", "a13", 
                                "a14", "a15", "a16", "a17", "a18", "a19", 
                                "a20", "a21", "a22", "a23", "a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

assignments &lt;-c("P", "P", "P", "F", "F", "F", "F", "F", "F", "F", "F", "F", 
                "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F", "F")

names(assignments) &lt;- rownames(performanceTable)

categoriesRanks &lt;-c(1,2)

names(categoriesRanks) &lt;- c("P","F")

criteriaMinMax &lt;- c("max","max","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

x&lt;-MRSortInferenceExact(performanceTable, assignments, categoriesRanks, 
                         criteriaMinMax, veto = TRUE, readableWeights = TRUE, 
                         readableProfiles = TRUE, 
                         alternativesIDs = c("a1","a2","a3","a4","a5","a6","a7"))

ElectreAssignments&lt;-MRSort(performanceTable, x$profilesPerformances, 
                           categoriesRanks,
                           x$weights, criteriaMinMax, x$lambda, 
                           criteriaVetos=x$vetoPerformances,
                           alternativesIDs = c("a1","a2","a3","a4","a5","a6","a7"))

</code></pre>

<hr>
<h2 id='MRSortInterval'>MRSort with imprecise evaluations</h2><span id='topic+MRSortInterval'></span>

<h3>Description</h3>

<p>This method is an extension of the classical MRSort, that allows the
handling of problems where the decision alternatives contain imprecise or
even missing evaluations. Unlike MRSort, where an alternative is assigned to
one category, MRSortInterval offers the possibility of assigning an
alternative to one or more neighboring categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MRSortInterval(
  performanceTable,
  categoriesLowerProfiles,
  categoriesRanks,
  criteriaWeights,
  criteriaMinMax,
  majorityThresholdPes,
  majorityThresholdOpt
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MRSortInterval_+3A_performancetable">performanceTable</code></td>
<td>
<p>Two-dimmensionnal list containing the performance
table.  Each row corresponds to an alternative, and each column to a
criterion.  Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).  This list may contain imprecise performances
of alternatives on the criteria, represented by interval evaluations, as
well as missing performances.</p>
</td></tr>
<tr><td><code id="MRSortInterval_+3A_categorieslowerprofiles">categoriesLowerProfiles</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories.  The columns are named according to the
criteria, and the rows are named according to the categories except of the
last one.</p>
</td></tr>
<tr><td><code id="MRSortInterval_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="MRSortInterval_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="MRSortInterval_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).</p>
</td></tr>
<tr><td><code id="MRSortInterval_+3A_majoritythresholdpes">majorityThresholdPes</code></td>
<td>
<p>The cut threshold for the pessimistic
concordance relation.</p>
</td></tr>
<tr><td><code id="MRSortInterval_+3A_majoritythresholdopt">majorityThresholdOpt</code></td>
<td>
<p>The cut threshold for the optimistic concordance
relation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the assignments of the
alternatives to all possibles categories.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- as.list(numeric(6*5))
dim(performanceTable)=c(6,5)
performanceTable[[1,1]]&lt;-0
performanceTable[[1,2]]&lt;-0
performanceTable[[1,3]]&lt;-0
performanceTable[[1,4]]&lt;-0
performanceTable[[1,5]]&lt;-0
performanceTable[[2,1]]&lt;-0
performanceTable[[2,2]]&lt;-0
performanceTable[[2,3]]&lt;-1
performanceTable[[2,4]]&lt;-0
performanceTable[[2,5]]&lt;-0
performanceTable[[3,1]]&lt;-0
performanceTable[[3,2]]&lt;-0
performanceTable[[3,3]]&lt;-2
performanceTable[[3,4]]&lt;-0
performanceTable[[3,5]]&lt;-0
performanceTable[[4,1]]&lt;-0
performanceTable[[4,2]]&lt;-0
performanceTable[[4,3]]&lt;-0:1
performanceTable[[4,4]]&lt;-0
performanceTable[[4,5]]&lt;-0
performanceTable[[5,1]]&lt;-0
performanceTable[[5,2]]&lt;-0
performanceTable[[5,3]]&lt;-NA
performanceTable[[5,4]]&lt;-0
performanceTable[[5,5]]&lt;-0
performanceTable[[6,1]]&lt;-0
performanceTable[[6,2]]&lt;-0
performanceTable[[6,3]]&lt;-0
performanceTable[[6,4]]&lt;-0
performanceTable[[6,5]]&lt;-NA

rownames(performanceTable)&lt;-c("a1","a2","a3","a4","a5","a6")
colnames(performanceTable)&lt;-c("c1","c2","c3","c4","c5")

# lower profiles of the categories (best category in the first position of the list)

categoriesLowerProfiles &lt;- rbind(c(1,1,1,1,1),c(0,0,0,2,2))
colnames(categoriesLowerProfiles) &lt;- colnames(performanceTable)

rownames(categoriesLowerProfiles)&lt;-c("Medium","Good")

categoriesRanks &lt;-c(1,2,3)

names(categoriesRanks) &lt;- c("Good","Medium","Bad")

# weights

criteriaWeights &lt;- c(1/5,1/5,1/5,1/5,1/5)
names(criteriaWeights) &lt;- colnames(performanceTable)

#pessimistic and optimistic majority thresholds
majorityThresholdPes=majorityThresholdOpt=3/5

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","min","max","max")
names(criteriaMinMax) &lt;- colnames(performanceTable)

#MRSortInterval

assignments&lt;-MRSortInterval(performanceTable,categoriesLowerProfiles,
                            categoriesRanks,criteriaWeights,
                            criteriaMinMax,majorityThresholdPes,
                            majorityThresholdOpt)

</code></pre>

<hr>
<h2 id='normalizePerformanceTable'>Function to normalize (or rescale) the columns (or criteria) of a
performance table.</h2><span id='topic+normalizePerformanceTable'></span>

<h3>Description</h3>

<p>Standardizes the range of the criteria according to a few methods :
percentage of max, scale between 0 and 1, scale to 0 mean and 1 standard
deviation, scale to euclidian unit length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalizePerformanceTable(
  performanceTable,
  normalizationTypes = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalizePerformanceTable_+3A_performancetable">performanceTable</code></td>
<td>
<p>A matrix containing the performance table to be
plotted. The columns are labelled according to the criteria IDs, and the
rows according to the alternatives IDs.</p>
</td></tr>
<tr><td><code id="normalizePerformanceTable_+3A_normalizationtypes">normalizationTypes</code></td>
<td>
<p>Vector indicating the type of normalization that
should be applied to each of the criteria. Possible values :
&quot;percentageOfMax&quot;, &quot;rescaling&quot; (minimum becomes 0, maximum becomes 1),
&quot;standardization&quot; (rescale to a mean of 0 and a standard deviation of 1),
&quot;scaleToUnitLength&quot; (scale the criteria values such that the column has
euclidian length 1). Any other value (like &quot;none&quot;) will result in no data
transformation. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="normalizePerformanceTable_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="normalizePerformanceTable_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MCDA)

performanceTable &lt;- matrix(runif(5*9), ncol=5)

row.names(performanceTable) &lt;- c("x1","x2","x3","x4","x5","x6","x7","x8","x9")

colnames(performanceTable) &lt;- c("g1","g2","g3","g4", "g5")

normalizationTypes &lt;- c("percentageOfMax","rescaling",
                        "standardization","scaleToUnitLength", "none")

names(normalizationTypes) &lt;- c("g1","g2","g3","g4","g5")

normalizedPerformanceTable &lt;- normalizePerformanceTable(performanceTable,
                                                        normalizationTypes)


</code></pre>

<hr>
<h2 id='pairwiseConsistencyMeasures'>Consistency Measures for Pairwise Comparison Matrices</h2><span id='topic+pairwiseConsistencyMeasures'></span>

<h3>Description</h3>

<p>This function calculates four pairwise consistency checks: Consistency Ratio
(CR) from Saaty (1980), Koczkodaj's Measure from Koczkodaj (1993) and
Congruence / Dissonance Measures from Siraj et al. (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwiseConsistencyMeasures(matrix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwiseConsistencyMeasures_+3A_matrix">matrix</code></td>
<td>
<p>A reciprocal matrix containing pairwise judgements</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list of outputs for the four pairwise
consistency checks
</p>


<h3>References</h3>

<p>Thomas Saaty (1980). The Analytic Hierarchy Process: Planning,
Priority Setting, ISBN 0-07-054371-2, McGraw-Hill.
</p>
<p>W.W. Koczkodaj (1993). A new definition of consistency of pairwise
comparisons. Mathematical and Computer Modelling. 18 (7).
</p>
<p>Sajid Siraj, Ludmil Mikhailov &amp; John A. Keane (2015). Contribution of
individual judgments toward inconsistency in pairwise comparisons. European
Journal of Operational Research. 242(2).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
examplematrix &lt;- t(matrix(c(1,0.25,4,1/6,4,1,4,0.25,0.25,0.25,1,0.2,6,4,5,1),nrow=4,ncol=4))
pairwiseConsistencyMeasures(examplematrix)

</code></pre>

<hr>
<h2 id='plotAlternativesValuesPreorder'>Function to plot a preorder of alternatives, based on some score or ranking.</h2><span id='topic+plotAlternativesValuesPreorder'></span>

<h3>Description</h3>

<p>Plots a preorder of alternatives as a graph, representing the ranking of the
alternatives, w.r.t. some scores or ranks. A decreasing order or increasing
order can be specified, w.r.t. to these scores or ranks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotAlternativesValuesPreorder(
  alternativesValues,
  decreasing = TRUE,
  alternativesIDs = NULL,
  silent = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotAlternativesValuesPreorder_+3A_alternativesvalues">alternativesValues</code></td>
<td>
<p>A vector containing some values related to
alternatives, as scores or ranks. The elements of the vector are named
according to the IDs of the alternatives.</p>
</td></tr>
<tr><td><code id="plotAlternativesValuesPreorder_+3A_decreasing">decreasing</code></td>
<td>
<p>A boolean to indicate if the alternatives are to be sorted
increasingly (FALSE) or decreasingly (TRUE) w.r.t. the alternativesValues.</p>
</td></tr>
<tr><td><code id="plotAlternativesValuesPreorder_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="plotAlternativesValuesPreorder_+3A_silent">silent</code></td>
<td>
<p>A boolean indicating if the order should be printed
to the terminal or not. Default is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector with the names of alternatives sorted (invisibly).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MCDA)

alternativesValues &lt;- c(10,1,8,3,8,3,4,4,8,5)

names(alternativesValues) &lt;- c("x10","x1","x9","x2","x8",
                                "x3","x7","x4","x6","x5")

plotAlternativesValuesPreorder(alternativesValues, 
                                decreasing=TRUE, 
                                alternativesIDs=c("x10","x3","x7",
                                                    "x4","x6","x5"))


</code></pre>

<hr>
<h2 id='plotMARE'>Plot Multi-Attribute Range Evaluations (MARE)</h2><span id='topic+plotMARE'></span>

<h3>Description</h3>

<p>Plots the output of function MARE()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMARE(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotMARE_+3A_x">x</code></td>
<td>
<p>Output from function MARE()</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTableMin &lt;- t(matrix(c(78,87,79,19,8,68,74,8,90,89,74.5,9,20,81,30),
                                  nrow=3,ncol=5, byrow=TRUE)) 
performanceTable &lt;- t(matrix(c(80,87,86,19,8,70,74,10,90,89,75,9,33,82,30),
                                nrow=3,ncol=5, byrow=TRUE))
performanceTableMax &lt;- t(matrix(c(81,87,95,19,8,72,74,15,90,89,75.5,9,36,84,30),
                                   nrow=3,ncol=5, byrow=TRUE))  

row.names(performanceTable) &lt;- c("Yield","Toxicity","Cost","Separation","Odour")
colnames(performanceTable) &lt;- c("Route One","Route Two","Route Three")
row.names(performanceTableMin) &lt;- row.names(performanceTable)
colnames(performanceTableMin) &lt;- colnames(performanceTable)
row.names(performanceTableMax) &lt;- row.names(performanceTable)
colnames(performanceTableMax) &lt;- colnames(performanceTable)

weights &lt;- c(0.339,0.077,0.434,0.127,0.023) 
names(weights) &lt;- row.names(performanceTable)

criteriaMinMax &lt;- c("max", "max", "max", "max", "max")
names(criteriaMinMax) &lt;- row.names(performanceTable)

overall1 &lt;- MARE(performanceTableMin, performanceTable, performanceTableMax, 
                           weights, criteriaMinMax)
plotMARE(overall1)

overall2 &lt;- MARE(performanceTableMin,
                    performanceTable,
                    performanceTableMax, 
                    weights,
                    criteriaMinMax, 
                    alternativesIDs = c("Route Two","Route Three"),
                    criteriaIDs = c("Yield","Toxicity","Cost","Separation"))
plotMARE(overall2)

</code></pre>

<hr>
<h2 id='plotMRSortSortingProblem'>Plot the categories and assignments of an Electre TRI-like sorting problem
(via separation profiles).</h2><span id='topic+plotMRSortSortingProblem'></span>

<h3>Description</h3>

<p>The profiles shown are the separation profiles between the classes. They are
stored as the lower profiles of the categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMRSortSortingProblem(
  performanceTable,
  categoriesLowerProfiles,
  categoriesRanks,
  assignments,
  criteriaMinMax,
  criteriaUBs,
  criteriaLBs,
  categoriesDictators = NULL,
  categoriesVetoes = NULL,
  majorityRule = NULL,
  criteriaWeights = NULL,
  majorityThreshold = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  legendRatio = 0.2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotMRSortSortingProblem_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_categorieslowerprofiles">categoriesLowerProfiles</code></td>
<td>
<p>Matrix containing, in each row, the lower
profiles of the categories (the separation profiles in fact). The columns
are named according to the criteria, and the rows are named according to the
categories. The index of the row in the matrix corresponds to the rank of
the category.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>A vector containing the ranks of the categories (1
for the best, with higher values for increasingly less preferred
categories). The vector needs to be named with the categories names, whereas
the ranks need to be a range of values from 1 to the number of categories.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_assignments">assignments</code></td>
<td>
<p>Vector containing the assignments (IDs of the categories)
of the alternatives to the categories. The elements are named according to
the alternatives.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_criteriaubs">criteriaUBs</code></td>
<td>
<p>Vector containing the upper bounds of the criteria to be
considered for the plotting. The elements are named according to the IDs of
the criteria.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_criterialbs">criteriaLBs</code></td>
<td>
<p>Vector containing the lower bounds of the criteria to be
considered for the plotting. The elements are named according to the IDs of
the criteria.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_categoriesdictators">categoriesDictators</code></td>
<td>
<p>Matrix containing, in each row, the lower
dictator profiles of the categories. The columns are named according to the
criteria, and the rows are named according to the categories. The index of
the row in the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_categoriesvetoes">categoriesVetoes</code></td>
<td>
<p>Matrix containing, in each row, the lower veto
profiles of the categories. The columns are named according to the criteria,
and the rows are named according to the categories. The index of the row in
the matrix corresponds to the rank of the category.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_majorityrule">majorityRule</code></td>
<td>
<p>A string containing one of the following values: 'V' ,
'D', 'v', 'd', 'dV', 'Dv', 'dv'. This indicates the type of majority rule
that will be used by the MRSort model. 'V' stands for MRSort with vetoes,
'D' stands for MRSort with dictators, 'v' stands for MRSort with vetoes
weakened by dictators, 'd' stands for MRSort with dictators weakened by
vetoes, 'dV' stands for MRSort with vetoes dominating dictators, 'Dv' stands
for MRSort with dictators dominating vetoes, while 'dv' stands for MRSort
with conflicting vetoes and dictators.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the criteria weights. The elements
are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_majoritythreshold">majorityThreshold</code></td>
<td>
<p>A value corresponding to the majority threshold.
Along with the criteria weights, this value is used to determine when a
coalition of criteria is sufficient in order to assert that an alternative
is at least as good as a category profile.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="plotMRSortSortingProblem_+3A_legendratio">legendRatio</code></td>
<td>
<p>The ratio between the legend and plot heights. By defaut
0.2.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# lower profiles of the categories 
# (best category in the first position of the list)

categoriesLowerProfiles &lt;- rbind(c(3, 11, 3),c(7, 25, 2),c(30,30,0))

colnames(categoriesLowerProfiles) &lt;- colnames(performanceTable)

rownames(categoriesLowerProfiles)&lt;-c("Good","Medium","Bad")

categoriesRanks &lt;-c(1,2,3)

names(categoriesRanks) &lt;- c("Good","Medium","Bad")

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# lower bounds of the criteria for the determination of value functions

criteriaLBs=c(0,5,0)

names(criteriaLBs) &lt;- colnames(performanceTable)

# upper bounds of the criteria for the determination of value functions

criteriaUBs=c(50,50,4)

names(criteriaUBs) &lt;- colnames(performanceTable)

# weights

criteriaWeights &lt;- c(1,3,2)

names(criteriaWeights) &lt;- colnames(performanceTable)

assignments &lt;- assignments&lt;-MRSort(performanceTable, 
                                   categoriesLowerProfiles, 
                                   categoriesRanks,
                                   criteriaWeights, 
                                   criteriaMinMax, 3)

names(assignments) &lt;- rownames(performanceTable)

plotMRSortSortingProblem(performanceTable, categoriesLowerProfiles, 
                         categoriesRanks, assignments, criteriaMinMax, 
                         criteriaUBs, criteriaLBs)

</code></pre>

<hr>
<h2 id='plotPiecewiseLinearValueFunctions'>Function to plot piecewise linear value functions.</h2><span id='topic+plotPiecewiseLinearValueFunctions'></span>

<h3>Description</h3>

<p>Plots piecewise linear value function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotPiecewiseLinearValueFunctions(valueFunctions, criteriaIDs = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotPiecewiseLinearValueFunctions_+3A_valuefunctions">valueFunctions</code></td>
<td>
<p>A list containing, for each criterion, the piecewise
linear value functions defined by the coordinates of the break points. Each
value function is defined by a matrix of breakpoints, where the first row
corresponds to the abscissa (row labelled &quot;x&quot;) and where the second row
corresponds to the ordinate (row labelled &quot;y&quot;).</p>
</td></tr>
<tr><td><code id="plotPiecewiseLinearValueFunctions_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>

v&lt;-list(
  Price = array(c(30, 0, 16, 0, 2, 0.0875), 
    dim=c(2,3), dimnames = list(c("x", "y"), NULL)), 
  Time = array(c(40, 0, 30, 0, 20, 0.025, 10, 0.9), 
    dim = c(2, 4), dimnames = list(c("x", "y"), NULL)), 
  Comfort = array(c(0, 0, 1, 0, 2, 0.0125, 3, 0.0125), 
    dim = c(2, 4), dimnames = list(c("x", "y"), NULL)))

# plot the value functions

plotPiecewiseLinearValueFunctions(v)

</code></pre>

<hr>
<h2 id='plotRadarPerformanceTable'>Function to plot radar plots of alternatives of a performance table.</h2><span id='topic+plotRadarPerformanceTable'></span>

<h3>Description</h3>

<p>Plots radar plots of alternatives contained in a performance table, either
in one radar plot, or on multiple radar plots. For a given alternative, the
plot shows how far above/below average (the thick black line) each of the
criteria performances values are (average taken w.r.t. to the filtered
performance table).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRadarPerformanceTable(
  performanceTable,
  criteriaMinMax = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  overlay = FALSE,
  bw = FALSE,
  lwd = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotRadarPerformanceTable_+3A_performancetable">performanceTable</code></td>
<td>
<p>A matrix containing the performance table to be
plotted. The columns are labelled according to the criteria IDs, and the
rows according to the alternatives IDs.</p>
</td></tr>
<tr><td><code id="plotRadarPerformanceTable_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector indicating whether criteria should be minimized
or maximized. If it is given, a &quot;higher&quot; value in the radar plot corresponds
to a more preferred value according to the decision maker. &quot;min&quot; (resp.
&quot;max&quot;) indicates that the criterion has to be minimized (maximized). The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="plotRadarPerformanceTable_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="plotRadarPerformanceTable_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="plotRadarPerformanceTable_+3A_overlay">overlay</code></td>
<td>
<p>Boolean value indicating if the plots should be overlayed on
one plot (TRUE), or not (FALSE)</p>
</td></tr>
<tr><td><code id="plotRadarPerformanceTable_+3A_bw">bw</code></td>
<td>
<p>Boolean value indicating if the plots should be in black/white
(TRUE) or color (FALSE)</p>
</td></tr>
<tr><td><code id="plotRadarPerformanceTable_+3A_lwd">lwd</code></td>
<td>
<p>Value indicating the line width of the plot.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
library(MCDA)

performanceTable &lt;- matrix(runif(6*9), ncol=6)

row.names(performanceTable) &lt;- c("x1","x2","x3","x4","x5","x6","x7","x8","x9")

colnames(performanceTable) &lt;- c("g1","g2","g3","g4","g5","g6")

criteriaMinMax &lt;- c("min","max","min","max","min","max")

names(criteriaMinMax) &lt;- c("g1","g2","g3","g4","g5","g6")

# plotRadarPerformanceTable(performanceTable, criteriaMinMax, overlay=TRUE)

plotRadarPerformanceTable(performanceTable, criteriaMinMax, 
                          alternativesIDs = c("x1","x2","x3","x4"), 
                          criteriaIDs = c("g1","g3","g4","g5","g6"), 
                          overlay=FALSE, bw=FALSE)

# plotRadarPerformanceTable(performanceTable, criteriaMinMax, 
#                          alternativesIDs = c("x1","x2"), 
#                          criteriaIDs = c("g1","g3","g4","g5","g6"),
#                          overlay=FALSE)


</code></pre>

<hr>
<h2 id='plotSURE'>Plot SURE kernel density plots.</h2><span id='topic+plotSURE'></span>

<h3>Description</h3>

<p>Plots the output of function SURE()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotSURE(SURE, greyScale = FALSE, separate = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotSURE_+3A_sure">SURE</code></td>
<td>
<p>Output from function SURE().</p>
</td></tr>
<tr><td><code id="plotSURE_+3A_greyscale">greyScale</code></td>
<td>
<p>TRUE/FALSE indicating if you want the plot to be in
greyscale.</p>
</td></tr>
<tr><td><code id="plotSURE_+3A_separate">separate</code></td>
<td>
<p>TRUE/FALSE indicating if you want the density plots to be
separated.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTableMin &lt;- t(matrix(c(78,87,79,19,8,68,74,8,90,89,74.5,9,20,81,30),
                  nrow=3,ncol=5, byrow=TRUE)) 
performanceTable &lt;- t(matrix(c(80,87,86,19,8,70,74,10,90,89,75,9,33,82,30),
                              nrow=3,ncol=5, byrow=TRUE))
performanceTableMax &lt;- t(matrix(c(81,87,95,19,8,72,74,15,90,89,75.5,9,36,84,30),
                                 nrow=3,ncol=5, byrow=TRUE))  

row.names(performanceTable) &lt;- c("Yield","Toxicity","Cost","Separation","Odour")
colnames(performanceTable) &lt;- c("Route One","Route Two","Route Three")
row.names(performanceTableMin) &lt;- row.names(performanceTable)
colnames(performanceTableMin) &lt;- colnames(performanceTable)
row.names(performanceTableMax) &lt;- row.names(performanceTable)
colnames(performanceTableMax) &lt;- colnames(performanceTable)

criteriaWeights &lt;- c(0.339,0.077,0.434,0.127,0.023) 
names(criteriaWeights) &lt;- row.names(performanceTable)

criteriaMinMax &lt;- c("max", "max", "max", "max", "max")
names(criteriaMinMax) &lt;- row.names(performanceTable)

test1 &lt;- SURE(performanceTableMin, 
                 performanceTable, 
                 performanceTableMax, 
                 criteriaWeights, 
                 criteriaMinMax,
                 NoOfSimulations = 101)

summary(test1)
plotSURE(test1)
plotSURE(test1, greyScale = TRUE, separate = TRUE)

</code></pre>

<hr>
<h2 id='PROMETHEEI'>PROMETHEE I</h2><span id='topic+PROMETHEEI'></span>

<h3>Description</h3>

<p>The PROMETHEE I constructs preference indices from the criteria evaluations
of alternatives and outputs three preference relations (P - preference, I -
indifference, R - incomparability) based on the outranking flows between the
alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PROMETHEEI(
  performanceTable,
  preferenceFunction,
  preferenceThreshold,
  indifferenceThreshold,
  gaussParameter,
  criteriaWeights,
  criteriaMinMax
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PROMETHEEI_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix containing the evaluation table.  Each row
corresponds to an alternative, and each column to a criterion.  Rows (resp.
columns) must be named according to the IDs of the alternatives (resp.
criteria).</p>
</td></tr>
<tr><td><code id="PROMETHEEI_+3A_preferencefunction">preferenceFunction</code></td>
<td>
<p>A vector with preference
functions.preferenceFunction should be equal to
Usual,U-shape,V-shape,Level,V-shape-Indiff or Gaussian.  The elements are
named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEI_+3A_preferencethreshold">preferenceThreshold</code></td>
<td>
<p>A vector containing threshold of strict
preference. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEI_+3A_indifferencethreshold">indifferenceThreshold</code></td>
<td>
<p>A vector containing threshold of indifference.
The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEI_+3A_gaussparameter">gaussParameter</code></td>
<td>
<p>A vector containing parameter of the Gaussian
preference function. The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEI_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEI_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns three matrices: The first one contains the
preference relations between the alternatives, the second one contains the
indifference relations between the alternatives and the third one contains
the incomparability relations between the alternatives.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The evaluation table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))
rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")
colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# The preference functions 
preferenceFunction&lt;-c("Gaussian","Level","V-shape-Indiff")

#Preference threshold
preferenceThreshold&lt;-c(5,15,3)
names(preferenceThreshold)&lt;-colnames(performanceTable)

#Indifference threshold
indifferenceThreshold&lt;-c(3,11,1)
names(indifferenceThreshold)&lt;-colnames(performanceTable)

#Parameter of the Gaussian preference function
gaussParameter&lt;-c(4,0,0)
names(gaussParameter)&lt;-colnames(performanceTable)

#weights

criteriaWeights&lt;-c(0.2,0.3,0.5)
names(criteriaWeights)&lt;-colnames(performanceTable)

# criteria to minimize or maximize

criteriaMinMax&lt;-c("min","min","max")
names(criteriaMinMax)&lt;-colnames(performanceTable)

PROMETHEEI(performanceTable, preferenceFunction,preferenceThreshold,
          indifferenceThreshold,gaussParameter,criteriaWeights,criteriaMinMax)


</code></pre>

<hr>
<h2 id='PROMETHEEII'>PROMETHEE II</h2><span id='topic+PROMETHEEII'></span>

<h3>Description</h3>

<p>The PROMETHEE II constructs preference indices from the criteria evaluations
of alternatives and outputs a pre-order based on the outranking flows
between the alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PROMETHEEII(
  performanceTable,
  preferenceFunction,
  preferenceThreshold,
  indifferenceThreshold,
  gaussParameter,
  criteriaWeights,
  criteriaMinMax
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PROMETHEEII_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix containing the evaluation table.  Each row
corresponds to an alternative, and each column to a criterion.  Rows (resp.
columns) must be named according to the IDs of the alternatives (resp.
criteria).</p>
</td></tr>
<tr><td><code id="PROMETHEEII_+3A_preferencefunction">preferenceFunction</code></td>
<td>
<p>A vector with preference
functions.preferenceFunction should be equal to Usual,U-shape,V-shape,
Level,V-shape-Indiff or Gaussian. The elements are named according to the
IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEII_+3A_preferencethreshold">preferenceThreshold</code></td>
<td>
<p>A vector containing threshold of strict
preference. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEII_+3A_indifferencethreshold">indifferenceThreshold</code></td>
<td>
<p>A vector containing threshold of indifference.
The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEII_+3A_gaussparameter">gaussParameter</code></td>
<td>
<p>A vector containing parameter of the Gaussian
preference function. The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEII_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEII_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing the alternatives IDs in
decreasing order of preference. Each elements of the list can be a vector of
alternatives IDs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The evaluation table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))
rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")
colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# The preference functions 
preferenceFunction&lt;-c("Gaussian","Level","V-shape-Indiff")

#Preference threshold
preferenceThreshold&lt;-c(5,15,3)
names(preferenceThreshold)&lt;-colnames(performanceTable)

#Indifference threshold
indifferenceThreshold&lt;-c(3,11,1)
names(indifferenceThreshold)&lt;-colnames(performanceTable)

#Parameter of the Gaussian preference function
gaussParameter&lt;-c(4,0,0)
names(gaussParameter)&lt;-colnames(performanceTable)

#weights

criteriaWeights&lt;-c(0.2,0.3,0.5)
names(criteriaWeights)&lt;-colnames(performanceTable)

# criteria to minimize or maximize

criteriaMinMax&lt;-c("min","min","max")
names(criteriaMinMax)&lt;-colnames(performanceTable)

PROMETHEEII(performanceTable, preferenceFunction,preferenceThreshold,
            indifferenceThreshold,gaussParameter,criteriaWeights,
            criteriaMinMax)


</code></pre>

<hr>
<h2 id='PROMETHEEOutrankingFlows'>Outranking flows for the PROMETHEE methods</h2><span id='topic+PROMETHEEOutrankingFlows'></span>

<h3>Description</h3>

<p>This function computes the positive and negative outranking flows for the
PROMETHEE methods. It takes as input a performance table and converts the
evaluations to preference indices based on the given function types and
parameters for each criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PROMETHEEOutrankingFlows(
  performanceTable,
  preferenceFunction,
  preferenceThreshold,
  indifferenceThreshold,
  gaussParameter,
  criteriaWeights,
  criteriaMinMax
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix containing the evaluation table.  Each row
corresponds to an alternative, and each column to a criterion.  Rows (resp.
columns) must be named according to the IDs of the alternatives (resp.
criteria).</p>
</td></tr>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_preferencefunction">preferenceFunction</code></td>
<td>
<p>A vector with preference
functions.preferenceFunction should be equal to Usual,U-shape,V-shape,
Level,V-shape-Indiff or Gaussian. The elements are named according to the
IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_preferencethreshold">preferenceThreshold</code></td>
<td>
<p>A vector containing threshold of strict
preference. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_indifferencethreshold">indifferenceThreshold</code></td>
<td>
<p>A vector containing threshold of indifference.
The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_gaussparameter">gaussParameter</code></td>
<td>
<p>A vector containing parameter of the Gaussian
preference function. The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEOutrankingFlows_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns two vectors: The first one contains the
positive outranking flows and the second one contains the negative
outranking flows.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The evaluation table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))
rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")
colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# The preference functions 
preferenceFunction&lt;-c("Gaussian","Level","V-shape-Indiff")

#Preference threshold
preferenceThreshold&lt;-c(5,15,3)
names(preferenceThreshold)&lt;-colnames(performanceTable)

#Indifference threshold
indifferenceThreshold&lt;-c(3,11,1)
names(indifferenceThreshold)&lt;-colnames(performanceTable)

#Parameter of the Gaussian preference function
gaussParameter&lt;-c(4,0,0)
names(gaussParameter)&lt;-colnames(performanceTable)

#weights

criteriaWeights&lt;-c(0.2,0.3,0.5)
names(criteriaWeights)&lt;-colnames(performanceTable)

# criteria to minimize or maximize

criteriaMinMax&lt;-c("min","min","max")
names(criteriaMinMax)&lt;-colnames(performanceTable)


# Outranking flows

outrankingFlows&lt;-PROMETHEEOutrankingFlows(performanceTable, preferenceFunction,
                                          preferenceThreshold,indifferenceThreshold,
                                          gaussParameter,criteriaWeights,
                                          criteriaMinMax)


</code></pre>

<hr>
<h2 id='PROMETHEEPreferenceIndices'>Preference indices for the PROMETHEE methods</h2><span id='topic+PROMETHEEPreferenceIndices'></span>

<h3>Description</h3>

<p>This function computes the preference indices from a performance table based
on the given function types and parameters for each criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PROMETHEEPreferenceIndices(
  performanceTable,
  preferenceFunction,
  preferenceThreshold,
  indifferenceThreshold,
  gaussParameter,
  criteriaWeights,
  criteriaMinMax
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix containing the performance table.  Each row
corresponds to an alternative, and each column to a criterion.  Rows (resp.
columns) must be named according to the IDs of the alternatives (resp.
criteria).</p>
</td></tr>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_preferencefunction">preferenceFunction</code></td>
<td>
<p>A vector containing the names of the preference
functions to be used. preferenceFunction should be equal to Usual, U-shape,
V-shape, Level, V-shape-Indiff or Gaussian. The elements of the vector are
named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_preferencethreshold">preferenceThreshold</code></td>
<td>
<p>A vector containing thresholds of strict
preference. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_indifferencethreshold">indifferenceThreshold</code></td>
<td>
<p>A vector containing thresholds of indifference.
The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_gaussparameter">gaussParameter</code></td>
<td>
<p>A vector containing parameters of the Gaussian
preference function. The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria.  The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="PROMETHEEPreferenceIndices_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a matrix containing all the aggregated
preference indices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# The evaluation table

performanceTable &lt;- rbind(
  c(1,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))
rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")
colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# The preference functions 
preferenceFunction&lt;-c("Gaussian","Level","V-shape-Indiff")

#Preference threshold
preferenceThreshold&lt;-c(5,15,3)
names(preferenceThreshold)&lt;-colnames(performanceTable)

#Indifference threshold
indifferenceThreshold&lt;-c(3,11,1)
names(indifferenceThreshold)&lt;-colnames(performanceTable)

#Parameter of the Gaussian preference function
gaussParameter&lt;-c(4,0,0)
names(gaussParameter)&lt;-colnames(performanceTable)

#weights

criteriaWeights&lt;-c(0.2,0.3,0.5)
names(criteriaWeights)&lt;-colnames(performanceTable)

# criteria to minimize or maximize

criteriaMinMax&lt;-c("min","min","max")
names(criteriaMinMax)&lt;-colnames(performanceTable)


#Preference indices

preferenceTable&lt;-PROMETHEEPreferenceIndices(performanceTable, preferenceFunction,
                                            preferenceThreshold, indifferenceThreshold,
                                            gaussParameter, criteriaWeights,
                                            criteriaMinMax)


</code></pre>

<hr>
<h2 id='SRMP'>SRMP: a simple ranking method using reference profiles</h2><span id='topic+SRMP'></span>

<h3>Description</h3>

<p>SRMP is a ranking method that uses dominating reference profiles, in a given
lexicographic ordering, in order to output a total preorder of a set of
alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMP(
  performanceTable,
  referenceProfiles,
  lexicographicOrder,
  criteriaWeights,
  criteriaMinMax,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMP_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMP_+3A_referenceprofiles">referenceProfiles</code></td>
<td>
<p>Matrix containing, in each row, the reference
profiles. The columns are named according to the criteria.</p>
</td></tr>
<tr><td><code id="SRMP_+3A_lexicographicorder">lexicographicOrder</code></td>
<td>
<p>A vector containing the indexes of the reference
profiles in a given order. This vetor needs to be of the same length as the
number of rows in referenceProfiles and it has to contain a permutation of
the indices of these rows.</p>
</td></tr>
<tr><td><code id="SRMP_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="SRMP_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMP_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMP_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the ranks of the
alternatives (the higher the better).
</p>


<h3>References</h3>

<p>A. Rolland. Procédures d’agrégation ordinale de préférences avec
points de référence pour l’aide a la décision. PhD thesis, Université Paris
VI, 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the performance table

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

referenceProfiles &lt;- rbind(c(5,5,5),c(10,10,10),c(15,15,15))

lexicographicOrder &lt;- c(2,1,3)

weights &lt;- c(0.2,0.44,0.36)

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

colnames(referenceProfiles) &lt;- c("c1","c2","c3")

names(weights) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

expectedpreorder &lt;- list('a16','a13',c('a3','a9'),'a14','a17',c('a1','a7'),'a18','a15',
                         c('a2','a8'),c('a11','a20','a22'),'a5',c('a10','a19','a24'),
                         'a4',c('a12','a21','a23'),'a6')

preorder&lt;-SRMP(performanceTable, referenceProfiles, lexicographicOrder, weights, criteriaMinMax)

</code></pre>

<hr>
<h2 id='SRMPInference'>Exact inference of an SRMP model given a maximum number of reference
profiles</h2><span id='topic+SRMPInference'></span>

<h3>Description</h3>

<p>Exact inference approach from pairwise comparisons of alternatives for the
SRMP ranking model. This method outputs an SRMP model that is as consistent
as possible with the provided pairwise comparisons (i.e. the model - the
number of profiles and their lexicographic order - that maximizes the number
of fulfilled pairwise comparisons). The method will search for a model with
the minimum possible number of profiles up to a given maximum value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInference(
  performanceTable,
  criteriaMinMax,
  maxProfilesNumber,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInference_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_maxprofilesnumber">maxProfilesNumber</code></td>
<td>
<p>A strictly pozitive numerical value which gives the
highest number of reference profiles the sought SRMP model should have.</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInference_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds
(default 60).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfilesNumber</code></td>
<td>
<p>The inferred
reference profiles number.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The inferred lexicographic order of the
profiles.</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The percentage (0 to 1) of fulfilled pair-wise
relations.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The solver status as given by glpk.</p>
</td></tr>
<tr><td><code>humanReadableStatus</code></td>
<td>
<p>A description of the solver status.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11","a5",
                            "a10","a4","a12","a13","a3","a14","a17","a1","a18","a15","a2",
                            "a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12","a12",
                              "a21","a9","a7","a8","a20","a22","a22","a19","a24","a24","a21",
                              "a23","a23"),12,2)

result&lt;-SRMPInference(performanceTable, criteriaMinMax, 3, preferencePairs, indifferencePairs,
                      alternativesIDs = c("a1","a3","a7","a9","a13","a14","a15","a16","a17",
                      "a18"))

</code></pre>

<hr>
<h2 id='SRMPInferenceApprox'>Approximative inference of an SRMP model</h2><span id='topic+SRMPInferenceApprox'></span>

<h3>Description</h3>

<p>Approximative inference approach from pairwise comparisons of alternatives
for the SRMP ranking model. This method outputs an SRMP model that fulfils
as many pairwise comparisons as possible. Neither the number of reference
profiles, nor the lexicographic order are fixed beforehand, however a
maximum value for the number of reference profiles needs to be provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceApprox(
  performanceTable,
  criteriaMinMax,
  maxProfilesNumber,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = 60,
  populationSize = 20,
  mutationProb = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceApprox_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_maxprofilesnumber">maxProfilesNumber</code></td>
<td>
<p>The maximum number of reference profiles of the
SRMP model.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds
(default 60).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_populationsize">populationSize</code></td>
<td>
<p>Allows to change the size of the population used by
the genetic algorithm (default 20).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApprox_+3A_mutationprob">mutationProb</code></td>
<td>
<p>Allows to change the mutation probability used by the
genetic algorithm (default 0.1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfilesNumber</code></td>
<td>
<p>The number of
inferred reference profiles.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred
reference profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The inferred lexicographic
order of the reference profiles.</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The percentage of fulfilled
pair-wise relations.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11",
                                "a12","a13","a14","a15","a16","a17","a18","a19","a20",
                                "a21","a22","a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# expected result for the tests below

expectedpreorder &lt;- list("a16","a13",c("a3","a9"),"a14","a17",c("a1","a7"),"a18","a15")

# test - preferences and indifferences

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11",
                            "a5","a10","a4","a12","a13","a3","a14","a17","a1","a18",
                            "a15","a2","a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12",
                              "a12","a21","a9","a7","a8","a20","a22","a22","a19","a24",
                              "a24","a21","a23","a23"),12,2)

set.seed(1)

result&lt;-SRMPInferenceApprox(performanceTable, criteriaMinMax, 3, preferencePairs,
                            indifferencePairs, alternativesIDs = c("a1","a3","a7",
                            "a9","a13","a14","a15","a16","a17","a18"))

</code></pre>

<hr>
<h2 id='SRMPInferenceApproxFixedLexicographicOrder'>Approximative inference of an SRMP model given the lexicographic order of
the profiles</h2><span id='topic+SRMPInferenceApproxFixedLexicographicOrder'></span>

<h3>Description</h3>

<p>Approximative inference approach from pairwise comparisons of alternatives
for the SRMP ranking model. This method outputs an SRMP model that fulfils
as many pairwise comparisons as possible. The number of reference profiles
and their lexicographic order is fixed beforehand.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceApproxFixedLexicographicOrder(
  performanceTable,
  criteriaMinMax,
  lexicographicOrder,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = 60,
  populationSize = 20,
  mutationProb = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_lexicographicorder">lexicographicOrder</code></td>
<td>
<p>A vector containing the indexes of the reference
profiles in a given order. The number of reference profiles to be used is
derrived implicitly from the size of this vector. The elements of this
vector need to be a permutation of the indices from 1 to its size.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds
(default 60).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_populationsize">populationSize</code></td>
<td>
<p>Allows to change the size of the population used by
the genetic algorithm (default 20).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedLexicographicOrder_+3A_mutationprob">mutationProb</code></td>
<td>
<p>Allows to change the mutation probability used by the
genetic algorithm (default 0.1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The lexicographic order of the
reference profiles, in this case the one that was originally given as
input.</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The percentage of fulfilled pair-wise relations.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

lexicographicOrder &lt;- c(1,2,3)

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11",
                                "a12","a13","a14","a15","a16","a17","a18","a19","a20",
                                "a21","a22","a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# expected result for the tests below

expectedpreorder &lt;- list("a16","a13",c("a3","a9"),"a14","a17",c("a1","a7"),"a18","a15")

# test - preferences and indifferences

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11",
                            "a5","a10","a4","a12","a13","a3","a14","a17","a1","a18",
                            "a15","a2","a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12",
                              "a12","a21","a9","a7","a8","a20","a22","a22","a19","a24",
                              "a24","a21","a23","a23"),12,2)

set.seed(1)

result&lt;-SRMPInferenceApproxFixedLexicographicOrder(performanceTable, criteriaMinMax,
                                                   lexicographicOrder, preferencePairs,
                                                   indifferencePairs, alternativesIDs =
                                                   c("a1","a3","a7","a9","a13","a14",
                                                   "a15","a16","a17","a18"))

</code></pre>

<hr>
<h2 id='SRMPInferenceApproxFixedProfilesNumber'>Approximative inference of an SRMP model given the number of reference
profiles</h2><span id='topic+SRMPInferenceApproxFixedProfilesNumber'></span>

<h3>Description</h3>

<p>Approximative inference approach from pairwise comparisons of alternatives
for the SRMP ranking model. This method outputs an SRMP model that fulfils
as many pairwise comparisons as possible. The number of reference profiles
is fixed beforehand, however the algorithm will explore any lexicographic
order between them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceApproxFixedProfilesNumber(
  performanceTable,
  criteriaMinMax,
  profilesNumber,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = 60,
  populationSize = 20,
  mutationProb = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_profilesnumber">profilesNumber</code></td>
<td>
<p>The number of reference profiles of the SRMP model.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds
(default 60).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_populationsize">populationSize</code></td>
<td>
<p>Allows to change the size of the population used by
the genetic algorithm (default 20).</p>
</td></tr>
<tr><td><code id="SRMPInferenceApproxFixedProfilesNumber_+3A_mutationprob">mutationProb</code></td>
<td>
<p>Allows to change the mutation probability used by the
genetic algorithm (default 0.1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The inferred lexicographic order of the
reference profiles.</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The percentage of fulfilled pair-wise
relations.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# the performance table

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11",
                                "a12","a13","a14","a15","a16","a17","a18","a19","a20",
                                "a21","a22","a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# expected result for the tests below

expectedpreorder &lt;- list("a16","a13",c("a3","a9"),"a14",c("a1","a7"),"a15")

# test - preferences and indifferences

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11",
                            "a5","a10","a4","a12","a13","a3","a14","a17","a1","a18",
                            "a15","a2","a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12",
                              "a12","a21","a9","a7","a8","a20","a22","a22","a19","a24",
                              "a24","a21","a23","a23"),12,2)

set.seed(1)

result&lt;-SRMPInferenceApproxFixedProfilesNumber(performanceTable, criteriaMinMax, 3,
                                               preferencePairs, indifferencePairs,
                                               alternativesIDs = c("a1","a3","a7","a9",
                                               "a13","a14","a15","a16"))


</code></pre>

<hr>
<h2 id='SRMPInferenceFixedLexicographicOrder'>Exact inference of an SRMP model given the lexicographic order of the
profiles</h2><span id='topic+SRMPInferenceFixedLexicographicOrder'></span>

<h3>Description</h3>

<p>Exact inference approach from pairwise comparisons of alternatives for the
SRMP ranking model. This method outputs an SRMP model that maximizes the
number of fulfilled pairwise comparisons. The number of reference profiles
and their lexicographic order is fixed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceFixedLexicographicOrder(
  performanceTable,
  criteriaMinMax,
  lexicographicOrder,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_lexicographicorder">lexicographicOrder</code></td>
<td>
<p>A vector containing the indexes of the reference
profiles in a given order. The number of reference profiles to be used is
derrived implicitly from the size of this vector. The elements of this
vector need to be a permutation of the indices from 1 to its size.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedLexicographicOrder_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds. By
default NULL (which corresponds to no time limit).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The percentage (0 to 1) of fulfilled pair-wise
relations.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The solver status as given by glpk.</p>
</td></tr>
<tr><td><code>humanReadableStatus</code></td>
<td>
<p>A description of the solver status.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# the performance table

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

lexicographicOrder &lt;- c(2,1,3)

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11","a5",
                            "a10","a4","a12","a13","a3","a14","a17","a1","a18","a15","a2",
                            "a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12","a12",
                              "a21","a9","a7","a8","a20","a22","a22","a19","a24","a24","a21",
                              "a23","a23"),12,2)

result&lt;-SRMPInferenceFixedLexicographicOrder(performanceTable, criteriaMinMax,
                                             lexicographicOrder, preferencePairs,
                                             indifferencePairs, alternativesIDs = 
                                             c("a1","a3","a7","a9","a13","a14","a16","a17"))

</code></pre>

<hr>
<h2 id='SRMPInferenceFixedProfilesNumber'>Exact inference of an SRMP model given the number of reference profiles</h2><span id='topic+SRMPInferenceFixedProfilesNumber'></span>

<h3>Description</h3>

<p>Exact inference approach from pairwise comparisons of alternatives for the
SRMP ranking model. This method outputs an SRMP model that is as consistent
as possible with the provided pairwise comparisons (i.e. the model - and the
lexicographic order of the reference profiles - that maximizes the number of
fulfilled pairwise comparisons). The number of reference profiles is fixed
and needs to be provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceFixedProfilesNumber(
  performanceTable,
  criteriaMinMax,
  profilesNumber,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_profilesnumber">profilesNumber</code></td>
<td>
<p>A strictly pozitive numerical value which gives the
number of reference profiles in the sought SRMP model.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceFixedProfilesNumber_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds. By
default NULL (which corresponds to no time limit).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The inferred lexicographic order of the
profiles.</p>
</td></tr> <tr><td><code>fitness</code></td>
<td>
<p>The percentage (0 to 1) of fulfilled pair-wise
relations.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The solver status as given by glpk.</p>
</td></tr>
<tr><td><code>humanReadableStatus</code></td>
<td>
<p>A description of the solver status.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11","a5",
                            "a10","a4","a12","a13","a3","a14","a17","a1","a18","a15","a2",
                            "a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12","a12",
                              "a21","a9","a7","a8","a20","a22","a22","a19","a24","a24","a21",
                              "a23","a23"),12,2)

result&lt;-SRMPInferenceFixedProfilesNumber(performanceTable, criteriaMinMax, 3, preferencePairs,
                                         indifferencePairs, alternativesIDs = c("a1","a3",
                                         "a7","a9","a13","a14","a15","a16","a17","a18"))


</code></pre>

<hr>
<h2 id='SRMPInferenceNoInconsist'>Exact inference of an SRMP model given a maximum number of reference
profiles - no inconsistencies</h2><span id='topic+SRMPInferenceNoInconsist'></span>

<h3>Description</h3>

<p>Exact inference approach from pairwise comparisons of alternatives for the
SRMP ranking model. This method only outputs a result when an SRMP model
consistent with the provided pairwise comparisons exists. The method will
search for a model with the minimum possible number of profiles up to a
given maximum value. If such a model exists, this method is significantly
faster than the one which handles inconsistencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceNoInconsist(
  performanceTable,
  criteriaMinMax,
  maxProfilesNumber,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_maxprofilesnumber">maxProfilesNumber</code></td>
<td>
<p>A strictly pozitive numerical value which gives the
highest number of reference profiles the sought SRMP model should have.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsist_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds. By
default NULL (which corresponds to no time limit).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfilesNumber</code></td>
<td>
<p>The inferred
reference profiles number.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The inferred lexicographic order of the
profiles.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The solver status as given by glpk.</p>
</td></tr>
<tr><td><code>humanReadableStatus</code></td>
<td>
<p>A description of the solver status.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11","a5",
                            "a10","a4","a12","a13","a3","a14","a17","a1","a18","a15","a2",
                            "a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12","a12",
                              "a21","a9","a7","a8","a20","a22","a22","a19","a24","a24","a21",
                              "a23","a23"),12,2)

result&lt;-SRMPInferenceNoInconsist(performanceTable, criteriaMinMax, 3, preferencePairs,
                                 indifferencePairs, alternativesIDs = c("a1","a2","a3","a4",
                                 "a5","a6","a7","a8","a10","a11","a12","a14","a16","a17","a18",
                                 "a19","a20","a21","a23","a24"))

</code></pre>

<hr>
<h2 id='SRMPInferenceNoInconsistFixedLexicographicOrder'>Exact inference of an SRMP model given the lexicographic order of the
profiles - no inconsistencies</h2><span id='topic+SRMPInferenceNoInconsistFixedLexicographicOrder'></span>

<h3>Description</h3>

<p>Exact inference approach from pairwise comparisons of alternatives for the
SRMP ranking model. This method only outputs a result when an SRMP model
consistent with the provided pairwise comparisons exists. The number of
reference profiles and their lexicographic order is fixed. If such a model
exists, this method is significantly faster than the one which handles
inconsistencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceNoInconsistFixedLexicographicOrder(
  performanceTable,
  criteriaMinMax,
  lexicographicOrder,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_lexicographicorder">lexicographicOrder</code></td>
<td>
<p>A vector containing the indexes of the reference
profiles in a given order. The number of reference profiles to be used is
derrived implicitly from the size of this vector. The elements of this
vector need to be a permutation of the indices from 1 to its size.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedLexicographicOrder_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds. By
default NULL (which corresponds to no time limit).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The solver status as given by glpk.</p>
</td></tr>
<tr><td><code>humanReadableStatus</code></td>
<td>
<p>A description of the solver status.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# the performance table

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

lexicographicOrder &lt;- c(2,1,3)

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11","a5",
                            "a10","a4","a12","a13","a3","a14","a17","a1","a18","a15","a2",
                            "a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12","a12",
                              "a21","a9","a7","a8","a20","a22","a22","a19","a24","a24","a21",
                              "a23","a23"),12,2)

result&lt;-SRMPInferenceNoInconsistFixedLexicographicOrder(performanceTable, criteriaMinMax,
                                                        lexicographicOrder, preferencePairs,
                                                        indifferencePairs, alternativesIDs =
                                                        c("a1","a2","a3","a4","a5","a6","a7",
                                                        "a8","a10","a11","a12","a14","a16",
                                                        "a17","a18","a19","a20","a21","a23",
                                                        "a24"))

</code></pre>

<hr>
<h2 id='SRMPInferenceNoInconsistFixedProfilesNumber'>Exact inference of an SRMP model given the number of reference profiles - no
inconsistencies</h2><span id='topic+SRMPInferenceNoInconsistFixedProfilesNumber'></span>

<h3>Description</h3>

<p>Exact inference approach from pairwise comparisons of alternatives for the
SRMP ranking model. This method only outputs a result when an SRMP model
consistent with the provided pairwise comparisons exists. The number of
reference profiles is fixed and need to be provided. If such a model exists,
this method is significantly faster than the one which handles
inconsistencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRMPInferenceNoInconsistFixedProfilesNumber(
  performanceTable,
  criteriaMinMax,
  profilesNumber,
  preferencePairs,
  indifferencePairs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  timeLimit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria.  &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized).  The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_profilesnumber">profilesNumber</code></td>
<td>
<p>A strictly pozitive numerical value which gives the
number of reference profiles in the sought SRMP model.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_preferencepairs">preferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair of
alternative names where the first alternative is considered to be strictly
preferred to the second.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_indifferencepairs">indifferencePairs</code></td>
<td>
<p>A two column matrix containing on each row a pair
of alternative names the two alternatives are considered to indifferent with
respect to each other.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SRMPInferenceNoInconsistFixedProfilesNumber_+3A_timelimit">timeLimit</code></td>
<td>
<p>Allows to fix a time limit of the execution, in seconds. By
default NULL (which corresponds to no time limit).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list containing: </p>
<table>
<tr><td><code>criteriaWeights</code></td>
<td>
<p>The
inferred criteria weights.</p>
</td></tr> <tr><td><code>referenceProfiles</code></td>
<td>
<p>The inferred reference
profiles.</p>
</td></tr> <tr><td><code>lexicographicOrder</code></td>
<td>
<p>The inferred lexicographic order of the
profiles.</p>
</td></tr> <tr><td><code>solverStatus</code></td>
<td>
<p>The solver status as given by glpk.</p>
</td></tr>
<tr><td><code>humanReadableStatus</code></td>
<td>
<p>A description of the solver status.</p>
</td></tr>
</table>


<h3>References</h3>

<p>A-L. OLTEANU, V. MOUSSEAU, W. OUERDANE, A. ROLLAND, Y. ZHENG,
Preference Elicitation for a Ranking Method based on Multiple Reference
Profiles, forthcoming 2018.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

performanceTable &lt;- rbind(c(10,10,9),c(10,9,10),c(9,10,10),c(9,9,10),c(9,10,9),c(10,9,9),
                          c(10,10,7),c(10,7,10),c(7,10,10),c(9,9,17),c(9,17,9),c(17,9,9),
                          c(7,10,17),c(10,17,7),c(17,7,10),c(7,17,10),c(17,10,7),c(10,7,17),
                          c(7,9,17),c(9,17,7),c(17,7,9),c(7,17,9),c(17,9,7),c(9,7,17))

criteriaMinMax &lt;- c("max","max","max")

rownames(performanceTable) &lt;- c("a1","a2","a3","a4","a5","a6","a7","a8","a9","a10","a11","a12",
                                "a13","a14","a15","a16","a17","a18","a19","a20","a21","a22",
                                "a23","a24")

colnames(performanceTable) &lt;- c("c1","c2","c3")

names(criteriaMinMax) &lt;- colnames(performanceTable)

preferencePairs &lt;- matrix(c("a16","a13","a3","a14","a17","a1","a18","a15","a2","a11","a5",
                            "a10","a4","a12","a13","a3","a14","a17","a1","a18","a15","a2",
                            "a11","a5","a10","a4","a12","a6"),14,2)
indifferencePairs &lt;- matrix(c("a3","a1","a2","a11","a11","a20","a10","a10","a19","a12","a12",
                              "a21","a9","a7","a8","a20","a22","a22","a19","a24","a24","a21",
                              "a23","a23"),12,2)

result&lt;-SRMPInferenceNoInconsistFixedProfilesNumber(performanceTable, criteriaMinMax, 3,
                                                    preferencePairs, indifferencePairs,
                                                    alternativesIDs = c("a1","a2","a3","a4",
                                                    "a5","a6","a7","a8","a10","a11","a12",
                                                    "a14","a16","a17","a18","a19","a20","a21",
                                                    "a23","a24"))

</code></pre>

<hr>
<h2 id='SURE'>Simulated Uncertainty Range Evaluations (SURE)</h2><span id='topic+SURE'></span>

<h3>Description</h3>

<p>SURE is a multi-criteria decision analysis method which was developed by
Richard Hodgett and Sajid Siraj. More details on the method are available in
https://doi.org/10.1016/j.eswa.2018.08.048
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SURE(
  performanceTableMin,
  performanceTable,
  performanceTableMax,
  criteriaWeights,
  criteriaMinMax,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  NoOfSimulations = 1e+05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SURE_+3A_performancetablemin">performanceTableMin</code></td>
<td>
<p>Matrix or data frame containing the minimum
performance table. Each column corresponds to an alternative, and each row
to a criterion. Columns (resp. rows) must be named according to the IDs of
the alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SURE_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the most likely
performance table. Each column corresponds to an alternative, and each row
to a criterion. Columns (resp. rows) must be named according to the IDs of
the alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SURE_+3A_performancetablemax">performanceTableMax</code></td>
<td>
<p>Matrix or data frame containing the maximum
performance table. Each column corresponds to an alternative, and each row
to a criterion. Columns (resp. rows) must be named according to the IDs of
the alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="SURE_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="SURE_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="SURE_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="SURE_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="SURE_+3A_noofsimulations">NoOfSimulations</code></td>
<td>
<p>Integer stating the number of Simulations to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an element of type SURE which contains the SURE
simulated scores for each alternative.
</p>


<h3>References</h3>

<p>Richard E. Hodgett, Sajid Siraj (2019). SURE: A method for
decision-making under uncertainty. Expert Systems with Applications, Volume
115, 684-694.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTableMin &lt;- t(matrix(c(78,87,79,19,8,68,74,8,90,89,74.5,9,20,81,30),
                  nrow=3,ncol=5, byrow=TRUE)) 
performanceTable &lt;- t(matrix(c(80,87,86,19,8,70,74,10,90,89,75,9,33,82,30),
                              nrow=3,ncol=5, byrow=TRUE))
performanceTableMax &lt;- t(matrix(c(81,87,95,19,8,72,74,15,90,89,75.5,9,36,84,30),
                                 nrow=3,ncol=5, byrow=TRUE))  

row.names(performanceTable) &lt;- c("Yield","Toxicity","Cost","Separation","Odour")
colnames(performanceTable) &lt;- c("Route One","Route Two","Route Three")
row.names(performanceTableMin) &lt;- row.names(performanceTable)
colnames(performanceTableMin) &lt;- colnames(performanceTable)
row.names(performanceTableMax) &lt;- row.names(performanceTable)
colnames(performanceTableMax) &lt;- colnames(performanceTable)

criteriaWeights &lt;- c(0.339,0.077,0.434,0.127,0.023) 
names(criteriaWeights) &lt;- row.names(performanceTable)

criteriaMinMax &lt;- c("max", "max", "max", "max", "max")
names(criteriaMinMax) &lt;- row.names(performanceTable)

test1 &lt;- SURE(performanceTableMin, 
                 performanceTable, 
                 performanceTableMax, 
                 criteriaWeights, 
                 criteriaMinMax, NoOfSimulations = 101)

summary(test1)
plotSURE(test1)
plotSURE(test1, greyScale = TRUE, separate = TRUE)

test2 &lt;- SURE(performanceTableMin, 
              performanceTable,
              performanceTableMax,
              criteriaWeights,
              criteriaMinMax,
              alternativesIDs = c("Route Two","Route Three"),
              criteriaIDs = c("Yield","Toxicity","Separation"),
              NoOfSimulations = 101)

summary(test2)
plotSURE(test2)
plotSURE(test2, greyScale = TRUE, separate = TRUE)

</code></pre>

<hr>
<h2 id='TOPSIS'>Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS)
method</h2><span id='topic+TOPSIS'></span>

<h3>Description</h3>

<p>TOPSIS is a multi-criteria decision analysis method which was originally
developed by Hwang and Yoon in 1981.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TOPSIS(
  performanceTable,
  criteriaWeights,
  criteriaMinMax,
  positiveIdealSolutions = NULL,
  negativeIdealSolutions = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TOPSIS_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="TOPSIS_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="TOPSIS_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="TOPSIS_+3A_positiveidealsolutions">positiveIdealSolutions</code></td>
<td>
<p>Vector containing the positive ideal solutions
for each criteria. The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="TOPSIS_+3A_negativeidealsolutions">negativeIdealSolutions</code></td>
<td>
<p>Vector containing the negative ideal solutions
for each criteria. The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="TOPSIS_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the data should be filtered.</p>
</td></tr>
<tr><td><code id="TOPSIS_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the TOPSIS score for each
alternative.
</p>


<h3>References</h3>

<p>Hwang, C.L.; Yoon, K. (1981). Multiple Attribute Decision
Making: Methods and Applications. New York: Springer-Verlag.
http://hodgett.co.uk/topsis-in-excel/
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
performanceTable &lt;- matrix(c(5490,51.4,8.5,285,6500,70.6,7,
                              288,6489,54.3,7.5,290),
                              nrow=3,
                              ncol=4,
                              byrow=TRUE)

row.names(performanceTable) &lt;- c("Corsa","Clio","Fiesta")

colnames(performanceTable) &lt;- c("Purchase Price","Economy",
                                   "Aesthetics","Boot Capacity")

weights &lt;- c(0.35,0.25,0.25,0.15)

criteriaMinMax &lt;- c("min", "max", "max", "max")

positiveIdealSolutions &lt;- c(0.179573776, 0.171636015, 0.159499658, 0.087302767)
negativeIdealSolutions &lt;- c(0.212610118, 0.124958799, 0.131352659, 0.085797547)

names(weights) &lt;- colnames(performanceTable)
names(criteriaMinMax) &lt;- colnames(performanceTable)
names(positiveIdealSolutions) &lt;- colnames(performanceTable)
names(negativeIdealSolutions) &lt;- colnames(performanceTable)

overall1 &lt;- TOPSIS(performanceTable, weights, criteriaMinMax)

overall2 &lt;- TOPSIS(performanceTable,
                       weights, 
                       criteriaMinMax,
                       positiveIdealSolutions,
                       negativeIdealSolutions)

overall3 &lt;- TOPSIS(performanceTable,
                      weights,
                      criteriaMinMax,
                      alternativesIDs = c("Corsa","Clio"),
                      criteriaIDs = c("Purchase Price","Economy","Aesthetics"))

overall4 &lt;- TOPSIS(performanceTable, 
                    weights,
                    criteriaMinMax,
                    positiveIdealSolutions,
                    negativeIdealSolutions,
                    alternativesIDs = c("Corsa","Clio"), 
                    criteriaIDs = c("Purchase Price","Economy","Aesthetics"))

</code></pre>

<hr>
<h2 id='UTA'>UTA method to elicit value functions.</h2><span id='topic+UTA'></span>

<h3>Description</h3>

<p>Elicits value functions from a ranking of alternatives, according to the UTA
method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UTA(
  performanceTable,
  criteriaMinMax,
  criteriaNumberOfBreakPoints,
  epsilon,
  alternativesRanks = NULL,
  alternativesPreferences = NULL,
  alternativesIndifferences = NULL,
  criteriaLBs = NULL,
  criteriaUBs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  kPostOptimality = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UTA_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="UTA_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="UTA_+3A_criterianumberofbreakpoints">criteriaNumberOfBreakPoints</code></td>
<td>
<p>Vector containing the number of
breakpoints of the piecewise linear value functions to be determined.
Minimum 2. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="UTA_+3A_epsilon">epsilon</code></td>
<td>
<p>Numeric value containing the minimal difference in value
between two consecutive alternatives in the final ranking.</p>
</td></tr>
<tr><td><code id="UTA_+3A_alternativesranks">alternativesRanks</code></td>
<td>
<p>Optional vector containing the ranks of the
alternatives. The elements are named according to the IDs of the
alternatives. If not present, then at least one of alternativesPreferences
or alternativesIndifferences should be given.</p>
</td></tr>
<tr><td><code id="UTA_+3A_alternativespreferences">alternativesPreferences</code></td>
<td>
<p>Optional matrix containing the preference
constraints on the alternatives. Each line of the matrix corresponds to a
constraint of the type alternative a is strictly preferred to alternative b.
If not present, then either alternativesRanks or alternativesIndifferences
should be given.</p>
</td></tr>
<tr><td><code id="UTA_+3A_alternativesindifferences">alternativesIndifferences</code></td>
<td>
<p>Optional matrix containing the indifference
constraints on the alternatives. Each line of the matrix corresponds to a
constraint of the type alternative a is indifferent to alternative b. If not
present, then either alternativesRanks or alternativesPreferences should be
given.</p>
</td></tr>
<tr><td><code id="UTA_+3A_criterialbs">criteriaLBs</code></td>
<td>
<p>Vector containing the lower bounds of the criteria to be
considered for the elicitation of the value functions. If not specified, the
lower bounds present in the performance table are taken.</p>
</td></tr>
<tr><td><code id="UTA_+3A_criteriaubs">criteriaUBs</code></td>
<td>
<p>Vector containing the upper bounds of the criteria to be
considered for the elicitation of the value functions. If not specified, the
upper bounds present in the performance table are taken.</p>
</td></tr>
<tr><td><code id="UTA_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="UTA_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="UTA_+3A_kpostoptimality">kPostOptimality</code></td>
<td>
<p>A small positive threshold used during the
postoptimality analysis (see article on UTA by Siskos and Lagreze in EJOR,
1982). If not specified, no postoptimality analysis is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list structured as follows :
</p>
<table>
<tr><td><code>optimum</code></td>
<td>
<p>The value of the objective function.</p>
</td></tr> <tr><td><code>valueFunctions</code></td>
<td>
<p>A
list containing the value functions which have been determined. Each value
function is defined by a matrix of breakpoints, where the first row
corresponds to the abscissa (row labelled &quot;x&quot;) and where the second row
corresponds to the ordinate (row labelled &quot;y&quot;).</p>
</td></tr> <tr><td><code>overallValues</code></td>
<td>
<p>A
vector of the overall values of the input alternatives.</p>
</td></tr> <tr><td><code>ranks</code></td>
<td>
<p>A
vector of the ranks of the alternatives obtained via the elicited value
functions. Ties method = &quot;min&quot;.</p>
</td></tr> <tr><td><code>Kendall</code></td>
<td>
<p>Kendall's tau between the
input ranking and the one obtained via the elicited value functions. NULL if
no input ranking is given but alternativesPreferences or
alternativesIndifferences.</p>
</td></tr> <tr><td><code>errors</code></td>
<td>
<p>A vector of the errors (sigma)
which have to be added to the overall values of the alternatives in order to
respect the input ranking.</p>
</td></tr> <tr><td><code>minimumWeightsPO</code></td>
<td>
<p>In case a
post-optimality analysis is performed, the minimal weight of each criterion,
else NULL.</p>
</td></tr> <tr><td><code>maximumWeightsPO</code></td>
<td>
<p>In case a post-optimality analysis is
performed, the maximal weight of each criterion, else NULL.</p>
</td></tr>
<tr><td><code>averageValueFunctionsPO</code></td>
<td>
<p>In case a post-optimality analysis is
performed, average value functions respecting the input ranking, else NULL.</p>
</td></tr>
</table>


<h3>References</h3>

<p>E. Jacquet-Lagreze, J. Siskos, Assessing a set of additive
utility functions for multicriteria decision-making, the UTA method,
European Journal of Operational Research, Volume 10, Issue 2, 151&ndash;164, June
1982.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the separation threshold

epsilon &lt;-0.05

# the performance table

performanceTable &lt;- rbind(
  		c(3,10,1),
			c(4,20,2),
			c(2,20,0),
			c(6,40,0),
			c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# ranks of the alternatives

alternativesRanks &lt;- c(1,2,2,3,4)

names(alternativesRanks) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# number of break points for each criterion

criteriaNumberOfBreakPoints &lt;- c(3,4,4)

names(criteriaNumberOfBreakPoints) &lt;- colnames(performanceTable)

x&lt;-UTA(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon, 
        alternativesRanks = alternativesRanks)

# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$valueFunctions)

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
  x$valueFunctions, 
  performanceTable)

# calculate the overall score of each alternative

weightedSum(transformedPerformanceTable,c(1,1,1))

# ----------------------------------------
# ranking some cars (from original article on UTA by Siskos and Lagreze, 1982)

# the separation threshold

epsilon &lt;-0.01

# the performance table

performanceTable &lt;- rbind(      
c(173, 11.4, 10.01, 10, 7.88, 49500),
c(176, 12.3, 10.48, 11, 7.96, 46700),
c(142, 8.2, 7.30, 5, 5.65, 32100),
c(148, 10.5, 9.61, 7, 6.15, 39150), 
c(178, 14.5, 11.05, 13, 8.06, 64700), 
c(180, 13.6, 10.40, 13, 8.47, 75700),
c(182, 12.7, 12.26, 11, 7.81, 68593), 
c(145, 14.3, 12.95, 11, 8.38, 55000),
c(161, 8.6, 8.42, 7, 5.11, 35200), 
c(117, 7.2, 6.75, 3, 5.81, 24800)
)

rownames(performanceTable) &lt;- c(
  "Peugeot 505 GR",
  "Opel Record 2000 LS",
  "Citroen Visa Super E",
  "VW Golf 1300 GLS",
  "Citroen CX 2400 Pallas",
  "Mercedes 230",
  "BMW 520",
  "Volvo 244 DL",
  "Peugeot 104 ZS",
  "Citroen Dyane")

colnames(performanceTable) &lt;- c(
  "MaximalSpeed",
  "ConsumptionTown",
  "Consumption120kmh",
  "HP",
  "Space",
  "Price")

# ranks of the alternatives

alternativesRanks &lt;- c(1,2,3,4,5,6,7,8,9,10)

names(alternativesRanks) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("max","min","min","max","max","min")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# number of break points for each criterion

criteriaNumberOfBreakPoints &lt;- c(5,4,4,5,4,5)

names(criteriaNumberOfBreakPoints) &lt;- colnames(performanceTable)

# lower bounds of the criteria for the determination of value functions

criteriaLBs=c(110,7,6,3,5,20000)

names(criteriaLBs) &lt;- colnames(performanceTable)

# upper bounds of the criteria for the determination of value functions

criteriaUBs=c(190,15,13,13,9,80000)

names(criteriaUBs) &lt;- colnames(performanceTable)

x&lt;-UTA(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon, 
        alternativesRanks = alternativesRanks,
        criteriaLBs = criteriaLBs, criteriaUBs = criteriaUBs)
        

# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$valueFunctions)

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
      x$valueFunctions, 
      performanceTable)

# calculate the overall score of each alternative

weights&lt;-c(1,1,1,1,1,1)

names(weights)&lt;-colnames(performanceTable)

weightedSum(transformedPerformanceTable,c(1,1,1,1,1,1))

# the same analysis with less extreme value functions 
# from the post-optimality analysis

x&lt;-UTA(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon,
        alternativesRanks = alternativesRanks,
        criteriaLBs = criteriaLBs, 
        criteriaUBs = criteriaUBs, 
        kPostOptimality = 0.01)
        
# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$averageValueFunctionsPO)

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
      x$averageValueFunctionsPO, 
      performanceTable)

# calculate the overall score of each alternative

weights&lt;-c(1,1,1,1,1,1)

names(weights)&lt;-colnames(performanceTable)

weightedSum(transformedPerformanceTable,c(1,1,1,1,1,1))


# ----------------------------------------
# Let us consider only 2 criteria : Price and MaximalSpeed. What happens ? 

# x&lt;-UTA(performanceTable, criteriaMinMax, 
#         criteriaNumberOfBreakPoints, epsilon,
#         alternativesRanks = alternativesRanks,
#         criteriaLBs = criteriaLBs, criteriaUBs = criteriaUBs,
#         criteriaIDs = c("MaximalSpeed","Price"))
        

# plot the value functions obtained

# plotPiecewiseLinearValueFunctions(x$valueFunctions, 
#                                   criteriaIDs = c("MaximalSpeed","Price"))

# apply the value functions on the original performance table

# transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
#   x$valueFunctions, 
#   performanceTable, 
#   criteriaIDs = c("MaximalSpeed","Price")
#   )

# calculate the overall score of each alternative

# weights&lt;-c(1,1,1,1,1,1)

# names(weights)&lt;-colnames(performanceTable)

# weightedSum(transformedPerformanceTable,
#          weights, criteriaIDs = c("MaximalSpeed","Price"))

# ----------------------------------------
# An example without alternativesRanks, but with alternativesPreferences
# and alternativesIndifferences

alternativesPreferences &lt;- rbind(c("Peugeot 505 GR","Opel Record 2000 LS"),
                                c("Opel Record 2000 LS","Citroen Visa Super E"))

alternativesIndifferences &lt;- rbind(c("Peugeot 104 ZS","Citroen Dyane"))

x&lt;-UTA(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon = 0.1,
        alternativesPreferences = alternativesPreferences,
        alternativesIndifferences = alternativesIndifferences,
        criteriaLBs = criteriaLBs, criteriaUBs = criteriaUBs
        )


</code></pre>

<hr>
<h2 id='UTADIS'>UTADIS method to elicit value functions in view of sorting alternatives in
ordered categories</h2><span id='topic+UTADIS'></span>

<h3>Description</h3>

<p>Elicits value functions from assignment examples, according to the UTADIS
method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UTADIS(
  performanceTable,
  criteriaMinMax,
  criteriaNumberOfBreakPoints,
  alternativesAssignments,
  categoriesRanks,
  epsilon,
  criteriaLBs = NULL,
  criteriaUBs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  categoriesIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UTADIS_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_criterianumberofbreakpoints">criteriaNumberOfBreakPoints</code></td>
<td>
<p>Vector containing the number of
breakpoints of the piecewise linear value functions to be determined.
Minimum 2. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_alternativesassignments">alternativesAssignments</code></td>
<td>
<p>Vector containing the assignments of the
alternatives to categories. Minimum 2 categories. The elements of the vector
are named according to the IDs of the alternatives.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_categoriesranks">categoriesRanks</code></td>
<td>
<p>Vector containing the ranks of the categories.
Minimum 2 categories. The elements of the vector are named according to the
IDs of the categories.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_epsilon">epsilon</code></td>
<td>
<p>Numeric value containing the minimal difference in value
between the upper bound of a category and an alternative of that category.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_criterialbs">criteriaLBs</code></td>
<td>
<p>Vector containing the lower bounds of the criteria to be
considered for the elicitation of the value functions. If not specified, the
lower bounds present in the performance table are taken.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_criteriaubs">criteriaUBs</code></td>
<td>
<p>Vector containing the upper bounds of the criteria to be
considered for the elicitation of the value functions. If not specified, the
upper bounds present in the performance table are taken.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="UTADIS_+3A_categoriesids">categoriesIDs</code></td>
<td>
<p>Vector containing IDs of categories, according to which
the data should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list structured as follows :
</p>
<table>
<tr><td><code>optimum</code></td>
<td>
<p>The value of the objective function.</p>
</td></tr> <tr><td><code>valueFunctions</code></td>
<td>
<p>A
list containing the value functions which have been determined. Each value
function is defined by a matrix of breakpoints, where the first row
corresponds to the abscissa (row labelled &quot;x&quot;) and where the second row
corresponds to the ordinate (row labelled &quot;y&quot;).</p>
</td></tr> <tr><td><code>overallValues</code></td>
<td>
<p>A
vector of the overall values of the input alternatives.</p>
</td></tr>
<tr><td><code>categoriesLBs</code></td>
<td>
<p>A vector containing the lower bounds of the considered
categories.</p>
</td></tr> <tr><td><code>errors</code></td>
<td>
<p>A list containing the errors (sigmaPlus and
sigmaMinus) which have to be substracted and added to the overall values of
the alternatives in order to respect the input ranking.</p>
</td></tr>
</table>


<h3>References</h3>

<p>J.M. Devaud, G. Groussaud, and E. Jacquet-Lagrèze, UTADIS : Une
méthode de construction de fonctions d'utilité additives rendant compte de
jugements globaux, European Working Group on Multicriteria Decision Aid,
Bochum, 1980.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the separation threshold

epsilon &lt;-0.05

# the performance table

performanceTable &lt;- rbind(
  c(3,10,1),
  c(4,20,2),
  c(2,20,0),
  c(6,40,0),
  c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# ranks of the alternatives

alternativesAssignments &lt;- c("good","medium","medium","bad","bad")

names(alternativesAssignments) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# number of break points for each criterion

criteriaNumberOfBreakPoints &lt;- c(3,4,4)

names(criteriaNumberOfBreakPoints) &lt;- colnames(performanceTable)

# ranks of the categories

categoriesRanks &lt;- c(1,2,3)

names(categoriesRanks) &lt;- c("good","medium","bad")

x&lt;-UTADIS(performanceTable, criteriaMinMax, criteriaNumberOfBreakPoints, 
           alternativesAssignments, categoriesRanks,0.1)

# filtering out category "good" and assigment examples "RER" and "TAXI" 

y&lt;-UTADIS(performanceTable, criteriaMinMax, criteriaNumberOfBreakPoints, 
           alternativesAssignments, categoriesRanks,0.1, 
           categoriesIDs=c("medium","bad"), 
           alternativesIDs=c("METRO1","METRO2","BUS"))

# working furthermore on only 2 criteria : "Comfort" and "Time"

z&lt;-UTADIS(performanceTable, criteriaMinMax, criteriaNumberOfBreakPoints, 
            alternativesAssignments, categoriesRanks,0.1, 
            criteriaIDs=c("Comfort","Time"))

</code></pre>

<hr>
<h2 id='UTASTAR'>UTASTAR method to elicit value functions.</h2><span id='topic+UTASTAR'></span>

<h3>Description</h3>

<p>Elicits value functions from a ranking of alternatives, according to the
UTASTAR method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UTASTAR(
  performanceTable,
  criteriaMinMax,
  criteriaNumberOfBreakPoints,
  epsilon,
  alternativesRanks = NULL,
  alternativesPreferences = NULL,
  alternativesIndifferences = NULL,
  criteriaLBs = NULL,
  criteriaUBs = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL,
  kPostOptimality = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UTASTAR_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Vector containing the preference direction on each of
the criteria. &quot;min&quot; (resp. &quot;max&quot;) indicates that the criterion has to be
minimized (maximized). The elements are named according to the IDs of the
criteria.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_criterianumberofbreakpoints">criteriaNumberOfBreakPoints</code></td>
<td>
<p>Vector containing the number of
breakpoints of the piecewise linear value functions to be determined.
Minimum 2. The elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_epsilon">epsilon</code></td>
<td>
<p>Numeric value containing the minimal difference in value
between two consecutive alternatives in the final ranking.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_alternativesranks">alternativesRanks</code></td>
<td>
<p>Optional vector containing the ranks of the
alternatives. The elements are named according to the IDs of the
alternatives. If not present, then at least one of alternativesPreferences
or alternativesIndifferences should be given.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_alternativespreferences">alternativesPreferences</code></td>
<td>
<p>Optional matrix containing the preference
constraints on the alternatives. Each line of the matrix corresponds to a
constraint of the type alternative a is strictly preferred to alternative b.
If not present, then either alternativesRanks or alternativesIndifferences
should be given.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_alternativesindifferences">alternativesIndifferences</code></td>
<td>
<p>Optional matrix containing the indifference
constraints on the alternatives. Each line of the matrix corresponds to a
constraint of the type alternative a is indifferent to alternative b. If not
present, then either alternativesRanks or alternativesPreferences should be
given.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_criterialbs">criteriaLBs</code></td>
<td>
<p>Vector containing the lower bounds of the criteria to be
considered for the elicitation of the value functions. If not specified, the
lower bounds present in the performance table are taken.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_criteriaubs">criteriaUBs</code></td>
<td>
<p>Vector containing the upper bounds of the criteria to be
considered for the elicitation of the value functions. If not specified, the
upper bounds present in the performance table are taken.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the datashould be filtered.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
data should be filtered.</p>
</td></tr>
<tr><td><code id="UTASTAR_+3A_kpostoptimality">kPostOptimality</code></td>
<td>
<p>A small positive threshold used during the
postoptimality analysis (see article on UTA by Siskos and Lagreze in EJOR,
1982). If not specified, no postoptimality analysis is performed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list structured as follows :
</p>
<table>
<tr><td><code>optimum</code></td>
<td>
<p>The value of the objective function.</p>
</td></tr> <tr><td><code>valueFunctions</code></td>
<td>
<p>A
list containing the value functions which have been determined. Each value
function is defined by a matrix of breakpoints, where the first row
corresponds to the abscissa (row labelled &quot;x&quot;) and where the second row
corresponds to the ordinate (row labelled &quot;y&quot;).</p>
</td></tr> <tr><td><code>overallValues</code></td>
<td>
<p>A
vector of the overall values of the input alternatives.</p>
</td></tr> <tr><td><code>ranks</code></td>
<td>
<p>A
vector of the ranks of the alternatives obtained via the elicited value
functions. Ties method = &quot;min&quot;.</p>
</td></tr> <tr><td><code>Kendall</code></td>
<td>
<p>Kendall's tau between the
input ranking and the one obtained via the elicited value functions.</p>
</td></tr>
<tr><td><code>errors</code></td>
<td>
<p>A list containing the errors (sigmaPlus and sigmaMinus) which
have to be substracted and added to the overall values of the alternatives
in order to respect the input ranking.</p>
</td></tr> <tr><td><code>minimumWeightsPO</code></td>
<td>
<p>In case a
post-optimality analysis is performed, the minimal weight of each criterion,
else NULL.</p>
</td></tr> <tr><td><code>maximumWeightsPO</code></td>
<td>
<p>In case a post-optimality analysis is
performed, the maximal weight of each criterion, else NULL.</p>
</td></tr>
<tr><td><code>averageValueFunctionsPO</code></td>
<td>
<p>In case a post-optimality analysis is
performed, average value functions respecting the input ranking, else NULL.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Siskos, Y. and D. Yannacopoulos, UTASTAR: An ordinal regression
method for building additive value functions, Investigacao Operacional , 5
(1), 39&ndash;53, 1985.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# the separation threshold

epsilon &lt;-0.05

# the performance table

performanceTable &lt;- rbind(
  		c(3,10,1),
			c(4,20,2),
			c(2,20,0),
			c(6,40,0),
			c(30,30,3))

rownames(performanceTable) &lt;- c("RER","METRO1","METRO2","BUS","TAXI")

colnames(performanceTable) &lt;- c("Price","Time","Comfort")

# ranks of the alternatives

alternativesRanks &lt;- c(1,2,2,3,4)

names(alternativesRanks) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("min","min","max")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# number of break points for each criterion

criteriaNumberOfBreakPoints &lt;- c(3,4,4)

names(criteriaNumberOfBreakPoints) &lt;- colnames(performanceTable)

x&lt;-UTASTAR(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon,
        alternativesRanks = alternativesRanks)

# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$valueFunctions)

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
  x$valueFunctions, 
  performanceTable)

# calculate the overall score of each alternative

weightedSum(transformedPerformanceTable,c(1,1,1))

# ----------------------------------------
# ranking some cars (from original article on UTA by Siskos and Lagreze, 1982)

# the separation threshold

epsilon &lt;-0.01

# the performance table

performanceTable &lt;- rbind(      
c(173, 11.4, 10.01, 10, 7.88, 49500),
c(176, 12.3, 10.48, 11, 7.96, 46700),
c(142, 8.2, 7.30, 5, 5.65, 32100),
c(148, 10.5, 9.61, 7, 6.15, 39150), 
c(178, 14.5, 11.05, 13, 8.06, 64700), 
c(180, 13.6, 10.40, 13, 8.47, 75700),
c(182, 12.7, 12.26, 11, 7.81, 68593), 
c(145, 14.3, 12.95, 11, 8.38, 55000),
c(161, 8.6, 8.42, 7, 5.11, 35200), 
c(117, 7.2, 6.75, 3, 5.81, 24800)
)

rownames(performanceTable) &lt;- c(
  "Peugeot 505 GR",
  "Opel Record 2000 LS",
  "Citroen Visa Super E",
  "VW Golf 1300 GLS",
  "Citroen CX 2400 Pallas",
  "Mercedes 230",
  "BMW 520",
  "Volvo 244 DL",
  "Peugeot 104 ZS",
  "Citroen Dyane")

colnames(performanceTable) &lt;- c(
  "MaximalSpeed",
  "ConsumptionTown",
  "Consumption120kmh",
  "HP",
  "Space",
  "Price")

# ranks of the alternatives

alternativesRanks &lt;- c(1,2,3,4,5,6,7,8,9,10)

names(alternativesRanks) &lt;- row.names(performanceTable)

# criteria to minimize or maximize

criteriaMinMax &lt;- c("max","min","min","max","max","min")

names(criteriaMinMax) &lt;- colnames(performanceTable)

# number of break points for each criterion

criteriaNumberOfBreakPoints &lt;- c(5,4,4,5,4,5)

names(criteriaNumberOfBreakPoints) &lt;- colnames(performanceTable)

# lower bounds of the criteria for the determination of value functions

criteriaLBs=c(110,7,6,3,5,20000)

names(criteriaLBs) &lt;- colnames(performanceTable)

# upper bounds of the criteria for the determination of value functions

criteriaUBs=c(190,15,13,13,9,80000)

names(criteriaUBs) &lt;- colnames(performanceTable)

x&lt;-UTASTAR(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon, 
        alternativesRanks = alternativesRanks,
        criteriaLBs = criteriaLBs, criteriaUBs = criteriaUBs)
        

# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$valueFunctions)

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
      x$valueFunctions, 
      performanceTable)

# calculate the overall score of each alternative

weights&lt;-c(1,1,1,1,1,1)

names(weights)&lt;-colnames(performanceTable)

weightedSum(transformedPerformanceTable,c(1,1,1,1,1,1))

# the same analysis with less extreme value functions
# from the post-optimality analysis

x&lt;-UTASTAR(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon, 
        alternativesRanks = alternativesRanks,
        criteriaLBs = criteriaLBs, 
        criteriaUBs = criteriaUBs, 
        kPostOptimality = 0.01)
        
# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$averageValueFunctionsPO)

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
      x$averageValueFunctionsPO, 
      performanceTable)

# calculate the overall score of each alternative

weights&lt;-c(1,1,1,1,1,1)

names(weights)&lt;-colnames(performanceTable)

weightedSum(transformedPerformanceTable,c(1,1,1,1,1,1))


# ----------------------------------------
# Let us consider only 2 criteria : Price and MaximalSpeed. What happens ? 

x&lt;-UTASTAR(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon, 
        alternativesRanks = alternativesRanks,
        criteriaLBs = criteriaLBs, criteriaUBs = criteriaUBs,
        criteriaIDs = c("MaximalSpeed","Price"))
        

# plot the value functions obtained

plotPiecewiseLinearValueFunctions(x$valueFunctions, 
                                  criteriaIDs = c("MaximalSpeed","Price"))

# apply the value functions on the original performance table

transformedPerformanceTable &lt;- applyPiecewiseLinearValueFunctionsOnPerformanceTable(
  x$valueFunctions, 
  performanceTable, 
  criteriaIDs = c("MaximalSpeed","Price")
  )

# calculate the overall score of each alternative

weights&lt;-c(1,1,1,1,1,1)

names(weights)&lt;-colnames(performanceTable)

weightedSum(transformedPerformanceTable,
          weights, criteriaIDs = c("MaximalSpeed","Price"))


# ----------------------------------------
# An example without alternativesRanks, but with alternativesPreferences
# and alternativesIndifferences

alternativesPreferences &lt;- rbind(c("Peugeot 505 GR","Opel Record 2000 LS"),
                                c("Opel Record 2000 LS","Citroen Visa Super E"))

alternativesIndifferences &lt;- rbind(c("Peugeot 104 ZS","Citroen Dyane"))

x&lt;-UTASTAR(performanceTable, criteriaMinMax, 
        criteriaNumberOfBreakPoints, epsilon = 0.1,
        alternativesPreferences = alternativesPreferences,
        alternativesIndifferences = alternativesIndifferences,
        criteriaLBs = criteriaLBs, criteriaUBs = criteriaUBs
        )


</code></pre>

<hr>
<h2 id='VIKOR'>VIKOR method</h2><span id='topic+VIKOR'></span>

<h3>Description</h3>

<p>VIKOR is a multi-criteria decision analysis method originally developed by 
Serafim Opricovic in his 1979 Ph.D. Thesis, and later published in 1998.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VIKOR(
  performanceTable,
  criteriaWeights,
  criteriaMinMax,
  v = 0.5,
  positiveIdealSolutions = NULL,
  negativeIdealSolutions = NULL,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VIKOR_+3A_performancetable">performanceTable</code></td>
<td>
<p>Information matrix with nAlt rows and nCrit columns. 
Values correspond to the level the corresponding criteria takes for the 
corresponding alternative. All values should be numeric. Rows and columns
should be named as the alternatives and criteria, respectively.</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Numeric vector with nCrit elements. Should be named.</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_criteriaminmax">criteriaMinMax</code></td>
<td>
<p>Character vector with nCrit elements. It should 
contain values &quot;min&quot; if the corresponding criteria is to be minimised (less 
is better), or &quot;max&quot; if the corresponding criteria is to be maximised (more 
is better).</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_v">v</code></td>
<td>
<p>Numeric scalar. Parameter defining the importance given to the group
utility, with respect to the minimun regret of the opponent alternative. 
Should be between 0 and 1. Default is 0.5.</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_positiveidealsolutions">positiveIdealSolutions</code></td>
<td>
<p>Numeric vector of ideal criteria values. If 
omitted, then they are defined as the best values observed among the 
existing alternatives.</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_negativeidealsolutions">negativeIdealSolutions</code></td>
<td>
<p>Numeric vector of worst possible criteria 
values. If omitted, then they are defined as the worst values observed among 
the existing alternatives.</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Character vector. Name of the alternatives to consider
in the evaluation. If omitted, all alternatives in performanceTable are used.</p>
</td></tr>
<tr><td><code id="VIKOR_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Character vector. Name of the criteria to consider 
in the evaluation. If omitted, all criteria in performanceTable are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the VIKOR score for each
alternative.
</p>


<h3>References</h3>

<p>Opricovic, S. (1998). Multicriteria optimization of civil 
engineering systems. Faculty of civil engineering, Belgrade, 2(1), 5-21.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alts &lt;- c("Corsa","Clio","Fiesta")
crit &lt;- c("price","economy", "aesthetics","bootCapacity")
performanceTable &lt;- matrix(c(5490, 51.4, 8.5, 285,
                             6500, 70.6, 7.0, 288,
                             6489, 54.3, 7.5, 290), 
                             nrow=3, ncol=4, byrow=TRUE, 
                             dimnames=list(alts, crit))
criteriaWeights &lt;- setNames(c(0.35,0.25,0.25,0.15), crit)
criteriaMinMax  &lt;- setNames(c("min", "max", "max", "max"), crit)
positiveIdealSolutions &lt;- setNames(c(4500, 80, 9, 300), crit)
negativeIdealSolutions &lt;- setNames(c(7000, 52, 7, 150), crit)

# Overall
VIKOR(performanceTable, criteriaWeights, criteriaMinMax)
# Assuming different ideal and worst solutions
VIKOR(performanceTable, criteriaWeights, criteriaMinMax,
      v=0.5, positiveIdealSolutions, negativeIdealSolutions)
# Using a subset of alternatives and criteria
VIKOR(performanceTable, criteriaWeights, criteriaMinMax,
      v=0.5, positiveIdealSolutions, negativeIdealSolutions,
      alternativesIDs = c("Clio","Fiesta"),
      criteriaIDs = c("price","economy","aesthetics"))
</code></pre>

<hr>
<h2 id='weightedSum'>Weighted sum of evaluations of alternatives.</h2><span id='topic+weightedSum'></span>

<h3>Description</h3>

<p>Computes the weighted sum of the evaluations of alternatives, stored in a
performance table, with respect to a vector of criteria weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedSum(
  performanceTable,
  criteriaWeights,
  alternativesIDs = NULL,
  criteriaIDs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weightedSum_+3A_performancetable">performanceTable</code></td>
<td>
<p>Matrix or data frame containing the performance
table. Each row corresponds to an alternative, and each column to a
criterion. Rows (resp. columns) must be named according to the IDs of the
alternatives (resp. criteria).</p>
</td></tr>
<tr><td><code id="weightedSum_+3A_criteriaweights">criteriaWeights</code></td>
<td>
<p>Vector containing the weights of the criteria. The
elements are named according to the IDs of the criteria.</p>
</td></tr>
<tr><td><code id="weightedSum_+3A_alternativesids">alternativesIDs</code></td>
<td>
<p>Vector containing IDs of alternatives, according to
which the performance table should be filtered.</p>
</td></tr>
<tr><td><code id="weightedSum_+3A_criteriaids">criteriaIDs</code></td>
<td>
<p>Vector containing IDs of criteria, according to which the
performance table should be filtered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a vector containing the weighted sum of the
alternatives with respect to the criteria weights.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alts &lt;- paste0("alt", 1:4)
crit &lt;- paste0("x", 1:3)
performanceTable &lt;- matrix(runif(length(alts)*length(crit)), 
                           nrow=length(alts), ncol=length(crit), 
                           dimnames=list(alts, crit))
weights &lt;- setNames(c(1,2,3), crit)
# Overall
weightedSum(performanceTable, weights)
# Subset of alteratives and criteria
weightedSum(performanceTable, weights, 
            alternativesIDs=c("alt2","alt3"), criteriaIDs=c("x2","x3"))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
