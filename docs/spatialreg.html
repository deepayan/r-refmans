<!DOCTYPE html><html><head><title>Help for package spatialreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {spatialreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aple'><p>Approximate profile-likelihood estimator (APLE)</p></a></li>
<li><a href='#aple.mc'><p>Approximate profile-likelihood estimator (APLE) permutation test</p></a></li>
<li><a href='#aple.plot'><p>Approximate profile-likelihood estimator (APLE) scatterplot</p></a></li>
<li><a href='#as.spam.listw'><p>Spatial neighbour sparse representation</p></a></li>
<li><a href='#do_ldet'><p>Spatial regression model Jacobian computations</p></a></li>
<li><a href='#GMerrorsar'><p>Spatial simultaneous autoregressive error model estimation by GMM</p></a></li>
<li><a href='#griffith_sone'><p>Spatial weights matrix eigenvalues</p></a></li>
<li><a href='#gstsls'><p>Spatial simultaneous autoregressive SAC model estimation by GMM</p></a></li>
<li><a href='#impacts'><p>Impacts in spatial lag models</p></a></li>
<li><a href='#invIrM'><p>Compute SAR generating operator</p></a></li>
<li><a href='#lagmess'><p>Matrix exponential spatial lag model</p></a></li>
<li><a href='#lextrB'><p>Find extreme eigenvalues of binary symmetric spatial weights</p></a></li>
<li><a href='#lmSLX'><p>Spatial Durbin linear (SLX, spatially lagged X) model</p></a></li>
<li><a href='#LR.Sarlm'><p>Likelihood ratio test</p></a></li>
<li><a href='#MCMCsamp'><p>MCMC sample from fitted spatial regression</p></a></li>
<li><a href='#ME'><p>Moran eigenvector GLM filtering</p></a></li>
<li><a href='#ML_models'><p>Spatial simultaneous autoregressive model estimation by maximum likelihood</p></a></li>
<li><a href='#predict.Sarlm'><p>Prediction for spatial simultaneous autoregressive linear</p>
model objects</a></li>
<li><a href='#set.mcOption'><p>Options for parallel support</p></a></li>
<li><a href='#set.ZeroPolicyOption'><p>Control checking of spatial object IDs</p></a></li>
<li><a href='#similar.listw'><p>Create symmetric similar weights lists</p></a></li>
<li><a href='#SpatialFiltering'><p>Semi-parametric spatial filtering</p></a></li>
<li><a href='#spautolm'><p>Spatial conditional and simultaneous autoregression model estimation</p></a></li>
<li><a href='#spBreg_lag'><p>Bayesian MCMC spatial simultaneous autoregressive model estimation</p></a></li>
<li><a href='#stsls'><p>Generalized spatial two stage least squares</p></a></li>
<li><a href='#trW'><p>Spatial weights matrix powers traces</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.3-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-06</td>
</tr>
<tr>
<td>Title:</td>
<td>Spatial Regression Analysis</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0), spData, Matrix, sf</td>
</tr>
<tr>
<td>Imports:</td>
<td>spdep (&ge; 1.3-1), coda, methods, MASS, boot, splines,
LearnBayes, nlme, multcomp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>parallel, RSpectra, tmap, foreign, spam, knitr, lmtest, expm,
sandwich, rmarkdown, igraph, tinytest</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of all the estimation functions for spatial cross-sectional models (on lattice/areal data using spatial weights matrices) contained up to now in 'spdep'. These model fitting functions include maximum likelihood methods for cross-sectional models proposed by 'Cliff' and 'Ord' (1973, ISBN:0850860369) and (1981, ISBN:0850860814), fitting methods initially described by 'Ord' (1975) &lt;<a href="https://doi.org/10.1080%2F01621459.1975.10480272">doi:10.1080/01621459.1975.10480272</a>&gt;. The models are further described by 'Anselin' (1988) &lt;<a href="https://doi.org/10.1007%2F978-94-015-7799-1">doi:10.1007/978-94-015-7799-1</a>&gt;. Spatial two stage least squares and spatial general method of moment models initially proposed by 'Kelejian' and 'Prucha' (1998) &lt;<a href="https://doi.org/10.1023%2FA%3A1007707430416">doi:10.1023/A:1007707430416</a>&gt; and (1999) &lt;<a href="https://doi.org/10.1111%2F1468-2354.00027">doi:10.1111/1468-2354.00027</a>&gt; are provided. Impact methods and MCMC fitting methods proposed by 'LeSage' and 'Pace' (2009) &lt;<a href="https://doi.org/10.1201%2F9781420064254">doi:10.1201/9781420064254</a>&gt; are implemented for the family of cross-sectional spatial regression models. Methods for fitting the log determinant term in maximum likelihood and MCMC fitting are compared by 'Bivand et al.' (2013) &lt;<a href="https://doi.org/10.1111%2Fgean.12008">doi:10.1111/gean.12008</a>&gt;, and model fitting methods by 'Bivand' and 'Piras' (2015) &lt;<a href="https://doi.org/10.18637%2Fjss.v063.i18">doi:10.18637/jss.v063.i18</a>&gt;; both of these articles include extensive lists of references. A recent review is provided by 'Bivand', 'Millo' and 'Piras' (2021) &lt;<a href="https://doi.org/10.3390%2Fmath9111276">doi:10.3390/math9111276</a>&gt;. 'spatialreg' &gt;= 1.1-* corresponded to 'spdep' &gt;= 1.1-1, in which the model fitting functions were deprecated and passed through to 'spatialreg', but masked those in 'spatialreg'. From versions 1.2-*, the functions have been made defunct in 'spdep'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/r-spatial/spatialreg/">https://github.com/r-spatial/spatialreg/</a>,
<a href="https://r-spatial.github.io/spatialreg/">https://r-spatial.github.io/spatialreg/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-spatial/spatialreg/issues/">https://github.com/r-spatial/spatialreg/issues/</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-06 11:52:52 UTC; rsb</td>
</tr>
<tr>
<td>Author:</td>
<td>Roger Bivand <a href="https://orcid.org/0000-0003-2392-6140"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Gianfranco Piras [aut],
  Luc Anselin [ctb],
  Andrew Bernat [ctb],
  Eric Blankmeyer [ctb],
  Yongwan Chun [ctb],
  Virgilio Gómez-Rubio [ctb],
  Daniel Griffith [ctb],
  Martin Gubri [ctb],
  Rein Halbersma [ctb],
  James LeSage [ctb],
  Angela Li [ctb],
  Hongfei Li [ctb],
  Jielai Ma [ctb],
  Abhirup Mallik [ctb, trl],
  Giovanni Millo [ctb],
  Kelley Pace [ctb],
  Pedro Peres-Neto [ctb],
  Tobias Rüttenauer [ctb],
  Mauricio Sarrias [ctb],
  JuanTomas Sayago [ctb],
  Michael Tiefelsdorf [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Roger Bivand &lt;Roger.Bivand@nhh.no&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-06 13:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aple'>Approximate profile-likelihood estimator (APLE)</h2><span id='topic+aple'></span>

<h3>Description</h3>

<p>The Approximate profile-likelihood estimator (APLE) of the simultaneous autoregressive model's spatial dependence parameter was introduced in Li et al. (2007). It employs a correction term using the eigenvalues of the spatial weights matrix, and consequently should not be used for large numbers of observations. It also requires that the variable has a mean of zero, and it is assumed that it has been detrended. The spatial weights object is assumed to be row-standardised, that is using default <code>style="W"</code> in <code>nb2listw</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aple(x, listw, override_similarity_check=FALSE, useTrace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aple_+3A_x">x</code></td>
<td>
<p>a zero-mean detrended continuous variable</p>
</td></tr>
<tr><td><code id="aple_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object from for example <code>spdep::nb2listw</code></p>
</td></tr>
<tr><td><code id="aple_+3A_override_similarity_check">override_similarity_check</code></td>
<td>
<p>default FALSE, if TRUE - typically for row-standardised weights with asymmetric underlying general weights - similarity is not checked</p>
</td></tr>
<tr><td><code id="aple_+3A_usetrace">useTrace</code></td>
<td>
<p>default TRUE, use trace of sparse matrix <code>W %*% W</code> (Li et al. (2010)), if FALSE, use crossproduct of eigenvalues of <code>W</code> as in Li et al. (2007)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation has been checked with Hongfei Li's own implementation using her data; her help was very valuable.
</p>


<h3>Value</h3>

<p>A scalar APLE value.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Li, H, Calder, C. A. and Cressie N. A. C. (2007) Beyond Moran's I: testing for spatial dependence based on the spatial autoregressive model. Geographical Analysis 39, 357-375; Li, H, Calder, C. A. and Cressie N. A. C. (2012) One-step estimation of spatial dependence parameters: Properties and extensions of the APLE statistic, Journal of Multivariate Analysis 105, 68-84.</p>


<h3>See Also</h3>

<p><code><a href="spdep.html#topic+nb2listw">nb2listw</a></code>, <code><a href="#topic+aple.mc">aple.mc</a></code>, <code><a href="#topic+aple.plot">aple.plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>wheat &lt;- st_read(system.file("shapes/wheat.shp", package="spData")[1], quiet=TRUE)
library(spdep)
nbr1 &lt;- spdep::poly2nb(wheat, queen=FALSE)
nbrl &lt;- spdep::nblag(nbr1, 2)
nbr12 &lt;- spdep::nblag_cumul(nbrl)
cms0 &lt;- with(as.data.frame(wheat), tapply(yield, c, median))
cms1 &lt;- c(model.matrix(~ factor(c) -1, data=wheat) %*% cms0)
wheat$yield_detrend &lt;- wheat$yield - cms1
isTRUE(all.equal(c(with(as.data.frame(wheat),
 tapply(yield_detrend, c, median))), rep(0.0, 25),
 check.attributes=FALSE))
spdep::moran.test(wheat$yield_detrend, spdep::nb2listw(nbr12, style="W"))
aple(as.vector(scale(wheat$yield_detrend, scale=FALSE)), spdep::nb2listw(nbr12, style="W"))
## Not run: 
errorsarlm(yield_detrend ~ 1, wheat, spdep::nb2listw(nbr12, style="W"))

## End(Not run)
</code></pre>

<hr>
<h2 id='aple.mc'>Approximate profile-likelihood estimator (APLE) permutation test</h2><span id='topic+aple.mc'></span>

<h3>Description</h3>

<p>A permutation bootstrap test for the approximate profile-likelihood estimator (APLE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aple.mc(x, listw, nsim, override_similarity_check=FALSE, useTrace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aple.mc_+3A_x">x</code></td>
<td>
<p>a zero-mean detrended continuous variable</p>
</td></tr>
<tr><td><code id="aple.mc_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object from for example <code>spdep::nb2listw</code></p>
</td></tr>
<tr><td><code id="aple.mc_+3A_nsim">nsim</code></td>
<td>
<p>number of simulations</p>
</td></tr>
<tr><td><code id="aple.mc_+3A_override_similarity_check">override_similarity_check</code></td>
<td>
<p>default FALSE, if TRUE - typically for row-standardised weights with asymmetric underlying general weights - similarity is not checked</p>
</td></tr>
<tr><td><code id="aple.mc_+3A_usetrace">useTrace</code></td>
<td>
<p>default TRUE, use trace of sparse matrix <code>W %*% W</code> (Li et al. (2010)), if FALSE, use crossproduct of eigenvalues of <code>W</code> as in Li et al. (2007)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>boot</code> object as returned by the <code>boot</code> function.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Li, H, Calder, C. A. and Cressie N. A. C. (2007) Beyond Moran's I: testing for spatial dependence based on the spatial autoregressive model. Geographical Analysis 39, 357-375; Li, H, Calder, C. A. and Cressie N. A. C. (2012) One-step estimation of spatial dependence parameters: Properties and extensions of the APLE statistic, Journal of Multivariate Analysis 105, 68-84.</p>


<h3>See Also</h3>

<p><code><a href="#topic+aple">aple</a></code>, <code><a href="boot.html#topic+boot">boot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
wheat &lt;- st_read(system.file("shapes/wheat.shp", package="spData")[1], quiet=TRUE)
nbr1 &lt;- spdep::poly2nb(wheat, queen=FALSE)
nbrl &lt;- spdep::nblag(nbr1, 2)
nbr12 &lt;- spdep::nblag_cumul(nbrl)
wheat_g &lt;- wheat
st_geometry(wheat_g) &lt;- NULL
cms0 &lt;- with(wheat_g, tapply(yield, c, median))
cms1 &lt;- c(model.matrix(~ factor(c) -1, data=wheat) %*% cms0)
wheat$yield_detrend &lt;- wheat$yield - cms1
oldRNG &lt;- RNGkind()
RNGkind("L'Ecuyer-CMRG")
set.seed(1L)
boot_out_ser &lt;- aple.mc(as.vector(scale(wheat$yield_detrend, scale=FALSE)),
 spdep::nb2listw(nbr12, style="W"), nsim=500)
plot(boot_out_ser)
boot_out_ser
library(parallel)
oldCores &lt;- set.coresOption(NULL)
nc &lt;- max(2L, detectCores(logical=FALSE), na.rm = TRUE)-1L
# set nc to 1L here
if (nc &gt; 1L) nc &lt;- 1L
invisible(set.coresOption(nc))
set.seed(1L)
if (!get.mcOption()) {
  cl &lt;- makeCluster(nc)
  set.ClusterOption(cl)
} else{
  mc.reset.stream()
}
boot_out_par &lt;- aple.mc(as.vector(scale(wheat$yield_detrend, scale=FALSE)),
    spdep::nb2listw(nbr12, style="W"), nsim=500)
if (!get.mcOption()) {
  set.ClusterOption(NULL)
  stopCluster(cl)
}
boot_out_par
invisible(set.coresOption(oldCores))
RNGkind(oldRNG[1], oldRNG[2])

## End(Not run)
</code></pre>

<hr>
<h2 id='aple.plot'>Approximate profile-likelihood estimator (APLE) scatterplot</h2><span id='topic+aple.plot'></span><span id='topic+localAple'></span>

<h3>Description</h3>

<p>A scatterplot decomposition of the approximate profile-likelihood estimator, and a local APLE based on the list of vectors returned by the scatterplot function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aple.plot(x, listw, override_similarity_check=FALSE, useTrace=TRUE, do.plot=TRUE, ...)
localAple(x, listw, override_similarity_check=FALSE, useTrace=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aple.plot_+3A_x">x</code></td>
<td>
<p>a zero-mean detrended continuous variable</p>
</td></tr>
<tr><td><code id="aple.plot_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object from for example <code>spdep::nb2listw</code></p>
</td></tr>
<tr><td><code id="aple.plot_+3A_override_similarity_check">override_similarity_check</code></td>
<td>
<p>default FALSE, if TRUE - typically for row-standardised weights with asymmetric underlying general weights - similarity is not checked</p>
</td></tr>
<tr><td><code id="aple.plot_+3A_usetrace">useTrace</code></td>
<td>
<p>default TRUE, use trace of sparse matrix <code>W %*% W</code> (Li et al. (2010)), if FALSE, use crossproduct of eigenvalues of <code>W</code> as in Li et al. (2007)</p>
</td></tr>
<tr><td><code id="aple.plot_+3A_do.plot">do.plot</code></td>
<td>
<p>default TRUE: should a scatterplot be drawn</p>
</td></tr>
<tr><td><code id="aple.plot_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function solves a secondary eigenproblem of size n internally, so constructing the values for the scatterplot is quite compute and memory intensive, and is not suitable for very large n.
</p>


<h3>Value</h3>

<p><code>aple.plot</code> returns list with components:
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>A vector as described in Li et al. (2007), p. 366.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>A vector as described in Li et al. (2007), p. 367.</p>
</td></tr>
</table>
<p><code>localAple</code> returns a vector of local APLE values.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Li, H, Calder, C. A. and Cressie N. A. C. (2007) Beyond Moran's I: testing for spatial dependence based on the spatial autoregressive model. Geographical Analysis 39, pp. 357-375; Li, H, Calder, C. A. and Cressie N. A. C. (2012) One-step estimation of spatial dependence parameters: Properties and extensions of the APLE statistic, Journal of Multivariate Analysis 105, 68-84.</p>


<h3>See Also</h3>

<p><code><a href="#topic+aple">aple</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
wheat &lt;- st_read(system.file("shapes/wheat.shp", package="spData")[1], quiet=TRUE)
nbr1 &lt;- spdep::poly2nb(wheat, queen=FALSE)
nbrl &lt;- spdep::nblag(nbr1, 2)
nbr12 &lt;- spdep::nblag_cumul(nbrl)
cms0 &lt;- with(as.data.frame(wheat), tapply(yield, c, median))
cms1 &lt;- c(model.matrix(~ factor(c) -1, data=wheat) %*% cms0)
wheat$yield_detrend &lt;- wheat$yield - cms1
plt_out &lt;- aple.plot(as.vector(scale(wheat$yield_detrend, scale=FALSE)),
 spdep::nb2listw(nbr12, style="W"), cex=0.6)
lm_obj &lt;- lm(Y ~ X, plt_out)
abline(lm_obj)
abline(v=0, h=0, lty=2)
zz &lt;- summary(influence.measures(lm_obj))
infl &lt;- as.integer(rownames(zz))
points(plt_out$X[infl], plt_out$Y[infl], pch=3, cex=0.6, col="red")
crossprod(plt_out$Y, plt_out$X)/crossprod(plt_out$X)
wheat$localAple &lt;- localAple(as.vector(scale(wheat$yield_detrend, scale=FALSE)),
 spdep::nb2listw(nbr12, style="W"))
mean(wheat$localAple)
hist(wheat$localAple)
opar &lt;- par(no.readonly=TRUE)
plot(wheat[,"localAple"], reset=FALSE)
text(st_coordinates(st_centroid(st_geometry(wheat)))[infl,], labels=rep("*", length(infl)))
par(opar)

## End(Not run)
</code></pre>

<hr>
<h2 id='as.spam.listw'>Spatial neighbour sparse representation</h2><span id='topic+as.spam.listw'></span><span id='topic+listw2U_spam'></span><span id='topic+as_dgRMatrix_listw'></span><span id='topic+as_dsTMatrix_listw'></span><span id='topic+as_dsCMatrix_I'></span><span id='topic+as_dsCMatrix_IrW'></span><span id='topic+listw2U_Matrix'></span><span id='topic+Jacobian_W'></span><span id='topic+coerce+2Clistw+2CCsparseMatrix-method'></span><span id='topic+coerce+2Clistw+2CRsparseMatrix-method'></span><span id='topic+coerce+2Clistw+2CsymmetricMatrix-method'></span><span id='topic+powerWeights'></span>

<h3>Description</h3>

<p>Interface between Matrix class objects and weights lists. The <code>as.spam.listw</code> method converts a <code>"listw"</code> object to a sparse matrix as defined in the <span class="pkg">spam</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.spam.listw(listw)
listw2U_spam(lw)
listw2U_Matrix(lw)
as_dgRMatrix_listw(listw)
as_dsTMatrix_listw(listw)
as_dsCMatrix_I(n)
as_dsCMatrix_IrW(W, rho)
Jacobian_W(W, rho)
powerWeights(W, rho, order=250, X, tol=.Machine$double.eps^(3/5))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.spam.listw_+3A_listw">listw</code>, <code id="as.spam.listw_+3A_lw">lw</code></td>
<td>
<p>a <code>listw</code> object from for example <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="as.spam.listw_+3A_w">W</code></td>
<td>
<p>a <code>dsTMatrix</code> object created using <code>as_dsTMatrix_listw</code> from a symmetric <code>listw</code> object</p>
</td></tr>
<tr><td><code id="as.spam.listw_+3A_rho">rho</code></td>
<td>
<p>spatial regression coefficient</p>
</td></tr>
<tr><td><code id="as.spam.listw_+3A_n">n</code></td>
<td>
<p>length of diagonal for identity matrix</p>
</td></tr>
<tr><td><code id="as.spam.listw_+3A_order">order</code></td>
<td>
<p>Power series maximum limit</p>
</td></tr>
<tr><td><code id="as.spam.listw_+3A_x">X</code></td>
<td>
<p>A numerical matrix</p>
</td></tr>
<tr><td><code id="as.spam.listw_+3A_tol">tol</code></td>
<td>
<p>Tolerance for convergence of power series</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>See Also</h3>

<p><code><a href="spdep.html#topic+nb2listw">nb2listw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(sf, quietly=TRUE)
columbus &lt;- st_read(system.file("shapes/columbus.shp", package="spData")[1], quiet=TRUE)
#require(spdep, quietly=TRUE)
col.gal.nb &lt;- spdep::read.gal(system.file("weights/columbus.gal", package="spData")[1])
col.listw &lt;- spdep::nb2listw(col.gal.nb)
if (require("spam", quietly=TRUE)) {
  col.sp &lt;- as.spam.listw(col.listw)
  str(col.sp)
}
suppressMessages(nyadjmat &lt;- as.matrix(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1])[-1]))
nyadjlw &lt;- spdep::mat2listw(nyadjmat)
listw_NY &lt;- spdep::nb2listw(nyadjlw$neighbours, style="B")
W_C &lt;- as(listw_NY, "CsparseMatrix")
W_R &lt;- as(listw_NY, "RsparseMatrix")
W_S &lt;- as(listw_NY, "symmetricMatrix")
n &lt;- nrow(W_S)
I &lt;- Diagonal(n)
rho &lt;- 0.1
c(determinant(I - rho * W_S, logarithm=TRUE)$modulus)
sum(log(1 - rho * eigenw(listw_NY)))
nW &lt;- - W_S
nChol &lt;- Cholesky(nW, Imult=8)
n * log(rho) + (2 * c(determinant(update(nChol, nW, 1/rho))$modulus))

## End(Not run)
nb7rt &lt;- spdep::cell2nb(7, 7, torus=TRUE)
x &lt;- matrix(sample(rnorm(500*length(nb7rt))), nrow=length(nb7rt))
lw &lt;- spdep::nb2listw(nb7rt)
if (FALSE) {
# Only needed in some simulation settings where the input and
# output distributions must agree in all but autocorrelation
e &lt;- eigenw(lw)
x &lt;- apply(x, 2, scale)
st &lt;- apply(x, 2, function(x) shapiro.test(x)$p.value)
x &lt;- x[, (st &gt; 0.2 &amp; st &lt; 0.8)]
x &lt;- apply(x, 2, function(v) residuals(spautolm(v ~ 1, listw=lw,
 method="eigen", control=list(pre_eig=e, fdHess=FALSE))))
x &lt;- apply(x, 2, scale)
}
W &lt;- as(lw, "CsparseMatrix")
system.time(e &lt;- invIrM(nb7rt, rho=0.98, method="solve", feasible=NULL) %*% x)
system.time(ee &lt;- powerWeights(W, rho=0.98, X=x))
str(attr(ee, "internal"))
all.equal(e, as(ee, "matrix"), check.attributes=FALSE)
## Not run: 
system.time(ee &lt;- powerWeights(W, rho=0.9, X=x))
system.time(ee &lt;- powerWeights(W, rho=0.98, order=1000, X=x))
all.equal(e, as(ee, "matrix"), check.attributes=FALSE)
nb60rt &lt;- spdep::cell2nb(60, 60, torus=TRUE)
W &lt;- as(spdep::nb2listw(nb60rt), "CsparseMatrix")
set.seed(1)
x &lt;- matrix(rnorm(dim(W)[1]), ncol=1)
system.time(ee &lt;- powerWeights(W, rho=0.3, X=x))
str(as(ee, "matrix"))
obj &lt;- errorsarlm(as(ee, "matrix")[,1] ~ 1, listw=spdep::nb2listw(nb60rt), method="Matrix")
coefficients(obj)

## End(Not run)
</code></pre>

<hr>
<h2 id='do_ldet'>Spatial regression model Jacobian computations</h2><span id='topic+do_ldet'></span><span id='topic+jacobianSetup'></span><span id='topic+eigen_setup'></span><span id='topic+eigen_pre_setup'></span><span id='topic+mcdet_setup'></span><span id='topic+cheb_setup'></span><span id='topic+spam_setup'></span><span id='topic+spam_update_setup'></span><span id='topic+Matrix_setup'></span><span id='topic+Matrix_J_setup'></span><span id='topic+LU_setup'></span><span id='topic+LU_prepermutate_setup'></span><span id='topic+moments_setup'></span><span id='topic+SE_classic_setup'></span><span id='topic+SE_whichMin_setup'></span><span id='topic+SE_interp_setup'></span><span id='topic+can.be.simmed'></span>

<h3>Description</h3>

<p>These functions are made available in the package namespace for other developers, and are not intended for users. They provide a shared infrastructure for setting up data for Jacobian computation, and then for caclulating the Jacobian, either exactly or approximately, in maximum likelihood fitting of spatial regression models. The techniques used are the exact eigenvalue, Cholesky decompositions (Matrix, spam), and LU ones, with Chebyshev and Monte Carlo approximations; moments use the methods due to Martin and Smirnov/Anselin.</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_ldet(coef, env, which=1)
jacobianSetup(method, env, con, pre_eig=NULL, trs=NULL, interval=NULL, which=1)
cheb_setup(env, q=5, which=1)
mcdet_setup(env, p=16, m=30, which=1)
eigen_setup(env, which=1)
eigen_pre_setup(env, pre_eig, which=1)
spam_setup(env, pivot="MMD", which=1)
spam_update_setup(env, in_coef=0.1, pivot="MMD", which=1)
Matrix_setup(env, Imult, super=as.logical(NA), which=1)
Matrix_J_setup(env, super=FALSE, which=1)
LU_setup(env, which=1)
LU_prepermutate_setup(env, coef=0.1, order=FALSE, which=1)
moments_setup(env, trs=NULL, m, p, type="MC", correct=TRUE, trunc=TRUE, eq7=TRUE, which=1)
SE_classic_setup(env, SE_method="LU", p=16, m=30, nrho=200, interpn=2000,
 interval=c(-1,0.999), SElndet=NULL, which=1)
SE_whichMin_setup(env, SE_method="LU", p=16, m=30, nrho=200, interpn=2000,
 interval=c(-1,0.999), SElndet=NULL, which=1)
SE_interp_setup(env, SE_method="LU", p=16, m=30, nrho=200,
 interval=c(-1,0.999), which=1)
can.be.simmed(listw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do_ldet_+3A_coef">coef</code></td>
<td>
<p>spatial coefficient value</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_env">env</code></td>
<td>
<p>environment containing pre-computed objects, fixed after assignment in setup functions</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_which">which</code></td>
<td>
<p>default 1; if 2, use second listw object</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_method">method</code></td>
<td>
<p>string value, used by <code>jacobianSetup</code> to choose method</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_con">con</code></td>
<td>
<p>control list passed from model fitting function and parsed in <code>jacobianSetup</code> to set environment variables for method-specific setup</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_pre_eig">pre_eig</code></td>
<td>
<p>pre-computed eigenvalues of length n</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_q">q</code></td>
<td>
<p>Chebyshev approximation order; default in calling spdep functions is 5, here it cannot be missing and does not have a default</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_p">p</code></td>
<td>
<p>Monte Carlo approximation number of random normal variables; default calling spdep functions is 16, here it cannot be missing and does not have a default</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_m">m</code></td>
<td>
<p>Monte Carlo approximation number of series terms; default in calling spdep functions is 30, here it cannot be missing and does not have a default; <code>m</code> serves the same purpose in the moments method</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_pivot">pivot</code></td>
<td>
<p>default &ldquo;MMD&rdquo;, may also be &ldquo;RCM&rdquo; for Cholesky decompisition using spam</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_in_coef">in_coef</code></td>
<td>
<p>fill-in initiation coefficient value, default 0.1</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_imult">Imult</code></td>
<td>
<p>see <code><a href="Matrix.html#topic+Cholesky">Cholesky</a></code>; numeric scalar which defaults to zero. The matrix that is decomposed is A+m*I where m is the value of Imult and I is the identity matrix of order ncol(A). Default in calling spdep functions is 2, here it cannot be missing and does not have a default, but is rescaled for binary weights matrices in proportion to the maximim row sum in those calling functions</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_super">super</code></td>
<td>
<p>see <code><a href="Matrix.html#topic+Cholesky">Cholesky</a></code>; logical scalar indicating is a supernodal decomposition should be created.  The alternative is a simplicial decomposition. Default in calling spdep functions is FALSE for &ldquo;Matrix_J&rdquo; and <code>as.logical(NA)</code> for &ldquo;Matrix&rdquo;.  Setting it to NA leaves the choice to a CHOLMOD-internal heuristic</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_order">order</code></td>
<td>
<p>default FALSE; used in LU_prepermutate, note warnings given for <code>lu</code> method</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_trs">trs</code></td>
<td>
<p>A numeric vector of <code>m</code> traces, as from <code>trW</code></p>
</td></tr>
<tr><td><code id="do_ldet_+3A_type">type</code></td>
<td>
<p>moments trace type, see <code><a href="#topic+trW">trW</a></code></p>
</td></tr>
<tr><td><code id="do_ldet_+3A_correct">correct</code></td>
<td>
<p>default TRUE: use Smirnov correction term, see <code><a href="#topic+trW">trW</a></code></p>
</td></tr>
<tr><td><code id="do_ldet_+3A_trunc">trunc</code></td>
<td>
<p>default TRUE: truncate Smirnov correction term, see <code><a href="#topic+trW">trW</a></code></p>
</td></tr>
<tr><td><code id="do_ldet_+3A_eq7">eq7</code></td>
<td>
<p>default TRUE; use equation 7 in Smirnov and Anselin (2009), if FALSE no unit root correction</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_se_method">SE_method</code></td>
<td>
<p>default &ldquo;LU&rdquo;, alternatively &ldquo;MC&rdquo;; underlying lndet method to use for generating SE toolbox emulation grid</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_nrho">nrho</code></td>
<td>
<p>default 200, number of lndet values in first stage SE toolbox emulation grid</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_interval">interval</code></td>
<td>
<p>default c(-1,0.999) if interval argument NULL, bounds for SE toolbox emulation grid</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_interpn">interpn</code></td>
<td>
<p>default 2000, number of lndet values to interpolate in second stage SE toolbox emulation grid</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_selndet">SElndet</code></td>
<td>
<p>default NULL, used to pass a pre-computed two-column matrix of coefficient values and corresponding interpolated lndet values</p>
</td></tr>
<tr><td><code id="do_ldet_+3A_listw">listw</code></td>
<td>
<p>a spatial weights object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Since environments are containers in the R workspace passed by reference rather than by value, they are useful for passing objects to functions called in numerical optimisation, here for the maximum likelihood estimation of spatial regression models. This technique can save a little time on each function call, balanced against the need to access the objects in the environment inside the function. The environment should contain a <code>family</code> string object either &ldquo;SAR&rdquo;, &ldquo;CAR&rdquo; or &ldquo;SMA&rdquo; (used in <code>do_ldet</code> to choose spatial moving average in <code>spautolm</code>, and these specific objects before calling the set-up functions:
</p>

<dl>
<dt>eigen</dt><dd><p>Classical Ord eigenvalue computations - either:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>can.sim</dt><dd><p>logical scalar: can the spatial weights be made symmetric by similarity</p>
</dd>
<dt>verbose</dt><dd><p>logical scalar: legacy report print control, for historical reasons only</p>
</dd>
</dl>
<p> or:
</p>

<dl>
<dt>pre_eig</dt><dd><p>pre-computed eigenvalues</p>
</dd>
</dl>

<p>and assigns to the environment:
</p>

<dl>
<dt>eig</dt><dd><p>a vector of eigenvalues</p>
</dd>
<dt>eig.range</dt><dd><p>the search interval for the spatial coefficient</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;eigen&rdquo;</p>
</dd>
</dl>

</dd>
<dt>Matrix</dt><dd><p>Sparse matrix pre-computed Cholesky decomposition with fast updating:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>can.sim</dt><dd><p>logical scalar: can the spatial weights be made symmetric by similarity</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>csrw</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>nW</dt><dd><p>negative sparse spatial weights matrix</p>
</dd>
<dt>pChol</dt><dd><p>a &ldquo;CHMfactor&rdquo; from factorising <code>csrw</code> with <code><a href="Matrix.html#topic+Cholesky">Cholesky</a></code></p>
</dd>
<dt>nChol</dt><dd><p>a &ldquo;CHMfactor&rdquo; from factorising <code>nW</code> with <code><a href="Matrix.html#topic+Cholesky">Cholesky</a></code></p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;Matrix&rdquo;</p>
</dd>
</dl>

</dd>
<dt>Matrix_J</dt><dd><p>Standard Cholesky decomposition without updating:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>can.sim</dt><dd><p>logical scalar: can the spatial weights be made symmetric by similarity</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>csrw</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>I</dt><dd><p>sparse identity matrix</p>
</dd>
<dt>super</dt><dd><p>the value of the <code>super</code> argument</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;Matrix_J&rdquo;</p>
</dd>
</dl>

</dd>
<dt>spam</dt><dd><p>Standard Cholesky decomposition without updating:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>can.sim</dt><dd><p>logical scalar: can the spatial weights be made symmetric by similarity</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>csrw</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>I</dt><dd><p>sparse identity matrix</p>
</dd>
<dt>pivot</dt><dd><p>string &mdash; pivot method</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;spam&rdquo;</p>
</dd>
</dl>

</dd>
<dt>spam_update</dt><dd><p>Pre-computed Cholesky decomposition with updating:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>can.sim</dt><dd><p>logical scalar: can the spatial weights be made symmetric by similarity</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>csrw</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>I</dt><dd><p>sparse identity matrix</p>
</dd>
<dt>csrwchol</dt><dd><p>A Cholesky decomposition for updating</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;spam&rdquo;</p>
</dd>
</dl>

</dd>
<dt>LU</dt><dd><p>Standard LU decomposition without updating:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>W</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>I</dt><dd><p>sparse identity matrix</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;LU&rdquo;</p>
</dd>
</dl>

</dd>
<dt>LU_prepermutate</dt><dd><p>Standard LU decomposition with updating (pre-computed fill-reducing permutation):
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>W</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>lu_order</dt><dd><p>order argument to lu</p>
</dd>
<dt>pq</dt><dd><p>2-column matrix for row and column permutation for fill-reduction</p>
</dd>
<dt>I</dt><dd><p>sparse identity matrix</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;LU&rdquo;</p>
</dd>
</dl>

</dd>
<dt>MC</dt><dd><p>Monte Carlo approximation:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>clx</dt><dd><p>list of Monte Carlo approximation terms  (the first two simulated traces are replaced by their analytical equivalents)</p>
</dd>
<dt>W</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;MC&rdquo;</p>
</dd>
</dl>

</dd>
<dt>cheb</dt><dd><p>Chebyshev approximation:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>trT</dt><dd><p>vector of Chebyshev approximation terms</p>
</dd>
<dt>W</dt><dd><p>sparse spatial weights matrix</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;Chebyshev&rdquo;</p>
</dd>
</dl>

</dd>
<dt>moments</dt><dd><p>moments approximation:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>can.sim</dt><dd><p>logical scalar: can the spatial weights be made symmetric by similarity</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>trs</dt><dd><p>vector of traces, possibly approximated</p>
</dd>
<dt>q12</dt><dd><p>integer vector of length 2, unit roots terms, ignored until 0.5-52</p>
</dd>
<dt>eq7</dt><dd><p>logical scalar: use equation 7</p>
</dd>
<dt>correct</dt><dd><p>logical scalar: use Smirnov correction term</p>
</dd>
<dt>trunc</dt><dd><p>logical scalar: truncate Smirnov correction term</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;moments&rdquo;</p>
</dd>
</dl>

</dd>
<dt>SE_classic</dt><dd><p>:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>detval</dt><dd><p>two column matrix of lndet grid values</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;SE_classic&rdquo;</p>
</dd>
<dt>SE_method</dt><dd><p>string: &ldquo;LU&rdquo; or &ldquo;MC&rdquo;</p>
</dd>
</dl>

</dd>
<dt>SE_whichMin</dt><dd><p>:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>detval</dt><dd><p>two column matrix of lndet grid values</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;SE_whichMin&rdquo;</p>
</dd>
<dt>SE_method</dt><dd><p>string: &ldquo;LU&rdquo; or &ldquo;MC&rdquo;</p>
</dd>
</dl>

</dd>
<dt>SE_interp</dt><dd><p>:
</p>

<dl>
<dt>listw</dt><dd><p>A listw spatial weights object</p>
</dd>
<dt>n</dt><dd><p>number of spatial objects</p>
</dd>
</dl>
<p> and assigns to the environment:
</p>

<dl>
<dt>fit</dt><dd><p>fitted spline object from which to predict lndet values</p>
</dd>
<dt>method</dt><dd><p>string: &ldquo;SE_interp&rdquo;</p>
</dd>
<dt>SE_method</dt><dd><p>string: &ldquo;LU&rdquo; or &ldquo;MC&rdquo;</p>
</dd>
</dl>

</dd>
</dl>

<p>Some set-up functions may also assign <code>similar</code> to the environment if the weights were made symmetric by similarity.
</p>
<p>Three set-up functions emulate the behaviour of the Spatial Econometrics toolbox (March 2010) maximum likelihood lndet grid performance. The toolbox lndet functions compute a smaller number of lndet values for a grid of coefficient values (spacing 0.01), and then interpolate to a finer grid of values (spacing 0.001). &ldquo;SE_classic&rdquo;, which is an implementation of the SE toolbox code, for example in f_sar.m, appears to have selected a row in the grid matrix one below the correct row when the candidate coefficient value was between 0.005 and 0.01-fuzz, always rounding the row index down. A possible alternative is to choose the index that is closest to the candidate coefficient value (&ldquo;SE_whichMin&rdquo;). Another alternative is to fit a spline model to the first stage coarser grid, and pass this fitted model to the log likelihood function to make a point prediction using the candidate coefficient value, rather than finding the grid index (&ldquo;SE_interp&rdquo;).
</p>


<h3>Value</h3>

<p><code>do_ldet</code> returns the value of the Jacobian for the calculation method recorded in the environment argument, and for the Monte Carlo approximation, returns a measure of the spread of the approximation as an &ldquo;sd&rdquo; attribute; the remaining functions modify the environment in place as a side effect and return nothing.</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>LeSage J and RK Pace (2009) Introduction to Spatial Econometrics. CRC Press, Boca Raton, pp. 77&ndash;110.
</p>
<p>Bivand, R. S., Hauke, J., and Kossowski, T. (2013). Computing the Jacobian in Gaussian spatial autoregressive models: An illustrated comparison of available methods. <em>Geographical Analysis</em>, 45(2), 150-179.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+spautolm">spautolm</a></code>, <code><a href="#topic+lagsarlm">lagsarlm</a></code>, <code><a href="#topic+errorsarlm">errorsarlm</a></code>, <code><a href="Matrix.html#topic+Cholesky">Cholesky</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(boston, package="spData")
#require("spdep", quietly=TRUE)
lw &lt;- spdep::nb2listw(boston.soi)
can.sim &lt;- can.be.simmed(lw)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("can.sim", can.sim, envir=env)
assign("similar", FALSE, envir=env)
assign("verbose", FALSE, envir=env)
assign("family", "SAR", envir=env)
eigen_setup(env)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("can.sim", can.sim, envir=env)
assign("similar", FALSE, envir=env)
assign("verbose", FALSE, envir=env)
assign("family", "SAR", envir=env)
assign("n", length(boston.soi), envir=env)
eigen_pre_setup(env, pre_eig=eigenw(similar.listw(lw)))
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("can.sim", can.sim, envir=env)
assign("similar", FALSE, envir=env)
assign("family", "SAR", envir=env)
assign("n", length(boston.soi), envir=env)
Matrix_setup(env, Imult=2, super=FALSE)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("n", length(boston.soi), envir=env)
assign("can.sim", can.sim, envir=env)
assign("similar", FALSE, envir=env)
assign("family", "SAR", envir=env)
spam_setup(env)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("n", length(boston.soi), envir=env)
assign("similar", FALSE, envir=env)
assign("family", "SAR", envir=env)
LU_setup(env)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("n", length(boston.soi), envir=env)
assign("similar", FALSE, envir=env)
assign("family", "SAR", envir=env)
LU_prepermutate_setup(env)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("similar", FALSE, envir=env)
assign("family", "SAR", envir=env)
cheb_setup(env, q=5)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
env &lt;- new.env(parent=globalenv())
assign("listw", lw, envir=env)
assign("n", length(boston.soi), envir=env)
assign("similar", FALSE, envir=env)
assign("family", "SAR", envir=env)
set.seed(12345)
mcdet_setup(env, p=16, m=30)
get("similar", envir=env)
do_ldet(0.5, env)
rm(env)
</code></pre>

<hr>
<h2 id='GMerrorsar'>Spatial simultaneous autoregressive error model estimation by GMM</h2><span id='topic+GMerrorsar'></span><span id='topic+residuals.Gmsar'></span><span id='topic+deviance.Gmsar'></span><span id='topic+coef.Gmsar'></span><span id='topic+fitted.Gmsar'></span><span id='topic+print.Gmsar'></span><span id='topic+summary.Gmsar'></span><span id='topic+print.summary.Gmsar'></span><span id='topic+Hausman.test.Gmsar'></span><span id='topic+GMargminImage'></span>

<h3>Description</h3>

<p>An implementation of Kelejian and Prucha's generalised moments estimator for the autoregressive parameter in a spatial model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GMerrorsar(formula, data = list(), listw, na.action = na.fail,
 zero.policy = attr(listw, "zero.policy"), method="nlminb", arnoldWied=FALSE, 
 control = list(), pars, scaleU=FALSE, verbose=NULL, legacy=FALSE,
 se.lambda=TRUE, returnHcov=FALSE, pWOrder=250, tol.Hcov=1.0e-10)
## S3 method for class 'Gmsar'
summary(object, correlation = FALSE, Hausman=FALSE, ...)
GMargminImage(obj, lambdaseq, s2seq)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GMerrorsar_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>na.fail</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE (default) assign NA - causing <code>GMerrorsar()</code> to terminate with an error</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_method">method</code></td>
<td>
<p>default <code>"nlminb"</code>, or optionally a method passed to <code>optim</code> to use an alternative optimizer</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_arnoldwied">arnoldWied</code></td>
<td>
<p>default FALSE</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See details in <code><a href="stats.html#topic+optim">optim</a></code> or <code><a href="stats.html#topic+nlminb">nlminb</a></code>.</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_pars">pars</code></td>
<td>
<p>starting values for <code class="reqn">\lambda</code> and <code class="reqn">\sigma^2</code> for GMM optimisation, if missing (default), approximated from initial OLS model as the autocorrelation coefficient corrected for weights style and model sigma squared</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_scaleu">scaleU</code></td>
<td>
<p>Default FALSE: scale the OLS residuals before computing the moment matrices; only used if the <code>pars</code> argument is missing</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE, reports function values during optimization.</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_legacy">legacy</code></td>
<td>
<p>default FALSE - compute using the unfiltered values of the response and right hand side variables; if TRUE - compute the fitted value and residuals from the spatially filtered model using the spatial error parameter</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_se.lambda">se.lambda</code></td>
<td>
<p>default TRUE, use the analytical method described in <a href="http://econweb.umd.edu/~prucha/STATPROG/OLS/desols.pdf">http://econweb.umd.edu/~prucha/STATPROG/OLS/desols.pdf</a></p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_returnhcov">returnHcov</code></td>
<td>
<p>default FALSE, return the Vo matrix for a spatial Hausman test</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_tol.hcov">tol.Hcov</code></td>
<td>
<p>the tolerance for computing the Vo matrix (default=1.0e-10)</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_pworder">pWOrder</code></td>
<td>
<p>default 250, if returnHcov=TRUE, pass this order to <code>powerWeights</code> as the power series maximum limit</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_object">object</code>, <code id="GMerrorsar_+3A_obj">obj</code></td>
<td>
<p><code>Gmsar</code> object from <code>GMerrorsar</code></p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_correlation">correlation</code></td>
<td>
<p>logical; (default=FALSE), TRUE not available</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_hausman">Hausman</code></td>
<td>
<p>if TRUE, the results of the Hausman test for error models are reported</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_...">...</code></td>
<td>
<p><code>summary</code> arguments passed through</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_lambdaseq">lambdaseq</code></td>
<td>
<p>if given, an increasing sequence of lambda values for gridding</p>
</td></tr>
<tr><td><code id="GMerrorsar_+3A_s2seq">s2seq</code></td>
<td>
<p>if given, an increasing sequence of sigma squared values for gridding</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the control list is set with care, the function will converge to values close to the ML estimator without requiring computation of the Jacobian, the most resource-intensive part of ML estimation. 
</p>
<p>Note that the fitted() function for the output object assumes that the response 
variable may be reconstructed as the sum of the trend, the signal, and the
noise (residuals). Since the values of the response variable are known,
their spatial lags are used to calculate signal components (Cressie 1993, p. 564). This differs from other software, including GeoDa, which does not use knowledge of the response 
variable in making predictions for the fitting data.
</p>
<p>The <code>GMargminImage</code> may be used to visualize the shape of the surface of the argmin function used to find lambda.
</p>


<h3>Value</h3>

<p>A list object of class <code>Gmsar</code>
</p>
<table>
<tr><td><code>type</code></td>
<td>
<p>&quot;ERROR&quot;</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>simultaneous autoregressive error coefficient</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>GMM coefficient estimates</p>
</td></tr>
<tr><td><code>rest.se</code></td>
<td>
<p>GMM coefficient standard errors</p>
</td></tr>
<tr><td><code>s2</code></td>
<td>
<p>GMM residual variance</p>
</td></tr>
<tr><td><code>SSE</code></td>
<td>
<p>sum of squared GMM errors</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>number of parameters estimated</p>
</td></tr>
<tr><td><code>lm.model</code></td>
<td>
<p>the <code>lm</code> object returned when estimating for <code class="reqn">\lambda=0</code></p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used to create this object</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>GMM residuals</p>
</td></tr>
<tr><td><code>lm.target</code></td>
<td>
<p>the <code>lm</code> object returned for the GMM fit</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>Difference between residuals and response variable</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>model formula</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>if not NULL, details of aliased variables</p>
</td></tr>
<tr><td><code>zero.policy</code></td>
<td>
<p>zero.policy for this model</p>
</td></tr>
<tr><td><code>vv</code></td>
<td>
<p>list of internal bigG and litg components for testing optimisation surface</p>
</td></tr>
<tr><td><code>optres</code></td>
<td>
<p>object returned by optimizer</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>start parameter values for optimisation</p>
</td></tr>
<tr><td><code>Hcov</code></td>
<td>
<p>Spatial DGP covariance matrix for Hausman test if available</p>
</td></tr>
<tr><td><code>legacy</code></td>
<td>
<p>input choice of unfiltered or filtered values</p>
</td></tr>
<tr><td><code>lambda.se</code></td>
<td>
<p>value computed if input argument TRUE</p>
</td></tr>
<tr><td><code>arnoldWied</code></td>
<td>
<p>were Arnold-Wied moments used</p>
</td></tr>
<tr><td><code>GMs2</code></td>
<td>
<p>GM argmin sigma squared</p>
</td></tr>
<tr><td><code>scaleU</code></td>
<td>
<p>input choice of scaled OLS residuals</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>variance-covariance matrix of regression coefficients</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>(possibly) named vector of excluded or omitted observations if non-default na.action argument used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luc Anselin and Roger Bivand</p>


<h3>References</h3>

<p>Kelejian, H. H., and Prucha, I. R., 1999. A Generalized Moments Estimator for the Autoregressive Parameter in a Spatial Model. International Economic Review, 40, pp. 509&ndash;533; Cressie, N. A. C. 1993 <em>Statistics for spatial data</em>, Wiley, New York.
</p>
<p>Roger Bivand, Gianfranco Piras (2015). Comparing Implementations of Estimation Methods for Spatial Econometrics. <em>Journal of Statistical Software</em>, 63(18), 1-36. <a href="https://doi.org/10.18637/jss.v063.i18">doi:10.18637/jss.v063.i18</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="stats.html#topic+nlminb">nlminb</a></code>, <code><a href="#topic+errorsarlm">errorsarlm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#require("spdep", quietly=TRUE)
data(oldcol, package="spdep")
COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="W"), method="eigen")
(x &lt;- summary(COL.errW.eig, Hausman=TRUE))
coef(x)
COL.errW.GM &lt;- GMerrorsar(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="W"), returnHcov=TRUE)
(x &lt;- summary(COL.errW.GM, Hausman=TRUE))
coef(x)
aa &lt;- GMargminImage(COL.errW.GM)
levs &lt;- quantile(aa$z, seq(0, 1, 1/12))
image(aa, breaks=levs, xlab="lambda", ylab="s2")
points(COL.errW.GM$lambda, COL.errW.GM$s2, pch=3, lwd=2)
contour(aa, levels=signif(levs, 4), add=TRUE)
COL.errW.GM1 &lt;- GMerrorsar(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="W"))
summary(COL.errW.GM1)
require("sf", quietly=TRUE)
nydata &lt;- st_read(system.file("shapes/NY8_bna_utm18.gpkg", package="spData")[1], quiet=TRUE)
suppressMessages(nyadjmat &lt;- as.matrix(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1])[-1]))
suppressMessages(ID &lt;- as.character(names(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1]))[-1]))
identical(substring(ID, 2, 10), substring(as.character(nydata$AREAKEY), 2, 10))
nyadjlw &lt;- spdep::mat2listw(nyadjmat, as.character(nydata$AREAKEY))
listw_NY &lt;- spdep::nb2listw(nyadjlw$neighbours, style="B")
esar1f &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, family="SAR", method="eigen")
summary(esar1f)
esar1gm &lt;- GMerrorsar(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY)
summary(esar1gm)
esar1gm1 &lt;- GMerrorsar(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, method="Nelder-Mead")
summary(esar1gm1)
</code></pre>

<hr>
<h2 id='griffith_sone'>Spatial weights matrix eigenvalues</h2><span id='topic+eigenw'></span><span id='topic+griffith_sone'></span><span id='topic+subgraph_eigenw'></span>

<h3>Description</h3>

<p>The <code>eigenw</code> function returns a numeric vector of eigenvalues of 
the weights matrix generated from the spatial weights object <code>listw</code>. 
The eigenvalues are used to speed the computation of the Jacobian in 
spatial model estimation:
</p>
<p style="text-align: center;"><code class="reqn">\log(\det[I - \rho W]) = \sum_{i=1}^{n}\log(1 - \rho \lambda_i)</code>
</p>

<p>where <code class="reqn">W</code> is the n by n spatial weights matrix, and <code class="reqn">\lambda_i</code> are the
eigenvalues of <code class="reqn">W</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eigenw(listw, quiet=NULL)
griffith_sone(P, Q, type="rook")
subgraph_eigenw(nb, glist=NULL, style="W", zero.policy=NULL, quiet=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="griffith_sone_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_quiet">quiet</code></td>
<td>
<p>default NULL, use global !verbose option value; set to FALSE for short summary</p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_p">P</code></td>
<td>
<p>number of columns in the grid (number of units in a horizontal axis direction)</p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_q">Q</code></td>
<td>
<p>number of rows in the grid (number of units in a vertical axis direction.)</p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_type">type</code></td>
<td>
<p>&ldquo;rook&rdquo; or &ldquo;queen&rdquo;</p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_nb">nb</code></td>
<td>
<p>an object of class <code>nb</code></p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_glist">glist</code></td>
<td>
<p>list of general weights corresponding to neighbours</p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_style">style</code></td>
<td>
<p><code>style</code> can take values &ldquo;W&rdquo;, &ldquo;B&rdquo;, &ldquo;C&rdquo;, &ldquo;U&rdquo;, &ldquo;minmax&rdquo; and &ldquo;S&rdquo;</p>
</td></tr>
<tr><td><code id="griffith_sone_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if FALSE stop with error for any empty neighbour sets, if TRUE permit the weights list to be formed with zero-length weights vectors</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The <code>griffith_sone</code> function function may be used, following Ord and Gasim (for references see Griffith and Sone (1995)), to calculate analytical eigenvalues for binary rook or queen contiguous neighbours where the data are arranged as a regular P times Q grid. The <code>subgraph_eigenw</code> function may be used when there are multiple graph components, of which the largest may be handled as a dense matrix. Here the eigenvalues are computed for each subgraph in turn, and catenated to reconstruct the complete set. The functions may be used to provide pre-computed eigenvalues for spatial regression functions.</p>


<h3>Value</h3>

<p>a numeric or complex vector of eigenvalues of the weights matrix generated from the spatial weights object.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Cliff, A. D., Ord, J. K. 1981 Spatial processes, Pion, p. 155;
Ord, J. K. 1975 Estimation methods for models of spatial interaction, Journal
of the American Statistical Association, 70, 120-126.; Griffith, D. A. and Sone, A. (1995). Trade-offs associated with normalizing constant computational simplifications for estimating spatial statistical models. Journal of Statistical Computation and Simulation, 51, 165-183.</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+eigen">eigen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#require(spdep)
data(oldcol, package="spdep")
W.eig &lt;- eigenw(spdep::nb2listw(COL.nb, style="W"))
1/range(W.eig)
S.eig &lt;- eigenw(spdep::nb2listw(COL.nb, style="S"))
1/range(S.eig)
B.eig &lt;- eigenw(spdep::nb2listw(COL.nb, style="B"))
1/range(B.eig)
# cases for intrinsically asymmetric weights
crds &lt;- cbind(COL.OLD$X, COL.OLD$Y)
k3 &lt;- spdep::knn2nb(spdep::knearneigh(crds, k=3))
spdep::is.symmetric.nb(k3)
k3eig &lt;- eigenw(spdep::nb2listw(k3, style="W"))
is.complex(k3eig)
rho &lt;- 0.5
Jc &lt;- sum(log(1 - rho * k3eig))
# complex eigenvalue Jacobian
Jc
# subgraphs
nc &lt;- spdep::n.comp.nb(k3)
nc$nc
table(nc$comp.id)
k3eigSG &lt;- subgraph_eigenw(k3, style="W")
all.equal(sort(k3eig), k3eigSG)
W &lt;- as(spdep::nb2listw(k3, style="W"), "CsparseMatrix")
I &lt;- diag(length(k3))
Jl &lt;- sum(log(abs(diag(slot(lu(I - rho * W), "U")))))
# LU Jacobian equals complex eigenvalue Jacobian
Jl
all.equal(Re(Jc), Jl)
# wrong value if only real part used
Jr &lt;- sum(log(1 - rho * Re(k3eig)))
Jr
all.equal(Jr, Jl)
# construction of Jacobian from complex conjugate pairs (Jan Hauke)
Rev &lt;- Re(k3eig)[which(Im(k3eig) == 0)]
# real eigenvalues
Cev &lt;- k3eig[which(Im(k3eig) != 0)]
pCev &lt;- Cev[Im(Cev) &gt; 0]
# separate complex conjugate pairs
RpCev &lt;- Re(pCev)
IpCev &lt;- Im(pCev)
# reassemble Jacobian
Jc1 &lt;- sum(log(1 - rho*Rev)) + sum(log((1 - rho * RpCev)^2 + (rho^2)*(IpCev^2)))
all.equal(Re(Jc), Jc1)
# impact of omitted complex part term in real part only Jacobian
Jc2 &lt;- sum(log(1 - rho*Rev)) + sum(log((1 - rho * RpCev)^2))
all.equal(Jr, Jc2)
# trace of asymmetric (WW) and crossprod of complex eigenvalues for APLE
sum(diag(W %*% W))
crossprod(k3eig)
# analytical regular grid eigenvalues
rg &lt;- spdep::cell2nb(ncol=7, nrow=7, type="rook")
rg_eig &lt;- eigenw(spdep::nb2listw(rg, style="B"))
rg_GS &lt;- griffith_sone(P=7, Q=7, type="rook")
all.equal(rg_eig, rg_GS)
## Not run: 
run &lt;- FALSE
if (require("RSpectra", quietly=TRUE)) run &lt;- TRUE
if (run) {
B &lt;- as(spdep::nb2listw(rg, style="B"), "CsparseMatrix")
res1 &lt;- eigs(B, k=1, which="LR")$values
resn &lt;- eigs(B, k=1, which="SR")$values
print(Re(c(resn, res1)))
}
if (run) {
print(all.equal(range(Re(rg_eig)), c(resn, res1))) 
}
if (run) {
lw &lt;- spdep::nb2listw(rg, style="W")
rg_eig &lt;- eigenw(similar.listw(lw))
print(range(Re(rg_eig)))
}
if (run) {
W  &lt;- as(lw, "CsparseMatrix")
print(Re(c(eigs(W, k=1, which="SR")$values, eigs(W, k=1, which="LR")$values)))
}
## End(Not run)
</code></pre>

<hr>
<h2 id='gstsls'>Spatial simultaneous autoregressive SAC model estimation by GMM</h2><span id='topic+gstsls'></span><span id='topic+impacts.Gmsar'></span>

<h3>Description</h3>

<p>An implementation of Kelejian and Prucha's generalised moments estimator for the autoregressive parameter in a spatial model
with a spatially lagged dependent variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gstsls(formula, data = list(), listw, listw2 = NULL, na.action = na.fail, 
    zero.policy = attr(listw, "zero.policy"), pars=NULL, scaleU=FALSE, control = list(), 
    verbose=NULL, method="nlminb", robust=FALSE, legacy=FALSE, W2X=TRUE) 
## S3 method for class 'Gmsar'
impacts(obj, ..., n = NULL, tr = NULL, R = NULL,
 listw = NULL, evalues=NULL, tol = 1e-06, empirical = FALSE, Q=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gstsls_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="gstsls_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="gstsls_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="gstsls_+3A_listw2">listw2</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code>, if not given, set to the same spatial weights as the listw argument</p>
</td></tr>
<tr><td><code id="gstsls_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>na.fail</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="gstsls_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE (default) assign NA - causing <code>GMerrorsar()</code> to terminate with an error</p>
</td></tr>
<tr><td><code id="gstsls_+3A_pars">pars</code></td>
<td>
<p>starting values for <code class="reqn">\lambda</code> and <code class="reqn">\sigma^2</code> for GMM optimisation, 
if missing (default), approximated from initial 2sls model as the autocorrelation coefficient corrected for weights style 
and model sigma squared</p>
</td></tr>
<tr><td><code id="gstsls_+3A_scaleu">scaleU</code></td>
<td>
<p>Default FALSE: scale the OLS residuals before computing the moment matrices; only used if the <code>pars</code> argument is missing</p>
</td></tr>
<tr><td><code id="gstsls_+3A_control">control</code></td>
<td>
<p>A list of control parameters. See details in <a href="stats.html#topic+optim">optim</a> or <a href="stats.html#topic+nlminb">nlminb</a></p>
</td></tr>
<tr><td><code id="gstsls_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE, reports function values during optimization.</p>
</td></tr>
<tr><td><code id="gstsls_+3A_method">method</code></td>
<td>
<p>default <a href="stats.html#topic+nlminb">nlminb</a>, or optionally a method passed to <a href="stats.html#topic+optim">optim</a> to use an alternative optimizer</p>
</td></tr>
<tr><td><code id="gstsls_+3A_robust">robust</code></td>
<td>
<p>see <code>stsls</code></p>
</td></tr>
<tr><td><code id="gstsls_+3A_legacy">legacy</code></td>
<td>
<p>see <code>stsls</code></p>
</td></tr>
<tr><td><code id="gstsls_+3A_w2x">W2X</code></td>
<td>
<p>see <code>stsls</code></p>
</td></tr>
<tr><td><code id="gstsls_+3A_obj">obj</code></td>
<td>
<p>A spatial regression object created by <code>lagsarlm</code>, <code>lagmess</code> or by <code>lmSLX</code>; in <code>HPDinterval.LagImpact</code>, a LagImpact object</p>
</td></tr>
<tr><td><code id="gstsls_+3A_...">...</code></td>
<td>
<p>Arguments passed through to methods in the <span class="pkg">coda</span> package</p>
</td></tr>
<tr><td><code id="gstsls_+3A_tr">tr</code></td>
<td>
<p>A vector of traces of powers of the spatial weights matrix created using <code>trW</code>, for approximate impact measures; if not given, <code>listw</code> must be given for exact measures (for small to moderate spatial weights matrices); the traces must be for the same spatial weights as were used in fitting the spatial regression, and must be row-standardised</p>
</td></tr>
<tr><td><code id="gstsls_+3A_evalues">evalues</code></td>
<td>
<p>vector of eigenvalues of spatial weights matrix for impacts calculations</p>
</td></tr>
<tr><td><code id="gstsls_+3A_r">R</code></td>
<td>
<p>If given, simulations are used to compute distributions for the impact measures, returned as <code>mcmc</code> objects; the objects are used for convenience but are not output by an MCMC process</p>
</td></tr>
<tr><td><code id="gstsls_+3A_tol">tol</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code>: tolerance (relative to largest variance) for numerical lack of positive-definiteness in the coefficient covariance matrix</p>
</td></tr>
<tr><td><code id="gstsls_+3A_empirical">empirical</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code> (default FALSE): if true, the coefficients and their covariance matrix specify the empirical not population mean and covariance matrix</p>
</td></tr>
<tr><td><code id="gstsls_+3A_q">Q</code></td>
<td>
<p>default NULL, else an integer number of cumulative power series impacts to calculate if <code>tr</code> is given</p>
</td></tr>
<tr><td><code id="gstsls_+3A_n">n</code></td>
<td>
<p>defaults to <code>length(obj$residuals)</code>; in the method for <code>Gmsar</code> objects it may be used in panel settings to compute the impacts for cross-sectional weights only, suggested by Angela Parenti</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the control list is set with care, the function will converge to values close to the ML estimator 
without requiring computation of the Jacobian, the most resource-intensive part of ML estimation. 
</p>


<h3>Value</h3>

<p>A list object of class <code>Gmsar</code>
</p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>simultaneous autoregressive error coefficient</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>GMM coefficient estimates (including the spatial autocorrelation coefficient)</p>
</td></tr>
<tr><td><code>rest.se</code></td>
<td>
<p>GMM coefficient standard errors</p>
</td></tr>
<tr><td><code>s2</code></td>
<td>
<p>GMM residual variance</p>
</td></tr>
<tr><td><code>SSE</code></td>
<td>
<p>sum of squared GMM errors</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>number of parameters estimated</p>
</td></tr>
<tr><td><code>lm.model</code></td>
<td>
<p>NULL</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used to create this object</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>GMM residuals</p>
</td></tr>
<tr><td><code>lm.target</code></td>
<td>
<p>NULL</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>Difference between residuals and response variable</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>model formula</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>NULL</p>
</td></tr>
<tr><td><code>zero.policy</code></td>
<td>
<p>zero.policy for this model</p>
</td></tr>
<tr><td><code>LL</code></td>
<td>
<p>NULL</p>
</td></tr>
<tr><td><code>vv</code></td>
<td>
<p>list of internal bigG and litg components for testing optimisation surface</p>
</td></tr>
<tr><td><code>optres</code></td>
<td>
<p>object returned by optimizer</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>start parameter values for optimisation</p>
</td></tr>
<tr><td><code>Hcov</code></td>
<td>
<p>NULL</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>(possibly) named vector of excluded or omitted observations if non-default na.action argument used</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gianfranco Piras and Roger Bivand</p>


<h3>References</h3>

<p>Kelejian, H. H., and Prucha, I. R., 1999. A Generalized Moments Estimator for the Autoregressive Parameter in a Spatial Model. International Economic Review, 40, pp. 509&ndash;533; Cressie, N. A. C. 1993 <em>Statistics for spatial data</em>, Wiley, New York.
</p>
<p>Roger Bivand, Gianfranco Piras (2015). Comparing Implementations of Estimation Methods for Spatial Econometrics. <em>Journal of Statistical Software</em>, 63(18), 1-36. <a href="https://doi.org/10.18637/jss.v063.i18">doi:10.18637/jss.v063.i18</a>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="stats.html#topic+nlminb">nlminb</a></code>, <code><a href="#topic+GMerrorsar">GMerrorsar</a></code>, <code><a href="#topic+GMargminImage">GMargminImage</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#require("spdep", quietly=TRUE) 
data(oldcol, package="spdep")
COL.errW.GM &lt;- gstsls(CRIME ~ INC + HOVAL, data=COL.OLD, spdep::nb2listw(COL.nb, style="W"))
summary(COL.errW.GM)
aa &lt;- GMargminImage(COL.errW.GM)
levs &lt;- quantile(aa$z, seq(0, 1, 1/12))
image(aa, breaks=levs, xlab="lambda", ylab="s2")
points(COL.errW.GM$lambda, COL.errW.GM$s2, pch=3, lwd=2)
contour(aa, levels=signif(levs, 4), add=TRUE)
COL.errW.GM &lt;- gstsls(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="W"), scaleU=TRUE)
summary(COL.errW.GM)
listw &lt;- spdep::nb2listw(COL.nb)
W &lt;- as(listw, "CsparseMatrix")
trMat &lt;- trW(W, type="mult")
impacts(COL.errW.GM, tr=trMat)
</code></pre>

<hr>
<h2 id='impacts'>Impacts in spatial lag models</h2><span id='topic+impacts'></span><span id='topic+plot.LagImpact'></span><span id='topic+print.LagImpact'></span><span id='topic+summary.LagImpact'></span><span id='topic+print.summary.LagImpact'></span><span id='topic+HPDinterval.LagImpact'></span><span id='topic+intImpacts'></span>

<h3>Description</h3>

<p>The calculation of impacts for spatial lag and spatial Durbin models is needed in order to interpret the regression coefficients correctly, because of the spillovers between the terms in these data generation processes (unlike the spatial error model). Methods for &ldquo;SLX&rdquo; and Bayesian fitted models are also provided, the former do not need MC simulations, while the latter pass through MCMC draws.</p>


<h3>Usage</h3>

<pre><code class='language-R'>#\method{impacts}{sarlm}(obj, \dots, tr, R = NULL, listw = NULL, evalues=NULL,
# useHESS = NULL, tol = 1e-06, empirical = FALSE, Q=NULL)
#\method{impacts}{lagmess}(obj, ..., R=NULL, listw=NULL, tol=1e-6,
# empirical=FALSE)
#\method{impacts}{SLX}(obj, ...)
#\method{impacts}{MCMC_sar_g}(obj, ..., tr=NULL, listw=NULL, evalues=NULL, Q=NULL)
#\method{impacts}{MCMC_sem_g}(obj, ..., tr=NULL, listw=NULL, evalues=NULL, Q=NULL)
#\method{impacts}{MCMC_sac_g}(obj, ..., tr=NULL, listw=NULL, evalues=NULL, Q=NULL)
## S3 method for class 'LagImpact'
plot(x, ..., choice="direct", trace=FALSE, density=TRUE)
## S3 method for class 'LagImpact'
print(x, ..., reportQ=NULL)
## S3 method for class 'LagImpact'
summary(object, ..., zstats=FALSE, short=FALSE, reportQ=NULL)
#\method{print}{WXImpact}(x, ...)
#\method{summary}{WXImpact}(object, ..., adjust_k=(attr(object, "type") == "SDEM"))
## S3 method for class 'LagImpact'
HPDinterval(obj, prob = 0.95, ..., choice="direct")
intImpacts(rho, beta, P, n, mu, Sigma, irho, drop2beta, bnames, interval,
 type, tr, R, listw, evalues, tol, empirical, Q, icept, iicept, p, mess=FALSE,
 samples=NULL, zero_fill = NULL, dvars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impacts_+3A_obj">obj</code></td>
<td>
<p>A spatial regression object created by <code>lagsarlm</code>
or by <code>lmSLX</code>; in <code>HPDinterval.LagImpact</code>, a LagImpact object</p>
</td></tr>
<tr><td><code id="impacts_+3A_...">...</code></td>
<td>
<p>Arguments passed through to methods in the <span class="pkg">coda</span> package</p>
</td></tr>
<tr><td><code id="impacts_+3A_tr">tr</code></td>
<td>
<p>A vector of traces of powers of the spatial weights matrix created using <code>trW</code>, for approximate impact measures; if not given, <code>listw</code> must be given for exact measures (for small to moderate spatial weights matrices); the traces must be for the same spatial weights as were used in fitting the spatial regression, and must be row-standardised</p>
</td></tr>
<tr><td><code id="impacts_+3A_listw">listw</code></td>
<td>
<p>If <code>tr</code> is not given, a spatial weights object as created by <code>nb2listw</code>; they must be the same spatial weights as were used in fitting the spatial regression, but do not have to be row-standardised</p>
</td></tr>
<tr><td><code id="impacts_+3A_evalues">evalues</code></td>
<td>
<p>vector of eigenvalues of spatial weights matrix for impacts calculations</p>
</td></tr>
<tr><td><code id="impacts_+3A_n">n</code></td>
<td>
<p>defaults to <code>length(obj$residuals)</code>; in the method for <code>gmsar</code> objects it may be used in panel settings to compute the impacts for cross-sectional weights only, suggested by Angela Parenti</p>
</td></tr>
<tr><td><code id="impacts_+3A_r">R</code></td>
<td>
<p>If given, simulations are used to compute distributions for the impact measures, returned as <code>mcmc</code> objects; the objects are used for convenience but are not output by an MCMC process</p>
</td></tr>
<tr><td><code id="impacts_+3A_usehess">useHESS</code></td>
<td>
<p>Use the Hessian approximation (if available) even if the asymptotic coefficient covariance matrix is available; used for comparing methods</p>
</td></tr>
<tr><td><code id="impacts_+3A_tol">tol</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code>: tolerance (relative to largest variance) for numerical lack of positive-definiteness in the coefficient covariance matrix</p>
</td></tr>
<tr><td><code id="impacts_+3A_empirical">empirical</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code> (default FALSE): if true, the coefficients and their covariance matrix specify the empirical not population mean and covariance matrix</p>
</td></tr>
<tr><td><code id="impacts_+3A_q">Q</code></td>
<td>
<p>default NULL, else an integer number of cumulative power series impacts to calculate if <code>tr</code> is given</p>
</td></tr>
<tr><td><code id="impacts_+3A_reportq">reportQ</code></td>
<td>
<p>default NULL; if TRUE and <code>Q</code> given as an argument to <code>impacts</code>, report impact components</p>
</td></tr>
<tr><td><code id="impacts_+3A_x">x</code>, <code id="impacts_+3A_object">object</code></td>
<td>
<p>LagImpact objects created by <code>impacts</code> methods</p>
</td></tr>
<tr><td><code id="impacts_+3A_zstats">zstats</code></td>
<td>
<p>default FALSE, if TRUE, also return z-values and p-values for the impacts based on the simulations</p>
</td></tr>
<tr><td><code id="impacts_+3A_short">short</code></td>
<td>
<p>default FALSE, if TRUE passed to the print summary method to omit printing of the mcmc summaries</p>
</td></tr>
<tr><td><code id="impacts_+3A_choice">choice</code></td>
<td>
<p>One of three impacts: direct, indirect, or total</p>
</td></tr>
<tr><td><code id="impacts_+3A_trace">trace</code></td>
<td>
<p>Argument passed to <code>plot.mcmc</code>: plot trace plots</p>
</td></tr>
<tr><td><code id="impacts_+3A_density">density</code></td>
<td>
<p>Argument passed to <code>plot.mcmc</code>: plot density plots</p>
</td></tr>
<tr><td><code id="impacts_+3A_prob">prob</code></td>
<td>
<p>Argument passed to <code>HPDinterval.mcmc</code>: a numeric scalar in the interval (0,1) giving the target probability content of the intervals</p>
</td></tr>
<tr><td><code id="impacts_+3A_adjust_k">adjust_k</code></td>
<td>
<p>default TRUE if SDEM else FALSE, adjust internal OLS SDEM standard errors by dividing by n rather than (n-k) (default changed and bug fixed after 0.7-8; standard errors now ML in SDEM summary and impacts summary and identical - for SLX use FALSE)</p>
</td></tr>
<tr><td><code id="impacts_+3A_rho">rho</code>, <code id="impacts_+3A_beta">beta</code>, <code id="impacts_+3A_p">P</code>, <code id="impacts_+3A_mu">mu</code>, <code id="impacts_+3A_sigma">Sigma</code>, <code id="impacts_+3A_irho">irho</code>, <code id="impacts_+3A_drop2beta">drop2beta</code>, <code id="impacts_+3A_bnames">bnames</code>, <code id="impacts_+3A_interval">interval</code>, <code id="impacts_+3A_type">type</code>, <code id="impacts_+3A_icept">icept</code>, <code id="impacts_+3A_iicept">iicept</code>, <code id="impacts_+3A_p">p</code>, <code id="impacts_+3A_mess">mess</code>, <code id="impacts_+3A_samples">samples</code>, <code id="impacts_+3A_zero_fill">zero_fill</code>, <code id="impacts_+3A_dvars">dvars</code></td>
<td>
<p>internal arguments shared inside impacts methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If called without <code>R</code> being set, the method returns the direct, indirect and total impacts for the variables in the model, for the variables themselves in tha spatial lag model case, for the variables and their spatial lags in the spatial Durbin (mixed) model case. The spatial lag impact measures are computed using eq. 2.46 (LeSage and Pace, 2009, p. 38), either using the exact dense matrix (when <code>listw</code> is given), or traces of powers of the weights matrix (when <code>tr</code> is given). When the traces are created by powering sparse matrices, the exact and the trace methods should give very similar results, unless the number of powers used is very small, or the spatial coefficient is close to its bounds.
</p>
<p>If <code>R</code> is given, simulations will be used to create distributions for the impact measures, provided that the fitted model object contains a coefficient covariance matrix. The simulations are made using <code><a href="MASS.html#topic+mvrnorm">mvrnorm</a></code> with the coefficients and their covariance matrix from the fitted model.
</p>
<p>The simulations are stored as <code>mcmc</code> objects as defined in the <span class="pkg">coda</span> package; the objects are used for convenience but are not output by an MCMC process. The simulated values of the coefficients are checked to see that the spatial coefficient remains within its valid interval &mdash; draws outside the interval are discarded.
</p>
<p>If a model is fitted with the &ldquo;Durbin=&rdquo; set to a formula subsetting the explanatory variables, the impacts object returned reports Durbin impacts for variables included in the formula and lag impacts for the other variables.
</p>
<p>When <code>Q</code> and <code>tr</code> are given, addition impact component results are provided for each step in the traces of powers of the weights matrix up to and including the <code>Q</code>'th power. This increases computing time because the output object is substantially increased in size in proportion to the size of <code>Q</code>.
</p>
<p>The method for <code>gmsar</code> objects is only for those of <code>type</code> <code>SARAR</code> output by <code>gstsls</code>, and assume that the spatial error coefficient is fixed, and thus omitted from the coefficients and covariance matrix used for simulation.
</p>


<h3>Value</h3>

<p>An object of class LagImpact.
</p>
<p>If no simulation is carried out, the object returned is a list with:
</p>
<table>
<tr><td><code>direct</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code>indirect</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code>total</code></td>
<td>
<p>numeric vector</p>
</td></tr>
</table>
<p>and a matching <code>Qres</code> list attribute if <code>Q</code> was given.
</p>
<p>If simulation is carried out, the object returned is a list with:
</p>
<table>
<tr><td><code>res</code></td>
<td>
<p>a list with three components as for the non-simulation case, with a matching <code>Qres</code> list attribute if <code>Q</code> was given</p>
</td></tr>
<tr><td><code>sres</code></td>
<td>
<p>a list with three <code>mcmc</code> matrices, for the direct, indirect and total impacts with a matching <code>Qmcmc</code> list attribute if <code>Q</code> was given</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>LeSage J and RK Pace (2009) <em>Introduction to Spatial Econometrics</em>. CRC Press, Boca Raton, pp. 33&ndash;42, 114&ndash;115; LeSage J and MM Fischer (2008) Spatial growth regressions: model specification, estimation and interpretation. <em>Spatial Economic Analysis</em> 3 (3), pp. 275&ndash;304.
</p>
<p>Roger Bivand, Gianfranco Piras (2015). Comparing Implementations of Estimation Methods for Spatial Econometrics. <em>Journal of Statistical Software</em>, 63(18), 1-36. <a href="https://doi.org/10.18637/jss.v063.i18">doi:10.18637/jss.v063.i18</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+trW">trW</a></code>, <code><a href="#topic+lagsarlm">lagsarlm</a></code>, <code><a href="spdep.html#topic+nb2listw">nb2listw</a></code>, <code><a href="MASS.html#topic+mvrnorm">mvrnorm</a></code>, <code><a href="coda.html#topic+plot.mcmc">plot.mcmc</a></code>, <code><a href="coda.html#topic+summary.mcmc">summary.mcmc</a></code>, <code><a href="coda.html#topic+HPDinterval">HPDinterval</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require("sf", quietly=TRUE)
columbus &lt;- st_read(system.file("shapes/columbus.shp", package="spData")[1], quiet=TRUE)
#require("spdep", quietly=TRUE)
col.gal.nb &lt;- spdep::read.gal(system.file("weights/columbus.gal", package="spData")[1])
listw &lt;- spdep::nb2listw(col.gal.nb)
ev &lt;- eigenw(listw)
lobj &lt;- lagsarlm(CRIME ~ INC + HOVAL, columbus, listw,
 control=list(pre_eig=ev))
summary(lobj)
mobj &lt;- lagsarlm(CRIME ~ INC + HOVAL, columbus, listw, Durbin=TRUE,
 control=list(pre_eig=ev))
summary(mobj)
mobj1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, columbus, listw, Durbin= ~ INC,
 control=list(pre_eig=ev))
summary(mobj1)
W &lt;- as(listw, "CsparseMatrix")
trMatc &lt;- trW(W, type="mult")
trMC &lt;- trW(W, type="MC")
set.seed(1)
impacts(lobj, listw=listw)
impacts(lobj, tr=trMatc)
impacts(lobj, tr=trMC)
impacts(lobj, evalues=ev)
library(coda)
lobjIQ5 &lt;- impacts(lobj, tr=trMatc, R=200, Q=5)
summary(lobjIQ5, zstats=TRUE, short=TRUE)
summary(lobjIQ5, zstats=TRUE, short=TRUE, reportQ=TRUE)
impacts(mobj, listw=listw)
impacts(mobj, tr=trMatc)
impacts(mobj, tr=trMC)
impacts(mobj1, tr=trMatc)
impacts(mobj1, listw=listw)
## Not run: 
try(impacts(mobj, evalues=ev), silent=TRUE)

## End(Not run)
summary(impacts(mobj, tr=trMatc, R=200), short=TRUE, zstats=TRUE)
summary(impacts(mobj1, tr=trMatc, R=200), short=TRUE, zstats=TRUE)
xobj &lt;- lmSLX(CRIME ~ INC + HOVAL, columbus, listw)
summary(impacts(xobj))
eobj &lt;- errorsarlm(CRIME ~ INC + HOVAL, columbus, listw, etype="emixed")
summary(impacts(eobj), adjust_k=TRUE)
## Not run: 
mobj1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, columbus, listw, type="mixed", 
method="Matrix", control=list(fdHess=TRUE))
summary(mobj1)
set.seed(1)
summary(impacts(mobj1, tr=trMatc, R=1000), zstats=TRUE, short=TRUE)
summary(impacts(mobj, tr=trMatc, R=1000), zstats=TRUE, short=TRUE)
mobj2 &lt;- lagsarlm(CRIME ~ INC + HOVAL, columbus, listw, type="mixed", 
method="Matrix", control=list(fdHess=TRUE, optimHess=TRUE))
summary(impacts(mobj2, tr=trMatc, R=1000), zstats=TRUE, short=TRUE)
mobj3 &lt;- lagsarlm(CRIME ~ INC + HOVAL, columbus, listw, type="mixed", 
method="spam", control=list(fdHess=TRUE))
summary(impacts(mobj3, tr=trMatc, R=1000), zstats=TRUE, short=TRUE)

## End(Not run)
## Not run: 
data(boston, package="spData")
Wb &lt;- as(spdep::nb2listw(boston.soi), "CsparseMatrix")
trMatb &lt;- trW(Wb, type="mult")
gp2mMi &lt;- lagsarlm(log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + 
I(RM^2) +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT), 
data=boston.c, spdep::nb2listw(boston.soi), type="mixed", method="Matrix", 
control=list(fdHess=TRUE), trs=trMatb)
summary(gp2mMi)
summary(impacts(gp2mMi, tr=trMatb, R=1000), zstats=TRUE, short=TRUE)
#data(house, package="spData")
#lw &lt;- spdep::nb2listw(LO_nb)
#form &lt;- formula(log(price) ~ age + I(age^2) + I(age^3) + log(lotsize) +
#   rooms + log(TLA) + beds + syear)
#lobj &lt;- lagsarlm(form, house, lw, method="Matrix",
# control=list(fdHess=TRUE), trs=trMat)
#summary(lobj)
#loobj &lt;- impacts(lobj, tr=trMat, R=1000)
#summary(loobj, zstats=TRUE, short=TRUE)
#lobj1 &lt;- stsls(form, house, lw)
#loobj1 &lt;- impacts(lobj1, tr=trMat, R=1000)
#summary(loobj1, zstats=TRUE, short=TRUE)
#mobj &lt;- lagsarlm(form, house, lw, type="mixed",
# method="Matrix", control=list(fdHess=TRUE), trs=trMat)
#summary(mobj)
#moobj &lt;- impacts(mobj, tr=trMat, R=1000)
#summary(moobj, zstats=TRUE, short=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='invIrM'>Compute SAR generating operator</h2><span id='topic+invIrM'></span><span id='topic+invIrW'></span>

<h3>Description</h3>

<p>Computes the matrix used for generating simultaneous autoregressive random variables, for a given value of rho, a neighbours list object or a matrix, a chosen coding scheme style, and optionally a list of general weights corresponding to neighbours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invIrM(neighbours, rho, glist=NULL, style="W", method="solve",
 feasible=NULL)
invIrW(x, rho, method="solve", feasible=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invIrM_+3A_neighbours">neighbours</code></td>
<td>
<p>an object of class <code>nb</code></p>
</td></tr>
<tr><td><code id="invIrM_+3A_rho">rho</code></td>
<td>
<p>autoregressive parameter</p>
</td></tr>
<tr><td><code id="invIrM_+3A_glist">glist</code></td>
<td>
<p>list of general weights corresponding to neighbours</p>
</td></tr>
<tr><td><code id="invIrM_+3A_style">style</code></td>
<td>
<p><code>style</code> can take values W, B, C, and S</p>
</td></tr>
<tr><td><code id="invIrM_+3A_method">method</code></td>
<td>
<p>default <code>solve</code>, can also take value <code>chol</code></p>
</td></tr>
<tr><td><code id="invIrM_+3A_feasible">feasible</code></td>
<td>
<p>if NULL, the given value of rho is checked to see if it lies within its feasible range, if TRUE, the test is not conducted</p>
</td></tr>
<tr><td><code id="invIrM_+3A_x">x</code></td>
<td>
<p>either a <code>listw</code> object from for example <code>nb2listw</code>, or a square spatial weights matrix, optionally a sparse matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>invIrW</code> function generates the full weights matrix V, checks that rho lies in its feasible range between 1/min(eigen(V)) and 1/max(eigen(V)), and returns the nxn inverted matrix </p>
<p style="text-align: center;"><code class="reqn">(I - \rho V)^{-1}</code>
</p>
<p>. With method=&ldquo;chol&rdquo; (only for a listw object), Cholesky decomposition is used, thanks to contributed code by Markus Reder and Werner Mueller.
</p>
<p>Note that, in some situations in simulation, it may matter that the random vector from <code>rnorm</code> or similar will not be exactly N(0, 1), and it will also contain random amounts of spatial autocorrelection itself, which will mix with the spatial autocorrelection injected by the process operator </p>
<p style="text-align: center;"><code class="reqn">(I - \rho V)^{-1}</code>
</p>
<p>. In addition, it will not follow the stipulated distribution exactly either, so that several steps may be needed to scale the random vector, to remove artefacts coming from its deviance from distributional parameters, and to remove random spatial autocorrelation - see the examples below. Thanks to Rune Østergaard Pedersen for bring up this question.
</p>
<p>The <code>powerWeights</code> function uses power series summation to cumulate the product </p>
<p style="text-align: center;"><code class="reqn">(I - \rho V)^{-1} \%*\% X</code>
</p>
<p> from </p>
<p style="text-align: center;"><code class="reqn">(I + \rho V + (\rho V)^2 + \dots) \%*\% X</code>
</p>
<p>, which can be done by storing only sparse V and several matrices of the same dimensions as X. This makes it possible to handle larger spatial weights matrices, but is sensitive to the power weights order and the tolerance arguments when the spatial coefficient is close to its bounds, leading to incorrect estimates of the implied inverse matrix.
</p>


<h3>Value</h3>

<p>An nxn matrix with a &quot;call&quot; attribute; the <code>powerWeights</code> function returns a matrix of the same dimensions as X which has been multipled by the power series equivalent of the dense matrix </p>
<p style="text-align: center;"><code class="reqn">(I - \rho V)^{-1}</code>
</p>
<p>.
</p>


<h3>Note</h3>

<p>Before version 0.6-10, <code>powerWeights</code> only worked correctly for positive rho, with differences from true values increasing as rho approached -1, and exploding between -1 and the true negative bound.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Tiefelsdorf, M., Griffith, D. A., Boots, B. 1999 A variance-stabilizing coding scheme for spatial link matrices, Environment and Planning A, 31, pp. 165-180; Tiefelsdorf, M. 2000 Modelling spatial processes, Lecture notes in earth sciences, Springer, p. 76; Haining, R. 1990 Spatial data analysis in the social and environmental sciences, Cambridge University Press, p. 117; Cliff, A. D., Ord, J. K. 1981 Spatial processes, Pion, p. 152; Reder, M. and Mueller, W. (2007) An Improvement of the invIrM Routine of the Geostatistical R-package spdep by Cholesky Inversion, Statistical Projects, LV No: 238.205, SS 2006, Department of Applied Statistics, Johannes Kepler University, Linz</p>


<h3>See Also</h3>

<p><code><a href="spdep.html#topic+nb2listw">nb2listw</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>library(spdep)
nb7rt &lt;- cell2nb(7, 7, torus=TRUE)
lw &lt;- nb2listw(nb7rt, style="W")
set.seed(1)
x &lt;- matrix(sample(rnorm(500*length(nb7rt))), nrow=length(nb7rt))
if (requireNamespace("spatialreg", quietly=TRUE)) {
# Only needed in some simulation settings where the input and
# output distributions must agree in all but autocorrelation
if (FALSE) {
e &lt;- spatialreg::eigenw(lw)
x &lt;- apply(x, 2, scale)
st &lt;- apply(x, 2, function(x) shapiro.test(x)$p.value)
x &lt;- x[, (st &gt; 0.2 &amp; st &lt; 0.8)]
x &lt;- apply(x, 2, function(v) spatialreg::residuals.spautolm(
 spatialreg::spautolm(v ~ 1, listw=lw, method="eigen",
 control=list(pre_eig=e, fdHess=FALSE))))
x &lt;- apply(x, 2, scale)
}
res0 &lt;- apply(invIrM(nb7rt, rho=0.0, method="chol",
 feasible=TRUE) %*% x, 2, function(x) var(x)/length(x))
res2 &lt;- apply(invIrM(nb7rt, rho=0.2, method="chol",
 feasible=TRUE) %*% x, 2, function(x) var(x)/length(x))
res4 &lt;- apply(invIrM(nb7rt, rho=0.4, method="chol",
 feasible=TRUE) %*% x, 2, function(x) var(x)/length(x))
res6 &lt;- apply(invIrM(nb7rt, rho=0.6, method="chol",
 feasible=TRUE) %*% x, 2, function(x) var(x)/length(x))
res8 &lt;- apply(invIrM(nb7rt, rho=0.8, method="chol",
 feasible=TRUE) %*% x, 2, function(x) var(x)/length(x))
res9 &lt;- apply(invIrM(nb7rt, rho=0.9, method="chol",
 feasible=TRUE) %*% x, 2, function(x) var(x)/length(x))
plot(density(res9), col="red", xlim=c(-0.01, max(density(res9)$x)),
  ylim=range(density(res0)$y),
  xlab="estimated variance of the mean",
  main=expression(paste("Effects of spatial autocorrelation for different ",
    rho, " values")))
lines(density(res0), col="black")
lines(density(res2), col="brown")
lines(density(res4), col="green")
lines(density(res6), col="orange")
lines(density(res8), col="pink")
legend(c(-0.02, 0.01), c(7, 25),
 legend=c("0.0", "0.2", "0.4", "0.6", "0.8", "0.9"),
 col=c("black", "brown", "green", "orange", "pink", "red"), lty=1, bty="n")
}
## Not run: 
x &lt;- matrix(rnorm(length(nb7rt)), ncol=1)
system.time(e &lt;- invIrM(nb7rt, rho=0.9, method="chol", feasible=TRUE) %*% x)
system.time(e &lt;- invIrM(nb7rt, rho=0.9, method="chol", feasible=NULL) %*% x)
system.time(e &lt;- invIrM(nb7rt, rho=0.9, method="solve", feasible=TRUE) %*% x)
system.time(e &lt;- invIrM(nb7rt, rho=0.9, method="solve", feasible=NULL) %*% x)

## End(Not run)
</code></pre>

<hr>
<h2 id='lagmess'>Matrix exponential spatial lag model</h2><span id='topic+lagmess'></span><span id='topic+print.Lagmess'></span><span id='topic+print.summary.Lagmess'></span><span id='topic+summary.Lagmess'></span><span id='topic+residuals.Lagmess'></span><span id='topic+deviance.Lagmess'></span><span id='topic+coef.Lagmess'></span><span id='topic+fitted.Lagmess'></span><span id='topic+logLik.Lagmess'></span><span id='topic+LR1.Lagmess'></span><span id='topic+impacts.Lagmess'></span>

<h3>Description</h3>

<p>The function fits a matrix exponential spatial lag model, using <code>optim</code> to find the value of <code>alpha</code>, the spatial coefficient.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagmess(formula, data = list(), listw, zero.policy = NULL, na.action = na.fail,
 q = 10, start = -2.5, control=list(), method="BFGS", verbose=NULL,
 use_expm=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lagmess_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="lagmess_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="lagmess_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>spdep::nb2listw()</code></p>
</td></tr>
<tr><td><code id="lagmess_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE assign NA - causing <code>lagmess()</code> to terminate with an error</p>
</td></tr>
<tr><td><code id="lagmess_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="lagmess_+3A_q">q</code></td>
<td>
<p>default 10; number of powers of the spatial weights to use</p>
</td></tr>
<tr><td><code id="lagmess_+3A_start">start</code></td>
<td>
<p>starting value for numerical optimization, should be a small negative number</p>
</td></tr>
<tr><td><code id="lagmess_+3A_control">control</code></td>
<td>
<p>control parameters passed to <code>optim</code></p>
</td></tr>
<tr><td><code id="lagmess_+3A_method">method</code></td>
<td>
<p>default <code>BFGS</code>, method passed to <code>optim</code></p>
</td></tr>
<tr><td><code id="lagmess_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE report function values during optimization</p>
</td></tr>
<tr><td><code id="lagmess_+3A_use_expm">use_expm</code></td>
<td>
<p>default FALSE; if TRUE use <code>expm::expAtv</code> instead of a truncated power series of W</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The underlying spatial lag model:
</p>
<p style="text-align: center;"><code class="reqn">y = \rho W y + X \beta + \varepsilon</code>
</p>

<p>where <code class="reqn">\rho</code> is the spatial parameter may be fitted by maximum likelihood. In that case, the log likelihood function includes the logarithm of cumbersome Jacobian term <code class="reqn">|I - \rho W|</code>. If we rewrite the model as:
</p>
<p style="text-align: center;"><code class="reqn">S y = X \beta + \varepsilon</code>
</p>

<p>we see that in the ML case <code class="reqn">S y = (I - \rho W) y</code>. If W is row-stochastic, S may be expressed as a linear combination of row-stochastic matrices. By pre-computing the matrix <code class="reqn">[y, Wy, W^2y, ..., W^{q-1}y]</code>, the term <code class="reqn">S y (\alpha)</code> can readily be found by numerical optimization using the matrix exponential approach. <code class="reqn">\alpha</code> and <code class="reqn">\rho</code> are related as <code class="reqn">\rho = 1 - \exp{\alpha}</code>, conditional on the number of matrix power terms taken <code>q</code>.</p>


<h3>Value</h3>

<p>The function returns an object of class <code>Lagmess</code> with components:
</p>
<table>
<tr><td><code>lmobj</code></td>
<td>
<p>the <code>lm</code> object returned after fitting <code>alpha</code></p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the spatial coefficient</p>
</td></tr>
<tr><td><code>alphase</code></td>
<td>
<p>the standard error of the spatial coefficient using the numerical Hessian</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>the value of <code>rho</code> implied by <code>alpha</code></p>
</td></tr>
<tr><td><code>bestmess</code></td>
<td>
<p>the object returned by <code>optim</code></p>
</td></tr>
<tr><td><code>q</code></td>
<td>
<p>the number of powers of the spatial weights used</p>
</td></tr>
<tr><td><code>start</code></td>
<td>
<p>the starting value for numerical optimization used</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>(possibly) named vector of excluded or omitted observations if non-default na.action argument used</p>
</td></tr>
<tr><td><code>nullLL</code></td>
<td>
<p>the log likelihood of the aspatial model for the same data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a> and Eric Blankmeyer</p>


<h3>References</h3>

<p>J. P. LeSage and R. K. Pace (2007) A matrix exponential specification. Journal of Econometrics, 140, 190-214; J. P. LeSage and R. K. Pace (2009) Introduction to Spatial Econometrics. CRC Press, Chapter 9.</p>


<h3>See Also</h3>

<p><code><a href="#topic+lagsarlm">lagsarlm</a></code>, <code><a href="stats.html#topic+optim">optim</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#require(spdep, quietly=TRUE)
data(baltimore, package="spData")
baltimore$AGE &lt;- ifelse(baltimore$AGE &lt; 1, 1, baltimore$AGE)
lw &lt;- spdep::nb2listw(spdep::knn2nb(spdep::knearneigh(cbind(baltimore$X, baltimore$Y), k=7)))
obj1 &lt;- lm(log(PRICE) ~ PATIO + log(AGE) + log(SQFT),
 data=baltimore)
spdep::lm.morantest(obj1, lw)
spdep::lm.LMtests(obj1, lw, test="all")
system.time(obj2 &lt;- lagmess(log(PRICE) ~ PATIO + log(AGE) + log(SQFT), data=baltimore, listw=lw))
(x &lt;- summary(obj2))
coef(x)
has_expm &lt;- require("expm", quietly=TRUE)
if (has_expm) {
system.time(
obj2a &lt;- lagmess(log(PRICE) ~ PATIO + log(AGE) + log(SQFT), data=baltimore, listw=lw, use_expm=TRUE)
)
summary(obj2a)
}
obj3 &lt;- lagsarlm(log(PRICE) ~ PATIO + log(AGE) + log(SQFT), data=baltimore, listw=lw)
summary(obj3)

data(boston, package="spData")
lw &lt;- spdep::nb2listw(boston.soi)
gp2 &lt;- lagsarlm(log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2)
 +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
 data=boston.c, lw, method="Matrix")
summary(gp2)
gp2a &lt;- lagmess(CMEDV ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2)
 +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
 data=boston.c, lw)
summary(gp2a)

</code></pre>

<hr>
<h2 id='lextrB'>Find extreme eigenvalues of binary symmetric spatial weights</h2><span id='topic+lextrB'></span><span id='topic+lextrW'></span><span id='topic+lextrS'></span><span id='topic+l_max'></span>

<h3>Description</h3>

<p>The functions find extreme eigenvalues of binary symmetric spatial weights, when these form planar graphs; general weights are not permiited. <code>l_max</code> finds the largest eigenvalue using Rayleigh quotient methods of any &ldquo;listw&rdquo; object. <code>lextrB</code> first calls <code>l_max</code>, and uses its output to find the smallest eigenvalue in addition for binary symmetric spatial weights. <code>lextrW</code> extends these to find the smallest eigenvalue for intrinsically symmetric row-standardized binary weights matrices (transformed to symmetric through similarity internally). <code>lextrS</code> does the same for variance-stabilized (&ldquo;S&rdquo; style) intrinsically symmetric binary weights matrices (transformed to symmetric through similarity internally).</p>


<h3>Usage</h3>

<pre><code class='language-R'>lextrB(lw, zero.policy = TRUE, control = list())
lextrW(lw, zero.policy=TRUE, control=list())
lextrS(lw, zero.policy=TRUE, control=list())
l_max(lw, zero.policy=TRUE, control=list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lextrB_+3A_lw">lw</code></td>
<td>
<p>a binary symmetric <code>listw</code> object from, for example, <code>nb2listw</code> with style &ldquo;B&rdquo; for <code>lextrB</code>, style &ldquo;W&rdquo; for <code>lextrW</code> and style &ldquo;S&rdquo; for <code>lextrS</code>; for <code>l_max</code>, the object may be asymmetric and does not have to be binary</p>
</td></tr>
<tr><td><code id="lextrB_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without neighbours, if FALSE assign NA</p>
</td></tr>
<tr><td><code id="lextrB_+3A_control">control</code></td>
<td>
<p>a list of control arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The functions return approximations to the extreme eigenvalues with the eigenvectors returned as attributes of this object.
</p>


<h3>Control arguments</h3>


<dl>
<dt>trace</dt><dd><p>report values in while loops, default NULL assuming FALSE; logical</p>
</dd>
<dt>tol</dt><dd><p>tolerance for breaking while loops, default <code>.Machine$double.eps^(1/2)</code>; numeric</p>
</dd>
<dt>maxiter</dt><dd><p>maximum number of iterations in while loops, default <code>6 * (length(lw$neighbours) - 2</code>; integer</p>
</dd>
<dt>useC</dt><dd><p>use C code, default TRUE, logical (not in <code>l_max</code>)</p>
</dd>
</dl>



<h3>Note</h3>

<p>It may be necessary to modify control arguments if warnings about lack of convergence are seen.</p>


<h3>Author(s)</h3>

<p>Roger Bivand, Yongwan Chun, Daniel Griffith</p>


<h3>References</h3>

<p>Griffith, D. A. (2004). Extreme eigenfunctions of adjacency matrices for planar graphs employed in spatial analyses. <em>Linear Algebra and its Applications</em>, 388:201&ndash;219.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(boston, package="spData")
#require(spdep, quietly=TRUE)
ab.listb &lt;- spdep::nb2listw(boston.soi, style="B")
er &lt;- range(eigenw(ab.listb))
er
res_1 &lt;- lextrB(ab.listb)
c(res_1)
run &lt;- FALSE
if (require("RSpectra", quietly=TRUE)) run &lt;- TRUE
if (run) {
B &lt;- as(ab.listb, "CsparseMatrix")
eigs(B, k=1, which="SR")$values
}
if (run) {
eigs(B, k=1, which="LR")$values
}
k5 &lt;- spdep::knn2nb(spdep::knearneigh(boston.utm, k=5))
c(l_max(spdep::nb2listw(k5, style="B")))
max(Re(eigenw(spdep::nb2listw(k5, style="B"))))
c(l_max(spdep::nb2listw(k5, style="C")))
max(Re(eigenw(spdep::nb2listw(k5, style="C"))))
ab.listw &lt;- spdep::nb2listw(boston.soi, style="W")
er &lt;- range(eigenw(similar.listw(ab.listw)))
er
res_1 &lt;- lextrW(ab.listw)
c(res_1)
if (run) {
B &lt;- as(similar.listw(ab.listw), "CsparseMatrix")
eigs(B, k=1, which="SR")$values
}
if (run) {
eigs(B, k=1, which="LR")$values
}
## Not run: 
ab.listw &lt;- spdep::nb2listw(boston.soi, style="S")
er &lt;- range(eigenw(similar.listw(ab.listw)))
er
res_1 &lt;- lextrS(ab.listw)
c(res_1)

## End(Not run)
if (run) {
B &lt;- as(similar.listw(ab.listw), "CsparseMatrix")
eigs(B, k=1, which="SR")$values
}
if (run) {
eigs(B, k=1, which="LR")$values
}
</code></pre>

<hr>
<h2 id='lmSLX'>Spatial Durbin linear (SLX, spatially lagged X) model</h2><span id='topic+lmSLX'></span><span id='topic+create_WX'></span><span id='topic+impacts.SlX'></span><span id='topic+print.WXimpact'></span><span id='topic+summary.WXimpact'></span><span id='topic+print.summary.WXimpact'></span><span id='topic+print.SlX'></span><span id='topic+summary.SlX'></span><span id='topic+print.summary.SlX'></span><span id='topic+predict.SlX'></span>

<h3>Description</h3>

<p><code>lmSLX</code> fits an <code>lm</code> model augmented with the spatially lagged RHS variables, including the lagged intercept when the spatial weights are not row-standardised. <code>create_WX</code> creates spatially lagged RHS variables, and is exposed for use in model fitting functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmSLX(formula, data = list(), listw, na.action, weights=NULL, Durbin=TRUE,
 zero.policy=NULL)
## S3 method for class 'SlX'
print(x, digits = max(3L, getOption("digits") - 3L), ...)
## S3 method for class 'SlX'
summary(object, correlation = FALSE, symbolic.cor = FALSE, ...)
## S3 method for class 'summary.SlX'
print(x, digits = max(3L, getOption("digits") - 3L),
 symbolic.cor = x$symbolic.cor, signif.stars = getOption("show.signif.stars"), ...)
## S3 method for class 'SlX'
impacts(obj, ...)
## S3 method for class 'WXimpact'
print(x, ...)
## S3 method for class 'WXimpact'
summary(object, ..., adjust_k=(attr(object, "type") == "SDEM"))
## S3 method for class 'SlX'
predict(object, newdata, listw, zero.policy=NULL, ...)
create_WX(x, listw, zero.policy=NULL, prefix="")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmSLX_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="lmSLX_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="lmSLX_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the spatial weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process. Non-NULL weights can be used to indicate that different observations have different variances (with the values in weights being inversely proportional to the variances); or equivalently, when the elements of weights are positive integers w_i, that each response y_i is the mean of w_i unit-weight observations (including the case that there are w_i observations equal to y_i and the data have been summarized) - <code><a href="stats.html#topic+lm">lm</a></code></p>
</td></tr>
<tr><td><code id="lmSLX_+3A_durbin">Durbin</code></td>
<td>
<p>default TRUE for <code>lmSLX</code> (Durbin model including WX); if TRUE, full spatial Durbin model; if a formula object, the subset of explanatory variables to lag</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without neighbours, if FALSE assign NA</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_correlation">correlation</code></td>
<td>
<p>logical; if <code>TRUE</code>, the correlation matrix of the estimated parameters is returned and printed</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_symbolic.cor">symbolic.cor</code></td>
<td>
<p>logical. If <code>TRUE</code>, print the correlations in a symbolic form (see 'symnum') rather than as numbers</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical. If <code>TRUE</code>, 'significance stars' are printed for each coefficient</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_obj">obj</code></td>
<td>
<p>A spatial regression object created by <code>lmSLX</code></p>
</td></tr>
<tr><td><code id="lmSLX_+3A_...">...</code></td>
<td>
<p>Arguments passed through</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_prefix">prefix</code></td>
<td>
<p>default empty string, may be &ldquo;lag&rdquo; in some cases</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_x">x</code>, <code id="lmSLX_+3A_object">object</code></td>
<td>
<p>model matrix to be lagged; lagImpact objects created by <code>impacts</code> methods</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_adjust_k">adjust_k</code></td>
<td>
<p>default TRUE if SDEM else FALSE, adjust internal OLS SDEM standard errors by dividing by n rather than (n-k) (default changed and bug fixed after 0.7-8; standard errors now ML in SDEM summary and impacts summary and identical - for SLX use FALSE)</p>
</td></tr>
<tr><td><code id="lmSLX_+3A_newdata">newdata</code></td>
<td>
<p>data frame in which to predict &mdash; if NULL, predictions are
for the data on which the model was fitted. Should have row names corresponding to region.id. If row names are exactly the same than the ones used for training, it uses in-sample predictors for forecast.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>lmSLX</code> function returns an &ldquo;lm&rdquo; object with a &ldquo;mixedImps&rdquo; list of three impact matrixes (impacts and standard errors) for direct, indirect and total impacts; total impacts calculated using a simplified local copy of the estimable function from the gmodels package.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(oldcol, package="spdep")
lw &lt;- spdep::nb2listw(COL.nb, style="W")
COL.SLX &lt;- lmSLX(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw)
summary(COL.SLX)
summary(impacts(COL.SLX))
COL.SLX &lt;- lmSLX(CRIME ~ INC + HOVAL + I(HOVAL^2), data=COL.OLD, listw=lw, Durbin=TRUE)
summary(impacts(COL.SLX))
summary(COL.SLX)
COL.SLX &lt;- lmSLX(CRIME ~ INC + HOVAL + I(HOVAL^2), data=COL.OLD, listw=lw, Durbin=~INC)
summary(impacts(COL.SLX))
summary(COL.SLX)
COL.SLX &lt;- lmSLX(CRIME ~ INC, data=COL.OLD, listw=lw)
summary(COL.SLX)
summary(impacts(COL.SLX))
## Not run: 
crds &lt;- cbind(COL.OLD$X, COL.OLD$Y)
mdist &lt;- sqrt(sum(diff(apply(crds, 2, range))^2))
dnb &lt;- spdep::dnearneigh(crds, 0, mdist)
dists &lt;- spdep::nbdists(dnb, crds)
f &lt;- function(x, form, data, dnb, dists, verbose) {
  glst &lt;- lapply(dists, function(d) 1/(d^x))
  lw &lt;- spdep::nb2listw(dnb, glist=glst, style="B")
  res &lt;- logLik(lmSLX(form=form, data=data, listw=lw))
  if (verbose) cat("power:", x, "logLik:", res, "\n")
  res
}
opt &lt;- optimize(f, interval=c(0.1, 4), form=CRIME ~ INC + HOVAL,
 data=COL.OLD, dnb=dnb, dists=dists, verbose=TRUE, maximum=TRUE)
glst &lt;- lapply(dists, function(d) 1/(d^opt$maximum))
lw &lt;- spdep::nb2listw(dnb, glist=glst, style="B")
SLX &lt;- lmSLX(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw)
summary(SLX)
summary(impacts(SLX))

## End(Not run)
COL.SLX &lt;- lmSLX(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw)
pslx0 &lt;- predict(COL.SLX)
pslx1 &lt;- predict(COL.SLX, newdata=COL.OLD, listw=lw)
all.equal(pslx0, pslx1)
COL.OLD1 &lt;- COL.OLD
COL.OLD1$INC &lt;- COL.OLD1$INC + 1
pslx2 &lt;- predict(COL.SLX, newdata=COL.OLD1, listw=lw)
sum(coef(COL.SLX)[c(2,4)])
mean(pslx2-pslx1)
</code></pre>

<hr>
<h2 id='LR.Sarlm'>Likelihood ratio test</h2><span id='topic+LR.Sarlm'></span><span id='topic+LR1.Sarlm'></span><span id='topic+Wald1.Sarlm'></span><span id='topic+Hausman.test'></span><span id='topic+Hausman.test.Sarlm'></span><span id='topic+logLik.Sarlm'></span><span id='topic+anova.Sarlm'></span><span id='topic+bptest.Sarlm'></span><span id='topic+impacts.Sarlm'></span>

<h3>Description</h3>

<p>The <code>LR.Sarlm()</code> function provides a likelihood ratio test for objects for which a <code>logLik()</code> function exists for their class, or for objects of class <code>logLik</code>. <code>LR1.Sarlm()</code> and <code>Wald1.Sarlm()</code> are used internally in <code>summary.Sarlm()</code>, but may be accessed directly; they report the values respectively of LR and Wald tests for the absence of spatial dependence in spatial lag or error models. The spatial Hausman test is available for models fitted with <code>errorSarlm</code> and <code>GMerrorsar</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LR.Sarlm(x, y)
## S3 method for class 'Sarlm'
logLik(object, ...)
LR1.Sarlm(object)
Wald1.Sarlm(object)
## S3 method for class 'Sarlm'
Hausman.test(object, ..., tol=NULL)
## S3 method for class 'Sarlm'
anova(object, ...)
bptest.Sarlm(object, varformula=NULL, studentize = TRUE, data=list())
## S3 method for class 'Sarlm'
impacts(obj, ..., tr, R = NULL, listw = NULL, evalues=NULL,
 useHESS = NULL, tol = 1e-06, empirical = FALSE, Q=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LR.Sarlm_+3A_x">x</code></td>
<td>
<p>a <code>logLik</code> object or an object for which a <code>logLik()</code> function exists</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_y">y</code></td>
<td>
<p>a <code>logLik</code> object or an object for which a <code>logLik()</code> function exists</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_object">object</code>, <code id="LR.Sarlm_+3A_obj">obj</code></td>
<td>
<p>a <code>Sarlm</code> object</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>

<tr><td><code id="LR.Sarlm_+3A_varformula">varformula</code></td>
<td>
<p>a formula describing only the potential explanatory variables for the variance (no dependent variable needed). By default the same explanatory variables are taken as in the main regression model</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_studentize">studentize</code></td>
<td>
<p>logical. If set to <code>TRUE</code> Koenker's studentized
version of the test statistic will be used.</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the varformula</p>
</td></tr>  <tr><td><code id="LR.Sarlm_+3A_tr">tr</code></td>
<td>
<p>A vector of traces of powers of the spatial weights matrix created using <code>trW</code>, for approximate impact measures; if not given, <code>listw</code> must be given for exact measures (for small to moderate spatial weights matrices); the traces must be for the same spatial weights as were used in fitting the spatial regression, and must be row-standardised</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_listw">listw</code></td>
<td>
<p>If <code>tr</code> is not given, a spatial weights object as created by <code>nb2listw</code>; they must be the same spatial weights as were used in fitting the spatial regression, but do not have to be row-standardised</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_evalues">evalues</code></td>
<td>
<p>vector of eigenvalues of spatial weights matrix for impacts calculations</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_r">R</code></td>
<td>
<p>If given, simulations are used to compute distributions for the impact measures, returned as <code>mcmc</code> objects; the objects are used for convenience but are not output by an MCMC process</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_usehess">useHESS</code></td>
<td>
<p>Use the Hessian approximation (if available) even if the asymptotic coefficient covariance matrix is available; used for comparing methods</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_tol">tol</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code> and <code>solve</code>: tolerance (relative to largest variance) for numerical lack of positive-definiteness in the coefficient covariance matrix</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_empirical">empirical</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code> (default FALSE): if true, the coefficients and their covariance matrix specify the empirical not population mean and covariance matrix</p>
</td></tr>
<tr><td><code id="LR.Sarlm_+3A_q">Q</code></td>
<td>
<p>default NULL, else an integer number of cumulative power series impacts to calculate if <code>tr</code> is given</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The tests return objects of class <code>htest</code> with:
</p>
<table>
<tr><td><code>statistic</code></td>
<td>
<p>value of statistic</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>Probability value</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>varies with test</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>description of test method</p>
</td></tr>
</table>
<p><code>logLik.Sarlm()</code> returns an object of class <code>logLik</code>
<code>LR1.Sarlm</code>, <code>Hausman.Sarlm</code> and <code>Wald1.Sarlm</code> returm objects of class <code>htest</code>
</p>


<h3>Note</h3>

<p>The numbers of degrees of freedom returned by <code>logLik.Sarlm()</code> include nuisance parameters, that is the number of regression coefficients, plus sigma, plus spatial parameter esitmate(s).</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a>, <code>bptest</code>: Torsten Hothorn and Achim Zeileis, modified by Roger Bivand</p>


<h3>References</h3>

<p>LeSage J and RK Pace (2009) Introduction to Spatial Econometrics. CRC Press, Boca Raton, pp. 61&ndash;63; Pace RK and LeSage J (2008) A spatial Hausman test. <em>Economics Letters</em> 101, 282&ndash;284.
T.S. Breusch &amp; A.R. Pagan (1979),
A Simple Test for Heteroscedasticity and Random Coefficient Variation.
<em>Econometrica</em> <b>47</b>, 1287&ndash;1294
</p>
<p>W. Krämer &amp; H. Sonnberger (1986),
<em>The Linear Regression Model under Test</em>. Heidelberg: Physica.
</p>
<p>L. Anselin (1988) <em>Spatial econometrics: methods and models.</em>
Dordrecht: Kluwer, pp. 121&ndash;122.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+logLik.lm">logLik.lm</a></code>, <code><a href="#topic+anova.Sarlm">anova.Sarlm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("sf", quietly=TRUE)
columbus &lt;- st_read(system.file("shapes/columbus.shp", package="spData")[1], quiet=TRUE)
#require("spdep", quietly=TRUE)
col.gal.nb &lt;- spdep::read.gal(system.file("weights/columbus.gal", package="spData")[1])
lm.mod &lt;- lm(CRIME ~ HOVAL + INC, data=columbus)
lag &lt;- lagsarlm(CRIME ~ HOVAL + INC, data=columbus, spdep::nb2listw(col.gal.nb))
mixed &lt;- lagsarlm(CRIME ~ HOVAL + INC, data=columbus, spdep::nb2listw(col.gal.nb), type="mixed")
error &lt;- errorsarlm(CRIME ~ HOVAL + INC, data=columbus, spdep::nb2listw(col.gal.nb))
Hausman.test(error)
LR.Sarlm(mixed, error)
anova(lag, lm.mod)
anova(lag, error, mixed)
AIC(lag, error, mixed)
bptest.Sarlm(error)
bptest.Sarlm(error, studentize=FALSE)
</code></pre>

<hr>
<h2 id='MCMCsamp'>MCMC sample from fitted spatial regression</h2><span id='topic+MCMCsamp'></span><span id='topic+MCMCsamp.Spautolm'></span><span id='topic+MCMCsamp.Sarlm'></span>

<h3>Description</h3>

<p>The <code>MCMCsamp</code> method uses <code><a href="LearnBayes.html#topic+rwmetrop">rwmetrop</a></code>, a random walk Metropolis algorithm, from <span class="pkg">LearnBayes</span> to make MCMC samples from fitted maximum likelihood spatial regression models.</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCMCsamp(object, mcmc = 1L, verbose = NULL, ...)
## S3 method for class 'Spautolm'
MCMCsamp(object, mcmc = 1L, verbose = NULL, ...,
 burnin = 0L, scale=1, listw, control = list())
## S3 method for class 'Sarlm'
MCMCsamp(object, mcmc = 1L, verbose = NULL, ...,
    burnin=0L, scale=1, listw, listw2=NULL, control=list())</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCMCsamp_+3A_object">object</code></td>
<td>
<p>A spatial regression model object fitted by maximum likelihood with <code><a href="#topic+spautolm">spautolm</a></code></p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_mcmc">mcmc</code></td>
<td>
<p>The number of MCMC iterations after burnin</p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE, reports progress</p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_...">...</code></td>
<td>
<p>Arguments passed through</p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_burnin">burnin</code></td>
<td>
<p>The number of burn-in iterations for the sampler</p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_scale">scale</code></td>
<td>
<p>a positive scale parameter</p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_listw">listw</code>, <code id="MCMCsamp_+3A_listw2">listw2</code></td>
<td>
<p><code>listw</code> objects created for example by <code>nb2listw</code>; should be the same object(s) used for fitting the model</p>
</td></tr>
<tr><td><code id="MCMCsamp_+3A_control">control</code></td>
<td>
<p>list of extra control arguments - see <code><a href="#topic+spautolm">spautolm</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &ldquo;mcmc&rdquo; suited to <span class="pkg">coda</span>, with attributes: &ldquo;accept&rdquo; acceptance rate; &ldquo;type&rdquo; input ML fitted model type &ldquo;SAR&rdquo;, &ldquo;CAR&rdquo;, &ldquo;SMA&rdquo;, &ldquo;lag&rdquo;, &ldquo;mixed&rdquo;, &ldquo;error&rdquo;, &ldquo;sac&rdquo;, &ldquo;sacmixed&rdquo;; &ldquo;timings&rdquo; run times</p>


<h3>Note</h3>

<p>If the acceptance rate is below 0.05, a warning will be issued; consider increasing mcmc.</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Jim Albert (2007) Bayesian Computation with R, Springer, New York, pp. 104-105.</p>


<h3>See Also</h3>

<p><code><a href="LearnBayes.html#topic+rwmetrop">rwmetrop</a></code>, <code><a href="#topic+spautolm">spautolm</a></code>, <code><a href="#topic+lagsarlm">lagsarlm</a></code>, <code><a href="#topic+errorsarlm">errorsarlm</a></code>, <code><a href="#topic+sacsarlm">sacsarlm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("sf", quietly=TRUE)
nydata &lt;- st_read(system.file("shapes/NY8_bna_utm18.gpkg", package="spData")[1], quiet=TRUE)
suppressMessages(nyadjmat &lt;- as.matrix(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1])[-1]))
suppressMessages(ID &lt;- as.character(names(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1]))[-1]))
identical(substring(ID, 2, 10), substring(as.character(nydata$AREAKEY), 2, 10))
#require("spdep", quietly=TRUE)
nyadjlw &lt;- spdep::mat2listw(nyadjmat, as.character(nydata$AREAKEY))
listw_NY &lt;- spdep::nb2listw(nyadjlw$neighbours, style="B")
esar1f &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, family="SAR", method="eigen")
summary(esar1f)
res &lt;- MCMCsamp(esar1f, mcmc=1000, burnin=200, listw=listw_NY)
summary(res)
## Not run: 
esar1fw &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="SAR", method="eigen")
summary(esar1fw)
res &lt;- MCMCsamp(esar1fw, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
ecar1f &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, family="CAR", method="eigen")
summary(ecar1f)
res &lt;- MCMCsamp(ecar1f, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
esar1fw &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="SAR", method="eigen")
summary(esar1fw)
res &lt;- MCMCsamp(esar1fw, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
ecar1fw &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="CAR", method="eigen")
summary(ecar1fw)
res &lt;- MCMCsamp(ecar1fw, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)

## End(Not run)
esar0 &lt;- errorsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY)
summary(esar0)
res &lt;- MCMCsamp(esar0, mcmc=1000, burnin=200, listw=listw_NY)
summary(res)
## Not run: 
esar0w &lt;- errorsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8)
summary(esar0)
res &lt;- MCMCsamp(esar0w, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
esar1 &lt;- errorsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, etype="emixed")
summary(esar1)
res &lt;- MCMCsamp(esar1, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
lsar0 &lt;- lagsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY)
summary(lsar0)
res &lt;- MCMCsamp(lsar0, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
lsar1 &lt;- lagsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, type="mixed")
summary(lsar1)
res &lt;- MCMCsamp(lsar1, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
ssar0 &lt;- sacsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY)
summary(ssar0)
res &lt;- MCMCsamp(ssar0, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)
ssar1 &lt;- sacsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, type="sacmixed")
summary(ssar1)
res &lt;- MCMCsamp(ssar1, mcmc=5000, burnin=500, listw=listw_NY)
summary(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='ME'>Moran eigenvector GLM filtering</h2><span id='topic+ME'></span><span id='topic+print.Me_res'></span><span id='topic+fitted.Me_res'></span>

<h3>Description</h3>

<p>The Moran eigenvector filtering function is intended to remove spatial autocorrelation from the residuals of generalised linear models. It uses brute force eigenvector selection to reach a subset of such vectors to be added to the RHS of the GLM model to reduce residual autocorrelation to below the specified alpha value. Since eigenvector selection only works on symmetric weights, the weights are made symmetric before the eigenvectors are found (from spdep 0.5-50).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ME(formula, data=list(), family = gaussian, weights, offset,
 na.action=na.fail,listw=NULL, alpha=0.05, nsim=99, verbose=NULL,
 stdev=FALSE, zero.policy=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ME_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit</p>
</td></tr>
<tr><td><code id="ME_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="ME_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model</p>
</td></tr>
<tr><td><code id="ME_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process</p>
</td></tr>
<tr><td><code id="ME_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be included in the linear predictor during fitting</p>
</td></tr>
<tr><td><code id="ME_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the spatial weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="ME_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="ME_+3A_alpha">alpha</code></td>
<td>
<p>used as a stopping rule to choose all eigenvectors up to and including the one with a p-value exceeding alpha</p>
</td></tr>
<tr><td><code id="ME_+3A_nsim">nsim</code></td>
<td>
<p>number of permutations for permutation bootstrap for finding p-values</p>
</td></tr>
<tr><td><code id="ME_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE report eigenvectors selected</p>
</td></tr>
<tr><td><code id="ME_+3A_stdev">stdev</code></td>
<td>
<p>if TRUE, p-value calculated from bootstrap permutation standard deviate using <code>pnorm</code> with alternative=&quot;greater&quot;, if FALSE the Hope-type p-value</p>
</td></tr>
<tr><td><code id="ME_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if FALSE stop with error for any empty neighbour sets, if TRUE permit the weights list to be formed with zero-length weights vectors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The eigenvectors for inclusion are chosen by calculating the empirical Moran's I values for the initial model plus each of the doubly centred symmetric spatial weights matrix eigenvectors in turn. Then the first eigenvector is chosen as that with the lowest Moran's I value. The procedure is repeated until the lowest remaining Moran's I value has a permutation-based probability value above alpha. The probability value is either Hope-type or based on using the mean and standard deviation of the permutations to calculate ZI based on the stdev argument.
</p>


<h3>Value</h3>

<p>An object of class <code>Me_res</code>:
</p>
<table>
<tr><td><code>selection</code></td>
<td>
<p>a matrix summarising the selection of eigenvectors for inclusion, with columns:
</p>

<dl>
<dt>Eigenvector</dt><dd><p>number of selected eigenvector</p>
</dd>
<dt>ZI</dt><dd><p>permutation-based standardized deviate of Moran's I if stdev=TRUE</p>
</dd>
<dt>pr(ZI)</dt><dd><p>probability value: if stdev=TRUE of the permutation-based standardized deviate, if FALSE the Hope-type probability value, in both cases on-sided</p>
</dd>
</dl>

<p>The first row is the value at the start of the search
</p>
</td></tr>
<tr><td><code>vectors</code></td>
<td>
<p>a matrix of the selected eigenvectors in order of selection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Bivand and Pedro Peres-Neto</p>


<h3>References</h3>

<p>Dray S, Legendre P and Peres-Neto PR (2005) Spatial modeling: a comprehensive framework for principle coordinate analysis of neigbbor matrices (PCNM), Ecological Modelling; Griffith DA and Peres-Neto PR (2006) Spatial modeling in ecology: the flexibility of eigenfunction spatial analyses.</p>


<h3>See Also</h3>

<p><code><a href="#topic+SpatialFiltering">SpatialFiltering</a></code>, <code><a href="stats.html#topic+glm">glm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#require("spdep", quietly=TRUE)
data(hopkins, package="spData")
hopkins_part &lt;- hopkins[21:36,36:21]
hopkins_part[which(hopkins_part &gt; 0, arr.ind=TRUE)] &lt;- 1
hopkins.rook.nb &lt;- spdep::cell2nb(16, 16, type="rook")
glmbase &lt;- glm(c(hopkins_part) ~ 1, family="binomial")
lw &lt;- spdep::nb2listw(hopkins.rook.nb, style="B")
set.seed(123)
system.time(MEbinom1 &lt;- ME(c(hopkins_part) ~ 1, family="binomial",
 listw=lw, alpha=0.05, verbose=TRUE, nsim=49))
glmME &lt;- glm(c(hopkins_part) ~ 1 + fitted(MEbinom1), family="binomial")
#anova(glmME, test="Chisq")
coef(summary(glmME))
anova(glmbase, glmME, test="Chisq")
## Not run: 
require("sf", quietly=TRUE)
columbus &lt;- st_read(system.file("shapes/columbus.shp", package="spData")[1], quiet=TRUE)
#require("spdep", quietly=TRUE)
col.gal.nb &lt;- spdep::read.gal(system.file("weights/columbus.gal", package="spData")[1])
lw &lt;- spdep::nb2listw(col.gal.nb)
lmbase &lt;- lm(CRIME ~ INC + HOVAL, data=columbus)
lagcol &lt;- SpatialFiltering(CRIME ~ 1, ~ INC + HOVAL, data=columbus,
 nb=col.gal.nb, style="W", alpha=0.1, verbose=TRUE)
lagcol
lmlag &lt;- lm(CRIME ~ INC + HOVAL + fitted(lagcol), data=columbus)
anova(lmbase, lmlag)
set.seed(123)
system.time(lagcol1 &lt;- ME(CRIME ~ INC + HOVAL, data=columbus, family="gaussian",
 listw=lw, alpha=0.1, verbose=TRUE))
lagcol1
lmlag1 &lt;- lm(CRIME ~ INC + HOVAL + fitted(lagcol1), data=columbus)
anova(lmbase, lmlag1)

set.seed(123)
lagcol2 &lt;- ME(CRIME ~ INC + HOVAL, data=columbus, family="gaussian",
 listw=lw, alpha=0.1, stdev=TRUE, verbose=TRUE)
lagcol2
lmlag2 &lt;- lm(CRIME ~ INC + HOVAL + fitted(lagcol2), data=columbus)
anova(lmbase, lmlag2)
NA.columbus &lt;- columbus
NA.columbus$CRIME[20:25] &lt;- NA
COL.ME.NA &lt;- ME(CRIME ~ INC + HOVAL, data=NA.columbus, family="gaussian",
 listw=lw, alpha=0.1, stdev=TRUE, verbose=TRUE,
 na.action=na.exclude)
COL.ME.NA$na.action
summary(lm(CRIME ~ INC + HOVAL + fitted(COL.ME.NA), data=NA.columbus,
 na.action=na.exclude))
nc.sids &lt;- st_read(system.file("shapes/sids.shp", package="spData")[1], quiet=TRUE)
rn &lt;- as.character(nc.sids$FIPS)
ncCC89_nb &lt;- spdep::read.gal(system.file("weights/ncCC89.gal", package="spData")[1],
 region.id=rn)
ncCR85_nb &lt;- spdep::read.gal(system.file("weights/ncCR85.gal", package="spData")[1],
 region.id=rn)
glmbase &lt;- glm(SID74 ~ 1, data=nc.sids, offset=log(BIR74),
 family="poisson")
set.seed(123)
MEpois1 &lt;- ME(SID74 ~ 1, data=nc.sids, offset=log(BIR74),
 family="poisson", listw=spdep::nb2listw(ncCR85_nb, style="B"), alpha=0.2, verbose=TRUE)
MEpois1
glmME &lt;- glm(SID74 ~ 1 + fitted(MEpois1), data=nc.sids, offset=log(BIR74),
 family="poisson")
anova(glmME, test="Chisq")
anova(glmbase, glmME, test="Chisq")

## End(Not run)
</code></pre>

<hr>
<h2 id='ML_models'>Spatial simultaneous autoregressive model estimation by maximum likelihood</h2><span id='topic+lagsarlm'></span><span id='topic+errorsarlm'></span><span id='topic+sacsarlm'></span><span id='topic+summary.Sarlm'></span><span id='topic+print.Sarlm'></span><span id='topic+print.summary.Sarlm'></span><span id='topic+residuals.Sarlm'></span><span id='topic+deviance.Sarlm'></span><span id='topic+coef.Sarlm'></span><span id='topic+vcov.Sarlm'></span><span id='topic+fitted.Sarlm'></span>

<h3>Description</h3>

<p>The <code>lagsarlm</code> function provides Maximum likelihood estimation of spatial simultaneous autoregressive lag and spatial Durbin (mixed) models of the form:
</p>
<p style="text-align: center;"><code class="reqn">y = \rho W y + X \beta + \varepsilon</code>
</p>

<p>where <code class="reqn">\rho</code> is found by <code>optimize()</code> first, and <code class="reqn">\beta</code> and other parameters by generalized least squares subsequently (one-dimensional search using optim performs badly on some platforms). In the spatial Durbin (mixed) model, the spatially lagged independent variables are added to X. Note that interpretation of the fitted coefficients should use impact measures, because of the feedback loops induced by the data generation process for this model. With one of the sparse matrix methods, larger numbers of observations can be handled, but the <code>interval=</code> argument may need be set when the weights are not row-standardised.
</p>
<p>Maximum likelihood estimation of spatial simultaneous autoregressive
error models of the form:
</p>
<p style="text-align: center;"><code class="reqn">y = X \beta + u, u = \lambda W u + \varepsilon</code>
</p>

<p>where <code class="reqn">\lambda</code> is found by <code>optimize()</code> first, and <code class="reqn">\beta</code> and other parameters by generalized least squares subsequently. With one of the sparse matrix methods, larger numbers of observations can be handled, but the <code>interval=</code> argument may need be set when the weights are not row-standardised. When <code>etype</code> is &ldquo;emixed&rdquo;, a so-called spatial Durbin error model is fitted.
</p>
<p>Maximum likelihood estimation of spatial simultaneous autoregressive
&ldquo;SAC/SARAR&rdquo; models of the form:
</p>
<p style="text-align: center;"><code class="reqn">y = \rho W1 y + X \beta + u, u = \lambda W2 u + \varepsilon</code>
</p>

<p>where <code class="reqn">\rho</code> and <code class="reqn">\lambda</code> are found by <code>nlminb</code> or <code>optim()</code> first, and <code class="reqn">\beta</code> and other parameters by generalized least squares subsequently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagsarlm(formula, data = list(), listw, na.action, Durbin, type,
 method="eigen", quiet=NULL, zero.policy=NULL, interval=NULL,
 tol.solve=.Machine$double.eps, trs=NULL, control=list())
errorsarlm(formula, data=list(), listw, na.action, weights=NULL,
 Durbin, etype, method="eigen", quiet=NULL, zero.policy=NULL,
 interval = NULL, tol.solve=.Machine$double.eps, trs=NULL, control=list())
sacsarlm(formula, data = list(), listw, listw2 = NULL, na.action, Durbin, type,
 method="eigen", quiet=NULL, zero.policy=NULL, tol.solve=.Machine$double.eps,
 llprof=NULL, interval1=NULL, interval2=NULL, trs1=NULL, trs2=NULL,
 control = list())
## S3 method for class 'Sarlm'
summary(object, correlation = FALSE, Nagelkerke = FALSE,
 Hausman=FALSE, adj.se=FALSE, ...)
## S3 method for class 'Sarlm'
print(x, ...)
## S3 method for class 'summary.Sarlm'
print(x, digits = max(5, .Options$digits - 3),
 signif.stars = FALSE, ...)
## S3 method for class 'Sarlm'
residuals(object, ...)
## S3 method for class 'Sarlm'
deviance(object, ...)
## S3 method for class 'Sarlm'
coef(object, ...)
## S3 method for class 'Sarlm'
vcov(object, ...)
## S3 method for class 'Sarlm'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ML_models_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="ML_models_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="ML_models_+3A_listw">listw</code>, <code id="ML_models_+3A_listw2">listw2</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code>; if <code>nb2listw</code> not given, set to the same spatial weights as the <code>listw</code> argument</p>
</td></tr>
<tr><td><code id="ML_models_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="ML_models_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process. Non-NULL weights can be used to indicate that different observations have different variances (with the values in weights being inversely proportional to the variances); or equivalently, when the elements of weights are positive integers w_i, that each response y_i is the mean of w_i unit-weight observations (including the case that there are w_i observations equal to y_i and the data have been summarized) - <code><a href="stats.html#topic+lm">lm</a></code></p>
</td></tr>
<tr><td><code id="ML_models_+3A_durbin">Durbin</code></td>
<td>
<p>default FALSE (spatial lag model); if TRUE, full spatial Durbin model; if a formula object, the subset of explanatory variables to lag</p>
</td></tr>
<tr><td><code id="ML_models_+3A_type">type</code></td>
<td>
<p>(use the &lsquo;Durbin=&rsquo; argument - retained for backwards compatibility only) default &quot;lag&quot;, may be set to &quot;mixed&quot;; when &quot;mixed&quot;, the lagged intercept is dropped for spatial weights style &quot;W&quot;, that is row-standardised weights, but otherwise included; &ldquo;Durbin&rdquo; may be used instead of &ldquo;mixed&rdquo;</p>
</td></tr>
<tr><td><code id="ML_models_+3A_etype">etype</code></td>
<td>
<p>(use the &lsquo;Durbin=&rsquo; argument - retained for backwards compatibility only) default &quot;error&quot;, may be set to &quot;emixed&quot; to include the spatially lagged independent variables added to X; when &quot;emixed&quot;, the lagged intercept is dropped for spatial weights style &quot;W&quot;, that is row-standardised weights, but otherwise included</p>
</td></tr>
<tr><td><code id="ML_models_+3A_method">method</code></td>
<td>
<p>&quot;eigen&quot; (default) - the Jacobian is computed as the product 
of (1 - rho*eigenvalue) using <code>eigenw</code>, and &quot;spam&quot; or &quot;Matrix_J&quot; for strictly symmetric weights lists of styles &quot;B&quot; and &quot;C&quot;, or made symmetric by similarity (Ord, 1975, Appendix C) if possible for styles &quot;W&quot; and &quot;S&quot;, using code from the spam or Matrix packages to calculate the determinant; &ldquo;Matrix&rdquo; and &ldquo;spam_update&rdquo; provide updating Cholesky decomposition methods; &quot;LU&quot; provides an alternative sparse matrix decomposition approach. In addition, there are &quot;Chebyshev&quot; and Monte Carlo &quot;MC&quot; approximate log-determinant methods; the Smirnov/Anselin (2009) trace approximation is available as &quot;moments&quot;. Three methods: &quot;SE_classic&quot;, &quot;SE_whichMin&quot;, and &quot;SE_interp&quot; are provided experimentally, the first to attempt to emulate the behaviour of Spatial Econometrics toolbox ML fitting functions. All use grids of log determinant values, and the latter two attempt to ameliorate some features of &quot;SE_classic&quot;.
</p>
</td></tr>
<tr><td><code id="ML_models_+3A_quiet">quiet</code></td>
<td>
<p>default NULL, use !verbose global option value; if FALSE, reports function values during optimization.</p>
</td></tr>
<tr><td><code id="ML_models_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE (default) assign NA - causing <code>lagsarlm()</code> to terminate with an error</p>
</td></tr>
<tr><td><code id="ML_models_+3A_interval">interval</code></td>
<td>
<p>default is NULL, search interval for autoregressive parameter</p>
</td></tr>
<tr><td><code id="ML_models_+3A_tol.solve">tol.solve</code></td>
<td>
<p>the tolerance for detecting linear dependencies in the columns of matrices to be inverted - passed to <code>solve()</code> (default=1.0e-10). This may be used if necessary to extract coefficient standard errors (for instance lowering to 1e-12), but errors in <code>solve()</code> may constitute indications of poorly scaled variables: if the variables have scales differing much from the autoregressive coefficient, the values in this matrix may be very different in scale, and inverting such a matrix is analytically possible by definition, but numerically unstable; rescaling the RHS variables alleviates this better than setting tol.solve to a very small value</p>
</td></tr>
<tr><td><code id="ML_models_+3A_llprof">llprof</code></td>
<td>
<p>default NULL, can either be an integer, to divide the feasible ranges into a grid of points, or a two-column matrix of spatial coefficient values, at which to evaluate the likelihood function</p>
</td></tr>
<tr><td><code id="ML_models_+3A_trs1">trs1</code>, <code id="ML_models_+3A_trs2">trs2</code></td>
<td>
<p>default NULL, if given, vectors for each weights object of powered spatial weights matrix traces output by <code>trW</code>; when given, used in some Jacobian methods</p>
</td></tr>
<tr><td><code id="ML_models_+3A_interval1">interval1</code>, <code id="ML_models_+3A_interval2">interval2</code></td>
<td>
<p>default is NULL, search intervals for each weights object for autoregressive parameters</p>
</td></tr>
<tr><td><code id="ML_models_+3A_trs">trs</code></td>
<td>
<p>default NULL, if given, a vector of powered spatial weights matrix traces output by <code>trW</code>; when given, insert the asymptotic analytical values into the numerical Hessian instead of the approximated values; may be used to get around some problems raised when the numerical Hessian is poorly conditioned, generating NaNs in subsequent operations; the use of trs is recommended</p>
</td></tr>
<tr><td><code id="ML_models_+3A_control">control</code></td>
<td>
<p>list of extra control arguments - see section below</p>
</td></tr>
<tr><td><code id="ML_models_+3A_object">object</code></td>
<td>
<p><code>Sarlm</code> object from <code>lagsarlm</code>, <code>errorsarlm</code> or <code>sacsarlm</code></p>
</td></tr>
<tr><td><code id="ML_models_+3A_correlation">correlation</code></td>
<td>
<p>logical; if 'TRUE', the correlation matrix of the estimated parameters including sigma is returned and printed (default=FALSE)</p>
</td></tr>
<tr><td><code id="ML_models_+3A_nagelkerke">Nagelkerke</code></td>
<td>
<p>if TRUE, the Nagelkerke pseudo R-squared is reported</p>
</td></tr>
<tr><td><code id="ML_models_+3A_hausman">Hausman</code></td>
<td>
<p>if TRUE, the results of the Hausman test for error models are reported</p>
</td></tr>
<tr><td><code id="ML_models_+3A_adj.se">adj.se</code></td>
<td>
<p>if TRUE, adjust the coefficient standard errors for the number of fitted coefficients</p>
</td></tr>
<tr><td><code id="ML_models_+3A_x">x</code></td>
<td>
<p><code>Sarlm</code> object from <code>lagsarlm</code>, <code>errorsarlm</code> or <code>sacsarlm</code> in <code>print.Sarlm</code>, summary object from <code>summary.Sarlm</code> for 
<code>print.summary.Sarlm</code></p>
</td></tr>
<tr><td><code id="ML_models_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing</p>
</td></tr>
<tr><td><code id="ML_models_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical. If TRUE, &quot;significance stars&quot; are printed
for each coefficient.</p>
</td></tr>
<tr><td><code id="ML_models_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The asymptotic standard error of <code class="reqn">\rho</code> is only computed when
method=&ldquo;eigen&rdquo;, because the full matrix operations involved would be costly
for large n typically associated with the choice of method=&quot;spam&quot; or &quot;Matrix&quot;. The same applies to the coefficient covariance matrix. Taken as the
asymptotic matrix from the literature, it is typically badly scaled, and with the elements involving <code class="reqn">\rho</code> (lag model) or <code class="reqn">\lambda</code> (error model) being very small,
while other parts of the matrix can be very large (often many orders
of magnitude in difference). It often happens that the <code>tol.solve</code>
argument needs to be set to a smaller value than the default, or the RHS variables can be centred or reduced in range.
</p>
<p>Versions of the package from 0.4-38 include numerical Hessian values where asymptotic standard errors are not available. This change has been introduced to permit the simulation of distributions for impact measures. The warnings made above with regard to variable scaling also apply in this case.
</p>
<p>Note that the fitted() function for the output object assumes that the response 
variable may be reconstructed as the sum of the trend, the signal, and the
noise (residuals). Since the values of the response variable are known,
their spatial lags are used to calculate signal components (Cressie 1993, 
p. 564). This differs from other software, including GeoDa, which does not use 
knowledge of the response variable in making predictions for the fitting data. 
Refer to the help page of <code><a href="#topic+predict.Sarlm">predict.Sarlm</a></code> for discussions and 
references.
</p>
<p>Because numerical optimisation is used to find the values of lambda and rho in <code>sacsarlm</code>, care needs to be shown. It has been found that the surface of the 2D likelihood function often forms a &ldquo;banana trench&rdquo; from (low rho, high lambda) through (high rho, high lambda) to (high rho, low lambda) values. In addition, sometimes the banana has optima towards both ends, one local, the other global, and conseqently the choice of the starting point for the final optimization becomes crucial. The default approach is not to use just (0, 0) as a starting point, nor the (rho, lambda) values from <code>gstsls</code>, which lie in a central part of the &ldquo;trench&rdquo;, but either four values at (low rho, high lambda), (0, 0), (high rho, high lambda), and (high rho, low lambda), and to use the best of these start points for the final optimization. Optionally, nine points can be used spanning the whole (lower, upper) space.
</p>


<h3>Control arguments</h3>


<dl>
<dt>tol.opt:</dt><dd><p>the desired accuracy of the optimization - passed to <code>optimize()</code> (default=square root of double precision machine tolerance, a larger root may be used needed, see help(boston) for an example)</p>
</dd>
<dt>returnHcov:</dt><dd><p>(error model) default TRUE, return the Vo matrix for a spatial Hausman test</p>
</dd>
<dt>pWOrder:</dt><dd><p>(error model) default 250, if returnHcov=TRUE and the method is not &ldquo;eigen&rdquo;, pass this order to <code>powerWeights</code> as the power series maximum limit</p>
</dd>
<dt>fdHess:</dt><dd><p>default NULL, then set to (method != &quot;eigen&quot;) internally; use <code>fdHess</code> to compute an approximate Hessian using finite differences when using sparse matrix methods; used to make a coefficient covariance matrix when the number of observations is large; may be turned off to save resources if need be</p>
</dd>
<dt>optimHess:</dt><dd><p>default FALSE, use <code>fdHess</code> from <span class="pkg">nlme</span>, if TRUE, use <code>optim</code> to calculate Hessian at optimum</p>
</dd>
<dt>optimHessMethod:</dt><dd><p>default &ldquo;optimHess&rdquo;, may be &ldquo;nlm&rdquo; or one of the <code>optim</code> methods</p>
</dd>
<dt>compiled_sse:</dt><dd><p>default FALSE; logical value used in the log likelihood function to choose compiled code for computing SSE</p>
</dd>
<dt>Imult:</dt><dd><p>default 2; used for preparing the Cholesky decompositions for updating in the Jacobian function</p>
</dd>
<dt>super:</dt><dd><p>if NULL (default), set to FALSE to use a simplicial decomposition for the sparse Cholesky decomposition and method &ldquo;Matrix_J&rdquo;, set to  <code>as.logical(NA)</code> for method &ldquo;Matrix&rdquo;, if TRUE, use a supernodal decomposition</p>
</dd>
<dt>cheb_q:</dt><dd><p>default 5; highest power of the approximating polynomial for the Chebyshev approximation</p>
</dd>
<dt>MC_p:</dt><dd><p>default 16; number of random variates</p>
</dd>
<dt>MC_m:</dt><dd><p>default 30; number of products of random variates matrix and spatial weights matrix</p>
</dd>
<dt>spamPivot:</dt><dd><p>default &ldquo;MMD&rdquo;, alternative &ldquo;RCM&rdquo;</p>
</dd>
<dt>in_coef</dt><dd><p>default 0.1, coefficient value for initial Cholesky decomposition in &ldquo;spam_update&rdquo;</p>
</dd>
<dt>type</dt><dd><p>default &ldquo;MC&rdquo;, used with method &ldquo;moments&rdquo;; alternatives &ldquo;mult&rdquo; and &ldquo;moments&rdquo;, for use if <code>trs</code> is missing, <code><a href="#topic+trW">trW</a></code></p>
</dd>
<dt>correct</dt><dd><p>default TRUE, used with method &ldquo;moments&rdquo; to compute the Smirnov/Anselin correction term</p>
</dd>
<dt>trunc</dt><dd><p>default TRUE, used with method &ldquo;moments&rdquo; to truncate the Smirnov/Anselin correction term</p>
</dd>
<dt>SE_method</dt><dd><p>default &ldquo;LU&rdquo;, may be &ldquo;MC&rdquo;</p>
</dd>
<dt>nrho</dt><dd><p>default 200, as in SE toolbox; the size of the first stage lndet grid; it may be reduced to for example 40</p>
</dd>
<dt>interpn</dt><dd><p>default 2000, as in SE toolbox; the size of the second stage lndet grid</p>
</dd>
<dt>small_asy</dt><dd><p>default TRUE; if the method is not &ldquo;eigen&rdquo;, use asymmetric covariances rather than numerical Hessian ones if n &lt;= small</p>
</dd>
<dt>small</dt><dd><p>default 1500; threshold number of observations for asymmetric covariances when the method is not &ldquo;eigen&rdquo;</p>
</dd>
<dt>SElndet</dt><dd><p>default NULL, may be used to pass a pre-computed SE toolbox style matrix of coefficients and their lndet values to the &quot;SE_classic&quot; and &quot;SE_whichMin&quot; methods</p>
</dd>
<dt>LU_order</dt><dd><p>default FALSE; used in &ldquo;LU_prepermutate&rdquo;, note warnings given for <code>lu</code> method</p>
</dd>
<dt>pre_eig</dt><dd><p>default NULL; may be used to pass a pre-computed vector of eigenvalues</p>
</dd>
<dt>OrdVsign</dt><dd><p>default 1; used to set the sign of the final component to negative if -1 (alpha times ((sigma squared) squared) in Ord (1975) equation B.1).</p>
</dd>
<dt>opt_method:</dt><dd><p>default &ldquo;nlminb&rdquo;, may be set to &ldquo;L-BFGS-B&rdquo; to use box-constrained optimisation in <code>optim</code></p>
</dd>
<dt>opt_control:</dt><dd><p>default <code>list()</code>, a control list to pass to <code>nlminb</code> or <code>optim</code></p>
</dd>
<dt>pars:</dt><dd><p>default <code>NULL</code>, for which five trial starting values spanning the lower/upper range are tried and the best selected, starting values of <code class="reqn">\rho</code> and <code class="reqn">\lambda</code></p>
</dd>
<dt>npars</dt><dd><p>default integer <code>4L</code>, four trial points; if not default value, nine trial points</p>
</dd>
<dt>pre_eig1, pre_eig2</dt><dd><p>default NULL; may be used to pass pre-computed vectors of eigenvalues</p>
</dd>
</dl>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a>, with thanks to Andrew 
Bernat for contributions to the asymptotic standard error code.</p>


<h3>References</h3>

<p>Cliff, A. D., Ord, J. K. 1981 <em>Spatial processes</em>, Pion;
Ord, J. K. 1975 Estimation methods for models of spatial interaction,
<em>Journal of the American Statistical Association</em>, 70, 120-126;
Anselin, L. 1988 <em>Spatial econometrics: methods and models.</em>
(Dordrecht: Kluwer); Anselin, L. 1995 SpaceStat, a software program for
the analysis of spatial data, version 1.80. Regional Research Institute,
West Virginia University, Morgantown, WV;
Anselin L, Bera AK (1998) Spatial dependence in linear regression models
with an introduction to spatial econometrics. In: Ullah A, Giles DEA
(eds) Handbook of applied economic statistics. Marcel Dekker, New York,
pp. 237-289; Nagelkerke NJD (1991) A note on a general definition of the 
coefficient of determination. Biometrika 78: 691-692; Cressie, N. A. C. 1993 <em>Statistics for spatial data</em>, Wiley, New York; LeSage J and RK Pace (2009) Introduction to Spatial Econometrics. CRC Press, Boca Raton.
</p>
<p>Roger Bivand, Gianfranco Piras (2015). Comparing Implementations of Estimation Methods for Spatial Econometrics. <em>Journal of Statistical Software</em>, 63(18), 1-36. <a href="https://doi.org/10.18637/jss.v063.i18">doi:10.18637/jss.v063.i18</a>.
</p>
<p>Bivand, R. S., Hauke, J., and Kossowski, T. (2013). Computing the Jacobian in Gaussian spatial autoregressive models: An illustrated comparison of available methods. <em>Geographical Analysis</em>, 45(2), 150-179.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="#topic+impacts">impacts</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(oldcol, package="spdep")
listw &lt;- spdep::nb2listw(COL.nb, style="W")
ev &lt;- eigenw(listw)
W &lt;- as(listw, "CsparseMatrix")
trMatc &lt;- trW(W, type="mult")
COL.lag.eig &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, listw=listw,
 method="eigen", quiet=FALSE, control=list(pre_eig=ev, OrdVsign=1))
(x &lt;- summary(COL.lag.eig, correlation=TRUE))
coef(x)
## Not run: 
COL.lag.eig$fdHess
COL.lag.eig$resvar
# using the apparent sign in Ord (1975, equation B.1) 
COL.lag.eigb &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, listw=listw,
 method="eigen", control=list(pre_eig=ev, OrdVsign=-1))
summary(COL.lag.eigb)
COL.lag.eigb$fdHess
COL.lag.eigb$resvar
# force numerical Hessian
COL.lag.eig1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw=listw, method="Matrix", control=list(small=25))
summary(COL.lag.eig1)
COL.lag.eig1$fdHess
# force LeSage &amp; Pace (2008, p. 57) approximation 
COL.lag.eig1a &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw=listw, method="Matrix", control=list(small=25), trs=trMatc)
summary(COL.lag.eig1a)
COL.lag.eig1a$fdHess
COL.lag.eig$resvar[2,2]
# using the apparent sign in Ord (1975, equation B.1) 
COL.lag.eigb$resvar[2,2]
# force numerical Hessian
COL.lag.eig1$fdHess[1,1]
# force LeSage &amp; Pace (2008, p. 57) approximation 
COL.lag.eig1a$fdHess[2,2]

## End(Not run)
system.time(COL.lag.M &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix", quiet=FALSE))
summary(COL.lag.M)
impacts(COL.lag.M, listw=listw)
## Not run: 
system.time(COL.lag.sp &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw=listw, method="spam", quiet=FALSE))
summary(COL.lag.sp)
COL.lag.B &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="B"), control=list(pre_eig=ev))
summary(COL.lag.B)
COL.mixed.B &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="B"), type="mixed", tol.solve=1e-9,
 control=list(pre_eig=ev))
summary(COL.mixed.B)
COL.mixed.W &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, type="mixed", control=list(pre_eig=ev))
summary(COL.mixed.W)
COL.mixed.D00 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin=TRUE, control=list(pre_eig=ev))
summary(COL.mixed.D00)
COL.mixed.D01 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin=FALSE, control=list(pre_eig=ev))
summary(COL.mixed.D01)
COL.mixed.D1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin= ~ INC + HOVAL, control=list(pre_eig=ev))
summary(COL.mixed.D1)
f &lt;- CRIME ~ INC + HOVAL
COL.mixed.D2 &lt;- lagsarlm(f, data=COL.OLD, listw,
 Durbin=as.formula(delete.response(terms(f))),
 control=list(pre_eig=ev))
summary(COL.mixed.D2)
COL.mixed.D1a &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin= ~ INC, control=list(pre_eig=ev))
summary(COL.mixed.D1a)
try(COL.mixed.D1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin= ~ inc + HOVAL, control=list(pre_eig=ev)))
try(COL.mixed.D1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin= ~ DISCBD + HOVAL, control=list(pre_eig=ev)))
NA.COL.OLD &lt;- COL.OLD
NA.COL.OLD$CRIME[20:25] &lt;- NA
COL.lag.NA &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=NA.COL.OLD,
 listw, na.action=na.exclude)
COL.lag.NA$na.action
COL.lag.NA
resid(COL.lag.NA)
COL.lag.NA1 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=NA.COL.OLD,
 listw, Durbin=~INC) # https://github.com/r-spatial/spatialreg/issues/10
COL.lag.NA1$na.action
COL.lag.NA2 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=NA.COL.OLD,
 listw, Durbin=~INC, na.action=na.exclude)
COL.lag.NA2$na.action
# https://github.com/r-spatial/spatialreg/issues/11
COL.lag.NA3 &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=NA.COL.OLD,
 listw, control=list(pre_eig=ev))
COL.lag.NA3$na.action

## End(Not run)

## Not run: 
data(boston, package="spData")
gp2mM &lt;- lagsarlm(log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + 
I(RM^2) +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT), 
data=boston.c, spdep::nb2listw(boston.soi), type="mixed", method="Matrix")
summary(gp2mM)
W &lt;- as(spdep::nb2listw(boston.soi), "CsparseMatrix")
trMatb &lt;- trW(W, type="mult")
gp2mMi &lt;- lagsarlm(log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + 
I(RM^2) +  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT), 
data=boston.c, spdep::nb2listw(boston.soi), type="mixed", method="Matrix", 
trs=trMatb)
summary(gp2mMi)

## End(Not run)
COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, quiet=FALSE, control=list(pre_eig=ev))
summary(COL.errW.eig)
COL.errW.eig_ev &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, control=list(pre_eig=ev))
all.equal(coefficients(COL.errW.eig), coefficients(COL.errW.eig_ev))
COL.errB.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="B"))
summary(COL.errB.eig)
COL.errW.M &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix", quiet=FALSE, trs=trMatc)
summary(COL.errW.M)
COL.SDEM.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, etype="emixed", control=list(pre_eig=ev))
summary(COL.SDEM.eig)
## Not run: 
COL.SDEM.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, Durbin=TRUE, control=list(pre_eig=ev))
summary(COL.SDEM.eig)
COL.SDEM.eig &lt;- errorsarlm(CRIME ~ DISCBD + INC + HOVAL, data=COL.OLD,
 listw, Durbin=~INC, control=list(pre_eig=ev))
summary(COL.SDEM.eig)
summary(impacts(COL.SDEM.eig))
NA.COL.OLD &lt;- COL.OLD
NA.COL.OLD$CRIME[20:25] &lt;- NA
COL.err.NA &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=NA.COL.OLD,
 listw, na.action=na.exclude)
COL.err.NA$na.action
COL.err.NA
resid(COL.err.NA)
print(system.time(ev &lt;- eigenw(similar.listw(listw))))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="eigen", control=list(pre_eig=ev))))
ocoef &lt;- coefficients(COL.errW.eig)
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="eigen", control=list(pre_eig=ev, LAPACK=FALSE))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="eigen", control=list(pre_eig=ev, compiled_sse=TRUE))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix_J", control=list(super=TRUE))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix_J", control=list(super=FALSE))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix_J", control=list(super=as.logical(NA)))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix", control=list(super=TRUE))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix", control=list(super=FALSE))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="Matrix", control=list(super=as.logical(NA)))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="spam", control=list(spamPivot="MMD"))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="spam", control=list(spamPivot="RCM"))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="spam_update", control=list(spamPivot="MMD"))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))
print(system.time(COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, method="spam_update", control=list(spamPivot="RCM"))))
print(all.equal(ocoef, coefficients(COL.errW.eig)))

## End(Not run)
COL.sacW.eig &lt;- sacsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, listw,
 control=list(pre_eig1=ev, pre_eig2=ev))
summary(COL.sacW.eig)
set.seed(1)
summary(impacts(COL.sacW.eig, tr=trMatc, R=2000), zstats=TRUE, short=TRUE)
COL.msacW.eig &lt;- sacsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, listw,
 type="sacmixed", control=list(pre_eig1=ev, pre_eig2=ev))
summary(COL.msacW.eig)
set.seed(1)
summary(impacts(COL.msacW.eig, tr=trMatc, R=2000), zstats=TRUE, short=TRUE)
COL.msacW1.eig &lt;- sacsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, listw,
 Durbin=TRUE, control=list(pre_eig1=ev, pre_eig2=ev))
summary(COL.msacW1.eig)
set.seed(1)
summary(impacts(COL.msacW1.eig, tr=trMatc, R=2000), zstats=TRUE, short=TRUE)
COL.msacW2.eig &lt;- sacsarlm(CRIME ~ DISCBD + INC + HOVAL, data=COL.OLD, 
 listw, Durbin= ~ INC, control=list(pre_eig1=ev, pre_eig2=ev))
summary(COL.msacW2.eig)
summary(impacts(COL.msacW2.eig, tr=trMatc, R=2000), zstats=TRUE, short=TRUE)
## Not run: 
COL.mix.eig &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, type="mixed", method="eigen")
summary(COL.mix.eig, correlation=TRUE, Nagelkerke=TRUE)
COL.mix.M &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw, type="mixed", method="Matrix")
summary(COL.mix.M, correlation=TRUE, Nagelkerke=TRUE)
COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
  spdep::nb2listw(COL.nb, style="W"), method="eigen")
summary(COL.errW.eig, correlation=TRUE, Nagelkerke=TRUE, Hausman=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.Sarlm'>Prediction for spatial simultaneous autoregressive linear
model objects</h2><span id='topic+predict.Sarlm'></span><span id='topic+print.Sarlm.pred'></span><span id='topic+as.data.frame.Sarlm.pred'></span>

<h3>Description</h3>

<p><code>predict.Sarlm()</code> calculates predictions as far as is at present possible for for spatial simultaneous autoregressive linear
model objects, using Haining's terminology for decomposition into
trend, signal, and noise, or other types of predictors &mdash; see references.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Sarlm'
predict(object, newdata = NULL, listw = NULL, pred.type = "TS", all.data = FALSE,
 zero.policy = NULL, legacy = TRUE, legacy.mixed = FALSE, power = NULL, order = 250,
 tol = .Machine$double.eps^(3/5), spChk = NULL, ...)
#\method{predict}{SLX}(object, newdata, listw, zero.policy=NULL, ...)
## S3 method for class 'Sarlm.pred'
print(x, ...)
## S3 method for class 'Sarlm.pred'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Sarlm_+3A_object">object</code></td>
<td>
<p><code>Sarlm</code> object returned by <code>lagsarlm</code>, 
<code>errorsarlm</code> or <code>sacsarlm</code>, the method for SLX objects takes the output of <code>lmSLX</code></p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_newdata">newdata</code></td>
<td>
<p>data frame in which to predict &mdash; if NULL, predictions are
for the data on which the model was fitted. Should have row names corresponding to region.id. If row names are exactly the same than the ones used for training, it uses in-sample predictors for forecast.  See &lsquo;Details&rsquo;</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code>. In the out-of-sample prediction case (ie. if newdata is not NULL), if <code>legacy.mixed=FALSE</code> or if <code>pred.type!="TS"</code>, it should include both in-sample and out-of-sample spatial units. In this case, if regions of the listw are not in the correct order, they are reordered.  See &lsquo;Details&rsquo;</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_pred.type">pred.type</code></td>
<td>
<p>predictor type &mdash; default &ldquo;TS&rdquo;, use decomposition into  
trend, signal, and noise ; other types available depending on <code>newdata</code>. If <code>newdata=NULL</code> (in-sample prediction), &ldquo;TS&rdquo;, &ldquo;trend&rdquo;, &ldquo;TC&rdquo; and &ldquo;BP&rdquo; are available. If <code>newdata</code> is not NULL and its row names are the same than the <code>data</code> used to fit the model (forecast case), &ldquo;TS&rdquo;, &ldquo;trend&rdquo; and &ldquo;TC&rdquo; are available. In other cases (out-of-sample prediction), &ldquo;TS&rdquo;, &ldquo;trend&rdquo;, &ldquo;KP1&rdquo;, &ldquo;KP2&rdquo;, &ldquo;KP3&rdquo;, &ldquo;KP4&rdquo;, &ldquo;KP5&rdquo;, &ldquo;TC&rdquo;, &ldquo;BP&rdquo;, &ldquo;BPW&rdquo;, &ldquo;BPN&rdquo;, &ldquo;TS1&rdquo;, &ldquo;TC1&rdquo;, &ldquo;BP1&rdquo;, &ldquo;BPW1&rdquo; and &ldquo;BPN1&rdquo; are available.  See &lsquo;Details&rsquo; and references</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_all.data">all.data</code></td>
<td>
<p>(only applies to <code>pred.type="TC"</code> and newdata is not NULL) default FALSE: return predictions only for newdata units, if TRUE return predictions for all data units.  See &lsquo;Details&rsquo;</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE (default) assign NA - causing the function to 
terminate with an error</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_legacy">legacy</code></td>
<td>
<p>(only applies to lag and Durbin (mixed) models for <code>pred.type="TS"</code>) default TRUE: use ad-hoc predictor, if FALSE use DGP-based predictor</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_legacy.mixed">legacy.mixed</code></td>
<td>
<p>(only applies to mixed models if newdata is not NULL) default FALSE: compute lagged variables from both in-sample and out-of-sample units with <code class="reqn">[W X]_O</code> and <code class="reqn">[W X]_S</code> where <code>X=cbind(Xs, Xo)</code>, if TRUE compute lagged variables independantly between in-sample and out-of-sample units with <code class="reqn">W_{OO} X_O</code> and <code class="reqn">W_{SS} X_S</code> </p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_power">power</code></td>
<td>
<p>(only applies to lag and Durbin (mixed) models for &ldquo;TS&rdquo;, &ldquo;KP1&rdquo;, &ldquo;KP2&rdquo;, &ldquo;KP3&rdquo;, &ldquo;TC&rdquo;, &ldquo;TC1&rdquo;, &ldquo;BP&rdquo;, &ldquo;BP1&rdquo;, &ldquo;BPN&rdquo;, &ldquo;BPN1&rdquo;, &ldquo;BPW&rdquo; and &ldquo;BPW1&rdquo; types) use <code>powerWeights</code>, if default NULL, set FALSE if <code>object$method</code> is &ldquo;eigen&rdquo;, otherwise TRUE</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_order">order</code></td>
<td>
<p>power series maximum limit if <code>power</code> is TRUE</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_tol">tol</code></td>
<td>
<p>tolerance for convergence of power series if <code>power</code> is TRUE</p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_spchk">spChk</code></td>
<td>
<p>should the row names of data frames be checked against the spatial objects for identity integrity, TRUE, or FALSE, default NULL to use <code>get.spChkOption()</code></p>
</td></tr>
<tr><td><code id="predict.Sarlm_+3A_x">x</code></td>
<td>
<p>the object to be printed</p>
</td></tr>


<tr><td><code id="predict.Sarlm_+3A_...">...</code></td>
<td>
<p>further arguments passed through</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function supports three types of prediction.  In-sample prediction is the computation of predictors on the data used to fit the model (<code>newdata=NULL</code>).  Prevision, also called forecast, is the computation of some predictors (&ldquo;trend&rdquo;, in-sample &ldquo;TC&rdquo; and out-of-sample &ldquo;TS&rdquo;) on the same spatial units than the ones used to fit the model, but with different observations of the variables in the model (row names of <code>newdata</code> should have the same row names than the data frame used to fit the model).  And out-of-sample prediction is the computation of predictors on other spatial units than the ones used to fit the model (<code>newdata</code> has different row names).  For extensive definitions, see Goulard et al. (2017). 
</p>
<p><code>pred.type</code> of predictors are available according to the model of <code>object</code> an to the type of prediction.  In the two following tables, &ldquo;yes&rdquo; means that the predictor can be used with the model, &ldquo;no&rdquo; means that <code>predict.Sarlm()</code> will stop with an error, and &ldquo;yes*&rdquo; means that the predictor is not designed for the specified model, but it can be used with <code>predict.Sarlm()</code>.  In the last case, be careful with the computation of a inappropriate predictor.
</p>
<p><em>In-sample predictors by models</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
  pred.type </td><td style="text-align: center;"> sem (mixed) </td><td style="text-align: center;"> lag (mixed) </td><td style="text-align: center;"> sac (mixed) </td>
</tr>
<tr>
 <td style="text-align: left;">
        </td><td style="text-align: center;">     </td><td style="text-align: center;">  </td><td style="text-align: center;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;trend&rdquo; </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;TS&rdquo;   </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  no </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;TC&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BP&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Note that only &ldquo;trend&rdquo; and &ldquo;TC&rdquo; are available for prevision.
</p>
<p><em>Out-of-sample predictors by models</em>
</p>

<table>
<tr>
 <td style="text-align: left;">
  pred.type </td><td style="text-align: center;"> sem (mixed) </td><td style="text-align: center;"> lag (mixed) </td><td style="text-align: center;"> sac (mixed) </td>
</tr>
<tr>
 <td style="text-align: left;">
        </td><td style="text-align: center;">     </td><td style="text-align: center;">  </td><td style="text-align: center;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;trend&rdquo; </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;TS&rdquo;   </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  no </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;TS1&rdquo; or &ldquo;KP4&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;TC&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;TC1&rdquo; or &ldquo;KP1&rdquo;  </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BP&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BP1&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BPW&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BPW1&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BN&rdquo;     </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;BPN1&rdquo;   </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;KP2&rdquo;   </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;KP3&rdquo;   </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  yes </td>
</tr>
<tr>
 <td style="text-align: left;">
  &ldquo;KP5&rdquo;   </td><td style="text-align: center;">  yes </td><td style="text-align: center;">  no </td><td style="text-align: center;">  yes* </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Values for <code>pred.type=</code> include &ldquo;TS1&rdquo;, &ldquo;TC&rdquo;, &ldquo;TC1&rdquo;, &ldquo;BP&rdquo;, &ldquo;BP1&rdquo;, &ldquo;BPW&rdquo;, &ldquo;BPW1&rdquo;, &ldquo;BPN&rdquo;, &ldquo;BPN1&rdquo;, following the notation in Goulard et al. (2017), and for <code>pred.type=</code> &ldquo;KP1&rdquo;, &ldquo;KP2&rdquo;, &ldquo;KP3&rdquo;, &ldquo;KP4&rdquo;, &ldquo;KP5&rdquo;, following the notation in Kelejian et al. (2007).  <code>pred.type="TS"</code> is described bellow and in Bivand (2002).  
</p>
<p>In the following, the trend is the non-spatial smooth, the signal is the
spatial smooth, and the noise is the residual.  The fit returned by <code>pred.type="TS"</code> is the
sum of the trend and the signal.  
</p>
<p>When <code>pred.type="TS"</code>, the function approaches prediction first by dividing invocations between 
those with or without newdata.  When no newdata is present, the response 
variable may be reconstructed as the sum of the trend, the signal, and the
noise (residuals).  Since the values of the response variable are known,
their spatial lags are used to calculate signal components (Cressie 1993, p. 564).  For the error
model, trend = <code class="reqn">X \beta</code>, and signal = <code class="reqn">\lambda W y - 
\lambda W X \beta</code>. For the lag and mixed
models, trend = <code class="reqn">X \beta</code>, and signal = <code class="reqn">\rho W y</code>.
</p>
<p>This approach differs from the design choices made in other software, for
example GeoDa, which does not use observations of the response variable,
and corresponds to the newdata situation described below.  
</p>
<p>When however newdata is used for prediction, no observations of the response 
variable being predicted are available.  Consequently, while the trend
components are the same, the signal cannot take full account of the spatial
smooth.  In the error model and Durbin error model, the signal is set to zero, since the spatial smooth is expressed in terms of the error: 
<code class="reqn">(I - \lambda W)^{-1} \varepsilon</code>.
</p>
<p>In the lag model, the signal can be expressed in the following way (for legacy=TRUE):
</p>
<p style="text-align: center;"><code class="reqn">(I - \rho W) y = X \beta + \varepsilon</code>
</p>

<p style="text-align: center;"><code class="reqn">y = (I - \rho W)^{-1} X \beta + (I - \rho W)^{-1} \varepsilon</code>
</p>

<p>giving a feasible signal component of:
</p>
<p style="text-align: center;"><code class="reqn">\rho W y = \rho W (I - \rho W)^{-1} X \beta</code>
</p>

<p>For legacy=FALSE, the trend is computed first as:
</p>
<p style="text-align: center;"><code class="reqn">X \beta</code>
</p>

<p>next the prediction using the DGP:
</p>
<p style="text-align: center;"><code class="reqn">(I - \rho W)^{-1} X \beta</code>
</p>

<p>and the signal is found as the difference between prediction and trend. The numerical results for the legacy and DGP methods are identical.  
</p>

<p>setting the error term to zero.  This also means that predictions of the
signal component for lag and mixed models require the inversion of an 
n-by-n matrix.  
</p>
<p>Because the outcomes of the spatial smooth on the error term are
unobservable, this means that the signal values for newdata are
incomplete.  In the mixed model, the spatially lagged RHS variables
influence both the trend and the signal, so that the root mean square
prediction error in the examples below for this case with newdata is
smallest, although the model was not the best fit.  
</p>
<p>If <code>newdata</code> has more than one row, leave-one-out predictors (<code>pred.type=</code> include &ldquo;TS1&rdquo;, &ldquo;TC1&rdquo;, &ldquo;BP1&rdquo;, &ldquo;BPW1&rdquo;, &ldquo;BPN1&rdquo;, &ldquo;KP1&rdquo;, &ldquo;KP2&rdquo;, &ldquo;KP3&rdquo;, &ldquo;KP4&rdquo;, &ldquo;KP5&rdquo;) are computed separatly on each out-of-sample unit.  
</p>
<p><code>listw</code> should be provided except if <code>newdata=NULL</code> and <code>pred.type=</code> include &ldquo;TS&rdquo;, &ldquo;trend&rdquo;, or if <code>newdata</code> is not <code>NULL</code>, <code>pred.type="trend"</code> and <code>object</code> is not a mixed model.  
</p>
<p><code>all.data</code> is useful when some out-of-sample predictors return different predictions for in-sample units, than the same predictor type computed only on in-sample data.  
</p>


<h3>Value</h3>

<p><code>predict.Sarlm()</code> returns a vector of predictions with three attribute 
vectors of trend, signal (only for <code>pred.type="TS"</code>) and region.id values and two other attributes
of pred.type and call with class <code>Sarlm.pred</code>. 
</p>
<p><code>print.Sarlm.pred()</code> is a print function for this class, printing and
returning a data frame with columns: &quot;fit&quot;, &quot;trend&quot; and &quot;signal&quot; (when available) and with region.id as row names.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a> and Martin Gubri</p>


<h3>References</h3>

<p>Haining, R. 1990 <em>Spatial data analysis in the social and environmental sciences</em>, Cambridge: Cambridge University Press, p. 258; Cressie, N. A. C. 1993 <em>Statistics for spatial data</em>, Wiley, New York; Michel Goulard, Thibault Laurent &amp; Christine Thomas-Agnan, 2017 <em>About predictions in spatial autoregressive models: optimal and almost optimal strategies</em>,  Spatial Economic Analysis Volume 12, Issue 2&ndash;3, 304&ndash;325 <a href="https://doi.org/10.1080/17421772.2017.1300679">doi:10.1080/17421772.2017.1300679</a>, ; Kelejian, H. H. and Prucha, I. R. 2007 <em>The relative efficiencies of various predictors in spatial econometric models containing spatial lags</em>, Regional Science and Urban Economics, Volume 37, Issue 3, 363&ndash;374; Bivand, R. 2002 <em>Spatial econometrics functions in R: Classes and methods</em>, Journal of Geographical Systems, Volume 4, No. 4, 405&ndash;421</p>


<h3>See Also</h3>

<p><code><a href="#topic+errorsarlm">errorsarlm</a></code>, <code><a href="#topic+lagsarlm">lagsarlm</a></code>, <code><a href="#topic+sacsarlm">sacsarlm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(oldcol, package="spdep")
lw &lt;- spdep::nb2listw(COL.nb)
COL.lag.eig &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw)

COL.mix.eig &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw,
  type="mixed")
print(p1 &lt;- predict(COL.mix.eig))
print(p2 &lt;- predict(COL.mix.eig, newdata=COL.OLD, listw=lw, pred.type = "TS",
 legacy.mixed = TRUE))
AIC(COL.mix.eig)
sqrt(deviance(COL.mix.eig)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(p1))^2)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(p2))^2)/length(COL.nb))

COL.err.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw)
AIC(COL.err.eig)
sqrt(deviance(COL.err.eig)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(predict(COL.err.eig)))^2)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(predict(COL.err.eig, newdata=COL.OLD,
  listw=lw, pred.type = "TS")))^2)/length(COL.nb))

COL.SDerr.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw,
 etype="emixed")
AIC(COL.SDerr.eig)
sqrt(deviance(COL.SDerr.eig)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(predict(COL.SDerr.eig)))^2)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(predict(COL.SDerr.eig, newdata=COL.OLD,
  listw=lw, pred.type = "TS")))^2)/length(COL.nb))

AIC(COL.lag.eig)
sqrt(deviance(COL.lag.eig)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(predict(COL.lag.eig)))^2)/length(COL.nb))
sqrt(sum((COL.OLD$CRIME - as.vector(predict(COL.lag.eig, newdata=COL.OLD,
  listw=lw, pred.type = "TS")))^2)/length(COL.nb))

p3 &lt;- predict(COL.mix.eig, newdata=COL.OLD, listw=lw, pred.type = "TS",
 legacy=FALSE, legacy.mixed = TRUE)
all.equal(p2, p3, check.attributes=FALSE)
p4 &lt;- predict(COL.mix.eig, newdata=COL.OLD, listw=lw, pred.type = "TS",
 legacy=FALSE, power=TRUE, legacy.mixed = TRUE)
all.equal(p2, p4, check.attributes=FALSE)
p5 &lt;- predict(COL.mix.eig, newdata=COL.OLD, listw=lw, pred.type = "TS",
 legacy=TRUE, power=TRUE, legacy.mixed = TRUE)
all.equal(p2, p5, check.attributes=FALSE)
</code></pre>

<hr>
<h2 id='set.mcOption'>Options for parallel support</h2><span id='topic+set.ClusterOption'></span><span id='topic+get.ClusterOption'></span><span id='topic+set.mcOption'></span><span id='topic+get.coresOption'></span><span id='topic+set.coresOption'></span><span id='topic+get.mcOption'></span>

<h3>Description</h3>

<p>Provides support for the use of parallel computation in the parallel package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.mcOption(value)
get.mcOption()
set.coresOption(value)
get.coresOption()
set.ClusterOption(cl)
get.ClusterOption()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.mcOption_+3A_value">value</code></td>
<td>
<p>valid replacement value</p>
</td></tr>
<tr><td><code id="set.mcOption_+3A_cl">cl</code></td>
<td>
<p>a cluster object created by <code>makeCluster</code> in <span class="pkg">parallel</span></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Options in the spatialreg package are held in an environment local to the package namespace and not exported. Option values are set and retrieved with pairs of access functions, get and set. The <code>mc</code> option is set by default to FALSE on Windows systems, as they cannot fork the R session; by default it is TRUE on other systems, but may be set FALSE. If <code>mc</code> is FALSE, the <code>Cluster</code> option is used: if <code>mc</code> is FALSE and the <code>Cluster</code> option is NULL no parallel computing is done, or the <code>Cluster</code> option is passed a &ldquo;cluster&rdquo; object created by the parallel or snow package for access without being passed as an argument. The <code>cores</code> option is set to NULL by default, and can be used to store the number of cores to use as an integer. If <code>cores</code> is NULL, facilities from the parallel package will not be used.
</p>


<h3>Value</h3>

<p>The option access functions return their current settings, the assignment functions usually return the previous value of the option.
</p>


<h3>Note</h3>

<p>An extended example is shown in the documentation of <code><a href="#topic+mom_calc">mom_calc</a></code>, including treatment of seeding of RNG for multicore/cluster.</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>ls(envir=spatialreg:::.spatialregOptions)
library(parallel)
nc &lt;- max(2L, detectCores(logical=FALSE), na.rm = TRUE)-1L
nc
# set nc to 1L here
if (nc &gt; 1L) nc &lt;- 1L
#nc &lt;- ifelse(nc &gt; 2L, 2L, nc)
coresOpt &lt;- get.coresOption()
coresOpt
if (!is.na(nc)) {
 invisible(set.coresOption(nc))
 print(exists("mom_calc"))
 if(.Platform$OS.type == "windows") {
# forking not permitted on Windows - start cluster
# removed for Github actions 210502
## Not run: 
  print(get.mcOption())
  cl &lt;- makeCluster(get.coresOption())
  print(clusterEvalQ(cl, exists("mom_calc")))
  set.ClusterOption(cl)
  clusterEvalQ(get.ClusterOption(), library(spatialreg))
  print(clusterEvalQ(cl, exists("mom_calc")))
  clusterEvalQ(get.ClusterOption(), detach(package:spatialreg))
  set.ClusterOption(NULL)
  print(clusterEvalQ(cl, exists("mom_calc")))
  stopCluster(cl)

## End(Not run)
 } else {
  mcOpt &lt;- get.mcOption()
  print(mcOpt)
  print(mclapply(1:get.coresOption(), function(i) exists("mom_calc"),
   mc.cores=get.coresOption()))
  invisible(set.mcOption(FALSE))
  cl &lt;- makeCluster(nc)
  print(clusterEvalQ(cl, exists("mom_calc")))
  set.ClusterOption(cl)
  clusterEvalQ(get.ClusterOption(), library(spatialreg))
  print(clusterEvalQ(cl, exists("mom_calc")))
  clusterEvalQ(get.ClusterOption(), detach(package:spatialreg))
  set.ClusterOption(NULL)
  print(clusterEvalQ(cl, exists("mom_calc")))
  stopCluster(cl)
  invisible(set.mcOption(mcOpt))
 }
 invisible(set.coresOption(coresOpt))
}
</code></pre>

<hr>
<h2 id='set.ZeroPolicyOption'>Control checking of spatial object IDs</h2><span id='topic+set.VerboseOption'></span><span id='topic+get.VerboseOption'></span><span id='topic+set.ZeroPolicyOption'></span><span id='topic+get.ZeroPolicyOption'></span>

<h3>Description</h3>

<p>Provides support for checking the mutual integrity of spatial neighbour weights and spatial data; similar mechanisms are used for passing global verbose and zero.policy options, and for providing access to a running cluster for embarrassingly parallel tasks. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.VerboseOption(check)
get.VerboseOption()
set.ZeroPolicyOption(check)
get.ZeroPolicyOption()
#set.listw_is_CsparseMatrix_Option(check)
#get.listw_is_CsparseMatrix_Option()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.ZeroPolicyOption_+3A_check">check</code></td>
<td>
<p>a logical value, TRUE or FALSE</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Analysis functions will have an spChk argument by default set to NULL, and will call <code>get.spChkOption()</code> to get the global spatial option for whether to check or not &mdash; this is initialised to FALSE, and consequently should not break anything. It can be changed to TRUE using <code>set.spChkOption(TRUE)</code>, or the spChk argument can be assigned in analysis functions. <code>spNamedVec()</code> is provided to ensure that rownames are passed on to single columns taken from two-dimensional arrays and data frames.
</p>


<h3>Value</h3>

<p><code>set.spChkOption()</code> returns the old logical value, <code>get.spChkOption()</code> returns the current logical value, and <code>chkIDs()</code> returns a logical value for the test lack of difference. <code>spNamedVec()</code> returns the selected column with the names set to the row names of the object from which it has been extracted.
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>get.VerboseOption()
get.ZeroPolicyOption()
</code></pre>

<hr>
<h2 id='similar.listw'>Create symmetric similar weights lists</h2><span id='topic+similar.listw'></span>

<h3>Description</h3>

<p>From Ord's 1975 paper, it is known that the Jacobian for SAR models may be found by &quot;symmetrizing&quot; by similarity (the eigenvalues of similar matrices are identical, so the Jacobian is too). This applies only to styles &quot;W&quot; and &quot;S&quot; with underlying symmetric binary neighbour relations or symmetric general neighbour relations (so no k-nearest neighbour relations). The function is invoked automatically within the SAR fitting functions, to call <code>eigen</code> on a symmetric matrix for the default eigen method, or to make it possible to use the Matrix method on weights that can be &quot;symmetrized&quot; in this way.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>similar.listw(listw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="similar.listw_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>spdep::nb2listw</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>listw</code> object
</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Ord, J. K. 1975 Estimation methods for models of spatial interaction, <em>Journal of the American Statistical Association</em>, 70, 120-126</p>


<h3>See Also</h3>

<p><code><a href="#topic+lagsarlm">lagsarlm</a></code>, <code><a href="#topic+errorsarlm">errorsarlm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#require("spdep", quietly=TRUE)
data(oldcol, package="spdep")
COL.W &lt;- spdep::nb2listw(COL.nb, style="W")
COL.S &lt;- spdep::nb2listw(COL.nb, style="S")
sum(log(1 - 0.5 * eigenw(COL.W)))
sum(log(1 - 0.5 * eigenw(similar.listw(COL.W))))
W_J &lt;- as(as_dsTMatrix_listw(similar.listw(COL.W)), "CsparseMatrix")
I &lt;- as_dsCMatrix_I(dim(W_J)[1])
c(determinant(I - 0.5 * W_J, logarithm=TRUE)$modulus)
sum(log(1 - 0.5 * eigenw(COL.S)))
sum(log(1 - 0.5 * eigenw(similar.listw(COL.S))))
W_J &lt;- as(as_dsTMatrix_listw(similar.listw(COL.S)), "CsparseMatrix")
c(determinant(I - 0.5 * W_J, logarithm=TRUE)$modulus)
</code></pre>

<hr>
<h2 id='SpatialFiltering'>Semi-parametric spatial filtering</h2><span id='topic+SpatialFiltering'></span><span id='topic+print.SfResult'></span><span id='topic+fitted.SfResult'></span>

<h3>Description</h3>

<p>The function selects eigenvectors in a semi-parametric spatial filtering approach to removing spatial dependence from linear models. Selection is by brute force by finding the single eigenvector reducing the standard variate of Moran's I for regression residuals most, and continuing until no candidate eigenvector reduces the value by more than <code>tol</code>. It returns a summary table from the selection process and a matrix of selected eigenvectors for the specified model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SpatialFiltering(formula, lagformula=NULL, data=list(), na.action=na.fail,
 nb=NULL, glist = NULL,
 style = "C", zero.policy = NULL, tol = 0.1, zerovalue = 1e-04,
 ExactEV = FALSE, symmetric = TRUE, alpha=NULL, alternative="two.sided",
 verbose=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SpatialFiltering_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit, assuming a spatial error representation; when lagformula is given, it should include only the response and the intercept term</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_lagformula">lagformula</code></td>
<td>
<p>An extra one-sided formula to be used when a spatial lag representation is desired; the intercept is excluded within the function if present because it is part of the formula argument, but excluding it explicitly in the lagformula argument in the presence of factors generates a collinear model matrix</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_nb">nb</code></td>
<td>
<p>an object of class <code>nb</code></p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_glist">glist</code></td>
<td>
<p>list of general weights corresponding to neighbours</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_style">style</code></td>
<td>
<p><code>style</code> can take values W, B, C, U, and S</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the spatial weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if FALSE stop with error for any empty neighbour sets, if TRUE permit the weights list to be formed with zero-length weights vectors</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_tol">tol</code></td>
<td>
<p>tolerance value for convergence of spatial filtering</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_zerovalue">zerovalue</code></td>
<td>
<p>eigenvectors with eigenvalues of an absolute value smaller than zerovalue will be excluded in eigenvector search</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_exactev">ExactEV</code></td>
<td>
<p>Set ExactEV=TRUE to use exact expectations and variances rather than the expectation and variance of Moran's I from the previous iteration, default FALSE</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_symmetric">symmetric</code></td>
<td>
<p>Should the spatial weights matrix be forced to symmetry, default TRUE</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_alpha">alpha</code></td>
<td>
<p>if not NULL, used instead of the tol= argument as a stopping rule to choose all eigenvectors up to and including the one with a probability value exceeding alpha.</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis, must be one of greater, less or two.sided (default).</p>
</td></tr>
<tr><td><code id="SpatialFiltering_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE report eigenvectors selected</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>SfResult</code> object, with:
</p>
<table>
<tr><td><code>selection</code></td>
<td>
<p>a matrix summarising the selection of eigenvectors for inclusion, with columns:
</p>

<dl>
<dt>Step</dt><dd><p>Step counter of the selection procedure</p>
</dd>
<dt>SelEvec</dt><dd><p>number of selected eigenvector (sorted descending)</p>
</dd>
<dt>Eval</dt><dd><p>its associated eigenvalue</p>
</dd>
<dt>MinMi</dt><dd><p>value Moran's I for residual autocorrelation</p>
</dd>
<dt>ZMinMi</dt><dd><p>standardized value of Moran's I assuming a normal approximation</p>
</dd>
<dt>pr(ZI)</dt><dd><p>probability value of the permutation-based standardized deviate for the given value of the alternative argument</p>
</dd>
<dt>R2</dt><dd><p>R^2 of the model including exogenous variables and eigenvectors</p>
</dd>
<dt>gamma</dt><dd><p>regression coefficient of selected eigenvector in fit</p>
</dd>
</dl>

<p>The first row is the value at the start of the search
</p>
</td></tr>
<tr><td><code>dataset</code></td>
<td>
<p>a matrix of the selected eigenvectors in order of selection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yongwan Chun, Michael Tiefelsdorf, Roger Bivand</p>


<h3>References</h3>

<p>Tiefelsdorf M, Griffith DA. (2007) Semiparametric Filtering of Spatial Autocorrelation: The Eigenvector Approach. Environment and Planning A, 39 (5) 1193 - 1221.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="base.html#topic+eigen">eigen</a></code>, <code><a href="spdep.html#topic+nb2listw">nb2listw</a></code>, <code><a href="spdep.html#topic+listw2U">listw2U</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("sf", quietly=TRUE)
columbus &lt;- st_read(system.file("shapes/columbus.shp", package="spData")[1], quiet=TRUE)
#require("spdep", quietly=TRUE)
col.gal.nb &lt;- spdep::read.gal(system.file("weights/columbus.gal", package="spData")[1])
lmbase &lt;- lm(CRIME ~ INC + HOVAL, data=columbus)
sarcol &lt;- SpatialFiltering(CRIME ~ INC + HOVAL, data=columbus,
 nb=col.gal.nb, style="W", ExactEV=TRUE)
sarcol
lmsar &lt;- lm(CRIME ~ INC + HOVAL + fitted(sarcol), data=columbus)
(x &lt;- summary(lmsar))
coef(x)
anova(lmbase, lmsar)
spdep::lm.morantest(lmsar, spdep::nb2listw(col.gal.nb))
lagcol &lt;- SpatialFiltering(CRIME ~ 1, ~ INC + HOVAL - 1, data=columbus,
 nb=col.gal.nb, style="W")
lagcol
lmlag &lt;- lm(CRIME ~ INC + HOVAL + fitted(lagcol), data=columbus)
lmlag
anova(lmbase, lmlag)
spdep::lm.morantest(lmlag, spdep::nb2listw(col.gal.nb))
NA.columbus &lt;- columbus
NA.columbus$CRIME[20:25] &lt;- NA
COL.SF.NA &lt;- SpatialFiltering(CRIME ~ INC + HOVAL, data=NA.columbus,
 nb=col.gal.nb, style="W", na.action=na.exclude)
COL.SF.NA$na.action
summary(lm(CRIME ~ INC + HOVAL + fitted(COL.SF.NA), data=NA.columbus,
 na.action=na.exclude))
</code></pre>

<hr>
<h2 id='spautolm'>Spatial conditional and simultaneous autoregression model estimation</h2><span id='topic+spautolm'></span><span id='topic+residuals.Spautolm'></span><span id='topic+deviance.Spautolm'></span><span id='topic+coef.Spautolm'></span><span id='topic+fitted.Spautolm'></span><span id='topic+print.Spautolm'></span><span id='topic+summary.Spautolm'></span><span id='topic+LR1.Spautolm'></span><span id='topic+logLik.Spautolm'></span><span id='topic+print.summary.Spautolm'></span>

<h3>Description</h3>

<p>Function taking family and weights arguments for spatial autoregression model estimation by Maximum Likelihood, using dense matrix methods, not suited to large data sets with thousands of observations. With one of the sparse matrix methods, larger numbers of observations can be handled, but the <code>interval=</code> argument should be set. The implementation is GLS using the single spatial coefficient value, here termed lambda, found by line search using <code>optimize</code> to maximise the log likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spautolm(formula, data = list(), listw, weights,
 na.action, family = "SAR", method="eigen", verbose = NULL, trs=NULL,
 interval=NULL, zero.policy = NULL, tol.solve=.Machine$double.eps,
 llprof=NULL, control=list())
## S3 method for class 'Spautolm'
summary(object, correlation = FALSE, adj.se=FALSE,
 Nagelkerke=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spautolm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="spautolm_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="spautolm_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="spautolm_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting process</p>
</td></tr>
<tr><td><code id="spautolm_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="spautolm_+3A_family">family</code></td>
<td>
<p>character string: either <code>"SAR"</code> or <code>"CAR"</code> for simultaneous or conditional autoregressions; <code>"SMA"</code> for spatial moving average added thanks to Jielai Ma - <code>"SMA"</code> is only implemented for method=<code>"eigen"</code> because it necessarily involves dense matrices</p>
</td></tr>
<tr><td><code id="spautolm_+3A_method">method</code></td>
<td>
<p>character string: default <code>"eigen"</code> for use of dense matrices, <code>"Matrix_J"</code> for sparse matrices (restricted to spatial weights symmetric or similar to symmetric) using methods in the Matrix package; &ldquo;Matrix&rdquo; provides updating Cholesky decomposition methods. Values of method may also include &quot;LU&quot;, which provides an alternative sparse matrix decomposition approach, and the &quot;Chebyshev&quot; and Monte Carlo &quot;MC&quot; approximate log-determinant methods.</p>
</td></tr>
<tr><td><code id="spautolm_+3A_verbose">verbose</code></td>
<td>
<p>default NULL, use global option value; if TRUE, reports function values during optimization.</p>
</td></tr>
<tr><td><code id="spautolm_+3A_trs">trs</code></td>
<td>
<p>default NULL, if given, a vector of powered spatial weights matrix traces output by <code>trW</code>; when given, used in some Jacobian methods</p>
</td></tr>
<tr><td><code id="spautolm_+3A_interval">interval</code></td>
<td>
<p>search interval for autoregressive parameter when not using method=&quot;eigen&quot;; default is c(-1,0.999), <code>optimize</code> will reset NA/NaN to a bound and gives a warning when the interval is poorly set; method=&quot;Matrix&quot; will attempt to search for an appropriate interval, if find_interval=TRUE (fails on some platforms)</p>
</td></tr>
<tr><td><code id="spautolm_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; Include list of no-neighbour observations in output if TRUE &mdash; otherwise zero.policy is handled within the listw argument</p>
</td></tr>
<tr><td><code id="spautolm_+3A_tol.solve">tol.solve</code></td>
<td>
<p>the tolerance for detecting linear dependencies in the columns of matrices to be inverted - passed to <code>solve()</code> (default=double precision machine tolerance). Errors in <code>solve()</code> may constitute indications of poorly scaled variables: if the variables have scales differing much from the autoregressive coefficient, the values in this matrix may be very different in scale, and inverting such a matrix is analytically possible by definition, but numerically unstable; rescaling the RHS variables alleviates this better than setting tol.solve to a very small value</p>
</td></tr>
<tr><td><code id="spautolm_+3A_llprof">llprof</code></td>
<td>
<p>default NULL, can either be an integer, to divide the feasible range into llprof points, or a sequence of spatial coefficient values, at which to evaluate the likelihood function</p>
</td></tr>
<tr><td><code id="spautolm_+3A_control">control</code></td>
<td>
<p>list of extra control arguments - see section below</p>
</td></tr>
<tr><td><code id="spautolm_+3A_object">object</code></td>
<td>
<p><code>Spautolm</code> object from <code>spautolm</code></p>
</td></tr>
<tr><td><code id="spautolm_+3A_correlation">correlation</code></td>
<td>
<p>logical; if 'TRUE', the correlation matrix of the estimated parameters is returned and printed (default=FALSE)</p>
</td></tr>
<tr><td><code id="spautolm_+3A_adj.se">adj.se</code></td>
<td>
<p>if TRUE, adjust the coefficient standard errors for the number of fitted coefficients</p>
</td></tr>
<tr><td><code id="spautolm_+3A_nagelkerke">Nagelkerke</code></td>
<td>
<p>if TRUE, the Nagelkerke pseudo R-squared is reported</p>
</td></tr>
<tr><td><code id="spautolm_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation is based on <code><a href="MASS.html#topic+lm.gls">lm.gls</a></code> and <code><a href="#topic+errorsarlm">errorsarlm</a></code>. In particular, the function does not (yet) prevent asymmetric spatial weights being used with &quot;CAR&quot; family models. It appears that both numerical issues (convergence in particular) and uncertainties about the exact spatial weights matrix used make it difficult to reproduce Cressie and Chan's 1989 results, also given in Cressie 1993.
</p>
<p>Note that the fitted() function for the output object assumes that the response 
variable may be reconstructed as the sum of the trend, the signal, and the
noise (residuals). Since the values of the response variable are known,
their spatial lags are used to calculate signal components (Cressie 1993, p. 564). This differs from other software, including GeoDa, which does not use knowledge of the response 
variable in making predictions for the fitting data.
</p>


<h3>Value</h3>

<p>A list object of class <code>Spautolm</code>:
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>a list, with items:
</p>

<dl>
<dt>coefficients</dt><dd><p>ML coefficient estimates</p>
</dd>
<dt>SSE</dt><dd><p>ML sum of squared errors</p>
</dd>
<dt>s2</dt><dd><p>ML residual variance</p>
</dd>
<dt>imat</dt><dd><p>ML coefficient covariance matrix (before multiplying by s2)</p>
</dd>
<dt>signal_trend</dt><dd><p>non-spatial component of fitted.values</p>
</dd>
<dt>signal_stochastic</dt><dd><p>spatial component of fitted.values</p>
</dd>
<dt>fitted.values</dt><dd><p>sum of non-spatial and spatial components of fitted.values</p>
</dd>
<dt>residuals</dt><dd><p>difference between observed and fitted values</p>
</dd>
</dl>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>ML autoregressive coefficient</p>
</td></tr>
<tr><td><code>LL</code></td>
<td>
<p>log likelihood for fitted model</p>
</td></tr>
<tr><td><code>LL0</code></td>
<td>
<p>log likelihood for model with lambda=0</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used to create this object</p>
</td></tr>
<tr><td><code>parameters</code></td>
<td>
<p>number of parameters estimated</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>if not NULL, details of aliased variables</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>Jacobian method chosen</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>family chosen</p>
</td></tr>
<tr><td><code>zero.policy</code></td>
<td>
<p>zero.policy used</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>case weights used</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>
<p>the line search interval used</p>
</td></tr>
<tr><td><code>timings</code></td>
<td>
<p>processing timings</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>(possibly) named vector of excluded or omitted observations if non-default na.action argument used</p>
</td></tr>
<tr><td><code>llprof</code></td>
<td>
<p>if not NULL, a list with components lambda and ll of equal length</p>
</td></tr>
<tr><td><code>lambda.se</code></td>
<td>
<p>Numerical Hessian-based standard error of lambda</p>
</td></tr>
<tr><td><code>fdHess</code></td>
<td>
<p>Numerical Hessian-based variance-covariance matrix</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>covariates used in model fitting</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>response used in model fitting</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>weights used in model fitting</p>
</td></tr>
</table>


<h3>Control arguments</h3>


<dl>
<dt>tol.opt:</dt><dd><p>the desired accuracy of the optimization - passed to <code>optimize()</code> (default=<code>.Machine$double.eps^(2/3)</code>)</p>
</dd>
<dt>fdHess:</dt><dd><p>default NULL, then set to (method != &quot;eigen&quot;) internally; use <code>fdHess</code> to compute an approximate Hessian using finite differences when using sparse matrix methods; used to make a coefficient covariance matrix when the number of observations is large; may be turned off to save resources if need be</p>
</dd>
<dt>optimHess:</dt><dd><p>default FALSE, use <code>fdHess</code> from <span class="pkg">nlme</span>, if TRUE, use <code>optim</code> to calculate Hessian at optimum</p>
</dd>
<dt>optimHessMethod:</dt><dd><p>default &ldquo;optimHess&rdquo;, may be &ldquo;nlm&rdquo; or one of the <code>optim</code> methods</p>
</dd>
<dt>Imult:</dt><dd><p>default 2; used for preparing the Cholesky decompositions for updating in the Jacobian function</p>
</dd>
<dt>super:</dt><dd><p>if NULL (default), set to FALSE to use a simplicial decomposition for the sparse Cholesky decomposition and method &ldquo;Matrix_J&rdquo;, set to  <code>as.logical(NA)</code> for method &ldquo;Matrix&rdquo;, if TRUE, use a supernodal decomposition</p>
</dd>
<dt>cheb_q:</dt><dd><p>default 5; highest power of the approximating polynomial for the Chebyshev approximation</p>
</dd>
<dt>MC_p:</dt><dd><p>default 16; number of random variates</p>
</dd>
<dt>MC_m:</dt><dd><p>default 30; number of products of random variates matrix and spatial weights matrix</p>
</dd>
<dt>type</dt><dd><p>default &ldquo;MC&rdquo;, used with method &ldquo;moments&rdquo;; alternatives &ldquo;mult&rdquo; and &ldquo;moments&rdquo;, for use if <code>trs</code> is missing, <code><a href="#topic+trW">trW</a></code></p>
</dd>
<dt>correct</dt><dd><p>default TRUE, used with method &ldquo;moments&rdquo; to compute the Smirnov/Anselin correction term</p>
</dd>
<dt>trunc</dt><dd><p>default TRUE, used with method &ldquo;moments&rdquo; to truncate the Smirnov/Anselin correction term</p>
</dd>
<dt>SE_method</dt><dd><p>default &ldquo;LU&rdquo;, may be &ldquo;MC&rdquo;</p>
</dd>
<dt>nrho</dt><dd><p>default 200, as in SE toolbox; the size of the first stage lndet grid; it may be reduced to for example 40</p>
</dd>
<dt>interpn</dt><dd><p>default 2000, as in SE toolbox; the size of the second stage lndet grid</p>
</dd>
<dt>small_asy</dt><dd><p>default TRUE; if the method is not &ldquo;eigen&rdquo;, use asymmetric covariances rather than numerical Hessian ones if n &lt;= small</p>
</dd>
<dt>small</dt><dd><p>default 1500; threshold number of observations for asymmetric covariances when the method is not &ldquo;eigen&rdquo;</p>
</dd>
<dt>SElndet</dt><dd><p>default NULL, may be used to pass a pre-computed SE toolbox style matrix of coefficients and their lndet values to the &quot;SE_classic&quot; and &quot;SE_whichMin&quot; methods</p>
</dd>
<dt>LU_order</dt><dd><p>default FALSE; used in &ldquo;LU_prepermutate&rdquo;, note warnings given for <code>lu</code> method</p>
</dd>
<dt>pre_eig</dt><dd><p>default NULL; may be used to pass a pre-computed vector of eigenvalues</p>
</dd>
</dl>


<h3>Note</h3>

<p>The standard errors given in Waller and Gotway (2004) are adjusted for the numbers of parameters estimated, and may be reproduced by using the additional argument <code>adj.se=TRUE</code> in the <code>summary</code> method. In addition, the function returns fitted values and residuals as given by Cressie (1993) p. 564.</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>Cliff, A. D., Ord, J. K. 1981 <em>Spatial processes</em>, Pion;
Ord, J. K. 1975 Estimation methods for models of spatial interaction,
<em>Journal of the American Statistical Association</em>, 70, 120-126; Waller, L. A., Gotway, C. A. 2004 <em>Applied spatial statistics for public health</em>, Wiley, Hoboken, NJ, 325-380; Cressie, N. A. C. 1993 <em>Statistics for spatial data</em>, Wiley, New York, 548-568; Ripley, B. D. 1981 <em>Spatial statistics</em>, Wiley, New York, 88-95; LeSage J and RK Pace (2009) Introduction to Spatial Econometrics. CRC Press, Boca Raton.</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+optimize">optimize</a></code>, <code><a href="#topic+errorsarlm">errorsarlm</a></code>, <code><a href="#topic+do_ldet">do_ldet</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>require("sf", quietly=TRUE)
nydata &lt;- st_read(system.file("shapes/NY8_bna_utm18.gpkg", package="spData")[1], quiet=TRUE)
## Not run: 
lm0 &lt;- lm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata)
summary(lm0)
lm0w &lt;- lm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata, weights=POP8)
summary(lm0w)

## End(Not run)
suppressMessages(nyadjmat &lt;- as.matrix(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1])[-1]))
suppressMessages(ID &lt;- as.character(names(foreign::read.dbf(system.file(
 "misc/nyadjwts.dbf", package="spData")[1]))[-1]))
identical(substring(ID, 2, 10), substring(as.character(nydata$AREAKEY), 2, 10))
#require("spdep", quietly=TRUE)
nyadjlw &lt;- spdep::mat2listw(nyadjmat, as.character(nydata$AREAKEY))
listw_NY &lt;- spdep::nb2listw(nyadjlw$neighbours, style="B")
eigs &lt;- eigenw(listw_NY)
## Not run: 
esar0 &lt;- errorsarlm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY)
summary(esar0)
system.time(esar1f &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, family="SAR", method="eigen",
 control=list(pre_eig=eigs)))
res &lt;- summary(esar1f)
print(res)
coef(res)
sqrt(diag(res$resvar))
sqrt(diag(esar1f$fit$imat)*esar1f$fit$s2)
sqrt(diag(esar1f$fdHess))
system.time(esar1M &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, family="SAR", method="Matrix"))
summary(esar1M)
system.time(esar1M &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, family="SAR", method="Matrix",
 control=list(super=TRUE)))
summary(esar1M)
esar1wf &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="SAR", method="eigen",
 control=list(pre_eig=eigs))
summary(esar1wf)
system.time(esar1wM &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, weights=POP8, family="SAR", method="Matrix"))
summary(esar1wM)
esar1wlu &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="SAR", method="LU")
summary(esar1wlu)
esar1wch &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="SAR", method="Chebyshev")
summary(esar1wch)

## End(Not run)
ecar1f &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, family="CAR", method="eigen",
 control=list(pre_eig=eigs))
summary(ecar1f)
## Not run: 
system.time(ecar1M &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, family="CAR", method="Matrix"))
summary(ecar1M)

## End(Not run)
ecar1wf &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME, data=nydata,
 listw=listw_NY, weights=POP8, family="CAR", method="eigen",
 control=list(pre_eig=eigs))
summary(ecar1wf)
## Not run: 
system.time(ecar1wM &lt;- spautolm(Z ~ PEXPOSURE + PCTAGE65P + PCTOWNHOME,
 data=nydata, listw=listw_NY, weights=POP8, family="CAR", method="Matrix"))
summary(ecar1wM)

## End(Not run)
## Not run: 
require("sf", quietly=TRUE)
nc.sids &lt;- st_read(system.file("shapes/sids.shp", package="spData")[1], quiet=TRUE)
ft.SID74 &lt;- sqrt(1000)*(sqrt(nc.sids$SID74/nc.sids$BIR74) +
 sqrt((nc.sids$SID74+1)/nc.sids$BIR74))
lm_nc &lt;- lm(ft.SID74 ~ 1)
sids.nhbr30 &lt;- spdep::dnearneigh(cbind(nc.sids$east, nc.sids$north), 0, 30,
 row.names=row.names(nc.sids))
sids.nhbr30.dist &lt;- spdep::nbdists(sids.nhbr30, cbind(nc.sids$east, nc.sids$north))
sids.nhbr &lt;- spdep::listw2sn(spdep::nb2listw(sids.nhbr30,
 glist=sids.nhbr30.dist, style="B", zero.policy=TRUE))
dij &lt;- sids.nhbr[,3]
n &lt;- nc.sids$BIR74
el1 &lt;- min(dij)/dij
el2 &lt;- sqrt(n[sids.nhbr$to]/n[sids.nhbr$from])
sids.nhbr$weights &lt;- el1*el2
sids.nhbr.listw &lt;- spdep::sn2listw(sids.nhbr)
both &lt;- factor(paste(nc.sids$L_id, nc.sids$M_id, sep=":"))
ft.NWBIR74 &lt;- sqrt(1000)*(sqrt(nc.sids$NWBIR74/nc.sids$BIR74) +
 sqrt((nc.sids$NWBIR74+1)/nc.sids$BIR74))
mdata &lt;- data.frame(both, ft.NWBIR74, ft.SID74, BIR74=nc.sids$BIR74)
outl &lt;- which.max(rstandard(lm_nc))
as.character(nc.sids$NAME[outl])
mdata.4 &lt;- mdata[-outl,]
W &lt;- spdep::listw2mat(sids.nhbr.listw)
W.4 &lt;- W[-outl, -outl]
sids.nhbr.listw.4 &lt;- spdep::mat2listw(W.4)
esarI &lt;- errorsarlm(ft.SID74 ~ 1, data=mdata, listw=sids.nhbr.listw,
 zero.policy=TRUE)
summary(esarI)
esarIa &lt;- spautolm(ft.SID74 ~ 1, data=mdata, listw=sids.nhbr.listw,
 family="SAR")
summary(esarIa)
esarIV &lt;- errorsarlm(ft.SID74 ~ ft.NWBIR74, data=mdata, listw=sids.nhbr.listw,
 zero.policy=TRUE)
summary(esarIV)
esarIVa &lt;- spautolm(ft.SID74 ~ ft.NWBIR74, data=mdata, listw=sids.nhbr.listw,
 family="SAR")
summary(esarIVa)
esarIaw &lt;- spautolm(ft.SID74 ~ 1, data=mdata, listw=sids.nhbr.listw,
 weights=BIR74, family="SAR")
summary(esarIaw)
esarIIaw &lt;- spautolm(ft.SID74 ~ both - 1, data=mdata, listw=sids.nhbr.listw,
 weights=BIR74, family="SAR")
summary(esarIIaw)
esarIVaw &lt;- spautolm(ft.SID74 ~ ft.NWBIR74, data=mdata,
 listw=sids.nhbr.listw, weights=BIR74, family="SAR")
summary(esarIVaw)
ecarIaw &lt;- spautolm(ft.SID74 ~ 1, data=mdata.4, listw=sids.nhbr.listw.4,
 weights=BIR74, family="CAR")
summary(ecarIaw)
ecarIIaw &lt;- spautolm(ft.SID74 ~ both - 1, data=mdata.4,
 listw=sids.nhbr.listw.4, weights=BIR74, family="CAR")
summary(ecarIIaw)
ecarIVaw &lt;- spautolm(ft.SID74 ~ ft.NWBIR74, data=mdata.4,
 listw=sids.nhbr.listw.4, weights=BIR74, family="CAR")
summary(ecarIVaw)
nc.sids$fitIV &lt;- append(fitted.values(ecarIVaw), NA, outl-1)
plot(nc.sids[,"fitIV"], nbreaks=12) # Cressie 1993, p. 565

## End(Not run)
## Not run: 
data(oldcol, package="spdep")
COL.errW.eig &lt;- errorsarlm(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="W"))
summary(COL.errW.eig)
COL.errW.sar &lt;- spautolm(CRIME ~ INC + HOVAL, data=COL.OLD,
 spdep::nb2listw(COL.nb, style="W"))
summary(COL.errW.sar)
data(boston, package="spData")
gp1 &lt;- spautolm(log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2)
 + I(RM^2) + AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT), 
 data=boston.c, spdep::nb2listw(boston.soi), family="SMA")
summary(gp1)

## End(Not run)
</code></pre>

<hr>
<h2 id='spBreg_lag'>Bayesian MCMC spatial simultaneous autoregressive model estimation</h2><span id='topic+spBreg_lag'></span><span id='topic+spBreg_err'></span><span id='topic+spBreg_sac'></span><span id='topic+impacts.MCMC_sar_G'></span><span id='topic+impacts.MCMC_sem_G'></span><span id='topic+impacts.MCMC_sac_G'></span>

<h3>Description</h3>

<p>The <code>spBreg_lag</code> function is an early-release version of the Matlab Spatial Econometrics Toolbox function <code>sar_g.m</code>, using drawing by inversion, and not accommodating heteroskedastic disturbances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spBreg_lag(formula, data = list(), listw, na.action, Durbin, type,
    zero.policy=NULL, control=list())
spBreg_sac(formula, data = list(), listw, listw2=NULL, na.action, 
    Durbin, type, zero.policy=NULL, control=list())
spBreg_err(formula, data = list(), listw, na.action, Durbin, etype,
    zero.policy=NULL, control=list())
## S3 method for class 'MCMC_sar_G'
impacts(obj, ..., tr=NULL, listw=NULL, evalues=NULL, Q=NULL)
## S3 method for class 'MCMC_sem_G'
impacts(obj, ..., tr=NULL, listw=NULL, evalues=NULL, Q=NULL)
## S3 method for class 'MCMC_sac_G'
impacts(obj, ..., tr=NULL, listw=NULL, evalues=NULL, Q=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spBreg_lag_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_listw">listw</code>, <code id="spBreg_lag_+3A_listw2">listw2</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>options("na.action")</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_durbin">Durbin</code></td>
<td>
<p>default FALSE (spatial lag model); if TRUE, full spatial Durbin model; if a formula object, the subset of explanatory variables to lag</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_type">type</code>, <code id="spBreg_lag_+3A_etype">etype</code></td>
<td>
<p>(use the &lsquo;Durbin=&rsquo; argument - retained for backwards compatibility only) default &quot;lag&quot;, may be set to &quot;mixed&quot;; when &quot;mixed&quot;, the lagged intercept is dropped for spatial weights style &quot;W&quot;, that is row-standardised weights, but otherwise included; &ldquo;Durbin&rdquo; may be used instead of &ldquo;mixed&rdquo;</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE (default) assign NA</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_control">control</code></td>
<td>
<p>list of extra control arguments - see section below</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_obj">obj</code></td>
<td>
<p>A spatial regression object</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_...">...</code></td>
<td>
<p>Arguments passed through to methods in the <span class="pkg">coda</span> package</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_tr">tr</code></td>
<td>
<p>A vector of traces of powers of the spatial weights matrix created using <code>trW</code>, for approximate impact measures; if not given, <code>listw</code> must be given for exact measures (for small to moderate spatial weights matrices); the traces must be for the same spatial weights as were used in fitting the spatial regression, and must be row-standardised</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_evalues">evalues</code></td>
<td>
<p>vector of eigenvalues of spatial weights matrix for impacts calculations</p>
</td></tr>
<tr><td><code id="spBreg_lag_+3A_q">Q</code></td>
<td>
<p>default NULL, else an integer number of cumulative power series impacts to calculate if <code>tr</code> is given</p>
</td></tr>
</table>


<h3>Control arguments</h3>


<dl>
<dt>tol.opt:</dt><dd><p>the desired accuracy of the optimization - passed to <code>optimize()</code> (default=square root of double precision machine tolerance, a larger root may be used needed, see help(boston) for an example)</p>
</dd>
<dt>fdHess:</dt><dd><p>default NULL, then set to (method != &quot;eigen&quot;) internally; use <code>fdHess</code> to compute an approximate Hessian using finite differences when using sparse matrix methods; used to make a coefficient covariance matrix when the number of observations is large; may be turned off to save resources if need be</p>
</dd>
<dt>optimHess:</dt><dd><p>default FALSE, use <code>fdHess</code> from <span class="pkg">nlme</span>, if TRUE, use <code>optim</code> to calculate Hessian at optimum</p>
</dd>
<dt>optimHessMethod:</dt><dd><p>default &ldquo;optimHess&rdquo;, may be &ldquo;nlm&rdquo; or one of the <code>optim</code> methods</p>
</dd>
<dt>compiled_sse:</dt><dd><p>default FALSE; logical value used in the log likelihood function to choose compiled code for computing SSE</p>
</dd>
<dt>Imult:</dt><dd><p>default 2; used for preparing the Cholesky decompositions for updating in the Jacobian function</p>
</dd>
<dt>super:</dt><dd><p>if NULL (default), set to FALSE to use a simplicial decomposition for the sparse Cholesky decomposition and method &ldquo;Matrix_J&rdquo;, set to  <code>as.logical(NA)</code> for method &ldquo;Matrix&rdquo;, if TRUE, use a supernodal decomposition</p>
</dd>
<dt>cheb_q:</dt><dd><p>default 5; highest power of the approximating polynomial for the Chebyshev approximation</p>
</dd>
<dt>MC_p:</dt><dd><p>default 16; number of random variates</p>
</dd>
<dt>MC_m:</dt><dd><p>default 30; number of products of random variates matrix and spatial weights matrix</p>
</dd>
<dt>spamPivot:</dt><dd><p>default &ldquo;MMD&rdquo;, alternative &ldquo;RCM&rdquo;</p>
</dd>
<dt>in_coef</dt><dd><p>default 0.1, coefficient value for initial Cholesky decomposition in &ldquo;spam_update&rdquo;</p>
</dd>
<dt>type</dt><dd><p>default &ldquo;MC&rdquo;, used with method &ldquo;moments&rdquo;; alternatives &ldquo;mult&rdquo; and &ldquo;moments&rdquo;, for use if <code>trs</code> is missing, <code><a href="#topic+trW">trW</a></code></p>
</dd>
<dt>correct</dt><dd><p>default TRUE, used with method &ldquo;moments&rdquo; to compute the Smirnov/Anselin correction term</p>
</dd>
<dt>trunc</dt><dd><p>default TRUE, used with method &ldquo;moments&rdquo; to truncate the Smirnov/Anselin correction term</p>
</dd>
<dt>SE_method</dt><dd><p>default &ldquo;LU&rdquo;, may be &ldquo;MC&rdquo;</p>
</dd>
<dt>nrho</dt><dd><p>default 200, as in SE toolbox; the size of the first stage lndet grid; it may be reduced to for example 40</p>
</dd>
<dt>interpn</dt><dd><p>default 2000, as in SE toolbox; the size of the second stage lndet grid</p>
</dd>
<dt>small_asy</dt><dd><p>default TRUE; if the method is not &ldquo;eigen&rdquo;, use asymmetric covariances rather than numerical Hessian ones if n &lt;= small</p>
</dd>
<dt>small</dt><dd><p>default 1500; threshold number of observations for asymmetric covariances when the method is not &ldquo;eigen&rdquo;</p>
</dd>
<dt>SElndet</dt><dd><p>default NULL, may be used to pass a pre-computed SE toolbox style matrix of coefficients and their lndet values to the &quot;SE_classic&quot; and &quot;SE_whichMin&quot; methods</p>
</dd>
<dt>LU_order</dt><dd><p>default FALSE; used in &ldquo;LU_prepermutate&rdquo;, note warnings given for <code>lu</code> method</p>
</dd>
<dt>pre_eig</dt><dd><p>default NULL; may be used to pass a pre-computed vector of eigenvalues</p>
</dd>
<dt>OrdVsign</dt><dd><p>default 1; used to set the sign of the final component to negative if -1 (alpha times ((sigma squared) squared) in Ord (1975) equation B.1).</p>
</dd>
</dl>


<h3>Extra Bayesian control arguments</h3>


<dl>
<dt>ldet_method</dt><dd><p>default &ldquo;SE_classic&rdquo;; equivalent to the <code>method</code> argument in <code>lagsarlm</code></p>
</dd>
<dt>interval</dt><dd><p>default <code>c(-1, 1)</code>; used unmodified or set internally by <code>jacobianSetup</code></p>
</dd>
<dt>ndraw</dt><dd><p>default <code>2500L</code>; integer total number of draws</p>
</dd>
<dt>nomit</dt><dd><p>default <code>500L</code>; integer total number of omitted burn-in draws</p>
</dd>
<dt>thin</dt><dd><p>default <code>1L</code>; integer thinning proportion</p>
</dd>
<dt>verbose</dt><dd><p>default <code>FALSE</code>; inverse of <code>quiet</code> argument in <code>lagsarlm</code></p>
</dd>
<dt>detval</dt><dd><p>default <code>NULL</code>; not yet in use, precomputed matrix of log determinants</p>
</dd>
<dt>prior</dt><dd><p>a list with the following components:
</p>

<dl>
<dt>rhoMH, lambdaMH</dt><dd><p>default FALSE; use Metropolis or griddy Gibbs</p>
</dd>
<dt>Tbeta</dt><dd><p>default <code>NULL</code>; values of the betas variance-covariance matrix, set to <code>diag(k)*1e+12</code> if <code>NULL</code></p>
</dd>
<dt>c_beta</dt><dd><p>default <code>NULL</code>; values of the betas set to 0 if <code>NULL</code></p>
</dd>
<dt>rho</dt><dd><p>default <code>0.5</code>; value of the autoregressive coefficient</p>
</dd>
<dt>sige</dt><dd><p>default <code>1</code>; value of the residual variance</p>
</dd>
<dt>nu</dt><dd><p>default <code>0</code>; informative Gamma(nu,d0) prior on sige</p>
</dd>
<dt>d0</dt><dd><p>default <code>0</code>; informative Gamma(nu,d0) prior on sige</p>
</dd>
<dt>a1</dt><dd><p>default <code>1.01</code>; parameter for beta(a1,a2) prior on rho</p>
</dd>
<dt>a2</dt><dd><p>default <code>1.01</code>; parameter for beta(a1,a2) prior on rho</p>
</dd>
<dt>cc</dt><dd><p>default <code>0.2</code>; initial tuning parameter for M-H sampling</p>
</dd>
<dt>gG_sige</dt><dd><p>default TRUE; include sige in lambda griddy Gibbs update</p>
</dd>
<dt>cc1</dt><dd><p>default <code>0.2</code>; initial tuning parameter for M-H sampling</p>
</dd>
<dt>cc2</dt><dd><p>default <code>0.2</code>; initial tuning parameter for M-H sampling</p>
</dd>
</dl>
</dd>
</dl>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a>, with thanks to Abhirup Mallik and Virgilio Gómez-Rubio for initial coding GSoC 2011</p>


<h3>References</h3>

<p>LeSage J and RK Pace (2009) Introduction to Spatial Econometrics. CRC Press, Boca Raton.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#require("spdep", quietly=TRUE)
data(oldcol, package="spdep")
lw &lt;- spdep::nb2listw(COL.nb, style="W")
require("coda", quietly=TRUE)
set.seed(1)
COL.err.Bayes &lt;- spBreg_err(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw)
print(summary(COL.err.Bayes))
print(raftery.diag(COL.err.Bayes, r=0.01))
## Not run: 
ev &lt;- eigenw(lw)
W &lt;- as(lw, "CsparseMatrix")
trMatc &lt;- trW(W, type="mult")
set.seed(1)
COL.err.Bayes &lt;- spBreg_err(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 control=list(prior=list(lambdaMH=TRUE)))
print(summary(COL.err.Bayes))
print(raftery.diag(COL.err.Bayes, r=0.01))
set.seed(1)
COL.err.Bayes &lt;- spBreg_err(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 Durbin=TRUE)
print(summary(COL.err.Bayes))
print(summary(impacts(COL.err.Bayes)))
print(raftery.diag(COL.err.Bayes, r=0.01))
set.seed(1)
COL.err.Bayes &lt;- spBreg_err(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 Durbin=TRUE, control=list(prior=list(lambdaMH=TRUE)))
print(summary(COL.err.Bayes))
print(summary(impacts(COL.err.Bayes)))
print(raftery.diag(COL.err.Bayes, r=0.01))
set.seed(1)
COL.err.Bayes &lt;- spBreg_err(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 Durbin=~INC)
print(summary(COL.err.Bayes))
print(summary(impacts(COL.err.Bayes)))
print(raftery.diag(COL.err.Bayes, r=0.01))
set.seed(1)
COL.err.Bayes &lt;- spBreg_err(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 Durbin=~INC, control=list(prior=list(lambdaMH=TRUE)))
print(summary(COL.err.Bayes))
print(summary(impacts(COL.err.Bayes)))
print(raftery.diag(COL.err.Bayes, r=0.01))
set.seed(1)
COL.sacW.B0 &lt;- spBreg_sac(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 Durbin=FALSE, control=list(ndraw=1500L, nomit=500L))
print(summary(COL.sacW.B0))
print(summary(impacts(COL.sacW.B0, tr=trMatc), zstats=TRUE, short=TRUE))
set.seed(1)
COL.sacW.B1 &lt;- spBreg_sac(CRIME ~ INC + HOVAL, data=COL.OLD, listw=lw,
 Durbin=TRUE, control=list(ndraw=1500L, nomit=500L))
print(summary(COL.sacW.B1))
print(summary(impacts(COL.sacW.B1, tr=trMatc), zstats=TRUE, short=TRUE))
set.seed(1)
COL.lag.Bayes &lt;- spBreg_lag(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw=lw)
print(summary(COL.lag.Bayes))
print(summary(impacts(COL.lag.Bayes, tr=trMatc), short=TRUE, zstats=TRUE))
print(summary(impacts(COL.lag.Bayes, evalues=ev), short=TRUE, zstats=TRUE))
set.seed(1)
COL.D0.Bayes &lt;- spBreg_lag(CRIME ~ INC + HOVAL, data=COL.OLD,
 listw=lw, Durbin=TRUE)
print(summary(COL.D0.Bayes))
print(summary(impacts(COL.D0.Bayes, tr=trMatc), short=TRUE, zstats=TRUE))
set.seed(1)
COL.D1.Bayes &lt;- spBreg_lag(CRIME ~ DISCBD + INC + HOVAL, data=COL.OLD,
 listw=lw, Durbin= ~ INC)
print(summary(COL.D1.Bayes))
print(summary(impacts(COL.D1.Bayes, tr=trMatc), short=TRUE, zstats=TRUE))
#data(elect80, package="spData")
#lw &lt;- spdep::nb2listw(e80_queen, zero.policy=TRUE)
#el_ml &lt;- lagsarlm(log(pc_turnout) ~ log(pc_college) + log(pc_homeownership)
# + log(pc_income), data=elect80, listw=lw, zero.policy=TRUE, method="LU")
#print(summary(el_ml))
#set.seed(1)
#el_B &lt;- spBreg_lag(log(pc_turnout) ~ log(pc_college) + log(pc_homeownership)
# + log(pc_income), data=elect80, listw=lw, zero.policy=TRUE)
#print(summary(el_B))
#print(el_ml$timings)
#print(attr(el_B, "timings"))

## End(Not run)
</code></pre>

<hr>
<h2 id='stsls'>Generalized spatial two stage least squares</h2><span id='topic+stsls'></span><span id='topic+print.Stsls'></span><span id='topic+print.summary.Stsls'></span><span id='topic+summary.Stsls'></span><span id='topic+residuals.Stsls'></span><span id='topic+coef.Stsls'></span><span id='topic+deviance.Stsls'></span><span id='topic+impacts.Stsls'></span>

<h3>Description</h3>

<p>The function fits a spatial lag model by two stage least squares, with the option of adjusting the results for heteroskedasticity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stsls(formula, data = list(), listw, zero.policy = NULL,
 na.action = na.fail, robust = FALSE, HC=NULL, legacy=FALSE, W2X = TRUE)
## S3 method for class 'Stsls'
impacts(obj, ..., tr, R = NULL, listw = NULL, evalues=NULL,
 tol = 1e-06, empirical = FALSE, Q=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stsls_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit. The details 
of model specification are given for <code>lm()</code></p>
</td></tr>
<tr><td><code id="stsls_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables in the model. 
By default the variables are taken from the environment which the function 
is called.</p>
</td></tr>
<tr><td><code id="stsls_+3A_listw">listw</code></td>
<td>
<p>a <code>listw</code> object created for example by <code>nb2listw</code></p>
</td></tr>
<tr><td><code id="stsls_+3A_zero.policy">zero.policy</code></td>
<td>
<p>default NULL, use global option value; if TRUE assign zero to the lagged value of zones without 
neighbours, if FALSE (default) assign NA - causing <code>lagsarlm()</code> to terminate with an error</p>
</td></tr>
<tr><td><code id="stsls_+3A_na.action">na.action</code></td>
<td>
<p>a function (default <code>na.fail</code>), can also be <code>na.omit</code> or <code>na.exclude</code> with consequences for residuals and fitted values - in these cases the weights list will be subsetted to remove NAs in the data. It may be necessary to set zero.policy to TRUE because this subsetting may create no-neighbour observations. Note that only weights lists created without using the glist argument to <code>nb2listw</code> may be subsetted.</p>
</td></tr>
<tr><td><code id="stsls_+3A_robust">robust</code></td>
<td>
<p>default FALSE, if TRUE, apply a heteroskedasticity correction to the coefficients covariances</p>
</td></tr>
<tr><td><code id="stsls_+3A_hc">HC</code></td>
<td>
<p>default NULL, if <code>robust</code> is TRUE, assigned &ldquo;HC0&rdquo;, may take values &ldquo;HC0&rdquo; or &ldquo;HC1&rdquo; for White estimates or MacKinnon-White estimates respectively</p>
</td></tr>
<tr><td><code id="stsls_+3A_legacy">legacy</code></td>
<td>
<p>the argument chooses between two implementations of the robustness correction: default FALSE - use the estimate of Omega only in the White consistent estimator of the variance-covariance matrix, if TRUE, use the original implementation which runs a GLS using the estimate of Omega, and yields different coefficient estimates as well - see example below</p>
</td></tr>
<tr><td><code id="stsls_+3A_w2x">W2X</code></td>
<td>
<p>default TRUE, if FALSE only WX are used as instruments in the spatial two stage least squares; until release 0.4-60, only WX were used - see example below </p>
</td></tr>
<tr><td><code id="stsls_+3A_obj">obj</code></td>
<td>
<p>A spatial regression object created by <code>lagsarlm</code>, <code>lagmess</code> or by <code>lmSLX</code>; in <code>HPDinterval.LagImpact</code>, a LagImpact object</p>
</td></tr>
<tr><td><code id="stsls_+3A_...">...</code></td>
<td>
<p>Arguments passed through to methods in the <span class="pkg">coda</span> package</p>
</td></tr>
<tr><td><code id="stsls_+3A_tr">tr</code></td>
<td>
<p>A vector of traces of powers of the spatial weights matrix created using <code>trW</code>, for approximate impact measures; if not given, <code>listw</code> must be given for exact measures (for small to moderate spatial weights matrices); the traces must be for the same spatial weights as were used in fitting the spatial regression, and must be row-standardised</p>
</td></tr>
<tr><td><code id="stsls_+3A_evalues">evalues</code></td>
<td>
<p>vector of eigenvalues of spatial weights matrix for impacts calculations</p>
</td></tr>
<tr><td><code id="stsls_+3A_r">R</code></td>
<td>
<p>If given, simulations are used to compute distributions for the impact measures, returned as <code>mcmc</code> objects; the objects are used for convenience but are not output by an MCMC process</p>
</td></tr>
<tr><td><code id="stsls_+3A_tol">tol</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code>: tolerance (relative to largest variance) for numerical lack of positive-definiteness in the coefficient covariance matrix</p>
</td></tr>
<tr><td><code id="stsls_+3A_empirical">empirical</code></td>
<td>
<p>Argument passed to <code>mvrnorm</code> (default FALSE): if true, the coefficients and their covariance matrix specify the empirical not population mean and covariance matrix</p>
</td></tr>
<tr><td><code id="stsls_+3A_q">Q</code></td>
<td>
<p>default NULL, else an integer number of cumulative power series impacts to calculate if <code>tr</code> is given</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fitting implementation fits a spatial lag model:
</p>
<p style="text-align: center;"><code class="reqn">y = \rho W y + X \beta + \varepsilon</code>
</p>

<p>by using spatially lagged X variables as instruments for the spatially lagged dependent variable.
</p>


<h3>Value</h3>

<p>an object of class &quot;Stsls&quot; containing:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>coefficient estimates</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p>coefficient covariance matrix</p>
</td></tr>
<tr><td><code>sse</code></td>
<td>
<p>sum of squared errors</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>model residuals</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luc Anselin, Gianfranco Piras and Roger Bivand</p>


<h3>References</h3>

<p>Kelejian, H.H. and I.R. Prucha (1998). A generalized spatial two
stage least squares procedure for estimating a spatial autoregressive
model with autoregressive disturbances. <em>Journal of Real Estate
Finance and Economics</em> 17, 99-121.
</p>
<p>Roger Bivand, Gianfranco Piras (2015). Comparing Implementations of Estimation Methods for Spatial Econometrics. <em>Journal of Statistical Software</em>, 63(18), 1-36. <a href="https://doi.org/10.18637/jss.v063.i18">doi:10.18637/jss.v063.i18</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lagsarlm">lagsarlm</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(oldcol, package="spdep")
#require(spdep, quietly=TRUE)
lw &lt;- spdep::nb2listw(COL.nb)
COL.lag.eig &lt;- lagsarlm(CRIME ~ INC + HOVAL, data=COL.OLD, lw)
summary(COL.lag.eig, correlation=TRUE)
COL.lag.stsls &lt;- stsls(CRIME ~ INC + HOVAL, data=COL.OLD, lw)
(x &lt;- summary(COL.lag.stsls, correlation=TRUE))
coef(x)
W &lt;- as(lw, "CsparseMatrix")
trMatc &lt;- trW(W, type="mult")
loobj1 &lt;- impacts(COL.lag.stsls, R=200, tr=trMatc)
summary(loobj1, zstats=TRUE, short=TRUE)
ev &lt;- eigenw(lw)
loobj2 &lt;- impacts(COL.lag.stsls, R=200, evalues=ev)
summary(loobj2, zstats=TRUE, short=TRUE)
require(coda)
HPDinterval(loobj1)
COL.lag.stslsW &lt;- stsls(CRIME ~ INC + HOVAL, data=COL.OLD, lw, W2X=FALSE)
summary(COL.lag.stslsW, correlation=TRUE)
COL.lag.stslsR &lt;- stsls(CRIME ~ INC + HOVAL, data=COL.OLD, lw,
robust=TRUE, W2X=FALSE)
summary(COL.lag.stslsR, correlation=TRUE)
COL.lag.stslsRl &lt;- stsls(CRIME ~ INC + HOVAL, data=COL.OLD, lw,
robust=TRUE, legacy=TRUE, W2X=FALSE)
summary(COL.lag.stslsRl, correlation=TRUE)
data(boston, package="spData")
gp2a &lt;- stsls(log(CMEDV) ~ CRIM + ZN + INDUS + CHAS + I(NOX^2) + I(RM^2) +
  AGE + log(DIS) + log(RAD) + TAX + PTRATIO + B + log(LSTAT),
 data=boston.c, spdep::nb2listw(boston.soi))
summary(gp2a)
</code></pre>

<hr>
<h2 id='trW'>Spatial weights matrix powers traces</h2><span id='topic+trW'></span><span id='topic+mom_calc'></span><span id='topic+mom_calc_int2'></span>

<h3>Description</h3>

<p>The function is used to prepare a vector of traces of powers of a spatial weights matrix</p>


<h3>Usage</h3>

<pre><code class='language-R'>trW(W=NULL, m = 30, p = 16, type = "mult", listw=NULL, momentsSymmetry=TRUE)
mom_calc(lw, m)
mom_calc_int2(is, m, nb, weights, Card)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trW_+3A_w">W</code></td>
<td>
<p>A spatial weights matrix in CsparseMatrix form</p>
</td></tr>
<tr><td><code id="trW_+3A_m">m</code></td>
<td>
<p>The number of powers; must be an even number for &lsquo;type&rsquo;=&ldquo;moments&rdquo; (default changed from 100 to 30 (2010-11-17))</p>
</td></tr>
<tr><td><code id="trW_+3A_p">p</code></td>
<td>
<p>The number of samples used in Monte Carlo simulation of the traces if type is MC (default changed from 50 to 16 (2010-11-17))</p>
</td></tr>
<tr><td><code id="trW_+3A_type">type</code></td>
<td>
<p>Either &ldquo;mult&rdquo; (default) for powering a sparse matrix (with moderate or larger N, the matrix becomes dense, and may lead to swapping), or &ldquo;MC&rdquo; for Monte Carlo simulation of the traces (the first two simulated traces are replaced by their analytical equivalents), or &ldquo;moments&rdquo; to use the looping space saving algorithm proposed by Smirnov and Anselin (2009) - for &ldquo;moments&rdquo;, <code>W</code> must be symmetric, for row-standardised weights through a similarity transformation</p>
</td></tr>
<tr><td><code id="trW_+3A_listw">listw</code>, <code id="trW_+3A_lw">lw</code></td>
<td>
<p>a listw object, which should either be fully symmetric, or be constructed as similar to symmetric from intrinsically symmetric neighbours using <code><a href="#topic+similar.listw">similar.listw</a></code>, used with &lsquo;type&rsquo;=&ldquo;moments&rdquo;</p>
</td></tr>
<tr><td><code id="trW_+3A_momentssymmetry">momentsSymmetry</code></td>
<td>
<p>default TRUE; assert Smirnov/Anselin symmetry assumption</p>
</td></tr>
<tr><td><code id="trW_+3A_is">is</code></td>
<td>
<p>(used internally only in <code>mom_calc_int2</code> for &lsquo;type&rsquo;=&ldquo;moments&rdquo; on a cluster)</p>
</td></tr>
<tr><td><code id="trW_+3A_nb">nb</code></td>
<td>
<p>(used internally only in <code>mom_calc_int2</code> for &lsquo;type&rsquo;=&ldquo;moments&rdquo; on a cluster)</p>
</td></tr>
<tr><td><code id="trW_+3A_weights">weights</code></td>
<td>
<p>(used internally only in <code>mom_calc_int2</code> for &lsquo;type&rsquo;=&ldquo;moments&rdquo; on a cluster)</p>
</td></tr>
<tr><td><code id="trW_+3A_card">Card</code></td>
<td>
<p>(used internally only in <code>mom_calc_int2</code> for &lsquo;type&rsquo;=&ldquo;moments&rdquo; on a cluster)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of <code>m</code> traces, with &ldquo;timings&rdquo; and &ldquo;type&rdquo; attributes; the &lsquo;type&rsquo;=&ldquo;MC&rdquo; also returns the standard deviation of the p-vector V divided by the square root of p as a measure of spread for the trace estimates.
</p>


<h3>Note</h3>

<p><code>mom_calc</code> and <code>mom_calc_int2</code> are for internal use only</p>


<h3>Author(s)</h3>

<p>Roger Bivand <a href="mailto:Roger.Bivand@nhh.no">Roger.Bivand@nhh.no</a></p>


<h3>References</h3>

<p>LeSage J and RK Pace (2009) <em>Introduction to Spatial Econometrics</em>. CRC Press, Boca Raton, pp. 96&ndash;105; Smirnov O and L Anselin (2009) An O(N) parallel method of computing the Log-Jacobian of the variable transformation for models with spatial interaction on a lattice. <em>Computational Statistics and Data Analysis</em> 53 (2009) 2983&ndash;2984.</p>


<h3>See Also</h3>

<p><code><a href="#topic+as_dgRMatrix_listw">as_dgRMatrix_listw</a></code>, <code><a href="spdep.html#topic+nb2listw">nb2listw</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require("sf", quietly=TRUE) 
columbus &lt;- st_read(system.file("shapes/columbus.shp", package="spData")[1], quiet=TRUE)
#require(spdep, quietly=TRUE)
col.gal.nb &lt;- spdep::read.gal(system.file("weights/columbus.gal", package="spData")[1])
listw &lt;- spdep::nb2listw(col.gal.nb)
W &lt;- as(listw, "CsparseMatrix")
system.time(trMat &lt;- trW(W, type="mult"))
str(trMat)
set.seed(1100)
system.time(trMC &lt;- trW(W, type="MC"))
str(trMC)
plot(trMat, trMC)
abline(a=0, b=1)
for(i in 3:length(trMC)) {
 segments(trMat[i], trMC[i]-2*attr(trMC, "sd")[i], trMat[i],
  trMC[i]+2*attr(trMC, "sd")[i])
}
listwS &lt;- similar.listw(listw)
W &lt;- forceSymmetric(as(listwS, "CsparseMatrix"))
system.time(trmom &lt;- trW(listw=listwS, m=24, type="moments"))
str(trmom)
all.equal(trMat[1:24], trmom, check.attributes=FALSE)
system.time(trMat &lt;- trW(W, m=24, type="mult"))
str(trMat)
all.equal(trMat, trmom, check.attributes=FALSE)
set.seed(1)
system.time(trMC &lt;- trW(W, m=24, type="MC"))
str(trMC)
## Not run: 
data(boston, package="spData")
listw &lt;- spdep::nb2listw(boston.soi)
listwS &lt;- similar.listw(listw)
system.time(trmom &lt;- trW(listw=listwS, m=24, type="moments"))
str(trmom)
library(parallel)
nc &lt;- max(2L, detectCores(logical=FALSE), na.rm = TRUE)-1L
# set nc to 1L here
if (nc &gt; 1L) nc &lt;- 1L
coresOpt &lt;- get.coresOption()
invisible(set.coresOption(nc))
if(!get.mcOption()) {
  cl &lt;- makeCluster(get.coresOption())
  set.ClusterOption(cl)
}
system.time(trmomp &lt;- trW(listw=listwS, m=24, type="moments"))
if(!get.mcOption()) {
  set.ClusterOption(NULL)
  stopCluster(cl)
}
all.equal(trmom, trmomp, check.attributes=FALSE)
invisible(set.coresOption(coresOpt))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
