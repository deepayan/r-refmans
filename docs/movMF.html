<!DOCTYPE html><html lang="en"><head><title>Help for package movMF</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {movMF}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#FLXMCvMF'><p>Flexmix Driver for Mixtures of von Mises-Fisher Distributions</p></a></li>
<li><a href='#movMF'><p>Fit Mixtures of von Mises-Fisher Distributions</p></a></li>
<li><a href='#movMF_distribution'><p>Mixtures of von Mises-Fisher Distributions</p></a></li>
<li><a href='#useR_2008_abstracts'><p>useR! 2008 Abstracts</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.2-9</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Mixtures of von Mises-Fisher Distributions</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit and simulate mixtures of von Mises-Fisher distributions.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>skmeans (&ge; 0.2-10), clue, slam (&ge; 0.1-43), stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lattice, tm (&ge; 0.7-5), vcd, SnowballC, HSAUR3, colorspace,
flexmix (&ge; 2.3-17), methods</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-13 06:57:44 UTC; hornik</td>
</tr>
<tr>
<td>Author:</td>
<td>Kurt Hornik <a href="https://orcid.org/0000-0003-4198-9911"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Bettina Grün <a href="https://orcid.org/0000-0001-7265-4773"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kurt Hornik &lt;Kurt.Hornik@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-13 07:13:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='FLXMCvMF'>Flexmix Driver for Mixtures of von Mises-Fisher Distributions</h2><span id='topic+FLXMCvMF'></span>

<h3>Description</h3>

<p>This driver for <code><a href="flexmix.html#topic+flexmix">flexmix</a></code> implements
estimation of mixtures of von Mises-Fisher distributions where the
data can be stored in a dense or a <a href="slam.html#topic+simple+20triplet+20matrix">simple triplet matrix</a>
(package <span class="pkg">slam</span>) format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FLXMCvMF(formula = . ~ ., kappa = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FLXMCvMF_+3A_formula">formula</code></td>
<td>
<p>a formula which is interpreted relative to the formula
specified in the call to <code><a href="flexmix.html#topic+flexmix">flexmix</a></code> using
<code><a href="stats.html#topic+update.formula">update.formula</a></code>.  Only the
left-hand side (response) of the formula is used. Default is to use
the original <code><a href="flexmix.html#topic+flexmix">flexmix</a></code> model
formula.</p>
</td></tr>
<tr><td><code id="FLXMCvMF_+3A_kappa">kappa</code></td>
<td>
<p>see the <code>control</code> argument of <code><a href="#topic+movMF">movMF</a></code></p>
</td></tr></table>
<p>.
</p>


<h3>Value</h3>

<p>An object of class <code>"FLXMCvMF"</code>.
</p>


<h3>Author(s)</h3>

<p>Bettina Grün
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("flexmix", quietly = TRUE)) {
## Generate and fit a "small-mix" data set a la Banerjee et al.
mu &lt;- rbind(c(-0.251, -0.968),
            c(0.399, 0.917))
kappa &lt;- c(4, 4)
theta &lt;- kappa * mu
theta
alpha &lt;- c(0.48, 0.52)
## Generate a sample of size n = 50 from the von Mises-Fisher mixture
## with the above parameters.
set.seed(123)
x &lt;- rmovMF(50, theta, alpha)
## Fit a von Mises-Fisher mixture with the "right" number of components,
## using 10 EM runs.
set.seed(123)
y2 &lt;- flexmix::stepFlexmix(x ~ 1, k = 2, model = FLXMCvMF(), verbose = FALSE)
## Inspect the fitted parameters:
y2
## Compare the fitted classes to the true ones:
table(True = attr(x, "z"), Fitted = flexmix::clusters(y2))
## To use a common kappa:
y2cv &lt;- flexmix::stepFlexmix(x ~ 1, k = 2,
  model = FLXMCvMF(kappa = list(common = TRUE)), verbose = FALSE)
## To use a common kappa fixed to the true value of 4:
y2cf &lt;- flexmix::stepFlexmix(x ~ 1, k = 2,
  model = FLXMCvMF(kappa = 4), verbose = FALSE)
## Comparing solutions via BIC:
sapply(list(y2, y2cf, y2cv), BIC)
##  Use a different kappa solver:
set.seed(123)
y2a &lt;- flexmix::stepFlexmix(x ~ 1, k = 2,
  model = FLXMCvMF(kappa = "uniroot"), verbose = FALSE)
y2a
## Using a sparse matrix:
x &lt;- slam::as.simple_triplet_matrix(x)
y2 &lt;- flexmix::stepFlexmix(x ~ 1, k = 2,
  model = FLXMCvMF(), verbose = FALSE)
}
</code></pre>

<hr>
<h2 id='movMF'>Fit Mixtures of von Mises-Fisher Distributions</h2><span id='topic+movMF'></span>

<h3>Description</h3>

<p>Fit mixtures of von Mises-Fisher distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movMF(x, k, control = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="movMF_+3A_x">x</code></td>
<td>
<p>a numeric data matrix, with rows corresponding to
observations.  Standardized to unit row lengths if necessary.
Can be a dense matrix, a
<a href="slam.html#topic+simple+20triplet+20matrix">simple triplet matrix</a>
(package <span class="pkg">slam</span>), or a
<a href="Matrix.html#topic+dgTMatrix-class">dgTMatrix</a>
(package <span class="pkg">Matrix</span>).</p>
</td></tr>
<tr><td><code id="movMF_+3A_k">k</code></td>
<td>
<p>an integer giving the desired number of mixture components
(classes).</p>
</td></tr>
<tr><td><code id="movMF_+3A_control">control</code></td>
<td>
<p>a list of control parameters.  See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="movMF_+3A_...">...</code></td>
<td>
<p>a list of control parameters (overriding those specified
in <code>control</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>movMF</code> returns an object of class <code>"movMF"</code> representing
the fitted mixture of von Mises-Fisher distributions model.  Available
methods for such objects include <code><a href="stats.html#topic+coef">coef</a></code>,
<code><a href="stats.html#topic+logLik">logLik</a></code>, <code><a href="base.html#topic+print">print</a></code> and <code><a href="stats.html#topic+predict">predict</a></code>.
<code><a href="stats.html#topic+predict">predict</a></code> has an extra <code>type</code> argument with possible
values <code>"class_ids"</code> (default) and <code>"memberships"</code> for
indicating hard or soft prediction, respectively.
</p>
<p>The mixture of von Mises-Fisher distributions is fitted using EM
variants as specified by control option <code>E</code> (specifying the
E-step employed), with possible values <code>"softmax"</code> (default),
<code>"hardmax"</code> or <code>"stochmax"</code> where the first two implement
algorithms soft-moVMF and hard-moVMF of Banerjee et al (2005).  For
<code>"stochmax"</code>, class assignments are drawn from the posteriors for
each observation in the E-step as outlined as SEM in Celeux and
Govaert (1992). The stopping criterion for this algorithm is by
default changed to not check for convergence (logical control option
<code>converge</code>), but to return the parameters with the maximum
likelihood encountered. <code>E</code> may be abbreviated.
</p>
<p>In the M-step, the parameters <code class="reqn">\theta</code> of the respective component
distributions are estimated via maximum likelihood, which is
accomplished by taking <code class="reqn">\theta</code> proportional to suitable weighted
sample means <code class="reqn">\bar{x}</code>, with length <code class="reqn">\kappa</code> solving the
equation <code class="reqn">A_d(\kappa) = \|\bar{x}\|</code>, where
<code class="reqn">A_d(\kappa) = I_{d/2}(\kappa) / I_{d/2-1}(\kappa)</code> with <code class="reqn">I</code>
the modified Bessel function of the first kind.  Via control argument
<code>kappa</code>, one can specify how to (approximately) solve these
equations, and whether a common (possibly given) length <code class="reqn">\kappa</code>
should be employed.  If <code>kappa</code> is a number, it gives a common
length to be employed.  If it is a character string, it specifies the
method to be used for solving the <code class="reqn">\kappa</code> equation. The possible
methods are:
</p>

<dl>
<dt><code>"Banerjee_et_al_2005"</code></dt><dd><p>uses the approximation of
Banerjee et al (2005).</p>
</dd>
<dt><code>"Tanabe_et_al_2007"</code></dt><dd><p>uses the fixed-point iteration of
Tanabe et al (2007) with starting point for <code class="reqn">\kappa</code> in the
interval established by Tanabe et al (2007) implied by a given
<code>c</code> with values in [0, 2]. The default is <code>c</code> = 1, the
mid-point of the interval.</p>
</dd>
<dt><code>"Sra_2012"</code></dt><dd><p>uses two Newton steps as suggested in
Sra (2012) starting in the approximation of Banerjee et al (2005).</p>
</dd>
<dt><code>"Song_et_al_2012"</code></dt><dd><p>uses two Halley steps as
suggested in Song et al (2012) starting in the approximation of
Banerjee et al (2005).</p>
</dd>
<dt><code>"uniroot"</code></dt><dd><p>uses a straightforward call to
<code><a href="stats.html#topic+uniroot">uniroot</a></code> with the bounds established in Hornik and
Grün (2014).</p>
</dd>
<dt><code>"Newton"</code></dt><dd><p>uses a full Newton algorithm started in the
approximation of Hornik and Grün (2014).</p>
</dd>
<dt><code>"Halley"</code></dt><dd><p>uses a full Halley algorithm started in the
approximation of Hornik and Grün (2014).</p>
</dd>
<dt><code>"hybrid"</code></dt><dd><p>implements a combination of a
derivative-based step (Newton or Halley) and a bisection step as
outlined in Press et al. (2002). The derivative-based step can be
specified via the argument <code>step</code> which expects a function
performing this step. Currently <code>step_Newton</code> and
<code>step_Halley</code> (default) are available.</p>
</dd>
<dt><code>"Newton_Fourier"</code> (default)</dt><dd><p>uses a variant of the
Newton-Fourier method for strictly increasing concave functions as
for example given in Atkinson (1989, pp. 62&ndash;64). Concavity can
be established using Hornik and Grün (2013).</p>
</dd>
</dl>

<p>The lower-cased version of the given <code>kappa</code> specification is
matched against the lower-cased names of the available methods using
<code><a href="base.html#topic+pmatch">pmatch</a></code>.  Finally, to indicate using a common (but not
given) <code class="reqn">\kappa</code> for all component distributions, <code>kappa</code>
should be a list with element <code>common = TRUE</code> (and optionally a
character string giving the estimation method).
</p>
<p>Additional control parameters are as follows.
</p>

<dl>
<dt><code>maxiter</code></dt><dd><p>an integer giving the maximal number of EM
iterations to be performed.  Default: 100.
</p>
</dd>
<dt><code>reltol</code></dt><dd><p>the minimum relative improvement of the
objective function per iteration. If improvement is less, the EM
algorithm will stop under the assumption that no further
significant improvement can be made.  Defaults to
<code>sqrt(.Machine$double.eps)</code>.
</p>
</dd>
<dt><code>ids</code></dt><dd><p>either a vector of class memberships or
<code>TRUE</code> which implies that the class memberships are obtained
from the attribute named <code>"z"</code> of the input data; these class
memberships are used for initializing the EM algorithm and the
algorithm is stopped after the first iteration.</p>
</dd>
<dt><code>start</code></dt><dd><p>a specification of the starting values to be
employed.  Can be a list of matrices giving the memberships of
objects to components, or of vectors giving component ids
(numbers from 1 to the given <code>k</code>).  Can also be a character
vector with elements <code>"i"</code> (randomly pick component ids for
the observations), or one of <code>"p"</code>, <code>"S"</code> or <code>"s"</code>.
The latter first determine component &ldquo;prototypes&rdquo;, and then
determine an optimal &ldquo;fuzzy&rdquo; membership matrix from the
implied cosine dissimilarities between observations and
prototypes.  Prototypes are obtained as follows: for <code>"p"</code>,
observations are randomly picked.  For <code>"S"</code>, one takes the
first prototype to minimize total cosine dissimilarity to the
observations, and then successively picks observations farthest
away from the already picked prototypes.  For <code>"s"</code>, one
takes a randomly chosen observation as the first prototype, and
then proceeds as for <code>"S"</code>. 
</p>
<p>By default, initialization method <code>"p"</code> is used.
</p>
<p>If several starting values are specified, the EM algorithm is
performed individually to each starting value, and the best
solution found is returned.
</p>
</dd>
<dt><code>nruns</code></dt><dd><p>an integer giving the number of EM runs to be
performed.  Default: 1. 
Only used if <code>start</code> is not given.
</p>
</dd>
<dt><code>minalpha</code></dt><dd><p>a numeric indicating the minimum prior
probability.  Components falling below this threshold are removed
during the iteration.  If <code class="reqn">\ge 1</code>, this is taken as the
minimal number of observations in a component.
Default: 0.</p>
</dd>
<dt><code>converge</code></dt><dd><p>a logical, if <code>TRUE</code> the EM algorithm is
stopped if the <code>reltol</code> criterion is met and the current
parameter estimate is returned. If <code>FALSE</code> the EM algorithm
is run for <code>maxiter</code> iterations and the parametrizations
with the maximum likelihood encountered during the EM algorithm is
returned. Default: <code>TRUE</code>, changed to <code>FALSE</code> if
<code>E="stochmax"</code>.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>a logical indicating whether to provide
some output on algorithmic progress.
Defaults to <code>getOption("verbose")</code>.</p>
</dd>
</dl>

<p>One popular application context of mixtures of von Mises-Fisher
distributions is text mining, where the data matrices are typically
very large and sparse.  The provided implementation should be able to
handle such large corpora with reasonable efficiency by employing
suitable sparse matrix representations and computations.  In addition,
straightforward computations of the normalizing constants in the von
Mises-Fisher densities (see <a href="#topic+dmovMF">movMF_distribution</a>) by
directly employing the modified Bessel functions of the first kind are
computationally infeasible for large <code class="reqn">d</code> (dimension of the
observations) and/or values of the parameter lengths <code class="reqn">\kappa</code>.
Instead, we use suitably scaled hypergeometric-type power series for
computing (the logarithms of) the normalizing constants.
</p>


<h3>Value</h3>

<p>An object of class <code>"movMF"</code> representing the fitted mixture of
von Mises-Fisher distributions, which is a list containing at least
the following components:
</p>
<table role = "presentation">
<tr><td><code>theta</code></td>
<td>
<p>a matrix with rows giving the fitted parameters of the
mixture components.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>a numeric vector with the fitted mixture probabilities.</p>
</td></tr>
</table>
<p>See <a href="#topic+vMF">vMF</a> for the employed parametrization of the von
Mises-Fisher distribution.
</p>


<h3>References</h3>

<p>K. E. Atkinson (1989).
<em>An Introduction to Numerical Analysis.</em>
2nd edition. John Wiley &amp; Sons.
</p>
<p>A. Banerjee, I. S. Dhillon, J. Ghosh, and S. Sra (2005).
Clustering on the unit hypersphere using von Mises-Fisher
distributions.
<em>Journal of Machine Learning Research</em>, <b>6</b>, 1345&ndash;1382.
<a href="https://jmlr.csail.mit.edu/papers/v6/banerjee05a.html">https://jmlr.csail.mit.edu/papers/v6/banerjee05a.html</a>.
</p>
<p>G. Celeux, and G. Govaert (1992).
A classification EM algorithm for clustering and two stochastic
versions.
<em>Computational Statistics &amp; Data Analysis</em>, <b>14</b>, 315&ndash;332.
<a href="https://doi.org/10.1016/0167-9473%2892%2990042-E">doi:10.1016/0167-9473(92)90042-E</a>.
</p>
<p>K. Hornik, and B. Grün (2013).
Amos-type bounds for modified Bessel function ratios.
<em>Journal of Mathematical Analysis and Applications</em>,
<b>408</b>(1), 91&ndash;101.
<a href="https://doi.org/10.1016/j.jmaa.2013.05.070">doi:10.1016/j.jmaa.2013.05.070</a>.
</p>
<p>K. Hornik, and B. Grün (2014).
On maximum likelihood estimation of the concentration
parameter of von Mises-Fisher distributions.
<em>Computational Statistics</em>, <b>29</b>, 945&ndash;957.
<a href="https://doi.org/10.1007/s00180-013-0471-0">doi:10.1007/s00180-013-0471-0</a>.
</p>
<p>W. H. Press, S. A. Teukolsky, W. T. Vetterling and Brian P. Flannery
(2002).
<em>Numerical Recipes in C: The Art of Scientific Computing.</em>
2nd edition. Cambridge University Press.
</p>
<p>H. Song, J. Liu, and G. Wang.
High-order parameter approximation for von Mises-Fisher distributions.
<em>Applied Mathematics and Computation</em>, <b>218</b>, 11880&ndash;11890.
<a href="https://doi.org/10.1016/j.amc.2012.05.050">doi:10.1016/j.amc.2012.05.050</a>.
</p>
<p>S. Sra (2012).
A short note on parameter approximation for von Mises-Fisher
distributions: and a fast implementation of <code class="reqn">I_s(x)</code>.
<em>Computational Statistics</em>, <b>27</b>, 177&ndash;190.
<a href="https://doi.org/10.1007/s00180-011-0232-x">doi:10.1007/s00180-011-0232-x</a>.
</p>
<p>A. Tanabe, K. Fukumizu, S. Oba, T. Takenouchi, and S. Ishii.
Parameter estimation for von Mises-Fisher distributions.
<em>Computational Statistics</em>, <b>22</b>, 145&ndash;157.
<a href="https://doi.org/10.1007/s00180-007-0030-7">doi:10.1007/s00180-007-0030-7</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate and fit a "small-mix" data set a la Banerjee et al.
mu &lt;- rbind(c(-0.251, -0.968),
            c(0.399, 0.917))
kappa &lt;- c(4, 4)
theta &lt;- kappa * mu
theta
alpha &lt;- c(0.48, 0.52)
## Generate a sample of size n = 50 from the von Mises-Fisher mixture
## with the above parameters.
set.seed(123)
x &lt;- rmovMF(50, theta, alpha)
## Fit a von Mises-Fisher mixture with the "right" number of components,
## using 10 EM runs.
set.seed(123)
y2 &lt;- movMF(x, 2, nruns = 10)
## Inspect the fitted parameters:
y2
## Compare the fitted classes to the true ones:
table(True = attr(x, "z"), Fitted = predict(y2))
## To use a common kappa:
y2cv &lt;- movMF(x, 2, nruns = 10, kappa = list(common = TRUE))
## To use a common kappa fixed to the true value of 4:
y2cf &lt;- movMF(x, 2, nruns = 10, kappa = 4)
## Comparing solutions via BIC:
sapply(list(y2, y2cf, y2cv), BIC)
##  Use a different kappa solver:
set.seed(123)
y2a &lt;- movMF(x, 2, nruns = 10, kappa = "uniroot")
y2a
</code></pre>

<hr>
<h2 id='movMF_distribution'>Mixtures of von Mises-Fisher Distributions</h2><span id='topic+dmovMF'></span><span id='topic+rmovMF'></span><span id='topic+vMF'></span>

<h3>Description</h3>

<p>Density and random number generation for finite mixtures of von
Mises-Fisher distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dmovMF(x, theta, alpha = 1, log = FALSE)
rmovMF(n, theta, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="movMF_distribution_+3A_x">x</code></td>
<td>
<p>a matrix of rows of points on the unit hypersphere.
Standardized to unit row length if necessary.</p>
</td></tr>
<tr><td><code id="movMF_distribution_+3A_theta">theta</code></td>
<td>
<p>a matrix with rows giving the parameters of the mixture
components.</p>
</td></tr>
<tr><td><code id="movMF_distribution_+3A_alpha">alpha</code></td>
<td>
<p>a numeric vector with non-negative elements giving the
mixture probabilities.
Standardized to sum to one if necessary.</p>
</td></tr>
<tr><td><code id="movMF_distribution_+3A_log">log</code></td>
<td>
<p>a logical; if <code>TRUE</code> log-densities are computed.</p>
</td></tr>
<tr><td><code id="movMF_distribution_+3A_n">n</code></td>
<td>
<p>an integer giving the number of samples to draw.</p>
</td></tr>  
</table>


<h3>Details</h3>

<p>A random <code class="reqn">d</code>-dimensional unit length vector <code class="reqn">x</code> has a von
Mises-Fisher (or Langevin, short: vMF) distribution with parameter
<code class="reqn">\theta</code> if its density with respect to the uniform distribution
on the unit hypersphere is given by
</p>
<p style="text-align: center;"><code class="reqn">f(x|\theta) = \exp(\theta'x) / {}_0F_1(; d/2; \|\theta\|^2/4),</code>
</p>

<p>where <code class="reqn">{}_0F_1</code> is a generalized hypergeometric function
(e.g.,
<a href="https://en.wikipedia.org/wiki/Generalized_hypergeometric_function">https://en.wikipedia.org/wiki/Generalized_hypergeometric_function</a>)
and related to the modified Bessel function <code class="reqn">I_\nu</code> of the first
kind via
</p>
<p style="text-align: center;"><code class="reqn">{}_0F_1(; \nu+1; z^2/4) =
    I_\nu(z)\Gamma(\nu+1) / (z/2)^\nu.</code>
</p>

<p>With this parametrization, the von Mises-Fisher family is the natural
exponential family through the uniform distribution on the unit
sphere, with cumulant transform
</p>
<p style="text-align: center;"><code class="reqn">M(\theta) = \log({}_0F_1(; d/2; \|\theta\|^2/4)).</code>
</p>

<p>We note that the vMF distribution is commonly parametrized by the
<em>mean direction parameter</em> <code class="reqn">\mu = \theta / \|\theta\|</code> (which however is not well-defined if <code class="reqn">\theta =
  0</code>) and the <em>concentration parameter</em> <code class="reqn">\kappa = \|\theta\|</code>, e.g., 
<a href="https://en.wikipedia.org/wiki/Von_Mises%E2%80%93Fisher_distribution">https://en.wikipedia.org/wiki/Von_Mises%E2%80%93Fisher_distribution</a>
(which also uses the un-normalized Haar measure on the unit sphere as
the reference distribution, and hence includes the &ldquo;area&rdquo; of
the unit sphere as an additional normalizing constant).
</p>
<p><code>dmovMF</code> computes the (log) density of mixtures of vMF
distributions.
</p>
<p><code>rmovMF</code> generates samples from finite mixtures of vMF
distributions, using Algorithm VM* in Wood (1994) for sampling from
the vMF distribution.
</p>
<p>Arguments <code>theta</code> and <code>alpha</code> are recycled to a common
number of mixture components.
</p>


<h3>Value</h3>

<p>For <code>dmovMF</code>, a numeric vector of (log) density values.
</p>
<p>For <code>rmovMF</code>, a matrix with <code>n</code> unit length rows
representing the samples from the vMF mixture distribution.
</p>


<h3>References</h3>

<p>A. T. A. Wood (1994).
Simulation of the von Mises Fisher distribution.
<em>Communications in Statistics &ndash; Simulation and Computation</em>,
<b>23</b>(1), 157&ndash;164.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## To simulate from the vMF distribution with mean direction
## proportional to c(1, -1) and concentration parameter 3:
rmovMF(10, 3 * c(1, -1) / sqrt(2))
## To simulate from a mixture of vMF distributions with mean direction
## parameters c(1, 0) and c(0, 1), concentration parameters 3 and 4, and
## mixture probabilities 1/3 and 2/3, respectively:
rmovMF(10, c(3, 4) * rbind(c(1, 0), c(0, 1)), c(1, 2))
</code></pre>

<hr>
<h2 id='useR_2008_abstracts'>useR! 2008 Abstracts</h2><span id='topic+useR_2008_abstracts'></span>

<h3>Description</h3>

<p>Abstracts and some metadata for presentations at the useR! 2008 conference
held August 12-14, 2008 at Technische Universität Dortmund, Germany.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("useR_2008_abstracts")</code></pre>


<h3>Format</h3>

<p>A data frame with 177 observations on the following 5 character
variables.
</p>

<dl>
<dt><code>Abstract</code>:</dt><dd><p>the text of the abstract.</p>
</dd>
<dt><code>Title</code>:</dt><dd><p>the title of the presentation.</p>
</dd>
<dt><code>Author</code>:</dt><dd><p>the authors of the presentation, collapsed with
&lsquo;<span class="samp">&#8288; and &#8288;</span>&rsquo;.</p>
</dd>
<dt><code>Session</code>:</dt><dd><p>an identifier indicating the session the
presentation was slotted into (leading &lsquo;<span class="samp">&#8288;foc&#8288;</span>&rsquo; and &lsquo;<span class="samp">&#8288;kal&#8288;</span>&rsquo;
indicate useR! Focus and useR! Kaleidoscope sections, respectively).</p>
</dd>
<dt><code>Keywords</code>:</dt><dd><p>keywords for the presentation, collapsed with
&lsquo;<span class="samp">&#8288;, &#8288;</span>&rsquo;.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Abstracts were obtained in PDF format from
<a href="https://www.r-project.org/conferences/useR-2008/abstracts/">https://www.r-project.org/conferences/useR-2008/abstracts/</a>,
converted to text using <code>pdftotext</code>, and hand-edited.
Metadata were provided by the conference organizers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("useR_2008_abstracts")

words &lt;-
    with(useR_2008_abstracts,
         strsplit(Abstract, "[[:space:]]+"))
## (A poor word tokenizer ...)
n_of_words &lt;- sapply(words, length)

authors &lt;-
    with(useR_2008_abstracts,
         strsplit(Author, " and ", fixed = TRUE))
n_of_authors &lt;- sapply(authors, length)

## Do more authors write longer abstracts?
boxplot(n_of_words ~ n_of_authors)

## Session structure:
sessions &lt;-
    with(useR_2008_abstracts,
         sub("-[[:digit:]].*", "", Session))
sort(unique(sessions))    
## Numbers of focus, invited and kaleidoscope presentations:
table(sub("-.*", "", sessions))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
