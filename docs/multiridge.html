<!DOCTYPE html><html lang="en"><head><title>Help for package multiridge</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {multiridge}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#multiridge-package'>
<p>Fast cross-validation for multi-penalty ridge regression</p></a></li>
<li><a href='#augment'>
<p>Augment data with zeros.</p></a></li>
<li><a href='#betasout'>
<p>Coefficient estimates from (converged) IWLS fit</p></a></li>
<li><a href='#createXblocks'>
<p>Create list of paired data blocks</p></a></li>
<li><a href='#createXXblocks'>
<p>Creates list of (unscaled) sample covariance matrices</p></a></li>
<li><a href='#CVfolds'>
<p>Creates (repeated) cross-validation folds</p></a></li>
<li><a href='#CVscore'>
<p>Cross-validated score</p></a></li>
<li><a href='#dataXXmirmeth'>
<p>Contains R-object <code>dataXXmirmeth</code></p></a></li>
<li><a href='#doubleCV'>
<p>Double cross-validation for estimating performance of <code>multiridge</code></p></a></li>
<li><a href='#fastCV2'>
<p>Fast cross-validation per data block</p></a></li>
<li><a href='#IWLSCoxridge'>
<p>Iterative weighted least squares algorithm for Cox ridge regression.</p></a></li>
<li><a href='#IWLSridge'>
<p>Iterative weighted least squares algorithm for linear and logistic ridge regression.</p>
</p></a></li>
<li><a href='#mgcv_lambda'>
<p>Maximum marginal likelihood score</p></a></li>
<li><a href='#mlikCV'>
<p>Outer-loop cross-validation for estimating performance of marginal likelihood based <code>multiridge</code></p></a></li>
<li><a href='#optLambdas'>
<p>Find optimal ridge penalties.</p></a></li>
<li><a href='#optLambdas_mgcv'>
<p>Find optimal ridge penalties with maximimum marginal likelihood</p></a></li>
<li><a href='#optLambdas_mgcvWrap'>
<p>Find optimal ridge penalties with sequential optimization.</p></a></li>
<li><a href='#optLambdasWrap'>
<p>Find optimal ridge penalties with sequential optimization.</p></a></li>
<li><a href='#predictIWLS'>
<p>Predictions from ridge fits</p></a></li>
<li><a href='#Scoring'>
<p>Evaluate predictions</p></a></li>
<li><a href='#setupParallel'>
<p>Setting up parallel computing</p></a></li>
<li><a href='#SigmaFromBlocks'>
<p>Create penalized sample cross-product matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Fast Cross-Validation for Multi-Penalty Ridge Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>1.11</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-06-13</td>
</tr>
<tr>
<td>Author:</td>
<td>Mark A. van de Wiel</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mark A. van de Wiel &lt;mark.vdwiel@amsterdamumc.nl&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), survival, pROC, methods, mgcv, snowfall</td>
</tr>
<tr>
<td>Description:</td>
<td>Multi-penalty linear, logistic and cox ridge regression, including estimation of the penalty parameters by efficient (repeated) cross-validation and marginal likelihood maximization. Multiple high-dimensional data types that require penalization are allowed, as well as unpenalized variables. Paired and preferential data types can be specified. See Van de Wiel et al. (2021), &lt;<a href="https://doi.org/10.48550/arXiv.2005.09301">doi:10.48550/arXiv.2005.09301</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-13 13:11:49 UTC; VNOB-0735</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-13 15:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='multiridge-package'>
Fast cross-validation for multi-penalty ridge regression
</h2><span id='topic+multiridge-package'></span><span id='topic+multiridge'></span>

<h3>Description</h3>

<p>The package implements multi-penalty linear, logistic and cox ridge regression, including estimation of the penalty parameters by efficient (repeated) cross-validation or marginal likelihood maximization. It allows for multiple high-dimensional data types that require penalization, as well as unpenalized variables. Moreover, it allows a paired penalty for paired data types, and preferential data types can be specified.
</p>


<h3>Details</h3>

<p>The DESCRIPTION file:
</p>

<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> multiridge</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Title: </td><td style="text-align: left;"> Fast Cross-Validation for Multi-Penalty Ridge Regression</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.11</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2022-06-13</td>
</tr>
<tr>
 <td style="text-align: left;">
Author: </td><td style="text-align: left;"> Mark A. van de Wiel</td>
</tr>
<tr>
 <td style="text-align: left;">
Maintainer: </td><td style="text-align: left;"> Mark A. van de Wiel &lt;mark.vdwiel@amsterdamumc.nl&gt;</td>
</tr>
<tr>
 <td style="text-align: left;">
Depends: </td><td style="text-align: left;"> R (&gt;= 3.5.0), survival, pROC, methods, mgcv, snowfall</td>
</tr>
<tr>
 <td style="text-align: left;">
Description: </td><td style="text-align: left;"> Multi-penalty linear, logistic and cox ridge regression, including estimation of the penalty parameters by efficient (repeated) cross-validation and marginal likelihood maximization. Multiple high-dimensional data types that require penalization are allowed, as well as unpenalized variables. Paired and preferential data types can be specified. See Van de Wiel et al. (2021), &lt;arXiv:2005.09301&gt;. </td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL (&gt;=3)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<p>Index of help topics:
</p>
<pre>
CVfolds                 Creates (repeated) cross-validation folds
CVscore                 Cross-validated score
IWLSCoxridge            Iterative weighted least squares algorithm for
                        Cox ridge regression.
IWLSridge               Iterative weighted least squares algorithm for
                        linear and logistic ridge regression.
Scoring                 Evaluate predictions
SigmaFromBlocks         Create penalized sample cross-product matrix
augment                 Augment data with zeros.
betasout                Coefficient estimates from (converged) IWLS fit
createXXblocks          Creates list of (unscaled) sample covariance
                        matrices
createXblocks           Create list of paired data blocks
dataXXmirmeth           Contains R-object 'dataXXmirmeth'
doubleCV                Double cross-validation for estimating
                        performance of 'multiridge'
fastCV2                 Fast cross-validation per data block
mgcv_lambda             Maximum marginal likelihood score
mlikCV                  Outer-loop cross-validation for estimating
                        performance of marginal likelihood based
                        'multiridge'
multiridge-package      Fast cross-validation for multi-penalty ridge
                        regression
optLambdas              Find optimal ridge penalties.
optLambdasWrap          Find optimal ridge penalties with sequential
                        optimization.
optLambdas_mgcv         Find optimal ridge penalties with maximimum
                        marginal likelihood
optLambdas_mgcvWrap     Find optimal ridge penalties with sequential
                        optimization.
predictIWLS             Predictions from ridge fits
setupParallel           Setting up parallel computing
</pre>
<p><code><a href="#topic+betasout">betasout</a></code>: Coefficient estimates from (converged) IWLS fit <br />
<code><a href="#topic+createXXblocks">createXXblocks</a></code>: Creates list of (unscaled) sample covariance matrices <br />
<code><a href="#topic+CVscore">CVscore</a></code>: Cross-validated score for given penalty parameters <br />
<code><a href="#topic+dataXXmirmeth">dataXXmirmeth</a></code>: Example data <br />
<code><a href="#topic+doubleCV">doubleCV</a></code>:  Double cross-validation for estimating performance <br />
<code><a href="#topic+fastCV2">fastCV2</a></code>: Fast cross-validation per data block; no dependency<br />
<code><a href="#topic+IWLSCoxridge">IWLSCoxridge</a></code>: Iterative weighted least squares algorithm for Cox ridge regression <br />
<code><a href="#topic+IWLSridge">IWLSridge</a></code>: Iterative weighted least squares algorithm for linear and logistic ridge regression <br />
<code><a href="#topic+mlikCV">mlikCV</a></code>:  Cross-validation for estimating performance of marginal likelihood estimation<br />
<code><a href="#topic+optLambdasWrap">optLambdasWrap</a></code>: Find optimal ridge penalties by cross-validation  <br />
<code><a href="#topic+optLambdas_mgcvWrap">optLambdas_mgcvWrap</a></code>: Find optimal ridge penalties in terms of marginal likelihood  <br />
<code><a href="#topic+predictIWLS">predictIWLS</a></code>: Predictions from ridge fits <br />
<code><a href="#topic+setupParallel">setupParallel</a></code>: Setting up parallel computing<br />
<code><a href="#topic+SigmaFromBlocks">SigmaFromBlocks</a></code>: Create penalized sample cross-product matrix
</p>


<h3>Author(s)</h3>

<p>Mark A. van de Wiel (mark.vdwiel@amsterdamumc.nl)
</p>


<h3>References</h3>

<p>Mark A. van de Wiel, Mirrelijn van Nee, Armin Rauschenberger (2021). Fast cross-validation for high-dimensional ridge regression. J Comp Graph Stat
</p>


<h3>See Also</h3>

<p>A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Create (repeated) CV-splits of the data.
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)

# Compute cross-validated score for initial lambdas
CVscore(penalties=lambdas, XXblocks=XXmirmeth,Y=resp,folds=leftout,
score="loglik")

# Optimizes cross-validate criterion (default: log-lik)
# Increase the number of iterations for optimal results
jointlambdas &lt;- optLambdasWrap(penaltiesinit=lambdas, XXblocks=XXmirmeth,Y=resp,
folds=leftout,score="loglik",save=T, maxItropt1=5, maxItropt2=5)


# Alternatively: optimize by using marginal likelihood criterion
## Not run: 
jointlambdas2 &lt;- optLambdas_mgcvWrap(penaltiesinit=lambdas, XXblocks=XXmirmeth,
Y=resp)

## End(Not run)

# Optimal lambdas
optlambdas &lt;- jointlambdas$optpen

# Prepare fitting for the optimal lambdas.
XXT &lt;- SigmaFromBlocks(XXmirmeth,penalties=optlambdas)

# Fit. fit$etas contains the n linear predictors
fit &lt;- IWLSridge(XXT,Y=resp)
</code></pre>

<hr>
<h2 id='augment'>
Augment data with zeros.
</h2><span id='topic+augment'></span>

<h3>Description</h3>

<p>This function augments data with zeros to allow pairing of data on the same variables, but from DIFFERENT samples</p>


<h3>Usage</h3>

<pre><code class='language-R'>augment(Xdata1, Xdata2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="augment_+3A_xdata1">Xdata1</code></td>
<td>

<p>Data frame or data matrix of dimension <code>n_1 x p</code>.
</p>
</td></tr>
<tr><td><code id="augment_+3A_xdata2">Xdata2</code></td>
<td>

<p>Data frame or data matrix of dimension <code>n_2 x p</code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Xdata1 and Xdata2 should have the same number of columns. These columns represent variables. Augments both data matrices with zeros,
such that the matrices can be paired using <code><a href="#topic+createXXblocks">createXXblocks</a></code> on the output of this function.
</p>


<h3>Value</h3>

<p>List
</p>
<table role = "presentation">
<tr><td><code>Xaug1</code></td>
<td>
<p>Augmented data matrix 1</p>
</td></tr>
<tr><td><code>Xaug2</code></td>
<td>
<p>Augmented data matrix 2</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>#Example
#Simulate
n1 &lt;- 10
n2 &lt;- 20
p &lt;- 100
X1 &lt;- matrix(rnorm(p*n1),nrow=n1)
X2 &lt;- matrix(rnorm(p*n2),nrow=n2)

#check whether column dimension is correct
ncol(X1)==ncol(X2)

#create cross-product
Xaugm &lt;- augment(X1,X2)

#check dimensions (should be (n1+n2) x p)
dim(Xaugm[[1]])
dim(Xaugm[[2]])
</code></pre>

<hr>
<h2 id='betasout'>
Coefficient estimates from (converged) IWLS fit
</h2><span id='topic+betasout'></span>

<h3>Description</h3>

<p>Extracts estimated regression coefficients from the final Iterative Weighted Least Squares fit, as obtained from linear, logistic, or Cox ridge regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betasout(IWLSfit, Xblocks, X1=NULL, penalties, pairing = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betasout_+3A_iwlsfit">IWLSfit</code></td>
<td>

<p>List object, see details
</p>
</td></tr>
<tr><td><code id="betasout_+3A_xblocks">Xblocks</code></td>
<td>

<p>List of data frames or matrices, representing <code>b=1,...,B</code> data blocks of dimensions <code>n x p_b</code>.
</p>
</td></tr>
<tr><td><code id="betasout_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates.
</p>
</td></tr>
<tr><td><code id="betasout_+3A_penalties">penalties</code></td>
<td>

<p>Numerical vector.
</p>
</td></tr>
<tr><td><code id="betasout_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>IWLSfit</code> should be the output of either <code><a href="#topic+IWLSridge">IWLSridge</a></code> or <code><a href="#topic+IWLSCoxridge">IWLSCoxridge</a></code>. <code>Xblocks</code> may be created by <code><a href="#topic+createXblocks">createXblocks</a></code>.
</p>


<h3>Value</h3>

<p>List. Number of components equals number of components of <code>Xblocks</code> plus one, as the output is augmented with an intercept estimate (first component, <code>NULL</code> if absent).
Each component is a numerical vector representing regression parameter estimates. Lengths of vectors match column dimensions of <code>Xblocks</code> (nr of variables for given data type)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+createXblocks">createXblocks</a></code>. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]
lambdas &lt;- c(100,1000)

# Prepare fitting for the specified penalties.
XXT &lt;- SigmaFromBlocks(XXmirmeth,penalties=lambdas)

# Fit. fit$etas contains the n linear predictors
fit &lt;- IWLSridge(XXT,Y=resp)

# Computation of the regression coefficients requires the original
# (large!) nxp data sets, available from link above
## Not run: 
Xbl &lt;- createXblocks(list(datamir,datameth))
betas &lt;- betasout(fit, Xblocks=Xbl, penalties=lambdas)

## End(Not run)
</code></pre>

<hr>
<h2 id='createXblocks'>
Create list of paired data blocks</h2><span id='topic+createXblocks'></span>

<h3>Description</h3>

<p>Create list of paired data blocks
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createXblocks(datablocks, which2pair = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createXblocks_+3A_datablocks">datablocks</code></td>
<td>

<p>List of data frames or matrices representing <code>b=1,...,B</code> data blocks of dimensions <code>n x p_b</code>.
</p>
</td></tr>
<tr><td><code id="createXblocks_+3A_which2pair">which2pair</code></td>
<td>

<p>Integer vector of size 2 (or <code>NULL</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Only use this function when you wish to pair two data blocks. If <code>which2pair = NULL</code> the output
matches the input. If not, the function adds a paired data block, pairing the two data blocks corresponding to the elements of
<code>which2pair</code>.
</p>


<h3>Value</h3>

<p>List. Same length as <code>datablocks</code> when <code>which2pair = NULL</code>, or augmented with one paired data block.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+createXXblocks">createXXblocks</a></code>. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 43
p &lt;- 100
fakeXbl &lt;- createXblocks(list(X1 = matrix(rnorm(n*p),nrow=n),X2 = matrix(rnorm(n*p),nrow=n)))
</code></pre>

<hr>
<h2 id='createXXblocks'>
Creates list of (unscaled) sample covariance matrices
</h2><span id='topic+createXXblocks'></span>

<h3>Description</h3>

<p>Creates list of (unscaled) sample covariance matrices <code>X_b %*% t(X_b)</code> for data blocks b = 1,..., B.</p>


<h3>Usage</h3>

<pre><code class='language-R'>createXXblocks(datablocks, datablocksnew = NULL, which2pair = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createXXblocks_+3A_datablocks">datablocks</code></td>
<td>

<p>List of data frames or matrices
</p>
</td></tr>
<tr><td><code id="createXXblocks_+3A_datablocksnew">datablocksnew</code></td>
<td>

<p>List of data frames or matrices
</p>
</td></tr>
<tr><td><code id="createXXblocks_+3A_which2pair">which2pair</code></td>
<td>

<p>Integer vector of size 2 (or <code>NULL</code>)
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The efficiency of <code>multiridge</code> for high-dimendional data relies largely on this function:
all iterative calculation are performed on the out put of this function, which contains <code>B</code> blocks of
<code>nxn</code> matrices. If <code>which2pair != NULL</code>, the function adds a paired covariance block, pairing the two data blocks corresponding to the elements of <code>which2pair</code>. If predictions for new samples are desired, one also needs to specify
<code>datablocksnew</code>, which should have he exact same format as <code>datablocks</code> with matching column dimension (number of variables).
</p>


<h3>Value</h3>

<p>List. Same number of component as <code>datablocks</code> when <code>which2pair = NULL</code>, or augmented with one paired data block.
Dimension is <code>nxn</code> for all components.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+createXblocks">createXblocks</a></code>, which is required when parameter estimates are desired (not needed for prediction). A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Example
#Simulate
Xbl1 &lt;- matrix(rnorm(1000),nrow=10)
Xbl2 &lt;- matrix(rnorm(2000),nrow=10)

#check whether dimensions are correct
ncol(Xbl1)==nrow(Xbl2)

#create cross-product
XXbl &lt;- createXXblocks(list(Xbl1,Xbl2))

#suppose penalties for two data types equal 5,10, respectively
Sigma &lt;- SigmaFromBlocks(XXbl,c(5,10))

#check dimensions (should be n x n)
dim(Sigma)
</code></pre>

<hr>
<h2 id='CVfolds'>
Creates (repeated) cross-validation folds
</h2><span id='topic+CVfolds'></span>

<h3>Description</h3>

<p>Creates (repeated) cross-validation folds for samples
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVfolds(Y, model = NULL, balance = TRUE, kfold = 10, fixedfolds = TRUE, nrepeat = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CVfolds_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="CVfolds_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="CVfolds_+3A_balance">balance</code></td>
<td>

<p>Boolean. Should the splits be balanced in terms of response labels?
</p>
</td></tr>
<tr><td><code id="CVfolds_+3A_kfold">kfold</code></td>
<td>

<p>Integer. Desired fold.
</p>
</td></tr>
<tr><td><code id="CVfolds_+3A_fixedfolds">fixedfolds</code></td>
<td>

<p>Boolean. Should fixed splits be used for reproducibility?
</p>
</td></tr>
<tr><td><code id="CVfolds_+3A_nrepeat">nrepeat</code></td>
<td>

<p>Numeric. Number of repeats.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Creates (repeated), possibly balanced,  splits of the samples. Computing time will often largely depend on
on <code>kfold*nrepeat</code>, the number of training-test splits evaluated.
</p>


<h3>Value</h3>

<p>List object with <code>kfold*nrepeat</code> elements containing the sample indices of the left-out samples per split.
</p>


<h3>See Also</h3>

<p>A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)
</code></pre>

<hr>
<h2 id='CVscore'>
Cross-validated score
</h2><span id='topic+CVscore'></span>

<h3>Description</h3>

<p>Cross-validated score for given penalty parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CVscore(penalties, XXblocks, Y, X1 = NULL, pairing = NULL, folds, intercept =
ifelse(is(Y, "Surv"),FALSE, TRUE), frac1 = NULL, score = "loglik", model =
NULL, eps = 1e-07, maxItr = 100, trace = FALSE,   printCV = TRUE, save = FALSE,
parallel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CVscore_+3A_penalties">penalties</code></td>
<td>

<p>Numeric vector.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates </p>
</td></tr>
<tr><td><code id="CVscore_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_folds">folds</code></td>
<td>

<p>List of integer vector. Usually output of <code><a href="#topic+CVfolds">CVfolds</a></code>.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_frac1">frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model=" logistic"</code>.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_score">score</code></td>
<td>

<p>Character. See Details.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_eps">eps</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_maxitr">maxItr</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_trace">trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_printcv">printCV</code></td>
<td>

<p>Boolean. Should the CV-score be printed on screen?
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_save">save</code></td>
<td>

<p>Boolean. If TRUE appends the penalties and resulting CVscore to global variable <code>allscores</code>
</p>
</td></tr>
<tr><td><code id="CVscore_+3A_parallel">parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code><a href="#topic+setupParallel">setupParallel</a></code> first.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+Scoring">Scoring</a></code> for details on <code>score</code>.
</p>


<h3>Value</h3>

<p>Numeric, cross-validated prediction score for given penalties
</p>


<h3>See Also</h3>

<p><code><a href="#topic+doubleCV">doubleCV</a></code> for double cross-validation, used for performance evaluation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Create training-test splits
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)
CVscore(penalties=lambdas, XXblocks=XXmirmeth,Y=resp,folds=leftout,score="loglik")
</code></pre>

<hr>
<h2 id='dataXXmirmeth'>
Contains R-object <code>dataXXmirmeth</code>
</h2><span id='topic+dataXXmirmeth'></span>

<h3>Description</h3>

<p>This list object contains the binary response (control/case) and two data blocks corresponding to miRNA and methylation data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dataXXmirmeth)</code></pre>


<h3>Format</h3>

<p>The format is a list with two components:
resp: numeric (0/1) [1:43]\
XXmirmeth: list with 2 components, each a matrix [1:43,1:43]\
</p>


<h3>Details</h3>

<p>The object <code>XXmirmeth</code> is created by applying <code>createXXblocks(list(datamir,datameth))</code>, where
objects <code>datamir</code> and <code>datameth</code> are large data matrices stored in the
<code>mirmethdata.Rdata</code> file, which is available from the link below.
</p>


<h3>Source</h3>

<p>Snoek, B. C. et al. (2019), Genome-wide microRNA analysis of HPV-positive self-samples yields novel
triage markers for early detection of cervical cancer, International Journal of Cancer
144(2), 372-379.
</p>
<p>Verlaat, W. et al. (2018), Identification and validation of a 3-gene methylation classifier for hpv-based cervical screening on self-samples, Clinical Cancer Research 24(14), 3456-3464.
</p>


<h3>References</h3>

<p>Mark A. van de Wiel, Mirrelijn van Nee, Armin Rauschenberger (2021). Fast cross-validation for multi-penalty
high-dimensional ridge regression. J Comp Graph Stat
</p>


<h3>See Also</h3>

<p><code>createXXblocks</code>. Source data file is available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]
</code></pre>

<hr>
<h2 id='doubleCV'>
Double cross-validation for estimating performance of <code>multiridge</code>
</h2><span id='topic+doubleCV'></span>

<h3>Description</h3>

<p>Double cross-validation for estimating performance of <code>multiridge</code>. Outer fold is for testing, inner fold for penalty parameter tuning</p>


<h3>Usage</h3>

<pre><code class='language-R'>doubleCV(penaltiesinit, XXblocks, Y, X1 = NULL, pairing = NULL, outfold = 5,
  infold = 10, nrepeatout =   1, nrepeatin = 1, balance = TRUE, fixedfolds =
  TRUE, intercept = ifelse(is(Y, "Surv"), FALSE,     TRUE), frac1 = NULL,
  score = "loglik",model = NULL, eps = 1e-07, maxItr = 10, trace = FALSE,
  printCV   = TRUE, reltol = 1e-04, optmethod1 = "SANN", optmethod2 =
  ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"), maxItropt1 = 10,
  maxItropt2 = 25, save = FALSE, parallel = FALSE, pref = NULL, fixedpen = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="doubleCV_+3A_penaltiesinit">penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code><a href="#topic+fastCV2">fastCV2</a></code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates </p>
</td></tr>
<tr><td><code id="doubleCV_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_outfold">outfold</code></td>
<td>

<p>Integer. Outer fold for test samples.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_infold">infold</code></td>
<td>

<p>Integer. Inner fold for tuning penalty parameters.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_nrepeatout">nrepeatout</code></td>
<td>

<p>Integer. Number of repeated splits for outer fold.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_nrepeatin">nrepeatin</code></td>
<td>

<p>Integer. Number of repeated splits for inner fold.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_balance">balance</code></td>
<td>

<p>Boolean. Should the splits be balanced in terms of response labels?
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_fixedfolds">fixedfolds</code></td>
<td>

<p>Boolean. Should fixed splits be used for reproducibility?
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_frac1">frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model=" logistic"</code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_score">score</code></td>
<td>

<p>Character. See Details.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_eps">eps</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_maxitr">maxItr</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_trace">trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_printcv">printCV</code></td>
<td>

<p>Boolean. Should the CV-score be printed on screen?
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_optmethod1">optmethod1</code></td>
<td>

<p>Character. First, global search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
simulated annealing by <code>"Sann"</code> is recommended to search a wide landscape. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_optmethod2">optmethod2</code></td>
<td>

<p>Character. Second, local search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_maxitropt1">maxItropt1</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod1</code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_maxitropt2">maxItropt2</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod2</code>.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_save">save</code></td>
<td>

<p>Boolean. If TRUE appends the penalties and resulting CVscore to global variable <code>allscores</code>
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_parallel">parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code><a href="#topic+setupParallel">setupParallel</a></code> first.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_pref">pref</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types in <code>XXblocks</code> that are preferential.
</p>
</td></tr>
<tr><td><code id="doubleCV_+3A_fixedpen">fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: this function may be very time-consuming. The number of evaluations may equal <code>nrepeatout*outerfold*nrepeatin*innerfold*maxItr*(maxItropt1+maxItropt2)</code>. Computing time may be estimated by multiplying computing time of <code><a href="#topic+optLambdasWrap">optLambdasWrap</a></code> by
<code>nrepeatout*outerfold</code>. See <code><a href="#topic+Scoring">Scoring</a></code> for details on <code>score</code>.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table role = "presentation">
<tr><td><code>sampleindex</code></td>
<td>
<p>Numerical vector: sample indices</p>
</td></tr>
<tr><td><code>true</code></td>
<td>
<p>True responses</p>
</td></tr>
<tr><td><code>linpred</code></td>
<td>
<p>Cross-validated linear predictors</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdas">optLambdas</a></code>, <code><a href="#topic+optLambdasWrap">optLambdasWrap</a></code> which optimize the penalties.
<code><a href="#topic+Scoring">Scoring</a></code> which may applied to output of this function to obtain overall cross-validated performance score. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Double cross-validation
## Not run: 
perf &lt;- doubleCV(penaltiesinit=lambdas,XXblocks=XXmirmeth,Y=resp,
score="loglik",outfold=10, infold=10, nrepeatout=1, nrepeatin=3, parallel=TRUE)

# Performance metrics
Scoring(perf$linpred,perf$true,score="auc",print=TRUE)
Scoring(perf$linpred,perf$true,score="brier",print=TRUE)
Scoring(perf$linpred,perf$true,score="loglik",print=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='fastCV2'>
Fast cross-validation per data block
</h2><span id='topic+fastCV2'></span>

<h3>Description</h3>

<p>Fast cross-validation for high-dimensional data. Finds optimal penalties separately per data block. Useful for initialization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastCV2(XXblocks, Y, X1 = NULL, kfold = 10, intercept =
ifelse(is(Y, "Surv"), FALSE, TRUE), parallel = FALSE, fixedfolds = TRUE,
model = NULL, eps = 1e-10, reltol = 0.5, lambdamax= 10^6, traceCV=TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fastCV2_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of data frames or matrices, representing <code>b=1,...,B</code> data blocks of dimensions <code>n x p_b</code>.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_kfold">kfold</code></td>
<td>

<p>Integer. Desired fold.</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_parallel">parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code><a href="#topic+setupParallel">setupParallel</a></code> first.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_fixedfolds">fixedfolds</code></td>
<td>

<p>Boolean. Should fixed splits be used for reproducibility?
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_eps">eps</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization method.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_lambdamax">lambdamax</code></td>
<td>

<p>Numeric. Upperbound for lambda.
</p>
</td></tr>
<tr><td><code id="fastCV2_+3A_tracecv">traceCV</code></td>
<td>

<p>Boolean. Should the CV results be traced and printed?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is basically a wrapper for applying <code><a href="#topic+optLambdas">optLambdas</a></code> per data block separately using Brent optimization.
</p>


<h3>Value</h3>

<p>Numerical vector containing penalties optimized separately per data block. Useful for initialization.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdas">optLambdas</a></code>, <code><a href="#topic+optLambdasWrap">optLambdasWrap</a></code> which optimize the penalties jointly.
A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas
</code></pre>

<hr>
<h2 id='IWLSCoxridge'>
Iterative weighted least squares algorithm for Cox ridge regression.
</h2><span id='topic+IWLSCoxridge'></span>

<h3>Description</h3>

<p>Iterative weighted least squares algorithm for Cox ridge regression. Updates the weights and linear predictors until convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IWLSCoxridge(XXT, Y, X1 = NULL, intercept = FALSE, eps = 1e-07, maxItr = 25,
trace = FALSE, E0 = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IWLSCoxridge_+3A_xxt">XXT</code></td>
<td>

<p>Matrix. Dimensions <code>nxn</code>. Sample cross-product from penalized variables, usually computed by <code><a href="#topic+SigmaFromBlocks">SigmaFromBlocks</a></code>.
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_y">Y</code></td>
<td>

<p>Response vector: class <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates.
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_eps">eps</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_maxitr">maxItr</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_trace">trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="IWLSCoxridge_+3A_e0">E0</code></td>
<td>

<p>Numerical vector or <code>NULL</code>. Optional initial values for linear predictor. Same length as <code>Y</code>. Usually <code>NULL</code>, which initializes linear predictor with 0.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Usually, Cox ridge regression does not use an intercept, as this is part of the baseline hazard. The latter is estimated using the Breslow estimator. To keep the function computationally efficient it returns the linear predictors (which suffice for predictions), instead of parameter estimates. These may be obtained by applying the <code><a href="#topic+betasout">betasout</a></code> function to the output of this function.
</p>


<h3>Value</h3>

<p>List, containing:
</p>
<table role = "presentation">
<tr><td><code>etas</code></td>
<td>
<p>Numerical vector: Final linear predictors</p>
</td></tr>
<tr><td><code>Ypred</code></td>
<td>
<p>Predicted survival</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Boolean: has IWLS converged?</p>
</td></tr>
<tr><td><code>nIt</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code>Hres</code></td>
<td>
<p>Auxiliary list object. Passed on to other functions</p>
</td></tr>
<tr><td><code>linearized</code></td>
<td>
<p>Linearized predictions</p>
</td></tr>
<tr><td><code>unpen</code></td>
<td>
<p>Boolean: are there any unpenalized covariates involved? Passed on to other functions</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Boolean: Is an intercept included? </p>
</td></tr>
<tr><td><code>eta0</code></td>
<td>
<p>Numerical vector: Initial linear predictors</p>
</td></tr>
<tr><td><code>X1</code></td>
<td>
<p>Matrix: design matrix unpenalized variables</p>
</td></tr>
</table>


<h3>References</h3>

<p>Mark A. van de Wiel, Mirrelijn van Nee, Armin Rauschenberger (2021). Fast cross-validation for high-dimensional ridge regression. J Comp Graph Stat
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IWLSridge">IWLSridge</a></code> for linear and logistic ridge. <code><a href="#topic+betasout">betasout</a></code> for obtaining parameter estimates.
<code><a href="#topic+predictIWLS">predictIWLS</a></code> for predictions on new samples. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]
lambdas &lt;- c(100,1000)

# Create fake survival data
respsurv &lt;- Surv(rexp(length(resp)),resp)

# Prepare fitting for the specified penalties.
XXT &lt;- SigmaFromBlocks(XXmirmeth,penalties=lambdas)

# Fit. fit$etas contains the n linear predictors
fit &lt;- IWLSCoxridge(XXT,Y=respsurv)
</code></pre>

<hr>
<h2 id='IWLSridge'>
Iterative weighted least squares algorithm for linear and logistic ridge regression.
</h2><span id='topic+IWLSridge'></span>

<h3>Description</h3>

<p>Iterative weighted least squares algorithm for linear and logistic ridge regression. Updates the weights and linear predictors until convergence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IWLSridge(XXT, Y, X1 = NULL, intercept = TRUE, frac1 = NULL, eps = 1e-07,
maxItr = 25, trace = FALSE, model = NULL, E0 = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IWLSridge_+3A_xxt">XXT</code></td>
<td>

<p>Matrix. Dimensions <code>nxn</code>. Sample cross-product from penalized variables, usually computed by <code><a href="#topic+SigmaFromBlocks">SigmaFromBlocks</a></code>.
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, or two-class factor
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates.
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_frac1">frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model="logistic"</code>.
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_eps">eps</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_maxitr">maxItr</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_trace">trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>. Note that the cox model for survival is covered by the function <code><a href="#topic+IWLSCoxridge">IWLSCoxridge</a></code>.
</p>
</td></tr>
<tr><td><code id="IWLSridge_+3A_e0">E0</code></td>
<td>

<p>Numerical vector or <code>NULL</code>. Optional initial values for linear predictor. Same length as <code>Y</code>. Usually <code>NULL</code>, which initializes linear predictor with 0.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An (unpenalized) intercept is included by default. To keep the function computationally efficient it returns the linear predictors (which suffice for predictions), instead of parameter estimates. These may be obtained by applying the <code><a href="#topic+betasout">betasout</a></code> function to the output of this function.</p>


<h3>Value</h3>

<p>List, containing:
</p>
<table role = "presentation">
<tr><td><code>etas</code></td>
<td>
<p>Numerical vector: Final linear predictors</p>
</td></tr>
<tr><td><code>Ypred</code></td>
<td>
<p>Predicted survival</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Boolean: has IWLS converged?</p>
</td></tr>
<tr><td><code>nIt</code></td>
<td>
<p>Number of iterations</p>
</td></tr>
<tr><td><code>Hres</code></td>
<td>
<p>Auxiliary list object. Passed on to other functions</p>
</td></tr>
<tr><td><code>linearized</code></td>
<td>
<p>Linearized predictions</p>
</td></tr>
<tr><td><code>unpen</code></td>
<td>
<p>Boolean: are there any unpenalized covariates involved? Passed on to other functions</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Boolean: Is an intercept included? </p>
</td></tr>
<tr><td><code>eta0</code></td>
<td>
<p>Numerical vector: Initial linear predictors</p>
</td></tr>
<tr><td><code>X1</code></td>
<td>
<p>Matrix: design matrix unpenalized variables</p>
</td></tr>
</table>


<h3>References</h3>

<p>Mark A. van de Wiel, Mirrelijn van Nee, Armin Rauschenberger (2021). Fast cross-validation for high-dimensional ridge regression. J Comp Graph Stat
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IWLSCoxridge">IWLSCoxridge</a></code> for Cox ridge. <code><a href="#topic+betasout">betasout</a></code> for obtaining parameter estimates.
<code><a href="#topic+predictIWLS">predictIWLS</a></code> for predictions on new samples. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]
lambdas &lt;- c(100,1000)

# Prepare fitting for the specified penalties.
XXT &lt;- SigmaFromBlocks(XXmirmeth,penalties=lambdas)

# Fit. fit$etas contains the n linear predictors
fit &lt;- IWLSridge(XXT,Y=resp)
</code></pre>

<hr>
<h2 id='mgcv_lambda'>
Maximum marginal likelihood score
</h2><span id='topic+mgcv_lambda'></span>

<h3>Description</h3>

<p>Computed maximum marginal likelihood score for given penalty parameters using <code>mgcv</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mgcv_lambda(penalties, XXblocks,Y, model=NULL, printscore=TRUE, pairing=NULL, sigmasq = 1,
  opt.sigma=ifelse(model=="linear",TRUE, FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mgcv_lambda_+3A_penalties">penalties</code></td>
<td>

<p>Numeric vector.
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_printscore">printscore</code></td>
<td>
<p>Boolean. Should the score be printed?
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_pairing">pairing</code></td>
<td>
<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing, plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_sigmasq">sigmasq</code></td>
<td>
<p>Default error variance.
</p>
</td></tr>
<tr><td><code id="mgcv_lambda_+3A_opt.sigma">opt.sigma</code></td>
<td>
<p>Boolean. Should the error variance be optimized as well? Only relevant for <code>model="linear"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="mgcv.html#topic+gam">gam</a></code> for details on how the marginal likelihood is computed.
</p>


<h3>Value</h3>

<p>Numeric, marginal likelihood score for given penalties
</p>


<h3>References</h3>

<p>Wood, S. N. (2011), Fast stable restricted maximum likelihood and marginal likelihood
estimation of semiparametric generalized linear models, J. Roy. Statist. Soc., B 73(1), 3-36.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CVscore">CVscore</a></code> for cross-validation alternative. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>

<hr>
<h2 id='mlikCV'>
Outer-loop cross-validation for estimating performance of marginal likelihood based <code>multiridge</code>
</h2><span id='topic+mlikCV'></span>

<h3>Description</h3>

<p>Outer-loop cross-validation for estimating performance of marginal likelihood based <code>multiridge</code>.
Outer fold is for testing;  penalty parameter tuning is performed by marginal likelihood estimation</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlikCV(penaltiesinit, XXblocks, Y, pairing = NULL, outfold = 5, nrepeatout = 1,
balance = TRUE,fixedfolds = TRUE,  model = NULL, intercept =
ifelse(is(Y, "Surv"), FALSE, TRUE), reltol = 1e-04, trace = FALSE, optmethod1 = "SANN",
optmethod2 = ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"),
maxItropt1 = 10, maxItropt2 = 25, parallel = FALSE, pref = NULL,
fixedpen = NULL, sigmasq = 1, opt.sigma=ifelse(model=="linear",TRUE, FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mlikCV_+3A_penaltiesinit">penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code><a href="#topic+fastCV2">fastCV2</a></code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_outfold">outfold</code></td>
<td>

<p>Integer. Outer fold for test samples.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_nrepeatout">nrepeatout</code></td>
<td>

<p>Integer. Number of repeated splits for outer fold.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_balance">balance</code></td>
<td>

<p>Boolean. Should the splits be balanced in terms of response labels?
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_fixedfolds">fixedfolds</code></td>
<td>

<p>Boolean. Should fixed splits be used for reproducibility?
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_trace">trace</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_optmethod1">optmethod1</code></td>
<td>

<p>Character. First, global search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
simulated annealing by <code>"Sann"</code> is recommended to search a wide landscape. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_optmethod2">optmethod2</code></td>
<td>

<p>Character. Second, local search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_maxitropt1">maxItropt1</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod1</code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_maxitropt2">maxItropt2</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod2</code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_parallel">parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code><a href="#topic+setupParallel">setupParallel</a></code> first.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_pref">pref</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types in <code>XXblocks</code> that are preferential.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_fixedpen">fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_sigmasq">sigmasq</code></td>
<td>
<p>Default error variance.
</p>
</td></tr>
<tr><td><code id="mlikCV_+3A_opt.sigma">opt.sigma</code></td>
<td>
<p>Boolean. Should the error variance be optimized as well? Only relevant for <code>model="linear"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: this function may be very time-consuming. The number of evaluations may equal <code>nrepeatout*outerfold*(maxItropt1+maxItropt2)</code>. Computing time may be estimated by multiplying computing time of <code><a href="#topic+optLambdas_mgcvWrap">optLambdas_mgcvWrap</a></code> by
<code>nrepeatout*outerfold</code>.
</p>


<h3>Value</h3>

<p>List with the following components:
</p>
<table role = "presentation">
<tr><td><code>sampleindex</code></td>
<td>
<p>Numerical vector: sample indices</p>
</td></tr>
<tr><td><code>true</code></td>
<td>
<p>True responses</p>
</td></tr>
<tr><td><code>linpred</code></td>
<td>
<p>Cross-validated linear predictors</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdas_mgcv">optLambdas_mgcv</a></code>, <code><a href="#topic+optLambdas_mgcvWrap">optLambdas_mgcvWrap</a></code> which optimize the penalties.
<code><a href="#topic+Scoring">Scoring</a></code> which may applied to output of this function to obtain overall cross-validated performance score.
<code><a href="#topic+doubleCV">doubleCV</a></code> for double cross-validation counterpart. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Outer cross-validation, inner marginal likelihood optimization
## Not run: 
perfmlik &lt;- mlikCV(penaltiesinit=lambdas,XXblocks=XXmirmeth,Y=resp,outfold=10,
nrepeatout=1)


# Performance metrics
Scoring(perfmlik$linpred,perfmlik$true,score="auc",print=TRUE)
Scoring(perfmlik$linpred,perfmlik$true,score="brier",print=TRUE)
Scoring(perfmlik$linpred,perfmlik$true,score="loglik",print=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='optLambdas'>
Find optimal ridge penalties.
</h2><span id='topic+optLambdas'></span>

<h3>Description</h3>

<p>Optimizes a cross-validated score w.r.t. ridge penalties for multiple data blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optLambdas(penaltiesinit = NULL, XXblocks, Y, X1 = NULL, pairing = NULL, folds,
  intercept = ifelse(is(Y, "Surv"), FALSE, TRUE), frac1 = NULL, score = "loglik",
  model = NULL, epsIWLS = 0.001, maxItrIWLS = 25, traceCV = TRUE, reltol = 1e-04,
  optmethod = ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"), maxItropt = 500,
  save = FALSE, parallel = FALSE, fixedpen = NULL, fixedseed = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optLambdas_+3A_penaltiesinit">penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code><a href="#topic+fastCV2">fastCV2</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates </p>
</td></tr>
<tr><td><code id="optLambdas_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_folds">folds</code></td>
<td>

<p>List, containing the splits of the samples. Usually obtained by <code><a href="#topic+CVfolds">CVfolds</a></code>
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_frac1">frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model=" logistic"</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_score">score</code></td>
<td>

<p>Character. See Details.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_epsiwls">epsIWLS</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_maxitriwls">maxItrIWLS</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_tracecv">traceCV</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_optmethod">optmethod</code></td>
<td>

<p>Character. Optimization method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_maxitropt">maxItropt</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_save">save</code></td>
<td>

<p>Boolean. If TRUE appends the penalties and resulting CVscore to global variable <code>allscores</code>
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_parallel">parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code><a href="#topic+setupParallel">setupParallel</a></code> first.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_fixedpen">fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_+3A_fixedseed">fixedseed</code></td>
<td>

<p>Boolean. Should the initialization be fixed? For reproducibility.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+Scoring">Scoring</a></code> for details on <code>score</code>.
We highly recommend to use smooth scoring functions, in particular <code>"loglik"</code>.
For ranking-based criteria like <code>auc</code> and <code>cindex</code> we advise to use repeated CV (see <code><a href="#topic+CVfolds">CVfolds</a></code>) to avoid ending up in any of the many local optima.
</p>


<h3>Value</h3>

<p>List, with components:
</p>
<table role = "presentation">
<tr><td><code>optres</code></td>
<td>
<p>Output of the optimizer</p>
</td></tr>
<tr><td><code>optpen</code></td>
<td>
<p>Vector with determined optimal penalties</p>
</td></tr>
<tr><td><code>allsc</code></td>
<td>
<p>Matrix with CV scores for all penalty parameter configurations used by the optimizer</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdasWrap">optLambdasWrap</a></code> for i) (recommended) optimization in two steps: first global, then local; and ii) sequential optimization
when some data types are preferred over others. <code><a href="#topic+fastCV2">fastCV2</a></code> for initialization of penalties. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Create (repeated) CV-splits of the data.
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)

# One-pass optimization
# Increase the number of iterations for optimal results
jointlambdas &lt;- optLambdas(penaltiesinit=lambdas, XXblocks=XXmirmeth,Y=resp,
folds=leftout,score="loglik",save=T,maxItropt=5)
</code></pre>

<hr>
<h2 id='optLambdas_mgcv'>
Find optimal ridge penalties with maximimum marginal likelihood
</h2><span id='topic+optLambdas_mgcv'></span>

<h3>Description</h3>

<p>Optimizes a marginal likelihood score w.r.t. ridge penalties for multiple data blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optLambdas_mgcv(penaltiesinit=NULL, XXblocks,Y, pairing=NULL, model=NULL, reltol=1e-4,
  optmethod=ifelse(length(penaltiesinit)==1,"Brent", "Nelder-Mead"),maxItropt=500,
  tracescore=TRUE, fixedpen=NULL, fixedseed =TRUE, sigmasq = 1,
  opt.sigma=ifelse(model=="linear",TRUE, FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optLambdas_mgcv_+3A_penaltiesinit">penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code><a href="#topic+fastCV2">fastCV2</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_pairing">pairing</code></td>
<td>
<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing, plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_optmethod">optmethod</code></td>
<td>

<p>Character. Optimization method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_maxitropt">maxItropt</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_tracescore">tracescore</code></td>
<td>

<p>Boolean. Should the output of the scores be traced?
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_fixedpen">fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty
is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_fixedseed">fixedseed</code></td>
<td>

<p>Boolean. Should the initialization be fixed? For reproducibility.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_sigmasq">sigmasq</code></td>
<td>
<p>Default error variance.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcv_+3A_opt.sigma">opt.sigma</code></td>
<td>
<p>Boolean. Should the error variance be optimized as well? Only relevant for <code>model="linear"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="mgcv.html#topic+gam">gam</a></code> for details on how the marginal likelihood is computed.
</p>


<h3>Value</h3>

<p>List, with components:
</p>
<table role = "presentation">
<tr><td><code>optres</code></td>
<td>
<p>Output of the optimizer</p>
</td></tr>
<tr><td><code>optpen</code></td>
<td>
<p>Vector with determined optimal penalties</p>
</td></tr>
<tr><td><code>allsc</code></td>
<td>
<p>Matrix with marginal likelihood scores for all penalty parameter configurations used by the optimizer</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdas_mgcvWrap">optLambdas_mgcvWrap</a></code> for i) (recommended) optimization in two steps: first global, then local; and ii) sequential optimization
when some data types are preferred over others. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Create (repeated) CV-splits of the data.
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)

# Compute cross-validated score for initial lambdas
CVscore(penalties=lambdas, XXblocks=XXmirmeth,Y=resp,folds=leftout,
score="loglik")

# Optimize by using marginal likelihood criterion
jointlambdas2 &lt;- optLambdas_mgcvWrap(penaltiesinit=lambdas, XXblocks=XXmirmeth,
Y=resp)

# Optimal lambdas
optlambdas &lt;- jointlambdas2$optpen

</code></pre>

<hr>
<h2 id='optLambdas_mgcvWrap'>
Find optimal ridge penalties with sequential optimization.
</h2><span id='topic+optLambdas_mgcvWrap'></span>

<h3>Description</h3>

<p>Sequentially optimizes a marginal likelihood score w.r.t. ridge penalties for multiple data blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optLambdas_mgcvWrap(penaltiesinit=NULL, XXblocks,Y, pairing=NULL, model=NULL, reltol=1e-4,
  optmethod1= "SANN", optmethod2 =ifelse(length(penaltiesinit)==1,"Brent", "Nelder-Mead"),
  maxItropt1=10,maxItropt2=25,tracescore=TRUE,fixedseed =TRUE, pref=NULL, fixedpen=NULL,
  sigmasq = 1, opt.sigma=ifelse(model=="linear",TRUE, FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optLambdas_mgcvWrap_+3A_penaltiesinit">penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code><a href="#topic+fastCV2">fastCV2</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_pairing">pairing</code></td>
<td>
<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing, plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_optmethod1">optmethod1</code></td>
<td>

<p>Character. First, global search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
simulated annealing by <code>"Sann"</code> is recommended to search a wide landscape. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_optmethod2">optmethod2</code></td>
<td>

<p>Character. Second, local search method. Any of the methods <code>c("Brent", "Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_maxitropt1">maxItropt1</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod1</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_maxitropt2">maxItropt2</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod2</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_tracescore">tracescore</code></td>
<td>

<p>Boolean. Should the output of the scores be traced?
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_fixedseed">fixedseed</code></td>
<td>

<p>Boolean. Should the initialization be fixed? For reproducibility.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_pref">pref</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types in <code>XXblocks</code>
that are preferential.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_fixedpen">fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty
is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_sigmasq">sigmasq</code></td>
<td>
<p>Default error variance.
</p>
</td></tr>
<tr><td><code id="optLambdas_mgcvWrap_+3A_opt.sigma">opt.sigma</code></td>
<td>
<p>Boolean. Should the error variance be optimized as well? Only relevant for <code>model="linear"</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As opposed to <code><a href="#topic+optLambdas_mgcv">optLambdas_mgcv</a></code> this function first searches globally, then locally.
Hence, more time-consuming, but better guarded against multiple local optima.
See <code><a href="mgcv.html#topic+gam">gam</a></code> for details on how the marginal likelihood is computed.
</p>


<h3>Value</h3>

<p>List, with components:
</p>
<table role = "presentation">
<tr><td><code>res</code></td>
<td>
<p>Outputs of all optimizers used</p>
</td></tr>
<tr><td><code>lambdas</code></td>
<td>
<p>List of penalties found by the  optimizers</p>
</td></tr>
<tr><td><code>optpen</code></td>
<td>
<p>Numerical vector with final, optimal penalties</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wood, S. N. (2011), Fast stable restricted maximum likelihood and marginal likelihood
estimation of semiparametric generalized linear models, J. Roy. Statist. Soc., B 73(1), 3-36.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdas_mgcv">optLambdas_mgcv</a></code> for one-pass optimization. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>

<hr>
<h2 id='optLambdasWrap'>
Find optimal ridge penalties with sequential optimization.
</h2><span id='topic+optLambdasWrap'></span>

<h3>Description</h3>

<p>Sequentially optimizes a cross-validated score w.r.t. ridge penalties for multiple data blocks.
Also implements preferential ridge, which allows to first optimize for the preferential data types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optLambdasWrap(penaltiesinit = NULL, XXblocks, Y, X1 = NULL, pairing = NULL,
  folds, intercept = ifelse(is(Y, "Surv"), FALSE, TRUE), frac1 = NULL,
  score = "loglik", model = NULL, epsIWLS = 0.001, maxItrIWLS = 25,
  traceCV = TRUE, reltol = 1e-04, optmethod1 = "SANN", optmethod2 =
  ifelse(length(penaltiesinit) == 1, "Brent", "Nelder-Mead"), maxItropt1 = 10,
  maxItropt2 = 25, save = FALSE, parallel = FALSE, pref = NULL, fixedpen = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optLambdasWrap_+3A_penaltiesinit">penaltiesinit</code></td>
<td>

<p>Numeric vector. Initial values for penaltyparameters. May be obtained from <code><a href="#topic+fastCV2">fastCV2</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_x1">X1</code></td>
<td>

<p>Matrix. Dimension <code>n x p_0, p_0 &lt; n</code>, representing unpenalized covariates </p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents
the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_folds">folds</code></td>
<td>

<p>List, containing the splits of the samples. Usually obtained by
<code><a href="#topic+CVfolds">CVfolds</a></code>
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_intercept">intercept</code></td>
<td>

<p>Boolean. Should an intercept be included?
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_frac1">frac1</code></td>
<td>

<p>Scalar. Prior fraction of cases. Only relevant for <code>model=" logistic"</code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_score">score</code></td>
<td>

<p>Character. See Details.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_epsiwls">epsIWLS</code></td>
<td>

<p>Scalar. Numerical bound for IWLS convergence.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_maxitriwls">maxItrIWLS</code></td>
<td>

<p>Integer. Maximum number of iterations used in IWLS.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_tracecv">traceCV</code></td>
<td>

<p>Boolean. Should the output of the IWLS algorithm be traced?
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_reltol">reltol</code></td>
<td>

<p>Scalar. Relative tolerance for optimization methods.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_optmethod1">optmethod1</code></td>
<td>

<p>Character. First, global search method. Any of the methods <code>c("Brent",
"Nelder-Mead", "Sann")</code> may be used, but
simulated annealing by <code>"Sann"</code> is recommended to search a wide landscape.
Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_optmethod2">optmethod2</code></td>
<td>

<p>Character. Second, local search method. Any of the methods <code>c("Brent",
"Nelder-Mead", "Sann")</code> may be used, but
<code>"Nelder-Mead"</code> is generally recommended. Other unconstrained methods
offered by <code><a href="stats.html#topic+optim">optim</a></code> may also be used, but have not been tested.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_maxitropt1">maxItropt1</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod1</code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_maxitropt2">maxItropt2</code></td>
<td>

<p>Integer. Maximum number of iterations for <code>optmethod2</code>.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_save">save</code></td>
<td>

<p>Boolean. If TRUE appends the penalties and resulting CVscore to global variable <code>allscores</code>
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_parallel">parallel</code></td>
<td>

<p>Boolean. Should computation be done in parallel? If <code>TRUE</code>, requires to run <code><a href="#topic+setupParallel">setupParallel</a></code> first.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_pref">pref</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types in <code>XXblocks</code>
that are preferential.
</p>
</td></tr>
<tr><td><code id="optLambdasWrap_+3A_fixedpen">fixedpen</code></td>
<td>

<p>Integer vector or <code>NULL</code>. Contains indices of data types of which penalty
is fixed to the corresponding value in <code>penaltiesinit</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As opposed to <code><a href="#topic+optLambdas">optLambdas</a></code> this function first searches globally,
then locally.
Hence, more time-consuming, but better guarded against multiple local optima.
</p>
<p>See <code><a href="#topic+Scoring">Scoring</a></code> for details on <code>score</code>. We highly recommend to
use smooth scoring functions, in particular <code>"loglik"</code>.
For ranking-based criteria like <code>"auc"</code> and <code>"cindex"</code> we advise to
use repeated CV (see <code><a href="#topic+CVfolds">CVfolds</a></code>) to avoid ending up in any of the
many local optima.
</p>


<h3>Value</h3>

<p>List, with components:
</p>
<table role = "presentation">
<tr><td><code>res</code></td>
<td>
<p>Outputs of all optimizers used</p>
</td></tr>
<tr><td><code>lambdas</code></td>
<td>
<p>List of penalties found by the  optimizers</p>
</td></tr>
<tr><td><code>optpen</code></td>
<td>
<p>Numerical vector with final, optimal penalties</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+optLambdas">optLambdas</a></code> for one-pass optimization. <code><a href="#topic+fastCV2">fastCV2</a></code> for initialization of penalties.A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(dataXXmirmeth)
resp &lt;- dataXXmirmeth[[1]]
XXmirmeth &lt;- dataXXmirmeth[[2]]

# Find initial lambdas: fast CV per data block separately.
cvperblock2 &lt;- fastCV2(XXblocks=XXmirmeth,Y=resp,kfold=10,fixedfolds = TRUE)
lambdas &lt;- cvperblock2$lambdas

# Create (repeated) CV-splits of the data.
leftout &lt;- CVfolds(Y=resp,kfold=10,nrepeat=3,fixedfolds = TRUE)

# Optimizes cross-validate criterion (default: log-lik)
# Increase the number of iterations for optimal results
jointlambdas &lt;- optLambdasWrap(penaltiesinit=lambdas, XXblocks=XXmirmeth,Y=resp,
folds=leftout,score="loglik",save=T,maxItropt1=5, maxItropt2=5)
</code></pre>

<hr>
<h2 id='predictIWLS'>
Predictions from ridge fits
</h2><span id='topic+predictIWLS'></span>

<h3>Description</h3>

<p>Produces predictions from ridge fits for new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predictIWLS(IWLSfit, X1new = NULL, Sigmanew)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predictIWLS_+3A_iwlsfit">IWLSfit</code></td>
<td>

<p>List, containing fits from either <code><a href="#topic+IWLSridge">IWLSridge</a></code> (linear, logistic
ridge) or <code><a href="#topic+IWLSCoxridge">IWLSCoxridge</a></code>
</p>
</td></tr>
<tr><td><code id="predictIWLS_+3A_x1new">X1new</code></td>
<td>

<p>Matrix. Dimension <code>nnew x p_0</code>, representing unpenalized covariates for
new data.
</p>
</td></tr>
<tr><td><code id="predictIWLS_+3A_sigmanew">Sigmanew</code></td>
<td>

<p>Matrix. Dimensions <code>nnew x n</code>. Sample cross-product from penalized
variables, usually computed by first applying <code><a href="#topic+createXXblocks">createXXblocks</a></code>
and then <code><a href="#topic+SigmaFromBlocks">SigmaFromBlocks</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Predictions rely purely on the linear predictors, and do not require producing
the parameter vector.
</p>


<h3>Value</h3>

<p>Numerical vector of linear predictor for the test samples.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+IWLSridge">IWLSridge</a></code> (<code><a href="#topic+IWLSCoxridge">IWLSCoxridge</a></code>) for fitting linear and
logistic ridge (Cox ridge). <code><a href="#topic+betasout">betasout</a></code> for obtaining parameter
estimates.
<code><a href="#topic+Scoring">Scoring</a></code> to evaluate the predictions. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Example below shows how to create the input argument Sigmanew (for simulated data)
#Simulate
Xbl1 &lt;- matrix(rnorm(1000),nrow=10)
Xbl2 &lt;- matrix(rnorm(2000),nrow=10)
Xbl1new &lt;- matrix(rnorm(200),nrow=2)
Xbl2new &lt;- matrix(rnorm(400),nrow=2)

#check whether dimensions are correct
nrow(Xbl1)==nrow(Xbl1new)
nrow(Xbl2)==nrow(Xbl2new)
ncol(Xbl1)==nrow(Xbl2)
ncol(Xbl1new)==ncol(Xbl2new)

#create cross-product
XXbl &lt;- createXXblocks(list(Xbl1,Xbl2),list(Xbl1new,Xbl2new))

#suppose penalties for two data types equal 5,10, respectively
Sigmanew &lt;- SigmaFromBlocks(XXbl,c(5,10))

#check dimensions (should be nnew x n)
dim(Sigmanew)
</code></pre>

<hr>
<h2 id='Scoring'>
Evaluate predictions
</h2><span id='topic+Scoring'></span>

<h3>Description</h3>

<p>Evaluates predictions by a score suitable for the corresponding response
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Scoring(lp, Y, model = NULL, score = ifelse(model == "linear", "mse", "loglik"),
  print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Scoring_+3A_lp">lp</code></td>
<td>

<p>Numerical vector. Linear predictor.
</p>
</td></tr>
<tr><td><code id="Scoring_+3A_y">Y</code></td>
<td>

<p>Response vector: numeric, binary, factor or <code>survival</code>.
</p>
</td></tr>
<tr><td><code id="Scoring_+3A_score">score</code></td>
<td>

<p>Character. See Details.
</p>
</td></tr>
<tr><td><code id="Scoring_+3A_model">model</code></td>
<td>

<p>Character. Any of <code>c("linear", "logistic", "cox")</code>. Is inferred from
<code>Y</code> when <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="Scoring_+3A_print">print</code></td>
<td>

<p>Boolean. Should the score be printed on screen.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several scores are allowed, depending on the type of output. For <code>model = "linear"</code>,
<code>score</code> equals any of <code>c("loglik","mse","abserror","cor","kendall","spearman")</code>, denoting
CV-ed log-likelihood, mean-squared error, mean absolute error, Pearson (Kendall, Spearman) correlation with response.
For <code>model = "logistic"</code>, <code>score</code> equals any of <code>c("loglik","auc", "brier")</code>, denoting
CV-ed log-likelihood, area-under-the-ROC-curve, and brier score a.k.a. MSE.
For <code>model = "cox"</code>, <code>score</code> equals any of <code>c("loglik","cindex")</code>, denoting
CV-ed log-likelihood, and c-index. 
</p>


<h3>Value</h3>

<p>Numerical value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CVscore">CVscore</a></code> for obtaining the cross-validated score (for given penalties), and <code><a href="#topic+doubleCV">doubleCV</a></code> to obtain doubly cross-validated linear predictors to which <code>Scoring</code> can be applied to estimated predictive performance by double cross-validation. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>

<hr>
<h2 id='setupParallel'>
Setting up parallel computing
</h2><span id='topic+setupParallel'></span>

<h3>Description</h3>

<p>This function sets up parallel computing by the package <code>snowfall</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setupParallel(ncpus = 2, sourcefile = NULL, sourcelibraries =
c("multiridge","survival","pROC","risksetROC"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="setupParallel_+3A_ncpus">ncpus</code></td>
<td>

<p>Integer. Number of cpus to use. Should be &gt;= 2.
</p>
</td></tr>
<tr><td><code id="setupParallel_+3A_sourcefile">sourcefile</code></td>
<td>

<p>Character. Additional source files to be loaded in parallel. Only required when parallel computing is also desired for functions
not available in <code>multiridge</code>.
</p>
</td></tr>
<tr><td><code id="setupParallel_+3A_sourcelibraries">sourcelibraries</code></td>
<td>

<p>Character vector. Libraries to be loaded in parallel. Defaults to the libraries multiridge depends on.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parallel computing is available for several functions that rely on cross-validation. If double CV is used, parallel computing is applied to the outer loop, to optimize efficiency.
</p>


<h3>Value</h3>

<p>No return value, called for side effects</p>


<h3>See Also</h3>

<p>Snowfall package for further documentation on parallel computing. A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
setupParallel(ncpus=4)

## End(Not run)
</code></pre>

<hr>
<h2 id='SigmaFromBlocks'>
Create penalized sample cross-product matrix
</h2><span id='topic+SigmaFromBlocks'></span>

<h3>Description</h3>

<p>Creates penalized sample cross-product matrix, dimension <code>nxn</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SigmaFromBlocks(XXblocks, penalties, pairing = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SigmaFromBlocks_+3A_xxblocks">XXblocks</code></td>
<td>

<p>List of <code>nxn</code> matrices. Usually output of <code><a href="#topic+createXXblocks">createXXblocks</a></code>.
</p>
</td></tr>
<tr><td><code id="SigmaFromBlocks_+3A_penalties">penalties</code></td>
<td>

<p>Numeric vector, representing penaltyparameters.
</p>
</td></tr>
<tr><td><code id="SigmaFromBlocks_+3A_pairing">pairing</code></td>
<td>

<p>Numerical vector of length 3 or <code>NULL</code> when pairs are absent. Represents the indices (in <code>XXblocks</code>) of the two data blocks involved in pairing,
plus the index of the paired block.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix of size <code>nxn</code>.
</p>


<h3>See Also</h3>

<p>A full demo and data are available from:<br />
<a href="https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4">https://drive.google.com/open?id=1NUfeOtN8-KZ8A2HZzveG506nBwgW64e4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Example
#Simulate
Xbl1 &lt;- matrix(rnorm(1000),nrow=10)
Xbl2 &lt;- matrix(rnorm(2000),nrow=10)

#check whether dimensions are correct
ncol(Xbl1)==nrow(Xbl2)

#create cross-product
XXbl &lt;- createXXblocks(list(Xbl1,Xbl2))

#suppose penalties for two data types equal 5,10, respectively
Sigma &lt;- SigmaFromBlocks(XXbl,c(5,10))

#check dimensions (should be n x n)
dim(Sigma)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
