<!DOCTYPE html><html><head><title>Help for package HDDesign</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HDDesign}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv_method'>

<p>Formula-based PCC of a CV-based classifier</p></a></li>
<li><a href='#cv_method_corr'>

<p>Formula-based method to calculate the PCC of a CV-based classifier when features are correlated.</p></a></li>
<li><a href='#cv_method_MC'>

<p>MC simulation-based method to calculate the PCC of a CV-based classifier; calculated using training and test datasets in MC simulations.</p></a></li>
<li><a href='#cv_method_MC_corr'>

<p>MC simulation-based method to calculate the PCC of a CV-based classifier when features are correlated; uses training and testing datasets.</p></a></li>
<li><a href='#ds_method'>
<p>Estimate PCC by DS Method</p></a></li>
<li><a href='#hct_beta'>

<p>Alternative HCT Procedure to Choose P-Value Threshold Based on Beta Distribution of P-Values.</p></a></li>
<li><a href='#hct_empirical'>

<p>Original HCT Procedure to Choose P-Value Threshold for Feature Selection</p></a></li>
<li><a href='#hct_method'>

<p>Estimate PCC of HCT Classifiers</p></a></li>
<li><a href='#hct_method_corr'>

<p>Estimate PCC of HCT Classifiers via implementation of Monte Carlo simulations with correlated features.</p></a></li>
<li><a href='#hct_method_MC'>

<p>Estimate PCC of HCT Classifiers via implementation of Monte Carlo simulations, using training and testing datasets</p></a></li>
<li><a href='#hct_method_MC_corr'>

<p>Estimate PCC of HCT Classifiers constructed with correlated features using Monte Carlo simulations</p></a></li>
<li><a href='#HDDesign-package'>
<p>Sample Size Calculation for High Dimensional Classification Study</p>
</p></a></li>
<li><a href='#ideal_pcc'>

<p>Determine the Ideal PCC</p></a></li>
<li><a href='#samplesize'>

<p>Determine the Sample Size Requirement</p></a></li>
<li><a href='#which.region'>

<p>Determine the Feasibility Region</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-06-10</td>
</tr>
<tr>
<td>Title:</td>
<td>Sample Size Calculation for High Dimensional Classification
Study</td>
</tr>
<tr>
<td>Author:</td>
<td>
	Meihua Wu &lt;meihuawu@umich.edu&gt;,
	Brisa N. Sanchez &lt;brisa@umich.edu&gt;,
	Peter X.K. Song &lt;pxsong@umich.edu&gt;, 
	Raymond Luu &lt;raluu@umich.edu&gt;,
	Wen Wang &lt;wangwen@umich.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Brisa N. Sanchez &lt;brisa@umich.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Determine the sample size requirement to achieve the target probability of correct classification (PCC) for studies employing high-dimensional features.  The package implements functions to 1) determine the asymptotic feasibility of the classification problem; 2) compute the upper bounds of the PCC for any linear classifier; 3) estimate the PCC of three design methods given design assumptions; 4) determine the sample size requirement to achieve the target PCC for three design methods. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-06-11 01:01:05 UTC; jiangwenjiaowa</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-06-11 09:37:25</td>
</tr>
</table>
<hr>
<h2 id='cv_method'>

Formula-based PCC of a CV-based classifier
</h2><span id='topic+cv_method'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for a high dimensional classification study employing 
cross validation to determine an optimal p-value cutoff to select features that are included in a linear classifier. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	cv_method(mu0, p, m, n, alpha_list, nrep, p1 = 0.5, ss = F, sampling.p=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_method_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_alpha_list">alpha_list</code></td>
<td>


<p>The search grid for the p-value threshold. 
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity.
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="cv_method_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to Sanchez, Wu, Song, Wang 2016, Section 2.2 for the details of the algorithm. This function was used to produce Figure 2 of the paper. 
</p>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	set.seed(1)
	cv_method(mu0=0.4, p=500, m=10, n=80, alpha_list=c(0.0000001, 0.0001, 0.01), 
	nrep=10, p1=0.6, ss=TRUE)
	#return: 0.8012142 0.8210082 0.7714031
	#alpha_list should be a dense list of p-value cutoffs; 
	#here we only use a few values to ease computation of the example.
</code></pre>

<hr>
<h2 id='cv_method_corr'>

Formula-based method to calculate the PCC of a CV-based classifier when features are correlated.
</h2><span id='topic+cv_method_corr'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for a high dimensional classification study employing 
Cross validation classifier. This is similar to cv_method, but features generated are correlated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	cv_method_corr(mu0, p, m, n, alpha_list, nrep, p1 = 0.5, ss = F, pcorr, 
	chol.rho,sampling.p=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_method_corr_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_alpha_list">alpha_list</code></td>
<td>


<p>The search grid for the p-value threshold. 
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity.
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_pcorr">pcorr</code></td>
<td>


<p>Number of correlated features.  
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_chol.rho">chol.rho</code></td>
<td>


<p>Cholesky decomposition of the covariance of the pcorr features that are correlated. It is assumed that the m important features are part of the pcorr correlated features.   
</p>
</td></tr>
<tr><td><code id="cv_method_corr_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to Sanchez, Wu, Song, Wang 2015, Section 3 and Supplementary materials.
</p>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Sigma_1 in the paper
	#first block is pcorr x pcorr of compound symmetry
	#other diagonal block is Identity; off diagonal blocks are 0
	pcorr=10  
	p=500
	rho.cs=.8
	#create first block
	rho=diag(c((1-rho.cs)*rep(1,pcorr),rep(1,p-pcorr)))+ matrix(c(rho.cs*
	rep(1,pcorr),rep(0,p-pcorr)),ncol=1) %*% c(rep(1,pcorr),rep(0,p-pcorr))
	chol.rho1.500=chol(rho[1:pcorr,1:pcorr])
	lmax= max(eigen(rho)$values)
	print(lmax)
	set.seed(1)
	cv_method_corr(mu0=0.4,p=500,m=10,n=80,alpha_list=c(0.0000001,0.0001,0.01),
	nrep=10,p1=0.6,ss=TRUE,pcorr=pcorr,chol.rho=chol.rho1.500,sampling.p=0.5)
	#return 0.6689385 0.6806896 0.6513119
	#alpha_list should be a dense grid of pvalue cut-offs; 
	#three values are used here for simplicity of the example 
</code></pre>

<hr>
<h2 id='cv_method_MC'>

MC simulation-based method to calculate the PCC of a CV-based classifier; calculated using training and test datasets in MC simulations.
</h2><span id='topic+cv_method_MC'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for a high dimensional classification study employing 
Cross validation classifier. In contrast to the cv_method this function also generates a test dataset so that the estimated PCC
does not rely on the normal approximation for the PCC formula. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	cv_method_MC(mu0, p, m, n, alpha_list, nrep, p1 = 0.5, ss = F, ntest, 
	sampling.p=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_method_MC_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups, that would be used to develop the classifier.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_alpha_list">alpha_list</code></td>
<td>


<p>The search grid for the p-value threshold. The examples below use only three values for the sake of giving examples that run quickly but this should ideally be a dense grid,
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_ntest">ntest</code></td>
<td>


<p>Sample size for the test dataset.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to  Sanchez, Wu, Song, Wang 2016, Section 2.2. This function was used to verify that a given sample size achieves the target PCC in Table 1 of the manuscript. 
</p>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>

<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	set.seed(1)
	cv_method_MC(mu0=0.4,p=500,m=10,n=80,alpha_list=c(0.0000001,0.0001,0.01),
	nrep=10,p1=0.6,ss=TRUE,ntest=100)
#return: 0.818 0.882 0.754
#alpha_list should be a dense list of p-value cutoffs; 
#here we only use a few values to ease computation of the example.
</code></pre>

<hr>
<h2 id='cv_method_MC_corr'>

MC simulation-based method to calculate the PCC of a CV-based classifier when features are correlated; uses training and testing datasets.
</h2><span id='topic+cv_method_MC_corr'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for a high dimensional classification study employing 
Cross validation classifier. This is similar to cv_method_MC, but instead features generated are correlated. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	cv_method_MC_corr(mu0, p, m, n, alpha_list, nrep, p1 = 0.5, ss = F, ntest, 
	pcorr, chol.rho,sampling.p=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_method_MC_corr_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_alpha_list">alpha_list</code></td>
<td>


<p>The search grid for the p-value threshold. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_ntest">ntest</code></td>
<td>


<p>Sample size for the test dataset. 
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_pcorr">pcorr</code></td>
<td>


<p>Number of correlated features.
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_chol.rho">chol.rho</code></td>
<td>


<p>Cholesky decomposition of the covariance of the pcorr features that are correlated. It is assumed that the m important features are part of the pcorr correlated features.   
</p>
</td></tr>
<tr><td><code id="cv_method_MC_corr_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to Sanchez, Wu, Song, Wang 2016, supplementary materials. This function is used to verify if a study using the sample sizes in Table 1 of the manuscript attains the PCC target via MC simulations. 
</p>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Sigma_1 in the paper
	#first block is pcorr x pcorr of compound symmetry
	#other diagonal block is Identity; off diagonal blocks are 0
	
	pcorr=10  
	p=500
	rho.cs=.8
	
	#create first block
	rho=matrix(rep(0,p^2),nrow=p)
	rho[1:pcorr,1:pcorr]=rho.cs
	diag(rho)=rep(1,p)
	
	chol.rho1.500=chol(rho[1:pcorr,1:pcorr])
	
	set.seed(1)
	cv_method_MC_corr(mu0=0.4,p=500,m=10,n=80,alpha_list=c(0.0000001,0.0001,0.01),
	nrep=10,p1=0.6,ss=TRUE,ntest=100,pcorr=10,chol.rho=chol.rho1.500)
	#return: 0.623 0.670 0.576
	#alpha_list should be a dense list of p-value cutoffs; 
	#here we only use a few values to ease computation of the example.
</code></pre>

<hr>
<h2 id='ds_method'>
Estimate PCC by DS Method
</h2><span id='topic+ds_method'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for studies employing high dimensional features for classification; 
uses the method proposed by (Dobbin and Simon 2007) to choose the p-value threshold for feature selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	ds_method(mu0, p, m, n, p1=0.5, lmax=1, ss=F, sampling.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ds_method_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_lmax">lmax</code></td>
<td>


<p>The maximum eigenvalue of the variance-covariance matrix of the p features. Defaults to 1 which implies that the features are assumed i.i.d.
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="ds_method_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to Dobbin and Simon (2007)
</p>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Dobbin, K.K., and Simon R.M. (2007). &quot;Sample Size Planning for Developing Classifiers Using High-dimensional DNA Microarray Data.&quot; Biostatistics 8 (1): 101-117. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ds_method(mu0=0.6, p=500, m=10, n=38, p1=0.5, lmax=1, ss=TRUE)
#[1] 0.9252471 0.9252471 0.9252471
</code></pre>

<hr>
<h2 id='hct_beta'>

Alternative HCT Procedure to Choose P-Value Threshold Based on Beta Distribution of P-Values.
</h2><span id='topic+hct_beta'></span>

<h3>Description</h3>


<p>This procedure chooses the p-value threshold for feature selection in a similar fashion to hct_empirical. However, it is based on the Beta distribution of the p-values. 
Only the features whose p-values are less than the thresold will be included in the classifier. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hct_beta(pvalue, p, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hct_beta_+3A_pvalue">pvalue</code></td>
<td>


<p>A vector containing the p*alpha_0 smallest p-values; typically alpha_0=0.10
</p>
</td></tr>
<tr><td><code id="hct_beta_+3A_p">p</code></td>
<td>


<p>The number of the features in total.
</p>
</td></tr>
<tr><td><code id="hct_beta_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to Sanchez, et al (2016), Section 3 and supplementary materials. 
</p>


<h3>Value</h3>






<p>The p-value threshold for feature selection. Only the features whose p-values are less than the threshold will be included in the classifier. 
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hct_beta(pvalue=0.10,p=500,n=80)
# 0.1
</code></pre>

<hr>
<h2 id='hct_empirical'>

Original HCT Procedure to Choose P-Value Threshold for Feature Selection
</h2><span id='topic+hct_empirical'></span>

<h3>Description</h3>


<p>This is the original Higher Criticism Threshold (HCT) procedure (Donoho and Jin 2009) to choose p-value threshold for feature selection. 
Only the features whose p-values are less than the thresold will be included in the classifier. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hct_empirical(pvalue, p, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hct_empirical_+3A_pvalue">pvalue</code></td>
<td>


<p>A vector containing the p*alpha_0 smallest p-values.
</p>
</td></tr>
<tr><td><code id="hct_empirical_+3A_p">p</code></td>
<td>


<p>The number of the features in total.
</p>
</td></tr>
<tr><td><code id="hct_empirical_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Refer to (Donoho and Jin 2009)
</p>


<h3>Value</h3>






<p>The p-value threshold for feature selection. Only the features whose p-values are less than the thresold will be included in the classifier. 
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Donoho, D. and Jin, J. 2009. &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906): 4449-4470.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>hct_empirical(pvalue=0.10,p=500,n=80)
# 0.1
</code></pre>

<hr>
<h2 id='hct_method'>

Estimate PCC of HCT Classifiers
</h2><span id='topic+hct_method'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for studies employing high dimensional features for classification. 
It is assumed that a Higher Criticism Threshold (HCT) is used to choose the p-value threshold for feature selection and that features meeting the threshold are regarded as important for classification. A linear combination of important features is assumed to form the classification rule, with all important features having equal weight. 
In addition to the original HCT procedure by Donoho and Jin (2009), two more procedures to choose p-value threshold have developed 
and implemented. This function generates a fraction (alpha0) of the smallest p-values, calculates the threshold, examines which p-values meet the p-value threshold, and uses the normal CDF to estimate the PCC of the classifier. Neither training nor testing data are used. (See Sanchez et al 2016.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	hct_method(mu0, p, m, n, hct, alpha0, nrep, p1 = 0.5, ss = F, sampling.p=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hct_method_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_hct">hct</code></td>
<td>


<p>The HCT procedure employed to choose the p-value threshold for feature selection. There are two valid choices (case sensitive): 
1) hct_empirical, the HCT procedure originally proposed by (Donoho and Jin 2009); 
2) hct_beta, an alternative HCT procedure which makes use of the beta distribution of the p-values under the null; 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_alpha0">alpha0</code></td>
<td>


<p>The proportion of the smallest p-values we will consider in the HCT algorithm, typically 0.1. 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity. 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="hct_method_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Donoho, D, and Jin, J. (2009). &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906): 4449-4470.
</p>
<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
hct_method(mu0=0.4, p=500, m=10, n=80, hct=hct_beta, alpha0=0.5, nrep=10, 
p1 = 0.5, ss = TRUE) 
#return: 0.807098 0.807098 0.807098
</code></pre>

<hr>
<h2 id='hct_method_corr'>

Estimate PCC of HCT Classifiers via implementation of Monte Carlo simulations with correlated features.
</h2><span id='topic+hct_method_corr'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for studies employing high dimensional features for classification. 
Higher Criticisms Threshold (HCT) classifier is used to choose the p-value threshold for feature selection. 
In addition to the original HCT procedure by (Donoho and Jin 2009), two more procedures to choose p-value threshold have developed 
and implemented. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	hct_method_corr(mu0, p, m, n, hct, alpha0, nrep, p1 = 0.5, 
	ss = F, pcorr, chol.rho, sampling.p=0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hct_method_corr_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_hct">hct</code></td>
<td>


<p>The HCT procedure employed to choose the p-value threshold for feature selection. There are two valid choices (case sensitive): 
1) hct_empirical, the HCT procedure originally proposed by (Donoho and Jin 2009); 
2) hct_beta, an alternative HCT procedure which makes use of the beta distribution of the p-values under the null
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_alpha0">alpha0</code></td>
<td>


<p>The proportion of the smallest p-values we will consider in the HCT algorithm. 
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity. 
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_pcorr">pcorr</code></td>
<td>


<p>Number of correlated features.
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_chol.rho">chol.rho</code></td>
<td>


<p>Cholesky decomposition of the covariance of the pcorr features that are correlated. It is assumed that the m important features are part of the pcorr correlated features.   
</p>
</td></tr>
<tr><td><code id="hct_method_corr_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Donoho, D., and Jin, J. (2009). &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906) (November 13): 4449-4470.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Sigma_1 in the paper
#first block is pcorr x pcorr of compound symmetry
#other diagonal block is Identity; off diagonal blocks are 0
	pcorr=10  
	p=500
	rho.cs=.8
	#create first block
	rho= diag(c((1-rho.cs)*rep(1,pcorr),rep(1,p-pcorr)))+ matrix(c(rho.cs*
	rep(1,pcorr),rep(0,p-pcorr)), ncol=1) %*% c(rep(1,pcorr),rep(0,p-pcorr))
	chol.rho1.500=chol(rho[1:pcorr,1:pcorr])
	set.seed(1)
	hct_method_corr(mu0=0.4,p=500,m=10,n=80,hct=hct_beta,alpha0=0.5,nrep=10,
	p1=0.5,ss=TRUE,pcorr=pcorr,chol.rho=chol.rho1.500)
	#return: 0.6672256 0.6672256 0.6672256
</code></pre>

<hr>
<h2 id='hct_method_MC'>

Estimate PCC of HCT Classifiers via implementation of Monte Carlo simulations, using training and testing datasets
</h2><span id='topic+hct_method_MC'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for studies employing high dimensional features for classification. 
It is assumed that a Higher Criticism Threshold (HCT) is used to choose the p-value threshold for feature selection and that features meeting the threshold are important for classification. 
In addition to the original HCT procedure by Donoho and Jin (2009), two procedures to choose p-value threshold have been 
implemented (See hct_empirical and hct_beta). This function is similar to hct_method but this does not rely on the normal CDF to approximate the PCC. Instead training and testing datasets are generated at each iteration of the algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	hct_method_MC(mu0, p, m, n, hct, alpha0, nrep, p1=0.5, ss=F, ntest,
	sampling.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hct_method_MC_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_hct">hct</code></td>
<td>


<p>The HCT procedure employed to choose the p-value threshold for feature selection. There are two valid choices (case sensitive): 
1) hct_empirical, the HCT procedure originally proposed by Donoho and Jin (2009); 
2) hct_beta, an alternative HCT procedure which makes use of the beta distribution of the p-values under the null; 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_alpha0">alpha0</code></td>
<td>


<p>The proportion of the smallest p-values we will consider in the HCT algorithm. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_ntest">ntest</code></td>
<td>


<p>Sample size for the test dataset.
</p>
</td></tr>
<tr><td><code id="hct_method_MC_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Donoho, D., and Jin J. (2009). &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906) (November 13): 4449-4470.
</p>
<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
hct_method_MC(mu0=0.4,p=500,m=10,n=80,hct=hct_beta,alpha0=0.5,nrep=10,p1=0.5,
ss=TRUE,ntest=100,sampling.p=0.5)
#return: 0.801 0.806 0.796
</code></pre>

<hr>
<h2 id='hct_method_MC_corr'>

Estimate PCC of HCT Classifiers constructed with correlated features using Monte Carlo simulations
</h2><span id='topic+hct_method_MC_corr'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for studies employing high dimensional features for classification. 
It is assumed that a Higher Criticism Threshold (HCT) is used to choose the p-value threshold for feature selection and that features meeting the threshold are important for classification. 
In addition to the original HCT procedure by (Donoho and Jin 2009), two procedures to choose p-value threshold have been 
implemented (See hct_empirical and hct_beta). This function is similar to hct_method_corr but this does not rely on the normal CDF to approximate the PCC. Instead training and testing datasets are generated at each iteration of the algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	hct_method_MC_corr(mu0, p, m, n, hct, alpha0, nrep, p1=0.5, 
	ss=FALSE, ntest, pcorr, chol.rho,sampling.p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hct_method_MC_corr_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_hct">hct</code></td>
<td>


<p>The HCT procedure employed to choose the p-value threshold for feature selection. There are two valid choices (case sensitive): 
1) hct_empirical, the HCT procedure originally proposed by (Donoho and Jin 2009); 
2) hct_beta, an alternative HCT procedure which makes use of the beta distribution of the p-values under the null; 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_alpha0">alpha0</code></td>
<td>


<p>The proportion of the smallest p-values we will consider in the HCT algorithm. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_nrep">nrep</code></td>
<td>


<p>The number of simulation replicates employed to compute the expected PCC and/or sensitivity and specificity. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_ss">ss</code></td>
<td>


<p>Boolean variable, default to FALSE. The TRUE value instruct the program to compute the sensitivity and the specificity of the classifier. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_ntest">ntest</code></td>
<td>


<p>Sample size for the test dataset. 
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_pcorr">pcorr</code></td>
<td>


<p>Number of correlated features.
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_chol.rho">chol.rho</code></td>
<td>


<p>Cholesky decomposition of the covariance of the pcorr features that are correlated. It is assumed that the m important features are part of the pcorr correlated features.   
</p>
</td></tr>
<tr><td><code id="hct_method_MC_corr_+3A_sampling.p">sampling.p</code></td>
<td>


<p>The assumed proportion of group 1 samples in the training data; default of 0.5 assumes groups are equally represented regardless of p1.
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>If ss=FALSE, the function returns the expected PCC. 
If ss=TRUE, the function returns a vector containing the expected PCC, sensitivity and specificity.
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Donoho, D., and Jin J. (2009). &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906) (November 13): 4449-4470.
</p>
<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Sigma_1 in the paper
#first block is pcorr x pcorr of compound symmetry
#other diagonal block is Identity; off diagonal blocks are 0
pcorr=10  
p=500
rho.cs=.8
#create first block
rho=matrix(rep(0,p^2),nrow=p)
rho[1:pcorr,1:pcorr]=rho.cs
diag(rho)=rep(1,p)
chol.rho1.500=chol(rho[1:pcorr,1:pcorr])
set.seed(1)
hct_method_MC_corr(mu0=0.4, p=500, m=10, n=80, hct=hct_beta, alpha0=0.5, nrep=10, 
p1 = 0.5, ss=TRUE, ntest=100, pcorr=10, chol.rho=chol.rho1.500,sampling.p=0.5)
#return: 0.673 0.686 0.660
</code></pre>

<hr>
<h2 id='HDDesign-package'>
Sample Size Calculation for High Dimensional Classification Study
</h2><span id='topic+HDDesign-package'></span><span id='topic+HDDesign'></span>

<h3>Description</h3>

<p>This package facilitates the design of studies employing high dimensional features for binary classification.  
The package assumes that the study will build a linear classifier by first screening features and selecting those that appear important for classification, and then forming a linear predictor based on the selected features.  
The package implements functions to 
1) determine the asymptotic feasibility of the classification problem; 
2) compute the upper bounds of the PCC for any linear classifiers; 
3) estimate the PCC of three design methods given design assumptions; 
4) determine the sample size requirement to achieve the target PCC for various design methods. 
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> HDDesign</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2016-04-26</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Design of high-dimensional classification studies involves several aspects. Firstly, we need to consider the feasibility of the classification. 
For high dimensional classification, the important signals are sometimes
so sparse and weak that the performance of any linear classifiers is no better than a random assignment classifier.
We implement functions to determine the asymptotic feasibility of the classification problem based on the theory 
of the rare and weak model (Donoho and Jin 2009). If the classification is feasible, we need to determine the appropriate target PCC to calibrate the sample size calculation.
The lower bound of the PCC corresponds to the worst case scenario where
the classifier performs as poor as the random assignment classifier. 
Then the lower bound of the PCC is the prevalence of the dominating group.
The upper bound of the PCC corresponds to the best case scenario where 
the classifier performs as good as the ideal classifier which uses full knowledge
of the data generating mechanism by Dobbin and Simon (2007). 
We implement a function to compute the PCC of the ideal classifier. 
Then  the target PCC can be chosen between the lower and upper bounds, depending
on the budget and other constraints of the study. Furthermore, we need to incorporate the uncertainty in feature selection into our sample size calculations in the design stage to ensure the target PCC is achieved at the analysis stage. 
We have implemented the following feature selection methods: 
a procedure proposed by Dobbin and Simon (2007), 
thresholding by cross validation,
and Higher Criticism Threshold (HCT) by Donoho and Jin (2009). We implement an efficient algorithm to calculate the sample size required when features are iid, for the case when HCT
is used to build the classifier. The CV method is more computationally intensive. We also adapt the approaches for the cases when features are correlated, however the resulting sample sizes will often be conservative.
</p>
<p>In this package we use the following assumptions and notations. We assume features have the same variance across groups, and for simplicity assume all variances equal 1. 
If the differences between the means of a feature between the groups is zero,
then this feature does not differentially express between
the groups and it is therefore not important for the purpose of classification. 
If, however, the difference is non zero, this feature is important and its effect size 
is half of the absolute value of the difference. We denote the effect size by mu0, the total
number of features by p; the number of important features by m; and the total sample size for
two groups by n; the prevalence of &quot;group 1&quot; in the population by p1 and the prevalence of &quot;group -1&quot; by 1-p1. Finally, pvalues for all pairwise associations are derived from the t-distribution instead of a normal distribution to take into account the fact that some studies may have a small sample size. 
</p>
<p>In the example below, we will illustrate how to use the functions implemented in this
package to address the sample size calculation problem for studies employing high dimensional 
features for classification.
</p>


<h3>Author(s)</h3>

<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>

<p>Donoho, D, and Jin, J. (2009). &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906) : 4449-4470.
</p>
<p>Dobbin, K.K., and Simon R.M. (2007). &quot;Sample Size Planning for Developing Classifiers Using High-dimensional DNA Microarray Data.&quot; Biostatistics 8 (1): 101-117. 
</p>
<p>Sanchez, B.N., Wu, M., Song, P.X.K., and Wang W. (2016). &quot;Study design in high-dimensional classification analysis.&quot; Biostatistics, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Consider the following design scenario:
# Prevalence of Group 1
p1=0.5
# Effect size
mu0=0.4
# Total number of features
p=500
# The number of important features
m=10


# Step 1: Feasibility of the classification for a study with about 100 individuals
which.region(mu0=mu0, p=p, m=m, n=100)
# return 4, indicating the classification belongs to the feasible region. 

# Step 2: Upper bound of the PCC
ideal_pcc(mu0=mu0, m=m, p1=p1)
# return 0.8970484, 
# So the target PCC can be chosen between 0.5 and 0.8970484.

# Step 3: Obtain the sample requirement for target PCC equal to 0.8
#Use method proposed by Dobbin and Simon (2007)
set.seed(1)
samplesize(target=0.8, nmin=20, nmax=100, ds_method, mu0=0.4, p=500, m=10)
#return sample size n=66

#Use cross validation(commented due to long waiting time)
#set.seed(1)
#samplesize(target=0.8, nmin=20, nmax=100, cv_method, mu0=0.4, p=500, m=10, 
#alpha_list=10^((-10):(-2)), nrep=100) 
#alpha_list should be a dense list of p-value cutoffs; 
#here we only use a few values to ease computation of the example.
#return sample size n=78.

#Use HCT 
set.seed(1)
samplesize(target=0.8, nmin=20, nmax=100, hct_method, mu0=0.4, p=500, m=10, 
hct=hct_beta, alpha0=0.5, nrep=100) 
#return sample size n=78.

</code></pre>

<hr>
<h2 id='ideal_pcc'>

Determine the Ideal PCC
</h2><span id='topic+ideal_pcc'></span>

<h3>Description</h3>


<p>Determine the probability of correct classification (PCC) for a study employing the ideal classifier. The ideal classifier is constructed
assuming we know exactly the important features and their effect size. The ideal PCC is the uppper bound of the PCC of any linear classifiers. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ideal_pcc(mu0, m, p1 = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ideal_pcc_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="ideal_pcc_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="ideal_pcc_+3A_p1">p1</code></td>
<td>


<p>The prevalence of the group 1 in the population, default to 0.5.
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>The PCC of the ideal classifier. 
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Dobbin, Kevin K., and Richard M. Simon. 2007. &quot;Sample Size Planning for Developing Classifiers Using High-dimensional DNA Microarray Data.&quot; Biostatistics 8 (1) (January 1): 101-117. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ideal_pcc(mu0=0.4, m=10, p1 = 0.6) 
#return: 0.8999055
</code></pre>

<hr>
<h2 id='samplesize'>

Determine the Sample Size Requirement
</h2><span id='topic+samplesize'></span>

<h3>Description</h3>


<p>Determine the sample size to achieve the target probability of correct classification (PCC) using various design methods. Sample sizes are chosen using a binary search algorithm between the range nmin to nmax.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	samplesize(target, nmin, nmax, f, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="samplesize_+3A_target">target</code></td>
<td>


<p>Set the target probability of correct classifcation (PCC) for the study.
</p>
</td></tr>
<tr><td><code id="samplesize_+3A_nmin">nmin</code></td>
<td>


<p>The mimimum sample size for both groups combined. Typically 0.05 smaller than the ideal PCC. It must be an even number. 
</p>
</td></tr>
<tr><td><code id="samplesize_+3A_nmax">nmax</code></td>
<td>


<p>The maximum sample size for both groups combined. So it must be an even number. 
</p>
</td></tr>
<tr><td><code id="samplesize_+3A_f">f</code></td>
<td>


<p>Specify the PCC estimation function: ds_method, cv_method, or hct_method
</p>
</td></tr>
<tr><td><code id="samplesize_+3A_...">...</code></td>
<td>


<p>The design assumptions and other arguments for the PCC estimation function, f. 
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>The smallest sample size that achieves the target PCC. 
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
samplesize(target=0.8, nmin=20, nmax=100, hct_method, mu0=0.4, p=500, 
m=10, hct=hct_beta, alpha0=0.5, nrep=100) 
#return: 78.0000000  0.8043205
</code></pre>

<hr>
<h2 id='which.region'>

Determine the Feasibility Region
</h2><span id='topic+which.region'></span>

<h3>Description</h3>


<p>Given the design assumption, determine which feasiblity region the design problem belongs to.
The feasibility region is constructed from the asymptotic properties of the rare-and-weak model (Donoho and Jin 2009). 
The two groups are assumed to be equally proportioned, i.e. p_+1=p_-1=0.5.
If the the problem is feasible, then the probability of correct classification (PCC) of the HCT classifer 
will approach 1 when the number of features goes to infinity. 
If the the problem is unfeasible, then the probability of correct classification (PCC) of any linear classifer 
will approach 0.5  when the number of features goes to infinity. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>which.region(mu0, p, m, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="which.region_+3A_mu0">mu0</code></td>
<td>


<p>The effect size of the important features. 
</p>
</td></tr>
<tr><td><code id="which.region_+3A_p">p</code></td>
<td>


<p>The number of the features in total. 
</p>
</td></tr>
<tr><td><code id="which.region_+3A_m">m</code></td>
<td>


<p>The number of the important features. 
</p>
</td></tr>
<tr><td><code id="which.region_+3A_n">n</code></td>
<td>


<p>The total sample size for the two groups.
</p>
</td></tr>
</table>


<h3>Value</h3>






<table>
<tr><td><code>0</code></td>
<td>
<p>The classification problem belongs to the unfeasible region.</p>
</td></tr>
<tr><td><code>1</code></td>
<td>
<p>The classification problem belongs to the feasible region.</p>
</td></tr>
<tr><td><code>2</code></td>
<td>
<p>The classification problem belongs to the feasible region.</p>
</td></tr>
<tr><td><code>3</code></td>
<td>
<p>The classification problem belongs to the feasible region.</p>
</td></tr>
<tr><td><code>4</code></td>
<td>
<p>The classification problem belongs to the feasible region.</p>
</td></tr>
</table>
<p>Region 1-4 are all feasible regions. Their difference is discussed in more details in ().
</p>


<h3>Author(s)</h3>


<p>Meihua Wu &lt;meihuawu@umich.edu&gt;
Brisa N. Sanchez &lt;brisa@umich.edu&gt;
Peter X.K. Song &lt;pxsong@umich.edu&gt; 
Raymond Luu &lt;raluu@umich.edu&gt;
Wen Wang &lt;wangwen@umich.edu&gt;
</p>


<h3>References</h3>


<p>Donoho, David, and Jiashun Jin. 2009. &quot;Feature Selection by Higher Criticism Thresholding Achieves the Optimal Phase Diagram.&quot; Philosophical Transactions. Series A, Mathematical, Physical, and Engineering Sciences 367 (1906) (November 13): 4449-4470.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	which.region(mu0=0.4, p=500, m=10, n=80) 
	#return: 4
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
