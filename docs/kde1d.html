<!DOCTYPE html><html><head><title>Help for package kde1d</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kde1d}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dkde1d'><p>Working with a kde1d object</p></a></li>
<li><a href='#equi_jitter'><p>Conditionally equidistant jittering</p></a></li>
<li><a href='#kde1d'><p>Univariate local-polynomial likelihood kernel density estimation</p></a></li>
<li><a href='#kde1d-package'><p>One-Dimensional Kernel Density Estimation</p></a></li>
<li><a href='#plot.kde1d'><p>Plotting kde1d objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Univariate Kernel Density Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.7</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an efficient implementation of univariate local polynomial
    kernel density estimators that can handle bounded and discrete data. See 
    Geenens (2014) &lt;<a href="https://arxiv.org/abs/1303.4121">arXiv:1303.4121</a>&gt;, 
    Geenens and Wang (2018) &lt;<a href="https://arxiv.org/abs/1602.04862">arXiv:1602.04862</a>&gt;, 
    Nagler (2018a) &lt;<a href="https://arxiv.org/abs/1704.07457">arXiv:1704.07457</a>&gt;, 
    Nagler (2018b) &lt;<a href="https://arxiv.org/abs/1705.05431">arXiv:1705.05431</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH, Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, Rcpp, randtoolbox, stats, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tnagler/kde1d">https://github.com/tnagler/kde1d</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tnagler/kde1d/issues">https://github.com/tnagler/kde1d/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-26 16:00:47 UTC; n5</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas Nagler [aut, cre],
  Thibault Vatter [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Nagler &lt;mail@tnagler.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-26 16:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dkde1d'>Working with a kde1d object</h2><span id='topic+dkde1d'></span><span id='topic+pkde1d+2C'></span><span id='topic+qkde1d+2C'></span><span id='topic+rkde1d'></span><span id='topic+pkde1d'></span><span id='topic+qkde1d'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random generation
for a 'kde1d' kernel density estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dkde1d(x, obj)

pkde1d(q, obj)

qkde1d(p, obj)

rkde1d(n, obj, quasi = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dkde1d_+3A_x">x</code></td>
<td>
<p>vector of density evaluation points.</p>
</td></tr>
<tr><td><code id="dkde1d_+3A_obj">obj</code></td>
<td>
<p>a <code>kde1d</code> object.</p>
</td></tr>
<tr><td><code id="dkde1d_+3A_q">q</code></td>
<td>
<p>vector of quantiles.</p>
</td></tr>
<tr><td><code id="dkde1d_+3A_p">p</code></td>
<td>
<p>vector of probabilities.</p>
</td></tr>
<tr><td><code id="dkde1d_+3A_n">n</code></td>
<td>
<p>integer; number of observations.</p>
</td></tr>
<tr><td><code id="dkde1d_+3A_quasi">quasi</code></td>
<td>
<p>logical; the default (<code>FALSE</code>) returns pseudo-random
numbers, use <code>TRUE</code> for quasi-random numbers (generalized Halton, see
<code><a href="randtoolbox.html#topic+quasiRNG">randtoolbox::sobol()</a></code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+dkde1d">dkde1d()</a></code> gives the density, <code><a href="#topic+pkde1d">pkde1d()</a></code> gives
the distribution function, <code><a href="#topic+qkde1d">qkde1d()</a></code> gives the quantile function,
and <code><a href="#topic+rkde1d">rkde1d()</a></code> generates random deviates.
</p>
<p>The length of the result is determined by <code>n</code> for <code><a href="#topic+rkde1d">rkde1d()</a></code>, and
is the length of the numerical argument for the other functions.
</p>


<h3>Value</h3>

<p>The density, distribution function or quantile functions estimates
evaluated respectively at <code>x</code>, <code>q</code>, or <code>p</code>, or a sample of <code>n</code> random
deviates from the estimated kernel density.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kde1d">kde1d()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(0) # for reproducibility
x &lt;- rnorm(100) # simulate some data
fit &lt;- kde1d(x) # estimate density
dkde1d(0, fit) # evaluate density estimate (close to dnorm(0))
pkde1d(0, fit) # evaluate corresponding cdf (close to pnorm(0))
qkde1d(0.5, fit) # quantile function (close to qnorm(0))
hist(rkde1d(100, fit)) # simulate
</code></pre>

<hr>
<h2 id='equi_jitter'>Conditionally equidistant jittering</h2><span id='topic+equi_jitter'></span>

<h3>Description</h3>

<p>Converts ordered variables to numeric and Adds deterministic uniform noise.
See <em>Details</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equi_jitter(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="equi_jitter_+3A_x">x</code></td>
<td>
<p>observations; the function does nothing if <code>x</code> is already numeric.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Jittering makes discrete variables continuous by adding noise. This simple
trick allows to consistently estimate densities with tools designed for the
continuous case (see, Nagler, 2018a/b). The drawback is that estimates are
random and the noise may deteriorate the estimate by chance.
</p>
<p>Here, we add a form of deterministic noise that makes estimators well
behaved. Tied occurences of a factor level are spread out uniformly
(i.e., equidistantly) on the interval <code class="reqn">[-0.5, 0.5]</code>. This is similar to
adding random noise that is uniformly distributed, conditional on the
observed outcome. Integrating over the outcome, one can check that the
unconditional noise distribution is also uniform on <code class="reqn">[-0.5, 0.5]</code>.
</p>
<p>Asymptotically, the deterministic jittering variant is equivalent to the
random one.
</p>


<h3>References</h3>

<p>Nagler, T. (2018a). <em>A generic approach to nonparametric function estimation
with mixed data.</em> Statistics &amp; Probability Letters, 137:326â€“330,
<a href="https://arxiv.org/abs/1704.07457">arXiv:1704.07457</a>
</p>
<p>Nagler, T. (2018b). <em>Asymptotic analysis of the jittering kernel density
estimator.</em> Mathematical Methods of Statistics, in press,
<a href="https://arxiv.org/abs/1705.05431">arXiv:1705.05431</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- as.factor(rbinom(10, 1, 0.5))
equi_jitter(x)
</code></pre>

<hr>
<h2 id='kde1d'>Univariate local-polynomial likelihood kernel density estimation</h2><span id='topic+kde1d'></span>

<h3>Description</h3>

<p>The estimators can handle data with bounded, unbounded, and discrete support,
see <em>Details</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kde1d(
  x,
  xmin = NaN,
  xmax = NaN,
  mult = 1,
  bw = NA,
  deg = 2,
  weights = numeric(0)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kde1d_+3A_x">x</code></td>
<td>
<p>vector (or one-column matrix/data frame) of observations; can be
<code>numeric</code> or <code>ordered</code>.</p>
</td></tr>
<tr><td><code id="kde1d_+3A_xmin">xmin</code></td>
<td>
<p>lower bound for the support of the density (only for continuous
data); <code>NaN</code> means no boundary.</p>
</td></tr>
<tr><td><code id="kde1d_+3A_xmax">xmax</code></td>
<td>
<p>upper bound for the support of the density (only for continuous
data); <code>NaN</code> means no boundary.</p>
</td></tr>
<tr><td><code id="kde1d_+3A_mult">mult</code></td>
<td>
<p>positive bandwidth multiplier; the actual bandwidth used is
<code class="reqn">bw*mult</code>.</p>
</td></tr>
<tr><td><code id="kde1d_+3A_bw">bw</code></td>
<td>
<p>bandwidth parameter; has to be a positive number or <code>NA</code>; the
latter uses the plug-in methodology of Sheather and Jones (1991) with
appropriate modifications for <code>deg &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="kde1d_+3A_deg">deg</code></td>
<td>
<p>degree of the polynomial; either <code>0</code>, <code>1</code>, or <code>2</code> for
log-constant, log-linear, and log-quadratic fitting, respectively.</p>
</td></tr>
<tr><td><code id="kde1d_+3A_weights">weights</code></td>
<td>
<p>optional vector of weights for individual observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A gaussian kernel is used in all cases. If <code>xmin</code> or <code>xmax</code> are
finite, the density estimate will be 0 outside of <code class="reqn">[xmin, xmax]</code>. A
log-transform is used if there is only one boundary (see, Geenens and Wang,
2018); a probit transform is used if there are two (see, Geenens, 2014).
</p>
<p>Discrete variables are handled via jittering (see, Nagler, 2018a, 2018b).
A specific form of deterministic jittering is used, see <code><a href="#topic+equi_jitter">equi_jitter()</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>kde1d</code>.
</p>


<h3>References</h3>

<p>Geenens, G. (2014). <em>Probit transformation for kernel density
estimation on the unit interval</em>. Journal of the American Statistical
Association, 109:505, 346-358,
<a href="https://arxiv.org/abs/1303.4121">arXiv:1303.4121</a>
</p>
<p>Geenens, G., Wang, C. (2018). <em>Local-likelihood transformation kernel density
estimation for positive random variables.</em> Journal of Computational and
Graphical Statistics, to appear,
<a href="https://arxiv.org/abs/1602.04862">arXiv:1602.04862</a>
</p>
<p>Nagler, T. (2018a). <em>A generic approach to nonparametric function estimation
with mixed data.</em> Statistics &amp; Probability Letters, 137:326â€“330,
<a href="https://arxiv.org/abs/1704.07457">arXiv:1704.07457</a>
</p>
<p>Nagler, T. (2018b). <em>Asymptotic analysis of the jittering kernel density
estimator.</em> Mathematical Methods of Statistics, in press,
<a href="https://arxiv.org/abs/1705.05431">arXiv:1705.05431</a>
</p>
<p>Sheather, S. J. and Jones, M. C. (1991). A reliable data-based bandwidth
selection method for kernel density estimation. Journal of the Royal
Statistical Society, Series B, 53, 683â€“690.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dkde1d">dkde1d()</a></code>, <code><a href="#topic+pkde1d">pkde1d()</a></code>, <code><a href="#topic+qkde1d">qkde1d()</a></code>, <code><a href="#topic+rkde1d">rkde1d()</a></code>,
<code><a href="#topic+plot.kde1d">plot.kde1d()</a></code>, <code><a href="#topic+lines.kde1d">lines.kde1d()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## unbounded data
x &lt;- rnorm(500) # simulate data
fit &lt;- kde1d(x) # estimate density
dkde1d(0, fit) # evaluate density estimate
summary(fit) # information about the estimate
plot(fit) # plot the density estimate
curve(dnorm(x),
  add = TRUE, # add true density
  col = "red"
)

## bounded data, log-linear
x &lt;- rgamma(500, shape = 1) # simulate data
fit &lt;- kde1d(x, xmin = 0, deg = 1) # estimate density
dkde1d(seq(0, 5, by = 1), fit) # evaluate density estimate
summary(fit) # information about the estimate
plot(fit) # plot the density estimate
curve(dgamma(x, shape = 1), # add true density
  add = TRUE, col = "red",
  from = 1e-3
)

## discrete data
x &lt;- rbinom(500, size = 5, prob = 0.5) # simulate data
x &lt;- ordered(x, levels = 0:5) # declare as ordered
fit &lt;- kde1d(x) # estimate density
dkde1d(sort(unique(x)), fit) # evaluate density estimate
summary(fit) # information about the estimate
plot(fit) # plot the density estimate
points(ordered(0:5, 0:5), # add true density
  dbinom(0:5, 5, 0.5),
  col = "red"
)

## weighted estimate
x &lt;- rnorm(100) # simulate data
weights &lt;- rexp(100) # weights as in Bayesian bootstrap
fit &lt;- kde1d(x, weights = weights) # weighted fit
plot(fit) # compare with unweighted fit
lines(kde1d(x), col = 2)
</code></pre>

<hr>
<h2 id='kde1d-package'>One-Dimensional Kernel Density Estimation</h2><span id='topic+kde1d-package'></span>

<h3>Description</h3>

<p>Provides an efficient implementation of univariate local polynomial
kernel density estimators that can handle bounded and discrete data. The
implementation utilizes spline interpolation to reduce memory usage and
computational demand for large data sets.
</p>


<h3>References</h3>

<p>Geenens, G. (2014). <em>Probit transformation for kernel density estimation on
the unit interval</em>. Journal of the American Statistical Association,
109:505, 346-358, <a href="https://arxiv.org/abs/1303.4121">arXiv:1303.4121</a>
</p>
<p>Geenens, G., Wang, C. (2018). <em>Local-likelihood transformation kernel
density estimation for positive random variables.</em> Journal of Computational
and Graphical Statistics, to appear,
<a href="https://arxiv.org/abs/1602.04862">arXiv:1602.04862</a>
</p>
<p>Nagler, T. (2018a). <em>A generic approach to nonparametric function
estimation with mixed data.</em> Statistics &amp; Probability Letters, 137:326â€“330,
<a href="https://arxiv.org/abs/1704.07457">arXiv:1704.07457</a>
</p>
<p>Nagler, T. (2018b). <em>Asymptotic analysis of the jittering kernel density
estimator.</em> Mathematical Methods of Statistics, in press,
<a href="https://arxiv.org/abs/1705.05431">arXiv:1705.05431</a>
</p>

<hr>
<h2 id='plot.kde1d'>Plotting kde1d objects</h2><span id='topic+plot.kde1d'></span><span id='topic+lines.kde1d'></span>

<h3>Description</h3>

<p>Plotting kde1d objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kde1d'
plot(x, ...)

## S3 method for class 'kde1d'
lines(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.kde1d_+3A_x">x</code></td>
<td>
<p><code>kde1d</code> object.</p>
</td></tr>
<tr><td><code id="plot.kde1d_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="graphics.html#topic+plot.default">plot.default()</a></code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+kde1d">kde1d()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## continuous data
x &lt;- rbeta(100, shape1 = 0.3, shape2 = 0.4) # simulate data
fit &lt;- kde1d(x) # unbounded estimate
plot(fit, ylim = c(0, 4)) # plot estimate
curve(dbeta(x, 0.3, 0.4), # add true density
  col = "red", add = TRUE
)
fit_bounded &lt;- kde1d(x, xmin = 0, xmax = 1) # bounded estimate
lines(fit_bounded, col = "green")

## discrete data
x &lt;- rpois(100, 3) # simulate data
x &lt;- ordered(x, levels = 0:20) # declare variable as ordered
fit &lt;- kde1d(x) # estimate density
plot(fit, ylim = c(0, 0.25)) # plot density estimate
points(ordered(0:20, 0:20), # add true density values
  dpois(0:20, 3),
  col = "red"
)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
