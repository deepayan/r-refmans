<!DOCTYPE html><html lang="en"><head><title>Help for package vimpclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {vimpclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#check_fun_groupsparsw'><p>check_fun_groupsparsw</p></a></li>
<li><a href='#DataMice'><p>Mice Protein Expression Data Set</p></a></li>
<li><a href='#groupsoft'><p>Group soft-thresholding operator</p></a></li>
<li><a href='#groupsparsewkm'><p>Group-sparse weighted k-means</p></a></li>
<li><a href='#HDdata'><p>Statlog (Heart) Data Set</p></a></li>
<li><a href='#info_clust'><p>Description of a set of partitions</p></a></li>
<li><a href='#plot.spwkm'><p>Plots from a &quot;spwkm&quot; object</p></a></li>
<li><a href='#recodmix'><p>Recoding mixed data</p></a></li>
<li><a href='#sparsewkm'><p>Sparse weighted k-means</p></a></li>
<li><a href='#weightedss'><p>Weighted sum-of-squares criteria</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Importance in Clustering</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of methods related to sparse clustering and variable importance 
    in clustering. The package currently allows to perform sparse k-means clustering with a group 
    penalty, so that it automatically selects groups of numerical features. It also allows to 
    perform sparse clustering and variable selection on mixed data (categorical and numerical 
    features), by preprocessing each categorical feature as a group of numerical features.
    Several methods for visualizing and exploring the results are also provided. 
    M. Chavent, J. Lacaille, A. Mourer and M. Olteanu (2020)<a href="https://www.esann.org/sites/default/files/proceedings/2020/ES2020-103.pdf">https://www.esann.org/sites/default/files/proceedings/2020/ES2020-103.pdf</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>PCAmixdata, ggplot2, Polychrome, mclust, rlang</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-12-18 13:36:56 UTC; administrateur</td>
</tr>
<tr>
<td>Author:</td>
<td>Alex Mourer [aut],
  Marie Chavent [aut, ths],
  Madalina Olteanu [aut, ths, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Madalina Olteanu &lt;madalina.olteanu@dauphine.psl.eu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-01-08 09:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='check_fun_groupsparsw'>check_fun_groupsparsw</h2><span id='topic+check_fun_groupsparsw'></span>

<h3>Description</h3>

<p>check_fun_groupsparsw
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_fun_groupsparsw(
  X,
  lambda,
  nlambda,
  index,
  sizegroup,
  itermaxw,
  scaling,
  verbose
)
</code></pre>

<hr>
<h2 id='DataMice'>Mice Protein Expression Data Set</h2><span id='topic+DataMice'></span>

<h3>Description</h3>

<p>The data set consists of the expression levels of 68 proteins that produced detectable signal in the nuclear fraction of 
cortex for a sample of 72 mice. There are 38 control mice and 34 trisomic mice. Several measurements were recorded for each protein
and for each mouse. The measurements containing missing observations in the original data were suppressed, so that one has between
12 and 15 measurements per protein and per mouse. 
</p>
<p>Mice may be further described based on the treatment they received (injected with memantine or saline), and on their behaviour 
(stimulated to learn or not).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DataMice
</code></pre>


<h3>Format</h3>

<p>A data frame of 72 rows (mice) and 905 columns (variables):
</p>


<h3>Fields</h3>


<dl>
<dt><code>Protein_X_meas_Y</code></dt><dd><p>Numerical. The expression level for protein X at measurement Y. X has values between 1 and 68, Y has values
between 1 and 12 or 15, according to the number of measurements.</p>
</dd>
<dt><code>Genotype</code></dt><dd><p>Categorical. Two values: &quot;Control&quot; and &quot;Ts65Dn&quot; (trisomic mouse).</p>
</dd>
<dt><code>Treatment</code></dt><dd><p>Categorical. Two values: &quot;Memantine&quot; and &quot;Saline&quot;.</p>
</dd>
<dt><code>Behaviour</code></dt><dd><p>Categorical. Two values: &quot;C/S&quot; (stimulated to learn) and &quot;S/C&quot; (not stimulated to learn).</p>
</dd>
<dt><code>Class.mouse</code></dt><dd><p>Categorical. This variables creates eight classes of mice, based on crossing the categories of <code>Genotype</code>,
<code>Behaviour</code> and <code>Treatment</code>.</p>
</dd>
<dt><code>MouseID</code></dt><dd><p>Factor. The key variable identifying each mouse in the sample.</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression">https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression</a>
</p>


<h3>References</h3>

<p>C. Higuera, K.J. Gardiner, and K.J. Cios (2015) Self-organizing feature maps identify proteins critical 
to learning in a mouse model of Down syndrome. PLoS ONE 10(6): e0129126.
</p>

<hr>
<h2 id='groupsoft'>Group soft-thresholding operator</h2><span id='topic+groupsoft'></span>

<h3>Description</h3>

<p>This function implements the group soft-thresholding operator for a vector which elements are priorly split into groups. For the complete mathematical 
formulation, the reader may refer to the references below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>groupsoft(b, lambda, index = 1:length(b), sizegroup = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="groupsoft_+3A_b">b</code></td>
<td>
<p>a numerical vector.</p>
</td></tr>
<tr><td><code id="groupsoft_+3A_lambda">lambda</code></td>
<td>
<p>a positive scalar containing the regularization parameter.</p>
</td></tr>
<tr><td><code id="groupsoft_+3A_index">index</code></td>
<td>
<p>a vector of integers of size <code>length(b)</code> containing the group membership for
each element of <code>b</code>. By default, <code>index=1:length(b)</code> i.e. each element of <code>b</code> constitutes its own group.</p>
</td></tr>
<tr><td><code id="groupsoft_+3A_sizegroup">sizegroup</code></td>
<td>
<p>a boolean. if TRUE, the size of 
the groups is taken into account in the thresholding operation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the sparse vector after the group soft-thresholding operation.
</p>


<h3>References</h3>

<p>M. Chavent, J. Lacaille, A. Mourer and M. Olteanu (2020). 
Sparse k-means for mixed data via group-sparse clustering, to appear in ESANN proceedings.
</p>
<p>M. Yuan and Y. Lin (2006). Model selection and estimation in regression with grouped variables. J. R. Statist. Soc. B, Vol. 68(1), p. 49-67.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+groupsparsewkm">groupsparsewkm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>b &lt;- c(0.1, 0.2, 0.8, 0.1, 0.1, 0.3)
index &lt;- c(1,1,2,2,3,3)
lambda &lt;- 0.1
groupsoft(b=b, lambda=lambda, index=index, sizegroup=TRUE)
lambda &lt;- 0.3
groupsoft(b=b, lambda=lambda, index=index, sizegroup=TRUE)
lambda &lt;- 0.8
groupsoft(b=b, lambda=lambda, index=index, sizegroup=TRUE)

</code></pre>

<hr>
<h2 id='groupsparsewkm'>Group-sparse weighted k-means</h2><span id='topic+groupsparsewkm'></span>

<h3>Description</h3>

<p>This function performs group-sparse weighted k-means on a set 
of observations described by numerical variables organized in groups. 
It generalizes the sparse clustering algorithm introduced by 
Witten &amp; Tibshirani (2010) to groups. While the algorithm clusters the observations, the groups of variables are supposed priorly known.
The algorithm computes a series of weights associated to the groups of variables, the weights
indicating the importance of each group in the clustering process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>groupsparsewkm(
  X,
  centers,
  lambda = NULL,
  nlambda = 20,
  index = 1:ncol(X),
  sizegroup = TRUE,
  nstart = 10,
  itermaxw = 20,
  itermaxkm = 10,
  scaling = TRUE,
  verbose = 1,
  epsilonw = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="groupsparsewkm_+3A_x">X</code></td>
<td>
<p>a numerical matrix or a dataframe of dimension <code>n</code> (observations) by <code>p</code> 
(variables).</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_centers">centers</code></td>
<td>
<p>an integer representing the number of clusters.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_lambda">lambda</code></td>
<td>
<p>a vector of numerical values (or a single value) providing 
a grid of values for the regularization parameter. If NULL (by default), the function computes its 
own lambda sequence of length <code>nlambda</code> (see details).</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_nlambda">nlambda</code></td>
<td>
<p>an integer indicating the number of values for the regularization parameter. 
By default, <code>nlambda=20</code>.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_index">index</code></td>
<td>
<p>a vector of integers of size <code>p</code> providing the group membership
for each variable. By default, <code>index=1:ncol(X)</code> i.e. no groups or groups of size 1.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_sizegroup">sizegroup</code></td>
<td>
<p>a boolean. If TRUE, the group sizes (number of variables in each group) are taken into account in the penalty term (see details).
By default, <code>sizegroup=TRUE</code>.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_nstart">nstart</code></td>
<td>
<p>an integer representing the number of random starts in the k-means algorithm.
By default, <code>nstart=10</code>.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_itermaxw">itermaxw</code></td>
<td>
<p>an integer indicating the maximum number of iterations for the inside 
loop over the weights <code>w</code>. By default, <code>itermaxw=20</code>.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_itermaxkm">itermaxkm</code></td>
<td>
<p>an integer representing the maximum number of iterations in the k-means 
algorithm. By default, <code>itermaxkm=10</code>.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_scaling">scaling</code></td>
<td>
<p>a boolean. If TRUE, variables are scaled to zero mean and unit variance. By default, <code>scaling=TRUE</code>.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_verbose">verbose</code></td>
<td>
<p>an integer value. If <code>verbose=0</code>, the function stays silent, if <code>verbose=1</code> (default option), it  prints
whether the stopping criterion over the weights <code>w</code> is satisfied.</p>
</td></tr>
<tr><td><code id="groupsparsewkm_+3A_epsilonw">epsilonw</code></td>
<td>
<p>a positive numerical value. It provides the precision of the stopping criterion over <code>w</code>. By default, <code>epsilonw =1e-04</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Group-sparse weighted k-means performs clustering on data described by numerical variables priorly partitionned into groups, and automatically selects the most discriminant groups by 
setting to zero the weights of the non-discriminant ones. 
</p>
<p>The algorithm is based on the optimization of a cost function which is the weighted between-class variance penalized by a group L1-norm. The groups must be priorly defined through 
expert knowledge. If there is no group structure (each group contains one variable only), the algorithm reduces to the sparse weighted k-means introduced in Witten &amp; Tibshirani (2010).
The penalty term may take into account the size of the groups by setting <code>sizegroup=TRUE</code> (see Chavent et al. (2020) for further details on the mathematical expression of the
optimized criterion). The importance of the penalty term may be adjusted through the regularization parameter <code>lambda</code>. If <code>lambda=0</code>, there is no penalty applied to the 
weighted between-class variance. The larger <code>lambda</code>, the larger the penalty term and the number of groups with null weights. 
</p>
<p>The output of the algorithm is three-folded: one gets a partitioning of the data, a vector of weights associated to each group, and a vector of weights associated to each
variable. Weights equal to zero imply that the associated variables or the associated groups do not participate in the clustering process. 
</p>
<p>Since it is difficult to chose the regularization parameter <code>lambda</code> without prior knowledge, the function builds automatically a grid of parameters and finds the partitioning
and the vectors of weights associated to each value in the grid. 
</p>
<p>Note that when the regularization parameter is equal to 0 (no penalty applied), the output is different from that of a regular k-means, since the optimized criterion is a weighted 
between-class variance and not the between-class variance only.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>lambda</code></td>
<td>
<p>a numerical vector containing the regularization parameters (a grid of values).</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>a <code>p</code> by <code>length(lambda)</code> numerical matrix. It contains the weights associated to each variable.</p>
</td></tr>
<tr><td><code>Wg</code></td>
<td>
<p>a <code>L</code> by <code>length(lambda)</code> numerical matrix, where <code>L</code> is the number of groups. It contains the weights associated to each group.</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>
<p>a <code>n</code> by <code>length(lambda)</code> integer matrix. It contains the cluster memberships, for each value of the regularization parameter.</p>
</td></tr>
<tr><td><code>sel.feat</code></td>
<td>
<p>a numerical vector of the same length as <code>lambda</code>, giving the number of selected variables for each value of the regularization parameter.</p>
</td></tr>
<tr><td><code>sel.groups</code></td>
<td>
<p>a numerical vector of the same length as <code>lambda</code>, giving the number of selected groups of variables for each value of the regularization parameter.</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>a matrix of size <code>n</code> by <code>p</code> containing the scaled data if <code>scaling=TRUE</code>, and a copy of <code>X</code> otherwise.</p>
</td></tr>
<tr><td><code>bss.per.feature</code></td>
<td>
<p>a matrix of size <code>p</code> by <code>length(lambda)</code>. It contains the between-class variance computed for each variable.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten, D. M., &amp; Tibshirani, R. (2010). A framework for feature 
selection in clustering. Journal of the American Statistical Association, 
105(490), p.713-726.
</p>
<p>Chavent, M. &amp; Lacaille, J. &amp; Mourer, A. &amp; Olteanu, M. (2020). 
Sparse k-means for mixed data via group-sparse clustering, ESANN proceedings.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.spwkm">plot.spwkm</a></code>, <code><a href="#topic+info_clust">info_clust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# define two groups of variables: 
# "Sepal.Length" and "Sepal.Width" in group 1
# "Petal.Length" and "Petal.Width"  in group 2
index &lt;- c(1, 2, 1, 2)
# group-sparse k-means

out &lt;- groupsparsewkm(X = iris[,-5], centers = 3, index = index)
# grid of regularization parameters
out$lambda
k &lt;- 10
# weights of the variables for the k-th regularization parameter
out$W[,k]
# weights of the groups for the k-th regularization parameter
out$Wg[,k]
# partition obtained with for the k-th regularization parameter
out$cluster[,k]
# between-class variance on each variable
out$bss.per.feature[,k]
# between-class variance 
sum(out$bss.per.feature[,k])/length(index)

# one variable per group (equivalent to sparse k-means)
index &lt;- 1:4 # default option in groupsparsewkm
# sparse k-means
out &lt;- groupsparsewkm(X = iris[,-5], centers = 3, index = index)
# or
out &lt;- groupsparsewkm(X = iris[,-5], centers = 3)
# group weights and variable weights are identical in this case
out$Wg 
out$W

</code></pre>

<hr>
<h2 id='HDdata'>Statlog (Heart) Data Set</h2><span id='topic+HDdata'></span>

<h3>Description</h3>

<p>The data consists of 270 patients described by six numerical 
variables and eight categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HDdata
</code></pre>


<h3>Format</h3>

<p>A data frame of 270 rows (patients) and 14 columns (variables):
</p>


<h3>Fields</h3>


<dl>
<dt><code>age</code></dt><dd><p>Numerical. Age in years.</p>
</dd>
<dt><code>resting_blood_pressure(trestbps)</code></dt><dd><p>Numerical. Resting blood pressure (in mmHg) at hospital admittance.</p>
</dd>
<dt><code>maximum_heart_rate_achieved(maxhr).</code></dt><dd><p>Numerical. Maximum heart rate achieved during exercise.</p>
</dd>
<dt><code>oldpeak</code></dt><dd><p>Numerical. ST depression induced by exercise relative to rest.</p>
</dd>
<dt><code>number_of_major_vessels_colored_by_fluoroscopy(numv)</code></dt><dd><p>Numerical. Number of major vessels (0-3) colored by fluoroscopy.</p>
</dd>
<dt><code>sex</code></dt><dd><p>Categorical. Sex (1 = male; 0 = female).</p>
</dd>
<dt><code>chest_pain_type(cp)</code></dt><dd><p>Categorical. 1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic.</p>
</dd>
<dt><code>fasting_blood_sugar_&gt;_120mg/dl(fbs)</code></dt><dd><p>Categorical. 1 = true; 0 = false.</p>
</dd>
<dt><code>resting_electrocardiographic_results(restecg)</code></dt><dd><p>Categorical. 0: normal, 1: ST-T wave abnormality (T wave inversions and/or ST
elevation or depression &gt;0.05mV), 2: showing probable or definite left ventricular hypertrophy by Estes' criteria.</p>
</dd>
<dt><code>exercice_induced_angina(exang)</code></dt><dd><p>Categorical. 1 = yes; 0 = no.</p>
</dd>
<dt><code>the_slope_of_the_peak_exercice_ST_segment(slope)</code></dt><dd><p>Categorical. 1: upsloping, 2: flat, 3: downsloping.</p>
</dd>
<dt><code>thalassemia(thal)</code></dt><dd><p>Categorical. 3: normal blood flow, 6: fixed defect, 7: reversible defect.</p>
</dd>
<dt><code>presence_or_absence_of_heart_disease(HD)</code></dt><dd><p>Categorical. Absence or presence of a heart disease.</p>
</dd>
</dl>


<h3>Source</h3>

<p><a href="http://archive.ics.uci.edu/ml/datasets/statlog+(heart)">http://archive.ics.uci.edu/ml/datasets/statlog+(heart)</a>
</p>


<h3>References</h3>

<p>A. Frank and A. Asuncion. UCI machine learning repository, statlog (heart) data set, 2010.
</p>

<hr>
<h2 id='info_clust'>Description of a set of partitions</h2><span id='topic+info_clust'></span>

<h3>Description</h3>

<p>This function computes descriptive statistics of the clustering produced with 
group-sparse weighted k-means on numerical data, or with sparse weighted k-means on mixed data.
It displays the average of the numerical variables per cluster, and the relative frequencies 
of the levels in the categorical variables per cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>info_clust(out, which.lambda, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="info_clust_+3A_out">out</code></td>
<td>
<p>an object of class <code>spwkm</code>.</p>
</td></tr>
<tr><td><code id="info_clust_+3A_which.lambda">which.lambda</code></td>
<td>
<p>an integer or a vector of integers
selecting the clusterings for which summaries are computed.</p>
</td></tr>
<tr><td><code id="info_clust_+3A_x">X</code></td>
<td>
<p>a matrix or a data frame. The initial data set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values in <code>which.lambda</code> must be integers between 1 and <code>length(out$lambda)</code>. One may
thus select the clusterings corresponding to specific regularization parameters, or the whole set
of clusterings
obtained for the whole grid of <code>out$lambda</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>mean.by.clust</code></td>
<td>
<p>a list of numerical matrices. Each matrix contains the mean values
of the numerical variables computed per cluster, for a given value of the regularization parameter.</p>
</td></tr>
<tr><td><code>freq.by.clust</code></td>
<td>
<p>a list of numerical matrices. Each matrix contains the relative 
frequencies of each level associated to categorical variables, 
computed per cluster and for a given value of the regularization parameter.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>a scalar or a numerical vector. The selected values of the regularization
parameter. </p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+groupsparsewkm">groupsparsewkm</a></code>, <code><a href="#topic+sparsewkm">sparsewkm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HDdata)
out &lt;- sparsewkm(X = HDdata[,-14], centers = 2)
info_clust(out, which.lambda=c(1,10,20), X = HDdata[,-14])
</code></pre>

<hr>
<h2 id='plot.spwkm'>Plots from a &quot;spwkm&quot; object</h2><span id='topic+plot.spwkm'></span>

<h3>Description</h3>

<p>Produces several graphics to help interpreting a <code>spwkm</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'spwkm'
plot(
  x,
  what = "weights.features",
  Which = NULL,
  xtitle = NULL,
  ytitle = NULL,
  title = NULL,
  showlegend = NULL,
  legendtitle = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.spwkm_+3A_x">x</code></td>
<td>
<p>An object of class <code>spwkm</code>.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_what">what</code></td>
<td>
<p>A character string indicating which element of <code>x</code> to be plotted. See section
&quot;Details&quot; below for further information.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_which">Which</code></td>
<td>
<p>A numerical vector indexing the groups or the variables to be displayed. See section
&quot;Details&quot; below for further information.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_xtitle">xtitle</code></td>
<td>
<p>The title of the x-axis.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_ytitle">ytitle</code></td>
<td>
<p>The title of the y-axis.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_title">title</code></td>
<td>
<p>The title of the graphic.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_showlegend">showlegend</code></td>
<td>
<p>A boolean. If <code>showlegend=NULL</code> (default value), the legend is displayed.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_legendtitle">legendtitle</code></td>
<td>
<p>The title of the legend.</p>
</td></tr>
<tr><td><code id="plot.spwkm_+3A_...">...</code></td>
<td>
<p>Further arguments to the <code>plot</code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> function allows to represent the regularization paths for a grid of values of <code>lambda</code>, as well as several quality criteria associated to the 
clustering. 
</p>
<p>For both <code>groupsparsewkm</code> and <code>sparsewkm</code> functions, the following options are available:
</p>
<p>If <code>what=weights.features</code>, the regularization paths for the weights associated to the variables are displayed. 
</p>
<p>If <code>what=sel.features</code>, the graph represents the number of selected variables for each value of the regularization parameter <code>lambda</code>. In the case of 
sparse weighted k-means for mixed data, categorical variables are represented with dotted lines so that one easily identifies them. 
</p>
<p>If <code>what=expl.var</code>, the explained variance (computed as the contribution of the between-class variance to the global variance) is displayed. This criterion is 
computed for all variables in the data set, without taking into account the weights of the group or of the variables. 
</p>
<p>If <code>what=w.expl.var</code>, the explained weighted variance is computed. The difference with the criterion above is that the weights of the variables are
taken into account in the computation. This leads to a criterion which, for large regularization parameters <code>lambda</code>, may be computed on one variable only, if 
its weight becomes equal to 1 and all the others are discarded. 
</p>
<p>If <code>what=pen.crit</code>, the graph displays the evolution of the penalized criterion, maximized by the algorithm. This criterion writes as 
the between-class weighted sum-of-squares, penalized by a group L1-norm. For more details on the mathematical expressions, one may refer to Chavel et al. (2020). 
</p>
<p>For the outcome of the <code>groupsparsewkm</code> function trained on numerical data only, two more options are available:
</p>
<p>If <code>what=weights.groups</code>, the regularization paths for the weights associated to the groups of variables are displayed.
</p>
<p>If <code>what=sel.groups</code>, the graph represents the number of selected groups for each value of the regularization parameter <code>lambda</code>.
</p>
<p>For the outcome of the <code>sparsewkm</code> function trained on mixed data, two more options are also available:
</p>
<p>If <code>what=weights.levels</code>, the regularization paths for the weights associated to the levels of the categorical variables are displayed. 
</p>
<p>If <code>what=sel.levels</code>, the graph represents the number of selected levels associated to the categorical variables plus the number of selected 
numerical variables, for each value of the regularization parameter <code>lambda</code>.
</p>
<p>If the number of groups in <code>groupsparsewkm</code> or if the number of features in <code>sparsewkm</code> are too large to have easily interpretable graphics, one may select 
some groups or some variables using the argument <code>Which</code>. Note that when training <code>sparsewkm</code> on mixed data, the initial order of the variables is changed:
after the processing step, numerical variables are displayed first, and categorical second. The indexing provided in <code>Which</code> should take this into account (see the
Examples section).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>p</code></td>
<td>
<p>an object of class <code>ggplot</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M., Chavent, J. Lacaille, A. Mourer, and M. Olteanu (2020). 
Sparse k-means for mixed data via group-sparse clustering. To appear in ESANN proceedings.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sparsewkm">sparsewkm</a></code>, <code><a href="#topic+groupsparsewkm">groupsparsewkm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sparse weighted k-means on mixed data

data(HDdata)
out &lt;- sparsewkm(X = HDdata[,-14], centers = 2)
plot(out, what = "weights.features")
plot(out, what = "weights.levels")
plot(out, what = "sel.features")
plot(out, what = "sel.levels")
plot(out, what = "expl.var")
plot(out, what = "w.expl.var")
plot(out, what = "pen.crit")
# plot the regularization paths for first three variables only 
plot(out, what = "weights.features", Which=1:3)
 
# group sparse weighted k-means on numerical data
data(iris)
index &lt;- c(1, 2, 1, 2)
out &lt;- groupsparsewkm(X = iris[,-5], centers = 3, index = index)
plot(out, what = "weights.groups")
plot(out, what = "weights.features")
plot(out, what = "sel.groups")
plot(out, what = "sel.features")
plot(out, what = "expl.var")
plot(out, what = "w.expl.var")
plot(out, what = "pen.crit")
# plot the regularization paths for the variables in the first group only
plot(out, what = "weights.features", Which=1)

</code></pre>

<hr>
<h2 id='recodmix'>Recoding mixed data</h2><span id='topic+recodmix'></span>

<h3>Description</h3>

<p>This function transforms and scales a dataset with numerical and/or categorical
variables. Numerical variables are scaled to zero mean and unit variance. Categorical variables
are first transformed into dummy variables according to their levels, and second centered and 
normalized with respect to the square roots of the relative frequencies of the levels. The complete 
procedure is described in Chavent et al. (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recodmix(X, renamelevel = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recodmix_+3A_x">X</code></td>
<td>
<p>a matrix or a dataframe with numerical and/or categorical variables. Categorical variables 
must be given as factors.</p>
</td></tr>
<tr><td><code id="recodmix_+3A_renamelevel">renamelevel</code></td>
<td>
<p>a boolean. If TRUE (default value), the levels of the categorical variables
are renamed as <code>'variable_name=level_name'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>a data frame or a matrix. The input data <code>X</code> with reordered columns 
(numerical first, categorical second).</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>a data frame. The transformed data matrix with scaled numerical variables
and scaled dummy variables coding for the levels.</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>a vector of integers. Contains an implicit partitioning of the transformed
variables: each scaled numerical variable represents a group, all scaled dummy variables 
summarizing the levels of a categorical variable represent a group. <code>index</code> allows to 
preserve the information on the initial structure of the data, particularly for categorical variables.</p>
</td></tr>
</table>


<h3>References</h3>

<p>M. Chavent, V. Kuentz-Simonet, A. Labenne and J. Saracco (2014).
Multivariate analysis of mixed data: the PCAmixdata R package, arXiv:1411.4911.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(HDdata)
out &lt;- recodmix(HDdata[,-14], renamelevel=TRUE)
# reordered data (numerical/categorical)
colnames(out$X)
# transformed and scaled data
colnames(out$Z)
# transformed variables partitioning and group membership
out$index
</code></pre>

<hr>
<h2 id='sparsewkm'>Sparse weighted k-means</h2><span id='topic+sparsewkm'></span>

<h3>Description</h3>

<p>This function performs sparse weighted k-means on a set 
of observations described by numerical and/or categorical variables.
It generalizes the sparse clustering algorithm introduced in
Witten &amp; Tibshirani (2010) to any type of data (numerical, categorical
or a mixture of both). The weights of the variables indicate their importance
in the clustering process and discriminant variables are thus selected by 
means of weights set to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparsewkm(
  X,
  centers,
  lambda = NULL,
  nlambda = 20,
  nstart = 10,
  itermaxw = 20,
  itermaxkm = 10,
  renamelevel = TRUE,
  verbose = 1,
  epsilonw = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparsewkm_+3A_x">X</code></td>
<td>
<p>a dataframe of dimension <code>n</code> (observations) by <code>p</code> (variables) with
numerical, categorical or mixed data.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_centers">centers</code></td>
<td>
<p>an integer representing the number of clusters.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_lambda">lambda</code></td>
<td>
<p>a vector of numerical values (or a single value) providing 
a grid of values for the regularization parameter. If NULL (by default), the function computes its 
own lambda sequence of length <code>nlambda</code> (see details).</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_nlambda">nlambda</code></td>
<td>
<p>an integer indicating the number of values for the regularization parameter. 
By default, <code>nlambda=20</code>.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_nstart">nstart</code></td>
<td>
<p>an integer representing the number of random starts in the k-means algorithm.
By default, <code>nstart=10</code>.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_itermaxw">itermaxw</code></td>
<td>
<p>an integer indicating the maximum number of iterations for the inside 
loop over the weights <code>w</code>. By default, <code>itermaxw=20</code>.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_itermaxkm">itermaxkm</code></td>
<td>
<p>an integer representing the maximum number of iterations in the k-means 
algorithm. By default, <code>itermaxkm=10</code>.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_renamelevel">renamelevel</code></td>
<td>
<p>a boolean. If TRUE (default option), each level of a categorical variable
is renamed as <code>'variable_name=level_name'</code>.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_verbose">verbose</code></td>
<td>
<p>an integer value. If <code>verbose=0</code>, the function stays silent, if <code>verbose=1</code> (default option), it  prints
whether the stopping criterion over the weights <code>w</code> is satisfied.</p>
</td></tr>
<tr><td><code id="sparsewkm_+3A_epsilonw">epsilonw</code></td>
<td>
<p>a positive numerical value. It provides the precision of the stopping 
criterion over <code>w</code>. By default, <code>epsilonw =1e-04</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sparse weighted k-means performs clustering on mixed data (numerical and/or categorical), and automatically
selects the most discriminant variables by setting to zero the weights of the non-discriminant ones. 
</p>
<p>The mixted data is first preprocessed: numerical variables are scaled to zero mean and unit variance;
categorical variables are transformed into dummy variables, and scaled &ndash; in mean and variance &ndash; with
respect to the relative frequency of each level. 
</p>
<p>The algorithm is based on the optimization of a cost function which is the weighted between-class variance penalized
by a group L1-norm. The groups are implicitely defined: each numerical variable constitutes its own group, the levels 
associated to one categorical variable constitute a group. The importance of the penalty term may be adjusted through
the regularization parameter <code>lambda</code>.
</p>
<p>The output of the algorithm is two-folded: one gets a partitioning of the data set and a vector of weights associated
to each variable. Some of the weights are equal to 0, meaning that the associated variables do not participate in the
clustering process. If <code>lambda</code> is equal to zero, there is no penalty applied to the weighted between-class variance in the 
optimization procedure. The larger the value of <code>lambda</code>, the larger the penalty term and the number of variables with
null weights. Furthemore, the weights associated to each level of a categorical variable are also computed.
</p>
<p>Since it is difficult to choose the regularization parameter <code>lambda</code> without prior knowledge,
the function builds automatically a grid of parameters and finds a partition and vector of weights for each 
value of the grid.
</p>
<p>Note also that the columns of the data frame <code>X</code> must be of class factor for 
categorical variables.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>lambda</code></td>
<td>
<p>a numerical vector containing the regularization parameters (a grid of values).</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>a <code>p</code> by <code>length(lambda)</code> matrix. It contains the weights associated to each variable.</p>
</td></tr>
<tr><td><code>Wm</code></td>
<td>
<p>a <code>q</code> by <code>length(lambda)</code> matrix, where <code>q</code> is the 
number of numerical variables plus the number of levels of the categorical 
variables. It contains the weights associated to the numerical variables and to the levels of the categorical
variables.</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>
<p>a <code>n</code> by <code>length(lambda)</code> integer matrix. It contains the 
cluster memberships, for each value of the regularization parameter.</p>
</td></tr>
<tr><td><code>sel.init.feat</code></td>
<td>
<p>a numerical vector of the same length as <code>lambda</code>, giving the 
number of selected variables for each value of the regularization parameter.</p>
</td></tr>
<tr><td><code>sel.trans.feat</code></td>
<td>
<p>a numerical vector of the same length as <code>lambda</code>, giving the 
number of selected numerical variables and levels of categorical variables.</p>
</td></tr>
<tr><td><code>X.transformed</code></td>
<td>
<p>a matrix of size <code>n</code> by <code>q</code>, containing the transformed data: numerical variables scaled to 
zero mean and unit variables, categorical variables transformed into dummy variables, scaled (in means and variance)
with respect to the relative frequency of the levels.</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>a numerical vector indexing the variables and allowing to group together the levels of a
categorical variable.</p>
</td></tr>
<tr><td><code>bss.per.feature</code></td>
<td>
<p>a matrix of size <code>q</code> by <code>length(lambda)</code>. 
It contains the between-class variance computed on the <code>q</code> transformed variables (numerical variables and 
levels of categorical variables).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten, D. M., &amp; Tibshirani, R. (2010). A framework for feature 
selection in clustering. Journal of the American Statistical Association, 
105(490), 713-726.
</p>
<p>Chavent, M. &amp; Lacaille, J. &amp; Mourer, A. &amp; Olteanu, M. (2020). 
Sparse k-means for mixed data via group-sparse clustering, ESANN proceedings.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.spwkm">plot.spwkm</a></code>, <code><a href="#topic+info_clust">info_clust</a></code>, 
<code><a href="#topic+groupsparsewkm">groupsparsewkm</a></code>, <code><a href="#topic+recodmix">recodmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HDdata)

out &lt;- sparsewkm(X = HDdata[,-14], centers = 2)
# grid of automatically selected regularization parameters
out$lambda
k &lt;- 10
# weights of the variables for the k-th regularization parameter
out$W[,k]
# weights of the numerical variables and of the levels 
out$Wm[,k]
# partitioning obtained for the k-th regularization parameter
out$cluster[,k]
# number of selected variables
out$sel.init.feat
# between-class variance on each variable
out$bss.per.feature[,k]
# between-class variance
sum(out$bss.per.feature[,k])

</code></pre>

<hr>
<h2 id='weightedss'>Weighted sum-of-squares criteria</h2><span id='topic+weightedss'></span>

<h3>Description</h3>

<p>This function computes various weighted sum-of-squares criteria for a given
partition of a dataset described by numerical features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weightedss(X, cl, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weightedss_+3A_x">X</code></td>
<td>
<p>a matrice or a dataframe of size <code>n</code> (observations) by <code>p</code> (variables) 
with numerical features only.</p>
</td></tr>
<tr><td><code id="weightedss_+3A_cl">cl</code></td>
<td>
<p>a vector of integers of length <code>n</code>. It contains the cluster membership of the data.</p>
</td></tr>
<tr><td><code id="weightedss_+3A_w">w</code></td>
<td>
<p>a numerical vector of length <code>p</code>. It contains the weights to be applied to the features. 
By default, <code>w=NULL</code>, which amounts to setting each weight equal to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>bss.per.feature</code></td>
<td>
<p>a numerical vector of length <code>p</code> containing the weighted 
between sum-of-squares per feature.</p>
</td></tr>
<tr><td><code>wss.per.feature</code></td>
<td>
<p>a numerical vector of length <code>p</code> containing the weighted 
within sum-of-squares per feature.</p>
</td></tr>
<tr><td><code>bss.per.cluster</code></td>
<td>
<p>a numerical vector of length <code>K</code> (<code>K</code> is the number of 
clusters) containing the weighted between sum-of-squares per cluster.</p>
</td></tr>
<tr><td><code>wss.per.cluster</code></td>
<td>
<p>a numerical vector of length <code>K</code> 
containing the weighted within sum-of-squares per cluster.</p>
</td></tr>
<tr><td><code>bss</code></td>
<td>
<p>a scalar representing the weighted between sum-of-squares of the partition.
It may be computed as the sum over <code>bss.per.feature</code> or <code>bss.per.cluster</code>.</p>
</td></tr>
<tr><td><code>wss</code></td>
<td>
<p>a scalar representing the weighted within sum-of-squares of the partition.
It may be computed as the sum over <code>wss.per.feature</code> or <code>wss.per.cluster</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
out &lt;- weightedss(X = iris[,1:4], cl = as.numeric(iris$Species))
out$bss.per.feature
out$bss.per.cluster
out$bss

w &lt;- c(0.3,0.3,0.2,0.2)
out &lt;- weightedss(X = iris[,1:4], cl = as.numeric(iris$Species), w=w)
out$bss.per.feature
out$bss.per.cluster
out$bss
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
