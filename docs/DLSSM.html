<!DOCTYPE html><html lang="en"><head><title>Help for package DLSSM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DLSSM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Batched'><p>Combine data into Batched data</p></a></li>
<li><a href='#car.insur'><p>Dataset contains information of full comprehensive Australian automobile insurance policies between years 2004 and 2005</p>
A dataset containing the claim and three attributes of 67,856 policies</a></li>
<li><a href='#DLSSM'><p>Combine model training and validation in a integrated function</p></a></li>
<li><a href='#DLSSM.init'><p>Initial model fitting</p></a></li>
<li><a href='#DLSSM.plot'><p>Plot coefficients</p></a></li>
<li><a href='#DLSSM.valid'><p>Dynamical prediction on validation dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Dynamic Logistic State Space Prediction Model</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jiakun Jiang &lt;jiakunj@bnu.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the dynamic logistic state space model for binary outcome data proposed by Jiang et al. (2021) &lt;<a href="https://doi.org/10.1111%2Fbiom.13593">doi:10.1111/biom.13593</a>&gt;.
 It provides a computationally efficient way to update the prediction whenever new data becomes available.
 It allows for both time-varying and time-invariant coefficients, and use cubic smoothing splines to model varying coefficients.
 The smoothing parameters are objectively chosen by maximum likelihood. The model is updated using batch data accumulated at pre-specified time intervals.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.0</td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.10)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0), withr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-17 09:09:33 UTC; jiakun</td>
</tr>
<tr>
<td>Author:</td>
<td>Jiakun Jiang [aut, cre],
  Wei Yang [aut],
  Wensheng Guo [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-17 12:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Batched'>Combine data into Batched data</h2><span id='topic+Batched'></span>

<h3>Description</h3>

<p>The time domain of observation will first be standardized into [0,1]. Then [0,1] will be divided into S equally spaced intervals as described in Jiang et al.(2021, Biometrics).
Then those intervals slice the dataset to S batches of data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Batched(formula, data, time, S)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Batched_+3A_formula">formula</code></td>
<td>
<p>An object of class &quot;formula&quot; (or one that can be coerced to that class): a symbolic description of response and covariates in the model.</p>
</td></tr>
<tr><td><code id="Batched_+3A_data">data</code></td>
<td>
<p>Dataset matrix containing the observations (one rows is a sample).</p>
</td></tr>
<tr><td><code id="Batched_+3A_time">time</code></td>
<td>
<p>The time variable in the dataset. The varying coefficient functions are assumed to be smooth functions of this variable.</p>
</td></tr>
<tr><td><code id="Batched_+3A_s">S</code></td>
<td>
<p>Number of batches</p>
</td></tr>
</table>


<h3>Value</h3>


<table>
<tr>
 <td style="text-align: left;">
   <code>batched</code> </td><td style="text-align: left;"> List of batched data, the element of list is matrix with each row representing a sample </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>gap.len</code> </td><td style="text-align: left;"> interval length 1/S  </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Jiakun Jiang, Wei Yang, Wensheng Guo
</p>

<hr>
<h2 id='car.insur'>Dataset contains information of full comprehensive Australian automobile insurance policies between years 2004 and 2005
A dataset containing the claim and three attributes of 67,856 policies</h2><span id='topic+car.insur'></span>

<h3>Description</h3>

<p>Dataset contains information of full comprehensive Australian automobile insurance policies between years 2004 and 2005
A dataset containing the claim and three attributes of 67,856 policies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>car.insur
</code></pre>


<h3>Format</h3>

<p>A data frame with 67856 rows and 4 columns
</p>

<dl>
<dt>y</dt><dd><p>Binary vaiable with 0 denote a policy with no claim, and 1 denote a claim policy.</p>
</dd>
<dt>gender</dt><dd><p>gender of deriver</p>
</dd>
<dt>age</dt><dd><p>age of deriver</p>
</dd>
<dt>exposure</dt><dd><p>period from the date of insured to the investigation, with a maximum of one year</p>
</dd>
</dl>



<h3>References</h3>

<p>De Jong P et al. (2008). “Generalized linear models for insurance data.” Cambridge Books.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(car.insur)
</code></pre>

<hr>
<h2 id='DLSSM'>Combine model training and validation in a integrated function</h2><span id='topic+DLSSM'></span>

<h3>Description</h3>

<p>This combine model training and validation in a integrated automatic function DLSSM().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DLSSM(data.batched, S0, vary.effects, autotune = TRUE, Lambda = NULL, K)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DLSSM_+3A_data.batched">data.batched</code></td>
<td>
<p>A object generated by function Data.batched()</p>
</td></tr>
<tr><td><code id="DLSSM_+3A_s0">S0</code></td>
<td>
<p>Number of batches of data to be used as training dataset</p>
</td></tr>
<tr><td><code id="DLSSM_+3A_vary.effects">vary.effects</code></td>
<td>
<p>The names of variables in the dataset assumed to have a time-varying regression effect on the outcome.</p>
</td></tr>
<tr><td><code id="DLSSM_+3A_autotune">autotune</code></td>
<td>
<p>T/F indicates whether or not the automatic tuning procedure desribed in Jiakun et al. (2021) should be applied.  Default is true.</p>
</td></tr>
<tr><td><code id="DLSSM_+3A_lambda">Lambda</code></td>
<td>
<p>Specify smoothing parameters if autotune=F</p>
</td></tr>
<tr><td><code id="DLSSM_+3A_k">K</code></td>
<td>
<p>Number of steps for ahead prediction</p>
</td></tr>
</table>


<h3>Value</h3>


<table>
<tr>
 <td style="text-align: left;">
   <code>Lambda:</code> </td><td style="text-align: left;"> smoothing parameters </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>Smooth:</code> </td><td style="text-align: left;"> smoothed state vector </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>Smooth.var:</code> </td><td style="text-align: left;"> covariance of smoothed state vector in Smooth.  </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Jiakun Jiang, Wei Yang and Wensheng Guo
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
set.seed(321)
n=8000
beta0=function(t)   0.1*t-1
beta1=function(t)  cos(2*pi*t)
beta2=function(t)  sin(2*pi*t)
alph1=alph2=1
x=matrix(runif(n*4,min=-4,max=4),nrow=n,ncol=4)
t=sort(runif(n))
coef=cbind(beta0(t),beta1(t),beta2(t),rep(alph1,n),rep(alph2,n))
covar=cbind(rep(1,n),x)
linear=apply(coef*covar,1,sum)
prob=exp(linear)/(1+exp(linear))
y=as.numeric(runif(n)&lt;prob)
sim.data=cbind(y,x,t)
colnames(sim.data)=c("y","x1","x2","x3","x4","t")
formula = y~x1+x2+x3+x4
# Divide the time domain [0,1] into S=100 equally spaced intervals
S=100
S0=75
data.batched=Batched(formula, data=sim.data, time="t", S)

# Take first S0=75 batches as training data, remaining S-S0=25 batches of data as validation data.
 fit1=DLSSM(data.batched, S0, vary.effects=c("x1","x2"), autotune=TRUE, Lambda=NULL, K=1)
 DLSSM.plot(fit1)
 fit2=DLSSM(data.batched, S0, vary.effects=c("x1","x2"), autotune=TRUE, Lambda=NULL, K=2)
 DLSSM.plot(fit2)
 
</code></pre>

<hr>
<h2 id='DLSSM.init'>Initial model fitting</h2><span id='topic+DLSSM.init'></span>

<h3>Description</h3>

<p>This function is for tuning smoothing parameters using training data. The likelihood was calculated by Kalman Filter and maximized to estimate the smoothing parameters.
For the given smoothing parameters, the model coefficients can
be efficiently estimated using a Kalman filtering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DLSSM.init(data.batched, S0, vary.effects, autotune = TRUE, Lambda = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DLSSM.init_+3A_data.batched">data.batched</code></td>
<td>
<p>A object generated by function Data.batched()</p>
</td></tr>
<tr><td><code id="DLSSM.init_+3A_s0">S0</code></td>
<td>
<p>Number of batches of data to be used as training dataset</p>
</td></tr>
<tr><td><code id="DLSSM.init_+3A_vary.effects">vary.effects</code></td>
<td>
<p>The names of variables in the dataset assumed to have a time-varying regression effect on the outcome.</p>
</td></tr>
<tr><td><code id="DLSSM.init_+3A_autotune">autotune</code></td>
<td>
<p>T/F indicates whether or not the automatic tuning procedure described in Jiang et al. (2021) should be applied.  Default is true.</p>
</td></tr>
<tr><td><code id="DLSSM.init_+3A_lambda">Lambda</code></td>
<td>
<p>Specify smoothing parameters if autotune=F</p>
</td></tr>
</table>


<h3>Value</h3>


<table>
<tr>
 <td style="text-align: left;">
   <code>Lambda:</code> </td><td style="text-align: left;"> smoothing parameters </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>Smooth:</code> </td><td style="text-align: left;"> smoothed state vector </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>Smooth.var:</code> </td><td style="text-align: left;"> covariance of smoothed state vector in Smooth.  </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Jiakun Jiang, Wei Yang and Wensheng Guo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(321)
n=8000
beta0=function(t)   0.1*t-1
beta1=function(t)  cos(2*pi*t)
beta2=function(t)  sin(2*pi*t)
alph1=alph2=1
x=matrix(runif(n*4,min=-4,max=4),nrow=n,ncol=4)
t=sort(runif(n))
coef=cbind(beta0(t),beta1(t),beta2(t),rep(alph1,n),rep(alph2,n))
covar=cbind(rep(1,n),x)
linear=apply(coef*covar,1,sum)
prob=exp(linear)/(1+exp(linear))
y=as.numeric(runif(n)&lt;prob)
sim.data=cbind(y,x,t)
colnames(sim.data)=c("y","x1","x2","x3","x4","t")
formula = y~x1+x2+x3+x4
# Divide the time domain [0,1] into S=100 equally spaced intervals
S=100
S0=75
data.batched=Batched(formula, data=sim.data, time="t", S)

# using first 75 batches as training dataset to tune smoothing parameters
fit0=DLSSM.init(data.batched, S0, vary.effects=c("x1","x2"))
fit0$Lambda
DLSSM.plot(fit0)

</code></pre>

<hr>
<h2 id='DLSSM.plot'>Plot coefficients</h2><span id='topic+DLSSM.plot'></span>

<h3>Description</h3>

<p>Plot smoothed coefficients in the training part and predicted coefficients in validation part, the two parts are divided by vertical dash line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DLSSM.plot(fit)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DLSSM.plot_+3A_fit">fit</code></td>
<td>
<p>fitted object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If argument &quot;fit&quot; is an initial fitted model then only smoothed coefficients part are plotted.
</p>


<h3>Value</h3>

<p>Figures
</p>


<h3>Author(s)</h3>

<p>Jiakun Jiang, Wei Yang and Wensheng Guo
</p>

<hr>
<h2 id='DLSSM.valid'>Dynamical prediction on validation dataset</h2><span id='topic+DLSSM.valid'></span>

<h3>Description</h3>

<p>After we have fitted  initial model, we can do validation. It is iteratively doing K-steps ahead prediction and model updating (filtering)
when a new batch of data becomes available.
The validation include K-steps ahead prediction of state vector and probabilities on validation interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DLSSM.valid(fit0, data.batched, K)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DLSSM.valid_+3A_fit0">fit0</code></td>
<td>
<p>Initial fitted model</p>
</td></tr>
<tr><td><code id="DLSSM.valid_+3A_data.batched">data.batched</code></td>
<td>
<p>Batched dataset generated by function Batched()</p>
</td></tr>
<tr><td><code id="DLSSM.valid_+3A_k">K</code></td>
<td>
<p>Number of steps for ahead prediction</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The argument fit could be object of DLSSM or DLSSM.init.
</p>


<h3>Value</h3>


<table>
<tr>
 <td style="text-align: left;">
   <code>pred.K:</code> </td><td style="text-align: left;"> K-steps ahead predicted coefficients </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>pred.var.K:</code> </td><td style="text-align: left;">  covariance of K-steps ahead predicted coefficients </td>
</tr>
<tr>
 <td style="text-align: left;">
   </td><td style="text-align: left;"> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>pred.prob.K:</code> </td><td style="text-align: left;">  K-steps ahead predicted probabilities </td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Jiakun Jiang, Wei Yang and Wensheng Guo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(321)
n=8000
beta0=function(t)   0.1*t-1
beta1=function(t)  cos(2*pi*t)
beta2=function(t)  sin(2*pi*t)
alph1=alph2=1
x=matrix(runif(n*4,min=-4,max=4),nrow=n,ncol=4)
t=sort(runif(n))
coef=cbind(beta0(t),beta1(t),beta2(t),rep(alph1,n),rep(alph2,n))
covar=cbind(rep(1,n),x)
linear=apply(coef*covar,1,sum)
prob=exp(linear)/(1+exp(linear))
y=as.numeric(runif(n)&lt;prob)
sim.data=cbind(y,x,t)
colnames(sim.data)=c("y","x1","x2","x3","x4","t")
formula = y~x1+x2+x3+x4
# Divide the time domain [0,1] into S=100 equally spaced intervals
S=100
S0=75
data.batched=Batched(formula, data=sim.data, time="t", S)

# using first 75 batches as training dataset to tune smoothing parameters
fit0=DLSSM.init(data.batched, S0, vary.effects=c("x1","x2"))
fit0$Lambda

#After initial model fitting on training data, we move to dynamic prediction
 fit=DLSSM.valid(fit0, data.batched, K=1)
 DLSSM.plot(fit)
 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
