<!DOCTYPE html><html lang="en"><head><title>Help for package samplr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {samplr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#samplr-package'><p>samplr: Compare Human Performance to Sampling Algorithms</p></a></li>
<li><a href='#Bayesian_Sampler'><p>Bayesian Sampler Model</p></a></li>
<li><a href='#calc_all'><p>Diagnostics Wrapper</p></a></li>
<li><a href='#calc_autocorr'><p>Autocorrelation Calculator</p></a></li>
<li><a href='#calc_levy'><p>Levy Flights Calculator</p></a></li>
<li><a href='#calc_PSD'><p>Power Spectral Density Calculator</p></a></li>
<li><a href='#calc_qqplot'><p>QQ-Plot Calculator</p></a></li>
<li><a href='#calc_sigma_scaling'><p>Sigma Scaling Calculator</p></a></li>
<li><a href='#CoreABS'><p>CoreABS Object</p></a></li>
<li><a href='#Mean_Variance'><p>Mean Variance Estimates</p></a></li>
<li><a href='#plot_2d_density'><p>Density Plotter</p></a></li>
<li><a href='#plot_series'><p>Series Plotter</p></a></li>
<li><a href='#sampler_hmc'><p>Hamiltonian Monte-Carlo Sampler (HMC)</p></a></li>
<li><a href='#sampler_mc3'><p>Metropolis-coupled MCMC sampler (MC3)</p></a></li>
<li><a href='#sampler_mchmc'><p>Metropolis-Coupled Hamiltonian Monte Carlo (MCHMC)</p></a></li>
<li><a href='#sampler_mcrec'><p>Metropolis-Coupled Recycled-Momentum HMC Sampler (MCREC)</p></a></li>
<li><a href='#sampler_mh'><p>Metropolis-Hastings (MH) Sampler</p></a></li>
<li><a href='#sampler_rec'><p>Recycled-Momentum HMC Sampler (REC)</p></a></li>
<li><a href='#Z_identities'><p>Z Identities</p></a></li>
<li><a href='#Zhu23ABS'><p>Auto-correlated Bayesian Sampler by Zhu (2023)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Compare Human Performance to Sampling Algorithms</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Lucas Castillo &lt;lucas.castillo-marti@warwick.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Understand human performance from the perspective of sampling, both looking at how people generate samples and how people use the samples they have generated. A longer overview and other resources can be found at <a href="https://sampling.warwick.ac.uk">https://sampling.warwick.ac.uk</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.6), ggplot2, latex2exp, pracma, stats, lme4,
Rdpack, R6, graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0), vdiffr, bench, dplyr,
tidyr, magrittr, mvtnorm, xml2, samplrData</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppDist, testthat,</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/lucas-castillo/samplr">https://github.com/lucas-castillo/samplr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lucas-castillo/samplr/issues">https://github.com/lucas-castillo/samplr/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-19 08:00:27 UTC; Lucas</td>
</tr>
<tr>
<td>Author:</td>
<td>Lucas Castillo <a href="https://orcid.org/0000-0003-0274-0777"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Yun-Xiao Li <a href="https://orcid.org/0000-0002-3509-6618"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cph],
  Adam N Sanborn <a href="https://orcid.org/0000-0003-0442-4372"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cph],
  European Research Council (ERC) [fnd]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-19 08:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='samplr-package'>samplr: Compare Human Performance to Sampling Algorithms</h2><span id='topic+samplr'></span><span id='topic+samplr-package'></span>

<h3>Description</h3>

<p>Understand human performance from the perspective of sampling, both looking at how people generate samples and how people use the samples they have generated. A longer overview and other resources can be found at <a href="https://sampling.warwick.ac.uk">https://sampling.warwick.ac.uk</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Lucas Castillo <a href="mailto:lucas.castillo-marti@warwick.ac.uk">lucas.castillo-marti@warwick.ac.uk</a> (<a href="https://orcid.org/0000-0003-0274-0777">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Yun-Xiao Li <a href="mailto:yunxiao.li@warwick.ac.uk">yunxiao.li@warwick.ac.uk</a> (<a href="https://orcid.org/0000-0002-3509-6618">ORCID</a>) [copyright holder]
</p>
</li>
<li><p> Adam N Sanborn <a href="mailto:a.n.sanborn@warwick.ac.uk">a.n.sanborn@warwick.ac.uk</a> (<a href="https://orcid.org/0000-0003-0442-4372">ORCID</a>) [copyright holder]
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> European Research Council (ERC) [funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/lucas-castillo/samplr">https://github.com/lucas-castillo/samplr</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/lucas-castillo/samplr/issues">https://github.com/lucas-castillo/samplr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='Bayesian_Sampler'>Bayesian Sampler Model</h2><span id='topic+Bayesian_Sampler'></span>

<h3>Description</h3>

<p>As described in (Zhu et al. 2020). Vectors can be provided for each parameter, allowing multiple estimates at once.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bayesian_Sampler(
  a_and_b,
  b_and_not_a,
  a_and_not_b,
  not_a_and_not_b,
  beta,
  N,
  N2 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bayesian_Sampler_+3A_a_and_b">a_and_b</code>, <code id="Bayesian_Sampler_+3A_b_and_not_a">b_and_not_a</code>, <code id="Bayesian_Sampler_+3A_a_and_not_b">a_and_not_b</code>, <code id="Bayesian_Sampler_+3A_not_a_and_not_b">not_a_and_not_b</code></td>
<td>
<p>True probabilites for the conjuctions and disjunctions of A and B. Must add to 1.</p>
</td></tr>
<tr><td><code id="Bayesian_Sampler_+3A_beta">beta</code></td>
<td>
<p>Prior parameter.</p>
</td></tr>
<tr><td><code id="Bayesian_Sampler_+3A_n">N</code></td>
<td>
<p>Number of samples drawn</p>
</td></tr>
<tr><td><code id="Bayesian_Sampler_+3A_n2">N2</code></td>
<td>
<p>Optional. Number of samples drawn for conjunctions and disjunctions. (called N' in the paper). If not given, it will default to N2=N. Must be equal or smaller than N.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list with predicted probabilities for every possible combination of A and B.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Bayesian_Sampler(
    a_and_b = c(.4, .25),
    b_and_not_a = c(.4,  .25),
    a_and_not_b = c(.1, .25),
    not_a_and_not_b = c(.1, .25),
    beta = 1,
    N &lt;- c(10, 12),
    N2 &lt;- c(10, 10)
)
</code></pre>

<hr>
<h2 id='calc_all'>Diagnostics Wrapper</h2><span id='topic+calc_all'></span>

<h3>Description</h3>

<p>Calculates all diagnostic functions in the samplr package for a given chain. Optionally, plots them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_all(chain, plot = TRUE, acf.alpha = 0.05, acf.lag.max = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_all_+3A_chain">chain</code></td>
<td>
<p>Vector of n length, where n is the number of trials or sampler iterations</p>
</td></tr>
<tr><td><code id="calc_all_+3A_plot">plot</code></td>
<td>
<p>Boolean. Whether to additionally plot the diagnostics.</p>
</td></tr>
<tr><td><code id="calc_all_+3A_acf.alpha">acf.alpha</code>, <code id="calc_all_+3A_acf.lag.max">acf.lag.max</code></td>
<td>
<p>Additional parameters to <a href="#topic+calc_autocorr">calc_autocorr</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with all diagnostic calculations (a list of lists); and optionally a grid of plots.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
diagnostics &lt;- calc_all(chain1[[1]])
names(diagnostics)
</code></pre>

<hr>
<h2 id='calc_autocorr'>Autocorrelation Calculator</h2><span id='topic+calc_autocorr'></span>

<h3>Description</h3>

<p>Calculates the autocorrelation of a given sequence, or of the size of the steps (returns).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_autocorr(chain, change = TRUE, alpha = 0.05, lag.max = 100, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_autocorr_+3A_chain">chain</code></td>
<td>
<p>Vector of n length, where n is the number of trials or sampler iterations</p>
</td></tr>
<tr><td><code id="calc_autocorr_+3A_change">change</code></td>
<td>
<p>Boolean. If true, plot the autocorrelation of the change series. If false, plot the autocorrelation of the given chain.</p>
</td></tr>
<tr><td><code id="calc_autocorr_+3A_alpha">alpha</code></td>
<td>
<p>Measure of Type I error - defaults to .05</p>
</td></tr>
<tr><td><code id="calc_autocorr_+3A_lag.max">lag.max</code></td>
<td>
<p>Length of the x axis. How far to examine the lags.</p>
</td></tr>
<tr><td><code id="calc_autocorr_+3A_plot">plot</code></td>
<td>
<p>Boolean. Whether to additionally plot the result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Markets display no significant autocorrelations in the returns of a given asset.
</p>


<h3>Value</h3>

<p>A vector with the standard deviations at each lag
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
calc_autocorr(chain1[[1]], plot=TRUE)
</code></pre>

<hr>
<h2 id='calc_levy'>Levy Flights Calculator</h2><span id='topic+calc_levy'></span>

<h3>Description</h3>

<p>This function analyses if the length of the jumps the sampler is making (<code class="reqn">l</code>) belongs to a Levy probability density distribution, <code class="reqn">P(l) \approx l^{-\mu}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_levy(chain, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_levy_+3A_chain">chain</code></td>
<td>
<p>Matrix of n x d dimensions, n = iterations, d = dimensions.</p>
</td></tr>
<tr><td><code id="calc_levy_+3A_plot">plot</code></td>
<td>
<p>Boolean. plot Boolean. Whether to also plot the distance-frequency relationship.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Values of <code class="reqn">\mu \approx 2</code> have been used to describe foraging in animals, and produce the most effective foraging (Viswanathan et al. 1999). See Zhu et al. (2018) for a comparison of Levy Flight and PSD measures for different samplers in multimodal representations.
</p>


<h3>Value</h3>

<p>If plot is true, it returns a simple plot with the log absolute difference in estimates and their frequency, as well as an estimate for the <code class="reqn">\mu</code> parameter. If false it returns a list with what's required to make the plot.
</p>


<h3>References</h3>

<p>Viswanathan GM, Buldyrev SV, Havlin S, Da Luz MGE, Raposo EP, Stanley HE (1999).
&ldquo;Optimizing the Success of Random Searches.&rdquo;
<em>Nature</em>, <b>401</b>(6756), 911&ndash;914.
<a href="https://doi.org/10.1038/44831">doi:10.1038/44831</a>.<br /><br /> Zhu J, Sanborn AN, Chater N (2018).
&ldquo;Mental Sampling in Multimodal Representations.&rdquo;
<em>Advances in Neural Information Processing Systems</em>, <b>31</b>, 5748&ndash;5759.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
calc_levy(chain1[[1]], plot=TRUE)
</code></pre>

<hr>
<h2 id='calc_PSD'>Power Spectral Density Calculator</h2><span id='topic+calc_PSD'></span>

<h3>Description</h3>

<p>This function estimates the log power spectral density against the log frequency, and calculates a slope <code class="reqn">\alpha</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_PSD(chain, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_PSD_+3A_chain">chain</code></td>
<td>
<p>Matrix of n x d dimensions, n = iterations, d = dimensions sequence</p>
</td></tr>
<tr><td><code id="calc_PSD_+3A_plot">plot</code></td>
<td>
<p>Boolean. Whether to return a plot or the elements used to make it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A number of studies have reported that cognitive activities contain a long-range slowly decaying autocorrelation. In the frequency domain, this is expressed as <code class="reqn">S(f)</code> ~  <code class="reqn">1/f^{-\alpha}</code>, with <code class="reqn">f</code> being frequency, <code class="reqn">S(f)</code> being spectral power, and <code class="reqn">\alpha</code> <code class="reqn">\epsilon</code> <code class="reqn">[0.5,1.5]</code> is considered <code class="reqn">1/f</code> scaling. See See Zhu et al. (2018) for a comparison of Levy Flight and PSD measures for different samplers in multimodal representations.
</p>


<h3>Value</h3>

<p>Returns a list with log frequencies, log PSDs, and slope and intercept estimates.
</p>


<h3>References</h3>

<p>Zhu J, Sanborn AN, Chater N (2018).
&ldquo;Mental Sampling in Multimodal Representations.&rdquo;
<em>Advances in Neural Information Processing Systems</em>, <b>31</b>, 5748&ndash;5759.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
calc_PSD(chain1[[1]], plot= TRUE)
</code></pre>

<hr>
<h2 id='calc_qqplot'>QQ-Plot Calculator</h2><span id='topic+calc_qqplot'></span>

<h3>Description</h3>

<p>Estimates values for a QQ plot of Empirical values against Theoretical values from a normal distribution, for either the chain points or the distances between successive points. Optionally, returns a plot as well as the values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_qqplot(chain, change = TRUE, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_qqplot_+3A_chain">chain</code></td>
<td>
<p>Vector of n length, where n is the number of trials or sampler iterations</p>
</td></tr>
<tr><td><code id="calc_qqplot_+3A_change">change</code></td>
<td>
<p>Boolean. If false, it calculates a qqplot of the given chain. If true, it creates a chain of step sizes.</p>
</td></tr>
<tr><td><code id="calc_qqplot_+3A_plot">plot</code></td>
<td>
<p>Boolean. Whether to plot the QQ plot or just return the values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the theoretical and empirical quantiles, and the intercept and slope of the line connecting the points
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
calc_qqplot(chain1[[1]], plot = TRUE)
</code></pre>

<hr>
<h2 id='calc_sigma_scaling'>Sigma Scaling Calculator</h2><span id='topic+calc_sigma_scaling'></span>

<h3>Description</h3>

<p>Calculates the sigma scaling of the chain, and optionally plots the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_sigma_scaling(chain, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_sigma_scaling_+3A_chain">chain</code></td>
<td>
<p>Vector of n length, where n is the number of trials or sampler iterations</p>
</td></tr>
<tr><td><code id="calc_sigma_scaling_+3A_plot">plot</code></td>
<td>
<p>Boolean. Whether to additionally plot the result.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sigma scaling is defined as the slope of the regression connecting log time lags and the standard deviation of value changes across time lags. Markets show values of 0.5.
</p>


<h3>Value</h3>

<p>A list containing the vector of possible lags, the sd of the distances at each lag, their log10 counterparts, and the calculated intercept and slope.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
calc_sigma_scaling(chain1[[1]], plot = TRUE)

</code></pre>

<hr>
<h2 id='CoreABS'>CoreABS Object</h2><span id='topic+CoreABS'></span>

<h3>Description</h3>

<p>This is the parent <a href="R6.html#topic+R6Class">R6</a> class of the Auto-correlated Bayesian Sampler (ABS, Zhu et al. 2024). It is a sequential sampling model assuming people draw autocorrelated samples from memory or beliefs, i.e., posterior of hypotheses.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>n_chains</code></dt><dd><p>an integer of the number of chains for the sampler.</p>
</dd>
<dt><code>nd_time</code></dt><dd><p>a numeric value of the non-decision time (in seconds).</p>
</dd>
<dt><code>s_nd_time</code></dt><dd><p>a numeric value of the inter-trial-variability of the non-decision time (in seconds).</p>
</dd>
<dt><code>distr_name</code></dt><dd><p>a character string indicating the type of the posterior hypothesis distribution.</p>
</dd>
<dt><code>distr_params</code></dt><dd><p>a numeric vector of the additional parameters for the posterior hypothesis distribution.</p>
</dd>
<dt><code>custom_distr</code></dt><dd><p>a list of functions that define the posterior hypothesis distribution.</p>
</dd>
<dt><code>custom_start</code></dt><dd><p>a numeric value of the starting point if &quot;custom_distr&quot; is provided.</p>
</dd>
<dt><code>sim_results</code></dt><dd><p>a data frame for saving the simulation results.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CoreABS-new"><code>CoreABS$new()</code></a>
</p>
</li>
<li> <p><a href="#method-CoreABS-clone"><code>CoreABS$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-CoreABS-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new 'CoreABS' object.
</p>


<h5>Usage</h5>

<div class="r"><pre>CoreABS$new(
  n_chains,
  nd_time,
  s_nd_time,
  distr_name = NULL,
  distr_params = NULL,
  custom_distr = NULL,
  custom_start = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>n_chains</code></dt><dd><p>an integer of the number of chains for the sampler.</p>
</dd>
<dt><code>nd_time</code></dt><dd><p>a numeric value of the non-decision time (in seconds).</p>
</dd>
<dt><code>s_nd_time</code></dt><dd><p>a numeric value of the inter-trial-variability of the non-decision time (in seconds).</p>
</dd>
<dt><code>distr_name</code></dt><dd><p>a character string indicating the type of the posterior hypothesis distribution. The package currently only supports <code>norm</code>, which represents normal distribution.</p>
</dd>
<dt><code>distr_params</code></dt><dd><p>a numeric vector of the additional parameters for the posterior hypothesis distribution.</p>
</dd>
<dt><code>custom_distr</code></dt><dd><p>a list of functions that define the posterior hypothesis distribution.</p>
</dd>
<dt><code>custom_start</code></dt><dd><p>a numeric value of the starting point if &quot;custom_distr&quot; is provided.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new 'CoreABS' object.
</p>


<hr>
<a id="method-CoreABS-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>CoreABS$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Zhu J, Sundh J, Spicer J, Chater N, Sanborn AN (2024).
&ldquo;The Autocorrelated Bayesian Sampler: A Rational Process for Probability Judgments, Estimates, Confidence Intervals, Choices, Confidence Judgments, and Response Times.&rdquo;
<em>Psychological Review</em>, <b>131</b>(2), 456&ndash;493.
<a href="https://doi.org/10.1037/rev0000427">doi:10.1037/rev0000427</a>.
</p>

<hr>
<h2 id='Mean_Variance'>Mean Variance Estimates</h2><span id='topic+Mean_Variance'></span>

<h3>Description</h3>

<p>Estimates number of samples and prior parameters of the Bayesian Sampler using the Mean/Variance relationship as shown by (Sundh et al. 2023). For consistency with the Bayesian Sampler function we call beta the prior parameter, and b0 and b1 slope and intercept respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mean_Variance(rawData, idCol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Mean_Variance_+3A_rawdata">rawData</code></td>
<td>
<p>Dataframe with the following column variables for N repetitions of each unique query: participant ID ('id'), response query 1, response query 2, ... , response query N</p>
</td></tr>
<tr><td><code id="Mean_Variance_+3A_idcol">idCol</code></td>
<td>
<p>Name of the 'ID' column.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with values for the intercept (b0) and slope (b1) of the estimated regression, as well as estimates for N, d, and beta (termed b in the paper) for each participant.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
library(tidyr)
library(magrittr)
library(samplrData)
data &lt;- sundh2023.meanvariance.e3 %&gt;%
  group_by(ID, querydetail) %&gt;% 
  mutate(iteration = LETTERS[1:n()]) %&gt;% 
  pivot_wider(id_cols = c(ID, querydetail), 
      values_from = estimate, names_from = iteration) %&gt;% 
  mutate(across(where(is.numeric), \(x){x/100})) %&gt;% 
  ungroup %&gt;% 
  select(-querydetail)
head(data)
head(Mean_Variance(data, "ID"))
</code></pre>

<hr>
<h2 id='plot_2d_density'>Density Plotter</h2><span id='topic+plot_2d_density'></span>

<h3>Description</h3>

<p>Plots a 2D map of the density of a distribution. If plot = FALSE, returns a dataframe with the density for each cell in the grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_2d_density(
  start,
  size,
  cellsPerRow = 50,
  names = NULL,
  params = NULL,
  weights = NULL,
  customDensity = NULL,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_2d_density_+3A_start">start</code></td>
<td>
<p>Vector c(x, y) with the coordinates of the bottom-left corner of the map.</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_size">size</code></td>
<td>
<p>Distance covered by the map. In other words, the top-right corner of the map has coordinates c(x + size, y + size)</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_cellsperrow">cellsPerRow</code></td>
<td>
<p>Number of cells to plot in every row. The higher, the more resolution</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_names">names</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_params">params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_weights">weights</code></td>
<td>
<p>Distribution weights (if it's a mix of distributions)</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_customdensity">customDensity</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
<tr><td><code id="plot_2d_density_+3A_plot">plot</code></td>
<td>
<p>Whether to return a plot or a dataframe with the density in each coordinate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Density Plot or dataframe
</p>


<h3>Examples</h3>

<pre><code class='language-R'># plot supported distribution
plot_2d_density(
c(-5, -5), 10, cellsPerRow = 100, names = c("mvnorm", "mvnorm"),
params = list(list(c(-2,1), diag(2)), list(c(2,1), diag(2)))
)

# plot custom distribution
customDensity_r &lt;- function(x){
    if (x[1] &gt; 0 &amp;&amp; x[1] &lt; 3 &amp;&amp; x[2] &lt; 0 &amp;&amp; x[2] &gt; -3){
        return (1)
    } else {
        return (0)
    }
}
plot_2d_density(start = c(0,-4), size = 5, customDensity = customDensity_r)


</code></pre>

<hr>
<h2 id='plot_series'>Series Plotter</h2><span id='topic+plot_series'></span>

<h3>Description</h3>

<p>Plots the value of a one-dimensional series against the iteration where it occurred. Useful to see the general pattern of the chain (white noise, random walk, volatility clustering)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_series(chain, change = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_series_+3A_chain">chain</code></td>
<td>
<p>Vector of n length, where n is the number of trials or sampler iterations</p>
</td></tr>
<tr><td><code id="plot_series_+3A_change">change</code></td>
<td>
<p>Boolean. Whether to plot the series of values or the series of changes between values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A series plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
chain1 &lt;- sampler_mh(1, "norm", c(0,1), diag(1))
plot_series(chain1[[1]])
</code></pre>

<hr>
<h2 id='sampler_hmc'>Hamiltonian Monte-Carlo Sampler (HMC)</h2><span id='topic+sampler_hmc'></span>

<h3>Description</h3>

<p>Hamiltonian Monte-Carlo, also called Hybrid Monte Carlo, is a sampling algorithm that uses Hamiltonian Dynamics to approximate a posterior distribution. Unlike MH and MC3, HMC uses not only the current position, but also a sense of momentum, to draw future samples. An introduction to HMC can be read in Betancourt (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_hmc(
  start,
  distr_name = NULL,
  distr_params = NULL,
  epsilon = 0.5,
  L = 10,
  iterations = 1024,
  weights = NULL,
  custom_density = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampler_hmc_+3A_start">start</code></td>
<td>
<p>Vector. Starting position of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_distr_name">distr_name</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_distr_params">distr_params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_epsilon">epsilon</code></td>
<td>
<p>Size of the leapfrog step</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_l">L</code></td>
<td>
<p>Number of leapfrog steps per iteration</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_weights">weights</code></td>
<td>
<p>If using a mixture distribution, the weights given to each constituent distribution. If none given, it defaults to equal weights for all distributions.</p>
</td></tr>
<tr><td><code id="sampler_hmc_+3A_custom_density">custom_density</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementations assumes that the momentum is drawn from a normal distribution with mean 0 and identity covariance matrix (p ~ N (0, I)). Hamiltonian Monte Carlo does not support discrete distributions.
</p>
<p>This algorithm has been used to model human data in Aitchison and Lengyel (2016), Castillo et al. (2024) and Zhu et al. (2022) among others.
</p>


<h3>Value</h3>

<p>A named list containing
</p>

<ol>
<li><p>Samples: the history of visited places (an n x d matrix, n = iterations; d = dimensions)
</p>
</li>
<li><p>Momentums: the history of momentum values (an n x d matrix, n = iterations; d = dimensions). Nothing is proposed in the first iteration (the first iteration is the start value) and so the first row is NA
</p>
</li>
<li><p>Acceptance Ratio: The proportion of proposals that were accepted.
</p>
</li></ol>



<h3>References</h3>

<p>Aitchison L, Lengyel M (2016).
&ldquo;The Hamiltonian Brain: Efficient Probabilistic Inference with Excitatory-Inhibitory Neural Circuit Dynamics.&rdquo;
<em>PLOS Computational Biology</em>, <b>12</b>(12), e1005186.
<a href="https://doi.org/10.1371/journal.pcbi.1005186">doi:10.1371/journal.pcbi.1005186</a>.<br /><br /> Betancourt M (2018).
&ldquo;A Conceptual Introduction to Hamiltonian Monte Carlo.&rdquo;
<a href="http://arxiv.org/abs/1701.02434">http://arxiv.org/abs/1701.02434</a>.<br /><br /> Castillo L, León-Villagrá P, Chater N, Sanborn A (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.<br /><br /> Zhu J, León-Villagrá P, Chater N, Sanborn AN (2022).
&ldquo;Understanding the Structure of Cognitive Noise.&rdquo;
<em>PLoS Computational Biology</em>, <b>18</b>(8), e1010312.
<a href="https://doi.org/10.1371/journal.pcbi.1010312">doi:10.1371/journal.pcbi.1010312</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>result &lt;- sampler_hmc(
    distr_name = "norm", distr_params = c(0,1), 
    start = 1, epsilon = .01, L = 100
    )
cold_chain &lt;- result$Samples
</code></pre>

<hr>
<h2 id='sampler_mc3'>Metropolis-coupled MCMC sampler (MC3)</h2><span id='topic+sampler_mc3'></span>

<h3>Description</h3>

<p>This sampler is a variant of MH in which multiple parallel chains are run at different temperatures. The chains stochastically swap positions which allows the coldest chain to visit regions far from its starting point (unlike in MH). Because of this, an MC3 sampler can explore far-off regions, whereas an MH sampler may become stuck in a particular point of high density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_mc3(
  start,
  distr_name = NULL,
  distr_params = NULL,
  sigma_prop = NULL,
  nChains = 6,
  delta_T = 4,
  swap_all = TRUE,
  iterations = 1024L,
  weights = NULL,
  custom_density = NULL,
  alpha = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampler_mc3_+3A_start">start</code></td>
<td>
<p>Either a vector or a matrix. If it is a vector, it will be the starting point of all the chains (with length = number of dimensions). If it's a matrix, every row will be the starting point of one chain (and so it must have as many rows as nChains, and as many columns as number of dimensions in the space).</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_distr_name">distr_name</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_distr_params">distr_params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_sigma_prop">sigma_prop</code></td>
<td>
<p>Covariance matrix of the proposal distribution. If sampling in 1D space, it can be instead a number.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_nchains">nChains</code></td>
<td>
<p>Number of chains to run.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_delta_t">delta_T</code></td>
<td>
<p>numeric, &gt;1. Temperature increment parameter. The bigger this number, the steeper the increase in temperature between the cold chain and the next chain</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_swap_all">swap_all</code></td>
<td>
<p>Boolean. If true, every iteration attempts floor(nChains / 2) swaps. If false, only one swap per iteration.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_weights">weights</code></td>
<td>
<p>If using a mixture distribution, the weights given to each constituent distribution. If none given, it defaults to equal weights for all distributions.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_custom_density">custom_density</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
<tr><td><code id="sampler_mc3_+3A_alpha">alpha</code></td>
<td>
<p>autocorrelation of proposals parameter, from -1 to 1, with 0 being independent proposals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm has been used to model human data in Castillo et al. (2024), Zhu et al. (2022) and Zhu et al. (2018) among others.
</p>


<h3>Value</h3>

<p>A named list containing
</p>

<ol>
<li><p>Samples: the history of visited places (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain')
</p>
</li>
<li><p>Proposals: the history of proposed places (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain'). Nothing is proposed in the first iteration (the first iteration is the start value) and so the first row is NA
</p>
</li>
<li><p>Acceptance Ratio: The proportion of proposals that were accepted (for each chain).
</p>
</li>
<li><p>Beta Values: The set of temperatures used in each chain
</p>
</li>
<li><p>Swap History: the history of chain swaps
</p>
</li>
<li><p>Swap Acceptance Ratio: The ratio of swap acceptances
</p>
</li></ol>



<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn A (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.<br /><br /> Zhu J, León-Villagrá P, Chater N, Sanborn AN (2022).
&ldquo;Understanding the Structure of Cognitive Noise.&rdquo;
<em>PLoS Computational Biology</em>, <b>18</b>(8), e1010312.
<a href="https://doi.org/10.1371/journal.pcbi.1010312">doi:10.1371/journal.pcbi.1010312</a>.<br /><br /> Zhu J, Sanborn AN, Chater N (2018).
&ldquo;Mental Sampling in Multimodal Representations.&rdquo;
<em>Advances in Neural Information Processing Systems</em>, <b>31</b>, 5748&ndash;5759.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Sample from a normal distribution
result &lt;- sampler_mc3(
    distr_name = "norm", distr_params = c(0,1), 
    start = 1, sigma_prop = diag(1)
)
cold_chain &lt;- result$Samples[,,1]
</code></pre>

<hr>
<h2 id='sampler_mchmc'>Metropolis-Coupled Hamiltonian Monte Carlo (MCHMC)</h2><span id='topic+sampler_mchmc'></span>

<h3>Description</h3>

<p>Metropolis-Coupled version of HMC, i.e. running multiple chains at different temperatures which stochastically swap positions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_mchmc(
  start,
  distr_name = NULL,
  distr_params = NULL,
  epsilon = 0.5,
  L = 10,
  nChains = 6,
  delta_T = 4,
  swap_all = TRUE,
  iterations = 1024L,
  weights = NULL,
  custom_density = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampler_mchmc_+3A_start">start</code></td>
<td>
<p>Vector. Starting position of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_distr_name">distr_name</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_distr_params">distr_params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_epsilon">epsilon</code></td>
<td>
<p>Size of the leapfrog step</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_l">L</code></td>
<td>
<p>Number of leapfrog steps per iteration</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_nchains">nChains</code></td>
<td>
<p>Number of chains to run.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_delta_t">delta_T</code></td>
<td>
<p>numeric, &gt;1. Temperature increment parameter. The bigger this number, the steeper the increase in temperature between the cold chain and the next chain</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_swap_all">swap_all</code></td>
<td>
<p>Boolean. If true, every iteration attempts floor(nChains / 2) swaps. If false, only one swap per iteration.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_weights">weights</code></td>
<td>
<p>If using a mixture distribution, the weights given to each constituent distribution. If none given, it defaults to equal weights for all distributions.</p>
</td></tr>
<tr><td><code id="sampler_mchmc_+3A_custom_density">custom_density</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Metropolis-Coupled HMC does not support discrete distributions.
</p>
<p>This algorithm has been used to model human data in Castillo et al. (2024).
</p>


<h3>Value</h3>

<p>A named list containing
</p>

<ol>
<li><p>Samples: the history of visited places (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain')
</p>
</li>
<li><p>Momentums: the history of momentum values (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain'). Nothing is proposed in the first iteration (the first iteration is the start value) and so the first row is NA
</p>
</li>
<li><p>Acceptance Ratio: The proportion of proposals that were accepted (for each chain).
</p>
</li>
<li><p>Beta Values: The set of temperatures used in each chain
</p>
</li>
<li><p>Swap History: the history of chain swaps
</p>
</li>
<li><p>Swap Acceptance Ratio: The ratio of swap acceptances
</p>
</li></ol>



<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn A (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
result &lt;- sampler_mchmc(
    distr_name = "norm", distr_params = c(0,1), 
    start = 1, epsilon = .01, L = 100
)
cold_chain &lt;- result$Samples[,,1]
</code></pre>

<hr>
<h2 id='sampler_mcrec'>Metropolis-Coupled Recycled-Momentum HMC Sampler (MCREC)</h2><span id='topic+sampler_mcrec'></span>

<h3>Description</h3>

<p>Metropolis-Coupled version of Recycled-Momentum HMC, i.e. running multiple chains at different temperatures which stochastically swap positions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_mcrec(
  start,
  distr_name = NULL,
  distr_params = NULL,
  epsilon = 0.5,
  L = 10,
  alpha = 0.1,
  nChains = 6,
  delta_T = 4,
  swap_all = TRUE,
  iterations = 1024L,
  weights = NULL,
  custom_density = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampler_mcrec_+3A_start">start</code></td>
<td>
<p>Vector. Starting position of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_distr_name">distr_name</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_distr_params">distr_params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_epsilon">epsilon</code></td>
<td>
<p>Size of the leapfrog step</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_l">L</code></td>
<td>
<p>Number of leapfrog steps per iteration</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_alpha">alpha</code></td>
<td>
<p>Recycling factor, from -1 to 1 (see Details).</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_nchains">nChains</code></td>
<td>
<p>Number of chains to run.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_delta_t">delta_T</code></td>
<td>
<p>numeric, &gt;1. Temperature increment parameter. The bigger this number, the steeper the increase in temperature between the cold chain and the next chain</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_swap_all">swap_all</code></td>
<td>
<p>Boolean. If true, every iteration attempts floor(nChains / 2) swaps. If false, only one swap per iteration.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_weights">weights</code></td>
<td>
<p>If using a mixture distribution, the weights given to each constituent distribution. If none given, it defaults to equal weights for all distributions.</p>
</td></tr>
<tr><td><code id="sampler_mcrec_+3A_custom_density">custom_density</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Metropolis-Coupled Recycled-Momentum HMC does not support discrete distributions.
</p>
<p>This algorithm has been used to model human data in Castillo et al. (2024).
</p>


<h3>Value</h3>

<p>A named list containing
</p>

<ol>
<li><p>Samples: the history of visited places (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain')
</p>
</li>
<li><p>Momentums: the history of momentum values (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain'). Nothing is proposed in the first iteration (the first iteration is the start value) and so the first row is NA
</p>
</li>
<li><p>Acceptance Ratio: The proportion of proposals that were accepted (for each chain).
</p>
</li>
<li><p>Beta Values: The set of temperatures used in each chain
</p>
</li>
<li><p>Swap History: the history of chain swaps
</p>
</li>
<li><p>Swap Acceptance Ratio: The ratio of swap acceptances
</p>
</li></ol>



<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn A (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
result &lt;- sampler_mcrec(
    distr_name = "norm", distr_params = c(0,1), 
    start = 1, epsilon = .01, L = 100
)
cold_chain &lt;- result$Samples[,,1]
</code></pre>

<hr>
<h2 id='sampler_mh'>Metropolis-Hastings (MH) Sampler</h2><span id='topic+sampler_mh'></span>

<h3>Description</h3>

<p>This sampler navigates the proposal distribution following a random walk. At each step, it generates a new proposal from a proposal distribution (in this case a Gaussian centered at the current position) and chooses to accept it or reject it following the Metropolis-Hastings rule: it accepts it if the density of the posterior distribution at the proposed point is higher than at the current point. If the current position is denser, it still may accept the proposal with probability <code>proposal_density / current_density</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_mh(
  start,
  distr_name = NULL,
  distr_params = NULL,
  sigma_prop = NULL,
  iterations = 1024L,
  weights = NULL,
  custom_density = NULL,
  alpha = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampler_mh_+3A_start">start</code></td>
<td>
<p>Vector. Starting position of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_distr_name">distr_name</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_distr_params">distr_params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_sigma_prop">sigma_prop</code></td>
<td>
<p>Covariance matrix of the proposal distribution. If sampling in 1D space, it can be instead a number.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_weights">weights</code></td>
<td>
<p>If using a mixture distribution, the weights given to each constituent distribution. If none given, it defaults to equal weights for all distributions.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_custom_density">custom_density</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
<tr><td><code id="sampler_mh_+3A_alpha">alpha</code></td>
<td>
<p>autocorrelation of proposals parameter, from -1 to 1, with 0 being independent proposals</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As mentioned, the proposal distribution is a Normal distribution. Its mean is the current position, and its variance is equal to the <code>sigma_prop</code> parameter, which defaults to the identity matrix if not specified.
</p>
<p>This algorithm has been used to model human data in many places (e.g. Castillo et al. 2024; Dasgupta et al. 2017; Lieder et al. 2018; Zhu et al. 2022).
</p>


<h3>Value</h3>

<p>A named list containing
</p>

<ol>
<li><p>Samples: the history of visited places (an n x d matrix, n = iterations; d = dimensions)
</p>
</li>
<li><p>Proposals: the history of proposed places (an n x d matrix, n = iterations; d = dimensions). Nothing is proposed in the first iteration (the first iteration is the start value) and so the first row is NA
</p>
</li>
<li><p>Acceptance Ratio: The proportion of proposals that were accepted.
</p>
</li></ol>



<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn A (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.<br /><br /> Dasgupta I, Schulz E, Gershman SJ (2017).
&ldquo;Where Do Hypotheses Come From?&rdquo;
<em>Cognitive Psychology</em>, <b>96</b>, 1&ndash;25.
<a href="https://doi.org/10.1016/j.cogpsych.2017.05.001">doi:10.1016/j.cogpsych.2017.05.001</a>.<br /><br /> Lieder F, Griffiths TL, M. Huys QJ, Goodman ND (2018).
&ldquo;The Anchoring Bias Reflects Rational Use of Cognitive Resources.&rdquo;
<em>Psychonomic Bulletin &amp; Review</em>, <b>25</b>(1), 322&ndash;349.
<a href="https://doi.org/10.3758/s13423-017-1286-8">doi:10.3758/s13423-017-1286-8</a>.<br /><br /> Zhu J, León-Villagrá P, Chater N, Sanborn AN (2022).
&ldquo;Understanding the Structure of Cognitive Noise.&rdquo;
<em>PLoS Computational Biology</em>, <b>18</b>(8), e1010312.
<a href="https://doi.org/10.1371/journal.pcbi.1010312">doi:10.1371/journal.pcbi.1010312</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Sample from a normal distribution
result &lt;- sampler_mh(
         distr_name = "norm", distr_params = c(0,1),
         start = 1, sigma_prop = diag(1)
         )
cold_chain &lt;- result$Samples
</code></pre>

<hr>
<h2 id='sampler_rec'>Recycled-Momentum HMC Sampler (REC)</h2><span id='topic+sampler_rec'></span>

<h3>Description</h3>

<p>Recycled-Momentum HMC is a sampling algorithm that uses Hamiltonian Dynamics to approximate a posterior distribution. Unlike in standard HMC, proposals are autocorrelated, as the momentum of the current trajectory is not independent of the last trajectory, but is instead updated by a parameter alpha (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampler_rec(
  start,
  distr_name = NULL,
  distr_params = NULL,
  epsilon = 0.5,
  L = 10,
  alpha = 0.1,
  iterations = 1024L,
  weights = NULL,
  custom_density = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampler_rec_+3A_start">start</code></td>
<td>
<p>Vector. Starting position of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_distr_name">distr_name</code></td>
<td>
<p>Name of the distribution from which to sample from.</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_distr_params">distr_params</code></td>
<td>
<p>Distribution parameters.</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_epsilon">epsilon</code></td>
<td>
<p>Size of the leapfrog step</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_l">L</code></td>
<td>
<p>Number of leapfrog steps per iteration</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_alpha">alpha</code></td>
<td>
<p>Recycling factor, from -1 to 1 (see Details).</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_iterations">iterations</code></td>
<td>
<p>Number of iterations of the sampler.</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_weights">weights</code></td>
<td>
<p>If using a mixture distribution, the weights given to each constituent distribution. If none given, it defaults to equal weights for all distributions.</p>
</td></tr>
<tr><td><code id="sampler_rec_+3A_custom_density">custom_density</code></td>
<td>
<p>Instead of providing names, params and weights, the user may prefer to provide a custom density function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>While in HMC the momentum in each iteration is an independent draw,, here the momentum of the last utterance <code class="reqn">p^{n-1}</code> is also involved. In each iteration, the momentum <code class="reqn">p</code> is obtained as follows </p>
<p style="text-align: center;"><code class="reqn">p \gets \alpha \times p^{n-1} + (1 - \alpha^2)^{\frac{1}{2}} \times v</code>
</p>
<p>; where <code class="reqn">v \sim N(0, I)</code>.
</p>
<p>Recycled-Momentum HMC does not support discrete distributions.
</p>
<p>This algorithm has been used to model human data in Castillo et al. (2024)
</p>


<h3>Value</h3>

<p>A named list containing
</p>

<ol>
<li><p>Samples: the history of visited places (an n x d x c array, n = iterations; d = dimensions; c = chain index, with c==1 being the 'cold chain')
</p>
</li>
<li><p>Momentums: the history of momentum values (an n x d matrix, n = iterations; d = dimensions). Nothing is proposed in the first iteration (the first iteration is the start value) and so the first row is NA
</p>
</li>
<li><p>Acceptance Ratio: The proportion of proposals that were accepted (for each chain).
</p>
</li></ol>



<h3>References</h3>

<p>Castillo L, León-Villagrá P, Chater N, Sanborn A (2024).
&ldquo;Explaining the Flaws in Human Random Generation as Local Sampling with Momentum.&rdquo;
<em>PLOS Computational Biology</em>, <b>20</b>(1), 1&ndash;24.
<a href="https://doi.org/10.1371/journal.pcbi.1011739">doi:10.1371/journal.pcbi.1011739</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
result &lt;- sampler_rec(
    distr_name = "norm", distr_params = c(0,1), 
    start = 1, epsilon = .01, L = 100
)
cold_chain &lt;- result$Samples
</code></pre>

<hr>
<h2 id='Z_identities'>Z Identities</h2><span id='topic+Z_identities'></span>

<h3>Description</h3>

<p>Calculates identities Z1 to Z18 as defined in (Costello and Watts 2016; Zhu et al. 2020). Probability theory predicts that these will all equal 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Z_identities(
  a = NULL,
  b = NULL,
  a_and_b = NULL,
  a_or_b = NULL,
  a_given_b = NULL,
  b_given_a = NULL,
  a_given_not_b = NULL,
  b_given_not_a = NULL,
  a_and_not_b = NULL,
  b_and_not_a = NULL,
  not_a = NULL,
  not_b = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Z_identities_+3A_a">a</code>, <code id="Z_identities_+3A_b">b</code>, <code id="Z_identities_+3A_a_and_b">a_and_b</code>, <code id="Z_identities_+3A_a_or_b">a_or_b</code>, <code id="Z_identities_+3A_a_given_b">a_given_b</code>, <code id="Z_identities_+3A_b_given_a">b_given_a</code>, <code id="Z_identities_+3A_a_given_not_b">a_given_not_b</code>, <code id="Z_identities_+3A_b_given_not_a">b_given_not_a</code>, <code id="Z_identities_+3A_a_and_not_b">a_and_not_b</code>, <code id="Z_identities_+3A_b_and_not_a">b_and_not_a</code></td>
<td>
<p>Probability estimates given by participants</p>
</td></tr>
<tr><td><code id="Z_identities_+3A_not_a">not_a</code>, <code id="Z_identities_+3A_not_b">not_b</code></td>
<td>
<p>Probability estimates given by participants. If not given, they'll default to 1-a and 1-b respectively</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If some of the probability estimates are not given, calculation will proceed and equalities that cannot be calculated will be coded as NA.
</p>


<h3>Value</h3>

<p>Dataframe with identities Z1 to Z18
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Z_identities(
 a=.5, 
 b=.1, 
 a_and_b=.05, 
 a_or_b=.55, 
 a_given_b=.5,
 b_given_a=.1,
 a_given_not_b=.5,
 b_given_not_a=.1,
 a_and_not_b=.45,
 b_and_not_a=.05,
 )
#Get identities for a set of participants
library(magrittr)
library(dplyr)
library(tidyr)
data.frame(
 ID = LETTERS[1:20],
 a=runif(20),
 b=runif(20),
 a_and_b=runif(20),
 a_or_b=runif(20),
 a_given_b=runif(20),
 b_given_a=runif(20),
 a_given_not_b=runif(20),
 b_given_not_a=runif(20),
 a_and_not_b=runif(20),
 b_and_not_a=runif(20),
 not_a=runif(20),
 not_b=runif(20)
) %&gt;% 
 group_by(ID) %&gt;% 
 do(
   Z_identities(
     .$a,
     .$b,
     .$a_and_b,
     .$a_or_b,
     .$a_given_b,
     .$b_given_a,
     .$a_given_not_b,
     .$b_given_not_a,
     .$a_and_not_b,
     .$b_and_not_a,
     .$not_a,
     .$not_b
   )
 )
</code></pre>

<hr>
<h2 id='Zhu23ABS'>Auto-correlated Bayesian Sampler by Zhu (2023)</h2><span id='topic+Zhu23ABS'></span>

<h3>Description</h3>

<p>This Auto-correlated Bayesian Sampler model (ABS, Zhu et al. 2024) is developed by Zhu.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+CoreABS">samplr::CoreABS</a></code> -&gt; <code>Zhu23ABS</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>width</code></dt><dd><p>the standard deviation of the proposal distribution for MC3.</p>
</dd>
<dt><code>lambda</code></dt><dd><p>the rate parameter of the Erlang distribution for decision time.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Zhu23ABS-new"><code>Zhu23ABS$new()</code></a>
</p>
</li>
<li> <p><a href="#method-Zhu23ABS-simulate"><code>Zhu23ABS$simulate()</code></a>
</p>
</li>
<li> <p><a href="#method-Zhu23ABS-confidence_interval"><code>Zhu23ABS$confidence_interval()</code></a>
</p>
</li>
<li> <p><a href="#method-Zhu23ABS-reset_sim_results"><code>Zhu23ABS$reset_sim_results()</code></a>
</p>
</li>
<li> <p><a href="#method-Zhu23ABS-clone"><code>Zhu23ABS$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Zhu23ABS-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create a new 'Zhu23ABS' object.
</p>


<h5>Usage</h5>

<div class="r"><pre>Zhu23ABS$new(
  width,
  n_chains,
  nd_time,
  s_nd_time,
  lambda,
  distr_name = NULL,
  distr_params = NULL,
  custom_distr = NULL,
  custom_start = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>width</code></dt><dd><p>a numeric value of the standard deviation of the proposal distribution for MC3.</p>
</dd>
<dt><code>n_chains</code></dt><dd><p>an integer of the number of chains for the sampler.</p>
</dd>
<dt><code>nd_time</code></dt><dd><p>a numeric value of the non-decision time (in seconds). When <code>s_nd_time</code> is not 0, <code>nd_time</code> represents the lower bound of the non-decision time.</p>
</dd>
<dt><code>s_nd_time</code></dt><dd><p>a numeric value of the inter-trial-variability of the non-decision time (in seconds).</p>
</dd>
<dt><code>lambda</code></dt><dd><p>a numeric value of the rate parameter of the Erlang distribution for decision time.</p>
</dd>
<dt><code>distr_name</code></dt><dd><p>a character string indicating the type of the posterior hypothesis distribution.</p>
</dd>
<dt><code>distr_params</code></dt><dd><p>a numeric vector of the additional parameters for the posterior hypothesis distribution.</p>
</dd>
<dt><code>custom_distr</code></dt><dd><p>a list of functions that define the posterior hypothesis distribution.</p>
</dd>
<dt><code>custom_start</code></dt><dd><p>a numeric value of the starting point if &quot;custom_distr&quot; is provided.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A new 'Zhu23ABS' object.
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>zhuabs &lt;- Zhu23ABS$new(
    width = 1, n_chains = 5, nd_time = 0.3, s_nd_time = 0.5, 
    lambda = 10, distr_name = 'norm', distr_params = 1
)

</pre>
</div>


<hr>
<a id="method-Zhu23ABS-simulate"></a>



<h4>Method <code>simulate()</code></h4>

<p>Simulate the ABS model.
</p>


<h5>Usage</h5>

<div class="r"><pre>Zhu23ABS$simulate(stopping_rule, start_point = NA, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>stopping_rule</code></dt><dd><p>a character string indicating the stopping rule of ABS to be applied. Possible values are <code>"fixed"</code> and <code>"relative"</code>. See also <code>Details</code>.</p>
</dd>
<dt><code>start_point</code></dt><dd><p>a numeric vector setting the start point of each trial for the sampler. By default, it's set to <code>NA</code>, indicating that the starting point of the first trial is a random point from the posterior of hypotheses, and the starting points of subsequent trials are set to the last sample of the previous trial. For more detailed information, please refer to the vignette &quot;Simulations of the Autocorrelated Bayesian Sampler&quot;.</p>
</dd>
<dt><code>...</code></dt><dd><p>further arguments passed to the ABS model, see also <code>Details</code>.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>The ABS model has two types of stopping rules: fixed and relative. The fixed stopping rule means that a fixed number of samples are drawn to complete the tasks such as estimations and confidence intervals. This rule applies to tasks such as estimation tasks. On the other hand, the relative stopping rule means that the model counts the difference in evidence between the two hypotheses, and terminates the sampling process whenever the accumulated difference exceeds a threshold. This rule applies to tasks such as two-alternative force choice tasks.
</p>
<p>When the <code style="white-space: pre;">&#8288;stopping rule&#8288;</code> is <code>"fixed"</code>, the following arguments are required:
</p>

<ul>
<li> <p><code>n_sample</code> an integer of the fixed number of samples for each trial.
</p>
</li>
<li> <p><code>trial_stim</code> a numeric vector of the stimulus of each trial.
</p>
</li></ul>

<p>When the <code style="white-space: pre;">&#8288;stopping rule&#8288;</code> is <code>"relative"</code>, the following arguments are required:
</p>

<ul>
<li> <p><code>delta</code> an integer of the relative difference between the number of samples supporting each hypothesis.
</p>
</li>
<li> <p><code>dec_bdry</code> a numeric value of the decision boundary that separates the posterior hypothesis distribution.
</p>
</li>
<li> <p><code>discrim</code> a numeric value of the stimuli discriminability.
</p>
</li>
<li> <p><code>trial_stim</code> a factor that indicates the stimuli of each trial. It only consists of either one level or two levels. By definition, level 1 represents the stimulus below the decision boundary, while level 2 represents the stimulus above the decision boundary.
</p>
</li>
<li> <p><code>prior_on_resp</code> a numeric vector for the Beta prior on responses. Defaults to <code>c(1,1)</code> representing the distribution <code>Beta(1,1)</code>.
</p>
</li>
<li> <p><code>prior_depend</code> a boolean variable that control whether the prior on responses changes regarding the last stimulus. Defaults to <code>TRUE</code>. Please refer to the vignette for more information.
</p>
</li>
<li> <p><code>max_iterations</code> an integer of the maximum length of the MC3 sampler. Defaults to 1000. The program will stop the sampling process after the length of the sampling sequence reaches to this limitation.
</p>
</li></ul>

<p>No values will be return after running this method, but the field <code>sim_results</code> will be updated instead. If the stopping rule is &quot;fixed&quot;, <code>simulation_results</code> will be a data frame with five columns:
</p>

<ol>
<li><p>trial: The index of trials;
</p>
</li>
<li><p>samples: The samples of ABS sampler for the trial;
</p>
</li>
<li><p>stimulus: The stimuli of the experiment;
</p>
</li>
<li><p>rt: The response time;
</p>
</li>
<li><p>point_est: The response of point estimation;
</p>
</li></ol>

<p>On the other hand, if the stopping rule is &quot;relative&quot;, <code>sim_results</code> will be a data frame with seven columns:
</p>

<ol>
<li><p>trial: The index of trials;
</p>
</li>
<li><p>samples: The samples of ABS sampler for the trial;
</p>
</li>
<li><p>response: The response predicted by ABS;
</p>
</li>
<li><p>stimulus: The stimuli of the experiment;
</p>
</li>
<li><p>accuracy: Whether the response is the same as the feedback. 0 represents error, and 1 represents correct;
</p>
</li>
<li><p>rt: The response time, including both the non-decision and the decision time;
</p>
</li>
<li><p>confidence: The confidence of the response.
</p>
</li></ol>




<h5>Examples</h5>

<div class="r example copy">
<pre>
trial_stim &lt;- round(runif(5, 10, 50))
zhuabs$simulate(stopping_rule='fixed', n_sample = 5, trial_stim = trial_stim)
zhuabs$sim_results

zhuabs$reset_sim_results()
trial_stim &lt;- factor(sample(c('left', 'right'), 5, TRUE))
zhuabs$simulate(stopping_rule='relative', 
   delta = 4, dec_bdry = 0, 
   discrim = 1, trial_stim = trial_stim
)
zhuabs$sim_results

</pre>
</div>


<hr>
<a id="method-Zhu23ABS-confidence_interval"></a>



<h4>Method <code>confidence_interval()</code></h4>

<p>This function calculates the confidence interval of the <code>simulate</code> method's results when the &quot;fixed&quot; stopping rule was used.
</p>


<h5>Usage</h5>

<div class="r"><pre>Zhu23ABS$confidence_interval(conf_level)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>conf_level</code></dt><dd><p>the required confidence level.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>No values will be returned by this method. Instead, two new columns will be added to the <code>sim_results</code>:
</p>

<ol>
<li><p>conf_interval_l: The lower bound of the confidence interval with the given level;
</p>
</li>
<li><p>conf_interval_u: The upper bound of the confidence interval with the given level;
</p>
</li></ol>




<h5>Examples</h5>

<div class="r example copy">
<pre>zhuabs$confidence_interval(conf_level = 0.9)

</pre>
</div>


<hr>
<a id="method-Zhu23ABS-reset_sim_results"></a>



<h4>Method <code>reset_sim_results()</code></h4>

<p>This function is for resetting the <code>sim_results</code> to run new simulations.
</p>


<h5>Usage</h5>

<div class="r"><pre>Zhu23ABS$reset_sim_results()</pre></div>


<hr>
<a id="method-Zhu23ABS-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Zhu23ABS$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Zhu J, Sundh J, Spicer J, Chater N, Sanborn AN (2024).
&ldquo;The Autocorrelated Bayesian Sampler: A Rational Process for Probability Judgments, Estimates, Confidence Intervals, Choices, Confidence Judgments, and Response Times.&rdquo;
<em>Psychological Review</em>, <b>131</b>(2), 456&ndash;493.
<a href="https://doi.org/10.1037/rev0000427">doi:10.1037/rev0000427</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## ------------------------------------------------
## Method `Zhu23ABS$new`
## ------------------------------------------------

zhuabs &lt;- Zhu23ABS$new(
    width = 1, n_chains = 5, nd_time = 0.3, s_nd_time = 0.5, 
    lambda = 10, distr_name = 'norm', distr_params = 1
)


## ------------------------------------------------
## Method `Zhu23ABS$simulate`
## ------------------------------------------------


trial_stim &lt;- round(runif(5, 10, 50))
zhuabs$simulate(stopping_rule='fixed', n_sample = 5, trial_stim = trial_stim)
zhuabs$sim_results

zhuabs$reset_sim_results()
trial_stim &lt;- factor(sample(c('left', 'right'), 5, TRUE))
zhuabs$simulate(stopping_rule='relative', 
   delta = 4, dec_bdry = 0, 
   discrim = 1, trial_stim = trial_stim
)
zhuabs$sim_results


## ------------------------------------------------
## Method `Zhu23ABS$confidence_interval`
## ------------------------------------------------

zhuabs$confidence_interval(conf_level = 0.9)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
