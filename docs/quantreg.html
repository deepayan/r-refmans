<!DOCTYPE html><html><head><title>Help for package quantreg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {quantreg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#akj'><p>Density Estimation using Adaptive Kernel method</p></a></li>
<li><a href='#anova.rq'><p> Anova function for quantile regression fits</p></a></li>
<li><a href='#bandwidth.rq'><p> bandwidth selection for rq functions</p></a></li>
<li><a href='#barro'><p>Barro Data</p></a></li>
<li><a href='#boot.crq'><p> Bootstrapping Censored Quantile Regression</p></a></li>
<li><a href='#boot.rq'><p> Bootstrapping Quantile Regression</p></a></li>
<li><a href='#boot.rq.pwxy'>
<p>Preprocessing weighted bootstrap method</p></a></li>
<li><a href='#boot.rq.pxy'>
<p>Preprocessing bootstrap method</p></a></li>
<li><a href='#Bosco'><p>Boscovich Data</p></a></li>
<li><a href='#CobarOre'><p> Cobar Ore data</p></a></li>
<li><a href='#combos'><p>Ordered Combinations</p></a></li>
<li><a href='#critval'>
<p>Hotelling Critical Values</p></a></li>
<li><a href='#crq'><p>Functions to fit censored quantile regression models</p></a></li>
<li><a href='#dither'><p> Function to randomly perturb a vector</p></a></li>
<li><a href='#dynrq'><p>Dynamic Linear Quantile Regression</p></a></li>
<li><a href='#engel'><p>Engel Data</p></a></li>
<li><a href='#FAQ'><p>FAQ and ChangeLog  of a package</p></a></li>
<li><a href='#gasprice'><p>Time Series of US Gasoline Prices</p></a></li>
<li><a href='#KhmaladzeTest'><p> Tests of Location and Location Scale Shift Hypotheses for Linear Models</p></a></li>
<li><a href='#kuantile'><p>Quicker Sample Quantiles</p></a></li>
<li><a href='#LassoLambdaHat'><p>Lambda selection for QR lasso problems</p></a></li>
<li><a href='#latex'><p> Make a latex version of an R object</p></a></li>
<li><a href='#latex.summary.rqs'><p> Make a latex table from a table of rq results</p></a></li>
<li><a href='#latex.table'><p> Writes a latex formatted table to a file</p></a></li>
<li><a href='#lm.fit.recursive'><p> Recursive Least Squares</p></a></li>
<li><a href='#lprq'><p> locally polynomial quantile regression</p></a></li>
<li><a href='#Mammals'><p>Garland(1983) Data on Running Speed of Mammals</p></a></li>
<li><a href='#MelTemp'><p>Daily maximum temperatures in Melbourne, Australia</p></a></li>
<li><a href='#Munge'>
<p>Munge rqss formula</p></a></li>
<li><a href='#nlrq'><p> Function to compute nonlinear quantile regression estimates</p></a></li>
<li><a href='#nlrq.control'><p> Set control parameters for nlrq</p></a></li>
<li><a href='#ParetoTest'><p>Estimation and Inference on the Pareto Tail Exponent for Linear Models</p></a></li>
<li><a href='#Peirce'><p>C.S. Peirce's Auditory Response Data</p></a></li>
<li><a href='#plot.KhmaladzeTest'><p> Plot a KhmaladzeTest object</p></a></li>
<li><a href='#plot.rq'><p> plot the coordinates of the quantile regression process</p></a></li>
<li><a href='#plot.rqs'><p>Visualizing sequences of quantile regressions</p></a></li>
<li><a href='#plot.rqss'><p>Plot Method for rqss Objects</p></a></li>
<li><a href='#plot.summary.rqs'><p>Visualizing sequences of quantile regression summaries</p></a></li>
<li><a href='#predict.rq'><p>Quantile Regression Prediction</p></a></li>
<li><a href='#predict.rqss'><p>Predict from fitted nonparametric quantile regression smoothing spline models</p></a></li>
<li><a href='#print.KhmaladzeTest'><p> Print a KhmaladzeTest object</p></a></li>
<li><a href='#print.rq'><p> Print an rq object</p></a></li>
<li><a href='#print.summary.rq'><p> Print Quantile Regression Summary Object</p></a></li>
<li><a href='#q489'><p>Even Quicker Sample Quantiles</p></a></li>
<li><a href='#qrisk'><p> Function to compute Choquet portfolio weights</p></a></li>
<li><a href='#qss'><p>Additive Nonparametric Terms for rqss Fitting</p></a></li>
<li><a href='#QTECox'><p>Function to obtain QTE from a Cox model</p></a></li>
<li><a href='#ranks'>
<p>Quantile Regression Ranks</p></a></li>
<li><a href='#rearrange'><p>Rearrangement</p></a></li>
<li><a href='#residuals.nlrq'><p> Return residuals of an nlrq object</p></a></li>
<li><a href='#rq'>
<p>Quantile Regression</p></a></li>
<li><a href='#rq.fit'><p>Function to choose method for Quantile Regression</p></a></li>
<li><a href='#rq.fit.br'>
<p>Quantile Regression Fitting by Exterior Point Methods</p></a></li>
<li><a href='#rq.fit.conquer'><p>Optional Fitting Method for Quantile Regression</p></a></li>
<li><a href='#rq.fit.fnb'>
<p>Quantile Regression Fitting via Interior Point Methods</p></a></li>
<li><a href='#rq.fit.fnc'>
<p>Quantile Regression Fitting via Interior Point Methods</p></a></li>
<li><a href='#rq.fit.hogg'><p>weighted quantile regression fitting</p></a></li>
<li><a href='#rq.fit.lasso'>
<p>Lasso Penalized Quantile Regression</p></a></li>
<li><a href='#rq.fit.pfn'><p> Preprocessing Algorithm for Quantile Regression</p></a></li>
<li><a href='#rq.fit.pfnb'>
<p>Quantile Regression Fitting via Interior Point Methods</p></a></li>
<li><a href='#rq.fit.ppro'>
<p>Preprocessing fitting method for QR</p></a></li>
<li><a href='#rq.fit.qfnb'>
<p>Quantile Regression Fitting via Interior Point Methods</p></a></li>
<li><a href='#rq.fit.scad'>
<p>SCADPenalized Quantile Regression</p></a></li>
<li><a href='#rq.fit.sfn'><p>Sparse Regression Quantile Fitting</p></a></li>
<li><a href='#rq.fit.sfnc'><p>Sparse Constrained Regression Quantile Fitting</p></a></li>
<li><a href='#rq.object'>
<p>Linear Quantile Regression Object</p></a></li>
<li><a href='#rq.process.object'>
<p>Linear Quantile Regression Process Object</p></a></li>
<li><a href='#rq.wfit'><p>Function to choose method for Weighted Quantile Regression</p></a></li>
<li><a href='#rqProcess'><p> Compute Standardized Quantile Regression Process</p></a></li>
<li><a href='#rqs.fit'><p>Function to fit multiple response quantile regression models</p></a></li>
<li><a href='#rqss'><p>Additive Quantile Regression Smoothing</p></a></li>
<li><a href='#rqss.object'><p>RQSS Objects and Summarization Thereof</p></a></li>
<li><a href='#sfn.control'><p>Set Control Parameters for Sparse Fitting</p></a></li>
<li><a href='#srisk'><p> Markowitz (Mean-Variance) Portfolio Optimization</p></a></li>
<li><a href='#summary.crq'>
<p>Summary methods for Censored Quantile Regression</p></a></li>
<li><a href='#summary.rq'>
<p>Summary methods for Quantile Regression</p></a></li>
<li><a href='#summary.rqss'><p>Summary of rqss fit</p></a></li>
<li><a href='#table.rq'>
<p>Table of Quantile Regression Results</p></a></li>
<li><a href='#uis'><p>UIS Drug Treatment study data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Quantile Regression</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimation and inference methods for models for conditional quantile functions: 
  Linear and nonlinear parametric and non-parametric (total variation penalized) models 
  for conditional quantiles of a univariate response and several methods for handling
  censored survival data.  Portfolio selection methods based on expected shortfall
  risk are also now included. See Koenker, R. (2005) Quantile Regression, Cambridge U. Press,
  &lt;<a href="https://doi.org/10.1017%2FCBO9780511754098">doi:10.1017/CBO9780511754098</a>&gt; and Koenker, R. et al. (2017) Handbook of Quantile Regression, 
  CRC Press, &lt;<a href="https://doi.org/10.1201%2F9781315120256">doi:10.1201/9781315120256</a>&gt;. </td>
</tr>
<tr>
<td>Version:</td>
<td>5.97</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Roger Koenker &lt;rkoenker@illinois.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5), stats, SparseM</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, graphics, Matrix, MatrixModels, survival, MASS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>interp, rgl, logspline, nor1mix, Formula, zoo, R.rsp, conquer</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.r-project.org">https://www.r-project.org</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-19 12:48:42 UTC; roger</td>
</tr>
<tr>
<td>Author:</td>
<td>Roger Koenker [cre, aut],
  Stephen Portnoy [ctb] (Contributions to Censored QR code),
  Pin Tian Ng [ctb] (Contributions to Sparse QR code),
  Blaise Melly [ctb] (Contributions to preprocessing code),
  Achim Zeileis [ctb] (Contributions to dynrq code essentially identical to his
    dynlm code),
  Philip Grosjean [ctb] (Contributions to nlrq code),
  Cleve Moler [ctb] (author of several linpack routines),
  Yousef Saad [ctb] (author of sparskit2),
  Victor Chernozhukov [ctb] (contributions to extreme value inference code),
  Ivan Fernandez-Val [ctb] (contributions to extreme value inference code),
  Brian D Ripley [trl, ctb] (Initial (2001) R port from S (to my everlasting shame
    -- how could I have been so slow to adopt R!) and for numerous other
    suggestions and useful advice)</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-19 13:50:05 UTC</td>
</tr>
<tr>
<td>Built:</td>
<td>R 4.4.0; x86_64-pc-linux-gnu; 2024-01-02 07:51:43 UTC; unix</td>
</tr>
</table>
<hr>
<h2 id='akj'>Density Estimation using Adaptive Kernel method</h2><span id='topic+akj'></span>

<h3>Description</h3>

<p>Univariate <em>adaptive</em> kernel density estimation a la Silverman.
As used by Portnoy and Koenker (1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>akj(x, z =, p =, h = -1, alpha = 0.5, kappa = 0.9, iker1 = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="akj_+3A_x">x</code></td>
<td>
<p>points used for centers of kernel assumed to be sorted.</p>
</td></tr>
<tr><td><code id="akj_+3A_z">z</code></td>
<td>
<p>points at which density is calculated; defaults to an
equispaced sequence covering the range of x.</p>
</td></tr>
<tr><td><code id="akj_+3A_p">p</code></td>
<td>
<p>vector of probabilities associated with <code>x</code>s; defaults
to 1/n for each x.</p>
</td></tr>
<tr><td><code id="akj_+3A_h">h</code></td>
<td>
<p>initial window size (overall); defaults to Silverman's normal
reference.</p>
</td></tr>
<tr><td><code id="akj_+3A_alpha">alpha</code></td>
<td>
<p>a sensitivity parameter that determines the sensitivity of
the local bandwidth to variations in the pilot density; defaults to .5.</p>
</td></tr>
<tr><td><code id="akj_+3A_kappa">kappa</code></td>
<td>
<p>constant multiplier for initial (default) window width</p>
</td></tr>
<tr><td><code id="akj_+3A_iker1">iker1</code></td>
<td>
<p>integer kernel indicator: 0 for normal kernel (default)
while 1 for Cauchy kernel (<code><a href="stats.html#topic+dcauchy">dcauchy</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+list">list</a></code> structure is with components
</p>
<table>
<tr><td><code>dens</code></td>
<td>
<p>the vector of estimated density values <code class="reqn">f(z)</code></p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>a vector of <code class="reqn">\psi=-f'/f</code> function values.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>a vector of score <code class="reqn">\psi' = (f'/f)^2 - f''/f</code> function
values.</p>
</td></tr>
<tr><td><code>h</code></td>
<td>
<p>same as the input argument h</p>
</td></tr>
</table>


<h3>Note</h3>

<p>if the <code>score</code> function values are of interest, the Cauchy kernel
may be preferable.
</p>


<h3>References</h3>

<p>Portnoy, S and R Koenker, (1989)
Adaptive L Estimation of Linear Models;
<em>Annals of Statistics</em> <b>17</b>, 362&ndash;81.
</p>
<p>Silverman, B. (1986)
<em>Density Estimation</em>, pp 100&ndash;104.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> set.seed(1)
 x &lt;- c(rnorm(600), 2 + 2*rnorm(400))
 xx &lt;- seq(-5, 8, length=200)
 z &lt;- akj(x, xx)
 plot(xx, z$dens, ylim=range(0,z$dens), type ="l", col=2)
 abline(h=0, col="gray", lty=3)
 plot(xx, z$psi, type ="l", col=2, main = expression(hat(psi(x))))
 plot(xx, z$score, type ="l", col=2,
      main = expression("score " * hat(psi) * "'" * (x)))

 if(require("nor1mix")) {
  m3 &lt;- norMix(mu= c(-4, 0, 3), sig2 = c(1/3^2, 1, 2^2),
               w = c(.1,.5,.4))
  plot(m3, p.norm = FALSE)
  set.seed(11)
  x &lt;- rnorMix(1000, m3)
  z2 &lt;- akj(x, xx)
  lines(xx, z2$dens, col=2)
  z3 &lt;- akj(x, xx, kappa = 0.5, alpha = 0.88)
  lines(xx, z3$dens, col=3)
 }
</code></pre>

<hr>
<h2 id='anova.rq'> Anova function for quantile regression fits </h2><span id='topic+anova.rq'></span><span id='topic+anova.rqs'></span><span id='topic+anova.rqlist'></span><span id='topic+print.anova.rq'></span><span id='topic+rq.test.rank'></span><span id='topic+rq.test.anowar'></span>

<h3>Description</h3>

<p>Compute test statistics for two or more quantile regression fits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq'
anova(object, ..., test = "Wald", joint = TRUE, score =
                       "tau", se = "nid", iid = TRUE, R = 200, trim = NULL)
## S3 method for class 'rqs'
anova(object, ..., se = "nid", iid = TRUE, joint = TRUE)
## S3 method for class 'rqlist'
anova(object, ...,  test = "Wald", joint = TRUE, 
	score = "tau", se = "nid", iid = TRUE, R = 200, trim = NULL)
rq.test.rank(x0, x1, y, v = NULL, score = "wilcoxon", weights = NULL, tau=.5,
        iid = TRUE, delta0 = rep(0,NCOL(x1)), omega = 1, trim = NULL, pvalue = "F")
rq.test.anowar(x0,x1,y,tau,R)
## S3 method for class 'anova.rq'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.rq_+3A_object">object</code>, <code id="anova.rq_+3A_...">...</code></td>
<td>
<p>objects of class &lsquo;rq&rsquo;, originating from a call to &lsquo;rq&rsquo;. 
or a single object of class rqs, originating from a call to 'rq' with
multiple taus specified.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_test">test</code></td>
<td>
<p> A character string specifying the test statistic to use.
Can be either &lsquo;Wald&rsquo; or &lsquo;rank&rsquo;.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_joint">joint</code></td>
<td>
<p>A logical flag indicating whether tests of equality of slopes
should be done as joint tests on all slope parameters, or whether
(when joint = FALSE) separate tests on each of the slope parameters
should be reported.  This option applies only to the tests of 
equality of slopes in the case that estimated models correspond
to distinct taus.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_score">score</code></td>
<td>
<p> A character string specifying the score function to use,
only needed or applicable for the &lsquo;rank&rsquo; form of the test.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_trim">trim</code></td>
<td>
<p>optional trimming proportion parameter(s)  &ndash; only applicable for the
Wilcoxon score function &ndash;  when one value is provided there is symmetric
trimming of the score integral to the interval <code>(trim, 1-trim)</code>, when
there are two values provided, then the trimming restricts the integration
to <code>(trim[1], trim[2])</code>.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_x">x</code></td>
<td>
<p> objects of class &lsquo;summary.rq&rsquo;, originating from a call to &lsquo;summary&rsquo;. </p>
</td></tr>
<tr><td><code id="anova.rq_+3A_x0">x0</code></td>
<td>
<p>design matrix for the null component of the rank and anowar tests. </p>
</td></tr>
<tr><td><code id="anova.rq_+3A_x1">x1</code></td>
<td>
<p>design matrix for the alternative component of the rank and anowar tests. </p>
</td></tr>
<tr><td><code id="anova.rq_+3A_y">y</code></td>
<td>
<p>response vector for the alternative component of the rank and anowar tests. </p>
</td></tr>
<tr><td><code id="anova.rq_+3A_v">v</code></td>
<td>
<p>optional rq process fit</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_se">se</code></td>
<td>
<p>method for computing standard errors, either &quot;nid&quot; or &quot;ker&quot;, note 
that &quot;boot&quot; cannot be used for testing homogeneity of slopes.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_tau">tau</code></td>
<td>
<p>quantile of interest for quantile specific forms of testing.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_iid">iid</code></td>
<td>
<p>logical flag for quantile specific forms of testing, if TRUE the
test presumes that the conditional densities take identical values,
if it is FALSE then local densities are estimated and used, see Koenker(2005)
p. 90.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_delta0">delta0</code></td>
<td>
<p>vector of hypothetical parameter values under test, typically zeros
but can be specified to be nonzero in cases where simulations are being used
to evaluate the validity of the non-central chisquare theory of the test.</p>
</td></tr> 
<tr><td><code id="anova.rq_+3A_omega">omega</code></td>
<td>
<p>value to be used for the score and F dependent constant appearing
in the non-centrality parameter,  this is only needed/useful when delta0
is specified to be non-zero.  In the usual Wilcoxon (untrimmed) case this
value is the integral the squared density.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_pvalue">pvalue</code></td>
<td>
<p>type of p-value to be used, by default a pseudo F-statistic is
produced and the corresponding F p-value is computed, otherwise the
more conventional chisquared p-values are reported.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_weights">weights</code></td>
<td>
<p>optional weight vector to be used for fitting.</p>
</td></tr>
<tr><td><code id="anova.rq_+3A_r">R</code></td>
<td>
<p> The number of resampling replications for the anowar form of the test, 
used to estimate the reference distribution for the test statistic.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two (as yet) distinct forms of the test.  In the first the
fitted objects all have the same specified quantile (tau) and the intent
is to test the hypothesis that smaller models are adequate relative to
the largest specified model.  In the second form of the test the linear predictor 
of the fits are all the same, but the specified quantiles (taus) are different.  
</p>
<p>In the former case there are three options for
the argument &lsquo;test&rsquo;, by default a Wald test is computed as in 
Bassett and Koenker (1982).  If <code>test = 'anowar'</code> is specified
then the test is based on the procedure suggested in Chen, Ying, Zhang
and Zhao (2008); the test is based on the difference in the QR objective
functions at the restricted and unrestricted models with a reference
distribution computed by simulation.  The p-value of this form of the
test is produced by fitting a density to the simulation values forming
the reference distribution using the <code>logspline</code> function from
the <span class="pkg">logspline</span> package.  The acronym anowar stands for  analysis
of weighted absolute residuals.  If <code>test='rank'</code> is specified, then a rank
test statistic is computed as described in Gutenbrunner, Jureckova,
Koenker and Portnoy (1993).  In the latter case one can also specify
a form for the score function of the rank test, by default the Wilcoxon
score is used, the other options are score=&lsquo;sign&rsquo; for median (sign) scores,
or score=&lsquo;normal&rsquo; for normal (van der Waerden) scores.  A fourth option
is score=&lsquo;tau&rsquo; which is a generalization of median scores to an arbitrary
quantile, in this case the quantile is assumed to be the one associated
with the fitting of the specified objects.  The computing of
the rank form of the test is carried out in the <code><a href="quantreg.html#topic+rq.test.rank">rq.test.rank</a></code>
function, see <code><a href="quantreg.html#topic+ranks">ranks</a></code> for further details on the score function
options.  The Wald form of the test is local in sense that the null hypothesis
asserts only that a subset of the covariates are &ldquo;insignificant&rdquo; at
the specified quantile of interest.  The rank form of the test can also be
used to test the global hypothesis that a subset is &ldquo;insignificant&rdquo;
over an entire range of quantiles.  The use of the score function
score = &quot;tau&quot; restricts the rank test to the local hypothesis of
the Wald test.  
</p>
<p>In the latter case the hypothesis of interest is that the slope coefficients of
the models are identical.  The test statistic is a variant of the Wald 
test described in Koenker and Bassett (1982).
</p>
<p>By default, both forms of the tests return an F-like statistic in the sense that the
an asymptotically Chi-squared statistic is divided by its degrees of
freedom and the reported p-value is computed for an F statistic based on 
the numerator degrees of freedom equal to the rank of the null hypothesis and
the denominator degrees of freedom is taken to be the sample size
minus the number of parameters of the maintained model.
</p>


<h3>Value</h3>

<p>An object of class &lsquo;&quot;anova&quot;&rsquo; inheriting from class &lsquo;&quot;data.frame&quot;&rsquo;.
</p>


<h3>WARNING </h3>

<p>An attempt to verify that the models are nested in the first form
of the test is made, but this relies on checking set inclusion of
the list of variable names and is subject to obvious ambiguities
when variable names are generic.
The comparison between two or more models will only be valid if
they are fitted to the same dataset. This may be a problem if
there are missing values and R's default of &lsquo;na.action = na.omit&rsquo; is used. 
The rank version of the nested model tests involves computing the entire
regression quantile process using parametric linear programming and thus
can be rather slow and memory intensive on problems with more than 
several thousand observations.</p>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p>[1] Bassett, G. and R. Koenker  (1982). Tests of Linear Hypotheses
and L1 Estimation,
<em>Econometrica</em>, <b>50</b>, 1577&ndash;83.
</p>
<p>[2] Koenker, R. W. and Bassett, G. W. (1982). Robust Tests for
Heteroscedasticity based on Regression Quantiles,
<em>Econometrica</em>, <b>50</b>, 43&ndash;61.
</p>
<p>[3] Gutenbrunner, C., Jureckova, J., Koenker, R, and S. Portnoy  (1993).
Tests of Linear Hypotheses based on Regression Rank Scores,
<em>J. of Nonparametric Statistics</em>, <b>2</b>, 307&ndash;331.
</p>
<p>[4] Chen, K. Z. Ying, H. Zhang, and L Zhao, (2008) Analysis of least absolute
deviations, Biometrika, 95, 107-122.
</p>
<p>[5] Koenker, R. W. (2005).  Quantile Regression, Cambridge U. Press. 
</p>


<h3>See Also</h3>

<p>The model fitting function  <code><a href="quantreg.html#topic+rq">rq</a></code>, 
and the functions for testing hypothesis on the entire quantile
regression process <code><a href="quantreg.html#topic+KhmaladzeTest">KhmaladzeTest</a></code>.  For further details
on the rank tests see <code><a href="quantreg.html#topic+ranks">ranks</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(barro)
fit0 &lt;- rq(y.net ~  lgdp2 + fse2 + gedy2 , data = barro)
fit1 &lt;- rq(y.net ~  lgdp2 + fse2 + gedy2 + Iy2 + gcony2, data = barro)
fit2 &lt;- rq(y.net ~  lgdp2 + fse2 + gedy2 + Iy2 + gcony2, data = barro,tau=.75)
fit3 &lt;- rq(y.net ~  lgdp2 + fse2 + gedy2 + Iy2 + gcony2, data = barro,tau=.25)
anova(fit1,fit0)
anova(fit1,fit2,fit3)
anova(fit1,fit2,fit3,joint=FALSE)
# Alternatively fitting can be done in one call:
fit &lt;- rq(y.net ~  lgdp2 + fse2 + gedy2 + Iy2 + gcony2, 
	  method = "fn", tau = 1:4/5, data = barro)
</code></pre>

<hr>
<h2 id='bandwidth.rq'> bandwidth selection for rq functions </h2><span id='topic+bandwidth.rq'></span>

<h3>Description</h3>

<p>function to compute bandwidth for sparsity estimation 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bandwidth.rq(p, n, hs=TRUE, alpha=0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bandwidth.rq_+3A_p">p</code></td>
<td>
<p> quantile(s) of interest </p>
</td></tr>
<tr><td><code id="bandwidth.rq_+3A_n">n</code></td>
<td>
<p> sample size </p>
</td></tr>
<tr><td><code id="bandwidth.rq_+3A_hs">hs</code></td>
<td>
<p> flag for hall-sheather method </p>
</td></tr>
<tr><td><code id="bandwidth.rq_+3A_alpha">alpha</code></td>
<td>
<p> alpha level for intended confidence intervals </p>
</td></tr>
</table>


<h3>Details</h3>

<p> If hs=TRUE (default) then the Hall-Sheather(1988) rule <code class="reqn">O(n^{-1/3})</code>
is used, if hs=FALSE then the Bofinger <code class="reqn">O(n^{-1/5})</code> is used.
</p>


<h3>Value</h3>

<p>returns a vector of bandwidths corresponding to the argument p.
</p>


<h3>Author(s)</h3>

<p> Roger Koenker rkoenker@uiuc.edu</p>


<h3>References</h3>

<p> Hall and Sheather(1988, JRSS(B)),Bofinger (1975, Aus. J. Stat)</p>

<hr>
<h2 id='barro'>Barro Data</h2><span id='topic+barro'></span>

<h3>Description</h3>

<p>Version of the Barro Growth Data used in Koenker and Machado(1999).
This is a regression data set consisting of 161 observations on determinants
of cross country GDP growth rates. There are 13 covariates with dimnames
corresponding to the original Barro and Lee source.  See
https://www.nber.org/pub/barro.lee/.  The first 71 observations are on
the period 1965-75, remainder on 1987-85.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(barro)</code></pre>


<h3>Format</h3>

<p>A data frame containing 161 observations on 14 variables:
</p>

<table>
<tr>
 <td style="text-align: right;">
        [,1] </td><td style="text-align: left;"> "Annual Change Per Capita GDP"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,2] </td><td style="text-align: left;"> "Initial Per Capita GDP"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,3] </td><td style="text-align: left;"> "Male Secondary Education"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,4] </td><td style="text-align: left;"> "Female Secondary Education"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,5] </td><td style="text-align: left;"> "Female Higher Education"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,6] </td><td style="text-align: left;"> "Male Higher Education"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,7] </td><td style="text-align: left;"> "Life Expectancy"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,8] </td><td style="text-align: left;"> "Human Capital"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,9] </td><td style="text-align: left;"> "Education/GDP"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,10] </td><td style="text-align: left;"> "Investment/GDP"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,11] </td><td style="text-align: left;"> "Public Consumption/GDP"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,12] </td><td style="text-align: left;"> "Black Market Premium"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,13] </td><td style="text-align: left;"> "Political Instability"</td>
</tr>
<tr>
 <td style="text-align: right;">
        [,14] </td><td style="text-align: left;"> "Growth Rate Terms Trade"</td>
</tr>

</table>



<h3>References</h3>

<p>Koenker, R. and J.A.F. Machado (1999) Goodness of Fit and Related Inference Processes for Quantile Regression, JASA, 1296-1310.</p>

<hr>
<h2 id='boot.crq'> Bootstrapping Censored Quantile Regression</h2><span id='topic+boot.crq'></span>

<h3>Description</h3>

<p>Functions used to estimated standard errors, confidence
intervals and tests of hypotheses for censored quantile regression models
using the Portnoy and Peng-Huang methods.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.crq(x, y, c, taus, method, ctype = "right", R = 100, mboot, bmethod = "jack", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.crq_+3A_x">x</code></td>
<td>
<p> The regression design matrix</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_y">y</code></td>
<td>
<p> The regression response vector</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_c">c</code></td>
<td>
<p> The censoring indicator</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_taus">taus</code></td>
<td>
<p> The quantiles of interest</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_method">method</code></td>
<td>
<p> The fitting method: either &quot;P&quot; for Portnoy or &quot;PH&quot; for Peng and Huang.</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_ctype">ctype</code></td>
<td>
<p> Either &quot;right&quot; or &quot;left&quot;</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_r">R</code></td>
<td>
<p> The number of bootstrap replications</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_bmethod">bmethod</code></td>
<td>
<p> The bootstrap method to be employed.  There are (as yet) three
options:  method  = &quot;jack&quot; uses the delete-d jackknife method
described by Portnoy (2013), method = &quot;xy-pair&quot; uses the xy-pair method, 
that is the usual multinomial resampling of xy-pairs, while  method
= &quot;Bose&quot; uses the Bose and Chatterjee (2003) weighted resampling
method with exponential weights.  The &quot;jack&quot; method is now the default.</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_mboot">mboot</code></td>
<td>
<p> optional argument for the bootstrap method:  for bmethod = &quot;jack&quot;
it specifies the number, d, of the delete-d jackknife, for 
method = &quot;xy-pair&quot; it specifies the size of the bootstrap samples,
that permits subsampling (m out of n) bootstrap.  By default in the
former case it is set to 2 [sqrt(n)], for the latter the default is
n.  Obviously mboot should be substantially larger than the column dimension 
of x, and should be less than the sample size in both cases.</p>
</td></tr>
<tr><td><code id="boot.crq_+3A_...">...</code></td>
<td>
<p> Optional further arguments to control bootstrapping</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are several refinements that are still unimplemented.  Percentile
methods should be incorporated, and extensions of the methods to be used 
in anova.rq should be made.  Note that bootstrapping for the Powell 
method &quot;Powell&quot; is done via <code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code>.  For problems with
<code>n &gt; 3000</code> a message is printed indicated progress in the resampling.
</p>


<h3>Value</h3>

<p>A matrix of dimension R by p is returned with the R resampled
estimates of the vector of quantile regression parameters. When
mofn &lt; n for the &quot;xy&quot; method this matrix has been deflated by
the factor sqrt(m/n)
</p>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

 
<p>Bose, A. and S. Chatterjee, (2003) Generalized bootstrap for estimators
of minimizers of convex functions, <em>J. Stat. Planning and Inf</em>, 117,
225-239.
Portnoy, S. (2013) The Jackknife's Edge:  Inference for Censored Quantile Regression,
<em>CSDA</em>, forthcoming.
</p>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+summary.crq">summary.crq</a></code></p>

<hr>
<h2 id='boot.rq'> Bootstrapping Quantile Regression</h2><span id='topic+boot.rq'></span><span id='topic+boot.rq.xy'></span><span id='topic+boot.rq.wxy'></span><span id='topic+boot.rq.pwy'></span><span id='topic+boot.rq.spwy'></span><span id='topic+boot.rq.mcmb'></span>

<h3>Description</h3>

<p>These functions can be used to construct standard errors, confidence
intervals and tests of hypotheses regarding quantile regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.rq(x, y, tau = 0.5, R = 200, bsmethod = "xy", mofn = length(y), 
	coef = NULL, blbn = NULL, cluster = NULL, U = NULL,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.rq_+3A_x">x</code></td>
<td>
<p> The regression design matrix</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_y">y</code></td>
<td>
<p> The regression response vector</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_tau">tau</code></td>
<td>
<p> The quantile of interest</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_r">R</code></td>
<td>
<p> The number of bootstrap replications</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_bsmethod">bsmethod</code></td>
<td>
<p> The method to be employed.  There are (as yet) five
options:  method = &quot;xy&quot; uses the xy-pair method, and
method = &quot;pwy&quot; uses the method of Parzen, Wei and Ying (1994)
method = &quot;mcmb&quot; uses the Markov chain marginal bootstrap
of He and Hu (2002) and Kocherginsky, He and Mu (2003).
The &quot;mcmb&quot; method isn't compatible with sparse X matrices.
The fourth method = &quot;wxy&quot; uses the generalized bootstrap
of Bose and Chatterjee (2003) with unit exponential weights,
see also Chamberlain and Imbens (2003).  The fifth method
&quot;wild&quot; uses the wild bootstrap method proposed by Feng, He and Hu (2011). </p>
</td></tr>
<tr><td><code id="boot.rq_+3A_mofn">mofn</code></td>
<td>
<p> optional argument for the bootstrap method &quot;xy&quot; that
permits subsampling (m out of n) bootstrap.  Obviously mofn
should be substantially larger than the column dimension of x,
and should be less than the sample size.</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_coef">coef</code></td>
<td>
<p>coefficients from initial fitted object</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_blbn">blbn</code></td>
<td>
<p>orginal sample size for the BLB model</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_cluster">cluster</code></td>
<td>
<p>If non-NULL this argument should specify cluster id
numbers for each observation, in which case the clustered version of 
the bootstrap based on the proposal of Hagemann (2017). If present
<code>bsmethod</code> is set to set to &quot;cluster&quot;. If this option is used
and the fitting method for the original call was &quot;sfn&quot; then the
bootstrapping will be carried out with the &quot;sfn&quot; as well.  This
is usually substantially quicker than the older version which
employed the &quot;br&quot; variant of the simplex method.  Use of &quot;sfn&quot;
also applies to the &quot;pwy&quot; method when the original fitting 
was done with &quot;sfn&quot;.  Finally, if <code>na.action = "omit"</code> and
<code>length(object$na.action) &gt; 0</code> then these elements are also
removed from the <code>cluster</code> variable.  Consequently, the 
length of the <code>cluster</code> variable should always be the same
as the length of the original response variable before any 
<code>na.action</code> takes place.  </p>
</td></tr>
<tr><td><code id="boot.rq_+3A_u">U</code></td>
<td>
<p>If non-NULL this argument should specify an array of indices
or gradient evaluations to be used by the corresponding bootstrap
method as specified by <code>bsmethod</code>.  This is NOT intended as
a user specified input, instead it is specified in <code>summary.rqs</code>
to ensure that bootstrap samples for multiple taus use the same
realizations of the random sampling.</p>
</td></tr>
<tr><td><code id="boot.rq_+3A_...">...</code></td>
<td>
<p> Optional arguments to control bootstrapping</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Their are several refinements that are still unimplemented.  Percentile
methods should be incorporated, and extensions of the methods to be used 
in anova.rq should be made.  And more flexibility about what algorithm is
used would also be good. 
</p>


<h3>Value</h3>

<p>A list consisting of two elements:
A matrix <code>B</code> of dimension R by p is returned with the R resampled
estimates of the vector of quantile regression parameters. When
mofn &lt; n for the &quot;xy&quot; method this matrix has been deflated by
the factor sqrt(m/n).
A matrix <code>U</code> of sampled indices (for <code>bsmethod in c("xy", "wxy")</code>) 
or gradient evaluations (for <code>bsmethod in c("pwy", "cluster")</code>)
used to generate the bootstrapped realization, and potentially reused
for other <code>taus</code> when invoked from <code>summary.rqs</code>.
</p>


<h3>Author(s)</h3>

<p> Roger Koenker (and Xuming He and M. Kocherginsky for the mcmb code)</p>


<h3>References</h3>

 
<p>[1] Koenker, R. W. (1994). Confidence Intervals for regression quantiles, in
P. Mandl and M. Huskova (eds.), <em>Asymptotic Statistics</em>, 349&ndash;359,
Springer-Verlag, New York.
</p>
<p>[2] Kocherginsky, M., He, X. and Mu, Y. (2005).
Practical Confidence Intervals for Regression Quantiles,
Journal of Computational and Graphical Statistics, 14, 41-55.
</p>
<p>[3] Hagemann, A. (2017) Cluster Robust Bootstrap inference in 
quantile regression models, Journal of the American Statistical Association , 
112, 446&ndash;456.
</p>
<p>[4] He, X. and Hu, F. (2002). Markov Chain Marginal Bootstrap.
Journal of the American Statistical Association , Vol. 97, no. 459,
783-795. 
</p>
<p>[5] Parzen, M. I., L. Wei,  and Z. Ying  (1994): A resampling
method based on pivotal estimating functions,&rdquo; Biometrika, 81, 341&ndash;350.
</p>
<p>[6] Bose, A. and S. Chatterjee, (2003) Generalized bootstrap for estimators
of minimizers of convex functions, <em>J. Stat. Planning and Inf</em>, 117, 225-239.
</p>
<p>[7]  Chamberlain G.  and Imbens G.W.  (2003) Nonparametric Applications of 
Bayesian Inference, Journal of Business &amp; Economic Statistics, 21, pp. 12-18.
</p>
<p>[8]  Feng, Xingdong, Xuming He, and Jianhua Hu (2011) Wild Bootstrap for
Quantile Regression, Biometrika, 98, 995&ndash;999. 
</p>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(50)
x &lt;- matrix(rnorm(100),50)
fit &lt;- rq(y~x,tau = .4)
summary(fit,se = "boot", bsmethod= "xy")
summary(fit,se = "boot", bsmethod= "pwy")
#summary(fit,se = "boot", bsmethod= "mcmb")
</code></pre>

<hr>
<h2 id='boot.rq.pwxy'>
Preprocessing weighted bootstrap method
</h2><span id='topic+boot.rq.pwxy'></span>

<h3>Description</h3>

<p>Bootstrap method exploiting preprocessing strategy to reduce 
computation time for large problem.  In contrast to 
<code><a href="quantreg.html#topic+boot.rq.pxy">boot.rq.pxy</a></code>  which uses the classical multinomial 
sampling scheme and is coded in R, this uses the exponentially
weighted bootstrap scheme and is coded in fortran and consequently
is considerably faster in larger problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.rq.pwxy(x, y, tau, coef, R = 200, m0 = NULL, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.rq.pwxy_+3A_x">x</code></td>
<td>

<p>Design matrix
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_y">y</code></td>
<td>

<p>response vector
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_tau">tau</code></td>
<td>

<p>quantile of interest
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_coef">coef</code></td>
<td>

<p>point estimate of fitted object
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_r">R</code></td>
<td>

<p>the number of bootstrap replications desired.
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_m0">m0</code></td>
<td>

<p>constant to determine initial sample size, defaults to sqrt(n*p)
but could use some further tuning...
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_eps">eps</code></td>
<td>

<p>tolerance for convergence of fitting algorithm
</p>
</td></tr>
<tr><td><code id="boot.rq.pwxy_+3A_...">...</code></td>
<td>

<p>other parameters not yet envisaged.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fortran implementation is quite similar to the R code for 
<code><a href="quantreg.html#topic+boot.rq.pxy">boot.rq.pxy</a></code> except that there is no multinomial sampling.
Instead <code>rexp(n)</code> weights are used.
</p>


<h3>Value</h3>

<p>returns a list with elements: 
</p>

<ol>
<li><p>coefficientsa matrix of dimension ncol(x) by R
</p>
</li>
<li><p>nit a 5 by m matrix of iteration counts
</p>
</li>
<li><p>info an m-vector of convergence flags
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Blaise Melly and Roger Koenker
</p>


<h3>References</h3>

<p>Chernozhukov, V.  I. Fernandez-Val and B. Melly,
Fast Algorithms for the Quantile Regression Process, 2019,
arXiv, 1909.05782,
</p>
<p>Portnoy, S.  and R. Koenker, The Gaussian Hare and the Laplacian
Tortoise, Statistical Science, (1997) 279-300
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+boot.rq.pxy">boot.rq.pxy</a></code>
</p>

<hr>
<h2 id='boot.rq.pxy'>
Preprocessing bootstrap method
</h2><span id='topic+boot.rq.pxy'></span>

<h3>Description</h3>

<p>Bootstrap method exploiting preprocessing strategy to reduce 
computation time for large problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.rq.pxy(x, y, s, tau = 0.5, coef, method = "fn", Mm.factor = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.rq.pxy_+3A_x">x</code></td>
<td>

<p>Design matrix
</p>
</td></tr>
<tr><td><code id="boot.rq.pxy_+3A_y">y</code></td>
<td>

<p>response vector
</p>
</td></tr>
<tr><td><code id="boot.rq.pxy_+3A_s">s</code></td>
<td>

<p>matrix of multinomial draws for xy bootstrap
</p>
</td></tr>
<tr><td><code id="boot.rq.pxy_+3A_tau">tau</code></td>
<td>

<p>quantile of interest
</p>
</td></tr>
<tr><td><code id="boot.rq.pxy_+3A_coef">coef</code></td>
<td>

<p>point estimate of fitted object
</p>
</td></tr>
<tr><td><code id="boot.rq.pxy_+3A_method">method</code></td>
<td>

<p>fitting method for bootstrap
</p>
</td></tr>
<tr><td><code id="boot.rq.pxy_+3A_mm.factor">Mm.factor</code></td>
<td>

<p>constant to determine initial sample size
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See references for further details.
</p>


<h3>Value</h3>

<p>Returns matrix of bootstrap estimates.
</p>


<h3>Author(s)</h3>

<p>Blaise Melly and Roger Koenker
</p>


<h3>References</h3>

<p>Chernozhukov, V.  I. Fernandez-Val and B. Melly,
Fast Algorithms for the Quantile Regression Process, 2019,
arXiv, 1909.05782,
</p>
<p>Portnoy, S.  and R. Koenker, The Gaussian Hare and the Laplacian
Tortoise, Statistical Science, (1997) 279-300
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq.fit.ppro">rq.fit.ppro</a></code>
</p>

<hr>
<h2 id='Bosco'>Boscovich Data</h2><span id='topic+Bosco'></span>

<h3>Description</h3>

<p>Boscovich data used to estimate the ellipticity of the earth.
There are five measurements of the arc length of one degree of 
latitude taken at 5 different latitudes.  See Koenker (2005) for
further details and references.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Bosco)</code></pre>


<h3>Format</h3>

<p>A data frame containing 5 observations on 2 variables
</p>

<dl>
<dt>x</dt><dd><p>sine squared of latitude measured in degrees</p>
</dd>
<dt>y</dt><dd><p>arc length of one degree of latitude measured in toise - 56,700,
one toise approximately equals 1.95 meters. </p>
</dd>
</dl>



<h3>References</h3>

<p>Koenker, R. (2005), &quot;Quantile Regression&quot;, Cambridge.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Bosco)
plot(0:10/10,0:10*100,xlab="sin^2(latitude)",
        ylab="arc-length of 1 degree of latitude",type="n")
points(Bosco)
text(Bosco, pos = 3, rownames(Bosco))
z &lt;- rq(y ~ x, tau = -1, data = Bosco)
title("Boscovitch Ellipticity of the Earth Example")
xb &lt;- c(.85,.9,.6,.6)
yb &lt;- c(400,600,450,600)
for(i in 1:4){
        abline(c(z$sol[4:5,i]))
        interval &lt;- paste("t=(",format(round(z$sol[1,i],2)),",",
                format(round(z$sol[1,i+1],2)),")",delim="")
        text(xb[i],yb[i],interval)
        }
</code></pre>

<hr>
<h2 id='CobarOre'> Cobar Ore data </h2><span id='topic+CobarOre'></span>

<h3>Description</h3>

<p>Cobar Ore data from Green and Silverman (1994). 
The data consists of measurements on the &quot;true width&quot;
of an ore-bearing rock layer from a mine in Cobar, Australia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CobarOre)</code></pre>


<h3>Format</h3>

<p>A data frame with 38 observations on the following 3 variables.
</p>

<dl>
<dt>x</dt><dd><p>x-coordinate of location of mine site</p>
</dd>
<dt>y</dt><dd><p>y-coordinate of location of mine site</p>
</dd>
<dt>z</dt><dd><p>ore thickness</p>
</dd>
</dl>



<h3>Source</h3>

<p>Green, P.J. and B.W. Silverman (1994) Nonparametric Regression Generalized Linear Models:
A roughness penalty approach, Chapman Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(CobarOre)
plot(CobarOre)
</code></pre>

<hr>
<h2 id='combos'>Ordered Combinations</h2><span id='topic+combos'></span>

<h3>Description</h3>

<p>All m combinations of the first n integers taken p at a time
are computed and return as an p by m matrix.  The columns
of the matrix are ordered so that adjacent columns differ
by only one element.  This is just a reordered version of
<code>combn</code> in base R, but the ordering is useful for some
applications.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combos(n,p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="combos_+3A_n">n</code></td>
<td>
<p>The n in n choose p</p>
</td></tr>
<tr><td><code id="combos_+3A_p">p</code></td>
<td>
<p>The p in n choose p</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>matrix</code> of dimension p by <code>choose(n,p)</code>
</p>


<h3>Note</h3>

<p>Implementation based on a Pascal algorithm of Limin Xiang 
and Kazuo Ushijima (2001) translated to ratfor for R.
If you have <span class="pkg">rgl</span> installed you might try <code>demo("combos")</code>
for a visual impression of how this works.
</p>


<h3>References</h3>

<p>Limin Xiang and Kazuo Ushijima (2001) 
&quot;On O(1) Time Algorithms for Combinatorial Generation,&quot; 
<em>Computer Journal</em>, 44(4), 292-302. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>H &lt;- combos(20,3)
</code></pre>

<hr>
<h2 id='critval'>
Hotelling Critical Values
</h2><span id='topic+critval'></span>

<h3>Description</h3>

<p>Critical values for uniform confidence bands for rqss fitting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>critval(kappa, alpha = 0.05, rdf = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="critval_+3A_kappa">kappa</code></td>
<td>

<p>length of the tube
</p>
</td></tr>
<tr><td><code id="critval_+3A_alpha">alpha</code></td>
<td>

<p>desired non-coverage of the band, intended coverage is 1 - alpha
</p>
</td></tr>
<tr><td><code id="critval_+3A_rdf">rdf</code></td>
<td>

<p>&quot;residual&quot; degrees of freedom of the fitted object.  If <code>rdf=0</code>
then the Gaussian version of the critical value is computed, otherwise
the value is based on standard Student t theory.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hotelling tube approach to inference has a long and illustrious
history.  See Johansen and Johnstone (1989) for an overview.  The implementation
here is based on Sun and Loader (1994) and Loader's <span class="pkg">locfit</span> package, although
a simpler root finding approach is substituted for the iterative method used
there.  At this stage, only univariate bands may be constructed.
</p>


<h3>Value</h3>

<p>A scalar critical value that acts as a multiplier for the uniform
confidence band construction.
</p>


<h3>References</h3>

<p>Hotelling, H.  (1939): &ldquo;Tubes and Spheres in $n$-spaces, and a class
of statistical problems,&rdquo; <em>Am J. Math</em>, 61, 440&ndash;460.
</p>
<p>Johansen, S.,   I.M. Johnstone  (1990): &ldquo;Hotelling's
Theorem on the Volume of Tubes: Some Illustrations in Simultaneous
Inference and Data Analysis,&rdquo; <em>The Annals of Statistics</em>, 18, 652&ndash;684.
</p>
<p>Sun, J. and C.V. Loader:  (1994) &ldquo;Simultaneous Confidence Bands for Linear Regression
and smoothing,&rdquo; <em>The Annals of Statistics</em>, 22, 1328&ndash;1345.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+plot.rqss">plot.rqss</a></code>
</p>

<hr>
<h2 id='crq'>Functions to fit censored quantile regression models</h2><span id='topic+crq'></span><span id='topic+crq.fit.por'></span><span id='topic+crq.fit.por2'></span><span id='topic+crq.fit.pow'></span><span id='topic+crq.fit.pen'></span><span id='topic+print.crq'></span><span id='topic+print.crq'></span><span id='topic+coef.crq'></span><span id='topic+predict.crq'></span><span id='topic+predict.crqs'></span><span id='topic+Curv'></span>

<h3>Description</h3>

<p>Fits a conditional quantile regression model for censored data. There
are three distinct methods:  the first is the fixed censoring method
of Powell (1986) as implemented by Fitzenberger (1996), the second is the random
censoring method of Portnoy (2003).  The third method is based on Peng and Huang (2008).</p>


<h3>Usage</h3>

<pre><code class='language-R'>crq(formula, taus, data, subset, weights, na.action, 
	method = c("Powell", "Portnoy", "Portnoy2", "PengHuang"), contrasts = NULL, ...)
crq.fit.pow(x, y, yc, tau=0.5, weights=NULL, start, left=TRUE, maxit = 500)
crq.fit.pen(x, y, cen, weights=NULL, grid, ctype = "right") 
crq.fit.por(x, y, cen, weights=NULL, grid, ctype = "right") 
crq.fit.por2(x, y, cen, weights=NULL, grid, ctype = "right") 
Curv(y, yc, ctype=c("left","right"))
## S3 method for class 'crq'
print(x, ...)
## S3 method for class 'crq'
print(x, ...)
## S3 method for class 'crq'
predict(object, newdata,  ...)
## S3 method for class 'crqs'
predict(object, newdata, type = NULL, ...)
## S3 method for class 'crq'
coef(object,taus = 1:4/5,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crq_+3A_formula">formula</code></td>
<td>
<p>A formula object, with the response on the left of the &lsquo;~&rsquo;
operator, and the terms on the right.  The response must be a
<code>Surv</code> object as returned by either the <code>Curv</code> or <code>Surv</code> 
function. For the Powell method, the Surv object should
be created by <code>Curv</code> and have arguments (event time, censoring time,type), 
where &quot;type&quot; can take values either &quot;left&quot; or &quot;right&quot;. 
The default (for historical reasons) for type in this case is &quot;left&quot;.
For the Portnoy and Peng and Huang  methods the <code>Surv</code>  should be created 
with the usual <code>Surv</code> function and have (event time, censoring indicator).</p>
</td></tr>  
<tr><td><code id="crq_+3A_y">y</code></td>
<td>
<p>The event time.</p>
</td></tr>
<tr><td><code id="crq_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame in which to look for variables with which 
to predict. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="crq_+3A_grid">grid</code></td>
<td>
<p>A vector of taus on which the quantile process should be evaluated. This
should be monotonic, and take values in (0,1).  For the &quot;Portnoy&quot;  method,
grid = &quot;pivot&quot; computes the full solution for all distinct taus.  The &quot;Portnoy&quot;
method also enforces an equally spaced grid, see the code for details.</p>
</td></tr>
<tr><td><code id="crq_+3A_x">x</code></td>
<td>
<p>An object of class <code>crq</code> or <code>crq</code>.</p>
</td></tr>
<tr><td><code id="crq_+3A_object">object</code></td>
<td>
<p>An object of class <code>crq</code> or <code>crq</code>.</p>
</td></tr>
<tr><td><code id="crq_+3A_yc">yc</code></td>
<td>
<p>The censoring times for the &quot;Powell&quot; method.</p>
</td></tr>
<tr><td><code id="crq_+3A_ctype">ctype</code></td>
<td>
<p>Censoring type: for the &quot;Powell&quot; method, used in <code>Curv</code>, by 
default &quot;left&quot;.  If you don't like &quot;left&quot;, maybe you will like &quot;right&quot;.
Note that for fixed censoring assumed in the &quot;Powell&quot; method, censoring
times <code>yc</code> must be provided for all observations and the event
times <code>y</code> must satisfy the (respective) inequality constraints.
For the Portnoy and Peng-Huang methods ctype is determined by the
specification of the response as specified in <code>Surv</code>.
</p>
</td></tr>
<tr><td><code id="crq_+3A_type">type</code></td>
<td>
<p>specifies either &quot;left&quot; or &quot;right&quot; as the form of censoring 
in the <code>Surv</code> function for the &quot;Portnoy&quot; and &quot;PengHuang&quot;  methods.</p>
</td></tr>
<tr><td><code id="crq_+3A_cen">cen</code></td>
<td>
<p>The censoring indicator for the &quot;Portnoy&quot; and &quot;PengHuang&quot;  methods.</p>
</td></tr>
<tr><td><code id="crq_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations allowed for the &quot;Powell&quot; methods.</p>
</td></tr>
<tr><td><code id="crq_+3A_start">start</code></td>
<td>
<p>The starting value for the coefs for the &quot;Powell&quot; method.  Because
the Fitzenberger algorithm stops when it achieves a local minimum
of the Powell objective function, the starting value acts as an
a priori &quot;preferred point&quot;.  This is advantageous in some instances
since the global Powell solution can be quite extreme. By default the
starting value is the &quot;naive rq&quot; solution that  treats all the censored
observations as uncensored.  If <code>start</code> is equal to &quot;global&quot;
then an attempt is made to compute to global optimum of the Powell
objective.  This entails an exhaustive evaluation of all n choose p
distinct basic solution so is rather impractical for moderately large
problems. Otherwise, the starting value can specify a set of p indices
from 1:n defining an initial basic solution, or it may specify a p-vector
of initial regression coefficients.  In the latter case the initial basic
solution is the one closest to the specified parameter vector.</p>
</td></tr>
<tr><td><code id="crq_+3A_left">left</code></td>
<td>
<p>A logical indicator for left censoring for the &quot;Powell&quot; method.</p>
</td></tr>
<tr><td><code id="crq_+3A_taus">taus</code></td>
<td>
<p>The quantile(s) at which the model is to be estimated.</p>
</td></tr>
<tr><td><code id="crq_+3A_tau">tau</code></td>
<td>
<p>The quantile at which the model is to be estimated.</p>
</td></tr>
<tr><td><code id="crq_+3A_data">data</code></td>
<td>
<p>A data.frame in which to interpret the variables named in the
&lsquo;formula&rsquo;,  in the &lsquo;subset&rsquo;, and the &lsquo;weights&rsquo; argument.</p>
</td></tr>
<tr><td><code id="crq_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="crq_+3A_weights">weights</code></td>
<td>
<p>vector of observation weights; if supplied, the algorithm
fits to minimize the sum of the weights multiplied into the
absolute residuals. The length of weights vector must be the same as
the number of observations.  The weights must be nonnegative
and it is strongly recommended that they be strictly
positive, since zero weights are ambiguous.</p>
</td></tr> 
<tr><td><code id="crq_+3A_na.action">na.action</code></td>
<td>
<p>a function to filter missing data.  This is applied to the
model.frame after any subset argument has been used.  The
default (with 'na.fail') is to create an error if any missing
values are   found.  A possible alternative is 'na.omit',
which  deletes observations that contain one or more missing
values. </p>
</td></tr> 
<tr><td><code id="crq_+3A_method">method</code></td>
<td>
<p>The method used for fitting.  There are currently
two options: method &quot;Powell&quot; computes the Powell estimator using
the algorithm of Fitzenberger (1996), method &quot;Portnoy&quot; computes the
Portnoy (2003) estimator.  The  method is &quot;PengHuang&quot; uses the method
of Peng and Huang (2007), in this case the variable &quot;grid&quot;
can be passed to specify the vector of quantiles at which the solution
is desired.</p>
</td></tr>
<tr><td><code id="crq_+3A_contrasts">contrasts</code></td>
<td>
<p>a list giving contrasts for some or all of the factors 
default = 'NULL' appearing in the model formula.  The
elements of the list should have the same name as the
variable  and should be either a contrast matrix
(specifically, any full-rank  matrix with as many rows as
there are levels in the factor),  or else a function to
compute such a matrix given the number of levels.</p>
</td></tr> 
<tr><td><code id="crq_+3A_...">...</code></td>
<td>
<p>additional arguments for the fitting routine, for method &quot;Powell&quot;
it may be useful to pass starting values of the regression parameter
via the argument &quot;start&quot;, while for methods &quot;Portnoy&quot; or &quot;PengHuang&quot;
one may wish to specify an alternative to the default grid for evaluating 
the fit.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Fitzenberger algorithm uses a variant of the Barrodale and Roberts
simplex method.  Exploiting the fact that the solution must be characterized
by an exact fit to p points when there are p parameters to be estimated,
at any trial basic solution it computes the directional derivatives in the 
2p distinct directions
and choses the direction that (locally) gives steepest descent.  It then
performs a one-dimensional line search to choose the new basic observation
and continues until it reaches a local mimumum.  By default it starts at
the naive <code>rq</code> solution ignoring the censoring;  this has the (slight)
advantage that the estimator is consequently equivariant to canonical
transformations of the data.  Since the objective function is no longer convex
there can be no guarantee that this  produces a global minimum estimate.
In small problems exhaustive search over solutions defined by p-element
subsets of the n observations can be used, but this quickly becomes
impractical for large p and n.   This global version of the Powell
estimator can be invoked by specifying <code>start = "global"</code>. Users
interested in this option would be well advised to compute <code>choose(n,p)</code>
for their problems before trying it.  The method operates by pivoting
through this many distinct solutions and choosing the one that gives the
minimal Powell objective.  The algorithm used for the Portnoy 
method is described in considerable detail in Portnoy (2003). 
There is a somewhat simplified version of the Portnoy method that is
written in R and iterates over a discrete grid.  This version should
be considered somewhat experimental at this stage, but it is known to
avoid some difficulties with the more complicated fortran version of
the algorithm that can occur in degenerate problems.
Both the Portnoy and Peng-Huang estimators may be unable to compute
estimates of the conditional quantile parameters in the upper tail of
distribution.  Like the Kaplan-Meier estimator, when censoring is heavy
in the upper tail the estimated distribution is defective  and quantiles
are only estimable on a sub-interval of (0,1).
The Peng and Huang estimator can be
viewed as a generalization of the Nelson Aalen estimator of the cumulative
hazard function,  and can be formulated as a variant of the conventional
quantile regression dual problem.  See Koenker (2008) for further details.
This paper is available from the package with <code>vignette("crq")</code>.</p>


<h3>Value</h3>

<p>An object of class <code>crq</code>.</p>


<h3>Author(s)</h3>

<p>Steve Portnoy and  Roger Koenker</p>


<h3>References</h3>

<p>Fitzenberger, B.  (1996): &ldquo;A Guide to Censored Quantile
Regressions,&rdquo; in <em>Handbook of Statistics</em>, ed. by C.~Rao,   and
G.~Maddala. North-Holland: New York.
</p>
<p>Fitzenberger, B.  and P. Winker (2007): &ldquo;Improving the Computation of
Censored Quantile Regression Estimators,&rdquo; CSDA, 52,  88-108.
</p>
<p>Koenker, R. (2008): &ldquo;Censored Quantile Regression Redux,&rdquo; <em>J. 
Statistical Software</em>, 27, <a href="https://www.jstatsoft.org/v27/i06">https://www.jstatsoft.org/v27/i06</a>.
</p>
<p>Peng, L and Y Huang, (2008) Survival Analysis with Quantile Regression Models,
<em>J. Am. Stat. Assoc.</em>, 103, 637-649. 
</p>
<p>Portnoy, S. (2003) &ldquo;Censored Quantile Regression,&rdquo; <em>JASA</em>,
98,1001-1012.
</p>
<p>Powell, J. (1986) &ldquo;Censored Regression Quantiles,&rdquo; <em>J.
Econometrics</em>, 32, 143&ndash;155.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+summary.crq">summary.crq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># An artificial Powell example
set.seed(2345)
x &lt;- sqrt(rnorm(100)^2)
y &lt;-  -0.5 + x +(.25 + .25*x)*rnorm(100)
plot(x,y, type="n")
s &lt;- (y &gt; 0)
points(x[s],y[s],cex=.9,pch=16)
points(x[!s],y[!s],cex=.9,pch=1)
yLatent &lt;- y
y &lt;- pmax(0,y)
yc &lt;- rep(0,100)
for(tau in (1:4)/5){
        f &lt;- crq(Curv(y,yc) ~ x, tau = tau, method = "Pow")
        xs &lt;- sort(x)
        lines(xs,pmax(0,cbind(1,xs)%*%f$coef),col="red")
        abline(rq(y ~ x, tau = tau), col="blue")
        abline(rq(yLatent ~ x, tau = tau), col="green")
        }
legend(.15,2.5,c("Naive QR","Censored QR","Omniscient QR"),
        lty=rep(1,3),col=c("blue","red","green"))

# crq example with left censoring
set.seed(1968)
n &lt;- 200
x &lt;-rnorm(n)
y &lt;- 5 + x + rnorm(n)
plot(x,y,cex = .5)
c &lt;- 4 + x + rnorm(n)
d &lt;- (y &gt; c)
points(x[!d],y[!d],cex = .5, col = 2)
f &lt;- crq(survival::Surv(pmax(y,c), d, type = "left") ~ x, method = "Portnoy")
g &lt;- summary(f)
for(i in 1:4) abline(coef(g[[i]])[,1])
</code></pre>

<hr>
<h2 id='dither'> Function to randomly perturb a vector</h2><span id='topic+dither'></span>

<h3>Description</h3>

<p>With malice aforethought, dither adds a specified random perturbation to each element
of the input vector, usually employed as a device to mitigate the effect of ties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dither(x, type = "symmetric", value = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dither_+3A_x">x</code></td>
<td>
<p><code>x</code> a numeric vector </p>
</td></tr>
<tr><td><code id="dither_+3A_type">type</code></td>
<td>
<p><code>type</code> is either 'symmetric' or 'right' </p>
</td></tr>
<tr><td><code id="dither_+3A_value">value</code></td>
<td>
<p><code>value</code> scale of dequantization </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>dither</code> operates slightly differently than the function
<code>jitter</code> in base R, permitting strictly positive perturbations with
the option <code>type = "right"</code> and using somewhat different default schemes
for the scale of the perturbation.  Dithering the response variable is
frequently a useful option in quantile regression fitting to avoid deleterious
effects of degenerate solutions.  See, e.g. Machado  and Santos Silva (2005).
For a general introduction and some etymology see the Wikipedia article on &quot;dither&quot;.
For integer data it is usually advisable to use <code>value = 1</code>.
When 'x' is a matrix or array dither treats all elements as a vector but returns
an object of the original class.
</p>


<h3>Value</h3>

<p>A dithered version of the input vector 'x'.
</p>


<h3>Note</h3>

<p> Some further generality might be nice, for example something other than
uniform noise would be desirable in some circumstances.  Note that when dithering
you are entering into the &quot;state of sin&quot; that John von Neumann famously attributed
to anyone considering &quot;arithmetical methods of producing random digits.&quot;  If you 
need to preserve reproducibility, then <code>set.seed</code> is your friend.
</p>


<h3>Author(s)</h3>

<p> R. Koenker </p>


<h3>References</h3>

 
<p>Machado, J.A.F. and Santos Silva, J.M.C. (2005), Quantiles for Counts,  Journal of the American Statistical Association, vol. 100, no. 472, pp. 1226-1237. 
</p>


<h3>See Also</h3>

 <p><code><a href="base.html#topic+jitter">jitter</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rlnorm(40)
y &lt;- rpois(40, exp(.5 + log(x)))
f &lt;- rq(dither(y, type = "right", value = 1) ~ x)
</code></pre>

<hr>
<h2 id='dynrq'>Dynamic Linear Quantile Regression</h2><span id='topic+dynrq'></span><span id='topic+print.dynrq'></span><span id='topic+print.dynrqs'></span><span id='topic+summary.dynrq'></span><span id='topic+summary.dynrqs'></span><span id='topic+print.summary.dynrq'></span><span id='topic+print.summary.dynrqs'></span><span id='topic+time.dynrq'></span><span id='topic+index.dynrq'></span><span id='topic+start.dynrq'></span><span id='topic+end.dynrq'></span>

<h3>Description</h3>

<p>Interface to <code><a href="quantreg.html#topic+rq.fit">rq.fit</a></code> and <code><a href="quantreg.html#topic+rq.wfit">rq.wfit</a></code> for fitting dynamic linear 
quantile regression models.  The interface is based very closely
on Achim Zeileis's dynlm package.  In effect, this is  mainly
&ldquo;syntactic sugar&rdquo; for formula processing, but one should never underestimate
the value of good, natural sweeteners.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dynrq(formula, tau = 0.5, data, subset, weights, na.action, method = "br",
  contrasts = NULL, start = NULL, end = NULL, ...)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dynrq_+3A_formula">formula</code></td>
<td>
<p>a <code>"formula"</code> describing the linear model to be fit.
For details see below and <code><a href="quantreg.html#topic+rq">rq</a></code>.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_tau">tau</code></td>
<td>
<p>the quantile(s) to be estimated, may be vector valued, but all
all values must be in (0,1).</p>
</td></tr> 
<tr><td><code id="dynrq_+3A_data">data</code></td>
<td>
<p>an optional <code>"data.frame"</code> or time series object (e.g.,
<code>"ts"</code> or <code>"zoo"</code>), containing the variables
in the model.  If not found in <code>data</code>, the variables are taken
from <code>environment(formula)</code>, typically the environment from which
<code>rq</code> is called.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used
in the fitting process. If specified, weighted least squares is used
with weights <code>weights</code> (that is, minimizing <code>sum(w*e^2)</code>);
otherwise ordinary least squares is used.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and is
<code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.  The &ldquo;factory-fresh&rdquo;
default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>. Another possible value is
<code>NULL</code>, no action. Note, that for time series regression
special methods like <code><a href="stats.html#topic+na.contiguous">na.contiguous</a></code>, <code><a href="zoo.html#topic+na.locf">na.locf</a></code>
and <code><a href="zoo.html#topic+na.approx">na.approx</a></code> are available.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_method">method</code></td>
<td>
<p>the method to be used; for fitting, by default
<code>method = "br"</code> is used; <code>method = "fn"</code> employs
the interior point (Frisch-Newton) algorithm.  The latter is advantageous
for problems with sample sizes larger than about 5,000.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code>
of <code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_start">start</code></td>
<td>
<p>start of the time period which should be used for fitting the model.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_end">end</code></td>
<td>
<p>end of the time period which should be used for fitting the model.</p>
</td></tr>
<tr><td><code id="dynrq_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the low level
regression fitting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interface and internals of <code>dynrq</code> are very similar to <code><a href="quantreg.html#topic+rq">rq</a></code>,
but currently <code>dynrq</code> offers two advantages over the direct use of
<code>rq</code> for time series applications of quantile regression: 
extended formula processing, and preservation of time series attributes.  
Both features have been shamelessly lifted from Achim Zeileis's
package dynlm.
</p>
<p>For specifying the <code>formula</code> of the model to be fitted, there are several
functions available which allow for convenient specification
of dynamics (via <code>d()</code> and <code>L()</code>) or linear/cyclical patterns
(via <code>trend()</code>, <code>season()</code>, and <code>harmon()</code>).
These new formula functions require that their arguments are time
series objects (i.e., <code>"ts"</code> or <code>"zoo"</code>).
</p>
<p>Dynamic models: An example would be <code>d(y) ~ L(y, 2)</code>, where
<code>d(x, k)</code> is <code>diff(x, lag = k)</code> and <code>L(x, k)</code> is
<code>lag(x, lag = -k)</code>, note the difference in sign. The default
for <code>k</code> is in both cases <code>1</code>. For <code>L()</code>, it
can also be vector-valued, e.g., <code>y ~ L(y, 1:4)</code>. 
</p>
<p>Trends: <code>y ~ trend(y)</code> specifies a linear time trend where
<code>(1:n)/freq</code> is used by default as the covariate, <code>n</code> is the 
number of observations and <code>freq</code> is the frequency of the series
(if any, otherwise <code>freq = 1</code>). Alternatively, <code>trend(y, scale = FALSE)</code>
would employ <code>1:n</code> and <code>time(y)</code> would employ the original time index.
</p>
<p>Seasonal/cyclical patterns: Seasonal patterns can be specified
via <code>season(x, ref = NULL)</code> and harmonic patterns via
<code>harmon(x, order = 1)</code>.  <code>season(x, ref = NULL)</code> creates a factor 
with levels for each cycle of the season. Using
the <code>ref</code> argument, the reference level can be changed from the default
first level to any other. <code>harmon(x, order = 1)</code> creates a matrix of
regressors corresponding to <code>cos(2 * o * pi * time(x))</code> and 
<code>sin(2 * o * pi * time(x))</code> where <code>o</code> is chosen from <code>1:order</code>.
</p>
<p>See below for examples. 
</p>
<p>Another aim of <code>dynrq</code> is to preserve 
time series properties of the data. Explicit support is currently available 
for <code>"ts"</code> and <code>"zoo"</code> series. Internally, the data is kept as a <code>"zoo"</code>
series and coerced back to <code>"ts"</code> if the original dependent variable was of
that class (and no internal <code>NA</code>s were created by the <code>na.action</code>).
</p>


<h3>See Also</h3>

<p><code><a href="zoo.html#topic+zoo">zoo</a></code>, 
<code><a href="zoo.html#topic+merge.zoo">merge.zoo</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>###########################
## Dynamic Linear Quantile Regression Models ##
###########################

if(require(zoo)){
## multiplicative median SARIMA(1,0,0)(1,0,0)_12 model fitted to UK seatbelt data
     uk &lt;- log10(UKDriverDeaths)
     dfm &lt;- dynrq(uk ~ L(uk, 1) + L(uk, 12))
     dfm

     dfm3 &lt;- dynrq(uk ~ L(uk, 1) + L(uk, 12),tau = 1:3/4)
     summary(dfm3)
 ## explicitly set start and end
     dfm1 &lt;- dynrq(uk ~ L(uk, 1) + L(uk, 12), start = c(1975, 1), end = c(1982, 12))
 ## remove lag 12
     dfm0 &lt;- update(dfm1, . ~ . - L(uk, 12))
     tuk1  &lt;- anova(dfm0, dfm1)
 ## add seasonal term
     dfm1 &lt;- dynrq(uk ~ 1, start = c(1975, 1), end = c(1982, 12))
     dfm2 &lt;- dynrq(uk ~ season(uk), start = c(1975, 1), end = c(1982, 12))
     tuk2 &lt;- anova(dfm1, dfm2)
 ## regression on multiple lags in a single L() call
     dfm3 &lt;- dynrq(uk ~ L(uk, c(1, 11, 12)), start = c(1975, 1), end = c(1982, 12))
     anova(dfm1, dfm3)
}

###############################
## Time Series Decomposition ##
###############################

## airline data
## Not run: 
ap &lt;- log(AirPassengers)
fm &lt;- dynrq(ap ~ trend(ap) + season(ap), tau = 1:4/5)
sfm &lt;- summary(fm)
plot(sfm)

## End(Not run)

## Alternative time trend specifications:
##   time(ap)                  1949 + (0, 1, ..., 143)/12
##   trend(ap)                 (1, 2, ..., 144)/12
##   trend(ap, scale = FALSE)  (1, 2, ..., 144)

###############################
## An Edgeworth (1886) Problem##
###############################
# DGP
## Not run: 
fye &lt;- function(n, m = 20){
    a &lt;- rep(0,n)
    s &lt;- sample(0:9, m, replace = TRUE)
    a[1] &lt;- sum(s)
    for(i in 2:n){
       s[sample(1:20,1)] &lt;- sample(0:9,1)
       a[i] &lt;- sum(s)
    }
    zoo::zoo(a)
}
x &lt;- fye(1000)
f &lt;- dynrq(x ~ L(x,1))
plot(x,cex = .5, col = "red")
lines(fitted(f), col = "blue")

## End(Not run)
</code></pre>

<hr>
<h2 id='engel'>Engel Data</h2><span id='topic+engel'></span>

<h3>Description</h3>

<p>Engel food expenditure data used in Koenker and Bassett(1982).
This is a regression data set consisting of 235 observations on
income and expenditure on food for Belgian working class households.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(engel)</code></pre>


<h3>Format</h3>

<p>A data frame containing 235 observations on 2 variables
</p>

<dl>
<dt>income</dt><dd><p>annual household income in Belgian francs</p>
</dd>
<dt>foodexp</dt><dd><p>annual household food expenditure in Belgian francs</p>
</dd>
</dl>



<h3>References</h3>

<p>Koenker, R. and Bassett, G (1982)
Robust Tests of Heteroscedasticity based on Regression Quantiles;
<em>Econometrica</em> <b>50</b>, 43&ndash;61.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See also    demo("engel1")
##             --------------

data(engel)
plot(engel, log = "xy",
     main = "'engel' data  (log - log scale)")
plot(log10(foodexp) ~ log10(income), data = engel,
     main = "'engel' data  (log10 - transformed)")
taus &lt;- c(.15, .25, .50, .75, .95, .99)
rqs &lt;- as.list(taus)
for(i in seq(along = taus)) {
  rqs[[i]] &lt;- rq(log10(foodexp) ~ log10(income), tau = taus[i], data = engel)
  lines(log10(engel$income), fitted(rqs[[i]]), col = i+1)
}
legend("bottomright", paste("tau = ", taus), inset = .04,
       col = 2:(length(taus)+1), lty=1)
</code></pre>

<hr>
<h2 id='FAQ'>FAQ and ChangeLog  of a package</h2><span id='topic+FAQ'></span><span id='topic+ChangeLog'></span>

<h3>Description</h3>

<p> Show the FAQ or ChangeLog of a specified package  </p>


<h3>Usage</h3>

<pre><code class='language-R'>FAQ(pkg = "quantreg")
ChangeLog(pkg = "quantreg")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FAQ_+3A_pkg">pkg</code></td>
<td>
<p> Package Name </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assumes that the FAQ and/or ChangeLog files exist in the proper &quot;inst&quot; directory.
</p>


<h3>Value</h3>

<p>Has only the side effect of showing the files on the screen.  
</p>

<hr>
<h2 id='gasprice'>Time Series of US Gasoline Prices
</h2><span id='topic+gasprice'></span>

<h3>Description</h3>

<p> Time Series of Weekly US Gasoline Prices: 1990:8 &ndash; 2003:26
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("gasprice")</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasprice)
</code></pre>

<hr>
<h2 id='KhmaladzeTest'> Tests of Location and Location Scale Shift Hypotheses for Linear Models</h2><span id='topic+KhmaladzeTest'></span>

<h3>Description</h3>

<p>Tests of the hypothesis that a linear model specification
is of the location shift or location-scale shift form.  The tests are based 
on the Doob-Meyer Martingale transformation approach proposed by Khmaladze(1981)
for general goodness of fit problems as adapted to quantile regression by 
Koenker and Xiao (2002).</p>


<h3>Usage</h3>

<pre><code class='language-R'>KhmaladzeTest(formula, data = NULL, taus = 1:99/100, nullH = "location" ,  
	trim = c(0.05, 0.95), h = 1, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KhmaladzeTest_+3A_formula">formula</code></td>
<td>
<p>a formula specifying the model to fit by <code><a href="quantreg.html#topic+rqProcess">rqProcess</a></code></p>
</td></tr>
<tr><td><code id="KhmaladzeTest_+3A_data">data</code></td>
<td>
<p>a data frame within which to interpret the formula</p>
</td></tr>
<tr><td><code id="KhmaladzeTest_+3A_taus">taus</code></td>
<td>
<p>An equally spaced grid of points on which to evaluate the 
quantile regression process, if any taus fall outside (0,1) then the full
process is computed.</p>
</td></tr>
<tr><td><code id="KhmaladzeTest_+3A_nullh">nullH</code></td>
<td>
<p>a character vector indicating whether the &quot;location&quot; shift hypothesis
(default) or the &quot;location-scale&quot; shift hypothesis  should be tested.  </p>
</td></tr>
<tr><td><code id="KhmaladzeTest_+3A_trim">trim</code></td>
<td>
<p> a vector indicating the lower and upper bound of the quantiles to
included in the computation of the test statistics (only, not
estimates).  </p>
</td></tr>
<tr><td><code id="KhmaladzeTest_+3A_h">h</code></td>
<td>
<p>an initial bandwidth for the call to <code><a href="quantreg.html#topic+akj">akj</a></code>.</p>
</td></tr> 
<tr><td><code id="KhmaladzeTest_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code><a href="quantreg.html#topic+summary.rq">summary.rq</a>.</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class KhmaladzeTest  is returned containing:
</p>
<table>
<tr><td><code>nullH</code></td>
<td>
<p> The form of the null hypothesis.</p>
</td></tr>
<tr><td><code>Tn</code></td>
<td>

<p>Joint test statistic of the hypothesis that all the slope
parameters of the model satisfy the hypothesis.
</p>
</td></tr>
<tr><td><code>THn</code></td>
<td>

<p>Vector of test statistics testing whether individual slope
parameters satisfy the null hypothesis.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Khmaladze, E. (1981) &ldquo;Martingale Approach in the Theory of
Goodness-of-fit Tests,&rdquo; <em>Theory of Prob. and its Apps</em>, 26,
240&ndash;257.
</p>
<p>Koenker, Roger and Zhijie Xiao (2002), &ldquo;Inference on the Quantile
Regression Process&rdquo;,  <em>Econometrica</em>,  81, 1583&ndash;1612.
<a href="http://www.econ.uiuc.edu/~roger/research/inference/inference.html">http://www.econ.uiuc.edu/~roger/research/inference/inference.html</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(barro)
T = KhmaladzeTest( y.net ~ lgdp2 + fse2 + gedy2 + Iy2 + gcony2, 
		data = barro, taus = seq(.05,.95,by = .01))
plot(T)
</code></pre>

<hr>
<h2 id='kuantile'>Quicker Sample Quantiles </h2><span id='topic+kuantile'></span><span id='topic+kselect'></span><span id='topic+kunique'></span>

<h3>Description</h3>

<p>The function 'kuantile' computes sample quantiles corresponding
to the specified probabilities. The intent is to mimic the generic
(base) function 'quantile' but using a variant of the Floyd and
Rivest (1975) algorithm which is somewhat quicker, especially for
large sample sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kuantile(x, probs = seq(0, 1, .25), na.rm = FALSE, names = TRUE, type = 7, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kuantile_+3A_x">x</code></td>
<td>
<p>numeric vector whose sample quantiles are wanted.</p>
</td></tr>
<tr><td><code id="kuantile_+3A_probs">probs</code></td>
<td>
<p>numeric vector of probabilities with values in [0,1].</p>
</td></tr>
<tr><td><code id="kuantile_+3A_type">type</code></td>
<td>
<p> an integer between 1 and 9 selecting one of the nine quantile
algorithms detailed below to be used.</p>
</td></tr>
<tr><td><code id="kuantile_+3A_na.rm">na.rm</code></td>
<td>
<p>logical: if true, any 'NA' and 'NaN&rdquo;s are removed from 'x'
before the quantiles are computed.</p>
</td></tr>
<tr><td><code id="kuantile_+3A_names">names</code></td>
<td>
<p>logical: if true, the result has a 'names' attribute. </p>
</td></tr> 
<tr><td><code id="kuantile_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> A vector of length 'length(p)' is returned.  See the documentation
for 'quantile' for further details on the types.  The algorithm was written
by K.C. Kiwiel.  It is a modified version of the (algol 68) SELECT procedure of
Floyd and Rivest (1975), incorporating modifications of Brown(1976).
The algorithm has linear growth in the number of comparisons required as
sample size grows.  For the median, average case behavior requires
<code class="reqn">1.5 n + O((n log n)^{1/2})</code> comparisons. See Kiwiel (2005) and Knuth (1998)
for further details.  When the number of required elements of p is large, it
may be preferable to revert to a full  sort.</p>


<h3>Value</h3>

<p>A vector of quantiles of the same length as the vector p.
</p>


<h3>Author(s)</h3>

<p> K.C. Kiwiel, R interface:  Roger Koenker </p>


<h3>References</h3>

 
<p>R.W. Floyd and R.L. Rivest: &quot;Algorithm 489: The Algorithm
SELECT&mdash;for Finding the $i$th Smallest of $n$ Elements&quot;,
Comm. ACM 18, 3 (1975) 173,
</p>
<p>T. Brown: &quot;Remark on Algorithm 489&quot;, ACM Trans. Math.
Software 3, 2 (1976), 301-304.
</p>
<p>K.C. Kiwiel: On Floyd and Rivest's SELECT Algorithm, Theoretical
Computer Sci. 347 (2005) 214-238.
</p>
<p>D. Knuth, The Art of Computer Programming, Volume 3, Sorting and 
Searching, 2nd Ed., (1998), Addison-Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>     kuantile(x &lt;- rnorm(1001))# Extremes &amp; Quartiles by default

     ### Compare different types
     p &lt;- c(0.1,0.5,1,2,5,10,50)/100
     res &lt;- matrix(as.numeric(NA), 9, 7)
     for(type in 1:9) res[type, ] &lt;- y &lt;- kuantile(x,  p, type=type)
     dimnames(res) &lt;- list(1:9, names(y))
     ktiles &lt;- res

     ### Compare different types
     p &lt;- c(0.1,0.5,1,2,5,10,50)/100
     res &lt;- matrix(as.numeric(NA), 9, 7)
     for(type in 1:9) res[type, ] &lt;- y &lt;- quantile(x,  p, type=type)
     dimnames(res) &lt;- list(1:9, names(y))
     qtiles &lt;- res

     max(abs(ktiles - qtiles))


</code></pre>

<hr>
<h2 id='LassoLambdaHat'>Lambda selection for QR lasso problems</h2><span id='topic+LassoLambdaHat'></span>

<h3>Description</h3>

<p>Default procedure for selection of lambda in lasso constrained
quantile regression as proposed by Belloni and Chernozhukov (2011)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LassoLambdaHat(X, R = 1000, tau = 0.5, C = 1, alpha = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LassoLambdaHat_+3A_x">X</code></td>
<td>
<p>Design matrix</p>
</td></tr>
<tr><td><code id="LassoLambdaHat_+3A_r">R</code></td>
<td>
<p>Number of replications</p>
</td></tr>
<tr><td><code id="LassoLambdaHat_+3A_tau">tau</code></td>
<td>
<p>quantile of interest</p>
</td></tr>
<tr><td><code id="LassoLambdaHat_+3A_c">C</code></td>
<td>
<p>Cosmological constant</p>
</td></tr>
<tr><td><code id="LassoLambdaHat_+3A_alpha">alpha</code></td>
<td>
<p>Interval threshold</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As proposed by Belloni and Chernozhukov, a reasonable default lambda
would be the upper quantile of the simulated values.  The procedure is based 
on idea that a simulated gradient can be used as a pivotal statistic.
Elements of the default vector are standardized by the respective standard deviations
of the covariates. Note that the sqrt(tau(1-tau)) factor cancels in their (2.4) (2.6).
In this formulation even the intercept is penalized.  If the lower limit of the
simulated interval is desired one can specify <code>alpha = 0.05</code>.
</p>


<h3>Value</h3>

<p>vector of default lambda values of length p, the column dimension of X.
</p>


<h3>References</h3>

<p>Belloni, A. and  V. Chernozhukov. (2011) l1-penalized quantile regression 
in high-dimensional sparse models. <em>Annals of Statistics</em>, 39 82 - 130.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
p &lt;- 10
x &lt;- matrix(rnorm(n*p), n, p)
b &lt;- c(1,1, rep(0, p-2))
y &lt;- x %*% b + rnorm(n)
f &lt;- rq(y ~ x, tau = 0.8, method = "lasso")
# See f$lambda to see the default lambda selection
</code></pre>

<hr>
<h2 id='latex'> Make a latex version of an R object </h2><span id='topic+latex'></span>

<h3>Description</h3>

<p>Generic function for converting an  <span class="rlang"><b>R</b></span> object into a latex file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>latex(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="latex_+3A_x">x</code></td>
<td>
 <p><code>x</code> is an <span class="rlang"><b>R</b></span> object </p>
</td></tr>
<tr><td><code id="latex_+3A_...">...</code></td>
<td>
 <p><code>...</code> optional arguments </p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+latex.table">latex.table</a></code>, <code><a href="quantreg.html#topic+latex.summary.rqs">latex.summary.rqs</a></code>
</p>

<hr>
<h2 id='latex.summary.rqs'> Make a latex table from a table of rq results</h2><span id='topic+latex.summary.rqs'></span>

<h3>Description</h3>

<p>Produces a file with latex commands for a table of rq results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.rqs'
latex(x, transpose = FALSE, caption = "caption goes here.", 
		digits = 3, file = as.character(substitute(x)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="latex.summary.rqs_+3A_x">x</code></td>
<td>
<p><code>x</code> is an object of class <code>summary.rqs</code></p>
</td></tr>
<tr><td><code id="latex.summary.rqs_+3A_transpose">transpose</code></td>
<td>
<p>if <code>TRUE</code> transpose table so that 
rows are quantiles and columns are covariates. </p>
</td></tr>
<tr><td><code id="latex.summary.rqs_+3A_caption">caption</code></td>
<td>
<p> caption for the table</p>
</td></tr>
<tr><td><code id="latex.summary.rqs_+3A_digits">digits</code></td>
<td>
<p> decimal precision of table entries.</p>
</td></tr>
<tr><td><code id="latex.summary.rqs_+3A_file">file</code></td>
<td>
<p> name of file </p>
</td></tr>
<tr><td><code id="latex.summary.rqs_+3A_...">...</code></td>
<td>
<p> optional arguments for <code>latex.table</code>  </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calls  <code>latex.table</code>. 
</p>


<h3>Value</h3>

<p>Returns invisibly after writing the file.
</p>


<h3>Author(s)</h3>

<p> R. Koenker</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+summary.rqs">summary.rqs</a></code>, <code><a href="quantreg.html#topic+latex.table">latex.table</a></code></p>

<hr>
<h2 id='latex.table'> Writes a latex formatted table to a file</h2><span id='topic+latex.table'></span>

<h3>Description</h3>

<p>Automatically generates a latex formatted table from the matrix x
Controls rounding, alignment, etc, etc
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'table'
latex(x, file=as.character(substitute(x)), 
	rowlabel=file, rowlabel.just="l", cgroup, n.cgroup, rgroup, n.rgroup=NULL, 
	digits, dec, rdec, cdec, append=FALSE, dcolumn=FALSE, cdot=FALSE, 
	longtable=FALSE, table.env=TRUE, lines.page=40, caption, caption.lot, 
	label=file, double.slash=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="latex.table_+3A_x">x</code></td>
<td>
<p> A matrix <code>x</code> with dimnames</p>
</td></tr>
<tr><td><code id="latex.table_+3A_file">file</code></td>
<td>
<p> Name of output <code>file</code> (.tex will be added) </p>
</td></tr>
<tr><td><code id="latex.table_+3A_rowlabel">rowlabel</code></td>
<td>
<p> If &lsquo;x&rsquo; has row dimnames, rowlabel is a character 
string containing the column heading for the row dimnames. 
The default is the name of the argument for x. </p>
</td></tr>
<tr><td><code id="latex.table_+3A_rowlabel.just">rowlabel.just</code></td>
<td>
<p> If &lsquo;x&rsquo; has row dimnames, specifies the 
justification for printing them.  Possible values are '
&quot;l&quot;, &quot;r&quot;, &quot;c&quot;'. The heading (&lsquo;rowlabel&rsquo;) itself
is left justified if &lsquo;rowlabel.just=&quot;l&quot;&rsquo;, otherwise it is centered. </p>
</td></tr>
<tr><td><code id="latex.table_+3A_cgroup">cgroup</code></td>
<td>
<p> a vector of character strings defining major column headings. 
The default is to have none. </p>
</td></tr>
<tr><td><code id="latex.table_+3A_n.cgroup">n.cgroup</code></td>
<td>
<p> a vector containing the number of columns for which each 
element in cgroup is a heading.  For example, specify 'cgroup=
c(&quot;Major 1&quot;,&quot;Major 2&quot;)', &lsquo;n.cgroup=c(3,3)&rsquo; if &quot;Major 1&quot; is to 
span columns 1-3 and &quot;Major 2&quot; is to span columns 4-6.  
&lsquo;rowlabel&rsquo; does not count in the column numbers.  You can omit 
&lsquo;n.cgroup&rsquo; if all groups have the same number of columns.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_rgroup">rgroup</code></td>
<td>
<p> a vector of character strings containing headings for row 
groups.  &lsquo;n.rgroup&rsquo; must be present when &lsquo;rgroup&rsquo; is given. The 
first &lsquo;n.rgroup[1]&rsquo; rows are sectioned off and &lsquo;rgroup[1]&rsquo; is 
used as a bold heading for them. The usual row dimnames (which must 
be present if &lsquo;rgroup&rsquo; is) are indented. The next &lsquo;n.rgroup[2]&rsquo; 
rows are treated likewise, etc.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_n.rgroup">n.rgroup</code></td>
<td>
<p>integer vector giving the number of rows in each grouping. 
If &lsquo;rgroup&rsquo; is not specified, &lsquo;n.rgroup&rsquo; is just used to divide off 
blocks of rows by horizontal lines. If &lsquo;rgroup&rsquo; is given but 
&lsquo;n.rgroup&rsquo; is omitted, &lsquo;n.rgroup&rsquo; will default so that each row 
group contains the same number of rows.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_digits">digits</code></td>
<td>
<p> causes all values in the table to be formatted to &lsquo;digits&rsquo; 
significant digits.  &lsquo;dec&rsquo; is usually preferred.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_dec">dec</code></td>
<td>
<p> If &lsquo;dec&rsquo; is a scalar, all elements of the matrix will be 
rounded to &lsquo;dec&rsquo; decimal places to the right of the decimal. 
&lsquo;dec&rsquo; can also be a matrix whose elements correspond to &lsquo;x&rsquo;, for 
customized rounding of each element.</p>
</td></tr>
<tr><td><code id="latex.table_+3A_rdec">rdec</code></td>
<td>
<p> a vector specifying the number of decimal places to the right 
for each row (&lsquo;cdec&rsquo; is more commonly used than &lsquo;rdec&rsquo;) </p>
</td></tr>
<tr><td><code id="latex.table_+3A_cdec">cdec</code></td>
<td>
<p> a vector specifying the number of decimal places for each 
column </p>
</td></tr>
<tr><td><code id="latex.table_+3A_append">append</code></td>
<td>
<p>  defaults to &lsquo;F&rsquo;. Set to &lsquo;T&rsquo; to append output to an 
existing file.</p>
</td></tr>
<tr><td><code id="latex.table_+3A_dcolumn">dcolumn</code></td>
<td>
<p> Set to &lsquo;T&rsquo; to use David Carlisles &lsquo;dcolumn&rsquo; style for 
decimal alignment.
Default is &lsquo;F&rsquo;, which aligns columns of numbers by changing leading
blanks to &quot;~&quot;, the LaTeX space-holder. You will probably want to
use &lsquo;dcolumn&rsquo; if you use &lsquo;rdec&rsquo;, as a column may then contain varying
number of places to the right of the decimal. &lsquo;dcolumn&rsquo; can line up
all such numbers on the decimal point, with integer values right-
justified at the decimal point location of numbers that actually
contain decimal places.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_cdot">cdot</code></td>
<td>
<p> Set to &lsquo;T&rsquo; to use centered dots rather than ordinary periods 
in numbers.</p>
</td></tr>
<tr><td><code id="latex.table_+3A_longtable">longtable</code></td>
<td>
<p> Set to &lsquo;T&rsquo; to use David Carlisles LaTeX &lsquo;longtable&rsquo; style, 
allowing long tables to be split over multiple pages with headers 
repeated on each page.</p>
</td></tr>
<tr><td><code id="latex.table_+3A_table.env">table.env</code></td>
<td>
<p>Set &lsquo;table.env=FALSE&rsquo; to suppress enclosing the table
in a LaTeX &lsquo;table&rsquo; environment.  &lsquo;table.env&rsquo; only applies when 
&lsquo;longtable=FALSE&rsquo;.  You may not specify a &lsquo;caption&rsquo; if &lsquo;table.env=FALSE&rsquo;.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_lines.page">lines.page</code></td>
<td>
<p> Applies if &lsquo;longtable=TRUE&rsquo;. No more than &lsquo;lines.page&rsquo; 
lines in the body of a table will be placed on a single page. 
Page breaks will only occur at &lsquo;rgroup&rsquo; boundaries. </p>
</td></tr>
<tr><td><code id="latex.table_+3A_caption">caption</code></td>
<td>
<p> a text string to use as a caption to print at the top of the 
first page of the table. Default is no caption.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_caption.lot">caption.lot</code></td>
<td>
<p> a text string representing a short caption to be used 
in the &quot;List of Tables&quot;.  By default, LaTeX will use &lsquo;caption&rsquo;.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_label">label</code></td>
<td>
<p> a text string representing a symbolic label for the table 
for referencing with the LaTex &lsquo;\ref{label}&rsquo; command. The default 
is &lsquo;file&rsquo;.  &lsquo;label&rsquo; is only used if &lsquo;caption&rsquo; is given.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_double.slash">double.slash</code></td>
<td>
<p>set to &lsquo;T&rsquo; to output &lsquo;\&rsquo; as &lsquo;\\&rsquo; in LaTeX commands. 
Useful when you are reading the output file back into an S vector 
for later output.  </p>
</td></tr>
<tr><td><code id="latex.table_+3A_...">...</code></td>
<td>
<p>other optional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p> returns invisibly </p>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p> Minor modification of Frank Harrell's Splus code </p>

<hr>
<h2 id='lm.fit.recursive'> Recursive Least Squares </h2><span id='topic+lm.fit.recursive'></span>

<h3>Description</h3>

<p>This function fits a linear model by recursive least squares.  It is
a utility routine for the <code><a href="quantreg.html#topic+KhmaladzeTest">KhmaladzeTest</a></code> function of the quantile regression
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lm.fit.recursive(X, y, int=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lm.fit.recursive_+3A_x">X</code></td>
<td>
<p> Design Matrix </p>
</td></tr>
<tr><td><code id="lm.fit.recursive_+3A_y">y</code></td>
<td>
<p> Response Variable</p>
</td></tr>
<tr><td><code id="lm.fit.recursive_+3A_int">int</code></td>
<td>
<p> if TRUE then append intercept to X</p>
</td></tr>
</table>


<h3>Value</h3>

<p>return p by n matrix of fitted parameters, where p. The
ith column gives the solution up to &quot;time&quot; i. 
</p>


<h3>Author(s)</h3>

<p> R. Koenker </p>


<h3>References</h3>

<p> A. Harvey, (1993) Time Series Models, MIT </p>

<hr>
<h2 id='lprq'> locally polynomial quantile regression </h2><span id='topic+lprq'></span>

<h3>Description</h3>

<p>This is a toy function to illustrate how to do locally polynomial
quantile regression univariate smoothing.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lprq(x, y, h, tau = .5, m = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lprq_+3A_x">x</code></td>
<td>
<p> The conditioning covariate</p>
</td></tr>
<tr><td><code id="lprq_+3A_y">y</code></td>
<td>
<p> The response variable  </p>
</td></tr>
<tr><td><code id="lprq_+3A_h">h</code></td>
<td>
<p> The bandwidth parameter </p>
</td></tr>
<tr><td><code id="lprq_+3A_tau">tau</code></td>
<td>
<p> The quantile to be estimated </p>
</td></tr>
<tr><td><code id="lprq_+3A_m">m</code></td>
<td>
<p> The number of points at which the function is to be estimated </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function obviously only does locally linear fitting but can be easily
adapted to locally polynomial fitting of higher order.  The author doesn't
really approve of this sort of smoothing, being more of a spline person,
so the code is left is its (almost) most trivial form. 
</p>


<h3>Value</h3>

<p>The function compute a locally weighted linear quantile regression fit
at each of the m design points, and returns:
</p>
<table>
<tr><td><code>xx</code></td>
<td>
<p>The design points at which the evaluation occurs</p>
</td></tr>
<tr><td><code>fv</code></td>
<td>
<p>The estimated function values at these design points</p>
</td></tr>
<tr><td><code>dev</code></td>
<td>
<p>The estimated first derivative values at the design points</p>
</td></tr>
</table>


<h3>Note</h3>

<p>One can also consider using B-spline expansions see <code>bs</code>.</p>


<h3>Author(s)</h3>

<p>R. Koenker </p>


<h3>References</h3>

<p> Koenker, R. (2004) Quantile Regression </p>


<h3>See Also</h3>

 <p><code>rqss</code> for a general approach to oonparametric QR fitting.  </p>


<h3>Examples</h3>

<pre><code class='language-R'>require(MASS)
data(mcycle)
attach(mcycle)
plot(times,accel,xlab = "milliseconds", ylab = "acceleration (in g)")
hs &lt;- c(1,2,3,4)
for(i in hs){
        h = hs[i]
        fit &lt;- lprq(times,accel,h=h,tau=.5)
        lines(fit$xx,fit$fv,lty=i)
        }
legend(50,-70,c("h=1","h=2","h=3","h=4"),lty=1:length(hs))
</code></pre>

<hr>
<h2 id='Mammals'>Garland(1983) Data on Running Speed of Mammals</h2><span id='topic+Mammals'></span>

<h3>Description</h3>

<p>Observations on the maximal running speed of mammal species
and their body mass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Mammals)</code></pre>


<h3>Format</h3>

<p>A data frame with 107 observations on the following 4 variables.
</p>

<dl>
<dt>weight</dt><dd><p>Body mass in Kg for &quot;typical adult sizes&quot;</p>
</dd>
<dt>speed</dt><dd><p>Maximal running speed (fastest sprint velocity on record)</p>
</dd>
<dt>hoppers</dt><dd><p>logical variable indicating animals that ambulate
by hopping, e.g. kangaroos</p>
</dd>
<dt>specials</dt><dd><p>logical variable indicating special animals with
&quot;lifestyles in which speed does not figure as an important
factor&quot;:  Hippopotamus, raccoon (Procyon), badger (Meles),
coati (Nasua), skunk (Mephitis), man (Homo), porcupine
(Erithizon), oppossum (didelphis), and sloth (Bradypus)
</p>
</dd>
</dl>



<h3>Details</h3>

<p>Used by Chappell (1989) and Koenker, Ng and Portnoy (1994) to
illustrate the fitting of piecewise linear curves.
</p>


<h3>Source</h3>

<p>Garland, T. (1983) The relation between maximal running speed and body 
mass in terrestrial mammals, <em>J. Zoology</em>, 199, 1557-1570.
</p>


<h3>References</h3>

<p>Koenker, R., P. Ng and S. Portnoy, (1994)  Quantile Smoothing Splines&rdquo; 
<em>Biometrika</em>, 81, 673-680.
</p>
<p>Chappell, R. (1989) Fitting Bent Lines to Data, with Applications ot
Allometry,  <em>J. Theo. Biology</em>, 138, 235-256.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rqss">rqss</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Mammals)
attach(Mammals)
x &lt;- log(weight)
y &lt;- log(speed)
plot(x,y, xlab="Weight in log(Kg)", ylab="Speed in log(Km/hour)",type="n")
points(x[hoppers],y[hoppers],pch = "h", col="red")
points(x[specials],y[specials],pch = "s", col="blue")
others &lt;- (!hoppers &amp; !specials)
points(x[others],y[others], col="black",cex = .75)
fit &lt;- rqss(y ~ qss(x, lambda = 1),tau = .9)
plot(fit)
</code></pre>

<hr>
<h2 id='MelTemp'>Daily maximum temperatures in Melbourne, Australia</h2><span id='topic+MelTemp'></span>

<h3>Description</h3>

<p>Daily maximum temperatures in Melbourne, Australia, from
1981-1990. Leap days have been omitted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MelTemp)</code></pre>


<h3>Format</h3>

<p>Time series of frequency 365</p>


<h3>Source</h3>

<p>Hyndman, R.J., Bashtannyk, D.M. and Grunwald, G.K. (1996)
&quot;Estimating and visualizing conditional densities&quot;. _Journal of
Computational and Graphical Statistics_, *5*, 315-336.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MelTemp)
demo(Mel)
</code></pre>

<hr>
<h2 id='Munge'>
Munge rqss formula
</h2><span id='topic+Munge'></span>

<h3>Description</h3>

<p>function to recursively substitute arguments into rqss formula 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Munge(formula, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Munge_+3A_formula">formula</code></td>
<td>

<p>A rqss formula
</p>
</td></tr>
<tr><td><code id="Munge_+3A_...">...</code></td>
<td>

<p>Arguments to be substituted into formula
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Intended (originally) for use with <code>demo(MCV)</code>.
Based on an R-help suggestion of Gabor Grothendieck.
</p>


<h3>Value</h3>

<p>A new formula after substitution
</p>


<h3>See Also</h3>

<p><code>demo(MCV)</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>lams &lt;- c(1.3, 3.3)
f &lt;- y ~ qss(x, lambda = lams[1]) + qss(z, lambda = lams[2]) + s
ff &lt;- Munge(f, lams = lams)
</code></pre>

<hr>
<h2 id='nlrq'> Function to compute nonlinear quantile regression estimates</h2><span id='topic+nlrq'></span><span id='topic+nlrqModel'></span><span id='topic+print.nlrq'></span><span id='topic+summary.nlrq'></span><span id='topic+deviance.nlrq'></span><span id='topic+formula.nlrq'></span><span id='topic+coef.nlrq'></span><span id='topic+fitted.nlrq'></span><span id='topic+logLik.nlrq'></span><span id='topic+AIC.nlrq'></span><span id='topic+extractAIC.nlrq'></span><span id='topic+predict.nlrq'></span><span id='topic+print.summary.nlrq'></span><span id='topic+tau.nlrq'></span>

<h3>Description</h3>

<p>This function implements an R version of an interior point method
for computing the solution to quantile regression problems which
are nonlinear in the parameters.  The algorithm is based on interior
point ideas described in Koenker and Park (1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlrq(formula, data=parent.frame(), start, tau=0.5, 
	control, trace=FALSE,method="L-BFGS-B")
## S3 method for class 'nlrq'
summary(object, ...)
## S3 method for class 'summary.nlrq'
print(x, digits = max(5, .Options$digits - 2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlrq_+3A_formula">formula</code></td>
<td>
<p> formula for model in nls format; accept self-starting models </p>
</td></tr>
<tr><td><code id="nlrq_+3A_data">data</code></td>
<td>
<p> an optional data frame in which to evaluate the variables in
&lsquo;formula&rsquo; </p>
</td></tr>
<tr><td><code id="nlrq_+3A_start">start</code></td>
<td>
<p>a named list or named numeric vector of starting estimates </p>
</td></tr>
<tr><td><code id="nlrq_+3A_tau">tau</code></td>
<td>
<p> a vector of quantiles to be estimated</p>
</td></tr>
<tr><td><code id="nlrq_+3A_control">control</code></td>
<td>
<p> an optional list of control settings.  See &lsquo;nlrq.control&rsquo; for
the names of the settable control values and their effect.</p>
</td></tr>
<tr><td><code id="nlrq_+3A_trace">trace</code></td>
<td>
<p> logical value indicating if a trace of the iteration progress
should be printed.  Default is &lsquo;FALSE&rsquo;.  If &lsquo;TRUE&rsquo; intermediary results
are printed at the end of each iteration. </p>
</td></tr> 
<tr><td><code id="nlrq_+3A_method">method</code></td>
<td>
<p> method passed to optim for line search, default is &quot;L-BFGS-B&quot;
but for some problems &quot;BFGS&quot; may be preferable.  See <code><a href="stats.html#topic+optim">optim</a></code> for
further details.  Note that the algorithm wants to pass
upper and lower bounds for the line search to optim, which is fine for
the L-BFGS-B method.  Use of other methods will produce warnings about
these arguments &ndash; so users should proceed at their own risk.</p>
</td></tr>
<tr><td><code id="nlrq_+3A_object">object</code></td>
<td>
<p>an object of class nlrq needing summary.</p>
</td></tr>
<tr><td><code id="nlrq_+3A_x">x</code></td>
<td>
<p>an object of class summary.nlrq needing printing.</p>
</td></tr>
<tr><td><code id="nlrq_+3A_digits">digits</code></td>
<td>
<p>Significant digits reported in the printed table.</p>
</td></tr>
<tr><td><code id="nlrq_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to printing function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An &lsquo;nlrq&rsquo; object is a type of fitted model object.  It has methods
for the generic functions &lsquo;coef&rsquo; (parameters estimation at best solution),
&lsquo;formula&rsquo; (model used), &lsquo;deviance&rsquo; (value of the objective function at best 
solution), &lsquo;print&rsquo;, &lsquo;summary&rsquo;, &lsquo;fitted&rsquo; (vector of fitted variable according
to the model), &lsquo;predict&rsquo; (vector of data points predicted by the model, using
a different matrix for the independent variables) and also for the function
&lsquo;tau&rsquo; (quantile used for fitting the model, as the tau argument of the
function). Further help is also available for the method &lsquo;residuals&rsquo;.
The summary method for nlrq uses a bootstrap approach based on the final
linearization of the model evaluated at the estimated parameters.  
</p>


<h3>Value</h3>

<p>A list consisting of: 
</p>
<table>
<tr><td><code>m</code></td>
<td>
<p>an &lsquo;nlrqModel&rsquo; object similar to an &lsquo;nlsModel&rsquo; in package nls</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the expression that was passed to &lsquo;nlrq&rsquo; as the data argument.
The actual data values are present in the environment of the
&lsquo;m&rsquo; component. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Based on S code by Roger Koenker modified for R and to accept models
as specified by nls by Philippe Grosjean.</p>


<h3>References</h3>

<p> Koenker, R. and Park, B.J. (1994). An Interior Point Algorithm for
Nonlinear Quantile Regression, Journal of Econometrics, 71(1-2): 265-283.
</p>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+nlrq.control">nlrq.control</a></code> , <code><a href="quantreg.html#topic+residuals.nlrq">residuals.nlrq</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># build artificial data with multiplicative error
Dat &lt;- NULL; Dat$x &lt;- rep(1:25, 20)
set.seed(1)
Dat$y &lt;- SSlogis(Dat$x, 10, 12, 2)*rnorm(500, 1, 0.1)
plot(Dat)
# fit first a nonlinear least-square regression
Dat.nls &lt;- nls(y ~ SSlogis(x, Asym, mid, scal), data=Dat); Dat.nls
lines(1:25, predict(Dat.nls, newdata=list(x=1:25)), col=1)
# then fit the median using nlrq
Dat.nlrq &lt;- nlrq(y ~ SSlogis(x, Asym, mid, scal), data=Dat, tau=0.5, trace=TRUE)
lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=2)
# the 1st and 3rd quartiles regressions
Dat.nlrq &lt;- nlrq(y ~ SSlogis(x, Asym, mid, scal), data=Dat, tau=0.25, trace=TRUE)
lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=3)
Dat.nlrq &lt;- nlrq(y ~ SSlogis(x, Asym, mid, scal), data=Dat, tau=0.75, trace=TRUE)
lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=3)
# and finally "external envelopes" holding 95 percent of the data
Dat.nlrq &lt;- nlrq(y ~ SSlogis(x, Asym, mid, scal), data=Dat, tau=0.025, trace=TRUE)
lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=4)
Dat.nlrq &lt;- nlrq(y ~ SSlogis(x, Asym, mid, scal), data=Dat, tau=0.975, trace=TRUE)
lines(1:25, predict(Dat.nlrq, newdata=list(x=1:25)), col=4)
leg &lt;- c("least squares","median (0.5)","quartiles (0.25/0.75)",".95 band (0.025/0.975)")
legend(1, 12.5, legend=leg, lty=1, col=1:4)
</code></pre>

<hr>
<h2 id='nlrq.control'> Set control parameters for nlrq </h2><span id='topic+nlrq.control'></span>

<h3>Description</h3>

<p>Set algorithmic parameters for nlrq (nonlinear quantile regression function)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlrq.control(maxiter=100, k=2, InitialStepSize = 1, big=1e+20, eps=1e-07, beta=0.97)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlrq.control_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of allowed iterations</p>
</td></tr>
<tr><td><code id="nlrq.control_+3A_k">k</code></td>
<td>
<p>the number of iterations of the Meketon algorithm to be calculated 
in each step, usually 2 is reasonable, occasionally it may be helpful 
to set k=1 </p>
</td></tr>
<tr><td><code id="nlrq.control_+3A_initialstepsize">InitialStepSize</code></td>
<td>
<p> Starting value in <code>optim</code> to determine the step
length of iterations.  The default value of 1 is sometimes too optimistic.
In such cases, the value 0 forces optim to just barely stick its toe in
the water.</p>
</td></tr>
<tr><td><code id="nlrq.control_+3A_big">big</code></td>
<td>
<p> a large scalar</p>
</td></tr>
<tr><td><code id="nlrq.control_+3A_eps">eps</code></td>
<td>
<p> tolerance for convergence of the algorithm </p>
</td></tr>
<tr><td><code id="nlrq.control_+3A_beta">beta</code></td>
<td>
<p> a shrinkage parameter which controls the recentering process 
in the interior point algorithm. </p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+nlrq">nlrq</a></code> </p>

<hr>
<h2 id='ParetoTest'>Estimation and Inference on the Pareto Tail Exponent for Linear Models</h2><span id='topic+ParetoTest'></span><span id='topic+Hill'></span><span id='topic+Hill.fit'></span><span id='topic+print.Hill'></span><span id='topic+summary.Hill'></span><span id='topic+print.summary.Hill'></span><span id='topic+Pickands.fit'></span><span id='topic+Pickands'></span><span id='topic+print.Pickands'></span><span id='topic+summary.Pickands'></span><span id='topic+print.summary.Pickands'></span><span id='topic+Pickands.fit'></span>

<h3>Description</h3>

<p>Estimation and inference about the tail behavior of the response in
linear models are based on the adaptation of the univariate Hill (1975)
and Pickands (1975) estimators for quantile regression by Chernozhukov,
Fernandez-Val and Kaji (2018).</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParetoTest(formula, tau = 0.1, data = NULL, flavor = "Hill", m = 2, cicov = .9, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ParetoTest_+3A_formula">formula</code></td>
<td>
<p>a formula specifying the model to fit by <code><a href="quantreg.html#topic+rq">rq</a></code></p>
</td></tr>
<tr><td><code id="ParetoTest_+3A_tau">tau</code></td>
<td>
<p>A threshold on which to base the estimation</p>
</td></tr>
<tr><td><code id="ParetoTest_+3A_data">data</code></td>
<td>
<p>a data frame within which to interpret the formula</p>
</td></tr>
<tr><td><code id="ParetoTest_+3A_flavor">flavor</code></td>
<td>
<p>Currently limited to either &quot;Hill&quot; or &quot;Pickands&quot;</p>
</td></tr>
<tr><td><code id="ParetoTest_+3A_m">m</code></td>
<td>
<p>a tuning parameter for the Pickands method .</p>
</td></tr> 
<tr><td><code id="ParetoTest_+3A_cicov">cicov</code></td>
<td>
<p>Desired coverage probability of confidence interval.</p>
</td></tr> 
<tr><td><code id="ParetoTest_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to <code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code>.
by default the summary method is the usual xy bootstrap, with
<code>B = 200</code> replications.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class ParetoTest  is returned containing:
</p>
<table>
<tr><td><code>z</code></td>
<td>
<p> A named vector with components: the estimate, a bias
corrected estimate, a lower bound of the confidence interval,
an upper bound of the confidence interval, and a Bootstrap
Standard Error estimate.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>The tau threshold used to compute the estimate
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chernozhukov, Victor, Ivan Fernandez-Val, and Tetsuya Kaji, (2018)
Extremal Quantile Regression, in Handbook of Quantile Regression, 
Eds. Roger Koenker, Victor Chernozhukov, Xuming He, Limin Peng,
CRC Press.
</p>
<p>Hill, B. M. (1975). A simple general approach to inference about the tail of a distribution. 
The Annals of Statistics 3(5), 1163-1174.
</p>
<p>Pickands, J. (1975). Statistical inference using extreme order statistics. 
The Annals of Statistics 3(1), 119-131.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n = 500
x = rnorm(n)
y = x + rt(n,2)
Z = ParetoTest(y ~ x, .9, flavor = "Pickands")
</code></pre>

<hr>
<h2 id='Peirce'>C.S. Peirce's Auditory Response Data</h2><span id='topic+Peirce'></span>

<h3>Description</h3>

<p>Data from sequence experiments conducted by C.S. Pierce in 1872 to
determine the distribution of response times to an auditory stimulus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Peirce)</code></pre>


<h3>Format</h3>

<p>A <code>link{list}</code> of 24 objects each representing one day of the
experiment.  Each element of the list consists of three components:
the date the measurements were made, an <code>x</code> component
recording the response time in milliseconds, and an associated  <code>y</code>
component recording a count of the number of times that the response
was recorded to be equal to be equal to the  corresponding <code>x</code> entry.
There  are roughly 500 observations (counts) on each of the 24 days.
</p>


<h3>Details</h3>

<p>A detailed description of the experiment can be found in Peirce (1873).  A
young man of about 18 with no prior experience was  employed to respond to
a signal  &ldquo;consisting of a sharp sound like a rap, the answer being made
upon a telegraph-operator's key nicely adjusted.&rdquo;  The response times,
made with the aid of a Hipp cronoscope were recorded to the nearest 
millisecond.  The data was analyzed by Peirce who concluded that after
the first day, when the the observer was entirely inexperienced, the
curves representing the densities of the response times &ldquo;differed very
little from that derived from the theory of least squares,&rdquo; i.e. from
the Gaussian density.
</p>
<p>The data was subsequently analysed by Samama, in a diploma thesis supervised
by Maurice Frechet, who reported briefly the findings in Frechet (1924),
and by Wilson and Hilferty (1929).  In both instances the reanalysis showed
that Laplace's first law of error, the double exponential distribution, was
a better representation for the data than was the Gaussian law.  Koenker (2009)
constains further discussion and an attempt to reproduce the Wilson and
Hilferty analysis.
</p>
<p>The data is available in two formats:  The first in a &quot;raw&quot; form as 24 text
files as scanned from the reprinted Peirce source, the second as an R
dataset <code>Peirce.rda</code> containing the list.  Only the latter
is provided here, for the raw data and how to read see the more complete
archive at:  <a href="http://www.econ.uiuc.edu/~roger/research/frechet/frechet.html">http://www.econ.uiuc.edu/~roger/research/frechet/frechet.html</a>
See the examples section below for some details on 
provisional  attempt to reproduce part of the Wilson and Hilferty
analysis.  An open question regarding the dataset is:  How did Wilson
and Hilferty compute standard deviations for the median as they appear
in their table?  The standard textbook suggestion of Yule (1917) yields
far too small a bandwidth.  The methods employed in the example section
below, which rely on relatively recent proposals, are somewhat closer, 
but still deviate somewhat from the results reported by Wilson and Hilferty.
</p>


<h3>Source</h3>

<p>Peirce, C.~S.  (1873): &ldquo;On the Theory of Errors of Observation,&rdquo;
<em>Report of the Superintendent of the U.S. Coast Survey</em>, pp. 200&ndash;224,
Reprinted in <em>The New Elements of Mathematics</em>, (1976) collected papers
of C.S. Peirce, ed. by C. Eisele, Humanities Press: Atlantic Highlands, N.J.,
vol. 3, part 1, 639&ndash;676.
</p>


<h3>References</h3>

<p>Fr\'echet, M.  (1924): &ldquo;Sur la loi des erreurs d'observation,&rdquo;
<em>Matematichiskii Sbornik</em>, 32, 5&ndash;8.
Koenker, R. (2009): &ldquo;The Median is the Message:  Wilson and Hilferty's 
Reanalysis of C.S. Peirce's Experiments on the Law of Errors,&rdquo; 
<em>American Statistician</em>, 63, 20-25.
Wilson, E.~B.,  and M.~M. Hilferty  (1929): &ldquo;Note on C.S.
Peirces Experimental Discussion of the Law of Errors,&rdquo; <em>Proceedings
of the National Academy of Sciences of the U.S.A.</em>, 15, 120&ndash;125.
Yule, G.~U.  (1917): <em>An Introduction to the Theory of
Statistics</em>. Charles Griffen: London, 4 edn.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Make table like Wilson and Hilferty

data("Peirce")
set.seed(10) #Dither the counts
tab &lt;- matrix(0,24,11)
for(i in 1:24){
	y &lt;- rep(Peirce[[i]]$x, Peirce[[i]]$y) + runif(sum(Peirce[[i]]$y), -.5, .5)
	f1 &lt;- summary(rq(y~1),se="iid")$coef[1:2]
	n &lt;- length(y)
	f0 &lt;- 1/(2 * sum(abs(y-f1[1])/n)) #Laplace proposal
	f0 &lt;- (1/(2 * f0))/ sqrt(n)
	f2 &lt;- summary(lm(y~1))$coef[1:2]
	outm &lt;- sum(y &lt; (f1[1] - 3.1 * sqrt(n) * f2[2]))
	outp &lt;- sum(y &gt; (f1[1] + 3.1 * sqrt(n) * f2[2]))
	outt &lt;- outm + outp
	inm &lt;- y &gt; (f1[1] - 0.25 * sqrt(n) * f2[2])
	inp &lt;- y &lt; (f1[1] + 0.25 * sqrt(n) * f2[2])
	int &lt;- sum(inm * inp)
	Eint &lt;- round(n * (pnorm(.25) - pnorm(-.25)))
	excess &lt;- round(100*(int - Eint)/Eint)
	tab[i,] &lt;- c(f1, f0, f2, outm, outp, outt,int,Eint,excess)
	cnames &lt;- c("med","sdmed1","sdmed0","mean","sdmean","below","above","outliers",
		"inliers","Einliers","ExcessIns")
	dimnames(tab) &lt;- list(paste("Day",1:24),cnames)
	}
</code></pre>

<hr>
<h2 id='plot.KhmaladzeTest'> Plot a KhmaladzeTest object</h2><span id='topic+plot.KhmaladzeTest'></span>

<h3>Description</h3>

<p>Plot an object generated by KhmaladzeTest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KhmaladzeTest'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.KhmaladzeTest_+3A_x">x</code></td>
<td>

<p>Object returned from KhmaladzeTest representing the fit of the model.
</p>
</td></tr>
<tr><td><code id="plot.KhmaladzeTest_+3A_...">...</code></td>
<td>

<p>Optional arguments. 
</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+KhmaladzeTest">KhmaladzeTest</a></code></p>

<hr>
<h2 id='plot.rq'> plot the coordinates of the quantile regression process</h2><span id='topic+plot.rq.process'></span>

<h3>Description</h3>

<p> Function to plot quantile regression  process.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq.process'
plot(x, nrow=3, ncol=2, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rq_+3A_x">x</code></td>
<td>
<p> an object produced by rq() fitting  </p>
</td></tr>
<tr><td><code id="plot.rq_+3A_nrow">nrow</code></td>
<td>
<p> rows in mfrow </p>
</td></tr>
<tr><td><code id="plot.rq_+3A_ncol">ncol</code></td>
<td>
<p> columns in mfrow</p>
</td></tr>
<tr><td><code id="plot.rq_+3A_...">...</code></td>
<td>
<p> optional arguments to plot</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Roger Koenker rkoenker@uiuc.edu</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rq">rq</a></code></p>

<hr>
<h2 id='plot.rqs'>Visualizing sequences of quantile regressions</h2><span id='topic+plot.rqs'></span>

<h3>Description</h3>

<p>A sequence of coefficient estimates for quantile
regressions with varying <code>tau</code> parameters is visualized.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rqs'
plot(x, parm = NULL, ols = TRUE,
  mfrow = NULL, mar = NULL, ylim = NULL, main = NULL, col = 1:2, lty = 1:2,
  cex = 0.5, pch = 20, type = "b", xlab = "", ylab = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rqs_+3A_x">x</code></td>
<td>
<p>an object of class <code>"rqs"</code> as produce by <code><a href="quantreg.html#topic+rq">rq</a></code>
(with a vector of <code>tau</code> values).</p>
</td></tr>
<tr><td><code id="plot.rqs_+3A_parm">parm</code></td>
<td>
<p>a specification of which parameters are to be plotted,
either a vector of numbers or a vector of names.  By default, all
parameters are considered.</p>
</td></tr>
<tr><td><code id="plot.rqs_+3A_ols">ols</code></td>
<td>
<p>logical. Should a line for the OLS coefficient (as estimated
by <code><a href="stats.html#topic+lm">lm</a></code>) be added?</p>
</td></tr>
<tr><td><code id="plot.rqs_+3A_mfrow">mfrow</code>, <code id="plot.rqs_+3A_mar">mar</code>, <code id="plot.rqs_+3A_ylim">ylim</code>, <code id="plot.rqs_+3A_main">main</code></td>
<td>
<p>graphical parameters. Suitable defaults are chosen
based on the coefficients to be visualized.</p>
</td></tr>
<tr><td><code id="plot.rqs_+3A_col">col</code>, <code id="plot.rqs_+3A_lty">lty</code></td>
<td>
<p>graphical parameters. For each parameter, the first
element corresponds to the <code>rq</code> coefficients and the second to
the <code>lm</code> coefficients.</p>
</td></tr>
<tr><td><code id="plot.rqs_+3A_cex">cex</code>, <code id="plot.rqs_+3A_pch">pch</code>, <code id="plot.rqs_+3A_type">type</code>, <code id="plot.rqs_+3A_xlab">xlab</code>, <code id="plot.rqs_+3A_ylab">ylab</code>, <code id="plot.rqs_+3A_...">...</code></td>
<td>
<p>further graphical parameters
passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> method for <code>"rqs"</code> objects visualizes the
coefficients only, confidence bands can be added by using the <code>plot</code>
method for the associated <code>"summary.rqs"</code> object.</p>


<h3>Value</h3>

<p>A matrix with all coefficients visualized is returned invisibly.</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+plot.summary.rqs">plot.summary.rqs</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## fit Engel models (in levels) for tau = 0.1, ..., 0.9
data("engel")
fm &lt;- rq(foodexp ~ income, data = engel, tau = 1:9/10)

## visualizations
plot(fm)
plot(fm, parm = 2, mar = c(5.1, 4.1, 2.1, 2.1), main = "", xlab = "tau", 
  ylab = "income coefficient", cex = 1, pch = 19)
</code></pre>

<hr>
<h2 id='plot.rqss'>Plot Method for rqss Objects</h2><span id='topic+plot.rqss'></span><span id='topic+plot.qss1'></span><span id='topic+plot.qts1'></span><span id='topic+plot.qss2'></span><span id='topic+plot.summary.rqss'></span>

<h3>Description</h3>

<p>Takes a fitted <code>rqss</code> object produced by <code>rqss()</code> and plots
the component smooth functions that make up the ANOVA decomposition.
Since the components &quot;omit the intercept&quot; the estimated intercept is added back
in &ndash; this facilitates the comparison of quantile fits particularly.
For models with a partial linear component or several <code>qss</code> components
it may be preferable to plot the output of <code>predict.rqss</code>.
Note that these functions are intended to plot <code>rqss</code> objects only, attempting
to plot summary.rqss  objects just generates a warning message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rqss'
plot(x, rug = TRUE, jit = TRUE, bands = NULL, coverage = 0.95,
	add = FALSE, shade = TRUE, select = NULL, pages = 0, titles = NULL, 
	bcol = NULL, ...)
## S3 method for class 'qss1'
plot(x, rug = TRUE, jit = TRUE, add = FALSE, ...)
## S3 method for class 'qts1'
plot(x, rug = TRUE, jit = TRUE, add = FALSE, ...)
## S3 method for class 'qss2'
plot(x, render = "contour", ncol = 100, zcol = NULL, ...)
## S3 method for class 'summary.rqss'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.rqss_+3A_x">x</code></td>
<td>
<p>a fitted <code>rqss</code> object produced by <code><a href="quantreg.html#topic+rqss">rqss</a>()</code>.</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_...">...</code></td>
<td>
<p>additional arguments for the plotting algorithm</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_rug">rug</code></td>
<td>
<p>if TRUE, a rugplot for the x-coordinate is plotted</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_jit">jit</code></td>
<td>
<p>if TRUE, the x-values of the rug plot are jittered</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_bands">bands</code></td>
<td>
<p>if TRUE, confidence bands for the smoothed effects are plotted, if
&quot;uniform&quot; then uniform bands are plotted, if &quot;both&quot; then both the uniform
and the pointwise bands are plotted.</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_coverage">coverage</code></td>
<td>
<p>desired coverage probability of confidence bands, if requested</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_select">select</code></td>
<td>
<p>vector of indices of qss objects to be plotted, by default all</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_pages">pages</code></td>
<td>
<p>number of pages desired for the plots</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_render">render</code></td>
<td>
<p>a character specifying the rendering for bivariate fits;
either <code>"contour"</code> (default) or <code>"rgl"</code>.  The latter
requires package <span class="pkg">rgl</span>.</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_add">add</code></td>
<td>
<p>if TRUE then add qss curve to existing (usually) scatterplot,
otherwise initiate a new plot</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_shade">shade</code></td>
<td>
<p>if TRUE then shade the confidence band</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_titles">titles</code></td>
<td>
<p>title(s) as vector of character strings, by default titles are chosen for
each plot as &quot;Effect of CovariateName&quot;</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_bcol">bcol</code></td>
<td>
<p>vector of two colors for confidence bands</p>
</td></tr>
<tr><td><code id="plot.rqss_+3A_ncol">ncol</code>, <code id="plot.rqss_+3A_zcol">zcol</code></td>
<td>
<p>Only for <code>render = "rgl"</code>: number of colors and
z values for color construction.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For univariate <code>qss</code> components with <code>Dorder = 0</code> the fitted
function is piecewise constant, not piecewise linear.  In this case the constraints 
are limited to increasing, decreasing or none.  
If <code>bands == "uniform"</code> then the bands are uniform bands based on the 
Hotelling (1939) tube approach.  See also Naiman (1986), 
Johansen and Johnstone (1990), Sun and Loader (1994), 
and Krivobokova, Kneib, and Claeskens (2009), in particular the computation of
the &quot;tube length&quot; is based on the last of these references.  If <code>bands</code>
is non null, and not &quot;uniform&quot; then pointwise bands are returned.
Since bands for bivariate components are not (yet) supported, if requested
such components will be returned as <code>NULL</code>.
</p>


<h3>Value</h3>

<p>The function produces plots for the ANOVA components as a side effect. For
<code>"qss1"</code> the <code>"add = TRUE"</code> can be used to overplot the fit on a 
scatterplot.  When there are multiple pages required <code>"par(ask = TRUE)"</code>
is turned on so that the plots may be examined sequentially.  If <code>bands != NULL</code>
then a list with three components for each qss component is returned (invisibly):
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>The x coordinates of the confidence bands</p>
</td></tr>
<tr><td><code>blo</code></td>
<td>
<p>The y coordinates of the lower confidence curve, if 
<code>bands = "both"</code> then this is a  matrix with two columns</p>
</td></tr>
<tr><td><code>bhi</code></td>
<td>
<p>The y coordinates of the upper confidence curve, if
<code>bands = "both"</code> then this is a  matrix with two columns</p>
</td></tr>	
</table>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p>[1] Hotelling, H.  (1939): &ldquo;Tubes and Spheres in $n$-spaces, and a class
of statistical problems,&rdquo; <em>Am J. Math</em>, 61, 440&ndash;460.
</p>
<p>[2] Johansen, S.,   and I.M. Johnstone  (1990): &ldquo;Hotelling's
Theorem on the Volume of Tubes: Some Illustrations in Simultaneous
Inference and Data Analysis,&rdquo; <em>The Annals of Statistics</em>, 18, 652&ndash;684.
</p>
<p>[3] Naiman, D. (1986)  Conservative confidence bands in curvilinear regression,  
<em>The Annals of Statistics</em>, 14, 896&ndash;906.
</p>
<p>[4] Sun, J. and C.R. Loader, (1994) Simultaneous confidence bands for linear
regression and smoothing, <em>The Annals of Statistics</em>, 22, 1328&ndash;1345.
</p>
<p>[5] Krivobokova, T., T. Kneib, and G. Claeskens (2009) Simultaneous Confidence
Bands for Penalized Spline Estimators, preprint.
</p>
<p>[6] Koenker, R. (2010) Additive Models for Quantile Regression:  Model Selection
and Confidence Bandaids, preprint.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rqss">rqss</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
x &lt;- sort(rchisq(n,4))
z &lt;- x + rnorm(n)
y &lt;- log(x)+ .1*(log(x))^2 + log(x)*rnorm(n)/4 + z
plot(x,y-z)
fN &lt;- rqss(y~qss(x,constraint="N")+z)
plot(fN)
fI &lt;- rqss(y~qss(x,constraint="I")+z)
plot(fI,  col="blue")
fCI &lt;- rqss(y~qss(x,constraint="CI")+z)
plot(fCI, col="red")


## A bivariate example
if(requireNamespace("interp")){
if(requireNamespace("interp")){
data(CobarOre)
fCO &lt;- rqss(z~qss(cbind(x,y),lambda=.08), data = CobarOre)
plot(fCO)
}}
</code></pre>

<hr>
<h2 id='plot.summary.rqs'>Visualizing sequences of quantile regression summaries</h2><span id='topic+plot.summary.rqs'></span><span id='topic+plot.summary.rq'></span>

<h3>Description</h3>

<p>A sequence of coefficient estimates for quantile
regressions with varying <code>tau</code> parameters is visualized
along with associated confidence bands.</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.rqs'
plot(x, parm = NULL, level = 0.9, ols = TRUE,
  mfrow = NULL, mar = NULL, ylim = NULL, main = NULL,
  col = gray(c(0, 0.75)), border = NULL, lcol = 2, lty = 1:2,
  cex = 0.5, pch = 20, type = "b", xlab = "", ylab = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.summary.rqs_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.rqs"</code> as produce by 
applying the <code>summary</code> method to a <code><a href="quantreg.html#topic+rq">rq</a></code> object
(with a vector of <code>tau</code> values).</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_parm">parm</code></td>
<td>
<p>a specification of which parameters are to be plotted,
either a vector of numbers or a vector of names.  By default, all
parameters are considered.</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_level">level</code></td>
<td>
<p>Confidence level of bands.  When using
the rank based confidence intervals in summary, which is the default
method for sample sizes under 1000, you will need to control the level
of the intervals by passing the parameter alpha to 
<code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code>, prior to calling 
<code><a href="quantreg.html#topic+plot.summary.rqs">plot.summary.rqs</a></code>.  Note also that alpha = 1 - level.</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_ols">ols</code></td>
<td>
<p>logical. Should a line for the OLS coefficient and their confidence
bands (as estimated by <code><a href="stats.html#topic+lm">lm</a></code>) be added?</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_mfrow">mfrow</code>, <code id="plot.summary.rqs_+3A_mar">mar</code>, <code id="plot.summary.rqs_+3A_ylim">ylim</code>, <code id="plot.summary.rqs_+3A_main">main</code></td>
<td>
<p>graphical parameters. Suitable defaults are chosen
based on the coefficients to be visualized.  It can be useful to use a common
vertical scale when plotting as a way of comparing confidence bands constructed
by different methods. For this purpose one can specify a <code>ylim</code> as a 
2 by <code>length(parm)</code> matrix.</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_col">col</code></td>
<td>
<p>vector of color specification for <code>rq</code> coefficients
and the associated confidence polygon.</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_border">border</code></td>
<td>
<p>color specification for the confidence polygon. By default,
the second element of <code>col</code> is used.</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_lcol">lcol</code>, <code id="plot.summary.rqs_+3A_lty">lty</code></td>
<td>
<p>color and line type specification for OLS coefficients
and their confidence bounds.</p>
</td></tr>
<tr><td><code id="plot.summary.rqs_+3A_cex">cex</code>, <code id="plot.summary.rqs_+3A_pch">pch</code>, <code id="plot.summary.rqs_+3A_type">type</code>, <code id="plot.summary.rqs_+3A_xlab">xlab</code>, <code id="plot.summary.rqs_+3A_ylab">ylab</code>, <code id="plot.summary.rqs_+3A_...">...</code></td>
<td>
<p>further graphical parameters
passed to <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot</code> method for <code>"summary.rqs"</code> objects visualizes
the coefficients along with their confidence bands. The bands can be
omitted by using the <code>plot</code> method for <code>"rqs"</code> objects directly.</p>


<h3>Value</h3>

<p>A list with components <code>z</code>, an array with all coefficients visualized 
(and associated confidence bands), and <code>Ylim</code>, a 2 by p matrix containing  
the y plotting limits.  The latter component may be useful for establishing a
common scale for two or more similar plots.  The list is returned invisibly.</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+plot.rqs">plot.rqs</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## fit Engel models (in levels) for tau = 0.1, ..., 0.9
data("engel")
fm &lt;- rq(foodexp ~ income, data = engel, tau = 1:9/10)
sfm &lt;- summary(fm)

## visualizations
plot(sfm)
plot(sfm, parm = 2, mar = c(5.1, 4.1, 2.1, 2.1), main = "", xlab = "tau", 
  ylab = "income coefficient", cex = 1, pch = 19)
</code></pre>

<hr>
<h2 id='predict.rq'>Quantile Regression Prediction</h2><span id='topic+predict.rq'></span><span id='topic+predict.rqs'></span><span id='topic+predict.rq.process'></span>

<h3>Description</h3>

<p>Prediction based on fitted quantile regression model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq'
predict(object, newdata, type = "none", interval = c("none", "confidence"), 
	level = .95, na.action = na.pass, ...)
## S3 method for class 'rqs'
predict(object, newdata, type = "Qhat", stepfun = FALSE, na.action = na.pass, ...)
## S3 method for class 'rq.process'
predict(object, newdata, type = "Qhat", stepfun = FALSE, na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rq_+3A_object">object</code></td>
<td>
<p> object of class rq or rqs or rq.process produced by <code>rq</code> </p>
</td></tr>
<tr><td><code id="predict.rq_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame in which to look for variables with
which to predict.  If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict.rq_+3A_interval">interval</code></td>
<td>
<p>type of interval desired:  default is  'none', when set to
'confidence' the function returns a matrix predictions with point predictions
for each of the 'newdata' points as well as lower and upper confidence limits.</p>
</td></tr>
<tr><td><code id="predict.rq_+3A_level">level</code></td>
<td>
<p>converage probability for the 'confidence' intervals.</p>
</td></tr>
<tr><td><code id="predict.rq_+3A_type">type</code></td>
<td>
<p>For <code>predict.rq</code>, the  method for 'confidence' intervals, if desired. 
If 'percentile' then one of the bootstrap methods is used to generate percentile 
intervals for each prediction, if 'direct' then a version of the Portnoy and Zhou 
(1998) method is used, and otherwise an estimated covariance matrix for the parameter
estimates is used.  Further arguments to determine the choice of bootstrap
method or covariance matrix estimate can be passed via the ... argument.
For <code>predict.rqs</code> and <code>predict.rq.process</code> when <code>stepfun = TRUE</code>,
<code>type</code> is &quot;Qhat&quot;, &quot;Fhat&quot; or &quot;fhat&quot; depending  on whether the user would
like to have estimates of the conditional quantile, distribution or density  functions
respectively.  As noted below the two former estimates can be monotonized with the 
function <code>rearrange</code>.  When the &quot;fhat&quot; option is invoked, a list of conditional
density functions is returned based on Silverman's adaptive kernel method as
implemented in <code>akj</code> and <code>approxfun</code>.</p>
</td></tr>
<tr><td><code id="predict.rq_+3A_stepfun">stepfun</code></td>
<td>
<p>If 'TRUE' return stepfunctions otherwise return matrix of predictions.
these functions can be estimates of either the conditional quantile or distribution
functions depending upon the <code>type</code> argument.  When <code>stepfun = FALSE</code>
a matrix of point estimates of the conditional quantile function at the points
specified by the <code>newdata</code> argument. </p>
</td></tr>
<tr><td><code id="predict.rq_+3A_na.action">na.action</code></td>
<td>
<p> function determining what should be done with missing values
in 'newdata'.  The default is to predict 'NA'.</p>
</td></tr>
<tr><td><code id="predict.rq_+3A_...">...</code></td>
<td>
<p> Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Produces predicted values, obtained by evaluating the quantile
regression function in the frame 'newdata' (which defaults to
'model.frame(object)'.  These predictions purport to estimate
the conditional quantile function of the response variable of
the fitted model evaluated at the covariate values specified
in &quot;newdata&quot; and the quantile(s) specified by the &quot;tau&quot; argument.
Several methods are provided to compute confidence intervals for
these predictions.  
</p>


<h3>Value</h3>

<p>A vector or matrix of predictions, depending upon the setting of 
'interval'.  In the case that there are multiple taus in <code>object</code>
when object is of class 'rqs' setting 'stepfun = TRUE'  will produce a
<code>stepfun</code> object or a list of <code>stepfun</code> objects.
The function <code>rearrange</code> can be used to monotonize these
step-functions, if desired.
</p>


<h3>Author(s)</h3>

<p>R. Koenker</p>


<h3>References</h3>

 
<p>Zhou, Kenneth Q. and Portnoy, Stephen L. (1998) 
Statistical inference on heteroscedastic models based on regression quantiles 
Journal of Nonparametric Statistics, 9, 239-260 
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rq">rq</a></code> <code><a href="quantreg.html#topic+rearrange">rearrange</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(airquality)
airq &lt;- airquality[143:145,]
f &lt;- rq(Ozone ~ ., data=airquality)
predict(f,newdata=airq)
f &lt;- rq(Ozone ~ ., data=airquality, tau=1:19/20)
fp &lt;- predict(f, newdata=airq, stepfun = TRUE)
fpr &lt;- rearrange(fp)
plot(fp[[2]],main = "Conditional Ozone Quantile Prediction")
lines(fpr[[2]], col="red")
legend(.2,20,c("raw","cooked"),lty = c(1,1),col=c("black","red"))
fp &lt;- predict(f, newdata=airq, type = "Fhat", stepfun = TRUE)
fpr &lt;- rearrange(fp)
plot(fp[[2]],main = "Conditional Ozone Distribution Prediction")
lines(fpr[[2]], col="red")
legend(20,.4,c("raw","cooked"),lty = c(1,1),col=c("black","red"))
  </code></pre>

<hr>
<h2 id='predict.rqss'>Predict from fitted nonparametric quantile regression smoothing spline models</h2><span id='topic+predict.rqss'></span><span id='topic+predict.qss1'></span><span id='topic+predict.qss2'></span>

<h3>Description</h3>

<p>Additive models for nonparametric quantile regression using total
variation penalty methods can be fit with the <code><a href="quantreg.html#topic+rqss">rqss</a></code>
function.  Univarariate and bivariate components can be predicted
using these functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rqss'
predict(object, newdata, interval = "none", level = 0.95, ...)
## S3 method for class 'qss1'
predict(object, newdata, ...)
## S3 method for class 'qss2'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.rqss_+3A_object">object</code></td>
<td>
<p> is a fitted object produced by <code><a href="quantreg.html#topic+rqss">rqss</a></code> </p>
</td></tr>
<tr><td><code id="predict.rqss_+3A_newdata">newdata</code></td>
<td>
<p> a data frame describing the observations at which
prediction is to be made.  For qss components, newdata should
lie in strictly within the convex hull of the fitting data.  Newdata
corresponding to the partially linear component of the model
may require caution concerning the treatment of factor levels, if any.</p>
</td></tr>
<tr><td><code id="predict.rqss_+3A_interval">interval</code></td>
<td>
<p>If set to <code>confidence</code> then a <code>level</code> confidence interval
for the predictions is returned.</p>
</td></tr>
<tr><td><code id="predict.rqss_+3A_level">level</code></td>
<td>
<p>intended coverage probability for the confidence intervals</p>
</td></tr>
<tr><td><code id="predict.rqss_+3A_...">...</code></td>
<td>
<p> optional arguments </p>
</td></tr>
</table>


<h3>Details</h3>

<p>For both univariate and bivariate prediction linear interpolation is
done.  In the bivariate case, this involves computing barycentric
coordinates of the new points relative to their enclosing triangles.
It may be of interest to plot individual components of fitted rqss
models:  this is usually best done by fixing the values of other
covariates at reference values typical of the sample data and
predicting the response at varying values of one qss term at a
time.   Direct use of the <code>predict.qss1</code> and <code>predict.qss2</code> functions
is discouraged since it usually corresponds to predicted values
at absurd  reference values of the other covariates, i.e. zero.
</p>


<h3>Value</h3>

<p>A vector of predictions, or in the case that <code>interval = "confidence")</code>
a matrix whose first column is the vector of predictions and whose second and
third columns are the lower and upper confidence limits for each prediction.
</p>


<h3>Author(s)</h3>

<p> R. Koenker </p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rqss">rqss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
lam &lt;- 2
x &lt;- sort(rchisq(n,4))
z &lt;- exp(rnorm(n)) + x
y &lt;- log(x)+ .1*(log(x))^2 + z/4 +  log(x)*rnorm(n)/4
plot(x,y - z/4 + mean(z)/4)
Ifit &lt;- rqss(y ~ qss(x,constraint="I") + z)
sfit &lt;- rqss(y ~ qss(x,lambda = lam) + z)
xz &lt;- data.frame(z = mean(z),
                 x = seq(min(x)+.01,max(x)-.01,by=.25))
lines(xz[["x"]], predict(Ifit, xz), col=2)
lines(xz[["x"]], predict(sfit, xz), col=3)
legend(10,2,c("Increasing","Smooth"),lty = 1, col = c(2,3))
title("Predicted Median Response at Mean Value of z")


## Bivariate example -- loads pkg "interp"
if(requireNamespace("interp")){
if(requireNamespace("interp")){
data(CobarOre)
fit &lt;- rqss(z ~ qss(cbind(x,y), lambda=.08),
            data= CobarOre)
plot(fit, col="grey",
     main = "CobarOre data -- rqss(z ~ qss(cbind(x,y)))")
T &lt;- with(CobarOre, interp::tri.mesh(x, y))
set.seed(77)
ndum &lt;- 100
xd &lt;- with(CobarOre, runif(ndum, min(x), max(x)))
yd &lt;- with(CobarOre, runif(ndum, min(y), max(y)))
table(s &lt;- interp::in.convex.hull(T, xd, yd))
pred &lt;- predict(fit, data.frame(x = xd[s], y = yd[s]))
contour(interp::interp(xd[s],yd[s], pred),
        col="red", add = TRUE)
}}</code></pre>

<hr>
<h2 id='print.KhmaladzeTest'> Print a KhmaladzeTest object</h2><span id='topic+print.KhmaladzeTest'></span>

<h3>Description</h3>

<p>Print an object generated by KhmaladzeTest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'KhmaladzeTest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.KhmaladzeTest_+3A_x">x</code></td>
<td>

<p>Object returned from KhmaladzeTest representing the fit of the model.
</p>
</td></tr>
<tr><td><code id="print.KhmaladzeTest_+3A_...">...</code></td>
<td>

<p>Optional arguments. 
</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+KhmaladzeTest">KhmaladzeTest</a></code></p>

<hr>
<h2 id='print.rq'> Print an rq object</h2><span id='topic+print.rq'></span><span id='topic+print.rqs'></span>

<h3>Description</h3>

<p>Print an object generated by rq
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq'
print(x, ...)
## S3 method for class 'rqs'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.rq_+3A_x">x</code></td>
<td>

<p>Object returned from rq representing the fit of the model.
</p>
</td></tr>
<tr><td><code id="print.rq_+3A_...">...</code></td>
<td>

<p>Optional arguments. 
</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+rq">rq</a></code></p>

<hr>
<h2 id='print.summary.rq'> Print Quantile Regression Summary Object </h2><span id='topic+print.summary.rq'></span><span id='topic+print.summary.rqs'></span>

<h3>Description</h3>

<p>Print summary of quantile regression object</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.rq'
print(x, digits=max(5, .Options$digits - 2), ...)
## S3 method for class 'summary.rqs'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.rq_+3A_x">x</code></td>
<td>

<p>This is an object of class <code>"summary.rq"</code> produced by a call to 
<code>summary.rq()</code>.
</p>
</td></tr>
<tr><td><code id="print.summary.rq_+3A_digits">digits</code></td>
<td>

<p>Significant digits reported in the printed table.
</p>
</td></tr>
<tr><td><code id="print.summary.rq_+3A_...">...</code></td>
<td>

<p>Optional arguments passed to printing function
</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code> </p>

<hr>
<h2 id='q489'>Even Quicker Sample Quantiles </h2><span id='topic+q489'></span>

<h3>Description</h3>

<p>The function <code>q489</code> computes a single sample quantile using a 
fortran implementation of the Floyd and Rivest (1975) algorithm.
In contrast to the more elaborate function <code>kuantile</code> that uses
the Kiweil (2005) implementation it does not attempt to replicate the
nine varieties of quantiles as documented in the base function.
<code>quantile</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>q489(x, tau = .5) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="q489_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="q489_+3A_tau">tau</code></td>
<td>
<p>the quantile of intereste.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> This is a direct translation of the Algol 68 implementation of
Floyd and Rivest (1975), implemented in Ratfor.  For the median, average 
case behavior requires <code class="reqn">1.5 n + O((n log n)^{1/2})</code> comparisons. 
In preliminary experiments it seems to be somewhat faster in large samples
than the implementation <code>kuantile</code> of Kiwiel (2005). See  Knuth (1998)
for further details. No provision is made for non-uniqueness of the quantile.
so, when <code class="reqn">\tau n</code> is an integer there may be some discrepancy.</p>


<h3>Value</h3>

<p>A scalar quantile of the same length as the vector p.
</p>


<h3>Author(s)</h3>

<p> R.W.Floyd and R.L.Rivest, R implementation:  Roger Koenker </p>


<h3>References</h3>

 
<p>R.W. Floyd and R.L. Rivest: &quot;Algorithm 489: The Algorithm
SELECT&mdash;for Finding the $i$th Smallest of $n$ Elements&quot;,
Comm. ACM 18, 3 (1975) 173,
</p>
<p>K.C. Kiwiel: On Floyd and Rivest's SELECT Algorithm, Theoretical
Computer Sci. 347 (2005) 214-238.
</p>
<p>D. Knuth, The Art of Computer Programming, Volume 3, Sorting and 
Searching, 2nd Ed., (1998), Addison-Wesley.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+quantile">quantile</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>     medx &lt;- q489(rnorm(1001))
</code></pre>

<hr>
<h2 id='qrisk'> Function to compute Choquet portfolio weights</h2><span id='topic+qrisk'></span>

<h3>Description</h3>

<p>This function solves a weighted quantile regression problem to find the
optimal portfolio weights minimizing a Choquet risk criterion described
in Bassett, Koenker, and Kordas (2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qrisk(x, alpha = c(0.1, 0.3), w = c(0.7, 0.3), mu = 0.07, 
      R = NULL, r = NULL, lambda = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qrisk_+3A_x">x</code></td>
<td>
<p>n by q matrix of historical or simulated asset returns </p>
</td></tr>
<tr><td><code id="qrisk_+3A_alpha">alpha</code></td>
<td>
<p>vector of alphas receiving positive weights in the Choquet criterion</p>
</td></tr>
<tr><td><code id="qrisk_+3A_w">w</code></td>
<td>
<p>weights associated with alpha in the Choquet criterion  </p>
</td></tr>
<tr><td><code id="qrisk_+3A_mu">mu</code></td>
<td>
<p>targeted rate of return for the portfolio</p>
</td></tr>
<tr><td><code id="qrisk_+3A_r">R</code></td>
<td>
<p>matrix of constraints on the parameters of the quantile regression, see below</p>
</td></tr>
<tr><td><code id="qrisk_+3A_r">r</code></td>
<td>
<p>rhs vector of the constraints described by R</p>
</td></tr>
<tr><td><code id="qrisk_+3A_lambda">lambda</code></td>
<td>
<p>Lagrange multiplier associated with the constraints</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function calls <code>rq.fit.hogg</code> which in turn calls the constrained Frisch
Newton algorithm.  The constraints Rb=r are intended to apply only to the slope
parameters, not the intercept parameters.  The user is completely responsible to
specify constraints that are consistent, ie that have at least one feasible point.
See examples for imposing non-negative portfolio weights.
</p>


<h3>Value</h3>

<table>
<tr><td><code>pihat</code></td>
<td>
<p>the optimal portfolio weights</p>
</td></tr>
<tr><td><code>muhat</code></td>
<td>
<p>the in-sample mean return of the optimal portfolio</p>
</td></tr>
<tr><td><code>qrisk</code></td>
<td>
<p>the in-sample Choquet risk of the optimal portfolio</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> R. Koenker </p>


<h3>References</h3>

<p><a href="http://www.econ.uiuc.edu/~roger/research/risk/risk.html">http://www.econ.uiuc.edu/~roger/research/risk/risk.html</a>
</p>
<p>Bassett, G., R. Koenker, G Kordas, (2004) Pessimistic Portfolio Allocation and 
Choquet Expected Utility, J. of Financial Econometrics,  2, 477-492.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq.fit.hogg">rq.fit.hogg</a></code>, <code><a href="quantreg.html#topic+srisk">srisk</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>#Fig 1:  ... of Choquet paper
        mu1 &lt;- .05; sig1 &lt;- .02; mu2 &lt;- .09; sig2 &lt;- .07
        x &lt;- -10:40/100
        u &lt;- seq(min(c(x)),max(c(x)),length=100)
        f1 &lt;- dnorm(u,mu1,sig1)
        F1 &lt;- pnorm(u,mu1,sig1)
        f2 &lt;- dchisq(3-sqrt(6)*(u-mu1)/sig1,3)*(sqrt(6)/sig1)
        F2 &lt;- pchisq(3-sqrt(6)*(u-mu1)/sig1,3)
        f3 &lt;- dnorm(u,mu2,sig2)
        F3 &lt;- pnorm(u,mu2,sig2)
        f4 &lt;- dchisq(3+sqrt(6)*(u-mu2)/sig2,3)*(sqrt(6)/sig2)
        F4 &lt;- pchisq(3+sqrt(6)*(u-mu2)/sig2,3)
        plot(rep(u,4),c(f1,f2,f3,f4),type="n",xlab="return",ylab="density")
        lines(u,f1,lty=1,col="blue")
        lines(u,f2,lty=2,col="red")
        lines(u,f3,lty=3,col="green")
        lines(u,f4,lty=4,col="brown")
        legend(.25,25,paste("Asset ",1:4),lty=1:4,col=c("blue","red","green","brown"))
#Now generate random sample of returns from these four densities.
n &lt;- 1000
if(TRUE){ #generate a new returns sample if TRUE
	x1 &lt;- rnorm(n)
	x1 &lt;- (x1-mean(x1))/sqrt(var(x1))
	x1 &lt;- x1*sig1 + mu1
	x2 &lt;- -rchisq(n,3)
	x2 &lt;- (x2-mean(x2))/sqrt(var(x2))
	x2 &lt;- x2*sig1 +mu1
	x3 &lt;- rnorm(n)
	x3 &lt;- (x3-mean(x3))/sqrt(var(x3))
	x3 &lt;- x3*sig2 +mu2
	x4 &lt;- rchisq(n,3)
	x4 &lt;- (x4-mean(x4))/sqrt(var(x4))
	x4 &lt;- x4*sig2 +mu2
	}
library(quantreg)
x &lt;- cbind(x1,x2,x3,x4)
qfit &lt;- qrisk(x)
sfit &lt;- srisk(x)
# Try new distortion function
qfit1 &lt;- qrisk(x,alpha = c(.05,.1), w = c(.9,.1),mu = 0.09)
# Constrain portfolio weights to be non-negative
qfit2 &lt;- qrisk(x,alpha = c(.05,.1), w = c(.9,.1),mu = 0.09,
	       R = rbind(rep(-1,3), diag(3)), r = c(-1, rep(0,3)))
</code></pre>

<hr>
<h2 id='qss'>Additive Nonparametric Terms for rqss Fitting</h2><span id='topic+qss'></span><span id='topic+qss1'></span><span id='topic+qts1'></span><span id='topic+qss2'></span><span id='topic+triogram.fidelity'></span><span id='topic+triogram.penalty'></span>

<h3>Description</h3>

<p>In the formula specification of <code>rqss</code> nonparametric terms
are specified with <code>qss</code>.  Both univariate and bivariate
specifications are possible, and qualitative constraints may also be specified
for the qss terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qss(x, constraint = "N", lambda = 1, ndum = 0, dummies = NULL, 
    Dorder = 1, w = rep(1, length(x)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qss_+3A_x">x</code></td>
<td>
<p>The covariate determining the nonparametric component, if
x is a matrix with two columns then  the qss
function will construct a penalized triogram term.</p>
</td></tr>
<tr><td><code id="qss_+3A_lambda">lambda</code></td>
<td>
<p>The smoothing parameter governing the tradeoff between
fidelity and the penalty component for this term.  Larger lambdas
produce smoother fits. In future
versions there should be an automatic mechanism for default
choice of the lambdas.  For now, this is the responsibility
of the user.</p>
</td></tr>
<tr><td><code id="qss_+3A_constraint">constraint</code></td>
<td>
<p>Optional specification of qualitative constraints
on the fitted univariate qss functions, take the values: &quot;N&quot;,&quot;I&quot;,&quot;D&quot;,&quot;V&quot;,&quot;C&quot;
&quot;VI&quot;,&quot;VD&quot;,&quot;CI&quot;,&quot;CD&quot; for none, increasing, decreasing, convex,
concave, convex and increasing, etc.  And for bivariate qss
components can take the values &quot;N&quot;,&quot;V&quot;,&quot;C&quot; for none, convex, and concave.
Note that confidence bands for constrained fits of this sort, while
available from <code>plot.rqss</code> as of yet lack a formal justification.</p>
</td></tr>
<tr><td><code id="qss_+3A_ndum">ndum</code></td>
<td>
<p>number of dummy vertices: this is only relevant for qss2
terms.  In addition to vertices at the observed (x,y) points
ndum dummy vertices are generated &ndash; distributed uniformly over
the rectangle given by the Cartesian product of the ranges of
x and y &ndash; observations that fall in the convex hull of the
observations are retained. So the actual number of dummy
vertices used is smaller than ndum.  The values of these
vertices are returned in the list dummies, so that they can
be reused.</p>
</td></tr>
<tr><td><code id="qss_+3A_dorder">Dorder</code></td>
<td>
<p>Order of the total variation penalty, the default of 1
implies a penalty on the first derivative of the fitted function,
a value of 0 implies total variation of the fitted function
itself will be penalized.  Note that only monotonicity constraints,
&quot;I&quot; and &quot;D&quot; are allowed when <code>Dorder = 0</code>, and result in estimates
that are equivalent to a form of isotonic regression when lambda is
sufficiently near zero.  Results in this case from the package <span class="pkg">isotone</span>
may differ slightly when plotted due to multiple solutions so it is prudent
to evaluate the objective function for both solutions.</p>
</td></tr>
<tr><td><code id="qss_+3A_dummies">dummies</code></td>
<td>
<p>list of dummy vertices as generated, for example by
triogram.fidelity when ndum &gt; 0.  Should be a list with x
and y components.  These points should lie inside the convex
hull of the real xy points, but no explicit checking of this
assertion is currently done.</p>
</td></tr>
<tr><td><code id="qss_+3A_w">w</code></td>
<td>
<p> weights not yet unimplemented </p>
</td></tr>
</table>


<h3>Details</h3>

<p>The various pieces returned are stored in sparse matrix.csr form.
See <code><a href="quantreg.html#topic+rqss">rqss</a></code> for details on how they are assembled.  To preserve the
sparsity of the design matrix the first column of each qss term is dropped.
This differs from the usual convention that would have forced qss terms
to have mean zero.  This convention has implications for prediction that need to be
recognized.  The penalty components for qss terms are based on total
variation penalization of the first derivative (and gradient, for bivariate x)
as described in the references appearing in the help for <code>rqss</code>.
When Dorder = 0, fitting is like the taut string methods of Davies (2014), except
for the fact that fidelity is quantilesque rather than quadratic,
and that no provision is made for automatic selection of the smoothing 
parameter.
</p>
<p>For the bivariate case, package <span class="pkg">interp</span> (and for plotting also
<span class="pkg">interp</span>) are required (automatically, by the <span class="rlang"><b>R</b></span> code).
</p>


<h3>Value</h3>

<table>
<tr><td><code>F</code></td>
<td>
<p>Fidelity component of the design matrix</p>
</td></tr>
<tr><td><code>dummies</code></td>
<td>
<p>List of dummy vertices</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>Penalty component of the design matrix</p>
</td></tr>
<tr><td><code>R</code></td>
<td>
<p>Constraint component of the design matrix</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Constraint component of the rhs</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker</p>


<h3>References</h3>

<p>Davies, Laurie (2014) <em>Data Analysis and Approximate Models</em>, CRC Press.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rqss">rqss</a></code></p>

<hr>
<h2 id='QTECox'>Function to obtain QTE from a Cox model</h2><span id='topic+QTECox'></span>

<h3>Description</h3>

<p>Computes quantile treatment effects comparable to those of 
crq model from a coxph object.</p>


<h3>Usage</h3>

<pre><code class='language-R'>QTECox(x, smooth = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QTECox_+3A_x">x</code></td>
<td>
<p>An object of class coxph produced by <code>coxph</code>.</p>
</td></tr>
<tr><td><code id="QTECox_+3A_smooth">smooth</code></td>
<td>
<p>Logical indicator if TRUE (default) 
then Cox survival function is smoothed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Estimates of the Cox QTE, <code class="reqn">\frac{dQ(t|x)}{dx_{j}}</code> 
at <code class="reqn">x=\bar{x}</code>, can be expressed as a function of t as follows:
</p>
<p style="text-align: center;"><code class="reqn">\frac{dQ(t|x)}{dx_{j}}=\frac{dt}{dx_{j}}\frac{dQ(t|x)}{dt}</code>
</p>

<p>The Cox survival function, <code class="reqn">S(y|x)=\exp \{-H_{0}(y)\exp (b^{\prime
}x)\}</code>
</p>
<p style="text-align: center;"><code class="reqn">\frac{dS(y|x)}{dx_{j}}=S(y|x)log \{S(y|x)\}b_{j}</code>
</p>

<p>where <code class="reqn">\frac{dQ(t|x)}{dx_{j}}</code>
can be estimated by <code class="reqn">\frac{\Delta (t)}{\Delta (S)}
(1-t)</code>
where $S$  and $t$ denote the <code>surv</code> and <code>time</code> components
of the  <code>survfit</code> object.
Note that since <code class="reqn">t=1-S(y|x)</code>, the above is the 
value corresponding to the argument $(1-t)$; and furthermore
</p>
<p style="text-align: center;"><code class="reqn">\frac{dt}{dx_{j}}=-\frac{dS(y|x)}{dx_{j}}=-(1-t) log (1-t)b_{j}</code>
</p>

<p>Thus the QTE at the mean of x's is:
</p>
<p style="text-align: center;"><code class="reqn">(1-S)= \frac{\Delta (t)}{\Delta (S)}S ~log
(S)b_{j}</code>
</p>

<p>Since <code class="reqn">\Delta S</code> is negative and $log (S)$ is also negative
this has the same sign as <code class="reqn">b_{j}</code>
The crq  model fits the usual AFT form  Surv(log(Time),Status), then 
</p>
<p style="text-align: center;"><code class="reqn">\frac{d log (Q(t|x))}{dx_{j}}=\frac{dQ(t|x)}{dx_{j}}/
Q(t|x)</code>
</p>

<p>This is the matrix form returned.
</p>


<h3>Value</h3>

<table>
<tr><td><code>taus</code></td>
<td>
<p>points of evaluation of the QTE.</p>
</td></tr>
<tr><td><code>QTE</code></td>
<td>
<p>matrix of QTEs, the ith column contains the QTE for the
ith covariate effect.  Note that there is no intercept effect.
see <code>plot.summary.crqs</code> for usage.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roger Koenker Stephen Portnoy &amp; Tereza Neocleous</p>


<h3>References</h3>

<p>Koenker, R. and Geling, O. (2001). Reappraising Medfly 
longevity: a quantile regression survival analysis, J. Amer. Statist. 
Assoc., 96, 458-468</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+crq">crq</a></code></p>

<hr>
<h2 id='ranks'>
Quantile Regression Ranks
</h2><span id='topic+ranks'></span>

<h3>Description</h3>

<p>Function to compute ranks from the dual (regression rankscore) process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranks(v, score="wilcoxon", tau=0.5, trim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ranks_+3A_v">v</code></td>
<td>

<p>object of class <code>"rq.process"</code> generated by <code>rq()</code>
</p>
</td></tr>
<tr><td><code id="ranks_+3A_score">score</code></td>
<td>

<p>The score function desired.  Currently  implemented score  functions  
are <code>"wilcoxon"</code>, <code>"normal"</code>, and <code>"sign"</code>
which are asymptotically optimal  for  
the  logistic,  Gaussian  and Laplace location shift models respectively.
The &quot;normal&quot; score  function is also sometimes called van der Waerden scores.
Also implemented are the <code>"tau"</code> which generalizes sign scores to an
arbitrary quantile, <code>"interquartile"</code> which is appropriate
for tests of scale shift, <code>normalscale</code> for Gaussian scale shift,
<code>halfnormalscale</code> for Gaussian scale shift only to the right of the median,
and <code>lehmann</code> for Lehmann local alternatives. See Koenker (2010) for
further details on the last three of these scores.
</p>
</td></tr>
<tr><td><code id="ranks_+3A_tau">tau</code></td>
<td>

<p>the optional value of <code>tau</code> if the <code>"tau"</code> score function is used.
</p>
</td></tr>
<tr><td><code id="ranks_+3A_trim">trim</code></td>
<td>
<p>optional trimming proportion parameter(s)  &ndash; only applicable for the
Wilcoxon score function &ndash;  when one value is provided there is symmetric 
trimming of the score integral to the interval <code>(trim, 1-trim)</code>, when
there are two values provided, then the trimming restricts the integration
to <code>(trim[1], trim[2])</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See GJKP(1993) for further details.
</p>


<h3>Value</h3>

<p>The function returns two components. One is the ranks,  the
other is a scale factor which is the <code class="reqn">L_2</code> norm of the score
function.  All score functions should be normalized to have mean zero.
</p>


<h3>References</h3>

<p>Gutenbrunner, C., J. Jureckova,  Koenker, R. and  Portnoy,
S. (1993)  Tests  of linear hypotheses  based on regression
rank scores, <em>Journal of  Nonparametric  Statistics</em>,  (2), 307&ndash;331.
</p>
<p>Koenker, R. Rank Tests for Heterogeneous Treatment Effects with Covariates, preprint.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+rq.test.rank">rq.test.rank</a></code> <code><a href="stats.html#topic+anova">anova</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
ranks(rq(stack.loss ~ stack.x, tau=-1))
</code></pre>

<hr>
<h2 id='rearrange'>Rearrangement</h2><span id='topic+rearrange'></span>

<h3>Description</h3>

<p> Monotonize a step function by rearrangement </p>


<h3>Usage</h3>

<pre><code class='language-R'> rearrange(f,xmin,xmax) </code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="rearrange_+3A_f">f</code></td>
<td>
<p> object of class stepfun </p>
</td></tr> 
<tr><td><code id="rearrange_+3A_xmin">xmin</code></td>
<td>
<p>minimum of the support of the rearranged f</p>
</td></tr> 
<tr><td><code id="rearrange_+3A_xmax">xmax</code></td>
<td>
<p>maximum of the support of the rearranged f</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>Given a stepfunction <code class="reqn">Q(u)</code>, not necessarily monotone, let 
<code class="reqn">F(y) = \int \{ Q(u) \le y \} du</code> denote the associated cdf
obtained by randomly evaluating <code class="reqn">Q</code> at <code class="reqn">U \sim U[0,1]</code>.  The
rearranged version of <code class="reqn">Q</code> is <code class="reqn">\tilde Q (u) = \inf \{
   u: F(y) \ge u \}.  The rearranged function inherits the right
   or left continuity of original stepfunction.</code>
</p>


<h3>Value</h3>

<p> Produces transformed stepfunction that is monotonic increasing.  </p>


<h3>Author(s)</h3>

<p>R. Koenker</p>


<h3>References</h3>

 
<p>Chernozhukov, V., I. Fernandez-Val, and A. Galichon, (2006)  Quantile and Probability
Curves without Crossing, Econometrica, forthcoming.
</p>
<p>Chernozhukov, V., I. Fernandez-Val, and A. Galichon, (2009)  Improving Estimates of
Monotone Functions by Rearrangement, Biometrika, 96, 559&ndash;575. 
</p>
<p>Hardy, G.H., J.E. Littlewood, and G. Polya (1934)  Inequalities,  Cambridge U. Press.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rq">rq</a></code> <code><a href="quantreg.html#topic+rearrange">rearrange</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(engel)
z &lt;- rq(foodexp ~ income, tau = -1,data =engel)
zp &lt;- predict(z,newdata=list(income=quantile(engel$income,.03)),stepfun = TRUE)
plot(zp,do.points = FALSE, xlab = expression(tau),
        ylab = expression(Q ( tau )), main="Engel Food Expenditure Quantiles")
plot(rearrange(zp),do.points = FALSE, add=TRUE,col.h="red",col.v="red")
legend(.6,300,c("Before Rearrangement","After Rearrangement"),lty=1,col=c("black","red"))
</code></pre>

<hr>
<h2 id='residuals.nlrq'> Return residuals of an nlrq object </h2><span id='topic+residuals.nlrq'></span>

<h3>Description</h3>

<p>Set algorithmic parameters for nlrq (nonlinear quantile regression function)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nlrq'
residuals(object, type = c("response", "rho"), ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.nlrq_+3A_object">object</code></td>
<td>
<p>an &lsquo;nlrq&rsquo; object as returned by function &lsquo;nlrq&rsquo;</p>
</td></tr>
<tr><td><code id="residuals.nlrq_+3A_type">type</code></td>
<td>
<p>the type of residuals to return: &quot;response&quot; is the distance
between observed and predicted values; &quot;rho&quot; is the weighted distance used
to calculate the objective function in the minimisation algorithm as 
tau * pmax(resid, 0) + (1 - tau) * pmin(resid, 0), where resid are the
simple residuals as above (with type=&quot;response&quot;).
</p>
</td></tr>
<tr><td><code id="residuals.nlrq_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+nlrq">nlrq</a></code> </p>

<hr>
<h2 id='rq'>
Quantile Regression 
</h2><span id='topic+rq'></span>

<h3>Description</h3>

<p>Returns an object of class <code>"rq"</code> <code>"rqs"</code> 
or <code>"rq.process"</code> that represents a quantile regression fit. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq(formula, tau=.5, data, subset, weights, na.action,
   method="br", model = TRUE, contrasts, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq_+3A_formula">formula</code></td>
<td>

<p>a formula object, with the response on the left of a <code>~</code> operator, 
and the terms, separated by <code>+</code> operators, on the right. 
</p>
</td></tr>
<tr><td><code id="rq_+3A_tau">tau</code></td>
<td>

<p>the quantile(s) to be estimated, this is generally a number strictly between 0 and 1, 
but if specified strictly outside this range, it is presumed that the solutions 
for all values of <code>tau</code> in (0,1) are desired.  In the former case an
object of class <code>"rq"</code> is returned, in the latter,
an object of class <code>"rq.process"</code> is returned.  As of version 3.50,
tau can also be a vector of values between 0 and 1; in this case an
object of class <code>"rqs"</code> is returned containing among other things
a matrix of coefficient estimates at the specified quantiles.
</p>
</td></tr>
<tr><td><code id="rq_+3A_data">data</code></td>
<td>

<p>a data.frame in which to interpret the variables 
named in the formula, or in the subset and the weights argument. 
If this is missing, then the variables in the formula should be on the 
search list.  This may also be a single number to handle some special  
cases &ndash; see below for details.   
</p>
</td></tr>
<tr><td><code id="rq_+3A_subset">subset</code></td>
<td>

<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="rq_+3A_weights">weights</code></td>
<td>

<p>vector of observation weights; if supplied, the algorithm fits
to minimize the sum of the weights multiplied into the
absolute residuals. The length of weights must be the same as
the number of observations.  The weights must be nonnegative
and it is strongly recommended that they be strictly positive,
since zero weights are ambiguous. 
</p>
</td></tr>
<tr><td><code id="rq_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data. 
This is applied to the model.frame after any subset argument has been used. 
The default (with <code>na.fail</code>) is to create an error if any missing values are  
found.  A possible alternative is <code>na.omit</code>, which 
deletes observations that contain one or more missing values. 
</p>
</td></tr>
<tr><td><code id="rq_+3A_model">model</code></td>
<td>
<p>if TRUE then the model frame is returned.  This is
essential if one wants to call summary subsequently.
</p>
</td></tr>
<tr><td><code id="rq_+3A_method">method</code></td>
<td>

<p>the algorithmic method used to compute the fit.  There are several
options:   
</p>

<ol>
<li> <p><code>"br"</code> The default method is the modified  version of the
Barrodale and Roberts algorithm for <code class="reqn">l_1</code>-regression,
used by <code>l1fit</code> in S, and is described in detail in 
Koenker and d'Orey(1987, 1994),  default = <code>"br"</code>. 
This is quite efficient for problems up to several thousand observations, 
and may be used to compute the full quantile regression process.  It 
also implements a scheme for computing confidence intervals for 
the estimated parameters, based on inversion of a rank test described 
in Koenker(1994).  
</p>
</li>
<li> <p><code>"fn"</code> For larger problems it is advantageous to use 
the Frisch&ndash;Newton interior point method <code>"fn"</code>. 
This is described in detail in Portnoy and Koenker(1997).
</p>
</li>
<li> <p><code>"pfn"</code> For even larger problems one can use the Frisch&ndash;Newton approach after 
preprocessing <code>"pfn"</code>.  Also described in detail in Portnoy and Koenker(1997), 
this method is primarily well-suited for large n, small p problems, that is when the 
parametric dimension of the model is modest.  
</p>
</li>
<li> <p><code>"sfn"</code>  For large problems with  large
parametric dimension it is often advantageous to use method <code>"sfn"</code>
which also uses the Frisch-Newton algorithm, but exploits sparse algebra
to compute iterates.  This is especially helpful when the model includes
factor variables that, when expanded, generate design matrices that
are very sparse.  At present options for inference, i.e. summary methods
are somewhat limited when using the <code>"sfn"</code> method.  Only the option
<code>se = "nid"</code> is currently available, but I hope to implement some
bootstrap options in the near future.
</p>
</li>
<li> <p><code>"fnc"</code>  Another option enables the user to specify
linear inequality constraints on the fitted coefficients; in this
case one needs to specify the matrix <code>R</code> and the vector <code>r</code>
representing the constraints in the form <code class="reqn">Rb \geq r</code>.  See the
examples below.  
</p>
</li>
<li> <p><code>"conquer"</code>  For very large problems especially those with
large parametric dimension, this option provides a link to the <span class="pkg">conquer</span>
of He, Pan, Tan, and Zhou (2020).  Calls to <code>summary</code> when the fitted
object is computed with this option invoke the multiplier bootstrap percentile
method of the <span class="pkg">conquer</span> package and can be considerably quicker than other
options when the problem size is large.  Further options for this fitting
method are described in the <span class="pkg">conquer</span> package.  Note that this option
employs a smoothing form of the usual QR objective function so solutions
may be expected to differ somewhat from those produced with the other options.
</p>
</li>
<li> <p><code>"pfnb"</code> This option is intended for applications with large
sample sizes and/or moderately fine tau grids.  It uses a form of preprocessing
to accelerate the solution process.  The loop over taus occurs inside the Fortran
call and there should be more efficient than other methods in large problems.
</p>
</li>
<li> <p><code>"qfnb"</code> This option is like the preceeding one except that it doesn't
use the preprocessing option.
</p>
</li>
<li> <p><code>"ppro"</code> This option is an R prototype of the <code>pfnb</code> and is 
offered for historical/interpretative purposes, but probably should be considered
deprecated.
</p>
</li>
<li> <p><code>"lasso"</code> There are two penalized methods:  <code>"lasso"</code> 
and <code>"scad"</code> that implement the lasso penalty and Fan and Li
smoothly clipped absolute deviation penalty, respectively.  These
methods should probably be regarded as experimental.  Note:  weights
are ignored when the method is penalized.
</p>
</li></ol>

</td></tr>
<tr><td><code id="rq_+3A_contrasts">contrasts</code></td>
<td>

<p>a list giving contrasts for some or all of the factors 
default = <code>NULL</code> appearing in the model formula. 
The elements of the list should have the same name as the variable 
and should be either a contrast matrix (specifically, any full-rank 
matrix with as many rows as there are levels in the factor), 
or else a function to compute such a matrix given the number of levels. 
</p>
</td></tr>
<tr><td><code id="rq_+3A_...">...</code></td>
<td>

<p>additional arguments for the fitting routines 
(see <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code> and <code><a href="quantreg.html#topic+rq.fit.fnb">rq.fit.fnb</a></code>, etc.
and the functions they call). 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For further details see the vignette available from <span class="rlang"><b>R</b></span> with
<code> vignette("rq",package="quantreg")</code> and/or the Koenker (2005).
For estimation of nonlinear (in parameters) quantile regression models
there is the function <code>nlrq</code> and for nonparametric additive 
quantile regression there is the function <code>rqss</code>.
Fitting of quantile regression models with censored data is handled by the
<code>crq</code> function.</p>


<h3>Value</h3>

<p>See <code><a href="quantreg.html#topic+rq.object">rq.object</a></code> and <code><a href="quantreg.html#topic+rq.process.object">rq.process.object</a></code> for details. 
Inferential matters are handled with <code><a href="base.html#topic+summary">summary</a></code>.  There are
extractor methods <code>logLik</code> and <code>AIC</code> that are potentially
relevant for model selection.
</p>


<h3>Method</h3>

<p>The function computes an estimate on the tau-th conditional quantile
function of the response, given the covariates, as specified by the
formula argument.  Like <code>lm()</code>, the function presumes a linear
specification for the quantile regression model, i.e. that the formula
defines a model that is linear in parameters.  For non-linear (in parameters)
quantile regression see the package <code>nlrq()</code>.  
The function minimizes a weighted sum of absolute
residuals that can be formulated as a linear programming problem.  As
noted above, there are several different algorithms that can be chosen
depending on problem size and other characteristics.  For moderate sized
problems (<code class="reqn">n \ll 5,000, p \ll 20</code>) it is recommended 
that the default <code>"br"</code> method be used. There are several choices of methods for
computing confidence intervals and associated test statistics.  
See the documentation for <code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code> for further details
and options.  
</p>


<h3>References</h3>

<p>[1] Koenker, R. W. and Bassett, G. W. (1978). Regression quantiles, 
<em>Econometrica</em>, <b>46</b>, 33&ndash;50. 
</p>
<p>[2] Koenker, R.W. and d'Orey (1987, 1994). Computing regression quantiles. 
<em>Applied Statistics</em>, <b>36</b>, 383&ndash;393, and <b>43</b>, 410&ndash;414. 
</p>
<p>[3] Gutenbrunner, C. Jureckova, J. (1991). 
Regression quantile and regression rank score process in the 
linear model and derived statistics, <em>Annals of Statistics</em>,
<b>20</b>, 305&ndash;330.
</p>
<p>[4] Xuming He and Xiaoou Pan and Kean Ming Tan and Wen-Xin Zhou, (2020)
conquer: Convolution-Type Smoothed Quantile Regression,
<a href="https://CRAN.R-project.org/package=conquer">https://CRAN.R-project.org/package=conquer</a>
</p>
<p>[4] Koenker, R. W. (1994). Confidence Intervals for regression quantiles, in 
P. Mandl and M. Huskova (eds.), <em>Asymptotic Statistics</em>, 349&ndash;359,  
Springer-Verlag, New York.   
</p>
<p>[5] Koenker, R. and S. Portnoy (1997) The Gaussian Hare and the Laplacean 
Tortoise:  Computability of Squared-error vs Absolute Error Estimators, 
(with discussion).  <em>Statistical Science,</em> <b>12</b>, 279-300.
</p>
<p>[6] Koenker, R. W. (2005). <em>Quantile Regression</em>,  Cambridge U. Press.
</p>
<p>There is also recent information available at the URL:
<a href="http://www.econ.uiuc.edu/~roger/">http://www.econ.uiuc.edu/~roger/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+FAQ">FAQ</a></code>, 
<code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code>, 
<code><a href="quantreg.html#topic+nlrq">nlrq</a></code>,
<code><a href="quantreg.html#topic+rq.fit">rq.fit</a></code>,
<code><a href="quantreg.html#topic+rq.wfit">rq.wfit</a></code>,
<code><a href="quantreg.html#topic+rqss">rqss</a></code>,
<code><a href="quantreg.html#topic+rq.object">rq.object</a></code>,
<code><a href="quantreg.html#topic+rq.process.object">rq.process.object</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
rq(stack.loss ~ stack.x,.5)  #median (l1) regression  fit for the stackloss data. 
rq(stack.loss ~ stack.x,.25)  #the 1st quartile, 
        #note that 8 of the 21 points lie exactly on this plane in 4-space! 
rq(stack.loss ~ stack.x, tau=-1)   #this returns the full rq process
rq(rnorm(50) ~ 1, ci=FALSE)    #ordinary sample median --no rank inversion ci
rq(rnorm(50) ~ 1, weights=runif(50),ci=FALSE)  #weighted sample median 
#plot of engel data and some rq lines see KB(1982) for references to data
data(engel)
attach(engel)
plot(income,foodexp,xlab="Household Income",ylab="Food Expenditure",type = "n", cex=.5)
points(income,foodexp,cex=.5,col="blue")
taus &lt;- c(.05,.1,.25,.75,.9,.95)
xx &lt;- seq(min(income),max(income),100)
f &lt;- coef(rq((foodexp)~(income),tau=taus))
yy &lt;- cbind(1,xx)%*%f
for(i in 1:length(taus)){
        lines(xx,yy[,i],col = "gray")
        }
abline(lm(foodexp ~ income),col="red",lty = 2)
abline(rq(foodexp ~ income), col="blue")
legend(3000,500,c("mean (LSE) fit", "median (LAE) fit"),
	col = c("red","blue"),lty = c(2,1))
#Example of plotting of coefficients and their confidence bands
plot(summary(rq(foodexp~income,tau = 1:49/50,data=engel)))
#Example to illustrate inequality constrained fitting
n &lt;- 100
p &lt;- 5
X &lt;- matrix(rnorm(n*p),n,p)
y &lt;- .95*apply(X,1,sum)+rnorm(n)
#constrain slope coefficients to lie between zero and one
R &lt;- cbind(0,rbind(diag(p),-diag(p)))
r &lt;- c(rep(0,p),-rep(1,p))
rq(y~X,R=R,r=r,method="fnc")
</code></pre>

<hr>
<h2 id='rq.fit'>Function to choose method for Quantile Regression  </h2><span id='topic+rq.fit'></span>

<h3>Description</h3>

<p>Function to choose method for quantile regression</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit(x, y, tau=0.5, method="br", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit_+3A_x">x</code></td>
<td>

<p>the design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit_+3A_y">y</code></td>
<td>

<p>the response variable
</p>
</td></tr>
<tr><td><code id="rq.fit_+3A_tau">tau</code></td>
<td>

<p>the quantile desired, if tau lies outside (0,1) the whole process
is estimated.
</p>
</td></tr>
<tr><td><code id="rq.fit_+3A_method">method</code></td>
<td>

<p>method of computation:  &quot;br&quot; is Barrodale and Roberts exterior point
&quot;fn&quot; is the Frisch-Newton interior point method.
</p>
</td></tr>
<tr><td><code id="rq.fit_+3A_...">...</code></td>
<td>

<p>Optional arguments passed to fitting routine.
</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+rq">rq</a></code> <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code> <code><a href="quantreg.html#topic+rq.fit.fnb">rq.fit.fnb</a></code></p>

<hr>
<h2 id='rq.fit.br'>
Quantile Regression Fitting by Exterior Point Methods
</h2><span id='topic+rq.fit.br'></span>

<h3>Description</h3>

<p>This function controls the details of QR fitting by the simplex approach
embodied in the algorithm of Koenker and d'Orey based on the median
regression algorithm of Barrodale and Roberts.  Typically, options
controlling the construction of the confidence intervals would be passed
via the <code>...{}</code> argument of <code>rq()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.br(x, y, tau=0.5, alpha=0.1, ci=FALSE, iid=TRUE, interp=TRUE, tcrit=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.br_+3A_x">x</code></td>
<td>

<p>the design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_y">y</code></td>
<td>

<p>the response variable
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_tau">tau</code></td>
<td>

<p>the quantile desired, if tau lies outside (0,1) the whole process
is estimated.
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_alpha">alpha</code></td>
<td>

<p>the nominal noncoverage probability for the confidence intervals, i.e. 1-alpha
is the nominal coverage probability of the intervals. 
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_ci">ci</code></td>
<td>

<p>logical flag if T then compute confidence intervals for the parameters
using the rank inversion method of Koenker (1994).  See <code>rq()</code> for more
details.  If F then return only the estimated coefficients.  Note that
for large problems the default option ci = TRUE can be rather slow.
Note also that rank inversion only works for p&gt;1, an error message is
printed in the case that ci=T and p=1.
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_iid">iid</code></td>
<td>

<p>logical flag if T then the rank inversion is based on an assumption of
iid error model, if F then it is based on an nid error assumption.
See Koenker and Machado (1999) for further details on this distinction.
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_interp">interp</code></td>
<td>

<p>As with typical order statistic type confidence intervals the test
statistic is discrete, so it is reasonable to consider intervals that
interpolate between values of the parameter just below the specified
cutoff and values just above the specified cutoff.  If <code>interp =
    F</code> then
the 2 &ldquo;exact&rdquo; values above and below on which the interpolation would
be based are returned.
</p>
</td></tr>
<tr><td><code id="rq.fit.br_+3A_tcrit">tcrit</code></td>
<td>

<p>Logical flag if T -  Student t critical values are used, if F then normal
values are used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If tau lies in (0,1) then an object of class <code>"rq"</code> is
returned with various
related inference apparatus.  If tau lies outside [0,1] then an object
of class <code>rq.process</code> is returned.  In this case parametric programming
methods are used to find all of the solutions to the QR problem for
tau in (0,1), the p-variate resulting process is then returned as the
array sol containing the primal solution and dsol containing the dual
solution.  There are roughly <code class="reqn">O(n \log n))</code> distinct
solutions, so users should
be aware that these arrays may be large and somewhat time consuming to
compute for large problems.
</p>


<h3>Value</h3>

<p>Returns an object of class <code>"rq"</code>
for tau in (0,1), or else of class <code>"rq.process"</code>.
Note that <code>rq.fit.br</code> when called for a single tau value
will return the vector of optimal dual variables.
See <code><a href="quantreg.html#topic+rq.object">rq.object</a></code> and <code><a href="quantreg.html#topic+rq.process.object">rq.process.object</a></code>
for further details.
</p>


<h3>References</h3>

<p>Koenker, R. and J.A.F. Machado, (1999) Goodness of fit and related inference 
processes for quantile regression,
<em>J. of Am Stat. Assoc.</em>, 94, 1296-1310. 
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+rq.fit.fnb">rq.fit.fnb</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
rq.fit.br(stack.x, stack.loss, tau=.73 ,interp=FALSE)
</code></pre>

<hr>
<h2 id='rq.fit.conquer'>Optional Fitting Method for Quantile Regression</h2><span id='topic+rq.fit.conquer'></span>

<h3>Description</h3>

<p>This fitting method provides a link to the gradient descent 
for convolution smoothed quantile regression problem implemented
in the <span class="pkg">conquer</span> package of He et al (2020).</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.conquer (x, y, tau=0.5, kernel = c("Gaussian", "uniform",
    "parabolic", "triangular"), h = 0, tol = 1e-04,
    iteMax = 5000, ci = FALSE, alpha = 0.05, B = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.conquer_+3A_x">x</code></td>
<td>
<p>design matrix usually supplied via rq(), expected to
have a intercept as the first column </p>
</td></tr>
<tr><td><code id="rq.fit.conquer_+3A_y">y</code></td>
<td>
<p> response vector usually supplied via rq() </p>
</td></tr>
<tr><td><code id="rq.fit.conquer_+3A_tau">tau</code></td>
<td>
<p> quantile of interest </p>
</td></tr>
<tr><td><code id="rq.fit.conquer_+3A_kernel">kernel</code></td>
<td>
<p>A character string specifying the choice of
kernel function. Default is &quot;Gaussian&quot;. Other choices are
&quot;uniform&quot;, &quot;parabolic&quot; or &quot;triangular&quot;.</p>
</td></tr> 
<tr><td><code id="rq.fit.conquer_+3A_h">h</code></td>
<td>
<p>The bandwidth parameter for kernel smoothing of the QR
objective function.  Default is max((log(n) + p) / n)^0.4, 0.05. 
The default is used if the input value is less than 0.05.</p>
</td></tr> 
<tr><td><code id="rq.fit.conquer_+3A_tol">tol</code></td>
<td>
<p>Tolerance level of the gradient descent
algorithm. The gradient descent algorithm terminates when the
maximal entry of the gradient is less than &quot;tol&quot;. Default is
1e-05.</p>
</td></tr>
<tr><td><code id="rq.fit.conquer_+3A_itemax">iteMax</code></td>
<td>
<p>Maximum number of iterations. Default is 5000.</p>
</td></tr> 
<tr><td><code id="rq.fit.conquer_+3A_ci">ci</code></td>
<td>
<p>A logical flag. Default is FALSE. If &quot;ci =
TRUE&quot;, then three types of confidence intervals (percentile,
pivotal and normal) will be constructed via multiplier
bootstrap.  This option is subsumed in normal use by the
<code>summary.rq</code> functionality.</p>
</td></tr>
<tr><td><code id="rq.fit.conquer_+3A_alpha">alpha</code></td>
<td>
<p>Nominal level for confidence intervals, may be passed
via the call to <code>summary</code></p>
</td></tr>
<tr><td><code id="rq.fit.conquer_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replications.  May be passed via summary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See documentation in the <span class="pkg">conquer</span> package.
</p>


<h3>Value</h3>

<p>Returns an object of class &quot;rq&quot;.
</p>


<h3>References</h3>

 
<p>Xuming He and Xiaoou Pan and Kean Ming Tan and Wen-Xin Zhou, (2020)
conquer: Convolution-Type Smoothed Quantile Regression,
<a href="https://CRAN.R-project.org/package=conquer">https://CRAN.R-project.org/package=conquer</a></p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code></p>

<hr>
<h2 id='rq.fit.fnb'>
Quantile Regression Fitting via Interior Point Methods
</h2><span id='topic+rq.fit.fnb'></span>

<h3>Description</h3>

<p>This is a lower level routine called by <code>rq()</code> to compute quantile
regression methods using the Frisch-Newton algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.fnb(x, y, tau=0.5, rhs = (1-tau)*apply(x,2,sum), beta=0.99995, eps=1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.fnb_+3A_x">x</code></td>
<td>

<p>The design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.fnb_+3A_y">y</code></td>
<td>

<p>The response vector
</p>
</td></tr>
<tr><td><code id="rq.fit.fnb_+3A_tau">tau</code></td>
<td>

<p>The quantile of interest, must lie in (0,1)
</p>
</td></tr>
<tr><td><code id="rq.fit.fnb_+3A_rhs">rhs</code></td>
<td>

<p>The right hand size of the dual equality constraint, modify at your own risk.
</p>
</td></tr>
<tr><td><code id="rq.fit.fnb_+3A_beta">beta</code></td>
<td>

<p>technical step length parameter &ndash; alter at your own risk!
</p>
</td></tr>
<tr><td><code id="rq.fit.fnb_+3A_eps">eps</code></td>
<td>

<p>tolerance parameter for convergence.  In cases of multiple optimal solutions
there may be some discrepancy between solutions produced by method
<code>"fn"</code> and method <code>"br"</code>.  This is due to the fact that
<code>"fn"</code> tends to converge to a point near the centroid of the
solution set, while <code>"br"</code> stops at a vertex of the set.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details of the algorithm are explained in Koenker and Portnoy (1997).
The basic idea can be traced back to the log-barrier methods proposed by
Frisch in the 1950's for constrained optimization.  But the current
implementation is based on proposals by Mehrotra and others in the
recent (explosive) literature on interior point methods for solving linear 
programming problems.  This function replaces an earlier one <code>rq.fit.fn</code>,
which required the initial dual values to be feasible.  This version allows the
user to specify an infeasible starting point for the dual problem, that
is one that may not satisfy the dual equality constraints.  It still 
assumes that the starting value satisfies the upper and lower bounds.
</p>


<h3>Value</h3>

<p>returns an object of class <code>"rq"</code>, which can be passed to
<code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code> to obtain standard errors, etc.
</p>


<h3>References</h3>

<p>Koenker, R. and S. Portnoy (1997).
The Gaussian Hare and the Laplacian Tortoise:
Computability of squared-error vs. absolute-error estimators, with discussion,
<em>Statistical Science</em>, <b>12</b>, 279-300.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code>,
<code><a href="quantreg.html#topic+rq.fit.pfn">rq.fit.pfn</a></code>
</p>

<hr>
<h2 id='rq.fit.fnc'>
Quantile Regression Fitting via Interior Point Methods
</h2><span id='topic+rq.fit.fnc'></span>

<h3>Description</h3>

<p>This is a lower level routine called by <code>rq()</code> to compute quantile
regression methods using the Frisch-Newton algorithm.  It allows the
call to specify linear inequality constraints to which the fitted
coefficients will be subjected.  The constraints are assumed to be 
formulated as Rb &gt;= r.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.fnc(x, y, R, r, tau=0.5, beta=0.9995, eps=1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.fnc_+3A_x">x</code></td>
<td>

<p>The design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.fnc_+3A_y">y</code></td>
<td>

<p>The response vector
</p>
</td></tr>
<tr><td><code id="rq.fit.fnc_+3A_r">R</code></td>
<td>

<p>The matrix describing the inequality constraints
</p>
</td></tr>
<tr><td><code id="rq.fit.fnc_+3A_r">r</code></td>
<td>

<p>The right hand side vector of inequality constraints
</p>
</td></tr>
<tr><td><code id="rq.fit.fnc_+3A_tau">tau</code></td>
<td>

<p>The quantile of interest, must lie in (0,1)
</p>
</td></tr>
<tr><td><code id="rq.fit.fnc_+3A_beta">beta</code></td>
<td>

<p>technical step length parameter &ndash; alter at your own risk!
</p>
</td></tr>
<tr><td><code id="rq.fit.fnc_+3A_eps">eps</code></td>
<td>

<p>tolerance parameter for convergence.  In cases of multiple optimal solutions
there may be some discrepancy between solutions produced by method
<code>"fn"</code> and method <code>"br"</code>.  This is due to the fact that
<code>"fn"</code> tends to converge to a point near the centroid of the
solution set, while <code>"br"</code> stops at a vertex of the set.  
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details of the algorithm are explained in Koenker and Ng (2002).
The basic idea can be traced back to the log-barrier methods proposed by
Frisch in the 1950's for constrained optimization.  But the current
implementation is based on proposals by Mehrotra and others in the
recent (explosive) literature on interior point methods for solving linear 
programming problems.  See <code>"rq"</code> helpfile for an example.
It is an open research problem to provide an inference apparatus for
inequality constrained quantile regression.
</p>


<h3>Value</h3>

<p>returns an object of class <code>"rq"</code>, which can be passed to
<code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code> to obtain standard errors, etc.  
</p>


<h3>References</h3>

<p>Koenker, R. and S. Portnoy (1997).
The Gaussian Hare and the Laplacian Tortoise:
Computability of squared-error vs. absolute-error estimators, with discussion,
<em>Statistical Science</em>, <b>12</b>, 279-300.
</p>
<p>Koenker, R. and P. Ng(2005).
Inequality Constrained Quantile Regression, <em>Sankya</em>, 418-440.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code>,
<code><a href="quantreg.html#topic+rq.fit.pfn">rq.fit.pfn</a></code>
</p>

<hr>
<h2 id='rq.fit.hogg'>weighted quantile regression fitting</h2><span id='topic+rq.fit.hogg'></span>

<h3>Description</h3>

<p>Function to estimate a regression mmodel by minimizing the weighted sum of several
quantile regression functions.  See Koenker(1984) for an asymptotic look at these
estimators.  This is a slightly generalized version of what Zou and Yuan (2008) call
composite quantile regression in that it permits weighting of the components of the
objective function and also allows further linear inequality constraints on the coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.hogg(x, y, taus = c(0.1, 0.3, 0.5), weights = c(0.7, 0.2, 0.1), 
	    R = NULL, r = NULL, beta = 0.99995, eps = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.hogg_+3A_x">x</code></td>
<td>
<p>design matrix</p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_y">y</code></td>
<td>
<p>response vector </p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_taus">taus</code></td>
<td>
<p>quantiles getting positive weight</p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_weights">weights</code></td>
<td>
<p>weights assigned to the quantiles </p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_r">R</code></td>
<td>
<p>optional matrix describing linear inequality constraints</p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_r">r</code></td>
<td>
<p>optional vector describing linear inequality constraints</p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_beta">beta</code></td>
<td>
<p>step length parameter of the Frisch Newton Algorithm</p>
</td></tr>
<tr><td><code id="rq.fit.hogg_+3A_eps">eps</code></td>
<td>
<p>tolerance parameter for the Frisch Newton Algorithm</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mimimizes a weighted sum of quantile regression objective functions using
the specified taus.  The model permits distinct intercept parameters at
each of the specified taus, but the slope parameters are constrained to
be the same for all taus.  This estimator was originally suggested to
the author by Bob Hogg in one of his famous blue notes of 1979.
The algorithm used to solve the resulting linear programming problems
is either the Frisch Newton algorithm described in Portnoy and Koenker (1997),
or the closely related algorithm described in Koenker and Ng(2002) that
handles linear inequality constraints.  See <code><a href="quantreg.html#topic+qrisk">qrisk</a></code> for illustration
of its use in portfolio allocation.
</p>
<p>Linear inequality constraints of the form <code class="reqn">Rb \geq r</code> can be imposed  with
the convention that <code class="reqn">b</code> is a <code class="reqn">m+p</code> where <code class="reqn">m</code> is the <code>length(taus)</code>
and <code class="reqn">p</code> is the column dimension of <code>x</code> without the intercept.
</p>


<h3>Value</h3>

<table>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated coefficients of the model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p>Zou, Hui and and Ming Yuan (2008)  Composite quantile regression and the
Oracle model selection theory, Annals of Statistics, 36, 1108&ndash;11120.
</p>
<p>Koenker, R. (1984) A note on L-estimates for linear models, 
Stat. and Prob Letters, 2, 323-5.
</p>
<p>Portnoy, S. and Koenker, R. (1997) The Gaussian Hare and the 
Laplacean Tortoise:  Computability of Squared-error vs Absolute Error Estimators, 
(with discussion).  Statistical Science, (1997) 12, 279-300.
</p>
<p>Koenker, R. and Ng, P (2003) Inequality Constrained Quantile Regression, preprint.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+qrisk">qrisk</a></code></p>

<hr>
<h2 id='rq.fit.lasso'>
Lasso Penalized Quantile Regression 
</h2><span id='topic+rq.fit.lasso'></span>

<h3>Description</h3>

<p>The fitting method implements the lasso penalty for
fitting quantile regression models.  When  the argument <code>lambda</code>
is a scalar the penalty function is the l1
norm of the last (p-1) coefficients, under the presumption that the
first coefficient is an intercept parameter that should not be subject
to the penalty.  When <code>lambda</code> is a vector it should have length
equal the column dimension of the matrix <code>x</code> and then defines a
coordinatewise specific vector of lasso penalty parameters.  In this
case <code>lambda</code> entries of zero indicate covariates that are not
penalized.  If <code>lambda</code> is not specified, a default value is
selected according to the proposal of Belloni and Chernozhukov (2011).
See <code>LassoLambdaHat</code> for further details.
There should be a sparse version of this, but isn't (yet).
There should also be a preprocessing version, but isn't (yet).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.lasso(x, y, tau = 0.5, lambda = NULL, beta = .99995, eps = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.lasso_+3A_x">x</code></td>
<td>

<p>the design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.lasso_+3A_y">y</code></td>
<td>

<p>the response variable
</p>
</td></tr>
<tr><td><code id="rq.fit.lasso_+3A_tau">tau</code></td>
<td>

<p>the quantile desired, defaults to 0.5.
</p>
</td></tr>
<tr><td><code id="rq.fit.lasso_+3A_lambda">lambda</code></td>
<td>

<p>the value of the penalty parameter(s) that determine how much shrinkage is done.
This should be either a scalar, or a vector of length equal to the column dimension
of the <code>x</code> matrix.  If unspecified, a default value is chosen according to
the proposal of Belloni and Chernozhukov (2011).
</p>
</td></tr>
<tr><td><code id="rq.fit.lasso_+3A_beta">beta</code></td>
<td>

<p>step length parameter for Frisch-Newton method.
</p>
</td></tr>
<tr><td><code id="rq.fit.lasso_+3A_eps">eps</code></td>
<td>

<p>tolerance parameter for convergence. 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with a coefficient, residual, tau and lambda components.  
When called from <code>"rq"</code> (as intended) the returned object
has class &quot;lassorqs&quot;.  
</p>


<h3>Author(s)</h3>

<p>R. Koenker</p>


<h3>References</h3>

<p>Koenker, R. (2005) <em>Quantile Regression</em>, CUP.
</p>
<p>Belloni, A. and  V. Chernozhukov. (2011) l1-penalized quantile regression 
in high-dimensional sparse models. <em>Annals of Statistics</em>, 39 82 - 130.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 60
p &lt;- 7
rho &lt;- .5
beta &lt;- c(3,1.5,0,2,0,0,0)
R &lt;- matrix(0,p,p)
for(i in 1:p){
        for(j in 1:p){
                R[i,j] &lt;- rho^abs(i-j)
                }
        }
set.seed(1234)
x &lt;- matrix(rnorm(n*p),n,p) %*% t(chol(R))
y &lt;- x %*% beta + rnorm(n)

f &lt;- rq(y ~ x, method="lasso",lambda = 30)
g &lt;- rq(y ~ x, method="lasso",lambda = c(rep(0,4),rep(30,4)))
</code></pre>

<hr>
<h2 id='rq.fit.pfn'> Preprocessing Algorithm for Quantile Regression</h2><span id='topic+rq.fit.pfn'></span>

<h3>Description</h3>

<p>A preprocessing algorithm for the Frisch Newton algorithm 
for quantile regression. This is one possible method for rq().</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.pfn(x, y, tau=0.5, Mm.factor=0.8, max.bad.fixups=3, eps=1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.pfn_+3A_x">x</code></td>
<td>
<p>design matrix usually supplied via rq() </p>
</td></tr>
<tr><td><code id="rq.fit.pfn_+3A_y">y</code></td>
<td>
<p> response vector usually supplied via rq() </p>
</td></tr>
<tr><td><code id="rq.fit.pfn_+3A_tau">tau</code></td>
<td>
<p> quantile of interest </p>
</td></tr>
<tr><td><code id="rq.fit.pfn_+3A_mm.factor">Mm.factor</code></td>
<td>
<p>  constant to determine sub sample size m</p>
</td></tr>
<tr><td><code id="rq.fit.pfn_+3A_max.bad.fixups">max.bad.fixups</code></td>
<td>
<p> number of allowed mispredicted signs of residuals </p>
</td></tr>
<tr><td><code id="rq.fit.pfn_+3A_eps">eps</code></td>
<td>
<p> convergence tolerance </p>
</td></tr>
</table>


<h3>Details</h3>

<p>Preprocessing algorithm to reduce the effective sample size for QR
problems with (plausibly) iid samples.  The preprocessing relies
on subsampling of the original data, so situations in which the
observations are not plausibly iid, are likely to cause problems.
The tolerance eps may be relaxed somewhat.
</p>


<h3>Value</h3>

<p>Returns an object of type rq
</p>


<h3>Author(s)</h3>

<p> Roger Koenker &lt;rkoenker@uiuc.edu&gt;</p>


<h3>References</h3>

<p> Portnoy and Koenker, Statistical Science, (1997) 279-300</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rq">rq</a></code></p>

<hr>
<h2 id='rq.fit.pfnb'>
Quantile Regression Fitting via Interior Point Methods
</h2><span id='topic+rq.fit.pfnb'></span>

<h3>Description</h3>

<p>This is a lower level routine called by <code>rq()</code> to compute quantile
regression parameters using the Frisch-Newton algorithm.  It uses a form
of preprocessing to accelerate the computations for situations in which
several taus are required for the same model specification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.pfnb(x, y, tau, m0 = NULL, eps = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.pfnb_+3A_x">x</code></td>
<td>

<p>The design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.pfnb_+3A_y">y</code></td>
<td>

<p>The response vector
</p>
</td></tr>
<tr><td><code id="rq.fit.pfnb_+3A_tau">tau</code></td>
<td>

<p>The quantiles of interest, must lie in (0,1), be sorted and preferably equally
spaced.
</p>
</td></tr>
<tr><td><code id="rq.fit.pfnb_+3A_m0">m0</code></td>
<td>

<p>An initial reduced sample size by default is set to be 
<code>round((n * (log(p) + 1) )^(2/3)</code> this could be explored further
to aid performance in extreme cases.
</p>
</td></tr>
<tr><td><code id="rq.fit.pfnb_+3A_eps">eps</code></td>
<td>
<p>A tolerance parameter intended to bound the confidence band entries
away from zero.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details of the Frisch-Newton algorithm are explained in Koenker and Portnoy (1997),
as is the preprocessing idea which is related to partial sorting and the algorithms
such as <code>kuantile</code> for univariate quantiles that operate in time O(n).
The preprocessing idea of exploiting nearby quantile solutions to accelerate
estimation of adjacent quantiles is proposed in Chernozhukov et al (2020).
This version calls a fortran version of the preprocessing algorithm that accepts
multiple taus.  The preprocessing approach is also implemented for a single tau
in <code>rq.fit.pfn</code> which may be regarded as a prototype for this function since
it is written entirely in R and therefore is easier to experiment with.
</p>


<h3>Value</h3>

<p>returns a list with elements consisting of 
</p>

<ol>
<li><p>coefficientsa matrix of dimension ncol(x) by length(taus)

</p>
</li>
<li><p>nit a 5 by m matrix of iteration counts: first two coordinates
of each column are the number of interior point iterations, the third is the 
number of observations in the final globbed sample size, and the last two 
are the number of fixups and bad-fixups respectively.  This is intended to
aid fine tuning of the initial sample size, m0.
</p>
</li>
<li><p>info an m-vector of convergence flags
</p>
</li></ol>



<h3>References</h3>

<p>Koenker, R. and S. Portnoy (1997).
The Gaussian Hare and the Laplacian Tortoise:
Computability of squared-error vs. absolute-error estimators, with discussion,
<em>Statistical Science</em>, <b>12</b>, 279-300.
</p>
<p>Chernozhukov, V., I., Fernandez-Val, and Melly, B. (2020), 'Fast algorithms for 
the quantile regression process', Empirical Economics, forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code>,
<code><a href="quantreg.html#topic+rq.fit.pfn">rq.fit.pfn</a></code>
</p>

<hr>
<h2 id='rq.fit.ppro'>
Preprocessing fitting method for QR
</h2><span id='topic+rq.fit.ppro'></span>

<h3>Description</h3>

<p>Preprocessing method for fitting quantile regression models that
exploits the fact that adjacent tau's should have nearly the same
sign vectors for residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.ppro(x, y, tau, weights = NULL, Mm.factor = 0.8, eps = 1e-06, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.ppro_+3A_x">x</code></td>
<td>

<p>Design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.ppro_+3A_y">y</code></td>
<td>

<p>Response vector
</p>
</td></tr>
<tr><td><code id="rq.fit.ppro_+3A_tau">tau</code></td>
<td>

<p>quantile vector of interest 
</p>
</td></tr>
<tr><td><code id="rq.fit.ppro_+3A_weights">weights</code></td>
<td>

<p>case weights
</p>
</td></tr>
<tr><td><code id="rq.fit.ppro_+3A_mm.factor">Mm.factor</code></td>
<td>

<p>constant determining initial sample size
</p>
</td></tr>
<tr><td><code id="rq.fit.ppro_+3A_eps">eps</code></td>
<td>

<p>Convergence tolerance
</p>
</td></tr>
<tr><td><code id="rq.fit.ppro_+3A_...">...</code></td>
<td>

<p>Other arguments
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See references for further details.
</p>


<h3>Value</h3>

<p>Returns a list with components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>Matrix of coefficient estimates</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>Matrix of residual estimates</p>
</td></tr>
<tr><td><code>rho</code></td>
<td>
<p>vector of objective function values</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>vector of case weights</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Blaise Melly and Roger Koenker
</p>


<h3>References</h3>

<p>Chernozhukov, V.  I. Fernandez-Val and B. Melly,
Fast Algorithms for the Quantile Regression Process, 2020,
Empirical Economics.,
</p>
<p>Portnoy, S.  and R. Koenker, The Gaussian Hare and the Laplacian
Tortoise, Statistical Science, (1997) 279-300
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq.fit.pfn">rq.fit.pfn</a></code>, <code><a href="quantreg.html#topic+boot.rq.pxy">boot.rq.pxy</a></code> 
</p>

<hr>
<h2 id='rq.fit.qfnb'>
Quantile Regression Fitting via Interior Point Methods
</h2><span id='topic+rq.fit.qfnb'></span>

<h3>Description</h3>

<p>This is a lower level routine called by <code>rq()</code> to compute quantile
regression parameters using the Frisch-Newton algorithm.  In contrast to
method &quot;fn&quot; it computes solutions for all the specified taus inside a
fortran loop.  See <code><a href="quantreg.html#topic+rq.fit.pfnb">rq.fit.pfnb</a></code> for further details on a more
efficient preprocessing method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.qfnb(x, y, tau)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.qfnb_+3A_x">x</code></td>
<td>

<p>The design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.qfnb_+3A_y">y</code></td>
<td>

<p>The response vector
</p>
</td></tr>
<tr><td><code id="rq.fit.qfnb_+3A_tau">tau</code></td>
<td>

<p>The quantiles of interest, must lie in (0,1), be sorted and preferably equally
spaced.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The details of the Frisch-Newton algorithm are explained in Koenker and Portnoy (1997).
The basic idea can be traced back to the log-barrier methods proposed by
Frisch in the 1950's for linear programming.  But the current
implementation is based on proposals by Mehrotra and others in the
recent (explosive) literature on interior point methods for solving linear 
programming problems.  This function replaces an earlier one <code>rq.fit.fn</code>,
which required the initial dual values to be feasible.  The current version allows the
user to specify an infeasible starting point for the dual problem, that
is one that may not satisfy the dual equality constraints.  It still 
assumes that the starting value satisfies the upper and lower bounds.
</p>


<h3>Value</h3>

<p>returns a list with elements consisting of 
</p>

<ol>
<li><p>coefficientsa matrix of dimension ncol(x) by length(taus)

</p>
</li>
<li><p>nit a 3-vector of iteration counts
</p>
</li>
<li><p>info a convergence flag
</p>
</li></ol>



<h3>References</h3>

<p>Koenker, R. and S. Portnoy (1997).
The Gaussian Hare and the Laplacian Tortoise:
Computability of squared-error vs. absolute-error estimators, with discussion,
<em>Statistical Science</em>, <b>12</b>, 279-300.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>, <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code>,
<code><a href="quantreg.html#topic+rq.fit.pfn">rq.fit.pfn</a></code>
</p>

<hr>
<h2 id='rq.fit.scad'>
SCADPenalized Quantile Regression 
</h2><span id='topic+rq.fit.scad'></span>

<h3>Description</h3>

<p>The fitting method implements the smoothly clipped absolute deviation
penalty of Fan and Li for fitting quantile regression models.  
When  the argument <code>lambda</code>
is a scalar the penalty function is the scad modified l1
norm of the last (p-1) coefficients, under the presumption that the
first coefficient is an intercept parameter that should not be subject
to the penalty.  When <code>lambda</code> is a vector it should have length
equal the column dimension of the matrix <code>x</code> and then defines a
coordinatewise specific vector of scad penalty parameters.  In this
case <code>lambda</code> entries of zero indicate covariates that are not
penalized.  There should be a sparse version of this, but isn't (yet).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.scad(x, y, tau = 0.5, alpha = 3.2, lambda = 1, start="rq", 
	beta = .9995, eps = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.scad_+3A_x">x</code></td>
<td>

<p>the design matrix
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_y">y</code></td>
<td>

<p>the response variable
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_tau">tau</code></td>
<td>

<p>the quantile desired, defaults to 0.5.
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_alpha">alpha</code></td>
<td>

<p>tuning parameter of the scad penalty.
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_lambda">lambda</code></td>
<td>

<p>the value of the penalty parameter that determines how much shrinkage is done.
This should be either a scalar, or a vector of length equal to the column dimension
of the <code>x</code> matrix.
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_start">start</code></td>
<td>

<p>starting method, default method 'rq' uses the unconstrained rq estimate, while
method 'lasso' uses the corresponding lasso estimate with the specified lambda.
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_beta">beta</code></td>
<td>

<p>step length parameter for Frisch-Newton method.
</p>
</td></tr>
<tr><td><code id="rq.fit.scad_+3A_eps">eps</code></td>
<td>

<p>tolerance parameter for convergence. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm is an adaptation of the &quot;difference convex algorithm&quot;
described in Wu and Liu (2008).  It solves a sequence of (convex) QR problems 
to approximate solutions of the (non-convex) scad problem.</p>


<h3>Value</h3>

<p>Returns a list with a coefficient, residual, tau and lambda components.  
When called from <code>"rq"</code> as intended the returned object
has class &quot;scadrqs&quot;.  
</p>


<h3>Author(s)</h3>

<p>R. Koenker</p>


<h3>References</h3>

<p>Wu, Y. and Y. Liu (2008) Variable  Selection in Quantile Regression, <em>Statistica
Sinica</em>, to appear.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 60
p &lt;- 7
rho &lt;- .5
beta &lt;- c(3,1.5,0,2,0,0,0)
R &lt;- matrix(0,p,p)
for(i in 1:p){
        for(j in 1:p){
                R[i,j] &lt;- rho^abs(i-j)
                }
        }
set.seed(1234)
x &lt;- matrix(rnorm(n*p),n,p) %*% t(chol(R))
y &lt;- x %*% beta + rnorm(n)

f &lt;- rq(y ~ x, method="scad",lambda = 30)
g &lt;- rq(y ~ x, method="scad", start = "lasso", lambda = 30)
</code></pre>

<hr>
<h2 id='rq.fit.sfn'>Sparse Regression Quantile Fitting</h2><span id='topic+rq.fit.sfn'></span><span id='topic+sfnMessage'></span>

<h3>Description</h3>

<p>Fit a quantile regression model using a sparse implementation of the
Frisch-Newton interior-point algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.sfn(a, y, tau = 0.5, rhs = (1-tau)*c(t(a) %*% rep(1,length(y))), control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.sfn_+3A_a">a</code></td>
<td>
<p>structure of the design matrix X stored in csr format</p>
</td></tr>
<tr><td><code id="rq.fit.sfn_+3A_y">y</code></td>
<td>
<p>response vector</p>
</td></tr>
<tr><td><code id="rq.fit.sfn_+3A_tau">tau</code></td>
<td>
<p>desired quantile</p>
</td></tr>
<tr><td><code id="rq.fit.sfn_+3A_rhs">rhs</code></td>
<td>
<p>the right-hand-side of the dual problem; regular users
shouldn't need to specify this, but in special cases can be quite
usefully altered to meet special needs.  See e.g. Section 6.8 of
Koenker (2005).</p>
</td></tr>
<tr><td><code id="rq.fit.sfn_+3A_control">control</code></td>
<td>
<p>control parameters for fitting routines:  see <code>sfn.control</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a sparse implementation of the Frisch-Newton algorithm for quantile
regression described in Portnoy and Koenker (1997). The sparse matrix
linear algebra is implemented through the functions available in the R
package <span class="pkg">SparseM</span>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>coef</code></td>
<td>
<p>Regression quantile coefficients</p>
</td></tr>
<tr><td><code>ierr</code></td>
<td>
<p>Error code for the internal Fortran routine <code>srqfnc</code>:
</p>

<dl>
<dt>1:</dt><dd><p> insufficient work space in call to <code>extract</code></p>
</dd>
<dt>2:</dt><dd><p> nnzd &gt; nnzdmax</p>
</dd>
<dt>3:</dt><dd><p> insufficient storage in iwork when calling ordmmd</p>
</dd>
<dt>4:</dt><dd><p> insufficient storage in iwork when calling sfinit</p>
</dd>
<dt>5:</dt><dd><p> nnzl &gt; nnzlmax when calling sfinit</p>
</dd>
<dt>6:</dt><dd><p> nsub &gt; nsubmax when calling sfinit</p>
</dd>
<dt>7:</dt><dd><p> insufficient work space in iwork when calling symfct</p>
</dd>
<dt>8:</dt><dd><p> inconsistancy in input when calling symfct</p>
</dd>
<dt>9:</dt><dd><p> tmpsiz &gt; tmpmax when calling bfinit; increase tmpmax</p>
</dd>
<dt>10:</dt><dd><p> nonpositive diagonal encountered, not positive definite</p>
</dd>
<dt>11:</dt><dd><p> insufficient work storage in tmpvec when calling blkfct</p>
</dd>
<dt>12:</dt><dd><p> insufficient work storage in iwork when calling blkfct</p>
</dd>
<dt>17:</dt><dd><p> tiny diagonals replaced with Inf when calling blkfct</p>
</dd>
</dl>

</td></tr>
<tr><td><code>it</code></td>
<td>
<p>Iteration count</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>Amount of time used in the computation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pin Ng</p>


<h3>References</h3>

<p>Portnoy, S. and R. Koenker (1997) The Gaussian Hare and the Laplacean Tortoise: 
Computability of Squared-error vs Absolute Error Estimators, (with discussion). 
<em>Statistical Science</em>, 12, 279-300.
</p>
<p>Koenker, R and Ng, P. (2003).  SparseM:  A Sparse Matrix Package for <span class="rlang"><b>R</b></span>, 
<em>J. of Stat. Software</em>, 8, 1&ndash;9.
</p>
<p>Koenker, R. (2005) <em>Quantile Regression</em>, Cambridge U. Press.
</p>


<h3>See Also</h3>

<p><code>rq.fit.sfnc</code> for the constrained version,
<code>SparseM</code> for a sparse matrix package for <span class="rlang"><b>R</b></span>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## An artificial example :
n &lt;- 200
p &lt;- 50
set.seed(101)
X &lt;- rnorm(n*p)
X[abs(X) &lt; 2.0] &lt;- 0
X &lt;- cbind(1, matrix(X, n, p))
y &lt;- 0.5 * apply(X,1,sum) + rnorm(n) ## true beta = (0.5, 0.5, ...)

sX &lt;- as.matrix.csr(X)
try(rq.o &lt;- rq.fit.sfn(sX, y)) #-&gt; not enough tmp memory
(tmpmax &lt;- floor(1e5 + exp(-12.1)*(sX@ia[p+1]-1)^2.35))
## now ok:
rq.o &lt;- rq.fit.sfn(sX, y, control = list(tmpmax= tmpmax))
</code></pre>

<hr>
<h2 id='rq.fit.sfnc'>Sparse Constrained Regression Quantile Fitting</h2><span id='topic+rq.fit.sfnc'></span>

<h3>Description</h3>

<p>Fit constrained regression quantiles using a sparse implementation of
the Frisch-Newton Interior-point algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.fit.sfnc(x, y, R, r, tau = 0.5,
            rhs = (1-tau)*c(t(x) %*% rep(1,length(y))),control)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rq.fit.sfnc_+3A_x">x</code></td>
<td>
<p>structure of the design matrix X stored in csr format</p>
</td></tr>
<tr><td><code id="rq.fit.sfnc_+3A_y">y</code></td>
<td>
<p>response vector</p>
</td></tr>
<tr><td><code id="rq.fit.sfnc_+3A_r">R</code></td>
<td>
<p>constraint matrix stored in csr format</p>
</td></tr>
<tr><td><code id="rq.fit.sfnc_+3A_r">r</code></td>
<td>
<p>right-hand-side of the constraint</p>
</td></tr>
<tr><td><code id="rq.fit.sfnc_+3A_tau">tau</code></td>
<td>
<p>desired quantile</p>
</td></tr>
<tr><td><code id="rq.fit.sfnc_+3A_rhs">rhs</code></td>
<td>
<p>the right-hand-side of the dual problem; regular users
shouldn't need to specify this.</p>
</td></tr>
<tr><td><code id="rq.fit.sfnc_+3A_control">control</code></td>
<td>
<p>control paramters for fitting see <code>sfn.control</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a sparse implementation of the Frisch-Newton algorithm for
constrained quantile regression described in Koenker and Portnoy (1996).
The sparse matrix linear algebra is implemented through the functions
available in the R package <span class="pkg">SparseM</span>.
</p>


<h3>Value</h3>

<table>
<tr><td><code>coef</code></td>
<td>
<p>Regression quantile coefficients</p>
</td></tr>
<tr><td><code>ierr</code></td>
<td>
<p>Error code for the internal Fortran routine <code>srqfn</code>:
</p>

<dl>
<dt>1:</dt><dd><p> insufficient work space in call to <code>extract</code></p>
</dd>
<dt>3:</dt><dd><p> insufficient storage in iwork when calling ordmmd</p>
</dd>
<dt>4:</dt><dd><p> insufficient storage in iwork when calling sfinit</p>
</dd>
<dt>5:</dt><dd><p> nnzl &gt; nnzlmax when calling sfinit</p>
</dd>
<dt>6:</dt><dd><p> nsub &gt; nsubmax when calling sfinit</p>
</dd>
<dt>7:</dt><dd><p> insufficient work space in iwork when calling symfct</p>
</dd>
<dt>8:</dt><dd><p> inconsistancy in input when calling symfct</p>
</dd>
<dt>9:</dt><dd><p> tmpsiz &gt; tmpmax when calling symfct; increase tmpmax</p>
</dd>
<dt>10:</dt><dd><p> nonpositive diagonal encountered when calling blkfct</p>
</dd>
<dt>11:</dt><dd><p> insufficient work storage in tmpvec when calling blkfct</p>
</dd>
<dt>12:</dt><dd><p> insufficient work storage in iwork when calling blkfct</p>
</dd>
<dt>13:</dt><dd><p> nnzd &gt; nnzdmax in e,je when calling amub</p>
</dd>
<dt>14:</dt><dd><p> nnzd &gt; nnzdmax in g,jg when calling amub</p>
</dd>
<dt>15:</dt><dd><p> nnzd &gt; nnzdmax in h,jh when calling aplb</p>
</dd>
<dt>15:</dt><dd><p> tiny diagonals replaced with Inf when calling blkfct</p>
</dd>
</dl>

</td></tr>
<tr><td><code>it</code></td>
<td>
<p>Iteration count</p>
</td></tr>
<tr><td><code>time</code></td>
<td>
<p>Amount of time used in the computation</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pin Ng</p>


<h3>References</h3>

<p>Koenker, R and Ng, P. (2002).  SparseM:  A Sparse Matrix Package for <span class="rlang"><b>R</b></span>; 
<a href="https://CRAN.R-project.org/package=SparseM">https://CRAN.R-project.org/package=SparseM</a>
</p>
<p>Koenker, R. and P. Ng(2005).
Inequality Constrained Quantile Regression, <em>Sankya</em>, 418-440.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq.fit.sfn">rq.fit.sfn</a></code> for the unconstrained version,
<span class="pkg">SparseM</span> for the underlying sparse matrix <span class="rlang"><b>R</b></span> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## An artificial example :
n &lt;- 200
p &lt;- 50
set.seed(17)
X &lt;- rnorm(n*p)
X[abs(X) &lt; 2.0] &lt;- 0
X &lt;- cbind(1,matrix(X,n,p))
y &lt;- 0.5 * apply(X,1,sum) + rnorm(n) ## true beta = (0.5, 0.5, ...)
R &lt;- rbind(diag(p+1), -diag(p+1))
r &lt;- c(rep( 0, p+1), rep(-1, p+1))

sX &lt;- as.matrix.csr(X)
sR &lt;- as.matrix.csr(R)
try(rq.o &lt;- rq.fit.sfnc(sX, y, sR, r)) #-&gt; not enough tmp memory

(tmpmax &lt;- floor(1e5 + exp(-12.1)*(sX@ia[p+1]-1)^2.35))
## now ok:
rq.o &lt;- rq.fit.sfnc(sX, y, sR, r, control = list(tmpmax = tmpmax))
</code></pre>

<hr>
<h2 id='rq.object'>
Linear Quantile Regression Object 
</h2><span id='topic+rq.object'></span><span id='topic+formula.rq'></span><span id='topic+logLik.rq'></span><span id='topic+logLik.rqs'></span><span id='topic+AIC.rq'></span><span id='topic+AIC.rqs'></span><span id='topic+extractAIC.rq'></span>

<h3>Description</h3>

<p>These are objects of class <code>"rq"</code>.
They represent the fit of a linear conditional quantile function model. 
</p>


<h3>Details</h3>

<p>The coefficients, residuals, and effects may be extracted 
by the generic functions of the same name, rather than 
by the <code>$</code> operator.   For pure <code>rq</code> objects this is less critical 
than for some of the inheritor classes.  In particular, for fitted rq objects
using &quot;lasso&quot; and &quot;scad&quot; penalties, <code>logLik</code> and <code>AIC</code> functions
compute degrees of freedom of the fitted model as the number of estimated
parameters whose absolute value exceeds a threshold <code>edfThresh</code>.  By
default this threshold is 0.0001, but this can be passed via the <code>AIC</code>
function if this value is deemed unsatisfactory.  The function <code>AIC</code>
is a generic function in R, with parameter <code>k</code> that controls the form
of the penalty:  the default value of <code>k</code> is 2 which yields the classical
Akaike form of the penalty, while <code>k &lt;= 0</code> yields the Schwarz (BIC)
form of the penalty.
Note that the extractor function <code>coef</code> returns a vector with missing values 
omitted.  
</p>


<h3>Generation</h3>

<p>This class of objects is returned from the <code>rq</code> function 
to represent a fitted linear quantile regression model. 
</p>


<h3>Methods</h3>

<p>The <code>"rq"</code> class of objects has methods for the following generic 
functions: 
<code>coef</code>, <code>effects</code>
, <code>formula</code>
, <code>labels</code>
, <code>model.frame</code>
, <code>model.matrix</code>
, <code>plot</code>
, <code>logLik</code>
, <code>AIC</code>
, <code>extractAIC</code>
, <code>predict</code>
, <code>print</code>
, <code>print.summary</code>
, <code>residuals</code>
, <code>summary</code>
</p>


<h3>Structure</h3>

<p>The following components must be included in a legitimate <code>rq</code> object. 
</p>

<dl>
<dt><code>coefficients</code></dt><dd>
<p>the coefficients of the quantile regression fit. 
The names of the coefficients are the names of the 
single-degree-of-freedom effects (the columns of the 
model matrix). 
If the model was fitted by method <code>"br"</code> with <code>ci=TRUE</code>, then
the coefficient component consists of a matrix whose
first column consists of the vector of estimated coefficients
and the second and third columns are the lower and upper
limits of a confidence interval for the respective coefficients.
</p>
</dd>
<dt><code>residuals</code></dt><dd>
<p>the residuals from the fit. 
</p>
</dd>
<dt><code>dual</code></dt><dd>
<p>the vector dual variables from the fit. 
</p>
</dd>
<dt><code>rho</code></dt><dd>
<p>The value(s) of objective function at the solution.
</p>
</dd>
<dt><code>contrasts</code></dt><dd>
<p>a list containing sufficient information to construct the contrasts 
used to fit any factors occurring in the model. 
The list contains entries that are either matrices or character vectors. 
When a factor is coded by contrasts, the corresponding contrast matrix 
is stored in this list. 
Factors that appear only as dummy variables and variables in the model 
that are matrices correspond to character vectors in the list. 
The character vector has the level names for a factor or the column 
labels for a matrix. 
</p>
</dd>
<dt><code>model</code></dt><dd>
<p>optionally the model frame, if <code>model=TRUE</code>. 
</p>
</dd>
<dt><code>x</code></dt><dd>
<p>optionally the model matrix, if <code>x=TRUE</code>. 
</p>
</dd>
<dt><code>y</code></dt><dd>
<p>optionally the response, if <code>y=TRUE</code>. 
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>,  <code><a href="stats.html#topic+coefficients">coefficients</a></code>.   
</p>

<hr>
<h2 id='rq.process.object'>
Linear Quantile Regression Process Object 
</h2><span id='topic+rq.process.object'></span>

<h3>Description</h3>

<p>These are objects of class <code>rq.process.</code>
They represent the fit of a linear conditional quantile function model. 
</p>


<h3>Details</h3>

<p>These arrays are computed by parametric linear programming methods
using using the exterior point (simplex-type) methods of the 
Koenker&ndash;d'Orey algorithm based on Barrodale and Roberts median
regression algorithm.
</p>


<h3>Generation</h3>

<p>This class of objects is returned from the <code>rq</code>
function 
to represent a fitted linear quantile regression model. 
</p>


<h3>Methods</h3>

<p>The <code>"rq.process"</code> class of objects has 
methods for the following generic 
functions: 
<code>effects</code>, <code>formula</code>
, <code>labels</code>
, <code>model.frame</code>
, <code>model.matrix</code>
, <code>plot</code>
, <code>predict</code>
, <code>print</code>
, <code>print.summary</code>
, <code>summary</code>
</p>


<h3>Structure</h3>

<p>The following components must be included in a legitimate <code>rq.process</code>
object. 
</p>

<dl>
<dt><code>sol</code></dt><dd>
<p>The primal solution array.  This is a (p+3)  by  J  matrix  whose  
first  row  contains  the 'breakpoints'
<code class="reqn">tau_1, tau_2, \dots, tau_J</code>,   
of  the  quantile function, i.e. the values in [0,1] at which  the  
solution changes,  row  two  contains  the  corresponding quantiles 
evaluated at the mean design point, i.e. the inner product of  
xbar  and  <code class="reqn">b(tau_i)</code>, the third row contains the value of the objective
function evaluated at the corresponding <code class="reqn">tau_j</code>, and the last p rows 
of the matrix give <code class="reqn">b(tau_i)</code>.  The solution <code class="reqn">b(tau_i)</code> prevails from  
<code class="reqn">tau_i</code> to <code class="reqn">tau_i+1</code>.  Portnoy (1991) shows that
<code class="reqn">J=O_p(n \log n)</code>.
</p>
</dd>
<dt><code>dsol</code></dt><dd>
<p>The dual solution array.  This is a
n by J matrix  containing the  dual  solution  corresponding to sol,
the ij-th entry is 1 if <code class="reqn">y_i &gt; x_i b(tau_j)</code>, is 0 if <code class="reqn">y_i &lt;  x_i
      b(tau_j)</code>,  and is between 0 and 1 otherwise, i.e. if the
residual is zero. See  Gutenbrunner and Jureckova(1991)
for a detailed discussion of the statistical
interpretation of dsol.  The use of dsol in inference is described
in Gutenbrunner, Jureckova, Koenker, and Portnoy (1994).
</p>
</dd>
</dl>



<h3>References</h3>

<p>[1] Koenker, R. W. and Bassett, G. W. (1978). Regression quantiles,
<em>Econometrica</em>, <b>46</b>, 33&ndash;50.
</p>
<p>[2] Koenker, R. W. and d'Orey (1987, 1994).
Computing Regression Quantiles.
<em>Applied Statistics</em>, <b>36</b>, 383&ndash;393, and <b>43</b>, 410&ndash;414.
</p>
<p>[3] Gutenbrunner, C. Jureckova, J. (1991).
Regression quantile and regression rank score process in the
linear model and derived statistics, <em>Annals of Statistics</em>,
<b>20</b>, 305&ndash;330.
</p>
<p>[4] Gutenbrunner, C., Jureckova, J., Koenker, R. and
Portnoy, S. (1994)  Tests of linear hypotheses based on regression  
rank scores.   <em>Journal of Nonparametric Statistics</em>, 
(2), 307&ndash;331.
</p>
<p>[5]  Portnoy, S. (1991).  Asymptotic behavior of the number of regression
quantile breakpoints, <em>SIAM Journal of Scientific
and  Statistical Computing</em>, <b>12</b>, 867&ndash;883.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>.
</p>

<hr>
<h2 id='rq.wfit'>Function to choose method for Weighted Quantile Regression  </h2><span id='topic+rq.wfit'></span>

<h3>Description</h3>

<p> Weight the data and then call the chosen fitting algorithm.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>rq.wfit(x, y, tau=0.5, weights, method="br", ...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr><td><code id="rq.wfit_+3A_x">x</code></td>
<td>
 
<p>the design matrix 
</p>
</td></tr> 
<tr><td><code id="rq.wfit_+3A_y">y</code></td>
<td>
 
<p>the response variable 
</p>
</td></tr> 
<tr><td><code id="rq.wfit_+3A_tau">tau</code></td>
<td>
 
<p>the quantile desired, if tau lies outside (0,1) the whole process 
is estimated. 
</p>
</td></tr> 
<tr><td><code id="rq.wfit_+3A_weights">weights</code></td>
<td>
 
<p>weights used in the fitting
</p>
</td></tr> 
<tr><td><code id="rq.wfit_+3A_method">method</code></td>
<td>
 
<p>method of computation:  &quot;br&quot; is Barrodale and Roberts exterior point 
&quot;fn&quot; is the Frisch-Newton interior point method. 
</p>
</td></tr> 
<tr><td><code id="rq.wfit_+3A_...">...</code></td>
<td>
 
<p>Optional arguments passed to fitting routine.
</p>
</td></tr> 
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+rq">rq</a></code> <code><a href="quantreg.html#topic+rq.fit.br">rq.fit.br</a></code> <code><a href="quantreg.html#topic+rq.fit.fnb">rq.fit.fnb</a></code></p>

<hr>
<h2 id='rqProcess'> Compute Standardized Quantile Regression Process </h2><span id='topic+rqProcess'></span>

<h3>Description</h3>

<p>Computes a standardize quantile regression process for the model
specified by the formula, on the partition of [0,1] specified by the
taus argument, and standardized according to the argument nullH. 
Intended for use in <code><a href="quantreg.html#topic+KhmaladzeTest">KhmaladzeTest</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rqProcess(formula, data, taus, nullH = "location", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rqProcess_+3A_formula">formula</code></td>
<td>
<p>model formula  </p>
</td></tr>
<tr><td><code id="rqProcess_+3A_data">data</code></td>
<td>
<p>data frame to be used to interpret formula </p>
</td></tr>
<tr><td><code id="rqProcess_+3A_taus">taus</code></td>
<td>
<p> quantiles at which the process is to be evaluated, if any
of the taus lie outside (0,1)  then the full process is computed 
for all distinct solutions.</p>
</td></tr>
<tr><td><code id="rqProcess_+3A_nullh">nullH</code></td>
<td>
<p>Null hypothesis to be used for standardization</p>
</td></tr>
<tr><td><code id="rqProcess_+3A_...">...</code></td>
<td>
<p>optional arguments passed to <code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The process computes standardized estimates based on the 
hypothesis specified in the <code>nullH</code> argument.  
The Vhat component is rescaled by the Cholesky 
decomposition of the tau specific covariance matrix, the vhat component is
rescaled by the marginal standard errors.  The nature of the covariance
matrix used for the standardization is controlled arguments passed via
the <code>...</code> argument to <code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code>.  If the full
process is estimated then these covariance options aren't available
and only a simple iid-error form of the covariance matrix is used.
</p>


<h3>Value</h3>

<table>
<tr><td><code>taus</code></td>
<td>
<p>The points of evaluation of the process</p>
</td></tr>
<tr><td><code>qtaus</code></td>
<td>
<p>Values of xbar'betahat(taus)</p>
</td></tr>
<tr><td><code>Vhat</code></td>
<td>
<p>Joint parametric QR process</p>
</td></tr>
<tr><td><code>vhat</code></td>
<td>
<p>Marginal parametric QR processes</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Koenker</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+KhmaladzeTest">KhmaladzeTest</a></code></p>

<hr>
<h2 id='rqs.fit'>Function to fit multiple response quantile regression models</h2><span id='topic+rqs.fit'></span>

<h3>Description</h3>

<p>Function intended for multiple response quantile regression
called from <code>boot.rq</code> for wild bootstrap option.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rqs.fit(x, y, tau=0.5, tol = 0.0001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rqs.fit_+3A_x">x</code></td>
<td>

<p>the design matrix an n by p matrix.
</p>
</td></tr>
<tr><td><code id="rqs.fit_+3A_y">y</code></td>
<td>

<p>the response variable as a n by m matrix
</p>
</td></tr>
<tr><td><code id="rqs.fit_+3A_tau">tau</code></td>
<td>

<p>the quantile desired, if tau lies outside (0,1) 
</p>
</td></tr>
<tr><td><code id="rqs.fit_+3A_tol">tol</code></td>
<td>

<p>tolerance parameter for Barrodale and Roberts exterior point method.
</p>
</td></tr>
</table>


<h3>See Also</h3>

  <p><code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code> </p>

<hr>
<h2 id='rqss'>Additive Quantile Regression Smoothing</h2><span id='topic+rqss'></span><span id='topic+rqss.fit'></span><span id='topic++5B.terms'></span><span id='topic+untangle.specials'></span>

<h3>Description</h3>

<p>Fitting function for additive quantile regression models with possible univariate
and/or bivariate nonparametric terms estimated by total variation regularization.
See <code>summary.rqss</code> and <code>plot.rqss</code> for further details on inference and
confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rqss(formula, tau = 0.5, data = parent.frame(), weights, subset, na.action,
	method = "sfn", lambda = NULL, contrasts = NULL, ztol = 1e-5, control, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rqss_+3A_formula">formula</code></td>
<td>
<p>  a formula object, with the response on the left of a &lsquo;~&rsquo;
operator,  and terms, separated by &lsquo;+&rsquo; operators, on the right.
The terms may include <code>qss</code> terms that represent additive
nonparametric components.  These terms can be univariate or
bivariate.  See <code><a href="quantreg.html#topic+qss">qss</a></code> for details on how to
specify these terms.</p>
</td></tr>
<tr><td><code id="rqss_+3A_tau">tau</code></td>
<td>

<p>the quantile to be estimated, this must be a number between 0 and 1,
</p>
</td></tr>
<tr><td><code id="rqss_+3A_data">data</code></td>
<td>

<p>a data.frame in which to interpret the variables
named in the formula, or in the subset and the weights argument.
</p>
</td></tr>
<tr><td><code id="rqss_+3A_weights">weights</code></td>
<td>

<p>vector of observation weights; if supplied, the algorithm fits
to minimize the sum of the weights multiplied into the
absolute residuals. The length of weights must be the same as
the number of observations.  The weights must be nonnegative
and it is strongly recommended that they be strictly positive,
since zero weights are ambiguous.
</p>
</td></tr>
<tr><td><code id="rqss_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting.  This can be a vector of indices of observations
to be included, or a logical vector.</p>
</td></tr> 
<tr><td><code id="rqss_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data.
This is applied to the model.frame after any subset argument has been used.
The default (with <code>na.fail</code>) is to create an error if any missing values are
found.  A possible alternative is <code>na.omit</code>, which
deletes observations that contain one or more missing values.
</p>
</td></tr>
<tr><td><code id="rqss_+3A_method">method</code></td>
<td>

<p>the algorithmic method used to compute the fit.  There are currently
two options.   Both are implementations of the Frisch&ndash;Newton interior
point method described in detail in Portnoy and Koenker(1997).   Both
are implemented using sparse Cholesky decomposition as described in
Koenker and Ng (2003).
</p>
<p>Option <code>"sfnc"</code> is used if the user specifies inequality constraints.
Option <code>"sfn"</code> is used if there are no inequality constraints.
Linear inequality constraints on the fitted coefficients are specified
by a matrix <code>R</code> and a vector <code>r</code>, specified inside the <code>qss</code>
terms, representing the constraints in the form <code class="reqn">Rb \ge r</code>.
</p>
<p>The option <code>method = "lasso"</code> allows one to penalize the coefficients
of the covariates that have been entered linearly as in <code><a href="quantreg.html#topic+rq.fit.lasso">rq.fit.lasso</a></code>;
when this is specified then there should be an additional <code>lambda</code>
argument specified that determines the amount of shrinkage.  
</p>
</td></tr>
<tr><td><code id="rqss_+3A_lambda">lambda</code></td>
<td>
<p> can be either a scalar, in which case all the slope coefficients 
are assigned this value, or alternatively, the user can specify a vector of length 
equal to the number of linear covariates plus one (for the intercept) and these
values will be used as coordinate dependent shrinkage factors.
</p>
</td></tr>
<tr><td><code id="rqss_+3A_contrasts">contrasts</code></td>
<td>

<p>a list giving contrasts for some or all of the factors
default = <code>NULL</code> appearing in the model formula.
The elements of the list should have the same name as the variable
and should be either a contrast matrix (specifically, any full-rank
matrix with as many rows as there are levels in the factor),
or else a function to compute such a matrix given the number of levels.
</p>
</td></tr>
<tr><td><code id="rqss_+3A_ztol">ztol</code></td>
<td>
<p>A zero tolerance parameter used to determine the number of
zero residuals in the fitted object which in turn determines the effective
dimensionality of the fit.</p>
</td></tr>
<tr><td><code id="rqss_+3A_control">control</code></td>
<td>
<p> control argument for the fitting routines
(see <code><a href="quantreg.html#topic+sfn.control">sfn.control</a></code></p>
</td></tr> 
<tr><td><code id="rqss_+3A_...">...</code></td>
<td>
<p>Other arguments passed to fitting routines</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Total variation regularization for univariate and
bivariate nonparametric quantile smoothing is described
in Koenker, Ng and Portnoy (1994) and Koenker and Mizera(2003)
respectively.  The additive model extension of this approach
depends crucially on the sparse linear algebra implementation
for R described in Koenker and Ng (2003).  There are extractor
methods <code><a href="stats.html#topic+logLik">logLik</a></code> and <code><a href="stats.html#topic+AIC">AIC</a></code> that is
relevant to lambda selection.  A more detailed description of
some recent developments of these methods is available from
within the package with <code>vignette("rq")</code>.  Since this
function uses sparse versions of the interior point algorithm
it may also prove to be useful for fitting linear models
without <code><a href="quantreg.html#topic+qss">qss</a></code> terms when the design has a sparse
structure, as for example when there is a complicated factor 
structure.  
</p>
<p>If the <span class="pkg">MatrixModels</span> and <span class="pkg">Matrix</span> packages are both  loadable then the 
linear-in-parameters portion of the design matrix is made in sparse matrix form;
this is helpful in large applications with many factor variables for which dense 
formation of the design matrix would take too much space.
</p>
<p>Although modeling with <code>rqss</code> typically imposes smoothing penalties on
the total variation of the first derivative, or gradient, of the fitted functions,
for univariate smoothing, it is also possible to penalize total variation of
the function itself using the option <code>Dorder = 0</code> inside <code>qss</code> terms.
In such cases, estimated functions are piecewise constant rather than piecewise
linear.  See the documentation for <code>qss</code> for further details.
</p>


<h3>Value</h3>

<p>The function returns a fitted object representing the estimated
model specified in the formula.  See <code><a href="quantreg.html#topic+rqss.object">rqss.object</a></code>
for further details on this object, and references to methods
to look at it.
</p>


<h3>Note</h3>

<p>If you intend to embed calls to <code>rqss</code> inside another function, then
it is advisable to pass a data frame explicitly as the <code>data</code> argument
of the <code>rqss</code> call, rather than relying on the magic of R scoping rules.
</p>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p>[1] Koenker, R. and S. Portnoy (1997)
The Gaussian Hare and the Laplacean
Tortoise:  Computability of Squared-error vs Absolute Error Estimators,
(with discussion).
<em>Statistical Science</em> <b>12</b>, 279&ndash;300.
</p>
<p>[2] Koenker, R., P. Ng and S. Portnoy, (1994)
Quantile Smoothing Splines;
<em>Biometrika</em> <b>81</b>, 673&ndash;680.
</p>
<p>[3] Koenker, R. and I. Mizera, (2003)
Penalized Triograms: Total Variation Regularization for Bivariate Smoothing;
<em>JRSS(B)</em> <b>66</b>, 145&ndash;163.
</p>
<p>[4] Koenker, R. and P. Ng (2003)
SparseM:  A Sparse Linear Algebra Package for R,
<em>J. Stat. Software</em>.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+qss">qss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
x &lt;- sort(rchisq(n,4))
z &lt;- x + rnorm(n)
y &lt;- log(x)+ .1*(log(x))^2 + log(x)*rnorm(n)/4 + z
plot(x, y-z)
f.N  &lt;- rqss(y ~ qss(x, constraint= "N") + z)
f.I  &lt;- rqss(y ~ qss(x, constraint= "I") + z)
f.CI &lt;- rqss(y ~ qss(x, constraint= "CI") + z)

lines(x[-1], f.N $coef[1] + f.N $coef[-(1:2)])
lines(x[-1], f.I $coef[1] + f.I $coef[-(1:2)], col="blue")
lines(x[-1], f.CI$coef[1] + f.CI$coef[-(1:2)], col="red")

## A bivariate example
if(requireNamespace("interp")){
if(requireNamespace("interp")){
data(CobarOre)
fCO &lt;- rqss(z ~ qss(cbind(x,y), lambda= .08), data=CobarOre)
plot(fCO)
}}</code></pre>

<hr>
<h2 id='rqss.object'>RQSS Objects and Summarization Thereof</h2><span id='topic+rqss.object'></span><span id='topic+logLik.rqss'></span><span id='topic+AIC.rqss'></span><span id='topic+fitted.rqss'></span><span id='topic+resid.rqss'></span><span id='topic+print.rqss'></span>

<h3>Description</h3>

<p>Functions to reveal the inner meaning of objects created by <code>rqss</code> fitting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rqss'
logLik(object, ...)
## S3 method for class 'rqss'
AIC(object, ..., k=2)
## S3 method for class 'rqss'
print(x, ...)
## S3 method for class 'rqss'
resid(object, ...)
## S3 method for class 'rqss'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rqss.object_+3A_object">object</code></td>
<td>
<p>an object returned from <code>rqss</code> fitting, describing
an additive model estimating a conditional quantile function. 
See <code><a href="quantreg.html#topic+qss">qss</a></code> for details on how to specify these terms.</p>
</td></tr>
<tr><td><code id="rqss.object_+3A_x">x</code></td>
<td>
<p>an rqss object, as above.</p>
</td></tr>
<tr><td><code id="rqss.object_+3A_k">k</code></td>
<td>
<p>a constant factor governing the weight attached to the penalty
term on effective degrees of freedom of the fit.  By default 
k =2 corresponding to the Akaike version of the penalty, negative
values indicate that the k should be set to log(n) as proposed
by Schwarz (1978).</p>
</td></tr> 
<tr><td><code id="rqss.object_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p> Total variation regularization for univariate and
bivariate nonparametric quantile smoothing is described
in Koenker, Ng and Portnoy (1994) and Koenker and Mizera(2003)
respectively.  The additive model extension of this approach
depends crucially on the sparse linear algebra implementation
for R described in Koenker and Ng (2003).  Eventually, these
functions should be expanded to provide an automated lambda
selection procedure.</p>


<h3>Value</h3>

<p>The function <code>summary.rqss</code> returns a list consisting of
the following components:
</p>
<table>
<tr><td><code>fidelity</code></td>
<td>
<p>Value of the quantile regression objective function.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>A list consisting of the values of the total variation 
smoothing penalty for each of additive components.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>Effective degrees of freedom of the fitted model, defined
as the number of zero residuals of the fitted model,  Koenker
Mizera (2003) for details.</p>
</td></tr>
<tr><td><code>qssedfs</code></td>
<td>
<p>A list of effective degrees of freedom for each of
the additive components of the fitted model, defined as the
number of non-zero elements of each penalty component of the
residual vector.</p>
</td></tr>
<tr><td><code>lamdas</code></td>
<td>
<p>A list of the lambdas specified for each of the additive
components of the model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p>[1] Koenker, R. and S. Portnoy (1997)
The Gaussian Hare and the Laplacean
Tortoise:  Computability of Squared-error vs Absolute Error Estimators,
(with discussion).
<em>Statistical Science</em> <b>12</b>, 279&ndash;300.
</p>
<p>[2] Koenker, R., P. Ng and S. Portnoy, (1994)
Quantile Smoothing Splines;
<em>Biometrika</em> <b>81</b>, 673&ndash;680.
</p>
<p>[3] Koenker, R. and I. Mizera, (2003)
Penalized Triograms: Total Variation Regularization for Bivariate Smoothing;
<em>JRSS(B)</em> <b>66</b>, 145&ndash;163.
</p>
<p>[4] Koenker, R. and P. Ng (2003)
SparseM:  A Sparse Linear Algebra Package for R,
<em>J. Stat. Software</em>.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+plot.rqss">plot.rqss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(MatrixModels)
n &lt;- 200
x &lt;- sort(rchisq(n,4))
z &lt;- x + rnorm(n)
y &lt;- log(x)+ .1*(log(x))^2 + log(x)*rnorm(n)/4 + z
plot(x, y-z)
f.N  &lt;- rqss(y ~ qss(x, constraint= "N") + z)
f.I  &lt;- rqss(y ~ qss(x, constraint= "I") + z)
f.CI &lt;- rqss(y ~ qss(x, constraint= "CI") + z)

lines(x[-1], f.N $coef[1] + f.N $coef[-(1:2)])
lines(x[-1], f.I $coef[1] + f.I $coef[-(1:2)], col="blue")
lines(x[-1], f.CI$coef[1] + f.CI$coef[-(1:2)], col="red")

## A bivariate example
if(requireNamespace("interp")){
if(requireNamespace("interp")){
data(CobarOre)
fCO &lt;- rqss(z ~ qss(cbind(x,y), lambda= .08), data=CobarOre)
plot(fCO)
}}</code></pre>

<hr>
<h2 id='sfn.control'>Set Control Parameters for Sparse Fitting </h2><span id='topic+sfn.control'></span>

<h3>Description</h3>

<p>Auxiliary function for setting storage dimensions and other parameters rq.fit.sfn[c]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfn.control(nsubmax = NULL, tmpmax = NULL, nnzlmax = NULL, cachsz = 64, 
	small = 1e-06, maxiter = 100, warn.mesg = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sfn.control_+3A_nsubmax">nsubmax</code></td>
<td>

<p>upper bound for dimension of lindx
</p>
</td></tr>
<tr><td><code id="sfn.control_+3A_tmpmax">tmpmax</code></td>
<td>

<p>upper bound for dimension of tmpvec
</p>
</td></tr>
<tr><td><code id="sfn.control_+3A_nnzlmax">nnzlmax</code></td>
<td>

<p>upper bound for non-zero entries of L stored in lnz, including diagonal
</p>
</td></tr>
<tr><td><code id="sfn.control_+3A_cachsz">cachsz</code></td>
<td>

<p>size of cache in kbytes on target machine
</p>
</td></tr>
<tr><td><code id="sfn.control_+3A_small">small</code></td>
<td>

<p>convergence tolerance for interior point algorithm
</p>
</td></tr>
<tr><td><code id="sfn.control_+3A_maxiter">maxiter</code></td>
<td>

<p>maximal number of interior point iterations. 
</p>
</td></tr>
<tr><td><code id="sfn.control_+3A_warn.mesg">warn.mesg</code></td>
<td>

<p>logical flag controlling printing of warnings. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sparse fitting requires a number of temporary storage arrays whose size depends
on problem specific features in somewhat mysterious ways, parameters controlling
these sizes and some other fitting aspects can be controlled by specifying elements
of this control object.
</p>


<h3>Value</h3>

<p>List with components named as the arguments given above.
</p>


<h3>Author(s)</h3>

<p>Roger Koenker
</p>


<h3>See Also</h3>

<p>See Also <code><a href="quantreg.html#topic+rq.fit.sfn">rq.fit.sfn</a></code>
</p>

<hr>
<h2 id='srisk'> Markowitz (Mean-Variance) Portfolio Optimization</h2><span id='topic+srisk'></span>

<h3>Description</h3>

<p>This function estimates optimal mean-variance portfolio weights from a matrix
of historical or simulated asset returns.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>srisk(x, mu = 0.07, lambda = 1e+08, alpha = 0.1, eps = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="srisk_+3A_x">x</code></td>
<td>
<p> Matrix of asset returns </p>
</td></tr>
<tr><td><code id="srisk_+3A_mu">mu</code></td>
<td>
<p>Required mean rate of return for the portfolio </p>
</td></tr>
<tr><td><code id="srisk_+3A_lambda">lambda</code></td>
<td>
<p>Lagrange multiplier associated with mean return constraint</p>
</td></tr>
<tr><td><code id="srisk_+3A_alpha">alpha</code></td>
<td>
<p>Choquet risk parameter, unimplemented </p>
</td></tr>
<tr><td><code id="srisk_+3A_eps">eps</code></td>
<td>
<p> tolerance parameter for mean return constraint</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The portfolio weights are estimated by solving a constrained least squares problem.
</p>


<h3>Value</h3>

<table>
<tr><td><code>pihat</code></td>
<td>
<p>Optimal portfolio weights</p>
</td></tr>
<tr><td><code>muhat</code></td>
<td>
<p>Mean return in sample</p>
</td></tr>
<tr><td><code>sighat</code></td>
<td>
<p>Standard deviation of returns in sample</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> R. Koenker </p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+qrisk">qrisk</a></code></p>

<hr>
<h2 id='summary.crq'>
Summary methods for Censored Quantile Regression
</h2><span id='topic+summary.crqs'></span><span id='topic+summary.crq'></span><span id='topic+print.summary.crq'></span><span id='topic+print.summary.crqs'></span><span id='topic+plot.summary.crqs'></span>

<h3>Description</h3>

<p>Returns a summary object for a censored quantile regression fit.  A null value
will be returned if printing is invoked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'crq'
summary(object, taus = 1:4/5, alpha = .05, se="boot", covariance=TRUE,  ...)
## S3 method for class 'summary.crq'
print(x, digits = max(5, .Options$digits - 2), ...)
## S3 method for class 'summary.crqs'
print(x,  ...)
## S3 method for class 'summary.crqs'
plot(x, nrow = 3, ncol = 3, CoxPHit = NULL,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.crq_+3A_object">object</code></td>
<td>

<p>An object of class <code>"crq"</code>  produced by a call to <code>crq()</code>.
</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_taus">taus</code></td>
<td>
<p>Quantiles to be summarized.  This should be a vector of
length greater than one.</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_x">x</code></td>
<td>

<p>An object of class <code>"crq"</code>  produced by a call to <code>crq()</code>.
</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_se">se</code></td>
<td>

<p>specifies the method used to compute standard standard errors. but
the only available method (so far) is &quot;boot&quot;.  Further arguments to
<code><a href="quantreg.html#topic+boot.crq">boot.crq</a></code> and <code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code>  can be passed with 
the ... argument. 
</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_covariance">covariance</code></td>
<td>

<p>logical flag to indicate whether the full covariance matrix of the 
estimated parameters should be returned. 
</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_nrow">nrow</code></td>
<td>
<p>Number of rows of the plot layout.</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_ncol">ncol</code></td>
<td>
<p>Number of columns of the plot layout.</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_alpha">alpha</code></td>
<td>
<p>Confidence level for summary intervals.</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_digits">digits</code></td>
<td>
<p>Number of digits to be printed in summary display.</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_coxphit">CoxPHit</code></td>
<td>
<p>An object of class coxph produced by <code>coxph</code>.</p>
</td></tr>
<tr><td><code id="summary.crq_+3A_...">...</code></td>
<td>

<p>Optional arguments to summary, e.g. to specify bootstrap methods
sample sizes, etc.  see <code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code> and <code><a href="quantreg.html#topic+boot.crq">boot.crq</a></code>
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the Powell method the resampling strategy used by the
<code>se = "boot"</code> method is based on the Bilias, Chen and Ying (2000) 
proposal.  For the Portnoy and Peng-Huang methods the bootstrapping 
is by default actually based on  a delete-d jackknife, as described in
Portnoy (2013), but resampling xy pairs using either conventional multinomial 
resampling or using exponential weighting as in Bose and Chatterjee (2003)
can be used by specifying the <code>bmethod</code> argument.  Note that the default
number of replications is set at <code class="reqn">R = 100</code> a value that is obviously too small for
most applications.  This is done merely to speed up the examples in the 
documentation and facilitate testing. Larger, more appropriate values of <code class="reqn">R</code>
can be passed to the bootstrapping functions via the <code>...</code> argument
of the <code>summary</code> method.  It is important to recognize that when some
of the bootstrap replications are NA they are simply ignored in the computation
of the confidence bands and standard errors as currently reported.  The number
of these NAs is returned as part of the <code>summary.crq</code> object, and 
when printed is also reported. 
</p>


<h3>Value</h3>

<p>For method &quot;Powell&quot; an object of class <code>summary.crq</code>  is returned 
with the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>

<p>a p by 4 matrix consisting of the coefficients, their estimated standard
errors, their t-statistics, and their associated p-values.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>the estimated covariance matrix for the coefficients in the model,
provided that <code>covariance = TRUE</code> appears in the calling sequence.
</p>
</td></tr>
<tr><td><code>rdf</code></td>
<td>

<p>the residual degrees of freedom
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>the quantile estimated
</p>
</td></tr>
</table>
<p>For the other methods an object of class <code>summary.crq</code>  is returned 
with the following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>

<p>a list of  p by 6 matrix consisting of the coefficients, upper and lower bounds
for a (1-alpha) level confidence interval, their estimated standard
errors, their t-statistics, and their associated p-values, one component for each
element of the specified <code>taus</code> vector.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>the estimated covariance matrix for the coefficients in the model,
provided that <code>covariance = TRUE</code> in the called sequence.
</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bose, A. and S. Chatterjee, (2003) Generalized bootstrap for estimators 
of minimizers of convex functions, <em>J. Stat. Planning and Inf</em>, 117,
225-239.
</p>
<p>Bilias, Y. Chen, S. and Z. Ying, (2000) Simple resampling methods for censored
quantile regression, <em>J. of Econometrics</em>, 99, 373-386.
</p>
<p>Portnoy, S. (2013) The Jackknife's Edge:  Inference for Censored Quantile Regression,
<em>CSDA</em>, forthcoming.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+crq">crq</a></code>, <code><a href="quantreg.html#topic+QTECox">QTECox</a></code>
</p>

<hr>
<h2 id='summary.rq'>
Summary methods for Quantile Regression
</h2><span id='topic+summary.rq'></span><span id='topic+summary.rqs'></span><span id='topic+summary.rcrqs'></span>

<h3>Description</h3>

<p>Returns a summary list for a quantile regression fit.  A null value
will be returned if printing is invoked.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rq'
summary(object, se = NULL, covariance=FALSE, hs = TRUE,  U = NULL, gamma = 0.7, ...)
## S3 method for class 'rqs'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rq_+3A_object">object</code></td>
<td>

<p>This is an object of class <code>"rq"</code> or <code>"rqs"</code> produced by 
a call to <code>rq()</code>, depending on whether one or more taus are
specified.
</p>
</td></tr>
<tr><td><code id="summary.rq_+3A_se">se</code></td>
<td>

<p>specifies the method used to compute standard standard errors.  There
are currently seven available methods:  
</p>

<ol>
<li> <p><code>"rank"</code> which produces confidence intervals for the
estimated parameters by inverting a rank test as described in
Koenker (1994).  This method involves solving a parametric linear
programming problem, and for large sample sizes can be extremely
slow, so by default it is only used when the sample size is less
than 1000, see below.  The default option assumes that the errors are
iid, while the option iid = FALSE implements a proposal of Koenker
Machado (1999).  See the documentation for <code>rq.fit.br</code> for additional arguments.
</p>
</li>
<li> <p><code>"iid"</code> which presumes that the errors are iid and computes
an estimate of the asymptotic covariance matrix as in KB(1978).
</p>
</li>
<li> <p><code>"nid"</code> which presumes local (in <code>tau</code>)
linearity (in <code>x</code>) of the
the conditional quantile functions and computes a Huber
sandwich estimate using a local estimate of the sparsity.
If the initial fitting was done with method &quot;sfn&quot; then use
of <code>se = "nid"</code> is recommended.  However, if the cluster
option is also desired then <code>se = "boot"</code> can be used
and bootstrapping will also employ the &quot;sfn&quot; method.
</p>
</li>
<li> <p><code>"ker"</code> which uses a kernel estimate of the sandwich
as proposed by Powell(1991).
</p>
</li>
<li> <p><code>"boot"</code> which implements one of several possible bootstrapping
alternatives for estimating standard errors including a variate of the wild
bootstrap for clustered response.  See <code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code> for
further details.  
</p>
</li>
<li> <p><code>"BLB"</code> which implements the bag of little bootstraps method
proposed in Kleiner, et al (2014).  The sample size of the little bootstraps
is controlled by the parameter <code>gamma</code>, see below.  At present only
<code>bsmethod = "xy"</code> is sanction, and even that is experimental.  This
option is intended for applications with very large n where other flavors
of the bootstrap can be slow.
</p>
</li>
<li> <p><code>"conquer"</code> which is invoked automatically if the fitted 
object was created with <code>method = "conquer"</code>, and returns the
multiplier bootstrap percentile confidence intervals described in
He et al (2020).
</p>
</li>
<li> <p><code>"extreme"</code> which uses the subsampling method of Chernozhukov
Fernandez-Val, and Kaji (2018) designed for inference on extreme quantiles.
</p>
</li></ol>

<p>If <code>se = NULL</code> (the default)  and <code>covariance = FALSE</code>, and
the sample size is less than 1001, then the &quot;rank&quot; method is used, 
otherwise the &quot;nid&quot; method is used.
</p>
</td></tr>
<tr><td><code id="summary.rq_+3A_covariance">covariance</code></td>
<td>

<p>logical flag to indicate whether the full covariance matrix of the 
estimated parameters should be returned. 
</p>
</td></tr>
<tr><td><code id="summary.rq_+3A_hs">hs</code></td>
<td>

<p>Use Hall Sheather bandwidth for sparsity estimation
If false revert to Bofinger bandwidth.
</p>
</td></tr>
<tr><td><code id="summary.rq_+3A_u">U</code></td>
<td>
<p>Resampling indices or gradient evaluations used for bootstrap,
see <code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code>.</p>
</td></tr>
<tr><td><code id="summary.rq_+3A_gamma">gamma</code></td>
<td>
<p>parameter controlling the effective sample size of the'bag
of little bootstrap samples that will be <code>b = n^gamma</code> where
<code>n</code> is the sample size of the original model.</p>
</td></tr>
<tr><td><code id="summary.rq_+3A_...">...</code></td>
<td>

<p>Optional arguments to summary, e.g. bsmethod to use bootstrapping.
see <code><a href="quantreg.html#topic+boot.rq">boot.rq</a></code>.  When using the &quot;rank&quot; method for confidence
intervals, which is the default method for sample sizes less than 1000,
the type I error probability of the intervals can be controlled with the
alpha parameter passed via &quot;...&quot;,  thereby controlling the width of the
intervals plotted by <code>plot.summary.rqs</code>. Similarly, the arguments
alpha, mofn and kex can be passed when invoking the <code>"extreme"</code> option
for  &quot;se&quot; to control the percentile interval reported, given by estimated
quantiles [alpha/2, 1 - alpha/2]; <code>kex</code> is a tuning parameter for the
extreme value confidence interval construction. The size of the bootstrap
subsamples for the &quot;extreme&quot; option can also be controlled by passing
the argument <code>mofm</code> via &quot;...&quot;.  Default values for kex, mofn and
alpha are 20, <code>floor(n/5)</code> and 0.1, respectively.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the default summary method is used, it tries to estimate a sandwich
form of the asymptotic covariance matrix and this involves estimating
the conditional density at each of the sample observations, negative
estimates can occur if there is crossing of the neighboring quantile
surfaces used to compute the difference quotient estimate.  
A warning message is issued when such negative estimates exist indicating
the number of occurrences &ndash; if this number constitutes a large proportion
of the sample size, then it would be prudent to consider an alternative 
inference method like the bootstrap.
If the number of these is large relative to the sample size it is sometimes
an indication that some additional nonlinearity in the covariates
would be helpful, for instance quadratic effects.
Note that the default <code>se</code> method is rank, unless the sample size exceeds
1001, in which case the <code>rank</code> method is used.
There are several options for alternative resampling methods.  When
<code>summary.rqs</code> is invoked, that is when <code>summary</code> is called
for a <code>rqs</code> object consisting of several <code>taus</code>, the <code>B</code>
components of the returned object can be used to construct a joint covariance
matrix for the full object.</p>


<h3>Value</h3>

<p>a list is returned with the following components, when <code>object</code>
is of class <code>"rqs"</code> then there is a list of such lists.
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>

<p>a p by 4 matrix consisting of the coefficients, their estimated standard
errors, their t-statistics, and their associated p-values, in the case of
most &quot;se&quot; methods.  For methods &quot;rank&quot; and &quot;extreme&quot; potentially asymetric
confidence intervals are return in lieu of standard errors and p-values.
</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>

<p>the estimated covariance matrix for the coefficients in the model,
provided that <code>cov=TRUE</code> in the called sequence.  This option
is not available when se = &quot;rank&quot;.
</p>
</td></tr>
<tr><td><code>Hinv</code></td>
<td>

<p>inverse of the estimated Hessian matrix returned if <code>cov=TRUE</code> and
<code>se %in% c("nid","ker") </code>, note that for <code>se = "boot"</code> there
is no way to split the estimated covariance matrix into its sandwich
constituent parts.
</p>
</td></tr>
<tr><td><code>J</code></td>
<td>

<p>Unscaled Outer product of gradient matrix returned if <code>cov=TRUE</code> and <code>se
    != "iid"</code>. The Huber sandwich is <code>cov = tau (1-tau) Hinv %*% J %*% Hinv</code>.
as for the <code>Hinv</code> component, there is no <code>J</code> component when
<code>se == "boot"</code>.  (Note that to make the Huber sandwich you need to add the 
tau (1-tau) mayonnaise yourself.)
</p>
</td></tr>
<tr><td><code>B</code></td>
<td>
<p>Matrix of bootstrap realizations.</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>Matrix of bootstrap randomization draws.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chernozhukov, Victor, Ivan Fernandez-Val, and Tetsuya Kaji, (2018)
Extremal Quantile Regression, in Handbook of Quantile Regression,
Eds. Roger Koenker, Victor Chernozhukov, Xuming He, Limin Peng,
CRC Press.
</p>
<p>Koenker, R. (2004) <em>Quantile Regression</em>.
</p>
<p>Bilias, Y. Chen, S. and Z. Ying, Simple resampling methods for censored
quantile regression, <em>J. of Econometrics</em>, 99, 373-386.
</p>
<p>Kleiner, A., Talwalkar, A., Sarkar, P. and Jordan, M.I. (2014) A Scalable
bootstrap for massive data, <em>JRSS(B)</em>, 76, 795-816.
</p>
<p>Powell, J. (1991) Estimation of Monotonic Regression Models under
Quantile Restrictions, in Nonparametric and Semiparametric Methods
in Econometrics, W. Barnett, J. Powell, and G Tauchen (eds.),
Cambridge U. Press.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code>
<code><a href="quantreg.html#topic+bandwidth.rq">bandwidth.rq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
y &lt;- stack.loss
x &lt;- stack.x
summary(rq(y ~ x, method="fn")) # Compute se's for fit using "nid" method.
summary(rq(y ~ x, ci=FALSE),se="ker")
# default "br" alg, and compute kernel method se's
</code></pre>

<hr>
<h2 id='summary.rqss'>Summary of rqss fit</h2><span id='topic+summary.rqss'></span><span id='topic+print.summary.rqss'></span>

<h3>Description</h3>

<p> Summary Method for a fitted rqss model.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rqss'
summary(object, cov = FALSE, ztol = 1e-5, ...) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.rqss_+3A_object">object</code></td>
<td>
<p>an object returned from <code>rqss</code> fitting, describing
an additive model estimating a conditional quantile function. 
See <code><a href="quantreg.html#topic+qss">qss</a></code> for details on how to specify these terms.</p>
</td></tr>
<tr><td><code id="summary.rqss_+3A_cov">cov</code></td>
<td>
<p>if TRUE return covariance matrix for the parametric components
as <code>Vcov</code> and a list of covariance matrices for the nonparametric
components as <code>Vqss</code></p>
</td></tr>
<tr><td><code id="summary.rqss_+3A_ztol">ztol</code></td>
<td>
<p>Zero tolerance parameter used to determine the number of zero
residuals indicating the estimated parametric dimension of the model,
the so-called effective degrees of freedom.</p>
</td></tr>
<tr><td><code id="summary.rqss_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p> This function is intended to explore
inferential methods for rqss fitting.  The function is modeled after
<code>summary.gam</code> in Simon Wood's (2006)  <span class="pkg">mgcv</span> package.  (Of course,
Simon should not be blamed for any deficiencies in the current implementation.
The basic idea is to condition on the lambda selection and construct
quasi-Bayesian credibility intervals based on normal approximation of
the &quot;posterior,&quot; as computed using the Powell kernel estimate of the
usual quantile regression sandwich.  See <code><a href="quantreg.html#topic+summary.rq">summary.rq</a></code> for
further details and references.
The function produces a conventional coefficient table with standard errors
t-statistics and p-values for the coefficients on the parametric part of the
model, and another table for additive nonparametric effects.  The latter
reports F statistics intended to evaluate the significance of these components
individually.  In addition the fidelity (value of the QR objective function
evaluated at the fitted model), the effective degrees of freedom, and the
sample size are reported.
</p>


<h3>Value</h3>

<table>
<tr><td><code>coef</code></td>
<td>
<p>Table of estimated coefficients and their standard errors,
t-statistics, and p-values for the parametric components of the model</p>
</td></tr>
<tr><td><code>qsstab</code></td>
<td>
<p>Table of approximate F statistics, effective degrees of freedom
and values of the penalty terms for each of the additive nonparametric 
components of the model, and the lambda values assigned to each.</p>
</td></tr> 
<tr><td><code>fidelity</code></td>
<td>
<p>Value of the quantile regression objective function.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>Quantile of the estimated model</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>formula of the estimated model</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>Effective degrees of freedom of the fitted model, defined
as the number of zero residuals of the fitted model,  see Koenker
Mizera (2003) for details.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>The sample size used to fit the model.</p>
</td></tr>
<tr><td><code>Vcov</code></td>
<td>
<p>Estimated covariance matrix of the fitted parametric component</p>
</td></tr>
<tr><td><code>Vqss</code></td>
<td>
<p>List of estimated covariance matrices of the fitted 
nonparametric component</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Roger Koenker </p>


<h3>References</h3>

<p>[1] Koenker, R., P. Ng and S. Portnoy, (1994)
Quantile Smoothing Splines;
<em>Biometrika</em> <b>81</b>, 673&ndash;680.
</p>
<p>[2] Koenker, R. and I. Mizera, (2003)
Penalized Triograms: Total Variation Regularization for Bivariate Smoothing;
<em>JRSS(B)</em> <b>66</b>, 145&ndash;163.
</p>
<p>[3] Wood, S. (2006) <em>Generalized Additive Models</em>, Chapman-Hall.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+plot.rqss">plot.rqss</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 200
x &lt;- sort(rchisq(n,4))
z &lt;- x + rnorm(n)
y &lt;- log(x)+ .1*(log(x))^2 + log(x)*rnorm(n)/4 + z
f  &lt;- rqss(y ~ qss(x) + z)
summary(f)
</code></pre>

<hr>
<h2 id='table.rq'>
Table of Quantile Regression Results
</h2><span id='topic+table.rq'></span><span id='topic+latex.table.rq'></span><span id='topic+plot.table.rq'></span>

<h3>Description</h3>

<p>Defunct Function to produce a table of quantile regression results for a group
of specified quantiles.  See <code>rq</code> which now permits multiple taus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>table.rq(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="table.rq_+3A_x">x</code></td>
<td>

<p>input
</p>
</td></tr>
<tr><td><code id="table.rq_+3A_...">...</code></td>
<td>

<p>other optional arguments 
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None.
</p>


<h3>See Also</h3>

 <p><code><a href="quantreg.html#topic+rq">rq</a></code>, </p>

<hr>
<h2 id='uis'>UIS Drug Treatment study data</h2><span id='topic+uis'></span>

<h3>Description</h3>

<p>There are 628 data points in the original data, 575 of which have no missing values.
</p>
<p>Variable descriptions:
</p>

<table>
<tr>
 <td style="text-align: left;">
Variable  </td><td style="text-align: left;"> Description                     </td><td style="text-align: left;"> Codes/Values                   </td>
</tr>
<tr>
 <td style="text-align: left;">
ID        </td><td style="text-align: left;"> Identification Code             </td><td style="text-align: left;"> 1 - 628                        </td>
</tr>
<tr>
 <td style="text-align: left;">
AGE       </td><td style="text-align: left;"> Age at Enrollment               </td><td style="text-align: left;"> Years                          </td>
</tr>
<tr>
 <td style="text-align: left;">
BECK      </td><td style="text-align: left;"> Beck DepressionScore            </td><td style="text-align: left;"> 0.000 - 54.000                 </td>
</tr>
<tr>
 <td style="text-align: left;">
HC        </td><td style="text-align: left;"> Heroin/Cocaine Use During       </td><td style="text-align: left;"> 1 = Heroin &amp; Cocaine           </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;"> 3 Months Prior to Admission     </td><td style="text-align: left;"> 2 = Heroin Only                </td>
</tr>
<tr>
 <td style="text-align: left;"> 
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 3 = Cocaine Only               </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 4 = Neither Heroin nor Cocaine </td>
</tr>
<tr>
 <td style="text-align: left;">
IV        </td><td style="text-align: left;"> History of IV Drug Use          </td><td style="text-align: left;"> 1 = Never                      </td>
</tr>
<tr>
 <td style="text-align: left;"> 
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 2 = Previous                   </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 3 = Recent                     </td>
</tr>
<tr>
 <td style="text-align: left;">
NDT       </td><td style="text-align: left;"> Number of Prior Drug Treatments </td><td style="text-align: left;"> 0 - 40                         </td>
</tr>
<tr>
 <td style="text-align: left;">
RACE      </td><td style="text-align: left;"> Subject's Race                  </td><td style="text-align: left;"> 0 = White                      </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 1 = Non-White                  </td>
</tr>
<tr>
 <td style="text-align: left;">
TREAT     </td><td style="text-align: left;"> Treatment Randomization         </td><td style="text-align: left;"> 0 = Short                      </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;"> Assignment                      </td><td style="text-align: left;"> 1 = Long                       </td>
</tr>
<tr>
 <td style="text-align: left;">
SITE      </td><td style="text-align: left;"> Treatment Site                  </td><td style="text-align: left;"> 0 = A                          </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 1 = B                          </td>
</tr>
<tr>
 <td style="text-align: left;">
LEN.T     </td><td style="text-align: left;"> Length of Stay in Treatment     </td><td style="text-align: left;"> Days                           </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;"> (Admission Date to Exit Date)   </td><td style="text-align: left;">                                </td>
</tr>
<tr>
 <td style="text-align: left;"> 
TIME      </td><td style="text-align: left;"> Time to Drug Relapse            </td><td style="text-align: left;"> Days                           </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;"> (Measured from Admission Date)  </td><td style="text-align: left;">                                </td>
</tr>
<tr>
 <td style="text-align: left;">
CENSOR    </td><td style="text-align: left;"> Event for Treating Lost to      </td><td style="text-align: left;"> 1 = Returned to Drugs          </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;"> Follow-Up as Returned to Drugs  </td><td style="text-align: left;">     or Lost to Follow-Up       </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 0 = Otherwise                  </td>
</tr>
<tr>
 <td style="text-align: left;">
Y         </td><td style="text-align: left;"> log of TIME                     </td><td style="text-align: left;">                                </td>
</tr>
<tr>
 <td style="text-align: left;">  
ND1       </td><td style="text-align: left;"> Component of NDT                </td><td style="text-align: left;">                                </td>
</tr>
<tr>
 <td style="text-align: left;">  
ND2       </td><td style="text-align: left;"> Component of NDT                </td><td style="text-align: left;">                                </td>
</tr>
<tr>
 <td style="text-align: left;">
LNDT      </td><td style="text-align: left;">                                 </td><td style="text-align: left;">                                </td>
</tr>
<tr>
 <td style="text-align: left;"> 
FRAC      </td><td style="text-align: left;"> Compliance fraction             </td><td style="text-align: left;"> LEN.T/90 for short trt         </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> LEN.T/180 for long trt         </td>
</tr>
<tr>
 <td style="text-align: left;">
IV3       </td><td style="text-align: left;"> Recent IV use                   </td><td style="text-align: left;"> 1 = Yes                        </td>
</tr>
<tr>
 <td style="text-align: left;">
          </td><td style="text-align: left;">                                 </td><td style="text-align: left;"> 0 = No 

</td>
</tr>

</table>



<h3>Usage</h3>

<pre><code class='language-R'>data(uis)</code></pre>


<h3>Format</h3>

<p>A data frame with dimension 575 by 18.</p>


<h3>Source</h3>

<p>Table 1.3 of Hosmer,D.W. and Lemeshow, S. (1998) </p>


<h3>References</h3>

<p>Hosmer,D.W. and Lemeshow, S. (1998) Applied Survival
Analysis: Regression Modeling of Time to Event Data, John Wiley and Sons Inc.,
New York, NY</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
