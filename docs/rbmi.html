<!DOCTYPE html><html><head><title>Help for package rbmi</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rbmi}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#rbmi-package'><p>rbmi: Reference Based Multiple Imputation</p></a></li>
<li><a href='#add_class'><p>Add a class</p></a></li>
<li><a href='#adjust_trajectories'><p>Adjust trajectories due to the intercurrent event (ICE)</p></a></li>
<li><a href='#adjust_trajectories_single'><p>Adjust trajectory of a subject's outcome due to the intercurrent event (ICE)</p></a></li>
<li><a href='#analyse'><p>Analyse Multiple Imputed Datasets</p></a></li>
<li><a href='#ancova'><p>Analysis of Covariance</p></a></li>
<li><a href='#ancova_single'><p>Implements an Analysis of Covariance (ANCOVA)</p></a></li>
<li><a href='#antidepressant_data'><p>Antidepressant trial data</p></a></li>
<li><a href='#apply_delta'><p>Applies delta adjustment</p></a></li>
<li><a href='#as_analysis'><p>Construct an <code>analysis</code> object</p></a></li>
<li><a href='#as_ascii_table'><p>as_ascii_table</p></a></li>
<li><a href='#as_class'><p>Set Class</p></a></li>
<li><a href='#as_cropped_char'><p>as_cropped_char</p></a></li>
<li><a href='#as_dataframe'><p>Convert object to dataframe</p></a></li>
<li><a href='#as_draws'><p>Creates a <code>draws</code> object</p></a></li>
<li><a href='#as_imputation'><p>Create an imputation object</p></a></li>
<li><a href='#as_indices'><p>Convert indicator to index</p></a></li>
<li><a href='#as_mmrm_df'><p>Creates a &quot;MMRM&quot; ready dataset</p></a></li>
<li><a href='#as_mmrm_formula'><p>Create MMRM formula</p></a></li>
<li><a href='#as_model_df'><p>Expand <code>data.frame</code> into a design matrix</p></a></li>
<li><a href='#as_simple_formula'><p>Creates a simple formula object from a string</p></a></li>
<li><a href='#as_stan_array'><p>As array</p></a></li>
<li><a href='#as_strata'><p>Create vector of Stratas</p></a></li>
<li><a href='#assert_variables_exist'><p>Assert that all variables exist within a dataset</p></a></li>
<li><a href='#char2fct'><p>Convert character variables to factor</p></a></li>
<li><a href='#check_ESS'><p>Diagnostics of the MCMC based on ESS</p></a></li>
<li><a href='#check_hmc_diagn'><p>Diagnostics of the MCMC based on HMC-related measures.</p></a></li>
<li><a href='#check_mcmc'><p>Diagnostics of the MCMC</p></a></li>
<li><a href='#compute_sigma'><p>Compute covariance matrix for some reference-based methods (JR, CIR)</p></a></li>
<li><a href='#convert_to_imputation_list_df'><p>Convert list of <code>imputation_list_single()</code> objects to an <code>imputation_list_df()</code> object</p>
(i.e. a list of <code>imputation_df()</code> objects's)</a></li>
<li><a href='#d_lagscale'><p>Calculate delta from a lagged scale coefficient</p></a></li>
<li><a href='#delta_template'><p>Create a delta <code>data.frame</code> template</p></a></li>
<li><a href='#do_not_run'><p>Do not run this function</p></a></li>
<li><a href='#draws'><p>Fit the base imputation model and get parameter estimates</p></a></li>
<li><a href='#encap_get_mmrm_sample'><p>Encapsulate get_mmrm_sample</p></a></li>
<li><a href='#eval_mmrm'><p>Evaluate a call to mmrm</p></a></li>
<li><a href='#expand'><p>Expand and fill in missing <code>data.frame</code> rows</p></a></li>
<li><a href='#extract_covariates'><p>Extract Variables from string vector</p></a></li>
<li><a href='#extract_data_nmar_as_na'><p>Set to NA outcome values that would be MNAR if they were missing</p>
(i.e. which occur after an ICE handled using a reference-based imputation strategy)</a></li>
<li><a href='#extract_draws'><p>Extract draws from a <code>stanfit</code> object</p></a></li>
<li><a href='#extract_imputed_df'><p>Extract imputed dataset</p></a></li>
<li><a href='#extract_imputed_dfs'><p>Extract imputed datasets</p></a></li>
<li><a href='#extract_params'><p>Extract parameters from a MMRM model</p></a></li>
<li><a href='#fit_mcmc'><p>Fit the base imputation model using a Bayesian approach</p></a></li>
<li><a href='#fit_mmrm'><p>Fit a MMRM model</p></a></li>
<li><a href='#generate_data_single'><p>Generate data for a single group</p></a></li>
<li><a href='#get_bootstrap_stack'><p>Creates a stack object populated with bootstrapped samples</p></a></li>
<li><a href='#get_cluster'><p>Create cluster</p></a></li>
<li><a href='#get_conditional_parameters'><p>Derive conditional multivariate normal parameters</p></a></li>
<li><a href='#get_delta_template'><p>Get delta utility variables</p></a></li>
<li><a href='#get_draws_mle'><p>Fit the base imputation model on bootstrap samples</p></a></li>
<li><a href='#get_ESS'><p>Extract the Effective Sample Size (ESS) from a <code>stanfit</code> object</p></a></li>
<li><a href='#get_ests_bmlmi'><p>Von Hippel and Bartlett pooling of BMLMI method</p></a></li>
<li><a href='#get_example_data'><p>Simulate a realistic example dataset</p></a></li>
<li><a href='#get_jackknife_stack'><p>Creates a stack object populated with jackknife samples</p></a></li>
<li><a href='#get_mmrm_sample'><p>Fit MMRM and returns parameter estimates</p></a></li>
<li><a href='#get_pattern_groups'><p>Determine patients missingness group</p></a></li>
<li><a href='#get_pattern_groups_unique'><p>Get Pattern Summary</p></a></li>
<li><a href='#get_pool_components'><p>Expected Pool Components</p></a></li>
<li><a href='#get_visit_distribution_parameters'><p>Derive visit distribution parameters</p></a></li>
<li><a href='#getStrategies'><p>Get imputation strategies</p></a></li>
<li><a href='#has_class'><p>Does object have a class ?</p></a></li>
<li><a href='#ife'><p>if else</p></a></li>
<li><a href='#imputation_df'><p>Create a valid <code>imputation_df</code> object</p></a></li>
<li><a href='#imputation_list_df'><p>List of imputations_df</p></a></li>
<li><a href='#imputation_list_single'><p>A collection of <code>imputation_singles()</code> grouped by a single subjid ID</p></a></li>
<li><a href='#imputation_single'><p>Create a valid <code>imputation_single</code> object</p></a></li>
<li><a href='#impute'><p>Create imputed datasets</p></a></li>
<li><a href='#impute_data_individual'><p>Impute data for a single subject</p></a></li>
<li><a href='#impute_internal'><p>Create imputed datasets</p></a></li>
<li><a href='#impute_outcome'><p>Sample outcome value</p></a></li>
<li><a href='#invert'><p>invert</p></a></li>
<li><a href='#invert_indexes'><p>Invert and derive indexes</p></a></li>
<li><a href='#is_absent'><p>Is value absent</p></a></li>
<li><a href='#is_char_fact'><p>Is character or factor</p></a></li>
<li><a href='#is_char_one'><p>Is single character</p></a></li>
<li><a href='#is_in_rbmi_development'><p>Is package in development mode?</p></a></li>
<li><a href='#is_num_char_fact'><p>Is character, factor or numeric</p></a></li>
<li><a href='#locf'><p>Last Observation Carried Forward</p></a></li>
<li><a href='#longDataConstructor'><p>R6 Class for Storing / Accessing &amp; Sampling Longitudinal Data</p></a></li>
<li><a href='#ls_design'><p>Calculate design vector for the lsmeans</p></a></li>
<li><a href='#lsmeans'><p>Least Square Means</p></a></li>
<li><a href='#method'><p>Set the multiple imputation methodology</p></a></li>
<li><a href='#parametric_ci'><p>Calculate parametric confidence intervals</p></a></li>
<li><a href='#pool'><p>Pool analysis results obtained from the imputed datasets</p></a></li>
<li><a href='#pool_bootstrap_normal'><p>Bootstrap Pooling via normal approximation</p></a></li>
<li><a href='#pool_bootstrap_percentile'><p>Bootstrap Pooling via Percentiles</p></a></li>
<li><a href='#pool_internal'><p>Internal Pool Methods</p></a></li>
<li><a href='#prepare_stan_data'><p>Prepare input data to run the Stan model</p></a></li>
<li><a href='#print.analysis'><p>Print <code>analysis</code> object</p></a></li>
<li><a href='#print.draws'><p>Print <code>draws</code> object</p></a></li>
<li><a href='#print.imputation'><p>Print <code>imputation</code> object</p></a></li>
<li><a href='#progressLogger'><p>R6 Class for printing current sampling progress</p></a></li>
<li><a href='#pval_percentile'><p>P-value of percentile bootstrap</p></a></li>
<li><a href='#QR_decomp'><p>QR decomposition</p></a></li>
<li><a href='#random_effects_expr'><p>Construct random effects formula</p></a></li>
<li><a href='#record'><p>Capture all Output</p></a></li>
<li><a href='#recursive_reduce'><p>recursive_reduce</p></a></li>
<li><a href='#remove_if_all_missing'><p>Remove subjects from dataset if they have no observed values</p></a></li>
<li><a href='#rubin_df'><p>Barnard and Rubin degrees of freedom adjustment</p></a></li>
<li><a href='#rubin_rules'><p>Combine estimates using Rubin's rules</p></a></li>
<li><a href='#sample_ids'><p>Sample Patient Ids</p></a></li>
<li><a href='#sample_list'><p>Create and validate a <code>sample_list</code> object</p></a></li>
<li><a href='#sample_mvnorm'><p>Sample random values from the multivariate normal distribution</p></a></li>
<li><a href='#sample_single'><p>Create object of <code>sample_single</code> class</p></a></li>
<li><a href='#scalerConstructor'><p>R6 Class for scaling (and un-scaling) design matrices</p></a></li>
<li><a href='#set_simul_pars'><p>Set simulation parameters of a study group.</p></a></li>
<li><a href='#set_vars'><p>Set key variables</p></a></li>
<li><a href='#simulate_data'><p>Generate data</p></a></li>
<li><a href='#simulate_dropout'><p>Simulate drop-out</p></a></li>
<li><a href='#simulate_ice'><p>Simulate intercurrent event</p></a></li>
<li><a href='#simulate_test_data'><p>Create simulated datasets</p></a></li>
<li><a href='#sort_by'><p>Sort <code>data.frame</code></p></a></li>
<li><a href='#split_dim'><p>Transform array into list of arrays</p></a></li>
<li><a href='#split_imputations'><p>Split a flat list of <code>imputation_single()</code> into multiple <code>imputation_df()</code>'s by ID</p></a></li>
<li><a href='#Stack'><p>R6 Class for a FIFO stack</p></a></li>
<li><a href='#str_contains'><p>Does a string contain a substring</p></a></li>
<li><a href='#strategies'><p>Strategies</p></a></li>
<li><a href='#string_pad'><p>string_pad</p></a></li>
<li><a href='#transpose_imputations'><p>Transpose imputations</p></a></li>
<li><a href='#transpose_results'><p>Transpose results object</p></a></li>
<li><a href='#transpose_samples'><p>Transpose samples</p></a></li>
<li><a href='#validate'><p>Generic validation method</p></a></li>
<li><a href='#validate_analyse_pars'><p>Validate analysis results</p></a></li>
<li><a href='#validate_datalong'><p>Validate a longdata object</p></a></li>
<li><a href='#validate_strategies'><p>Validate user specified strategies</p></a></li>
<li><a href='#validate.analysis'><p>Validate <code>analysis</code> objects</p></a></li>
<li><a href='#validate.draws'><p>Validate <code>draws</code> object</p></a></li>
<li><a href='#validate.is_mar'><p>Validate <code>is_mar</code> for a given subject</p></a></li>
<li><a href='#validate.ivars'><p>Validate inputs for <code>vars</code></p></a></li>
<li><a href='#validate.references'><p>Validate user supplied references</p></a></li>
<li><a href='#validate.sample_list'><p>Validate <code>sample_list</code> object</p></a></li>
<li><a href='#validate.sample_single'><p>Validate <code>sample_single</code> object</p></a></li>
<li><a href='#validate.simul_pars'><p>Validate a <code>simul_pars</code> object</p></a></li>
<li><a href='#validate.stan_data'><p>Validate a <code>stan_data</code> object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Reference Based Multiple Imputation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements standard and reference based multiple imputation methods for continuous
    longitudinal endpoints (Gower-Page et al. (2022) &lt;<a href="https://doi.org/10.21105%2Fjoss.04251">doi:10.21105/joss.04251</a>&gt;). In particular,
    this package supports deterministic conditional mean imputation and jackknifing as described
    in Wolbers et al.  (2022) &lt;<a href="https://doi.org/10.1002%2Fpst.2234">doi:10.1002/pst.2234</a>&gt;, Bayesian multiple imputation as described
    in Carpenter et al. (2013) &lt;<a href="https://doi.org/10.1080%2F10543406.2013.834911">doi:10.1080/10543406.2013.834911</a>&gt;, and bootstrapped maximum
    likelihood imputation as described in von Hippel and Bartlett (2021) &lt;<a href="https://doi.org/10.1214%2F20-STS793">doi:10.1214/20-STS793</a>&gt;.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://insightsengineering.github.io/rbmi/">https://insightsengineering.github.io/rbmi/</a>,
<a href="https://github.com/insightsengineering/rbmi">https://github.com/insightsengineering/rbmi</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/insightsengineering/rbmi/issues">https://github.com/insightsengineering/rbmi/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>dplyr, tidyr, nlme, testthat, emmeans, tibble, mvtnorm,
knitr, rmarkdown, bookdown, lubridate, purrr, ggplot2, R.rsp</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>mmrm, pkgload, Matrix, methods, Rcpp (&ge; 0.12.0), RcppParallel
(&ge; 5.0.1), rstan (&ge; 2.26.0), rstantools (&ge; 2.1.1), R6,
assertthat</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>BH (&ge; 1.66.0), Rcpp (&ge; 0.12.0), RcppEigen (&ge; 0.3.3.3.0),
RcppParallel (&ge; 5.0.1), rstan (&ge; 2.26.0), StanHeaders (&ge;
2.26.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License (&ge; 2)</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-24 13:29:25 UTC; gowerc</td>
</tr>
<tr>
<td>Author:</td>
<td>Craig Gower-Page [aut, cre],
  Alessandro Noci [aut],
  Marcel Wolbers [ctb],
  Roche [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Craig Gower-Page &lt;craig.gower-page@roche.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-24 14:00:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='rbmi-package'>rbmi: Reference Based Multiple Imputation</h2><span id='topic+rbmi'></span><span id='topic+rbmi-package'></span>

<h3>Description</h3>

<p>The rbmi package is used to perform reference based multiple imputation. The package
provides implementations for common, patient-specific imputation strategies whilst allowing the user to
select between various standard Bayesian and frequentist approaches.
</p>
<p>The package is designed around 4 core functions:
</p>

<ul>
<li> <p><code><a href="#topic+draws">draws()</a></code> - Fits multiple imputation models
</p>
</li>
<li> <p><code><a href="#topic+impute">impute()</a></code> - Imputes multiple datasets
</p>
</li>
<li> <p><code><a href="#topic+analyse">analyse()</a></code> - Analyses multiple datasets
</p>
</li>
<li> <p><code><a href="#topic+pool">pool()</a></code> - Pools multiple results into a single statistic
</p>
</li></ul>

<p>To learn more about rbmi, please see the quickstart vignette:
</p>
<p><code>vignette(topic= "quickstart", package = "rbmi")</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Craig Gower-Page <a href="mailto:craig.gower-page@roche.com">craig.gower-page@roche.com</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Alessandro Noci <a href="mailto:alessandro.noci@roche.com">alessandro.noci@roche.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Marcel Wolbers <a href="mailto:marcel.wolbers@roche.com">marcel.wolbers@roche.com</a> [contributor]
</p>
</li>
<li><p> Roche [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://insightsengineering.github.io/rbmi/">https://insightsengineering.github.io/rbmi/</a>
</p>
</li>
<li> <p><a href="https://github.com/insightsengineering/rbmi">https://github.com/insightsengineering/rbmi</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/insightsengineering/rbmi/issues">https://github.com/insightsengineering/rbmi/issues</a>
</p>
</li></ul>


<hr>
<h2 id='add_class'>Add a class</h2><span id='topic+add_class'></span>

<h3>Description</h3>

<p>Utility function to add a class to an object. Adds the new class
after any existing classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_class(x, cls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_class_+3A_x">x</code></td>
<td>
<p>object to add a class to.</p>
</td></tr>
<tr><td><code id="add_class_+3A_cls">cls</code></td>
<td>
<p>the class to be added.</p>
</td></tr>
</table>

<hr>
<h2 id='adjust_trajectories'>Adjust trajectories due to the intercurrent event (ICE)</h2><span id='topic+adjust_trajectories'></span>

<h3>Description</h3>

<p>Adjust trajectories due to the intercurrent event (ICE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_trajectories(
  distr_pars_group,
  outcome,
  ids,
  ind_ice,
  strategy_fun,
  distr_pars_ref = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust_trajectories_+3A_distr_pars_group">distr_pars_group</code></td>
<td>
<p>Named list containing the simulation parameters of the multivariate
normal distribution assumed for the given treatment group. It contains the following elements:
</p>

<ul>
<li> <p><code>mu</code>: Numeric vector indicating the mean outcome trajectory. It should include the outcome
at baseline.
</p>
</li>
<li> <p><code>sigma</code> Covariance matrix of the outcome trajectory.
</p>
</li></ul>
</td></tr>
<tr><td><code id="adjust_trajectories_+3A_outcome">outcome</code></td>
<td>
<p>Numeric variable that specifies the longitudinal outcome.</p>
</td></tr>
<tr><td><code id="adjust_trajectories_+3A_ids">ids</code></td>
<td>
<p>Factor variable that specifies the id of each subject.</p>
</td></tr>
<tr><td><code id="adjust_trajectories_+3A_ind_ice">ind_ice</code></td>
<td>
<p>A binary variable that takes value <code>1</code> if the corresponding outcome is affected
by the ICE and <code>0</code> otherwise.</p>
</td></tr>
<tr><td><code id="adjust_trajectories_+3A_strategy_fun">strategy_fun</code></td>
<td>
<p>Function implementing trajectories after the intercurrent event (ICE). Must
be one of <code><a href="#topic+getStrategies">getStrategies()</a></code>. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for details.</p>
</td></tr>
<tr><td><code id="adjust_trajectories_+3A_distr_pars_ref">distr_pars_ref</code></td>
<td>
<p>Optional. Named list containing the simulation parameters of the
reference arm. It contains the following elements:
</p>

<ul>
<li> <p><code>mu</code>: Numeric vector indicating the mean outcome trajectory assuming no ICEs. It should
include the outcome at baseline.
</p>
</li>
<li> <p><code>sigma</code> Covariance matrix of the outcome trajectory assuming no ICEs.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector containing the adjusted trajectories.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjust_trajectories_single">adjust_trajectories_single()</a></code>.
</p>

<hr>
<h2 id='adjust_trajectories_single'>Adjust trajectory of a subject's outcome due to the intercurrent event (ICE)</h2><span id='topic+adjust_trajectories_single'></span>

<h3>Description</h3>

<p>Adjust trajectory of a subject's outcome due to the intercurrent event (ICE)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjust_trajectories_single(
  distr_pars_group,
  outcome,
  strategy_fun,
  distr_pars_ref = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjust_trajectories_single_+3A_distr_pars_group">distr_pars_group</code></td>
<td>
<p>Named list containing the simulation parameters of the multivariate
normal distribution assumed for the given treatment group. It contains the following elements:
</p>

<ul>
<li> <p><code>mu</code>: Numeric vector indicating the mean outcome trajectory. It should include the
outcome at baseline.
</p>
</li>
<li> <p><code>sigma</code> Covariance matrix of the outcome trajectory.
</p>
</li></ul>
</td></tr>
<tr><td><code id="adjust_trajectories_single_+3A_outcome">outcome</code></td>
<td>
<p>Numeric variable that specifies the longitudinal outcome.</p>
</td></tr>
<tr><td><code id="adjust_trajectories_single_+3A_strategy_fun">strategy_fun</code></td>
<td>
<p>Function implementing trajectories after the intercurrent event (ICE).
Must be one of <code><a href="#topic+getStrategies">getStrategies()</a></code>. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for details.</p>
</td></tr>
<tr><td><code id="adjust_trajectories_single_+3A_distr_pars_ref">distr_pars_ref</code></td>
<td>
<p>Optional. Named list containing the simulation parameters of the
reference arm. It contains the following elements:
</p>

<ul>
<li> <p><code>mu</code>: Numeric vector indicating the mean outcome trajectory assuming no ICEs. It should
include the outcome at baseline.
</p>
</li>
<li> <p><code>sigma</code> Covariance matrix of the outcome trajectory assuming no ICEs.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p><code>outcome</code> should be specified such that all-and-only the post-ICE observations
(i.e. the
observations to be adjusted) are set to <code>NA</code>.
</p>


<h3>Value</h3>

<p>A numeric vector containing the adjusted trajectory for a single subject.
</p>

<hr>
<h2 id='analyse'>Analyse Multiple Imputed Datasets</h2><span id='topic+analyse'></span>

<h3>Description</h3>

<p>This function takes multiple imputed datasets (as generated by
the <code><a href="#topic+impute">impute()</a></code> function) and runs an analysis function on
each of them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyse(imputations, fun = ancova, delta = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyse_+3A_imputations">imputations</code></td>
<td>
<p>An <code>imputations</code> object as created by <code><a href="#topic+impute">impute()</a></code>.</p>
</td></tr>
<tr><td><code id="analyse_+3A_fun">fun</code></td>
<td>
<p>An analysis function to be applied to each imputed dataset. See details.</p>
</td></tr>
<tr><td><code id="analyse_+3A_delta">delta</code></td>
<td>
<p>A <code>data.frame</code> containing the delta transformation to be applied to the imputed
datasets prior to running <code>fun</code>. See details.</p>
</td></tr>
<tr><td><code id="analyse_+3A_...">...</code></td>
<td>
<p>Additional arguments passed onto <code>fun</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function works by performing the following steps:
</p>

<ol>
<li><p> Extract a dataset from the <code>imputations</code> object.
</p>
</li>
<li><p> Apply any delta adjustments as specified by the <code>delta</code> argument.
</p>
</li>
<li><p> Run the analysis function <code>fun</code> on the dataset.
</p>
</li>
<li><p> Repeat steps 1-3 across all of the datasets inside the <code>imputations</code>
object.
</p>
</li>
<li><p> Collect and return all of the analysis results.
</p>
</li></ol>

<p>The analysis function <code>fun</code> must take a <code>data.frame</code> as its first
argument. All other options to <code><a href="#topic+analyse">analyse()</a></code> are passed onto <code>fun</code>
via <code>...</code>.
<code>fun</code> must return a named list with each element itself being a
list containing a single
numeric element called <code>est</code> (or additionally <code>se</code> and <code>df</code> if
you had originally specified <code><a href="#topic+method_bayes">method_bayes()</a></code> or <code><a href="#topic+method_approxbayes">method_approxbayes()</a></code>)
i.e.:
</p>
<div class="sourceCode"><pre>myfun &lt;- function(dat, ...) {
    mod_1 &lt;- lm(data = dat, outcome ~ group)
    mod_2 &lt;- lm(data = dat, outcome ~ group + covar)
    x &lt;- list(
        trt_1 = list(
            est = coef(mod_1)[[group]],
            se = sqrt(vcov(mod_1)[group, group]),
            df = df.residual(mod_1)
        ),
        trt_2 = list(
            est = coef(mod_2)[[group]],
            se = sqrt(vcov(mod_2)[group, group]),
            df = df.residual(mod_2)
        )
     )
     return(x)
 }
</pre></div>
<p>Please note that the <code>vars$subjid</code> column (as defined in the original call to
<code><a href="#topic+draws">draws()</a></code>) will be scrambled in the data.frames that are provided to <code>fun</code>.
This is to say they will not contain the original subject values and as such
any hard coding of subject ids is strictly to be avoided.
</p>
<p>By default <code>fun</code> is the <code><a href="#topic+ancova">ancova()</a></code> function.
Please note that this function
requires that a <code>vars</code> object, as created by <code><a href="#topic+set_vars">set_vars()</a></code>, is provided via
the <code>vars</code> argument e.g. <code>analyse(imputeObj, vars = set_vars(...))</code>. Please
see the documentation for <code><a href="#topic+ancova">ancova()</a></code> for full details.
Please also note that the theoretical justification for the conditional mean imputation
method (<code>method = method_condmean()</code> in <code><a href="#topic+draws">draws()</a></code>) relies on the fact that ANCOVA is
a linear transformation of the outcomes.
Thus care is required when applying alternative analysis functions in this setting.
</p>
<p>The <code>delta</code> argument can be used to specify offsets to be applied
to the outcome variable in the imputed datasets prior to the analysis.
This is typically used for sensitivity or tipping point analyses. The
delta dataset must contain columns <code>vars$subjid</code>, <code>vars$visit</code> (as specified
in the original call to <code><a href="#topic+draws">draws()</a></code>) and <code>delta</code>. Essentially this <code>data.frame</code>
is merged onto the imputed dataset by <code>vars$subjid</code> and <code>vars$visit</code> and then
the outcome variable is modified by:
</p>
<div class="sourceCode"><pre>imputed_data[[vars$outcome]] &lt;- imputed_data[[vars$outcome]] + imputed_data[["delta"]]
</pre></div>
<p>Please note that in order to provide maximum flexibility, the <code>delta</code> argument
can be used to modify any/all outcome values including those that were not
imputed. Care must be taken when defining offsets. It is recommend that you
use the helper function <code><a href="#topic+delta_template">delta_template()</a></code> to define the delta datasets as
this provides utility variables such as <code>is_missing</code> which can be used to identify
exactly which visits have been imputed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract_imputed_dfs">extract_imputed_dfs()</a></code> for manually extracting imputed
datasets.
</p>
<p><code><a href="#topic+delta_template">delta_template()</a></code> for creating delta data.frames.
</p>
<p><code><a href="#topic+ancova">ancova()</a></code> for the default analysis function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
vars &lt;- set_vars(
    subjid = "subjid",
    visit = "visit",
    outcome = "outcome",
    group = "group",
    covariates = c("sex", "age", "sex*age")
)

analyse(
    imputations = imputeObj,
    vars = vars
)

deltadf &lt;- data.frame(
    subjid = c("Pt1", "Pt1", "Pt2"),
    visit = c("Visit_1", "Visit_2", "Visit_2"),
    delta = c( 5, 9, -10)
)

analyse(
    imputations = imputeObj,
    delta = deltadf,
    vars = vars
)

## End(Not run)
</code></pre>

<hr>
<h2 id='ancova'>Analysis of Covariance</h2><span id='topic+ancova'></span>

<h3>Description</h3>

<p>Performs an analysis of covariance between two groups returning the estimated
&quot;treatment effect&quot; (i.e. the contrast between the two treatment groups) and
the least square means estimates in each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ancova(data, vars, visits = NULL, weights = c("proportional", "equal"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ancova_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing the data to be used in the model.</p>
</td></tr>
<tr><td><code id="ancova_+3A_vars">vars</code></td>
<td>
<p>A <code>vars</code> object as generated by <code><a href="#topic+set_vars">set_vars()</a></code>. Only the <code>group</code>,
<code>visit</code>, <code>outcome</code> and <code>covariates</code> elements are required. See details.</p>
</td></tr>
<tr><td><code id="ancova_+3A_visits">visits</code></td>
<td>
<p>An optional character vector specifying which visits to
fit the ancova model at. If <code>NULL</code>, a separate ancova model will be fit to the
outcomes for each visit (as determined by <code>unique(data[[vars$visit]])</code>).
See details.</p>
</td></tr>
<tr><td><code id="ancova_+3A_weights">weights</code></td>
<td>
<p>Character, either <code>"proportional"</code> (default) or <code>"equal"</code>. Specifies the
weighting strategy to be used for categorical covariates when calculating the lsmeans.
See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works as follows:
</p>

<ol>
<li><p> Select the first value from <code>visits</code>.
</p>
</li>
<li><p> Subset the data to only the observations that occurred on this visit.
</p>
</li>
<li><p> Fit a linear model as  <code>vars$outcome ~ vars$group + vars$covariates</code>.
</p>
</li>
<li><p> Extract the &quot;treatment effect&quot; &amp; least square means for each treatment group.
</p>
</li>
<li><p> Repeat points 2-3 for all other values in <code>visits</code>.
</p>
</li></ol>

<p>If no value for <code>visits</code> is provided then it will be set to
<code>unique(data[[vars$visit]])</code>.
</p>
<p>In order to meet the formatting standards set by <code><a href="#topic+analyse">analyse()</a></code> the results will be collapsed
into a single list suffixed by the visit name, e.g.:
</p>
<div class="sourceCode"><pre>list(
   trt_visit_1 = list(est = ...),
   lsm_ref_visit_1 = list(est = ...),
   lsm_alt_visit_1 = list(est = ...),
   trt_visit_2 = list(est = ...),
   lsm_ref_visit_2 = list(est = ...),
   lsm_alt_visit_2 = list(est = ...),
   ...
)
</pre></div>
<p>Please note that &quot;ref&quot; refers to the first factor level of <code>vars$group</code> which does not necessarily
coincide with the control arm. Analogously, &quot;alt&quot; refers to the second factor level of <code>vars$group</code>.
&quot;trt&quot; refers to the model contrast translating the mean difference between the second level and first level.
</p>
<p>If you want to include interaction terms in your model this can be done
by providing them to the <code>covariates</code> argument of <code><a href="#topic+set_vars">set_vars()</a></code>
e.g. <code>set_vars(covariates = c("sex*age"))</code>.
</p>


<h4>Weighting</h4>

<p><code>"proportional"</code> is the default scheme that is used. This is equivalent to standardization,
i.e. the lsmeans in
each group are equal to the predicted mean outcome from the ancova model for
that group based on baseline characteristics of all subjects regardless of
their assigned group. The alternative weighting scheme, <code>"equal"</code>, creates hypothetical
patients by expanding out all combinations of the models categorical covariates. The
lsmeans are then calculated as the average of
the predicted mean outcome for these hypothetical patients assuming they come from each
group in turn.
</p>
<p>In short:
</p>

<ul>
<li> <p><code>"proportional"</code> weights categorical covariates based upon their frequency of occurrence
in the data.
</p>
</li>
<li> <p><code>"equal"</code> weights categorical covariates equally across all theoretical combinations.
</p>
</li></ul>




<h3>See Also</h3>

<p><code><a href="#topic+analyse">analyse()</a></code>
</p>
<p><code><a href="stats.html#topic+lm">stats::lm()</a></code>
</p>
<p><code><a href="#topic+set_vars">set_vars()</a></code>
</p>

<hr>
<h2 id='ancova_single'>Implements an Analysis of Covariance (ANCOVA)</h2><span id='topic+ancova_single'></span>

<h3>Description</h3>

<p>Performance analysis of covariance. See <code><a href="#topic+ancova">ancova()</a></code> for full details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ancova_single(
  data,
  outcome,
  group,
  covariates,
  weights = c("proportional", "equal")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ancova_single_+3A_data">data</code></td>
<td>
<p>The <code>data.frame</code> containing all of the data required for the model.</p>
</td></tr>
<tr><td><code id="ancova_single_+3A_outcome">outcome</code></td>
<td>
<p>Character, the name of the outcome variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="ancova_single_+3A_group">group</code></td>
<td>
<p>Character, the name of the group variable in <code>data</code>.</p>
</td></tr>
<tr><td><code id="ancova_single_+3A_covariates">covariates</code></td>
<td>
<p>Character vector containing the name of any additional covariates
to be included in the model as well as any interaction terms.</p>
</td></tr>
<tr><td><code id="ancova_single_+3A_weights">weights</code></td>
<td>
<p>Character, specifies whether to use &quot;proportional&quot; or &quot;equal&quot; weighting for each
categorical covariate combination when calculating the lsmeans.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code>group</code> must be a factor variable with only 2 levels.
</p>
</li>
<li> <p><code>outcome</code> must be a continuous numeric variable.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ancova">ancova()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
iris2 &lt;- iris[ iris$Species %in% c("versicolor", "virginica"), ]
iris2$Species &lt;- factor(iris2$Species)
ancova_single(iris2, "Sepal.Length", "Species", c("Petal.Length * Petal.Width"))

## End(Not run)
</code></pre>

<hr>
<h2 id='antidepressant_data'>Antidepressant trial data</h2><span id='topic+antidepressant_data'></span>

<h3>Description</h3>

<p>A dataset containing data from a publicly available example data set from an antidepressant
clinical trial.
The dataset is available on the website of the
<a href="https://www.lshtm.ac.uk/research/centres-projects-groups/missing-data#dia-missing-data">Drug Information Association Scientific Working Group on Estimands and Missing Data</a>.
As per that website, the original data are from an antidepressant clinical trial with four
treatments; two doses of an experimental medication,
a positive control, and placebo and was published in Goldstein et al (2004). To mask the real
data, week 8 observations were removed and two arms were created:
the original placebo arm and a &quot;drug arm&quot; created by randomly selecting patients from the
three non-placebo arms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>antidepressant_data
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 608 rows and 11 variables:
</p>

<ul>
<li> <p><code>PATIENT</code>: patients IDs.
</p>
</li>
<li> <p><code>HAMATOTL</code>: total score Hamilton Anxiety Rating Scale.
</p>
</li>
<li> <p><code>PGIIMP</code>: patient's Global Impression of Improvement Rating Scale.
</p>
</li>
<li> <p><code>RELDAYS</code>: number of days between visit and baseline.
</p>
</li>
<li> <p><code>VISIT</code>: post-baseline visit. Has levels 4,5,6,7.
</p>
</li>
<li> <p><code>THERAPY</code>: the treatment group variable. It is equal to <code>PLACEBO</code> for observations from
the placebo arm, or <code>DRUG</code> for observations from the active arm.
</p>
</li>
<li> <p><code>GENDER</code>: patient's gender.
</p>
</li>
<li> <p><code>POOLINV</code>: pooled investigator.
</p>
</li>
<li> <p><code>BASVAL</code>: baseline outcome value.
</p>
</li>
<li> <p><code>HAMDTL17</code>: Hamilton 17-item rating scale value.
</p>
</li>
<li> <p><code>CHANGE</code>: change from baseline in the Hamilton 17-item rating scale.
</p>
</li></ul>



<h3>Details</h3>

<p>The relevant endpoint is the Hamilton 17-item rating scale for depression (HAMD17) for
which baseline and weeks 1, 2, 4, and 6 assessments are included.
Study drug discontinuation occurred in 24% subjects from the active drug and 26% from
placebo.
All data after study drug discontinuation are missing and there is a single additional
intermittent missing observation.
</p>


<h3>References</h3>

<p>Goldstein, Lu, Detke, Wiltse, Mallinckrodt, Demitrack. Duloxetine in the treatment of
depression: a double-blind placebo-controlled comparison with paroxetine.
J Clin Psychopharmacol 2004;24: 389-399.
</p>

<hr>
<h2 id='apply_delta'>Applies delta adjustment</h2><span id='topic+apply_delta'></span>

<h3>Description</h3>

<p>Takes a delta dataset and adjusts the outcome variable by adding the
corresponding delta.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>apply_delta(data, delta = NULL, group = NULL, outcome = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="apply_delta_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> which will have its <code>outcome</code> column adjusted.</p>
</td></tr>
<tr><td><code id="apply_delta_+3A_delta">delta</code></td>
<td>
<p><code>data.frame</code> (must contain a column called <code>delta</code>).</p>
</td></tr>
<tr><td><code id="apply_delta_+3A_group">group</code></td>
<td>
<p>character vector of variables in both <code>data</code> and <code>delta</code> that will be used
to merge the 2 data.frames together by.</p>
</td></tr>
<tr><td><code id="apply_delta_+3A_outcome">outcome</code></td>
<td>
<p>character, name of the outcome variable in <code>data</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='as_analysis'>Construct an <code>analysis</code> object</h2><span id='topic+as_analysis'></span>

<h3>Description</h3>

<p>Creates an analysis object ensuring that all components are
correctly defined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_analysis(results, method, delta = NULL, fun = NULL, fun_name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_analysis_+3A_results">results</code></td>
<td>
<p>A list of lists contain the analysis results for each imputation
See <code><a href="#topic+analyse">analyse()</a></code> for details on what this object should look like.</p>
</td></tr>
<tr><td><code id="as_analysis_+3A_method">method</code></td>
<td>
<p>The method object as specified in <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
<tr><td><code id="as_analysis_+3A_delta">delta</code></td>
<td>
<p>The delta dataset used. See <code><a href="#topic+analyse">analyse()</a></code> for details on how this
should be specified.</p>
</td></tr>
<tr><td><code id="as_analysis_+3A_fun">fun</code></td>
<td>
<p>The analysis function that was used.</p>
</td></tr>
<tr><td><code id="as_analysis_+3A_fun_name">fun_name</code></td>
<td>
<p>The character name of the analysis function (used for printing)
purposes.</p>
</td></tr>
</table>

<hr>
<h2 id='as_ascii_table'>as_ascii_table</h2><span id='topic+as_ascii_table'></span>

<h3>Description</h3>

<p>This function takes a data.frame and attempts to convert it into
a simple ascii format suitable for printing to the screen
It is assumed all variable values have a as.character() method
in order to cast them to character.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_ascii_table(dat, line_prefix = "  ", pcol = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_ascii_table_+3A_dat">dat</code></td>
<td>
<p>Input dataset to convert into a ascii table</p>
</td></tr>
<tr><td><code id="as_ascii_table_+3A_line_prefix">line_prefix</code></td>
<td>
<p>Symbols to prefix infront of every line of the table</p>
</td></tr>
<tr><td><code id="as_ascii_table_+3A_pcol">pcol</code></td>
<td>
<p>name of column to be handled as a p-value. Sets the value to &lt;0.001 if the value is 0 after rounding</p>
</td></tr>
</table>

<hr>
<h2 id='as_class'>Set Class</h2><span id='topic+as_class'></span>

<h3>Description</h3>

<p>Utility function to set an objects class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_class(x, cls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_class_+3A_x">x</code></td>
<td>
<p>object to set the class of.</p>
</td></tr>
<tr><td><code id="as_class_+3A_cls">cls</code></td>
<td>
<p>the class to be set.</p>
</td></tr>
</table>

<hr>
<h2 id='as_cropped_char'>as_cropped_char</h2><span id='topic+as_cropped_char'></span>

<h3>Description</h3>

<p>Makes any character string above x chars
Reduce down to a x char string with ...
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_cropped_char(inval, crop_at = 30, ndp = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_cropped_char_+3A_inval">inval</code></td>
<td>
<p>a single element value</p>
</td></tr>
<tr><td><code id="as_cropped_char_+3A_crop_at">crop_at</code></td>
<td>
<p>character limit</p>
</td></tr>
<tr><td><code id="as_cropped_char_+3A_ndp">ndp</code></td>
<td>
<p>Number of decimal places to display</p>
</td></tr>
</table>

<hr>
<h2 id='as_dataframe'>Convert object to dataframe</h2><span id='topic+as_dataframe'></span>

<h3>Description</h3>

<p>Convert object to dataframe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_dataframe(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_dataframe_+3A_x">x</code></td>
<td>
<p>a data.frame like object
</p>
<p>Utility function to convert a &quot;data.frame-like&quot; object to an actual <code>data.frame</code>
to avoid issues with inconsistency on methods (such as  <code>[</code>() and dplyr's grouped dataframes)</p>
</td></tr>
</table>

<hr>
<h2 id='as_draws'>Creates a <code>draws</code> object</h2><span id='topic+as_draws'></span>

<h3>Description</h3>

<p>Creates a <code>draws</code> object which is the final output of a call to <code><a href="#topic+draws">draws()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_draws(method, samples, data, formula, n_failures = NULL, fit = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_draws_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object as generated by either <code><a href="#topic+method_bayes">method_bayes()</a></code>,
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code>, <code><a href="#topic+method_condmean">method_condmean()</a></code> or <code><a href="#topic+method_bmlmi">method_bmlmi()</a></code>.</p>
</td></tr>
<tr><td><code id="as_draws_+3A_samples">samples</code></td>
<td>
<p>A list of <code>sample_single</code> objects. See <code><a href="#topic+sample_single">sample_single()</a></code>.</p>
</td></tr>
<tr><td><code id="as_draws_+3A_data">data</code></td>
<td>
<p>R6 <code>longdata</code> object containing all relevant input data information.</p>
</td></tr>
<tr><td><code id="as_draws_+3A_formula">formula</code></td>
<td>
<p>Fixed effects formula object used for the model specification.</p>
</td></tr>
<tr><td><code id="as_draws_+3A_n_failures">n_failures</code></td>
<td>
<p>Absolute number of failures of the model fit.</p>
</td></tr>
<tr><td><code id="as_draws_+3A_fit">fit</code></td>
<td>
<p>If <code>method_bayes()</code> is chosen, returns the MCMC Stan fit object. Otherwise <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>draws</code> object which is a named list containing the following:
</p>

<ul>
<li> <p><code>data</code>: R6 <code>longdata</code> object containing all relevant input data information.
</p>
</li>
<li> <p><code>method</code>: A <code>method</code> object as generated by either <code><a href="#topic+method_bayes">method_bayes()</a></code>,
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code> or <code><a href="#topic+method_condmean">method_condmean()</a></code>.
</p>
</li>
<li> <p><code>samples</code>: list containing the estimated parameters of interest.
Each element of <code>samples</code> is a named list containing the following:
</p>

<ul>
<li> <p><code>ids</code>: vector of characters containing the ids of the subjects included in the original dataset.
</p>
</li>
<li> <p><code>beta</code>: numeric vector of estimated regression coefficients.
</p>
</li>
<li> <p><code>sigma</code>: list of estimated covariance matrices (one for each level of <code>vars$group</code>).
</p>
</li>
<li> <p><code>theta</code>: numeric vector of transformed covariances.
</p>
</li>
<li> <p><code>failed</code>: Logical. <code>TRUE</code> if the model fit failed.
</p>
</li>
<li> <p><code>ids_samp</code>: vector of characters containing the ids of the subjects included in the given sample.
</p>
</li></ul>

</li>
<li> <p><code>fit</code>: if <code>method_bayes()</code> is chosen, returns the MCMC Stan fit object. Otherwise <code>NULL</code>.
</p>
</li>
<li> <p><code>n_failures</code>: absolute number of failures of the model fit.
Relevant only for <code>method_condmean(type = "bootstrap")</code>, <code>method_approxbayes()</code> and <code>method_bmlmi()</code>.
</p>
</li>
<li> <p><code>formula</code>: fixed effects formula object used for the model specification.
</p>
</li></ul>


<hr>
<h2 id='as_imputation'>Create an imputation object</h2><span id='topic+as_imputation'></span>

<h3>Description</h3>

<p>This function creates the object that is returned from <code><a href="#topic+impute">impute()</a></code>. Essentially
it is a glorified wrapper around <code><a href="base.html#topic+list">list()</a></code> ensuring that the required elements have been
set and that the class is added as expected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_imputation(imputations, data, method, references)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_imputation_+3A_imputations">imputations</code></td>
<td>
<p>A list of <code>imputations_list</code>'s as created by <code><a href="#topic+imputation_df">imputation_df()</a></code></p>
</td></tr>
<tr><td><code id="as_imputation_+3A_data">data</code></td>
<td>
<p>A <code>longdata</code> object as created by <code><a href="#topic+longDataConstructor">longDataConstructor()</a></code></p>
</td></tr>
<tr><td><code id="as_imputation_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object as created by <code><a href="#topic+method_condmean">method_condmean()</a></code>, <code><a href="#topic+method_bayes">method_bayes()</a></code> or
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code></p>
</td></tr>
<tr><td><code id="as_imputation_+3A_references">references</code></td>
<td>
<p>A named vector. Identifies the references to be used when generating the
imputed values. Should be of the form <code>c("Group" = "Reference", "Group" = "Reference")</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='as_indices'>Convert indicator to index</h2><span id='topic+as_indices'></span>

<h3>Description</h3>

<p>Converts a string of 0's and 1's into index positions of the 1's
padding the results by 0's so they are all the same length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_indices(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_indices_+3A_x">x</code></td>
<td>
<p>a character vector whose values are all either &quot;0&quot; or &quot;1&quot;. All elements of
the vector must be the same length</p>
</td></tr>
</table>


<h3>Details</h3>

<p>i.e.
</p>
<div class="sourceCode"><pre>patmap(c("1101", "0001"))  -&gt;   list(c(1,2,4,999), c(4,999, 999, 999))
</pre></div>

<hr>
<h2 id='as_mmrm_df'>Creates a &quot;MMRM&quot; ready dataset</h2><span id='topic+as_mmrm_df'></span>

<h3>Description</h3>

<p>Converts a design matrix + key variables into a common format
In particular this function does the following:
</p>

<ul>
<li><p> Renames all covariates as <code>V1</code>, <code>V2</code>, etc to avoid issues of special characters in variable names
</p>
</li>
<li><p> Ensures all key variables are of the right type
</p>
</li>
<li><p> Inserts the outcome, visit and subjid variables into the <code>data.frame</code>
naming them as <code>outcome</code>, <code>visit</code> and <code>subjid</code>
</p>
</li>
<li><p> If provided will also insert the group variable into the <code>data.frame</code> named as <code>group</code>
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>as_mmrm_df(designmat, outcome, visit, subjid, group = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_mmrm_df_+3A_designmat">designmat</code></td>
<td>
<p>a <code>data.frame</code> or <code>matrix</code> containing the covariates to use in the MMRM model.
Dummy variables must already be expanded out, i.e. via <code><a href="stats.html#topic+model.matrix">stats::model.matrix()</a></code>. Cannot contain
any missing values</p>
</td></tr>
<tr><td><code id="as_mmrm_df_+3A_outcome">outcome</code></td>
<td>
<p>a numeric vector. The outcome value to be regressed on in the MMRM model.</p>
</td></tr>
<tr><td><code id="as_mmrm_df_+3A_visit">visit</code></td>
<td>
<p>a character / factor vector. Indicates which visit the outcome value occurred on.</p>
</td></tr>
<tr><td><code id="as_mmrm_df_+3A_subjid">subjid</code></td>
<td>
<p>a character / factor vector. The subject identifier used to link separate visits
that belong to the same subject.</p>
</td></tr>
<tr><td><code id="as_mmrm_df_+3A_group">group</code></td>
<td>
<p>a character / factor vector. Indicates which treatment group the patient belongs to.</p>
</td></tr>
</table>

<hr>
<h2 id='as_mmrm_formula'>Create MMRM formula</h2><span id='topic+as_mmrm_formula'></span>

<h3>Description</h3>

<p>Derives the MMRM model formula from the structure of mmrm_df.
returns a formula object of the form:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_mmrm_formula(mmrm_df, cov_struct)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_mmrm_formula_+3A_mmrm_df">mmrm_df</code></td>
<td>
<p>an mmrm <code>data.frame</code> as created by <code><a href="#topic+as_mmrm_df">as_mmrm_df()</a></code></p>
</td></tr>
<tr><td><code id="as_mmrm_formula_+3A_cov_struct">cov_struct</code></td>
<td>
<p>Character - The covariance structure to be used, must be one of <code>"us"</code>,
<code>"toep"</code>, <code>"cs"</code>, <code>"ar1"</code></p>
</td></tr>
</table>


<h3>Details</h3>

<div class="sourceCode"><pre>outcome ~ 0 + V1 + V2 + V4 + ... + us(visit | group / subjid)
</pre></div>

<hr>
<h2 id='as_model_df'>Expand <code>data.frame</code> into a design matrix</h2><span id='topic+as_model_df'></span>

<h3>Description</h3>

<p>Expands out a <code>data.frame</code> using a formula to create a design matrix.
Key details are that it will always place the outcome variable into
the first column of the return object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_model_df(dat, frm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_model_df_+3A_dat">dat</code></td>
<td>
<p>a data.frame</p>
</td></tr>
<tr><td><code id="as_model_df_+3A_frm">frm</code></td>
<td>
<p>a formula</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The outcome column may contain NA's but none of the other variables
listed in the formula should contain missing values
</p>

<hr>
<h2 id='as_simple_formula'>Creates a simple formula object from a string</h2><span id='topic+as_simple_formula'></span>

<h3>Description</h3>

<p>Converts a string list of variables into a formula object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_simple_formula(outcome, covars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_simple_formula_+3A_outcome">outcome</code></td>
<td>
<p>character (length 1 vector). Name of the outcome variable</p>
</td></tr>
<tr><td><code id="as_simple_formula_+3A_covars">covars</code></td>
<td>
<p>character (vector). Name of covariates</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A formula
</p>

<hr>
<h2 id='as_stan_array'>As array</h2><span id='topic+as_stan_array'></span>

<h3>Description</h3>

<p>Converts a numeric value of length 1 into a 1 dimension array.
This is to avoid type errors that are thrown by stan when length 1 numeric vectors
are provided by R for stan::vector inputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_stan_array(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_stan_array_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
</table>

<hr>
<h2 id='as_strata'>Create vector of Stratas</h2><span id='topic+as_strata'></span>

<h3>Description</h3>

<p>Collapse multiple categorical variables into distinct unique categories.
e.g.
</p>
<div class="sourceCode"><pre>as_strata(c(1,1,2,2,2,1), c(5,6,5,5,6,5))
</pre></div>
<p>would return
</p>
<div class="sourceCode"><pre>c(1,2,3,3,4,1)
</pre></div>


<h3>Usage</h3>

<pre><code class='language-R'>as_strata(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_strata_+3A_...">...</code></td>
<td>
<p>numeric/character/factor vectors of the same length</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
as_strata(c(1,1,2,2,2,1), c(5,6,5,5,6,5))

## End(Not run)
</code></pre>

<hr>
<h2 id='assert_variables_exist'>Assert that all variables exist within a dataset</h2><span id='topic+assert_variables_exist'></span>

<h3>Description</h3>

<p>Performs an assertion check to ensure that a vector of variable exists within a data.frame as expected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_variables_exist(data, vars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assert_variables_exist_+3A_data">data</code></td>
<td>
<p>a data.frame</p>
</td></tr>
<tr><td><code id="assert_variables_exist_+3A_vars">vars</code></td>
<td>
<p>a character vector of variable names</p>
</td></tr>
</table>

<hr>
<h2 id='char2fct'>Convert character variables to factor</h2><span id='topic+char2fct'></span>

<h3>Description</h3>

<p>Provided a vector of variable names this function converts any
character variables into factors. Has no affect on numeric or existing
factor variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>char2fct(data, vars = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="char2fct_+3A_data">data</code></td>
<td>
<p>A data.frame</p>
</td></tr>
<tr><td><code id="char2fct_+3A_vars">vars</code></td>
<td>
<p>a character vector of variables in <code>data</code></p>
</td></tr>
</table>

<hr>
<h2 id='check_ESS'>Diagnostics of the MCMC based on ESS</h2><span id='topic+check_ESS'></span>

<h3>Description</h3>

<p>Check the quality of the MCMC draws from the posterior distribution
by checking whether the relative ESS is sufficiently large.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_ESS(stan_fit, n_draws, threshold_lowESS = 0.4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_ESS_+3A_stan_fit">stan_fit</code></td>
<td>
<p>A <code>stanfit</code> object.</p>
</td></tr>
<tr><td><code id="check_ESS_+3A_n_draws">n_draws</code></td>
<td>
<p>Number of MCMC draws.</p>
</td></tr>
<tr><td><code id="check_ESS_+3A_threshold_lowess">threshold_lowESS</code></td>
<td>
<p>A number in <code style="white-space: pre;">&#8288;[0,1]&#8288;</code> indicating the minimum acceptable
value of the relative ESS. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>check_ESS()</code> works as follows:
</p>

<ol>
<li><p> Extract the ESS from <code>stan_fit</code> for each parameter of the model.
</p>
</li>
<li><p> Compute the relative ESS (i.e. the ESS divided by the number of draws).
</p>
</li>
<li><p> Check whether for any of the parameter the ESS is lower than <code>threshold</code>.
If for at least one parameter the relative ESS is below the threshold,
a warning is thrown.
</p>
</li></ol>



<h3>Value</h3>

<p>A warning message in case of detected problems.
</p>

<hr>
<h2 id='check_hmc_diagn'>Diagnostics of the MCMC based on HMC-related measures.</h2><span id='topic+check_hmc_diagn'></span>

<h3>Description</h3>

<p>Check that:
</p>

<ol>
<li><p> There are no divergent iterations.
</p>
</li>
<li><p> The Bayesian Fraction of Missing Information (BFMI) is sufficiently low.
</p>
</li>
<li><p> The number of iterations that saturated the max treedepth is zero.
</p>
</li></ol>

<p>Please see <code><a href="rstan.html#topic+check_hmc_diagnostics">rstan::check_hmc_diagnostics()</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_hmc_diagn(stan_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_hmc_diagn_+3A_stan_fit">stan_fit</code></td>
<td>
<p>A <code>stanfit</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A warning message in case of detected problems.
</p>

<hr>
<h2 id='check_mcmc'>Diagnostics of the MCMC</h2><span id='topic+check_mcmc'></span>

<h3>Description</h3>

<p>Diagnostics of the MCMC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_mcmc(stan_fit, n_draws, threshold_lowESS = 0.4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_mcmc_+3A_stan_fit">stan_fit</code></td>
<td>
<p>A <code>stanfit</code> object.</p>
</td></tr>
<tr><td><code id="check_mcmc_+3A_n_draws">n_draws</code></td>
<td>
<p>Number of MCMC draws.</p>
</td></tr>
<tr><td><code id="check_mcmc_+3A_threshold_lowess">threshold_lowESS</code></td>
<td>
<p>A number in <code style="white-space: pre;">&#8288;[0,1]&#8288;</code> indicating the minimum acceptable
value of the relative ESS. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Performs checks of the quality of the MCMC. See <code><a href="#topic+check_ESS">check_ESS()</a></code> and <code><a href="#topic+check_hmc_diagn">check_hmc_diagn()</a></code>
for details.
</p>


<h3>Value</h3>

<p>A warning message in case of detected problems.
</p>

<hr>
<h2 id='compute_sigma'>Compute covariance matrix for some reference-based methods (JR, CIR)</h2><span id='topic+compute_sigma'></span>

<h3>Description</h3>

<p>Adapt covariance matrix in reference-based methods. Used for Copy Increments in
Reference (CIR) and Jump To Reference (JTR) methods, to adapt the covariance matrix
to different pre-deviation and post deviation covariance structures. See Carpenter
et al. (2013)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_sigma(sigma_group, sigma_ref, index_mar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_sigma_+3A_sigma_group">sigma_group</code></td>
<td>
<p>the covariance matrix with dimensions equal to <code>index_mar</code> for
the subjects original group</p>
</td></tr>
<tr><td><code id="compute_sigma_+3A_sigma_ref">sigma_ref</code></td>
<td>
<p>the covariance matrix with dimensions equal to <code>index_mar</code> for
the subjects reference group</p>
</td></tr>
<tr><td><code id="compute_sigma_+3A_index_mar">index_mar</code></td>
<td>
<p>A logical vector indicating which visits meet the MAR assumption
for the subject. I.e. this identifies the observations that after a non-MAR
intercurrent event (ICE).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Carpenter, James R., James H. Roger, and Michael G. Kenward. &quot;Analysis of longitudinal
trials with protocol deviation: a framework for relevant, accessible assumptions, and
inference via multiple imputation.&quot; Journal of Biopharmaceutical statistics 23.6 (2013):
1352-1371.
</p>

<hr>
<h2 id='convert_to_imputation_list_df'>Convert list of <code><a href="#topic+imputation_list_single">imputation_list_single()</a></code> objects to an <code><a href="#topic+imputation_list_df">imputation_list_df()</a></code> object
(i.e. a list of <code><a href="#topic+imputation_df">imputation_df()</a></code> objects's)</h2><span id='topic+convert_to_imputation_list_df'></span>

<h3>Description</h3>

<p>Convert list of <code><a href="#topic+imputation_list_single">imputation_list_single()</a></code> objects to an <code><a href="#topic+imputation_list_df">imputation_list_df()</a></code> object
(i.e. a list of <code><a href="#topic+imputation_df">imputation_df()</a></code> objects's)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_to_imputation_list_df(imputes, sample_ids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="convert_to_imputation_list_df_+3A_imputes">imputes</code></td>
<td>
<p>a list of <code><a href="#topic+imputation_list_single">imputation_list_single()</a></code> objects</p>
</td></tr>
<tr><td><code id="convert_to_imputation_list_df_+3A_sample_ids">sample_ids</code></td>
<td>
<p>A list with 1 element per required imputation_df. Each element
must contain a vector of &quot;ID&quot;'s which correspond to the <code><a href="#topic+imputation_single">imputation_single()</a></code> ID's
that are required for that dataset. The total number of ID's must by equal to the
total number of rows within all of <code>imputes$imputations</code>
</p>
<p>To accommodate for <code>method_bmlmi()</code> the <code><a href="#topic+impute_data_individual">impute_data_individual()</a></code> function returns
a list of <code><a href="#topic+imputation_list_single">imputation_list_single()</a></code> objects with 1 object per each subject.
</p>
<p><code><a href="#topic+imputation_list_single">imputation_list_single()</a></code> stores the subjects imputations as a matrix where the columns
of the matrix correspond to the D of <code><a href="#topic+method_bmlmi">method_bmlmi()</a></code>. Note that all other methods
(i.e. <code style="white-space: pre;">&#8288;methods_*()&#8288;</code>) are a special case of this with D = 1. The number of rows in the
matrix varies for each subject and is equal to the number of times the patient was selected
for imputation (for non-conditional mean methods this should be 1 per subject per imputed
dataset).
</p>
<p>This function is best illustrated by an example:
</p>
<div class="sourceCode"><pre>imputes = list(
    imputation_list_single(
        id = "Tom",
        imputations = matrix(
             imputation_single_t_1_1,  imputation_single_t_1_2,
             imputation_single_t_2_1,  imputation_single_t_2_2,
             imputation_single_t_3_1,  imputation_single_t_3_2
        )
    ),
    imputation_list_single(
        id = "Tom",
        imputations = matrix(
             imputation_single_h_1_1,  imputation_single_h_1_2,
        )
    )
)

sample_ids &lt;- list(
    c("Tom", "Harry", "Tom"),
    c("Tom")
)
</pre></div>
<p>Then <code>convert_to_imputation_df(imputes, sample_ids)</code> would result in:
</p>
<div class="sourceCode"><pre>imputation_list_df(
    imputation_df(
        imputation_single_t_1_1,
        imputation_single_h_1_1,
        imputation_single_t_2_1
    ),
    imputation_df(
        imputation_single_t_1_2,
        imputation_single_h_1_2,
        imputation_single_t_2_2
    ),
    imputation_df(
        imputation_single_t_3_1
    ),
    imputation_df(
        imputation_single_t_3_2
    )
)
</pre></div>
<p>Note that the different repetitions (i.e. the value set for D) are grouped together
sequentially.</p>
</td></tr>
</table>

<hr>
<h2 id='d_lagscale'>Calculate delta from a lagged scale coefficient</h2><span id='topic+d_lagscale'></span>

<h3>Description</h3>

<p>Calculates a delta value based upon a baseline delta value and a
post ICE scaling coefficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d_lagscale(delta, dlag, is_post_ice)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d_lagscale_+3A_delta">delta</code></td>
<td>
<p>a numeric vector. Determines the baseline amount of delta
to be applied to each visit.</p>
</td></tr>
<tr><td><code id="d_lagscale_+3A_dlag">dlag</code></td>
<td>
<p>a numeric vector. Determines the scaling to be applied
to <code>delta</code> based upon with visit the ICE occurred on. Must be the same
length as delta.</p>
</td></tr>
<tr><td><code id="d_lagscale_+3A_is_post_ice">is_post_ice</code></td>
<td>
<p>logical vector. Indicates whether a visit is &quot;post-ICE&quot; or
not.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+delta_template">delta_template()</a></code> for full details on how this calculation is performed.
</p>

<hr>
<h2 id='delta_template'>Create a delta <code>data.frame</code> template</h2><span id='topic+delta_template'></span>

<h3>Description</h3>

<p>Creates a <code>data.frame</code> in the format required by <code><a href="#topic+analyse">analyse()</a></code> for the use
of applying a delta adjustment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delta_template(imputations, delta = NULL, dlag = NULL, missing_only = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delta_template_+3A_imputations">imputations</code></td>
<td>
<p>an <code>imputation</code> object as created by <code><a href="#topic+impute">impute()</a></code>.</p>
</td></tr>
<tr><td><code id="delta_template_+3A_delta">delta</code></td>
<td>
<p><code>NULL</code> or a numeric vector. Determines the baseline amount of delta
to be applied to each visit. See details. If a numeric vector it must have
the same length as the number of unique visits in the original dataset.</p>
</td></tr>
<tr><td><code id="delta_template_+3A_dlag">dlag</code></td>
<td>
<p><code>NULL</code> or a numeric vector. Determines the scaling to be applied
to <code>delta</code> based upon which visit the ICE occurred on. See details. If a
numeric vector it must have the same length as the number of unique visits in
the original dataset.</p>
</td></tr>
<tr><td><code id="delta_template_+3A_missing_only">missing_only</code></td>
<td>
<p>Logical, if <code>TRUE</code> then non-missing post-ICE data will have a delta value
of 0 assigned. Note that the calculation (as described in the details section) is performed
first and then overwritten with 0's at the end (i.e. the delta values for missing
post-ICE visits will stay the same regardless of this option).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To apply a delta adjustment the <code><a href="#topic+analyse">analyse()</a></code> function expects
a delta <code>data.frame</code> with 3 variables: <code>vars$subjid</code>, <code>vars$visit</code> and <code>delta</code>
(where <code>vars</code> is the object supplied in the original call to <code><a href="#topic+draws">draws()</a></code>
as created by the <code><a href="#topic+set_vars">set_vars()</a></code> function).
</p>
<p>This function will return a <code>data.frame</code> with the aforementioned variables with one
row per subject per visit. If the <code>delta</code> argument to this function is <code>NULL</code>
then the <code>delta</code> column in the returned <code>data.frame</code> will be 0 for all observations.
If the <code>delta</code> argument is not <code>NULL</code> then <code>delta</code> will be calculated separately
for each subject as the accumulative sum of <code>delta</code> multiplied by the scaling
coefficient <code>dlag</code> based upon how many visits after the subject's intercurrent
event (ICE) the visit in question is.
This is best illustrated with an example:
</p>
<p>Let <code>delta = c(5,6,7,8)</code> and <code>dlag=c(1,2,3,4)</code> (i.e. assuming there are 4 visits)
and lets say that the subject had an ICE on visit 2. The calculation would then be
as follows:
</p>
<div class="sourceCode"><pre>v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   1   2   3  # lagged scaling starting from the first visit after the subjects ICE
--------------
 0   6  14  24  # delta * lagged scaling
--------------
 0   6  20  44  # accumulative sum of delta to be applied to each visit
</pre></div>
<p>That is to say the subject would have a delta offset of 0 applied for visit-1, 6
for visit-2, 20 for visit-3 and 44 for visit-4. As a comparison, lets say that the
subject instead had their ICE on visit 3, the calculation would then be as follows:
</p>
<div class="sourceCode"><pre>v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   0   1   2  # lagged scaling starting from the first visit after the subjects ICE
--------------
 0   0   7  16  # delta * lagged scaling
--------------
 0   0   7  23  # accumulative sum of delta to be applied to each visit
</pre></div>
<p>In terms of practical usage, lets say that you wanted a delta of 5 to be used for all post ICE visits
regardless of their proximity to the ICE visit. This can be achieved by setting
<code>delta = c(5,5,5,5)</code> and <code>dlag = c(1,0,0,0)</code>. For example lets say a subject had their
ICE on visit-1, then the calculation would be as follows:
</p>
<div class="sourceCode"><pre>v1  v2  v3  v4
--------------
 5   5   5   5  # delta assigned to each visit
 1   0   0   0  # lagged scaling starting from the first visit after the subjects ICE
--------------
 5   0   0  0  # delta * lagged scaling
--------------
 5   5   5  5  # accumulative sum of delta to be applied to each visit
</pre></div>
<p>Another way of using these arguments
is to set <code>delta</code> to be the difference in time between visits and <code>dlag</code> to be the
amount of delta per unit of time. For example lets say that we have a visit on weeks
1, 5, 6 &amp; 9 and that we want a delta of 3 to be applied for each week after an ICE. This
can be achieved by setting <code>delta = c(0,4,1,3)</code> (the difference in weeks between each visit)
and <code>dlag = c(3, 3, 3, 3)</code>. For example lets say we have a subject who had their ICE on week-5
(i.e. visit-2) then the calculation would be:
</p>
<div class="sourceCode"><pre>v1  v2  v3  v4
--------------
 0   4   1   3  # delta assigned to each visit
 0   0   3   3  # lagged scaling starting from the first visit after the subjects ICE
--------------
 0   0   3   9  # delta * lagged scaling
--------------
 0   0   3  12  # accumulative sum of delta to be applied to each visit
</pre></div>
<p>i.e. on week-6 (1 week after the ICE) they have a delta of 3 and on week-9 (4 weeks after the ICE)
they have a delta of 12.
</p>
<p>Please note that this function also returns several utility variables so that
the user can create their own custom logic for defining what <code>delta</code>
should be set to. These additional variables include:
</p>

<ul>
<li> <p><code>is_mar</code> - If the observation was missing would it be regarded as MAR? This variable
is set to <code>FALSE</code> for observations that occurred after a non-MAR ICE, otherwise it is set to <code>TRUE</code>.
</p>
</li>
<li> <p><code>is_missing</code> - Is the outcome variable for this observation missing.
</p>
</li>
<li> <p><code>is_post_ice</code> - Does the observation occur after the patient's ICE as defined by the
<code>data_ice</code> dataset supplied to <code><a href="#topic+draws">draws()</a></code>.
</p>
</li>
<li> <p><code>strategy</code> - What imputation strategy was assigned to for this subject.
</p>
</li></ul>

<p>The design and implementation of this function is largely based upon the same functionality
as implemented in the so called &quot;five marcos&quot; by James Roger. See Roger (2021).
</p>


<h3>References</h3>

<p>Roger, James. Reference-based mi via multivariate normal rm (the “five macros” and miwithd), 2021. URL
https://www.lshtm.ac.uk/research/centres-projects-groups/missing-data#dia-missing-data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+analyse">analyse()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
delta_template(imputeObj)
delta_template(imputeObj, delta = c(5,6,7,8), dlag = c(1,2,3,4))

## End(Not run)
</code></pre>

<hr>
<h2 id='do_not_run'>Do not run this function</h2><span id='topic+do_not_run'></span>

<h3>Description</h3>

<p>This function only exists to suppress the false positive
from R CMD Check about unused libraries
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_not_run()
</code></pre>


<h3>Details</h3>

<p>Both rstantools and RcppParallel are required but are only used at
installation time. In the case of RcppParallel it is used in the
<code>src/Makevars</code> file which is created on the fly during installation
by rstantools. rstantools is used in the <code>configure</code> file.
</p>

<hr>
<h2 id='draws'>Fit the base imputation model and get parameter estimates</h2><span id='topic+draws'></span><span id='topic+draws.approxbayes'></span><span id='topic+draws.condmean'></span><span id='topic+draws.bmlmi'></span><span id='topic+draws.bayes'></span>

<h3>Description</h3>

<p><code>draws</code> fits the base imputation model to the observed outcome data
according to the given multiple imputation methodology.
According to the user's method specification, it returns either draws from the posterior distribution of the
model parameters as required for Bayesian multiple imputation or frequentist parameter estimates from the
original data and bootstrapped or leave-one-out datasets as required for conditional mean imputation.
The purpose of the imputation model is to estimate model parameters
in the absence of intercurrent events (ICEs) handled using reference-based imputation methods.
For this reason, any observed outcome data after ICEs, for which reference-based imputation methods are
specified, are removed and considered as missing for the purpose of estimating the imputation model, and for
this purpose only. The imputation model is a mixed model for repeated measures (MMRM) that is valid
under a missing-at-random (MAR) assumption.
It can be fit using maximum likelihood (ML) or restricted ML (REML) estimation,
a Bayesian approach, or an approximate Bayesian approach according to the user's method specification.
The ML/REML approaches and the approximate Bayesian approach support several possible covariance structures,
while the Bayesian approach based on MCMC sampling supports only an unstructured covariance structure.
In any case the covariance matrix can be assumed to be the same or different across each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draws(data, data_ice = NULL, vars, method, ncores = 1, quiet = FALSE)

## S3 method for class 'approxbayes'
draws(data, data_ice = NULL, vars, method, ncores = 1, quiet = FALSE)

## S3 method for class 'condmean'
draws(data, data_ice = NULL, vars, method, ncores = 1, quiet = FALSE)

## S3 method for class 'bmlmi'
draws(data, data_ice = NULL, vars, method, ncores = 1, quiet = FALSE)

## S3 method for class 'bayes'
draws(data, data_ice = NULL, vars, method, ncores = 1, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draws_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing the data to be used in the model. See details.</p>
</td></tr>
<tr><td><code id="draws_+3A_data_ice">data_ice</code></td>
<td>
<p>A <code>data.frame</code> that specifies the information related
to the ICEs and the imputation strategies. See details.</p>
</td></tr>
<tr><td><code id="draws_+3A_vars">vars</code></td>
<td>
<p>A <code>vars</code> object as generated by <code><a href="#topic+set_vars">set_vars()</a></code>. See details.</p>
</td></tr>
<tr><td><code id="draws_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object as generated by either <code><a href="#topic+method_bayes">method_bayes()</a></code>,
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code>, <code><a href="#topic+method_condmean">method_condmean()</a></code> or <code><a href="#topic+method_bmlmi">method_bmlmi()</a></code>.
It specifies the multiple imputation methodology to be used. See details.</p>
</td></tr>
<tr><td><code id="draws_+3A_ncores">ncores</code></td>
<td>
<p>A single numeric specifying the number of cores to use in creating the draws object.
Note that this parameter is ignored for <code><a href="#topic+method_bayes">method_bayes()</a></code> (Default = 1).</p>
</td></tr>
<tr><td><code id="draws_+3A_quiet">quiet</code></td>
<td>
<p>Logical, if <code>TRUE</code> will suppress printing of progress information that is printed to
the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>draws</code> performs the first step of the multiple imputation (MI) procedure: fitting the
base imputation model. The goal is to estimate the parameters of interest needed
for the imputation phase (i.e. the regression coefficients and the covariance matrices
from a MMRM model).
</p>
<p>The function distinguishes between the following methods:
</p>

<ul>
<li><p> Bayesian MI based on MCMC sampling: <code>draws</code> returns the draws
from the posterior distribution of the parameters using a Bayesian approach based on
MCMC sampling. This method can be specified by using <code>method = method_bayes()</code>.
</p>
</li>
<li><p> Approximate Bayesian MI based on bootstrapping: <code>draws</code> returns
the draws from the posterior distribution of the parameters using an approximate Bayesian approach,
where the sampling from the posterior distribution is simulated by fitting the MMRM model
on bootstrap samples of the original dataset. This method can be specified by using
<code style="white-space: pre;">&#8288;method = method_approxbayes()]&#8288;</code>.
</p>
</li>
<li><p> Conditional mean imputation with bootstrap re-sampling: <code>draws</code> returns the
MMRM parameter estimates from the original dataset and from <code>n_samples</code> bootstrap samples.
This method can be specified by using <code>method = method_condmean()</code> with
argument <code>type = "bootstrap"</code>.
</p>
</li>
<li><p> Conditional mean imputation with jackknife re-sampling: <code>draws</code> returns the
MMRM parameter estimates from the original dataset and from each leave-one-subject-out sample.
This method can be specified by using <code>method = method_condmean()</code> with
argument <code>type = "jackknife"</code>.
</p>
</li>
<li><p> Bootstrapped Maximum Likelihood MI: <code>draws</code> returns the MMRM parameter estimates from
a given number of bootstrap samples needed to perform random imputations of the bootstrapped samples.
This method can be specified by using <code>method = method_bmlmi()</code>.
</p>
</li></ul>

<p>Bayesian MI based on MCMC sampling has been proposed in Carpenter, Roger, and Kenward (2013) who first introduced
reference-based imputation methods. Approximate Bayesian MI is discussed in Little and Rubin (2002).
Conditional mean imputation methods are discussed in Wolbers et al (2022).
Bootstrapped Maximum Likelihood MI is described in Von Hippel &amp; Bartlett (2021).
</p>
<p>The argument <code>data</code> contains the longitudinal data. It must have at least the following variables:
</p>

<ul>
<li> <p><code>subjid</code>: a factor vector containing the subject ids.
</p>
</li>
<li> <p><code>visit</code>: a factor vector containing the visit the outcome was observed on.
</p>
</li>
<li> <p><code>group</code>: a factor vector containing the group that the subject belongs to.
</p>
</li>
<li> <p><code>outcome</code>: a numeric vector containing the outcome variable. It might contain missing values.
Additional baseline or time-varying covariates must be included in <code>data</code>.
</p>
</li></ul>

<p><code>data</code> must have one row per visit per subject. This means that incomplete
outcome data must be set as <code>NA</code> instead of having the related row missing. Missing values
in the covariates are not allowed.
If <code>data</code> is incomplete
then the <code><a href="#topic+expand_locf">expand_locf()</a></code> helper function can be used to insert any missing rows using
Last Observation Carried Forward (LOCF) imputation to impute the covariates values.
Note that LOCF is generally not a principled imputation method and should only be used when appropriate
for the specific covariate.
</p>
<p>Please note that there is no special provisioning for the baseline outcome values. If you do not want baseline
observations to be included in the model as part of the response variable then these should be removed in advance
from the outcome variable in <code>data</code>. At the same time if you want to include the baseline outcome as covariate in
the model, then this should be included as a separate column of <code>data</code> (as any other covariate).
</p>
<p>Character covariates will be explicitly
cast to factors. If you use a custom analysis function that requires specific reference
levels for the character covariates (for example in the computation of the least square means
computation) then you are advised
to manually cast your character covariates to factor in advance of running <code><a href="#topic+draws">draws()</a></code>.
</p>
<p>The argument <code>data_ice</code> contains information about the occurrence of ICEs. It is a
<code>data.frame</code> with 3 columns:
</p>

<ul>
<li> <p><strong>Subject ID</strong>: a character vector containing the ids of the subjects that experienced
the ICE. This column must be named as specified in <code>vars$subjid</code>.
</p>
</li>
<li> <p><strong>Visit</strong>: a character vector containing the first visit after the occurrence of the ICE
(i.e. the first visit affected by the ICE).
The visits must be equal to one of the levels of <code>data[[vars$visit]]</code>.
If multiple ICEs happen for the same subject, then only the first non-MAR visit should be used.
This column must be named as specified in <code>vars$visit</code>.
</p>
</li>
<li> <p><strong>Strategy</strong>: a character vector specifying the imputation strategy to address the ICE for this subject.
This column must be named as specified in <code>vars$strategy</code>.
Possible imputation strategies are:
</p>

<ul>
<li> <p><code>"MAR"</code>: Missing At Random.
</p>
</li>
<li> <p><code>"CIR"</code>: Copy Increments in Reference.
</p>
</li>
<li> <p><code>"CR"</code>: Copy Reference.
</p>
</li>
<li> <p><code>"JR"</code>: Jump to Reference.
</p>
</li>
<li> <p><code>"LMCF"</code>: Last Mean Carried Forward.
For explanations of these imputation strategies, see Carpenter, Roger, and Kenward (2013), Cro et al (2021),
and Wolbers et al (2022).
Please note that user-defined imputation strategies can also be set.
</p>
</li></ul>

</li></ul>

<p>The <code>data_ice</code> argument is necessary at this stage since (as explained in Wolbers et al (2022)), the model is fitted
after removing the observations which are incompatible with the imputation model, i.e.
any observed data on or after <code>data_ice[[vars$visit]]</code> that are addressed with an imputation
strategy different from MAR are excluded for the model fit. However such observations
will not be discarded from the data in the imputation phase
(performed with the function (<code><a href="#topic+impute">impute()</a></code>). To summarize, <strong>at this stage only pre-ICE data
and post-ICE data that is after ICEs for which MAR imputation is specified are used</strong>.
</p>
<p>If the <code>data_ice</code> argument is omitted, or if a subject doesn't have a record within <code>data_ice</code>, then it is
assumed that all of the relevant subject's data is pre-ICE and as such all missing
visits will be imputed under the MAR assumption and all observed data will be used to fit the base imputation model.
Please note that the ICE visit cannot be updated via the <code>update_strategy</code> argument
in <code><a href="#topic+impute">impute()</a></code>; this means that subjects who didn't have a record in <code>data_ice</code> will always have their
missing data imputed under the MAR assumption even if their strategy is updated.
</p>
<p>The <code>vars</code> argument is a named list that specifies the names of key variables within
<code>data</code> and <code>data_ice</code>. This list is created by <code><a href="#topic+set_vars">set_vars()</a></code> and contains the following named elements:
</p>

<ul>
<li> <p><code>subjid</code>: name of the column in <code>data</code> and <code>data_ice</code> which contains the subject ids variable.
</p>
</li>
<li> <p><code>visit</code>: name of the column in <code>data</code> and <code>data_ice</code> which contains the visit variable.
</p>
</li>
<li> <p><code>group</code>: name of the column in <code>data</code> which contains the group variable.
</p>
</li>
<li> <p><code>outcome</code>: name of the column in <code>data</code> which contains the outcome variable.
</p>
</li>
<li> <p><code>covariates</code>: vector of characters which contains the covariates to be included
in the model (including interactions which are specified as <code style="white-space: pre;">&#8288;"covariateName1*covariateName2"``). If no covariates are provided the default model specification of &#8288;</code>outcome ~ 1 + visit + group<code style="white-space: pre;">&#8288;will be used. Please note that the&#8288;</code>group*visit' interaction
is <strong>not</strong> included in the model by default.
</p>
</li>
<li> <p><code>strata</code>: covariates used as stratification variables in the bootstrap sampling.
By default only the <code>vars$group</code> is set as stratification variable.
Needed only for <code>method_condmean(type = "bootstrap")</code> and <code>method_approxbayes()</code>.
</p>
</li>
<li> <p><code>strategy</code>: name of the column in <code>data_ice</code> which contains the subject-specific imputation strategy.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>draws</code> object which is a named list containing the following:
</p>

<ul>
<li> <p><code>data</code>: R6 <code>longdata</code> object containing all relevant input data information.
</p>
</li>
<li> <p><code>method</code>: A <code>method</code> object as generated by either <code><a href="#topic+method_bayes">method_bayes()</a></code>,
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code> or <code><a href="#topic+method_condmean">method_condmean()</a></code>.
</p>
</li>
<li> <p><code>samples</code>: list containing the estimated parameters of interest.
Each element of <code>samples</code> is a named list containing the following:
</p>

<ul>
<li> <p><code>ids</code>: vector of characters containing the ids of the subjects included in the original dataset.
</p>
</li>
<li> <p><code>beta</code>: numeric vector of estimated regression coefficients.
</p>
</li>
<li> <p><code>sigma</code>: list of estimated covariance matrices (one for each level of <code>vars$group</code>).
</p>
</li>
<li> <p><code>theta</code>: numeric vector of transformed covariances.
</p>
</li>
<li> <p><code>failed</code>: Logical. <code>TRUE</code> if the model fit failed.
</p>
</li>
<li> <p><code>ids_samp</code>: vector of characters containing the ids of the subjects included in the given sample.
</p>
</li></ul>

</li>
<li> <p><code>fit</code>: if <code>method_bayes()</code> is chosen, returns the MCMC Stan fit object. Otherwise <code>NULL</code>.
</p>
</li>
<li> <p><code>n_failures</code>: absolute number of failures of the model fit.
Relevant only for <code>method_condmean(type = "bootstrap")</code>, <code>method_approxbayes()</code> and <code>method_bmlmi()</code>.
</p>
</li>
<li> <p><code>formula</code>: fixed effects formula object used for the model specification.
</p>
</li></ul>



<h3>References</h3>

<p>James R Carpenter, James H Roger, and Michael G Kenward. Analysis of longitudinal trials with protocol deviation: a
framework for relevant, accessible assumptions, and inference via multiple imputation. Journal of Biopharmaceutical
Statistics, 23(6):1352–1371, 2013.
</p>
<p>Suzie Cro, Tim P Morris, Michael G Kenward, and James R Carpenter. Sensitivity analysis for clinical trials with
missing continuous outcome data using controlled multiple imputation: a practical guide. Statistics in
Medicine, 39(21):2815–2842, 2020.
</p>
<p>Roderick J. A. Little and Donald B. Rubin. Statistical Analysis with Missing Data, Second Edition. John Wiley &amp; Sons,
Hoboken, New Jersey, 2002. [Section 10.2.3]
</p>
<p>Marcel Wolbers, Alessandro Noci, Paul Delmar, Craig Gower-Page, Sean Yiu, Jonathan W. Bartlett. Standard and reference-based
conditional mean imputation. <a href="https://arxiv.org/abs/2109.11162">https://arxiv.org/abs/2109.11162</a>, 2022.
</p>
<p>Von Hippel, Paul T and Bartlett, Jonathan W.
Maximum likelihood multiple imputation: Faster imputations and consistent standard errors without posterior draws. 2021.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+method_bayes">method_bayes()</a></code>, <code><a href="#topic+method_approxbayes">method_approxbayes()</a></code>, <code><a href="#topic+method_condmean">method_condmean()</a></code>, <code><a href="#topic+method_bmlmi">method_bmlmi()</a></code> for setting <code>method</code>.
</p>
<p><code><a href="#topic+set_vars">set_vars()</a></code> for setting <code>vars</code>.
</p>
<p><code><a href="#topic+expand_locf">expand_locf()</a></code> for expanding <code>data</code> in case of missing rows.
</p>
<p>For more details see the quickstart vignette:
<code>vignette("quickstart", package = "rbmi")</code>.
</p>

<hr>
<h2 id='encap_get_mmrm_sample'>Encapsulate get_mmrm_sample</h2><span id='topic+encap_get_mmrm_sample'></span>

<h3>Description</h3>

<p>Function creates a new wrapper function around <code><a href="#topic+get_mmrm_sample">get_mmrm_sample()</a></code>
so that the arguments of <code><a href="#topic+get_mmrm_sample">get_mmrm_sample()</a></code> are enclosed within
the new function. This makes running parallel and single process
calls to the function smoother. In particular this function takes care
of exporting the arguments if required to parallel process in a cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>encap_get_mmrm_sample(cl, longdata, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="encap_get_mmrm_sample_+3A_cl">cl</code></td>
<td>
<p>Either a cluster from <code><a href="#topic+get_cluster">get_cluster()</a></code> or <code>NULL</code></p>
</td></tr>
<tr><td><code id="encap_get_mmrm_sample_+3A_longdata">longdata</code></td>
<td>
<p>A longdata object from <code>longDataConstructor$new()</code></p>
</td></tr>
<tr><td><code id="encap_get_mmrm_sample_+3A_method">method</code></td>
<td>
<p>A method object</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+get_cluster">get_cluster()</a></code> for more documentation on the function inputs
</p>

<hr>
<h2 id='eval_mmrm'>Evaluate a call to mmrm</h2><span id='topic+eval_mmrm'></span>

<h3>Description</h3>

<p>This is a utility function that attempts to evaluate a call to mmrm
managing any warnings or errors that are thrown. In particular
this function attempts to catch any warnings or errors and instead
of surfacing them it will simply add an additional element <code>failed</code>
with a value of TRUE. This allows for multiple calls to be made
without the program exiting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval_mmrm(expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval_mmrm_+3A_expr">expr</code></td>
<td>
<p>An expression to be evaluated. Should be a call to <code><a href="mmrm.html#topic+mmrm">mmrm::mmrm()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function was originally developed for use with glmmTMB which needed
more hand-holding and dropping of false-positive warnings. It is not
as important now but is kept around encase we need to catch
false-positive warnings again in the future.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+record">record()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
eval_mmrm({
    mmrm::mmrm(formula, data)
})

## End(Not run)
</code></pre>

<hr>
<h2 id='expand'>Expand and fill in missing <code>data.frame</code> rows</h2><span id='topic+expand'></span><span id='topic+fill_locf'></span><span id='topic+expand_locf'></span>

<h3>Description</h3>

<p>These functions are essentially wrappers around <code><a href="base.html#topic+expand.grid">base::expand.grid()</a></code> to ensure that missing
combinations of data are inserted into a <code>data.frame</code> with imputation/fill methods for updating
covariate values of newly created rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand(data, ...)

fill_locf(data, vars, group = NULL, order = NULL)

expand_locf(data, ..., vars, group, order)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expand_+3A_data">data</code></td>
<td>
<p>dataset to expand or fill in.</p>
</td></tr>
<tr><td><code id="expand_+3A_...">...</code></td>
<td>
<p>variables and the levels that should be expanded out (note that duplicate entries of
levels will result in multiple rows for that level).</p>
</td></tr>
<tr><td><code id="expand_+3A_vars">vars</code></td>
<td>
<p>character vector containing the names of variables that need to be filled in.</p>
</td></tr>
<tr><td><code id="expand_+3A_group">group</code></td>
<td>
<p>character vector containing the names of variables to group
by when performing LOCF imputation of <code>var</code>.</p>
</td></tr>
<tr><td><code id="expand_+3A_order">order</code></td>
<td>
<p>character vector containing the names of additional variables to sort the <code>data.frame</code>
by before performing LOCF.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+draws">draws()</a></code> function makes the assumption that all subjects and visits are present
in the <code>data.frame</code> and that all covariate values are non missing; <code>expand()</code>,
<code>fill_locf()</code> and <code>expand_locf()</code> are utility functions to support users in ensuring
that their <code>data.frame</code>'s conform to these assumptions.
</p>
<p><code>expand()</code> takes vectors for expected levels in a <code>data.frame</code> and expands out all
combinations inserting any missing rows into the <code>data.frame</code>. Note that all &quot;expanded&quot;
variables are cast as factors.
</p>
<p><code>fill_locf()</code> applies LOCF imputation to named covariates to fill in any NAs created
by the insertion of new rows by <code>expand()</code> (though do note that no distinction is
made between existing NAs and newly created NAs). Note that the <code>data.frame</code> is sorted
by <code>c(group, order)</code> before performing the LOCF imputation; the <code>data.frame</code>
will be returned in the original sort order however.
</p>
<p><code>expand_locf()</code> a simple composition function of <code>fill_locf()</code> and <code>expand()</code> i.e.
<code>fill_locf(expand(...))</code>.
</p>


<h4>Missing First Values</h4>

<p>The <code>fill_locf()</code> function performs last observation carried forward imputation.
A natural consequence of this is that it is unable to impute missing observations if the
observation is the first value for a given subject / grouping.
These values are deliberately not imputed as doing so risks silent errors in the case of time
varying covariates.
One solution is to first use <code>expand_locf()</code> on just
the visit variable and time varying covariates and then merge on the baseline covariates
afterwards i.e.
</p>
<div class="sourceCode"><pre>library(dplyr)

dat_expanded &lt;- expand(
    data = dat,
    subject = c("pt1", "pt2", "pt3", "pt4"),
    visit = c("vis1", "vis2", "vis3")
)

dat_filled &lt;- dat_expanded %&gt;%
    left_join(baseline_covariates, by = "subject")
</pre></div>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat_expanded &lt;- expand(
    data = dat,
    subject = c("pt1", "pt2", "pt3", "pt4"),
    visit = c("vis1", "vis2", "vis3")
)

dat_filled &lt;- fill_loc(
    data = dat_expanded,
    vars = c("Sex", "Age"),
    group = "subject",
    order = "visit"
)

## Or

dat_filled &lt;- expand_locf(
    data = dat,
    subject = c("pt1", "pt2", "pt3", "pt4"),
    visit = c("vis1", "vis2", "vis3"),
    vars = c("Sex", "Age"),
    group = "subject",
    order = "visit"
)

## End(Not run)
</code></pre>

<hr>
<h2 id='extract_covariates'>Extract Variables from string vector</h2><span id='topic+extract_covariates'></span>

<h3>Description</h3>

<p>Takes a string including potentially model terms like <code>*</code> and <code>:</code> and
extracts out the individual variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_covariates(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_covariates_+3A_x">x</code></td>
<td>
<p>string of variable names potentially including interaction terms</p>
</td></tr>
</table>


<h3>Details</h3>

<p>i.e.  <code>c("v1", "v2", "v2*v3", "v1:v2")</code> becomes <code>c("v1", "v2", "v3")</code>
</p>

<hr>
<h2 id='extract_data_nmar_as_na'>Set to NA outcome values that would be MNAR if they were missing
(i.e. which occur after an ICE handled using a reference-based imputation strategy)</h2><span id='topic+extract_data_nmar_as_na'></span>

<h3>Description</h3>

<p>Set to NA outcome values that would be MNAR if they were missing
(i.e. which occur after an ICE handled using a reference-based imputation strategy)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_data_nmar_as_na(longdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_data_nmar_as_na_+3A_longdata">longdata</code></td>
<td>
<p>R6 <code>longdata</code> object containing all relevant input data information.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> containing <code>longdata$get_data(longdata$ids)</code>, but MNAR outcome
values are set to <code>NA</code>.
</p>

<hr>
<h2 id='extract_draws'>Extract draws from a <code>stanfit</code> object</h2><span id='topic+extract_draws'></span>

<h3>Description</h3>

<p>Extract draws from a <code>stanfit</code> object and convert them into lists.
</p>
<p>The function <code><a href="rstan.html#topic+stanfit-method-extract">rstan::extract()</a></code> returns the draws for a given parameter as an array. This function
calls <code><a href="rstan.html#topic+stanfit-method-extract">rstan::extract()</a></code> to extract the draws from a <code>stanfit</code> object
and then convert the arrays into lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_draws(stan_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_draws_+3A_stan_fit">stan_fit</code></td>
<td>
<p>A <code>stanfit</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of length 2 containing:
</p>

<ul>
<li> <p><code>beta</code>: a list of length equal to the number of draws containing
the draws from the posterior distribution of the regression coefficients.
</p>
</li>
<li> <p><code>sigma</code>: a list of length equal to the number of draws containing
the draws from the posterior distribution of the covariance matrices. Each element
of the list is a list with length equal to 1 if <code>same_cov = TRUE</code> or equal to the
number of groups if <code>same_cov = FALSE</code>.
</p>
</li></ul>


<hr>
<h2 id='extract_imputed_df'>Extract imputed dataset</h2><span id='topic+extract_imputed_df'></span>

<h3>Description</h3>

<p>Takes an imputation object as generated by <code><a href="#topic+imputation_df">imputation_df()</a></code> and uses
this to extract a completed dataset from a <code>longdata</code> object as created
by <code><a href="#topic+longDataConstructor">longDataConstructor()</a></code>. Also applies a delta transformation
if a <code>data.frame</code> is provided to the <code>delta</code> argument. See <code><a href="#topic+analyse">analyse()</a></code> for
details on the structure of this <code>data.frame</code>.
</p>
<p>Subject IDs in the returned <code>data.frame</code> are scrambled i.e. are not the original
values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_imputed_df(imputation, ld, delta = NULL, idmap = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_imputed_df_+3A_imputation">imputation</code></td>
<td>
<p>An imputation object as generated by <code><a href="#topic+imputation_df">imputation_df()</a></code>.</p>
</td></tr>
<tr><td><code id="extract_imputed_df_+3A_ld">ld</code></td>
<td>
<p>A <code>longdata</code> object as generated by <code><a href="#topic+longDataConstructor">longDataConstructor()</a></code>.</p>
</td></tr>
<tr><td><code id="extract_imputed_df_+3A_delta">delta</code></td>
<td>
<p>Either <code>NULL</code> or a <code>data.frame</code>. Is used to offset outcome values in the imputed dataset.</p>
</td></tr>
<tr><td><code id="extract_imputed_df_+3A_idmap">idmap</code></td>
<td>
<p>Logical. If <code>TRUE</code> an attribute called &quot;idmap&quot; is attached to
the return object which contains a <code>list</code> that maps the old subject ids
the new subject ids.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code>.
</p>

<hr>
<h2 id='extract_imputed_dfs'>Extract imputed datasets</h2><span id='topic+extract_imputed_dfs'></span>

<h3>Description</h3>

<p>Extracts the imputed datasets contained within an <code>imputations</code> object generated
by <code><a href="#topic+impute">impute()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_imputed_dfs(
  imputations,
  index = seq_along(imputations$imputations),
  delta = NULL,
  idmap = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_imputed_dfs_+3A_imputations">imputations</code></td>
<td>
<p>An <code>imputations</code> object as created by <code><a href="#topic+impute">impute()</a></code>.</p>
</td></tr>
<tr><td><code id="extract_imputed_dfs_+3A_index">index</code></td>
<td>
<p>The indexes of the imputed datasets to return. By default,
all datasets within the <code>imputations</code> object will be returned.</p>
</td></tr>
<tr><td><code id="extract_imputed_dfs_+3A_delta">delta</code></td>
<td>
<p>A <code>data.frame</code> containing the delta transformation to be
applied to the imputed dataset. See <code><a href="#topic+analyse">analyse()</a></code> for details on the
format and specification of this <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="extract_imputed_dfs_+3A_idmap">idmap</code></td>
<td>
<p>Logical. The subject IDs in the imputed <code>data.frame</code>'s are
replaced with new IDs to ensure they are unique. Setting this argument to
<code>TRUE</code> attaches an attribute, called <code>idmap</code>, to the returned <code>data.frame</code>'s
that will provide a map from the new subject IDs to the old subject IDs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of data.frames equal in length to the <code>index</code> argument.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+delta_template">delta_template()</a></code> for creating delta data.frames.
</p>
<p><code><a href="#topic+analyse">analyse()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
extract_imputed_dfs(imputeObj)
extract_imputed_dfs(imputeObj, c(1:3))

## End(Not run)
</code></pre>

<hr>
<h2 id='extract_params'>Extract parameters from a MMRM model</h2><span id='topic+extract_params'></span>

<h3>Description</h3>

<p>Extracts the beta and sigma coefficients from an MMRM model created
by <code><a href="mmrm.html#topic+mmrm">mmrm::mmrm()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_params(fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_params_+3A_fit">fit</code></td>
<td>
<p>an object created by <code><a href="mmrm.html#topic+mmrm">mmrm::mmrm()</a></code></p>
</td></tr>
</table>

<hr>
<h2 id='fit_mcmc'>Fit the base imputation model using a Bayesian approach</h2><span id='topic+fit_mcmc'></span>

<h3>Description</h3>

<p><code>fit_mcmc()</code> fits the base imputation model using a Bayesian approach.
This is done through a MCMC method that is implemented in <code>stan</code>
and is run by using the function <code><a href="rstan.html#topic+stanmodel-method-sampling">rstan::sampling()</a></code>.
The function returns the draws from the posterior distribution of the model parameters
and the <code>stanfit</code> object. Additionally it performs multiple diagnostics checks of the chain
and returns warnings in case of any detected issues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_mcmc(designmat, outcome, group, subjid, visit, method, quiet = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_mcmc_+3A_designmat">designmat</code></td>
<td>
<p>The design matrix of the fixed effects.</p>
</td></tr>
<tr><td><code id="fit_mcmc_+3A_outcome">outcome</code></td>
<td>
<p>The response variable. Must be numeric.</p>
</td></tr>
<tr><td><code id="fit_mcmc_+3A_group">group</code></td>
<td>
<p>Character vector containing the group variable.</p>
</td></tr>
<tr><td><code id="fit_mcmc_+3A_subjid">subjid</code></td>
<td>
<p>Character vector containing the subjects IDs.</p>
</td></tr>
<tr><td><code id="fit_mcmc_+3A_visit">visit</code></td>
<td>
<p>Character vector containing the visit variable.</p>
</td></tr>
<tr><td><code id="fit_mcmc_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object as generated by <code><a href="#topic+method_bayes">method_bayes()</a></code>.</p>
</td></tr>
<tr><td><code id="fit_mcmc_+3A_quiet">quiet</code></td>
<td>
<p>Specify whether the stan sampling log should be printed to the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bayesian model assumes a multivariate normal likelihood function and weakly-informative
priors for the model parameters: in particular, uniform priors are assumed for the regression
coefficients and inverse-Wishart priors for the covariance matrices.
The chain is initialized using the REML parameter estimates from MMRM as starting values.
</p>
<p>The function performs the following steps:
</p>

<ol>
<li><p> Fit MMRM using a REML approach.
</p>
</li>
<li><p> Prepare the input data for the MCMC fit as described in the <code style="white-space: pre;">&#8288;data{}&#8288;</code>
block of the Stan file. See <code><a href="#topic+prepare_stan_data">prepare_stan_data()</a></code> for details.
</p>
</li>
<li><p> Run the MCMC according the input arguments and using as starting values the REML parameter estimates
estimated at point 1.
</p>
</li>
<li><p> Performs diagnostics checks of the MCMC. See <code><a href="#topic+check_mcmc">check_mcmc()</a></code> for details.
</p>
</li>
<li><p> Extract the draws from the model fit.
</p>
</li></ol>

<p>The chains perform <code>method$n_samples</code> draws by keeping one every <code>method$burn_between</code> iterations. Additionally
the first <code>method$burn_in</code> iterations are discarded. The total number of iterations will
then be <code>method$burn_in + method$burn_between*method$n_samples</code>.
The purpose of <code>method$burn_in</code> is to ensure that the samples are drawn from the stationary
distribution of the Markov Chain.
The <code>method$burn_between</code> aims to keep the draws uncorrelated each from other.
</p>


<h3>Value</h3>

<p>A named list composed by the following:
</p>

<ul>
<li> <p><code>samples</code>: a named list containing the draws for each parameter. It corresponds to the output of <code><a href="#topic+extract_draws">extract_draws()</a></code>.
</p>
</li>
<li> <p><code>fit</code>: a <code>stanfit</code> object.
</p>
</li></ul>


<hr>
<h2 id='fit_mmrm'>Fit a MMRM model</h2><span id='topic+fit_mmrm'></span>

<h3>Description</h3>

<p>Fits a MMRM model allowing for different covariance structures using <code><a href="mmrm.html#topic+mmrm">mmrm::mmrm()</a></code>.
Returns a <code>list</code> of key model parameters <code>beta</code>, <code>sigma</code> and an additional element <code>failed</code>
indicating whether or not the fit failed to converge. If the fit did fail to converge
<code>beta</code> and <code>sigma</code> will not be present.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_mmrm(
  designmat,
  outcome,
  subjid,
  visit,
  group,
  cov_struct = c("us", "toep", "cs", "ar1"),
  REML = TRUE,
  same_cov = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit_mmrm_+3A_designmat">designmat</code></td>
<td>
<p>a <code>data.frame</code> or <code>matrix</code> containing the covariates to use in the MMRM model.
Dummy variables must already be expanded out, i.e. via <code><a href="stats.html#topic+model.matrix">stats::model.matrix()</a></code>. Cannot contain
any missing values</p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_outcome">outcome</code></td>
<td>
<p>a numeric vector. The outcome value to be regressed on in the MMRM model.</p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_subjid">subjid</code></td>
<td>
<p>a character / factor vector. The subject identifier used to link separate visits
that belong to the same subject.</p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_visit">visit</code></td>
<td>
<p>a character / factor vector. Indicates which visit the outcome value occurred on.</p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_group">group</code></td>
<td>
<p>a character / factor vector. Indicates which treatment group the patient belongs to.</p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_cov_struct">cov_struct</code></td>
<td>
<p>a character value. Specifies which covariance structure to use. Must be one of
<code>"us"</code>, <code>"toep"</code>, <code>"cs"</code> or  <code>"ar1"</code></p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_reml">REML</code></td>
<td>
<p>logical. Specifies whether restricted maximum likelihood should be used</p>
</td></tr>
<tr><td><code id="fit_mmrm_+3A_same_cov">same_cov</code></td>
<td>
<p>logical. Used to specify if a shared or individual covariance matrix should be
used per <code>group</code></p>
</td></tr>
</table>

<hr>
<h2 id='generate_data_single'>Generate data for a single group</h2><span id='topic+generate_data_single'></span>

<h3>Description</h3>

<p>Generate data for a single group
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_data_single(pars_group, strategy_fun = NULL, distr_pars_ref = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_data_single_+3A_pars_group">pars_group</code></td>
<td>
<p>A <code>simul_pars</code> object as generated by <code><a href="#topic+set_simul_pars">set_simul_pars()</a></code>. It specifies
the simulation parameters of the given group.</p>
</td></tr>
<tr><td><code id="generate_data_single_+3A_strategy_fun">strategy_fun</code></td>
<td>
<p>Function implementing trajectories after the intercurrent event (ICE).
Must be one of <code><a href="#topic+getStrategies">getStrategies()</a></code>. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for details. If <code>NULL</code> then post-ICE
outcomes are untouched.</p>
</td></tr>
<tr><td><code id="generate_data_single_+3A_distr_pars_ref">distr_pars_ref</code></td>
<td>
<p>Optional. Named list containing the simulation parameters of the
reference arm. It contains the following elements:
</p>

<ul>
<li> <p><code>mu</code>: Numeric vector indicating the mean outcome trajectory assuming no ICEs. It should
include the outcome at baseline.
</p>
</li>
<li> <p><code>sigma</code> Covariance matrix of the outcome trajectory assuming no ICEs.
If <code>NULL</code>, then these parameters are inherited from <code>pars_group</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the simulated data. It includes the following variables:
</p>

<ul>
<li> <p><code>id</code>: Factor variable that specifies the id of each subject.
</p>
</li>
<li> <p><code>visit</code>: Factor variable that specifies the visit of each assessment. Visit <code>0</code> denotes
the baseline visit.
</p>
</li>
<li> <p><code>group</code>: Factor variable that specifies which treatment group each subject belongs to.
</p>
</li>
<li> <p><code>outcome_bl</code>: Numeric variable that specifies the baseline outcome.
</p>
</li>
<li> <p><code>outcome_noICE</code>: Numeric variable that specifies the longitudinal outcome assuming
no ICEs.
</p>
</li>
<li> <p><code>ind_ice1</code>: Binary variable that takes value <code>1</code> if the corresponding visit is
affected by ICE1 and <code>0</code> otherwise.
</p>
</li>
<li> <p><code>dropout_ice1</code>: Binary variable that takes value <code>1</code> if the corresponding visit is
affected by the drop-out following ICE1 and <code>0</code> otherwise.
</p>
</li>
<li> <p><code>ind_ice2</code>: Binary variable that takes value <code>1</code> if the corresponding visit is affected
by ICE2.
</p>
</li>
<li> <p><code>outcome</code>: Numeric variable that specifies the longitudinal outcome including ICE1, ICE2
and the intermittent missing values.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+simulate_data">simulate_data()</a></code>.
</p>

<hr>
<h2 id='get_bootstrap_stack'>Creates a stack object populated with bootstrapped samples</h2><span id='topic+get_bootstrap_stack'></span>

<h3>Description</h3>

<p>Function creates a <code><a href="#topic+Stack">Stack()</a></code> object and populated the stack with bootstrap
samples based upon <code>method$n_samples</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_bootstrap_stack(longdata, method, stack = Stack$new())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_bootstrap_stack_+3A_longdata">longdata</code></td>
<td>
<p>A <code><a href="#topic+longDataConstructor">longDataConstructor()</a></code> object</p>
</td></tr>
<tr><td><code id="get_bootstrap_stack_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object</p>
</td></tr>
<tr><td><code id="get_bootstrap_stack_+3A_stack">stack</code></td>
<td>
<p>A <code><a href="#topic+Stack">Stack()</a></code> object (this is only exposed for unit testing purposes)</p>
</td></tr>
</table>

<hr>
<h2 id='get_cluster'>Create cluster</h2><span id='topic+get_cluster'></span>

<h3>Description</h3>

<p>Create cluster
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_cluster(ncores = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_cluster_+3A_ncores">ncores</code></td>
<td>
<p>Number of parallel processes to use
</p>
<p>If <code>ncores</code> is <code>1</code> this function will return NULL
This function spawns a PSOCK cluster.
Ensures that <code>rbmi</code> and <code>assert_that</code> have been loaded
on the sub-processes</p>
</td></tr>
</table>

<hr>
<h2 id='get_conditional_parameters'>Derive conditional multivariate normal parameters</h2><span id='topic+get_conditional_parameters'></span>

<h3>Description</h3>

<p>Takes parameters for a multivariate normal distribution and observed values
to calculate the conditional distribution for the unobserved values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_conditional_parameters(pars, values)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_conditional_parameters_+3A_pars">pars</code></td>
<td>
<p>a <code>list</code> with elements <code>mu</code> and <code>sigma</code> defining the mean vector and
covariance matrix respectively.</p>
</td></tr>
<tr><td><code id="get_conditional_parameters_+3A_values">values</code></td>
<td>
<p>a vector of observed values to condition on, must be same length as <code>pars$mu</code>.
Missing values must be represented by an <code>NA</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the conditional distribution parameters:
</p>

<ul>
<li> <p><code>mu</code> - The conditional mean vector.
</p>
</li>
<li> <p><code>sigma</code> - The conditional covariance matrix.
</p>
</li></ul>


<hr>
<h2 id='get_delta_template'>Get delta utility variables</h2><span id='topic+get_delta_template'></span>

<h3>Description</h3>

<p>This function creates the default delta template (1 row per subject per visit)
and extracts all the utility information that users need to define their own logic
for defining delta. See <code><a href="#topic+delta_template">delta_template()</a></code> for full details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_delta_template(imputations)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_delta_template_+3A_imputations">imputations</code></td>
<td>
<p>an imputations object created by <code><a href="#topic+impute">impute()</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='get_draws_mle'>Fit the base imputation model on bootstrap samples</h2><span id='topic+get_draws_mle'></span>

<h3>Description</h3>

<p>Fit the base imputation model using a ML/REML approach on a given number of bootstrap samples as
specified by <code>method$n_samples</code>. Returns the parameter estimates from the model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_draws_mle(
  longdata,
  method,
  sample_stack,
  n_target_samples,
  first_sample_orig,
  use_samp_ids,
  failure_limit = 0,
  ncores = 1,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_draws_mle_+3A_longdata">longdata</code></td>
<td>
<p>R6 <code>longdata</code> object containing all relevant input data information.</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object as generated by either
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code> or <code><a href="#topic+method_condmean">method_condmean()</a></code> with argument <code>type = "bootstrap"</code>.</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_sample_stack">sample_stack</code></td>
<td>
<p>A stack object containing the subject ids to be used on each mmrm iteration.</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_n_target_samples">n_target_samples</code></td>
<td>
<p>Number of samples needed to be created</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_first_sample_orig">first_sample_orig</code></td>
<td>
<p>Logical. If <code>TRUE</code> the function returns <code>method$n_samples + 1</code> samples where
the first sample contains the parameter estimates from the original dataset and <code>method$n_samples</code>
samples contain the parameter estimates from bootstrap samples.
If <code>FALSE</code> the function returns <code>method$n_samples</code> samples containing the parameter estimates from
bootstrap samples.</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_use_samp_ids">use_samp_ids</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the sampled subject ids are returned. Otherwise
the subject ids from the original dataset are returned. These values are used to tell <code><a href="#topic+impute">impute()</a></code>
what subjects should be used to derive the imputed dataset.</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_failure_limit">failure_limit</code></td>
<td>
<p>Number of failed samples that are allowed before throwing an error</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_ncores">ncores</code></td>
<td>
<p>Number of processes to parallelise the job over</p>
</td></tr>
<tr><td><code id="get_draws_mle_+3A_quiet">quiet</code></td>
<td>
<p>Logical, If <code>TRUE</code> will suppress printing of progress information that is printed to
the console.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes a <code>Stack</code> object which contains multiple lists of patient ids. The function
takes this Stack and pulls a set ids and then constructs a dataset just consisting of these
patients (i.e. potentially a bootstrap or a jackknife sample).
</p>
<p>The function then fits a MMRM model to this dataset to create a sample object. The function
repeats this process until <code>n_target_samples</code> have been reached. If more than <code>failure_limit</code>
samples fail to converge then the function throws an error.
</p>
<p>After reaching the desired number of samples the function generates and returns a draws object.
</p>


<h3>Value</h3>

<p>A <code>draws</code> object which is a named list containing the following:
</p>

<ul>
<li> <p><code>data</code>: R6 <code>longdata</code> object containing all relevant input data information.
</p>
</li>
<li> <p><code>method</code>: A <code>method</code> object as generated by either <code><a href="#topic+method_bayes">method_bayes()</a></code>,
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code> or <code><a href="#topic+method_condmean">method_condmean()</a></code>.
</p>
</li>
<li> <p><code>samples</code>: list containing the estimated parameters of interest.
Each element of <code>samples</code> is a named list containing the following:
</p>

<ul>
<li> <p><code>ids</code>: vector of characters containing the ids of the subjects included in the original dataset.
</p>
</li>
<li> <p><code>beta</code>: numeric vector of estimated regression coefficients.
</p>
</li>
<li> <p><code>sigma</code>: list of estimated covariance matrices (one for each level of <code>vars$group</code>).
</p>
</li>
<li> <p><code>theta</code>: numeric vector of transformed covariances.
</p>
</li>
<li> <p><code>failed</code>: Logical. <code>TRUE</code> if the model fit failed.
</p>
</li>
<li> <p><code>ids_samp</code>: vector of characters containing the ids of the subjects included in the given sample.
</p>
</li></ul>

</li>
<li> <p><code>fit</code>: if <code>method_bayes()</code> is chosen, returns the MCMC Stan fit object. Otherwise <code>NULL</code>.
</p>
</li>
<li> <p><code>n_failures</code>: absolute number of failures of the model fit.
Relevant only for <code>method_condmean(type = "bootstrap")</code>, <code>method_approxbayes()</code> and <code>method_bmlmi()</code>.
</p>
</li>
<li> <p><code>formula</code>: fixed effects formula object used for the model specification.
</p>
</li></ul>


<hr>
<h2 id='get_ESS'>Extract the Effective Sample Size (ESS) from a <code>stanfit</code> object</h2><span id='topic+get_ESS'></span>

<h3>Description</h3>

<p>Extract the Effective Sample Size (ESS) from a <code>stanfit</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ESS(stan_fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ESS_+3A_stan_fit">stan_fit</code></td>
<td>
<p>A <code>stanfit</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named vector containing the ESS for each parameter of the model.
</p>

<hr>
<h2 id='get_ests_bmlmi'>Von Hippel and Bartlett pooling of BMLMI method</h2><span id='topic+get_ests_bmlmi'></span>

<h3>Description</h3>

<p>Compute pooled point estimates, standard error and degrees of freedom
according to the Von Hippel and Bartlett formula for Bootstrapped Maximum Likelihood
Multiple Imputation (BMLMI).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ests_bmlmi(ests, D)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ests_bmlmi_+3A_ests">ests</code></td>
<td>
<p>numeric vector containing estimates from the analysis of the imputed datasets.</p>
</td></tr>
<tr><td><code id="get_ests_bmlmi_+3A_d">D</code></td>
<td>
<p>numeric representing the number of imputations between each bootstrap sample in the BMLMI method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ests</code> must be provided in the following order: the firsts D elements are related to analyses from
random imputation of one bootstrap sample. The second set of D elements (i.e. from D+1 to 2*D)
are related to the second bootstrap sample and so on.
</p>


<h3>Value</h3>

<p>a list containing point estimate, standard error and degrees of freedom.
</p>


<h3>References</h3>

<p>Von Hippel, Paul T and Bartlett, Jonathan W8.
Maximum likelihood multiple imputation: Faster imputations and consistent standard errors without posterior draws. 2021
</p>

<hr>
<h2 id='get_example_data'>Simulate a realistic example dataset</h2><span id='topic+get_example_data'></span>

<h3>Description</h3>

<p>Simulate a realistic example dataset using <code><a href="#topic+simulate_data">simulate_data()</a></code> with hard-coded
values of all the input arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_example_data()
</code></pre>


<h3>Details</h3>

<p><code><a href="#topic+get_example_data">get_example_data()</a></code> simulates a 1:1 randomized trial of
an active drug (intervention) versus placebo (control) with 100 subjects per
group and 6 post-baseline assessments (bi-monthly visits until 12 months).
One intercurrent event corresponding to treatment discontinuation is also simulated.
Specifically, data are simulated under the following assumptions:
</p>

<ul>
<li><p> The mean outcome trajectory in the placebo group increases linearly from
50 at baseline (visit 0) to 60 at visit 6, i.e. the slope is 10 points/year.
</p>
</li>
<li><p> The mean outcome trajectory in the intervention group is identical to the
placebo group up to visit 2. From visit 2 onward, the slope decreases by 50% to 5 points/year.
</p>
</li>
<li><p> The covariance structure of the baseline and follow-up values in both groups
is implied by a random intercept and slope model with a standard deviation of 5
for both the intercept and the slope, and a correlation of 0.25.
In addition, an independent residual error with standard deviation 2.5 is added
to each assessment.
</p>
</li>
<li><p> The probability of study drug discontinuation after each visit is calculated
according to a logistic model which depends on the observed outcome at that visit.
Specifically, a visit-wise discontinuation probability of 2% and 3% in the control
and intervention group, respectively, is specified in case the observed outcome is
equal to 50 (the mean value at baseline). The odds of a discontinuation is simulated
to increase by +10% for each +1 point increase of the observed outcome.
</p>
</li>
<li><p> Study drug discontinuation is simulated to have no effect on the mean trajectory in
the placebo group. In the intervention group, subjects who discontinue follow
the slope of the mean trajectory from the placebo group from that time point onward.
This is compatible with a copy increments in reference (CIR) assumption.
</p>
</li>
<li><p> Study drop-out at the study drug discontinuation visit occurs with a probability
of 50% leading to missing outcome data from that time point onward.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+simulate_data">simulate_data()</a></code>, <code><a href="#topic+set_simul_pars">set_simul_pars()</a></code>
</p>

<hr>
<h2 id='get_jackknife_stack'>Creates a stack object populated with jackknife samples</h2><span id='topic+get_jackknife_stack'></span>

<h3>Description</h3>

<p>Function creates a <code><a href="#topic+Stack">Stack()</a></code> object and populated the stack with jackknife
samples based upon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_jackknife_stack(longdata, method, stack = Stack$new())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_jackknife_stack_+3A_longdata">longdata</code></td>
<td>
<p>A <code><a href="#topic+longDataConstructor">longDataConstructor()</a></code> object</p>
</td></tr>
<tr><td><code id="get_jackknife_stack_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object</p>
</td></tr>
<tr><td><code id="get_jackknife_stack_+3A_stack">stack</code></td>
<td>
<p>A <code><a href="#topic+Stack">Stack()</a></code> object (this is only exposed for unit testing purposes)</p>
</td></tr>
</table>

<hr>
<h2 id='get_mmrm_sample'>Fit MMRM and returns parameter estimates</h2><span id='topic+get_mmrm_sample'></span>

<h3>Description</h3>

<p><code>get_mmrm_sample</code> fits the base imputation model using a ML/REML approach.
Returns the parameter estimates from the fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_mmrm_sample(ids, longdata, method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_mmrm_sample_+3A_ids">ids</code></td>
<td>
<p>vector of characters containing the ids of the subjects.</p>
</td></tr>
<tr><td><code id="get_mmrm_sample_+3A_longdata">longdata</code></td>
<td>
<p>R6 <code>longdata</code> object containing all relevant input data information.</p>
</td></tr>
<tr><td><code id="get_mmrm_sample_+3A_method">method</code></td>
<td>
<p>A <code>method</code> object as generated by either
<code><a href="#topic+method_approxbayes">method_approxbayes()</a></code> or <code><a href="#topic+method_condmean">method_condmean()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of class <code>sample_single</code>. It contains the following:
</p>

<ul>
<li> <p><code>ids</code> vector of characters containing the ids of the subjects included in the original dataset.
</p>
</li>
<li> <p><code>beta</code> numeric vector of estimated regression coefficients.
</p>
</li>
<li> <p><code>sigma</code> list of estimated covariance matrices (one for each level of <code>vars$group</code>).
</p>
</li>
<li> <p><code>theta</code> numeric vector of transformed covariances.
</p>
</li>
<li> <p><code>failed</code> logical. <code>TRUE</code> if the model fit failed.
</p>
</li>
<li> <p><code>ids_samp</code> vector of characters containing the ids of the subjects included in the given sample.
</p>
</li></ul>


<hr>
<h2 id='get_pattern_groups'>Determine patients missingness group</h2><span id='topic+get_pattern_groups'></span>

<h3>Description</h3>

<p>Takes a design matrix with multiple rows per subject and returns a dataset
with 1 row per subject with a new column <code>pgroup</code> indicating which group
the patient belongs to (based upon their missingness pattern and treatment group)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pattern_groups(ddat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_pattern_groups_+3A_ddat">ddat</code></td>
<td>
<p>a <code>data.frame</code> with columns <code>subjid</code>, <code>visit</code>, <code>group</code>, <code>is_avail</code></p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> The column <code>is_avail</code> must be a character or numeric <code>0</code> or <code>1</code>
</p>
</li></ul>


<hr>
<h2 id='get_pattern_groups_unique'>Get Pattern Summary</h2><span id='topic+get_pattern_groups_unique'></span>

<h3>Description</h3>

<p>Takes a dataset of pattern information and creates a summary dataset of it
with just 1 row per pattern
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pattern_groups_unique(patterns)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_pattern_groups_unique_+3A_patterns">patterns</code></td>
<td>
<p>A <code>data.frame</code> with the columns <code>pgroup</code>, <code>pattern</code> and <code>group</code></p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> The column <code>pgroup</code> must be a numeric vector indicating which pattern group the patient belongs to
</p>
</li>
<li><p> The column <code>pattern</code> must be a character string of <code>0</code>'s or <code>1</code>'s. It must be identical for all
rows within the same <code>pgroup</code>
</p>
</li>
<li><p> The column <code>group</code> must be a character / numeric vector indicating which covariance group the observation
belongs to. It must be identical within the same <code>pgroup</code>
</p>
</li></ul>


<hr>
<h2 id='get_pool_components'>Expected Pool Components</h2><span id='topic+get_pool_components'></span>

<h3>Description</h3>

<p>Returns the elements expected to be contained in the analyse object
depending on what analysis method was specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pool_components(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_pool_components_+3A_x">x</code></td>
<td>
<p>Character name of the analysis method, must one of
either <code>"rubin"</code>, <code>"jackknife"</code>, &quot;<code style="white-space: pre;">&#8288;bootstrap"&#8288;</code> or <code>"bmlmi"</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='get_visit_distribution_parameters'>Derive visit distribution parameters</h2><span id='topic+get_visit_distribution_parameters'></span>

<h3>Description</h3>

<p>Takes patient level data and beta coefficients and expands them
to get a patient specific estimate for the visit distribution parameters
<code>mu</code> and <code>sigma</code>. Returns the values in a specific format
which is expected by downstream functions in the imputation process
(namely  <code>list(list(mu = ..., sigma = ...), list(mu = ..., sigma = ...))</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_visit_distribution_parameters(dat, beta, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_visit_distribution_parameters_+3A_dat">dat</code></td>
<td>
<p>Patient level dataset, must be 1 row per visit. Column order must
be in the same order as beta. The number of columns must match the length of beta</p>
</td></tr>
<tr><td><code id="get_visit_distribution_parameters_+3A_beta">beta</code></td>
<td>
<p>List of model beta coefficients. There should be 1 element for each sample
e.g. if there were 3 samples and the models each had 4 beta coefficients then this argument
should be of the form  <code>list( c(1,2,3,4) , c(5,6,7,8), c(9,10,11,12))</code>.
All elements of beta must be the same length and must be the same length and order as <code>dat</code>.</p>
</td></tr>
<tr><td><code id="get_visit_distribution_parameters_+3A_sigma">sigma</code></td>
<td>
<p>List of sigma. Must have the same number of entries as <code>beta</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='getStrategies'>Get imputation strategies</h2><span id='topic+getStrategies'></span>

<h3>Description</h3>

<p>Returns a list defining the imputation strategies to be used to create the
multivariate normal distribution parameters by merging those of the source
group and reference group per patient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getStrategies(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getStrategies_+3A_...">...</code></td>
<td>
<p>User defined methods to be added to the return list. Input must
be a function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default Jump to Reference (JR), Copy Reference (CR), Copy Increments in
Reference (CIR), Last Mean Carried Forward (LMCF) and Missing at Random (MAR)
are defined.
</p>
<p>The user can define their own strategy functions (or overwrite the pre-defined ones)
by specifying a named input to the function i.e. <code>NEW = function(...) ...</code>.
Only exception is MAR which cannot be overwritten.
</p>
<p>All user defined functions must take 3 inputs: <code>pars_group</code>, <code>pars_ref</code> and
<code>index_mar</code>. <code>pars_group</code> and <code>pars_ref</code> are both lists with elements <code>mu</code>
and <code>sigma</code> representing the multivariate normal distribution parameters for
the subject's current group and reference group respectively.  <code>index_mar</code> will be
a logical vector specifying which visits the subject met the MAR assumption
at. The function must return a list with elements <code>mu</code> and <code>sigma</code>. See the implementation
of <code>strategy_JR()</code> for an example.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
getStrategies()
getStrategies(
    NEW = function(pars_group, pars_ref, index_mar) code ,
    JR = function(pars_group, pars_ref, index_mar)  more_code
)

## End(Not run)

</code></pre>

<hr>
<h2 id='has_class'>Does object have a class ?</h2><span id='topic+has_class'></span>

<h3>Description</h3>

<p>Utility function to see if an object has a particular class.
Useful when we don't know how many other classes the object may
have.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>has_class(x, cls)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="has_class_+3A_x">x</code></td>
<td>
<p>the object we want to check the class of.</p>
</td></tr>
<tr><td><code id="has_class_+3A_cls">cls</code></td>
<td>
<p>the class we want to know if it has or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> if the object has the class.
<code>FALSE</code> if the object does not have the class.
</p>

<hr>
<h2 id='ife'>if else</h2><span id='topic+ife'></span>

<h3>Description</h3>

<p>A wrapper around <code style="white-space: pre;">&#8288;if() else()&#8288;</code> to prevent unexpected
interactions between <code>ifelse()</code> and factor variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ife(x, a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ife_+3A_x">x</code></td>
<td>
<p>True / False</p>
</td></tr>
<tr><td><code id="ife_+3A_a">a</code></td>
<td>
<p>value to return if True</p>
</td></tr>
<tr><td><code id="ife_+3A_b">b</code></td>
<td>
<p>value to return if False</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default <code>ifelse()</code> will convert factor variables to their
numeric values which is often undesirable. This connivance
function avoids that problem
</p>

<hr>
<h2 id='imputation_df'>Create a valid <code>imputation_df</code> object</h2><span id='topic+imputation_df'></span>

<h3>Description</h3>

<p>Create a valid <code>imputation_df</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputation_df(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputation_df_+3A_...">...</code></td>
<td>
<p>a list of <code>imputation_single</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='imputation_list_df'>List of imputations_df</h2><span id='topic+imputation_list_df'></span>

<h3>Description</h3>

<p>A container for multiple <a href="#topic+imputation_df">imputation_df</a>'s
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputation_list_df(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputation_list_df_+3A_...">...</code></td>
<td>
<p>objects of class <code>imputation_df</code></p>
</td></tr>
</table>

<hr>
<h2 id='imputation_list_single'>A collection of <code>imputation_singles()</code> grouped by a single subjid ID</h2><span id='topic+imputation_list_single'></span>

<h3>Description</h3>

<p>A collection of <code>imputation_singles()</code> grouped by a single subjid ID
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputation_list_single(imputations, D = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputation_list_single_+3A_imputations">imputations</code></td>
<td>
<p>a list of <code><a href="#topic+imputation_single">imputation_single()</a></code> objects ordered so that repetitions
are grouped sequentially</p>
</td></tr>
<tr><td><code id="imputation_list_single_+3A_d">D</code></td>
<td>
<p>the number of repetitions that were performed which determines how many columns
the imputation matrix should have
</p>
<p>This is a constructor function to create a <code>imputation_list_single</code> object
which contains a matrix of <code><a href="#topic+imputation_single">imputation_single()</a></code> objects grouped by a single <code>id</code>. The matrix
is split so that it has D columns (i.e. for non-bmlmi methods this will always be 1)
</p>
<p>The <code>id</code> attribute is determined by extracting the <code>id</code> attribute from the contributing
<code><a href="#topic+imputation_single">imputation_single()</a></code> objects. An error is throw if multiple <code>id</code> are detected</p>
</td></tr>
</table>

<hr>
<h2 id='imputation_single'>Create a valid <code>imputation_single</code> object</h2><span id='topic+imputation_single'></span>

<h3>Description</h3>

<p>Create a valid <code>imputation_single</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputation_single(id, values)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputation_single_+3A_id">id</code></td>
<td>
<p>a character string specifying the subject id.</p>
</td></tr>
<tr><td><code id="imputation_single_+3A_values">values</code></td>
<td>
<p>a numeric vector indicating the imputed values.</p>
</td></tr>
</table>

<hr>
<h2 id='impute'>Create imputed datasets</h2><span id='topic+impute'></span><span id='topic+impute.random'></span><span id='topic+impute.condmean'></span>

<h3>Description</h3>

<p><code>impute()</code> creates imputed datasets based upon the data and options specified in
the call to <code><a href="#topic+draws">draws()</a></code>. One imputed dataset is created per each &quot;sample&quot; created by
<code><a href="#topic+draws">draws()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute(
  draws,
  references = NULL,
  update_strategy = NULL,
  strategies = getStrategies()
)

## S3 method for class 'random'
impute(
  draws,
  references = NULL,
  update_strategy = NULL,
  strategies = getStrategies()
)

## S3 method for class 'condmean'
impute(
  draws,
  references = NULL,
  update_strategy = NULL,
  strategies = getStrategies()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_+3A_draws">draws</code></td>
<td>
<p>A <code>draws</code> object created by <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
<tr><td><code id="impute_+3A_references">references</code></td>
<td>
<p>A named vector. Identifies the references to be used for reference-based
imputation methods. Should be of the form <code>c("Group1" = "Reference1", "Group2" = "Reference2")</code>.
If <code>NULL</code> (default), the references are assumed to be of the form
<code>c("Group1" = "Group1", "Group2" = "Group2")</code>. This argument cannot be <code>NULL</code> if
an imputation strategy (as defined by <code>data_ice[[vars$strategy]]</code> in the call to <a href="#topic+draws">draws</a>) other than <code>MAR</code> is set.</p>
</td></tr>
<tr><td><code id="impute_+3A_update_strategy">update_strategy</code></td>
<td>
<p>An optional <code>data.frame</code>. Updates the imputation method that was
originally set via the <code>data_ice</code> option in <code><a href="#topic+draws">draws()</a></code>. See the details section for more
information.</p>
</td></tr>
<tr><td><code id="impute_+3A_strategies">strategies</code></td>
<td>
<p>A named list of functions. Defines the imputation functions to be used.
The names of the list should mirror the values specified in <code>strategy</code> column of <code>data_ice</code>.
Default = <code><a href="#topic+getStrategies">getStrategies()</a></code>. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for more details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>impute()</code> uses the imputation model parameter estimates, as generated by <code><a href="#topic+draws">draws()</a></code>, to
first calculate the marginal (multivariate normal) distribution of a subject's longitudinal
outcome variable
depending on their covariate values.
For subjects with intercurrent events (ICEs) handled using non-MAR methods, this marginal distribution
is then updated depending on the time of the first visit affected by the ICE,
the chosen imputation strategy and the chosen reference group as described in Carpenter, Roger, and Kenward (2013) .
The subject's imputation distribution used for imputing missing values is then defined as
their marginal distribution conditional on their observed outcome values.
One dataset is being generated per set of parameter estimates provided by <code><a href="#topic+draws">draws()</a></code>.
</p>
<p>The exact manner in how missing values are imputed from this conditional imputation distribution depends
on the <code>method</code> object that was provided to <code><a href="#topic+draws">draws()</a></code>, in particular:
</p>

<ul>
<li><p> Bayes &amp; Approximate Bayes: each imputed dataset contains 1 row per subject &amp; visit
from the original dataset with missing values imputed by taking a single random sample
from the conditional imputation distribution.
</p>
</li>
<li><p> Conditional Mean: each imputed dataset contains 1 row per subject &amp; visit from the
bootstrapped or jackknife dataset that was used to generate the corresponding parameter
estimates in <code><a href="#topic+draws">draws()</a></code>. Missing values are imputed by using the mean of the conditional
imputation distribution. Please note that the first imputed dataset refers to the conditional
mean imputation on the original dataset whereas all subsequent imputed datasets refer to
conditional mean imputations for bootstrap or jackknife samples, respectively, of the original data.
</p>
</li>
<li><p> Bootstrapped Maximum Likelihood MI (BMLMI): it performs <code>D</code> random imputations of each bootstrapped
dataset that was used to generate the corresponding parameter estimates in <code><a href="#topic+draws">draws()</a></code>. A total number of
<code>B*D</code> imputed datasets is provided, where <code>B</code> is the number of bootstrapped datasets. Missing values
are imputed by taking a random sample from the conditional imputation distribution.
</p>
</li></ul>

<p>The <code>update_strategy</code> argument can be used to update the imputation strategy that was
originally set via the <code>data_ice</code> option in <code><a href="#topic+draws">draws()</a></code>. This avoids having to re-run the <code><a href="#topic+draws">draws()</a></code>
function when changing the imputation strategy in certain circumstances (as detailed below).
The <code>data.frame</code> provided to <code>update_strategy</code> argument must contain two columns,
one for the subject ID and another for the imputation strategy, whose names are the same as
those defined in the <code>vars</code> argument as specified in the call to <code><a href="#topic+draws">draws()</a></code>. Please note that this
argument only allows you to update the imputation strategy and not other arguments such as the
time of the first visit affected by the ICE.
A key limitation of this functionality is
that one can only switch between a MAR and a non-MAR strategy (or vice versa) for subjects without
observed post-ICE data. The reason for this is that such a change would affect whether the post-ICE data is included
in the base imputation model or not (as explained in the help to <code><a href="#topic+draws">draws()</a></code>).
As an example, if a subject had their ICE on &quot;Visit 2&quot;
but had observed/known values for &quot;Visit 3&quot; then the function will throw an error
if one tries to switch the strategy from MAR to a non-MAR strategy. In contrast, switching from
a non-MAR to a MAR strategy, whilst valid, will raise a warning as not all usable data
will have been utilised in the imputation model.
</p>


<h3>References</h3>

<p>James R Carpenter, James H Roger, and Michael G Kenward. Analysis of longitudinal trials with protocol deviation:
a framework for relevant,
accessible assumptions, and inference via multiple imputation. Journal of Biopharmaceutical Statistics,
23(6):1352–1371, 2013. [Section 4.2 and 4.3]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

impute(
    draws = drawobj,
    references = c("Trt" = "Placebo", "Placebo" = "Placebo")
)

new_strategy &lt;- data.frame(
  subjid = c("Pt1", "Pt2"),
  strategy = c("MAR", "JR")
)

impute(
    draws = drawobj,
    references = c("Trt" = "Placebo", "Placebo" = "Placebo"),
    update_strategy = new_strategy
)

## End(Not run)

</code></pre>

<hr>
<h2 id='impute_data_individual'>Impute data for a single subject</h2><span id='topic+impute_data_individual'></span>

<h3>Description</h3>

<p>This function performs the imputation for a single subject at a time implementing the
process as detailed in <code><a href="#topic+impute">impute()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_data_individual(
  id,
  index,
  beta,
  sigma,
  data,
  references,
  strategies,
  condmean,
  n_imputations = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_data_individual_+3A_id">id</code></td>
<td>
<p>Character string identifying the subject.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_index">index</code></td>
<td>
<p>The sample indexes which the subject belongs to e.g <code>c(1,1,1,2,2,4)</code>.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_beta">beta</code></td>
<td>
<p>A list of beta coefficients for each sample, i.e. <code>beta[[1]]</code> is the set of
beta coefficients for the first sample.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_sigma">sigma</code></td>
<td>
<p>A list of the sigma coefficients for each sample split by group i.e.
<code>sigma[[1]][["A"]]</code> would give the sigma coefficients for group A for the first sample.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_data">data</code></td>
<td>
<p>A <code>longdata</code> object created by <code><a href="#topic+longDataConstructor">longDataConstructor()</a></code></p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_references">references</code></td>
<td>
<p>A named vector. Identifies the references to be used when generating the
imputed values. Should be of the form <code>c("Group" = "Reference", "Group" = "Reference")</code>.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_strategies">strategies</code></td>
<td>
<p>A named list of functions. Defines the imputation functions to be used.
The names of the list should mirror the values specified in <code>method</code> column of <code>data_ice</code>.
Default = <code>getStrategies()</code>. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_condmean">condmean</code></td>
<td>
<p>Logical. If <code>TRUE</code> will impute using the conditional mean values, if <code>FALSE</code>
will impute by taking a random draw from the multivariate normal distribution.</p>
</td></tr>
<tr><td><code id="impute_data_individual_+3A_n_imputations">n_imputations</code></td>
<td>
<p>When <code>condmean = FALSE</code> numeric representing the number of random imputations to be performed for each sample.
Default is <code>1</code> (one random imputation per sample).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this function performs all of the required imputations for a subject at the
same time. I.e. if a subject is included in samples  1,3,5,9 then all imputations (using
sample-dependent imputation model parameters) are performed in one step in order to avoid
having to look up a subjects's covariates and expanding them to a design matrix multiple times
(which would be more computationally expensive).
The function also supports subject belonging to the same sample multiple times,
i.e. 1,1,2,3,5,5, as will typically occur for bootstrapped datasets.
</p>

<hr>
<h2 id='impute_internal'>Create imputed datasets</h2><span id='topic+impute_internal'></span>

<h3>Description</h3>

<p>This is the work horse function that implements most of the functionality of impute.
See the user level function <code><a href="#topic+impute">impute()</a></code> for further details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_internal(
  draws,
  references = NULL,
  update_strategy,
  strategies,
  condmean
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_internal_+3A_draws">draws</code></td>
<td>
<p>A <code>draws</code> object created by <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
<tr><td><code id="impute_internal_+3A_references">references</code></td>
<td>
<p>A named vector. Identifies the references to be used for reference-based
imputation methods. Should be of the form <code>c("Group1" = "Reference1", "Group2" = "Reference2")</code>.
If <code>NULL</code> (default), the references are assumed to be of the form
<code>c("Group1" = "Group1", "Group2" = "Group2")</code>. This argument cannot be <code>NULL</code> if
an imputation strategy (as defined by <code>data_ice[[vars$strategy]]</code> in the call to <a href="#topic+draws">draws</a>) other than <code>MAR</code> is set.</p>
</td></tr>
<tr><td><code id="impute_internal_+3A_update_strategy">update_strategy</code></td>
<td>
<p>An optional <code>data.frame</code>. Updates the imputation method that was
originally set via the <code>data_ice</code> option in <code><a href="#topic+draws">draws()</a></code>. See the details section for more
information.</p>
</td></tr>
<tr><td><code id="impute_internal_+3A_strategies">strategies</code></td>
<td>
<p>A named list of functions. Defines the imputation functions to be used.
The names of the list should mirror the values specified in <code>strategy</code> column of <code>data_ice</code>.
Default = <code><a href="#topic+getStrategies">getStrategies()</a></code>. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="impute_internal_+3A_condmean">condmean</code></td>
<td>
<p>logical. If TRUE will impute using the conditional mean values, if values
will impute by taking a random draw from the multivariate normal distribution.</p>
</td></tr>
</table>

<hr>
<h2 id='impute_outcome'>Sample outcome value</h2><span id='topic+impute_outcome'></span>

<h3>Description</h3>

<p>Draws a random sample from a multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>impute_outcome(conditional_parameters, n_imputations = 1, condmean = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="impute_outcome_+3A_conditional_parameters">conditional_parameters</code></td>
<td>
<p>a list with elements <code>mu</code> and <code>sigma</code> which
contain the mean vector and covariance matrix to sample from.</p>
</td></tr>
<tr><td><code id="impute_outcome_+3A_n_imputations">n_imputations</code></td>
<td>
<p>numeric representing the number of random samples from the multivariate
normal distribution to be performed. Default is <code>1</code>.</p>
</td></tr>
<tr><td><code id="impute_outcome_+3A_condmean">condmean</code></td>
<td>
<p>should conditional mean imputation be performed (as opposed to random
sampling)</p>
</td></tr>
</table>

<hr>
<h2 id='invert'>invert</h2><span id='topic+invert'></span>

<h3>Description</h3>

<p>Utility function used to replicated purrr::transpose. Turns a list inside
out.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invert(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invert_+3A_x">x</code></td>
<td>
<p>list</p>
</td></tr>
</table>

<hr>
<h2 id='invert_indexes'>Invert and derive indexes</h2><span id='topic+invert_indexes'></span>

<h3>Description</h3>

<p>Takes a list of elements and creates a new list
containing 1 entry per unique element value containing
the indexes of which original elements it occurred in.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>invert_indexes(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invert_indexes_+3A_x">x</code></td>
<td>
<p>list of elements to invert and calculate index from (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This functions purpose is best illustrated by an example:
</p>
<p>input:
</p>
<div class="sourceCode"><pre>list( c("A", "B", "C"), c("A", "A", "B"))}
</pre></div>
<p>becomes:
</p>
<div class="sourceCode"><pre>list( "A" = c(1,2,2), "B" = c(1,2), "C" = 1 )
</pre></div>

<hr>
<h2 id='is_absent'>Is value absent</h2><span id='topic+is_absent'></span>

<h3>Description</h3>

<p>Returns true if a value is either NULL, NA or &quot;&quot;.
In the case of a vector all values must be NULL/NA/&quot;&quot;
for x to be regarded as absent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_absent(x, na = TRUE, blank = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_absent_+3A_x">x</code></td>
<td>
<p>a value to check if it is absent or not</p>
</td></tr>
<tr><td><code id="is_absent_+3A_na">na</code></td>
<td>
<p>do NAs count as absent</p>
</td></tr>
<tr><td><code id="is_absent_+3A_blank">blank</code></td>
<td>
<p>do blanks i.e. &quot;&quot; count as absent</p>
</td></tr>
</table>

<hr>
<h2 id='is_char_fact'>Is character or factor</h2><span id='topic+is_char_fact'></span>

<h3>Description</h3>

<p>returns true if x is character or factor vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_char_fact(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_char_fact_+3A_x">x</code></td>
<td>
<p>a character or factor vector</p>
</td></tr>
</table>

<hr>
<h2 id='is_char_one'>Is single character</h2><span id='topic+is_char_one'></span>

<h3>Description</h3>

<p>returns true if x is a length 1 character vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_char_one(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_char_one_+3A_x">x</code></td>
<td>
<p>a character vector</p>
</td></tr>
</table>

<hr>
<h2 id='is_in_rbmi_development'>Is package in development mode?</h2><span id='topic+is_in_rbmi_development'></span>

<h3>Description</h3>

<p>Returns <code>TRUE</code> if the package is being developed on i.e. you have a local copy of the
source code which you are actively editing
Returns <code>FALSE</code> otherwise
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_in_rbmi_development()
</code></pre>


<h3>Details</h3>

<p>Main use of this function is in parallel processing to indicate whether the sub-processes
need to load the current development version of the code or whether they should load
the main installed package on the system
</p>

<hr>
<h2 id='is_num_char_fact'>Is character, factor or numeric</h2><span id='topic+is_num_char_fact'></span>

<h3>Description</h3>

<p>returns true if x is a character, numeric or factor vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_num_char_fact(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_num_char_fact_+3A_x">x</code></td>
<td>
<p>a character, numeric or factor vector</p>
</td></tr>
</table>

<hr>
<h2 id='locf'>Last Observation Carried Forward</h2><span id='topic+locf'></span>

<h3>Description</h3>

<p>Returns a vector after applied last observation carried forward imputation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>locf(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="locf_+3A_x">x</code></td>
<td>
<p>a vector.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
locf(c(NA, 1, 2, 3, NA, 4)) # Returns c(NA, 1, 2, 3, 3, 4)

## End(Not run)
</code></pre>

<hr>
<h2 id='longDataConstructor'>R6 Class for Storing / Accessing &amp; Sampling Longitudinal Data</h2><span id='topic+longDataConstructor'></span>

<h3>Description</h3>

<p>A <code>longdata</code> object allows for efficient storage and recall of longitudinal datasets for use in
bootstrap sampling. The object works by de-constructing the data into lists based upon subject id
thus enabling efficient lookup.
</p>


<h3>Details</h3>

<p>The object also handles multiple other operations specific to <code>rbmi</code> such as defining whether an
outcome value is MAR / Missing or not as well as tracking which imputation strategy is assigned
to each subject.
</p>
<p>It is recognised that this objects functionality is fairly overloaded and is hoped that this can
be split out into more area specific objects / functions in the future. Further additions of functionality
to this object should be avoided if possible.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>data</code></dt><dd><p>The original dataset passed to the constructor (sorted by id and visit)</p>
</dd>
<dt><code>vars</code></dt><dd><p>The vars object (list of key variables) passed to the constructor</p>
</dd>
<dt><code>visits</code></dt><dd><p>A character vector containing the distinct visit levels</p>
</dd>
<dt><code>ids</code></dt><dd><p>A character vector containing the unique ids of each subject in <code>self$data</code></p>
</dd>
<dt><code>formula</code></dt><dd><p>A formula expressing how the design matrix for the data should be constructed</p>
</dd>
<dt><code>strata</code></dt><dd><p>A numeric vector indicating which strata each corresponding value of
<code>self$ids</code> belongs to.
If no stratification variable is defined this will default to 1 for all subjects
(i.e. same group).
This field is only used as part of the <code>self$sample_ids()</code> function to enable
stratified bootstrap
sampling</p>
</dd>
<dt><code>ice_visit_index</code></dt><dd><p>A list indexed by subject storing the index number of the first visit
affected by the ICE. If there is no ICE then it is set equal to the number of visits plus 1.</p>
</dd>
<dt><code>values</code></dt><dd><p>A list indexed by subject storing a numeric vector of the
original (unimputed) outcome values</p>
</dd>
<dt><code>group</code></dt><dd><p>A list indexed by subject storing a single character
indicating which imputation group the subject belongs to as defined
by <code>self$data[id, self$ivars$group]</code>
It is used
to determine what reference group should be used when imputing the subjects data.</p>
</dd>
<dt><code>is_mar</code></dt><dd><p>A list indexed by subject storing logical values indicating
if the subjects outcome values are MAR or not.
This list is defaulted to TRUE for all subjects &amp; outcomes and is then
modified by calls to <code>self$set_strategies()</code>.
Note that this does not indicate which values are missing, this variable
is True for outcome values that either occurred before the ICE visit
or are post the ICE visit and have an imputation strategy of MAR</p>
</dd>
<dt><code>strategies</code></dt><dd><p>A list indexed by subject storing a single character
value indicating the imputation
strategy assigned to that subject. This list is defaulted to &quot;MAR&quot;
for all subjects and is then
modified by calls to either <code>self$set_strategies()</code> or <code>self$update_strategies()</code></p>
</dd>
<dt><code>strategy_lock</code></dt><dd><p>A list indexed by subject storing a single
logical value indicating whether a
patients imputation strategy is locked or not. If a strategy is
locked it means that it can't change
from MAR to non-MAR. Strategies can be changed from non-MAR to MAR though
this will trigger a warning.
Strategies are locked if the patient is assigned a MAR strategy and
has non-missing after their ICE date. This list is populated by a call to
<code>self$set_strategies()</code>.</p>
</dd>
<dt><code>indexes</code></dt><dd><p>A list indexed by subject storing a numeric vector of
indexes which specify which rows in the
original dataset belong to this subject i.e. to recover the full data
for subject &quot;pt3&quot; you can use
<code>self$data[self$indexes[["pt3"]],]</code>. This may seem redundant over filtering
the data directly
however it enables efficient bootstrap sampling of the data i.e.
</p>
<div class="sourceCode"><pre>indexes &lt;- unlist(self$indexes[c("pt3", "pt3")])
self$data[indexes,]
</pre></div>
<p>This list is populated during the object initialisation.</p>
</dd>
<dt><code>is_missing</code></dt><dd><p>A list indexed by subject storing a logical vector
indicating whether the corresponding
outcome of a subject is missing. This list is populated during the
object initialisation.</p>
</dd>
<dt><code>is_post_ice</code></dt><dd><p>A list indexed by subject storing a logical vector
indicating whether the corresponding
outcome of a subject is post the date of their ICE. If no ICE data has
been provided this defaults to False
for all observations. This list is populated by a call to <code>self$set_strategies()</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-longdata-get_data"><code>longDataConstructor$get_data()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-add_subject"><code>longDataConstructor$add_subject()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-validate_ids"><code>longDataConstructor$validate_ids()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-sample_ids"><code>longDataConstructor$sample_ids()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-extract_by_id"><code>longDataConstructor$extract_by_id()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-update_strategies"><code>longDataConstructor$update_strategies()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-set_strategies"><code>longDataConstructor$set_strategies()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-check_has_data_at_each_visit"><code>longDataConstructor$check_has_data_at_each_visit()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-set_strata"><code>longDataConstructor$set_strata()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-new"><code>longDataConstructor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-longdata-clone"><code>longDataConstructor$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-longdata-get_data"></a>



<h4>Method <code>get_data()</code></h4>

<p>Returns a <code>data.frame</code> based upon required subject IDs. Replaces missing
values with new ones if provided.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$get_data(
  obj = NULL,
  nmar.rm = FALSE,
  na.rm = FALSE,
  idmap = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>obj</code></dt><dd><p>Either <code>NULL</code>, a character vector of subjects IDs or a
imputation list object. See details.</p>
</dd>
<dt><code>nmar.rm</code></dt><dd><p>Logical value. If <code>TRUE</code> will remove observations that are
not regarded as MAR (as determined from <code>self$is_mar</code>).</p>
</dd>
<dt><code>na.rm</code></dt><dd><p>Logical value. If <code>TRUE</code> will remove outcome values that are
missing (as determined from <code>self$is_missing</code>).</p>
</dd>
<dt><code>idmap</code></dt><dd><p>Logical value. If <code>TRUE</code> will add an attribute <code>idmap</code> which
contains a mapping from the new subject ids to the old subject ids. See details.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>If <code>obj</code> is <code>NULL</code> then the full original dataset is returned.
</p>
<p>If <code>obj</code> is a character vector then a new dataset consisting of just those subjects is
returned; if the character vector contains duplicate entries then that subject will be
returned multiple times.
</p>
<p>If <code>obj</code> is an <code>imputation_df</code> object (as created by <code><a href="#topic+imputation_df">imputation_df()</a></code>) then the
subject ids specified in the object will be returned and missing values will be filled
in by those specified in the imputation list object.  i.e.
</p>
<div class="sourceCode"><pre>obj &lt;- imputation_df(
  imputation_single( id = "pt1", values = c(1,2,3)),
  imputation_single( id = "pt1", values = c(4,5,6)),
  imputation_single( id = "pt3", values = c(7,8))
)
longdata$get_data(obj)
</pre></div>
<p>Will return a <code>data.frame</code> consisting of all observations for <code>pt1</code> twice and all of the
observations for <code>pt3</code> once. The first set of observations for <code>pt1</code> will have missing
values filled in with <code>c(1,2,3)</code> and the second set will be filled in by <code>c(4,5,6)</code>. The
length of the values must be equal to <code>sum(self$is_missing[[id]])</code>.
</p>
<p>If <code>obj</code> is not <code>NULL</code> then all subject IDs will be scrambled in order to ensure that they
are unique
i.e. If the <code>pt2</code> is requested twice then this process guarantees that each set of observations
be have a unique subject ID number. The <code>idmap</code> attribute (if requested) can be used
to map from the new ids back to the old ids.
</p>



<h5>Returns</h5>

<p>A <code>data.frame</code>.
</p>


<hr>
<a id="method-longdata-add_subject"></a>



<h4>Method <code>add_subject()</code></h4>

<p>This function decomposes a patient data from <code>self$data</code> and populates
all the corresponding lists i.e. <code>self$is_missing</code>, <code>self$values</code>, <code>self$group</code>, etc.
This function is only called upon the objects initialization.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$add_subject(id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>Character subject id that exists within <code>self$data</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-longdata-validate_ids"></a>



<h4>Method <code>validate_ids()</code></h4>

<p>Throws an error if any element of <code>ids</code> is not within the source data <code>self$data</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$validate_ids(ids)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>ids</code></dt><dd><p>A character vector of ids.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>TRUE
</p>


<hr>
<a id="method-longdata-sample_ids"></a>



<h4>Method <code>sample_ids()</code></h4>

<p>Performs random stratified sampling of patient ids (with replacement)
Each patient has an equal weight of being picked within their strata (i.e is not dependent on
how many non-missing visits they had).
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$sample_ids()</pre></div>



<h5>Returns</h5>

<p>Character vector of ids.
</p>


<hr>
<a id="method-longdata-extract_by_id"></a>



<h4>Method <code>extract_by_id()</code></h4>

<p>Returns a list of key information for a given subject. Is a convenience wrapper
to save having to manually grab each element.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$extract_by_id(id)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>Character subject id that exists within <code>self$data</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-longdata-update_strategies"></a>



<h4>Method <code>update_strategies()</code></h4>

<p>Convenience function to run self$set_strategies(dat_ice, update=TRUE)
kept for legacy reasons.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$update_strategies(dat_ice)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dat_ice</code></dt><dd><p>A <code>data.frame</code> containing ICE information see <code><a href="#topic+impute">impute()</a></code> for the format of this dataframe.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-longdata-set_strategies"></a>



<h4>Method <code>set_strategies()</code></h4>

<p>Updates the <code>self$strategies</code>, <code>self$is_mar</code>, <code>self$is_post_ice</code> variables based upon the provided ICE
information.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$set_strategies(dat_ice = NULL, update = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dat_ice</code></dt><dd><p>a <code>data.frame</code> containing ICE information. See details.</p>
</dd>
<dt><code>update</code></dt><dd><p>Logical, indicates that the ICE data should be used as an update. See details.</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>See <code><a href="#topic+draws">draws()</a></code> for the specification of <code>dat_ice</code> if <code>update=FALSE</code>.
See <code><a href="#topic+impute">impute()</a></code> for the format of <code>dat_ice</code> if <code>update=TRUE</code>.
If <code>update=TRUE</code> this function ensures that MAR strategies cannot be changed to non-MAR in the presence
of post-ICE observations.
</p>


<hr>
<a id="method-longdata-check_has_data_at_each_visit"></a>



<h4>Method <code>check_has_data_at_each_visit()</code></h4>

<p>Ensures that all visits have at least 1 observed &quot;MAR&quot; observation. Throws
an error if this criteria is not met. This is to ensure that the initial
MMRM can be resolved.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$check_has_data_at_each_visit()</pre></div>


<hr>
<a id="method-longdata-set_strata"></a>



<h4>Method <code>set_strata()</code></h4>

<p>Populates the <code>self$strata</code> variable. If the user has specified stratification variables
The first visit is used to determine the value of those variables. If no stratification variables
have been specified then everyone is defined as being in strata 1.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$set_strata()</pre></div>


<hr>
<a id="method-longdata-new"></a>



<h4>Method <code>new()</code></h4>

<p>Constructor function.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$new(data, vars)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>longitudinal dataset.</p>
</dd>
<dt><code>vars</code></dt><dd><p>an <code>ivars</code> object created by <code><a href="#topic+set_vars">set_vars()</a></code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-longdata-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>longDataConstructor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='ls_design'>Calculate design vector for the lsmeans</h2><span id='topic+ls_design'></span><span id='topic+ls_design_equal'></span><span id='topic+ls_design_proportional'></span>

<h3>Description</h3>

<p>Calculates the design vector as required to generate the lsmean
and standard error. <code>ls_design_equal</code> calculates it by
applying an equal weight per covariate combination whilst
<code>ls_design_proportional</code> applies weighting proportional
to the frequency in which the covariate combination occurred
in the actual dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ls_design_equal(data, frm, covars, fix)

ls_design_proportional(data, frm, covars, fix)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ls_design_+3A_data">data</code></td>
<td>
<p>A data.frame</p>
</td></tr>
<tr><td><code id="ls_design_+3A_frm">frm</code></td>
<td>
<p>Formula used to fit the original model</p>
</td></tr>
<tr><td><code id="ls_design_+3A_covars">covars</code></td>
<td>
<p>a character vector of variables names that exist in
<code>data</code> which should be extracted (<code>ls_design_equal</code> only)</p>
</td></tr>
<tr><td><code id="ls_design_+3A_fix">fix</code></td>
<td>
<p>A named list of variables with fixed values</p>
</td></tr>
</table>

<hr>
<h2 id='lsmeans'>Least Square Means</h2><span id='topic+lsmeans'></span>

<h3>Description</h3>

<p>Estimates the least square means from a linear model. This is done by
generating a prediction from the model using an hypothetical observation
that is constructed by averaging the data. See details for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsmeans(model, ..., .weights = c("proportional", "equal"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsmeans_+3A_model">model</code></td>
<td>
<p>A model created by <code>lm</code>.</p>
</td></tr>
<tr><td><code id="lsmeans_+3A_...">...</code></td>
<td>
<p>Fixes specific variables to specific values i.e.
<code>trt = 1</code> or <code>age = 50</code>. The name of the argument must be the name
of the variable within the dataset.</p>
</td></tr>
<tr><td><code id="lsmeans_+3A_.weights">.weights</code></td>
<td>
<p>Character, specifies whether to use &quot;proportional&quot; or &quot;equal&quot; weighting for each
categorical covariate combination when calculating the lsmeans.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The lsmeans are obtained by calculating hypothetical patients
and predicting their expected values. These hypothetical patients
are constructed by expanding out all possible combinations of each
categorical covariate and by setting any numerical covariates equal
to the mean.
</p>
<p>A final lsmean value is calculated by averaging these hypothetical
patients. If <code>.weights</code> equals <code>"proportional"</code> then the values are weighted
by the frequency in which they occur in the full dataset. If <code>.weights</code>
equals <code>"equal"</code> then each hypothetical patient is given an equal weight
regardless of what actually occurs in the dataset.
</p>
<p>Use the <code>...</code> argument to fix specific variables to specific values.
</p>
<p>See the references for identical implementations as done in SAS and
in R via the <code>emmeans</code> package. This function attempts to re-implement the
<code>emmeans</code> derivation for standard linear models but without having to include
all of it's dependencies.
</p>


<h3>References</h3>

<p><a href="https://CRAN.R-project.org/package=emmeans">https://CRAN.R-project.org/package=emmeans</a>
</p>
<p><a href="https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_glm_details41.htm">https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/statug/statug_glm_details41.htm</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
mod &lt;- lm(Sepal.Length ~ Species + Petal.Length, data = iris)
lsmeans(mod)
lsmeans(mod, Species = "virginica")
lsmeans(mod, Species = "versicolor")
lsmeans(mod, Species = "versicolor", Petal.Length = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='method'>Set the multiple imputation methodology</h2><span id='topic+method'></span><span id='topic+method_bayes'></span><span id='topic+method_approxbayes'></span><span id='topic+method_condmean'></span><span id='topic+method_bmlmi'></span>

<h3>Description</h3>

<p>These functions determine what methods <code>rbmi</code> should use when creating
the imputation models, generating imputed values and pooling the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>method_bayes(
  burn_in = 200,
  burn_between = 50,
  same_cov = TRUE,
  n_samples = 20,
  seed = sample.int(.Machine$integer.max, 1)
)

method_approxbayes(
  covariance = c("us", "toep", "cs", "ar1"),
  threshold = 0.01,
  same_cov = TRUE,
  REML = TRUE,
  n_samples = 20
)

method_condmean(
  covariance = c("us", "toep", "cs", "ar1"),
  threshold = 0.01,
  same_cov = TRUE,
  REML = TRUE,
  n_samples = NULL,
  type = c("bootstrap", "jackknife")
)

method_bmlmi(
  covariance = c("us", "toep", "cs", "ar1"),
  threshold = 0.01,
  same_cov = TRUE,
  REML = TRUE,
  B = 20,
  D = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="method_+3A_burn_in">burn_in</code></td>
<td>
<p>a numeric that specifies how many observations should be discarded
prior to extracting actual samples. Note that the sampler
is initialized at the maximum likelihood estimates and a weakly informative
prior is used thus in theory this value should not need to be that high.</p>
</td></tr>
<tr><td><code id="method_+3A_burn_between">burn_between</code></td>
<td>
<p>a numeric that specifies the &quot;thinning&quot; rate i.e. how many
observations should be discarded between each sample. This is used to prevent
issues associated with autocorrelation between the samples.</p>
</td></tr>
<tr><td><code id="method_+3A_same_cov">same_cov</code></td>
<td>
<p>a logical, if <code>TRUE</code> the imputation model will be fitted using a single
shared covariance matrix for all observations. If <code>FALSE</code> a separate covariance
matrix will be fit for each group as determined by the <code>group</code> argument of
<code>set_vars()</code>.</p>
</td></tr>
<tr><td><code id="method_+3A_n_samples">n_samples</code></td>
<td>
<p>a numeric that determines how many imputed datasets are generated.
In the case of <code>method_condmean(type = "jackknife")</code> this argument
must be set to <code>NULL</code>. See details.</p>
</td></tr>
<tr><td><code id="method_+3A_seed">seed</code></td>
<td>
<p>a numeric that specifies the seed to be used in the call to Stan. This
argument is passed onto the <code>seed</code> argument of <code><a href="rstan.html#topic+stanmodel-method-sampling">rstan::sampling()</a></code>. Note that
this is only required for <code>method_bayes()</code>, for all other methods you can achieve
reproducible results by setting the seed via <code>set.seed()</code>. See details.</p>
</td></tr>
<tr><td><code id="method_+3A_covariance">covariance</code></td>
<td>
<p>a character string that specifies the structure of the covariance
matrix to be used in the imputation model. Must be one of <code>"us"</code> (default), <code>"toep"</code>,
<code>"cs"</code> or <code>"ar1"</code>. See details.</p>
</td></tr>
<tr><td><code id="method_+3A_threshold">threshold</code></td>
<td>
<p>a numeric between 0 and 1, specifies the proportion of bootstrap
datasets that can fail to produce valid samples before an error is thrown.
See details.</p>
</td></tr>
<tr><td><code id="method_+3A_reml">REML</code></td>
<td>
<p>a logical indicating whether to use REML estimation rather than maximum
likelihood.</p>
</td></tr>
<tr><td><code id="method_+3A_type">type</code></td>
<td>
<p>a character string that specifies the resampling method used to perform inference
when a conditional mean imputation approach (set via <code>method_condmean()</code>) is used. Must be one of <code>"bootstrap"</code> or <code>"jackknife"</code>.</p>
</td></tr>
<tr><td><code id="method_+3A_b">B</code></td>
<td>
<p>a numeric that determines the number of bootstrap samples for <code>method_bmlmi</code>.</p>
</td></tr>
<tr><td><code id="method_+3A_d">D</code></td>
<td>
<p>a numeric that determines the number of random imputations for each bootstrap sample.
Needed for <code>method_bmlmi()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the case of <code>method_condmean(type = "bootstrap")</code> there will be <code>n_samples + 1</code>
imputation models and datasets generated as the first sample will be based on
the original dataset whilst the other <code>n_samples</code> samples will be
bootstrapped datasets. Likewise, for <code>method_condmean(type = "jackknife")</code> there will
be <code>length(unique(data$subjid)) + 1</code> imputation models and datasets generated. In both cases this is
represented by <code>n + 1</code> being displayed in the print message.
</p>
<p>The user is able to specify different covariance structures using the the <code>covariance</code>
argument. Currently supported structures include:
</p>

<ul>
<li><p> Unstructured (<code>"us"</code>)
</p>
</li>
<li><p> Toeplitz (<code>"toep"</code>)
</p>
</li>
<li><p> Compound Symmetry (<code>"cs"</code>)
</p>
</li>
<li><p> Autoregression-1 (<code>"ar1"</code>)
</p>
</li></ul>

<p>Note that at present Bayesian methods only support unstructured.
</p>
<p>In the case of <code>method_condmean(type = "bootstrap")</code>, <code>method_approxbayes()</code> and <code>method_bmlmi()</code> repeated
bootstrap samples of the original dataset are taken with an MMRM fitted to each sample.
Due to the randomness of these sampled datasets, as well as limitations in the optimisers
used to fit the models, it is not uncommon that estimates for a particular dataset can't
be generated. In these instances <code>rbmi</code> is designed to throw out that bootstrapped dataset
and try again with another. However to ensure that these errors are due to chance and
not due to some underlying misspecification in the data and/or model a tolerance limit
is set on how many samples can be discarded. Once the tolerance limit has been reached
an error will be thrown and the process aborted. The tolerance limit is defined as
<code>ceiling(threshold * n_samples)</code>. Note that for the jackknife method estimates need to be
generated for all leave-one-out datasets and as such an error will be thrown if
any of them fail to fit.
</p>
<p>Please note that at the time of writing (September 2021) Stan is unable to produce
reproducible samples across different operating systems even when the same seed is used.
As such care must be taken when using Stan across different machines. For more information
on this limitation please consult the Stan documentation
<a href="https://mc-stan.org/docs/2_27/reference-manual/reproducibility-chapter.html">https://mc-stan.org/docs/2_27/reference-manual/reproducibility-chapter.html</a>
</p>

<hr>
<h2 id='parametric_ci'>Calculate parametric confidence intervals</h2><span id='topic+parametric_ci'></span>

<h3>Description</h3>

<p>Calculates confidence intervals based upon a parametric
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parametric_ci(point, se, alpha, alternative, qfun, pfun, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parametric_ci_+3A_point">point</code></td>
<td>
<p>The point estimate.</p>
</td></tr>
<tr><td><code id="parametric_ci_+3A_se">se</code></td>
<td>
<p>The standard error of the point estimate. If using a non-&quot;normal&quot;
distribution this should be set to 1.</p>
</td></tr>
<tr><td><code id="parametric_ci_+3A_alpha">alpha</code></td>
<td>
<p>The type 1 error rate, should be a value between 0 and 1.</p>
</td></tr>
<tr><td><code id="parametric_ci_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of &quot;two.sided&quot; (default), &quot;greater&quot; or &quot;less&quot;.</p>
</td></tr>
<tr><td><code id="parametric_ci_+3A_qfun">qfun</code></td>
<td>
<p>The quantile function for the assumed distribution i.e. <code>qnorm</code>.</p>
</td></tr>
<tr><td><code id="parametric_ci_+3A_pfun">pfun</code></td>
<td>
<p>The CDF function for the assumed distribution i.e. <code>pnorm</code>.</p>
</td></tr>
<tr><td><code id="parametric_ci_+3A_...">...</code></td>
<td>
<p>additional arguments passed on <code>qfun</code> and <code>pfun</code> i.e. <code>df = 102</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='pool'>Pool analysis results obtained from the imputed datasets</h2><span id='topic+pool'></span><span id='topic+as.data.frame.pool'></span><span id='topic+print.pool'></span>

<h3>Description</h3>

<p>Pool analysis results obtained from the imputed datasets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool(
  results,
  conf.level = 0.95,
  alternative = c("two.sided", "less", "greater"),
  type = c("percentile", "normal")
)

## S3 method for class 'pool'
as.data.frame(x, ...)

## S3 method for class 'pool'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pool_+3A_results">results</code></td>
<td>
<p>an analysis object created by <code><a href="#topic+analyse">analyse()</a></code>.</p>
</td></tr>
<tr><td><code id="pool_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the returned confidence interval.
Must be a single number between 0 and 1. Default is 0.95.</p>
</td></tr>
<tr><td><code id="pool_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="pool_+3A_type">type</code></td>
<td>
<p>a character string of either <code>"percentile"</code> (default) or
<code>"normal"</code>. Determines what method should be used to calculate the bootstrap confidence
intervals. See details.
Only used if <code>method_condmean(type = "bootstrap")</code> was specified
in the original call to <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
<tr><td><code id="pool_+3A_x">x</code></td>
<td>
<p>a <code>pool</code> object generated by <code><a href="#topic+pool">pool()</a></code>.</p>
</td></tr>
<tr><td><code id="pool_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculation used to generate the point estimate, standard errors and
confidence interval depends upon the method specified in the original
call to <code><a href="#topic+draws">draws()</a></code>; In particular:
</p>

<ul>
<li> <p><code>method_approxbayes()</code> &amp; <code>method_bayes()</code> both use Rubin's rules to pool estimates
and variances across multiple imputed datasets, and the Barnard-Rubin rule to pool
degree's of freedom; see Little &amp; Rubin (2002).
</p>
</li>
<li> <p><code>method_condmean(type = "bootstrap")</code> uses percentile or normal approximation;
see Efron &amp; Tibshirani (1994). Note that for the percentile bootstrap, no standard error is
calculated, i.e. the standard errors will be <code>NA</code> in the object / <code>data.frame</code>.
</p>
</li>
<li> <p><code>method_condmean(type = "jackknife")</code> uses the standard jackknife variance formula;
see Efron &amp; Tibshirani (1994).
</p>
</li>
<li> <p><code>method_bmlmi</code> uses pooling procedure for Bootstrapped Maximum Likelihood MI (BMLMI).
See Von Hippel &amp; Bartlett (2021).
</p>
</li></ul>



<h3>References</h3>

<p>Bradley Efron and Robert J Tibshirani. An introduction to the bootstrap. CRC
press, 1994. [Section 11]
</p>
<p>Roderick J. A. Little and Donald B. Rubin. Statistical Analysis with Missing
Data, Second Edition. John Wiley &amp; Sons, Hoboken, New Jersey, 2002. [Section 5.4]
</p>
<p>Von Hippel, Paul T and Bartlett, Jonathan W.
Maximum likelihood multiple imputation: Faster imputations and consistent standard errors without posterior draws. 2021.
</p>

<hr>
<h2 id='pool_bootstrap_normal'>Bootstrap Pooling via normal approximation</h2><span id='topic+pool_bootstrap_normal'></span>

<h3>Description</h3>

<p>Get point estimate, confidence interval and p-value using
the normal approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool_bootstrap_normal(est, conf.level, alternative)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pool_bootstrap_normal_+3A_est">est</code></td>
<td>
<p>a numeric vector of point estimates from each bootstrap sample.</p>
</td></tr>
<tr><td><code id="pool_bootstrap_normal_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the returned confidence interval.
Must be a single number between 0 and 1. Default is 0.95.</p>
</td></tr>
<tr><td><code id="pool_bootstrap_normal_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The point estimate is taken to be the first element of est. The remaining
n-1 values of est are then used to generate the confidence intervals.
</p>

<hr>
<h2 id='pool_bootstrap_percentile'>Bootstrap Pooling via Percentiles</h2><span id='topic+pool_bootstrap_percentile'></span>

<h3>Description</h3>

<p>Get point estimate, confidence interval and p-value using
percentiles. Note that quantile &quot;type=6&quot; is used,
see <code><a href="stats.html#topic+quantile">stats::quantile()</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool_bootstrap_percentile(est, conf.level, alternative)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pool_bootstrap_percentile_+3A_est">est</code></td>
<td>
<p>a numeric vector of point estimates from each bootstrap sample.</p>
</td></tr>
<tr><td><code id="pool_bootstrap_percentile_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the returned confidence interval.
Must be a single number between 0 and 1. Default is 0.95.</p>
</td></tr>
<tr><td><code id="pool_bootstrap_percentile_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The point estimate is taken to be the first element of <code>est</code>. The remaining
n-1 values of <code>est</code> are then used to generate the confidence intervals.
</p>

<hr>
<h2 id='pool_internal'>Internal Pool Methods</h2><span id='topic+pool_internal'></span><span id='topic+pool_internal.jackknife'></span><span id='topic+pool_internal.bootstrap'></span><span id='topic+pool_internal.bmlmi'></span><span id='topic+pool_internal.rubin'></span>

<h3>Description</h3>

<p>Dispatches pool methods based upon results object class. See
<code><a href="#topic+pool">pool()</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pool_internal(results, conf.level, alternative, type, D)

## S3 method for class 'jackknife'
pool_internal(results, conf.level, alternative, type, D)

## S3 method for class 'bootstrap'
pool_internal(
  results,
  conf.level,
  alternative,
  type = c("percentile", "normal"),
  D
)

## S3 method for class 'bmlmi'
pool_internal(results, conf.level, alternative, type, D)

## S3 method for class 'rubin'
pool_internal(results, conf.level, alternative, type, D)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pool_internal_+3A_results">results</code></td>
<td>
<p>a list of results i.e. the <code>x$results</code> element of an
<code>analyse</code> object created by <code><a href="#topic+analyse">analyse()</a></code>).</p>
</td></tr>
<tr><td><code id="pool_internal_+3A_conf.level">conf.level</code></td>
<td>
<p>confidence level of the returned confidence interval.
Must be a single number between 0 and 1. Default is 0.95.</p>
</td></tr>
<tr><td><code id="pool_internal_+3A_alternative">alternative</code></td>
<td>
<p>a character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or <code>"less"</code>.</p>
</td></tr>
<tr><td><code id="pool_internal_+3A_type">type</code></td>
<td>
<p>a character string of either <code>"percentile"</code> (default) or
<code>"normal"</code>. Determines what method should be used to calculate the bootstrap confidence
intervals. See details.
Only used if <code>method_condmean(type = "bootstrap")</code> was specified
in the original call to <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
<tr><td><code id="pool_internal_+3A_d">D</code></td>
<td>
<p>numeric representing the number of imputations between each bootstrap sample in the BMLMI method.</p>
</td></tr>
</table>

<hr>
<h2 id='prepare_stan_data'>Prepare input data to run the Stan model</h2><span id='topic+prepare_stan_data'></span>

<h3>Description</h3>

<p>Prepare input data to run the Stan model.
Creates / calculates all the required inputs as required by the <code style="white-space: pre;">&#8288;data{}&#8288;</code> block of the MMRM Stan program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepare_stan_data(ddat, subjid, visit, outcome, group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepare_stan_data_+3A_ddat">ddat</code></td>
<td>
<p>A design matrix</p>
</td></tr>
<tr><td><code id="prepare_stan_data_+3A_subjid">subjid</code></td>
<td>
<p>Character vector containing the subjects IDs.</p>
</td></tr>
<tr><td><code id="prepare_stan_data_+3A_visit">visit</code></td>
<td>
<p>Vector containing the visits.</p>
</td></tr>
<tr><td><code id="prepare_stan_data_+3A_outcome">outcome</code></td>
<td>
<p>Numeric vector containing the outcome variable.</p>
</td></tr>
<tr><td><code id="prepare_stan_data_+3A_group">group</code></td>
<td>
<p>Vector containing the group variable.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> The <code>group</code> argument determines which covariance matrix group the subject belongs to. If you
want all subjects to use a shared covariance matrix then set group to &quot;1&quot; for everyone.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>stan_data</code> object. A named list as per <code style="white-space: pre;">&#8288;data{}&#8288;</code> block of the related Stan file. In particular it returns:
</p>

<ul>
<li><p> N - The number of rows in the design matrix
</p>
</li>
<li><p> P - The number of columns in the design matrix
</p>
</li>
<li><p> G - The number of distinct covariance matrix groups (i.e. <code>length(unique(group))</code>)
</p>
</li>
<li><p> n_visit - The number of unique outcome visits
</p>
</li>
<li><p> n_pat - The total number of pattern groups (as defined by missingness patterns &amp; covariance group)
</p>
</li>
<li><p> pat_G - Index for which Sigma each pattern group should use
</p>
</li>
<li><p> pat_n_pt - number of patients within each pattern group
</p>
</li>
<li><p> pat_n_visit - number of non-missing visits in each pattern group
</p>
</li>
<li><p> pat_sigma_index - rows/cols from Sigma to subset on for the pattern group (padded by 0's)
</p>
</li>
<li><p> y - The outcome variable
</p>
</li>
<li><p> Q - design matrix (after QR decomposition)
</p>
</li>
<li><p> R - R matrix from the QR decomposition of the design matrix
</p>
</li></ul>


<hr>
<h2 id='print.analysis'>Print <code>analysis</code> object</h2><span id='topic+print.analysis'></span>

<h3>Description</h3>

<p>Print <code>analysis</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'analysis'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.analysis_+3A_x">x</code></td>
<td>
<p>An <code>analysis</code> object generated by <code><a href="#topic+analyse">analyse()</a></code>.</p>
</td></tr>
<tr><td><code id="print.analysis_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.draws'>Print <code>draws</code> object</h2><span id='topic+print.draws'></span>

<h3>Description</h3>

<p>Print <code>draws</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'draws'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.draws_+3A_x">x</code></td>
<td>
<p>A <code>draws</code> object generated by <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
<tr><td><code id="print.draws_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>

<hr>
<h2 id='print.imputation'>Print <code>imputation</code> object</h2><span id='topic+print.imputation'></span>

<h3>Description</h3>

<p>Print <code>imputation</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'imputation'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.imputation_+3A_x">x</code></td>
<td>
<p>An <code>imputation</code> object generated by <code><a href="#topic+impute">impute()</a></code>.</p>
</td></tr>
<tr><td><code id="print.imputation_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='progressLogger'>R6 Class for printing current sampling progress</h2><span id='topic+progressLogger'></span>

<h3>Description</h3>

<p>Object is initalised with total number of iterations that are expected to occur.
User can then update the object with the <code>add</code> method to indicate how many more iterations
have just occurred.
Every time <code>step</code> * 100 % of iterations have occurred a message is printed to the console.
Use the <code>quiet</code> argument to prevent the object from printing anything at all
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>step</code></dt><dd><p>real, percentage of iterations to allow before printing the
progress to the console</p>
</dd>
<dt><code>step_current</code></dt><dd><p>integer, the total number of iterations completed since
progress was last printed to the console</p>
</dd>
<dt><code>n</code></dt><dd><p>integer, the current number of completed iterations</p>
</dd>
<dt><code>n_max</code></dt><dd><p>integer, total number of expected iterations to be completed
acts as the denominator for calculating progress percentages</p>
</dd>
<dt><code>quiet</code></dt><dd><p>logical holds whether or not to print anything</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-progressLogger-new"><code>progressLogger$new()</code></a>
</p>
</li>
<li> <p><a href="#method-progressLogger-add"><code>progressLogger$add()</code></a>
</p>
</li>
<li> <p><a href="#method-progressLogger-print_progress"><code>progressLogger$print_progress()</code></a>
</p>
</li>
<li> <p><a href="#method-progressLogger-clone"><code>progressLogger$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-progressLogger-new"></a>



<h4>Method <code>new()</code></h4>

<p>Create progressLogger object
</p>


<h5>Usage</h5>

<div class="r"><pre>progressLogger$new(n_max, quiet = FALSE, step = 0.1)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>n_max</code></dt><dd><p>integer, sets field <code>n_max</code></p>
</dd>
<dt><code>quiet</code></dt><dd><p>logical, sets field <code>quiet</code></p>
</dd>
<dt><code>step</code></dt><dd><p>real, sets field <code>step</code></p>
</dd>
</dl>

</div>


<hr>
<a id="method-progressLogger-add"></a>



<h4>Method <code>add()</code></h4>

<p>Records that <code>n</code> more iterations have been completed
this will add that number to the current step count (<code>step_current</code>) and will
print a progress message to the log if the step limit (<code>step</code>) has been reached.
This function will do nothing if <code>quiet</code> has been set to <code>TRUE</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>progressLogger$add(n)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>n</code></dt><dd><p>the number of successfully complete iterations since <code>add()</code> was last called</p>
</dd>
</dl>

</div>


<hr>
<a id="method-progressLogger-print_progress"></a>



<h4>Method <code>print_progress()</code></h4>

<p>method to print the current state of progress
</p>


<h5>Usage</h5>

<div class="r"><pre>progressLogger$print_progress()</pre></div>


<hr>
<a id="method-progressLogger-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>progressLogger$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='pval_percentile'>P-value of percentile bootstrap</h2><span id='topic+pval_percentile'></span>

<h3>Description</h3>

<p>Determines the (not necessarily unique) quantile (type=6) of &quot;est&quot; which gives a value of 0
From this, derive the p-value corresponding to the percentile bootstrap via inversion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pval_percentile(est)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pval_percentile_+3A_est">est</code></td>
<td>
<p>a numeric vector of point estimates from each bootstrap sample.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The p-value for H_0: theta=0 vs H_A: theta&gt;0 is the value <code>alpha</code> for which <code>q_alpha = 0</code>.
If there is at least one estimate equal to zero it returns the largest <code>alpha</code> such that <code>q_alpha = 0</code>.
If all bootstrap estimates are &gt; 0 it returns 0; if all bootstrap estimates are &lt; 0 it returns 1. Analogous
reasoning is applied for the p-value for H_0: theta=0 vs H_A: theta&lt;0.
</p>


<h3>Value</h3>

<p>A named numeric vector of length 2 containing the p-value for H_0: theta=0 vs H_A: theta&gt;0
(<code>"pval_greater"</code>) and the p-value for H_0: theta=0 vs H_A: theta&lt;0 (<code>"pval_less"</code>).
</p>

<hr>
<h2 id='QR_decomp'>QR decomposition</h2><span id='topic+QR_decomp'></span>

<h3>Description</h3>

<p>QR decomposition as defined in the
<a href="https://mc-stan.org/docs/2_27/stan-users-guide/QR-reparameterization-section.html">Stan user's guide (section 1.2)</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QR_decomp(mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QR_decomp_+3A_mat">mat</code></td>
<td>
<p>A matrix to perform the QR decomposition on.</p>
</td></tr>
</table>

<hr>
<h2 id='random_effects_expr'>Construct random effects formula</h2><span id='topic+random_effects_expr'></span>

<h3>Description</h3>

<p>Constructs a character representation of the random effects formula
for fitting a MMRM for subject by visit in the format required for <code><a href="mmrm.html#topic+mmrm">mmrm::mmrm()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>random_effects_expr(
  cov_struct = c("us", "toep", "cs", "ar1"),
  cov_by_group = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="random_effects_expr_+3A_cov_struct">cov_struct</code></td>
<td>
<p>Character - The covariance structure to be used, must be one of <code>"us"</code>,
<code>"toep"</code>, <code>"cs"</code>, <code>"ar1"</code></p>
</td></tr>
<tr><td><code id="random_effects_expr_+3A_cov_by_group">cov_by_group</code></td>
<td>
<p>Boolean - Whenever or not to use separate covariances per each group level</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example assuming the user specified a covariance structure of &quot;us&quot; and that no groups
were provided this will return
</p>
<div class="sourceCode"><pre>us(visit | subjid)
</pre></div>
<p>If <code>cov_by_group</code> is set to <code>FALSE</code> then this indicates that separate covariance matrices
are required per group and as such the following will be returned:
</p>
<div class="sourceCode"><pre>us( visit | group / subjid )
</pre></div>

<hr>
<h2 id='record'>Capture all Output</h2><span id='topic+record'></span>

<h3>Description</h3>

<p>This function silences all warnings, errors &amp; messages and instead returns a list
containing the results (if it didn't error) + the warning and error messages as
character vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>record(expr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="record_+3A_expr">expr</code></td>
<td>
<p>An expression to be executed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing
</p>

<ul>
<li> <p><strong>results</strong> - The object returned by <code>expr</code> or <code>list()</code> if an error was thrown
</p>
</li>
<li> <p><strong>warnings</strong> - NULL or a character vector if warnings were thrown
</p>
</li>
<li> <p><strong>errors</strong> - NULL or a string if an error was thrown
</p>
</li>
<li> <p><strong>messages</strong> - NULL or a character vector if messages were produced
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
record({
  x &lt;- 1
  y &lt;- 2
  warning("something went wrong")
  message("O nearly done")
  x + y
})

## End(Not run)
</code></pre>

<hr>
<h2 id='recursive_reduce'>recursive_reduce</h2><span id='topic+recursive_reduce'></span>

<h3>Description</h3>

<p>Utility function used to replicated purrr::reduce. Recursively applies a
function to a list of elements until only 1 element remains
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recursive_reduce(.l, .f)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recursive_reduce_+3A_.l">.l</code></td>
<td>
<p>list of values to apply a function to</p>
</td></tr>
<tr><td><code id="recursive_reduce_+3A_.f">.f</code></td>
<td>
<p>function to apply to each each element of the list in turn
i.e. <code style="white-space: pre;">&#8288;.l[[1]] &lt;- .f( .l[[1]] , .l[[2]]) ; .l[[1]] &lt;- .f( .l[[1]] , .l[[3]])&#8288;</code></p>
</td></tr>
</table>

<hr>
<h2 id='remove_if_all_missing'>Remove subjects from dataset if they have no observed values</h2><span id='topic+remove_if_all_missing'></span>

<h3>Description</h3>

<p>This function takes a <code>data.frame</code> with variables <code>visit</code>, <code>outcome</code> &amp; <code>subjid</code>.
It then removes all rows for a given <code>subjid</code> if they don't have any non-missing
values for <code>outcome</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_if_all_missing(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_if_all_missing_+3A_dat">dat</code></td>
<td>
<p>a <code>data.frame</code></p>
</td></tr>
</table>

<hr>
<h2 id='rubin_df'>Barnard and Rubin degrees of freedom adjustment</h2><span id='topic+rubin_df'></span>

<h3>Description</h3>

<p>Compute degrees of freedom according to the Barnard-Rubin formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rubin_df(v_com, var_b, var_t, M)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rubin_df_+3A_v_com">v_com</code></td>
<td>
<p>Positive number representing the degrees of freedom in the complete-data analysis.</p>
</td></tr>
<tr><td><code id="rubin_df_+3A_var_b">var_b</code></td>
<td>
<p>Between-variance of point estimate across multiply imputed datasets.</p>
</td></tr>
<tr><td><code id="rubin_df_+3A_var_t">var_t</code></td>
<td>
<p>Total-variance of point estimate according to Rubin's rules.</p>
</td></tr>
<tr><td><code id="rubin_df_+3A_m">M</code></td>
<td>
<p>Number of imputations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation takes into account limit cases where there is no missing data
(i.e. the between-variance <code>var_b</code> is zero) or where the complete-data degrees of freedom is
set to <code>Inf</code>. Moreover, if <code>v_com</code> is given as <code>NA</code>, the function returns <code>Inf</code>.
</p>


<h3>Value</h3>

<p>Degrees of freedom according to Barnard-Rubin formula. See Barnard-Rubin (1999).
</p>


<h3>References</h3>

<p>Barnard, J. and Rubin, D.B. (1999).
Small sample degrees of freedom with multiple imputation. Biometrika, 86, 948-955.
</p>

<hr>
<h2 id='rubin_rules'>Combine estimates using Rubin's rules</h2><span id='topic+rubin_rules'></span>

<h3>Description</h3>

<p>Pool together the results from <code>M</code> complete-data analyses according to Rubin's rules. See details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rubin_rules(ests, ses, v_com)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rubin_rules_+3A_ests">ests</code></td>
<td>
<p>Numeric vector containing the point estimates from the complete-data analyses.</p>
</td></tr>
<tr><td><code id="rubin_rules_+3A_ses">ses</code></td>
<td>
<p>Numeric vector containing the standard errors from the complete-data analyses.</p>
</td></tr>
<tr><td><code id="rubin_rules_+3A_v_com">v_com</code></td>
<td>
<p>Positive number representing the degrees of freedom in the complete-data analysis.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rubin_rules</code> applies Rubin's rules (Rubin, 1987) for pooling together
the results from a multiple imputation procedure. The pooled point estimate <code>est_point</code> is
is the average across the point estimates from the complete-data analyses (given by the input argument <code>ests</code>).
The total variance <code>var_t</code> is the sum of two terms representing the within-variance
and the between-variance (see Little-Rubin (2002)). The function
also returns <code>df</code>, the estimated pooled degrees of freedom according to Barnard-Rubin (1999)
that can be used for inference based on the t-distribution.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>est_point</code>: the pooled point estimate according to Little-Rubin (2002).
</p>
</li>
<li> <p><code>var_t</code>: total variance according to Little-Rubin (2002).
</p>
</li>
<li> <p><code>df</code>: degrees of freedom according to Barnard-Rubin (1999).
</p>
</li></ul>



<h3>References</h3>

<p>Barnard, J. and Rubin, D.B. (1999).
Small sample degrees of freedom with multiple imputation. Biometrika, 86, 948-955
</p>
<p>Roderick J. A. Little and Donald B. Rubin. Statistical Analysis with Missing
Data, Second Edition. John Wiley &amp; Sons, Hoboken, New Jersey, 2002. [Section 5.4]
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rubin_df">rubin_df()</a></code> for the degrees of freedom estimation.
</p>

<hr>
<h2 id='sample_ids'>Sample Patient Ids</h2><span id='topic+sample_ids'></span>

<h3>Description</h3>

<p>Performs a stratified bootstrap sample of IDS
ensuring the return vector is the same length as the input vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_ids(ids, strata = rep(1, length(ids)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_ids_+3A_ids">ids</code></td>
<td>
<p>vector to sample from</p>
</td></tr>
<tr><td><code id="sample_ids_+3A_strata">strata</code></td>
<td>
<p>strata indicator, ids are sampled within each strata
ensuring the that the numbers of each strata are maintained</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sample_ids( c("a", "b", "c", "d"), strata = c(1,1,2,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='sample_list'>Create and validate a <code>sample_list</code> object</h2><span id='topic+sample_list'></span>

<h3>Description</h3>

<p>Given a list of <code>sample_single</code> objects generate by <code><a href="#topic+sample_single">sample_single()</a></code>,
creates a <code>sample_list</code> objects and validate it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_list(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_list_+3A_...">...</code></td>
<td>
<p>A list of <code>sample_single</code> objects.</p>
</td></tr>
</table>

<hr>
<h2 id='sample_mvnorm'>Sample random values from the multivariate normal distribution</h2><span id='topic+sample_mvnorm'></span>

<h3>Description</h3>

<p>Sample random values from the multivariate normal distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_mvnorm(mu, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_mvnorm_+3A_mu">mu</code></td>
<td>
<p>mean vector</p>
</td></tr>
<tr><td><code id="sample_mvnorm_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix
</p>
<p>Samples multivariate normal variables by multiplying
univariate random normal variables by the cholesky
decomposition of the covariance matrix.
</p>
<p>If mu is length 1 then just uses rnorm instead.</p>
</td></tr>
</table>

<hr>
<h2 id='sample_single'>Create object of <code>sample_single</code> class</h2><span id='topic+sample_single'></span>

<h3>Description</h3>

<p>Creates an object of class <code>sample_single</code> which is a named list
containing the input parameters and validate them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_single(
  ids,
  beta = NA,
  sigma = NA,
  theta = NA,
  failed = any(is.na(beta)),
  ids_samp = ids
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_single_+3A_ids">ids</code></td>
<td>
<p>Vector of characters containing the ids of the subjects included in the original dataset.</p>
</td></tr>
<tr><td><code id="sample_single_+3A_beta">beta</code></td>
<td>
<p>Numeric vector of estimated regression coefficients.</p>
</td></tr>
<tr><td><code id="sample_single_+3A_sigma">sigma</code></td>
<td>
<p>List of estimated covariance matrices (one for each level of <code>vars$group</code>).</p>
</td></tr>
<tr><td><code id="sample_single_+3A_theta">theta</code></td>
<td>
<p>Numeric vector of transformed covariances.</p>
</td></tr>
<tr><td><code id="sample_single_+3A_failed">failed</code></td>
<td>
<p>Logical. <code>TRUE</code> if the model fit failed.</p>
</td></tr>
<tr><td><code id="sample_single_+3A_ids_samp">ids_samp</code></td>
<td>
<p>Vector of characters containing the ids of the subjects included in the given sample.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of class <code>sample_single</code>. It contains the following:
</p>

<ul>
<li> <p><code>ids</code> vector of characters containing the ids of the subjects included in the original dataset.
</p>
</li>
<li> <p><code>beta</code> numeric vector of estimated regression coefficients.
</p>
</li>
<li> <p><code>sigma</code> list of estimated covariance matrices (one for each level of <code>vars$group</code>).
</p>
</li>
<li> <p><code>theta</code> numeric vector of transformed covariances.
</p>
</li>
<li> <p><code>failed</code> logical. <code>TRUE</code> if the model fit failed.
</p>
</li>
<li> <p><code>ids_samp</code> vector of characters containing the ids of the subjects included in the given sample.
</p>
</li></ul>


<hr>
<h2 id='scalerConstructor'>R6 Class for scaling (and un-scaling) design matrices</h2><span id='topic+scalerConstructor'></span>

<h3>Description</h3>

<p>Scales a design matrix so that all non-categorical columns have a mean
of 0 and an standard deviation of 1.
</p>


<h3>Details</h3>

<p>The object initialisation
is used to determine the relevant mean and SD's to scale by and then
the scaling (and un-scaling) itself is performed by the relevant object
methods.
</p>
<p>Un-scaling is done on linear model Beta and Sigma coefficients. For this purpose
the first column on the dataset to be scaled is assumed to be the outcome variable
with all other variables assumed to be post-transformation predictor variables (i.e.
all dummy variables have already been expanded).
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>centre</code></dt><dd><p>Vector of column means. The first value is the outcome
variable, all other variables are the predictors.</p>
</dd>
<dt><code>scales</code></dt><dd><p>Vector of column standard deviations. The first value is the outcome
variable, all other variables are the predictors.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-scaler-new"><code>scalerConstructor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-scaler-scale"><code>scalerConstructor$scale()</code></a>
</p>
</li>
<li> <p><a href="#method-scaler-unscale_sigma"><code>scalerConstructor$unscale_sigma()</code></a>
</p>
</li>
<li> <p><a href="#method-scaler-unscale_beta"><code>scalerConstructor$unscale_beta()</code></a>
</p>
</li>
<li> <p><a href="#method-scaler-clone"><code>scalerConstructor$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-scaler-new"></a>



<h4>Method <code>new()</code></h4>

<p>Uses <code>dat</code> to determine the relevant column means and standard deviations to use
when scaling and un-scaling future datasets. Implicitly assumes that new datasets
have the same column order as <code>dat</code>
</p>


<h5>Usage</h5>

<div class="r"><pre>scalerConstructor$new(dat)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dat</code></dt><dd><p>A <code>data.frame</code> or matrix. All columns must be numeric (i.e dummy variables,
must have already been expanded out).</p>
</dd>
</dl>

</div>



<h5>Details</h5>

<p>Categorical columns (as determined by those who's values are entirely <code>1</code> or <code>0</code>)
will not be scaled. This is achieved by setting the corresponding values of centre
to <code>0</code> and scale to <code>1</code>.
</p>


<hr>
<a id="method-scaler-scale"></a>



<h4>Method <code>scale()</code></h4>

<p>Scales a dataset so that all continuous variables have a mean of 0 and a
standard deviation of 1.
</p>


<h5>Usage</h5>

<div class="r"><pre>scalerConstructor$scale(dat)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dat</code></dt><dd><p>A <code>data.frame</code> or matrix whose columns are all numeric (i.e. dummy
variables have all been expanded out) and whose columns are in the same
order as the dataset used in the initialization function.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-scaler-unscale_sigma"></a>



<h4>Method <code>unscale_sigma()</code></h4>

<p>Unscales a sigma value (or matrix) as estimated by a linear model
using a design matrix scaled by this object. This function only
works if the first column of the initialisation <code>data.frame</code> was the outcome
variable.
</p>


<h5>Usage</h5>

<div class="r"><pre>scalerConstructor$unscale_sigma(sigma)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>sigma</code></dt><dd><p>A numeric value or matrix.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A numeric value or matrix
</p>


<hr>
<a id="method-scaler-unscale_beta"></a>



<h4>Method <code>unscale_beta()</code></h4>

<p>Unscales a beta value (or vector) as estimated by a linear model
using a design matrix scaled by this object. This function only
works if the first column of the initialization <code>data.frame</code> was the outcome
variable.
</p>


<h5>Usage</h5>

<div class="r"><pre>scalerConstructor$unscale_beta(beta)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>beta</code></dt><dd><p>A numeric vector of beta coefficients as estimated from a linear model.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A numeric vector.
</p>


<hr>
<a id="method-scaler-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>scalerConstructor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='set_simul_pars'>Set simulation parameters of a study group.</h2><span id='topic+set_simul_pars'></span>

<h3>Description</h3>

<p>This function provides input arguments for each study group needed to
simulate data with <code><a href="#topic+simulate_data">simulate_data()</a></code>. <code><a href="#topic+simulate_data">simulate_data()</a></code> generates data for a two-arms
clinical trial with longitudinal continuous outcomes and two intercurrent events (ICEs).
ICE1 may be thought of as a discontinuation from study treatment due to study drug or
condition related (SDCR) reasons. ICE2 may be thought of as discontinuation from study
treatment due to uninformative study drop-out, i.e. due to not study drug or
condition related (NSDRC) reasons and outcome data after ICE2 is always missing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_simul_pars(
  mu,
  sigma,
  n,
  prob_ice1 = 0,
  or_outcome_ice1 = 1,
  prob_post_ice1_dropout = 0,
  prob_ice2 = 0,
  prob_miss = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_simul_pars_+3A_mu">mu</code></td>
<td>
<p>Numeric vector describing the mean outcome trajectory at each visit (including
baseline) assuming no ICEs.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_sigma">sigma</code></td>
<td>
<p>Covariance matrix of the outcome trajectory assuming no ICEs.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_n">n</code></td>
<td>
<p>Number of subjects belonging to the group.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_prob_ice1">prob_ice1</code></td>
<td>
<p>Numeric vector that specifies the probability of experiencing ICE1
(discontinuation from study treatment due to SDCR reasons) after each visit for a subject
with observed outcome at that visit equal to the mean at baseline (<code>mu[1]</code>).
If a single numeric is provided, then the same probability is applied to each visit.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_or_outcome_ice1">or_outcome_ice1</code></td>
<td>
<p>Numeric value that specifies the odds ratio of experiencing ICE1 after
each visit corresponding to a +1 higher value of the observed outcome at that visit.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_prob_post_ice1_dropout">prob_post_ice1_dropout</code></td>
<td>
<p>Numeric value that specifies the probability of study
drop-out following ICE1. If a subject is simulated to drop-out after ICE1, all outcomes after
ICE1 are set to missing.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_prob_ice2">prob_ice2</code></td>
<td>
<p>Numeric that specifies an additional probability that a post-baseline
visit is affected by study drop-out. Outcome data at the subject's first simulated visit
affected by study drop-out and all subsequent visits are set to missing. This generates
a second intercurrent event ICE2, which may be thought as treatment discontinuation due to
NSDRC reasons with subsequent drop-out.
If for a subject, both ICE1 and ICE2 are simulated to occur,
then it is assumed that only the earlier of them counts.
In case both ICEs are simulated to occur at the same time, it is assumed that ICE1 counts.
This means that a single subject can experience either ICE1 or ICE2, but not both of them.</p>
</td></tr>
<tr><td><code id="set_simul_pars_+3A_prob_miss">prob_miss</code></td>
<td>
<p>Numeric value that specifies an additional probability for a given
post-baseline observation to be missing. This can be used to produce
&quot;intermittent&quot; missing values which are not associated with any ICE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the details, please see <code><a href="#topic+simulate_data">simulate_data()</a></code>.
</p>


<h3>Value</h3>

<p>A <code>simul_pars</code> object which is a named list containing the simulation parameters.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simulate_data">simulate_data()</a></code>
</p>

<hr>
<h2 id='set_vars'>Set key variables</h2><span id='topic+set_vars'></span>

<h3>Description</h3>

<p>This function is used to define the names of key variables within the <code>data.frame</code>'s
that are provided as input arguments to <code><a href="#topic+draws">draws()</a></code> and <code><a href="#topic+ancova">ancova()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_vars(
  subjid = "subjid",
  visit = "visit",
  outcome = "outcome",
  group = "group",
  covariates = character(0),
  strata = group,
  strategy = "strategy"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set_vars_+3A_subjid">subjid</code></td>
<td>
<p>The name of the &quot;Subject ID&quot; variable. A length 1 character vector.</p>
</td></tr>
<tr><td><code id="set_vars_+3A_visit">visit</code></td>
<td>
<p>The name of the &quot;Visit&quot; variable. A length 1 character vector.</p>
</td></tr>
<tr><td><code id="set_vars_+3A_outcome">outcome</code></td>
<td>
<p>The name of the &quot;Outcome&quot; variable. A length 1 character vector.</p>
</td></tr>
<tr><td><code id="set_vars_+3A_group">group</code></td>
<td>
<p>The name of the &quot;Group&quot; variable. A length 1 character vector.</p>
</td></tr>
<tr><td><code id="set_vars_+3A_covariates">covariates</code></td>
<td>
<p>The name of any covariates to be used in the context of modeling.
See details.</p>
</td></tr>
<tr><td><code id="set_vars_+3A_strata">strata</code></td>
<td>
<p>The name of the any stratification variable to be used in the context of bootstrap
sampling. See details.</p>
</td></tr>
<tr><td><code id="set_vars_+3A_strategy">strategy</code></td>
<td>
<p>The name of the &quot;strategy&quot; variable. A length 1 character vector.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In both <code><a href="#topic+draws">draws()</a></code> and <code><a href="#topic+ancova">ancova()</a></code> the <code>covariates</code> argument can be specified to indicate
which variables should be included in the imputation and analysis models respectively. If you wish
to include interaction terms these need to be manually specified i.e.
<code>covariates = c("group*visit", "age*sex")</code>. Please note that the use of the <code><a href="base.html#topic+I">I()</a></code> function to
inhibit the interpretation/conversion of objects is not supported.
</p>
<p>Currently <code>strata</code> is only used by <code><a href="#topic+draws">draws()</a></code> in combination with <code>method_condmean(type = "bootstrap")</code>
and <code>method_approxbayes()</code> in order to allow for the specification of stratified bootstrap sampling.
By default <code>strata</code> is set equal to the value of <code>group</code> as it is assumed most users will want to
preserve the group size between samples. See <code><a href="#topic+draws">draws()</a></code> for more details.
</p>
<p>Likewise, currently the <code>strategy</code> argument is only used by <code><a href="#topic+draws">draws()</a></code> to specify the name of the
strategy variable within the <code>data_ice</code> data.frame. See <code><a href="#topic+draws">draws()</a></code> for more details.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+draws">draws()</a></code>
</p>
<p><code><a href="#topic+ancova">ancova()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Using CDISC variable names as an example
set_vars(
    subjid = "usubjid",
    visit = "avisit",
    outcome = "aval",
    group = "arm",
    covariates = c("bwt", "bht", "arm * avisit"),
    strategy = "strat"
)


## End(Not run)

</code></pre>

<hr>
<h2 id='simulate_data'>Generate data</h2><span id='topic+simulate_data'></span>

<h3>Description</h3>

<p>Generate data for a two-arms clinical trial with longitudinal continuous
outcome and two intercurrent events (ICEs).
ICE1 may be thought of as a discontinuation from study treatment due to study drug or
condition related (SDCR) reasons.
ICE2 may be thought of as discontinuation from study treatment due to uninformative
study drop-out, i.e. due to not study drug or
condition related (NSDRC) reasons and outcome data after ICE2 is always missing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_data(pars_c, pars_t, post_ice1_traj, strategies = getStrategies())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_data_+3A_pars_c">pars_c</code></td>
<td>
<p>A <code>simul_pars</code> object as generated by <code><a href="#topic+set_simul_pars">set_simul_pars()</a></code>. It specifies
the simulation parameters of the control arm.</p>
</td></tr>
<tr><td><code id="simulate_data_+3A_pars_t">pars_t</code></td>
<td>
<p>A <code>simul_pars</code> object as generated by <code><a href="#topic+set_simul_pars">set_simul_pars()</a></code>. It specifies
the simulation parameters of the treatment arm.</p>
</td></tr>
<tr><td><code id="simulate_data_+3A_post_ice1_traj">post_ice1_traj</code></td>
<td>
<p>A string which specifies how observed outcomes occurring after
ICE1 are simulated.
Must target a function included in <code>strategies</code>. Possible choices are: Missing At
Random <code>"MAR"</code>, Jump to Reference <code>"JR"</code>,
Copy Reference <code>"CR"</code>, Copy Increments in Reference <code>"CIR"</code>, Last Mean Carried
Forward <code>"LMCF"</code>. User-defined strategies
could also be added. See <code><a href="#topic+getStrategies">getStrategies()</a></code> for details.</p>
</td></tr>
<tr><td><code id="simulate_data_+3A_strategies">strategies</code></td>
<td>
<p>A named list of functions. Default equal to <code><a href="#topic+getStrategies">getStrategies()</a></code>.
See <code><a href="#topic+getStrategies">getStrategies()</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data generation works as follows:
</p>

<ul>
<li><p> Generate outcome data for all visits (including baseline) from a multivariate
normal distribution with parameters <code>pars_c$mu</code> and <code>pars_c$sigma</code>
for the control arm and parameters <code>pars_t$mu</code> and <code>pars_t$sigma</code> for the treatment
arm, respectively.
Note that for a randomized trial, outcomes have the same distribution at baseline
in both treatment groups, i.e. one should set
<code>pars_c$mu[1]=pars_t$mu[1]</code> and <code>pars_c$sigma[1,1]=pars_t$sigma[1,1]</code>.
</p>
</li>
<li><p> Simulate whether ICE1 (study treatment discontinuation due to SDCR reasons) occurs
after each visit according to parameters <code>pars_c$prob_ice1</code> and <code>pars_c$or_outcome_ice1</code>
for the control arm and <code>pars_t$prob_ice1</code> and <code>pars_t$or_outcome_ice1</code> for the
treatment arm, respectively.
</p>
</li>
<li><p> Simulate drop-out following ICE1 according to <code>pars_c$prob_post_ice1_dropout</code> and
<code>pars_t$prob_post_ice1_dropout</code>.
</p>
</li>
<li><p> Simulate an additional uninformative study drop-out with probabilities <code>pars_c$prob_ice2</code>
and <code>pars_t$prob_ice2</code> at each visit. This generates a second intercurrent event ICE2, which
may be thought as treatment discontinuation due to NSDRC reasons with subsequent drop-out.
The simulated time of drop-out is the subject's first visit which is affected by
drop-out and data from this visit and all subsequent visits are consequently set to missing.
If for a subject, both ICE1 and ICE2 are simulated to occur,
then it is assumed that only the earlier of them counts.
In case both ICEs are simulated to occur at the same time, it is assumed that ICE1 counts.
This means that a single subject can experience either ICE1 or ICE2, but not both of them.
</p>
</li>
<li><p> Adjust trajectories after ICE1 according to the given assumption expressed with
the <code>post_ice1_traj</code> argument. Note that only post-ICE1 outcomes in the intervention arm can be
adjusted. Post-ICE1 outcomes from the control arm  are not adjusted.
</p>
</li>
<li><p> Simulate additional intermittent missing outcome data as per arguments <code>pars_c$prob_miss</code>
and <code>pars_t$prob_miss</code>.
</p>
</li></ul>

<p>The probability of the ICE after each visit is modeled according to the following
logistic regression model:
<code>~ 1 + I(visit == 0) + ... + I(visit == n_visits-1) + I((x-alpha))</code> where:
</p>

<ul>
<li> <p><code>n_visits</code> is the number of visits (including baseline).
</p>
</li>
<li> <p><code>alpha</code> is the baseline outcome mean.
The term <code>I((x-alpha))</code> specifies the dependency of the probability of the ICE on
the current outcome value.
The corresponding regression coefficients of the logistic model are defined as follows:
The intercept is set to 0, the coefficients corresponding to discontinuation after
each visit for a subject with outcome equal to
the mean at baseline are set according to parameters <code>pars_c$prob_ice1</code> (<code>pars_t$prob_ice1</code>),
and the regression coefficient associated with the covariate <code>I((x-alpha))</code> is set
to <code>log(pars_c$or_outcome_ice1)</code> (<code>log(pars_t$or_outcome_ice1)</code>).
</p>
</li></ul>

<p>Please note that the baseline outcome cannot be missing nor be affected by any ICEs.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> containing the simulated data. It includes the following variables:
</p>

<ul>
<li> <p><code>id</code>: Factor variable that specifies the id of each subject.
</p>
</li>
<li> <p><code>visit</code>: Factor variable that specifies the visit of each assessment. Visit <code>0</code> denotes
the baseline visit.
</p>
</li>
<li> <p><code>group</code>: Factor variable that specifies which treatment group each subject belongs to.
</p>
</li>
<li> <p><code>outcome_bl</code>: Numeric variable that specifies the baseline outcome.
</p>
</li>
<li> <p><code>outcome_noICE</code>: Numeric variable that specifies the longitudinal outcome assuming
no ICEs.
</p>
</li>
<li> <p><code>ind_ice1</code>: Binary variable that takes value <code>1</code> if the corresponding visit is
affected by ICE1 and <code>0</code> otherwise.
</p>
</li>
<li> <p><code>dropout_ice1</code>: Binary variable that takes value <code>1</code> if the corresponding visit is
affected by the drop-out following ICE1 and <code>0</code> otherwise.
</p>
</li>
<li> <p><code>ind_ice2</code>: Binary variable that takes value <code>1</code> if the corresponding visit is affected
by ICE2.
</p>
</li>
<li> <p><code>outcome</code>: Numeric variable that specifies the longitudinal outcome including ICE1, ICE2
and the intermittent missing values.
</p>
</li></ul>


<hr>
<h2 id='simulate_dropout'>Simulate drop-out</h2><span id='topic+simulate_dropout'></span>

<h3>Description</h3>

<p>Simulate drop-out
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_dropout(prob_dropout, ids, subset = rep(1, length(ids)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_dropout_+3A_prob_dropout">prob_dropout</code></td>
<td>
<p>Numeric that specifies the probability that a post-baseline visit is
affected by study drop-out.</p>
</td></tr>
<tr><td><code id="simulate_dropout_+3A_ids">ids</code></td>
<td>
<p>Factor variable that specifies the id of each subject.</p>
</td></tr>
<tr><td><code id="simulate_dropout_+3A_subset">subset</code></td>
<td>
<p>Binary variable that specifies the subset that could be affected by drop-out.
I.e. <code>subset</code> is a binary vector
of length equal to the length of <code>ids</code> that takes value <code>1</code> if the corresponding visit could
be affected by drop-out and <code>0</code> otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>subset</code> can be used to specify outcome values that cannot be affected by the
drop-out. By default
<code>subset</code> will be set to <code>1</code> for all the values except the values corresponding to the
baseline outcome, since baseline is supposed to not be affected by drop-out.
Even if <code>subset</code> is specified by the user, the values corresponding to the baseline
outcome are still hard-coded to be <code>0</code>.
</p>


<h3>Value</h3>

<p>A binary vector of length equal to the length of <code>ids</code> that takes value <code>1</code> if the
corresponding outcome is
affected by study drop-out.
</p>

<hr>
<h2 id='simulate_ice'>Simulate intercurrent event</h2><span id='topic+simulate_ice'></span>

<h3>Description</h3>

<p>Simulate intercurrent event
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_ice(outcome, visits, ids, prob_ice, or_outcome_ice, baseline_mean)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_ice_+3A_outcome">outcome</code></td>
<td>
<p>Numeric variable that specifies the longitudinal outcome for a single group.</p>
</td></tr>
<tr><td><code id="simulate_ice_+3A_visits">visits</code></td>
<td>
<p>Factor variable that specifies the visit of each assessment.</p>
</td></tr>
<tr><td><code id="simulate_ice_+3A_ids">ids</code></td>
<td>
<p>Factor variable that specifies the id of each subject.</p>
</td></tr>
<tr><td><code id="simulate_ice_+3A_prob_ice">prob_ice</code></td>
<td>
<p>Numeric vector that specifies for each visit the probability of experiencing
the ICE after the current visit for a subject with outcome equal to the mean at baseline.
If a single numeric is provided, then the same probability is applied to each visit.</p>
</td></tr>
<tr><td><code id="simulate_ice_+3A_or_outcome_ice">or_outcome_ice</code></td>
<td>
<p>Numeric value that specifies the odds ratio of the ICE corresponding to
a +1 higher value of the outcome at the visit.</p>
</td></tr>
<tr><td><code id="simulate_ice_+3A_baseline_mean">baseline_mean</code></td>
<td>
<p>Mean outcome value at baseline.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The probability of the ICE after each visit is modeled according to the following
logistic regression model:
<code>~ 1 + I(visit == 0) + ... + I(visit == n_visits-1) + I((x-alpha))</code> where:
</p>

<ul>
<li> <p><code>n_visits</code> is the number of visits (including baseline).
</p>
</li>
<li> <p><code>alpha</code> is the baseline outcome mean set via argument <code>baseline_mean</code>.
The term <code>I((x-alpha))</code> specifies the dependency of the probability of the ICE on the current
outcome value.
The corresponding regression coefficients of the logistic model are defined as follows:
The intercept is set to 0, the coefficients corresponding to discontinuation after each visit
for a subject with outcome equal to
the mean at baseline are set according to parameter <code>or_outcome_ice</code>,
and the regression coefficient associated with the covariate <code>I((x-alpha))</code> is set to
<code>log(or_outcome_ice)</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A binary variable that takes value <code>1</code> if the corresponding outcome is affected
by the ICE and <code>0</code> otherwise.
</p>

<hr>
<h2 id='simulate_test_data'>Create simulated datasets</h2><span id='topic+simulate_test_data'></span><span id='topic+as_vcov'></span>

<h3>Description</h3>

<p>Creates a longitudinal dataset in the format that <code>rbmi</code> was
designed to analyse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulate_test_data(
  n = 200,
  sd = c(3, 5, 7),
  cor = c(0.1, 0.7, 0.4),
  mu = list(int = 10, age = 3, sex = 2, trt = c(0, 4, 8), visit = c(0, 1, 2))
)

as_vcov(sd, cor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate_test_data_+3A_n">n</code></td>
<td>
<p>the number of subjects to sample. Total number of observations returned
is thus <code>n * length(sd)</code></p>
</td></tr>
<tr><td><code id="simulate_test_data_+3A_sd">sd</code></td>
<td>
<p>the standard deviations for the outcome at each visit.
i.e. the square root of the diagonal of the covariance matrix for the outcome</p>
</td></tr>
<tr><td><code id="simulate_test_data_+3A_cor">cor</code></td>
<td>
<p>the correlation coefficients between the outcome values at each visit.
See details.</p>
</td></tr>
<tr><td><code id="simulate_test_data_+3A_mu">mu</code></td>
<td>
<p>the coefficients to use to construct the mean outcome value at each visit. Must
be a named list with elements <code>int</code>, <code>age</code>, <code>sex</code>, <code>trt</code> &amp; <code>visit</code>. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of visits is determined by the size of the variance covariance matrix.
i.e. if 3 standard deviation values are provided then 3 visits per patient will be
created.
</p>
<p>The covariates in the simulated dataset are produced as follows:
</p>

<ul>
<li><p> Patients age is sampled at random from a N(0,1) distribution
</p>
</li>
<li><p> Patients sex is sampled at random with a 50/50 split
</p>
</li>
<li><p> Patients group is sampled at random but fixed so that each group has <code>n/2</code> patients
</p>
</li>
<li><p> The outcome variable is sampled from a multivariate normal distribution, see below
for details
</p>
</li></ul>

<p>The mean for the outcome variable is derived as:
</p>
<div class="sourceCode"><pre>outcome = Intercept + age + sex + visit + treatment
</pre></div>
<p>The coefficients for the intercept, age and sex are taken from <code>mu$int</code>,
<code>mu$age</code> and <code>mu$sex</code> respectively, all of which must be a length 1 numeric.
</p>
<p>Treatment and visit coefficients are taken from <code>mu$trt</code> and <code>mu$visit</code> respectively
and must either be of length 1 (i.e. a constant affect across all visits) or equal to the
number of visits (as determined by the length of <code>sd</code>). I.e. if you wanted a treatment
slope of 5 and a visit slope of 1 you could specify:
</p>
<div class="sourceCode"><pre>mu = list(..., "trt" = c(0,5,10), "visit" = c(0,1,2))
</pre></div>
<p>The correlation matrix is constructed from <code>cor</code> as follows.
Let <code>cor = c(a, b, c, d, e, f)</code> then the correlation matrix would be:
</p>
<div class="sourceCode"><pre>1  a  b  d
a  1  c  e
b  c  1  f
d  e  f  1
</pre></div>

<hr>
<h2 id='sort_by'>Sort <code>data.frame</code></h2><span id='topic+sort_by'></span>

<h3>Description</h3>

<p>Sorts a <code>data.frame</code> (ascending by default) based upon variables within the dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sort_by(df, vars = NULL, decreasing = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort_by_+3A_df">df</code></td>
<td>
<p>data.frame</p>
</td></tr>
<tr><td><code id="sort_by_+3A_vars">vars</code></td>
<td>
<p>character vector of variables</p>
</td></tr>
<tr><td><code id="sort_by_+3A_decreasing">decreasing</code></td>
<td>
<p>logical whether sort order should be in descending or ascending (default) order.
Can be either a single logical value (in which case it is applied to
all variables) or a vector which is the same length as <code>vars</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sort_by(iris, c("Sepal.Length", "Sepal.Width"), decreasing = c(TRUE, FALSE))

## End(Not run)
</code></pre>

<hr>
<h2 id='split_dim'>Transform array into list of arrays</h2><span id='topic+split_dim'></span>

<h3>Description</h3>

<p>Transform an array into list of arrays where the listing
is performed on a given dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_dim(a, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_dim_+3A_a">a</code></td>
<td>
<p>Array with number of dimensions at least 2.</p>
</td></tr>
<tr><td><code id="split_dim_+3A_n">n</code></td>
<td>
<p>Positive integer. Dimension of <code>a</code> to be listed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, if <code>a</code> is a 3 dimensional array and <code>n = 1</code>,
<code>split_dim(a,n)</code> returns a list of 2 dimensional arrays (i.e.
a list of matrices) where each element of the list is <code>a[i, , ]</code>, where
<code>i</code> takes values from 1 to the length of the first dimension of the array.
</p>
<p>Example:
</p>
<p>inputs:
<code>a &lt;- array( c(1,2,3,4,5,6,7,8,9,10,11,12), dim = c(3,2,2))</code>,
which means that:
</p>
<div class="sourceCode"><pre>a[1,,]     a[2,,]     a[3,,]

[,1] [,2]  [,1] [,2]  [,1] [,2]
---------  ---------  ---------
 1    7     2    8     3    9
 4    10    5    11    6    12
</pre></div>
<p><code>n &lt;- 1</code>
</p>
<p>output of <code>res &lt;- split_dim(a,n)</code> is a list of 3 elements:
</p>
<div class="sourceCode"><pre>res[[1]]   res[[2]]   res[[3]]

[,1] [,2]  [,1] [,2]  [,1] [,2]
---------  ---------  ---------
 1    7     2    8     3    9
 4    10    5    11    6    12
</pre></div>


<h3>Value</h3>

<p>A list of length <code>n</code> of arrays with number of dimensions equal to the
number of dimensions of <code>a</code> minus 1.
</p>

<hr>
<h2 id='split_imputations'>Split a flat list of <code><a href="#topic+imputation_single">imputation_single()</a></code> into multiple <code><a href="#topic+imputation_df">imputation_df()</a></code>'s by ID</h2><span id='topic+split_imputations'></span>

<h3>Description</h3>

<p>Split a flat list of <code><a href="#topic+imputation_single">imputation_single()</a></code> into multiple <code><a href="#topic+imputation_df">imputation_df()</a></code>'s by ID
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_imputations(list_of_singles, split_ids)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_imputations_+3A_list_of_singles">list_of_singles</code></td>
<td>
<p>A list of <code><a href="#topic+imputation_single">imputation_single()</a></code>'s</p>
</td></tr>
<tr><td><code id="split_imputations_+3A_split_ids">split_ids</code></td>
<td>
<p>A list with 1 element per required split. Each element
must contain a vector of &quot;ID&quot;'s which correspond to the <code><a href="#topic+imputation_single">imputation_single()</a></code> ID's
that are required within that sample. The total number of ID's must by equal to the
length of <code>list_of_singles</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts a list of imputations from being structured per patient
to being structured per sample i.e. it converts
</p>
<div class="sourceCode"><pre>obj &lt;- list(
    imputation_single("Ben", numeric(0)),
    imputation_single("Ben", numeric(0)),
    imputation_single("Ben", numeric(0)),
    imputation_single("Harry", c(1, 2)),
    imputation_single("Phil", c(3, 4)),
    imputation_single("Phil", c(5, 6)),
    imputation_single("Tom", c(7, 8, 9))
)

index &lt;- list(
    c("Ben", "Harry", "Phil", "Tom"),
    c("Ben", "Ben", "Phil")
)
</pre></div>
<p>Into:
</p>
<div class="sourceCode"><pre>output &lt;- list(
    imputation_df(
        imputation_single(id = "Ben", values = numeric(0)),
        imputation_single(id = "Harry", values = c(1, 2)),
        imputation_single(id = "Phil", values = c(3, 4)),
        imputation_single(id = "Tom", values = c(7, 8, 9))
    ),
    imputation_df(
        imputation_single(id = "Ben", values = numeric(0)),
        imputation_single(id = "Ben", values = numeric(0)),
        imputation_single(id = "Phil", values = c(5, 6))
    )
)
</pre></div>

<hr>
<h2 id='Stack'>R6 Class for a FIFO stack</h2><span id='topic+Stack'></span>

<h3>Description</h3>

<p>This is a simple stack object offering add / pop functionality
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>stack</code></dt><dd><p>A list containing the current stack</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Stack-add"><code>Stack$add()</code></a>
</p>
</li>
<li> <p><a href="#method-Stack-pop"><code>Stack$pop()</code></a>
</p>
</li>
<li> <p><a href="#method-Stack-clone"><code>Stack$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Stack-add"></a>



<h4>Method <code>add()</code></h4>

<p>Adds content to the end of the stack (must be a list)
</p>


<h5>Usage</h5>

<div class="r"><pre>Stack$add(x)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>x</code></dt><dd><p>content to add to the stack</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Stack-pop"></a>



<h4>Method <code>pop()</code></h4>

<p>Retrieve content from the stack
</p>


<h5>Usage</h5>

<div class="r"><pre>Stack$pop(i)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>i</code></dt><dd><p>the number of items to retrieve from the stack. If there are less than <code>i</code>
items left on the stack it will just return everything that is left.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Stack-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Stack$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='str_contains'>Does a string contain a substring</h2><span id='topic+str_contains'></span>

<h3>Description</h3>

<p>Returns a vector of <code>TRUE</code>/<code>FALSE</code> for each element of x
if it contains any element in <code>subs</code>
</p>
<p>i.e.
</p>
<div class="sourceCode"><pre>str_contains( c("ben", "tom", "harry"), c("e", "y"))
[1] TRUE FALSE TRUE
</pre></div>


<h3>Usage</h3>

<pre><code class='language-R'>str_contains(x, subs)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="str_contains_+3A_x">x</code></td>
<td>
<p>character vector</p>
</td></tr>
<tr><td><code id="str_contains_+3A_subs">subs</code></td>
<td>
<p>a character vector of substrings to look for</p>
</td></tr>
</table>

<hr>
<h2 id='strategies'>Strategies</h2><span id='topic+strategies'></span><span id='topic+strategy_MAR'></span><span id='topic+strategy_JR'></span><span id='topic+strategy_CR'></span><span id='topic+strategy_CIR'></span><span id='topic+strategy_LMCF'></span>

<h3>Description</h3>

<p>These functions are used to implement various reference based imputation
strategies by combining a subjects own distribution with that of
a reference distribution based upon which of their visits failed to meet
the Missing-at-Random (MAR) assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strategy_MAR(pars_group, pars_ref, index_mar)

strategy_JR(pars_group, pars_ref, index_mar)

strategy_CR(pars_group, pars_ref, index_mar)

strategy_CIR(pars_group, pars_ref, index_mar)

strategy_LMCF(pars_group, pars_ref, index_mar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="strategies_+3A_pars_group">pars_group</code></td>
<td>
<p>A list of parameters for the subject's group. See details.</p>
</td></tr>
<tr><td><code id="strategies_+3A_pars_ref">pars_ref</code></td>
<td>
<p>A list of parameters for the subject's reference group. See details.</p>
</td></tr>
<tr><td><code id="strategies_+3A_index_mar">index_mar</code></td>
<td>
<p>A logical vector indicating which visits meet the MAR assumption
for the subject. I.e. this identifies the observations after a non-MAR
intercurrent event (ICE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pars_group</code> and <code>pars_ref</code> both must be a list containing elements <code>mu</code> and <code>sigma</code>.
<code>mu</code> must be a numeric vector and <code>sigma</code> must be a square matrix symmetric covariance
matrix with dimensions equal to the length of <code>mu</code> and <code>index_mar</code>. e.g.
</p>
<div class="sourceCode"><pre>list(
    mu = c(1,2,3),
    sigma = matrix(c(4,3,2,3,5,4,2,4,6), nrow = 3, ncol = 3)
)
</pre></div>
<p>Users can define their own strategy functions and include them via the <code>strategies</code>
argument to <code><a href="#topic+impute">impute()</a></code> using <code><a href="#topic+getStrategies">getStrategies()</a></code>. That being said the following
strategies are available &quot;out the box&quot;:
</p>

<ul>
<li><p> Missing at Random (MAR)
</p>
</li>
<li><p> Jump to Reference (JR)
</p>
</li>
<li><p> Copy Reference (CR)
</p>
</li>
<li><p> Copy Increments in Reference (CIR)
</p>
</li>
<li><p> Last Mean Carried Forward (LMCF)
</p>
</li></ul>


<hr>
<h2 id='string_pad'>string_pad</h2><span id='topic+string_pad'></span>

<h3>Description</h3>

<p>Utility function used to replicate str_pad. Adds white space to either end
of a string to get it to equal the desired length
</p>


<h3>Usage</h3>

<pre><code class='language-R'>string_pad(x, width)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="string_pad_+3A_x">x</code></td>
<td>
<p>string</p>
</td></tr>
<tr><td><code id="string_pad_+3A_width">width</code></td>
<td>
<p>desired length</p>
</td></tr>
</table>

<hr>
<h2 id='transpose_imputations'>Transpose imputations</h2><span id='topic+transpose_imputations'></span>

<h3>Description</h3>

<p>Takes an <code>imputation_df</code> object and transposes it e.g.
</p>
<div class="sourceCode"><pre>list(
    list(id = "a", values = c(1,2,3)),
    list(id = "b", values = c(4,5,6)
    )
)
</pre></div>


<h3>Usage</h3>

<pre><code class='language-R'>transpose_imputations(imputations)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transpose_imputations_+3A_imputations">imputations</code></td>
<td>
<p>An <code>imputation_df</code> object created by <code><a href="#topic+imputation_df">imputation_df()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>becomes
</p>
<div class="sourceCode"><pre>list(
    ids = c("a", "b"),
    values = c(1,2,3,4,5,6)
)
</pre></div>

<hr>
<h2 id='transpose_results'>Transpose results object</h2><span id='topic+transpose_results'></span>

<h3>Description</h3>

<p>Transposes a Results object (as created by <code><a href="#topic+analyse">analyse()</a></code>) in order to group
the same estimates together into vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transpose_results(results, components)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transpose_results_+3A_results">results</code></td>
<td>
<p>A list of results.</p>
</td></tr>
<tr><td><code id="transpose_results_+3A_components">components</code></td>
<td>
<p>a character vector of components to extract
(i.e. <code style="white-space: pre;">&#8288;"est", "se"&#8288;</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Essentially this function takes an object of the format:
</p>
<div class="sourceCode"><pre>x &lt;- list(
    list(
        "trt1" = list(
            est = 1,
            se  = 2
        ),
        "trt2" = list(
            est = 3,
            se  = 4
        )
    ),
    list(
        "trt1" = list(
            est = 5,
            se  = 6
        ),
        "trt2" = list(
            est = 7,
            se  = 8
        )
    )
)
</pre></div>
<p>and produces:
</p>
<div class="sourceCode"><pre>list(
    trt1 = list(
        est = c(1,5),
        se = c(2,6)
    ),
    trt2 = list(
        est = c(3,7),
        se = c(4,8)
    )
)
</pre></div>

<hr>
<h2 id='transpose_samples'>Transpose samples</h2><span id='topic+transpose_samples'></span>

<h3>Description</h3>

<p>Transposes samples generated by <code><a href="#topic+draws">draws()</a></code> so that they are grouped
by <code>subjid</code> instead of by sample number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transpose_samples(samples)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transpose_samples_+3A_samples">samples</code></td>
<td>
<p>A list of samples generated by <code><a href="#topic+draws">draws()</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='validate'>Generic validation method</h2><span id='topic+validate'></span>

<h3>Description</h3>

<p>This function is used to perform assertions that an object
conforms to its expected structure and no basic assumptions
have been violated. Will throw an error if checks do not pass.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_+3A_x">x</code></td>
<td>
<p>object to be validated.</p>
</td></tr>
<tr><td><code id="validate_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to the specific validation method.</p>
</td></tr>
</table>

<hr>
<h2 id='validate_analyse_pars'>Validate analysis results</h2><span id='topic+validate_analyse_pars'></span>

<h3>Description</h3>

<p>Validates analysis results generated by <code><a href="#topic+analyse">analyse()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_analyse_pars(results, pars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_analyse_pars_+3A_results">results</code></td>
<td>
<p>A list of results generated by the analysis <code>fun</code>
used in <code><a href="#topic+analyse">analyse()</a></code>.</p>
</td></tr>
<tr><td><code id="validate_analyse_pars_+3A_pars">pars</code></td>
<td>
<p>A list of expected parameters in each of the analysis.
lists i.e. <code>c("est", "se", "df")</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='validate_datalong'>Validate a longdata object</h2><span id='topic+validate_datalong'></span><span id='topic+validate_datalong_varExists'></span><span id='topic+validate_datalong_types'></span><span id='topic+validate_datalong_notMissing'></span><span id='topic+validate_datalong_complete'></span><span id='topic+validate_datalong_unifromStrata'></span><span id='topic+validate_dataice'></span>

<h3>Description</h3>

<p>Validate a longdata object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_datalong(data, vars)

validate_datalong_varExists(data, vars)

validate_datalong_types(data, vars)

validate_datalong_notMissing(data, vars)

validate_datalong_complete(data, vars)

validate_datalong_unifromStrata(data, vars)

validate_dataice(data, data_ice, vars, update = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_datalong_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> containing the longitudinal outcome data + covariates
for multiple subjects</p>
</td></tr>
<tr><td><code id="validate_datalong_+3A_vars">vars</code></td>
<td>
<p>a <code>vars</code> object as created by <code><a href="#topic+set_vars">set_vars()</a></code></p>
</td></tr>
<tr><td><code id="validate_datalong_+3A_data_ice">data_ice</code></td>
<td>
<p>a <code>data.frame</code> containing the subjects ICE data. See <code><a href="#topic+draws">draws()</a></code> for details.</p>
</td></tr>
<tr><td><code id="validate_datalong_+3A_update">update</code></td>
<td>
<p>logical, indicates if the ICE data is being set for the first time or if an update
is being applied</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are used to validate various different parts of the longdata object
to be used in <code><a href="#topic+draws">draws()</a></code>, <code><a href="#topic+impute">impute()</a></code>, <code><a href="#topic+analyse">analyse()</a></code> and <code><a href="#topic+pool">pool()</a></code>. In particular:
</p>

<ul>
<li><p> validate_datalong_varExists - Checks that each variable listed in <code>vars</code> actually exists
in the <code>data</code>
</p>
</li>
<li><p> validate_datalong_types - Checks that the types of each key variable is as expected
i.e. that visit is a factor variable
</p>
</li>
<li><p> validate_datalong_notMissing - Checks that none of the key variables (except the outcome variable)
contain any missing values
</p>
</li>
<li><p> validate_datalong_complete - Checks that <code>data</code> is complete i.e. there is 1 row for each subject *
visit combination. e.g. that <code>nrow(data) == length(unique(subjects)) * length(unique(visits))</code>
</p>
</li>
<li><p> validate_datalong_unifromStrata - Checks to make sure that any variables listed as stratification
variables do not vary over time. e.g. that subjects don't switch between stratification groups.
</p>
</li></ul>


<hr>
<h2 id='validate_strategies'>Validate user specified strategies</h2><span id='topic+validate_strategies'></span>

<h3>Description</h3>

<p>Compares the user provided strategies to those that are
required (the reference). Will throw an error if not all values
of reference have been defined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_strategies(strategies, reference)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_strategies_+3A_strategies">strategies</code></td>
<td>
<p>named list of strategies.</p>
</td></tr>
<tr><td><code id="validate_strategies_+3A_reference">reference</code></td>
<td>
<p>list or character vector of strategies that need to be defined.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Will throw an error if there is an issue otherwise will return <code>TRUE</code>.
</p>

<hr>
<h2 id='validate.analysis'>Validate <code>analysis</code> objects</h2><span id='topic+validate.analysis'></span>

<h3>Description</h3>

<p>Validates the return object of the <code><a href="#topic+analyse">analyse()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'analysis'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.analysis_+3A_x">x</code></td>
<td>
<p>An <code>analysis</code> results object (of class <code>"jackknife"</code>, <code>"bootstrap"</code>, <code>"rubin"</code>).</p>
</td></tr>
<tr><td><code id="validate.analysis_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='validate.draws'>Validate <code>draws</code> object</h2><span id='topic+validate.draws'></span>

<h3>Description</h3>

<p>Validate <code>draws</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'draws'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.draws_+3A_x">x</code></td>
<td>
<p>A <code>draws</code> object generated by <code><a href="#topic+as_draws">as_draws()</a></code>.</p>
</td></tr>
<tr><td><code id="validate.draws_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='validate.is_mar'>Validate <code>is_mar</code> for a given subject</h2><span id='topic+validate.is_mar'></span>

<h3>Description</h3>

<p>Checks that the longitudinal data for a patient is divided in MAR
followed by non-MAR data; a non-MAR observation followed by a MAR
observation is not allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'is_mar'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.is_mar_+3A_x">x</code></td>
<td>
<p>Object of class <code>is_mar</code>. Logical vector indicating whether observations are MAR.</p>
</td></tr>
<tr><td><code id="validate.is_mar_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Will error if there is an issue otherwise will return <code>TRUE</code>.
</p>

<hr>
<h2 id='validate.ivars'>Validate inputs for <code>vars</code></h2><span id='topic+validate.ivars'></span>

<h3>Description</h3>

<p>Checks that the required variable names are defined within <code>vars</code> and
are of appropriate datatypes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ivars'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.ivars_+3A_x">x</code></td>
<td>
<p>named list indicating the names of key variables in the source dataset</p>
</td></tr>
<tr><td><code id="validate.ivars_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>

<hr>
<h2 id='validate.references'>Validate user supplied references</h2><span id='topic+validate.references'></span>

<h3>Description</h3>

<p>Checks to ensure that the user specified references are
expect values (i.e. those found within the source data).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'references'
validate(x, control, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.references_+3A_x">x</code></td>
<td>
<p>named character vector.</p>
</td></tr>
<tr><td><code id="validate.references_+3A_control">control</code></td>
<td>
<p>factor variable (should be the <code>group</code> variable from the source dataset).</p>
</td></tr>
<tr><td><code id="validate.references_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Will error if there is an issue otherwise will return <code>TRUE</code>.
</p>

<hr>
<h2 id='validate.sample_list'>Validate <code>sample_list</code> object</h2><span id='topic+validate.sample_list'></span>

<h3>Description</h3>

<p>Validate <code>sample_list</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sample_list'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.sample_list_+3A_x">x</code></td>
<td>
<p>A <code>sample_list</code> object generated by <code><a href="#topic+sample_list">sample_list()</a></code>.</p>
</td></tr>
<tr><td><code id="validate.sample_list_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='validate.sample_single'>Validate <code>sample_single</code> object</h2><span id='topic+validate.sample_single'></span>

<h3>Description</h3>

<p>Validate <code>sample_single</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sample_single'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.sample_single_+3A_x">x</code></td>
<td>
<p>A <code>sample_single</code> object generated by <code><a href="#topic+sample_single">sample_single()</a></code>.</p>
</td></tr>
<tr><td><code id="validate.sample_single_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='validate.simul_pars'>Validate a <code>simul_pars</code> object</h2><span id='topic+validate.simul_pars'></span>

<h3>Description</h3>

<p>Validate a <code>simul_pars</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'simul_pars'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.simul_pars_+3A_x">x</code></td>
<td>
<p>An <code>simul_pars</code> object as generated by <code><a href="#topic+set_simul_pars">set_simul_pars()</a></code>.</p>
</td></tr>
<tr><td><code id="validate.simul_pars_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

<hr>
<h2 id='validate.stan_data'>Validate a <code>stan_data</code> object</h2><span id='topic+validate.stan_data'></span>

<h3>Description</h3>

<p>Validate a <code>stan_data</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'stan_data'
validate(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate.stan_data_+3A_x">x</code></td>
<td>
<p>A <code>stan_data</code> object.</p>
</td></tr>
<tr><td><code id="validate.stan_data_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
