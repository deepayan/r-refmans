<!DOCTYPE html><html><head><title>Help for package sdcMicro</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sdcMicro}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#addGhostVars'><p>addGhostVars</p></a></li>
<li><a href='#addNoise'><p>Adding noise to perturb data</p></a></li>
<li><a href='#argus_microaggregation'><p>argus_microaggregation</p></a></li>
<li><a href='#argus_rankswap'><p>argus_rankswap</p></a></li>
<li><a href='#calcRisks'><p>Recompute Risk and Frequencies for a sdcMicroObj</p></a></li>
<li><a href='#casc1'><p>Small Artificial Data set</p></a></li>
<li><a href='#CASCrefmicrodata'><p>Census data set</p></a></li>
<li><a href='#createDat'><p>Dummy Dataset for Record Swapping</p></a></li>
<li><a href='#createNewID'><p>Creates new randomized IDs</p></a></li>
<li><a href='#dataGen'><p>Fast generation of synthetic data</p></a></li>
<li><a href='#distributeDraws_cpp'><p>Distribute number of swaps</p></a></li>
<li><a href='#distributeRandom_cpp'><p>Distribute</p></a></li>
<li><a href='#dRisk'><p>overal disclosure risk</p></a></li>
<li><a href='#dRiskRMD'><p>RMD based disclosure risk</p></a></li>
<li><a href='#dUtility'><p>Data-Utility measures</p></a></li>
<li><a href='#EIA'><p>EIA data set</p></a></li>
<li><a href='#extractManipData'><p>Remove certain variables from the data set inside a sdc object.</p></a></li>
<li><a href='#francdat'><p>data from the casc project</p></a></li>
<li><a href='#free1'><p>Demo data set from mu-Argus</p></a></li>
<li><a href='#freq'><p>Freq</p></a></li>
<li><a href='#freqCalc'><p>Frequencies calculation for risk estimation</p></a></li>
<li><a href='#generateStrata'><p>Generate one strata variable from multiple factors</p></a></li>
<li><a href='#get.sdcMicroObj'><p>get.sdcMicroObj</p></a></li>
<li><a href='#globalRecode'><p>Global Recoding</p></a></li>
<li><a href='#groupAndRename'><p>Join levels of a variables in an object of class</p>
<code>sdcMicroObj-class</code> or <code>factor</code> or <code>data.frame</code></a></li>
<li><a href='#IL_correl'><p>Additional Information-Loss measures</p></a></li>
<li><a href='#importProblem'><p>importProblem</p></a></li>
<li><a href='#indivRisk'><p>Individual Risk computation</p></a></li>
<li><a href='#infoLoss'><p>Calculate information loss after targeted record swapping</p></a></li>
<li><a href='#kAnon_violations'><p><code>kAnon_violations</code></p></a></li>
<li><a href='#LocalRecProg'><p>Local recoding via Edmond's maximum weighted matching algorithm</p></a></li>
<li><a href='#localSupp'><p>Local Suppression</p></a></li>
<li><a href='#localSuppression'><p>Local Suppression to obtain k-anonymity</p></a></li>
<li><a href='#mafast'><p>Fast and Simple Microaggregation</p></a></li>
<li><a href='#measure_risk'><p>Disclosure Risk for Categorical Variables</p></a></li>
<li><a href='#mergeHouseholdData'><p>Replaces the raw household-level data with the anonymized household-level data in the full dataset</p>
for anonymization of data with a household structure (or other hierarchical structure).
Requires a matching household ID in both files.</a></li>
<li><a href='#microaggregation'><p>Microaggregation</p></a></li>
<li><a href='#microaggrGower'><p>Microaggregation for numerical and categorical key variables based on a</p>
distance similar to the Gower Distance</a></li>
<li><a href='#microData'><p>microData</p></a></li>
<li><a href='#modRisk'><p>Global risk using log-linear models.</p></a></li>
<li><a href='#mvTopCoding'><p>Detection and winsorization of multivariate outliers</p></a></li>
<li><a href='#nextSdcObj'><p>nextSdcObj</p></a></li>
<li><a href='#orderData_cpp'><p>Reorder data</p></a></li>
<li><a href='#plot.localSuppression'><p>Plots for localSuppression objects</p></a></li>
<li><a href='#plot.sdcMicroObj'><p>Plotfunctions for objects of class sdcMicroObj</p></a></li>
<li><a href='#plotMicro'><p>Comparison plots</p></a></li>
<li><a href='#pram'><p>Post Randomization</p></a></li>
<li><a href='#print.freqCalc'><p>Print method for objects from class freqCalc.</p></a></li>
<li><a href='#print.indivRisk'><p>Print method for objects from class indivRisk</p></a></li>
<li><a href='#print.localSuppression'><p>Print method for objects from class localSuppression</p></a></li>
<li><a href='#print.micro'><p>Print method for objects from class micro</p></a></li>
<li><a href='#print.modrisk'><p>Print method for objects from class modrisk</p></a></li>
<li><a href='#print.pram'><p>Print method for objects from class pram</p></a></li>
<li><a href='#print.sdcMicroObj'><p>Print and Extractor Functions for objects of class <code>sdcMicroObj-class</code></p></a></li>
<li><a href='#print.suda2'><p>Print method for objects from class suda2</p></a></li>
<li><a href='#randSample_cpp'><p>Random Sampling</p></a></li>
<li><a href='#rankSwap'><p>Rank Swapping</p></a></li>
<li><a href='#readMicrodata'><p>readMicrodata</p></a></li>
<li><a href='#recordSwap'><p>Targeted Record Swapping</p></a></li>
<li><a href='#recordSwap_cpp'><p>Targeted Record Swapping</p></a></li>
<li><a href='#removeDirectID'><p>Remove certain variables from the data set inside a sdc object.</p></a></li>
<li><a href='#report'><p>Generate an Html-report from an sdcMicroObj</p></a></li>
<li><a href='#riskyCells'><p>riskyCells</p></a></li>
<li><a href='#sampleDonor_cpp'><p>Random sample for donor records</p></a></li>
<li><a href='#sdcApp'><p>sdcApp</p></a></li>
<li><a href='#sdcMicro-package'><p>sdcMicro: Statistical Disclosure Control Methods for Anonymization of Data and Risk Estimation</p></a></li>
<li><a href='#sdcMicroObj-class'><p>Class <code>"sdcMicroObj"</code></p></a></li>
<li><a href='#selectHouseholdData'><p>Creates a household level file from a dataset with a household structure.</p></a></li>
<li><a href='#set.sdcMicroObj'><p>set.sdcMicroObj</p></a></li>
<li><a href='#setLevels_cpp'><p>Define Swap-Levels</p></a></li>
<li><a href='#setRisk_cpp'><p>Calculate Risk</p></a></li>
<li><a href='#show,sdcMicroObj-method'><p>Show</p></a></li>
<li><a href='#shuffle'><p>Shuffling and EGADP</p></a></li>
<li><a href='#subsetMicrodata'><p>subsetMicrodata</p></a></li>
<li><a href='#suda2'><p>Suda2: Detecting Special Uniques</p></a></li>
<li><a href='#summary.freqCalc'><p>Summary method for objects from class freqCalc</p></a></li>
<li><a href='#summary.micro'><p>Summary method for objects from class micro</p></a></li>
<li><a href='#summary.pram'><p>Summary method for objects from class pram</p></a></li>
<li><a href='#Tarragona'><p>Tarragona data set</p></a></li>
<li><a href='#testdata'><p>A real-world data set on household income and expenditures</p></a></li>
<li><a href='#topBotCoding'><p>Top and Bottom Coding</p></a></li>
<li><a href='#valTable'><p>Comparison of different microaggregation methods</p></a></li>
<li><a href='#varToFactor'><p>Change the a keyVariable of an object of class <code>sdcMicroObj-class</code> from Numeric to</p>
Factor or from Factor to Numeric</a></li>
<li><a href='#writeSafeFile'><p>writeSafeFile</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Disclosure Control Methods for Anonymization of Data
and Risk Estimation</td>
</tr>
<tr>
<td>Version:</td>
<td>5.7.8</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-09</td>
</tr>
<tr>
<td>Description:</td>
<td>Data from statistical agencies and other institutions are mostly
    confidential. This package, introduced in Templ, Kowarik and Meindl (2017) &lt;<a href="https://doi.org/10.18637%2Fjss.v067.i04">doi:10.18637/jss.v067.i04</a>&gt;, can be used for the generation of anonymized
    (micro)data, i.e. for the creation of public- and scientific-use files.
    The theoretical basis for the methods implemented can be found in Templ (2017) &lt;<a href="https://doi.org/10.1007%2F978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>&gt;.
    Various risk estimation and anonymization methods are included. Note that the package
    includes a graphical user interface published in Meindl and Templ (2019) &lt;<a href="https://doi.org/10.3390%2Fa12090191">doi:10.3390/a12090191</a>&gt; that allows to use various methods of this
    package.</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>laeken,testthat</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, stats, graphics, car, carData, rmarkdown, knitr,
data.table, xtable, robustbase, cluster, MASS, e1071, tools,
Rcpp, methods, ggplot2, shiny (&ge; 1.4.0), haven, rhandsontable,
DT, shinyBS, prettydoc, VIM(&ge; 4.7.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/sdcTools/sdcMicro">https://github.com/sdcTools/sdcMicro</a></td>
</tr>
<tr>
<td>Collate:</td>
<td>'0classes.r' 'addGhostVars.R' 'addNoise.r' 'aux_functions.r'
'createDat.R' 'createNewID.R' 'dataGen.r' 'dataSets.R'
'dRisk.R' 'dRiskRMD.R' 'dUtility.R' 'freqCalc.r'
'globalRecode.R' 'groupAndRename.R' 'GUIfunctions.R'
'indivRisk.R' 'infoLoss.R' 'LocalRecProg.R' 'localSupp.R'
'localSuppression.R' 'mdav.R' 'measure_risk.R' 'methods.r'
'microaggregation.R' 'modRisk.R'
'muargus_compatibility_functions.R' 'mvTopCoding.R'
'plotFunctions.R' 'plotMicro.R' 'pram.R' 'rankSwap.R'
'RcppExports.R' 'recordSwap.R' 'report.R' 'riskyCells.R'
'sdcMicro-package.R' 'shuffle.R' 'suda2.R' 'timeEstimation.R'
'topBotCoding.R' 'valTable.R' 'zzz.R' 'printFunctions.R'
'mafast.R' 'maG.R' 'sdcApp.R' 'show_sdcMicroObj.R'</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-10 12:00:14 UTC; matthias</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthias Templ <a href="https://orcid.org/0000-0002-8638-5276"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Bernhard Meindl [aut],
  Alexander Kowarik <a href="https://orcid.org/0000-0001-8598-4130"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Johannes Gussenbauer [aut],
  Organisation For Economic Co-Operation And Development [cph] (Initial
    published c(++) code (under LGPL) code for rank swapping,
    mdav-microaggregation, suda2 and other (hierarchical) risk
    measures),
  Statistics Netherlands [cph] (microAggregation cpp code (under EUPL
    v1.1)),
  Pascal Heus [cph] (original measure threshold cpp code (under LGPL))</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Matthias Templ &lt;matthias.templ@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-11 19:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='addGhostVars'>addGhostVars</h2><span id='topic+addGhostVars'></span>

<h3>Description</h3>

<p>specify variables that are <code>linked</code> to a key variable. This results in all
suppressions of the key-variable being also applied on the corresponding 'ghost'-variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addGhostVars(obj, keyVar, ghostVars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addGhostVars_+3A_obj">obj</code></td>
<td>
<p>an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="addGhostVars_+3A_keyvar">keyVar</code></td>
<td>
<p>character-vector of length 1 refering to a categorical key variable within <code>obj</code>.</p>
</td></tr>
<tr><td><code id="addGhostVars_+3A_ghostvars">ghostVars</code></td>
<td>
<p>a character vector specifying variables that are linked to <code>keyVar</code>. Variables listed here must not be be listed in either slots
<code>@keyVars</code>, <code>@numVars</code>, <code>@pramVars</code>, <code>@weightVar</code>, <code>@hhId</code> or <code>@strataVar</code> in <code>obj</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object.
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>References</h3>

<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4. <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
## we want to link the anonymization status of key variabe 'urbrur' to 'hhcivil'
sdc &lt;- addGhostVars(sdc, keyVar="urbrur", ghostVars=c("hhcivil"))
## we want to link the anonymization status of key variabe 'roof' to 'represent'
sdc &lt;- addGhostVars(sdc, keyVar="roof", ghostVars=c("represent"))
</code></pre>

<hr>
<h2 id='addNoise'>Adding noise to perturb data</h2><span id='topic+addNoise'></span>

<h3>Description</h3>

<p>Various methods for adding noise to perturb continuous scaled variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>addNoise(obj, variables = NULL, noise = 150, method = "additive", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="addNoise_+3A_obj">obj</code></td>
<td>
<p>either a <code>data.frame</code> or a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> that should be perturbed</p>
</td></tr>
<tr><td><code id="addNoise_+3A_variables">variables</code></td>
<td>
<p>vector with names of variables that should be perturbed</p>
</td></tr>
<tr><td><code id="addNoise_+3A_noise">noise</code></td>
<td>
<p>amount of noise (in percentages)</p>
</td></tr>
<tr><td><code id="addNoise_+3A_method">method</code></td>
<td>
<p>choose between &lsquo;additive&rsquo;, &lsquo;correlated&rsquo;,
&lsquo;correlated2&rsquo;, &lsquo;restr&rsquo;, &lsquo;ROMM&rsquo;, &lsquo;outdect&rsquo;</p>
</td></tr>
<tr><td><code id="addNoise_+3A_...">...</code></td>
<td>
<p>see possible arguments below</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If &lsquo;obj&rsquo; is of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>, all continuous key
variables are selected per default. If &lsquo;obj&rsquo; is of class
&ldquo;data.frame&rdquo; or &ldquo;matrix&rdquo;, the continuous variables have to be
specified.
</p>
<p>Method &lsquo;additive&rsquo; adds noise completely at random to each variable
depending on its size and standard deviation. &lsquo;correlated&rsquo; and
method &lsquo;correlated2&rsquo; adds noise and preserves the covariances as
described in R. Brand (2001) or in the reference given below. Method
&lsquo;restr&rsquo; takes the sample size into account when adding noise. Method
&lsquo;ROMM&rsquo; is an implementation of the algorithm ROMM (Random
Orthogonalized Matrix Masking) (Fienberg, 2004).  Method &lsquo;outdect&rsquo;
adds noise only to outliers. The outliers are identified with univariate
and robust multivariate procedures based on a robust mahalanobis distances
calculated by the MCD estimator.
</p>


<h3>Value</h3>

<p>If &lsquo;obj&rsquo; was of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> the corresponding
slots are filled, like manipNumVars, risk and utility.
</p>
<p>If &lsquo;obj&rsquo; was of class &ldquo;data.frame&rdquo; or &ldquo;matrix&rdquo; an
object of class &ldquo;micro&rdquo; with following entities is returned:
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p> the original data </p>
</td></tr>
<tr><td><code>xm</code></td>
<td>
<p> the modified (perturbed) data</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>method used for perturbation</p>
</td></tr>
<tr><td><code>noise</code></td>
<td>
<p>amount of noise</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ and Bernhard Meindl
</p>


<h3>References</h3>

<p>Domingo-Ferrer, J. and Sebe, F. and Castella, J., &ldquo;On the
security of noise addition for privacy in statistical databases&rdquo;, Lecture
Notes in Computer Science, vol. 3050, pp. 149-161, 2004.  ISSN 0302-9743.
Vol. Privacy in Statistical Databases, eds. J. Domingo-Ferrer and V. Torra,
Berlin: Springer-Verlag.
</p>
<p>Ting, D. Fienberg, S.E. and Trottini, M. &ldquo;ROMM Methodology for
Microdata Release&rdquo; Joint UNECE/Eurostat work session on statistical data
confidentiality, Geneva, Switzerland, 2005,
<a href="https://www.unece.org/fileadmin/DAM/stats/documents/ece/ces/ge.46/2005/wp.11.e.pdf">https://www.unece.org/fileadmin/DAM/stats/documents/ece/ces/ge.46/2005/wp.11.e.pdf</a>
</p>
<p>Ting, D., Fienberg, S.E., Trottini, M.  &ldquo;Random orthogonal matrix
masking methodology for microdata release&rdquo;, International Journal of
Information and Computer Security, vol. 2, pp. 86-105, 2008.
</p>
<p>Templ, M. and Meindl, B., <em>Robustification of Microdata Masking Methods
and the Comparison with Existing Methods</em>, Lecture Notes in Computer
Science, Privacy in Statistical Databases, vol. 5262, pp. 177-189, 2008.
</p>
<p>Templ, M.  <em>New Developments in Statistical Disclosure Control and
Imputation: Robust Statistics Applied to Official Statistics</em>,
Suedwestdeutscher Verlag fuer Hochschulschriften, 2009, ISBN: 3838108280,
264 pages.
</p>
<p>Templ, M. and Meindl, B. and Kowarik, A.: <em>Statistical Disclosure Control for
Micro-Data Using the R Package sdcMicro</em>, Journal of Statistical Software,
67 (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>, <code><a href="#topic+summary.micro">summary.micro</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Tarragona)

a1 &lt;- addNoise(Tarragona)
a1


data(testdata)

# donttest because Examples with CPU time &gt; 2.5 times elapsed time
testdata[, c('expend','income','savings')] &lt;-
addNoise(testdata[,c('expend','income','savings')])$xm

## for objects of class sdcMicroObj:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- addNoise(sdc)

</code></pre>

<hr>
<h2 id='argus_microaggregation'>argus_microaggregation</h2><span id='topic+argus_microaggregation'></span>

<h3>Description</h3>

<p>calls microaggregation code from mu-argus. In case only one variable should be
microaggregated and <code>useOptimal</code> is <code>TRUE</code>, Hansen-Mukherjee polynomial exact method
is applied. In any other case, the Mateo-Domingo method is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>argus_microaggregation(df, k, useOptimal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="argus_microaggregation_+3A_df">df</code></td>
<td>
<p>a <code>data.frame</code> with only numerical columns</p>
</td></tr>
<tr><td><code id="argus_microaggregation_+3A_k">k</code></td>
<td>
<p>required group size</p>
</td></tr>
<tr><td><code id="argus_microaggregation_+3A_useoptimal">useOptimal</code></td>
<td>
<p>(logical) should optimal microaggregation be applied (ony possible in
in case of one variable)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code> with two elements
</p>

<ul>
<li><p>original:  the originally provided input data
</p>
</li>
<li><p>microaggregated:  the microaggregated data.frame
</p>
</li></ul>



<h3>See Also</h3>

<p>mu-Argus manual at <a href="https://github.com/sdcTools/manuals/raw/master/mu-argus/MUmanual5.1.pdf">https://github.com/sdcTools/manuals/raw/master/mu-argus/MUmanual5.1.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(sample(1:100, 50, replace=TRUE), nrow=10, ncol=5)
df &lt;- as.data.frame(mat)
res &lt;- argus_microaggregation(df, k=5, useOptimal=FALSE)
</code></pre>

<hr>
<h2 id='argus_rankswap'>argus_rankswap</h2><span id='topic+argus_rankswap'></span>

<h3>Description</h3>

<p>argus_rankswap
</p>


<h3>Usage</h3>

<pre><code class='language-R'>argus_rankswap(df, perc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="argus_rankswap_+3A_df">df</code></td>
<td>
<p>a <code>data.frame</code> with only numerical columns</p>
</td></tr>
<tr><td><code id="argus_rankswap_+3A_perc">perc</code></td>
<td>
<p>a number defining the swapping percantage</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>list</code> with two elements
</p>

<ul>
<li><p>original:  the originally provided input data
</p>
</li>
<li><p>swapped:  the <code>data.frame</code> containing the swapped values
</p>
</li></ul>



<h3>See Also</h3>

<p>mu-Argus manual at <a href="https://github.com/sdcTools/manuals/raw/master/mu-argus/MUmanual5.1.pdf">https://github.com/sdcTools/manuals/raw/master/mu-argus/MUmanual5.1.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mat &lt;- matrix(sample(1:100, 50, replace=TRUE), nrow=10, ncol=5)
df &lt;- as.data.frame(mat)
res &lt;- argus_rankswap(df, perc=10)
</code></pre>

<hr>
<h2 id='calcRisks'>Recompute Risk and Frequencies for a sdcMicroObj</h2><span id='topic+calcRisks'></span>

<h3>Description</h3>

<p>Recomputation of Risk should be done after manual changing the content of an
object of class <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcRisks(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calcRisks_+3A_obj">obj</code></td>
<td>
<p>a <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> object</p>
</td></tr>
<tr><td><code id="calcRisks_+3A_...">...</code></td>
<td>
<p>no arguments at the moment</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By applying this function, the dislosure risk is re-estimated and the
corresponding slots of an object of class <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> are updated.
This function mostly used internally to automatically update the risk after
an sdc method is applied.
</p>


<h3>Value</h3>

<p>a <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> object with updated risk values
</p>


<h3>See Also</h3>

<p><a href="#topic+sdcMicroObj-class">sdcMicroObj</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- calcRisks(sdc)

</code></pre>

<hr>
<h2 id='casc1'>Small Artificial Data set</h2><span id='topic+casc1'></span>

<h3>Description</h3>

<p>Small Toy Example Data set which was used by Sanz-Mateo et.al.
</p>


<h3>Format</h3>

<p>The format is: int [1:13, 1:7] 10 12 17 21 9 12 12 14 13 15 ...  -
attr(*, &quot;dimnames&quot;)=List of 2 ..$ : chr [1:13] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...  ..$ :
chr [1:7] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(casc1)
casc1

</code></pre>

<hr>
<h2 id='CASCrefmicrodata'>Census data set</h2><span id='topic+CASCrefmicrodata'></span>

<h3>Description</h3>

<p>This test data set was obtained on July 27, 2000 using the public use Data
Extraction System of the U.S. Bureau of the Census.
</p>


<h3>Format</h3>

<p>A data frame sampled from year 1995 with 1080 observations on the
following 13 variables.  </p>

<dl>
<dt>AFNLWGT</dt><dd><p>Final weight (2 implied decimal places)</p>
</dd>
<dt>AGI</dt><dd><p>Adjusted gross income</p>
</dd>
<dt>EMCONTRB</dt><dd><p>Employer contribution for hlth insurance</p>
</dd>
<dt>FEDTAX</dt><dd><p>Federal income tax liability</p>
</dd>
<dt>PTOTVAL</dt><dd><p>Total person income</p>
</dd>
<dt>STATETAX</dt><dd><p>State income tax liability</p>
</dd>
<dt>TAXINC</dt><dd><p>Taxable income amount</p>
</dd>
<dt>POTHVAL</dt><dd><p>Total other persons income</p>
</dd>
<dt>INTVAL</dt><dd><p>Amt of interest income</p>
</dd>
<dt>PEARNVAL</dt><dd><p>Total person earnings</p>
</dd>
<dt>FICA</dt><dd><p>Soc. sec. retirement payroll deduction</p>
</dd>
<dt>WSALVAL</dt><dd><p>Amount: Total Wage and salary</p>
</dd>
<dt>ERNVAL</dt><dd><p>Business or Farm net earnings</p>
</dd></dl>



<h3>Source</h3>

<p>Public use file from the CASC project.  More information on this
test data can be found in the paper listed below.
</p>


<h3>References</h3>

<p>Brand, R. and Domingo-Ferrer, J. and Mateo-Sanz, J.M., Reference
data sets to test and compare SDC methods for protection of numerical
microdata.  Unpublished.
<a href="https://research.cbs.nl/casc/CASCrefmicrodata.pdf">https://research.cbs.nl/casc/CASCrefmicrodata.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(CASCrefmicrodata)
str(CASCrefmicrodata)

</code></pre>

<hr>
<h2 id='createDat'>Dummy Dataset for Record Swapping</h2><span id='topic+createDat'></span>

<h3>Description</h3>

<p>createDat() returns dummy data to illustrate
targeted record swapping. The generated data contain
household ids ('hid'), geographic variables
('nuts1', 'nuts2', 'nuts3', 'lau2') as well as some
other household or personal variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createDat(N = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createDat_+3A_n">N</code></td>
<td>
<p>integer, number of household to generate</p>
</td></tr>
</table>


<h3>Value</h3>

<p>'data.table' containing dummy data
</p>


<h3>See Also</h3>

<p>recordSwap
</p>

<hr>
<h2 id='createNewID'>Creates new randomized IDs</h2><span id='topic+createNewID'></span>

<h3>Description</h3>

<p>This is useful if the record IDs consist, for example, of a geo identifier and the household line number.
This method can be used to create new, random IDs that cannot be reconstructed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createNewID(obj, newID, withinVar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createNewID_+3A_obj">obj</code></td>
<td>
<p>an <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object</p>
</td></tr>
<tr><td><code id="createNewID_+3A_newid">newID</code></td>
<td>
<p>a character specifiying the desired variable name of the new ID</p>
</td></tr>
<tr><td><code id="createNewID_+3A_withinvar">withinVar</code></td>
<td>
<p>if not <code>NULL</code> a character vector specifying a variable (e.g an existing household ID) which
will be used when calculating the new IDs. If specified, the same IDs will be assigned to the same values of the given variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object with updated slot <code>origData</code>
</p>

<hr>
<h2 id='dataGen'>Fast generation of synthetic data</h2><span id='topic+dataGen'></span>

<h3>Description</h3>

<p>Fast generation of (primitive) synthetic multivariate normal data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataGen(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataGen_+3A_obj">obj</code></td>
<td>
<p>an <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="dataGen_+3A_...">...</code></td>
<td>
<p>see possible arguments below
</p>

<dl>
<dt>n:</dt><dd><p> amount of observations for the generated data, defaults to 200</p>
</dd>
<dt>use:</dt><dd><p> howto compute covariances in case of missing values, see also argument <code>use</code> in <code><a href="stats.html#topic+cov">cov</a></code>.
The default choice is 'everything', other possible choices are 'all.obs', 'complete.obs', 'na.or.complete' or 'pairwise.complete.obs'.</p>
</dd></dl>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses the cholesky decomposition to generate synthetic data with approx. the
same means and covariances. For details see at the reference.
</p>


<h3>Value</h3>

<p>the generated synthetic data.
</p>


<h3>Note</h3>

<p>With this method only multivariate normal distributed data with
approxiomately the same covariance as the original data can be generated
without reflecting the distribution of real complex data, which are, in
general, not follows a multivariate normal distribution.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Mateo-Sanz, Martinez-Balleste, Domingo-Ferrer. Fast Generation of Accurate Synthetic Microdata. 
International Workshop on Privacy in Statistical Databases PSD 2004: Privacy in Statistical Databases, pp 298-306.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>, <code><a href="#topic+shuffle">shuffle</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(mtcars)

cov(mtcars[,4:6])
cov(dataGen(mtcars[,4:6]))
pairs(mtcars[,4:6])
pairs(dataGen(mtcars[,4:6]))

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- dataGen(sdc)

</code></pre>

<hr>
<h2 id='distributeDraws_cpp'>Distribute number of swaps</h2><span id='topic+distributeDraws_cpp'></span>

<h3>Description</h3>

<p>Distribute number of swaps across lowest hierarchy level according to a predefined <code>swaprate</code>. The swaprate is applied such that a single swap counts as swapping 2 households.
Number of swaps are randomly rounded up or down, if needed, such that the total number of swaps is in coherence with the swaprate.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>distributeDraws</code> which is used inside the C++-function <code>recordSwap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distributeDraws_cpp(data, hierarchy, hid, swaprate, seed = 123456L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distributeDraws_cpp_+3A_data">data</code></td>
<td>
<p>micro data containing the hierarchy levels and household ID</p>
</td></tr>
<tr><td><code id="distributeDraws_cpp_+3A_hierarchy">hierarchy</code></td>
<td>
<p>column indices of variables in <code>data</code> which refers to the geographic hierarchy in the micro data set. For instance county &gt; municipality &gt; district.</p>
</td></tr>
<tr><td><code id="distributeDraws_cpp_+3A_hid">hid</code></td>
<td>
<p>column index in <code>data</code> which refers to the household identifier.</p>
</td></tr>
<tr><td><code id="distributeDraws_cpp_+3A_swaprate">swaprate</code></td>
<td>
<p>double between 0 and 1 defining the proportion of households which should be swapped, see details for more explanations</p>
</td></tr>
<tr><td><code id="distributeDraws_cpp_+3A_seed">seed</code></td>
<td>
<p>integer setting the sampling seed</p>
</td></tr>
</table>

<hr>
<h2 id='distributeRandom_cpp'>Distribute</h2><span id='topic+distributeRandom_cpp'></span>

<h3>Description</h3>

<p>Distribute 'totalDraws' using ratio/probability vector 'inputRatio' and randomly round each entry up or down such that the distribution results in an integer vector.
Returns an integer vector containing the number of units in 'totalDraws' distributetd according to proportions in 'inputRatio'.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>distributeRandom</code> which is used inside the C++-function <code>recordSwap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distributeRandom_cpp(inputRatio, totalDraws, seed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distributeRandom_cpp_+3A_inputratio">inputRatio</code></td>
<td>
<p>vector containing ratios which are used to distribute number units in 'totalDraws'.</p>
</td></tr>
<tr><td><code id="distributeRandom_cpp_+3A_totaldraws">totalDraws</code></td>
<td>
<p>number of units to distribute</p>
</td></tr>
<tr><td><code id="distributeRandom_cpp_+3A_seed">seed</code></td>
<td>
<p>integer setting the sampling seed</p>
</td></tr>
</table>

<hr>
<h2 id='dRisk'>overal disclosure risk</h2><span id='topic+dRisk'></span>

<h3>Description</h3>

<p>Distance-based disclosure risk estimation via standard deviation-based
intervals around observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dRisk(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dRisk_+3A_obj">obj</code></td>
<td>
<p>a <code>data.frame</code> or object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="dRisk_+3A_...">...</code></td>
<td>
<p>possible arguments are:
</p>

<dl>
<dt><code>xm</code>:</dt><dd><p>perturbed data</p>
</dd>
<dt><code>k</code>:</dt><dd><p>percentage of the standard deviation</p>
</dd></dl>
</td></tr>
</table>


<h3>Details</h3>

<p>An interval (based on the standard deviation) is built around each value of
the perturbed value.  Then we look if the original values lay in these
intervals or not. With parameter k one can enlarge or down scale the
interval.
</p>


<h3>Value</h3>

<p>The disclosure risk or/and the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>see method SDID in Mateo-Sanz, Sebe, Domingo-Ferrer. 
Outlier Protection in Continuous Microdata Masking.
International Workshop on Privacy in Statistical Databases.
PSD 2004: Privacy in Statistical Databases pp 201-215.
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dUtility">dUtility</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(free1)
free1 &lt;- as.data.frame(free1)

m1 &lt;- microaggregation(free1[, 31:34], method="onedims", aggr=3)
m2 &lt;- microaggregation(free1[, 31:34], method="pca", aggr=3)
dRisk(obj=free1[, 31:34], xm=m1$mx)
dRisk(obj=free1[, 31:34], xm=m2$mx)
dUtility(obj=free1[, 31:34], xm=m1$mx)
dUtility(obj=free1[, 31:34], xm=m2$mx)

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
## this is already made internally: sdc &lt;- dRisk(sdc)
## and already stored in sdc

</code></pre>

<hr>
<h2 id='dRiskRMD'>RMD based disclosure risk</h2><span id='topic+dRiskRMD'></span>

<h3>Description</h3>

<p>Distance-based disclosure risk estimation via robust Mahalanobis Distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dRiskRMD(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dRiskRMD_+3A_obj">obj</code></td>
<td>
<p>an <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="dRiskRMD_+3A_...">...</code></td>
<td>
<p>see possible arguments below
</p>

<dl>
<dt>xm</dt><dd><p>masked data</p>
</dd>
<dt>k</dt><dd><p>weight for adjusting the influence of the robust Mahalanobis
distances, i.e. to increase or decrease each of the disclosure risk intervals.</p>
</dd>
<dt>k2</dt><dd><p>parameter for method RMDID2 to choose a small interval around each
masked observation.</p>
</dd></dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is an extension of method SDID because it accounts for the
&ldquo;outlyingness&rdquo; of each observations. This is a quite natural approach
since outliers do have a higher risk of re-identification and therefore
these outliers should have larger disclosure risk intervals as observations
in the center of the data cloud.
</p>
<p>The algorithm works as follows:
</p>
<p>1. Robust Mahalanobis distances are estimated in order to get a robust
multivariate distance for each observation.
</p>
<p>2. Intervals are estimated for each observation around every data point of
the original data points where the length of the interval is
defined/weighted by the squared robust Mahalanobis distance and the
parameter $k$.  The higher the RMD of an observation the larger the
interval.
</p>
<p>3. Check if the corresponding masked values fall into the intervals around
the original values or not.  If the value of the corresponding observation
is within such an interval the whole observation is considered unsafe.  So,
we get a whole vector indicating which observation is save or not, and we
are finished already when using method RMDID1).
</p>
<p>4. For method RMDID1w: we return the weighted (via RMD) vector of disclosure
risk.
</p>
<p>5. For method RMDID2: whenever an observation is considered unsafe it is
checked if $m$ other observations from the masked data are very close
(defined by a parameter $k2$ for the length of the intervals as for SDID or
RSDID) to such an unsafe observation from the masked data, using Euclidean
distances.  If more than $m$ points are in such a small interval, we
conclude that this observation is &ldquo;save&rdquo;.
</p>


<h3>Value</h3>

<p>The disclosure risk or the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>
<table>
<tr><td><code>risk1</code></td>
<td>
<p>percentage of sensitive observations according to method RMDID1.</p>
</td></tr>
<tr><td><code>risk2</code></td>
<td>
<p>standardized version of risk1</p>
</td></tr>
<tr><td><code>wrisk1</code></td>
<td>
<p>amount of sensitive observations according to RMDID1 weighted
by their corresponding robust Mahalanobis distances.</p>
</td></tr>
<tr><td><code>wrisk2</code></td>
<td>
<p>RMDID2 measure</p>
</td></tr>
<tr><td><code>indexRisk1</code></td>
<td>
<p>index of observations with high risk according to risk1 measure</p>
</td></tr>
<tr><td><code>indexRisk2</code></td>
<td>
<p>index of observations with high risk according to wrisk2 measure</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Templ, M. and Meindl, B., <em>Robust Statistics Meets SDC: New
Disclosure Risk Measures for Continuous Microdata Masking</em>, Lecture Notes in
Computer Science, Privacy in Statistical Databases, vol. 5262, pp. 113-126,
2008.
</p>
<p>Templ, M. <em>New Developments in Statistical Disclosure Control and
Imputation: Robust Statistics Applied to Official Statistics</em>,
Suedwestdeutscher Verlag fuer Hochschulschriften, 2009, ISBN: 3838108280,
264 pages.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dRisk">dRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Tarragona)
x &lt;- Tarragona[, 5:7]
y &lt;- addNoise(x)$xm
dRiskRMD(x, xm=y)
dRisk(x, xm=y)

data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')

sdc &lt;- dRiskRMD(sdc)

</code></pre>

<hr>
<h2 id='dUtility'>Data-Utility measures</h2><span id='topic+dUtility'></span>

<h3>Description</h3>

<p><code><a href="#topic+dUtility">dUtility()</a></code> allows to compute different measures of data-utility based
on various distances using original and perturbed variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dUtility(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dUtility_+3A_obj">obj</code></td>
<td>
<p>original data or object of class <a href="#topic+sdcMicroObj-class">sdcMicroObj</a></p>
</td></tr>
<tr><td><code id="dUtility_+3A_...">...</code></td>
<td>
<p>see arguments below
</p>

<ul>
<li><p> xm: perturbed data
</p>
</li>
<li><p> method: method IL1, IL1s or eigen. More methods are implemented in
summary.micro()
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>The standardised distances of the perturbed data values to the original ones
are measured. The following measures are available:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;"IL1&#8288;</code>: sum of absolute distances between original and perturbed variables
scaled by absolute values of the original variables
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;"IL1s&#8288;</code>: measures the absolute distances between original
and perturbed ones, scaled by the standard deviation of original variables times
the square root of <code>2</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;"eigen&#8288;</code>; compares the eigenvalues of original and perturbed data
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;"robeigen&#8288;</code>; compares robust eigenvalues of original and perturbed data
</p>
</li></ul>



<h3>Value</h3>

<p>data utility or modified entry for data utility the <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>for IL1 and IL1s: see Mateo-Sanz, Sebe, Domingo-Ferrer.
Outlier Protection in Continuous Microdata Masking.
International Workshop on Privacy in Statistical Databases.
PSD 2004: Privacy in Statistical Databases pp 201-215.
</p>
<p>Templ, M. and Meindl, B., <code style="white-space: pre;">&#8288;Robust Statistics Meets SDC: New Disclosure Risk Measures for Continuous Microdata Masking&#8288;</code>, Lecture Notes in Computer
Science, Privacy in Statistical Databases, vol. 5262, pp. 113-126, 2008.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dRisk">dRisk()</a></code>, <code><a href="#topic+dRiskRMD">dRiskRMD()</a></code>
</p>

<hr>
<h2 id='EIA'>EIA data set</h2><span id='topic+EIA'></span>

<h3>Description</h3>

<p>Data set obtained from the U.S. Energy Information Authority.
</p>


<h3>Format</h3>

<p>A data frame with 4092 observations on the following 15 variables.
</p>

<dl>
<dt>UTILITYID</dt><dd><p>UNIQUE UTILITY IDENTIFICATION NUMBER</p>
</dd>
<dt>UTILNAME</dt><dd><p>UTILITY NAME. A factor with levels <code>4-County
Electric Power Assn</code> <code>Alabama Power Co</code> <code>Alaska Electric</code>
<code>Appalachian Electric Coop</code> <code>Appalachian Power Co</code> <code>Arizona
Public Service Co</code> <code>Arkansas Power &amp; Light Co</code> <code>Arkansas Valley
Elec Coop Corp</code> <code>Atlantic City Electric Company</code> <code>Baker Electric
Coop Inc</code> <code>Baltimore Gas &amp; Electric Co</code> <code>Bangor Hydro-Electric Co</code>
<code>Berkeley Electric Coop Inc</code> <code>Black Hills Corp</code> <code>Blackstone
Valley Electric Co</code> <code>Bonneville Power Admin</code> <code>Boston Edison Co</code>
<code>Bountiful City Light &amp; Power</code> <code>Bristol City of</code> <code>Brookings
City of</code> <code>Brunswick Electric Member Corp</code> <code>Burlington City of</code>
<code>Carolina Power &amp; Light Co</code> <code>Carroll Electric Coop Corp</code>
<code>Cass County Electric Coop Inc</code> <code>Central Illinois Light Company</code>
<code>Central Illinois Pub Serv Co</code> <code>Central Louisiana Elec Co Inc</code>
<code>Central Maine Power Co</code> <code>Central Power &amp; Light Co</code> <code>Central
Vermont Pub Serv Corp</code> <code>Chattanooga City of</code> <code>Cheyenne Light Fuel
&amp; Power Co</code> <code>Chugach Electric Assn Inc</code> <code>Cincinnati Gas &amp; Electric
Co</code> <code>Citizens Utilities Company</code> <code>City of Boulder City</code> <code>City
of Clinton</code> <code>City of Dover</code> <code>City of Eugene</code> <code>City of
Gillette</code> <code>City of Groton Dept of Utils</code> <code>City of Idaho Falls</code>
<code>City of Independence</code> <code>City of Newark</code> <code>City of Reading</code>
<code>City of Tupelo Water &amp; Light D</code> <code>Clarksville City of</code>
<code>Cleveland City of</code> <code>Cleveland Electric Illum Co</code> <code>Coast
Electric Power Assn</code> <code>Cobb Electric Membership Corp</code> <code>Colorado
River Commission</code> <code>Colorado Springs City of</code> <code>Columbus Southern
Power Co</code> <code>Commonwealth Edison Co</code> <code>Commonwealth Electric Co</code>
<code>Connecticut Light &amp; Power Co</code> <code>Consolidated Edison Co-NY Inc</code>
<code>Consumers Power Co</code> <code>Cornhusker Public Power Dist</code> <code>Cuivre
River Electric Coop Inc</code> <code>Cumberland Elec Member Corp</code> <code>Dakota
Electric Assn</code> <code>Dawson County Public Pwr Dist</code> <code>Dayton Power &amp;
Light Company</code> <code>Decatur City of</code> <code>Delaware Electric Coop Inc</code>
<code>Delmarva Power &amp; Light Co</code> <code>Detroit Edison Co</code> <code>Duck River
Elec Member Corp</code> <code>Duke Power Co</code> <code>Duquesne Light Company</code>
<code>East Central Electric Assn</code> <code>Eastern Maine Electric Coop</code>
<code>El Paso Electric Co</code> <code>Electric Energy Inc</code> <code>Empire District
Electric Co</code> <code>Exeter &amp; Hampton Electric Co</code> <code>Fairbanks City of</code>
<code>Fayetteville Public Works Comm</code> <code>First Electric Coop Corp</code>
<code>Florence City of</code> <code>Florida Power &amp; Light Co</code> <code>Florida Power
Corp</code> <code>Fort Collins Lgt &amp; Pwr Utility</code> <code>Fremont City of</code>
<code>Georgia Power Co</code> <code>Gibson County Elec Member Corp</code> <code>Golden
Valley Elec Assn Inc</code> <code>Grand Island City of</code> <code>Granite State
Electric Co</code> <code>Green Mountain Power Corp</code> <code>Green River Electric
Corp</code> <code>Greeneville City of</code> <code>Gulf Power Company</code> <code>Gulf States
Utilities Co</code> <code>Hasting Utilities</code> <code>Hawaii Electric Light Co Inc</code>
<code>Hawaiian Electric Co Inc</code> <code>Henderson-Union Rural E C C</code>
<code>Homer Electric Assn Inc</code> <code>Hot Springs Rural El Assn Inc</code>
<code>Houston Lighting &amp; Power Co</code> <code>Huntsville City of</code> <code>Idaho
Power Co</code> <code>IES Utilities Inc</code> <code>Illinois Power Co</code> <code>Indiana
Michigan Power Co</code> <code>Indianapolis Power &amp; Light Co</code> <code>Intermountain
Rural Elec Assn</code> <code>Interstate Power Co</code> <code>Jackson Electric Member
Corp</code> <code>Jersey Central Power&amp;Light Co</code> <code>Joe Wheeler Elec Member
Corp</code> <code>Johnson City City of</code> <code>Jones-Onslow Elec Member Corp</code>
<code>Kansas City City of</code> <code>Kansas City Power &amp; Light Co</code>
<code>Kentucky Power Co</code> <code>Kentucky Utilities Co</code> <code>Ketchikan Public
Utilities</code> <code>Kingsport Power Co</code> <code>Knoxville City of</code> <code>Kodiak
Electric Assn Inc</code> <code>Kootenai Electric Coop, Inc</code> <code>Lansing Board of
Water &amp; Light</code> <code>Lenoir City City of</code> <code>Lincoln City of</code> <code>Long
Island Lighting Co</code> <code>Los Angeles City of</code> <code>Louisiana Power &amp; Light
Co</code> <code>Louisville Gas &amp; Electric Co</code> <code>Loup River Public Power Dist</code>
<code>Lower Valley Power &amp; Light Inc</code> <code>Maine Public Service Company</code>
<code>Massachusetts Electric Co</code> <code>Matanuska Electric Assn Inc</code>
<code>Maui Electric Co Ltd</code> <code>McKenzie Electric Coop Inc</code> <code>Memphis
City of</code> <code>MidAmerican Energy Company</code> <code>Middle Tennessee E M C</code>
<code>Midwest Energy, Inc</code> <code>Minnesota Power &amp; Light Co</code>
<code>Mississippi Power &amp; Light Co</code> <code>Mississippi Power Co</code>
<code>Monongahela Power Co</code> <code>Montana-Dakota Utilities Co</code> <code>Montana
Power Co</code> <code>Moon Lake Electric Assn Inc</code> <code>Narragansett Electric Co</code>
<code>Nashville City of</code> <code>Nebraska Public Power District</code> <code>Nevada
Power Co</code> <code>New Hampshire Elec Coop, Inc</code> <code>New Orleans Public
Service Inc</code> <code>New York State Gas &amp; Electric</code> <code>Newport Electric
Corp</code> <code>Niagara Mohawk Power Corp</code> <code>Nodak Rural Electric Coop Inc</code>
<code>Norris Public Power District</code> <code>Northeast Oklahoma Electric Co</code>
<code>Northern Indiana Pub Serv Co</code> <code>Northern States Power Co</code>
<code>Northwestern Public Service Co</code> <code>Ohio Edison Co</code> <code>Ohio Power
Co</code> <code>Ohio Valley Electric Corp</code> <code>Oklahoma Electric Coop, Inc</code>
<code>Oklahoma Gas &amp; Electric Co</code> <code>Oliver-Mercer Elec Coop, Inc</code>
<code>Omaha Public Power District</code> <code>Otter Tail Power Co</code> <code>Pacific
Gas &amp; Electric Co</code> <code>Pacificorp dba Pacific Pwr &amp; L</code> <code>Palmetto
Electric Coop, Inc</code> <code>Pennsylvania Power &amp; Light Co</code> <code>Pennyrile
Rural Electric Coop</code> <code>Philadelphia Electric Co</code> <code>Pierre Municipal
Electric</code> <code>Portland General Electric Co</code> <code>Potomac Edison Co</code>
<code>Potomac Electric Power Co</code> <code>Poudre Valley R E A, Inc</code> <code>Power
Authority of State of NY</code> <code>Provo City Corporation</code> <code>Public Service
Co of Colorado</code> <code>Public Service Co of IN Inc</code> <code>Public Service Co
of NH</code> <code>Public Service Co of NM</code> <code>Public Service Co of Oklahoma</code>
<code>Public Service Electric&amp;Gas Co</code> <code>PUD No 1 of Clark County</code>
<code>PUD No 1 of Snohomish County</code> <code>Puget Sound Power &amp; Light Co</code>
<code>Rappahannock Electric Coop</code> <code>Rochester Public Utilities</code>
<code>Rockland Electric Company</code> <code>Rosebud Electric Coop Inc</code>
<code>Rutherford Elec Member Corp</code> <code>Sacramento Municipal Util Dist</code>
<code>Salmon River Electric Coop Inc</code> <code>Salt River Proj Ag I &amp; P Dist</code>
<code>San Antonio City of</code> <code>Savannah Electric &amp; Power Co</code> <code>Seattle
City of</code> <code>Sierra Pacific Power Co</code> <code>Singing River Elec Power Assn</code>
<code>Sioux Valley Empire E A Inc</code> <code>South Carolina Electric&amp;Gas Co</code>
<code>South Carolina Pub Serv Auth</code> <code>South Kentucky Rural E C C</code>
<code>Southern California Edison Co</code> <code>Southern Nebraska Rural P P D</code>
<code>Southern Pine Elec Power Assn</code> <code>Southwest Tennessee E M C</code>
<code>Southwestern Electric Power Co</code> <code>Southwestern Public Service Co</code>
<code>Springfield City of</code> <code>St Joseph Light &amp; Power Co</code> <code>State
Level Adjustment</code> <code>Tacoma City of</code> <code>Tampa Electric Co</code>
<code>Texas-New Mexico Power Co</code> <code>Texas Utilities Electric Co</code>
<code>Tri-County Electric Assn Inc</code> <code>Tucson Electric Power Co</code>
<code>Turner-Hutchinsin El Coop, Inc</code> <code>TVA</code> <code>U S Bureau of Indian
Affairs</code> <code>Union Electric Co</code> <code>Union Light Heat &amp; Power Co</code>
<code>United Illuminating Co</code> <code>Upper Cumberland E M C</code> <code>UtiliCorp
United Inc</code> <code>Verdigris Valley Electric Coop</code> <code>Verendrye Electric
Coop Inc</code> <code>Virginia Electric &amp; Power Co</code> <code>Volunteer Electric Coop</code>
<code>Wallingford Town of</code> <code>Warren Rural Elec Coop Corp</code>
<code>Washington Water Power Co</code> <code>Watertown Municipal Utils Dept</code>
<code>Wells Rural Electric Co</code> <code>West Penn Power Co</code> <code>West Plains
Electric Coop Inc</code> <code>West River Electric Assn, Inc</code> <code>Western
Massachusetts Elec Co</code> <code>Western Resources Inc</code> <code>Wheeling Power
Company</code> <code>Wisconsin Electric Power Co</code> <code>Wisconsin Power &amp; Light
Co</code> <code>Wisconsin Public Service Corp</code> <code>Wright-Hennepin Coop Elec
Assn</code> <code>Yellowstone Vlly Elec Coop Inc</code></p>
</dd>
<dt>STATE</dt><dd><p>STATE FOR WHICH THE UTILITY IS REPORTING. A factor with levels
<code>AK</code> <code>AL</code> <code>AR</code> <code>AZ</code> <code>CA</code> <code>CO</code> <code>CT</code>
<code>DC</code> <code>DE</code> <code>FL</code> <code>GA</code> <code>HI</code> <code>IA</code> <code>ID</code>
<code>IL</code> <code>IN</code> <code>KS</code> <code>KY</code> <code>LA</code> <code>MA</code> <code>MD</code>
<code>ME</code> <code>MI</code> <code>MN</code> <code>MO</code> <code>MS</code> <code>MT</code> <code>NC</code>
<code>ND</code> <code>NE</code> <code>NH</code> <code>NJ</code> <code>NM</code> <code>NV</code> <code>NY</code>
<code>OH</code> <code>OK</code> <code>OR</code> <code>PA</code> <code>RI</code> <code>SC</code> <code>SD</code>
<code>TN</code> <code>TX</code> <code>UT</code> <code>VA</code> <code>VT</code> <code>WA</code> <code>WI</code>
<code>WV</code> <code>WY</code></p>
</dd>
<dt>YEAR</dt><dd><p>REPORTING YEAR FOR THE DATA</p>
</dd>
<dt>MONTH</dt><dd><p>REPORTING MONTH FOR THE DATA</p>
</dd>
<dt>RESREVENUE</dt><dd><p>REVENUE FROM SALES TO RESIDENTIAL CONSUMERS</p>
</dd>
<dt>RESSALES</dt><dd><p>SALES TO RESIDENTIAL CONSUMERS</p>
</dd>
<dt>COMREVENUE</dt><dd><p>REVENUE FROM SALES TO COMMERCIAL CONSUMERS</p>
</dd>
<dt>COMSALES</dt><dd><p>SALES TO COMMERCIAL CONSUMERS</p>
</dd>
<dt>INDREVENUE</dt><dd><p>REVENUE FROM SALES TO INDUSTRIAL CONSUMERS</p>
</dd>
<dt>INDSALES</dt><dd><p>SALES TO INDUSTRIAL CONSUMERS</p>
</dd>
<dt>OTHREVENUE</dt><dd><p>REVENUE FROM SALES TO OTHER CONSUMERS</p>
</dd>
<dt>OTHRSALES</dt><dd><p>SALES TO OTHER CONSUMERS</p>
</dd>
<dt>TOTREVENUE</dt><dd><p>REVENUE FROM SALES TO ALL CONSUMERS</p>
</dd>
<dt>TOTSALES</dt><dd><p>SALES TO ALL CONSUMERS</p>
</dd></dl>



<h3>Source</h3>

<p>Public use file from the CASC project.
</p>


<h3>References</h3>

<p>Brand, R. and Domingo-Ferrer, J. and Mateo-Sanz, J.M., Reference
data sets to test and compare SDC methods for protection of numerical
microdata. Unpublished.
<a href="https://research.cbs.nl/casc/CASCrefmicrodata.pdf">https://research.cbs.nl/casc/CASCrefmicrodata.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(EIA)
head(EIA)

</code></pre>

<hr>
<h2 id='extractManipData'>Remove certain variables from the data set inside a sdc object.</h2><span id='topic+extractManipData'></span>

<h3>Description</h3>

<p>Extract the manipulated data from an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractManipData(
  obj,
  ignoreKeyVars = FALSE,
  ignorePramVars = FALSE,
  ignoreNumVars = FALSE,
  ignoreGhostVars = FALSE,
  ignoreStrataVar = FALSE,
  randomizeRecords = "no"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractManipData_+3A_obj">obj</code></td>
<td>
<p>object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="extractManipData_+3A_ignorekeyvars">ignoreKeyVars</code></td>
<td>
<p>If manipulated KeyVariables should be returned or the
unchanged original variables</p>
</td></tr>
<tr><td><code id="extractManipData_+3A_ignorepramvars">ignorePramVars</code></td>
<td>
<p>if manipulated PramVariables should be returned or the
unchanged original variables</p>
</td></tr>
<tr><td><code id="extractManipData_+3A_ignorenumvars">ignoreNumVars</code></td>
<td>
<p>if manipulated NumericVariables should be returned or
the unchanged original variables</p>
</td></tr>
<tr><td><code id="extractManipData_+3A_ignoreghostvars">ignoreGhostVars</code></td>
<td>
<p>if manipulated Ghost (linked) Variables should be returned or
the unchanged original variables</p>
</td></tr>
<tr><td><code id="extractManipData_+3A_ignorestratavar">ignoreStrataVar</code></td>
<td>
<p>if manipulated StrataVariables should be returned or
the unchanged original variables</p>
</td></tr>
<tr><td><code id="extractManipData_+3A_randomizerecords">randomizeRecords</code></td>
<td>
<p>(logical) specifies, if the output records should be randomized. The following
options are possible:
</p>

<dl>
<dt>'no'</dt><dd><p>default, no randomization takes place</p>
</dd>
<dt>'simple'</dt><dd><p>records are just randomly swapped.</p>
</dd>
<dt>'byHH'</dt><dd><p>if slot 'hhId' is not <code>NULL</code>, the clusters defined by this variable are randomized across the dataset. If
slot 'hhId' is <code>NULL</code>, the records or the dataset are randomly changed.</p>
</dd>
<dt>'withinHH'</dt><dd><p>if slot 'hhId' is not <code>NULL</code>, the clusters defined by this variable are randomized across the dataset and
additionally, the order of records within the clusters are also randomly changed. If slot 'hhId' is <code>NULL</code>, the records or the dataset are
randomly changed.</p>
</dd></dl>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> containing the anonymized data set
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik, Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata,
  keyVars=c('urbrur','roof'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- removeDirectID(sdc, var="age")
dataM &lt;- extractManipData(sdc)
</code></pre>

<hr>
<h2 id='francdat'>data from the casc project</h2><span id='topic+francdat'></span>

<h3>Description</h3>

<p>Small synthetic data from Capobianchi, Polettini, Lucarelli
</p>


<h3>Format</h3>

<p>A data frame with 8 observations on the following 8 variables.
</p>

<dl>
<dt>Num1</dt><dd><p>a numeric vector</p>
</dd>
<dt>Key1</dt><dd><p>Key variable 1. A numeric vector</p>
</dd>
<dt>Num2</dt><dd><p>a numeric vector</p>
</dd>
<dt>Key2</dt><dd><p>Key variable 2. A numeric vector</p>
</dd>
<dt>Key3</dt><dd><p>Key variable 3. A numeric vector</p>
</dd>
<dt>Key4</dt><dd><p>Key variable 4. A numeric vector</p>
</dd>
<dt>Num3</dt><dd><p>a numeric vector</p>
</dd>
<dt>w</dt><dd><p>The weight vector. A numeric vector</p>
</dd></dl>



<h3>Details</h3>

<p>This data set is very similar to that one which are used by the authors of
the paper given below. We need this data set only for demonstration effect,
i.e. that the package provides the same results as their software.
</p>


<h3>Source</h3>

<p><a href="https://research.cbs.nl/casc/deliv/12d1.pdf">https://research.cbs.nl/casc/deliv/12d1.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(francdat)
francdat
</code></pre>

<hr>
<h2 id='free1'>Demo data set from mu-Argus</h2><span id='topic+free1'></span>

<h3>Description</h3>

<p>The public use toy demo data set from the mu-Argus software for SDC.
</p>


<h3>Format</h3>

<p>The format is: num [1:4000, 1:34] 36 36 36 36 36 36 36 36 36 36 ...
- attr(*, &quot;dimnames&quot;)=List of 2 ..$ : NULL ..$ : chr [1:34] &quot;REGION&quot; &quot;SEX&quot;
&quot;AGE&quot; &quot;MARSTAT&quot; ...
</p>


<h3>Details</h3>

<p>Please, see at the link given below. Please note, that the correlation
structure of the data is not very realistic, especially concerning the
continuous scaled variables which drawn independently from are a
multivariate uniform distribution.
</p>


<h3>Source</h3>

<p>Public use file from the CASC project.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(free1)
head(free1)

</code></pre>

<hr>
<h2 id='freq'>Freq</h2><span id='topic+freq'></span>

<h3>Description</h3>

<p>Extract sample frequency counts (fk) or estimated population frequency counts (Fk)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freq(obj, type = "fk")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freq_+3A_obj">obj</code></td>
<td>
<p>an <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object</p>
</td></tr>
<tr><td><code id="freq_+3A_type">type</code></td>
<td>
<p>either <code>'fk'</code> or <code>'FK'</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector containing sample frequencies or weighted frequencies
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata)
sdc &lt;- createSdcObj(testdata,
  keyVars=c('urbrur','roof','walls','relat','sex'),
  pramVars=c('water','electcon'),
  numVars=c('expend','income','savings'), w='sampling_weight')
head(freq(sdc, type="fk"))
head(freq(sdc, type="Fk"))
</code></pre>

<hr>
<h2 id='freqCalc'>Frequencies calculation for risk estimation</h2><span id='topic+freqCalc'></span>

<h3>Description</h3>

<p>Computation and estimation of the sample and population frequency counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freqCalc(x, keyVars, w = NULL, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freqCalc_+3A_x">x</code></td>
<td>
<p>data frame or matrix</p>
</td></tr>
<tr><td><code id="freqCalc_+3A_keyvars">keyVars</code></td>
<td>
<p>key variables</p>
</td></tr>
<tr><td><code id="freqCalc_+3A_w">w</code></td>
<td>
<p>column index of the weight variable. Should be set to NULL if one
deal with a population.</p>
</td></tr>
<tr><td><code id="freqCalc_+3A_alpha">alpha</code></td>
<td>
<p>numeric value between 0 and 1 specifying how much keys that
contain missing values (<code>NAs</code>) should contribute to the calculation
of <code>fk</code> and <code>Fk</code>. For the default value of <code>1</code>, nothing changes with
respect to the implementation in prior versions. Each <em>wildcard-match</em> would
be counted while for <code>alpha=0</code> keys with missing values would be basically ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function considers the case of missing values in the data.  A missing
value stands for any of the possible categories of the variable considered.
It is possible to apply this function to large data sets with many
(catergorical) key variables, since the computation is done in C.
</p>
<p><em>freqCalc()</em> does not support sdcMicro S4 class objects.
</p>


<h3>Value</h3>

<p>Object from class freqCalc.
</p>
<table>
<tr><td><code>freqCalc</code></td>
<td>
<p>data set</p>
</td></tr>
<tr><td><code>keyVars</code></td>
<td>
<p>variables used for frequency calculation</p>
</td></tr>
<tr><td><code>w</code></td>
<td>
<p>index of weight vector. NULL if you do not have a sample.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>value of parameter <code>alpha</code></p>
</td></tr>
<tr><td><code>fk</code></td>
<td>
<p>the frequency of equal observations in
the key variables subset sample given for each observation.</p>
</td></tr>
<tr><td><code>Fk</code></td>
<td>
<p>estimated frequency in the population</p>
</td></tr>
<tr><td><code>n1</code></td>
<td>
<p>number of observations with fk=1</p>
</td></tr>
<tr><td><code>n2</code></td>
<td>
<p>number of observations with fk=2</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>References</h3>

<p>look e.g. in <a href="https://research.cbs.nl/casc/deliv/12d1.pdf">https://research.cbs.nl/casc/deliv/12d1.pdf</a>
Templ, M.  <em>Statistical Disclosure Control for Microdata Using the
R-Package sdcMicro</em>, Transactions on Data Privacy, vol. 1, number 2, pp.
67-85, 2008.  <a href="https://www.tdp.cat/issues/abs.a004a08.php">https://www.tdp.cat/issues/abs.a004a08.php</a>
</p>
<p>Templ, M.  <em>New Developments in Statistical Disclosure Control and
Imputation: Robust Statistics Applied to Official Statistics</em>,
Suedwestdeutscher Verlag fuer Hochschulschriften, 2009, ISBN: 3838108280,
264 pages.
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4. <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>
<p>Templ, M. and Meindl, B.: <em>Practical Applications in Statistical
Disclosure Control Using R</em>, Privacy and Anonymity in Information Management
Systems New Techniques for New Practical Problems, Springer, 31-62, 2010,
ISBN: 978-1-84996-237-7.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indivRisk">indivRisk</a></code>, <code><a href="#topic+measure_risk">measure_risk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(francdat)

f &lt;- freqCalc(francdat, keyVars=c(2,4,5,6),w=8)
f
f$freqCalc
f$fk
f$Fk
## with missings:
x &lt;- francdat
x[3,5] &lt;- NA
x[4,2] &lt;- x[4,4] &lt;- NA
x[5,6]  &lt;- NA
x[6,2]  &lt;- NA
f2 &lt;- freqCalc(x, keyVars=c(2,4,5,6),w=8)
cbind(f2$fk, f2$Fk)

## test parameter 'alpha'
f3a &lt;- freqCalc(x, keyVars=c(2,4,5,6), w=8, alpha=1)
f3b &lt;- freqCalc(x, keyVars=c(2,4,5,6), w=8, alpha=0.5)
f3c &lt;- freqCalc(x, keyVars=c(2,4,5,6), w=8, alpha=0.1)
data.frame(fka=f3a$fk, fkb=f3b$fk, fkc=f3c$fk)
data.frame(Fka=f3a$Fk, Fkb=f3b$Fk, Fkc=f3c$Fk)

</code></pre>

<hr>
<h2 id='generateStrata'>Generate one strata variable from multiple factors</h2><span id='topic+generateStrata'></span>

<h3>Description</h3>

<p>For strata defined by multiple variables (e.g. sex,age,country) one combined
variable is generated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateStrata(df, stratavars, name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateStrata_+3A_df">df</code></td>
<td>
<p>a data.frame</p>
</td></tr>
<tr><td><code id="generateStrata_+3A_stratavars">stratavars</code></td>
<td>
<p>character vector with variable name</p>
</td></tr>
<tr><td><code id="generateStrata_+3A_name">name</code></td>
<td>
<p>name of the newly generated variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original data set with one new column.
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- testdata
x &lt;- generateStrata(x,c("sex","urbrur"),"strataIDvar")
head(x)

</code></pre>

<hr>
<h2 id='get.sdcMicroObj'>get.sdcMicroObj</h2><span id='topic+get.sdcMicroObj'></span>

<h3>Description</h3>

<p>extract information from <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-objects depending on argument <code>type</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.sdcMicroObj(object, type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.sdcMicroObj_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object</p>
</td></tr>
<tr><td><code id="get.sdcMicroObj_+3A_type">type</code></td>
<td>
<p>a character vector of length 1 defining what to calculate|return|modify. Allowed types are are
all slotNames of <code>obj</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a slot of a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object depending on argument <code>type</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sl &lt;- slotNames(sdc)
res &lt;- sapply(sl, function(x) get.sdcMicroObj(sdc, type=x))
str(res)
</code></pre>

<hr>
<h2 id='globalRecode'>Global Recoding</h2><span id='topic+globalRecode'></span>

<h3>Description</h3>

<p>Global recoding of variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>globalRecode(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="globalRecode_+3A_obj">obj</code></td>
<td>
<p>a numeric vector, a <code>data.frame</code> or an object of class
<code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="globalRecode_+3A_...">...</code></td>
<td>
<p>see possible arguments below
</p>

<dl>
<dt>column: </dt><dd><p>which keyVar should be changed. Character vector of length 1 specifying the variable name that
should be recoded (required if <code>obj</code> is a <code>data.frame</code> or
an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>.</p>
</dd>
<dt>breaks: </dt><dd><p>either a numeric vector of cut points or number giving the
number of intervals which x is to be cut into.</p>
</dd>
<dt>labels: </dt><dd><p>labels for the levels of the resulting category. By default,
labels are constructed using &quot;(a,b]&quot; interval notation.  If labels = FALSE,
simple integer codes are returned instead of a factor.</p>
</dd>
<dt>method: </dt><dd><p>The following arguments are supported:
</p>

<ul>
<li> <p>&ldquo;equidistant:&rdquo; for equal sized intervalls
</p>
</li>
<li> <p>&ldquo;logEqui:&rdquo; for equal sized intervalls for log-transformed data
</p>
</li>
<li> <p>&ldquo;equalAmount:&rdquo; for intervalls with approxiomately the same amount
of observations
</p>
</li></ul>
</dd></dl>
</td></tr>
</table>


<h3>Details</h3>

<p>If a labels parameter is specified, its values are used to name the factor
levels.  If none is specified, the factor level labels are constructed.
</p>


<h3>Value</h3>

<p>the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> or a factor, unless labels = FALSE
which results in the mere integer level codes.
</p>


<h3>Note</h3>

<p><code>globalRecode</code> can not be applied to vectors stored as factors from sdcMicro &gt;= 4.7.0!
</p>


<h3>Author(s)</h3>

<p>Matthias Templ and Bernhard Meindl
</p>


<h3>References</h3>

<p>Templ, M. and Kowarik, A. and Meindl, B.
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro.
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4. <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+cut">cut</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(free1)
free1 &lt;- as.data.frame(free1)

## application to a vector
head(globalRecode(free1$AGE, breaks=c(1,9,19,29,39,49,59,69,100), labels=1:8))
table(globalRecode(free1$AGE, breaks=c(1,9,19,29,39,49,59,69,100), labels=1:8))

## application to a data.frame
# automatic labels
table(globalRecode(free1, column="AGE", breaks=c(1,9,19,29,39,49,59,69,100))$AGE)

## calculation of brea-points using different algorithms
table(globalRecode(free1$AGE, breaks=6))
table(globalRecode(free1$AGE, breaks=6, method="logEqui"))
table(globalRecode(free1$AGE, breaks=6, method="equalAmount"))

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- globalRecode(sdc, column="water", breaks=3)
table(get.sdcMicroObj(sdc, type="manipKeyVars")$water)
</code></pre>

<hr>
<h2 id='groupAndRename'>Join levels of a variables in an object of class
<code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> or <code>factor</code> or <code>data.frame</code></h2><span id='topic+groupAndRename'></span>

<h3>Description</h3>

<p>If the input is an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>, the
specified factor-variable is recoded into a factor with less levels and
risk-measures are automatically recomputed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>groupAndRename(obj, var, before, after, addNA = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="groupAndRename_+3A_obj">obj</code></td>
<td>
<p>object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="groupAndRename_+3A_var">var</code></td>
<td>
<p>name of the keyVariable to change</p>
</td></tr>
<tr><td><code id="groupAndRename_+3A_before">before</code></td>
<td>
<p>vector of levels before recoding</p>
</td></tr>
<tr><td><code id="groupAndRename_+3A_after">after</code></td>
<td>
<p>name of new level after recoding</p>
</td></tr>
<tr><td><code id="groupAndRename_+3A_addna">addNA</code></td>
<td>
<p>logical, if TRUE missing values in the input variables are added to the level specified in argument <code>after</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the input is of class <code>data.frame</code>, the result is a <code>data.frame</code> with
a modified column specified by <code>var</code>.
</p>
<p>If the input is of class <code>factor</code>, the result is a <code>factor</code> with different
levels.
</p>


<h3>Value</h3>

<p>the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>References</h3>

<p>Templ, M. and Kowarik, A. and Meindl, B. 
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro. 
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4. <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for objects of class sdcMicro:
data(testdata2)
testdata2$urbrur &lt;- as.factor(testdata2$urbrur)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- groupAndRename(sdc, var="urbrur", before=c("1","2"), after=c("1"))
</code></pre>

<hr>
<h2 id='IL_correl'>Additional Information-Loss measures</h2><span id='topic+IL_correl'></span><span id='topic+print.il_correl'></span><span id='topic+IL_variables'></span><span id='topic+print.il_variables'></span>

<h3>Description</h3>

<p>Measures <code><a href="#topic+IL_correl">IL_correl()</a></code> and <code><a href="#topic+IL_variables">IL_variables()</a></code> were proposed by Andrzej Mlodak and are (theoretically) bounded between <code>0</code> and <code>1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IL_correl(x, xm)

## S3 method for class 'il_correl'
print(x, digits = 3, ...)

IL_variables(x, xm)

## S3 method for class 'il_variables'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IL_correl_+3A_x">x</code></td>
<td>
<p>an object coercible to a <code>data.frame</code> representing the original dataset</p>
</td></tr>
<tr><td><code id="IL_correl_+3A_xm">xm</code></td>
<td>
<p>an object coercible to a <code>data.frame</code> representing the perturbed, modified dataset</p>
</td></tr>
<tr><td><code id="IL_correl_+3A_digits">digits</code></td>
<td>
<p>number digits used for rounding when displaying results</p>
</td></tr>
<tr><td><code id="IL_correl_+3A_...">...</code></td>
<td>
<p>additional parameter for print-methods; currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code>IL_correl()</code>: is a information-loss measure that can be applied to common numerically scaled variables in <code>x</code> and <code>xm</code>. It is based
on diagonal entries of inverse correlation matrices in the original and perturbed data.
</p>
</li>
<li> <p><code>IL_variables()</code>: for common-variables in <code>x</code> and <code>xm</code> the individual distance-functions depend on the class of the variable;
specifically these functions are different for numeric variables, ordered-factors and character/factor variables. The individual distances
are summed up and scaled by <code>n * m</code> with <code>n</code> being the number of records and <code>m</code> being the number of (common) variables.
</p>
</li></ul>

<p>Details can be found in the references below
</p>
<p>The implementation of <code><a href="#topic+IL_correl">IL_correl()</a></code> differs slightly with the original proposition from Mlodak, A. (2020) as
the constant multiplier was changed to <code>1 / sqrt(2)</code> instead of <code>1/2</code> for better efficiency and interpretability
of the measure.
</p>


<h3>Value</h3>

<p>the corresponding information-loss measure
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl <a href="mailto:bernhard.meindl@statistik.gv.at">bernhard.meindl@statistik.gv.at</a>
</p>


<h3>References</h3>

<p>Mlodak, A. (2020). Information loss resulting from statistical disclosure control of output data,
Wiadomosci Statystyczne. The Polish Statistician, 2020, 65(9), 7-27, DOI: 10.5604/01.3001.0014.4121
</p>
<p>Mlodak, A. (2019). Using the Complex Measure in an Assessment of the Information Loss Due to the Microdata Disclosure Control,
Przegląd Statystyczny, 2019, 66(1), 7-26,
DOI: 10.5604/01.3001.0013.8285
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Tarragona", package = "sdcMicro")
res1 &lt;- addNoise(obj = Tarragona, variables = colnames(Tarragona), noise = 100)
IL_correl(x = as.data.frame(res1$x), xm = as.data.frame(res1$xm))

res2 &lt;- addNoise(obj = Tarragona, variables = colnames(Tarragona), noise = 25) 
IL_correl(x = as.data.frame(res2$x), xm = as.data.frame(res2$xm))

# creating test-inputs
n &lt;- 150
x &lt;- xm &lt;- data.frame(
  v1 = factor(sample(letters[1:5], n, replace = TRUE), levels = letters[1:5]),
  v2 = rnorm(n),
  v3 = runif(3),
  v4 = ordered(sample(LETTERS[1:3], n, replace = TRUE), levels = c("A", "B", "C"))
)
xm$v1[1:5] &lt;- "a"
xm$v2 &lt;- rnorm(n, mean = 5)
xm$v4[1:5] &lt;- "A"
IL_variables(x, xm)
</code></pre>

<hr>
<h2 id='importProblem'>importProblem</h2><span id='topic+importProblem'></span>

<h3>Description</h3>

<p>reads an sdcProblem with code that has been exported within <code><a href="#topic+sdcApp">sdcApp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importProblem(path)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="importProblem_+3A_path">path</code></td>
<td>
<p>a file path</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>sdcMicro_GUI_export</code> or an object of class 'simple.error'
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>

<hr>
<h2 id='indivRisk'>Individual Risk computation</h2><span id='topic+indivRisk'></span>

<h3>Description</h3>

<p>Estimation of the risk for each observation. After the risk is computed one
can use e.g. the function localSuppr() for the protection of values of high
risk.  Further details can be found at the link given below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indivRisk(x, method = "approx", qual = 1, survey = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indivRisk_+3A_x">x</code></td>
<td>
<p>object from class freqCalc</p>
</td></tr>
<tr><td><code id="indivRisk_+3A_method">method</code></td>
<td>
<p>approx (default) or exact</p>
</td></tr>
<tr><td><code id="indivRisk_+3A_qual">qual</code></td>
<td>
<p>final correction factor</p>
</td></tr>
<tr><td><code id="indivRisk_+3A_survey">survey</code></td>
<td>
<p>TRUE, if we have survey data and FALSE if we deal with a population.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>S4 class sdcMicro objects are only supported by function <em>measure_risk</em>
that also estimates the individual risk with the same method.
</p>


<h3>Value</h3>


<dl>
<dt>rk: </dt><dd><p> base individual risk </p>
</dd>
<dt>method: </dt><dd><p>method</p>
</dd>
<dt>qual: </dt><dd><p>final correction factor</p>
</dd>
<dt>fk: </dt><dd><p>frequency count</p>
</dd>
<dt>knames: </dt><dd><p>colnames of the key variables</p>
</dd></dl>



<h3>Note</h3>

<p>The base individual risk method was developed by Benedetti,
Capobianchi and Franconi
</p>


<h3>Author(s)</h3>

<p>Matthias Templ. Bug in method &ldquo;exact&rdquo; fixed since version
2.6.5. by Youri Baeyens.
</p>


<h3>References</h3>

<p>Templ, M. and Kowarik, A. and Meindl, B. 
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro. 
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>
<p>Franconi, L. and Polettini, S. (2004) <em>Individual risk
estimation in mu-Argus: a review</em>. Privacy in Statistical Databases, Lecture
Notes in Computer Science, 262&ndash;272. Springer
</p>
<p>Machanavajjhala, A. and Kifer, D. and Gehrke, J. and Venkitasubramaniam, M.
(2007) <em>l-Diversity: Privacy Beyond k-Anonymity</em>.  ACM Trans. Knowl.
Discov. Data, 1(1)
</p>
<p>additionally, have a look at the vignettes of sdcMicro for further reading.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+measure_risk">measure_risk</a></code>, <code><a href="#topic+freqCalc">freqCalc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
f &lt;- freqCalc(francdat, keyVars=c(2,4,5,6),w=8)
f
f$fk
f$Fk
## individual risk calculation:
indivf &lt;- indivRisk(f)
indivf$rk

</code></pre>

<hr>
<h2 id='infoLoss'>Calculate information loss after targeted record swapping</h2><span id='topic+infoLoss'></span>

<h3>Description</h3>

<p>Calculate information loss after targeted record swapping using both the original and the swapped micro data.
Information loss will be calculated on table counts defined by parameter 'table_vars' using either implemented information loss measures like absolute deviaton, relative absolute deviation and absolute deviation of square roots or custom metric, See details below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infoLoss(
  data,
  data_swapped,
  table_vars,
  metric = c("absD", "relabsD", "abssqrtD"),
  custom_metric = NULL,
  hid = NULL,
  probs = sort(c(seq(0, 1, by = 0.1), 0.95, 0.99)),
  quantvals = c(0, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, Inf),
  apply_quantvals = c("relabsD", "abssqrtD"),
  exclude_zeros = FALSE,
  only_inner_cells = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="infoLoss_+3A_data">data</code></td>
<td>
<p>original micro data set, must be either a 'data.table' or 'data.frame'.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_data_swapped">data_swapped</code></td>
<td>
<p>micro data set after targeted record swapping was applied. Must be either a 'data.table' or 'data.frame'.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_table_vars">table_vars</code></td>
<td>
<p>column names in both 'data' and 'data_swapped'. Defines the variables over which a (multidimensional) frequency table is constructed.
Information loss is then calculated by applying the metric in 'metric' and 'custom_merics' over the cell-counts and margin counts of the table from 'data' and 'data_swapped'.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_metric">metric</code></td>
<td>
<p>character vector containing one or more of the already implemented metrices: &quot;absD&quot;,&quot;relabsD&quot; and/or &quot;abssqrtD&quot;.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_custom_metric">custom_metric</code></td>
<td>
<p>function or (named) list of functions. Functions defined here must be of the form 'fun(x,y,...)'
where 'x' and 'y' expect numeric values of the same length. The output of these functions must be a numeric vector of the same length as 'x' and 'y'.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_hid">hid</code></td>
<td>
<p>'NULL' or character containing household id in 'data' and 'data_swapped'. If not 'NULL' frequencies will reflect number of households, otherwise frequencies will reflect number of persons.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_probs">probs</code></td>
<td>
<p>numeric vector containing values in the inervall [0,1].</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_quantvals">quantvals</code></td>
<td>
<p>optional numeric vector which defines the groups used for the cumulative outputs. Is applied on the results 'm' from each information loss metric as 'cut(m,breaks=quantvals,include.lowest=TRUE)', see also return values.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_apply_quantvals">apply_quantvals</code></td>
<td>
<p>character vector defining for the output of which metrices 'quantvals' should be applied to.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_exclude_zeros">exclude_zeros</code></td>
<td>
<p>'TRUE' or 'FALSE', if 'TRUE' 0 cells in the frequency table using 'data_swapped' will be ignored.</p>
</td></tr>
<tr><td><code id="infoLoss_+3A_only_inner_cells">only_inner_cells</code></td>
<td>
<p>'TRUE' or 'FALSE', if 'TRUE' only inner cells of the frequency table defined by 'table_vars' will be compared. Otherwise also all tables margins will bei calculated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First frequency tables are build from both 'data' and 'data_swapped' using the variables defined in 'table_vars'. By default also all table margins will be calculated, see parameter 'only_inner_cells = FALSE'.
After that the information loss metrices defined in either 'metric' or 'custom_metric' are applied on each of the table cells from both frequency tables.
This is done in the sense of 'metric(x,y)' where 'metric' is the information loss, 'x' a cell from the table created from 'data' and 'y' the same cell from the table created from 'data_swapped'. 
One or more custom metrices can be applied using the parameter 'custom_metric', see also examples.
</p>


<h3>Value</h3>

<p>Returns a list containing:
</p>
<p>* 'cellvalues': 'data.table' showing in a long format for each table cell the frequency counts for 'data' ~ 'count_o' and 'data_swapped' ~ 'count_s'. 
* 'overview': 'data.table' containing the disribution of the 'noise' in number of cells and percentage. The 'noise' ist calculated as the difference between the cell values of the frequency table generated from the original and swapped data
* 'measures': 'data.table' containing the quantiles and mean (column 'waht') of the distribution of the information loss metrices applied on each table cell. The quantiles are defined by parameter 'probs'.
* 'cumdistr\*': 'data.table' containing the cumulative distribution of the information loss metrices. Distribution is shown in number of cells ('cnt') and percentage ('pct'). Column 'cat' shows all unique values of the information loss metric or the grouping defined by 'quantvals'.    
* 'false_zero': number of table cells which are non-zero when using 'data' and zero when using 'data_swapped'.
* 'false_nonzero': number of table cells which are zero when using 'data' and non-zero when using 'data_swapped'.
* 'exclude_zeros': value passed to 'exclude_zero' when calling the function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate dummy data 
seed &lt;- 2021
set.seed(seed)
nhid &lt;- 10000
dat &lt;- createDat( nhid )

# define paramters for swapping
k_anonymity &lt;- 1
swaprate &lt;- .05
similar &lt;- list(c("hsize"))
hier &lt;- c("nuts1","nuts2")
carry_along &lt;- c("nuts3","lau2")
risk_variables &lt;- c("ageGroup","national")
hid &lt;- "hid"

# # apply record swapping
# dat_s &lt;- recordSwap(data = dat, hid = hid, hierarchy = hier,
#                     similar = similar, swaprate = swaprate,
#                     k_anonymity = k_anonymity,
#                     risk_variables = risk_variables,
#                     carry_along = carry_along,
#                     return_swapped_id = TRUE,
#                     seed=seed)
# 
# 
# # calculate informationn loss
# # for the table nuts2 x national
# iloss &lt;- infoLoss(data=dat, data_swapped = dat_s,
#                   table_vars = c("nuts2","national"))
# iloss$measures # distribution of information loss measures
# iloss$false_zero # no false zeros
# iloss$false_nonzero # no false non-zeros
# 
# # frequency tables of households accross
# # nuts2 x hincome
# 
# iloss &lt;- infoLoss(data=dat, data_swapped = dat_s,
 #                  table_vars = c("nuts2","hincome"),
#                   hid = "hid")
# iloss$measures  
# 
# # define custom metric
# squareD &lt;- function(x,y){
#   (x-y)^2
# }
# 
# iloss &lt;- infoLoss(data=dat, data_swapped = dat_s,
#                  table_vars = c("nuts2","national"),
#                  custom_metric = list(squareD=squareD))
# iloss$measures # includes custom loss as well
# 
</code></pre>

<hr>
<h2 id='kAnon_violations'><code>kAnon_violations</code></h2><span id='topic+kAnon_violations'></span><span id='topic+kAnon_violations+2CsdcMicroObj+2Clogical+2Cnumeric-method'></span>

<h3>Description</h3>

<p>returns the number of observations violating k-anonymity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kAnon_violations(object, weighted, k)

## S4 method for signature 'sdcMicroObj,logical,numeric'
kAnon_violations(object, weighted, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kAnon_violations_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object</p>
</td></tr>
<tr><td><code id="kAnon_violations_+3A_weighted">weighted</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> defining if sampling weights should be taken into account</p>
</td></tr>
<tr><td><code id="kAnon_violations_+3A_k">k</code></td>
<td>
<p>a positive number defining parameter k</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the number of records that are violating k-anonymity based on 
unweighted sample data only (in case parameter <code>weighted</code> is <code>FALSE</code>) or computing
the number of observations that are estimated to violate k-anonymity in the population in case 
parameter <code>weighted</code> equals <code>TRUE</code>.
</p>

<hr>
<h2 id='LocalRecProg'>Local recoding via Edmond's maximum weighted matching algorithm</h2><span id='topic+LocalRecProg'></span>

<h3>Description</h3>

<p>To be used on both categorical and numeric input variables, although usage
on categorical variables is the focus of the development of this software.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LocalRecProg(
  obj,
  ancestors = NULL,
  ancestor_setting = NULL,
  k_level = 2,
  FindLowestK = TRUE,
  weight = NULL,
  lowMemory = FALSE,
  missingValue = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LocalRecProg_+3A_obj">obj</code></td>
<td>
<p>a <code>data.frame</code> or a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_ancestors">ancestors</code></td>
<td>
<p>Names of ancestors of the cateorical variables</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_ancestor_setting">ancestor_setting</code></td>
<td>
<p>For each ancestor the corresponding categorical variable</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_k_level">k_level</code></td>
<td>
<p>Level for k-anonymity</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_findlowestk">FindLowestK</code></td>
<td>
<p>requests the program to look for the smallest k that
results in complete matches of the data.</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_weight">weight</code></td>
<td>
<p>A weight for each variable (Default=1)</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_lowmemory">lowMemory</code></td>
<td>
<p>Slower algorithm with less memory consumption</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_missingvalue">missingValue</code></td>
<td>
<p>The output value for a suppressed value.</p>
</td></tr>
<tr><td><code id="LocalRecProg_+3A_...">...</code></td>
<td>
<p>see arguments below
</p>

<dl>
<dt>categorical</dt><dd><p>Names of categorical variables</p>
</dd>
<dt>numerical</dt><dd><p>Names of numerical variables</p>
</dd></dl>
</td></tr>
</table>


<h3>Details</h3>

<p>Each record in the data represents a category of the original data, and
hence all records in the input data should be unique by the N Input
Variables. To achieve bigger category sizes (k-anoymity), one can form new
categories based on the recoding result and repeatedly apply this algorithm.
</p>


<h3>Value</h3>

<p>dataframe with original variables and the supressed variables
(suffix _lr). / the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>


<h3>Methods</h3>


<dl>
<dt>list(&quot;signature(obj=\&quot;sdcMicroObj\&quot;)&quot;)</dt><dd></dd></dl>



<h3>Author(s)</h3>

<p>Alexander Kowarik, Bernd Prantner, IHSN C++ source, Akimichi Takemura
</p>


<h3>References</h3>

<p>Kowarik, A. and Templ, M. and Meindl, B. and Fonteneau, F. and Prantner, B.:
<em>Testing of IHSN Cpp Code and Inclusion of New Methods into sdcMicro</em>,
in: Lecture Notes in Computer Science, J. Domingo-Ferrer, I. Tinnirello
(editors.); Springer, Berlin, 2012, ISBN: 978-3-642-33626-3, pp. 63-77.
<a href="https://doi.org/10.1007/978-3-642-33627-0_6">doi:10.1007/978-3-642-33627-0_6</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata2)
cat_vars &lt;- c("urbrur", "roof", "walls", "water", "sex", "relat")
anc_var &lt;- c("water2", "water3", "relat2")
anc_setting &lt;- c("water","water","relat")

r1 &lt;- LocalRecProg(
  obj = testdata2,
  categorical = cat_vars,
  missingValue = -99)
r2 &lt;- LocalRecProg(
  obj = testdata2,
  categorical = cat_vars,
  ancestor = anc_var,
  ancestor_setting = anc_setting,
  missingValue = -99)
r3 &lt;- LocalRecProg(
  obj = testdata2,
  categorical = cat_vars,
  ancestor = anc_var,
  ancestor_setting = anc_setting,
  missingValue = -99,
  FindLowestK = FALSE)

# for objects of class sdcMicro:
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = c("urbrur", "roof", "walls", "water", "electcon", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight")
sdc &lt;- LocalRecProg(sdc)

</code></pre>

<hr>
<h2 id='localSupp'>Local Suppression</h2><span id='topic+localSupp'></span>

<h3>Description</h3>

<p>A simple method to perfom local suppression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>localSupp(obj, threshold = 0.15, keyVar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="localSupp_+3A_obj">obj</code></td>
<td>
<p>object of class <code><a href="#topic+freqCalc">freqCalc</a></code> or <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>.</p>
</td></tr>
<tr><td><code id="localSupp_+3A_threshold">threshold</code></td>
<td>
<p>threshold for individual risk</p>
</td></tr>
<tr><td><code id="localSupp_+3A_keyvar">keyVar</code></td>
<td>
<p>Variable on which some values might be suppressed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Values of high risk (above the threshold) of a certain variable (parameter
keyVar) are suppressed.
</p>


<h3>Value</h3>

<p>an updated object of class <code><a href="#topic+freqCalc">freqCalc</a></code> or the <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
object with manipulated data.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ and Bernhard Meindl
</p>


<h3>References</h3>

<p>Templ, M. <em>Statistical Disclosure Control for Microdata
Using the R-Package sdcMicro</em>, Transactions on Data Privacy, vol. 1, number
2, pp. 67-85, 2008. <a href="http://www.tdp.cat/issues/abs.a004a08.php">http://www.tdp.cat/issues/abs.a004a08.php</a>
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4. <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+freqCalc">freqCalc</a></code>, <code><a href="#topic+indivRisk">indivRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(francdat)
keyVars &lt;- paste0("Key",1:4)

f &lt;- freqCalc(francdat, keyVars = keyVars, w = 8)
f
f$fk
f$Fk

## individual risk calculation:
indivf &lt;- indivRisk(f)
indivf$rk

## Local Suppression
localS &lt;- localSupp(f, keyVar = "Key4", threshold = 0.15)
f2 &lt;- freqCalc(localS$freqCalc, keyVars = keyVars, w = 8)
indivf2 &lt;- indivRisk(f2)
indivf2$rk
identical(indivf$rk, indivf2$rk)

## select another keyVar and run localSupp once again,
# if you think the table is not fully protected

## for objects of class sdcMicro:
data(testdata)
sdc &lt;- createSdcObj(
  dat = testdata,
  keyVars = c("urbrur", "roof", "walls", "water", "electcon", "relat", "sex"),
  w = "sampling_weight"
)
sdc &lt;- localSupp(sdc, keyVar = "urbrur", threshold = 0.045)
print(sdc, type = "ls")

</code></pre>

<hr>
<h2 id='localSuppression'>Local Suppression to obtain k-anonymity</h2><span id='topic+localSuppression'></span><span id='topic+kAnon'></span>

<h3>Description</h3>

<p>Algorithm to achieve k-anonymity by performing local suppression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>localSuppression(obj, k = 2, importance = NULL, combs = NULL, ...)

kAnon(obj, k = 2, importance = NULL, combs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="localSuppression_+3A_obj">obj</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="localSuppression_+3A_k">k</code></td>
<td>
<p>threshold for k-anonymity</p>
</td></tr>
<tr><td><code id="localSuppression_+3A_importance">importance</code></td>
<td>
<p>numeric vector of numbers between 1 and n (n=length of
vector keyVars).  This vector represents the &quot;importance&quot; of variables that
should be used for local suppression in order to obtain k-anonymity.
key-variables with importance=1 will - if possible - not suppressed,
key-variables with importance=n will be used whenever possible.</p>
</td></tr>
<tr><td><code id="localSuppression_+3A_combs">combs</code></td>
<td>
<p>numeric vector. if specified, the algorithm will provide k-anonymity
for each combination of n key variables (with n being the value of the ith element
of this parameter. For example, if combs=c(4,3), the algorithm will provide
k-anonymity to all combinations of 4 key variables and then k-anonymity to all
combinations of 3 key variables. It is possible to apply different k to these
subsets by specifying k as a vector. If k has only one element, the same value
of k will be used for all subgroups.</p>
</td></tr>
<tr><td><code id="localSuppression_+3A_...">...</code></td>
<td>
<p>see arguments below
</p>

<dl>
<dt>keyVars: </dt><dd><p>names (or indices) of categorical key variables (for data-frame method)</p>
</dd>
<dt>strataVars: </dt><dd><p>name (or index) of variable which is used for stratification purposes, used
in the data.frame method. This means that k-anonymity is provided within each category
of the specified variable.</p>
</dd>
<dt>alpha: </dt><dd><p>numeric value between 0 and 1 specifying how much keys that
contain missing values (<code>NAs</code>) should contribute to the calculation
of <code>fk</code> and <code>Fk</code>. For the default value of <code>1</code>, nothing changes with
respect to the implementation in prior versions. Each <em>wildcard-match</em> would
be counted while for <code>alpha=0</code> keys with missing values would be basically ignored.
Used in the data-frame method only because in the method for <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-objects,
this value is extracted from slot <code>options</code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm provides a k-anonymized data set by suppressing values in key
variables. The algorithm tries to find an optimal solution to suppress as
few values as possible and considers the specified importance vector. If not
specified, the importance vector is constructed in a way such that key
variables with a high number of characteristics are considered less
important than key variables with a low number of characteristics.
</p>
<p>The implementation provides k-anonymity per strata, if slot 'strataVar' has
been set in <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> or if parameter 'strataVar' is
used when appying the data.frame method. For details, have a look
at the examples provided.
</p>


<h3>Value</h3>

<p>Manipulated data set with suppressions that has k-anonymity with
respect to specified key-variables or the manipulated data stored in the
<code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>.
</p>


<h3>Note</h3>

<p>Deprecated methods 'localSupp2' and 'localSupp2Wrapper' are no longer available
in sdcMicro &gt; 4.5.0.
<code>kAnon</code> is a more intutitive term for localSuppression because the aim is always
to obtain k-anonymity for some parts of the data.
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl, Matthias Templ
</p>


<h3>References</h3>

<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>
<p>Templ, M. and Kowarik, A. and Meindl, B.
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro.
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(francdat)

## Local Suppression
localS &lt;- localSuppression(francdat, keyVar=c(4,5,6))
localS
plot(localS)

## for objects of class sdcMicro, no stratification
data(testdata2)
kv &lt;- c("urbrur", "roof", "walls", "water", "electcon", "relat", "sex")
sdc &lt;- createSdcObj(testdata2, keyVars = kv, w = "sampling_weight")
sdc &lt;- localSuppression(sdc)

## for objects of class sdcMicro, with stratification
testdata2$ageG &lt;- cut(testdata2$age, 5, labels=paste0("AG",1:5))
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = kv,
  w = "sampling_weight",
  strataVar = "ageG"
)
sdc &lt;- localSuppression(sdc)

## it is also possible to provide k-anonymity for subsets of key-variables
## with different parameter k!
## in this case we want to provide 10-anonymity for all combinations
## of 5 key variables, 20-anonymity for all combinations with 4 key variables
## and 30-anonymity for all combinations of 3 key variables.
sdc &lt;- createSdcObj(testdata2, keyVars = kv, w = "sampling_weight")
combs &lt;- 5:3
k &lt;- c(10, 20, 30)
sdc &lt;- localSuppression(sdc, k = k, combs = combs)

## data.frame method (no stratification)
inp &lt;- testdata2[,c(kv, "ageG")]
ls &lt;- localSuppression(inp, keyVars = 1:7)
print(ls)
plot(ls)

## data.frame method (with stratification)
ls &lt;- kAnon(inp, keyVars = 1:7, strataVars = 8)
print(ls)
plot(ls)

</code></pre>

<hr>
<h2 id='mafast'>Fast and Simple Microaggregation</h2><span id='topic+mafast'></span>

<h3>Description</h3>

<p>Function to perform a fast and simple (primitive) method of
microaggregation. (for large datasets)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mafast(obj, variables = NULL, by = NULL, aggr = 3, measure = mean)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mafast_+3A_obj">obj</code></td>
<td>
<p>either a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="mafast_+3A_variables">variables</code></td>
<td>
<p>variables to microaggregate. If obj is of class sdcMicroObj
the numerical key variables are chosen per default.</p>
</td></tr>
<tr><td><code id="mafast_+3A_by">by</code></td>
<td>
<p>grouping variable for microaggregation. If obj is of class
sdcMicroObj the strata variables are chosen per default.</p>
</td></tr>
<tr><td><code id="mafast_+3A_aggr">aggr</code></td>
<td>
<p>aggregation level (default=3)</p>
</td></tr>
<tr><td><code id="mafast_+3A_measure">measure</code></td>
<td>
<p>aggregation statistic, mean, median, trim, onestep (default =
mean)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If &lsquo;obj&rsquo; was of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> the corresponding
slots are filled, like manipNumVars, risk and utility.  If &lsquo;obj&rsquo; was
of class &ldquo;data.frame&rdquo; or &ldquo;matrix&rdquo; an object of the same class
is returned.
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik
</p>


<h3>See Also</h3>

<p><code><a href="#topic+microaggregation">microaggregation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Tarragona)
m1 &lt;- mafast(Tarragona, variables=c("GROSS.PROFIT","OPERATING.PROFIT","SALES"),aggr=3)
data(testdata)
m2 &lt;- mafast(testdata,variables=c("expend","income","savings"),aggr=50,by="sex")
summary(m2)

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- dRisk(sdc)
sdc@risk$numeric
sdc1 &lt;- mafast(sdc,aggr=4)
sdc1@risk$numeric

sdc2 &lt;- mafast(sdc,aggr=10)
sdc2@risk$numeric

### Performance tests
x &lt;- testdata
for(i in 1:20){
  x &lt;- rbind(x,testdata)
}
system.time({
  xx &lt;- mafast(
    obj = x,
    variables = c("expend", "income", "savings"),
    aggr = 50,
    by = "sex"
  )
})


</code></pre>

<hr>
<h2 id='measure_risk'>Disclosure Risk for Categorical Variables</h2><span id='topic+measure_risk'></span><span id='topic+ldiversity'></span><span id='topic+print.measure_risk'></span><span id='topic+print.ldiversity'></span>

<h3>Description</h3>

<p>The function measures the disclosure risk for weighted or unweighted data.
It computes the individual risk (and household risk if reasonable) and the
global risk. It also computes a risk threshold based on a global risk value.
</p>
<p>Prints a 'measure_risk'-object
</p>
<p>Prints a 'ldiversity'-object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measure_risk(obj, ...)

ldiversity(obj, ldiv_index = NULL, l_recurs_c = 2, missing = -999, ...)

## S3 method for class 'measure_risk'
print(x, ...)

## S3 method for class 'ldiversity'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="measure_risk_+3A_obj">obj</code></td>
<td>
<p>Object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="measure_risk_+3A_...">...</code></td>
<td>
<p>see arguments below
</p>

<dl>
<dt>data: </dt><dd><p>Input data, a data.frame.</p>
</dd>
<dt>keyVars: </dt><dd><p>names (or indices) of categorical key variables (for data-frame method)</p>
</dd>
<dt>w: </dt><dd><p>name of variable containing sample weights</p>
</dd>
<dt>hid: </dt><dd><p>name of the clustering variable, e.g. the household ID</p>
</dd>
<dt>max_global_risk: </dt><dd><p>Maximal global risk for threshold computation</p>
</dd>
<dt>fast_hier: </dt><dd><p>If TRUE a fast approximation is computed if household data are provided.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="measure_risk_+3A_ldiv_index">ldiv_index</code></td>
<td>
<p>indices (or names) of the variables used for l-diversity</p>
</td></tr>
<tr><td><code id="measure_risk_+3A_l_recurs_c">l_recurs_c</code></td>
<td>
<p>l-Diversity Constant</p>
</td></tr>
<tr><td><code id="measure_risk_+3A_missing">missing</code></td>
<td>
<p>a integer value to be used as missing value in the C++ routine</p>
</td></tr>
<tr><td><code id="measure_risk_+3A_x">x</code></td>
<td>
<p>Output of measure_risk() or ldiversity()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To be used when risk of disclosure for individuals within a family is
considered to be statistical independent.
</p>
<p>Internally, function <em>freqCalc()</em> and <em>indivRisk</em> are used for
estimation.
</p>
<p>Measuring individual risk: The individual risk approach based on so-called
super-population models. In such models population frequency counts are
modeled given a certain distribution.  The estimation procedure of sample
frequency counts given the population frequency counts is modeled by
assuming a negative binomial distribution. This is used for the estimation
of the individual risk. The extensive theory can be found in Skinner (1998),
the approximation formulas for the individual risk used is described in
Franconi and Polettini (2004).
</p>
<p>Measuring hierarchical risk: If &ldquo;hid&rdquo; - the index of variable holding
information on the hierarchical cluster structures (e.g., individuals that
are clustered in households) - is provided, the hierarchical risk is
additional estimated.  Note that the risk of re-identifying an individual
within a household may also affect the probability of disclosure of other
members in the same household. Thus, the household or cluster-structure of
the data must be taken into account when estimating disclosure risks. It is
commonly assumed that the risk of re-identification of a household is the
risk that at least one member of the household can be disclosed. Thus this
probability can be simply estimated from individual risks as 1 minus the
probability that no member of the household can be identified.
</p>
<p>Global risk: The sum of the individual risks in the dataset gives the
expected number of re-identifications that serves as measure of the global
risk.
</p>
<p>l-Diversity: If &ldquo;ldiv_index&rdquo; is unequal to NULL, i.e. if the indices
of sensible variables are specified, various measures for l-diversity are
calculated. l-diverstiy is an extension of the well-known k-anonymity
approach where also the uniqueness in sensible variables for each pattern
spanned by the key variables are evaluated.
</p>


<h3>Value</h3>

<p>A modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object or a list with the following elements:
</p>

<dl>
<dt>global_risk_ER: </dt><dd><p>expected number of re-identification.</p>
</dd>
<dt>global_risk: </dt><dd><p>global risk (sum of indivdual risks).</p>
</dd>
<dt>global_risk_pct: </dt><dd><p>global risk in percent.</p>
</dd>
<dt>Res: </dt><dd><p>matrix with the risk, frequency in the sample and grossed-up frequency in the population (and the hierachical risk) for each observation.</p>
</dd>
<dt>global_threshold: </dt><dd><p>for a given max_global_risk the threshold for the risk of observations.</p>
</dd>
<dt>max_global_risk: </dt><dd><p>the input max_global_risk of the function.</p>
</dd>
<dt>hier_risk_ER: </dt><dd><p>expected number of re-identification with household structure.</p>
</dd>
<dt>hier_risk: </dt><dd><p>global risk with household structure (sum of indivdual risks).</p>
</dd>
<dt>hier_risk_pct: </dt><dd><p>global risk with household structure in percent.</p>
</dd>
<dt>ldiverstiy: </dt><dd><p>Matrix with Distinct_Ldiversity,
Entropy_Ldiversity and Recursive_Ldiversity for each sensitivity variable.</p>
</dd></dl>

<p>Prints risk-information into the console
</p>
<p>Information on L-Diversity Measures in the console
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik, Bernhard Meindl, Matthias Templ, Bernd Prantner, minor parts of IHSN C++ source
</p>


<h3>References</h3>

<p>Franconi, L. and Polettini, S. (2004) <em>Individual risk
estimation in mu-Argus: a review</em>. Privacy in Statistical Databases, Lecture
Notes in Computer Science, 262&ndash;272. Springer
</p>
<p>Machanavajjhala, A. and Kifer, D. and Gehrke, J. and Venkitasubramaniam, M.
(2007) <em>l-Diversity: Privacy Beyond k-Anonymity</em>.  ACM Trans. Knowl.
Discov. Data, 1(1)
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>.
</p>
<p>#' Templ, M. and Kowarik, A. and Meindl, B.
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro.
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+freqCalc">freqCalc</a></code>, <code><a href="#topic+indivRisk">indivRisk</a></code>
</p>
<p><code><a href="#topic+measure_risk">measure_risk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## measure_risk with sdcMicro objects:
data(testdata)

sdc &lt;- createSdcObj(testdata,
  keyVars=c('urbrur','roof','walls','water','electcon'),
numVars=c('expend','income','savings'), w='sampling_weight')

## risk is already estimated and available in...
names(sdc@risk)

## measure risk on data frames or matrices:
res &lt;- measure_risk(testdata,
  keyVars=c("urbrur","roof","walls","water","sex"))
print(res)
head(res$Res)
resw &lt;- measure_risk(testdata,
  keyVars=c("urbrur","roof","walls","water","sex"),w="sampling_weight")
print(resw)
head(resw$Res)
res1 &lt;- ldiversity(testdata,
  keyVars=c("urbrur","roof","walls","water","sex"),ldiv_index="electcon")
print(res1)
head(res1)
res2 &lt;- ldiversity(testdata,
  keyVars=c("urbrur","roof","walls","water","sex"),ldiv_index=c("electcon","relat"))
print(res2)
head(res2)

# measure risk with household risk
resh &lt;- measure_risk(testdata,
  keyVars=c("urbrur","roof","walls","water","sex"),w="sampling_weight",hid="ori_hid")
print(resh)

# change max_global_risk
rest &lt;- measure_risk(testdata,
  keyVars=c("urbrur","roof","walls","water","sex"),
  w="sampling_weight",max_global_risk=0.0001)
print(rest)

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
## -&gt; when using `createSdcObj()`, the risks are already internally computed
## and it is not required to explicitely run `sdc &lt;- measure_risk(sdc)`

</code></pre>

<hr>
<h2 id='mergeHouseholdData'>Replaces the raw household-level data with the anonymized household-level data in the full dataset
for anonymization of data with a household structure (or other hierarchical structure).
Requires a matching household ID in both files.</h2><span id='topic+mergeHouseholdData'></span>

<h3>Description</h3>

<p>Replaces the raw household-level data with the anonymized household-level data in the full dataset
for anonymization of data with a household structure (or other hierarchical structure).
Requires a matching household ID in both files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mergeHouseholdData(dat, hhId, dathh)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mergeHouseholdData_+3A_dat">dat</code></td>
<td>
<p>a data.frame with the full dataset</p>
</td></tr>
<tr><td><code id="mergeHouseholdData_+3A_hhid">hhId</code></td>
<td>
<p>name of the household (cluster) ID (identical in both datasets)</p>
</td></tr>
<tr><td><code id="mergeHouseholdData_+3A_dathh">dathh</code></td>
<td>
<p>a dataframe with the treated household level data (generated for example with <a href="#topic+selectHouseholdData">selectHouseholdData</a>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with the treated household level variables and the raw individual level variables
</p>


<h3>Author(s)</h3>

<p>Thijs Benschop and Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load data
x &lt;- testdata

## donttest is necessary because of 
## Examples with CPU time &gt; 2.5 times elapsed time
## caused by using C++ code and/or data.table
## Create household level dataset
x_hh &lt;- selectHouseholdData(dat=x, hhId="ori_hid",
  hhVars=c("urbrur", "roof",  "walls", "water", "electcon", "household_weights"))
## Anonymize household level dataset and extract data
sdc_hh &lt;- createSdcObj(x_hh, keyVars=c('urbrur','roof'), w='household_weights')
sdc_hh &lt;- kAnon(sdc_hh, k = 3)
x_hh_anon &lt;- extractManipData(sdc_hh)
 
## Merge anonymized household level data back into the full dataset
x_anonhh &lt;- mergeHouseholdData(x, "ori_hid", x_hh_anon)
 
## Anonymize full dataset and extract data
sdc_full &lt;- createSdcObj(x_anonhh, keyVars=c('sex', 'age', 'urbrur', 'roof'), w='sampling_weight')
sdc_full &lt;- kAnon(sdc_full, k = 3)
x_full_anon &lt;- extractManipData(sdc_full)

</code></pre>

<hr>
<h2 id='microaggregation'>Microaggregation</h2><span id='topic+microaggregation'></span>

<h3>Description</h3>

<p>Function to perform various methods of microaggregation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>microaggregation(
  obj,
  variables = NULL,
  aggr = 3,
  strata_variables = NULL,
  method = "mdav",
  weights = NULL,
  nc = 8,
  clustermethod = "clara",
  measure = "mean",
  trim = 0,
  varsort = 1,
  transf = "log"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="microaggregation_+3A_obj">obj</code></td>
<td>
<p>either an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="microaggregation_+3A_variables">variables</code></td>
<td>
<p>variables to microaggregate. For <code>NULL</code>: If obj is of class
sdcMicroObj, all numerical key variables are chosen per default. For
<code>data.frames</code>, all columns are chosen per default.</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_aggr">aggr</code></td>
<td>
<p>aggregation level (default=3)</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_strata_variables">strata_variables</code></td>
<td>
<p>for <code>data.frames</code>, by-variables for applying microaggregation only
within strata defined by the variables. For <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-objects, the
stratification-variable defined in slot <code>@strataVar</code> is used. This slot can be changed any
time using <code>strataVar&lt;-</code>.</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_method">method</code></td>
<td>
<p>pca, rmd, onedims, single, simple, clustpca, pppca,
clustpppca, mdav, clustmcdpca, influence, mcdpca</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_weights">weights</code></td>
<td>
<p>sampling weights. If obj is of class sdcMicroObj the vector
of sampling weights is chosen automatically. If determined, a weighted
version of the aggregation measure is chosen automatically, e.g. weighted
median or weighted mean.</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_nc">nc</code></td>
<td>
<p>number of cluster, if the chosen method performs cluster analysis</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_clustermethod">clustermethod</code></td>
<td>
<p>clustermethod, if necessary</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_measure">measure</code></td>
<td>
<p>aggregation statistic, mean, median, trim, onestep (default=mean)</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_trim">trim</code></td>
<td>
<p>trimming percentage, if measure=trim</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_varsort">varsort</code></td>
<td>
<p>variable for sorting, if method=single</p>
</td></tr>
<tr><td><code id="microaggregation_+3A_transf">transf</code></td>
<td>
<p>transformation for data x</p>
</td></tr>
</table>


<h3>Details</h3>

<p>On <a href="https://research.cbs.nl/casc/glossary.htm">https://research.cbs.nl/casc/glossary.htm</a> one can found the
&ldquo;official&rdquo; definition of microaggregation:
</p>
<p>Records are grouped based on a proximity measure of variables of interest,
and the same small groups of records are used in calculating aggregates for
those variables. The aggregates are released instead of the individual
record values.
</p>
<p>The recommended method is &ldquo;rmd&rdquo; which forms the proximity using
multivariate distances based on robust methods. It is an extension of the
well-known method &ldquo;mdav&rdquo;.  However, when computational speed is
important, method &ldquo;mdav&rdquo; is the preferable choice.
</p>
<p>While for the proximity measure very different concepts can be used, the
aggregation itself is naturally done with the arithmetic mean.
Nevertheless, other measures of location can be used for aggregation,
especially when the group size for aggregation has been taken higher than 3.
Since the median seems to be unsuitable for microaggregation because of
being highly robust, other mesures which are included can be chosen. If a
complex sample survey is microaggregated, the corresponding sampling weights
should be determined to either aggregate the values by the weighted
arithmetic mean or the weighted median.
</p>
<p>This function contains also a method with which the data can be clustered
with a variety of different clustering algorithms. Clustering observations
before applying microaggregation might be useful.  Note, that the data are
automatically standardised before clustering.
</p>
<p>The usage of clustering method &lsquo;Mclust&rsquo; requires package mclust02,
which must be loaded first. The package is not loaded automatically, since
the package is not under GPL but comes with a different licence.
</p>
<p>The are also some projection methods for microaggregation included.  The
robust version &lsquo;pppca&rsquo; or &lsquo;clustpppca&rsquo; (clustering at first)
are fast implementations and provide almost everytime the best results.
</p>
<p>Univariate statistics are preserved best with the individual ranking method
(we called them &lsquo;onedims&rsquo;, however, often this method is named
&lsquo;individual ranking&rsquo;), but multivariate statistics are strong
affected.
</p>
<p>With method &lsquo;simple&rsquo; one can apply microaggregation directly on the
(unsorted) data. It is useful for the comparison with other methods as a
benchmark, i.e. replies the question how much better is a sorting of the
data before aggregation.
</p>


<h3>Value</h3>

<p>If &lsquo;obj&rsquo; was of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> the corresponding
slots are filled, like manipNumVars, risk and utility. If &lsquo;obj&rsquo; was
of class &ldquo;data.frame&rdquo;, an object of class &ldquo;micro&rdquo; with following entities is returned:
</p>

<dl>
<dt><code>x</code>: </dt><dd><p>original data</p>
</dd>
<dt><code>mx</code>: </dt><dd><p>the microaggregated dataset</p>
</dd>
<dt><code>method</code>: </dt><dd><p>method</p>
</dd>
<dt><code>aggr</code>: </dt><dd><p>aggregation level</p>
</dd>
<dt><code>measure</code>: </dt><dd><p>proximity measure for aggregation</p>
</dd></dl>



<h3>Note</h3>

<p>if only one variable is specified, <code><a href="#topic+mafast">mafast</a></code> is applied and argument <code>method</code> is ignored.
Parameters <code>measure</code> are ignored for methods <code>mdav</code> and <code>rmd</code>.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Bernhard Meindl
</p>
<p>For method &ldquo;mdav&rdquo;: This work is being supported by the International
Household Survey Network (IHSN) and funded by a DGF Grant provided by the
World Bank to the PARIS21 Secretariat at the Organisation for Economic
Co-operation and Development (OECD).  This work builds on previous work
which is elsewhere acknowledged.
</p>
<p>Author for the integration of the code for mdav in R: Alexander Kowarik.
</p>


<h3>References</h3>

<p>Templ, M. and Meindl, B., <em>Robust Statistics Meets SDC: New Disclosure
Risk Measures for Continuous Microdata Masking</em>, Lecture Notes in Computer
Science, Privacy in Statistical Databases, vol. 5262, pp. 113-126, 2008.
</p>
<p>Templ, M. <em>Statistical Disclosure Control for Microdata Using the
R-Package sdcMicro</em>, Transactions on Data Privacy, vol. 1, number 2, pp.
67-85, 2008.  <a href="http://www.tdp.cat/issues/abs.a004a08.php">http://www.tdp.cat/issues/abs.a004a08.php</a>
</p>
<p>Templ, M. <em>New Developments in Statistical Disclosure Control and
Imputation: Robust Statistics Applied to Official Statistics</em>,
Suedwestdeutscher Verlag fuer Hochschulschriften, 2009, ISBN: 3838108280,
264 pages.
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4. <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>
<p>Templ, M. and Meindl, B. and Kowarik, A.: <em>Statistical Disclosure Control for
Micro-Data Using the R Package sdcMicro</em>, Journal of Statistical Software,
67 (4), 1&ndash;36, 2015.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.micro">summary.micro</a></code>, <code><a href="#topic+plotMicro">plotMicro</a></code>,
<code><a href="#topic+valTable">valTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata)
# donttest since Examples with CPU time larger 2.5 times elapsed time, because
# of using data.table and multicore computation.

m &lt;- microaggregation(
  obj = testdata[1:100, c("expend", "income", "savings")],
  method = "mdav",
  aggr = 4
)
summary(m)

## for objects of class sdcMicro:
## no stratification because `@strataVar` is `NULL`
data(testdata2)
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = c("urbrur", "roof", "walls", "water", "electcon", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight"
)
sdc &lt;- microaggregation(
  obj = sdc,
  variables = c("expend", "income")
)

## with stratification using variable `"relat"`
strataVar(sdc) &lt;- "relat"
sdc &lt;- microaggregation(
  obj = sdc,
  variables = "savings"
)

</code></pre>

<hr>
<h2 id='microaggrGower'>Microaggregation for numerical and categorical key variables based on a
distance similar to the Gower Distance</h2><span id='topic+microaggrGower'></span>

<h3>Description</h3>

<p>The microaggregation is based on the distances computed similar to the Gower
distance. The distance function makes distinction between the variable types
factor,ordered,numerical and mixed (semi-continuous variables with a fixed
probability mass at a constant value e.g. 0)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>microaggrGower(
  obj,
  variables = NULL,
  aggr = 3,
  dist_var = NULL,
  by = NULL,
  mixed = NULL,
  mixed.constant = NULL,
  trace = FALSE,
  weights = NULL,
  numFun = mean,
  catFun = VIM::sampleCat,
  addRandom = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="microaggrGower_+3A_obj">obj</code></td>
<td>
<p><code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_variables">variables</code></td>
<td>
<p>character vector with names of variables to be aggregated
(Default for sdcMicroObj is all keyVariables and all numeric key variables)</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_aggr">aggr</code></td>
<td>
<p>aggregation level (default=3)</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_dist_var">dist_var</code></td>
<td>
<p>character vector with variable names for distance
computation</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_by">by</code></td>
<td>
<p>character vector with variable names to split the dataset before
performing microaggregation (Default for sdcMicroObj is strataVar)</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_mixed">mixed</code></td>
<td>
<p>character vector with names of mixed variables</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_mixed.constant">mixed.constant</code></td>
<td>
<p>numeric vector with length equal to mixed, where the
mixed variables have the probability mass</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_trace">trace</code></td>
<td>
<p>TRUE/FALSE for some console output</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_weights">weights</code></td>
<td>
<p>numerical vector with length equal the number of variables
for distance computation</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_numfun">numFun</code></td>
<td>
<p>function: to be used to aggregated numerical variables</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_catfun">catFun</code></td>
<td>
<p>function: to be used to aggregated categorical variables</p>
</td></tr>
<tr><td><code id="microaggrGower_+3A_addrandom">addRandom</code></td>
<td>
<p>TRUE/FALSE if a random value should be added for the
distance computation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function sampleCat samples with probabilities corresponding to the
occurrence of the level in the NNs. The function maxCat chooses the level
with the most occurrences and random if the maximum is not unique.
</p>


<h3>Value</h3>

<p>The function returns the updated sdcMicroObj or simply an altered
data frame.
</p>


<h3>Note</h3>

<p>In each by group all distance are computed, therefore introducing more
by-groups significantly decreases the computation time and memory
consumption.
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik
</p>


<h3>See Also</h3>

<p><code><a href="VIM.html#topic+sampleCat">sampleCat</a></code> and <code><a href="VIM.html#topic+maxCat">maxCat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(testdata,package="sdcMicro")
testdata &lt;- testdata[1:200,]

for(i in c(1:7,9)) testdata[,i] &lt;- as.factor(testdata[,i])
test &lt;- microaggrGower(testdata,variables=c("relat","age","expend"),
  dist_var=c("age","sex","income","savings"),by=c("urbrur","roof"))

sdc &lt;- createSdcObj(testdata,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')

sdc &lt;- microaggrGower(sdc)

</code></pre>

<hr>
<h2 id='microData'>microData</h2><span id='topic+microData'></span>

<h3>Description</h3>

<p>Small aritificial toy data set.
</p>


<h3>Format</h3>

<p>The format is: num [1:13, 1:5] 5 7 2 1 7 8 12 3 15 4 ...  - attr(*,
&quot;dimnames&quot;)=List of 2 ..$ : chr [1:13] &quot;10000&quot; &quot;11000&quot; &quot;12000&quot; &quot;12100&quot; ...
..$ : chr [1:5] &quot;one&quot; &quot;two&quot; &quot;three&quot; &quot;four&quot; ...
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(microData)
microData &lt;- as.data.frame(microData)
m1 &lt;- microaggregation(microData, method="mdav")
summary(m1)

</code></pre>

<hr>
<h2 id='modRisk'>Global risk using log-linear models.</h2><span id='topic+modRisk'></span>

<h3>Description</h3>

<p>The sample frequencies are assumed to be independent and following a Poisson
distribution. The parameters of the corresponding parameters are estimated
by a log-linear model including the main effects and possible interactions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modRisk(obj, method = "default", weights, formulaM, bound = Inf, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="modRisk_+3A_obj">obj</code></td>
<td>
<p>An <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a numeric matrix
or data.frame containing all variables required in the specified model.</p>
</td></tr>
<tr><td><code id="modRisk_+3A_method">method</code></td>
<td>
<p>chose method for model-based risk-estimation. Currently, the
following methods can be selected:
</p>

<ul>
<li><p> &quot;default&quot;: the standard log-linear model.
</p>
</li>
<li><p> &quot;CE&quot;: the Clogg Eliason method, additionally,  considers survey weights by using an offset term.
</p>
</li>
<li><p> &quot;PML&quot;: the pseudo maximum likelihood method.
</p>
</li>
<li><p> &quot;weightedLLM&quot;: the weighted maximum likelihood method, considers survey weights by including them as one of the predictors.
</p>
</li>
<li><p> &quot;IPF&quot;: iterative proportional fitting as used in deprecated method 'LLmodGlobalRisk'.
</p>
</li></ul>
</td></tr>
<tr><td><code id="modRisk_+3A_weights">weights</code></td>
<td>
<p>a variable name specifying sampling weights</p>
</td></tr>
<tr><td><code id="modRisk_+3A_formulam">formulaM</code></td>
<td>
<p>A formula specifying the model.</p>
</td></tr>
<tr><td><code id="modRisk_+3A_bound">bound</code></td>
<td>
<p>a number specifying a threshold for 'risky' observations in the sample.</p>
</td></tr>
<tr><td><code id="modRisk_+3A_...">...</code></td>
<td>
<p>additional parameters passed through, currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This measure aims to (1) calculate the number of sample uniques that are
population uniques with a probabilistic Poisson model and (2) to estimate
the expected number of correct matches for sample uniques.
</p>
<p>ad 1) this risk measure is defined over all sample uniques as </p>
<p style="text-align: center;"><code class="reqn"> \tau_1
= \sum\limits_{j:f_j=1} P(F_j=1 | f_j=1) \quad , </code>
</p>
<p> i.e. the expected number
of sample uniques that are population uniques.
</p>
<p>ad 2) this risk measure is defined over all sample uniques as </p>
<p style="text-align: center;"><code class="reqn"> \tau_2
= \sum\limits_{j:f_j=1} P(1 / F_j | f_j=1) \quad . </code>
</p>

<p>Since population frequencies <code class="reqn">F_k</code> are unknown, they need to be
estimated.
</p>
<p>The iterative proportional fitting method is used to fit the parameters of
the Poisson distributed frequency counts related to the model specified to
fit the frequency counts. The obtained parameters are used to estimate a
global risk, defined in Skinner and Holmes (1998).
</p>


<h3>Value</h3>

<p>Two global risk measures and some model output given the specified model. If this method
is applied to an <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object, the slot 'risk' in the object ist updated
with the result of the model-based risk-calculation.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Marius Totter, Bernhard Meindl
</p>


<h3>References</h3>

<p>Skinner, C.J. and Holmes, D.J. (1998) <em>Estimating the
re-identification risk per record in microdata</em>. Journal of Official
Statistics, 14:361-372, 1998.
</p>
<p>Rinott, Y. and Shlomo, N. (1998). <em>A Generalized Negative Binomial
Smoothing Model for Sample Disclosure Risk Estimation</em>. Privacy in
Statistical Databases. Lecture Notes in Computer Science.  Springer-Verlag,
82&ndash;93.
</p>
<p>Clogg, C.C. and Eliasson, S.R. (1987). <em>Some Common Problems in Log-Linear Analysis</em>. Sociological Methods and Research, 8-44.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+loglm">loglm</a></code>, <code><a href="#topic+measure_risk">measure_risk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## data.frame method
data(testdata2)
form &lt;- ~sex+water+roof
w &lt;- "sampling_weight"

(modRisk(testdata2, method = "default", formulaM = form, weights = w))
(modRisk(testdata2, method = "CE", formulaM = form, weights = w))
(modRisk(testdata2, method = "PML", formulaM = form, weights = w))
(modRisk(testdata2, method = "weightedLLM", formulaM = form, weights = w))
(modRisk(testdata2, method = "IPF", formulaM = form, weights = w))

## application to a sdcMicroObj
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
 keyVars = c("urbrur", "roof", "walls", "electcon", "relat", "sex"),
 numVars = c("expend", "income", "savings"),
 w = "sampling_weight")
sdc &lt;- modRisk(sdc, form = ~sex+water+roof)
slot(sdc, "risk")$model



# an example using data from the laeken-pkg
library(laeken)
data(eusilc)
f &lt;- as.formula(paste(" ~ ", "db040 + hsize + rb090 +
             age + pb220a + age:rb090 + age:hsize +
             hsize:rb090"))
w &lt;- "rb050"
(modRisk(eusilc, method = "default", weights = w, formulaM = f, bound = 5))
(modRisk(eusilc, method = "CE", weights =  w, formulaM = f, bound = 5))
(modRisk(eusilc, method = "PML", weights = w, formulaM = f, bound = 5))
(modRisk(eusilc, method = "weightedLLM", weights = w, formulaM = f, bound = 5))


</code></pre>

<hr>
<h2 id='mvTopCoding'>Detection and winsorization of multivariate outliers</h2><span id='topic+mvTopCoding'></span>

<h3>Description</h3>

<p>Imputation and detection of outliers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvTopCoding(x, maha = NULL, center = NULL, cov = NULL, alpha = 0.025)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvTopCoding_+3A_x">x</code></td>
<td>
<p>an object coercible to a <code>data.table</code> containing numeric entries</p>
</td></tr>
<tr><td><code id="mvTopCoding_+3A_maha">maha</code></td>
<td>
<p>squared mahalanobis distance of each observation</p>
</td></tr>
<tr><td><code id="mvTopCoding_+3A_center">center</code></td>
<td>
<p>center of data, needed for calculation of mahalanobis
distance (if not provided)</p>
</td></tr>
<tr><td><code id="mvTopCoding_+3A_cov">cov</code></td>
<td>
<p>covariance matrix of data, needed for calcualtion of mahalanobis
distance (if not provided)</p>
</td></tr>
<tr><td><code id="mvTopCoding_+3A_alpha">alpha</code></td>
<td>
<p>significance level, determining the ellipsoide to which
outliers should be placed upon</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Winsorizes the potential outliers on the ellipsoid defined by
(robust) Mahalanobis distances in direction to the center of the data
</p>


<h3>Value</h3>

<p>the imputed winsorized data
</p>


<h3>Author(s)</h3>

<p>Johannes Gussenbauer, Matthias Templ
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- MASS::mvrnorm(20, mu = c(5,5), Sigma = matrix(c(1,0.9,0.9,1), ncol = 2))
x[1, 1] &lt;- 3
x[1, 2] &lt;- 6
plot(x)
ximp &lt;- mvTopCoding(x)
points(ximp, col = "blue", pch = 4)

# more dimensions
Sigma &lt;- diag(5)
Sigma[upper.tri(Sigma)] &lt;- 0.9
Sigma[lower.tri(Sigma)] &lt;- 0.9
x &lt;- MASS::mvrnorm(20, mu = rep(5,5), Sigma = Sigma)
x[1, 1] &lt;- 3
x[1, 2] &lt;- 6
pairs(x)

ximp &lt;- mvTopCoding(x)
xnew &lt;- data.frame(rbind(x, ximp))
xnew$beforeafter &lt;- rep(c(0,1), each = nrow(x))
pairs(xnew, col = xnew$beforeafter, pch = 4)

# by hand (non-robust)
x[2,2] &lt;- NA
m &lt;- colMeans(x, na.rm = TRUE)
s &lt;- cov(x, use = "complete.obs")
md &lt;- stats::mahalanobis(x, m, s)
ximp &lt;- mvTopCoding(x, center = m, cov = s, maha = md)
plot(x)
points(ximp, col = "blue", pch = 4)

</code></pre>

<hr>
<h2 id='nextSdcObj'>nextSdcObj</h2><span id='topic+nextSdcObj'></span>

<h3>Description</h3>

<p>internal function used to provide the undo-functionality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nextSdcObj(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nextSdcObj_+3A_obj">obj</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object
</p>

<hr>
<h2 id='orderData_cpp'>Reorder data</h2><span id='topic+orderData_cpp'></span>

<h3>Description</h3>

<p>Reorders the data according to a column in the data set.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>orderData</code> which is used inside the C++-function <code>recordSwap()</code> to speed up performance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orderData_cpp(data, orderIndex)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orderData_cpp_+3A_data">data</code></td>
<td>
<p>micro data set containing only numeric values.</p>
</td></tr>
<tr><td><code id="orderData_cpp_+3A_orderindex">orderIndex</code></td>
<td>
<p>column index in <code>data</code> refering to the column by which data should be ordered.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ordered data set.
</p>

<hr>
<h2 id='plot.localSuppression'>Plots for localSuppression objects</h2><span id='topic+plot.localSuppression'></span>

<h3>Description</h3>

<p>This function creates barplots to display the number of suppressed values
in categorical key variables to achieve <code>k</code>-anonymity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'localSuppression'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.localSuppression_+3A_x">x</code></td>
<td>
<p>object of derived from <code><a href="#topic+localSuppression">localSuppression()</a></code></p>
</td></tr>
<tr><td><code id="plot.localSuppression_+3A_...">...</code></td>
<td>
<p>Additional arguments, currently available are:
</p>

<ul>
<li> <p><code>"showDetails"</code>: logical, if set, a plot of suppressions by
strata is shown (if possible)
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>ggplot</code> plot object
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl, Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+localSuppression">localSuppression()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(francdat)
</code></pre>

<hr>
<h2 id='plot.sdcMicroObj'>Plotfunctions for objects of class <a href="#topic+sdcMicroObj-class">sdcMicroObj</a></h2><span id='topic+plot.sdcMicroObj'></span>

<h3>Description</h3>

<p>Descriptive plot function for <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>-objects. Currently
only visualization of local supression is implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sdcMicroObj'
plot(x, type = "ls", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sdcMicroObj_+3A_x">x</code></td>
<td>
<p>An object of class <a href="#topic+sdcMicroObj-class">sdcMicroObj</a></p>
</td></tr>
<tr><td><code id="plot.sdcMicroObj_+3A_type">type</code></td>
<td>
<p>specified what kind of plot will be generated
</p>

<ul>
<li> <p><code>"ls"</code>: plot of local suppressions in key variables
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.sdcMicroObj_+3A_...">...</code></td>
<td>
<p>currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>ggplot</code> plot object or (invisible) <code>NULL</code> if local suppression
using <code><a href="#topic+kAnon">kAnon()</a></code> has not been applied
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(testdata)
sdc &lt;- createSdcObj(testdata,
  keyVars = c("urbrur", "roof", "walls", "relat", "sex"),
  w = "sampling_weight")
sdc &lt;- kAnon(sdc, k = 3)
plot(sdc, type = "ls")

</code></pre>

<hr>
<h2 id='plotMicro'>Comparison plots</h2><span id='topic+plotMicro'></span>

<h3>Description</h3>

<p>Plots for the comparison of the original data and perturbed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMicro(x, p, which.plot = 1:3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotMicro_+3A_x">x</code></td>
<td>
<p>an output object of <code><a href="#topic+microaggregation">microaggregation()</a></code></p>
</td></tr>
<tr><td><code id="plotMicro_+3A_p">p</code></td>
<td>
<p>necessary parameter for the box cox transformation (<code>lambda</code>)</p>
</td></tr>
<tr><td><code id="plotMicro_+3A_which.plot">which.plot</code></td>
<td>
<p>which plot should be created?
</p>

<ul>
<li> <p><code>1</code>: density traces
</p>
</li>
<li> <p><code>2</code>: parallel boxplots
</p>
</li>
<li> <p><code>3</code>: differences in totals
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Univariate and multivariate comparison plots are implemented to detect
differences between the perturbed and the original data, but also to compare
perturbed data which are produced by different methods.
</p>


<h3>Value</h3>

<p>returns <code>NULL</code>; the selected plot is displayed
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Templ, M. and Meindl, B., <em>Software Development for SDC in
R</em>, Lecture Notes in Computer Science, Privacy in Statistical Databases,
vol. 4302, pp. 347-359, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+microaggregation">microaggregation()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(free1)
df &lt;- as.data.frame(free1)[, 31:34]
m1 &lt;- microaggregation(df, method = "onedims", aggr = 3)
plotMicro(m1, p = 1, which.plot = 1)
plotMicro(m1, p = 1, which.plot = 2)
plotMicro(m1, p = 1, which.plot = 3)
</code></pre>

<hr>
<h2 id='pram'>Post Randomization</h2><span id='topic+pram'></span>

<h3>Description</h3>

<p>To be used on categorical data stored as factors. The algorithm randomly
changes the values of variables in selected records (usually the risky ones)
according to an invariant probability transition matrix or a custom-defined
transition matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pram(obj, variables = NULL, strata_variables = NULL, pd = 0.8, alpha = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pram_+3A_obj">obj</code></td>
<td>
<p>Input data. Allowed input data are objects of class
<code>data.frame</code>, <code>factor</code> or <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>.</p>
</td></tr>
<tr><td><code id="pram_+3A_variables">variables</code></td>
<td>
<p>Names of variables in <code>obj</code> on which post-randomization
should be applied. If <code>obj</code> is a factor, this argument is ignored. Please note that
pram can only be applied to factor-variables.</p>
</td></tr>
<tr><td><code id="pram_+3A_strata_variables">strata_variables</code></td>
<td>
<p>names of variables for stratification (will be set
automatically for an object of class <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>. One can also specify
an integer vector or factor that specifies that desired groups. This vector must match the dimension
of the input data set, however. For a possible use case, have a look at the examples.</p>
</td></tr>
<tr><td><code id="pram_+3A_pd">pd</code></td>
<td>
<p>minimum diagonal entries for the generated transition matrix P.
Either a vector of length 1 (which is recycled) or a vector of the same length as
the number of variables that should be postrandomized. It is also possible to set <code>pd</code>
to a numeric matrix. This matrix will be used directly as the transition matrix. The matrix must
be constructed as follows:
</p>

<ul>
<li><p> the matrix must be a square matrix
</p>
</li>
<li><p> the rownames and colnames of the matrix must match the levels (in the same order) of the factor-variable that should be
postrandomized.
</p>
</li>
<li><p> the rowSums and colSums of the matrix need to equal 1
</p>
</li></ul>

<p>It is also possible to combine the different ways. For details have a look at the examples.</p>
</td></tr>
<tr><td><code id="pram_+3A_alpha">alpha</code></td>
<td>
<p>amount of perturbation for the invariant Pram method. This is a numeric vector
of length 1 (that will be recycled if necessary) or a vector of the same length as the number
of variables. If one specified as transition matrix directly, <code>alpha</code> is ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a modified <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> object or a new object containing
original and post-randomized variables (with suffix &quot;_pram&quot;).
</p>


<h3>Note</h3>

<p>Deprecated method 'pram_strata' is no longer available
in sdcMicro &gt; 4.5.0
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik, Matthias Templ, Bernhard Meindl
</p>


<h3>References</h3>

<p><a href="https://www.gnu.org/software/glpk/">https://www.gnu.org/software/glpk/</a>
</p>
<p>Kowarik, A. and Templ, M. and Meindl, B. and Fonteneau, F. and Prantner, B.:
<em>Testing of IHSN Cpp Code and Inclusion of New Methods into sdcMicro</em>,
in: Lecture Notes in Computer Science, J. Domingo-Ferrer, I. Tinnirello
(editors.); Springer, Berlin, 2012, ISBN: 978-3-642-33626-3, pp. 63-77.
<a href="https://doi.org/10.1007/978-3-642-33627-0_6">doi:10.1007/978-3-642-33627-0_6</a>
</p>
<p>Templ, M. and Kowarik, A. and Meindl, B.: <em>Statistical Disclosure Control for
Micro-Data Using the R Package sdcMicro.</em> in: Journal of Statistical Software, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>
<p>Templ, M.: <em>Statistical Disclosure Control for Microdata: Methods and Applications in R.</em>
in: Springer International Publishing, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata)

## donttest is necessary because of 
## Examples with CPU time &gt; 2.5 times elapsed time
## caused by using C++ code and/or data.table
## using a factor variable as input
res &lt;- pram(as.factor(testdata$roof))
print(res)
summary(res)

## using a data.frame as input
## pram can only be applied to factors
## -- &gt; we have to recode to factors beforehand
testdata$roof &lt;- factor(testdata$roof)
testdata$walls &lt;- factor(testdata$walls)
testdata$water &lt;- factor(testdata$water)

## pram() is applied within subgroups defined by
## variables "urbrur" and "sex"
res &lt;- pram(
  obj = testdata,
  variables = "roof",
 strata_variables = c("urbrur", "sex"))
print(res)
summary(res)

## default parameters (pd = 0.8 and alpha = 0.5) for the generation
## of the invariant transition matrix will be used for all variables
res1 &lt;- pram(
  obj = testdata,
  variables = c("roof", "walls", "water"))
print(res1)

## specific parameter settings for each variable
res2 &lt;- pram(
   obj = testdata,
   variables = c("roof", "walls", "water"),
   pd = c(0.95, 0.8, 0.9),
   alpha = 0.5)
print(res2)

## detailed information on pram-parameters (such as the transition matrix 'Rs')
## is stored in the output, eg. for variable 'roof'
#attr(res2, "pram_params")$roof
## we can also specify a custom transition-matrix directly
mat &lt;- diag(length(levels(testdata$roof)))
rownames(mat) &lt;- colnames(mat) &lt;- levels(testdata$roof)
res3 &lt;- pram(
   obj = testdata,
   variables = "roof",
  pd = mat)
print(res3) # of course, nothing has changed!
## it is possible use a transition matrix for a variable and use the 'traditional' way
## of specifying a number for the minimal diagonal entries of the transision matrix
## for other variables. In this case we must supply `pd` as list.
res4 &lt;- pram(
  obj = testdata,
  variables = c("roof", "walls"),
  pd = list(mat, 0.5),
  alpha = c(NA, 0.5))
print(res4)
summary(res4)
attr(res4, "pram_params")

## application to objects of class sdcMicro with default parameters
data(testdata2)
testdata2$urbrur &lt;- factor(testdata2$urbrur)
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = c("roof", "walls", "water", "electcon", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight")
sdc &lt;- pram(
  obj = sdc,
  variables = "urbrur")
print(sdc, type = "pram")

## this is equal to the previous application. If argument 'variables' is NULL,
## all variables from slot 'pramVars' will be used if possible.
sdc &lt;- createSdcObj(
   dat = testdata2,
  keyVars = c("roof", "walls", "water", "electcon", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight",
  pramVars = "urbrur")
sdc &lt;- pram(sdc)
print(sdc, type="pram")

## we can specify transition matrices for sdcMicroObj-objects too
#testdata2$roof &lt;- factor(testdata2$roof)
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = c("roof", "walls", "water", "electcon", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight")
mat &lt;- diag(length(levels(testdata2$roof)))

rownames(mat) &lt;- colnames(mat) &lt;- levels(testdata2$roof)
mat[1,] &lt;- c(0.9, 0, 0, 0.05, 0.05)
sdc &lt;- pram(
   obj = sdc,
   variables = "roof",
   pd = mat)
print(sdc, type = "pram")

## we can also have a look at the transitions
get.sdcMicroObj(sdc, "pram")$transitions

</code></pre>

<hr>
<h2 id='print.freqCalc'>Print method for objects from class freqCalc.</h2><span id='topic+print.freqCalc'></span>

<h3>Description</h3>

<p>Print method for objects from class freqCalc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'freqCalc'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.freqCalc_+3A_x">x</code></td>
<td>
<p>object from class <code><a href="#topic+freqCalc">freqCalc</a></code></p>
</td></tr>
<tr><td><code id="print.freqCalc_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>information about the frequency counts for key variables for object
of class <code><a href="#topic+freqCalc">freqCalc</a></code>.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+freqCalc">freqCalc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
f &lt;- freqCalc(francdat, keyVars=c(2,4,5,6),w=8)
f

</code></pre>

<hr>
<h2 id='print.indivRisk'>Print method for objects from class indivRisk</h2><span id='topic+print.indivRisk'></span>

<h3>Description</h3>

<p>Print method for objects from class indivRisk
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'indivRisk'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.indivRisk_+3A_x">x</code></td>
<td>
<p>object from class indivRisk</p>
</td></tr>
<tr><td><code id="print.indivRisk_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>few information about the method and the final correction factor for
objects of class &lsquo;indivRisk&rsquo;.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indivRisk">indivRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
f1 &lt;- freqCalc(francdat, keyVars=c(2,4,5,6),w=8)
data.frame(fk=f1$fk, Fk=f1$Fk)
## individual risk calculation:
indivRisk(f1)

</code></pre>

<hr>
<h2 id='print.localSuppression'>Print method for objects from class localSuppression</h2><span id='topic+print.localSuppression'></span>

<h3>Description</h3>

<p>Print method for objects from class localSuppression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'localSuppression'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.localSuppression_+3A_x">x</code></td>
<td>
<p>object from class localSuppression</p>
</td></tr>
<tr><td><code id="print.localSuppression_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Information about the frequency counts for key variables for object
of class &lsquo;localSuppression&rsquo;.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+localSuppression">localSuppression</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
l1 &lt;- localSuppression(francdat, keyVars=c(2,4,5,6))
l1

</code></pre>

<hr>
<h2 id='print.micro'>Print method for objects from class micro</h2><span id='topic+print.micro'></span>

<h3>Description</h3>

<p>printing an object of class <code>micro</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'micro'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.micro_+3A_x">x</code></td>
<td>
<p>object from class micro</p>
</td></tr>
<tr><td><code id="print.micro_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>information about method and aggregation level from objects of class
micro.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+microaggregation">microaggregation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(free1)
free1 &lt;- as.data.frame(free1)
m1 &lt;- microaggregation(free1[, 31:34], method='onedims', aggr=3)
m1

</code></pre>

<hr>
<h2 id='print.modrisk'>Print method for objects from class modrisk</h2><span id='topic+print.modrisk'></span><span id='topic+modrisk'></span>

<h3>Description</h3>

<p>Print method for objects from class modrisk
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'modrisk'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.modrisk_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+modrisk">modrisk</a></code></p>
</td></tr>
<tr><td><code id="print.modrisk_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Output of model-based risk estimation
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modRisk">modRisk</a></code>
</p>

<hr>
<h2 id='print.pram'>Print method for objects from class pram</h2><span id='topic+print.pram'></span>

<h3>Description</h3>

<p>Print method for objects from class pram
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pram'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.pram_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+pram">pram</a></code></p>
</td></tr>
<tr><td><code id="print.pram_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>absolute and relative frequencies of changed observations in each modified variable
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl, Matthias Templ
</p>
<p>Matthias Templ and Bernhard Meindl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pram">pram</a></code>
</p>

<hr>
<h2 id='print.sdcMicroObj'>Print and Extractor Functions for objects of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></h2><span id='topic+print.sdcMicroObj'></span><span id='topic+print+2CsdcMicroObj-method'></span>

<h3>Description</h3>

<p>Descriptive print function for Frequencies, local Supression, Recoding,
categorical risk and numerical risk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'sdcMicroObj'
print(x, type = "kAnon", docat = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sdcMicroObj_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="print.sdcMicroObj_+3A_type">type</code></td>
<td>
<p>Selection of the content to be returned or printed</p>
</td></tr>
<tr><td><code id="print.sdcMicroObj_+3A_docat">docat</code></td>
<td>
<p>logical, if TRUE (default) the results will be actually printed</p>
</td></tr>
<tr><td><code id="print.sdcMicroObj_+3A_...">...</code></td>
<td>
<p>the type argument for the print method, currently supported are:
</p>

<ul>
<li><p> general: basic information on the input obj such as the number of observations
and variables.
</p>
</li>
<li><p> kAnon: displays information about 2- and 3-anonymity
</p>
</li>
<li><p> ls: displays various information if local suppression has been applied.
</p>
</li>
<li><p> pram: displays various information if post-randomization has been applied.
</p>
</li>
<li><p> recode: shows information about categorical key variables before and after recoding
</p>
</li>
<li><p> risk: displays information on re-identification risks
</p>
</li>
<li><p> numrisk: displays risk- and utility measures for numerical key variables
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible values for the type argument of the print function are: &quot;freq&quot;: for
Frequencies, &quot;ls&quot;: for Local Supression output, &quot;pram&quot;: for results of
post-randomization &quot;recode&quot;:for Recodes, &quot;risk&quot;: forCategorical risk and
&quot;numrisk&quot;: for Numerical risk.
</p>
<p>Possible values for the type argument of the freq function are: &quot;fk&quot;: Sample
frequencies and &quot;Fk&quot;: weighted frequencies.
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik, Matthias Templ, Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata)

sdc &lt;- createSdcObj(testdata,
  keyVars=c('urbrur','roof','walls','relat','sex'),
  pramVars=c('water','electcon'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- microaggregation(sdc, method="mdav", aggr=3)
print(sdc)
print(sdc, type="general")
print(sdc, type="ls")
print(sdc, type="recode")
print(sdc, type="risk")
print(sdc, type="numrisk")
print(sdc, type="pram")
print(sdc, type="kAnon")
print(sdc, type="comp_numvars")

</code></pre>

<hr>
<h2 id='print.suda2'>Print method for objects from class suda2</h2><span id='topic+print.suda2'></span>

<h3>Description</h3>

<p>Print method for objects from class suda2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'suda2'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.suda2_+3A_x">x</code></td>
<td>
<p>an object of class suda2</p>
</td></tr>
<tr><td><code id="print.suda2_+3A_...">...</code></td>
<td>
<p>additional arguments passed through.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Table of dis suda scores.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+suda2">suda2</a></code>
</p>

<hr>
<h2 id='randSample_cpp'>Random Sampling</h2><span id='topic+randSample_cpp'></span>

<h3>Description</h3>

<p>Randomly select records given a probability weight vector <code>prob</code>.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>randSample</code> which is used inside the C++-function <code>recordSwap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randSample_cpp(ID, N, prob, IDused, seed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randSample_cpp_+3A_id">ID</code></td>
<td>
<p>vector containing record IDs from which to sample</p>
</td></tr>
<tr><td><code id="randSample_cpp_+3A_n">N</code></td>
<td>
<p>integer defining the number of records to be sampled</p>
</td></tr>
<tr><td><code id="randSample_cpp_+3A_prob">prob</code></td>
<td>
<p>a vector of probability weights for obtaining the elements of the vector being sampled.</p>
</td></tr>
<tr><td><code id="randSample_cpp_+3A_idused">IDused</code></td>
<td>
<p>vector containing IDs which must not be sampled</p>
</td></tr>
<tr><td><code id="randSample_cpp_+3A_seed">seed</code></td>
<td>
<p>integer setting the sampling seed</p>
</td></tr>
</table>

<hr>
<h2 id='rankSwap'>Rank Swapping</h2><span id='topic+rankSwap'></span>

<h3>Description</h3>

<p>Swapping values within a range so that, first, the correlation structure of
original variables are preserved, and second, the values in each record are
disturbed.  To be used on numeric or ordinal variables where the rank can be
determined and the correlation coefficient makes sense.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankSwap(
  obj,
  variables = NULL,
  TopPercent = 5,
  BottomPercent = 5,
  K0 = NULL,
  R0 = NULL,
  P = NULL,
  missing = NA,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankSwap_+3A_obj">obj</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object or a <code>data.frame</code></p>
</td></tr>
<tr><td><code id="rankSwap_+3A_variables">variables</code></td>
<td>
<p>names or index of variables for that rank swapping is
applied.  For an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>, all numeric key variables are
selected if variables=NULL.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_toppercent">TopPercent</code></td>
<td>
<p>Percentage of largest values that are grouped together
before rank swapping is applied.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_bottompercent">BottomPercent</code></td>
<td>
<p>Percentage of lowest values that are grouped together
before rank swapping is applied.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_k0">K0</code></td>
<td>
<p>Subset-mean preservation factor. Preserves the means before and
after rank swapping within a range based on K0.  K0 is the subset-mean
preservation factor such that <code class="reqn">| X_1 -X_2 | \leq \frac{2 K_0
X_1}{\sqrt(N_S)}</code>, where <code class="reqn">X_1</code>
and <code class="reqn">X_2</code> are the subset means of the field before and after
swapping, and <code class="reqn">N_S</code> is the sample size of the subset.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_r0">R0</code></td>
<td>
<p>Multivariate preservation factor. Preserves the correlation
between variables within a certain range based on the given constant R0.  We
can specify the preservation factor as <code class="reqn">R_0=\frac{R_1}{R_2}</code> where <code class="reqn">R_1</code> is the correlation coefficient of the two
fields after swapping, and <code class="reqn">R_2</code> is the correlation coefficient of
the two fields before swapping.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_p">P</code></td>
<td>
<p>Rank range as percentage of total sample size. We can specify the
rank range itself directly, noted as <code class="reqn">P</code>, which is the percentage of
the records. So two records are eligible for swapping if their ranks,
<code class="reqn">i</code> and <code class="reqn">j</code> respectively, satisfy <code class="reqn">| i-j | \le \frac{P
N}{100}</code>, where <code class="reqn">N</code> is the total sample size.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_missing">missing</code></td>
<td>
<p>missing - the value to be used as missing value
in the C++ routine instead of NA. If NA, a suitable value is calculated internally.
Note that in the returned dataset, all NA-values (if any) will be replaced with
this value.</p>
</td></tr>
<tr><td><code id="rankSwap_+3A_seed">seed</code></td>
<td>
<p>Seed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Rank swapping sorts the values of one numeric variable by their numerical
values (ranking).  The restricted range is determined by the rank of two
swapped values, which cannot differ, by definition, by more than P
percent of the total number of observations. Only positive P, R0 and K0 are
used and only one of it must be supplied. If none is supplied, sdcMicro sets
parameter r0 to 0.95 internally.
</p>


<h3>Value</h3>

<p>The rank-swapped data set or a modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object.
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik for the interface, Bernhard Meindl for improvements.
</p>
<p>For the underlying C++ code: This work is being supported by the
International Household Survey Network (IHSN) and funded by a DGF Grant
provided by the World Bank to the PARIS21 Secretariat at the Organisation
for Economic Co-operation and Development (OECD).  This work builds on
previous work which is elsewhere acknowledged.
</p>


<h3>References</h3>

<p>Moore, Jr.R. (1996) Controlled data-swapping techniques for
masking public use microdata, U.S. Bureau of the Census <em>Statistical
Research Division Report Series</em>, RR 96-04.
</p>
<p>Kowarik, A. and Templ, M. and Meindl, B. and Fonteneau, F. and Prantner, B.:
<em>Testing of IHSN Cpp Code and Inclusion of New Methods into sdcMicro</em>,
in: Lecture Notes in Computer Science, J. Domingo-Ferrer, I. Tinnirello
(editors.); Springer, Berlin, 2012, ISBN: 978-3-642-33626-3, pp. 63-77.
<a href="https://doi.org/10.1007/978-3-642-33627-0_6">doi:10.1007/978-3-642-33627-0_6</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(testdata2)
data_swap &lt;- rankSwap(
  obj = testdata2,
  variables = c("age", "income", "expend", "savings")
)

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = c("urbrur", "roof", "walls", "water", "electcon", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight")
sdc &lt;- rankSwap(sdc)
</code></pre>

<hr>
<h2 id='readMicrodata'>readMicrodata</h2><span id='topic+readMicrodata'></span>

<h3>Description</h3>

<p>reads data from various formats into R. Used in <code><a href="#topic+sdcApp">sdcApp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>readMicrodata(
  path,
  type,
  convertCharToFac = TRUE,
  drop_all_missings = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="readMicrodata_+3A_path">path</code></td>
<td>
<p>a file path</p>
</td></tr>
<tr><td><code id="readMicrodata_+3A_type">type</code></td>
<td>
<p>which format does the file have. currently allowed values are
</p>

<ul>
<li> <p><code>sas</code>
</p>
</li>
<li> <p><code>spss</code>
</p>
</li>
<li> <p><code>stata</code>
</p>
</li>
<li> <p><code>R</code>
</p>
</li>
<li> <p><code>rdf</code>
</p>
</li>
<li> <p><code>csv</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="readMicrodata_+3A_convertchartofac">convertCharToFac</code></td>
<td>
<p>(logical) if TRUE, all character vectors are automatically
converted to factors</p>
</td></tr>
<tr><td><code id="readMicrodata_+3A_drop_all_missings">drop_all_missings</code></td>
<td>
<p>(logical) if TRUE, all variables that contain NA-values only
will be dropped</p>
</td></tr>
<tr><td><code id="readMicrodata_+3A_...">...</code></td>
<td>
<p>additional parameters. Currently used only if <code>type='csv'</code> to pass
arguments to <code>read.table()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame or an object of class 'simple.error'. If a stata file was read in, the resulting <code>data.frame</code>
has an additional attribute <code>lab</code> in which variable and value labels are stored.
</p>


<h3>Note</h3>

<p>if <code>type</code> is either <code>'sas'</code>, <code>'spss'</code> or <code>'stata'</code>, values read in as <code>NaN</code>
will be converted to <code>NA</code>.
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>

<hr>
<h2 id='recordSwap'>Targeted Record Swapping</h2><span id='topic+recordSwap'></span><span id='topic+recordSwap.sdcMicroObj'></span><span id='topic+recordSwap.default'></span>

<h3>Description</h3>

<p>Applies targeted record swapping on micro data considering the identification
risk of each record as well the geographic topology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recordSwap(data, ...)

## S3 method for class 'sdcMicroObj'
recordSwap(data, ...)

## Default S3 method:
recordSwap(
  data,
  hid,
  hierarchy,
  similar,
  swaprate = 0.05,
  risk = NULL,
  risk_threshold = 0,
  k_anonymity = 3,
  risk_variables = NULL,
  carry_along = NULL,
  return_swapped_id = FALSE,
  log_file_name = "TRS_logfile.txt",
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recordSwap_+3A_data">data</code></td>
<td>
<p>must be either a micro data set in the form of a
'data.table' or 'data.frame', or an 'sdcObject', see
<a href="#topic+createSdcObj">createSdcObj</a>.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_...">...</code></td>
<td>
<p>parameters passed to 'recordSwap.default()'</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_hid">hid</code></td>
<td>
<p>column index or column name in 'data' which refers
to the household identifier.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_hierarchy">hierarchy</code></td>
<td>
<p>column indices or column names of variables in
'data' which refer to the geographic hierarchy in the micro data
set. For instance county &gt; municipality &gt; district.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_similar">similar</code></td>
<td>
<p>vector or list of integer vectors or column names
containing similarity profiles, see details for more explanations.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_swaprate">swaprate</code></td>
<td>
<p>double between 0 and 1 defining the proportion of
households which should be swapped, see details for more explanations</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_risk">risk</code></td>
<td>
<p>either column indices or column names in 'data' or
'data.table', 'data.frame' or 'matrix' indicating risk of each record
at each hierarchy level. If 'risk'-matrix is supplied to swapping procedure
will not use the k-anonymity rule but the values found in this matrix
for swapping.
When using the risk parameter is expected to have assigned a maximum value     
in a household for each member of the household. If this condition is not      
satisfied, the risk parameter is automatically adjusted to comply with this    
condition.
If risk parameter is provided then k-anonymity rule is suppressed.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_risk_threshold">risk_threshold</code></td>
<td>
<p>single numeric value indicating when a household is
considered &quot;high risk&quot;, e.g. when this household must be swapped. Is only
used when 'risk' is not 'NULL'.
Risk threshold indicates households that have to be swapped, but be aware      
that households with risk lower than threshold, but with still high enough      
risk may be swapped as well. Only households with risk set to 0 are not swapped.                                                   
Risk and risk threshold must be equal or bigger then 0.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_k_anonymity">k_anonymity</code></td>
<td>
<p>integer defining the threshold of high risk households
(counts&lt;k) for using k-anonymity rule</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_risk_variables">risk_variables</code></td>
<td>
<p>column indices or column names of variables in 'data'
which will be considered for estimating the risk. Only used when k-anonymity
rule is applied.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_carry_along">carry_along</code></td>
<td>
<p>integer vector indicating additional variables to swap
besides to hierarchy variables. These variables do not interfere with the
procedure of finding a record to swap with or calculating risk. This
parameter is only used at the end of the procedure when swapping the
hierarchies. We note that the variables to be used as 'carry_along' should
be at household level. In case it is detected that they are at individual
level (different values within 'hid'), a warning is given.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_return_swapped_id">return_swapped_id</code></td>
<td>
<p>boolean if 'TRUE' the output includes an
additional column showing the 'hid' with which a record was swapped with.
The new column will have the name 'paste0(hid,&quot;_swapped&quot;)'.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_log_file_name">log_file_name</code></td>
<td>
<p>character, path for writing a log file. The log
file contains a list of household IDs ('hid') which could not have been
swapped and is only created if any such households exist.</p>
</td></tr>
<tr><td><code id="recordSwap_+3A_seed">seed</code></td>
<td>
<p>integer defining the seed for the random number generator, for
reproducibility. if 'NULL' a random seed will be set using 'sample(1e5,1)'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure accepts a 'data.frame' or 'data.table'
containing all necessary information for the record swapping, e.g
parameter 'hid', 'similar', 'hierarchy', etc ...
First, the micro data in 'data' is ordered by 'hid' and the identification
risk is calculated for each record in each hierarchy level. As of right
now only counts is used as identification risk and the inverse of counts
is used as sampling probability.
NOTE: It will be possible to supply an identification risk for each record
and hierarchy level which will be passed down to the C++-function. This
is however not fully implemented.
</p>
<p>With the parameter 'k_anonymity' a k-anonymity rule is applied to define
risky households in each hierarchy level. A household is set to risky
if counts &lt; k_anonymity in any hierarchy level and the household needs
to be swapped across this hierarchy level.
For instance, having a geographic hierarchy of NUTS1 &gt; NUTS2 &gt; NUTS3 the
counts are calculated for each geographic variable and defined
'risk_variables'. If the counts for a record falls below 'k_anonymity'
for hierarchy county (NUTS1, NUTS2, ...) then this record needs to be swapped 
across counties.
Setting 'k_anonymity = 0' disables this feature and no risky households
are defined.
</p>
<p>After that the targeted record swapping is applied, starting from the highest
to the lowest hierarchy level and cycling through all possible geographic
areas at each hierarchy level, e.g every county, every municipality in
every county, etc, ...
</p>
<p>At each geographic area, a set of values is created for records to be
swapped. In all but the lowest hierarchy level, this is ONLY made out
of all records which do not fulfil the k-anonymity and have not already
been swapped. Those records are swapped with records not belonging to
the same geographic area, which have not already been swapped beforehand.
Swapping refers to the interchange of geographic variables defined in
'hierarchy'. When a record is swapped all other records containing the
same 'hid' are swapped as well.
</p>
<p>At the lowest hierarchy level in every geographic area, the set of records to
be swapped is made up of all records which do not fulfil the k-anonymity
as well as the remaining number of records such that the proportion of
swapped records of the geographic area is in coherence with the 'swaprate'.
If due to the k-anonymity condition, more records have already been swapped
in this geographic area then only the records which do not fulfil the
k-anonymity are swapped.
</p>
<p>Using the parameter 'similar' one can define similarity profiles.
'similar' needs to be a list of vectors with each list entry containing
column indices of 'data'. These entries are used when searching for donor
households, meaning that for a specific record the set of all donor
records is made out of records which have the same values in
'similar[[1]]'. It is however important to note, that these variables
can only be variables related to households (not persons!). If no suitable
donor can be found the next similarity profile is used, 'similar[[2]]' and
the set of all donors is then made up out of all records which have the
same values in the column indices in 'similar[[2]]'. This procedure
continues until a donor record was found or all the similarity profiles
have been used.
</p>
<p>'swaprate' sets the swaprate of households to be swapped, where a single
swap counts for swapping 2 households, the sampled household and the
corresponding donor. Prior to the procedure, the swaprate is applied on
the lowest hierarchy level, to determine the target number of swapped
households in each of the lowest hierarchies. If the target numbers of a
decimal point they will randomly be rounded up or down such that the
number of households swapped in total is in coherence to the swaprate.
</p>


<h3>Value</h3>

<p>'data.table' with swapped records.
</p>


<h3>Author(s)</h3>

<p>Johannes Gussenbauer
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate 10000 dummy households
library(data.table)
seed &lt;- 2021
set.seed(seed)
nhid &lt;- 10000

dat &lt;- sdcMicro::createDat(nhid)

# define paramters for swapping
k_anonymity &lt;- 1
swaprate &lt;- .05 # 5%
similar &lt;- list(c("hsize"))
hier &lt;- c("nuts1", "nuts2")
risk_variables &lt;- c("ageGroup", "national")
hid &lt;- "hid"

## apply record swapping
#dat_s &lt;- recordSwap(
#  data = dat,
#  hid = hid,
#  hierarchy = hier,
#  similar = similar,
#  swaprate = swaprate,
#  k_anonymity = k_anonymity,
#  risk_variables = risk_variables,
#  carry_along = NULL,
#  return_swapped_id = TRUE,
#  seed = seed
#)
#
## number of swapped households
#dat_s[hid != hid_swapped, uniqueN(hid)]
#
## hierarchies are not consistently swapped
#dat_s[hid != hid_swapped, .(nuts1, nuts2, nuts3, lau2)]
#
## use parameter carry_along
#dat_s &lt;- recordSwap(
#   data = dat,
#   hid = hid,
#  hierarchy = hier,
#  similar = similar,
#  swaprate = swaprate,
#  k_anonymity = k_anonymity,
#  risk_variables = risk_variables,
#  carry_along = c("nuts3", "lau2"),
#  return_swapped_id = TRUE,
#  seed = seed)
#
#dat_s[hid != hid_swapped, .(nuts1, nuts2, nuts3, lau2)]

</code></pre>

<hr>
<h2 id='recordSwap_cpp'>Targeted Record Swapping</h2><span id='topic+recordSwap_cpp'></span>

<h3>Description</h3>

<p>Applies targeted record swapping on micro data set, see <code>?recordSwap</code> for details.
<br />
<strong>NOTE:</strong> This is an internal function called by the R-function <code>recordSwap()</code>. It's only purpose is to include the C++-function recordSwap() using Rcpp.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recordSwap_cpp(
  data,
  hid,
  hierarchy,
  similar_cpp,
  swaprate,
  risk,
  risk_threshold,
  k_anonymity,
  risk_variables,
  carry_along,
  log_file_name,
  seed = 123456L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recordSwap_cpp_+3A_data">data</code></td>
<td>
<p>micro data set containing only integer values. A data.frame or data.table from R needs to be transposed beforehand so that data.size() ~ number of records - data.[0].size ~ number of varaibles per record.
<strong>NOTE:</strong> <em>data has to be ordered by hid beforehand.</em></p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_hid">hid</code></td>
<td>
<p>column index in <code>data</code> which refers to the household identifier.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_hierarchy">hierarchy</code></td>
<td>
<p>column indices of variables in <code>data</code> which refers to the geographic hierarchy in the micro data set. For instance county &gt; municipality &gt; district.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_similar_cpp">similar_cpp</code></td>
<td>
<p>List where each entry corresponds to column indices of variables in <code>data</code> which should be considered when swapping households.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_swaprate">swaprate</code></td>
<td>
<p>double between 0 and 1 defining the proportion of households which should be swapped, see details for more explanations</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_risk">risk</code></td>
<td>
<p>vector of vectors containing risks of each individual in each hierarchy level.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_risk_threshold">risk_threshold</code></td>
<td>
<p>double indicating risk threshold above every household needs to be swapped.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_k_anonymity">k_anonymity</code></td>
<td>
<p>integer defining the threshold of high risk households (k-anonymity). This is used as k_anonymity &lt;= counts.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_risk_variables">risk_variables</code></td>
<td>
<p>column indices of variables in <code>data</code> which will be considered for estimating the risk.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_carry_along">carry_along</code></td>
<td>
<p>integer vector indicating additional variables to swap besides to hierarchy variables.
These variables do not interfere with the procedure of finding a record to swap with or calculating risk.
This parameter is only used at the end of the procedure when swapping the hierarchies.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_log_file_name">log_file_name</code></td>
<td>
<p>character, path for writing a log file. The log file contains a list of household IDs ('hid') which could not have been swapped and is only created if any such households exist.</p>
</td></tr>
<tr><td><code id="recordSwap_cpp_+3A_seed">seed</code></td>
<td>
<p>integer defining the seed for the random number generator, for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns data set with swapped records.
</p>

<hr>
<h2 id='removeDirectID'>Remove certain variables from the data set inside a sdc object.</h2><span id='topic+removeDirectID'></span>

<h3>Description</h3>

<p>Delete variables without changing anything else in the sdcObject (writing
NAs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>removeDirectID(obj, var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="removeDirectID_+3A_obj">obj</code></td>
<td>
<p>object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="removeDirectID_+3A_var">var</code></td>
<td>
<p>name of the variable(s) to be remove</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata, keyVars=c('urbrur','roof'),
 numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- removeDirectID(sdc, var="age")
</code></pre>

<hr>
<h2 id='report'>Generate an Html-report from an sdcMicroObj</h2><span id='topic+report'></span>

<h3>Description</h3>

<p>Summary statistics of the original and the perturbed data set
</p>


<h3>Usage</h3>

<pre><code class='language-R'>report(
  obj,
  outdir = tempdir(),
  filename = "SDC-Report",
  title = "SDC-Report",
  internal = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="report_+3A_obj">obj</code></td>
<td>
<p>an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> or <code>reportObj</code></p>
</td></tr>
<tr><td><code id="report_+3A_outdir">outdir</code></td>
<td>
<p>output folder</p>
</td></tr>
<tr><td><code id="report_+3A_filename">filename</code></td>
<td>
<p>output filename</p>
</td></tr>
<tr><td><code id="report_+3A_title">title</code></td>
<td>
<p>Title for the report</p>
</td></tr>
<tr><td><code id="report_+3A_internal">internal</code></td>
<td>
<p>TRUE/FALSE, if TRUE a detailed internal report is produced,
else a non-disclosive overview</p>
</td></tr>
<tr><td><code id="report_+3A_verbose">verbose</code></td>
<td>
<p>TRUE/FALSE, if TRUE, some additional information is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The application of this function provides you with a html-report for your
sdcMicro object that contains useful summaries about the anonymization process.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(testdata2)
sdc &lt;- createSdcObj(
  dat = testdata2,
  keyVars = c("urbrur", "roof", "walls", "water", "electcon", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight"
)
report(sdc)

</code></pre>

<hr>
<h2 id='riskyCells'>riskyCells</h2><span id='topic+riskyCells'></span>

<h3>Description</h3>

<p>Allows to compute risky (unweighted) combinations of key variables either
up to a specified dimension or using identification level. This mimics the
approach taken in mu-argus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>riskyCells(obj, useIdentificationLevel = FALSE, threshold, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="riskyCells_+3A_obj">obj</code></td>
<td>
<p>a <code>data.frame</code>, <code>data.table</code> or an <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> object</p>
</td></tr>
<tr><td><code id="riskyCells_+3A_useidentificationlevel">useIdentificationLevel</code></td>
<td>
<p>(logical) specifies if tabulation should be
done up to a specific dimension (<code>useIdentificationLevel = FALSE</code> using
argument <code>maxDim</code>) or taking identification levels
(<code>useIdentificationLevel = FALSE</code> using argument <code>level</code>) into account.</p>
</td></tr>
<tr><td><code id="riskyCells_+3A_threshold">threshold</code></td>
<td>
<p>a numeric vector specifiying the thresholds at which cells
are considered to be unsafe. In case a tabulation is done up to a specific
level (<code>useIdentificationLevel = FALSE</code>), the thresholds may be specified
differently for each dimension. In the other case, the same threshold is
used for all tables.</p>
</td></tr>
<tr><td><code id="riskyCells_+3A_...">...</code></td>
<td>
<p>see possible arguments below
</p>

<ul>
<li> <p><code>keyVars</code>: index or variable-names within <code>obj</code> that should be used for
tabulation. In case <code>obj</code> is a <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> object, this argument is
not used and the pre-defined key-variables are used.
</p>
</li>
<li> <p><code>level</code>: in case <code>useIdentificationLevel = TRUE</code>, this numeric vector
specifies the importance of the key variables. The construction of output
tables follows the implementation in mu-argus, see e.g
<a href="https://github.com/sdcTools/manuals/raw/master/mu-argus/MUmanual5.1.pdf">mu-argus</a>.
The length of this numeric vector must match the number of key variables.
</p>
</li>
<li> <p><code>maxDim</code>: in case <code>useIdentificationLevel = FALSE</code>, this number specifies
maximal number of variables to tablulate.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.table</code> showing the number of unsafe cells, thresholds for
any combination of the key variables. If the input was a <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>
object and some modifications have been already applied to the categorical
key variables, the resulting output contains the number of unsafe cells
both for the original and the modified data.
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## data.frame method / all combinations up to maxDim
# riskyCells(
#  obj = testdata2,
#  keyVars = 1:5,
#  threshold = c(50, 25, 10, 5),
#  useIdentificationLevel = FALSE,
#  maxDim = 4
# )
#riskyCells(
#  obj  = testdata2,
#  keyVars = 1:5,
#  threshold = 10,
#  useIdentificationLevel = FALSE,
#  maxDim = 3
#)
#
### data.frame method / using identification levels
#riskyCells(
#  obj = testdata2,
#  keyVars = 1:6,
#  threshold = 20,
#  useIdentificationLevel = TRUE,
#  level = c(1, 1, 2, 3, 3, 5)
#)
#riskyCells(
#  obj = testdata2,
#  keyVars = c(1, 3, 4, 6),
#  threshold = 10,
#  useIdentificationLevel = TRUE,
#  level = c(1, 2, 2, 4)
#)
#
### sdcMicroObj-method / all combinations up to maxDim
#testdata2[1:6] &lt;- lapply(1:6, function(x) {
#  testdata2[[x]] &lt;- as.factor(testdata2[[x]])
#})
#
#sdc &lt;- createSdcObj(
#  dat = testdata2,
#  keyVars = c("urbrur", "roof", "walls", "water", "electcon", "relat", "sex"),
#  numVars = c("expend", "income", "savings"),
#  w = "sampling_weight")
#
#r0 &lt;- riskyCells(
#  obj = sdc,
#  useIdentificationLevel=FALSE,
# threshold = c(20, 10, 5),
# maxDim = 3
#)
#
### in case key-variables have been modified, we get counts for
### original and modified data
#sdc &lt;- groupAndRename(
#  obj = sdc,
#  var = "roof",
#  before = c("5", "6", "9"),
#  after = "5+"
#)
#r1 &lt;- riskyCells(
#  obj = sdc,
#  useIdentificationLevel = FALSE,
#  threshold = c(10, 5, 3),
#  maxDim = 3
#)
#
### sdcMicroObj-method / using identification levels
#riskyCells(
#  obj = sdc,
#  useIdentificationLevel = TRUE,
#  threshold = 10,
#  level = c(1, 1, 3, 4, 5, 5, 5)
#)
</code></pre>

<hr>
<h2 id='sampleDonor_cpp'>Random sample for donor records</h2><span id='topic+sampleDonor_cpp'></span>

<h3>Description</h3>

<p>Randomly select donor records given a probability weight vector. This sampling procedure is implemented differently than <code><a href="#topic+randSample_cpp">randSample_cpp</a></code> to speed up performance of C++-function <code>recordSwap()</code>.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>sampleDonor</code> which is used inside the C++-function <code>recordSwap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleDonor_cpp(
  data,
  similar_cpp,
  hid,
  IDswap,
  IDswap_pool_vec,
  prob,
  seed = 123456L
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleDonor_cpp_+3A_data">data</code></td>
<td>
<p>micro data containing the hierarchy levels and household ID</p>
</td></tr>
<tr><td><code id="sampleDonor_cpp_+3A_similar_cpp">similar_cpp</code></td>
<td>
<p>List where each entry corresponds to column indices of variables in <code>data</code> which should be considered when swapping households.</p>
</td></tr>
<tr><td><code id="sampleDonor_cpp_+3A_hid">hid</code></td>
<td>
<p>column index in <code>data</code> which refers to the household identifier.</p>
</td></tr>
<tr><td><code id="sampleDonor_cpp_+3A_idswap">IDswap</code></td>
<td>
<p>vector containing records for which a donor needs to be sampled</p>
</td></tr>
<tr><td><code id="sampleDonor_cpp_+3A_idswap_pool_vec">IDswap_pool_vec</code></td>
<td>
<p>set from which 'IDswap' was drawn</p>
</td></tr>
<tr><td><code id="sampleDonor_cpp_+3A_prob">prob</code></td>
<td>
<p>a vector of probability weights for obtaining the elements of the vector being sampled.</p>
</td></tr>
<tr><td><code id="sampleDonor_cpp_+3A_seed">seed</code></td>
<td>
<p>integer setting the sampling seed</p>
</td></tr>
</table>

<hr>
<h2 id='sdcApp'>sdcApp</h2><span id='topic+sdcApp'></span>

<h3>Description</h3>

<p>starts the graphical user interface developed with <em>shiny</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sdcApp(
  maxRequestSize = 50,
  debug = FALSE,
  theme = "IHSN",
  ...,
  shiny.server = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdcApp_+3A_maxrequestsize">maxRequestSize</code></td>
<td>
<p>(numeric) number defining the maximum allowed filesize (in megabytes)
for uploaded files, defaults to 50MB</p>
</td></tr>
<tr><td><code id="sdcApp_+3A_debug">debug</code></td>
<td>
<p>logical if <code>TRUE</code>, set shiny-debugging options</p>
</td></tr>
<tr><td><code id="sdcApp_+3A_theme">theme</code></td>
<td>
<p>select stylesheet for the interface. Supported choices are
</p>

<ul>
<li><p> 'yeti'
</p>
</li>
<li><p> 'flatly'
</p>
</li>
<li><p> 'journal'
</p>
</li>
<li><p> 'IHSN'
</p>
</li></ul>
</td></tr>
<tr><td><code id="sdcApp_+3A_...">...</code></td>
<td>
<p>arguments (e.g <code>host</code>) that are passed through <code><a href="shiny.html#topic+runApp">runApp</a></code> when
starting the shiny application</p>
</td></tr>
<tr><td><code id="sdcApp_+3A_shiny.server">shiny.server</code></td>
<td>
<p>Setting this parameter to <code>TRUE</code> will return the app in the form of an
object rather than invoking it. This is useful for deploying <code>sdcApp</code> via <code>shiny-server</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>starts the interactive graphical user interface which may be used to perform the
anonymization process.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(interactive()) {
  sdcApp(theme = "flatly")
}
</code></pre>

<hr>
<h2 id='sdcMicro-package'>sdcMicro: Statistical Disclosure Control Methods for Anonymization of Data and Risk Estimation</h2><span id='topic+sdcMicro'></span><span id='topic+sdcMicro-package'></span>

<h3>Description</h3>

<p>Data from statistical agencies and other institutions are mostly confidential. This package, introduced in Templ, Kowarik and Meindl (2017) <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>, can be used for the generation of anonymized (micro)data, i.e. for the creation of public- and scientific-use files. The theoretical basis for the methods implemented can be found in Templ (2017) <a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>. Various risk estimation and anonymization methods are included. Note that the package includes a graphical user interface published in Meindl and Templ (2019) <a href="https://doi.org/10.3390/a12090191">doi:10.3390/a12090191</a> that allows to use various methods of this package.
</p>
<p>This package includes all methods of the popular software mu-Argus plus
several new methods. In comparison with mu-Argus the advantages of this
package are that the results are fully reproducible even with the included
GUI, that the package can be used in batch-mode from other software, that
the functions can be used in a very flexible way, that everybody could look
at the source code and that there are no time-consuming meta-data management
is necessary. However, the user should have a detailed knowledge about SDC
when applying the methods on data.
</p>


<h3>Details</h3>

<p>The package is programmed using S4-classes and it comes with a well-defined
class structure.
</p>
<p>The implemented graphical user interface (GUI) for microdata protection
serves as an easy-to-handle tool for users who want to use the sdcMicro
package for statistical disclosure control but are not used to the native R
command line interface.  In addition to that, interactions between objects
which results from the anonymization process are provided within the GUI.
This allows an automated recalculation and displaying information of the
frequency counts, individual risk, information loss and data utility after
each anonymization step. In addition to that, the code for every
anonymization step carried out within the GUI is saved in a script which can
then be easily modified and reloaded.
</p>

<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> sdcMicro</td>
</tr>
<tr>
 <td style="text-align: left;"> Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> Version: </td><td style="text-align: left;">
2.5.9</td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;"> 2009-07-22</td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> GPL 2.0 </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Matthias Templ <a href="mailto:matthias.templ@gmail.com">matthias.templ@gmail.com</a> (<a href="https://orcid.org/0000-0002-8638-5276">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Bernhard Meindl <a href="mailto:Bernhard.Meindl@statistik.gv.at">Bernhard.Meindl@statistik.gv.at</a>
</p>
</li>
<li><p> Alexander Kowarik <a href="mailto:Alexander.Kowarik@statistik.gv.at">Alexander.Kowarik@statistik.gv.at</a> (<a href="https://orcid.org/0000-0001-8598-4130">ORCID</a>)
</p>
</li>
<li><p> Johannes Gussenbauer <a href="mailto:johannes.gussenbauer@statistik.gv.at">johannes.gussenbauer@statistik.gv.at</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Organisation For Economic Co-Operation And Development (Initial published c(++) code (under LGPL) code for rank swapping, mdav-microaggregation, suda2 and other (hierarchical) risk measures) [copyright holder]
</p>
</li>
<li><p> Statistics Netherlands (microAggregation cpp code (under EUPL v1.1)) [copyright holder]
</p>
</li>
<li><p> Pascal Heus (original measure threshold cpp code (under LGPL)) [copyright holder]
</p>
</li></ul>

<p>Matthias Templ, Alexander Kowarik, Bernhard Meindl
</p>
<p>Maintainer: Matthias Templ &lt;templ@statistik.tuwien.ac.at&gt;
</p>


<h3>References</h3>

<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>
<p>Templ, M. and Kowarik, A. and Meindl, B.
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro.
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>
<p>Templ, M. and Meindl, B. <em>Practical Applications in
Statistical Disclosure Control Using R</em>, Privacy and Anonymity in
Information Management Systems, Bookchapter, Springer London, pp. 31-62,
2010. <a href="https://doi.org/10.1007/978-1-84996-238-4_3">doi:10.1007/978-1-84996-238-4_3</a>
</p>
<p>Kowarik, A. and Templ, M. and Meindl, B. and Fonteneau, F. and Prantner, B.:
<em>Testing of IHSN Cpp Code and Inclusion of New Methods into sdcMicro</em>,
in: Lecture Notes in Computer Science, J. Domingo-Ferrer, I. Tinnirello
(editors.); Springer, Berlin, 2012, ISBN: 978-3-642-33626-3, pp. 63-77.
<a href="https://doi.org/10.1007/978-3-642-33627-0_6">doi:10.1007/978-3-642-33627-0_6</a>
</p>
<p>Templ, M.  <em>Statistical Disclosure Control for Microdata Using the
R-Package sdcMicro</em>, Transactions on Data Privacy, vol. 1, number 2, pp.
67-85, 2008. <a href="http://www.tdp.cat/issues/abs.a004a08.php">http://www.tdp.cat/issues/abs.a004a08.php</a>
</p>
<p>Templ, M.  <em>New Developments in Statistical Disclosure Control and
Imputation: Robust Statistics Applied to Official Statistics</em>,
Suedwestdeutscher Verlag fuer Hochschulschriften, 2009, ISBN: 3838108280,
264 pages.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/sdcTools/sdcMicro">https://github.com/sdcTools/sdcMicro</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
f &lt;- freqCalc(francdat, keyVars=c(2, 4:6), w = 8)
f
f$fk
f$Fk

## dealing with missing values:
x &lt;- francdat
x[3,5] &lt;- NA
x[4,2] &lt;- x[4,4] &lt;- NA
x[5,6]  &lt;- NA
x[6,2]  &lt;- NA
f2 &lt;- freqCalc(x, keyVars = c(2, 4:6), w = 8)
f2$fk
f2$Fk

## individual risk calculation:
indivf &lt;- indivRisk(f)
indivf$rk

## Local Suppression
localS &lt;- localSupp(f, keyVar = 2, threshold = 0.25)
f2 &lt;- freqCalc(localS$freqCalc, keyVars=c(2, 4:6), w = 8)
indivf2 &lt;- indivRisk(f2)
indivf2$rk

## select another keyVar and run localSupp() once again,
## if you think the table is not fully protected
data(free1)
free1 &lt;- as.data.frame(free1)
f &lt;- freqCalc(x = free1, keyVars = 1:3, w = 30)
ind &lt;- indivRisk(f)
## and now you can use the interactive plot for individual risk objects:
## plot(ind)

## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
l1 &lt;- localSuppression(
  obj = francdat,
  keyVars=c(2, 4:6),
  importance = c(1, 3, 2, 4)
)
l1
l1$x
l2 &lt;- localSuppression(obj = francdat, keyVars=c(2, 4:6), k = 2)
l3 &lt;- localSuppression(obj = francdat, keyVars=c(2, 4:6), k = 4)

## Global recoding:
data(free1)
free1 &lt;- as.data.frame(free1)
free1[, "AGE"] &lt;- globalRecode(
  obj = free1[, "AGE"],
  breaks = c(1,9,19,29,39,49,59,69,100),
  labels = 1:8
)

## Top coding:
topBotCoding(
  obj = free1[, "DEBTS"],
  value = 9000,
  replacement = 9100,
  kind = "top"
)

## Numerical Rank Swapping:
data(Tarragona)
Tarragona1 &lt;- rankSwap(Tarragona, P = 10, K0 = NULL, R0 = NULL)

## Microaggregation:
m1 &lt;- microaggregation(Tarragona, method = "onedims", aggr = 3)
m2 &lt;- microaggregation(Tarragona, method = "pca", aggr = 3)

## using a subset because of computation time
valTable(Tarragona[1:50, ], method = c("simple", "onedims", "pca"))

data(microData)
microData &lt;- as.data.frame(microData)
m_micro &lt;- microaggregation(microData, method = "mdav")
summary(m_micro)
plotMicro(m_micro, 1, which.plot = 1)  # not enough observations...
data(free1)
free1 &lt;- as.data.frame(free1)
plotMicro(
  x = microaggregation(free1[,31:34], method = "onedims"),
  p = 1,
  which.plot = 1
)

## disclosure risk (interval) and data utility:
m1 &lt;- microaggregation(Tarragona, method = "onedims", aggr = 3)
dRisk(obj = Tarragona, xm = m1$mx)
dRisk(obj = Tarragona, xm = m2$mx)
dUtility(obj = Tarragona, xm = m1$mx)
dUtility(obj = Tarragona, xm = m2$mx)

## Fast generation of synthetic data with approximately
## the same covariance matrix as the original one.
data(mtcars)
cov(mtcars[, 4:6])
df_gen &lt;- dataGen(obj = mtcars[, 4:6], n = 200)
cov(df_gen)
pairs(mtcars[, 4:6])
pairs(df_gen)

## Post-Randomization (PRAM)
x &lt;- factor(sample(1:4, 250, replace = TRUE))
pr1 &lt;- pram(x)
length(which(pr1$x_pram == x))
summary(pr1)
x2 &lt;- factor(sample(1:4, 250, replace=TRUE))
length(which(pram(x2)$x_pram == x2))

data(free1)
marstat &lt;- as.factor(free1[,"MARSTAT"])
marstatPramed &lt;- pram(marstat)
summary(marstatPramed)

## The same functionality can be also applied to `sdcMicroObj`-objects
data(testdata)

## undo-functionality is by default restricted to data sets
## with &lt;= `1e5` rows; to modify, env-var `sdcMicro_maxsize_undo`
## can to be changed before creating a problem instance
Sys.setenv("sdcMicro_maxsize_undo" = 1e6)

## create an object
testdata$water &lt;- factor(testdata$water)
sdc &lt;- createSdcObj(
  dat = testdata,
  keyVars = c("urbrur", "roof", "walls", "electcon", "water", "relat", "sex"),
  numVars = c("expend", "income", "savings"),
  w = "sampling_weight"
)
head(sdc@manipNumVars)

## Display risk-measures
sdc@risk$global
sdc &lt;- dRisk(sdc)
sdc@risk$numeric

## Generation of synthetic data
synthdat &lt;- dataGen(sdc)

## use addNoise with default parameters (not suggested)
sdc &lt;- addNoise(sdc, variables = c("expend", "income"))
head(sdc@manipNumVars)
sdc@risk$numeric

## undolast step (remove adding noise)
sdc &lt;- undolast(sdc)
head(sdc@manipNumVars)
sdc@risk$numeric

## apply addNoise() with custom parameters
sdc &lt;- addNoise(sdc, noise = 0.2)
head(sdc@manipNumVars)
sdc@risk$numeric

## LocalSuppression
sdc &lt;- undolast(sdc)
head(sdc@risk$individual)
sdc@risk$global
sdc &lt;- localSuppression(sdc)
head(sdc@risk$individual)
sdc@risk$global

## microaggregation
sdc &lt;- undolast(sdc)
head(get.sdcMicroObj(sdc, type = "manipNumVars"))
sdc &lt;- microaggregation(sdc)
head(get.sdcMicroObj(sdc, type = "manipNumVars"))

## Post-Randomization
sdc &lt;- undolast(sdc)
head(sdc@risk$individual)
sdc@risk$global
sdc &lt;- pram(sdc, variables = "water")
head(sdc@risk$individual)
sdc@risk$global

## rankSwap
sdc &lt;- undolast(sdc)
head(sdc@risk$individual)
sdc@risk$global
head(get.sdcMicroObj(sdc, type = "manipNumVars"))
sdc &lt;- rankSwap(sdc)
head(get.sdcMicroObj(sdc, type = "manipNumVars"))
head(sdc@risk$individual)
sdc@risk$global


## topBotCoding
head(get.sdcMicroObj(sdc, type = "manipNumVars"))
sdc@risk$numeric
sdc &lt;- topBotCoding(
  obj = sdc,
  value = 60000000,
  replacement = 62000000,
  column = "income"
)
head(get.sdcMicroObj(sdc, type = "manipNumVars"))
sdc@risk$numeric

## LocalRecProg
data(testdata2)
keyVars &lt;- c("urbrur", "roof", "walls", "water", "sex")
w &lt;- "sampling_weight"
sdc &lt;- createSdcObj(testdata2,
  keyVars = keyVars,
  weightVar = w
)
sdc@risk$global
sdc &lt;- LocalRecProg(sdc)
sdc@risk$global

## Model-based risks using a formula
form &lt;- as.formula(paste("~", paste(keyVars, collapse = "+")))
sdc &lt;- modRisk(sdc, method = "default", formulaM = form)
get.sdcMicroObj(sdc, "risk")$model

sdc &lt;- modRisk(sdc, method = "CE", formulaM = form)
get.sdcMicroObj(sdc, "risk")$model

sdc &lt;- modRisk(sdc, method = "PML", formulaM = form)
get.sdcMicroObj(sdc, "risk")$model

sdc &lt;- modRisk(sdc, method = "weightedLLM", formulaM = form)
get.sdcMicroObj(sdc, "risk")$model

sdc &lt;- modRisk(sdc, method = "IPF", formulaM = form)
get.sdcMicroObj(sdc, "risk")$model

</code></pre>

<hr>
<h2 id='sdcMicroObj-class'>Class <code>"sdcMicroObj"</code></h2><span id='topic+sdcMicroObj-class'></span><span id='topic+createSdcObj'></span><span id='topic+undolast'></span><span id='topic+strataVar+3C-'></span><span id='topic+strataVar+3C-+2CsdcMicroObj+2CcharacterOrNULL-method'></span>

<h3>Description</h3>

<p>Class to save all information about the SDC process
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createSdcObj(
  dat,
  keyVars,
  numVars = NULL,
  pramVars = NULL,
  ghostVars = NULL,
  weightVar = NULL,
  hhId = NULL,
  strataVar = NULL,
  sensibleVar = NULL,
  excludeVars = NULL,
  options = NULL,
  seed = NULL,
  randomizeRecords = FALSE,
  alpha = 1
)

undolast(object)

strataVar(object) &lt;- value

## S4 replacement method for signature 'sdcMicroObj,characterOrNULL'
strataVar(object) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sdcMicroObj-class_+3A_dat">dat</code></td>
<td>
<p>The microdata set. A numeric matrix or data frame containing the data.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_keyvars">keyVars</code></td>
<td>
<p>Indices or names of categorical key variables. They must, of
course, match with the columns of &lsquo;dat&rsquo;.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_numvars">numVars</code></td>
<td>
<p>Index or names of continuous key variables.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_pramvars">pramVars</code></td>
<td>
<p>Indices or names of categorical variables considered to be pramed.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_ghostvars">ghostVars</code></td>
<td>
<p>if specified a list which each element being a list of exactly two elements.
The first element must be a character vector specifying exactly one variable name that was
also specified as a categorical key variable (<code>keyVars</code>), while the second element is
a character vector of valid variable names (that must not be listed as <code>keyVars</code>).
If <code><a href="#topic+localSuppression">localSuppression</a></code> or <code><a href="#topic+kAnon">kAnon</a></code> was applied, the resulting
suppression pattern for each key-variable is transferred to the depending variables.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_weightvar">weightVar</code></td>
<td>
<p>Indices or name determining the vector of sampling weights.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_hhid">hhId</code></td>
<td>
<p>Index or name of the cluster ID (if available).</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_stratavar">strataVar</code></td>
<td>
<p>Indices or names of stratification variables.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_sensiblevar">sensibleVar</code></td>
<td>
<p>Indices or names of sensible variables (for l-diversity)</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_excludevars">excludeVars</code></td>
<td>
<p>which variables of <code>dat</code> should not be included in
result-object? Users may specify a vector of variable-names available in <code>dat</code>
that were not specified in either <code>keyVars</code>, <code>numVars</code>, <code>pramVars</code>,
<code>ghostVars</code>, <code>hhId</code>, <code>strataVar</code> or <code>sensibleVar</code>.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_options">options</code></td>
<td>
<p>additional options (if specified, a list must be used as input)</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_seed">seed</code></td>
<td>
<p>(numeric) number specifiying the seed which will be set to allow for
reproducablity. The number will be rounded and saved as element <code>seed</code> in slot <code>options</code>.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_randomizerecords">randomizeRecords</code></td>
<td>
<p>(logical) if <code>TRUE</code>, the order of observations in the input microdata set
will be randomized.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_alpha">alpha</code></td>
<td>
<p>numeric between 0 and 1 specifying the fraction on how much keys containing <code>NAs</code> should
contribute to the frequency calculation which is also crucial for risk-estimation.</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object</p>
</td></tr>
<tr><td><code id="sdcMicroObj-class_+3A_value">value</code></td>
<td>
<p><code>NULL</code> or a character vector of length 1 specifying a valid variable name</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> object
</p>
<p>an object of class <code>sdcMicroObj</code> with modified slot <code>@strataVar</code>
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form
<code>new("sdcMicroObj", ...)</code>.
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl, Alexander Kowarik, Matthias Templ, Elias Rut
</p>


<h3>References</h3>

<p>Templ, M. and Meindl, B. and Kowarik, A.: <em>Statistical Disclosure Control for
Micro-Data Using the R Package sdcMicro</em>, Journal of Statistical Software,
67 (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## we can also specify ghost (linked) variables
## these variables are linked to some categorical key variables
## and have the sampe suppression pattern as the variable that they
## are linked to after \code{\link{localSuppression}} has been applied
data(testdata)
testdata$electcon2 &lt;- testdata$electcon
testdata$electcon3 &lt;- testdata$electcon
testdata$water2 &lt;- testdata$water

keyVars &lt;- c("urbrur","roof","walls","water","electcon","relat","sex")
numVars &lt;- c("expend","income","savings")
w &lt;- "sampling_weight"

## we want to make sure that some variables not used as key-variables
## have the same suppression pattern as variables that have been
## selected as key variables. Thus, we are using 'ghost'-variables.
ghostVars &lt;- list()

## we want variables 'electcon2' and 'electcon3' to be linked
## to key-variable 'electcon'
ghostVars[[1]] &lt;- list()
ghostVars[[1]][[1]] &lt;- "electcon"
ghostVars[[1]][[2]] &lt;- c("electcon2","electcon3")


## donttest because Examples with CPU time &gt; 2.5 times elapsed time
## we want variable 'water2' to be linked to key-variable 'water'
ghostVars[[2]] &lt;- list()
ghostVars[[2]][[1]] &lt;- "water"
ghostVars[[2]][[2]] &lt;- "water2"

## create the sdcMicroObj
obj &lt;- createSdcObj(testdata, keyVars=keyVars,
  numVars=numVars, w=w, ghostVars=ghostVars)

## apply 3-anonymity to selected key variables
obj &lt;- kAnon(obj, k=3); obj

## check, if the suppression patterns are identical
manipGhostVars &lt;- get.sdcMicroObj(obj, "manipGhostVars")
manipKeyVars &lt;- get.sdcMicroObj(obj, "manipKeyVars")
all(is.na(manipKeyVars$electcon) == is.na(manipGhostVars$electcon2))
all(is.na(manipKeyVars$electcon) == is.na(manipGhostVars$electcon3))
all(is.na(manipKeyVars$water) == is.na(manipGhostVars$water2))

## exclude some variables
obj &lt;- createSdcObj(testdata, keyVars=c("urbrur","roof","walls"), numVars="savings",
   weightVar=w, excludeVars=c("relat","electcon","hhcivil","ori_hid","expend"))
colnames(get.sdcMicroObj(obj, "origData"))

</code></pre>

<hr>
<h2 id='selectHouseholdData'>Creates a household level file from a dataset with a household structure.</h2><span id='topic+selectHouseholdData'></span>

<h3>Description</h3>

<p>It removes individual level variables and selects one record per household based on a household ID. The function can also be used for other hierachical structures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectHouseholdData(dat, hhId, hhVars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectHouseholdData_+3A_dat">dat</code></td>
<td>
<p>a data.frame with the full dataset</p>
</td></tr>
<tr><td><code id="selectHouseholdData_+3A_hhid">hhId</code></td>
<td>
<p>name of the variable with the household (cluster) ID</p>
</td></tr>
<tr><td><code id="selectHouseholdData_+3A_hhvars">hhVars</code></td>
<td>
<p>character vector with names of all household level variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame with only household level variables and one record per household
</p>


<h3>Note</h3>

<p>It is of great importance that users select a variable with containing information on household-ids and weights in <code>hhVars</code>.
</p>


<h3>Author(s)</h3>

<p>Thijs Benschop and Bernhard Meindl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ori-hid: household-ids; household_weights: sampling weights for households
x_hh &lt;- selectHouseholdData(dat=testdata, hhId="ori_hid",
  hhVars=c("urbrur", "roof",  "walls", "water", "electcon", "household_weights"))
</code></pre>

<hr>
<h2 id='set.sdcMicroObj'>set.sdcMicroObj</h2><span id='topic+set.sdcMicroObj'></span>

<h3>Description</h3>

<p>modify <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-objects depending on argument <code>type</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.sdcMicroObj(object, type, input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="set.sdcMicroObj_+3A_object">object</code></td>
<td>
<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object</p>
</td></tr>
<tr><td><code id="set.sdcMicroObj_+3A_type">type</code></td>
<td>
<p>a character vector of length 1 defining what to calculate|return|modify. Allowed types are listed below
and the slot with the corresponding name will be replaced by the content of <code>input.</code>
</p>

<ul>
<li> <p><code>origData: </code>
</p>
</li>
<li> <p><code>keyVars: </code>
</p>
</li>
<li> <p><code>pramVars: </code>
</p>
</li>
<li> <p><code>numVars: </code>
</p>
</li>
<li> <p><code>weightVar: </code>
</p>
</li>
<li> <p><code>hhId: </code>
</p>
</li>
<li> <p><code>strataVar: </code>
</p>
</li>
<li> <p><code>sensibleVar: </code>
</p>
</li>
<li> <p><code>manipPramVars: </code>
</p>
</li>
<li> <p><code>manipNumVars: </code>
</p>
</li>
<li> <p><code>manipGhostVars: </code>
</p>
</li>
<li> <p><code>manipStrataVar: </code>
</p>
</li>
<li> <p><code>risk: </code>
</p>
</li>
<li> <p><code>utility: </code>
</p>
</li>
<li> <p><code>pram: </code>
</p>
</li>
<li> <p><code>localSuppression: </code>
</p>
</li>
<li> <p><code>options: </code>
</p>
</li>
<li> <p><code>prev: </code>
</p>
</li>
<li> <p><code>set: </code>
</p>
</li>
<li> <p><code>additionalResults: </code>
</p>
</li>
<li> <p><code>deletedVars: </code></p>
</li></ul>
</td></tr>
<tr><td><code id="set.sdcMicroObj_+3A_input">input</code></td>
<td>
<p>a list depending on argument <code>type</code>. The content of the list must
match the allowed data-type of the slot in the <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object
that should be replaced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
ind_pram &lt;- match(c("sex"), colnames(testdata2))
get.sdcMicroObj(sdc, type="pramVars")
sdc &lt;- set.sdcMicroObj(sdc, type="pramVars", input=list(ind_pram))
get.sdcMicroObj(sdc, type="pramVars")
</code></pre>

<hr>
<h2 id='setLevels_cpp'>Define Swap-Levels</h2><span id='topic+setLevels_cpp'></span>

<h3>Description</h3>

<p>Define hierarchy levels over which record needs to be swapped according to risk variables.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>setLevels()</code> which is applied inside <code>recordSwap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setLevels_cpp(risk, risk_threshold)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setLevels_cpp_+3A_risk">risk</code></td>
<td>
<p>vector of vectors containing risks of each individual in each hierarchy level. <code>risk[0]</code> returns the vector of risks for the first unit over all hierarchy levels.
<code>risk[1]</code> the vector if risks for all hierarchy level of unit 2, and so on.</p>
</td></tr>
<tr><td><code id="setLevels_cpp_+3A_risk_threshold">risk_threshold</code></td>
<td>
<p>double defining the risk threshold beyond which a record/household needs to be swapped. This is understood as risk&gt;=risk_threshhold.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integer vector with hierarchy level over which record needs to be swapped with.
</p>

<hr>
<h2 id='setRisk_cpp'>Calculate Risk</h2><span id='topic+setRisk_cpp'></span>

<h3>Description</h3>

<p>Calculate risk for records to be swapped and donor records.  Risks are defined by 1/counts, where counts is the number of records with the same values for specified <code>risk_variables</code> in the each geographic hierarchy.
This risk will be used as sampling probability for both sampling set and donor set.
<br />
<strong>NOTE:</strong> This is an internal function used for testing the C++-function <code>setRisk</code> which is used inside the C++-function <code>recordSwap()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>setRisk_cpp(data, hierarchy, risk_variables, hid)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="setRisk_cpp_+3A_data">data</code></td>
<td>
<p>micro data set containing only numeric values.</p>
</td></tr>
<tr><td><code id="setRisk_cpp_+3A_hierarchy">hierarchy</code></td>
<td>
<p>column indices of variables in <code>data</code> which refere to the geographic hierarchy in the micro data set. For instance county &gt; municipality &gt; district.</p>
</td></tr>
<tr><td><code id="setRisk_cpp_+3A_risk_variables">risk_variables</code></td>
<td>
<p>column indices of variables in <code>data</code> which will be considered for estimating the risk.</p>
</td></tr>
<tr><td><code id="setRisk_cpp_+3A_hid">hid</code></td>
<td>
<p>column index in <code>data</code> which refers to the household identifier.</p>
</td></tr>
</table>

<hr>
<h2 id='show+2CsdcMicroObj-method'>Show</h2><span id='topic+show+2CsdcMicroObj-method'></span>

<h3>Description</h3>

<p>show a sdcMicro object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'sdcMicroObj'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show+2B2CsdcMicroObj-method_+3A_object">object</code></td>
<td>
<p>an sdcmicro obj</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a sdcMicro object
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>

<hr>
<h2 id='shuffle'>Shuffling and EGADP</h2><span id='topic+shuffle'></span>

<h3>Description</h3>

<p>Data shuffling and General Additive Data Perturbation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shuffle(
  obj,
  form,
  method = "ds",
  weights = NULL,
  covmethod = "spearman",
  regmethod = "lm",
  gadp = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shuffle_+3A_obj">obj</code></td>
<td>
<p>An object of class sdcMicroObj or a data.frame including the
data.</p>
</td></tr>
<tr><td><code id="shuffle_+3A_form">form</code></td>
<td>
<p>An object of class &ldquo;formula&rdquo; (or one that can be coerced
to that class): a symbolic description of the model to be fitted.  The
responses have to consists of at least two variables of any class and the
response variables have to be of class numeric.  The response variables
belongs to numeric key variables (quasi-identifiers of numeric scale). The
predictors are can be distributed in any way (numeric, factor, ordered
factor).</p>
</td></tr>
<tr><td><code id="shuffle_+3A_method">method</code></td>
<td>
<p>currently either the original form of data shuffling
(&ldquo;ds&rdquo; - default), &ldquo;mvn&rdquo; or &ldquo;mlm&rdquo;, see the details
section. The last method is in experimental mode and almost untested.</p>
</td></tr>
<tr><td><code id="shuffle_+3A_weights">weights</code></td>
<td>
<p>Survey sampling weights. Automatically chosen when obj is of
class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>.</p>
</td></tr>
<tr><td><code id="shuffle_+3A_covmethod">covmethod</code></td>
<td>
<p>Method for covariance estimation. &ldquo;spearman&rdquo;,
&ldquo;pearson&rdquo; and \ dQuotemcd are possible. For the latter one, the
implementation in package robustbase is used.</p>
</td></tr>
<tr><td><code id="shuffle_+3A_regmethod">regmethod</code></td>
<td>
<p>Method for multivariate regression. &ldquo;lm&rdquo; and
&ldquo;MM&rdquo; are possible.  For method &ldquo;MM&rdquo;, the function &ldquo;rlm&rdquo;
from package MASS is applied.</p>
</td></tr>
<tr><td><code id="shuffle_+3A_gadp">gadp</code></td>
<td>
<p>TRUE, if the egadp results from a fit on the original data is
returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Perturbed values for the sensitive variables are generated.  The sensitive
variables have to be stored as responses in the argument &lsquo;form&rsquo;,
which is the usual formula interface for regression models in R.
</p>
<p>For method &ldquo;ds&rdquo; the EGADP method is applied on the norm inverse
percentiles. Shuffling then ranks the original values according to the GADP
output. For further details, please see the references.
</p>
<p>Method &ldquo;mvn&rdquo; uses a simplification and draws from the normal Copulas
directly before these draws are shuffled.
</p>
<p>Method &ldquo;mlm&rdquo; is also a simplification. A linear model is applied, the
expected values are used as perturbed values before shuffling is
applied.
</p>


<h3>Value</h3>

<p>If &lsquo;obj&rsquo; is of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> the corresponding
slots are filled, like manipNumVars, risk and utility.  If &lsquo;obj&rsquo; is
of class &ldquo;data.frame&rdquo; an object of class &ldquo;micro&rdquo; with
following entities is returned: </p>
<table>
<tr><td><code>shConf</code></td>
<td>
<p>the shuffled numeric key
variables</p>
</td></tr> <tr><td><code>egadp</code></td>
<td>
<p>the perturbed (using gadp method) numeric key
variables</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In this version, the covariance method chosen is used for any
covariance and correlation estimations in the whole gadp and shuffling
function.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ, Alexander Kowarik, Bernhard Meindl
</p>


<h3>References</h3>

<p>K. Muralidhar, R. Parsa, R. Saranthy (1999). A general additive
data perturbation method for database security. <em>Management Science</em>,
45, 1399-1415.
</p>
<p>K. Muralidhar, R. Sarathy (2006). Data shuffling - a new masking approach
for numerical data. <em>Management Science</em>, 52(5), 658-670, 2006.
</p>
<p>M. Templ, B. Meindl. (2008).  Robustification of Microdata Masking Methods
and the Comparison with Existing Methods, in: <em>Lecture Notes on
Computer Science</em>, J. Domingo-Ferrer, Y. Saygin (editors.); Springer,
Berlin/Heidelberg, 2008, ISBN: 978-3-540-87470-6, pp. 14-25.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rankSwap">rankSwap</a>, <a href="stats.html#topic+lm">lm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Prestige,package="carData")
form &lt;- formula(income + education ~ women + prestige + type, data=Prestige)
sh &lt;- shuffle(obj=Prestige,form)
plot(Prestige[,c("income", "education")])
plot(sh$sh)
colMeans(Prestige[,c("income", "education")])
colMeans(sh$sh)
cor(Prestige[,c("income", "education")], method="spearman")
cor(sh$sh, method="spearman")

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- shuffle(sdc, method=c('ds'),regmethod= c('lm'), covmethod=c('spearman'),
		form=savings+expend ~ urbrur+walls)
</code></pre>

<hr>
<h2 id='subsetMicrodata'>subsetMicrodata</h2><span id='topic+subsetMicrodata'></span>

<h3>Description</h3>

<p>allows to restrict original data to only a subset. This may be useful to test some anonymization
methods. This function will only be used in the graphical user interface <code><a href="#topic+sdcApp">sdcApp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsetMicrodata(obj, type, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsetMicrodata_+3A_obj">obj</code></td>
<td>
<p>an object of class <code><a href="base.html#topic+data.frame">data.frame</a></code> containing micro data</p>
</td></tr>
<tr><td><code id="subsetMicrodata_+3A_type">type</code></td>
<td>
<p>algorithm used to sample from original microdata. Currently supported choices are
</p>

<dl>
<dt><code>n_perc</code></dt><dd><p> the restricted microdata will be a <code>n-percent</code> sample of the original microdata.</p>
</dd>
<dt><code>first_n</code></dt><dd><p> only the first <code>n</code> observations will be used.</p>
</dd>
<dt><code>every_n</code></dt><dd><p> the restricted microdata set consists of every <code>n-th</code> record.</p>
</dd>
<dt><code>size_n</code></dt><dd><p> a total of <code>n</code> observations will be randomly drawn.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="subsetMicrodata_+3A_n">n</code></td>
<td>
<p>numeric vector of length 1 specifying the specific parameter with respect to argument <code>type</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> with modified slot <code>@origData</code>.
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>

<hr>
<h2 id='suda2'>Suda2: Detecting Special Uniques</h2><span id='topic+suda2'></span>

<h3>Description</h3>

<p>SUDA risk measure for data from (stratified) simple random sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>suda2(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="suda2_+3A_obj">obj</code></td>
<td>
<p>a <code>data.frame</code> or a <a href="#topic+sdcMicroObj-class">sdcMicroObj</a>-object</p>
</td></tr>
<tr><td><code id="suda2_+3A_...">...</code></td>
<td>
<p>see arguments below
</p>

<ul>
<li> <p><code>variables</code> Categorical (key) variables. Either the column names or and
index of the variables to be used for risk measurement.
</p>
</li>
<li> <p><code>missing</code>: Missing value coding in the given data set.
</p>
</li>
<li> <p><code>DisFraction</code>: It is the sampling fraction for the simple random
sampling, and the common sampling fraction for stratified sampling. By
default, it's set to 0.01.
</p>
</li>
<li> <p><code>original_scores</code>: if this argument is <code>TRUE</code> (the default), the
suda-scores are computed as described in paper &quot;SUDA: A Program for Detecting Special
Uniques&quot; by Elliot et al., if <code>FALSE</code>, the computation of the scores
is slightly different as it was done in the original implementation
of the algorithm by the IHSN.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>Suda 2 is a recursive algorithm for finding Minimal Sample Uniques. The
algorithm generates all possible variable subsets of defined categorical key
variables and scans them for unique patterns in the subsets of variables.
The lower the amount of variables needed to receive uniqueness, the higher
the risk of the corresponding observation.
</p>


<h3>Value</h3>

<p>A modified <a href="#topic+sdcMicroObj-class">sdcMicroObj</a> object or the following list
</p>

<ul>
<li> <p><code>ContributionPercent</code>: The contribution of each key variable to the SUDA
score, calculated for each row.
</p>
</li>
<li> <p><code>score</code>: The suda score
'disscore: The dis suda score
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;attribute_contributions:&#8288;</code> a <code>data.frame</code> showing how much of the total
risk is contributed by each variable. This information is stored in the
following two variables:
</p>

<ul>
<li> <p><code>variable</code>: containing the name of the variable
</p>
</li>
<li> <p><code>contribution</code>: contains how much risk a variable contributes to the total risk.
</p>
</li></ul>

</li>
<li> <p><code>attribute_level_contributions</code>: returns risks of each attribute-level as a
<code>data.frame</code> with the following three columns:
</p>

<ul>
<li> <p><code>variable</code>: the variable name
</p>
</li>
<li> <p><code>attribute</code>: holding relevant level-codes
</p>
</li>
<li> <p><code>contribution</code>: contains the risk of this level within the variable.
</p>
</li></ul>

</li></ul>



<h3>Note</h3>

<p>Since version &gt;5.0.2, the computation of suda-scores has changed and is now by default as described in
the original paper by Elliot et al.
</p>


<h3>Author(s)</h3>

<p>Alexander Kowarik and Bernhard Meindl (based on the C++ code from the Organisation For
Economic Co-Operation And Development.
</p>
<p>For the C++ code: This work is being supported by the International
Household Survey Network and funded by a DGF Grant provided by the World
Bank to the PARIS21 Secretariat at the Organisation for Economic
Co-operation and Development (OECD). This work builds on previous work which
is elsewhere acknowledged.
</p>


<h3>References</h3>

<p>C. J. Skinner; M. J. Elliot (20xx) A Measure of Disclosure Risk
for Microdata. <em>Journal of the Royal Statistical Society: Series B
(Statistical Methodology)</em>, Vol. 64 (4), pp 855&ndash;867.
</p>
<p>M. J. Elliot, A. Manning, K. Mayes, J. Gurd and M. Bane (20xx) SUDA: A
Program for Detecting Special Uniques, Using DIS to Modify the
Classification of Special Uniques
</p>
<p>Anna M. Manning, David J. Haglin, John A. Keane (2008) A recursive search
algorithm for statistical disclosure assessment. <em>Data Min Knowl Disc</em>
16:165 &ndash; 196
</p>
<p>Templ, M. Statistical Disclosure Control for Microdata: Methods and Applications in R.
<em>Springer International Publishing</em>, 287 pages, 2017. ISBN 978-3-319-50272-4.
<a href="https://doi.org/10.1007/978-3-319-50272-4">doi:10.1007/978-3-319-50272-4</a>
</p>

<hr>
<h2 id='summary.freqCalc'>Summary method for objects from class freqCalc</h2><span id='topic+summary.freqCalc'></span>

<h3>Description</h3>

<p>Summary method for objects of class &lsquo;freqCalc&rsquo; to provide information
about local suppressions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'freqCalc'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.freqCalc_+3A_object">object</code></td>
<td>
<p>object from class freqCalc</p>
</td></tr>
<tr><td><code id="summary.freqCalc_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shows the amount of local suppressions on each variable in which local
suppression was applied.
</p>


<h3>Value</h3>

<p>Information about local suppression in each variable (only if a
local suppression is already done).
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>See Also</h3>

<p><code><a href="#topic+freqCalc">freqCalc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example from Capobianchi, Polettini and Lucarelli:
data(francdat)
f &lt;- freqCalc(francdat, keyVars=c(2,4,5,6),w=8)
f
f$fk
f$Fk
## individual risk calculation:
indivf &lt;- indivRisk(f)
indivf$rk
## Local Suppression
localS &lt;- localSupp(f, keyVar=2, threshold=0.25)
f2 &lt;- freqCalc(localS$freqCalc, keyVars=c(4,5,6), w=8)
summary(f2)

</code></pre>

<hr>
<h2 id='summary.micro'>Summary method for objects from class micro</h2><span id='topic+summary.micro'></span>

<h3>Description</h3>

<p>Summary method for objects from class &lsquo;micro&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'micro'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.micro_+3A_object">object</code></td>
<td>
<p>objects from class micro</p>
</td></tr>
<tr><td><code id="summary.micro_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes several measures of information loss, such as
</p>


<h3>Value</h3>

<table>
<tr><td><code>meanx</code></td>
<td>
<p>A conventional summary of the original data</p>
</td></tr>
<tr><td><code>meanxm</code></td>
<td>
<p>A conventional summary of the microaggregated data</p>
</td></tr>
<tr><td><code>amean</code></td>
<td>
<p>average relative absolute deviation of means</p>
</td></tr>
<tr><td><code>amedian</code></td>
<td>
<p>average relative absolute deviation of medians</p>
</td></tr>
<tr><td><code>aonestep</code></td>
<td>
<p>average relative absolute deviation of onestep from median</p>
</td></tr>
<tr><td><code>devvar</code></td>
<td>
<p>average relative absolute deviation of variances</p>
</td></tr>
<tr><td><code>amad</code></td>
<td>
<p>average relative absolute deviation of the mad</p>
</td></tr>
<tr><td><code>acov</code></td>
<td>
<p>average relative absolute deviation of covariances</p>
</td></tr>
<tr><td><code>arcov</code></td>
<td>
<p>average relative absolute deviation of robust (with mcd) covariances</p>
</td></tr>
<tr><td><code>acor</code></td>
<td>
<p>average relative absolute deviation of correlations</p>
</td></tr>
<tr><td><code>arcor</code></td>
<td>
<p>average relative absolute deviation of robust (with mcd) correlations</p>
</td></tr>
<tr><td><code>acors</code></td>
<td>
<p>average relative absolute deviation of rank-correlations</p>
</td></tr>
<tr><td><code>adlm</code></td>
<td>
<p>average absolute deviation of lm regression coefficients (without intercept)</p>
</td></tr>
<tr><td><code>adlts</code></td>
<td>
<p>average absolute deviation of lts regression coefficients (without intercept)</p>
</td></tr>
<tr><td><code>apcaload</code></td>
<td>
<p>average absolute deviation of pca loadings</p>
</td></tr>
<tr><td><code>apppacaload</code></td>
<td>
<p>average absolute deviation of robust (with projection pursuit approach) pca loadings</p>
</td></tr>
<tr><td><code>atotals</code></td>
<td>
<p>average relative absolute deviation of totals</p>
</td></tr>
<tr><td><code>pmtotals</code></td>
<td>
<p>average relative deviation of totals</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Templ, M. <em>Statistical Disclosure Control for Microdata
Using the R-Package sdcMicro</em>, Transactions on Data Privacy, vol. 1, number
2, pp. 67-85, 2008. <a href="http://www.tdp.cat/issues/abs.a004a08.php">http://www.tdp.cat/issues/abs.a004a08.php</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+microaggregation">microaggregation</a></code>, <code><a href="#topic+valTable">valTable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Tarragona)
m1 &lt;- microaggregation(Tarragona, method = "onedims", aggr = 3)

summary(m1)

</code></pre>

<hr>
<h2 id='summary.pram'>Summary method for objects from class pram</h2><span id='topic+summary.pram'></span>

<h3>Description</h3>

<p>Summary method for objects from class &lsquo;pram&rsquo; to provide information
about transitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pram'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pram_+3A_object">object</code></td>
<td>
<p>object from class &lsquo;pram&rsquo;</p>
</td></tr>
<tr><td><code id="summary.pram_+3A_...">...</code></td>
<td>
<p>Additional arguments passed through.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Shows various information about the transitions.
</p>


<h3>Value</h3>

<p>The summary of object from class &lsquo;pram&rsquo;.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ and Bernhard Meindl
</p>


<h3>References</h3>

<p>Templ, M.  <em>Statistical Disclosure Control for Microdata
Using the R-Package sdcMicro</em>, Transactions on Data Privacy, vol. 1, number
2, pp. 67-85, 2008.  <a href="http://www.tdp.cat/issues/abs.a004a08.php">http://www.tdp.cat/issues/abs.a004a08.php</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pram">pram</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(free1)
x &lt;- as.factor(free1[,"MARSTAT"])
x2 &lt;- pram(x)
x2
summary(x2)

</code></pre>

<hr>
<h2 id='Tarragona'>Tarragona data set</h2><span id='topic+Tarragona'></span>

<h3>Description</h3>

<p>A real data set comprising figures of 834 companies in the Tarragona area.
Data correspond to year 1995.
</p>


<h3>Format</h3>

<p>A data frame with 834 observations on the following 13 variables.
</p>

<dl>
<dt>FIXED.ASSETS</dt><dd><p>a numeric vector</p>
</dd>
<dt>CURRENT.ASSETS</dt><dd><p>a numeric vector</p>
</dd>
<dt>TREASURY</dt><dd><p>a numeric vector</p>
</dd>
<dt>UNCOMMITTED.FUNDS</dt><dd><p>a numeric vector</p>
</dd>
<dt>PAID.UP.CAPITAL</dt><dd><p>a numeric vector</p>
</dd>
<dt>SHORT.TERM.DEBT</dt><dd><p>a numeric vector</p>
</dd>
<dt>SALES</dt><dd><p>a numeric vector</p>
</dd>
<dt>LABOR.COSTS</dt><dd><p>a numeric vector</p>
</dd>
<dt>DEPRECIATION</dt><dd><p>a numeric vector</p>
</dd>
<dt>OPERATING.PROFIT</dt><dd><p>a numeric vector</p>
</dd>
<dt>FINANCIAL.OUTCOME</dt><dd><p>a numeric vector</p>
</dd>
<dt>GROSS.PROFIT</dt><dd><p>a numeric vector</p>
</dd>
<dt>NET.PROFIT</dt><dd><p>a numeric vector</p>
</dd></dl>



<h3>Source</h3>

<p>Public use data from the CASC project.
</p>


<h3>References</h3>

<p>Brand, R. and Domingo-Ferrer, J. and Mateo-Sanz, J.M., Reference
data sets to test and compare SDC methods for protection of numerical
microdata. Unpublished.
<a href="https://research.cbs.nl/casc/CASCrefmicrodata.pdf">https://research.cbs.nl/casc/CASCrefmicrodata.pdf</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(Tarragona)
head(Tarragona)
dim(Tarragona)
</code></pre>

<hr>
<h2 id='testdata'>A real-world data set on household income and expenditures</h2><span id='topic+testdata'></span><span id='topic+testdata2'></span>

<h3>Description</h3>

<p>A concise (1-5 lines) description of the dataset.
</p>


<h3>Format</h3>

<p>testdata: a data frame with 4580 observations on the following 15 variables.
</p>

<dl>
<dt>urbrur</dt><dd><p>a numeric vector</p>
</dd>
<dt>roof</dt><dd><p>a numeric vector</p>
</dd>
<dt>walls</dt><dd><p>a numeric vector</p>
</dd>
<dt>water</dt><dd><p>a numeric vector</p>
</dd>
<dt>electcon</dt><dd><p>a numeric vector</p>
</dd>
<dt>relat</dt><dd><p>a numeric vector</p>
</dd>
<dt>sex</dt><dd><p>a numeric vector</p>
</dd>
<dt>age</dt><dd><p>a numeric vector</p>
</dd>
<dt>hhcivil</dt><dd><p>a numeric vector</p>
</dd>
<dt>expend</dt><dd><p>a numeric vector</p>
</dd>
<dt>income</dt><dd><p>a numeric vector</p>
</dd>
<dt>savings</dt><dd><p>a numeric vector</p>
</dd>
<dt>ori_hid</dt><dd><p>a numeric vector</p>
</dd>
<dt>sampling_weight</dt><dd><p>a numeric vector</p>
</dd>
<dt>household_weights</dt><dd><p>a numeric vector</p>
</dd></dl>

<p>testdata2: A data frame with 93 observations on the following 19 variables.
</p>

<dl>
<dt>urbrur</dt><dd><p>a numeric vector</p>
</dd>
<dt>roof</dt><dd><p>a numeric vector</p>
</dd>
<dt>walls</dt><dd><p>a numeric vector</p>
</dd>
<dt>water</dt><dd><p>a numeric vector</p>
</dd>
<dt>electcon</dt><dd><p>a numeric vector</p>
</dd>
<dt>relat</dt><dd><p>a numeric vector</p>
</dd>
<dt>sex</dt><dd><p>a numeric vector</p>
</dd>
<dt>age</dt><dd><p>a numeric vector</p>
</dd>
<dt>hhcivil</dt><dd><p>a numeric vector</p>
</dd>
<dt>expend</dt><dd><p>a numeric vector</p>
</dd>
<dt>income</dt><dd><p>a numeric vector</p>
</dd>
<dt>savings</dt><dd><p>a numeric vector</p>
</dd>
<dt>ori_hid</dt><dd><p>a numeric vector</p>
</dd>
<dt>sampling_weight</dt><dd><p>a numeric vector</p>
</dd>
<dt>represent</dt><dd><p>a numeric vector</p>
</dd>
<dt>category_count</dt><dd><p>a numeric vector</p>
</dd>
<dt>relat2</dt><dd><p>a numeric vector</p>
</dd>
<dt>water2</dt><dd><p>a numeric vector</p>
</dd>
<dt>water3</dt><dd><p>a numeric vector</p>
</dd></dl>



<h3>References</h3>

<p>The International Household Survey Network, www.ihsn.org
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(testdata)
head(testdata2)
</code></pre>

<hr>
<h2 id='topBotCoding'>Top and Bottom Coding</h2><span id='topic+topBotCoding'></span>

<h3>Description</h3>

<p>Function for Top and Bottom Coding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topBotCoding(obj, value, replacement, kind = "top", column = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="topBotCoding_+3A_obj">obj</code></td>
<td>
<p>a numeric vector, a <code>data.frame</code> or a <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>-object</p>
</td></tr>
<tr><td><code id="topBotCoding_+3A_value">value</code></td>
<td>
<p>limit, from where it should be top- or bottom-coded</p>
</td></tr>
<tr><td><code id="topBotCoding_+3A_replacement">replacement</code></td>
<td>
<p>replacement value.</p>
</td></tr>
<tr><td><code id="topBotCoding_+3A_kind">kind</code></td>
<td>
<p>top or bottom</p>
</td></tr>
<tr><td><code id="topBotCoding_+3A_column">column</code></td>
<td>
<p>variable name in case the input is a <code>data.frame</code> or an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Extreme values larger or lower than <code>value</code> are replaced by a different value (<code>replacement</code> in order to reduce the disclosure risk.
</p>


<h3>Value</h3>

<p>Top or bottom coded data or modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>.
</p>


<h3>Note</h3>

<p>top-/bottom coding of factors is no longer possible as of sdcMicro &gt;=4.7.0
</p>


<h3>Author(s)</h3>

<p>Matthias Templ and Bernhard Meindl
</p>


<h3>References</h3>

<p>Templ, M. and Kowarik, A. and Meindl, B. 
Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro. 
<em>Journal of Statistical Software</em>, <strong>67</strong> (4), 1&ndash;36, 2015. <a href="https://doi.org/10.18637/jss.v067.i04">doi:10.18637/jss.v067.i04</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indivRisk">indivRisk</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(free1)
res &lt;- topBotCoding(free1[,"DEBTS"], value=9000, replacement=9100, kind="top")
max(res)

data(testdata)
range(testdata$age)
testdata &lt;- topBotCoding(testdata, value=80, replacement=81, kind="top", column="age")
range(testdata$age)

## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2, keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
           numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- topBotCoding(sdc, value=500000, replacement=1000, column="income")
testdataout &lt;- extractManipData(sdc)
</code></pre>

<hr>
<h2 id='valTable'>Comparison of different microaggregation methods</h2><span id='topic+valTable'></span>

<h3>Description</h3>

<p>A Function for the comparison of different perturbation methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>valTable(
  x,
  method = c("simple", "onedims", "clustpppca", "addNoise: additive", "swappNum"),
  measure = "mean",
  clustermethod = "clara",
  aggr = 3,
  nc = 8,
  transf = "log",
  p = 15,
  noise = 15,
  w = 1:dim(x)[2],
  delta = 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="valTable_+3A_x">x</code></td>
<td>
<p>a <code>data.frame</code> or a <code>matrix</code></p>
</td></tr>
<tr><td><code id="valTable_+3A_method">method</code></td>
<td>
<p>character vector defining names of microaggregation-, adding-noise
or rank swapping methods.</p>
</td></tr>
<tr><td><code id="valTable_+3A_measure">measure</code></td>
<td>
<p>FUN for aggregation. Possible values are mean (default), median, trim, onestep.</p>
</td></tr>
<tr><td><code id="valTable_+3A_clustermethod">clustermethod</code></td>
<td>
<p>clustermethod, if a method will need a clustering procedure</p>
</td></tr>
<tr><td><code id="valTable_+3A_aggr">aggr</code></td>
<td>
<p>aggregation level (default=3)</p>
</td></tr>
<tr><td><code id="valTable_+3A_nc">nc</code></td>
<td>
<p>number of clusters. Necessary, if a method will need a clustering procedure</p>
</td></tr>
<tr><td><code id="valTable_+3A_transf">transf</code></td>
<td>
<p>Transformation of variables before clustering.</p>
</td></tr>
<tr><td><code id="valTable_+3A_p">p</code></td>
<td>
<p>Swapping range, if method swappNum has been chosen</p>
</td></tr>
<tr><td><code id="valTable_+3A_noise">noise</code></td>
<td>
<p>noise addition, if an addNoise method has been chosen</p>
</td></tr>
<tr><td><code id="valTable_+3A_w">w</code></td>
<td>
<p>variables for swapping, if method swappNum has been chosen</p>
</td></tr>
<tr><td><code id="valTable_+3A_delta">delta</code></td>
<td>
<p>parameter for adding noise method <code>"correlated2"</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tabularize the output from <code><a href="#topic+summary.micro">summary.micro()</a></code>. Will be enhanced to all
perturbation methods in future versions.
</p>
<p>Methods for adding noise should be named via <code>addNoise:{method}</code>, e.g.
<code>addNoise:correlated</code>, where <code>{method}</code> specifies the desired method as
described in <code><a href="#topic+addNoise">addNoise()</a></code>.
</p>


<h3>Value</h3>

<p>Measures of information loss splitted for the comparison of different methods.
</p>


<h3>Author(s)</h3>

<p>Matthias Templ
</p>


<h3>References</h3>

<p>Templ, M. and Meindl, B., <code style="white-space: pre;">&#8288;Software Development for SDC in R&#8288;</code>, Lecture Notes in Computer Science, Privacy in Statistical Databases,
vol. 4302, pp. 347-359, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+microaggregation">microaggregation()</a></code>, <code><a href="#topic+summary.micro">summary.micro()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Tarragona)

valTable(
  x = Tarragona[100:200, ],
  method=c("simple", "onedims", "pca")
)

</code></pre>

<hr>
<h2 id='varToFactor'>Change the a keyVariable of an object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code> from Numeric to
Factor or from Factor to Numeric</h2><span id='topic+varToFactor'></span><span id='topic+varToNumeric'></span>

<h3>Description</h3>

<p>Change the scale of a variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varToFactor(obj, var)

varToNumeric(obj, var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="varToFactor_+3A_obj">obj</code></td>
<td>
<p>object of class <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code></p>
</td></tr>
<tr><td><code id="varToFactor_+3A_var">var</code></td>
<td>
<p>name of the keyVariable to change</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the modified <code><a href="#topic+sdcMicroObj-class">sdcMicroObj-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## for objects of class sdcMicro:
data(testdata2)
sdc &lt;- createSdcObj(testdata2,
  keyVars=c('urbrur','roof','walls','water','electcon','relat','sex'),
  numVars=c('expend','income','savings'), w='sampling_weight')
sdc &lt;- varToFactor(sdc, var="urbrur")

</code></pre>

<hr>
<h2 id='writeSafeFile'>writeSafeFile</h2><span id='topic+writeSafeFile'></span>

<h3>Description</h3>

<p>writes an anonymized dataset to a file. This function should be used in the
graphical user interface <code><a href="#topic+sdcApp">sdcApp()</a></code> only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>writeSafeFile(obj, format, randomizeRecords, fileOut, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="writeSafeFile_+3A_obj">obj</code></td>
<td>
<p>a <code>data.frame</code> containing micro data</p>
</td></tr>
<tr><td><code id="writeSafeFile_+3A_format">format</code></td>
<td>
<p>(character) specifies the output file format. Accepted
values are:
</p>

<ul>
<li> <p><code>"rdata"</code>: output will be saved in the R binary file-format
</p>
</li>
<li> <p><code>"sav"</code>: output will be saved as SPSS-file
</p>
</li>
<li> <p><code>"dta"</code>: ouput will be saved as STATA-file
</p>
</li>
<li> <p><code>"csv"</code>: output will be saved as comma seperated (text)-file
</p>
</li>
<li> <p><code>"sas"</code>: output will be saved as SAS-file (sas7bdat)
</p>
</li></ul>
</td></tr>
<tr><td><code id="writeSafeFile_+3A_randomizerecords">randomizeRecords</code></td>
<td>
<p>(logical) specifies, if the output records should
be randomized. The following options are possible:
</p>

<ul>
<li> <p><code>"no"</code>: default, no randomization takes place
</p>
</li>
<li> <p><code>"simple"</code>: records are randomly swapped
</p>
</li>
<li> <p><code>"byHH"</code>: if slot <code>"hhId"</code> is not <code>NULL</code>, the clusters defined by this
variable are randomized across the dataset. If slot <code>"hhId"</code> is <code>NULL</code>, the
records or the dataset are randomly changed.
</p>
</li>
<li> <p><code>"withinHH"</code>: if slot <code>"hhId"</code> is not <code>NULL</code>, the clusters defined by
this variable are randomized across the dataset and additionally, the order
of records within the clusters are also randomly changed. If slot <code>"hhId"</code>
is <code>NULL</code>, the records or the dataset are randomly changed.
</p>
</li></ul>
</td></tr>
<tr><td><code id="writeSafeFile_+3A_fileout">fileOut</code></td>
<td>
<p>(character) file to which output should be written</p>
</td></tr>
<tr><td><code id="writeSafeFile_+3A_...">...</code></td>
<td>
<p>optional arguments used for <code><a href="utils.html#topic+write.table">utils::write.table()</a></code> if
argument <code>"format"</code> equals <code>"csv"</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>invisible <code>NULL</code> if the file was successfully written
</p>


<h3>Author(s)</h3>

<p>Bernhard Meindl
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
