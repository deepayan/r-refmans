<!DOCTYPE html><html lang="en"><head><title>Help for package mixsqp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mixsqp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mixsqp-package'><p>mixsqp: Sequential Quadratic Programming for Fast Maximum-Likelihood</p>
Estimation of Mixture Proportions</a></li>
<li><a href='#mixobjective'><p>Compute objective optimized by mixsqp.</p></a></li>
<li><a href='#mixsqp'><p>Maximum-likelihood estimation of mixture proportions using SQP</p></a></li>
<li><a href='#simulatemixdata'><p>Create likelihood matrix from simulated data set</p></a></li>
<li><a href='#tacks'><p>Beckett &amp; Diaconis tack rolling example.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3-54</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-20</td>
</tr>
<tr>
<td>Title:</td>
<td>Sequential Quadratic Programming for Fast Maximum-Likelihood
Estimation of Mixture Proportions</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/stephenslab/mixsqp">https://github.com/stephenslab/mixsqp</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/stephenslab/mixsqp/issues">https://github.com/stephenslab/mixsqp/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides an optimization method based on sequential
    quadratic programming (SQP) for maximum likelihood estimation of
    the mixture proportions in a finite mixture model where the
    component densities are known. The algorithm is expected to obtain
    solutions that are at least as accurate as the state-of-the-art
    MOSEK interior-point solver (called by function "KWDual" in the
    'REBayes' package), and they are expected to arrive at solutions
    more quickly when the number of samples is large and the number of
    mixture components is not too large. This implements the "mix-SQP"
    algorithm, with some improvements, described in Y. Kim,
    P. Carbonetto, M. Stephens &amp; M. Anitescu (2020)
    &lt;<a href="https://doi.org/10.1080%2F10618600.2019.1689985">doi:10.1080/10618600.2019.1689985</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, stats, irlba, Rcpp (&ge; 0.12.15)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-20 17:48:56 UTC; pcarbo</td>
</tr>
<tr>
<td>Author:</td>
<td>Youngseok Kim [aut],
  Peter Carbonetto [aut, cre],
  Mihai Anitescu [aut],
  Matthew Stephens [aut],
  Jason Willwerscheid [ctb],
  Jean Morrison [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Carbonetto &lt;peter.carbonetto@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-20 21:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mixsqp-package'>mixsqp: Sequential Quadratic Programming for Fast Maximum-Likelihood
Estimation of Mixture Proportions</h2><span id='topic+mixsqp-package'></span>

<h3>Description</h3>

<p>Provides optimization algorithms based on sequential quadratic
programming (SQP) for maximum likelihood estimation of the mixture
proportions in a finite mixture model where the component densities
are known. To learn more, visit
<a href="https://github.com/stephenslab/mixsqp">https://github.com/stephenslab/mixsqp</a>, and see the help for
function <code><a href="#topic+mixsqp">mixsqp</a></code>.
</p>

<hr>
<h2 id='mixobjective'>Compute objective optimized by mixsqp.</h2><span id='topic+mixobjective'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+mixsqp">mixsqp</a></code> for a full description of the
objective function optimized by the mix-SQP algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixobjective(L, x, w = rep(1, nrow(L)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixobjective_+3A_l">L</code></td>
<td>
<p>Matrix specifying the optimization problem to be solved.
In the context of mixture-model fitting, <code>L[j,k]</code> should be
the value of the kth mixture component density at the jth data
point. <code>L</code> should be a numeric matrix with at least two
columns, with all entries being non-negative and finite (and not
missing). Further, no column should be entirely zeros. For large
matrices, it is preferrable that the matrix is stored in
double-precision; see <code><a href="base.html#topic+storage.mode">storage.mode</a></code>.</p>
</td></tr>
<tr><td><code id="mixobjective_+3A_x">x</code></td>
<td>
<p>The point at which the objective is evaluated in
<code>mixobjective</code>; see argument <code>x0</code> in <code><a href="#topic+mixsqp">mixsqp</a></code>
for details.</p>
</td></tr>
<tr><td><code id="mixobjective_+3A_w">w</code></td>
<td>
<p>An optional numeric vector, with one entry for each row of
<code>L</code>, specifying the &quot;weights&quot; associated with the rows of
<code>L</code>. All weights must be finite, non-negative and not
missing. Internally, the weights are normalized to sum to 1,
which does not change the problem, but does change the value of the
objective function reported. By default, all weights are equal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value of the objective at <code>x</code>. If any entry of
<code>L %*% x</code> is less than or equal to zero, <code>Inf</code> is
returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixsqp">mixsqp</a></code>
</p>

<hr>
<h2 id='mixsqp'>Maximum-likelihood estimation of mixture proportions using SQP</h2><span id='topic+mixsqp'></span><span id='topic+mixsqp_control_default'></span>

<h3>Description</h3>

<p>The <code>mixsqp</code> function uses a Sequential Quadratic
Programming (SQP) algorithm to find the maximum likelihood
estimates of mixture proportions in a (finite) mixture model. More
generally, <code>mixsqp</code> solves the corresponding constrained,
convex optimization problem, which is given below (see
&lsquo;Details&rsquo;). See &lsquo;References&rsquo; for more details about
the SQP algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixsqp(
  L,
  w = rep(1, nrow(L)),
  x0 = rep(1, ncol(L)),
  log = FALSE,
  control = list()
)

mixsqp_control_default()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mixsqp_+3A_l">L</code></td>
<td>
<p>Matrix specifying the optimization problem to be solved.
In the context of mixture-model fitting, <code>L[j,k]</code> should be
the value of the kth mixture component density at the jth data
point. <code>L</code> should be a numeric matrix with at least two
columns, with all entries being non-negative and finite (and not
missing). In some cases, it is easier or more natural to compute
<code>log(L)</code>; for example, it is often easier to compute the
log-likelihood rather than the likelihood. Setting <code>log = TRUE</code>
will tell <code>mixsqp</code> to interpret this input as the logarithm of
the data matrix. Note that, for large matrices, it is preferrable
that the matrix is stored in double-precision; see
<code><a href="base.html#topic+storage.mode">storage.mode</a></code>.</p>
</td></tr>
<tr><td><code id="mixsqp_+3A_w">w</code></td>
<td>
<p>An optional numeric vector, with one entry for each row of
<code>L</code>, specifying the &quot;weights&quot; associated with the rows of
<code>L</code>. All weights must be finite, non-negative and not
missing. Internally, the weights are normalized to sum to 1,
which does not change the problem, but does change the value of the
objective function reported. By default, all weights are equal.</p>
</td></tr>
<tr><td><code id="mixsqp_+3A_x0">x0</code></td>
<td>
<p>An optional numeric vector providing an initial estimate
of the solution to the optimization problem. It should contain only
finite, non-missing, non-negative values, and all entries of
<code>L %*% x0</code> must be greater than zero (to ensure that the
objective evaluates to a finite value at <code>x0</code>). The vector
will be normalized to sum to 1. By default, <code>x0</code> is the vector
with all equal values.</p>
</td></tr>
<tr><td><code id="mixsqp_+3A_log">log</code></td>
<td>
<p>When <code>log = TRUE</code>, the input matrix <code>L</code> is
interpreted as containing the logarithm of the data matrix.</p>
</td></tr>
<tr><td><code id="mixsqp_+3A_control">control</code></td>
<td>
<p>A list of parameters controlling the behaviour of
the optimization algorithm. See &lsquo;Details&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>mixsqp</code> solves the following optimization problem.
Let <code class="reqn">L</code> be a matrix with <code class="reqn">n</code> rows and <code class="reqn">m</code> columns
containing only non-negative entries, and let <code class="reqn">w = (w_1,
\ldots, w_n)</code> be a vector of non-negative &quot;weights&quot;. <code>mixsqp</code>
computes the value of vector <code class="reqn">x = (x_1, \ldots, x_m)</code>
minimizing the following objective function, </p>
<p style="text-align: center;"><code class="reqn">f(x) =
-\sum_{j=1}^n w_j \log (\sum_{k=1}^m L_{jk} x_k),</code>
</p>
<p> subject to the
constraint that <code class="reqn">x</code> lie within the simplex; that is, the
entries of <code class="reqn">x</code> are non-negative and sum to 1.  Implicitly,
there is an additional constraint <code class="reqn">L*x &gt; 0</code> in order to ensure
that the objective has a finite value. In practice, this constraint
only needs to be checked for the initial estimate to ensure that it
holds for all subsequent iterates.
</p>
<p>If all weights are equal, solving this optimization problem
corresponds to finding the maximum-likelihood estimate of the
mixture proportions <code class="reqn">x</code> given <code class="reqn">n</code> independent data points
drawn from a mixture model with <code class="reqn">m</code> components. In this case,
<code class="reqn">L_{jk}</code> is the likelihood for mixture component <code class="reqn">k</code> and
data point <code class="reqn">j</code>.
</p>
<p>The Expectation Maximization (EM) algorithm can be used to solve
this optimization problem, but it is intolerably slow in many
interesting cases, and mixsqp is much faster. 
</p>
<p>A special feature of this optimization problem is that the gradient
of the objective does not change with re-scaling; for example, if
all the entries of matrix <code>L</code> are multiplied by 100, the
gradient does not change. A practical benefit of this property is
that the optimization algorithm will behave similarly irrespective
of the scale of <code>L</code>; for example, the same value for the
convergence tolerance <code>convtol.sqp</code> will have the same effect
at different scales.
</p>
<p>A related feature is that the solution to the optimization problem
is invariant to rescaling the rows of <code>L</code>; for example, the
solution will remain the same after all the entries in a row of
<code>L</code> are multiplied by 10. A simple normalization scheme
divides each row by the largest entry in the row so that all
entries of <code>L</code> are at most 1: <code>L &lt;- L / apply(L,1,max)</code>
Occasionally, it can be helpful to normalize the rows when some of
the entries are unusually large or unusually small. This can help
to avoid numerical overflow or underflow errors.
</p>
<p>The SQP algorithm is implemented using the Armadillo C++ linear
algebra library, which can automatically take advantage of
multithreaded matrix computations to speed up <code>mixsqp</code> for
large <code>L</code> matrices, but only when R has been configured with a
multithreaded BLAS/LAPACK library (e.g., OpenBLAS).
</p>
<p>A &quot;debugging mode&quot; is provided to aid in reproducing convergence
failures or other issues. When activated, mixsqp will generate an
.RData file containing the exact <code>mixsqp</code> inputs, and will
stop execution upon convergence failure. To activate the debugging
mode, run <code>options(mixsqp.debug.mode = TRUE)</code> prior to calling
<code>mixsqp</code>. By default, the output file is <code>mixsqp.RData</code>;
the file can be changed by setting the <code>"mixsqp.debug.file"</code>
global option.
</p>
<p>The <code>control</code> argument is a list in which any of the
following named components will override the default optimization
algorithm settings (as they are defined by
<code>mixsqp_control_default</code>):
</p>

<dl>
<dt><code>normalize.rows</code></dt><dd><p>When <code>normalize.rows = TRUE</code>, the
rows of the data matrix <code>L</code> are automatically scaled so that
the largest entry in each row is 1. This is the recommended setting
for better stability of the optimization. When <code>log = TRUE</code>,
this setting is ignored becase the rows are already normalized.
Note that the objective is computed on the original (unnormalized)
matrix to make the results easier to interpret.</p>
</dd>
<dt><code>tol.svd</code></dt><dd><p>Setting used to determine rank of truncated
SVD approximation for L. The rank of the truncated singular value
decomposition is determined by the number of singular values
surpassing <code>tol.svd</code>. When <code>tol.svd = 0</code> or when <code>L</code>
has 4 or fewer columns, all computations are performed using full L
matrix.</p>
</dd>
<dt><code>convtol.sqp</code></dt><dd><p>A small, non-negative number
specifying the convergence tolerance for SQP algorithm; convergence
is reached when the maximum dual residual in the Karush-Kuhn-Tucker
(KKT) optimality conditions is less than or equal to
<code>convtol.sqp</code>. Smaller values will result in more stringent
convergence criteria and more accurate solutions, at the expense of
greater computation time. Note that changes to this tolerance
parameter may require respective changes to
<code>convtol.activeset</code> and/or <code>zero.threshold.searchdir</code> to
obtain reliable convergence.</p>
</dd>
<dt><code>convtol.activeset</code></dt><dd><p>A small, non-negative number
specifying the convergence tolerance for the active-set
step. Smaller values will result in higher quality search
directions for the SQP algorithm but possibly a greater
per-iteration computational cost. Note that changes to this
tolerance parameter can affect how reliably the SQP convergence
criterion is satisfied, as determined by <code>convtol.sqp</code>.</p>
</dd>
<dt><code>zero.threshold.solution</code></dt><dd><p>A small, non-negative
number used to determine the &quot;active set&quot;; that is, it determines
which entries of the solution are exactly zero. Any entries that
are less than or equal to <code>zero.threshold.solution</code> are
considered to be exactly zero. Larger values of
<code>zero.threshold.solution</code> may lead to speedups for matrices
with many columns, at the (slight) risk of prematurely zeroing some
co-ordinates.</p>
</dd>
<dt><code>zero.threshold.searchdir</code></dt><dd><p>A small, non-negative
number used to determine when the search direction in the
active-set step is considered &quot;small enough&quot;. Note that changes to
this tolerance parameter can affect how reliably the SQP
convergence criterion is satisfied, as determined by
<code>convtol.sqp</code>, so choose this parameter carefully.</p>
</dd>
<dt><code>suffdecr.linesearch</code></dt><dd><p>This parameter determines how
stringent the &quot;sufficient decrease&quot; condition is for accepting a
step size in the backtracking line search. Larger values will make
the condition more stringent. This should be a positive number less
than 1.</p>
</dd>
<dt><code>stepsizereduce</code></dt><dd><p>The multiplicative factor for
decreasing the step size in the backtracking line search. Smaller
values will yield a faster backtracking line search at the expense
of a less fine-grained search. Should be a positive number less than
1.</p>
</dd>
<dt><code>minstepsize</code></dt><dd><p>The smallest step size accepted by the
line search step. Should be a number greater than 0 and at most 1.</p>
</dd>
<dt><code>identity.contrib.increase</code></dt><dd><p>When the Hessian is not
positive definite, a multiple of the identity is added to the
Hessian to ensure a unique search direction. The factor for
increasing the identity contribution in this modified Hessian is
determined by this control parameter.</p>
</dd>
<dt><code>eps</code></dt><dd><p>A small, non-negative number that is added to the
terms inside the logarithms to sidestep computing logarithms of
zero. This prevents numerical problems at the cost of introducing a
small inaccuracy in the solution. Increasing this number may lead
to faster convergence but possibly a less accurate solution.</p>
</dd>
<dt><code>maxiter.sqp</code></dt><dd><p>Maximum number of SQP iterations to
run before reporting a convergence failure; that is, the maximum
number of quadratic subproblems that will be solved by the
active-set method.</p>
</dd>
<dt><code>maxiter.activeset</code></dt><dd><p>Maximum number of active-set
iterations taken to solve each of the quadratic subproblems. If
<code>NULL</code>, the maximum number of active-set iterations is set to
<code>min(20,1 + ncol(L))</code>.</p>
</dd>
<dt><code>numiter.em</code></dt><dd><p>Number of expectation maximization (EM)
updates to perform prior to running mix-SQP. Although EM can often
be slow to converge, this &quot;pre-fitting&quot; step can help to obtain a
good initial estimate for mix-SQP at a small cost.</p>
</dd>
<dt><code>verbose</code></dt><dd><p>If <code>verbose = TRUE</code>, the algorithm's
progress and a summary of the optimization settings are printed to
the console. The algorithm's progress is displayed in a table with
one row per SQP (outer loop) iteration, and with the following
columns: &quot;iter&quot;, the (outer loop) SQP iteration; &quot;objective&quot;, the
value of the objective function (see <code class="reqn">f(x)</code>) at the current
estimate of the solution, <code class="reqn">x</code>; &quot;max(rdual)&quot;, the maximum &quot;dual
residual&quot; in the Karush-Kuhn-Tucker (KKT) conditions, which is used
to monitor convergence (see <code>convtol.sqp</code>); &quot;nnz&quot;, the number
of non-zero co-ordinates in the current estimate, as determined by
<code>zero.threshold.solution</code>; &quot;max.diff&quot;, the maximum difference
in the estimates between two successive iterations; &quot;nqp&quot;, the
number of (inner loop) active-set iterations taken to solve the
quadratic subproblem; &quot;nls&quot;, the number of iterations in the
backtracking line search.</p>
</dd>
</dl>



<h3>Value</h3>

<p>A list object with the following elements:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>If the SQP algorithm converges, this is the solution to
the convex optimization problem. If the algorithm fails to
converge, it is the best estimate of the solution achieved by the
algorithm. Note that if the SQP algorithm terminates before
reaching the solution, <code>x</code> may not satisfy the equality
constraint; that is, the entries of <code>x</code> may not sum to 1.</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the objective function, <code class="reqn">f(x)</code>, at
<code>x</code>.</p>
</td></tr>
<tr><td><code>grad</code></td>
<td>
<p>The gradient of the objective function at <code>x</code>.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>The Hessian of the objective function at
<code>x</code>. The truncated SVD approximation of L is used to compute
the Hessian when it is also used for mix-SQP.</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>A character string describing the status of the
algorithm upon termination.</p>
</td></tr>
<tr><td><code>progress</code></td>
<td>
<p>A data frame containing more detailed information
about the algorithm's progress. The data frame has one row per SQP
iteration. For an explanation of the columns, see the description
of the <code>verbose</code> control parameter in &lsquo;Details&rsquo;. Missing
values (<code>NA</code>'s) in the last row indicate that these quantities were
not computed because convergence was reached before computing
them. Also note that the storage of these quantities in the
<code>progress</code> data frame is slightly different than in the console
output (when <code>verbose = TRUE</code>) as the console output shows some
quantities that were computed after the convergence check in the
previous iteration.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Y. Kim, P. Carbonetto, M. Stephens and M. Anitescu (2020). A fast
algorithm for maximum likelihood estimation of mixture proportions
using sequential quadratic programming. <em>Journal of
Computational and Graphical Statistics</em> <b>29</b>,
261-273. doi: <a href="https://doi.org/10.1080/10618600.2019.1689985">10.1080/10618600.2019.1689985</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixobjective">mixobjective</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 1e5
m &lt;- 10
w &lt;- rep(1,n)/n
L &lt;- simulatemixdata(n,m)$L
out.mixsqp &lt;- mixsqp(L,w)
f &lt;- mixobjective(L,out.mixsqp$x,w)
print(f,digits = 16)

</code></pre>

<hr>
<h2 id='simulatemixdata'>Create likelihood matrix from simulated data set</h2><span id='topic+simulatemixdata'></span>

<h3>Description</h3>

<p>Simulate a data set, then compute the conditional
likelihood matrix under a univariate normal likelihood and a
mixture-of-normals prior. This models a simple nonparametric
Empirical Bayes method applied to simulated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulatemixdata(
  n,
  m,
  simtype = c("n", "nt"),
  log = FALSE,
  normalize.rows = !log
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simulatemixdata_+3A_n">n</code></td>
<td>
<p>Positive integer specifying the number of samples to
generate and, consequently, the number of rows of the likelihood
matrix L.</p>
</td></tr>
<tr><td><code id="simulatemixdata_+3A_m">m</code></td>
<td>
<p>Integer 2 or greater specifying the number of mixture
components.</p>
</td></tr>
<tr><td><code id="simulatemixdata_+3A_simtype">simtype</code></td>
<td>
<p>The type of data to simulate. If <code>simtype =
"n"</code>, simulate <code>n</code> random numbers from a mixture of three
univariate normals with mean zero and standard deviation 1, 3 and
6. If <code>simtype = "nt"</code>, simulate from a mixture of three
univariate normals (with zero mean and standard deviations 1, 3 and
5), and a t-distribution with 2 degrees of freedom.</p>
</td></tr>
<tr><td><code id="simulatemixdata_+3A_log">log</code></td>
<td>
<p>If <code>log = TRUE</code>, return the</p>
</td></tr>
<tr><td><code id="simulatemixdata_+3A_normalize.rows">normalize.rows</code></td>
<td>
<p>If <code>normalize.rows = TRUE</code>, normalize
the rows of the likelihood matrix so that the largest entry in each
row is 1. The maximum-likelihood estimate of the mixture weights
should be invariant to this normalization, and can improve the
numerical stability of the optimization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>simulatemixdata</code> returns a list with three list
elements:
</p>
<table role = "presentation">
<tr><td><code>x</code></td>
<td>
<p>The vector of simulated random numbers (it has length n).</p>
</td></tr>
<tr><td><code>s</code></td>
<td>
<p>The standard deviations of the mixture components in the
mixture-of-normals prior. The rules for selecting the standard
deviations are based on the <code>autoselect.mixsd</code> function from
the <code>ashr</code> package.</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>The n x m conditional likelihood matrix, in which
individual entries (i,j) of the likelihood matrix are given by the
normal density function with mean zero and variance <code>1 +
s[j]^2</code>. If <code>normalize.rows = TRUE</code>, the entries in each row
are normalized such that the larger entry in each row is 1. If
<code>log = TRUE</code>, the matrix of log-likelihoods is returned.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
# Generate the likelihood matrix for a data set with 1,000 samples
# and a nonparametric Empirical Bayes model with 20 mixture
# components.
dat &lt;- simulatemixdata(1000,20)

</code></pre>

<hr>
<h2 id='tacks'>Beckett &amp; Diaconis tack rolling example.</h2><span id='topic+tacks'></span>

<h3>Description</h3>

<p>This data set contains the likelihood matrix and
weights for the Beckett-Diaconis tacks example, in which the data
are modeled using a binomial mixture. These data were generated by
running the &quot;Bmix1&quot; demo from the REBayes package, and saving the
arguments passed to <code>KWDual</code>, as well as the (normalized)
solution returned by the <code>KWDual</code> call.
</p>


<h3>Format</h3>

<p><code>tacks</code> is a list with the following elements:
</p>

<dl>
<dt>L</dt><dd><p>9 x 299 likelihood matrix.</p>
</dd>
<dt>w</dt><dd><p>Numeric vector of length 9 specifying the weights
associated with the rows of <code>L</code>.</p>
</dd>
<dt>x</dt><dd><p>Solution provided by the <code>KWDual</code>
solver.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
# The optimal solution for the tack example is extremely sparse.
data(tacks)
plot(tacks$x,type = "l",col = "royalblue")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
