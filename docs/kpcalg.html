<!DOCTYPE html><html><head><title>Help for package kpcalg</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {kpcalg}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dcov.gamma'><p>Test to check the independence between two variables x and y using the Distance Covariance.</p>
The dcov.gamma() function, uses Distance Covariance independence criterion with gamma approximation to test for independence between two random variables.</a></li>
<li><a href='#frml.additive.smooth'><p>Formula for GAM without crossterms</p></a></li>
<li><a href='#frml.full.smooth'><p>Formula for GAM with crossterms</p></a></li>
<li><a href='#hsic.clust'><p>HSIC cluster permutation conditional independence test</p></a></li>
<li><a href='#hsic.gamma'><p>Hilber Schmidt Independence Criterion gamma test</p></a></li>
<li><a href='#hsic.perm'><p>Hilber Schmidt Independence Criterion permutation test</p></a></li>
<li><a href='#hsic.test'><p>Hilber Schmidt Independence Criterion test</p></a></li>
<li><a href='#kernelCItest'><p>Kernel Conditional Independence test</p></a></li>
<li><a href='#kpc'><p>Estimate the WAN-PDAG using the kPC Algorithm</p></a></li>
<li><a href='#regrVonPS'><p>Check if variable can be regressed to independence on its parents</p></a></li>
<li><a href='#regrXonS'><p>Regress set of variables on its parents</p></a></li>
<li><a href='#udag2wanpdag'><p>Last kPC Algorithm Step: Extend Object with Skeleton to Completed PDAG</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Date:</td>
<td>2017-01-19</td>
</tr>
<tr>
<td>Title:</td>
<td>Kernel PC Algorithm for Causal Structure Detection</td>
</tr>
<tr>
<td>Description:</td>
<td>Kernel PC (kPC) algorithm for causal structure learning and causal inference using graphical models. kPC is a version of PC algorithm that uses kernel based independence criteria in order to be able to deal with non-linear relationships and non-Gaussian noise.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Petras Verbyla, Nina Ines Bertille Desgranges, Lorenz Wernisch</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Petras Verbyla &lt;petras.verbyla@mrc-bsu.cam.ac.uk&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>pcalg, energy, kernlab, parallel, mgcv, RSpectra, methods,
graph, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rgraphviz, knitr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-01-20 12:37:53 UTC; petras</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-01-22 12:38:35</td>
</tr>
</table>
<hr>
<h2 id='dcov.gamma'>Test to check the independence between two variables x and y using the Distance Covariance.
The dcov.gamma() function, uses Distance Covariance independence criterion with gamma approximation to test for independence between two random variables.</h2><span id='topic+dcov.gamma'></span>

<h3>Description</h3>

<p>Test to check the independence between two variables x and y using the Distance Covariance.
The dcov.gamma() function, uses Distance Covariance independence criterion with gamma approximation to test for independence between two random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcov.gamma(x, y, index = 1, numCol = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dcov.gamma_+3A_x">x</code></td>
<td>
<p>data of first sample</p>
</td></tr>
<tr><td><code id="dcov.gamma_+3A_y">y</code></td>
<td>
<p>data of second sample</p>
</td></tr>
<tr><td><code id="dcov.gamma_+3A_index">index</code></td>
<td>
<p>exponent on Euclidean distance, in (0,2]</p>
</td></tr>
<tr><td><code id="dcov.gamma_+3A_numcol">numCol</code></td>
<td>
<p>Number of columns used in incomplete Singular Value Decomposition</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let x and y be two samples of length n. Gram matrices K and L are defined as: <code class="reqn">K_{i,j} = \| x_i-x_j \|^s</code> and <code class="reqn">L_{i,j} = \| y_i-y_j \|^s</code>, where 0&lt;s&lt;2. <code class="reqn">H_{i,j} = \delta_{i,j} - \frac{1}{n}</code>. Let A=HKH and B=HLH, then <code class="reqn">nV^2=\frac{1}{n^2}\sum A_{i,j} B_{i,j}</code>. For more detail: dcov.test in package energy. Gamma test compares <code class="reqn">nV^2_n(x,y)</code> with the <code class="reqn">\alpha</code> quantile of the gamma distribution with mean and variance same as <code class="reqn">nV^2_n</code> under independence hypothesis.
</p>


<h3>Value</h3>

<p>dcov.gamma() returns a list with class htest containing
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>observed value of the test statistic</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>nV^2(x,y)</p>
</td></tr>
<tr><td><code>estimates</code></td>
<td>
<p>a vector: [nV^2(x,y), mean of nV^2(x,y), variance of nV^2(x,y)]</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>replicates of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>approximate p-value of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>desciption of data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>) and Nina Ines Bertille Desgranges
</p>


<h3>References</h3>

<p>A. Gretton et al. (2005). Kernel Methods for Measuring Independence. JMLR 6 (2005) 2075-2129.
</p>
<p>G. Szekely, M. Rizzo and N. Bakirov (2007). Measuring and Testing Dependence by Correlation of Distances. The Annals of Statistics 2007, Vol. 35, No. 6, 2769-2794.
</p>


<h3>See Also</h3>

<p><a href="#topic+hsic.perm">hsic.perm</a>, <a href="#topic+hsic.clust">hsic.clust</a>, <a href="#topic+hsic.gamma">hsic.gamma</a>, dcov.test, <a href="#topic+kernelCItest">kernelCItest</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(energy)
set.seed(10)
#independence
x &lt;- runif(300)
y &lt;- runif(300)

hsic.gamma(x,y)
hsic.perm(x,y)
dcov.gamma(x,y)
dcov.test(x,y)

#uncorelated but not dependent
z &lt;- 10*(runif(300)-0.5)
w &lt;- z^2 + 10*runif(300)

cor(z,w)
hsic.gamma(z,w)
hsic.perm(z,w)
dcov.gamma(z,w)
dcov.test(z,w)
</code></pre>

<hr>
<h2 id='frml.additive.smooth'>Formula for GAM without crossterms</h2><span id='topic+frml.additive.smooth'></span>

<h3>Description</h3>

<p>Creates a formula for <a href="mgcv.html#topic+gam">gam</a> to be used in <a href="#topic+regrXonS">regrXonS</a>. For data <code class="reqn">X=(X_1,...X_n,X_{n+1},...,X_m)</code>, variable to be regressed <code class="reqn">X_{i}</code>, i=1...n and variables to regress on <code class="reqn">S={X_{n+1},...,X_m}</code> creates formula <code class="reqn">X_i \sim s(X_{n+1}) + ... + s(X_m)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frml.additive.smooth(target.ind, pred.inds, var.str = "x")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frml.additive.smooth_+3A_target.ind">target.ind</code></td>
<td>
<p>integer, number for the variable to be regressed</p>
</td></tr>
<tr><td><code id="frml.additive.smooth_+3A_pred.inds">pred.inds</code></td>
<td>
<p>integer(s), number(s) for the variable(s) on which we regress</p>
</td></tr>
<tr><td><code id="frml.additive.smooth_+3A_var.str">var.str</code></td>
<td>
<p>name of variables used to create formula, default is &quot;x&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>formula.additive.smooth() returns a formula <code class="reqn">X_i \sim s(X_{n+1}) + ... + s(X_m)</code>
</p>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>)
</p>


<h3>See Also</h3>

<p><a href="#topic+regrXonS">regrXonS</a>
</p>

<hr>
<h2 id='frml.full.smooth'>Formula for GAM with crossterms</h2><span id='topic+frml.full.smooth'></span>

<h3>Description</h3>

<p>Creates a formula for <a href="mgcv.html#topic+gam">gam</a> to be used in <a href="#topic+regrXonS">regrXonS</a>. For data <code class="reqn">X=(X_1,...X_n,X_{n+1},...,X_m)</code>, variable to be regressed <code class="reqn">X_{i}</code>, i=1...n and variables to regress on <code class="reqn">S={X_{n+1},...,X_m}</code> creates formula <code class="reqn">X_i \sim s(X_{n+1},...,X_m</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frml.full.smooth(target.ind, pred.inds, var.str = "x")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frml.full.smooth_+3A_target.ind">target.ind</code></td>
<td>
<p>integer, number for the variable to be regressed</p>
</td></tr>
<tr><td><code id="frml.full.smooth_+3A_pred.inds">pred.inds</code></td>
<td>
<p>integer(s), number(s) for the variable(s) on which we regress</p>
</td></tr>
<tr><td><code id="frml.full.smooth_+3A_var.str">var.str</code></td>
<td>
<p>name of variables used to create formula, default is &quot;x&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>formula.full.smooth() returns a formula <code class="reqn">X_i \sim s(X_{n+1},...,X_m)</code>
</p>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>)
</p>


<h3>See Also</h3>

<p><a href="#topic+regrXonS">regrXonS</a>
</p>

<hr>
<h2 id='hsic.clust'>HSIC cluster permutation conditional independence test</h2><span id='topic+hsic.clust'></span>

<h3>Description</h3>

<p>Conditional independence test using HSIC and permutation with clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsic.clust(x, y, z, sig = 1, p = 100, numCluster = 10, numCol = 50,
  eps = 0.1, paral = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsic.clust_+3A_x">x</code></td>
<td>
<p>first variable</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_y">y</code></td>
<td>
<p>second variable</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_z">z</code></td>
<td>
<p>set of variables on which we condition</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_sig">sig</code></td>
<td>
<p>the with of the Gaussian kernel</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_p">p</code></td>
<td>
<p>the number of permutations</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_numcluster">numCluster</code></td>
<td>
<p>number of clusters for clustering z</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_numcol">numCol</code></td>
<td>
<p>maximum number of columns that we use for the incomplete Cholesky decomposition</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_eps">eps</code></td>
<td>
<p>normalization parameter for HSIC cluster test</p>
</td></tr>
<tr><td><code id="hsic.clust_+3A_paral">paral</code></td>
<td>
<p>number of cores used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let x and y be two samples of length n. Gram matrices K and L are defined as: <code class="reqn">K_{i,j} = \exp\frac{(x_i-x_j)^2}{\sigma^2}</code>, <code class="reqn">L_{i,j} = \exp\frac{(y_i-y_j)^2}{\sigma^2}</code> and <code class="reqn">M_{i,j} = \exp\frac{(z_i-z_j)^2}{\sigma^2}</code>. <code class="reqn">H_{i,j} = \delta_{i,j} - \frac{1}{n}</code>. Let <code class="reqn">A=HKH</code>, <code class="reqn">B=HLH</code> and <code class="reqn">C=HMH</code>. <code class="reqn">HSIC(X,Y|Z) = \frac{1}{n^2}Tr(AB-2AC(C+\epsilon I)^{-2}CB+AC(C+\epsilon I)^{-2}CBC(C+\epsilon I)^{-2}C)</code>. Permutation test clusters Z and then permutes Y in the clusters of Z p times to get <code class="reqn">Y_{(p)}</code> and calculates <code class="reqn">HSIC(X,Y_{(p)}|Z)</code>. <code class="reqn">pval = \frac{1(HSIC(X,Y|Z)&gt;HSIC(Z,Y_{(p)}|Z))}{p}</code>.
</p>


<h3>Value</h3>

<p>hsic.clust() returns a list with class htest containing
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>observed value of the test statistic</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>HSIC(x,y)</p>
</td></tr>
<tr><td><code>estimates</code></td>
<td>
<p>a vector: [HSIC(x,y), mean of HSIC(x,y), variance of HSIC(x,y)]</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>replicates of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>approximate p-value of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>desciption of data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>) and Nina Ines Bertille Desgranges
</p>


<h3>References</h3>

<p>Tillman, R. E., Gretton, A. and Spirtes, P. (2009). Nonlinear directed acyclic structure learning with weakly additive noise model. NIPS 22, Vancouver.
</p>
<p>K. Fukumizu et al. (2007). Kernel Measures of Conditional Dependence. NIPS 20. <a href="https://papers.nips.cc/paper/3340-kernel-measures-of-conditional-dependence.pdf">https://papers.nips.cc/paper/3340-kernel-measures-of-conditional-dependence.pdf</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+hsic.gamma">hsic.gamma</a>, <a href="#topic+hsic.perm">hsic.perm</a>, <a href="#topic+kernelCItest">kernelCItest</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(energy)
set.seed(10)
# x and y dependent, but independent conditionally on z
z &lt;- 10*runif(300)
x &lt;- sin(z) + runif(300)
y &lt;- cos(z) + runif(300)
plot(x,y)
hsic.gamma(x,y)
hsic.perm(x,y)
dcov.test(x,y)
hsic.clust(x,y,z)
</code></pre>

<hr>
<h2 id='hsic.gamma'>Hilber Schmidt Independence Criterion gamma test</h2><span id='topic+hsic.gamma'></span>

<h3>Description</h3>

<p>Test to check the independence between two variables x and y using HSIC.
The hsic.gamma() function, uses Hilbert-Schmidt independence criterion to test for independence between
random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsic.gamma(x, y, sig = 1, numCol = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsic.gamma_+3A_x">x</code></td>
<td>
<p>data of first sample</p>
</td></tr>
<tr><td><code id="hsic.gamma_+3A_y">y</code></td>
<td>
<p>data of second sample</p>
</td></tr>
<tr><td><code id="hsic.gamma_+3A_sig">sig</code></td>
<td>
<p>Gaussian kernel width for HSIC tests. Default is 1</p>
</td></tr>
<tr><td><code id="hsic.gamma_+3A_numcol">numCol</code></td>
<td>
<p>maximum number of columns that we use for the incomplete Cholesky decomposition</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let x and y be two samples of length n. Gram matrices K and L are defined as: <code class="reqn">K_{i,j} = \exp\frac{(x_i-x_j)^2}{\sigma^2}</code> and <code class="reqn">L_{i,j} = \exp\frac{(y_i-y_j)^2}{\sigma^2}</code>. <code class="reqn">H_{i,j} = \delta_{i,j} - \frac{1}{n}</code>. Let <code class="reqn">A=HKH</code> and <code class="reqn">B=HLH</code>, then <code class="reqn">HSIC(x,y)=\frac{1}{n^2}Tr(AB)</code>. Gamma test compares HSIC(x,y) with the <code class="reqn">\alpha</code> quantile of the gamma distribution with mean and variance such as HSIC under independence hypothesis.
</p>


<h3>Value</h3>

<p>hsic.gamma() returns a list with class htest containing
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>observed value of the test statistic</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>HSIC(x,y)</p>
</td></tr>
<tr><td><code>estimates</code></td>
<td>
<p>a vector: [HSIC(x,y), mean of HSIC(x,y), variance of HSIC(x,y)]</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>replicates of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>approximate p-value of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>desciption of data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>) and Nina Ines Bertille Desgranges
</p>


<h3>References</h3>

<p>A. Gretton et al. (2005). Kernel Methods for Measuring Independence. JMLR 6 (2005) 2075-2129.
</p>


<h3>See Also</h3>

<p><a href="#topic+hsic.perm">hsic.perm</a>, <a href="#topic+hsic.clust">hsic.clust</a>, <a href="#topic+kernelCItest">kernelCItest</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(energy)
set.seed(10)
#independence
x &lt;- runif(300)
y &lt;- runif(300)

hsic.gamma(x,y)
hsic.perm(x,y)
dcov.gamma(x,y)
dcov.test(x,y)

#uncorelated but not dependent
z &lt;- 10*(runif(300)-0.5)
w &lt;- z^2 + 10*runif(300)

cor(z,w)
hsic.gamma(z,w)
hsic.perm(z,w)
dcov.gamma(z,w)
dcov.test(z,w)
</code></pre>

<hr>
<h2 id='hsic.perm'>Hilber Schmidt Independence Criterion permutation test</h2><span id='topic+hsic.perm'></span>

<h3>Description</h3>

<p>Test to check the independence between two variables x and y using HSIC.
The hsic.perm() function, uses Hilbert-Schmidt independence criterion to test for independence between
random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsic.perm(x, y, sig = 1, p = 100, numCol = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsic.perm_+3A_x">x</code></td>
<td>
<p>data of first sample</p>
</td></tr>
<tr><td><code id="hsic.perm_+3A_y">y</code></td>
<td>
<p>data of second sample</p>
</td></tr>
<tr><td><code id="hsic.perm_+3A_sig">sig</code></td>
<td>
<p>Gaussian kernel width for HSIC tests. Default is 1</p>
</td></tr>
<tr><td><code id="hsic.perm_+3A_p">p</code></td>
<td>
<p>Number of permutations. Default is 100</p>
</td></tr>
<tr><td><code id="hsic.perm_+3A_numcol">numCol</code></td>
<td>
<p>maximum number of columns that we use for the incomplete Cholesky decomposition</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let x and y be two samples of length n. Gram matrices K and L are defined as: <code class="reqn">K_{i,j} = \exp\frac{(x_i-x_j)^2}{\sigma^2}</code> and <code class="reqn">L_{i,j} = \exp\frac{(y_i-y_j)^2}{\sigma^2}</code>. <code class="reqn">H_{i,j} = \delta_{i,j} - \frac{1}{n}</code>. Let <code class="reqn">A=HKH</code> and <code class="reqn">B=HLH</code>, then <code class="reqn">HSIC(x,y)=\frac{1}{n^2}Tr(AB)</code>. Permutation test permutes y p times to get <code class="reqn">y_{(p)}</code> and calculates HSIC(x,y_(p)). <code class="reqn">pval = \frac{1(HSIC(x,y)&gt;HSIC(x,y_{(p)}))}{p}</code>.
</p>


<h3>Value</h3>

<p>hsic.perm() returns a list with class htest containing
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>observed value of the test statistic</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>HSIC(x,y)</p>
</td></tr>
<tr><td><code>estimates</code></td>
<td>
<p>a vector: [HSIC(x,y), mean of HSIC(x,y), variance of HSIC(x,y)]</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>replicates of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>approximate p-value of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>desciption of data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>) and Nina Ines Bertille Desgranges
</p>


<h3>References</h3>

<p>A. Gretton et al. (2005). Kernel Methods for Measuring Independence. JMLR 6 (2005) 2075-2129.
</p>


<h3>See Also</h3>

<p><a href="#topic+hsic.gamma">hsic.gamma</a>, <a href="#topic+hsic.clust">hsic.clust</a>, <a href="#topic+kernelCItest">kernelCItest</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(energy)
set.seed(10)
#independence
x &lt;- runif(300)
y &lt;- runif(300)

hsic.gamma(x,y)
hsic.perm(x,y)
dcov.gamma(x,y)
dcov.test(x,y)

#uncorelated but not dependent
z &lt;- 10*(runif(300)-0.5)
w &lt;- z^2 + 10*runif(300)

cor(z,w)
hsic.gamma(z,w)
hsic.perm(z,w)
dcov.gamma(z,w)
dcov.test(z,w)
</code></pre>

<hr>
<h2 id='hsic.test'>Hilber Schmidt Independence Criterion test</h2><span id='topic+hsic.test'></span>

<h3>Description</h3>

<p>Test to check the independence between two variables x and y using HSIC.
The hsic.test() function, uses Hilbert-Schmidt independence criterion to test for independence between two random variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hsic.test(x, y, p = 0, hsic.method = c("gamma", "perm"), sig = 1,
  numCol = floor(length(x)/10))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hsic.test_+3A_x">x</code></td>
<td>
<p>data of first sample</p>
</td></tr>
<tr><td><code id="hsic.test_+3A_y">y</code></td>
<td>
<p>data of second sample</p>
</td></tr>
<tr><td><code id="hsic.test_+3A_p">p</code></td>
<td>
<p>number of replicates, if 0</p>
</td></tr>
<tr><td><code id="hsic.test_+3A_hsic.method">hsic.method</code></td>
<td>
<p>method for HSIC test, either gamma test <a href="#topic+hsic.gamma">hsic.gamma</a> or permutation test <a href="#topic+hsic.perm">hsic.perm</a></p>
</td></tr>
<tr><td><code id="hsic.test_+3A_sig">sig</code></td>
<td>
<p>Gaussian kernel width for HSIC. Default is 1</p>
</td></tr>
<tr><td><code id="hsic.test_+3A_numcol">numCol</code></td>
<td>
<p>number of columns in the Incomplete Cholesky Decomposition of Gram matrices. Default is floor(length(x)/10)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let x and y be two samples of length n. Gram matrices K and L are defined as: <code class="reqn">K_{i,j} = \exp\frac{(x_i-x_j)^2}{\sigma^2}</code> and <code class="reqn">L_{i,j} = \exp\frac{(y_i-y_j)^2}{\sigma^2}</code>. <code class="reqn">H_{i,j} = \delta_{i,j} - \frac{1}{n}</code>. Let <code class="reqn">A=HKH</code> and <code class="reqn">B=HLH</code>, then <code class="reqn">HSIC(x,y)=\frac{1}{n^2}Tr(AB)</code>.
</p>


<h3>Value</h3>

<p>hsic.gamma() returns a list with class htest containing
</p>
<table>
<tr><td><code>method</code></td>
<td>
<p>description of test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>observed value of the test statistic</p>
</td></tr>
<tr><td><code>estimate</code></td>
<td>
<p>HSIC(x,y)</p>
</td></tr>
<tr><td><code>estimates</code></td>
<td>
<p>a vector: [HSIC(x,y), mean of HSIC(x,y), variance of HSIC(x,y)]</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>replicates of the test statistic</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>approximate p-value of the test</p>
</td></tr>
<tr><td><code>data.name</code></td>
<td>
<p>desciption of data</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>) and Nina Ines Bertille Desgranges
</p>


<h3>References</h3>

<p>A. Gretton et al. (2005). Kernel Methods for Measuring Independence. JMLR 6 (2005) 2075-2129.
</p>


<h3>See Also</h3>

<p><a href="#topic+hsic.perm">hsic.perm</a>, <a href="#topic+hsic.clust">hsic.clust</a>, <a href="#topic+kernelCItest">kernelCItest</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(energy)
set.seed(10)
#independence
x &lt;- runif(300)
y &lt;- runif(300)

hsic.gamma(x,y)
hsic.perm(x,y)
dcov.gamma(x,y)
dcov.test(x,y)

#uncorelated but not dependent
z &lt;- 10*(runif(300)-0.5)
w &lt;- z^2 + 10*runif(300)

cor(z,w)
hsic.gamma(z,w)
hsic.perm(z,w)
dcov.gamma(z,w)
dcov.test(z,w)
</code></pre>

<hr>
<h2 id='kernelCItest'>Kernel Conditional Independence test</h2><span id='topic+kernelCItest'></span>

<h3>Description</h3>

<p>Test to check the (conditional) dependence between two variables x and y given a set of variables S, using independence criteria. The kernelCItest() function, uses Distance Covariance or Hilbert-Schmidt Independence Criterion to test for the (conditional) independence between random variables, with an interface that can easily by used in <code>skeleton</code>, <code><a href="S4Vectors.html#topic+pc">pc</a></code> or <code><a href="#topic+kpc">kpc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernelCItest(x, y, S = NULL, suffStat, verbose = FALSE, data,
  ic.method = NULL, p = NULL, index = NULL, sig = NULL, numCol = NULL,
  numCluster = NULL, eps = NULL, paral = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kernelCItest_+3A_x">x</code>, <code id="kernelCItest_+3A_y">y</code>, <code id="kernelCItest_+3A_s">S</code></td>
<td>
<p>It is tested, whether x and y are conditionally independent given the subset S of the remaining nodes. x, y, S all are integers, corresponding to variable or node numbers.</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_suffstat">suffStat</code></td>
<td>
<p>a list of parameters consisting of data, ic.method, p, index, sig, numCol, numCluster, eps, paral</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_verbose">verbose</code></td>
<td>
<p>a logical parameter, if TRUE, detailed output is provided.</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_data">data</code></td>
<td>
<p>numeric matrix witch collumns representing variables and rows representing samples</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_ic.method">ic.method</code></td>
<td>
<p>Method for the (conditional) independence test: Distance Covariance (permutation or gamma test), HSIC (permutation or gamma test) or HSIC cluster</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_p">p</code></td>
<td>
<p>Number of permutations for Distance Covariance, HSIC permutation and HSIC cluster tests. Default is Distance Covariance</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_index">index</code></td>
<td>
<p>Number in (0,2] the power of the distance in the Distance Covariance</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_sig">sig</code></td>
<td>
<p>Gaussian kernel width for HSIC tests. Default is 1</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_numcol">numCol</code></td>
<td>
<p>Number of columns used in the incomplete Cholesky decomposition. Default is 50</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_numcluster">numCluster</code></td>
<td>
<p>Number of clusters for kPC clust algorithm</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_eps">eps</code></td>
<td>
<p>Normalization parameter for kPC clust. Default is 0.1</p>
</td></tr>
<tr><td><code id="kernelCItest_+3A_paral">paral</code></td>
<td>
<p>Number of cores to use for parallel calculations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>kernelCItest() returns the p-value of the test.
</p>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>) and Nina Ines Bertille Desgranges
</p>


<h3>References</h3>

<p>G. Szekely, M. Rizzo and N. Bakirov (2007). Measuring and Testing Dependence by Correlation of Distances. The Annals of Statistics 2007, Vol. 35, No. 6, 2769-2794.
</p>
<p>A. Gretton et al. (2005). Kernel Methods for Measuring Independence. JMLR 6 (2005) 2075-2129.
</p>
<p>R. Tillman, A. Gretton and P. Spirtes (2009). Nonlinear directed acyclic structure learning with weakly additive noise model. NIPS 22, Vancouver.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(10)
library(pcalg)
z &lt;- 10*runif(300)
w &lt;- 10*runif(300)
x &lt;- sin(z) + runif(300)
y &lt;- cos(z) + runif(300)

data &lt;- cbind(x,y,z,w)

#conditionally independent
test1a &lt;- kernelCItest(x=1,y=2,S=c(3),suffStat = list(data=data,ic.method="dcc.gamma"))
test2a &lt;- kernelCItest(x=1,y=2,S=c(3),suffStat = list(data=data,ic.method="dcc.perm"))
test3a &lt;- kernelCItest(x=1,y=2,S=c(3),suffStat = list(data=data,ic.method="hsic.gamma"))
test4a &lt;- kernelCItest(x=1,y=2,S=c(3),suffStat = list(data=data,ic.method="hsic.perm"))
test5a &lt;- kernelCItest(x=1,y=2,S=c(3),suffStat = list(data=data,ic.method="hsic.clust"))
test6a &lt;- gaussCItest( x=1,y=2,S=c(3),suffStat = list(C=cor(data),n=4))

test1a
test2a
test3a
test4a
test5a
test6a

#dependent
test1b &lt;- kernelCItest(x=1,y=2,S=c(4),suffStat = list(data=data,ic.method="dcc.gamma"))
test2b &lt;- kernelCItest(x=1,y=2,S=c(4),suffStat = list(data=data,ic.method="dcc.perm"))
test3b &lt;- kernelCItest(x=1,y=2,S=c(4),suffStat = list(data=data,ic.method="hsic.gamma"))
test4b &lt;- kernelCItest(x=1,y=2,S=c(4),suffStat = list(data=data,ic.method="hsic.perm"))
test5b &lt;- kernelCItest(x=1,y=2,S=c(4),suffStat = list(data=data,ic.method="hsic.clust"))
test6b &lt;- gaussCItest( x=1,y=2,S=c(4),suffStat = list(C=cor(data),n=4))

test1b
test2b
test3b
test4b
test5b
test6b
</code></pre>

<hr>
<h2 id='kpc'>Estimate the WAN-PDAG using the kPC Algorithm</h2><span id='topic+kpc'></span>

<h3>Description</h3>

<p>Estimates the weakly additive noise partially directed acyclic graph (WAN-PDAG) from observational data, using the kPC algorithm. This is a version of <code><a href="S4Vectors.html#topic+pc">pc</a></code> from pcalg package, that uses HSIC (<a href="#topic+hsic.gamma">hsic.gamma</a>, <a href="#topic+hsic.perm">hsic.perm</a> or <a href="#topic+hsic.clust">hsic.clust</a>) or distance covariance (<code>dcov.test</code> or <a href="#topic+dcov.gamma">dcov.gamma</a>)  independence tests and <a href="#topic+udag2wanpdag">udag2wanpdag</a> instead of <code>udag2pdag</code> in the last step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kpc(suffStat, indepTest, alpha, labels, p, fixedGaps = NULL,
  fixedEdges = NULL, NAdelete = TRUE, m.max = Inf, u2pd = c("relaxed",
  "rand", "retry"), skel.method = c("stable", "original", "stable.fast"),
  conservative = FALSE, maj.rule = FALSE, solve.confl = FALSE,
  verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kpc_+3A_suffstat">suffStat</code></td>
<td>
<p>a <a href="base.html#topic+list">list</a> of sufficient statistics, containing all necessary elements for the conditional independence decisions in the function indepTest</p>
</td></tr>
<tr><td><code id="kpc_+3A_indeptest">indepTest</code></td>
<td>
<p>A function for testing conditional independence. It is internally called as indepTest(x,y,S,suffStat), and tests conditional independence of x and y given S. Here, x and y are variables, and S is a (possibly empty) vector of variables (all variables are denoted by their column numbers in the adjacency matrix). suffStat is a list, see the argument above. The return value of indepTest is the p-value of the test for conditional independence. Default is <a href="#topic+kernelCItest">kernelCItest</a>.</p>
</td></tr>
<tr><td><code id="kpc_+3A_alpha">alpha</code></td>
<td>
<p>significance level (number in (0,1) for the individual conditional independence tests.</p>
</td></tr>
<tr><td><code id="kpc_+3A_labels">labels</code></td>
<td>
<p>(optional) character vector of variable (or &quot;node&quot;) names. Typically preferred to specifying p.</p>
</td></tr>
<tr><td><code id="kpc_+3A_p">p</code></td>
<td>
<p>(optional) number of variables (or nodes). May be specified if labels are not, in which case labels is set to 1:p.</p>
</td></tr>
<tr><td><code id="kpc_+3A_fixedgaps">fixedGaps</code></td>
<td>
<p>A logical matrix of dimension p*p. If entry [i,j] or [j,i] (or both) are TRUE, the edge i-j is removed before starting the algorithm. Therefore, this edge is guaranteed to be absent in the resulting graph.</p>
</td></tr>
<tr><td><code id="kpc_+3A_fixededges">fixedEdges</code></td>
<td>
<p>A logical matrix of dimension p*p. If entry [i,j] or [j,i] (or both) are TRUE, the edge i-j is never considered for removal. Therefore, this edge is guaranteed to be present in the resulting graph.</p>
</td></tr>
<tr><td><code id="kpc_+3A_nadelete">NAdelete</code></td>
<td>
<p>If indepTest returns NA and this option is TRUE, the corresponding edge is deleted. If this option is FALSE, the edge is not deleted.</p>
</td></tr>
<tr><td><code id="kpc_+3A_m.max">m.max</code></td>
<td>
<p>Maximal size of the conditioning sets that are considered in the conditional independence tests.</p>
</td></tr>
<tr><td><code id="kpc_+3A_u2pd">u2pd</code></td>
<td>
<p>String specifying the method for dealing with conflicting information when trying to orient edges (see details below).</p>
</td></tr>
<tr><td><code id="kpc_+3A_skel.method">skel.method</code></td>
<td>
<p>Character string specifying method; the default, &quot;stable&quot; provides an order-independent skeleton, see skeleton.</p>
</td></tr>
<tr><td><code id="kpc_+3A_conservative">conservative</code></td>
<td>
<p>Logical indicating if the conservative PC is used. In this case, only option u2pd = &quot;relaxed&quot; is supported. Note that therefore the resulting object might not be extendable to a DAG. See details for more information.</p>
</td></tr>
<tr><td><code id="kpc_+3A_maj.rule">maj.rule</code></td>
<td>
<p>Logical indicating that the triples shall be checked for ambiguity using a majority rule idea, which is less strict than the conservative PC algorithm. For more information, see details.</p>
</td></tr>
<tr><td><code id="kpc_+3A_solve.confl">solve.confl</code></td>
<td>
<p>If TRUE, the orientation of the v-structures and the orientation rules work with lists for candidate sets and allow bi-directed edges to resolve conflicting edge orientations. In this case, only option u2pd = relaxed is supported. Note, that therefore the resulting object might not be a CPDAG because bi-directed edges might be present. See details for more information.</p>
</td></tr>
<tr><td><code id="kpc_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, detailed output is provided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information: <code><a href="S4Vectors.html#topic+pc">pc</a></code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;pcAlgo&quot; (see <code>pcAlgo</code>) containing an estimate of the equivalence class of the underlying DAG.
</p>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>)
</p>


<h3>References</h3>

<p>Tillman, R. E., Gretton, A. and Spirtes, P. (2009). Nonlinear directed acyclic structure learning with weakly additive noise model. NIPS 22, Vancouver.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(pcalg)
set.seed(4)
n &lt;- 300
data &lt;- NULL
x1 &lt;- 2*(runif(n)-0.5)
x2 &lt;- x1 + runif(n)-0.5
x3 &lt;- x1^2 + 0.6*runif(n)
x4 &lt;- rnorm(n)
x5 &lt;- x3 + x4^2 + 2*runif(n)
x6 &lt;- 10*(runif(n)-0.5)
x7 &lt;- x6^2 + 5*runif(n)
x8 &lt;- 2*x7^2 + 1.5*rnorm(n)
x9 &lt;- x7 + 4*runif(n)
data &lt;- cbind(x1,x2,x3,x4,x5,x6,x7,x8,x9)
true &lt;- matrix(0,9,9)
true[c(1),c(2,3)]&lt;-true[c(3,4),5]&lt;-true[c(6),c(7)]&lt;-true[c(7),c(8)]&lt;-true[7,9]&lt;-1

pc &lt;- pc(suffStat = list(C = cor(data), n = 9),
         indepTest = gaussCItest,
         alpha = 0.9,
         labels = colnames(data),
         u2pd = "relaxed",
         skel.method = "stable",
         verbose = TRUE)
kpc1 &lt;- kpc(suffStat = list(data=data, ic.method="dcc.perm"),
            indepTest = kernelCItest,
            alpha = 0.1,
            labels = colnames(data),
            u2pd = "relaxed",
            skel.method = "stable",
            verbose = TRUE)
kpc2 &lt;- kpc(suffStat = list(data=data, ic.method="hsic.gamma"),
            indepTest = kernelCItest,
            alpha = 0.1,
            labels = colnames(data),
            u2pd = "relaxed",
            skel.method = "stable",
            verbose = TRUE)
kpc3 &lt;- kpc(suffStat = list(data=data, ic.method="hsic.perm"),
            indepTest = kernelCItest,
            alpha = 0.1,
            labels = colnames(data),
            u2pd = "relaxed",
            skel.method = "stable",
            verbose = TRUE)
kpc4 &lt;- kpc(suffStat = list(data=data, ic.method="hsic.clust"),
            indepTest = kernelCItest,
            alpha = 0.1,
            labels = colnames(data),
            u2pd = "relaxed",
            skel.method = "stable",
            verbose = TRUE)

if (require(Rgraphviz)) {
 par(mfrow=c(2,3))
 plot(pc,main="pc")
 plot(kpc1,main="dpc.perm")
 plot(kpc2,main="kpc.gamma")
 plot(kpc3,main="kpc.perm")
 plot(kpc4,main="kpc.clust")
 plot(as(true,"graphNEL"),main="True DAG")
}

## End(Not run)
</code></pre>

<hr>
<h2 id='regrVonPS'>Check if variable can be regressed to independence on its parents</h2><span id='topic+regrVonPS'></span>

<h3>Description</h3>

<p>Uses the generalised additive model <a href="mgcv.html#topic+gam">gam</a> to non-linearly and non-parametrically regress variable V on its parents and set of variables S.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regrVonPS(G, V, S, suffStat, indepTest = kernelCItest, alpha = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regrVonPS_+3A_g">G</code></td>
<td>
<p>adjacency matrix, for the graph</p>
</td></tr>
<tr><td><code id="regrVonPS_+3A_v">V</code></td>
<td>
<p>integer, node which we regress</p>
</td></tr>
<tr><td><code id="regrVonPS_+3A_s">S</code></td>
<td>
<p>integer(s), set we regress on</p>
</td></tr>
<tr><td><code id="regrVonPS_+3A_suffstat">suffStat</code></td>
<td>
<p>sufficient statistics to perform the independence test <a href="#topic+kernelCItest">kernelCItest</a></p>
</td></tr>
<tr><td><code id="regrVonPS_+3A_indeptest">indepTest</code></td>
<td>
<p>independence test to check for dependence between residuals of V and S</p>
</td></tr>
<tr><td><code id="regrVonPS_+3A_alpha">alpha</code></td>
<td>
<p>numeric cutoff for significance level of individual partial correlation tests</p>
</td></tr>
</table>


<h3>Value</h3>

<p>regrVonPS() returns the number of p-values smaller than the cutoff, i.e 0 means residuals of V are independent of all variables in S
</p>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>)
</p>

<hr>
<h2 id='regrXonS'>Regress set of variables on its parents</h2><span id='topic+regrXonS'></span>

<h3>Description</h3>

<p>Uses the generalised additive model <a href="mgcv.html#topic+gam">gam</a> to non-linearly and non-parametrically regress set of variables X on a set of variables S and returns residuals of X.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regrXonS(X, S)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regrXonS_+3A_x">X</code></td>
<td>
<p>numeric matrix, set of variables to be regressed. Each column represents separate variable</p>
</td></tr>
<tr><td><code id="regrXonS_+3A_s">S</code></td>
<td>
<p>numeric matrix, set of variables we will regress on. Each column represents separate variable</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the number of variables in S is <code class="reqn">\leq 5</code> we use <a href="#topic+frml.full.smooth">frml.full.smooth</a> as formula for <a href="mgcv.html#topic+gam">gam</a> to regress X on S, otherwise we use <a href="#topic+frml.additive.smooth">frml.additive.smooth</a>.
</p>


<h3>Value</h3>

<p>regrXonS() returns the residuals of X regressed on S.
</p>


<h3>Author(s)</h3>

<p>Petras Verbyla (<a href="mailto:petras.verbyla@mrc-bsu.cam.ac.uk">petras.verbyla@mrc-bsu.cam.ac.uk</a>)
</p>


<h3>See Also</h3>

<p><a href="#topic+kernelCItest">kernelCItest</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(10)
library(energy)
z &lt;- 10*runif(300)
w &lt;- 10*runif(300)
x &lt;- sin(z) + runif(300)
y &lt;- cos(z) + runif(300)
data &lt;- cbind(x,y,z,w)

hsic.gamma(x,y)
hsic.perm(x,y)
dcov.test(x,y)

resid &lt;- regrXonS(cbind(x,y),cbind(z,w))

hsic.gamma(resid[,1],resid[,2])
hsic.perm(resid[,1],resid[,2])
dcov.test(resid[,1],resid[,2])
</code></pre>

<hr>
<h2 id='udag2wanpdag'>Last kPC Algorithm Step: Extend Object with Skeleton to Completed PDAG</h2><span id='topic+udag2wanpdag'></span>

<h3>Description</h3>

<p>This function performs the last (generalised transitive) step in the <a href="#topic+kpc">kpc</a> algorithm. It transforms an object of the class &quot;pcAlgo&quot; containing a skeleton and corresponding conditional independence information into a weakly additive noise directed acyclic graph (CPDAG). The functions first determine the v-structures in the collider step, and then performs the Generalised Transitive Step as described in Tillman et al (2009) to orient as many of the remaining edges as possible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>udag2wanpdag(gInput, suffStat, indepTest = kernelCItest, alpha = 0.2,
  verbose = FALSE, unfVect = NULL, solve.confl = FALSE,
  orientCollider = TRUE, rules = rep(TRUE, 3))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="udag2wanpdag_+3A_ginput">gInput</code></td>
<td>
<p>&quot;pcAlgo&quot;-object containing skeleton and conditional indepedence information.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_suffstat">suffStat</code></td>
<td>
<p>a list of sufficient statistics, containing all necessary elements for the conditional independence decisions in the function indepTest.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_indeptest">indepTest</code></td>
<td>
<p>A function for testing conditional independence. It is internally called as indepTest(x,y,S,suffStat). Default is <a href="#topic+kernelCItest">kernelCItest</a>.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_alpha">alpha</code></td>
<td>
<p>significance level (number in (0,1) for the individual conditional independence tests.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_verbose">verbose</code></td>
<td>
<p>0: No output; 1: Details</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_unfvect">unfVect</code></td>
<td>
<p>vector containing numbers that encode ambiguous triples (as returned by pc.cons.intern). This is needed in the conservative and majority rule PC algorithms.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_solve.confl">solve.confl</code></td>
<td>
<p>if TRUE, the orientation of the v-structures and the orientation rules work with lists for candidate sets and allow bi-directed edges to resolve conflicting edge orientations. Note that therefore the resulting object is order-independent but might not be a PDAG because bi-directed edges can be present.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_orientcollider">orientCollider</code></td>
<td>
<p>if TRUE, collider are oriented.</p>
</td></tr>
<tr><td><code id="udag2wanpdag_+3A_rules">rules</code></td>
<td>
<p>Array of length 3 containing TRUE or FALSE for each rule. TRUE in position i means that rule i (Ri) will be applied. By default, all rules are used.gInput</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First we perform a collider step, that is orienting triples a-b-c as a-&gt;b&lt;-c iff b is not in separating set of a and c. Then we orient edges a-S as a-&gt;S if b_r is independent of a set S, where b_r are the residuals of b non parametrically regressed on S and parents of b and none of the edges S_i-a can be oriented as S_i-&gt;a, that is residuals S_i_r would be independent of a.
</p>


<h3>Value</h3>

<p>An oriented object of class &quot;pcAlgo&quot;.
</p>


<h3>References</h3>

<p>Tillman, R. E., Gretton, A. and Spirtes, P. (2009). Nonlinear directed acyclic structure learning with weakly additive noise model. NIPS 22, Vancouver.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(pcalg)
set.seed(4)
n &lt;- 300
data &lt;- NULL
x1 &lt;- 2*(runif(n)-0.5)
x2 &lt;- x1 + runif(n)-0.5
x3 &lt;- x1^2 + 0.6*runif(n)
x4 &lt;- rnorm(n)
x5 &lt;- x3 + x4^2 + 2*runif(n)
x6 &lt;- 10*(runif(n)-0.5)
x7 &lt;- x6^2 + 10*runif(n)
x8 &lt;- 2*x7^2 + rnorm(n)
x9 &lt;- x7 + 5*runif(n)
data &lt;- cbind(x1,x2,x3,x4,x5,x6,x7,x8,x9)
true &lt;- matrix(0,9,9)
true[c(1),c(2,3)]&lt;-true[c(3,4),5]&lt;-true[c(6),c(7)]&lt;-true[c(7),c(8)]&lt;-true[7,9]&lt;-1
## estimate skeleton
resU1 &lt;- skeleton(suffStat = list(data=data, ic.method="dcc.perm", p=200),
                  indepTest = kernelCItest,
                  verbose = TRUE, alpha = 0.1, p=9)

resU2 &lt;- skeleton(suffStat = list(data=data, ic.method="hsic.gamma",
                             sig=1, numCol = 50),
                  indepTest = kernelCItest,
                  verbose = TRUE, alpha = 0.1, p=9)

resU3 &lt;- skeleton(suffStat = list(data=data, ic.method="hsic.perm",
                             sig=1, numCol = 50, p=200),
                  indepTest = kernelCItest,
                  verbose = TRUE, alpha = 0.1, p=9)

resU4 &lt;- skeleton(suffStat = list(data=data, ic.method="hsic.clust",
                             p=200, sig=1, numCluster=100, numCol = 50,
                             eps = 0.1, paral = 1),
                  indepTest = kernelCItest,
                  verbose = TRUE, alpha = 0.1, p=9)

resU5 &lt;- skeleton(suffStat = list(C = cor(data), n = n),
                  indepTest = gaussCItest,
                  verbose = TRUE, alpha = 0.1, p=9)

if (require(Rgraphviz)) {
 par(mfrow=c(2,3))
 plot(resU1,main="dpc")
 plot(resU2,main="kpc-resid-gamma")
 plot(resU3,main="kpc-resid-perm")
 plot(resU4,main="kpc-clust")
 plot(resU5,main="pc")
 plot(as(true,"graphNEL"),main="True DAG")
}

## orient edges using three different methods
resD1 &lt;- udag2wanpdag(gInput = resU1,
                      suffStat = list(data=data, ic.method="dcc.perm", sig=1, numCol = 50, p=200),
                      indepTest = kernelCItest,
                      verbose = TRUE, alpha = 0.1)
resD2 &lt;- udag2wanpdag(gInput = resU1,
                      suffStat = list(data=data, ic.method="hsic.gamma", sig=1, numCol = 50),
                      indepTest = kernelCItest,
                      verbose = TRUE, alpha = 0.1)
resD3 &lt;- udag2wanpdag(gInput = resU1,
                      suffStat = list(data=data, ic.method="hsic.perm", sig=1, numCol = 50, p=200),
                      indepTest = kernelCItest,
                      verbose = TRUE, alpha = 0.1)
resD4 &lt;- udag2pdagRelaxed(gInput = resU1, verbose = T)
if (require(Rgraphviz)) {
 par(mfrow=c(2,3))
 plot(resD1,main="dpc")
 plot(resD2,main="kpc-resid-gamma")
 plot(resD3,main="kpc-resid-perm")
 plot(resD4,main="pc")
 plot(as(true,"graphNEL"),main="True DAG")
}

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
