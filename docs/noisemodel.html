<!DOCTYPE html><html><head><title>Help for package noisemodel</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {noisemodel}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#asy_def_ln'><p>Asymmetric default label noise</p></a></li>
<li><a href='#asy_int_an'><p>Asymmetric interval-based attribute noise</p></a></li>
<li><a href='#asy_spa_ln'><p>Asymmetric sparse label noise</p></a></li>
<li><a href='#asy_uni_an'><p>Asymmetric uniform attribute noise</p></a></li>
<li><a href='#asy_uni_ln'><p>Asymmetric uniform label noise</p></a></li>
<li><a href='#attm_uni_ln'><p>Attribute-mean uniform label noise</p></a></li>
<li><a href='#bord_dist'><p>Distance to SVM decision boundary</p></a></li>
<li><a href='#bord_noise'><p>Mislabeling based on k-nearest neighbors</p></a></li>
<li><a href='#boud_gau_an'><p>Boundary/dependent Gaussian attribute noise</p></a></li>
<li><a href='#clu_vot_ln'><p>Clustering-based voting label noise</p></a></li>
<li><a href='#diris2D'><p>diris2D dataset</p></a></li>
<li><a href='#exp_bor_ln'><p>Exponential borderline label noise</p></a></li>
<li><a href='#exps_cuni_ln'><p>Exponential/smudge completely-uniform label noise</p></a></li>
<li><a href='#findnoise'><p>Find the differences between two datasets</p></a></li>
<li><a href='#fra_bdir_ln'><p>Fraud bidirectional label noise</p></a></li>
<li><a href='#gam_bor_ln'><p>Gamma borderline label noise</p></a></li>
<li><a href='#gau_bor_ln'><p>Gaussian borderline label noise</p></a></li>
<li><a href='#gaum_bor_ln'><p>Gaussian-mixture borderline label noise</p></a></li>
<li><a href='#glev_uni_ln'><p>Gaussian-level uniform label noise</p></a></li>
<li><a href='#hubp_uni_ln'><p>Hubness-proportional uniform label noise</p></a></li>
<li><a href='#imp_int_an'><p>Importance interval-based attribute noise</p></a></li>
<li><a href='#iris2D'><p>iris2D dataset</p></a></li>
<li><a href='#irs_bdir_ln'><p>IR-stable bidirectional label noise</p></a></li>
<li><a href='#lap_bor_ln'><p>Laplace borderline label noise</p></a></li>
<li><a href='#larm_uni_ln'><p>Large-margin uniform label noise</p></a></li>
<li><a href='#maj_udir_ln'><p>Majority-class unidirectional label noise</p></a></li>
<li><a href='#mind_bdir_ln'><p>Minority-driven bidirectional label noise</p></a></li>
<li><a href='#minp_uni_ln'><p>Minority-proportional uniform label noise</p></a></li>
<li><a href='#mis_pre_ln'><p>Misclassification prediction label noise</p></a></li>
<li><a href='#mulc_udir_ln'><p>Multiple-class unidirectional label noise</p></a></li>
<li><a href='#nei_bor_ln'><p>Neighborwise borderline label noise</p></a></li>
<li><a href='#nlin_bor_ln'><p>Non-linearwise borderline label noise</p></a></li>
<li><a href='#noisetype'><p>Type of noise introduced by a noise model</p></a></li>
<li><a href='#oned_uni_ln'><p>One-dimensional uniform label noise</p></a></li>
<li><a href='#opes_idnn_ln'><p>Open-set ID/nearest-neighbor label noise</p></a></li>
<li><a href='#opes_idu_ln'><p>Open-set ID/uniform label noise</p></a></li>
<li><a href='#pai_bdir_ln'><p>Pairwise bidirectional label noise</p></a></li>
<li><a href='#plot.ndmodel'><p>Plot function for class ndmodel</p></a></li>
<li><a href='#pmd_con_ln'><p>PMD-based confidence label noise</p></a></li>
<li><a href='#print.ndmodel'><p>Print function for class ndmodel</p></a></li>
<li><a href='#print.sum.ndmodel'><p>Print function for class sum.ndmodel</p></a></li>
<li><a href='#qua_uni_ln'><p>Quadrant-based uniform label noise</p></a></li>
<li><a href='#runif_replace'><p>Random numbers considering reference values</p></a></li>
<li><a href='#safe_sample'><p>Safe sample function</p></a></li>
<li><a href='#sample_replace'><p>Sample considering reference values</p></a></li>
<li><a href='#sco_con_ln'><p>Score-based confidence label noise</p></a></li>
<li><a href='#sigb_uni_ln'><p>Sigmoid-bounded uniform label noise</p></a></li>
<li><a href='#smam_bor_ln'><p>Small-margin borderline label noise</p></a></li>
<li><a href='#smu_cuni_ln'><p>Smudge-based completely-uniform label noise</p></a></li>
<li><a href='#summary.ndmodel'><p>Summary function for class ndmodel</p></a></li>
<li><a href='#sym_adj_ln'><p>Symmetric adjacent label noise</p></a></li>
<li><a href='#sym_cen_ln'><p>Symmetric center-based label noise</p></a></li>
<li><a href='#sym_con_ln'><p>Symmetric confusion label noise</p></a></li>
<li><a href='#sym_cuni_an'><p>Symmetric completely-uniform attribute noise</p></a></li>
<li><a href='#sym_cuni_cn'><p>Symmetric completely-uniform combined noise</p></a></li>
<li><a href='#sym_cuni_ln'><p>Symmetric completely-uniform label noise</p></a></li>
<li><a href='#sym_ddef_ln'><p>Symmetric double-default label noise</p></a></li>
<li><a href='#sym_def_ln'><p>Symmetric default label noise</p></a></li>
<li><a href='#sym_dia_ln'><p>Symmetric diametrical label noise</p></a></li>
<li><a href='#sym_dran_ln'><p>Symmetric double-random label noise</p></a></li>
<li><a href='#sym_end_an'><p>Symmetric end-directed attribute noise</p></a></li>
<li><a href='#sym_exc_ln'><p>Symmetric exchange label noise</p></a></li>
<li><a href='#sym_gau_an'><p>Symmetric Gaussian attribute noise</p></a></li>
<li><a href='#sym_hie_ln'><p>Symmetric hierarchical label noise</p></a></li>
<li><a href='#sym_hienc_ln'><p>Symmetric hierarchical/next-class label noise</p></a></li>
<li><a href='#sym_int_an'><p>Symmetric interval-based attribute noise</p></a></li>
<li><a href='#sym_natd_ln'><p>Symmetric natural-distribution label noise</p></a></li>
<li><a href='#sym_nean_ln'><p>Symmetric nearest-neighbor label noise</p></a></li>
<li><a href='#sym_nexc_ln'><p>Symmetric next-class label noise</p></a></li>
<li><a href='#sym_nuni_ln'><p>Symmetric non-uniform label noise</p></a></li>
<li><a href='#sym_opt_ln'><p>Symmetric optimistic label noise</p></a></li>
<li><a href='#sym_pes_ln'><p>Symmetric pessimistic label noise</p></a></li>
<li><a href='#sym_sgau_an'><p>Symmetric scaled-Gaussian attribute noise</p></a></li>
<li><a href='#sym_uni_an'><p>Symmetric uniform attribute noise</p></a></li>
<li><a href='#sym_uni_ln'><p>Symmetric uniform label noise</p></a></li>
<li><a href='#sym_usim_ln'><p>Symmetric unit-simplex label noise</p></a></li>
<li><a href='#symd_gau_an'><p>Symmetric/dependent Gaussian attribute noise</p></a></li>
<li><a href='#symd_gimg_an'><p>Symmetric/dependent Gaussian-image attribute noise</p></a></li>
<li><a href='#symd_rpix_an'><p>Symmetric/dependent random-pixel attribute noise</p></a></li>
<li><a href='#symd_uni_an'><p>Symmetric/dependent uniform attribute noise</p></a></li>
<li><a href='#ugau_bor_ln'><p>Uneven-Gaussian borderline label noise</p></a></li>
<li><a href='#ulap_bor_ln'><p>Uneven-Laplace borderline noise</p></a></li>
<li><a href='#unc_fixw_an'><p>Unconditional fixed-width attribute noise</p></a></li>
<li><a href='#unc_vgau_an'><p>Unconditional vp-Gaussian attribute noise</p></a></li>
<li><a href='#uncs_guni_cn'><p>Unconditional/symmetric Gaussian/uniform combined noise</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Title:</td>
<td>Noise Models for Classification Datasets</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of models for the controlled introduction of errors in 
	classification datasets. This package contains the noise models described in 
	Saez (2022) &lt;<a href="https://doi.org/10.3390%2Fmath10203736">doi:10.3390/math10203736</a>&gt; that allow corrupting class labels, 
	attributes and both simultaneously.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, nnet, e1071, FNN, classInt, ggplot2, ExtDist, lsr,
stringr, RColorBrewer, RSNNS, C50</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Author:</td>
<td>José A. Sáez [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>José A. Sáez &lt;joseasaezm@ugr.es&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-17 06:20:02 UTC</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-14 13:05:44 UTC; joseasaezm</td>
</tr>
</table>
<hr>
<h2 id='asy_def_ln'>Asymmetric default label noise</h2><span id='topic+asy_def_ln'></span><span id='topic+asy_def_ln.default'></span><span id='topic+asy_def_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Asymmetric default label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
asy_def_ln(x, y, level, def = 1, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
asy_def_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asy_def_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each class.</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_def">def</code></td>
<td>
<p>an integer with the index of the default class (default: 1).</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="asy_def_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Asymmetric default label noise</em> randomly selects (<code>level</code>[i]·100)% of the samples
of each class <em>C</em>[i] in the dataset -the order of the class labels is determined by
<code>order</code>. Then, the labels of these samples are
replaced by a fixed label (<em>C</em>[<code>def</code>]) within the set of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>R. C. Prati, J. Luengo, and F. Herrera. 
<strong>Emerging topics and challenges of learning from noisy data in nonstandard classification: 
a survey beyond binary class noise</strong>. <em>Knowledge and Information Systems</em>, 60(1):63–97, 2019.
<a href="https://doi.org/10.1007/s10115-018-1244-4">doi:10.1007/s10115-018-1244-4</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_nean_ln">sym_nean_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- asy_def_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- asy_def_ln(formula = Species ~ ., data = iris2D, 
                     level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='asy_int_an'>Asymmetric interval-based attribute noise</h2><span id='topic+asy_int_an'></span><span id='topic+asy_int_an.default'></span><span id='topic+asy_int_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Asymmetric interval-based attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
asy_int_an(x, y, level, nbins = 10, sortid = TRUE, ...)

## S3 method for class 'formula'
asy_int_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asy_int_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each attribute.</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_nbins">nbins</code></td>
<td>
<p>an integer with the number of bins to create (default: 10).</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="asy_int_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Asymmetric interval-based attribute noise</em> corrupts (<code>level</code>[i]·100)% of the values for
each attribute <em>A</em>[i] in the dataset. In order to corrupt an attribute <em>A</em>[i], (<code>level</code>[i]·100)% of the
samples in the dataset are chosen. To corrupt a value in numeric
attributes, the attribute is split into equal-frequency intervals, one of its closest
intervals is picked out and a random valuen within the interval
is chosen as noisy. For nominal attributes, a random value within the domain is selected.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>M. V. Mannino, Y. Yang, and Y. Ryu. 
<strong>Classification algorithm sensitivity to training data with non representative attribute noise</strong>. 
<em>Decision Support Systems</em>, 46(3):743-751, 2009.
<a href="https://doi.org/10.1016/j.dss.2008.11.021">doi:10.1016/j.dss.2008.11.021</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+asy_uni_an">asy_uni_an</a></code>, <code><a href="#topic+symd_gimg_an">symd_gimg_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- asy_int_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                         level = c(0.1, 0.2))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- asy_int_an(formula = Species ~ ., data = iris2D,
                         level = c(0.1, 0.2))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='asy_spa_ln'>Asymmetric sparse label noise</h2><span id='topic+asy_spa_ln'></span><span id='topic+asy_spa_ln.default'></span><span id='topic+asy_spa_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Asymmetric sparse label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
asy_spa_ln(x, y, levelO, levelE, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
asy_spa_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asy_spa_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_levelo">levelO</code></td>
<td>
<p>a double with the noise level in [0,1] to be introduced into each odd class.</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_levele">levelE</code></td>
<td>
<p>a double with the noise level in [0,1] to be introduced into each even class.</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="asy_spa_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Asymmetric sparse label noise</em> randomly selects (<code>levelO</code>·100)% of the samples
in each odd class and (<code>levelE</code>·100)% of the samples
in each even class -the order of the class labels is determined by
<code>order</code>. Then, each odd class is flipped to the next class, whereas each even class
is flipped to the previous class. If the dataset has an odd number of classes, the last class is not corrupted.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. Wei and Y. Liu. 
<strong>When optimizing f-divergence is robust with label noise</strong>. 
In <em>Proc. 9th International Conference on Learning Representations</em>, pages 1-11, 2021.
url:<a href="https://openreview.net/forum?id=WesiCoRVQ15">https://openreview.net/forum?id=WesiCoRVQ15</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mind_bdir_ln">mind_bdir_ln</a></code>, <code><a href="#topic+fra_bdir_ln">fra_bdir_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- asy_spa_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                       levelO = 0.1, levelE = 0.3, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- asy_spa_ln(formula = Species ~ ., data = iris2D, 
                        levelO = 0.1, levelE = 0.3, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='asy_uni_an'>Asymmetric uniform attribute noise</h2><span id='topic+asy_uni_an'></span><span id='topic+asy_uni_an.default'></span><span id='topic+asy_uni_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Asymmetric uniform attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
asy_uni_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
asy_uni_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asy_uni_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="asy_uni_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="asy_uni_an_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each attribute.</p>
</td></tr>
<tr><td><code id="asy_uni_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="asy_uni_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="asy_uni_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="asy_uni_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Asymmetric uniform attribute noise</em> corrupts (<code>level</code>[i]·100)% of the values for
each attribute <em>A</em>[i] in the dataset. In order to corrupt an attribute <em>A</em>[i], (<code>level</code>[i]·100)% of the
samples in the dataset are chosen. Then, their values for <em>A</em>[i] are replaced by random different ones between
the minimum and maximum of the domain of the attribute following a uniform distribution (for numerical
attributes) or choosing a random value (for nominal attributes).
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>A. Petety, S. Tripathi, and N. Hemachandra. 
<strong>Attribute noise robust binary classification</strong>. 
In <em>Proc. 34th AAAI Conference on Artificial Intelligence</em>, pages 13897-13898, 2020.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+symd_gimg_an">symd_gimg_an</a></code>, <code><a href="#topic+unc_vgau_an">unc_vgau_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- asy_uni_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                         level = c(0.1, 0.2))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- asy_uni_an(formula = Species ~ ., data = iris2D,
                         level = c(0.1, 0.2))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='asy_uni_ln'>Asymmetric uniform label noise</h2><span id='topic+asy_uni_ln'></span><span id='topic+asy_uni_ln.default'></span><span id='topic+asy_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Asymmetric uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
asy_uni_ln(x, y, level, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
asy_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="asy_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each class.</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="asy_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Asymmetric uniform label noise</em> randomly selects (<code>level</code>[i]·100)% of the samples
of each class <em>C</em>[i] in the dataset -the order of the class labels is determined by
<code>order</code>. Finally, the labels of these samples are randomly
replaced by other different ones within the set of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>Z. Zhao, L. Chu, D. Tao, and J. Pei. 
<strong>Classification with label noise: a Markov chain sampling framework</strong>. 
<em>Data Mining and Knowledge Discovery</em>, 33(5):1468-1504, 2019.
<a href="https://doi.org/10.1007/s10618-018-0592-8">doi:10.1007/s10618-018-0592-8</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+maj_udir_ln">maj_udir_ln</a></code>, <code><a href="#topic+asy_def_ln">asy_def_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- asy_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                    level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- asy_uni_ln(formula = Species ~ ., data = iris2D, 
                     level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='attm_uni_ln'>Attribute-mean uniform label noise</h2><span id='topic+attm_uni_ln'></span><span id='topic+attm_uni_ln.default'></span><span id='topic+attm_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Attribute-mean uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
attm_uni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
attm_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="attm_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="attm_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="attm_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="attm_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="attm_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="attm_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="attm_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each sample, its distance to the mean of each attribute is computed. Then, 
(<code>level</code>·100)% of the samples in the dataset are randomly selected to be
mislabeled, more likely choosing samples whose features are generally close to the mean.
The labels of these samples are randomly replaced by other different ones within the set 
of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References
</p>


<h3>References</h3>

<p>B. Nicholson, V. S. Sheng, and J. Zhang. 
<strong>Label noise correction and application in crowdsourcing</strong>. 
<em>Expert Systems with Applications</em>, 66:149-162, 2016.
<a href="https://doi.org/10.1016/j.eswa.2016.09.003">doi:10.1016/j.eswa.2016.09.003</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+qua_uni_ln">qua_uni_ln</a></code>, <code><a href="#topic+exps_cuni_ln">exps_cuni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- attm_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- attm_uni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='bord_dist'>Distance to SVM decision boundary</h2><span id='topic+bord_dist'></span>

<h3>Description</h3>

<p>Calculation of the distance of each sample to the SVM decision boundary in a classification problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bord_dist(x, y, krn = "linear")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bord_dist_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="bord_dist_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="bord_dist_+3A_krn">krn</code></td>
<td>
<p>a character with the kernel of SVM -see <code>e1071::svm</code> (default: &quot;<code>linear</code>&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>nrow(x)</code> with the distance of each sample to the decision boundary.
</p>

<hr>
<h2 id='bord_noise'>Mislabeling based on k-nearest neighbors</h2><span id='topic+bord_noise'></span>

<h3>Description</h3>

<p>Computation of a noisy label based on majority class among <em>k</em> nearest neighbors with different label.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bord_noise(x, y, num_noise, idx_noise, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bord_noise_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="bord_noise_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="bord_noise_+3A_num_noise">num_noise</code></td>
<td>
<p>an integer with the number of noisy samples.</p>
</td></tr>
<tr><td><code id="bord_noise_+3A_idx_noise">idx_noise</code></td>
<td>
<p>an integer vector with the indices of noisy samples.</p>
</td></tr>
<tr><td><code id="bord_noise_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of length <code>length(y)</code> with the class of each sample, including the new noisy 
classes for the samples with indices <code>idx_noise</code>.
</p>

<hr>
<h2 id='boud_gau_an'>Boundary/dependent Gaussian attribute noise</h2><span id='topic+boud_gau_an'></span><span id='topic+boud_gau_an.default'></span><span id='topic+boud_gau_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Boundary/dependent Gaussian attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
boud_gau_an(x, y, level, k = 0.2, sortid = TRUE, ...)

## S3 method for class 'formula'
boud_gau_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boud_gau_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_k">k</code></td>
<td>
<p>a double in [0,1] with the scale used for the standard deviation (default: 0.2).</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="boud_gau_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Boundary/dependent Gaussian attribute noise</em> corrupts (<code>level</code>·100)% samples among the 
((<code>level</code>+0.1)·100)% of samples closest to the decision boundary. Their attribute values are corrupted by adding a random number 
that follows a Gaussian distribution of <em>mean</em> = 0 and <em>standard deviation</em> = (max-min)·<code>k</code>, being
<em>max</em> and <em>min</em> the limits of the attribute domain. For nominal attributes, a random value is chosen.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. Bi and T. Zhang. 
<strong>Support vector classification with input data uncertainty</strong>. 
In <em>Advances in Neural Information Processing Systems</em>, volume 17, pages 161-168, 2004.
url:<a href="https://proceedings.neurips.cc/paper/2004/hash/22b1f2e0983160db6f7bb9f62f4dbb39-Abstract.html">https://proceedings.neurips.cc/paper/2004/hash/22b1f2e0983160db6f7bb9f62f4dbb39-Abstract.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imp_int_an">imp_int_an</a></code>, <code><a href="#topic+asy_int_an">asy_int_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- boud_gau_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- boud_gau_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='clu_vot_ln'>Clustering-based voting label noise</h2><span id='topic+clu_vot_ln'></span><span id='topic+clu_vot_ln.default'></span><span id='topic+clu_vot_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Clustering-based voting label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
clu_vot_ln(x, y, k = nlevels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
clu_vot_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clu_vot_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="clu_vot_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="clu_vot_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of clusters (default: <code>nlevels(y)</code>).</p>
</td></tr>
<tr><td><code id="clu_vot_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="clu_vot_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="clu_vot_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="clu_vot_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Clustering-based voting label noise</em> divides the dataset into <code>k</code> clusters.
Then, the labels of each cluster are relabeled with the majority class among its samples.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, which considers <em>k</em>-means as 
unsupervised clustering method.
</p>


<h3>References</h3>

<p>Q. Wang, B. Han, T. Liu, G. Niu, J. Yang, and C. Gong. 
<strong>Tackling instance-dependent label noise via a universal probabilistic model</strong>. 
In <em>Proc. 35th AAAI Conference on Artificial Intelligence</em>, pages 10183-10191, 2021.
url:<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17221">https://ojs.aaai.org/index.php/AAAI/article/view/17221</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sco_con_ln">sco_con_ln</a></code>, <code><a href="#topic+mis_pre_ln">mis_pre_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- clu_vot_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)])

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- clu_vot_ln(formula = Species ~ ., data = iris2D)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='diris2D'>diris2D dataset</h2><span id='topic+diris2D'></span>

<h3>Description</h3>

<p>Discretized version of the <code>iris2D</code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diris2D)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 103 samples (rows) and 3 variables (columns) named Petal.Length, Petal.Width and Species.
</p>


<h3>Source</h3>

<p>Data collected by E. Anderson (1935).
</p>


<h3>References</h3>

<p>R. A. Fisher. <strong>The use of multiple measurements in taxonomic problems</strong>. 
<em>Annals of Eugenics</em>, 7:179-188, 1936.
</p>
<p>E. Anderson. <strong>The irises of the Gaspe Peninsula</strong>. 
<em>Bulletin of the American Iris Society</em>, 59:2-5, 1935.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+iris2D">iris2D</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load the dataset
data(diris2D)

# noise introduction
set.seed(9)
outdef &lt;- sym_uni_ln(x = diris2D[,-ncol(diris2D)], y = diris2D[,ncol(diris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)

</code></pre>

<hr>
<h2 id='exp_bor_ln'>Exponential borderline label noise</h2><span id='topic+exp_bor_ln'></span><span id='topic+exp_bor_ln.default'></span><span id='topic+exp_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Exponential borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
exp_bor_ln(x, y, level, rate = 1, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
exp_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_rate">rate</code></td>
<td>
<p>a double with the rate for the exponential distribution (default: 1).</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="exp_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Exponential borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then, an exponential distribution with parameter <code>rate</code> is used to compute the
value for the probability density function associated to each distance. 
Finally, (<code>level</code>·100)% of the samples in the dataset are randomly selected to be mislabeled
according to their values of the probability density function. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Bootkrajang. 
<strong>A generalised label noise model for classification in the presence of annotation errors</strong>. 
<em>Neurocomputing</em>, 192:61–71, 2016. 
<a href="https://doi.org/10.1016/j.neucom.2015.12.106">doi:10.1016/j.neucom.2015.12.106</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pmd_con_ln">pmd_con_ln</a></code>, <code><a href="#topic+clu_vot_ln">clu_vot_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- exp_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- exp_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='exps_cuni_ln'>Exponential/smudge completely-uniform label noise</h2><span id='topic+exps_cuni_ln'></span><span id='topic+exps_cuni_ln.default'></span><span id='topic+exps_cuni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Exponential/smudge completely-uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
exps_cuni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
exps_cuni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exps_cuni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="exps_cuni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="exps_cuni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the lambda value.</p>
</td></tr>
<tr><td><code id="exps_cuni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="exps_cuni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="exps_cuni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="exps_cuni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Exponential/smudge completely-uniform label noise</em> includes an additional attribute (<em>smudge</em>) in the dataset with 
random values in [0,1]. This attribute is used to compute the mislabeling probability for each sample
based on an exponential function (in which <code>level</code> is used as lambda). It selects samples
in the dataset based on these probabilities. Finally, the labels of these samples are 
randomly replaced by others within the set of class labels (this model can choose the original 
label of a sample as noisy).
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>B. Denham, R. Pears, and M. A. Naeem. 
<strong>Null-labelling: A generic approach for learning in the presence of class noise</strong>. 
In <em>Proc. 20th IEEE International Conference on Data Mining</em>, pages 990–995, 2020.
<a href="https://doi.org/10.1109/ICDM50108.2020.00114">doi:10.1109/ICDM50108.2020.00114</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+opes_idu_ln">opes_idu_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- exps_cuni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.8)

# show results
summary(outdef, showid = TRUE)
plot(outdef, pca = TRUE)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- exps_cuni_ln(formula = Species ~ ., data = iris2D, level = 0.8)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='findnoise'>Find the differences between two datasets</h2><span id='topic+findnoise'></span>

<h3>Description</h3>

<p>Detect the differences between two datasets, focusing on the input attributes (<code>x</code>, 
<code>xnoise</code>), the output class (<code>y</code>, <code>ynoise</code>) or both depending on the type of 
the model (label, attributes, combined).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findnoise(x, y, xnoise, ynoise, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="findnoise_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes (clean dataset).</p>
</td></tr>
<tr><td><code id="findnoise_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample (clean dataset).</p>
</td></tr>
<tr><td><code id="findnoise_+3A_xnoise">xnoise</code></td>
<td>
<p>a data frame of input attributes (noisy dataset).</p>
</td></tr>
<tr><td><code id="findnoise_+3A_ynoise">ynoise</code></td>
<td>
<p>a factor vector with the output class of each sample (noisy dataset).</p>
</td></tr>
<tr><td><code id="findnoise_+3A_model">model</code></td>
<td>
<p>a character with the name of the noise model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with four elements:
</p>
<table>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per variable.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per variable.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per variable.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per variable.</p>
</td></tr>
</table>

<hr>
<h2 id='fra_bdir_ln'>Fraud bidirectional label noise</h2><span id='topic+fra_bdir_ln'></span><span id='topic+fra_bdir_ln.default'></span><span id='topic+fra_bdir_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Fraud bidirectional label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
fra_bdir_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
fra_bdir_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fra_bdir_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="fra_bdir_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="fra_bdir_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="fra_bdir_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="fra_bdir_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="fra_bdir_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="fra_bdir_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Fraud bidirectional label noise</em> randomly selects (<code>level</code>·100)% of the samples
from the minority class in the dataset and <code>level</code>·10 samples from the majority class.
Then, minority class samples are mislabeled as belonging to the majority class and majority class 
samples are mislabeled as belonging to the minority class. In case of ties determining minority and majority classes, 
a random class is chosen among them.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>Z. Salekshahrezaee, J. L. Leevy, and T. M. Khoshgoftaar. 
<strong>A reconstruction error-based framework for label noise detection</strong>. 
<em>Journal of Big Data</em>, 8(1):1-16, 2021.
<a href="https://doi.org/10.1186/s40537-021-00447-5">doi:10.1186/s40537-021-00447-5</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irs_bdir_ln">irs_bdir_ln</a></code>, <code><a href="#topic+pai_bdir_ln">pai_bdir_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- fra_bdir_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- fra_bdir_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='gam_bor_ln'>Gamma borderline label noise</h2><span id='topic+gam_bor_ln'></span><span id='topic+gam_bor_ln.default'></span><span id='topic+gam_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Gamma borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
gam_bor_ln(x, y, level, shape = 1, rate = 0.5, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
gam_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gam_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_shape">shape</code></td>
<td>
<p>a double with the shape for the gamma distribution (default: 1)</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_rate">rate</code></td>
<td>
<p>a double with the rate for the gamma distribution (default: 0.5).</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="gam_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Gamma borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. 
Then, a gamma distribution with parameters (<code>shape</code>, <code>rate</code>) is used to compute the
value for the probability density function associated to each distance. 
Finally, (<code>level</code>·100)% of the samples in the dataset are randomly selected to be mislabeled
according to their values of the probability density function. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Bootkrajang. <strong>A generalised label noise model for classification</strong>. 
In <em>Proc. 23rd European Symposium on Artificial Neural Networks</em>, pages 
349-354, 2015. 
url:<a href="https://dblp.org/rec/conf/esann/Bootkrajang15.html?view=bibtex">https://dblp.org/rec/conf/esann/Bootkrajang15.html?view=bibtex</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exp_bor_ln">exp_bor_ln</a></code>, <code><a href="#topic+pmd_con_ln">pmd_con_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- gam_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- gam_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='gau_bor_ln'>Gaussian borderline label noise</h2><span id='topic+gau_bor_ln'></span><span id='topic+gau_bor_ln.default'></span><span id='topic+gau_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Gaussian borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
gau_bor_ln(x, y, level, mean = 0, sd = 1, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
gau_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gau_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_mean">mean</code></td>
<td>
<p>a double with the mean for the Gaussian distribution (default: 0).</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_sd">sd</code></td>
<td>
<p>a double with the standard deviation for the Gaussian distribution (default: 1).</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="gau_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Gaussian borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then, a Gaussian distribution with parameters (<code>mean</code>, <code>sd</code>) is 
used to compute the value for the probability density function associated to each distance. 
Finally, (<code>level</code>·100)% of the samples in the dataset are randomly selected to be mislabeled
according to their values of the probability density function. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Bootkrajang and J. Chaijaruwanich. 
<strong>Towards instance-dependent label noise-tolerant classification: a probabilistic approach</strong>. 
<em>Pattern Analysis and Applications</em>, 23(1):95-111, 2020.
<a href="https://doi.org/10.1007/s10044-018-0750-z">doi:10.1007/s10044-018-0750-z</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sigb_uni_ln">sigb_uni_ln</a></code>, <code><a href="#topic+larm_uni_ln">larm_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- gau_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- gau_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='gaum_bor_ln'>Gaussian-mixture borderline label noise</h2><span id='topic+gaum_bor_ln'></span><span id='topic+gaum_bor_ln.default'></span><span id='topic+gaum_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Gaussian-mixture borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
gaum_bor_ln(
  x,
  y,
  level,
  mean = c(0, 2),
  sd = c(sqrt(0.5), sqrt(0.5)),
  w = c(0.5, 0.5),
  k = 1,
  sortid = TRUE,
  ...
)

## S3 method for class 'formula'
gaum_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gaum_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_mean">mean</code></td>
<td>
<p>a double vector with the mean for each Gaussian distribution (default: <code>c</code>(0,2)).</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_sd">sd</code></td>
<td>
<p>a double vector with the standard deviation for each Gaussian distribution (default: <code>c</code>(<code>sqrt</code>(0.5),<code>sqrt</code>(0.5))).</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_w">w</code></td>
<td>
<p>a double vector with the weight for each Gaussian distribution (default: <code>c</code>(0.5,0.5)).</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="gaum_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Gaussian-mixture borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance to the decision border is computed. 
Then, a Gaussian mixture distribution with parameters (<code>mean</code>, <code>sd</code>) and weights <code>w</code> 
is used to compute the value for the probability density function
associated to each distance. Finally,
(<code>level</code>·100)% of the samples in the dataset are randomly selected to be mislabeled
according to their values of the probability density function. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Bootkrajang and J. Chaijaruwanich. 
<strong>Towards instance-dependent label noise-tolerant classification: a probabilistic approach</strong>. 
<em>Pattern Analysis and Applications</em>, 23(1):95-111, 2020.
<a href="https://doi.org/10.1007/s10044-018-0750-z">doi:10.1007/s10044-018-0750-z</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gau_bor_ln">gau_bor_ln</a></code>, <code><a href="#topic+sigb_uni_ln">sigb_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- gaum_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- gaum_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='glev_uni_ln'>Gaussian-level uniform label noise</h2><span id='topic+glev_uni_ln'></span><span id='topic+glev_uni_ln.default'></span><span id='topic+glev_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Gaussian-level uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
glev_uni_ln(x, y, level, sd = 0.01, sortid = TRUE, ...)

## S3 method for class 'formula'
glev_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glev_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_sd">sd</code></td>
<td>
<p>a double with the standard deviation for the Gaussian distribution (default: 0.01).</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="glev_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each sample, <em>Gaussian-level uniform label noise</em> assigns a random probability 
following a Gaussian distribution of mean = <code>level</code> and standard deviation <code>sd</code>. 
Noisy samples are chosen according to these probabilities.
The labels of these samples are randomly
replaced by other different ones within the set of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>D. Liu, G. Yang, J. Wu, J. Zhao, and F. Lv. 
<strong>Robust binary loss for multi-category classification with label noise</strong>. 
In <em>Proc. 2021 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, 
pages 1700-1704, 2021.
<a href="https://doi.org/10.1109/ICASSP39728.2021.9414493">doi:10.1109/ICASSP39728.2021.9414493</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_hienc_ln">sym_hienc_ln</a></code>, <code><a href="#topic+sym_nexc_ln">sym_nexc_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- glev_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- glev_uni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='hubp_uni_ln'>Hubness-proportional uniform label noise</h2><span id='topic+hubp_uni_ln'></span><span id='topic+hubp_uni_ln.default'></span><span id='topic+hubp_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Hubness-proportional uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
hubp_uni_ln(x, y, level, k = 3, sortid = TRUE, ...)

## S3 method for class 'formula'
hubp_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hubp_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of neighbors to compute the hubness of each sample (default: 3).</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="hubp_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Hubness-proportional uniform label noise</em> is based on the presence of hubs
in the dataset. It selects (<code>level</code>·100)% of the samples in the dataset using a 
discrete probability distribution based on the concept of hubness, which is computed 
using the nearest neighbors of each sample. Then, the class labels
of these samples are randomly replaced by different ones from the <em>c</em> classes.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>N. Tomasev and K. Buza. 
<strong>Hubness-aware kNN classification of high-dimensional data in presence of label noise</strong>. 
<em>Neurocomputing</em>, 160:157-172, 2015. 
<a href="https://doi.org/10.1016/j.neucom.2014.10.084">doi:10.1016/j.neucom.2014.10.084</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smu_cuni_ln">smu_cuni_ln</a></code>, <code><a href="#topic+oned_uni_ln">oned_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- hubp_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- hubp_uni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='imp_int_an'>Importance interval-based attribute noise</h2><span id='topic+imp_int_an'></span><span id='topic+imp_int_an.default'></span><span id='topic+imp_int_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Importance interval-based attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
imp_int_an(x, y, level, nbins = 10, ascending = TRUE, sortid = TRUE, ...)

## S3 method for class 'formula'
imp_int_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imp_int_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each attribute.</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_nbins">nbins</code></td>
<td>
<p>an integer with the number of bins to create (default: 10).</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_ascending">ascending</code></td>
<td>
<p>a boolean indicating how noise levels are assigned to attributes:
</p>

<ul>
<li><p><code>TRUE</code>: the lowest noise level is assigned to the most important attribute (default value).
</p>
</li>
<li><p><code>FALSE</code>: the highest noise level is assigned to the most important attribute.
</p>
</li></ul>
</td></tr>
<tr><td><code id="imp_int_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="imp_int_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values in <code>level</code> are ordered and assigned to attributes according to their information gain (using the 
ordering given by <code>ascending</code>). Then,
<em>Importance interval-based attribute noise</em> corrupts (<code>level</code>[i]·100)% of the values for
each attribute <em>A</em>[i] in the dataset. In order to corrupt each attribute <em>A</em>[i], (<code>level</code>[i]·100)% of the
samples in the dataset are chosen. To corrupt a value in numeric
attributes, the attribute is split into equal-frequency intervals, one of its closest
intervals is picked out and a random value within the interval
is chosen as noisy. For nominal attributes, a random value within the domain is chosen.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>M. V. Mannino, Y. Yang, and Y. Ryu. 
<strong>Classification algorithm sensitivity to training data with non representative attribute noise</strong>. 
<em>Decision Support Systems</em>, 46(3):743-751, 2009.
<a href="https://doi.org/10.1016/j.dss.2008.11.021">doi:10.1016/j.dss.2008.11.021</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+asy_int_an">asy_int_an</a></code>, <code><a href="#topic+asy_uni_an">asy_uni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- imp_int_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                        level = c(0.1, 0.2))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- imp_int_an(formula = Species ~ ., data = iris2D, 
                        level = c(0.1, 0.2))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='iris2D'>iris2D dataset</h2><span id='topic+iris2D'></span>

<h3>Description</h3>

<p>A 2-dimensional version of the well-known <code><a href="datasets.html#topic+iris">iris</a></code> dataset. It maintains the 
attributes <code>Petal.Length</code> and <code>Petal.Width</code>, which give the measurements in centimeters of 
the petal length and width of iris flowers belonging to three different species (<em>setosa</em>, <em>versicolor</em> and 
<em>virginica</em>). Duplicate and contradictory samples are removed from the dataset, resulting in a total 
of 103 samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(iris2D)
</code></pre>


<h3>Format</h3>

<p>A data.frame with 103 samples (rows) and 3 variables (columns) named Petal.Length, Petal.Width and Species.
</p>


<h3>Source</h3>

<p>Data collected by E. Anderson (1935).
</p>


<h3>References</h3>

<p>R. A. Fisher. <strong>The use of multiple measurements in taxonomic problems</strong>. 
<em>Annals of Eugenics</em>, 7:179-188, 1936.
</p>
<p>E. Anderson. <strong>The irises of the Gaspe Peninsula</strong>. 
<em>Bulletin of the American Iris Society</em>, 59:2-5, 1935.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_uni_ln">sym_uni_ln</a></code>, <code><a href="#topic+sym_uni_an">sym_uni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
library(RColorBrewer)

data(iris2D)

ggplot(data = iris2D, aes(x = iris2D[,1], y = iris2D[,2], color = iris2D[,3])) +
   geom_point(stroke = 0.5) +
   xlim(min(iris2D[,1]), max(iris2D[,1])) +
   ylim(min(iris2D[,2]), max(iris2D[,2])) +
   xlab(names(iris2D)[1]) + 
   ylab(names(iris2D)[2]) +
   labs(color='Species') +
   scale_color_manual(values = brewer.pal(3, "Dark2")) +
   theme(panel.border = element_rect(colour = "black", fill=NA),
         aspect.ratio = 1,
         axis.text = element_text(colour = 1, size = 12),
         legend.background = element_blank(),
         legend.box.background = element_rect(colour = "black"))

</code></pre>

<hr>
<h2 id='irs_bdir_ln'>IR-stable bidirectional label noise</h2><span id='topic+irs_bdir_ln'></span><span id='topic+irs_bdir_ln.default'></span><span id='topic+irs_bdir_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>IR-stable bidirectional label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
irs_bdir_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
irs_bdir_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="irs_bdir_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="irs_bdir_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="irs_bdir_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="irs_bdir_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="irs_bdir_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="irs_bdir_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="irs_bdir_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>IR-stable bidirectional label noise</em> randomly selects (<code>level</code>·100)% of the samples
from the minority class in the dataset and the same amount of samples from the majority class.
Then, minority class samples are mislabeled as belonging to the majority class and majority class 
samples are mislabeled as belonging to the minority class. In case of ties determining minority and majority classes, 
a random class is chosen among them.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>B. Chen, S. Xia, Z. Chen, B. Wang, and G. Wang. <strong>RSMOTE: A self-adaptive robust 
SMOTE for imbalanced problems with label noise.</strong> 
<em>Information Sciences</em>, 553:397-428, 2021.
<a href="https://doi.org/10.1016/j.ins.2020.10.013">doi:10.1016/j.ins.2020.10.013</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pai_bdir_ln">pai_bdir_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- irs_bdir_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- irs_bdir_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='lap_bor_ln'>Laplace borderline label noise</h2><span id='topic+lap_bor_ln'></span><span id='topic+lap_bor_ln.default'></span><span id='topic+lap_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Laplace borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
lap_bor_ln(x, y, level, mu = 0, b = 1, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
lap_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lap_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_mu">mu</code></td>
<td>
<p>a double with the location for the Laplace distribution (default: 0).</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_b">b</code></td>
<td>
<p>a double with the scale for the Laplace distribution (default: 1).</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="lap_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Laplace borderline label noise</em> uses uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then,
a Laplace distribution with parameters (<code>mu</code>, <code>b</code>) is used to compute the
value for the probability density function associated to each distance. Finally, 
(<code>level</code>·100)% of the samples in the dataset are randomly selected to be mislabeled
according to their values of the probability density function. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Du and Z. Cai. 
<strong>Modelling class noise with symmetric and asymmetric distributions</strong>. 
In <em>Proc. 29th AAAI Conference on Artificial Intelligence</em>, pages 2589-2595, 2015.
url:<a href="https://dl.acm.org/doi/10.5555/2886521.2886681">https://dl.acm.org/doi/10.5555/2886521.2886681</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ugau_bor_ln">ugau_bor_ln</a></code>, <code><a href="#topic+gaum_bor_ln">gaum_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- lap_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- lap_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='larm_uni_ln'>Large-margin uniform label noise</h2><span id='topic+larm_uni_ln'></span><span id='topic+larm_uni_ln.default'></span><span id='topic+larm_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Large-margin uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
larm_uni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
larm_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="larm_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="larm_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="larm_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="larm_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="larm_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="larm_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="larm_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Large-margin uniform label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then, the samples are ordered according to their distance and 
(<code>level</code>·100)% of the most distant correctly classified samples to the decision boundary 
are selected to be mislabeled with a random different class.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering SVM with linear 
kernel as classifier.
</p>


<h3>References</h3>

<p>E. Amid, M. K. Warmuth, and S. Srinivasan. 
<strong>Two-temperature logistic regression based on the Tsallis divergence</strong>.
In <em>Proc. 22nd International Conference on Artificial Intelligence and Statistics</em>, 
volume 89 of PMLR, pages 2388-2396, 2019. 
url:<a href="http://proceedings.mlr.press/v89/amid19a.html">http://proceedings.mlr.press/v89/amid19a.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+hubp_uni_ln">hubp_uni_ln</a></code>, <code><a href="#topic+smu_cuni_ln">smu_cuni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- larm_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.3)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- larm_uni_ln(formula = Species ~ ., data = iris2D, level = 0.3)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='maj_udir_ln'>Majority-class unidirectional label noise</h2><span id='topic+maj_udir_ln'></span><span id='topic+maj_udir_ln.default'></span><span id='topic+maj_udir_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Majority-class unidirectional label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
maj_udir_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
maj_udir_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maj_udir_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="maj_udir_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="maj_udir_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="maj_udir_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="maj_udir_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="maj_udir_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="maj_udir_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <em>A</em> be the majority class and <em>B</em> be the second majority class in the dataset.
The <em>Majority-class unidirectional label noise</em> introduction model randomly selects (<code>level</code>·100)% of the samples
of <em>A</em> and labels them as <em>B</em>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data.
</p>


<h3>References</h3>

<p>J. Li, Q. Zhu, Q. Wu, Z. Zhang, Y. Gong, Z. He, and F. Zhu. 
<strong>SMOTE- NaN-DE: Addressing the noisy and borderline examples problem in imbalanced 
classification by natural neighbors and differential evolution</strong>. 
<em>Knowledge-Based Systems</em>, 223:107056, 2021.
<a href="https://doi.org/10.1016/j.knosys.2021.107056">doi:10.1016/j.knosys.2021.107056</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+asy_def_ln">asy_def_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- maj_udir_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- maj_udir_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='mind_bdir_ln'>Minority-driven bidirectional label noise</h2><span id='topic+mind_bdir_ln'></span><span id='topic+mind_bdir_ln.default'></span><span id='topic+mind_bdir_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Minority-driven bidirectional label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
mind_bdir_ln(x, y, level, pos = 0.1, sortid = TRUE, ...)

## S3 method for class 'formula'
mind_bdir_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mind_bdir_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_pos">pos</code></td>
<td>
<p>a double in [0,1] with the proportion of samples from the positive class (default: 0.1).</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="mind_bdir_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Minority-driven bidirectional label noise</em> randomly selects <em>n</em> = 2<em>m</em>·<code>level</code> samples
in the dataset (with <em>m</em> the number of samples in the minority class), making sure that <em>n</em>·<code>pos</code> samples 
belong to the minority class and the rest to the majority class. 
Then, minority class samples are mislabeled as belonging to the majority class and majority class 
samples are mislabeled as belonging to the minority class. In case of ties determining minority and majority classes, 
a random class is chosen among them.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data.
</p>


<h3>References</h3>

<p>A. Folleco, T. M. Khoshgoftaar, J. V. Hulse, and L. A. Bullard. 
<strong>Software quality modeling: The impact of class noise on the random forest classifier</strong>. 
In <em>Proc. 2008 IEEE Congress on Evolutionary Computation</em>, pages 3853–3859, 2008.
<a href="https://doi.org/10.1109/CEC.2008.4631321">doi:10.1109/CEC.2008.4631321</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fra_bdir_ln">fra_bdir_ln</a></code>, <code><a href="#topic+irs_bdir_ln">irs_bdir_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- mind_bdir_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.5)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- mind_bdir_ln(formula = Species ~ ., data = iris2D, level = 0.5)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='minp_uni_ln'>Minority-proportional uniform label noise</h2><span id='topic+minp_uni_ln'></span><span id='topic+minp_uni_ln.default'></span><span id='topic+minp_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Minority-proportional uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
minp_uni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
minp_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="minp_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="minp_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="minp_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="minp_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="minp_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="minp_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="minp_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a dataset, assume the original class distribution of class <em>i</em> is 
<em>p</em>i and the distribution of the minority class is <em>p</em>m. 
Let <code>level</code> be the noise level, <em>Minority-proportional uniform label noise</em> introduces 
noise proportionally to different classes, where a sample with its label <em>i</em> has a probability 
(<em>p</em>m/<em>p</em>i)·<code>level</code> to be corrupted as another random class. That is, 
the least common class is used as the baseline for noise introduction.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>X. Zhu and X. Wu. 
<strong>Cost-guided class noise handling for effective cost-sensitive learning</strong>. 
In <em>Proc. 4th IEEE International Conference on Data Mining</em>, pages 297–304, 2004.
<a href="https://doi.org/10.1109/ICDM.2004.10108">doi:10.1109/ICDM.2004.10108</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+asy_uni_ln">asy_uni_ln</a></code>, <code><a href="#topic+maj_udir_ln">maj_udir_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- minp_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- minp_uni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='mis_pre_ln'>Misclassification prediction label noise</h2><span id='topic+mis_pre_ln'></span><span id='topic+mis_pre_ln.default'></span><span id='topic+mis_pre_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Misclassification prediction label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
mis_pre_ln(x, y, sortid = TRUE, ...)

## S3 method for class 'formula'
mis_pre_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mis_pre_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="mis_pre_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="mis_pre_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="mis_pre_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="mis_pre_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="mis_pre_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Misclassification prediction label noise</em> creates a Multi-Layer Perceptron (MLP) model from the dataset and relabels each
sample with the class predicted by the classifier.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>Q. Wang, B. Han, T. Liu, G. Niu, J. Yang, and C. Gong. 
<strong>Tackling instance-dependent label noise via a universal probabilistic model</strong>. 
In <em>Proc. 35th AAAI Conference on Artificial Intelligence</em>, pages 10183-10191, 2021.
url:<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17221">https://ojs.aaai.org/index.php/AAAI/article/view/17221</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smam_bor_ln">smam_bor_ln</a></code>, <code><a href="#topic+nlin_bor_ln">nlin_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- mis_pre_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)])

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- mis_pre_ln(formula = Species ~ ., data = iris2D)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='mulc_udir_ln'>Multiple-class unidirectional label noise</h2><span id='topic+mulc_udir_ln'></span><span id='topic+mulc_udir_ln.default'></span><span id='topic+mulc_udir_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Multiple-class unidirectional label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
mulc_udir_ln(x, y, level, goal, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
mulc_udir_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mulc_udir_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_goal">goal</code></td>
<td>
<p>an integer vector with the indices of noisy classes for each class.</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="mulc_udir_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Multiple-class unidirectional label noise</em> introduction model randomly selects (<code>level</code>·100)% of the samples
of each class <em>c</em> with <code>goal</code>[c] != <code>NA</code>. Then, the labels <em>c</em> of these samples are replaced by the class indicated in 
<code>goal</code>[c]. The order of indices in <code>goal</code> is determined by
<code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>Q. Wang, B. Han, T. Liu, G. Niu, J. Yang, and C. Gong. 
<strong>Tackling instance-dependent label noise via a universal probabilistic model</strong>. 
In <em>Proc. 35th AAAI Conference on Artificial Intelligence</em>, pages 10183-10191, 2021.
url:<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17221">https://ojs.aaai.org/index.php/AAAI/article/view/17221</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+minp_uni_ln">minp_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- mulc_udir_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1, 
                        goal = c(NA, 1, 2), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- mulc_udir_ln(formula = Species ~ ., data = iris2D, level = 0.1, 
                        goal = c(NA, 1, 2), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='nei_bor_ln'>Neighborwise borderline label noise</h2><span id='topic+nei_bor_ln'></span><span id='topic+nei_bor_ln.default'></span><span id='topic+nei_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Neighborwise borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
nei_bor_ln(x, y, level, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
nei_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nei_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="nei_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each sample in the dataset, <em>Neighborwise borderline label noise</em> computes the
ratio of two distances: the distance to its nearest neighbor from the same
class and the distance to its nearest neighbor from another class. Then,
these values are ordered in descending order and the first (<code>level</code>·100)% of them are used to determine the noisy samples. 
For each noisy sample, the majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, considering a mislabeling process 
using the neighborhood of noisy samples.
</p>


<h3>References</h3>

<p>L. P. F. Garcia, J. Lehmann, A. C. P. L. F. de Carvalho, and A. C. Lorena. 
<strong>New label noise injection methods for the evaluation of noise filters.</strong> 
<em>Knowledge-Based Systems</em>, 163:693–704, 2019.
<a href="https://doi.org/10.1016/j.knosys.2018.09.031">doi:10.1016/j.knosys.2018.09.031</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ulap_bor_ln">ulap_bor_ln</a></code>, <code><a href="#topic+lap_bor_ln">lap_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- nei_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- nei_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='nlin_bor_ln'>Non-linearwise borderline label noise</h2><span id='topic+nlin_bor_ln'></span><span id='topic+nlin_bor_ln.default'></span><span id='topic+nlin_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Non-linearwise borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
nlin_bor_ln(x, y, level, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
nlin_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlin_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="nlin_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Non-linearwise borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. Then, for each sample, its distance
to the decision border is computed. Finally, the
distances obtained are ordered in ascending order and the first (<code>level</code>·100)% of them are used to determine the noisy samples. 
For each noisy sample, the majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, considering a mislabeling process 
using the neighborhood of noisy samples.
</p>


<h3>References</h3>

<p>L. P. F. Garcia, J. Lehmann, A. C. P. L. F. de Carvalho, and A. C. Lorena. 
<strong>New label noise injection methods for the evaluation of noise filters.</strong> 
<em>Knowledge-Based Systems</em>, 163:693–704, 2019.
<a href="https://doi.org/10.1016/j.knosys.2018.09.031">doi:10.1016/j.knosys.2018.09.031</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nei_bor_ln">nei_bor_ln</a></code>, <code><a href="#topic+ulap_bor_ln">ulap_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- nlin_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- nlin_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='noisetype'>Type of noise introduced by a noise model</h2><span id='topic+noisetype'></span>

<h3>Description</h3>

<p>Given the function name of a model, it returns the type of noise it 
introduces: label, attributes, or both.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>noisetype(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="noisetype_+3A_model">model</code></td>
<td>
<p>a character with the function name of the noise model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character with the type of noise <code>model</code> introduces. It can be <code>cla</code> for 
label noise, <code>att</code> for attribute noise or <code>com</code> for combined noise.
</p>

<hr>
<h2 id='oned_uni_ln'>One-dimensional uniform label noise</h2><span id='topic+oned_uni_ln'></span><span id='topic+oned_uni_ln.default'></span><span id='topic+oned_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>One-dimensional uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
oned_uni_ln(
  x,
  y,
  level,
  att,
  lower,
  upper,
  order = levels(y),
  sortid = TRUE,
  ...
)

## S3 method for class 'formula'
oned_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="oned_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_att">att</code></td>
<td>
<p>an integer with the index of the attribute determining noisy samples.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_lower">lower</code></td>
<td>
<p>a vector with the lower bound to determine the noisy region of each class.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_upper">upper</code></td>
<td>
<p>a vector with the upper bound to determine the noisy region of each class.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="oned_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>One-dimensional uniform label noise</em> is based on the introduction of noise 
according to the values of the attribute <code>att</code>. Samples of class <em>i</em> with  
the attribute <code>att</code> falling between <code>lower</code>[i] and <code>upper</code>[i] 
have a probability <code>level</code> of being mislabeled. The labels of these samples are randomly
replaced by other different ones within the set of class labels. The order of the class labels is 
determined by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering a 
noise level to control the number of errors in the data
</p>


<h3>References</h3>

<p>N. Gornitz, A. Porbadnigk, A. Binder, C. Sannelli, M. L. Braun, K. Muller, and M. Kloft. 
<strong>Learning and evaluation in presence of non-i.i.d. label noise</strong>. 
In <em>Proc. 17th International Conference on Artificial Intelligence and Statistics</em>, 
volume 33 of PMLR, pages 293–302, 2014. url:<a href="https://proceedings.mlr.press/v33/gornitz14.html">https://proceedings.mlr.press/v33/gornitz14.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+attm_uni_ln">attm_uni_ln</a></code>, <code><a href="#topic+qua_uni_ln">qua_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- oned_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                    level = 0.5, att = 1, lower = c(1.5,2,6), upper = c(2,4,7))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- oned_uni_ln(formula = Species ~ ., data = iris2D, 
                    level = 0.5, att = 1, lower = c(1.5,2,6), upper = c(2,4,7))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='opes_idnn_ln'>Open-set ID/nearest-neighbor label noise</h2><span id='topic+opes_idnn_ln'></span><span id='topic+opes_idnn_ln.default'></span><span id='topic+opes_idnn_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Open-set ID/nearest-neighbor label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
opes_idnn_ln(
  x,
  y,
  level,
  openset = c(1),
  order = levels(y),
  sortid = TRUE,
  ...
)

## S3 method for class 'formula'
opes_idnn_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="opes_idnn_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_level">level</code></td>
<td>
<p>a double with the noise level in [0,1] to be introduced.</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_openset">openset</code></td>
<td>
<p>an integer vector with the indices of classes in the open set (default: <code>c(1)</code>).</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="opes_idnn_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Open-set ID/nearest-neighbor label noise</em> corrupts (<code>level</code>·100)% of the samples with classes in <code>openset</code>. 
Then, the labels of these samples are replaced by 
the label of the nearest sample of a different in-distribution class. The order of the class 
labels for the indices in <code>openset</code> is determined by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>P. H. Seo, G. Kim, and B. Han. <strong>Combinatorial inference against label noise</strong>. 
In <em>Advances in Neural Information Processing Systems</em>, volume 32, pages 1171-1181, 2019.
url:<a href="https://proceedings.neurips.cc/paper/2019/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html">https://proceedings.neurips.cc/paper/2019/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+opes_idu_ln">opes_idu_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- opes_idnn_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                      level = 0.4, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- opes_idnn_ln(formula = Species ~ ., data = iris2D, 
                      level = 0.4, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='opes_idu_ln'>Open-set ID/uniform label noise</h2><span id='topic+opes_idu_ln'></span><span id='topic+opes_idu_ln.default'></span><span id='topic+opes_idu_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Open-set ID/uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
opes_idu_ln(x, y, level, openset = c(1), order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
opes_idu_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="opes_idu_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_level">level</code></td>
<td>
<p>a double with the noise level in [0,1] to be introduced.</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_openset">openset</code></td>
<td>
<p>an integer vector with the indices of classes in the open set (default: <code>c(1)</code>).</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="opes_idu_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Open-set ID/uniform label noise</em> corrupts (<code>level</code>·100)% of the samples with classes in <code>openset</code>. 
For each sample selected, a label from in-distribution classes is randomly chosen. The order of the class 
labels for the indices in <code>openset</code> is determined by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>P. H. Seo, G. Kim, and B. Han. <strong>Combinatorial inference against label noise</strong>. 
In <em>Advances in Neural Information Processing Systems</em>, volume 32, pages 1171-1181, 2019.
url:<a href="https://proceedings.neurips.cc/paper/2019/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html">https://proceedings.neurips.cc/paper/2019/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+asy_spa_ln">asy_spa_ln</a></code>, <code><a href="#topic+mind_bdir_ln">mind_bdir_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- opes_idu_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = 0.4, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- opes_idu_ln(formula = Species ~ ., data = iris2D, 
                     level = 0.4, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='pai_bdir_ln'>Pairwise bidirectional label noise</h2><span id='topic+pai_bdir_ln'></span><span id='topic+pai_bdir_ln.default'></span><span id='topic+pai_bdir_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Pairwise bidirectional label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
pai_bdir_ln(x, y, level, pairs, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
pai_bdir_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pai_bdir_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_pairs">pairs</code></td>
<td>
<p>a list of integer vectors with the indices of classes to corrupt.</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="pai_bdir_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each vector (<em>c1</em>, <em>c2</em>) in <code>pairs</code>, 
<em>Pairwise bidirectional label noise</em> randomly selects (<code>level</code>·100)% of the samples
from class <em>c1</em> in the dataset and (<code>level</code>·100)% of the samples from class
<em>c2</em>. Then, <em>c1</em> samples are mislabeled as belonging to <em>c2</em> and 
<em>c2</em> samples are mislabeled as belonging to <em>c1</em>. The order of the class labels is 
determined by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>S. Fefilatyev, M. Shreve, K. Kramer, L. O. Hall, D. B. Goldgof, R. Kasturi, K. Daly, A. Remsen, and H. Bunke. 
<strong>Label-noise reduction with support vector machines</strong>. 
In <em>Proc. 21st International Conference on Pattern Recognition</em>, pages 3504-3508, 2012.
url:<a href="https://ieeexplore.ieee.org/document/6460920/">https://ieeexplore.ieee.org/document/6460920/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# create new class with some samples
class &lt;- as.character(iris2D$Species)
class[iris2D$Petal.Length &gt; 6] &lt;- "newclass"
iris2D$Species &lt;- as.factor(class)

# usage of the default method
set.seed(9)
outdef &lt;- pai_bdir_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                      level = 0.1, pairs = list(c(1,2), c(3,4)), 
                      order = c("virginica", "setosa", "newclass", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- pai_bdir_ln(formula = Species ~ ., data = iris2D, 
                      level = 0.1, pairs = list(c(1,2), c(3,4)), 
                      order = c("virginica", "setosa", "newclass", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='plot.ndmodel'>Plot function for class ndmodel</h2><span id='topic+plot.ndmodel'></span>

<h3>Description</h3>

<p>Representation of the dataset contained in an object of class <code>ndmodel</code> after the
application of a noise introduction model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ndmodel'
plot(x, ..., noise = NA, xvar = 1, yvar = 2, pca = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.ndmodel_+3A_x">x</code></td>
<td>
<p>an object of class <code>ndmodel</code>.</p>
</td></tr>
<tr><td><code id="plot.ndmodel_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="plot.ndmodel_+3A_noise">noise</code></td>
<td>
<p>a logical indicating which samples to show. The valid options are:
</p>

<ul>
<li><p><code>TRUE</code>: to show only the noisy samples.
</p>
</li>
<li><p><code>FALSE</code>: to show only the clean samples.
</p>
</li>
<li><p><code>NA</code>: to show both the clean and noisy samples (default value).
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.ndmodel_+3A_xvar">xvar</code></td>
<td>
<p>an integer with the index of the input attribute (if <code>pca = FALSE</code>) or the
principal component (if <code>pca = TRUE</code>) to represent in the <em>x</em> axis (default: 1).</p>
</td></tr>
<tr><td><code id="plot.ndmodel_+3A_yvar">yvar</code></td>
<td>
<p>an integer with the index of the input attribute (if <code>pca = FALSE</code>) or the
principal component (if <code>pca = TRUE</code>) to represent in the <em>y</em> axis (default: 2).</p>
</td></tr>
<tr><td><code id="plot.ndmodel_+3A_pca">pca</code></td>
<td>
<p>a logical indicating if PCA must be used (default: <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function performs a two-dimensional representation using the <code>ggplot2</code> package of
the dataset contained in the object <code>x</code> of class <code>ndmodel</code>.
Each of the classes in the dataset (available in <code>x$ynoise</code>) is represented by a
different color. There are two options to represent the input attributes of the samples
on the <em>x</em> and <em>y</em> axes of the graph:
</p>

<ul>
<li><p>If <code>pca = FALSE</code>, the values in the graph are taken from the current attribute
values found in <code>x$xnoise</code>. In this case, <code>xvar</code> and <code>yvar</code> indicate the
indices of the attributes to show in the <em>x</em> and <em>y</em> axes, respectively.
</p>
</li>
<li><p>If <code>pca = TRUE</code>, the values in the graph are taken after performing a PCA over
<code>x$xnoise</code>. In this case, <code>xvar</code> and <code>yvar</code> indicate the index of the
principal component according to the variance explained to show in the <em>x</em> and <em>y</em>
axes, respectively.
</p>
</li></ul>

<p>Finally, the parameter <code>noise</code> is used to indicate which samples (noisy, clean or all) to show.
Clean samples are represented by circles in the graph, while noisy samples are represented by crosses.
</p>


<h3>Value</h3>

<p>An object of class <code>ggplot</code> and <code>gg</code> with the graph created using the
<code>ggplot2</code> package.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+sym_uni_ln">sym_uni_ln</a></code>, <code><a href="#topic+sym_cuni_ln">sym_cuni_ln</a></code>, <code><a href="#topic+sym_uni_an">sym_uni_an</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris)

# apply the noise introduction model
set.seed(9)
output &lt;- sym_uni_ln(x = iris[,-ncol(iris)], y = iris[,ncol(iris)], level = 0.1)

# plots for all the samples, the clean samples and the noisy samples using PCA
plot(output, pca = TRUE)
plot(output, noise = FALSE, pca = TRUE)
plot(output, noise = TRUE, pca = TRUE)

# plots using the Petal.Length and Petal.Width variables
plot(output, xvar = 3, yvar = 4)
plot(output, noise = FALSE, xvar = 3, yvar = 4)
plot(output, noise = TRUE, xvar = 3, yvar = 4)

</code></pre>

<hr>
<h2 id='pmd_con_ln'>PMD-based confidence label noise</h2><span id='topic+pmd_con_ln'></span><span id='topic+pmd_con_ln.default'></span><span id='topic+pmd_con_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>PMD-based confidence label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
pmd_con_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
pmd_con_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmd_con_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="pmd_con_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="pmd_con_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="pmd_con_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="pmd_con_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="pmd_con_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="pmd_con_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>PMD-based confidence label noise</em> approximates the probability of noise using 
the confidence prediction of a neural network. These predictions are used to estimate the 
mislabeling probability and the most possible noisy class label for each sample. Finally,
(<code>level</code>·100)% of the samples in the dataset are randomly selected to be mislabeled
according to their values of probability computed.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>Y. Zhang, S. Zheng, P. Wu, M. Goswami, and C. Chen. 
<strong>Learning with feature-dependent label noise: A progressive approach</strong>. 
In <em>Proc. 9th International Conference on Learning Representations</em>, pages 1-13, 2021.
url:<a href="https://openreview.net/forum?id=ZPa2SyGcbwh">https://openreview.net/forum?id=ZPa2SyGcbwh</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clu_vot_ln">clu_vot_ln</a></code>, <code><a href="#topic+sco_con_ln">sco_con_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- pmd_con_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- pmd_con_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='print.ndmodel'>Print function for class ndmodel</h2><span id='topic+print.ndmodel'></span>

<h3>Description</h3>

<p>This method displays the basic information about the noise
introduction process contained in an object of class <code>ndmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ndmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ndmodel_+3A_x">x</code></td>
<td>
<p>an object of class <code>ndmodel</code>.</p>
</td></tr>
<tr><td><code id="print.ndmodel_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function presents the basic information of the noise introduction process and the resulting noisy dataset contained in the object <code>x</code> of class <code>ndmodel</code>.
The information offered is as follows:
</p>

<ul>
<li><p> the name of the noise introduction model.
</p>
</li>
<li><p> the parameters associated with the noise model.
</p>
</li>
<li><p> the number of noisy and clean samples in the dataset.
</p>
</li></ul>



<h3>Value</h3>

<p>This function does not return any value.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>, <code><a href="#topic+sym_uni_ln">sym_uni_ln</a></code>, <code><a href="#topic+sym_cuni_ln">sym_cuni_ln</a></code>, <code><a href="#topic+sym_uni_an">sym_uni_an</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
print(outdef)

</code></pre>

<hr>
<h2 id='print.sum.ndmodel'>Print function for class sum.ndmodel</h2><span id='topic+print.sum.ndmodel'></span>

<h3>Description</h3>

<p>Auxiliary function for printing information about the noise
introduction process contained in an object of class <code>sum.ndmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sum.ndmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sum.ndmodel_+3A_x">x</code></td>
<td>
<p>an object of class <code>sum.ndmodel</code>.</p>
</td></tr>
<tr><td><code id="print.sum.ndmodel_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function does not return any value.
</p>

<hr>
<h2 id='qua_uni_ln'>Quadrant-based uniform label noise</h2><span id='topic+qua_uni_ln'></span><span id='topic+qua_uni_ln.default'></span><span id='topic+qua_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Quadrant-based uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
qua_uni_ln(x, y, level, att1 = 1, att2 = 2, sortid = TRUE, ...)

## S3 method for class 'formula'
qua_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qua_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] in each quadrant.</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_att1">att1</code></td>
<td>
<p>an integer with the index of the first attribute forming the quadrants (default: 1).</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_att2">att2</code></td>
<td>
<p>an integer with the index of the second attribute forming the quadrants (default: 2).</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="qua_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each sample, the probability of flipping its label is based on which quadrant 
(with respect to the attributes <code>att1</code> and <code>att2</code>) the sample falls in. 
The probability of mislabeling for each quadrant is expressed with the argument <code>level</code>, 
whose length is equal to 4. 
Let <em>m1</em> and <em>m2</em> be the mean values of the domain of <code>att1</code> and <code>att2</code>, respectively. 
Each quadrant is defined as follows: values &lt;= <em>m1</em> 
and &lt;= <em>m2</em> (first quadrant); values &lt;= <em>m1</em> and &gt; <em>m2</em> (second quadrant); 
values &gt; <em>m1</em> and &lt;= <em>m2</em> (third quadrant); and values &gt; <em>m1</em> 
and &gt; <em>m2</em> (fourth quadrant). Finally, the labels of these samples are randomly 
replaced by other different ones within the set of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>A. Ghosh, N. Manwani, and P. S. Sastry. 
<strong>Making risk minimization tolerant to label noise</strong>. 
<em>Neurocomputing</em>, 160:93-107, 2015.
<a href="https://doi.org/10.1016/j.neucom.2014.09.081">doi:10.1016/j.neucom.2014.09.081</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exps_cuni_ln">exps_cuni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- qua_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                       level = c(0.05, 0.15, 0.20, 0.4))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- qua_uni_ln(formula = Species ~ ., data = iris2D, 
                        level = c(0.05, 0.15, 0.20, 0.4))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='runif_replace'>Random numbers considering reference values</h2><span id='topic+runif_replace'></span>

<h3>Description</h3>

<p>Generate <code>n</code> random numbers following a uniform distribution 
between <code>min</code> and <code>max</code>. The values in <code>ref</code> can be chosen or not, 
according to <code>original</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runif_replace(n, min, max, original, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runif_replace_+3A_n">n</code></td>
<td>
<p>an integer with the amount of random numbers to generate.</p>
</td></tr>
<tr><td><code id="runif_replace_+3A_min">min</code></td>
<td>
<p>a double with the lower limit of the distribution.</p>
</td></tr>
<tr><td><code id="runif_replace_+3A_max">max</code></td>
<td>
<p>a double with the upper limit of the distribution.</p>
</td></tr>
<tr><td><code id="runif_replace_+3A_original">original</code></td>
<td>
<p>a boolean indicating if the values in <code>ref</code> can be chosen.</p>
</td></tr>
<tr><td><code id="runif_replace_+3A_ref">ref</code></td>
<td>
<p>a double vector with <code>n</code> reference values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A double vector with the numbers generated.
</p>

<hr>
<h2 id='safe_sample'>Safe sample function</h2><span id='topic+safe_sample'></span>

<h3>Description</h3>

<p>Similar to standard <code>sample</code> function. Safe sample function considering the special case of an integer vector with only one element.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>safe_sample(x, size, replace = FALSE, prob = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="safe_sample_+3A_x">x</code></td>
<td>
<p>a vector with the alternatives to choose.</p>
</td></tr>
<tr><td><code id="safe_sample_+3A_size">size</code></td>
<td>
<p>an integer with the number of elements to select from <code>x</code>.</p>
</td></tr>
<tr><td><code id="safe_sample_+3A_replace">replace</code></td>
<td>
<p>a boolean indicating if the elements should be chosen with replacement (default: <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="safe_sample_+3A_prob">prob</code></td>
<td>
<p>a double vector with the probability associated to each element (default: <code>NULL</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the elements chosen.
</p>

<hr>
<h2 id='sample_replace'>Sample considering reference values</h2><span id='topic+sample_replace'></span>

<h3>Description</h3>

<p>Similar to standard <code>sample</code> function. The values in <code>ref</code> can be chosen or not, 
according to <code>original</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_replace(x, size, original, ref)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sample_replace_+3A_x">x</code></td>
<td>
<p>a vector with the alternatives to choose.</p>
</td></tr>
<tr><td><code id="sample_replace_+3A_size">size</code></td>
<td>
<p>an integer with the number of elements to select from <code>x</code>.</p>
</td></tr>
<tr><td><code id="sample_replace_+3A_original">original</code></td>
<td>
<p>a boolean indicating if the values in <code>ref</code> can be chosen.</p>
</td></tr>
<tr><td><code id="sample_replace_+3A_ref">ref</code></td>
<td>
<p>a vector with <code>n</code> reference values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the elements chosen from <code>x</code>.
</p>

<hr>
<h2 id='sco_con_ln'>Score-based confidence label noise</h2><span id='topic+sco_con_ln'></span><span id='topic+sco_con_ln.default'></span><span id='topic+sco_con_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Score-based confidence label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sco_con_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sco_con_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sco_con_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sco_con_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sco_con_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sco_con_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sco_con_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sco_con_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sco_con_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Score-based confidence label noise</em> follows the intuition that hard samples are 
more likely to be mislabeled. Given the confidence per class of each sample, 
if it is predicted with a different class with a high probability, it means that 
it is hard to clearly distinguish the sample from this class. The confidence information is used to compute a mislabeling score for each sample and its potential noisy 
label. Finally, (<code>level</code>·100)% of the samples with the highest mislabeling scores 
are chosen as noisy.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>P. Chen, J. Ye, G. Chen, J. Zhao, and P. Heng. 
<strong>Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise</strong>. 
In <em>Proc. 35th AAAI Conference on Artificial Intelligence</em>, pages 11442-11450, 2021.
url:<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17363">https://ojs.aaai.org/index.php/AAAI/article/view/17363</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mis_pre_ln">mis_pre_ln</a></code>, <code><a href="#topic+smam_bor_ln">smam_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sco_con_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sco_con_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sigb_uni_ln'>Sigmoid-bounded uniform label noise</h2><span id='topic+sigb_uni_ln'></span><span id='topic+sigb_uni_ln.default'></span><span id='topic+sigb_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Sigmoid-bounded uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sigb_uni_ln(x, y, level, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sigb_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigb_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each class.</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sigb_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Sigmoid-bounded uniform label noise</em> generates bounded instance-dependent and 
label-dependent label noise at random using a weight for each sample in 
the dataset to compute its noise probability through a sigmoid function. 
Note that this noise model considers the maximum noise level per class given by 
<code>level</code>, so the current noise level in each class may be lower than that specified. 
The order of the class labels is determined by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data.
</p>


<h3>References</h3>

<p>J. Cheng, T. Liu, K. Ramamohanarao, and D. Tao. 
<strong>Learning with bounded instance and label-dependent label noise</strong>. 
In <em>Proc. 37th International Conference on Machine Learning</em>, 
volume 119 of PMLR, pages 1789-1799, 2020.
url:<a href="http://proceedings.mlr.press/v119/cheng20c.html">http://proceedings.mlr.press/v119/cheng20c.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+larm_uni_ln">larm_uni_ln</a></code>, <code><a href="#topic+hubp_uni_ln">hubp_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sigb_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                      level = c(0.1, 0.2, 0.3))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sigb_uni_ln(formula = Species ~ ., data = iris2D, 
                      level = c(0.1, 0.2, 0.3))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='smam_bor_ln'>Small-margin borderline label noise</h2><span id='topic+smam_bor_ln'></span><span id='topic+smam_bor_ln.default'></span><span id='topic+smam_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Small-margin borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
smam_bor_ln(x, y, level, k = 1, sortid = TRUE, ...)

## S3 method for class 'formula'
smam_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smam_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="smam_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Small-margin borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then, the samples are ordered according to their distance and 
(<code>level</code>·100)% of the closest correctly classified samples to the decision boundary 
are selected to be mislabeled. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering SVM with linear 
kernel as classifier and a mislabeling process using the neighborhood of noisy samples.
</p>


<h3>References</h3>

<p>E. Amid, M. K. Warmuth, and S. Srinivasan. 
<strong>Two-temperature logistic regression based on the Tsallis divergence</strong>.
In <em>Proc. 22nd International Conference on Artificial Intelligence and Statistics</em>, 
volume 89 of PMLR, pages 2388-2396, 2019. 
url:<a href="http://proceedings.mlr.press/v89/amid19a.html">http://proceedings.mlr.press/v89/amid19a.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlin_bor_ln">nlin_bor_ln</a></code>, <code><a href="#topic+nei_bor_ln">nei_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- smam_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- smam_bor_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='smu_cuni_ln'>Smudge-based completely-uniform label noise</h2><span id='topic+smu_cuni_ln'></span><span id='topic+smu_cuni_ln.default'></span><span id='topic+smu_cuni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Smudge-based completely-uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
smu_cuni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
smu_cuni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smu_cuni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="smu_cuni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="smu_cuni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="smu_cuni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="smu_cuni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="smu_cuni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="smu_cuni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Smudge-based completely-uniform label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by others within the set of class labels. An additional attribute 
<code>smudge</code> is included in the dataset with value equal to 1 in mislabeled samples and equal to 0 
in clean samples.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>S. Thulasidasan, T. Bhattacharya, J. A. Bilmes, G. Chennupati, and J. Mohd-Yusof. 
<strong>Combating label noise in deep learning using abstention</strong>. 
In <em>Proc. 36th International Conference on Machine Learning</em>, volume 97 of PMLR, pages 6234-6243, 2019. 
url:<a href="http://proceedings.mlr.press/v97/thulasidasan19a.html">http://proceedings.mlr.press/v97/thulasidasan19a.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+oned_uni_ln">oned_uni_ln</a></code>, <code><a href="#topic+attm_uni_ln">attm_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- smu_cuni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef, pca = TRUE)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- smu_cuni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='summary.ndmodel'>Summary function for class ndmodel</h2><span id='topic+summary.ndmodel'></span>

<h3>Description</h3>

<p>This method displays a summary containing information about the noise
introduction process contained in an object of class <code>ndmodel</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ndmodel'
summary(object, ..., showid = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.ndmodel_+3A_object">object</code></td>
<td>
<p>an object of class <code>ndmodel</code>.</p>
</td></tr>
<tr><td><code id="summary.ndmodel_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="summary.ndmodel_+3A_showid">showid</code></td>
<td>
<p>a logical indicating if the indices of noisy samples must be displayed (default: <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function presents a summary containing information of the noise introduction process and the resulting
noisy dataset contained in the object <code>object</code> of class <code>ndmodel</code>.
The information offered is as follows:
</p>

<ul>
<li><p> the function call.
</p>
</li>
<li><p> the name of the noise introduction model.
</p>
</li>
<li><p> the parameters associated with the noise model.
</p>
</li>
<li><p> the number of noisy and clean samples in the dataset.
</p>
</li>
<li><p> the number of noisy samples per class/attribute.
</p>
</li>
<li><p> the number of clean samples per class/attribute.
</p>
</li>
<li><p> the indices of the noisy samples (if <code>showid = TRUE</code>).
</p>
</li></ul>



<h3>Value</h3>

<p>A list with the elements of <code>object</code>, including the <code>showid</code> argument.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>, <code><a href="#topic+sym_uni_ln">sym_uni_ln</a></code>, <code><a href="#topic+sym_cuni_ln">sym_cuni_ln</a></code>, <code><a href="#topic+sym_uni_an">sym_uni_an</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)

</code></pre>

<hr>
<h2 id='sym_adj_ln'>Symmetric adjacent label noise</h2><span id='topic+sym_adj_ln'></span><span id='topic+sym_adj_ln.default'></span><span id='topic+sym_adj_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric adjacent label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_adj_ln(x, y, level, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_adj_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_adj_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_adj_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric adjacent label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are 
replaced by a random adjacent class label according to <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. R. Cano, J. Luengo, and S. Garcia. 
<strong>Label noise filtering techniques to improve monotonic classification</strong>. 
<em>Neurocomputing</em>, 353:83-95, 2019.
<a href="https://doi.org/10.1016/j.neucom.2018.05.131">doi:10.1016/j.neucom.2018.05.131</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_dran_ln">sym_dran_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_adj_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                    level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_adj_ln(formula = Species ~ ., data = iris2D, 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_cen_ln'>Symmetric center-based label noise</h2><span id='topic+sym_cen_ln'></span><span id='topic+sym_cen_ln.default'></span><span id='topic+sym_cen_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric center-based label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_cen_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_cen_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_cen_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_cen_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_cen_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_cen_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_cen_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_cen_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_cen_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric center-based label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. The probability for chosing the noisy label 
is determined based on the distance between class centers.
Thus, the mislabeling probability between classes increases as the distance between their 
centers decreases. This model is consistent with the intuition that samples in similar 
classes are more likely to be mislabeled. Besides, the model also allows mislabeling 
data in dissimilar classes with a relatively small probability, which corresponds to 
label noise caused by random errors.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>X. Pu and C. Li. 
<strong>Probabilistic information-theoretic discriminant analysis for industrial 
label-noise fault diagnosis</strong>. 
<em>IEEE Transactions on Industrial Informatics</em>, 17(4):2664-2674, 2021.
<a href="https://doi.org/10.1109/TII.2020.3001335">doi:10.1109/TII.2020.3001335</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glev_uni_ln">glev_uni_ln</a></code>, <code><a href="#topic+sym_hienc_ln">sym_hienc_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_cen_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_cen_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_con_ln'>Symmetric confusion label noise</h2><span id='topic+sym_con_ln'></span><span id='topic+sym_con_ln.default'></span><span id='topic+sym_con_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric confusion label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_con_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_con_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_con_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_con_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_con_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_con_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_con_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_con_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_con_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric confusion label noise</em> considers that the mislabeling probability for each 
class is <code>level</code>. It obtains the confusion matrix from the dataset, which is 
row-normalized to estimate the transition matrix and get the probability of selecting each class 
when noise occurs.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, considering C5.0 as classifier.
</p>


<h3>References</h3>

<p>D. Ortego, E. Arazo, P. Albert, N. E. O’Connor, and K. McGuinness. 
<strong>Towards robust learning with different label noise distributions</strong>. 
In <em>Proc. 25th International Conference on Pattern Recognition</em>, pages 7020-7027, 2020.
<a href="https://doi.org/10.1109/ICPR48806.2021.9412747">doi:10.1109/ICPR48806.2021.9412747</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_cen_ln">sym_cen_ln</a></code>, <code><a href="#topic+glev_uni_ln">glev_uni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_con_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_con_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_cuni_an'>Symmetric completely-uniform attribute noise</h2><span id='topic+sym_cuni_an'></span><span id='topic+sym_cuni_an.default'></span><span id='topic+sym_cuni_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric completely-uniform attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_cuni_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_cuni_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_cuni_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_cuni_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_cuni_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_cuni_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_cuni_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_cuni_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_cuni_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric completely-uniform attribute noise</em> corrupts (<code>level</code>·100)% of the values of 
each attribute in the dataset. In order to corrupt an attribute <em>A</em>, (<code>level</code>·100)% of the
samples in the dataset are randomly chosen. Then, their values for <em>A</em> are replaced by random ones 
from the domain of the attribute. Note that the original attribute value of a sample can be chosen as noisy and the actual percentage 
of noise in the dataset can be lower than the theoretical noise level.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, only considering attribute 
noise introduction.
</p>


<h3>References</h3>

<p>C. Teng. <strong>Polishing blemishes: Issues in data correction</strong>. 
<em>IEEE Intelligent Systems</em>, 19(2):34-39, 2004. 
<a href="https://doi.org/10.1109/MIS.2004.1274909">doi:10.1109/MIS.2004.1274909</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_uni_an">sym_uni_an</a></code>, <code><a href="#topic+sym_cuni_cn">sym_cuni_cn</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_cuni_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_cuni_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_cuni_cn'>Symmetric completely-uniform combined noise</h2><span id='topic+sym_cuni_cn'></span><span id='topic+sym_cuni_cn.default'></span><span id='topic+sym_cuni_cn.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric completely-uniform combined noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_cuni_cn(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_cuni_cn(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_cuni_cn_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_cuni_cn_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_cuni_cn_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_cuni_cn_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_cuni_cn_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_cuni_cn_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_cuni_cn_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric completely-uniform combined noise</em> corrupts (<code>level</code>·100)% of the values of 
each attribute in the dataset. In order to corrupt an attribute <em>A</em>, (<code>level</code>·100)% of the
samples in the dataset are randomly chosen. Then, their values for <em>A</em> are replaced by random ones 
from the domain of the attribute.
</p>
<p>Additionally, this noise model also selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. The labels of these samples are randomly
replaced by other ones within the set of class labels.
</p>
<p>Note that, for both attributes and 
class labels, the original value of a sample can be chosen as noisy and the actual percentage 
of noise in the dataset can be lower than the theoretical noise level.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per variable.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per variable.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per variable.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per variable.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>C. Teng. <strong>Polishing blemishes: Issues in data correction</strong>. 
<em>IEEE Intelligent Systems</em>, 19(2):34-39, 2004. 
<a href="https://doi.org/10.1109/MIS.2004.1274909">doi:10.1109/MIS.2004.1274909</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+uncs_guni_cn">uncs_guni_cn</a></code>, <code><a href="#topic+sym_cuni_an">sym_cuni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_cuni_cn(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_cuni_cn(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_cuni_ln'>Symmetric completely-uniform label noise</h2><span id='topic+sym_cuni_ln'></span><span id='topic+sym_cuni_ln.default'></span><span id='topic+sym_cuni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric completely-uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_cuni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_cuni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_cuni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_cuni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_cuni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_cuni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_cuni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_cuni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_cuni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric completely-uniform label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by others within the set of class labels. Note that this model can choose the 
original label of a sample as noisy.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>A. Ghosh and A. S. Lan. <strong>Contrastive learning improves model robustness under label noise</strong>. 
In <em>Proc. 2021 IEEE Conference on Computer Vision and Pattern Recognition Workshops</em>, 
pages 2703-2708, 2021.
<a href="https://doi.org/10.1109/CVPRW53098.2021.00304">doi:10.1109/CVPRW53098.2021.00304</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_uni_ln">sym_uni_ln</a></code>, <code><a href="#topic+sym_cuni_an">sym_cuni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_cuni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_cuni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_ddef_ln'>Symmetric double-default label noise</h2><span id='topic+sym_ddef_ln'></span><span id='topic+sym_ddef_ln.default'></span><span id='topic+sym_ddef_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric double-default label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_ddef_ln(
  x,
  y,
  level,
  def1 = 1,
  def2 = 2,
  order = levels(y),
  sortid = TRUE,
  ...
)

## S3 method for class 'formula'
sym_ddef_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_ddef_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_def1">def1</code></td>
<td>
<p>an integer with the index of the first default class (default: 1).</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_def2">def2</code></td>
<td>
<p>an integer with the index of the second default class (default: 2).</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_ddef_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric double-default label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are
replaced by one of two fixed labels (<code>def1</code> or <code>def2</code>) within the set of class labels. The indices 
<code>def1</code> and <code>def2</code> are taken according to the order given by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>B. Han, J. Yao, G. Niu, M. Zhou, I. W. Tsang, Y. Zhang, and M. Sugiyama. 
<strong>Masking: A new perspective of noisy supervision</strong>. 
In <em>Advances in Neural Information Processing Systems</em>, volume 31, pages 5841-5851, 2018.
url:<a href="https://proceedings.neurips.cc/paper/2018/hash/aee92f16efd522b9326c25cc3237ac15-Abstract.html">https://proceedings.neurips.cc/paper/2018/hash/aee92f16efd522b9326c25cc3237ac15-Abstract.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_exc_ln">sym_exc_ln</a></code>, <code><a href="#topic+sym_cuni_ln">sym_cuni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_ddef_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)],
                      level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_ddef_ln(formula = Species ~ ., data = iris2D,
                      level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_def_ln'>Symmetric default label noise</h2><span id='topic+sym_def_ln'></span><span id='topic+sym_def_ln.default'></span><span id='topic+sym_def_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric default label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_def_ln(x, y, level, def = 1, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_def_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_def_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_def">def</code></td>
<td>
<p>an integer with the index of the default class (default: 1).</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_def_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric default label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are
replaced by a fixed label (<code>def</code>) within the set of class labels. 
The index <code>def</code> is taken according to the order given by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>M. Ren, W. Zeng, B. Yang, and R. Urtasun. <strong>Learning to reweight examples for robust 
deep learning</strong>. In <em>Proc. 35th International Conference on Machine Learning</em>, 
volume 80 of PMLR, pages 4331-4340, 2018.
url:<a href="http://proceedings.mlr.press/v80/ren18a.html">http://proceedings.mlr.press/v80/ren18a.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_ddef_ln">sym_ddef_ln</a></code>, <code><a href="#topic+sym_exc_ln">sym_exc_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_def_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_def_ln(formula = Species ~ ., data = iris2D,
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_dia_ln'>Symmetric diametrical label noise</h2><span id='topic+sym_dia_ln'></span><span id='topic+sym_dia_ln.default'></span><span id='topic+sym_dia_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric diametrical label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_dia_ln(x, y, level, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_dia_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_dia_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_dia_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric diametrical label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. 
In this model, diametrical (opposite) classes are more likely to have their labels mixed.
The probability of mislabel a sample of class <em>i</em> as belonging to class <em>j</em> is computed as 
<em>dij</em>/<em>S</em>, where <em>dij</em> = abs(<em>i</em>-<em>j</em>) and <em>S</em> is the sum of distances to class <em>i</em>.
The order of the classes is determined by <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>R. C. Prati, J. Luengo, and F. Herrera. 
<strong>Emerging topics and challenges of learning from noisy data in nonstandard classification: 
a survey beyond binary class noise</strong>. <em>Knowledge and Information Systems</em>, 60(1):63–97, 2019.
<a href="https://doi.org/10.1007/s10115-018-1244-4">doi:10.1007/s10115-018-1244-4</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_pes_ln">sym_pes_ln</a></code>, <code><a href="#topic+sym_opt_ln">sym_opt_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_dia_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_dia_ln(formula = Species ~ ., data = iris2D, 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_dran_ln'>Symmetric double-random label noise</h2><span id='topic+sym_dran_ln'></span><span id='topic+sym_dran_ln.default'></span><span id='topic+sym_dran_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric double-random label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_dran_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_dran_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_dran_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_dran_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_dran_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_dran_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_dran_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_dran_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_dran_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric double-random label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, each of the original class labels is 
flipped to one between two other random labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>A. Ghosh and A. S. Lan. 
<strong>Do we really need gold samples for sample weighting under label noise?</strong> 
In <em>Proc. 2021 IEEE Winter Conference on Applications of Computer Vision</em>, pages 3921-3930, 2021.
<a href="https://doi.org/10.1109/WACV48630.2021.00397">doi:10.1109/WACV48630.2021.00397</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_hie_ln">sym_hie_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_dran_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_dran_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_end_an'>Symmetric end-directed attribute noise</h2><span id='topic+sym_end_an'></span><span id='topic+sym_end_an.default'></span><span id='topic+sym_end_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric end-directed attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_end_an(x, y, level, scale = 0.2, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_end_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_end_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_scale">scale</code></td>
<td>
<p>a double in (0,1) with the scale to be used (default: 0.2).</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_end_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each attribute <em>A</em>, <em>Symmetric end-directed attribute noise</em> computes a
value <code>k</code> = <code>scale</code>·<em>max</em>(<em>A</em>). Then, it chooses (<code>level</code>·100)% of the values of that
attribute. For each value, it applies the following procedure:
</p>

<ul>
<li><p> If the value is less than the median of the attribute, the value transforms into
adding <code>k</code> to the maximum of the attribute <em>A</em>.
</p>
</li>
<li><p> If the value is greater than the median of the attribute, the value transforms into 
subtracting <code>k</code> from the minimum of the attribute <em>A</em>.
</p>
</li>
<li><p> If the value matches the median, one of the two previous alternatives is chosen.
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>T. M. Khoshgoftaar and J. V. Hulse. 
<strong>Empirical case studies in attribute noise detection</strong>. 
<em>IEEE Transactions on Systems, Man and Cybernetics Part C: Applications and Reviews</em>, 39(4):379-388, 2009.
<a href="https://doi.org/10.1109/TSMCC.2009.2013815">doi:10.1109/TSMCC.2009.2013815</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_sgau_an">sym_sgau_an</a></code>, <code><a href="#topic+symd_gau_an">symd_gau_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_end_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_end_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_exc_ln'>Symmetric exchange label noise</h2><span id='topic+sym_exc_ln'></span><span id='topic+sym_exc_ln.default'></span><span id='topic+sym_exc_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric exchange label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_exc_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_exc_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_exc_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_exc_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_exc_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_exc_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_exc_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_exc_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_exc_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric exchange label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. These samples are divided into two groups: <em>A</em> and <em>B</em>. 
Then, each sample of group <em>A</em> is labeled with the label of a sample of group <em>B</em> and vice versa.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. Schneider, J. P. Handali, and J. vom Brocke. <strong>Increasing trust in 
(big) data analytics</strong>. In <em>Proc. 2018 Advanced Information Systems 
Engineering Workshops</em>, volume 316 of LNBIP, pages 70-84, 2018.
<a href="https://doi.org/10.1007/978-3-319-92898-2_6">doi:10.1007/978-3-319-92898-2_6</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_cuni_ln">sym_cuni_ln</a></code>, <code><a href="#topic+sym_cuni_an">sym_cuni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_exc_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_exc_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_gau_an'>Symmetric Gaussian attribute noise</h2><span id='topic+sym_gau_an'></span><span id='topic+sym_gau_an.default'></span><span id='topic+sym_gau_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric Gaussian attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_gau_an(x, y, level, k = 0.2, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_gau_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_gau_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_k">k</code></td>
<td>
<p>a double in [0,1] with the scale used for the standard deviation (default: 0.2).</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_gau_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric Gaussian attribute noise</em> corrupts (<code>level</code>·100)% of the values of 
each attribute in the dataset. In order to corrupt an attribute <em>A</em>, (<code>level</code>·100)% of the
samples in the dataset are chosen. Then, their values for <em>A</em> are corrupted adding a random value
that follows a Gaussian distribution of <em>mean</em> = 0 and <em>standard deviation</em> = (<em>max</em>-<em>min</em>)·<code>k</code>, being
<em>max</em> and <em>min</em> the limits of the attribute domain. For nominal attributes, a random value is chosen.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. A. Sáez, M. Galar, J. Luengo, and F. Herrera. 
<strong>Analyzing the presence of noise in multi-class problems: alleviating its influence with the one-vs-one decomposition</strong>. 
<em>Knowledge and Information Systems</em>, 38(1):179-206, 2014.
<a href="https://doi.org/10.1007/s10115-012-0570-1">doi:10.1007/s10115-012-0570-1</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_int_an">sym_int_an</a></code>, <code><a href="#topic+symd_uni_an">symd_uni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_gau_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_gau_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_hie_ln'>Symmetric hierarchical label noise</h2><span id='topic+sym_hie_ln'></span><span id='topic+sym_hie_ln.default'></span><span id='topic+sym_hie_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric hierarchical label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_hie_ln(x, y, level, group, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_hie_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_hie_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_group">group</code></td>
<td>
<p>a list of integer vectors with the indices of classes in each superclass.</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_hie_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric hierarchical label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by other ones within the set of class labels related to them (given by the 
argument <code>group</code>). The indices in <code>group</code> are taken according to the order given by <code>order</code>. 
Note that if a class does not belong to any superclass, it may be mislabeled as any other class.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>D. Hendrycks, M. Mazeika, D. Wilson, and K. Gimpel. <strong>Using trusted 
data to train deep networks on labels corrupted by severe noise</strong>. In <em>Advances in 
Neural Information Processing Systems</em>, volume 31, pages 10477-10486, 2018.
url:<a href="https://proceedings.neurips.cc/paper/2018/hash/ad554d8c3b06d6b97ee76a2448bd7913-Abstract.html">https://proceedings.neurips.cc/paper/2018/hash/ad554d8c3b06d6b97ee76a2448bd7913-Abstract.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_uni_ln">sym_uni_ln</a></code>, <code><a href="#topic+sym_def_ln">sym_def_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method: a superclass with labels of indices 1 and 2
set.seed(9)
outdef &lt;- sym_hie_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1, 
                       group = list(c(1,2)), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_hie_ln(formula = Species ~ ., data = iris2D, level = 0.1,
                       group = list(c(1,2)), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_hienc_ln'>Symmetric hierarchical/next-class label noise</h2><span id='topic+sym_hienc_ln'></span><span id='topic+sym_hienc_ln.default'></span><span id='topic+sym_hienc_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric hierarchical/next-class label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_hienc_ln(x, y, level, group, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_hienc_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_hienc_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_group">group</code></td>
<td>
<p>a list of integer vectors with the indices of classes in each superclass.</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_hienc_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric hierarchical/next-class label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are replaced by 
the next class within the set of class labels related to them (given by the 
argument <code>group</code>). The indices in <code>group</code> are taken according to the order given by <code>order</code>. 
Note that if a class does not belong to any superclass, it may be mislabeled as any other class.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>T. Kaneko, Y. Ushiku, and T. Harada. 
<strong>Label-noise robust generative adversarial networks</strong>. 
In <em>Proc. 2019 IEEE Conference on Computer Vision and Pattern Recognition</em>, 
pages 2462-2471, 2019.
<a href="https://doi.org/10.1109/CVPR.2019.00257">doi:10.1109/CVPR.2019.00257</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_nexc_ln">sym_nexc_ln</a></code>, <code><a href="#topic+sym_dia_ln">sym_dia_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_hienc_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1, 
                       group = list(c(1,2)), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_hienc_ln(formula = Species ~ ., data = iris2D, level = 0.1,
                       group = list(c(1,2)), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_int_an'>Symmetric interval-based attribute noise</h2><span id='topic+sym_int_an'></span><span id='topic+sym_int_an.default'></span><span id='topic+sym_int_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric interval-based attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_int_an(x, y, level, nbins = 10, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_int_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_int_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_nbins">nbins</code></td>
<td>
<p>an integer with the number of bins to create (default: 10).</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_int_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric interval-based attribute noise</em> corrupts (<code>level</code>·100)% of the values of 
each attribute in the dataset. In order to corrupt an attribute <em>A</em>, (<code>level</code>·100)% of the
samples in the dataset are selected. To corrupt numeric
attributes, the attribute is split into <code>nbins</code> equal-frequency intervals, one of its closest
intervals is chosen and a random value within the interval
is picked out as noisy. For nominal attributes, a random value within the domain is chosen.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>M. V. Mannino, Y. Yang, and Y. Ryu. 
<strong>Classification algorithm sensitivity to training data with non representative attribute noise</strong>. 
<em>Decision Support Systems</em>, 46(3):743-751, 2009.
<a href="https://doi.org/10.1016/j.dss.2008.11.021">doi:10.1016/j.dss.2008.11.021</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+symd_uni_an">symd_uni_an</a></code>, <code><a href="#topic+sym_uni_an">sym_uni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_int_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_int_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_natd_ln'>Symmetric natural-distribution label noise</h2><span id='topic+sym_natd_ln'></span><span id='topic+sym_natd_ln.default'></span><span id='topic+sym_natd_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric natural-distribution label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_natd_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_natd_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_natd_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_natd_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_natd_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_natd_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_natd_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_natd_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_natd_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric natural-distribution label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by other different ones within the set of class labels. When noise for a certain 
class occurs, another class with a probability proportional to the natural class distribution 
replaces it.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>R. C. Prati, J. Luengo, and F. Herrera. 
<strong>Emerging topics and challenges of learning from noisy data in nonstandard classification: 
a survey beyond binary class noise</strong>. <em>Knowledge and Information Systems</em>, 60(1):63–97, 2019.
<a href="https://doi.org/10.1007/s10115-018-1244-4">doi:10.1007/s10115-018-1244-4</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_nuni_ln">sym_nuni_ln</a></code>, <code><a href="#topic+sym_adj_ln">sym_adj_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_natd_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_natd_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_nean_ln'>Symmetric nearest-neighbor label noise</h2><span id='topic+sym_nean_ln'></span><span id='topic+sym_nean_ln.default'></span><span id='topic+sym_nean_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric nearest-neighbor label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_nean_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_nean_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_nean_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_nean_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_nean_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_nean_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_nean_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_nean_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_nean_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric nearest-neighbor label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are replaced by 
the label of the nearest sample of a different class.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>P. H. Seo, G. Kim, and B. Han. <strong>Combinatorial inference against label noise</strong>. 
In <em>Advances in Neural Information Processing Systems</em>, volume 32, pages 1171-1181, 2019.
url:<a href="https://proceedings.neurips.cc/paper/2019/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html">https://proceedings.neurips.cc/paper/2019/hash/0cb929eae7a499e50248a3a78f7acfc7-Abstract.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_con_ln">sym_con_ln</a></code>, <code><a href="#topic+sym_cen_ln">sym_cen_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_nean_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_nean_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_nexc_ln'>Symmetric next-class label noise</h2><span id='topic+sym_nexc_ln'></span><span id='topic+sym_nexc_ln.default'></span><span id='topic+sym_nexc_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric next-class label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_nexc_ln(x, y, level, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_nexc_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_nexc_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_nexc_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <em>Symmetric next-class label noise</em> introduction model randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are 
replaced by the next class label according to <code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References
</p>


<h3>References</h3>

<p>S. Gehlot, A. Gupta, and R. Gupta. 
<strong>A CNN-based unified framework utilizing projection loss in unison with 
label noise handling for multiple Myeloma cancer diagnosis</strong>. 
<em>Medical Image Analysis</em>, 72:102099, 2021.
<a href="https://doi.org/10.1016/j.media.2021.102099">doi:10.1016/j.media.2021.102099</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_dia_ln">sym_dia_ln</a></code>, <code><a href="#topic+sym_pes_ln">sym_pes_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_nexc_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                      level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_nexc_ln(formula = Species ~ ., data = iris2D, 
                      level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_nuni_ln'>Symmetric non-uniform label noise</h2><span id='topic+sym_nuni_ln'></span><span id='topic+sym_nuni_ln.default'></span><span id='topic+sym_nuni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric non-uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_nuni_ln(x, y, level, tramat, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_nuni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_nuni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_tramat">tramat</code></td>
<td>
<p>a double matrix with the values of the transition matrix.</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_nuni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric non-uniform label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by other different ones according to the probabilities given in the transition matrix <code>tramat</code>. 
For details about the structure of the transition matrix, see Kang <em>et al.</em> (2021).
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. Kang, R. Fernandez-Beltran, P. Duan, X. Kang, and A. J. Plaza.
<strong>Robust normalized softmax loss for deep metric learning-based characterization of 
remote sensing images with label noise</strong>. 
<em>IEEE Transactions on Geoscience and Remote Sensing</em>, 59(10):8798-8811, 2021.
<a href="https://doi.org/10.1109/TGRS.2020.3042607">doi:10.1109/TGRS.2020.3042607</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_adj_ln">sym_adj_ln</a></code>, <code><a href="#topic+sym_dran_ln">sym_dran_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
tramat &lt;- matrix(data = c(0.9, 0.03, 0.07, 0.03, 0.9, 0.07, 0.03, 0.07, 0.9), 
                 nrow = 3, ncol = 3, byrow = TRUE)
outdef &lt;- sym_nuni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = 0.1, tramat = tramat)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_nuni_ln(formula = Species ~ ., data = iris2D, level = 0.1, tramat = tramat)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_opt_ln'>Symmetric optimistic label noise</h2><span id='topic+sym_opt_ln'></span><span id='topic+sym_opt_ln.default'></span><span id='topic+sym_opt_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric optimistic label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_opt_ln(x, y, level, levelH = 0.9, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_opt_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_opt_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_levelh">levelH</code></td>
<td>
<p>a double in (0.5, 1] with the noise level for higher classes (default: 0.9).</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_opt_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric optimistic label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. 
In the optimistic case, the probability of a class <em>i</em> of being mislabeled as class <em>j</em> is 
higher for <em>j</em> &gt; <em>i</em> in comparison to <em>j</em> &lt; <em>i</em>.
Thus, when noise for a certain class occurs, it is assigned to a random higher class with probability <code>levelH</code> 
and to a random lower class with probability 1-<code>levelH</code>. The order of the classes is determined by 
<code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>R. C. Prati, J. Luengo, and F. Herrera. 
<strong>Emerging topics and challenges of learning from noisy data in nonstandard classification: 
a survey beyond binary class noise</strong>. <em>Knowledge and Information Systems</em>, 60(1):63–97, 2019.
<a href="https://doi.org/10.1007/s10115-018-1244-4">doi:10.1007/s10115-018-1244-4</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_usim_ln">sym_usim_ln</a></code>, <code><a href="#topic+sym_natd_ln">sym_natd_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_opt_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_opt_ln(formula = Species ~ ., data = iris2D, 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_pes_ln'>Symmetric pessimistic label noise</h2><span id='topic+sym_pes_ln'></span><span id='topic+sym_pes_ln.default'></span><span id='topic+sym_pes_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric pessimistic label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_pes_ln(x, y, level, levelL = 0.9, order = levels(y), sortid = TRUE, ...)

## S3 method for class 'formula'
sym_pes_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_pes_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_levell">levelL</code></td>
<td>
<p>a double in (0.5, 1] with the noise level for lower classes (default: 0.9).</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_pes_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric pessimistic label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. 
In the pessimistic case, the probability of a class <em>i</em> of being mislabeled as class <em>j</em> is 
higher for <em>j</em> &lt; <em>i</em> in comparison to <em>j</em> &gt; <em>i</em>.
Thus, when noise for a certain class occurs, it is assigned to a random lower class with probability <code>levelL</code> 
and to a random higher class with probability 1-<code>levelL</code>. The order of the classes is determined by 
<code>order</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>R. C. Prati, J. Luengo, and F. Herrera. 
<strong>Emerging topics and challenges of learning from noisy data in nonstandard classification: 
a survey beyond binary class noise</strong>. <em>Knowledge and Information Systems</em>, 60(1):63–97, 2019.
<a href="https://doi.org/10.1007/s10115-018-1244-4">doi:10.1007/s10115-018-1244-4</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_opt_ln">sym_opt_ln</a></code>, <code><a href="#topic+sym_usim_ln">sym_usim_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_pes_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_pes_ln(formula = Species ~ ., data = iris2D, 
                     level = 0.1, order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_sgau_an'>Symmetric scaled-Gaussian attribute noise</h2><span id='topic+sym_sgau_an'></span><span id='topic+sym_sgau_an.default'></span><span id='topic+sym_sgau_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric scaled-Gaussian attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_sgau_an(x, y, level, k = 0.2, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_sgau_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_sgau_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_k">k</code></td>
<td>
<p>a double in [0,1] with the scale used for the standard deviation (default: 0.2).</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_sgau_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric scaled-Gaussian attribute noise</em> corrupts (<code>level</code>·100)% of the values of 
each attribute in the dataset. In order to corrupt an attribute <em>A</em>, (<code>level</code>·100)% of the
samples in the dataset are chosen. Then, their values for <em>A</em> are modified adding a random value
that follows a Gaussian distribution of <em>mean</em> = 0 and <em>standard deviation</em> = (<em>max</em>-<em>min</em>)·<code>k</code>·<code>level</code>, being
<em>max</em> and <em>min</em> the limits of the attribute domain. For nominal attributes, a random value is chosen.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>M. Koziarski, B. Krawczyk, and M. Wozniak. 
<strong>Radial-based oversampling for noisy imbalanced data classification</strong>. 
<em>Neurocomputing</em>, 343:19–33, 2019.
<a href="https://doi.org/10.1016/j.neucom.2018.04.089">doi:10.1016/j.neucom.2018.04.089</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_sgau_an">sym_sgau_an</a></code>, <code><a href="#topic+sym_gau_an">sym_gau_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_sgau_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_sgau_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_uni_an'>Symmetric uniform attribute noise</h2><span id='topic+sym_uni_an'></span><span id='topic+sym_uni_an.default'></span><span id='topic+sym_uni_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric uniform attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_uni_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_uni_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_uni_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_uni_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_uni_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_uni_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_uni_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_uni_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_uni_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric uniform attribute noise</em> corrupts (<code>level</code>·100)% of the values of 
each attribute in the dataset. In order to corrupt an attribute <em>A</em>, (<code>level</code>·100)% of the
samples in the dataset are randomly chosen. Then, their values for <em>A</em> are replaced by random 
different ones from the domain of the attribute.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>J. A. Sáez, M. Galar, J. Luengo, and F. Herrera.
<strong>Tackling the problem of classification with noisy data using Multiple Classifier Systems: Analysis of the performance and robustness</strong>. 
<em>Information Sciences</em>, 247:1-20, 2013.
<a href="https://doi.org/10.1016/j.ins.2013.06.002">doi:10.1016/j.ins.2013.06.002</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_cuni_an">sym_cuni_an</a></code>, <code><a href="#topic+sym_cuni_cn">sym_cuni_cn</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_uni_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_uni_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_uni_ln'>Symmetric uniform label noise</h2><span id='topic+sym_uni_ln'></span><span id='topic+sym_uni_ln.default'></span><span id='topic+sym_uni_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric uniform label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_uni_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_uni_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_uni_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_uni_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_uni_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_uni_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_uni_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_uni_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_uni_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric uniform label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by other different ones within the set of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>Y. Wei, C. Gong, S. Chen, T. Liu, J. Yang, and D. Tao. 
<strong>Harnessing side information for classification under label noise</strong>. 
<em>IEEE Transactions on Neural Networks and Learning Systems</em>, 31(9):3178–3192, 2020.
<a href="https://doi.org/10.1109/TNNLS.2019.2938782">doi:10.1109/TNNLS.2019.2938782</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_def_ln">sym_def_ln</a></code>, <code><a href="#topic+sym_ddef_ln">sym_ddef_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_uni_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_uni_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='sym_usim_ln'>Symmetric unit-simplex label noise</h2><span id='topic+sym_usim_ln'></span><span id='topic+sym_usim_ln.default'></span><span id='topic+sym_usim_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric unit-simplex label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
sym_usim_ln(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
sym_usim_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sym_usim_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="sym_usim_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="sym_usim_ln_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="sym_usim_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="sym_usim_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="sym_usim_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="sym_usim_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric unit-simplex label noise</em> randomly selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. Then, the labels of these samples are randomly
replaced by other different ones within the set of class labels. 
The probability for each noisy class is drawn uniformly and independently from the 
M-1-dimensional unit simplex (with M the number of classes).
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>I. Jindal, D. Pressel, B. Lester, and M. S. Nokleby. 
<strong>An effective label noise model for DNN text classification</strong>. 
In <em>Proc. 2019 Conference of the North American Chapter of the Association for 
Computational Linguistics: Human Language Technologies</em>, pages 3246-3256, 2019.
<a href="https://doi.org/10.18653/v1/n19-1328">doi:10.18653/v1/n19-1328</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_natd_ln">sym_natd_ln</a></code>, <code><a href="#topic+sym_nuni_ln">sym_nuni_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- sym_usim_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- sym_usim_ln(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='symd_gau_an'>Symmetric/dependent Gaussian attribute noise</h2><span id='topic+symd_gau_an'></span><span id='topic+symd_gau_an.default'></span><span id='topic+symd_gau_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric/dependent Gaussian attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
symd_gau_an(x, y, level, k = 0.2, sortid = TRUE, ...)

## S3 method for class 'formula'
symd_gau_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symd_gau_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_k">k</code></td>
<td>
<p>a double in [0,1] with the scale used for the standard deviation (default: 0.2).</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="symd_gau_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric/dependent Gaussian attribute noise</em> corrupts (<code>level</code>·100)% of the samples 
in the dataset. Their attribute values are modified adding a random value
that follows a Gaussian distribution of <em>mean</em> = 0 and and <em>standard deviation</em> = (<em>max</em>-<em>min</em>)·<code>k</code>, being
<em>max</em> and <em>min</em> the limits of the attribute domain. For nominal attributes, a random value is chosen.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>X. Huang, L. Shi, and J. A. K. Suykens. 
<strong>Support vector machine classifier with pinball loss</strong>. 
<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 36(5):984-997, 2014.
<a href="https://doi.org/10.1109/TPAMI.2013.178">doi:10.1109/TPAMI.2013.178</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_gau_an">sym_gau_an</a></code>, <code><a href="#topic+sym_int_an">sym_int_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- symd_gau_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- symd_gau_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='symd_gimg_an'>Symmetric/dependent Gaussian-image attribute noise</h2><span id='topic+symd_gimg_an'></span><span id='topic+symd_gimg_an.default'></span><span id='topic+symd_gimg_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric/dependent Gaussian-image attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
symd_gimg_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
symd_gimg_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symd_gimg_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="symd_gimg_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="symd_gimg_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="symd_gimg_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="symd_gimg_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="symd_gimg_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="symd_gimg_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric/dependent Gaussian-image attribute noise</em> corrupts (<code>level</code>·100)% 
of the samples in the dataset.
For each sample, a Gaussian distribution (with matching mean and variance to the original sample) is used to 
generate random attribute values for that sample.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>L. Huang, C. Zhang, and H. Zhang.
<strong>Self-adaptive training: Beyond empirical risk minimization</strong>.
In <em>Proceedings of the Advances in Neural Information Processing Systems</em>, 2020, Vol. 33, pp. 19365–19376.
<a href="https://proceedings.neurips.cc/paper/2020/file/e0ab531ec312161511493b002f9be2ee-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/e0ab531ec312161511493b002f9be2ee-Paper.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+unc_vgau_an">unc_vgau_an</a></code>, <code><a href="#topic+symd_rpix_an">symd_rpix_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- symd_gimg_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- symd_gimg_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='symd_rpix_an'>Symmetric/dependent random-pixel attribute noise</h2><span id='topic+symd_rpix_an'></span><span id='topic+symd_rpix_an.default'></span><span id='topic+symd_rpix_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric/dependent random-pixel attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
symd_rpix_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
symd_rpix_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symd_rpix_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="symd_rpix_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="symd_rpix_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="symd_rpix_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="symd_rpix_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="symd_rpix_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="symd_rpix_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric/dependent random-pixel attribute noise</em> corrupts (<code>level</code>·100)% 
of the samples in the dataset. 
For each sample, its attribute values are shuffled using independent random permutations.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>L. Huang, C. Zhang, and H. Zhang.
<strong>Self-adaptive training: Beyond empirical risk minimization</strong>.
In <em>Proceedings of the Advances in Neural Information Processing Systems</em>, 2020, Vol. 33, pp. 19365–19376.
<a href="https://proceedings.neurips.cc/paper/2020/file/e0ab531ec312161511493b002f9be2ee-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/e0ab531ec312161511493b002f9be2ee-Paper.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+unc_fixw_an">unc_fixw_an</a></code>, <code><a href="#topic+sym_end_an">sym_end_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- symd_rpix_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- symd_rpix_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='symd_uni_an'>Symmetric/dependent uniform attribute noise</h2><span id='topic+symd_uni_an'></span><span id='topic+symd_uni_an.default'></span><span id='topic+symd_uni_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Symmetric/dependent uniform attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
symd_uni_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
symd_uni_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="symd_uni_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="symd_uni_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="symd_uni_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="symd_uni_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="symd_uni_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="symd_uni_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="symd_uni_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Symmetric/dependent uniform attribute noise</em> corrupts (<code>level</code>·100)% of the samples 
in the dataset.  
Their attribute values are replaced by random different ones between
the minimum and maximum of the domain of each attribute following a uniform distribution (for numerical
attributes) or choosing a random value (for nominal attributes).
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>A. Petety, S. Tripathi, and N. Hemachandra. 
<strong>Attribute noise robust binary classification</strong>. 
In <em>Proc. 34th AAAI Conference on Artificial Intelligence</em>, pages 13897-13898, 2020.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_uni_an">sym_uni_an</a></code>, <code><a href="#topic+sym_cuni_an">sym_cuni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- symd_uni_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- symd_uni_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='ugau_bor_ln'>Uneven-Gaussian borderline label noise</h2><span id='topic+ugau_bor_ln'></span><span id='topic+ugau_bor_ln.default'></span><span id='topic+ugau_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Uneven-Gaussian borderline label noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
ugau_bor_ln(
  x,
  y,
  level,
  mean = 0,
  sd = 1,
  k = 1,
  order = levels(y),
  sortid = TRUE,
  ...
)

## S3 method for class 'formula'
ugau_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ugau_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each class.</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_mean">mean</code></td>
<td>
<p>a double with the mean for the Gaussian distribution (default: 0).</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_sd">sd</code></td>
<td>
<p>a double with the standard deviation for the Gaussian distribution (default: 1).</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="ugau_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Uneven-Gaussian borderline label noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then, a Gaussian distribution with parameters (<code>mean</code>, <code>sd</code>) is 
used to compute the value for the probability density function associated to each distance. 
For each class <em>c</em>[i], it randomly selects (<code>level</code>[i]·100)% of the samples
in the dataset based on their values of the probability density function -the order of the class labels is determined by
<code>order</code>. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Du and Z. Cai. 
<strong>Modelling class noise with symmetric and asymmetric distributions</strong>. 
In <em>Proc. 29th AAAI Conference on Artificial Intelligence</em>, pages 2589-2595, 2015.
url:<a href="https://dl.acm.org/doi/10.5555/2886521.2886681">https://dl.acm.org/doi/10.5555/2886521.2886681</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gaum_bor_ln">gaum_bor_ln</a></code>, <code><a href="#topic+gau_bor_ln">gau_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- ugau_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], 
                      level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- ugau_bor_ln(formula = Species ~ ., data = iris2D,
                      level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='ulap_bor_ln'>Uneven-Laplace borderline noise</h2><span id='topic+ulap_bor_ln'></span><span id='topic+ulap_bor_ln.default'></span><span id='topic+ulap_bor_ln.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Uneven-Laplace borderline noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
ulap_bor_ln(
  x,
  y,
  level,
  mu = 0,
  b = 1,
  k = 1,
  order = levels(y),
  sortid = TRUE,
  ...
)

## S3 method for class 'formula'
ulap_bor_ln(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ulap_bor_ln_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_level">level</code></td>
<td>
<p>a double vector with the noise levels in [0,1] to be introduced into each class.</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_mu">mu</code></td>
<td>
<p>a double with the location for the Laplace distribution (default: 0).</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_b">b</code></td>
<td>
<p>a double with the scale for the Laplace distribution (default: 1).</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_k">k</code></td>
<td>
<p>an integer with the number of nearest neighbors to be used (default: 1).</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_order">order</code></td>
<td>
<p>a character vector indicating the order of the classes (default: <code>levels(y)</code>).</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="ulap_bor_ln_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Uneven-Laplace borderline noise</em> uses an SVM to induce the decision border 
in the dataset. For each sample, its distance
to the decision border is computed. Then, a Laplace distribution with parameters (<code>mu</code>, <code>b</code>) is 
used to compute the value for the probability density function associated to each distance. 
For each class <em>c</em>[i], it randomly selects (<code>level</code>[i]·100)% of the samples
in the dataset based on their values of the probability density function -the order of the class labels is determined by
<code>order</code>. For each noisy sample, the 
majority class among its <code>k</code>-nearest neighbors of a different class 
is chosen as the new label.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per class.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per class.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References to multiclass data, considering SVM with linear 
kernel as classifier, a mislabeling process using the neighborhood of noisy samples and a 
noise level to control the number of errors in the data.
</p>


<h3>References</h3>

<p>J. Du and Z. Cai. 
<strong>Modelling class noise with symmetric and asymmetric distributions</strong>. 
In <em>Proc. 29th AAAI Conference on Artificial Intelligence</em>, pages 2589-2595, 2015.
url:<a href="https://dl.acm.org/doi/10.5555/2886521.2886681">https://dl.acm.org/doi/10.5555/2886521.2886681</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lap_bor_ln">lap_bor_ln</a></code>, <code><a href="#topic+ugau_bor_ln">ugau_bor_ln</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- ulap_bor_ln(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)],
                      level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- ulap_bor_ln(formula = Species ~ ., data = iris2D,
                      level = c(0.1, 0.2, 0.3), order = c("virginica", "setosa", "versicolor"))

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='unc_fixw_an'>Unconditional fixed-width attribute noise</h2><span id='topic+unc_fixw_an'></span><span id='topic+unc_fixw_an.default'></span><span id='topic+unc_fixw_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Unconditional fixed-width attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
unc_fixw_an(x, y, level, k = 0.1, sortid = TRUE, ...)

## S3 method for class 'formula'
unc_fixw_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unc_fixw_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced in nominal attributes.</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_k">k</code></td>
<td>
<p>a double in [0,1] with the domain proportion of the noise width (default: 0.1).</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="unc_fixw_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Unconditional fixed-width attribute noise</em> corrupts all the samples in the dataset. 
For each attribute <em>A</em>, all the original values are corrupted by adding a random number in the interval 
[-<em>width</em>, <em>width</em>], being <em>width</em> = (<em>max</em>(<em>A</em>)-<em>min</em>(<em>A</em>))·k. For 
nominal attributes, (<code>level</code>·100)% of the samples in the dataset 
are chosen and a random value is selected as noisy.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, corrupting all samples and 
allowing nominal attributes.
</p>


<h3>References</h3>

<p>A. Ramdas, B. Poczos, A. Singh, and L. A. Wasserman. 
<strong>An analysis of active learning with uniform feature noise</strong>. 
In <em>Proc. 17th International Conference on Artificial Intelligence and Statistics</em>, 
volume 33 of JMLR, pages 805-813, 2014.
url:<a href="http://proceedings.mlr.press/v33/ramdas14.html">http://proceedings.mlr.press/v33/ramdas14.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_end_an">sym_end_an</a></code>, <code><a href="#topic+sym_sgau_an">sym_sgau_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- unc_fixw_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- unc_fixw_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='unc_vgau_an'>Unconditional vp-Gaussian attribute noise</h2><span id='topic+unc_vgau_an'></span><span id='topic+unc_vgau_an.default'></span><span id='topic+unc_vgau_an.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Unconditional vp-Gaussian attribute noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
unc_vgau_an(x, y, level, sortid = TRUE, ...)

## S3 method for class 'formula'
unc_vgau_an(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unc_vgau_an_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="unc_vgau_an_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="unc_vgau_an_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="unc_vgau_an_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="unc_vgau_an_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="unc_vgau_an_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="unc_vgau_an_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <em>Unconditional vp-Gaussian attribute noise</em>, the noise level for numeric attributes indicates 
the magnitude of the errors introduced. For each attribute <em>A</em>, all the original values are corrupted 
by adding a random number that follows a Gaussian distribution with <em>mean</em> = 0 and 
<em>variance</em> = <code>level</code>%
of the variance of <em>A</em>. For nominal attributes, (<code>level</code>·100)% of the samples in the dataset 
are chosen and a random value is selected as noisy.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per attribute.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per attribute.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per attribute.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References, corrupting all samples and 
allowing nominal attributes.
</p>


<h3>References</h3>

<p>X. Huang, L. Shi, and J. A. K. Suykens. 
<strong>Support vector machine classifier with pinball loss</strong>. 
<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 36(5):984-997, 2014.
<a href="https://doi.org/10.1109/TPAMI.2013.178">doi:10.1109/TPAMI.2013.178</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+symd_rpix_an">symd_rpix_an</a></code>, <code><a href="#topic+unc_fixw_an">unc_fixw_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- unc_vgau_an(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- unc_vgau_an(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

<hr>
<h2 id='uncs_guni_cn'>Unconditional/symmetric Gaussian/uniform combined noise</h2><span id='topic+uncs_guni_cn'></span><span id='topic+uncs_guni_cn.default'></span><span id='topic+uncs_guni_cn.formula'></span>

<h3>Description</h3>

<p>Introduction of <em>Unconditional/symmetric Gaussian/uniform combined noise</em> into a classification dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## Default S3 method:
uncs_guni_cn(x, y, level, k = 0.2, sortid = TRUE, ...)

## S3 method for class 'formula'
uncs_guni_cn(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uncs_guni_cn_+3A_x">x</code></td>
<td>
<p>a data frame of input attributes.</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_y">y</code></td>
<td>
<p>a factor vector with the output class of each sample.</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_level">level</code></td>
<td>
<p>a double in [0,1] with the noise level to be introduced.</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_k">k</code></td>
<td>
<p>a double in [0,1] with the scale used for the standard deviation (default: 0.2).</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_sortid">sortid</code></td>
<td>
<p>a logical indicating if the indices must be sorted at the output (default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_...">...</code></td>
<td>
<p>other options to pass to the function.</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_formula">formula</code></td>
<td>
<p>a formula with the output class and, at least, one input attribute.</p>
</td></tr>
<tr><td><code id="uncs_guni_cn_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables in the formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><em>Unconditional/symmetric Gaussian/uniform combined noise</em> corrupts all the samples for
each attribute in the dataset. Their values are corrupted by adding a random value
following a Gaussian distribution of <em>mean</em> = 0 and <em>standard deviation</em> = (<em>max</em>-<em>min</em>)·<code>k</code>, being
<em>max</em> and <em>min</em> the limits of the attribute domain. For nominal attributes, a random value is chosen. 
Additionally, this noise model also selects (<code>level</code>·100)% of the samples
in the dataset with independence of their class. The labels of these samples are randomly
replaced by different ones within the set of class labels.
</p>


<h3>Value</h3>

<p>An object of class <code>ndmodel</code> with elements:
</p>
<table>
<tr><td><code>xnoise</code></td>
<td>
<p>a data frame with the noisy input attributes.</p>
</td></tr>
<tr><td><code>ynoise</code></td>
<td>
<p>a factor vector with the noisy output class.</p>
</td></tr>
<tr><td><code>numnoise</code></td>
<td>
<p>an integer vector with the amount of noisy samples per variable.</p>
</td></tr>
<tr><td><code>idnoise</code></td>
<td>
<p>an integer vector list with the indices of noisy samples per variable.</p>
</td></tr>
<tr><td><code>numclean</code></td>
<td>
<p>an integer vector with the amount of clean samples per variable.</p>
</td></tr>
<tr><td><code>idclean</code></td>
<td>
<p>an integer vector list with the indices of clean samples per variable.</p>
</td></tr>
<tr><td><code>distr</code></td>
<td>
<p>an integer vector with the samples per class in the original data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the full name of the noise introduction model used.</p>
</td></tr>
<tr><td><code>param</code></td>
<td>
<p>a list of the argument values.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the function call.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Noise model adapted from the papers in References.
</p>


<h3>References</h3>

<p>S. Kazmierczak and J. Mandziuk. 
<strong>A committee of convolutional neural networks for image classification in the 
concurrent presence of feature and label noise</strong>. 
In <em>Proc. 16th International Conference on Parallel Problem Solving from Nature</em>, 
volume 12269 of LNCS, pages 498-511, 2020.
<a href="https://doi.org/10.1007/978-3-030-58112-1_34">doi:10.1007/978-3-030-58112-1_34</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sym_cuni_cn">sym_cuni_cn</a></code>, <code><a href="#topic+sym_cuni_an">sym_cuni_an</a></code>, <code><a href="#topic+print.ndmodel">print.ndmodel</a></code>, <code><a href="#topic+summary.ndmodel">summary.ndmodel</a></code>, <code><a href="#topic+plot.ndmodel">plot.ndmodel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># load the dataset
data(iris2D)

# usage of the default method
set.seed(9)
outdef &lt;- uncs_guni_cn(x = iris2D[,-ncol(iris2D)], y = iris2D[,ncol(iris2D)], level = 0.1)

# show results
summary(outdef, showid = TRUE)
plot(outdef)

# usage of the method for class formula
set.seed(9)
outfrm &lt;- uncs_guni_cn(formula = Species ~ ., data = iris2D, level = 0.1)

# check the match of noisy indices
identical(outdef$idnoise, outfrm$idnoise)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
