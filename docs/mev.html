<!DOCTYPE html><html lang="en"><head><title>Help for package mev</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mev}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#.C1'><p>Contrast matrix</p></a></li>
<li><a href='#.exp_info_algebraic'><p>Algebraic calculation of the expected information</p></a></li>
<li><a href='#.fit.gpd.grimshaw'><p>GP fitting function of Grimshaw (1993)</p></a></li>
<li><a href='#.fit.gpd.rob'><p>Robust threshold selection of Dupuis</p></a></li>
<li><a href='#.gev.postpred'><p>Posterior predictive distribution and density for the GEV distribution</p></a></li>
<li><a href='#.gpd_2D_fit'><p>Maximum likelihood method for the generalized Pareto Model</p></a></li>
<li><a href='#.is.CNSD'><p>Is the matrix conditionally negative semi-definite?</p>
Function adapted from 'is.CNSD' in the CEGO package, v 2.1.0</a></li>
<li><a href='#.Joint_MLE_Expl'><p>Joint maximum likelihood estimation for exponential model</p></a></li>
<li><a href='#.Joint_MLE_NHPP'><p>Joint maximum likelihood for the non-homogeneous Poisson Process</p></a></li>
<li><a href='#.mvasym.check'><p>Internal function</p></a></li>
<li><a href='#.mvrnorm_arma'><p>Multivariate Normal distribution sampler (Rcpp version), derived using the eigendecomposition</p>
of the covariance matrix Sigma. The function utilizes the arma random normal generator</a></li>
<li><a href='#.rbilogspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the bilogistic model</p></a></li>
<li><a href='#.rbrspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Brown-Resnick model</p></a></li>
<li><a href='#.rdirmixspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Dirichlet mixture model</p></a></li>
<li><a href='#.rdirspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the extremal Dirichlet</p>
model</a></li>
<li><a href='#.rexstudspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the extremal Student model</p></a></li>
<li><a href='#.rhrspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Husler-Reiss model</p></a></li>
<li><a href='#.rlogspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the logistic model</p></a></li>
<li><a href='#.rmevA1'><p>Multivariate extreme value distribution sampling algorithm via angular measure</p></a></li>
<li><a href='#.rmevA2'><p>Multivariate extreme value distribution sampling algorithm via extremal functions</p></a></li>
<li><a href='#.rmevasy'><p>Random samples from asymmetric logistic distribution</p></a></li>
<li><a href='#.rmevspec_cpp'><p>Random sampling from spectral distribution on l1 sphere</p></a></li>
<li><a href='#.rneglogspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the negative logistic model</p></a></li>
<li><a href='#.rpairbetaspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the pairwise Beta model</p></a></li>
<li><a href='#.rpairexpspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the pairwise exponential model</p></a></li>
<li><a href='#.rPbilog'><p>Generate from bilogistic <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is the probability of extremal functions</a></li>
<li><a href='#.rPBrownResnick'><p>Generate from Brown-Resnick process <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is probability of extremal function</a></li>
<li><a href='#.rPdir'><p>Generate from extremal Dirichlet <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is the probability of extremal functions from the Dirichlet model of
Coles and Tawn.</a></li>
<li><a href='#.rPdirmix'><p>Generate from extremal Dirichlet <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is the probability of extremal functions from a Dirichlet mixture</a></li>
<li><a href='#.rPexstud'><p>Generate from extremal Student-t <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is probability of extremal function</a></li>
<li><a href='#.rPHuslerReiss'><p>Generate from extremal Husler-Reiss distribution <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is probability of extremal function</a></li>
<li><a href='#.rPlog'><p>Generate from logistic <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is probability of extremal function scaled by a Frechet variate</a></li>
<li><a href='#.rPneglog'><p>Generate from negative logistic <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is probability of extremal function scaled by a Frechet variate</a></li>
<li><a href='#.rPsite'><p>Samples from exceedances at site (scaled extremal function definition)</p></a></li>
<li><a href='#.rPSmith'><p>Generate from Smith model (moving maxima) <code class="reqn">Y \sim {P_x}</code>, where</p>
<code class="reqn">P_{x}</code> is probability of extremal function</a></li>
<li><a href='#.rsmithspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Smith model (moving maxima)</p></a></li>
<li><a href='#.rwdirbsspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the weighted Dirichlet model</p></a></li>
<li><a href='#.rwexpbsspec'><p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the weighted exponential model</p></a></li>
<li><a href='#.score_algebraic'><p>Algebraic score</p></a></li>
<li><a href='#.wecdf'><p>Weighted empirical distribution function</p></a></li>
<li><a href='#abisko'><p>Abisko rainfall</p></a></li>
<li><a href='#angextrapo'><p>Bivariate angular dependence function for extrapolation based on rays</p></a></li>
<li><a href='#angmeas'><p>Rank-based transformation to angular measure</p></a></li>
<li><a href='#angmeasdir'><p>Dirichlet mixture smoothing of the angular measure</p></a></li>
<li><a href='#automrl'><p>Automated mean residual life plots</p></a></li>
<li><a href='#chibar'><p>Parametric estimates of <code class="reqn">\bar{\chi}</code></p></a></li>
<li><a href='#clikmgp'><p>Censored likelihood for multivariate peaks over threshold models</p></a></li>
<li><a href='#confint.eprof'><p>Confidence intervals for profile likelihood objects</p></a></li>
<li><a href='#cvselect'><p>Threshold selection via coefficient of variation</p></a></li>
<li><a href='#distg'><p>Distance matrix with geometric anisotropy</p></a></li>
<li><a href='#egp'><p>Extended generalised Pareto families</p></a></li>
<li><a href='#egp-function'><p>Extended generalised Pareto families of Papastathopoulos and Tawn (functions)</p></a></li>
<li><a href='#egp.fit'><p>Fit of extended GP models and parameter stability plots</p></a></li>
<li><a href='#egp.fitrange'><p>Deprecated function for parameter stability plots</p></a></li>
<li><a href='#egp2.fit'><p>Fit an extended generalized Pareto distribution of Naveau et al.</p></a></li>
<li><a href='#emplik'><p>Self-concordant empirical likelihood for a vector mean</p></a></li>
<li><a href='#eskrain'><p>Eskdalemuir Observatory Daily Rainfall</p></a></li>
<li><a href='#expme'><p>Exponent measure for multivariate generalized Pareto distributions</p></a></li>
<li><a href='#ext.index'><p>Extremal index estimators based on interexceedance time and gap of exceedances</p></a></li>
<li><a href='#extcoef'><p>Estimators of the extremal coefficient</p></a></li>
<li><a href='#extgp'><p>Extended generalised Pareto families of Naveau et al. (2016)</p></a></li>
<li><a href='#extgp.G'><p>Carrier distribution for the extended GP distributions of Naveau et al.</p></a></li>
<li><a href='#extremo'><p>Pairwise extremogram for max-risk functional</p></a></li>
<li><a href='#fit.egp'><p>Parameter stability plot and maximum likelihood routine for extended GP models</p></a></li>
<li><a href='#fit.extgp'><p>Fit an extended generalized Pareto distribution of Naveau et al.</p></a></li>
<li><a href='#fit.gev'><p>Maximum likelihood estimation for the generalized extreme value distribution</p></a></li>
<li><a href='#fit.gpd'><p>Maximum likelihood estimation for the generalized Pareto distribution</p></a></li>
<li><a href='#fit.pp'><p>Maximum likelihood estimation of the point process of extremes</p></a></li>
<li><a href='#fit.rlarg'><p>Maximum likelihood estimates of point process for the r-largest observations</p></a></li>
<li><a href='#frwind'><p>French wind data</p></a></li>
<li><a href='#geomagnetic'><p>Magnetic storms</p></a></li>
<li><a href='#gev'><p>Generalized extreme value distribution</p></a></li>
<li><a href='#gev.abias'><p>Asymptotic bias of block maxima for fixed sample sizes</p></a></li>
<li><a href='#gev.bcor'><p>Bias correction for GEV distribution</p></a></li>
<li><a href='#gev.bias'><p>Cox-Snell first order bias for the GEV distribution</p></a></li>
<li><a href='#gev.Fscore'><p>Firth's modified score equation for the generalized extreme value distribution</p></a></li>
<li><a href='#gev.infomat'><p>Information matrix for the generalized extreme value distribution</p></a></li>
<li><a href='#gev.ll'><p>log likelihood for the generalized extreme value distribution</p></a></li>
<li><a href='#gev.mle'><p>Generalized extreme value maximum likelihood estimates for various quantities of interest</p></a></li>
<li><a href='#gev.Nyr'><p>N-year return levels, median and mean estimate</p></a></li>
<li><a href='#gev.pll'><p>Profile log-likelihood for the generalized extreme value distribution</p></a></li>
<li><a href='#gev.retlev'><p>Return level for the generalized extreme value distribution</p></a></li>
<li><a href='#gev.score'><p>Score vector for the generalized extreme value distribution</p></a></li>
<li><a href='#gev.tem'><p>Tangent exponential model approximation for the GEV distribution</p></a></li>
<li><a href='#gev.temstat'><p>Tangent exponential model statistics for the generalized extreme value distribution</p></a></li>
<li><a href='#gevdist'><p>Generalized extreme value distribution</p></a></li>
<li><a href='#gevN'><p>Generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</p></a></li>
<li><a href='#gevN.infomat'><p>Information matrix of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</p></a></li>
<li><a href='#gevN.ll'><p>Negative log likelihood of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</p></a></li>
<li><a href='#gevN.mean'><p>This function returns the mean of N observations from the GEV.</p></a></li>
<li><a href='#gevN.score'><p>Score of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</p></a></li>
<li><a href='#gevN.temstat'><p>Tangent exponential model statistics for the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</p></a></li>
<li><a href='#gevr'><p>Generalized extreme value distribution (return level parametrization)</p></a></li>
<li><a href='#gevr.infomat'><p>Observed information matrix for GEV distribution (return levels)</p></a></li>
<li><a href='#gevr.ll'><p>Negative log likelihood of the generalized extreme value distribution (return levels)</p></a></li>
<li><a href='#gevr.score'><p>Score of the log likelihood for the GEV distribution (return levels)</p></a></li>
<li><a href='#gevr.temstat'><p>Tangent exponential model statistics for the GEV distribution (return level)</p></a></li>
<li><a href='#gp.fit'><p>Maximum likelihood estimate of generalized Pareto applied to threshold exceedances</p></a></li>
<li><a href='#gpd'><p>Generalized Pareto distribution</p></a></li>
<li><a href='#gpd.abias'><p>Asymptotic bias of threshold exceedances for k order statistics</p></a></li>
<li><a href='#gpd.bcor'><p>Bias correction for GP distribution</p></a></li>
<li><a href='#gpd.bias'><p>Cox-Snell first order bias expression for the generalized Pareto distribution</p></a></li>
<li><a href='#gpd.boot'><p>Bootstrap approximation for generalized Pareto parameters</p></a></li>
<li><a href='#gpd.Fscore'><p>Firth's modified score equation for the generalized Pareto distribution</p></a></li>
<li><a href='#gpd.infomat'><p>Information matrix for the generalized Pareto distribution</p></a></li>
<li><a href='#gpd.ll'><p>Log likelihood for the generalized Pareto distribution</p></a></li>
<li><a href='#gpd.mle'><p>Generalized Pareto maximum likelihood estimates for various quantities of interest</p></a></li>
<li><a href='#gpd.pll'><p>Profile log-likelihood for the generalized Pareto distribution</p></a></li>
<li><a href='#gpd.score'><p>Score vector for the generalized Pareto distribution</p></a></li>
<li><a href='#gpd.tem'><p>Tangent exponential model approximation for the GP distribution</p></a></li>
<li><a href='#gpd.temstat'><p>Tangent exponential model statistics for the generalized Pareto distribution</p></a></li>
<li><a href='#gpde'><p>Generalized Pareto distribution (expected shortfall parametrization)</p></a></li>
<li><a href='#gpde.infomat'><p>Observed information matrix for the GP distribution (expected shortfall)</p></a></li>
<li><a href='#gpde.ll'><p>Negative log likelihood of the generalized Pareto distribution (expected shortfall)</p></a></li>
<li><a href='#gpde.score'><p>Score vector for the GP distribution (expected shortfall)</p></a></li>
<li><a href='#gpde.temstat'><p>Tangent exponential model statistics for the generalized Pareto distribution (expected shortfall)</p></a></li>
<li><a href='#gpdist'><p>Generalized Pareto distribution</p></a></li>
<li><a href='#gpdN'><p>Generalized Pareto distribution (mean of maximum of N exceedances parametrization)</p></a></li>
<li><a href='#gpdN.infomat'><p>Information matrix of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</p></a></li>
<li><a href='#gpdN.ll'><p>Negative log likelihood of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</p></a></li>
<li><a href='#gpdN.mean'><p>This function returns the mean of N maxima from the GP.</p></a></li>
<li><a href='#gpdN.quant'><p>This function returns the qth percentile of N maxima from the GP.</p></a></li>
<li><a href='#gpdN.score'><p>Score vector of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</p></a></li>
<li><a href='#gpdN.temstat'><p>Tangent exponential model statistics for the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</p></a></li>
<li><a href='#gpdr'><p>Generalized Pareto distribution (return level parametrization)</p></a></li>
<li><a href='#gpdr.infomat'><p>Observed information matrix for GP distribution (return levels)</p></a></li>
<li><a href='#gpdr.ll'><p>Negative log likelihood of the generalized Pareto distribution (return levels)</p></a></li>
<li><a href='#gpdr.score'><p>Score of the profile log likelihood for the GP distribution (return levels parametrization)</p></a></li>
<li><a href='#gpdr.temstat'><p>Tangent exponential model statistics for the generalized Pareto distribution (return level)</p></a></li>
<li><a href='#gpdtopar'><p>Transformation from the generalized Pareto to unit Pareto</p></a></li>
<li><a href='#ibvpot'><p>Interpret bivariate threshold exceedance models</p></a></li>
<li><a href='#infomat.test'><p>Information matrix test statistic and MLE for the extremal index</p></a></li>
<li><a href='#intensBR'><p>Intensity function for the Brown-Resnick model</p></a></li>
<li><a href='#intensXstud'><p>Intensity function for the extremal Student model</p></a></li>
<li><a href='#jac'><p>Jacobian of the transformation from generalized Pareto to unit Pareto distribution</p></a></li>
<li><a href='#Lambda2cov'><p>Transform variogram matrix to covariance of conditional random field</p></a></li>
<li><a href='#lambdadep'><p>Estimation of the bivariate angular dependence function of Wadsworth and Tawn (2013)</p></a></li>
<li><a href='#likmgp'><p>Likelihood for multivariate peaks over threshold models</p></a></li>
<li><a href='#maiquetia'><p>Maiquetia Daily Rainfall</p></a></li>
<li><a href='#maxstabtest'><p>P-P plot for testing max stability</p></a></li>
<li><a href='#mvrnorm'><p>Multivariate Normal distribution sampler</p></a></li>
<li><a href='#NC.diag'><p>Score and likelihood ratio tests fit of equality of shape over multiple thresholds</p></a></li>
<li><a href='#nidd'><p>River Nidd Flow</p></a></li>
<li><a href='#nutrients'><p>Nutrient data</p></a></li>
<li><a href='#pandemics'><p>Deaths from pandemics</p></a></li>
<li><a href='#pextgp.G'><p>Extended GP functions</p></a></li>
<li><a href='#PickandsXU'><p>Extreme U-statistic Pickands estimator</p></a></li>
<li><a href='#plot.eprof'><p>Plot of (modified) profile likelihood</p></a></li>
<li><a href='#plot.fr'><p>Plot of tangent exponential model profile likelihood</p></a></li>
<li><a href='#power.vario'><p>Power variogram model</p></a></li>
<li><a href='#powerexp.cor'><p>Power exponential correlation model</p></a></li>
<li><a href='#pp'><p>Poisson process of extremes.</p></a></li>
<li><a href='#pp.infomat'><p>Information matrix for the Poisson process likelihood</p></a></li>
<li><a href='#pp.ll'><p>Log-likelihood of Poisson process of threshold exceedances</p></a></li>
<li><a href='#pp.score'><p>Score vector for the Poisson process of threshold exceedances</p></a></li>
<li><a href='#rdir'><p>Random variate generation for Dirichlet distribution on <code class="reqn">S_{d}</code></p></a></li>
<li><a href='#rgparp'><p>Simulation from generalized R-Pareto processes</p></a></li>
<li><a href='#rlarg'><p>Distribution of the r-largest observations</p></a></li>
<li><a href='#rlarg.infomat'><p>Information matrix for the r-largest observations.</p></a></li>
<li><a href='#rlarg.ll'><p>Log-likelihood of the point process of r-largest observations</p></a></li>
<li><a href='#rlarg.score'><p>Score of the r-largest observations</p></a></li>
<li><a href='#rmev'><p>Exact simulations of multivariate extreme value distributions</p></a></li>
<li><a href='#rmevspec'><p>Random samples from spectral distributions of multivariate extreme value models.</p></a></li>
<li><a href='#rparp'><p>Simulation from R-Pareto processes</p></a></li>
<li><a href='#rparpcs'><p>Simulation from Pareto processes using composition sampling</p></a></li>
<li><a href='#rparpcshr'><p>Simulation of generalized Huesler-Reiss Pareto vectors via composition sampling</p></a></li>
<li><a href='#rrlarg'><p>Simulate r-largest observations from point process of extremes</p></a></li>
<li><a href='#schlather.vario'><p>Variogram model of Schlather and Moreva</p></a></li>
<li><a href='#scoreindep'><p>Ramos and Ledford test of independence</p></a></li>
<li><a href='#smith.penult'><p>Smith's penultimate approximations</p></a></li>
<li><a href='#smith.penult.fn'><p>Smith's third penultimate approximation</p></a></li>
<li><a href='#spline.corr'><p>Spline correction for Fraser-Reid approximations</p></a></li>
<li><a href='#spunif'><p>Semi-parametric marginal transformation to uniform</p></a></li>
<li><a href='#taildep'><p>Coefficient of tail correlation and tail dependence</p></a></li>
<li><a href='#tem.corr'><p>Bridging the singularity for higher order asymptotics</p></a></li>
<li><a href='#tstab.gpd'><p>Parameter stability plots for peaks-over-threshold</p></a></li>
<li><a href='#venice'><p>Venice Sea Levels</p></a></li>
<li><a href='#vmetric.diag'><p>Metric-based threshold selection</p></a></li>
<li><a href='#W.diag'><p>Wadsworth's univariate and bivariate exponential threshold diagnostics</p></a></li>
<li><a href='#w1500m'><p>Best 200 times of Women 1500m Track</p></a></li>
<li><a href='#xasym'><p>Coefficient of extremal asymmetry</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Modelling of Extreme Values</td>
</tr>
<tr>
<td>Version:</td>
<td>1.17</td>
</tr>
<tr>
<td>Description:</td>
<td>Various tools for the analysis of univariate, multivariate and functional extremes. Exact simulation from max-stable processes [Dombry, Engelke and Oesting (2016) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasw008">doi:10.1093/biomet/asw008</a>&gt;, R-Pareto processes for various parametric models, including Brown-Resnick (Wadsworth and Tawn, 2014, &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fast042">doi:10.1093/biomet/ast042</a>&gt;) and Extremal Student (Thibaud and Opitz, 2015, &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasv045">doi:10.1093/biomet/asv045</a>&gt;). Threshold selection methods, including Wadsworth (2016) &lt;<a href="https://doi.org/10.1080%2F00401706.2014.998345">doi:10.1080/00401706.2014.998345</a>&gt;, and Northrop and Coleman (2014) &lt;<a href="https://doi.org/10.1007%2Fs10687-014-0183-z">doi:10.1007/s10687-014-0183-z</a>&gt;. Multivariate extreme diagnostics. Estimation and likelihoods for univariate extremes, e.g., Coles (2001) &lt;<a href="https://doi.org/10.1007%2F978-1-4471-3675-0">doi:10.1007/978-1-4471-3675-0</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://lbelzile.github.io/mev/">https://lbelzile.github.io/mev/</a>, <a href="https://github.com/lbelzile/mev/">https://github.com/lbelzile/mev/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/lbelzile/mev/issues/">https://github.com/lbelzile/mev/issues/</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4)</td>
</tr>
<tr>
<td>Imports:</td>
<td>alabama, methods, nleqslv, Rcpp (&ge; 0.12.16), Rsolnp, stats,</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, cobs, evd, knitr, MASS, mvPot (&ge; 0.1.4), mvtnorm, gmm,
revdbayes, rmarkdown, ismev, tinytest, TruncatedNormal (&ge; 1.1)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-09 03:31:35 UTC; lbelzile</td>
</tr>
<tr>
<td>Author:</td>
<td>Leo Belzile <a href="https://orcid.org/0000-0002-9135-014X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Jennifer L. Wadsworth [aut],
  Paul J. Northrop [aut],
  Scott D. Grimshaw [aut],
  Jin Zhang [ctb],
  Michael A. Stephens [ctb],
  Art B. Owen [ctb],
  Raphael Huser [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Leo Belzile &lt;belzilel@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-09 04:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='.C1'>Contrast matrix</h2><span id='topic+.C1'></span>

<h3>Description</h3>

<p>Produces a contrast matrix with (1,-1) elements running down the two diagonals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.C1(k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".C1_+3A_k">k</code></td>
<td>
<p>number of columns (the number of rows is <code>k-1</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>k-1</code> x <code>k</code> contrast matrix
</p>

<hr>
<h2 id='.exp_info_algebraic'>Algebraic calculation of the expected information</h2><span id='topic+.exp_info_algebraic'></span>

<h3>Description</h3>

<p>Algebraic calculation of the expected information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.exp_info_algebraic(x, w, v, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".exp_info_algebraic_+3A_x">x</code></td>
<td>
<p>parameter vector: (<code>sigma1</code>, <code>phi_1</code>, ..., <code>phi_m</code>)</p>
</td></tr>
<tr><td><code id=".exp_info_algebraic_+3A_w">w</code></td>
<td>
<p>differences between thresholds (<code>w[m]</code> not used)</p>
</td></tr>
<tr><td><code id=".exp_info_algebraic_+3A_v">v</code></td>
<td>
<p>thresholds relative to lowest threshold</p>
</td></tr>
<tr><td><code id=".exp_info_algebraic_+3A_m">m</code></td>
<td>
<p>number of thresholds</p>
</td></tr>
</table>

<hr>
<h2 id='.fit.gpd.grimshaw'>GP fitting function of Grimshaw (1993)</h2><span id='topic+.fit.gpd.grimshaw'></span>

<h3>Description</h3>

<p>Function for estimating parameters <code>k</code> and <code>a</code> for a random sample from a GPD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fit.gpd.grimshaw(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".fit.gpd.grimshaw_+3A_x">x</code></td>
<td>
<p>sample values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the maximum likelihood estimates of components <code>a</code> and <code>k</code>
</p>


<h3>Author(s)</h3>

<p>Scott D. Grimshaw
</p>

<hr>
<h2 id='.fit.gpd.rob'>Robust threshold selection of Dupuis</h2><span id='topic+.fit.gpd.rob'></span>

<h3>Description</h3>

<p>The optimal bias-robust estimator (OBRE) for the generalized Pareto.
This function returns robust estimates and the associated weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.fit.gpd.rob(dat, thresh, k = 4, tol = 1e-05, show = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".fit.gpd.rob_+3A_dat">dat</code></td>
<td>
<p>a numeric vector of data</p>
</td></tr>
<tr><td><code id=".fit.gpd.rob_+3A_thresh">thresh</code></td>
<td>
<p>threshold parameter</p>
</td></tr>
<tr><td><code id=".fit.gpd.rob_+3A_k">k</code></td>
<td>
<p>bound on the influence function; the constant <code>k</code> is a robustness parameter
(higher bounds are more efficient, low bounds are more robust). Default to 4.</p>
</td></tr>
<tr><td><code id=".fit.gpd.rob_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for OBRE weights iterations.</p>
</td></tr>
<tr><td><code id=".fit.gpd.rob_+3A_show">show</code></td>
<td>
<p>logical: should diagnostics and estimates be printed. Default to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the same components as <code><a href="#topic+fit.gpd">fit.gpd</a></code>,
in addition to
</p>

<ul>
<li> <p><code>estimate</code>: optimal bias-robust estimates of the <code>scale</code> and <code>shape</code> parameters.
</p>
</li>
<li> <p><code>weights</code>: vector of OBRE weights.
</p>
</li></ul>



<h3>References</h3>

<p>Dupuis, D.J. (1998). Exceedances over High Thresholds: A Guide to Threshold Selection,
<em>Extremes</em>, <b>1</b>(3), 251&ndash;261.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.gpd">fit.gpd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- rexp(100)
.fit.gpd.rob(dat, 0.1)
</code></pre>

<hr>
<h2 id='.gev.postpred'>Posterior predictive distribution and density for the GEV distribution</h2><span id='topic+.gev.postpred'></span>

<h3>Description</h3>

<p>This function calculates the posterior predictive density at points x
based on a matrix of posterior density parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.gev.postpred(x, posterior, Nyr = 100, type = c("density", "quantile"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".gev.postpred_+3A_x">x</code></td>
<td>
<p><code>n</code> vector of points</p>
</td></tr>
<tr><td><code id=".gev.postpred_+3A_posterior">posterior</code></td>
<td>
<p><code>n</code> by <code>3</code> matrix of posterior samples</p>
</td></tr>
<tr><td><code id=".gev.postpred_+3A_nyr">Nyr</code></td>
<td>
<p>number of years to extrapolate</p>
</td></tr>
<tr><td><code id=".gev.postpred_+3A_type">type</code></td>
<td>
<p>string indicating whether to return the posterior <code>density</code> or the <code>quantile</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of values for the posterior predictive density or quantile at <code>x</code>, depending on the value of <code>type</code>
</p>

<hr>
<h2 id='.gpd_2D_fit'>Maximum likelihood method for the generalized Pareto Model</h2><span id='topic+.gpd_2D_fit'></span>

<h3>Description</h3>

<p>Maximum-likelihood estimation for the generalized Pareto model, including generalized linear modelling of each parameter. This function was adapted by Paul Northrop to include the gradient in the <code>gpd.fit</code> routine from <code>ismev</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.gpd_2D_fit(
  xdat,
  threshold,
  npy = 365,
  ydat = NULL,
  sigl = NULL,
  shl = NULL,
  siglink = identity,
  shlink = identity,
  siginit = NULL,
  shinit = NULL,
  show = TRUE,
  method = "Nelder-Mead",
  maxit = 10000,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".gpd_2D_fit_+3A_xdat">xdat</code></td>
<td>
<p>numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_threshold">threshold</code></td>
<td>
<p>a scalar or a numeric   vector of the same length as <code>xdat</code>.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_npy">npy</code></td>
<td>
<p>number of observations per year/block.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_ydat">ydat</code></td>
<td>
<p>matrix of covariates for generalized linear modelling of the parameters (or <code>NULL</code> (the default) for stationary fitting). The number of rows should be the same as the length of <code>xdat</code>.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_sigl">sigl</code></td>
<td>
<p>numeric vector of integers, giving the columns of <code>ydat</code> that contain covariates for generalized linear modelling of the scale parameter (or <code>NULL</code> (the default) if the corresponding parameter is stationary).</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_shl">shl</code></td>
<td>
<p>numeric vector of integers, giving the columns of <code>ydat</code> that contain covariates for generalized linear modelling of the shape parameter (or <code>NULL</code> (the default) if the corresponding parameter is stationary).</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_siglink">siglink</code></td>
<td>
<p>inverse link functions for generalized linear modelling of the scale parameter</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_shlink">shlink</code></td>
<td>
<p>inverse link functions for generalized linear modelling of the shape parameter</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_siginit">siginit</code></td>
<td>
<p>numeric giving initial value(s) for parameter estimates. If <code>NULL</code> the default is <code>sqrt(6 * var(xdat))/pi</code></p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_shinit">shinit</code></td>
<td>
<p>numeric giving initial value(s) for the shape parameter estimate; if <code>NULL</code>, this is 0.1.  If using parameter covariates, then these values are used for the constant term, and zeros for all other terms.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), print details of the fit.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_method">method</code></td>
<td>
<p>optimization method (see <code><a href="stats.html#topic+optim">optim</a></code> for details).</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
<tr><td><code id=".gpd_2D_fit_+3A_...">...</code></td>
<td>
<p>other control parameters for the optimization. These are passed to components of the <code>control</code> argument of <code>optim</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For non-stationary fitting it is recommended that the covariates within the generalized linear models are (at least approximately) centered and scaled (i.e. the columns of <code>ydat</code> should be approximately centered and scaled).
</p>
<p>The form of the GP model used follows Coles (2001) Eq (4.7).  In particular, the shape parameter is defined so that positive values imply a heavy tail and negative values imply a bounded upper value.
</p>


<h3>Value</h3>

<p>a list with components
</p>

<dl>
<dt>nexc</dt><dd><p>scalar giving the number of threshold exceedances.</p>
</dd>
<dt>nllh</dt><dd><p>scalar giving the negative log-likelihood value.</p>
</dd>
<dt>mle</dt><dd><p>numeric vector giving the MLE's for the scale and shape parameters, resp.</p>
</dd>
<dt>rate</dt><dd><p>scalar giving the estimated probability of exceeding the threshold.</p>
</dd>
<dt>se</dt><dd><p>numeric vector giving the standard error estimates for the scale and shape parameter estimates, resp.</p>
</dd>
<dt>trans</dt><dd><p>logical indicator for a non-stationary fit.</p>
</dd>
<dt>model</dt><dd><p>list with components <code>sigl</code> and <code>shl</code>.</p>
</dd>
<dt>link</dt><dd><p>character vector giving inverse link functions.</p>
</dd>
<dt>threshold</dt><dd><p>threshold, or vector of thresholds.</p>
</dd>
<dt>nexc</dt><dd><p>number of data points above the threshold.</p>
</dd>
<dt>data</dt><dd><p>data that lie above the threshold. For non-stationary models, the data are standardized.</p>
</dd>
<dt>conv</dt><dd><p>convergence code, taken from the list returned by <code><a href="stats.html#topic+optim">optim</a></code>. A zero indicates successful convergence.</p>
</dd>
<dt>nllh</dt><dd><p>negative log likelihood evaluated at the maximum likelihood estimates.</p>
</dd>
<dt>vals</dt><dd><p>matrix with three columns containing the maximum likelihood estimates of the scale and shape parameters, and the threshold, at each data point.</p>
</dd>
<dt>mle</dt><dd><p>vector containing the maximum likelihood estimates.</p>
</dd>
<dt>rate</dt><dd><p>proportion of data points that lie above the threshold.</p>
</dd>
<dt>cov</dt><dd><p>covariance matrix.</p>
</dd>
<dt>se</dt><dd><p>numeric vector containing the standard errors.</p>
</dd>
<dt>n</dt><dd><p>number of data points (i.e., the length of <code>xdat</code>).</p>
</dd>
<dt>npy</dt><dd><p>number of observations per year/block.</p>
</dd>
<dt>xdata</dt><dd><p>data that has been fitted.</p>
</dd>
</dl>



<h3>References</h3>

<p>Coles, S., 2001.  An Introduction to Statistical Modeling of Extreme Values.  Springer-Verlag, London.
</p>

<hr>
<h2 id='.is.CNSD'>Is the matrix conditionally negative semi-definite?
Function adapted from 'is.CNSD' in the CEGO package, v 2.1.0</h2><span id='topic+.is.CNSD'></span>

<h3>Description</h3>

<p>Is the matrix conditionally negative semi-definite?
Function adapted from 'is.CNSD' in the CEGO package, v 2.1.0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.is.CNSD(X, tol = 1e-08)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".is.CNSD_+3A_x">X</code></td>
<td>
<p>a symmetric matrix</p>
</td></tr>
<tr><td><code id=".is.CNSD_+3A_tol">tol</code></td>
<td>
<p>tolerance value; eigenvalues between <code>-tol</code> and <code>tol</code> are assumed to be zero.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Zaefferer
</p>

<hr>
<h2 id='.Joint_MLE_Expl'>Joint maximum likelihood estimation for exponential model</h2><span id='topic+.Joint_MLE_Expl'></span>

<h3>Description</h3>

<p>Calculates the MLEs of the rate parameter, and joint asymptotic covariance matrix of these MLEs
over a range of thresholds as supplied by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.Joint_MLE_Expl(x, u = NULL, k, q1, q2 = 1, param)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".Joint_MLE_Expl_+3A_x">x</code></td>
<td>
<p>vector of data</p>
</td></tr>
<tr><td><code id=".Joint_MLE_Expl_+3A_u">u</code></td>
<td>
<p>vector of thresholds. If not supplied, then <code>k</code>
thresholds between quantiles (<code>q1</code>, <code>q2</code>) will be used</p>
</td></tr>
<tr><td><code id=".Joint_MLE_Expl_+3A_k">k</code></td>
<td>
<p>number of thresholds to consider if u not supplied</p>
</td></tr>
<tr><td><code id=".Joint_MLE_Expl_+3A_q1">q1</code></td>
<td>
<p>lower quantile to consider for threshold</p>
</td></tr>
<tr><td><code id=".Joint_MLE_Expl_+3A_q2">q2</code></td>
<td>
<p>upper quantile to consider for threshold</p>
</td></tr>
<tr><td><code id=".Joint_MLE_Expl_+3A_param">param</code></td>
<td>
<p>character specifying <code>'InvRate'</code> or <code>'Rate'</code>
for either inverse rate parameter / rate parameter, respectively</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with
</p>

<ul>
<li><p> mle vector of MLEs above the supplied thresholds
</p>
</li>
<li><p> cov joint asymptotic covariance matrix of these MLEs
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Jennifer L. Wadsworth
</p>

<hr>
<h2 id='.Joint_MLE_NHPP'>Joint maximum likelihood for the non-homogeneous Poisson Process</h2><span id='topic+.Joint_MLE_NHPP'></span>

<h3>Description</h3>

<p>Calculates the MLEs of the parameters (<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>), and joint
asymptotic covariance matrix of these MLEs over a range of thresholds as supplied by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.Joint_MLE_NHPP(x, u = NULL, k, q1, q2 = 1, par, M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".Joint_MLE_NHPP_+3A_x">x</code></td>
<td>
<p>vector of data</p>
</td></tr>
<tr><td><code id=".Joint_MLE_NHPP_+3A_u">u</code></td>
<td>
<p>optional vector of thresholds. If not supplied, then k thresholds between quantiles (q1, q2) will be used</p>
</td></tr>
<tr><td><code id=".Joint_MLE_NHPP_+3A_k">k</code></td>
<td>
<p>number of thresholds to consider if <code>u</code> not supplied</p>
</td></tr>
<tr><td><code id=".Joint_MLE_NHPP_+3A_q1">q1</code></td>
<td>
<p>lower  quantile to consider for threshold</p>
</td></tr>
<tr><td><code id=".Joint_MLE_NHPP_+3A_q2">q2</code></td>
<td>
<p>upper quantile to consider for threshold. Default to 1</p>
</td></tr>
<tr><td><code id=".Joint_MLE_NHPP_+3A_par">par</code></td>
<td>
<p>starting values for the optimization</p>
</td></tr>
<tr><td><code id=".Joint_MLE_NHPP_+3A_m">M</code></td>
<td>
<p>number of superpositions or 'blocks' / 'years' the process corresponds to.
It affects the estimation of <code class="reqn">mu</code> and <code class="reqn">sigma</code>,
but these can be changed post-hoc to correspond to any number)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with components
</p>

<ul>
<li><p> mle matrix of MLEs above the supplied thresholds; columns are (<code class="reqn">\mu</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>)
</p>
</li>
<li><p> Cov.all joint asymptotic covariance matrix of all MLEs
</p>
</li>
<li><p> Cov.mu joint asymptotic covariance matrix of MLEs for <code class="reqn">\mu</code>
</p>
</li>
<li><p> Cov.sig joint asymptotic covariance matrix of MLEs for <code class="reqn">\sigma</code>
</p>
</li>
<li><p> Cov.xi joint asymptotic covariance matrix of MLEs for <code class="reqn">\xi</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Jennifer L. Wadsworth
</p>

<hr>
<h2 id='.mvasym.check'>Internal function</h2><span id='topic+.mvasym.check'></span>

<h3>Description</h3>

<p>Takes a list of asymmetry parameters with an associated dependence vector and returns
the corresponding asymmetry matrix for the asymmetric logistic and asymmetric negative logistic models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.mvasym.check(asy, dep, d, model = c("alog", "aneglog", "maxlin"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".mvasym.check_+3A_asy">asy</code></td>
<td>
<p>a list of <code class="reqn">2^d-1</code> asymmetry components, as in Stephenson bvevd functions</p>
</td></tr>
<tr><td><code id=".mvasym.check_+3A_dep">dep</code></td>
<td>
<p>vector of <code class="reqn">2^d-d-1</code> values for the dependence parameter</p>
</td></tr>
<tr><td><code id=".mvasym.check_+3A_d">d</code></td>
<td>
<p>dimension of the model</p>
</td></tr>
<tr><td><code id=".mvasym.check_+3A_model">model</code></td>
<td>
<p>either <code>alog</code> for the asymmetric logistic or <code>aneglog</code>
for the asymmetric negative logistic</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is extracted from the evd package and modified
(C) Alec Stephenson
</p>


<h3>Value</h3>

<p>a matrix of asymmetry components, enumerating all possible <code class="reqn">2^d-1</code> subsets of
the power set
</p>

<hr>
<h2 id='.mvrnorm_arma'>Multivariate Normal distribution sampler (Rcpp version), derived using the eigendecomposition
of the covariance matrix Sigma. The function utilizes the arma random normal generator</h2><span id='topic+.mvrnorm_arma'></span>

<h3>Description</h3>

<p>Multivariate Normal distribution sampler (Rcpp version), derived using the eigendecomposition
of the covariance matrix Sigma. The function utilizes the arma random normal generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.mvrnorm_arma(n, Mu, Xmat, eigen = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".mvrnorm_arma_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".mvrnorm_arma_+3A_mu">Mu</code></td>
<td>
<p>mean vector. Will set the dimension</p>
</td></tr>
<tr><td><code id=".mvrnorm_arma_+3A_xmat">Xmat</code></td>
<td>
<p>covariance matrix, of same dimension as <code>Mu</code> (and square matrix).
No sanity check is performed to validate that the matrix is symmetric, so use at own risk</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> sample from a multivariate Normal distribution
</p>

<hr>
<h2 id='.rbilogspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the bilogistic model</h2><span id='topic+.rbilogspec'></span>

<h3>Description</h3>

<p>Simulation algorithm of Boldi (2009) for the bilogistic model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rbilogspec(n, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rbilogspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rbilogspec_+3A_alpha">alpha</code></td>
<td>
<p>vector of parameter of dimension <code>d</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>References</h3>

<p>Boldi (2009). A note on the representation of parametric models
for multivariate extremes. <em>Extremes</em> <b>12</b>, 211&ndash;218.
</p>

<hr>
<h2 id='.rbrspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Brown-Resnick model</h2><span id='topic+.rbrspec'></span>

<h3>Description</h3>

<p>Simulation algorithm of Dombry et al. (2015)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rbrspec(n, Sigma_chol, Sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rbrspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rbrspec_+3A_sigma_chol">Sigma_chol</code></td>
<td>
<p>Cholesky root of <code>Sigma</code></p>
</td></tr>
<tr><td><code id=".rbrspec_+3A_sigma">Sigma</code></td>
<td>
<p><code>d</code>-dimensional covariance matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes,
<em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>

<hr>
<h2 id='.rdirmixspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Dirichlet mixture model</h2><span id='topic+.rdirmixspec'></span>

<h3>Description</h3>

<p>Simulation algorithm of Dombry et al. (2015)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rdirmixspec(n, d, alpha, weight)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rdirmixspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rdirmixspec_+3A_d">d</code></td>
<td>
<p>dimension of the 1-sample</p>
</td></tr>
<tr><td><code id=".rdirmixspec_+3A_alpha">alpha</code></td>
<td>
<p>a <code class="reqn">d \times n</code> dimensional vector of positive parameter values for the Dirichlet vector</p>
</td></tr>
<tr><td><code id=".rdirmixspec_+3A_weight">weight</code></td>
<td>
<p>a <code>m</code> vector of mixture weights, which sum to 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>

<hr>
<h2 id='.rdirspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the extremal Dirichlet
model</h2><span id='topic+.rdirspec'></span>

<h3>Description</h3>

<p>This model was introduced in Coles and Tawn (1991); the
present method uses the simulation algorithm of Boldi (2009) for the extremal Dirichlet model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rdirspec(n, d, alpha, irv = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rdirspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rdirspec_+3A_d">d</code></td>
<td>
<p>dimension of sample</p>
</td></tr>
<tr><td><code id=".rdirspec_+3A_alpha">alpha</code></td>
<td>
<p>vector of Dirichlet parameters of dimension <code>d</code>, or <code class="reqn">d+1</code> vector with the <code>d</code> Dirichlet parameters and an index of regular variation in <code class="reqn">[0, 1]</code></p>
</td></tr>
<tr><td><code id=".rdirspec_+3A_irv">irv</code></td>
<td>
<p>should the usual model (<code>FALSE</code>) or the general scaled version (<code>TRUE</code>) be used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>References</h3>

<p>Boldi (2009). A note on the representation of parametric models
for multivariate extremes. <em>Extremes</em> <b>12</b>, 211&ndash;218.
</p>

<hr>
<h2 id='.rexstudspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the extremal Student model</h2><span id='topic+.rexstudspec'></span>

<h3>Description</h3>

<p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the extremal Student model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rexstudspec(n, sigma, al)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rexstudspec_+3A_sigma">sigma</code></td>
<td>
<p>a positive semi-definite covariance matrix with unit variance</p>
</td></tr>
<tr><td><code id=".rexstudspec_+3A_al">al</code></td>
<td>
<p>the alpha parameter in Proposition 7. Corresponds to degrees of freedom - 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>

<hr>
<h2 id='.rhrspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Husler-Reiss model</h2><span id='topic+.rhrspec'></span>

<h3>Description</h3>

<p>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Husler-Reiss model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rhrspec(n, Lambda)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rhrspec_+3A_lambda">Lambda</code></td>
<td>
<p>an symmetric square matrix of coefficients <code class="reqn">\lambda^2</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>

<hr>
<h2 id='.rlogspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the logistic model</h2><span id='topic+.rlogspec'></span>

<h3>Description</h3>

<p>Simulation algorithm of Dombry et al. (2015)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rlogspec(n, d, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rlogspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rlogspec_+3A_theta">theta</code></td>
<td>
<p>a one-dimensional parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes,
<em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>

<hr>
<h2 id='.rmevA1'>Multivariate extreme value distribution sampling algorithm via angular measure</h2><span id='topic+.rmevA1'></span>

<h3>Description</h3>

<p>This algorithm corresponds to Algorithm 1 in Dombry, Engelke and Oesting (2016),
using the formulation of the Dirichlet mixture of Coles and Tawn (1991)
as described and derived in Boldi (2009) for the bilogistic and extremal
Dirichlet model. Models currently implemented include logistic, negative
logistic, extremal Dirichlet and bilogistic MEV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rmevA1(n, d, par, model, Sigma, loc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rmevA1_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rmevA1_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate distribution</p>
</td></tr>
<tr><td><code id=".rmevA1_+3A_par">par</code></td>
<td>
<p>a vector of parameters</p>
</td></tr>
<tr><td><code id=".rmevA1_+3A_model">model</code></td>
<td>
<p>integer, currently ranging from 1 to 9, corresponding respectively to
(1) <code>log</code>, (2) <code>neglog</code>, (3) <code>dirmix</code>, (4) <code>bilog</code>,
(5) <code>extstud</code>, (6) <code>br</code>, (7) <code>ct</code> and <code>sdir</code>, (8) <code>smith</code> and (9) <code>hr</code>.</p>
</td></tr>
<tr><td><code id=".rmevA1_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick, Smith and extremal student. Conditionally negative definite
matrix of parameters for the Huesler&ndash;Reiss model. Default matrix for compatibility</p>
</td></tr>
<tr><td><code id=".rmevA1_+3A_loc">loc</code></td>
<td>
<p>matrix of location for Smith model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>n</code> by <code>d</code> matrix containing the sample
</p>

<hr>
<h2 id='.rmevA2'>Multivariate extreme value distribution sampling algorithm via extremal functions</h2><span id='topic+.rmevA2'></span>

<h3>Description</h3>

<p>Code implementing Algorithm 2 in Dombry, Engelke and Oesting (2016)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rmevA2(n, d, par, model, Sigma, loc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rmevA2_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rmevA2_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate distribution</p>
</td></tr>
<tr><td><code id=".rmevA2_+3A_par">par</code></td>
<td>
<p>a vector of parameters</p>
</td></tr>
<tr><td><code id=".rmevA2_+3A_model">model</code></td>
<td>
<p>integer, currently ranging from 1 to 9, corresponding respectively to
(1) <code>log</code>, (2) <code>neglog</code>, (3) <code>dirmix</code>, (4) <code>bilog</code>,
(5) <code>extstud</code>, (6) <code>br</code>, (7) <code>ct</code> and <code>sdir</code>, (8) <code>smith</code> and (9) <code>hr</code>.</p>
</td></tr>
<tr><td><code id=".rmevA2_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick, Smith and extremal student. Default for compatibility</p>
</td></tr>
<tr><td><code id=".rmevA2_+3A_loc">loc</code></td>
<td>
<p>matrix of location for Smith model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>n</code> by <code>d</code> matrix containing the sample
</p>

<hr>
<h2 id='.rmevasy'>Random samples from asymmetric logistic distribution</h2><span id='topic+.rmevasy'></span>

<h3>Description</h3>

<p>Simulation algorithm of Stephenson (2003), using exact-samples from the logistic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rmevasy(n, d, par, asym, ncompo, Sigma, model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rmevasy_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rmevasy_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate distribution</p>
</td></tr>
<tr><td><code id=".rmevasy_+3A_par">par</code></td>
<td>
<p>a vector of parameters</p>
</td></tr>
<tr><td><code id=".rmevasy_+3A_asym">asym</code></td>
<td>
<p>matrix of bool indicating which component belong to the corresponding row logistic model</p>
</td></tr>
<tr><td><code id=".rmevasy_+3A_ncompo">ncompo</code></td>
<td>
<p>number of components for the (negative) logistic in row</p>
</td></tr>
<tr><td><code id=".rmevasy_+3A_sigma">Sigma</code></td>
<td>
<p>matrix of asymmetry parameters</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>n</code> by <code>d</code> matrix containing the sample
</p>


<h3>References</h3>

<p>Stephenson, A. G. (2003) Simulating multivariate extreme value distributions of logistic type.
<em>Extremes</em>, <b>6</b>(1), 49&ndash;60.
</p>
<p>Joe, H. (1990). Families of min-stable multivariate exponential and multivariate
extreme value distributions, <b>9</b>, 75&ndash;81.
</p>

<hr>
<h2 id='.rmevspec_cpp'>Random sampling from spectral distribution on l1 sphere</h2><span id='topic+.rmevspec_cpp'></span>

<h3>Description</h3>

<p>Generate from <code class="reqn">Q_i</code>, the spectral measure of a given multivariate extreme value model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rmevspec_cpp(n, d, par, model, Sigma, loc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rmevspec_cpp_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rmevspec_cpp_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate distribution</p>
</td></tr>
<tr><td><code id=".rmevspec_cpp_+3A_par">par</code></td>
<td>
<p>a vector of parameters</p>
</td></tr>
<tr><td><code id=".rmevspec_cpp_+3A_model">model</code></td>
<td>
<p>integer, currently ranging from 1 to 9, corresponding respectively to
(1) <code>log</code>, (2) <code>neglog</code>, (3) <code>dirmix</code>, (4) <code>bilog</code>,
(5) <code>extstud</code>, (6) <code>br</code>, (7) <code>ct</code> and <code>sdir</code>, (8) <code>smith</code> and (9) <code>hr</code>.</p>
</td></tr>
<tr><td><code id=".rmevspec_cpp_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick and extremal student, symmetric matrix
of squared coefficients <code class="reqn">\lambda^2</code> for Husler-Reiss. Default for compatibility</p>
</td></tr>
<tr><td><code id=".rmevspec_cpp_+3A_loc">loc</code></td>
<td>
<p>matrix of locations for the Smith model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>n</code> by <code>d</code> matrix containing the sample
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes,
<em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>
<p>Boldi (2009). A note on the representation of parametric models for multivariate extremes. <em>Extremes</em> <b>12</b>, 211&ndash;218.
</p>

<hr>
<h2 id='.rneglogspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the negative logistic model</h2><span id='topic+.rneglogspec'></span>

<h3>Description</h3>

<p>Simulation algorithm of Dombry et al. (2016)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rneglogspec(n, d, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rneglogspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rneglogspec_+3A_theta">theta</code></td>
<td>
<p>a one-dimensional parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes,
<em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>

<hr>
<h2 id='.rpairbetaspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the pairwise Beta model</h2><span id='topic+.rpairbetaspec'></span>

<h3>Description</h3>

<p>This model was introduced in Cooley, Davis and Naveau (2010).
The sample is drawn from a mixture and the algorithm follows from the proof of Theorem 1 in Ballani and Schlather (2011)
and is written in full in Algorithm 1 of Sabourin et al. (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rpairbetaspec(n, d, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rpairbetaspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rpairbetaspec_+3A_alpha">alpha</code></td>
<td>
<p>concentration parameter</p>
</td></tr>
<tr><td><code id=".rpairbetaspec_+3A_beta">beta</code></td>
<td>
<p>vector of all pairwise component (lexicographic order, by row)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of samples from the angular distribution
</p>
<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Cooley, D., R.A. Davis and P. Naveau (2010). The pairwise beta distribution: A flexible parametric multivariate model for extremes, <em>Journal of Multivariate Analysis</em>, <b>101</b>(9), 2103&ndash;2117.
</p>
<p>Ballani, D. and M. Schlather (2011). A construction principle for multivariate extreme value distributions, <em>Biometrika</em>, <b>98</b>(3), 633&ndash;645.
</p>
<p>Sabourin, A., P. Naveau and A. Fougeres (2013). Bayesian model averaging for extremes, <em>Extremes</em>, <b>16</b>, 325&ndash;350.
</p>

<hr>
<h2 id='.rpairexpspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the pairwise exponential model</h2><span id='topic+.rpairexpspec'></span>

<h3>Description</h3>

<p>The sample is drawn from a mixture and the algorithm follows from the proof of Theorem 1 in Ballani and Schlather (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rpairexpspec(n, d, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rpairexpspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rpairexpspec_+3A_alpha">alpha</code></td>
<td>
<p>concentration parameter</p>
</td></tr>
<tr><td><code id=".rpairexpspec_+3A_beta">beta</code></td>
<td>
<p>vector of all pairwise component (lexicographic order, by row)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of samples from the angular distribution
</p>
<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Ballani, D. and M. Schlather (2011). A construction principle for multivariate extreme value distributions, <em>Biometrika</em>, <b>98</b>(3), 633&ndash;645.
</p>

<hr>
<h2 id='.rPbilog'>Generate from bilogistic <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is the probability of extremal functions</h2><span id='topic+.rPbilog'></span>

<h3>Description</h3>

<p>Generate from bilogistic <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is the probability of extremal functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPbilog(d, index, alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPbilog_+3A_d">d</code></td>
<td>
<p>dimension of the 1-sample</p>
</td></tr>
<tr><td><code id=".rPbilog_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPbilog_+3A_alpha">alpha</code></td>
<td>
<p>a <code class="reqn">d</code> dimensional vector of positive parameter values for the Dirichlet vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPBrownResnick'>Generate from Brown-Resnick process <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function</h2><span id='topic+.rPBrownResnick'></span>

<h3>Description</h3>

<p>Generate from Brown-Resnick process <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPBrownResnick(index, Sigma_chol, Sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPBrownResnick_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPBrownResnick_+3A_sigma">Sigma</code></td>
<td>
<p>a positive definite covariance matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPdir'>Generate from extremal Dirichlet <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is the probability of extremal functions from the Dirichlet model of
Coles and Tawn.</h2><span id='topic+.rPdir'></span>

<h3>Description</h3>

<p>Note: we generate from the Dirichlet rather than the Gamma distribution, since the former is parallelized
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPdir(d, index, alpha, irv = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPdir_+3A_d">d</code></td>
<td>
<p>dimension of the 1-sample</p>
</td></tr>
<tr><td><code id=".rPdir_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPdir_+3A_alpha">alpha</code></td>
<td>
<p>a <code class="reqn">d</code> dimensional vector of positive parameter values for the Dirichlet vector, or
<code class="reqn">d+1</code> if the last entry is the index of regular variation of the model, a constant in <code>(0, 1]</code></p>
</td></tr>
<tr><td><code id=".rPdir_+3A_irv">irv</code></td>
<td>
<p>should the usual model (<code>FALSE</code>) or the general scaled version (<code>TRUE</code>) be used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPdirmix'>Generate from extremal Dirichlet <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is the probability of extremal functions from a Dirichlet mixture</h2><span id='topic+.rPdirmix'></span>

<h3>Description</h3>

<p>Generate from extremal Dirichlet <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is the probability of extremal functions from a Dirichlet mixture
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPdirmix(d, index, alpha, weight)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPdirmix_+3A_d">d</code></td>
<td>
<p>dimension of the 1-sample</p>
</td></tr>
<tr><td><code id=".rPdirmix_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPdirmix_+3A_alpha">alpha</code></td>
<td>
<p>a <code class="reqn">d \times n</code> dimensional vector of positive parameter values for the Dirichlet vector</p>
</td></tr>
<tr><td><code id=".rPdirmix_+3A_weight">weight</code></td>
<td>
<p>a <code>m</code> vector of mixture weights, which sum to 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPexstud'>Generate from extremal Student-t <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function</h2><span id='topic+.rPexstud'></span>

<h3>Description</h3>

<p>Generate from extremal Student-t <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPexstud(index, cholesky, sigma, al)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPexstud_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPexstud_+3A_cholesky">cholesky</code></td>
<td>
<p>Cholesky root of transformed correlation matrix</p>
</td></tr>
<tr><td><code id=".rPexstud_+3A_sigma">sigma</code></td>
<td>
<p>a positive semi-definite correlation matrix</p>
</td></tr>
<tr><td><code id=".rPexstud_+3A_al">al</code></td>
<td>
<p>the alpha parameter in Proposition 7. Corresponds to degrees of freedom - 1</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPHuslerReiss'>Generate from extremal Husler-Reiss distribution <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function</h2><span id='topic+.rPHuslerReiss'></span>

<h3>Description</h3>

<p>Generate from extremal Husler-Reiss distribution <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPHuslerReiss(index, cholesky, Sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPHuslerReiss_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPHuslerReiss_+3A_cholesky">cholesky</code></td>
<td>
<p>the Cholesky root of <code>Sigma</code></p>
</td></tr>
<tr><td><code id=".rPHuslerReiss_+3A_sigma">Sigma</code></td>
<td>
<p>a covariance matrix formed from the symmetric square matrix of coefficients <code class="reqn">\lambda^2</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPlog'>Generate from logistic <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function scaled by a Frechet variate</h2><span id='topic+.rPlog'></span>

<h3>Description</h3>

<p>Generate from logistic <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function scaled by a Frechet variate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPlog(d, index, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPlog_+3A_d">d</code></td>
<td>
<p>dimension of the 1-sample</p>
</td></tr>
<tr><td><code id=".rPlog_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPlog_+3A_theta">theta</code></td>
<td>
<p>a one-dimensional parameter for the logistic model, strictly greater than 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPneglog'>Generate from negative logistic <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function scaled by a Frechet variate</h2><span id='topic+.rPneglog'></span>

<h3>Description</h3>

<p>Generate from negative logistic <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function scaled by a Frechet variate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPneglog(d, index, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPneglog_+3A_d">d</code></td>
<td>
<p>dimension of the 1-sample</p>
</td></tr>
<tr><td><code id=".rPneglog_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPneglog_+3A_theta">theta</code></td>
<td>
<p>a one-dimensional parameter for the negative logistic model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rPsite'>Samples from exceedances at site (scaled extremal function definition)</h2><span id='topic+.rPsite'></span>

<h3>Description</h3>

<p>Samples from exceedances at site (scaled extremal function definition)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPsite(n, j, d, par, model, Sigma, loc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPsite_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rPsite_+3A_j">j</code></td>
<td>
<p>index of the site or variable</p>
</td></tr>
<tr><td><code id=".rPsite_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate distribution</p>
</td></tr>
<tr><td><code id=".rPsite_+3A_par">par</code></td>
<td>
<p>a vector of parameters</p>
</td></tr>
<tr><td><code id=".rPsite_+3A_model">model</code></td>
<td>
<p>integer, currently ranging from 1 to 9, corresponding respectively to
(1) <code>log</code>, (2) <code>neglog</code>, (3) <code>dirmix</code>, (4) <code>bilog</code>,
(5) <code>extstud</code>, (6) <code>br</code>, (7) <code>ct</code> and <code>sdir</code>, (8) <code>smith</code> and (9) <code>hr</code>.</p>
</td></tr>
<tr><td><code id=".rPsite_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick, Smith and extremal student. Default for compatibility</p>
</td></tr>
<tr><td><code id=".rPsite_+3A_loc">loc</code></td>
<td>
<p>matrix of location for Smith model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>n</code> by <code>d</code> matrix containing the sample
</p>

<hr>
<h2 id='.rPSmith'>Generate from Smith model (moving maxima) <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function</h2><span id='topic+.rPSmith'></span>

<h3>Description</h3>

<p>Generate from Smith model (moving maxima) <code class="reqn">Y \sim {P_x}</code>, where
<code class="reqn">P_{x}</code> is probability of extremal function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rPSmith(index, Sigma_chol, loc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rPSmith_+3A_index">index</code></td>
<td>
<p>index of the location. An integer in 0, ..., <code class="reqn">d-1</code></p>
</td></tr>
<tr><td><code id=".rPSmith_+3A_sigma_chol">Sigma_chol</code></td>
<td>
<p>the Cholesky root of the covariance matrix</p>
</td></tr>
<tr><td><code id=".rPSmith_+3A_loc">loc</code></td>
<td>
<p>location matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code>-vector from <code class="reqn">P_x</code>
</p>

<hr>
<h2 id='.rsmithspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the Smith model (moving maxima)</h2><span id='topic+.rsmithspec'></span>

<h3>Description</h3>

<p>Simulation algorithm of Dombry et al. (2015)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rsmithspec(n, Sigma_chol, loc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rsmithspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rsmithspec_+3A_sigma_chol">Sigma_chol</code></td>
<td>
<p>Cholesky decomposition of the <code>d</code>-dimensional covariance matrix (upper triangular)</p>
</td></tr>
<tr><td><code id=".rsmithspec_+3A_loc">loc</code></td>
<td>
<p>location matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes,
<em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>

<hr>
<h2 id='.rwdirbsspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the weighted Dirichlet model</h2><span id='topic+.rwdirbsspec'></span>

<h3>Description</h3>

<p>This model was introduced in Ballani and Schlather (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rwdirbsspec(n, d, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rwdirbsspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rwdirbsspec_+3A_alpha">alpha</code></td>
<td>
<p>vector of concentration parameters</p>
</td></tr>
<tr><td><code id=".rwdirbsspec_+3A_beta">beta</code></td>
<td>
<p>vector of Dirichlet components</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of samples from the angular distribution
</p>
<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Ballani, D. and M. Schlather (2011). A construction principle for multivariate extreme value distributions, <em>Biometrika</em>, <b>98</b>(3), 633&ndash;645.
</p>

<hr>
<h2 id='.rwexpbsspec'>Generates from <code class="reqn">Q_i</code>, the spectral measure of the weighted exponential model</h2><span id='topic+.rwexpbsspec'></span>

<h3>Description</h3>

<p>This model was introduced in Ballani and Schlather (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.rwexpbsspec(n, d, alpha, beta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".rwexpbsspec_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id=".rwexpbsspec_+3A_alpha">alpha</code></td>
<td>
<p>vector of concentration parameters</p>
</td></tr>
<tr><td><code id=".rwexpbsspec_+3A_beta">beta</code></td>
<td>
<p>vector of Dirichlet components</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of samples from the angular distribution
</p>
<p>an <code>n</code> by <code>d</code> sample from the spectral distribution
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Ballani, D. and M. Schlather (2011). A construction principle for multivariate extreme value distributions, <em>Biometrika</em>, <b>98</b>(3), 633&ndash;645.
</p>

<hr>
<h2 id='.score_algebraic'>Algebraic score</h2><span id='topic+.score_algebraic'></span>

<h3>Description</h3>

<p>Algebraic score
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.score_algebraic(y, x, w, v, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".score_algebraic_+3A_y">y</code></td>
<td>
<p>vector of excesses of lowest threshold <code>u1</code></p>
</td></tr>
<tr><td><code id=".score_algebraic_+3A_x">x</code></td>
<td>
<p>parameter vector (<code>sigma1</code>, <code>phi_1</code>, ..., <code>phi_m</code>)</p>
</td></tr>
<tr><td><code id=".score_algebraic_+3A_w">w</code></td>
<td>
<p>differences between thresholds (<code>w[m]</code> not used)</p>
</td></tr>
<tr><td><code id=".score_algebraic_+3A_v">v</code></td>
<td>
<p>thresholds relative to lowest threshold</p>
</td></tr>
<tr><td><code id=".score_algebraic_+3A_m">m</code></td>
<td>
<p>number of thresholds</p>
</td></tr>
</table>

<hr>
<h2 id='.wecdf'>Weighted empirical distribution function</h2><span id='topic+.wecdf'></span>

<h3>Description</h3>

<p>Compute an empirical distribution function with weights <code>w</code> at each of <code>x</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.wecdf(x, w)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id=".wecdf_+3A_x">x</code></td>
<td>
<p>observations</p>
</td></tr>
<tr><td><code id=".wecdf_+3A_w">w</code></td>
<td>
<p>weights</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a function of class <code>ecdf</code>
</p>

<hr>
<h2 id='abisko'>Abisko rainfall</h2><span id='topic+abisko'></span>

<h3>Description</h3>

<p>Daily non-zero rainfall measurements in Abisko (Sweden) from January 1913 until December 2014.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="abisko_+3A_date">date</code></td>
<td>
<p><code>Date</code> of the measurement</p>
</td></tr>
<tr><td><code id="abisko_+3A_precip">precip</code></td>
<td>
<p>rainfall amount (in mm)</p>
</td></tr>
</table>


<h3>Format</h3>

<p>a data frame with 15132 rows and two variables
</p>


<h3>Source</h3>

<p>Abisko Scientific Research Station
</p>


<h3>References</h3>

<p>A. Kiriliouk, H. Rootzen, J. Segers and J.L. Wadsworth (2019), <em>Peaks over thresholds modeling with multivariate generalized Pareto distributions</em>,  Technometrics, <b>61</b>(1), 123&ndash;135, &lt;doi:10.1080/00401706.2018.1462738&gt;
</p>

<hr>
<h2 id='angextrapo'>Bivariate angular dependence function for extrapolation based on rays</h2><span id='topic+angextrapo'></span>

<h3>Description</h3>

<p>The scale parameter <code class="reqn">g(w)</code> in the Ledford and Tawn approach is estimated empirically for
<code class="reqn">x</code> large as </p>
<p style="text-align: center;"><code class="reqn">\frac{\Pr(X_P&gt;xw, Y_P&gt;x(1-w))}{\Pr(X_P&gt;x, Y_P&gt;x)}</code>
</p>

<p>where the sample (<code class="reqn">X_P, Y_P</code>) are observations on a common unit Pareto scale.
The coefficient <code class="reqn">\eta</code> is estimated using maximum likelihood as the
shape parameter of a generalized Pareto distribution on <code class="reqn">\min(X_P, Y_P)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angextrapo(dat, qu = 0.95, w = seq(0.05, 0.95, length = 20))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="angextrapo_+3A_dat">dat</code></td>
<td>
<p>an <code class="reqn">n</code> by <code class="reqn">2</code> matrix of multivariate observations</p>
</td></tr>
<tr><td><code id="angextrapo_+3A_qu">qu</code></td>
<td>
<p>quantile level on uniform scale at which to threshold data. Default to 0.95</p>
</td></tr>
<tr><td><code id="angextrapo_+3A_w">w</code></td>
<td>
<p>vector of unique angles between 0 and 1 at which to evaluate scale empirically.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements
</p>

<ul>
<li> <p><code>w</code>: angles between zero and one
</p>
</li>
<li> <p><code>g</code>: scale function at a given value of <code>w</code>
</p>
</li>
<li> <p><code>eta</code>: Ledford and Tawn tail dependence coefficient
</p>
</li></ul>



<h3>References</h3>

<p>Ledford, A.W. and J. A. Tawn (1996), Statistics for near independence in multivariate extreme values. <em>Biometrika</em>, <b>83</b>(1), 169&ndash;187.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>angextrapo(rmev(n = 1000, model = 'log', d = 2, param = 0.5))
</code></pre>

<hr>
<h2 id='angmeas'>Rank-based transformation to angular measure</h2><span id='topic+angmeas'></span>

<h3>Description</h3>

<p>The method uses the pseudo-polar transformation for suitable norms, transforming
the data to pseudo-observations, than marginally to unit Frechet or unit Pareto.
Empirical or Euclidean weights are computed and returned alongside with the angular and
radial sample for values above threshold(s) <code>th</code>, specified in terms of quantiles
of the radial component <code>R</code> or marginal quantiles. Only complete tuples are kept.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angmeas(
  x,
  th,
  Rnorm = c("l1", "l2", "linf"),
  Anorm = c("l1", "l2", "linf", "arctan"),
  marg = c("Frechet", "Pareto"),
  wgt = c("Empirical", "Euclidean"),
  region = c("sum", "min", "max"),
  is.angle = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="angmeas_+3A_x">x</code></td>
<td>
<p>an <code>n</code> by <code>d</code> sample matrix</p>
</td></tr>
<tr><td><code id="angmeas_+3A_th">th</code></td>
<td>
<p>threshold of length 1 for <code>'sum'</code>, or <code>d</code> marginal thresholds otherwise.</p>
</td></tr>
<tr><td><code id="angmeas_+3A_rnorm">Rnorm</code></td>
<td>
<p>character string indicating the norm for the radial component.</p>
</td></tr>
<tr><td><code id="angmeas_+3A_anorm">Anorm</code></td>
<td>
<p>character string indicating the norm for the angular component. <code>arctan</code> is only implemented for <code class="reqn">d=2</code></p>
</td></tr>
<tr><td><code id="angmeas_+3A_marg">marg</code></td>
<td>
<p>character string indicating choice of marginal transformation, either to Frechet or Pareto scale</p>
</td></tr>
<tr><td><code id="angmeas_+3A_wgt">wgt</code></td>
<td>
<p>character string indicating weighting function for the equation. Can be based on Euclidean or empirical likelihood for the mean</p>
</td></tr>
<tr><td><code id="angmeas_+3A_region">region</code></td>
<td>
<p>character string specifying which observations to consider (and weight). <code>'sum'</code> corresponds to a radial threshold
<code class="reqn">\sum x_i &gt; </code><code>th</code>, <code>'min'</code> to <code class="reqn">\min x_i &gt;</code><code>th</code> and <code>'max'</code> to <code class="reqn">\max x_i &gt;</code><code>th</code>.</p>
</td></tr>
<tr><td><code id="angmeas_+3A_is.angle">is.angle</code></td>
<td>
<p>logical indicating whether observations are already angle with respect to <code>region</code>. Default to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical likelihood weighted mean problem is implemented for all thresholds,
while the Euclidean likelihood is only supported for diagonal thresholds specified
via <code>region=sum</code>.
</p>


<h3>Value</h3>

<p>a list with arguments <code>ang</code> for the <code class="reqn">d-1</code> pseudo-angular sample, <code>rad</code> with the radial component
and possibly <code>wts</code> if <code>Rnorm='l1'</code> and the empirical likelihood algorithm converged. The Euclidean algorithm always returns weights even if some of these are negative.
</p>
<p>a list with components
</p>

<ul>
<li> <p><code>ang</code> matrix of pseudo-angular observations
</p>
</li>
<li> <p><code>rad</code> vector of radial contributions
</p>
</li>
<li> <p><code>wts</code> empirical or Euclidean likelihood weights for angular observations
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Einmahl, J.H.J. and J. Segers (2009). Maximum empirical likelihood estimation of the spectral measure of an extreme-value distribution, <em>Annals of Statistics</em>, <b>37</b>(5B), 2953&ndash;2989.
</p>
<p>de Carvalho, M. and B. Oumow and J. Segers and M. Warchol (2013). A Euclidean likelihood estimator for bivariate tail dependence, <em>Comm. Statist. Theory Methods</em>, <b>42</b>(7), 1176&ndash;1192.
</p>
<p>Owen, A.B. (2001). <em>Empirical Likelihood</em>, CRC Press, 304p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rmev(n=25, d=3, param=0.5, model='log')
wts &lt;- angmeas(x=x, th=0, Rnorm='l1', Anorm='l1', marg='Frechet', wgt='Empirical')
wts2 &lt;- angmeas(x=x, Rnorm='l2', Anorm='l2', marg='Pareto', th=0)
</code></pre>

<hr>
<h2 id='angmeasdir'>Dirichlet mixture smoothing of the angular measure</h2><span id='topic+angmeasdir'></span>

<h3>Description</h3>

<p>This function computes the empirical or Euclidean likelihood
estimates of the spectral measure and uses the points returned from a call to <code>angmeas</code> to compute the Dirichlet
mixture smoothing of de Carvalho, Warchol and Segers (2012), placing a Dirichlet kernel at each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>angmeasdir(
  x,
  th,
  Rnorm = c("l1", "l2", "linf"),
  Anorm = c("l1", "l2", "linf", "arctan"),
  marg = c("Frechet", "Pareto"),
  wgt = c("Empirical", "Euclidean"),
  region = c("sum", "min", "max"),
  is.angle = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="angmeasdir_+3A_x">x</code></td>
<td>
<p>an <code>n</code> by <code>d</code> sample matrix</p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_th">th</code></td>
<td>
<p>threshold of length 1 for <code>'sum'</code>, or <code>d</code> marginal thresholds otherwise.</p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_rnorm">Rnorm</code></td>
<td>
<p>character string indicating the norm for the radial component.</p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_anorm">Anorm</code></td>
<td>
<p>character string indicating the norm for the angular component. <code>arctan</code> is only implemented for <code class="reqn">d=2</code></p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_marg">marg</code></td>
<td>
<p>character string indicating choice of marginal transformation, either to Frechet or Pareto scale</p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_wgt">wgt</code></td>
<td>
<p>character string indicating weighting function for the equation. Can be based on Euclidean or empirical likelihood for the mean</p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_region">region</code></td>
<td>
<p>character string specifying which observations to consider (and weight). <code>'sum'</code> corresponds to a radial threshold
<code class="reqn">\sum x_i &gt; </code><code>th</code>, <code>'min'</code> to <code class="reqn">\min x_i &gt;</code><code>th</code> and <code>'max'</code> to <code class="reqn">\max x_i &gt;</code><code>th</code>.</p>
</td></tr>
<tr><td><code id="angmeasdir_+3A_is.angle">is.angle</code></td>
<td>
<p>logical indicating whether observations are already angle with respect to <code>region</code>. Default to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cross-validation
bandwidth is the solution of
</p>
<p style="text-align: center;"><code class="reqn">\max_{\nu} \sum_{i=1}^n \log \left\{ \sum_{k=1,k \neq i}^n p_{k, -i} f(\mathbf{w}_i; \nu \mathbf{w}_k)\right\},</code>
</p>

<p>where <code class="reqn">f</code> is the density of the Dirichlet distribution, <code class="reqn">p_{k, -i}</code> is the Euclidean weight
obtained from estimating the Euclidean likelihood problem without observation <code class="reqn">i</code>.
</p>


<h3>Value</h3>

<p>an invisible list with components
</p>

<ul>
<li> <p><code>nu</code> bandwidth parameter obtained by cross-validation;
</p>
</li>
<li> <p><code>dirparmat</code> <code>n</code> by <code>d</code> matrix of Dirichlet parameters for the mixtures;
</p>
</li>
<li> <p><code>wts</code> mixture weights.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x &lt;- rmev(n=100, d=2, param=0.5, model='log')
out &lt;- angmeasdir(x=x, th=0, Rnorm='l1', Anorm='l1', marg='Frechet', wgt='Empirical')
</code></pre>

<hr>
<h2 id='automrl'>Automated mean residual life plots</h2><span id='topic+automrl'></span>

<h3>Description</h3>

<p>This function implements the automated proposal from
Section 2.2 of Langousis et al. (2016)
for mean residual life plots. It returns the threshold
that minimize the weighted mean square error and
moment estimators for the scale and shape parameter
based on weighted least squares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>automrl(xdat, kmax, thresh, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="automrl_+3A_xdat">xdat</code></td>
<td>
<p>[numeric] vector of observations</p>
</td></tr>
<tr><td><code id="automrl_+3A_kmax">kmax</code></td>
<td>
<p>[integer] maximum number of order statistics</p>
</td></tr>
<tr><td><code id="automrl_+3A_thresh">thresh</code></td>
<td>
<p>[numeric] vector of thresholds; if missing, uses all order statistics from the 20th largest until <code>kmax</code> as candidates</p>
</td></tr>
<tr><td><code id="automrl_+3A_plot">plot</code></td>
<td>
<p>[logical] if <code>TRUE</code> (default), return a plot of the mean residual life plot with the fitted slope
and the chosen threshold</p>
</td></tr>
<tr><td><code id="automrl_+3A_...">...</code></td>
<td>
<p>additional arguments, currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure consists in estimating the usual
</p>


<h3>Value</h3>

<p>a list containing
</p>

<ul>
<li> <p><code>thresh</code>: selected threshold
</p>
</li>
<li> <p><code>scale</code>: scale parameter estimate
</p>
</li>
<li> <p><code>shape</code>: shape parameter estimate
</p>
</li></ul>



<h3>References</h3>

<p>Langousis, A., A. Mamalakis, M. Puliga and R. Deidda (2016).
<em>Threshold detection for the generalized Pareto distribution:
Review of representative methods and application to the
NOAA NCDC daily rainfall database</em>, Water Resources Research, <strong>52</strong>, 2659&ndash;2681.
</p>

<hr>
<h2 id='chibar'>Parametric estimates of <code class="reqn">\bar{\chi}</code></h2><span id='topic+chibar'></span>

<h3>Description</h3>

<p>The function fits a generalized Pareto distribution to minima of Pareto variates,
using the representation </p>
<p style="text-align: center;"><code class="reqn">\Pr(\min(X) &gt; x) = \frac{L(x)}{x^{1/\eta}},</code>
</p>

<p>where <code class="reqn">\bar{\chi}=2\eta-1</code>. The data are transformed to the unit Pareto scale and
a generalized Pareto variable is fitted to the minimum. The parameter <code class="reqn">\eta</code> corresponds to the shape of the latter.
The confidence intervals can be based either on the delta-method, a profile likelihood or a tangent exponential model approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chibar(dat, confint = c("delta", "profile", "tem"), qu = 0, level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chibar_+3A_dat">dat</code></td>
<td>
<p>an <code class="reqn">n</code> by <code class="reqn">d</code> matrix of multivariate observations</p>
</td></tr>
<tr><td><code id="chibar_+3A_confint">confint</code></td>
<td>
<p>string indicating the type of confidence interval.</p>
</td></tr>
<tr><td><code id="chibar_+3A_qu">qu</code></td>
<td>
<p>percentile level at which to threshold. Default to all observations.</p>
</td></tr>
<tr><td><code id="chibar_+3A_level">level</code></td>
<td>
<p>the confidence level required</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named vector of length 3 containing the point estimate, the lower and the upper confidence intervals
</p>


<h3>See Also</h3>

<p><code><a href="evd.html#topic+chiplot">chiplot</a></code> for empirical estimates of <code class="reqn">\chi</code> and <code class="reqn">\bar{\chi}</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(765)
# Max-stable model, chibar = 1
dat &lt;- rmev(n = 1000, model = "log", d = 2, param = 0.5)
chibar(dat, 'profile', qu = 0.5)
s &lt;- seq(0.05,1, length = 30)
chibar_est &lt;- t(sapply(s, function(keep){chibar(dat, 'delta', qu = keep)}))
matplot(s, chibar_est, type = 'l', col = c(1, 2, 2),  lty = c(1, 2, 2),
 ylab = expression(bar(chi)), xlab = 'p')
abline(h = 1, lty = 3, col = 'grey')
# Multivariate normal sample, chibar = 0 - strong asymptotic independence at penultimate level
dat &lt;- mvrnorm(n = 1000, mu = c(0, 0), Sigma = cbind(c(1, 0.75), c(0.75, 1)))
chibar(dat, 'tem', q = 0.1)
chibar_est &lt;- t(sapply(s, function(keep){chibar(dat, 'profile', qu = keep)}))
matplot(s, chibar_est, type = 'l', col = c(1, 2, 2),  lty = c(1, 2, 2),
 ylab = expression(bar(chi)), xlab = 'p')
abline(h = 1, lty = 3, col = 'grey')

## End(Not run)
</code></pre>

<hr>
<h2 id='clikmgp'>Censored likelihood for multivariate peaks over threshold models</h2><span id='topic+clikmgp'></span>

<h3>Description</h3>

<p>Censored likelihoods for various parametric limiting models over region determined by
</p>
<p style="text-align: center;"><code class="reqn">\{y \in F: \max_{j=1}^D \sigma_j \frac{y^\xi_j-1}{\xi_j}+\mu_j  &gt; u\};</code>
</p>

<p>where <code class="reqn">\mu</code> is <code>loc</code>, <code class="reqn">\sigma</code> is <code>scale</code> and <code class="reqn">\xi</code> is <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clikmgp(
  dat,
  thresh,
  mthresh = thresh,
  loc,
  scale,
  shape,
  par,
  model = c("log", "neglog", "br", "xstud"),
  likt = c("mgp", "pois", "binom"),
  lambdau = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clikmgp_+3A_dat">dat</code></td>
<td>
<p>matrix of observations</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_thresh">thresh</code></td>
<td>
<p>functional threshold for the maximum</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_mthresh">mthresh</code></td>
<td>
<p>vector of individuals thresholds under which observations are censored</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_loc">loc</code></td>
<td>
<p>vector of location parameter for the marginal generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_scale">scale</code></td>
<td>
<p>vector of scale parameter for the marginal generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_shape">shape</code></td>
<td>
<p>vector of shape parameter for the marginal generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_par">par</code></td>
<td>
<p>list of parameters: <code>alpha</code> for the logistic model, <code>Lambda</code> for the Brown&ndash;Resnick model or else <code>Sigma</code> and <code>df</code> for the extremal Student.</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_model">model</code></td>
<td>
<p>string indicating the model family, one of <code>"log"</code>, <code>"neglog"</code>, <code>"br"</code> or <code>"xstud"</code></p>
</td></tr>
<tr><td><code id="clikmgp_+3A_likt">likt</code></td>
<td>
<p>string indicating the type of likelihood, with an additional contribution for the non-exceeding components: one of  <code>"mgp"</code>, <code>"binom"</code> and <code>"pois"</code>.</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_lambdau">lambdau</code></td>
<td>
<p>vector of marginal rate of marginal threshold exceedance.</p>
</td></tr>
<tr><td><code id="clikmgp_+3A_...">...</code></td>
<td>
<p>additional arguments (see Details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Optional arguments can be passed to the function via <code>...</code>
</p>

<ul>
<li> <p><code>censored</code> matrix of booleans and <code>NA</code> indicating whether observations <code>dat</code> fall below the mthreshold <code>mthresh</code>
</p>
</li>
<li> <p><code>cl</code> cluster instance  created by <code>makeCluster</code> (default to <code>NULL</code>)
</p>
</li>
<li> <p><code>ncors</code> number of cores for parallel computing of the likelihood
</p>
</li>
<li> <p><code>numAbovePerRow</code> number of observations above mthreshold (non-missing) per row
</p>
</li>
<li> <p><code>numAbovePerCol</code> number of observations above mthreshold (non-missing) per column
</p>
</li>
<li> <p><code>mmax</code> maximum per column
</p>
</li>
<li> <p><code>B1</code> number of replicates for quasi Monte Carlo integral for the exponent measure
</p>
</li>
<li> <p><code>B2</code> number of replicates for quasi Monte Carlo integral for the censored intensity contribution
</p>
</li>
<li> <p><code>genvec1</code> generating vector for the quasi Monte Carlo routine (exponent measure), associated with <code>B1</code>
</p>
</li>
<li> <p><code>genvec2</code> generating vector for the quasi Monte Carlo routine (individual obs contrib), associated with <code>B2</code>
</p>
</li></ul>



<h3>Value</h3>

<p>the value of the log-likelihood with <code>attributes</code> <code>expme</code>, giving the exponent measure
</p>


<h3>Note</h3>

<p>The location and scale parameters are not identifiable unless one of them is fixed.
</p>

<hr>
<h2 id='confint.eprof'>Confidence intervals for profile likelihood objects</h2><span id='topic+confint.eprof'></span>

<h3>Description</h3>

<p>Computes confidence intervals for the parameter psi for profile likelihood objects.
This function uses spline interpolation to derive <code>level</code> confidence intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eprof'
confint(
  object,
  parm,
  level = 0.95,
  prob = c((1 - level)/2, 1 - (1 - level)/2),
  print = FALSE,
  method = c("cobs", "smooth.spline"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.eprof_+3A_object">object</code></td>
<td>
<p>an object of class <code>eprof</code>, normally the output of <a href="#topic+gpd.pll">gpd.pll</a> or <a href="#topic+gev.pll">gev.pll</a>.</p>
</td></tr>
<tr><td><code id="confint.eprof_+3A_parm">parm</code></td>
<td>
<p>a specification of which parameters are to be given confidence intervals,
either a vector of numbers or a vector of names. If missing, all parameters are considered.</p>
</td></tr>
<tr><td><code id="confint.eprof_+3A_level">level</code></td>
<td>
<p>confidence level, with default value of 0.95</p>
</td></tr>
<tr><td><code id="confint.eprof_+3A_prob">prob</code></td>
<td>
<p>percentiles, with default giving symmetric 95% confidence intervals</p>
</td></tr>
<tr><td><code id="confint.eprof_+3A_print">print</code></td>
<td>
<p>should a summary be printed. Default to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="confint.eprof_+3A_method">method</code></td>
<td>
<p>string for the method, either <code>cobs</code> (constrained robust B-spline from eponym package) or <code>smooth.spline</code></p>
</td></tr>
<tr><td><code id="confint.eprof_+3A_...">...</code></td>
<td>
<p>additional arguments passed to functions. Providing a logical <code>warn=FALSE</code> turns off warning messages when the lower or upper confidence interval for <code>psi</code> are extrapolated beyond the provided calculations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a 2 by 3 matrix containing point estimates, lower and upper confidence intervals based on the likelihood root and modified version thereof
</p>

<hr>
<h2 id='cvselect'>Threshold selection via coefficient of variation</h2><span id='topic+cvselect'></span>

<h3>Description</h3>

<p>This function computes the empirical coefficient of variation and
computes a weighted statistic comparing the squared distance with
the theoretical coefficient variation corresponding to a specific
shape parameter (estimated from the data using a moment estimator
as the value minimizing the test statistic, or using maximum likelihood).
The procedure stops if there are no more than 10 exceedances above the
highest threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvselect(
  xdat,
  thresh,
  method = c("mle", "wcv", "cv"),
  nsim = 999L,
  nthresh = 10L,
  level = 0.05,
  lazy = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cvselect_+3A_xdat">xdat</code></td>
<td>
<p>[vector] vector of observations</p>
</td></tr>
<tr><td><code id="cvselect_+3A_thresh">thresh</code></td>
<td>
<p>[vector] vector of threshold. If missing, set to <code class="reqn">p^k</code> for <code class="reqn">k=0</code> to <code class="reqn">k=</code><code>nthresh</code></p>
</td></tr>
<tr><td><code id="cvselect_+3A_method">method</code></td>
<td>
<p>[string], either moment estimator for the (weighted) coefficient of variation (<code>wcv</code> and <code>cv</code>) or maximum likelihood (<code>mle</code>)</p>
</td></tr>
<tr><td><code id="cvselect_+3A_nsim">nsim</code></td>
<td>
<p>[integer] number of bootstrap replications</p>
</td></tr>
<tr><td><code id="cvselect_+3A_nthresh">nthresh</code></td>
<td>
<p>[integer] number of thresholds, if <code>thresh</code> is not supplied by the user</p>
</td></tr>
<tr><td><code id="cvselect_+3A_level">level</code></td>
<td>
<p>[numeric] probability level for sequential testing procedure</p>
</td></tr>
<tr><td><code id="cvselect_+3A_lazy">lazy</code></td>
<td>
<p>[logical] compute the bootstrap p-value until the test stops rejecting at level <code>level</code>? Default to <code>FALSE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements
</p>

<ul>
<li> <p><code>thresh</code>: value of threshold returned by the procedure, <code>NA</code> if the hypothesis is rejected at all thresholds
</p>
</li>
<li> <p><code>cthresh</code>: sorted vector of candidate thresholds
</p>
</li>
<li> <p><code>cindex</code>: index of selected threshold among <code>cthresh</code> or <code>NA</code> if none returned
</p>
</li>
<li> <p><code>pval</code>: bootstrap p-values, with <code>NA</code> if <code>lazy</code> and the p-value exceeds level at lower thresholds
</p>
</li>
<li> <p><code>shape</code>: shape parameter estimates
</p>
</li>
<li> <p><code>nexc</code>: number of exceedances of each threshold <code>cthresh</code>
</p>
</li>
<li> <p><code>method</code>: estimation method for the shape parameter
</p>
</li></ul>



<h3>References</h3>

<p>del Castillo, J. and M. Padilla (2016). <em>Modelling extreme values by the residual coefficient of variation</em>, SORT, 40(<b>2</b>), pp. 303&ndash;320.
</p>

<hr>
<h2 id='distg'>Distance matrix with geometric anisotropy</h2><span id='topic+distg'></span>

<h3>Description</h3>

<p>The function computes the distance between locations, with geometric anisotropy.
The parametrization assumes there is a scale parameter, say <code class="reqn">\sigma</code>, so that <code>scale</code>
is the distortion for the second component only. The angle <code>rho</code> must lie in
<code class="reqn">[-\pi/2, \pi/2]</code>. The dilation and rotation matrix is 
</p>
<p style="text-align: center;"><code class="reqn">\left(\begin{matrix} \cos(\rho) &amp; \sin(\rho) \\ - \sigma\sin(\rho) &amp; \sigma\cos(\rho) \end{matrix} \right)</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>distg(loc, scale, rho)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distg_+3A_loc">loc</code></td>
<td>
<p>a <code>d</code> by 2 matrix of locations giving the coordinates of a site per row.</p>
</td></tr>
<tr><td><code id="distg_+3A_scale">scale</code></td>
<td>
<p>numeric vector of length 1, greater than 1.</p>
</td></tr>
<tr><td><code id="distg_+3A_rho">rho</code></td>
<td>
<p>angle for the anisotropy, must be larger than <code class="reqn">\pi/2</code> in modulus.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>d</code> by <code>d</code> square matrix of pairwise distance
</p>

<hr>
<h2 id='egp'>Extended generalised Pareto families</h2><span id='topic+egp'></span>

<h3>Description</h3>

<p>This function provides the log-likelihood and quantiles for the three different families presented
in Papastathopoulos and Tawn (2013). The latter include an additional parameter, <code class="reqn">\kappa</code>.
All three families share the same tail index as the generalized Pareto distribution, while allowing for lower thresholds.
In the case <code class="reqn">\kappa=1</code>, the models reduce to the generalised Pareto.
</p>
<p><code>egp.retlev</code> gives the return levels for the extended generalised Pareto distributions
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="egp_+3A_xdat">xdat</code></td>
<td>
<p>vector of observations, greater than the threshold</p>
</td></tr>
<tr><td><code id="egp_+3A_thresh">thresh</code></td>
<td>
<p>threshold value</p>
</td></tr>
<tr><td><code id="egp_+3A_par">par</code></td>
<td>
<p>parameter vector (<code class="reqn">\kappa</code>, <code class="reqn">\sigma</code>,<code class="reqn">\xi</code>).</p>
</td></tr>
<tr><td><code id="egp_+3A_model">model</code></td>
<td>
<p>a string indicating which extended family to fit</p>
</td></tr>
<tr><td><code id="egp_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code>, print the results of the optimization</p>
</td></tr>
<tr><td><code id="egp_+3A_p">p</code></td>
<td>
<p>extreme event probability; <code>p</code> must be greater than the rate of exceedance for the calculation to make sense. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="egp_+3A_plot">plot</code></td>
<td>
<p>boolean indicating whether or not to plot the return levels</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For return levels, the <code>p</code> argument can be related to <code class="reqn">T</code> year exceedances as follows:
if there are <code class="reqn">n_y</code> observations per year, than take <code>p</code>
to equal <code class="reqn">1/(Tn_y)</code> to obtain the <code class="reqn">T</code>-years return level.
</p>


<h3>Value</h3>

<p><code>egp.ll</code> returns the log-likelihood value.
</p>
<p><code>egp.retlev</code> returns a plot of the return levels if <code>plot=TRUE</code> and a matrix of return levels.
</p>


<h3>Usage</h3>

<p><code>egp.ll(xdat, thresh, par, model=c('egp1','egp2','egp3'))</code>
</p>
<p><code>egp.retlev(xdat, thresh, par, model=c('egp1','egp2','egp3'), p, plot=TRUE)</code>
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Papastathopoulos, I. and J. Tawn (2013). Extended generalised Pareto models for tail estimation, <em>Journal of Statistical Planning and Inference</em> <b>143</b>(3), 131&ndash;143.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
xdat &lt;- mev::rgp(1000, loc = 0, scale = 2, shape = 0.5)
par &lt;- fit.egp(xdat, thresh = 0, model = 'egp3')$par
p &lt;- c(1/1000, 1/1500, 1/2000)
#With multiple thresholds
th &lt;- c(0, 0.1, 0.2, 1)
opt &lt;- tstab.egp(xdat, th, model = 'egp1')
egp.retlev(xdat, opt$thresh, opt$par, 'egp1', p = p)
opt &lt;- tstab.egp(xdat, th, model = 'egp2', plots = NA)
egp.retlev(xdat, opt$thresh, opt$par, 'egp2', p = p)
opt &lt;- tstab.egp(xdat, th, model = 'egp3', plots = NA)
egp.retlev(xdat, opt$thresh, opt$par, 'egp3', p = p)
</code></pre>

<hr>
<h2 id='egp-function'>Extended generalised Pareto families of Papastathopoulos and Tawn (functions)</h2><span id='topic+egp-function'></span><span id='topic+egp.ll'></span><span id='topic+egp.retlev'></span>

<h3>Description</h3>

<p>This function provides the log-likelihood and quantiles for the three different families presented
in Papastathopoulos and Tawn (2013). The latter include an additional parameter, <code class="reqn">\kappa</code>.
All three families share the same tail index than the GP model, while allowing for lower thresholds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>egp.ll(xdat, thresh, par, model = c("egp1", "egp2", "egp3"))

egp.retlev(
  xdat,
  thresh,
  par,
  model = c("egp1", "egp2", "egp3"),
  p,
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="egp-function_+3A_xdat">xdat</code></td>
<td>
<p>vector of observations, greater than the threshold</p>
</td></tr>
<tr><td><code id="egp-function_+3A_thresh">thresh</code></td>
<td>
<p>threshold value</p>
</td></tr>
<tr><td><code id="egp-function_+3A_par">par</code></td>
<td>
<p>parameter vector (<code class="reqn">\kappa</code>, <code class="reqn">\sigma</code>,<code class="reqn">\xi</code>).</p>
</td></tr>
<tr><td><code id="egp-function_+3A_model">model</code></td>
<td>
<p>a string indicating which extended family to fit</p>
</td></tr>
<tr><td><code id="egp-function_+3A_p">p</code></td>
<td>
<p>extreme event probability; <code>p</code> must be greater than the rate of exceedance for the calculation to make sense. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="egp-function_+3A_plot">plot</code></td>
<td>
<p>boolean indicating whether or not to plot the return levels</p>
</td></tr>
</table>

<hr>
<h2 id='egp.fit'>Fit of extended GP models and parameter stability plots</h2><span id='topic+egp.fit'></span>

<h3>Description</h3>

<p>This function is an alias of <code><a href="#topic+fit.egp">fit.egp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>egp.fit(xdat, thresh, model = c("egp1", "egp2", "egp3"), init, show = FALSE)
</code></pre>


<h3>Details</h3>

<p>Supported for backward compatibility
</p>

<hr>
<h2 id='egp.fitrange'>Deprecated function for parameter stability plots</h2><span id='topic+egp.fitrange'></span>

<h3>Description</h3>

<p>Deprecated function for parameter stability plots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>egp.fitrange(
  xdat,
  thresh,
  model = c("egp1", "egp2", "egp3"),
  plots = 1:3,
  umin,
  umax,
  nint
)
</code></pre>

<hr>
<h2 id='egp2.fit'>Fit an extended generalized Pareto distribution of Naveau et al.</h2><span id='topic+egp2.fit'></span>

<h3>Description</h3>

<p>Deprecated function name to fit an extended generalized Pareto family. The user should call <code><a href="#topic+fit.extgp">fit.extgp</a></code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>egp2.fit(
  data,
  model = 1,
  method = c("mle", "pwm"),
  init,
  censoring = c(0, Inf),
  rounded = 0,
  CI = FALSE,
  R = 1000,
  ncpus = 1,
  plots = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="egp2.fit_+3A_data">data</code></td>
<td>
<p>data vector.</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_model">model</code></td>
<td>
<p>integer ranging from 0 to 4 indicating the model to select (see <code><a href="#topic+extgp">extgp</a></code>).</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_method">method</code></td>
<td>
<p>string; either <code>'mle'</code> for maximum likelihood, or <code>'pwm'</code> for probability weighted moments, or both.</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_init">init</code></td>
<td>
<p>vector of initial values, comprising of <code class="reqn">p</code>, <code class="reqn">\kappa</code>, <code class="reqn">\delta</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code> (in that order) for the optimization. All parameters may not appear depending on <code>model</code>.</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_censoring">censoring</code></td>
<td>
<p>numeric vector of length 2 containing the lower and upper bound for censoring; <code>censoring=c(0,Inf)</code> is equivalent to no censoring.</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_rounded">rounded</code></td>
<td>
<p>numeric giving the instrumental precision (and rounding of the data), with default of 0.</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap replications.</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_ncpus">ncpus</code></td>
<td>
<p>integer; number of CPUs for parallel calculations (default: 1).</p>
</td></tr>
<tr><td><code id="egp2.fit_+3A_plots">plots</code></td>
<td>
<p>logical; whether to produce histogram and density plots.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fit.extgp">fit.extgp</a></code>
</p>

<hr>
<h2 id='emplik'>Self-concordant empirical likelihood for a vector mean</h2><span id='topic+emplik'></span>

<h3>Description</h3>

<p>Self-concordant empirical likelihood for a vector mean
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emplik(
  dat,
  mu = rep(0, ncol(dat)),
  lam = rep(0, ncol(dat)),
  eps = 1/nrow(dat),
  M = 1e+30,
  thresh = 1e-30,
  itermax = 100
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="emplik_+3A_dat">dat</code></td>
<td>
<p><code>n</code> by <code>d</code> matrix of <code>d</code>-variate observations</p>
</td></tr>
<tr><td><code id="emplik_+3A_mu">mu</code></td>
<td>
<p><code>d</code> vector of hypothesized mean of <code>dat</code></p>
</td></tr>
<tr><td><code id="emplik_+3A_lam">lam</code></td>
<td>
<p>starting values for Lagrange multiplier vector, default to zero vector</p>
</td></tr>
<tr><td><code id="emplik_+3A_eps">eps</code></td>
<td>
<p>lower cutoff for <code class="reqn">-\log</code>, with default <code>1/nrow(dat)</code></p>
</td></tr>
<tr><td><code id="emplik_+3A_m">M</code></td>
<td>
<p>upper cutoff for <code class="reqn">-\log</code>.</p>
</td></tr>
<tr><td><code id="emplik_+3A_thresh">thresh</code></td>
<td>
<p>convergence threshold for log likelihood (default of <code>1e-30</code> is aggressive)</p>
</td></tr>
<tr><td><code id="emplik_+3A_itermax">itermax</code></td>
<td>
<p>upper bound on number of Newton steps.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with components
</p>

<ul>
<li> <p><code>logelr</code> log empirical likelihood ratio.
</p>
</li>
<li> <p><code>lam</code> Lagrange multiplier (vector of length <code>d</code>).
</p>
</li>
<li> <p><code>wts</code> <code>n</code> vector of observation weights (probabilities).
</p>
</li>
<li> <p><code>conv</code> boolean indicating convergence.
</p>
</li>
<li> <p><code>niter</code> number of iteration until convergence.
</p>
</li>
<li> <p><code>ndec</code> Newton decrement.
</p>
</li>
<li> <p><code>gradnorm</code> norm of gradient of log empirical likelihood.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Art Owen, <code>C++</code> port by Leo Belzile
</p>


<h3>References</h3>

<p>Owen, A.B. (2013). Self-concordance for empirical likelihood, <em>Canadian Journal of Statistics</em>, <b>41</b>(3), 387&ndash;397.
</p>

<hr>
<h2 id='eskrain'>Eskdalemuir Observatory Daily Rainfall</h2><span id='topic+eskrain'></span>

<h3>Description</h3>

<p>This dataset contains exceedances of 30mm for daily
cumulated rainfall observations over the period 1970-1986.
These data were aggregated from hourly series.
</p>


<h3>Format</h3>

<p>a vector with 93 daily cumulated rainfall measurements exceeding 30mm.
</p>


<h3>Details</h3>

<p>The station is one of the rainiest of the whole UK, with an average 1554m of cumulated rainfall per year.
The data consisted of 6209 daily observations, of which 4409 were non-zero.
Only the 93 largest observations are provided.
</p>


<h3>Source</h3>

<p>Met Office.
</p>

<hr>
<h2 id='expme'>Exponent measure for multivariate generalized Pareto distributions</h2><span id='topic+expme'></span>

<h3>Description</h3>

<p>Integrated intensity over the region defined by <code class="reqn">[0, z]^c</code> for logistic, Huesler-Reiss, Brown-Resnick and extremal Student processes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expme(
  z,
  par,
  model = c("log", "neglog", "hr", "br", "xstud"),
  method = c("TruncatedNormal", "mvtnorm", "mvPot")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expme_+3A_z">z</code></td>
<td>
<p>vector at which to estimate exponent measure</p>
</td></tr>
<tr><td><code id="expme_+3A_par">par</code></td>
<td>
<p>list of parameters</p>
</td></tr>
<tr><td><code id="expme_+3A_model">model</code></td>
<td>
<p>string indicating the model family</p>
</td></tr>
<tr><td><code id="expme_+3A_method">method</code></td>
<td>
<p>string indicating the package from which to extract the numerical integration routine</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric giving the measure of the complement of <code class="reqn">[0,z]</code>.
</p>


<h3>Note</h3>

<p>The list <code>par</code> must contain different arguments depending on the model. For the Brown&ndash;Resnick model, the user must supply the conditionally negative definite matrix <code>Lambda</code> following the parametrization in Engelke <em>et al.</em> (2015) or the covariance matrix <code>Sigma</code>, following Wadsworth and Tawn (2014). For the Husler&ndash;Reiss model, the user provides the mean and covariance matrix, <code>m</code> and <code>Sigma</code>. For the extremal student, the covariance matrix <code>Sigma</code> and the degrees of freedom <code>df</code>. For the logistic model, the strictly positive dependence parameter <code>alpha</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Extremal Student
Sigma &lt;- stats::rWishart(n = 1, df = 20, Sigma = diag(10))[, , 1]
expme(z = rep(1, ncol(Sigma)), par = list(Sigma = cov2cor(Sigma), df = 3), model = "xstud")
# Brown-Resnick model
D &lt;- 5L
loc &lt;- cbind(runif(D), runif(D))
di &lt;- as.matrix(dist(rbind(c(0, ncol(loc)), loc)))
semivario &lt;- function(d, alpha = 1.5, lambda = 1) {
  (d / lambda)^alpha
}
Vmat &lt;- semivario(di)
Lambda &lt;- Vmat[-1, -1] / 2
expme(z = rep(1, ncol(Lambda)), par = list(Lambda = Lambda), model = "br", method = "mvPot")
Sigma &lt;- outer(Vmat[-1, 1], Vmat[1, -1], "+") - Vmat[-1, -1]
expme(z = rep(1, ncol(Lambda)), par = list(Lambda = Lambda), model = "br", method = "mvPot")

## End(Not run)
</code></pre>

<hr>
<h2 id='ext.index'>Extremal index estimators based on interexceedance time and gap of exceedances</h2><span id='topic+ext.index'></span>

<h3>Description</h3>

<p>The function implements the maximum likelihood estimator and iteratively reweighted least
square estimators of Suveges (2007)  as well as the intervals estimator. The implementation
differs from the presentation of the paper in that an iteration limit is enforced to make sure
the iterative procedure terminates. Multiple thresholds can be supplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ext.index(
  xdat,
  q = 0.95,
  method = c("wls", "mle", "intervals"),
  plot = FALSE,
  warn = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ext.index_+3A_xdat">xdat</code></td>
<td>
<p>numeric vector of observations</p>
</td></tr>
<tr><td><code id="ext.index_+3A_q">q</code></td>
<td>
<p>a vector of quantile levels in (0,1). Defaults to 0.95</p>
</td></tr>
<tr><td><code id="ext.index_+3A_method">method</code></td>
<td>
<p>a string specifying the chosen method. Must be either <code>wls</code>
for weighted least squares, <code>mle</code> for maximum likelihood estimation or <code>intervals</code>
for the intervals estimator of Ferro and Segers (2003). Partial match is allowed.</p>
</td></tr>
<tr><td><code id="ext.index_+3A_plot">plot</code></td>
<td>
<p>logical; if <code>TRUE</code>, plot the extremal index as a function of <code>q</code></p>
</td></tr>
<tr><td><code id="ext.index_+3A_warn">warn</code></td>
<td>
<p>logical; if <code>TRUE</code>, receive a warning when the sample size is too small</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The iteratively reweighted least square is a procedure based on the gaps of exceedances <code class="reqn">S_n=T_n-1</code>
The model is first fitted to non-zero gaps, which are rescaled to have unit exponential scale. The slope
between the theoretical quantiles and the normalized gap of exceedances is <code class="reqn">b=1/\theta</code>,
with intercept <code class="reqn">a=\log(\theta)/\theta</code>.
As such, the estimate of the extremal index is based on <code class="reqn">\hat{\theta}=\exp(\hat{a}/\hat{b})</code>.
The weights are chosen in such a way as to reduce the influence of the smallest values.
The estimator exploits the dual role of <code class="reqn">\theta</code> as the parameter of the mean for
the interexceedance time as well as the mixture proportion for the non-zero component.
</p>
<p>The maximum likelihood is based on an independence likelihood for the rescaled gap of exceedances,
namely <code class="reqn">\bar{F}(u_n)S(u_n)</code>. The score equation is equivalent to a quadratic equation in
<code class="reqn">\theta</code> and the maximum likelihood estimate is available in closed form.
Its validity requires however condition <code class="reqn">D^{(2)}(u_n)</code> to apply;
this should be checked by the user beforehand.
</p>
<p>A warning is emitted if the effective sample size is less than 50 observations.
</p>


<h3>Value</h3>

<p>a vector or matrix of estimated extremal index of dimension <code>length(method)</code> by <code>length(q)</code>.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Ferro and Segers (2003). Inference for clusters of extreme values,
JRSS: Series B, <strong>65</strong>(2), 545-556.
</p>
<p>Suveges (2007) Likelihood estimation of the extremal index. <em>Extremes</em>,
<strong>10</strong>(1), 41-55.
</p>
<p>Suveges and Davison (2010), Model misspecification in peaks over threshold analysis. <em>Annals of Applied Statistics</em>, <strong>4</strong>(1), 203-221.
</p>
<p>Fukutome, Liniger and Suveges (2015), Automatic threshold and run parameter selection: a climatology
for extreme hourly precipitation in Switzerland. <em>Theoretical and Applied Climatology</em>,
<strong>120</strong>(3), 403-416.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(234)
#Moving maxima model with theta=0.5
a &lt;- 1; theta &lt;-  1/(1+a)
sim &lt;- rgev(10001, loc=1/(1+a),scale=1/(1+a),shape=1)
x &lt;- pmax(sim[-length(sim)]*a,sim[-1])
q &lt;- seq(0.9,0.99,by=0.01)
ext.index(xdat=x,q=q,method=c('wls','mle'))
</code></pre>

<hr>
<h2 id='extcoef'>Estimators of the extremal coefficient</h2><span id='topic+extcoef'></span>

<h3>Description</h3>

<p>These functions estimate the extremal coefficient using an approximate sample
from the Frechet distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extcoef(
  dat,
  coord = NULL,
  thresh = NULL,
  estimator = c("schlather", "smith", "fmado"),
  standardize = TRUE,
  method = c("nonparametric", "parametric"),
  prob = 0,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extcoef_+3A_dat">dat</code></td>
<td>
<p>an <code>n</code> by <code>D</code> matrix of unit Frechet observations</p>
</td></tr>
<tr><td><code id="extcoef_+3A_coord">coord</code></td>
<td>
<p>an optional <code>d</code> by <code>D</code> matrix of location coordinates</p>
</td></tr>
<tr><td><code id="extcoef_+3A_thresh">thresh</code></td>
<td>
<p>threshold parameter (default is to keep all data if <code>prob = 0</code>).</p>
</td></tr>
<tr><td><code id="extcoef_+3A_estimator">estimator</code></td>
<td>
<p>string indicating which model estimates to compute, one of <code>smith</code>, <code>schlather</code> or <code>fmado</code>.</p>
</td></tr>
<tr><td><code id="extcoef_+3A_standardize">standardize</code></td>
<td>
<p>logical; should observations be transformed to unit Frechet scale? Default is to transform</p>
</td></tr>
<tr><td><code id="extcoef_+3A_method">method</code></td>
<td>
<p>string indicating which method to use to transform the margins. See <b>Details</b></p>
</td></tr>
<tr><td><code id="extcoef_+3A_prob">prob</code></td>
<td>
<p>probability of not exceeding threshold <code>thresh</code></p>
</td></tr>
<tr><td><code id="extcoef_+3A_plot">plot</code></td>
<td>
<p>logical; should cloud of pairwise empirical estimates be plotted? Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="extcoef_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function, currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <b>Smith</b> estimator: suppose <code class="reqn">Z(x)</code> is simple max-stable vector
(i.e., with unit Frechet marginals). Then
<code class="reqn">1/Z</code> is unit exponential and <code class="reqn">1/\max(Z(s_1), Z(s_2))</code> is exponential
with rate <code class="reqn">\theta = \max\{Z(s_1), Z(s_2)\}</code>.
The extremal index for the pair can therefore be calculated using the reciprocal mean.
</p>
<p>The <b>Schlather and Tawn</b> estimator: the likelihood of the naive estimator for a pair
of two sites <code class="reqn">A</code> is
</p>
<p style="text-align: center;"><code class="reqn"> \mathrm{card}\left\{ j: \max_{i \in A} X_i^{(j)}\bar{X}_i)&gt;z \right\}
\log(\theta_A) - \theta_A \sum_{j=1}^n \left[ \max \left\{z, \max_{i \in A}
(X_i^{(j)}\bar{X}_i)\right\}\right]^{-1},</code>
</p>

<p>where <code class="reqn">\bar{X}_i = n^{-1} \sum_{j=1}^n 1/X_i^{(j)}</code> is the harmonic mean and <code class="reqn">z</code>
is a threshold on the unit Frechet scale.
The search for the maximum likelihood estimate for every pair <code class="reqn">A</code>
is restricted to the interval <code class="reqn">[1,3]</code>. A binned version of the extremal coefficient cloud is also returned.
The Schlather estimator is not self-consistent. The Schlather and Tawn estimator includes as special case
the Smith estimator if we do not censor the data (<code>p = 0</code>) and do not standardize observations by their harmonic mean.
</p>
<p>The <b>F-madogram</b> estimator is a non-parametric estimate based on a stationary process
<code class="reqn">Z</code>; the extremal coefficient satisfies
</p>
<p style="text-align: center;"><code class="reqn">\theta(h)=\frac{1+2\nu(h)}{1-2\nu(h)},</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\nu(h) = \frac{1}{2} \mathsf{E}[|F(Z(s+h)-F(Z(s))|]</code>
</p>

<p>The implementation only uses complete pairs to calculate the relative ranks.
</p>
<p>All estimators are coded in plain R and computations are not optimized. The estimation
time can therefore be significant for large data sets. If there are no missing observations,
the routine <code>fmadogram</code> from the <code>SpatialExtremes</code> package should be prefered as it is
noticeably faster.
</p>
<p>The data will typically consist of max-stable vectors or block maxima.
Both of the Smith and the Schlather&ndash;Tawn estimators require unit Frechet margins; the margins will be standardized
to the unit Frechet scale, either parametrically or nonparametrically unless <code>standardize = FALSE</code>.
If <code>method = "parametric"</code>, a parametric GEV model is fitted to each column of <code>dat</code> using maximum likelihood
estimation and transformed back using the probability integral transform. If <code>method = "nonparametric"</code>,
using the empirical distribution function. The latter is the default, as it is appreciably faster.
</p>


<h3>Value</h3>

<p>an invisible list with vectors <code>dist</code> if <code>coord</code> is non-null or else a matrix of pairwise indices <code>ind</code>,
<code>extcoef</code> and the supplied <code>estimator</code>, <code>fmado</code> and <code>binned</code>. If <code>estimator == "schlather"</code>, an additional matrix with 2 columns containing the binned distance <code>binned</code> with the <code>h</code> and the binned extremal coefficient.
</p>


<h3>References</h3>

<p>Schlather, M. and J. Tawn (2003). A dependence measure for multivariate and spatial extremes, <em>Biometrika</em>, <b>90</b>(1), pp.139&ndash;156.
</p>
<p>Cooley, D., P. Naveau and P. Poncet (2006). Variograms for spatial max-stable random fields,  In: Bertail P., Soulier P., Doukhan P. (eds) <em>Dependence in Probability and Statistics</em>. Lecture Notes in Statistics, vol. 187. Springer, New York, NY
</p>
<p>R. J. Erhardt, R. L. Smith (2012), Approximate Bayesian computing for spatial extremes, <em>Computational Statistics and Data Analysis</em>, <b>56</b>, pp.1468&ndash;1481.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
coord &lt;- 10*cbind(runif(50), runif(50))
di &lt;- as.matrix(dist(coord))
dat &lt;- rmev(n = 1000, d = 100, param = 3, sigma = exp(-di/2), model = 'xstud')
res &lt;- extcoef(dat = dat, coord = coord)
# Extremal Student extremal coefficient function

XT.extcoeffun &lt;- function(h, nu, corrfun, ...){
  if(!is.function(corrfun)){
    stop('Invalid function \"corrfun\".')
  }
  h &lt;- unique(as.vector(h))
  rhoh &lt;- sapply(h, corrfun, ...)
  cbind(h = h, extcoef = 2*pt(sqrt((nu+1)*(1-rhoh)/(1+rhoh)), nu+1))
}
#This time, only one graph with theoretical extremal coef
plot(res$dist, res$extcoef, ylim = c(1,2), pch = 20); abline(v = 2, col = 'gray')
extcoefxt &lt;- XT.extcoeffun(seq(0, 10, by = 0.1), nu = 3,
                            corrfun = function(x){exp(-x/2)})
lines(extcoefxt[,'h'], extcoefxt[,'extcoef'], type = 'l', col = 'blue', lwd = 2)
# Brown--Resnick extremal coefficient function
BR.extcoeffun &lt;- function(h, vario, ...){
  if(!is.function(vario)){
    stop('Invalid function \"vario\".')
  }
  h &lt;- unique(as.vector(h))
  gammah &lt;- sapply(h, vario, ...)
  cbind(h = h, extcoef = 2*pnorm(sqrt(gammah/4)))
}
extcoefbr&lt;- BR.extcoeffun(seq(0, 20, by = 0.25), vario = function(x){2*x^0.7})
lines(extcoefbr[,'h'], extcoefbr[,'extcoef'], type = 'l', col = 'orange', lwd = 2)

coord &lt;- 10*cbind(runif(20), runif(20))
di &lt;- as.matrix(dist(coord))
dat &lt;- rmev(n = 1000, d = 20, param = 3, sigma = exp(-di/2), model = 'xstud')
res &lt;- extcoef(dat = dat, coord = coord, estimator = "smith")

## End(Not run)
</code></pre>

<hr>
<h2 id='extgp'>Extended generalised Pareto families of Naveau et al. (2016)</h2><span id='topic+extgp'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and random generation for the extended generalized Pareto distribution (GPD) with scale and shape parameters.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extgp_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="extgp_+3A_x">x</code></td>
<td>
<p>vector of observations</p>
</td></tr>
<tr><td><code id="extgp_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="extgp_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="extgp_+3A_prob">prob</code></td>
<td>
<p>mixture probability for model <code>type</code> <code>4</code></p>
</td></tr>
<tr><td><code id="extgp_+3A_kappa">kappa</code></td>
<td>
<p>shape parameter for <code>type</code> <code>1</code>, <code>3</code> and <code>4</code></p>
</td></tr>
<tr><td><code id="extgp_+3A_delta">delta</code></td>
<td>
<p>additional parameter for <code>type</code> <code>2</code>, <code>3</code> and <code>4</code></p>
</td></tr>
<tr><td><code id="extgp_+3A_sigma">sigma</code></td>
<td>
<p>scale parameter</p>
</td></tr>
<tr><td><code id="extgp_+3A_xi">xi</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="extgp_+3A_type">type</code></td>
<td>
<p>integer between 0 to 5 giving the model choice</p>
</td></tr>
<tr><td><code id="extgp_+3A_step">step</code></td>
<td>
<p>function of step size for discretization with default <code>0</code>, corresponding to continuous quantiles</p>
</td></tr>
<tr><td><code id="extgp_+3A_log">log</code></td>
<td>
<p>logical; should the log-density be returned (default to <code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="extgp_+3A_unifsamp">unifsamp</code></td>
<td>
<p>sample of uniform; if provided, the data will be used in place of new uniform random variates</p>
</td></tr>
<tr><td><code id="extgp_+3A_censoring">censoring</code></td>
<td>
<p>numeric vector of length 2 containing the lower and upper bound for censoring</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The extended generalized Pareto families proposed in Naveau <em>et al.</em> (2016)
retain the tail index of the distribution while being compliant with the theoretical behavior of extreme
low rainfall. There are five proposals, the first one being equivalent to the GP distribution.
</p>

<ul>
<li> <p><code>type</code> 0 corresponds to uniform carrier, <code class="reqn">G(u)=u</code>.
</p>
</li>
<li> <p><code>type</code> 1 corresponds to a three parameters family, with carrier <code class="reqn">G(u)=u^\kappa</code>.
</p>
</li>
<li> <p><code>type</code> 2 corresponds to a three parameters family, with carrier <code class="reqn">G(u)=1-V_\delta((1-u)^\delta)</code>.
</p>
</li>
<li> <p><code>type</code> 3 corresponds to a four parameters family, with carrier </p>
<p style="text-align: center;"><code class="reqn">G(u)=1-V_\delta((1-u)^\delta))^{\kappa/2}</code>
</p>
<p>.
</p>
</li>
<li> <p><code>type</code> 4 corresponds to a five parameter model (a mixture of <code>type</code> 2, with <code class="reqn">G(u)=pu^\kappa + (1-p)*u^\delta</code>
</p>
</li></ul>



<h3>Usage</h3>

<p><code>pextgp(q, prob=NA, kappa=NA, delta=NA, sigma=NA, xi=NA, type=1)</code>
</p>
<p><code>dextgp(x, prob=NA, kappa=NA, delta=NA, sigma=NA, xi=NA, type=1, log=FALSE)</code>
</p>
<p><code>qextgp(p, prob=NA, kappa=NA, delta=NA, sigma=NA, xi=NA, type=1)</code>
</p>
<p><code>rextgp(n, prob=NA, kappa=NA, delta=NA, sigma=NA, xi=NA, type=1, unifsamp=NULL, censoring=c(0,Inf))</code>
</p>


<h3>Author(s)</h3>

<p>Raphael Huser and Philippe Naveau
</p>


<h3>References</h3>

<p>Naveau, P., R. Huser, P. Ribereau, and A. Hannart (2016), Modeling jointly low, moderate, and heavy rainfall intensities without a threshold selection, <em>Water Resour. Res.</em>, 52, 2753-2769, <code>doi:10.1002/2015WR018552</code>.
</p>

<hr>
<h2 id='extgp.G'>Carrier distribution for the extended GP distributions of Naveau et al.</h2><span id='topic+extgp.G'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random number
generation for the carrier distributions of the extended Generalized Pareto distributions.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extgp.G_+3A_u">u</code></td>
<td>
<p>vector of observations (<code>dextgp.G</code>), probabilities (<code>qextgp.G</code>) or quantiles (<code>pextgp.G</code>), in <code class="reqn">[0,1]</code></p>
</td></tr>
<tr><td><code id="extgp.G_+3A_prob">prob</code></td>
<td>
<p>mixture probability for model <code>type</code> <code>4</code></p>
</td></tr>
<tr><td><code id="extgp.G_+3A_kappa">kappa</code></td>
<td>
<p>shape parameter for <code>type</code> <code>1</code>, <code>3</code> and <code>4</code></p>
</td></tr>
<tr><td><code id="extgp.G_+3A_delta">delta</code></td>
<td>
<p>additional parameter for <code>type</code> <code>2</code>, <code>3</code> and <code>4</code></p>
</td></tr>
<tr><td><code id="extgp.G_+3A_type">type</code></td>
<td>
<p>integer between 0 to 5 giving the model choice</p>
</td></tr>
<tr><td><code id="extgp.G_+3A_log">log</code></td>
<td>
<p>logical; should the log-density be returned (default to <code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="extgp.G_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="extgp.G_+3A_unifsamp">unifsamp</code></td>
<td>
<p>sample of uniform; if provided, the data will be used in place of new uniform random variates</p>
</td></tr>
<tr><td><code id="extgp.G_+3A_censoring">censoring</code></td>
<td>
<p>numeric vector of length 2 containing the lower and upper bound for censoring</p>
</td></tr>
<tr><td><code id="extgp.G_+3A_direct">direct</code></td>
<td>
<p>logical; which method to use for sampling in model of <code>type</code> <code>4</code>?</p>
</td></tr>
</table>


<h3>Usage</h3>

<p><code>pextgp.G(u, type=1, prob, kappa, delta)</code>
</p>
<p><code>dextgp.G(u, type=1, prob=NA, kappa=NA, delta=NA, log=FALSE)</code>
</p>
<p><code>qextgp.G(u, type=1, prob=NA, kappa=NA, delta=NA)</code>
</p>
<p><code>rextgp.G(n, prob=NA, kappa=NA, delta=NA,
type=1, unifsamp=NULL, direct=FALSE, censoring=c(0,1))</code>
</p>


<h3>Author(s)</h3>

<p>Raphael Huser and Philippe Naveau
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extgp">extgp</a></code>
</p>

<hr>
<h2 id='extremo'>Pairwise extremogram for max-risk functional</h2><span id='topic+extremo'></span>

<h3>Description</h3>

<p>The function computes the pairwise <code class="reqn">chi</code> estimates and plots them as a function of the distance between sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extremo(dat, margp, coord, scale = 1, rho = 0, plot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extremo_+3A_dat">dat</code></td>
<td>
<p>data matrix</p>
</td></tr>
<tr><td><code id="extremo_+3A_margp">margp</code></td>
<td>
<p>marginal probability above which to threshold observations</p>
</td></tr>
<tr><td><code id="extremo_+3A_coord">coord</code></td>
<td>
<p>matrix of coordinates (one site per row)</p>
</td></tr>
<tr><td><code id="extremo_+3A_scale">scale</code></td>
<td>
<p>geometric anisotropy scale parameter</p>
</td></tr>
<tr><td><code id="extremo_+3A_rho">rho</code></td>
<td>
<p>geometric anisotropy angle parameter</p>
</td></tr>
<tr><td><code id="extremo_+3A_plot">plot</code></td>
<td>
<p>logical; should a graph of the pairwise estimates against distance? Default to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="extremo_+3A_...">...</code></td>
<td>
<p>additional arguments passed to plot</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an invisible matrix with pairwise estimates of chi along with distance (unsorted)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
lon &lt;- seq(650, 720, length = 10)
lat &lt;- seq(215, 290, length = 10)
# Create a grid
grid &lt;- expand.grid(lon,lat)
coord &lt;- as.matrix(grid)
dianiso &lt;- distg(coord, 1.5, 0.5)
sgrid &lt;- scale(grid, scale = FALSE)
# Specify marginal parameters `loc` and `scale` over grid
eta &lt;- 26 + 0.05*sgrid[,1] - 0.16*sgrid[,2]
tau &lt;- 9 + 0.05*sgrid[,1] - 0.04*sgrid[,2]
# Parameter matrix of Huesler--Reiss
# associated to power variogram
Lambda &lt;- ((dianiso/30)^0.7)/4
# Regular Euclidean distance between sites
di &lt;- distg(coord, 1, 0)
# Simulate generalized max-Pareto field
set.seed(345)
simu1 &lt;- rgparp(n = 1000, thresh = 50, shape = 0.1, riskf = "max",
                scale = tau, loc = eta, sigma = Lambda, model = "hr")
extdat &lt;- extremo(dat = simu1, margp = 0.98, coord = coord,
                  scale = 1.5, rho = 0.5, plot = TRUE)

# Constrained optimization
# Minimize distance between extremal coefficient from fitted variogram
mindistpvario &lt;- function(par, emp, coord){
alpha &lt;- par[1]; if(!isTRUE(all(alpha &gt; 0, alpha &lt; 2))){return(1e10)}
scale &lt;- par[2]; if(scale &lt;= 0){return(1e10)}
a &lt;- par[3]; if(a&lt;1){return(1e10)}
rho &lt;- par[4]; if(abs(rho) &gt;= pi/2){return(1e10)}
semivariomat &lt;- power.vario(distg(coord, a, rho), alpha = alpha, scale = scale)
  sum((2*(1-pnorm(sqrt(semivariomat[lower.tri(semivariomat)]/2))) - emp)^2)
}

hin &lt;- function(par, ...){
  c(1.99-par[1], -1e-5 + par[1],
    -1e-5 + par[2],
    par[3]-1,
    pi/2 - par[4],
    par[4]+pi/2)
  }
opt &lt;- alabama::auglag(par = c(0.7, 30, 1, 0),
                       hin = hin,
                        fn = function(par){
                          mindistpvario(par, emp = extdat[,'prob'], coord = coord)})
stopifnot(opt$kkt1, opt$kkt2)
# Plotting the extremogram in the deformed space
distfa &lt;- distg(loc = coord, opt$par[3], opt$par[4])
plot(
 x = c(distfa[lower.tri(distfa)]), 
 y = extdat[,2], 
 pch = 20,
 yaxs = "i", 
 xaxs = "i", 
 bty = 'l',
 xlab = "distance", 
 ylab= "cond. prob. of exceedance", 
 ylim = c(0,1))
lines(
  x = (distvec &lt;- seq(0,200, length = 1000)), 
  col = 2, lwd = 2,
  y = 2*(1-pnorm(sqrt(power.vario(distvec, alpha = opt$par[1],
                               scale = opt$par[2])/2))))

## End(Not run)
</code></pre>

<hr>
<h2 id='fit.egp'>Parameter stability plot and maximum likelihood routine for extended GP models</h2><span id='topic+fit.egp'></span><span id='topic+tstab.egp'></span>

<h3>Description</h3>

<p>The function <code>tstab.egp</code> provides classical threshold stability plot for (<code class="reqn">\kappa</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code>).
The fitted parameter values are displayed with pointwise normal 95% confidence intervals.
The function returns an invisible list with parameter estimates and standard errors, and p-values for the Wald test that <code class="reqn">\kappa=1</code>.
The plot is for the modified scale (as in the generalised Pareto model) and as such it is possible that the modified scale be negative.
<code>tstab.egp</code> can also be used to fit the model to multiple thresholds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.egp(xdat, thresh, model = c("egp1", "egp2", "egp3"), init, show = FALSE)

tstab.egp(
  xdat,
  thresh,
  model = c("egp1", "egp2", "egp3"),
  plots = 1:3,
  umin,
  umax,
  nint,
  changepar = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.egp_+3A_xdat">xdat</code></td>
<td>
<p>vector of observations, greater than the threshold</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_thresh">thresh</code></td>
<td>
<p>threshold value</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_model">model</code></td>
<td>
<p>a string indicating which extended family to fit</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_init">init</code></td>
<td>
<p>vector of initial values, with <code class="reqn">\log(\kappa)</code> and <code class="reqn">\log(\sigma)</code>; can be omitted.</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code>, print the results of the optimization</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_plots">plots</code></td>
<td>
<p>vector of integers specifying which parameter stability to plot (if any); passing <code>NA</code> results in no plots</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_umin">umin</code></td>
<td>
<p>optional minimum value considered for threshold (if <code>thresh</code> is not provided)</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_umax">umax</code></td>
<td>
<p>optional maximum value considered for threshold (if <code>thresh</code> is not provided)</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_nint">nint</code></td>
<td>
<p>optional integer number specifying the number of thresholds to test.</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_changepar">changepar</code></td>
<td>
<p>logical; if <code>TRUE</code>, the graphical parameters (via a call to <code>par</code>) are modified.</p>
</td></tr>
<tr><td><code id="fit.egp_+3A_...">...</code></td>
<td>
<p>additional arguments for the plot function, currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fit.egp</code> is a numerical optimization routine to fit the extended generalised Pareto models of Papastathopoulos and Tawn (2013),
using maximum likelihood estimation.
</p>


<h3>Value</h3>

<p><code>fit.egp</code> outputs the list returned by <a href="stats.html#topic+optim">optim</a>, which contains the parameter values, the hessian and in addition the standard errors
</p>
<p><code>tstab.egp</code> returns a plot(s) of the parameters fit over the range of provided thresholds, with pointwise normal confidence intervals; the function also returns an invisible list containing notably the matrix of point estimates (<code>par</code>) and standard errors (<code>se</code>).
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Papastathopoulos, I. and J. Tawn (2013). Extended generalised Pareto models for tail estimation, <em>Journal of Statistical Planning and Inference</em> <b>143</b>(3), 131&ndash;143.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xdat &lt;- mev::rgp(
  n = 100,
  loc = 0,
  scale = 1,
  shape = 0.5)
fitted &lt;- fit.egp(
  xdat = xdat,
  thresh = 1,
  model = "egp2",
  show = TRUE)
thresh &lt;- mev::qgp(seq(0.1, 0.5, by = 0.05), 0, 1, 0.5)
tstab.egp(
   xdat = xdat,
   thresh = thresh,
   model = "egp2",
   plots = 1:3)
</code></pre>

<hr>
<h2 id='fit.extgp'>Fit an extended generalized Pareto distribution of Naveau et al.</h2><span id='topic+fit.extgp'></span>

<h3>Description</h3>

<p>This is a wrapper function to obtain PWM or MLE estimates for
the extended GP models of Naveau et al. (2016) for rainfall intensities. The function calculates confidence intervals
by means of nonparametric percentile bootstrap and returns histograms and QQ plots of
the fitted distributions. The function handles both censoring and rounding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.extgp(
  data,
  model = 1,
  method = c("mle", "pwm"),
  init,
  censoring = c(0, Inf),
  rounded = 0,
  confint = FALSE,
  R = 1000,
  ncpus = 1,
  plots = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.extgp_+3A_data">data</code></td>
<td>
<p>data vector.</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_model">model</code></td>
<td>
<p>integer ranging from 0 to 4 indicating the model to select (see <code><a href="#topic+extgp">extgp</a></code>).</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_method">method</code></td>
<td>
<p>string; either <code>'mle'</code> for maximum likelihood, or <code>'pwm'</code> for probability weighted moments, or both.</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_init">init</code></td>
<td>
<p>vector of initial values, comprising of <code class="reqn">p</code>, <code class="reqn">\kappa</code>, <code class="reqn">\delta</code>, <code class="reqn">\sigma</code>, <code class="reqn">\xi</code> (in that order) for the optimization. All parameters may not appear depending on <code>model</code>.</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_censoring">censoring</code></td>
<td>
<p>numeric vector of length 2 containing the lower and upper bound for censoring; <code>censoring=c(0,Inf)</code> is equivalent to no censoring.</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_rounded">rounded</code></td>
<td>
<p>numeric giving the instrumental precision (and rounding of the data), with default of 0.</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_confint">confint</code></td>
<td>
<p>logical; should confidence interval be returned (percentile bootstrap).</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap replications.</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_ncpus">ncpus</code></td>
<td>
<p>integer; number of CPUs for parallel calculations (default: 1).</p>
</td></tr>
<tr><td><code id="fit.extgp_+3A_plots">plots</code></td>
<td>
<p>logical; whether to produce histogram and density plots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The different models include the following transformations:
</p>

<ul>
<li> <p><code>model</code> 0 corresponds to uniform carrier, <code class="reqn">G(u)=u</code>.
</p>
</li>
<li> <p><code>model</code> 1 corresponds to a three parameters family, with carrier <code class="reqn">G(u)=u^\kappa</code>.
</p>
</li>
<li> <p><code>model</code> 2 corresponds to a three parameters family, with carrier <code class="reqn">G(u)=1-V_\delta((1-u)^\delta)</code>.
</p>
</li>
<li> <p><code>model</code> 3 corresponds to a four parameters family, with carrier </p>
<p style="text-align: center;"><code class="reqn">G(u)=1-V_\delta((1-u)^\delta))^{\kappa/2}</code>
</p>
<p>.
</p>
</li>
<li> <p><code>model</code> 4 corresponds to a five parameter model (a mixture of <code>type</code> 2, with <code class="reqn">G(u)=pu^\kappa + (1-p)*u^\delta</code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Raphael Huser and Philippe Naveau
</p>


<h3>References</h3>

<p>Naveau, P., R. Huser, P. Ribereau, and A. Hannart (2016), Modeling jointly low, moderate, and heavy rainfall intensities without a threshold selection, <em>Water Resour. Res.</em>, 52, 2753-2769, <code>doi:10.1002/2015WR018552</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+egp.fit">egp.fit</a></code>, <code><a href="#topic+egp">egp</a></code>, <code><a href="#topic+extgp">extgp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(rain, package = "ismev")
fit.extgp(rain[rain&gt;0], model=1, method = 'mle', init = c(0.9, gp.fit(rain, 0)$est),
 rounded = 0.1, confint = TRUE, R = 20)

## End(Not run)
</code></pre>

<hr>
<h2 id='fit.gev'>Maximum likelihood estimation for the generalized extreme value distribution</h2><span id='topic+fit.gev'></span>

<h3>Description</h3>

<p>This function returns an object of class <code>mev_gev</code>, with default methods for printing and quantile-quantile plots.
The default starting values are the solution of the probability weighted moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.gev(
  xdat,
  start = NULL,
  method = c("nlminb", "BFGS"),
  show = FALSE,
  fpar = NULL,
  warnSE = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.gev_+3A_xdat">xdat</code></td>
<td>
<p>a numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="fit.gev_+3A_start">start</code></td>
<td>
<p>named list of starting values</p>
</td></tr>
<tr><td><code id="fit.gev_+3A_method">method</code></td>
<td>
<p>string indicating the outer optimization routine for the augmented Lagrangian. One of <code>nlminb</code> or <code>BFGS</code>.</p>
</td></tr>
<tr><td><code id="fit.gev_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code> (the default), print details of the fit.</p>
</td></tr>
<tr><td><code id="fit.gev_+3A_fpar">fpar</code></td>
<td>
<p>a named list with optional fixed components <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="fit.gev_+3A_warnse">warnSE</code></td>
<td>
<p>logical; if <code>TRUE</code>, a warning is printed if the standard errors cannot be returned from the observed information matrix when the shape is less than -0.5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following components:
</p>

<ul>
<li> <p><code>estimate</code> a vector containing the maximum likelihood estimates.
</p>
</li>
<li> <p><code>std.err</code> a vector containing the standard errors.
</p>
</li>
<li> <p><code>vcov</code> the variance covariance matrix, obtained as the numerical inverse of the observed information matrix.
</p>
</li>
<li> <p><code>method</code> the method used to fit the parameter.
</p>
</li>
<li> <p><code>nllh</code> the negative log-likelihood evaluated at the parameter <code>estimate</code>.
</p>
</li>
<li> <p><code>convergence</code> components taken from the list returned by <code><a href="alabama.html#topic+auglag">auglag</a></code>.
Values other than <code>0</code> indicate that the algorithm likely did not converge.
</p>
</li>
<li> <p><code>counts</code> components taken from the list returned by <code><a href="alabama.html#topic+auglag">auglag</a></code>.
</p>
</li>
<li> <p><code>xdat</code> vector of data
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>xdat &lt;- mev::rgev(n = 100)
fit.gev(xdat, show = TRUE)
# Example with fixed parameter
fit.gev(xdat, show = TRUE, fpar = list(shape = 0))
</code></pre>

<hr>
<h2 id='fit.gpd'>Maximum likelihood estimation for the generalized Pareto distribution</h2><span id='topic+fit.gpd'></span>

<h3>Description</h3>

<p>Numerical optimization of the generalized Pareto distribution for
data exceeding <code>threshold</code>.
This function returns an object of class <code>mev_gpd</code>, with default methods for printing and quantile-quantile plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.gpd(
  xdat,
  threshold = 0,
  method = "Grimshaw",
  show = FALSE,
  MCMC = NULL,
  k = 4,
  tol = 1e-08,
  fpar = NULL,
  warnSE = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.gpd_+3A_xdat">xdat</code></td>
<td>
<p>a numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_threshold">threshold</code></td>
<td>
<p>the chosen threshold.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_method">method</code></td>
<td>
<p>the method to be used. See <b>Details</b>. Can be abbreviated.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code> (the default), print details of the fit.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_mcmc">MCMC</code></td>
<td>
<p><code>NULL</code> for frequentist estimates, otherwise a boolean or a list with parameters passed. If <code>TRUE</code>, runs a Metropolis-Hastings sampler to get posterior mean estimates. Can be used to pass arguments <code>niter</code>, <code>burnin</code> and <code>thin</code> to the sampler as a list.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_k">k</code></td>
<td>
<p>bound on the influence function (<code>method = "obre"</code>); the constant <code>k</code> is a robustness parameter
(higher bounds are more efficient, low bounds are more robust). Default to 4, must be larger than <code class="reqn">\sqrt{2}</code>.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for OBRE weights iterations (<code>method = "obre"</code>). Default to <code>1e-8</code>.</p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_fpar">fpar</code></td>
<td>
<p>a named list with fixed parameters, either <code>scale</code> or <code>shape</code></p>
</td></tr>
<tr><td><code id="fit.gpd_+3A_warnse">warnSE</code></td>
<td>
<p>logical; if <code>TRUE</code>, a warning is printed if the standard errors cannot be returned from the observed information matrix when the shape is less than -0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default method is <code>'Grimshaw'</code>, which maximizes the profile likelihood for the ratio scale/shape.  Other options include <code>'obre'</code> for optimal <code class="reqn">B</code>-robust estimator of the parameter of Dupuis (1998), vanilla maximization of the log-likelihood using constrained optimization routine <code>'auglag'</code>, 1-dimensional optimization of the profile likelihood using <code><a href="stats.html#topic+nlm">nlm</a></code> and <code><a href="stats.html#topic+optim">optim</a></code>. Method <code>'ismev'</code> performs the two-dimensional optimization routine <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code> from the <code><a href="ismev.html#topic+ismev">ismev</a></code> library, with in addition the algebraic gradient.
The approximate Bayesian methods (<code>'zs'</code> and <code>'zhang'</code>) are extracted respectively from Zhang and Stephens (2009) and Zhang (2010) and consists of a approximate posterior mean calculated via importance
sampling assuming a GPD prior is placed on the parameter of the profile likelihood.
</p>


<h3>Value</h3>

<p>If <code>method</code> is neither <code>'zs'</code> nor <code>'zhang'</code>, a list containing the following components:
</p>

<ul>
<li> <p><code>estimate</code> a vector containing the <code>scale</code> and <code>shape</code> parameters (optimized and fixed).
</p>
</li>
<li> <p><code>std.err</code> a vector containing the standard errors. For <code>method = "obre"</code>, these are Huber's robust standard errors.
</p>
</li>
<li> <p><code>vcov</code> the variance covariance matrix, obtained as the numerical inverse of the observed information matrix. For <code>method = "obre"</code>,
this is the sandwich Godambe matrix inverse.
</p>
</li>
<li> <p><code>threshold</code> the threshold.
</p>
</li>
<li> <p><code>method</code> the method used to fit the parameter. See details.
</p>
</li>
<li> <p><code>nllh</code> the negative log-likelihood evaluated at the parameter <code>estimate</code>.
</p>
</li>
<li> <p><code>nat</code> number of points lying above the threshold.
</p>
</li>
<li> <p><code>pat</code> proportion of points lying above the threshold.
</p>
</li>
<li> <p><code>convergence</code> components taken from the list returned by <code><a href="stats.html#topic+optim">optim</a></code>.
Values other than <code>0</code> indicate that the algorithm likely did not converge (in particular 1 and 50).
</p>
</li>
<li> <p><code>counts</code> components taken from the list returned by <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</li>
<li> <p><code>exceedances</code> excess over the threshold.
</p>
</li></ul>

<p>Additionally, if <code>method = "obre"</code>, a vector of OBRE <code>weights</code>.
</p>
<p>Otherwise, a list containing
</p>

<ul>
<li> <p><code>threshold</code> the threshold.
</p>
</li>
<li> <p><code>method</code> the method used to fit the parameter. See <b>Details</b>.
</p>
</li>
<li> <p><code>nat</code> number of points lying above the threshold.
</p>
</li>
<li> <p><code>pat</code> proportion of points lying above the threshold.
</p>
</li>
<li> <p><code>approx.mean</code> a vector containing containing the approximate posterior mean estimates.
</p>
</li></ul>

<p>and in addition if MCMC is neither <code>FALSE</code>, nor <code>NULL</code>
</p>

<ul>
<li> <p><code>post.mean</code> a vector containing the posterior mean estimates.
</p>
</li>
<li> <p><code>post.se</code> a vector containing the posterior standard error estimates.
</p>
</li>
<li> <p><code>accept.rate</code> proportion of points lying above the threshold.
</p>
</li>
<li> <p><code>niter</code> length of resulting Markov Chain
</p>
</li>
<li> <p><code>burnin</code> amount of discarded iterations at start, capped at 10000.
</p>
</li>
<li> <p><code>thin</code> thinning integer parameter describing
</p>
</li></ul>



<h3>Note</h3>

<p>Some of the internal functions (which are hidden from the user) allow for modelling of the parameters using covariates. This is not currently implemented within <code>gp.fit</code>, but users can call internal functions should they wish to use these features.
</p>


<h3>Author(s)</h3>

<p>Scott D. Grimshaw for the <code>Grimshaw</code> option. Paul J. Northrop and Claire L. Coleman for the methods <code>optim</code>, <code>nlm</code> and <code>ismev</code>.
J. Zhang and Michael A. Stephens (2009) and Zhang (2010) for the <code>zs</code> and <code>zhang</code> approximate methods and L. Belzile for methods <code>auglag</code> and <code>obre</code>, the wrapper and MCMC samplers.
</p>
<p>If <code>show = TRUE</code>, the optimal <code class="reqn">B</code> robust estimated weights for the largest observations are printed alongside with the
<code class="reqn">p</code>-value of the latter, obtained from the empirical distribution of the weights. This diagnostic can be used to guide threshold selection:
small weights for the <code class="reqn">r</code>-largest order statistics indicate that the robust fit is driven by the lower tail
and that the threshold should perhaps be increased.
</p>


<h3>References</h3>

<p>Davison, A.C. (1984). Modelling excesses over high thresholds, with an application, in
<em>Statistical extremes and applications</em>, J. Tiago de Oliveira (editor), D. Reidel Publishing Co., 461&ndash;482.
</p>
<p>Grimshaw, S.D. (1993). Computing Maximum Likelihood Estimates for the Generalized
Pareto Distribution, <em>Technometrics</em>, <b>35</b>(2), 185&ndash;191.
</p>
<p>Northrop, P.J. and C. L. Coleman (2014). Improved threshold diagnostic plots for extreme value
analyses, <em>Extremes</em>, <b>17</b>(2), 289&ndash;303.
</p>
<p>Zhang, J. (2010). Improving on estimation for the generalized Pareto distribution, <em>Technometrics</em> <b>52</b>(3), 335&ndash;339.
</p>
<p>Zhang, J.  and M. A. Stephens (2009). A new and efficient estimation method for the generalized Pareto distribution.
<em>Technometrics</em> <b>51</b>(3), 316&ndash;325.
</p>
<p>Dupuis, D.J. (1998). Exceedances over High Thresholds: A Guide to Threshold Selection,
<em>Extremes</em>, <b>1</b>(3), 251&ndash;261.
</p>


<h3>See Also</h3>

<p><code><a href="evd.html#topic+fpot">fpot</a></code> and <code><a href="ismev.html#topic+gpd.fit">gpd.fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(eskrain)
fit.gpd(eskrain, threshold = 35, method = 'Grimshaw', show = TRUE)
fit.gpd(eskrain, threshold = 30, method = 'zs', show = TRUE)
</code></pre>

<hr>
<h2 id='fit.pp'>Maximum likelihood estimation of the point process of extremes</h2><span id='topic+fit.pp'></span>

<h3>Description</h3>

<p>Data above <code>threshold</code> is modelled using the limiting point process
of extremes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.pp(
  xdat,
  threshold = 0,
  npp = 1,
  np = NULL,
  method = c("nlminb", "BFGS"),
  start = NULL,
  show = FALSE,
  fpar = NULL,
  warnSE = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.pp_+3A_xdat">xdat</code></td>
<td>
<p>a numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="fit.pp_+3A_threshold">threshold</code></td>
<td>
<p>the chosen threshold.</p>
</td></tr>
<tr><td><code id="fit.pp_+3A_npp">npp</code></td>
<td>
<p>number of observation per period. See <b>Details</b></p>
</td></tr>
<tr><td><code id="fit.pp_+3A_np">np</code></td>
<td>
<p>number of periods of data, if <code>xdat</code> only contains exceedances.</p>
</td></tr>
<tr><td><code id="fit.pp_+3A_method">method</code></td>
<td>
<p>the method to be used. See <b>Details</b>. Can be abbreviated.</p>
</td></tr>
<tr><td><code id="fit.pp_+3A_start">start</code></td>
<td>
<p>named list of starting values</p>
</td></tr>
<tr><td><code id="fit.pp_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code> (the default), print details of the fit.</p>
</td></tr>
<tr><td><code id="fit.pp_+3A_fpar">fpar</code></td>
<td>
<p>a named list with optional fixed components <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="fit.pp_+3A_warnse">warnSE</code></td>
<td>
<p>logical; if <code>TRUE</code>, a warning is printed if the standard errors cannot be returned from the observed information matrix when the shape is less than -0.5.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameter <code>npp</code> controls the frequency of observations.
If data are recorded on a daily basis, using a value of <code>npp = 365.25</code>
yields location and scale parameters that correspond to those of the
generalized extreme value distribution fitted to block maxima.
</p>


<h3>Value</h3>

<p>a list containing the following components:
</p>

<ul>
<li> <p><code>estimate</code> a vector containing all parameters (optimized and fixed).
</p>
</li>
<li> <p><code>std.err</code> a vector containing the standard errors.
</p>
</li>
<li> <p><code>vcov</code> the variance covariance matrix, obtained as the numerical inverse of the observed information matrix.
</p>
</li>
<li> <p><code>threshold</code> the threshold.
</p>
</li>
<li> <p><code>method</code> the method used to fit the parameter. See details.
</p>
</li>
<li> <p><code>nllh</code> the negative log-likelihood evaluated at the parameter <code>estimate</code>.
</p>
</li>
<li> <p><code>nat</code> number of points lying above the threshold.
</p>
</li>
<li> <p><code>pat</code> proportion of points lying above the threshold.
</p>
</li>
<li> <p><code>convergence</code> components taken from the list returned by <code><a href="stats.html#topic+optim">optim</a></code>.
Values other than <code>0</code> indicate that the algorithm likely did not converge (in particular 1 and 50).
</p>
</li>
<li> <p><code>counts</code> components taken from the list returned by <code><a href="stats.html#topic+optim">optim</a></code>.
</p>
</li></ul>



<h3>References</h3>

<p>Coles, S. (2001), An introduction to statistical modelling of extreme values. Springer : London, 208p.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(eskrain)
pp_mle &lt;- fit.pp(eskrain, threshold = 30, np = 6201)
plot(pp_mle)
</code></pre>

<hr>
<h2 id='fit.rlarg'>Maximum likelihood estimates of point process for the r-largest observations</h2><span id='topic+fit.rlarg'></span>

<h3>Description</h3>

<p>This uses a constrained optimization routine to return the maximum likelihood estimate
based on an <code>n</code> by <code>r</code> matrix of observations. Observations should be ordered, i.e.,
the <code>r</code>-largest should be in the last column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.rlarg(
  xdat,
  start = NULL,
  method = c("nlminb", "BFGS"),
  show = FALSE,
  fpar = NULL,
  warnSE = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit.rlarg_+3A_xdat">xdat</code></td>
<td>
<p>a numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="fit.rlarg_+3A_start">start</code></td>
<td>
<p>named list of starting values</p>
</td></tr>
<tr><td><code id="fit.rlarg_+3A_method">method</code></td>
<td>
<p>the method to be used. See <b>Details</b>. Can be abbreviated.</p>
</td></tr>
<tr><td><code id="fit.rlarg_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code> (the default), print details of the fit.</p>
</td></tr>
<tr><td><code id="fit.rlarg_+3A_fpar">fpar</code></td>
<td>
<p>a named list with fixed parameters, either <code>scale</code> or <code>shape</code></p>
</td></tr>
<tr><td><code id="fit.rlarg_+3A_warnse">warnSE</code></td>
<td>
<p>logical; if <code>TRUE</code>, a warning is printed if the standard errors cannot be returned from the observed information matrix when the shape is less than -0.5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following components:
</p>

<ul>
<li> <p><code>estimate</code> a vector containing all the maximum likelihood estimates.
</p>
</li>
<li> <p><code>std.err</code> a vector containing the standard errors.
</p>
</li>
<li> <p><code>vcov</code> the variance covariance matrix, obtained as the numerical inverse of the observed information matrix.
</p>
</li>
<li> <p><code>method</code> the method used to fit the parameter.
</p>
</li>
<li> <p><code>nllh</code> the negative log-likelihood evaluated at the parameter <code>estimate</code>.
</p>
</li>
<li> <p><code>convergence</code> components taken from the list returned by <code><a href="alabama.html#topic+auglag">auglag</a></code>.
Values other than <code>0</code> indicate that the algorithm likely did not converge.
</p>
</li>
<li> <p><code>counts</code> components taken from the list returned by <code><a href="alabama.html#topic+auglag">auglag</a></code>.
</p>
</li>
<li> <p><code>xdat</code> an <code>n</code> by <code>r</code> matrix of data
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>xdat &lt;- rrlarg(n = 10, loc = 0, scale = 1, shape = 0.1, r = 4)
fit.rlarg(xdat)
</code></pre>

<hr>
<h2 id='frwind'>French wind data</h2><span id='topic+frwind'></span>

<h3>Description</h3>

<p>Daily mean wind speed (in km/h) at four stations in the south of France, namely Cap Cepet (<code>S1</code>), Lyon St-Exupery (<code>S2</code>), Marseille Marignane (<code>S3</code>) and Montelimar (<code>S4</code>).
The data includes observations from January 1976 until April 2023; days containing missing values are omitted.
</p>


<h3>Format</h3>

<p>A data frame with 17209 observations and 8 variables:
</p>

<dl>
<dt><code>date</code></dt><dd><p>date of measurement</p>
</dd>
<dt><code>S1</code></dt><dd><p>wind speed (in km/h) at Cap Cepet</p>
</dd>
<dt><code>S2</code></dt><dd><p>wind speed (in km/h) at Lyon Saint-Exupery</p>
</dd>
<dt><code>S3</code></dt><dd><p>wind speed (in km/h) at Marseille Marignane</p>
</dd>
<dt><code>S4</code></dt><dd><p>wind speed (in km/h) at Montelimar</p>
</dd>
<dt><code>H2</code></dt><dd><p>humidity (in percentage) at Lyon Saint-Exupery</p>
</dd>
<dt><code>T2</code></dt><dd><p>mean temperature (in degree Celcius) at Lyon Saint-Exupery</p>
</dd>
</dl>

<p>The <code>metadata</code> attribute includes latitude and longitude (in degrees, minutes, seconds), altitude (in m), station name and station id.
</p>


<h3>Source</h3>

<p>European Climate Assessment and Dataset project <a href="https://www.ecad.eu/">https://www.ecad.eu/</a>
</p>


<h3>References</h3>

<p>Klein Tank, A.M.G. and Coauthors, 2002. Daily dataset of 20th-century surface air temperature and precipitation series for the
European Climate Assessment. Int. J. of Climatol., 22, 1441-1453.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(frwind, package = "mev")
head(frwind)
attr(frwind, which = "metadata")
</code></pre>

<hr>
<h2 id='geomagnetic'>Magnetic storms</h2><span id='topic+geomagnetic'></span>

<h3>Description</h3>

<p>Absolute magnitude of 373 geomagnetic storms lasting more than 48h with absolute magnitude (dst) larger than 100 in 1957-2014.
</p>


<h3>Format</h3>

<p>a vector of size 373
</p>


<h3>Note</h3>

<p>For a detailed article presenting the derivation of the Dst index, see <code>http://wdc.kugi.kyoto-u.ac.jp/dstdir/dst2/onDstindex.html</code>
</p>


<h3>Source</h3>

<p>Aki Vehtari
</p>


<h3>References</h3>

<p>World Data Center for Geomagnetism, Kyoto, M. Nose, T. Iyemori, M. Sugiura, T. Kamei (2015), <em>Geomagnetic Dst index</em>, &lt;doi:10.17593/14515-74000&gt;.
</p>

<hr>
<h2 id='gev'>Generalized extreme value distribution</h2><span id='topic+gev'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix, bias,
approximate ancillary statistics and sample space derivative
for the generalized extreme value distribution
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gev_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gev_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gev.Vfun</code></p>
</td></tr>
<tr><td><code id="gev_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="gev_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
</table>


<h3>Usage</h3>

<pre>gev.ll(par, dat)
gev.ll.optim(par, dat)
gev.score(par, dat)
gev.infomat(par, dat, method = c('obs','exp'))
gev.retlev(par, p)
gev.bias(par, n)
gev.Fscore(par, dat, method=c('obs','exp'))
gev.Vfun(par, dat)
gev.phi(par, dat, V)
gev.dphi(par, dat, V)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gev.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gev.ll.optim</code>: negative log likelihood parametrized in terms of location, <code>log(scale)</code> and shape
in order to perform unconstrained optimization
</p>
</li>
<li> <p><code>gev.score</code>: score vector
</p>
</li>
<li> <p><code>gev.infomat</code>: observed or expected information matrix
</p>
</li>
<li> <p><code>gev.retlev</code>: return level, corresponding to the <code class="reqn">(1-p)</code>th quantile
</p>
</li>
<li> <p><code>gev.bias</code>: Cox-Snell first order bias
</p>
</li>
<li> <p><code>gev.Fscore</code>: Firth's modified score equation
</p>
</li>
<li> <p><code>gev.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gev.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gev.dphi</code>: derivative matrix of the canonical parameter in the local exponential family approximation
</p>
</li></ul>



<h3>References</h3>

<p>Firth, D. (1993). Bias reduction of maximum likelihood estimates, <em>Biometrika</em>, <strong>80</strong>(1), 27&ndash;38.
</p>
<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer, 209 p.
</p>
<p>Cox, D. R. and E. J. Snell (1968). A general definition of residuals, <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <strong>30</strong>, 248&ndash;275.
</p>
<p>Cordeiro, G. M. and R. Klein (1994). Bias correction in ARMA models, <em>Statistics and Probability Letters</em>, <strong>19</strong>(3), 169&ndash;176.
</p>

<hr>
<h2 id='gev.abias'>Asymptotic bias of block maxima for fixed sample sizes</h2><span id='topic+gev.abias'></span>

<h3>Description</h3>

<p>Asymptotic bias of block maxima for fixed sample sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.abias(shape, rho)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.abias_+3A_shape">shape</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="gev.abias_+3A_rho">rho</code></td>
<td>
<p>second-order parameter, non-positive</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of length three containing the bias for location, scale and shape (in this order)
</p>


<h3>References</h3>

<p>Dombry, C. and A. Ferreira (2017). Maximum likelihood estimators based on the block maxima method. <code>https://arxiv.org/abs/1705.00465</code>
</p>

<hr>
<h2 id='gev.bcor'>Bias correction for GEV distribution</h2><span id='topic+gev.bcor'></span>

<h3>Description</h3>

<p>Bias corrected estimates for the generalized extreme value distribution using
Firth's modified score function or implicit bias subtraction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.bcor(par, dat, corr = c("subtract", "firth"), method = c("obs", "exp"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.bcor_+3A_par">par</code></td>
<td>
<p>parameter vector (<code>scale</code>, <code>shape</code>)</p>
</td></tr>
<tr><td><code id="gev.bcor_+3A_dat">dat</code></td>
<td>
<p>sample of observations</p>
</td></tr>
<tr><td><code id="gev.bcor_+3A_corr">corr</code></td>
<td>
<p>string indicating which correction to employ either <code>subtract</code> or <code>firth</code></p>
</td></tr>
<tr><td><code id="gev.bcor_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> &mdash; the default) information matrix. Used only if <code>corr='firth'</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method <code>subtract</code>solves
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\boldsymbol{\theta}} = \hat{\boldsymbol{\theta}} + b(\tilde{\boldsymbol{\theta}}</code>
</p>

<p>for <code class="reqn">\tilde{\boldsymbol{\theta}}</code>, using the first order term in the bias expansion as given by <code><a href="#topic+gev.bias">gev.bias</a></code>.
</p>
<p>The alternative is to use Firth's modified score and find the root of
</p>
<p style="text-align: center;"><code class="reqn">U(\tilde{\boldsymbol{\theta}})-i(\tilde{\boldsymbol{\theta}})b(\tilde{\boldsymbol{\theta}}),</code>
</p>

<p>where <code class="reqn">U</code> is the score vector, <code class="reqn">b</code> is the first order bias and <code class="reqn">i</code> is either the observed or Fisher information.
</p>
<p>The routine uses the MLE (bias-corrected) as starting values and proceeds
to find the solution using a root finding algorithm.
Since the bias-correction is not valid for <code class="reqn">\xi &lt; -1/3</code>, any solution that is unbounded
will return a vector of <code>NA</code> as the solution does not exist then.
</p>


<h3>Value</h3>

<p>vector of bias-corrected parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
dat &lt;- mev::rgev(n=40, loc = 1, scale=1, shape=-0.2)
par &lt;- mev::fit.gev(dat)$estimate
gev.bcor(par, dat, 'subtract')
gev.bcor(par, dat, 'firth') #observed information
gev.bcor(par, dat, 'firth','exp')
</code></pre>

<hr>
<h2 id='gev.bias'>Cox-Snell first order bias for the GEV distribution</h2><span id='topic+gev.bias'></span>

<h3>Description</h3>

<p>Bias vector for the GEV distribution based on an <code>n</code> sample.
Due to numerical instability, values of the information matrix and the bias
are linearly interpolated when the value of the shape parameter is close to zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.bias(par, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.bias_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.bias_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gev">gev</a></code>
</p>

<hr>
<h2 id='gev.Fscore'>Firth's modified score equation for the generalized extreme value distribution</h2><span id='topic+gev.Fscore'></span>

<h3>Description</h3>

<p>Firth's modified score equation for the generalized extreme value distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.Fscore(par, dat, method = "obs")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.Fscore_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.Fscore_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gev.Fscore_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected ('exp') or the observed ('obs' - the default) information matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Firth, D. (1993). Bias reduction of maximum likelihood estimates, <em>Biometrika</em>, <strong>80</strong>(1), 27&ndash;38.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gev">gev</a></code>
</p>

<hr>
<h2 id='gev.infomat'>Information matrix for the generalized extreme value distribution</h2><span id='topic+gev.infomat'></span>

<h3>Description</h3>

<p>The function returns the expected or observed information matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.infomat(par, dat, method = c("obs", "exp"), nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.infomat_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gev.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gev.infomat_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
</table>

<hr>
<h2 id='gev.ll'>log likelihood for the generalized extreme value distribution</h2><span id='topic+gev.ll'></span><span id='topic+gev.ll.optim'></span>

<h3>Description</h3>

<p>Function returning the density of an <code>n</code> sample from the GEV distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.ll(par, dat)

gev.ll.optim(par, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.ll_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>gev.ll.optim</code> returns the negative log likelihood parametrized in terms of location, <code>log(scale)</code> and shape in order to perform unconstrained optimization
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gev">gev</a></code>
</p>

<hr>
<h2 id='gev.mle'>Generalized extreme value maximum likelihood estimates for various quantities of interest</h2><span id='topic+gev.mle'></span>

<h3>Description</h3>

<p>This function calls the <code>fit.gev</code> routine on the sample of block maxima and returns maximum likelihood
estimates for all quantities of interest, including location, scale and shape parameters, quantiles and mean and
quantiles of maxima of <code>N</code> blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.mle(
  xdat,
  args = c("loc", "scale", "shape", "quant", "Nmean", "Nquant"),
  N,
  p,
  q
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.mle_+3A_xdat">xdat</code></td>
<td>
<p>sample vector of maxima</p>
</td></tr>
<tr><td><code id="gev.mle_+3A_args">args</code></td>
<td>
<p>vector of strings indicating which arguments to return the maximum likelihood values for.</p>
</td></tr>
<tr><td><code id="gev.mle_+3A_n">N</code></td>
<td>
<p>size of block over which to take maxima. Required only for <code>args</code> <code>Nmean</code> and <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gev.mle_+3A_p">p</code></td>
<td>
<p>tail probability. Required only for <code>arg</code> <code>quant</code>.</p>
</td></tr>
<tr><td><code id="gev.mle_+3A_q">q</code></td>
<td>
<p>level of quantile for maxima of <code>N</code> exceedances. Required only for <code>args</code> <code>Nquant</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named vector with maximum likelihood estimated parameter values for arguments <code>args</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- mev::rgev(n = 100, shape = 0.2)
gev.mle(xdat = dat, N = 100, p = 0.01, q = 0.5)

</code></pre>

<hr>
<h2 id='gev.Nyr'>N-year return levels, median and mean estimate</h2><span id='topic+gev.Nyr'></span>

<h3>Description</h3>

<p>N-year return levels, median and mean estimate
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.Nyr(par, nobs, N, type = c("retlev", "median", "mean"), p = 1/N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.Nyr_+3A_par">par</code></td>
<td>
<p>vector of location, scale and shape parameters for the GEV distribution</p>
</td></tr>
<tr><td><code id="gev.Nyr_+3A_nobs">nobs</code></td>
<td>
<p>integer number of observation on which the fit is based</p>
</td></tr>
<tr><td><code id="gev.Nyr_+3A_n">N</code></td>
<td>
<p>integer number of observations for return level. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gev.Nyr_+3A_type">type</code></td>
<td>
<p>string indicating the statistic to be calculated (can be abbreviated).</p>
</td></tr>
<tr><td><code id="gev.Nyr_+3A_p">p</code></td>
<td>
<p>probability indicating the return level, corresponding to the quantile at 1-1/p</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are <code class="reqn">n_y</code> observations per year, the <code>L</code>-year return level is obtained by taking
<code>N</code> equal to <code class="reqn">n_yL</code>.
</p>


<h3>Value</h3>

<p>a list with components
</p>

<ul>
<li><p>est point estimate
</p>
</li>
<li><p>var variance estimate based on delta-method
</p>
</li>
<li><p>type statistic
</p>
</li></ul>


<hr>
<h2 id='gev.pll'>Profile log-likelihood for the generalized extreme value distribution</h2><span id='topic+gev.pll'></span>

<h3>Description</h3>

<p>This function calculates the profile likelihood along with two small-sample corrections
based on Severini's (1999) empirical covariance and the Fraser and Reid tangent exponential
model approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.pll(
  psi,
  param = c("loc", "scale", "shape", "quant", "Nmean", "Nquant"),
  mod = "profile",
  dat,
  N = NULL,
  p = NULL,
  q = NULL,
  correction = TRUE,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.pll_+3A_psi">psi</code></td>
<td>
<p>parameter vector over which to profile (unidimensional)</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_param">param</code></td>
<td>
<p>string indicating the parameter to profile over</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_mod">mod</code></td>
<td>
<p>string indicating the model, one of <code>profile</code>, <code>tem</code> or <code>modif</code>.See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_n">N</code></td>
<td>
<p>size of block over which to take maxima. Required only for <code>param</code> <code>Nmean</code> and <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_p">p</code></td>
<td>
<p>tail probability. Required only for <code>param</code> <code>quant</code>.</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_q">q</code></td>
<td>
<p>probability level of quantile. Required only for <code>param</code> <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_correction">correction</code></td>
<td>
<p>logical indicating whether to use <code>spline.corr</code> to smooth the tem approximation.</p>
</td></tr>
<tr><td><code id="gev.pll_+3A_plot">plot</code></td>
<td>
<p>logical; should the profile likelihood be displayed? Default to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gev.pll_+3A_...">...</code></td>
<td>
<p>additional arguments such as output from call to <code>Vfun</code> if <code>mode='tem'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The two additional <code>mod</code> available are <code>tem</code>, the tangent exponential model (TEM) approximation and
<code>modif</code> for the penalized profile likelihood based on <code class="reqn">p^*</code> approximation proposed by Severini.
For the latter, the penalization is based on the TEM or an empirical covariance adjustment term.
</p>


<h3>Value</h3>

<p>a list with components
</p>

<ul>
<li> <p><code>mle</code>: maximum likelihood estimate
</p>
</li>
<li> <p><code>psi.max</code>: maximum profile likelihood estimate
</p>
</li>
<li> <p><code>param</code>: string indicating the parameter to profile over
</p>
</li>
<li> <p><code>std.error</code>: standard error of <code>psi.max</code>
</p>
</li>
<li> <p><code>psi</code>: vector of parameter <code class="reqn">\psi</code> given in <code>psi</code>
</p>
</li>
<li> <p><code>pll</code>: values of the profile log likelihood at <code>psi</code>
</p>
</li>
<li> <p><code>maxpll</code>: value of maximum profile log likelihood
</p>
</li></ul>

<p>In addition, if <code>mod</code> includes <code>tem</code>
</p>

<ul>
<li> <p><code>normal</code>: maximum likelihood estimate and standard error of the interest parameter <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>r</code>: values of likelihood root corresponding to <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>q</code>: vector of likelihood modifications
</p>
</li>
<li> <p><code>rstar</code>: modified likelihood root vector
</p>
</li>
<li> <p><code>rstar.old</code>: uncorrected modified likelihood root vector
</p>
</li>
<li> <p><code>tem.psimax</code>: maximum of the tangent exponential model likelihood
</p>
</li></ul>

<p>In addition, if <code>mod</code> includes <code>modif</code>
</p>

<ul>
<li> <p><code>tem.mle</code>: maximum of tangent exponential modified profile log likelihood
</p>
</li>
<li> <p><code>tem.profll</code>: values of the modified profile log likelihood at <code>psi</code>
</p>
</li>
<li> <p><code>tem.maxpll</code>: value of maximum modified profile log likelihood
</p>
</li>
<li> <p><code>empcov.mle</code>: maximum of Severini's empirical covariance modified profile log likelihood
</p>
</li>
<li> <p><code>empcov.profll</code>: values of the modified profile log likelihood at <code>psi</code>
</p>
</li>
<li> <p><code>empcov.maxpll</code>: value of maximum modified profile log likelihood
</p>
</li></ul>



<h3>References</h3>

<p>Fraser, D. A. S., Reid, N. and Wu, J. (1999), A simple general formula for tail probabilities for frequentist and Bayesian inference. <em>Biometrika</em>, <b>86</b>(2), 249&ndash;264.
</p>
<p>Severini, T. (2000) Likelihood Methods in Statistics. Oxford University Press. ISBN 9780198506508.
</p>
<p>Brazzale, A. R., Davison, A. C. and Reid, N. (2007) Applied asymptotics: case studies in small-sample statistics. Cambridge University Press, Cambridge. ISBN 978-0-521-84703-2
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(123)
dat &lt;- rgev(n = 100, loc = 0, scale = 2, shape = 0.3)
gev.pll(psi = seq(0,0.5, length = 50), param = 'shape', dat = dat)
gev.pll(psi = seq(-1.5, 1.5, length = 50), param = 'loc', dat = dat)
gev.pll(psi = seq(10, 40, length = 50), param = 'quant', dat = dat, p = 0.01)
gev.pll(psi = seq(12, 100, length = 50), param = 'Nmean', N = 100, dat = dat)
gev.pll(psi = seq(12, 90, length = 50), param = 'Nquant', N = 100, dat = dat, q = 0.5)

## End(Not run)
</code></pre>

<hr>
<h2 id='gev.retlev'>Return level for the generalized extreme value distribution</h2><span id='topic+gev.retlev'></span>

<h3>Description</h3>

<p>This function returns the <code class="reqn">1-p</code>th quantile of the GEV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.retlev(par, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.retlev_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.retlev_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gev">gev</a></code>
</p>

<hr>
<h2 id='gev.score'>Score vector for the generalized extreme value distribution</h2><span id='topic+gev.score'></span>

<h3>Description</h3>

<p>Score vector for the generalized extreme value distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.score(par, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.score_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
</table>

<hr>
<h2 id='gev.tem'>Tangent exponential model approximation for the GEV distribution</h2><span id='topic+gev.tem'></span>

<h3>Description</h3>

<p>The function <code>gev.tem</code> provides a tangent exponential model (TEM) approximation
for higher order likelihood inference for a scalar parameter for the generalized extreme value distribution.
Options include location scale and shape parameters as well as value-at-risk (or return levels).
The function attempts to find good values for <code>psi</code> that will
cover the range of options, but the fail may fit and return an error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.tem(
  param = c("loc", "scale", "shape", "quant", "Nmean", "Nquant"),
  dat,
  psi = NULL,
  p = NULL,
  q = 0.5,
  N = NULL,
  n.psi = 50,
  plot = TRUE,
  correction = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.tem_+3A_param">param</code></td>
<td>
<p>parameter over which to profile</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_dat">dat</code></td>
<td>
<p>sample vector for the GEV distribution</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_psi">psi</code></td>
<td>
<p>scalar or ordered vector of values for the interest parameter. If <code>NULL</code> (default), a grid of values centered at the MLE is selected</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_p">p</code></td>
<td>
<p>tail probability for the (1-p)th quantile (return levels). Required only if <code>param = 'retlev'</code></p>
</td></tr>
<tr><td><code id="gev.tem_+3A_q">q</code></td>
<td>
<p>probability level of quantile. Required only for <code>param</code> <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_n">N</code></td>
<td>
<p>size of block over which to take maxima. Required only for <code>param</code> <code>Nmean</code> and <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_n.psi">n.psi</code></td>
<td>
<p>number of values of <code>psi</code> at which the likelihood is computed, if <code>psi</code> is not supplied (<code>NULL</code>). Odd values are more prone to give rise to numerical instabilities near the MLE. If <code>psi</code> is a vector of length 2 and <code>n.psi</code> is greater than 2, these are taken to be endpoints of the sequence.</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_plot">plot</code></td>
<td>
<p>logical indicating whether <code>plot.fr</code> should be called upon exit</p>
</td></tr>
<tr><td><code id="gev.tem_+3A_correction">correction</code></td>
<td>
<p>logical indicating whether <a href="#topic+spline.corr">spline.corr</a> should be called.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an invisible object of class <code>fr</code> (see <code>tem</code> in package <code>hoa</code>) with elements
</p>

<ul>
<li> <p><code>normal</code>: maximum likelihood estimate and standard error of the interest parameter <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>par.hat</code>: maximum likelihood estimates
</p>
</li>
<li> <p><code>par.hat.se</code>: standard errors of maximum likelihood estimates
</p>
</li>
<li> <p><code>th.rest</code>: estimated maximum profile likelihood at (<code class="reqn">\psi</code>, <code class="reqn">\hat{\lambda}</code>)
</p>
</li>
<li> <p><code>r</code>: values of likelihood root corresponding to <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>psi</code>: vector of interest parameter
</p>
</li>
<li> <p><code>q</code>: vector of likelihood modifications
</p>
</li>
<li> <p><code>rstar</code>: modified likelihood root vector
</p>
</li>
<li> <p><code>rstar.old</code>: uncorrected modified likelihood root vector
</p>
</li>
<li> <p><code>param</code>: parameter
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1234)
dat &lt;- rgev(n = 40, loc = 0, scale = 2, shape = -0.1)
gev.tem('shape', dat = dat, plot = TRUE)
gev.tem('quant', dat = dat, p = 0.01, plot = TRUE)
gev.tem('scale', psi = seq(1, 4, by = 0.1), dat = dat, plot = TRUE)
dat &lt;- rgev(n = 40, loc = 0, scale = 2, shape = 0.2)
gev.tem('loc', dat = dat, plot = TRUE)
gev.tem('Nmean', dat = dat, p = 0.01, N=100, plot = TRUE)
gev.tem('Nquant', dat = dat, q = 0.5, N=100, plot = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='gev.temstat'>Tangent exponential model statistics for the generalized extreme value distribution</h2><span id='topic+gev.temstat'></span><span id='topic+gev.Vfun'></span><span id='topic+gev.phi'></span><span id='topic+gev.dphi'></span>

<h3>Description</h3>

<p>Matrix of approximate ancillary statistics, sample space derivative of the
log likelihood and mixed derivative for the generalized extreme value distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gev.Vfun(par, dat)

gev.phi(par, dat, V)

gev.dphi(par, dat, V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gev.temstat_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gev.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gev.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gev.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gev">gev</a></code>
</p>

<hr>
<h2 id='gevdist'>Generalized extreme value distribution</h2><span id='topic+gevdist'></span><span id='topic+qgev'></span><span id='topic+rgev'></span><span id='topic+dgev'></span><span id='topic+pgev'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random number generation for the generalized extreme value
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qgev(p, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)

rgev(n, loc = 0, scale = 1, shape = 0)

dgev(x, loc = 0, scale = 1, shape = 0, log = FALSE)

pgev(q, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevdist_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="gevdist_+3A_loc">loc</code></td>
<td>
<p>scalar or vector of location parameters whose length matches that of the input</p>
</td></tr>
<tr><td><code id="gevdist_+3A_scale">scale</code></td>
<td>
<p>scalar or vector of positive scale parameters whose length matches that of the input</p>
</td></tr>
<tr><td><code id="gevdist_+3A_shape">shape</code></td>
<td>
<p>scalar shape parameter</p>
</td></tr>
<tr><td><code id="gevdist_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), returns the distribution function, otherwise the survival function</p>
</td></tr>
<tr><td><code id="gevdist_+3A_n">n</code></td>
<td>
<p>scalar number of observations</p>
</td></tr>
<tr><td><code id="gevdist_+3A_x">x</code>, <code id="gevdist_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="gevdist_+3A_log">log</code>, <code id="gevdist_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities <code class="reqn">p</code> are given as
<code class="reqn">\log(p)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distribution function of a GEV distribution with parameters
<code>loc</code> = <code class="reqn">\mu</code>, <code>scale</code> = <code class="reqn">\sigma</code> and
<code>shape</code> = <code class="reqn">\xi</code> is
</p>
<p style="text-align: center;"><code class="reqn">F(x) = \exp\{-[1 + \xi (x - \mu) / \sigma] ^ {-1/\xi} \}</code>
</p>

<p>for <code class="reqn">1 + \xi (x - \mu) / \sigma &gt; 0</code>.  If <code class="reqn">\xi = 0</code> the
distribution function is defined as the limit as <code class="reqn">\xi</code> tends to zero.
</p>
<p>The quantile function, when evaluated at zero or one,
returns the lower and upper endpoint, whether the latter is finite or not.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile, with code adapted from Paul Northrop
</p>


<h3>References</h3>

<p>Jenkinson, A. F. (1955) The frequency distribution of the
annual maximum (or minimum) of meteorological elements.
<em>Quart. J. R. Met. Soc.</em>, <strong>81</strong>, 158-171.
Chapter 3: <a href="https://doi.org/10.1002/qj.49708134804">doi:10.1002/qj.49708134804</a>
</p>
<p>Coles, S. G. (2001) <em>An Introduction to Statistical
Modeling of Extreme Values</em>, Springer-Verlag, London.
<a href="https://doi.org/10.1007/978-1-4471-3675-0_3">doi:10.1007/978-1-4471-3675-0_3</a>
</p>

<hr>
<h2 id='gevN'>Generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</h2><span id='topic+gevN'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix,
approximate ancillary statistics and sample space derivative
for the generalized extreme value distribution  parametrized in terms of the
quantiles/mean of N-block maxima parametrization <code class="reqn">z</code>, scale and shape.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevN_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, quantile/mean of N-block maximum and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevN_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevN_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gevN.Vfun</code></p>
</td></tr>
<tr><td><code id="gevN_+3A_q">q</code></td>
<td>
<p>probability, corresponding to <code class="reqn">q</code>th quantile of the <code>N</code>-block maximum</p>
</td></tr>
<tr><td><code id="gevN_+3A_qty">qty</code></td>
<td>
<p>string indicating whether to calculate the <code>q</code> quantile or the mean</p>
</td></tr>
</table>


<h3>Usage</h3>

<pre>gevN.ll(par, dat, N, q, qty = c('mean', 'quantile'))
gevN.ll.optim(par, dat, N, q = 0.5, qty = c('mean', 'quantile'))
gevN.score(par, dat, N, q = 0.5, qty = c('mean', 'quantile'))
gevN.infomat(par, dat, qty = c('mean', 'quantile'), method = c('obs', 'exp'), N, q = 0.5, nobs = length(dat))
gevN.Vfun(par, dat, N, q = 0.5, qty = c('mean', 'quantile'))
gevN.phi(par, dat, N, q = 0.5, qty = c('mean', 'quantile'), V)
gevN.dphi(par, dat, N, q = 0.5, qty = c('mean', 'quantile'), V)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gevN.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gevN.score</code>: score vector
</p>
</li>
<li> <p><code>gevN.infomat</code>: expected and observed information matrix
</p>
</li>
<li> <p><code>gevN.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gevN.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gevN.dphi</code>: derivative matrix of the canonical parameter in the local exponential family approximation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>

<hr>
<h2 id='gevN.infomat'>Information matrix of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</h2><span id='topic+gevN.infomat'></span>

<h3>Description</h3>

<p>Information matrix of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevN.infomat(
  par,
  dat,
  method = c("obs", "exp"),
  qty = c("mean", "quantile"),
  N,
  q = 0.5,
  nobs = length(dat)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevN.infomat_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, quantile/mean of N-block maximum and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevN.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevN.infomat_+3A_qty">qty</code></td>
<td>
<p>string indicating whether to calculate the <code>q</code> quantile or the mean</p>
</td></tr>
<tr><td><code id="gevN.infomat_+3A_q">q</code></td>
<td>
<p>probability, corresponding to <code class="reqn">q</code>th quantile of the <code>N</code>-block maximum</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevN">gevN</a></code>
</p>

<hr>
<h2 id='gevN.ll'>Negative log likelihood of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</h2><span id='topic+gevN.ll'></span>

<h3>Description</h3>

<p>Negative log likelihood of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevN.ll(par, dat, N, q = 0.5, qty = c("mean", "quantile"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevN.ll_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, quantile/mean of N-block maximum and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevN.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevN.ll_+3A_q">q</code></td>
<td>
<p>probability, corresponding to <code class="reqn">q</code>th quantile of the <code>N</code>-block maximum</p>
</td></tr>
<tr><td><code id="gevN.ll_+3A_qty">qty</code></td>
<td>
<p>string indicating whether to calculate the <code>q</code> quantile or the mean</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevN">gevN</a></code>
</p>

<hr>
<h2 id='gevN.mean'>This function returns the mean of N observations from the GEV.</h2><span id='topic+gevN.mean'></span>

<h3>Description</h3>

<p>This function returns the mean of N observations from the GEV.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevN.mean(par, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevN.mean_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, quantile/mean of N-block maximum and <code>shape</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevN">gevN</a></code>
</p>

<hr>
<h2 id='gevN.score'>Score of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)</h2><span id='topic+gevN.score'></span>

<h3>Description</h3>

<p>Score of the generalized extreme value distribution (quantile/mean of N-block maxima parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevN.score(par, dat, N, q = 0.5, qty = c("mean", "quantile"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevN.score_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, quantile/mean of N-block maximum and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevN.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevN.score_+3A_q">q</code></td>
<td>
<p>probability, corresponding to <code class="reqn">q</code>th quantile of the <code>N</code>-block maximum</p>
</td></tr>
<tr><td><code id="gevN.score_+3A_qty">qty</code></td>
<td>
<p>string indicating whether to calculate the <code>q</code> quantile or the mean</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevN">gevN</a></code>
</p>

<hr>
<h2 id='gevN.temstat'>Tangent exponential model statistics for the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</h2><span id='topic+gevN.temstat'></span><span id='topic+gevN.Vfun'></span><span id='topic+gevN.phi'></span><span id='topic+gevN.dphi'></span>

<h3>Description</h3>

<p>Vector implementing conditioning on approximate ancillary statistics for the TEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevN.Vfun(par, dat, N, q = 0.5, qty = c("mean", "quantile"))

gevN.phi(par, dat, N, q = 0.5, qty = c("mean", "quantile"), V)

gevN.dphi(par, dat, N, q = 0.5, qty = c("mean", "quantile"), V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevN.temstat_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, quantile/mean of N-block maximum and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevN.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevN.temstat_+3A_q">q</code></td>
<td>
<p>probability, corresponding to <code class="reqn">q</code>th quantile of the <code>N</code>-block maximum</p>
</td></tr>
<tr><td><code id="gevN.temstat_+3A_qty">qty</code></td>
<td>
<p>string indicating whether to calculate the <code>q</code> quantile or the mean</p>
</td></tr>
<tr><td><code id="gevN.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gevN.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevN">gevN</a></code>
</p>

<hr>
<h2 id='gevr'>Generalized extreme value distribution (return level parametrization)</h2><span id='topic+gevr'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix,
approximate ancillary statistics and sample space derivative
for the generalized extreme value distribution  parametrized in terms of the return level <code class="reqn">z</code>, scale and shape.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevr_+3A_par">par</code></td>
<td>
<p>vector of <code>retlev</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevr_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevr_+3A_p">p</code></td>
<td>
<p>tail probability, corresponding to <code class="reqn">(1-p)</code>th quantile for <code class="reqn">z</code></p>
</td></tr>
<tr><td><code id="gevr_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gevr_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="gevr_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gevr.Vfun</code></p>
</td></tr>
</table>


<h3>Usage</h3>

<pre>gevr.ll(par, dat, p)
gevr.ll.optim(par, dat, p)
gevr.score(par, dat, p)
gevr.infomat(par, dat, p, method = c('obs', 'exp'), nobs = length(dat))
gevr.Vfun(par, dat, p)
gevr.phi(par, dat, p, V)
gevr.dphi(par, dat, p, V)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gevr.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gevr.ll.optim</code>: negative log likelihood parametrized in terms of return levels, <code>log(scale)</code> and shape in order to perform unconstrained optimization
</p>
</li>
<li> <p><code>gevr.score</code>: score vector
</p>
</li>
<li> <p><code>gevr.infomat</code>: observed information matrix
</p>
</li>
<li> <p><code>gevr.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gevr.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gevr.dphi</code>: derivative matrix of the canonical parameter in the local exponential family approximation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>

<hr>
<h2 id='gevr.infomat'>Observed information matrix for GEV distribution (return levels)</h2><span id='topic+gevr.infomat'></span>

<h3>Description</h3>

<p>The information matrix is parametrized in terms of return level (<code class="reqn">(1-p)</code>th quantile), scale and shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevr.infomat(par, dat, method = c("obs", "exp"), p, nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevr.infomat_+3A_par">par</code></td>
<td>
<p>vector of <code>retlev</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevr.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevr.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gevr.infomat_+3A_p">p</code></td>
<td>
<p>tail probability, corresponding to <code class="reqn">(1-p)</code>th quantile for <code class="reqn">z</code></p>
</td></tr>
<tr><td><code id="gevr.infomat_+3A_nobs">nobs</code></td>
<td>
<p>integer number of observations</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevr">gevr</a></code>
</p>

<hr>
<h2 id='gevr.ll'>Negative log likelihood of the generalized extreme value distribution (return levels)</h2><span id='topic+gevr.ll'></span><span id='topic+gevr.ll.optim'></span>

<h3>Description</h3>

<p>Negative log likelihood of the generalized extreme value distribution (return levels)
</p>
<p>Negative log likelihood parametrized in terms of location, log return level and shape in order to perform unconstrained optimization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevr.ll(par, dat, p)

gevr.ll.optim(par, dat, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevr.ll_+3A_par">par</code></td>
<td>
<p>vector of <code>retlev</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevr.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevr.ll_+3A_p">p</code></td>
<td>
<p>tail probability, corresponding to <code class="reqn">(1-p)</code>th quantile for <code class="reqn">z</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevr">gevr</a></code>
</p>

<hr>
<h2 id='gevr.score'>Score of the log likelihood for the GEV distribution (return levels)</h2><span id='topic+gevr.score'></span>

<h3>Description</h3>

<p>Score of the log likelihood for the GEV distribution (return levels)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevr.score(par, dat, p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevr.score_+3A_par">par</code></td>
<td>
<p>vector of <code>retlev</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevr.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevr.score_+3A_p">p</code></td>
<td>
<p>tail probability, corresponding to <code class="reqn">(1-p)</code>th quantile for <code class="reqn">z</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevr">gevr</a></code>
</p>

<hr>
<h2 id='gevr.temstat'>Tangent exponential model statistics for the GEV distribution (return level)</h2><span id='topic+gevr.temstat'></span><span id='topic+gevr.Vfun'></span><span id='topic+gevr.phi'></span><span id='topic+gevr.dphi'></span>

<h3>Description</h3>

<p>Vector implementing conditioning on approximate ancillary statistics for the TEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gevr.Vfun(par, dat, p)

gevr.phi(par, dat, p, V)

gevr.dphi(par, dat, p, V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gevr.temstat_+3A_par">par</code></td>
<td>
<p>vector of <code>retlev</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gevr.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gevr.temstat_+3A_p">p</code></td>
<td>
<p>tail probability, corresponding to <code class="reqn">(1-p)</code>th quantile for <code class="reqn">z</code></p>
</td></tr>
<tr><td><code id="gevr.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gevr.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gevr">gevr</a></code>
</p>

<hr>
<h2 id='gp.fit'>Maximum likelihood estimate of generalized Pareto applied to threshold exceedances</h2><span id='topic+gp.fit'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+fit.gpd">fit.gpd</a></code> is a wrapper around <code>gp.fit</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gp.fit(
  xdat,
  threshold,
  method = c("Grimshaw", "auglag", "nlm", "optim", "ismev", "zs", "zhang"),
  show = FALSE,
  MCMC = NULL,
  fpar = NULL,
  warnSE = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gp.fit_+3A_xdat">xdat</code></td>
<td>
<p>a numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="gp.fit_+3A_threshold">threshold</code></td>
<td>
<p>the chosen threshold.</p>
</td></tr>
<tr><td><code id="gp.fit_+3A_method">method</code></td>
<td>
<p>the method to be used. See <b>Details</b>. Can be abbreviated.</p>
</td></tr>
<tr><td><code id="gp.fit_+3A_show">show</code></td>
<td>
<p>logical; if <code>TRUE</code> (the default), print details of the fit.</p>
</td></tr>
<tr><td><code id="gp.fit_+3A_mcmc">MCMC</code></td>
<td>
<p><code>NULL</code> for frequentist estimates, otherwise a boolean or a list with parameters passed. If <code>TRUE</code>, runs a Metropolis-Hastings sampler to get posterior mean estimates. Can be used to pass arguments <code>niter</code>, <code>burnin</code> and <code>thin</code> to the sampler as a list.</p>
</td></tr>
<tr><td><code id="gp.fit_+3A_fpar">fpar</code></td>
<td>
<p>a named list with fixed parameters, either <code>scale</code> or <code>shape</code></p>
</td></tr>
<tr><td><code id="gp.fit_+3A_warnse">warnSE</code></td>
<td>
<p>logical; if <code>TRUE</code>, a warning is printed if the standard errors cannot be returned from the observed information matrix when the shape is less than -0.5.</p>
</td></tr>
</table>

<hr>
<h2 id='gpd'>Generalized Pareto distribution</h2><span id='topic+gpd'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix, bias,
approximate ancillary statistics and sample space derivative
for the generalized Pareto distribution
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpd_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for the exponential model</p>
</td></tr>
<tr><td><code id="gpd_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gpd_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpd.Vfun</code></p>
</td></tr>
<tr><td><code id="gpd_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>Usage</h3>

<pre>gpd.ll(par, dat, tol=1e-5)
gpd.ll.optim(par, dat, tol=1e-5)
gpd.score(par, dat)
gpd.infomat(par, dat, method = c('obs','exp'))
gpd.bias(par, n)
gpd.Fscore(par, dat, method = c('obs','exp'))
gpd.Vfun(par, dat)
gpd.phi(par, dat, V)
gpd.dphi(par, dat, V)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gpd.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gpd.ll.optim</code>: negative log likelihood parametrized in terms of <code>log(scale)</code> and shape
in order to perform unconstrained optimization
</p>
</li>
<li> <p><code>gpd.score</code>: score vector
</p>
</li>
<li> <p><code>gpd.infomat</code>: observed or expected information matrix
</p>
</li>
<li> <p><code>gpd.bias</code>: Cox-Snell first order bias
</p>
</li>
<li> <p><code>gpd.Fscore</code>: Firth's modified score equation
</p>
</li>
<li> <p><code>gpd.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gpd.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gpd.dphi</code>: derivative matrix of the canonical parameter in the local
exponential family approximation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Firth, D. (1993). Bias reduction of maximum likelihood estimates, <em>Biometrika</em>, <strong>80</strong>(1), 27&ndash;38.
</p>
<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer, 209 p.
</p>
<p>Cox, D. R. and E. J. Snell (1968). A general definition of residuals, <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <strong>30</strong>, 248&ndash;275.
</p>
<p>Cordeiro, G. M. and R. Klein (1994). Bias correction in ARMA models, <em>Statistics and Probability Letters</em>, <strong>19</strong>(3), 169&ndash;176.
</p>
<p>Giles, D. E., Feng, H. and R. T. Godwin (2016).  Bias-corrected maximum likelihood estimation of the  parameters of the generalized Pareto distribution, <em>Communications in Statistics - Theory and Methods</em>, <strong>45</strong>(8), 2465&ndash;2483.
</p>

<hr>
<h2 id='gpd.abias'>Asymptotic bias of threshold exceedances for k order statistics</h2><span id='topic+gpd.abias'></span>

<h3>Description</h3>

<p>The formula given in de Haan and Ferreira, 2007 (Springer). Note that the latter differs from that found in Drees, Ferreira and de Haan.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.abias(shape, rho)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.abias_+3A_shape">shape</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="gpd.abias_+3A_rho">rho</code></td>
<td>
<p>second-order parameter, non-positive</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of length containing the bias for scale and shape (in this order)
</p>


<h3>References</h3>

<p>Dombry, C. and A. Ferreira (2017). Maximum likelihood estimators based on the block maxima method. <code>https://arxiv.org/abs/1705.00465</code>
</p>

<hr>
<h2 id='gpd.bcor'>Bias correction for GP distribution</h2><span id='topic+gpd.bcor'></span>

<h3>Description</h3>

<p>Bias corrected estimates for the generalized Pareto distribution using
Firth's modified score function or implicit bias subtraction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.bcor(par, dat, corr = c("subtract", "firth"), method = c("obs", "exp"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.bcor_+3A_par">par</code></td>
<td>
<p>parameter vector (<code>scale</code>, <code>shape</code>)</p>
</td></tr>
<tr><td><code id="gpd.bcor_+3A_dat">dat</code></td>
<td>
<p>sample of observations</p>
</td></tr>
<tr><td><code id="gpd.bcor_+3A_corr">corr</code></td>
<td>
<p>string indicating which correction to employ either <code>subtract</code> or <code>firth</code></p>
</td></tr>
<tr><td><code id="gpd.bcor_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> &mdash; the default) information matrix. Used only if <code>corr='firth'</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Method <code>subtract</code> solves
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\boldsymbol{\theta}} = \hat{\boldsymbol{\theta}} + b(\tilde{\boldsymbol{\theta}}</code>
</p>

<p>for <code class="reqn">\tilde{\boldsymbol{\theta}}</code>, using the first order term in the bias expansion as given by <code><a href="#topic+gpd.bias">gpd.bias</a></code>.
</p>
<p>The alternative is to use Firth's modified score and find the root of
</p>
<p style="text-align: center;"><code class="reqn">U(\tilde{\boldsymbol{\theta}})-i(\tilde{\boldsymbol{\theta}})b(\tilde{\boldsymbol{\theta}}),</code>
</p>

<p>where <code class="reqn">U</code> is the score vector, <code class="reqn">b</code> is the first order bias and <code class="reqn">i</code> is either the observed or Fisher information.
</p>
<p>The routine uses the MLE as starting value and proceeds
to find the solution using a root finding algorithm.
Since the bias-correction is not valid for <code class="reqn">\xi &lt; -1/3</code>, any solution that is unbounded
will return a vector of <code>NA</code> as the bias correction does not exist then.
</p>


<h3>Value</h3>

<p>vector of bias-corrected parameters
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
dat &lt;- rgp(n=40, scale=1, shape=-0.2)
par &lt;- gp.fit(dat, threshold=0, show=FALSE)$estimate
gpd.bcor(par,dat, 'subtract')
gpd.bcor(par,dat, 'firth') #observed information
gpd.bcor(par,dat, 'firth','exp')
</code></pre>

<hr>
<h2 id='gpd.bias'>Cox-Snell first order bias expression for the generalized Pareto distribution</h2><span id='topic+gpd.bias'></span>

<h3>Description</h3>

<p>Bias vector for the GP distribution based on an <code>n</code> sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.bias(par, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.bias_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd.bias_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer, 209 p.
</p>
<p>Cox, D. R. and E. J. Snell (1968). A general definition of residuals, <em>Journal of the Royal Statistical Society: Series B (Methodological)</em>, <strong>30</strong>, 248&ndash;275.
</p>
<p>Cordeiro, G. M. and R. Klein (1994). Bias correction in ARMA models, <em>Statistics and Probability Letters</em>, <strong>19</strong>(3), 169&ndash;176.
</p>
<p>Giles, D. E., Feng, H. and R. T. Godwin (2016).  Bias-corrected maximum likelihood estimation of the  parameters of the generalized Pareto distribution, <em>Communications in Statistics - Theory and Methods</em>, <strong>45</strong>(8), 2465&ndash;2483.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>, <code><a href="#topic+gpd.bcor">gpd.bcor</a></code>
</p>

<hr>
<h2 id='gpd.boot'>Bootstrap approximation for generalized Pareto parameters</h2><span id='topic+gpd.boot'></span>

<h3>Description</h3>

<p>Given an object of class <code>mev_gpd</code>,
returns a matrix of parameter values to mimic
the estimation uncertainty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.boot(object, B = 1000L, method = c("post", "norm"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.boot_+3A_object">object</code></td>
<td>
<p>object of class <code>mev_gpd</code></p>
</td></tr>
<tr><td><code id="gpd.boot_+3A_b">B</code></td>
<td>
<p>number of pairs to sample</p>
</td></tr>
<tr><td><code id="gpd.boot_+3A_method">method</code></td>
<td>
<p>string; one of <code>'norm'</code> for the
normal approximation or <code>'post'</code> (default) for posterior sampling</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two options are available: a normal approximation to
the scale and shape based on the maximum likelihood
estimates and the observed information matrix.
This method uses forward sampling to simulate
from a bivariate normal distribution that satisfies
the support and positivity constraints
</p>
<p>The second approximation uses the ratio-of-uniforms
method to obtain samples from the posterior
distribution with uninformative priors, thus
mimicking the joint distribution of maximum likelihood.
The benefit of the latter is that it is more reliable
in small samples and when the shape is negative.
</p>


<h3>Value</h3>

<p>a matrix of size B by 2 whose columns contain scale and shape parameters
</p>

<hr>
<h2 id='gpd.Fscore'>Firth's modified score equation for the generalized Pareto distribution</h2><span id='topic+gpd.Fscore'></span>

<h3>Description</h3>

<p>Firth's modified score equation for the generalized Pareto distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.Fscore(par, dat, method = c("obs", "exp"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.Fscore_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd.Fscore_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpd.Fscore_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Firth, D. (1993). Bias reduction of maximum likelihood estimates, <em>Biometrika</em>, <strong>80</strong>(1), 27&ndash;38.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>, <code><a href="#topic+gpd.bcor">gpd.bcor</a></code>
</p>

<hr>
<h2 id='gpd.infomat'>Information matrix for the generalized Pareto distribution</h2><span id='topic+gpd.infomat'></span>

<h3>Description</h3>

<p>The function returns the expected or observed information matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.infomat(par, dat, method = c("obs", "exp"), nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.infomat_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpd.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gpd.infomat_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>
</p>

<hr>
<h2 id='gpd.ll'>Log likelihood for the generalized Pareto distribution</h2><span id='topic+gpd.ll'></span><span id='topic+gpd.ll.optim'></span>

<h3>Description</h3>

<p>Function returning the density of an <code>n</code> sample from the GP distribution.
<code>gpd.ll.optim</code> returns the negative log likelihood parametrized in terms of <code>log(scale)</code> and shape
in order to perform unconstrained optimization. The function is coded in such a way that the log likelihood is infinite when <code class="reqn">\xi &lt; -1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.ll(par, dat, tol = 1e-05)

gpd.ll.optim(par, dat, tol = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.ll_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpd.ll_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for the exponential model</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>
</p>

<hr>
<h2 id='gpd.mle'>Generalized Pareto maximum likelihood estimates for various quantities of interest</h2><span id='topic+gpd.mle'></span>

<h3>Description</h3>

<p>This function calls the <code>fit.gpd</code> routine on the sample of excesses and returns maximum likelihood
estimates for all quantities of interest, including scale and shape parameters, quantiles and value-at-risk,
expected shortfall and mean and quantiles of maxima of <code>N</code> threshold exceedances
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.mle(
  xdat,
  args = c("scale", "shape", "quant", "VaR", "ES", "Nmean", "Nquant"),
  m,
  N,
  p,
  q
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.mle_+3A_xdat">xdat</code></td>
<td>
<p>sample vector of excesses</p>
</td></tr>
<tr><td><code id="gpd.mle_+3A_args">args</code></td>
<td>
<p>vector of strings indicating which arguments to return the maximum likelihood values for</p>
</td></tr>
<tr><td><code id="gpd.mle_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. Required only for <code>args</code> values <code>'VaR'</code> or <code>'ES'</code></p>
</td></tr>
<tr><td><code id="gpd.mle_+3A_n">N</code></td>
<td>
<p>size of block over which to take maxima. Required only for <code>args</code> <code>Nmean</code> and <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gpd.mle_+3A_p">p</code></td>
<td>
<p>tail probability, equivalent to <code class="reqn">1/m</code>. Required only for <code>args</code> <code>quant</code>.</p>
</td></tr>
<tr><td><code id="gpd.mle_+3A_q">q</code></td>
<td>
<p>level of quantile for N-block maxima. Required only for <code>args</code> <code>Nquant</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>named vector with maximum likelihood values for arguments <code>args</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xdat &lt;- mev::rgp(n = 30, shape = 0.2)
gpd.mle(xdat = xdat, N = 100, p = 0.01, q = 0.5, m = 100)
</code></pre>

<hr>
<h2 id='gpd.pll'>Profile log-likelihood for the generalized Pareto distribution</h2><span id='topic+gpd.pll'></span>

<h3>Description</h3>

<p>This function calculates the (modified) profile likelihood based on the <code class="reqn">p^*</code> formula.
There are two small-sample corrections that use a proxy for
<code class="reqn">\ell_{\lambda; \hat{\lambda}}</code>,
which are based on Severini's (1999) empirical covariance
and the Fraser and Reid tangent exponential model approximation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.pll(
  psi,
  param = c("scale", "shape", "quant", "VaR", "ES", "Nmean", "Nquant"),
  mod = "profile",
  mle = NULL,
  dat,
  m = NULL,
  N = NULL,
  p = NULL,
  q = NULL,
  correction = TRUE,
  threshold = NULL,
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.pll_+3A_psi">psi</code></td>
<td>
<p>parameter vector over which to profile (unidimensional)</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_param">param</code></td>
<td>
<p>string indicating the parameter to profile over</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_mod">mod</code></td>
<td>
<p>string indicating the model. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_mle">mle</code></td>
<td>
<p>maximum likelihood estimate in <code class="reqn">(\psi, \xi)</code> parametrization if <code class="reqn">\psi \neq \xi</code> and <code class="reqn">(\sigma, \xi)</code> otherwise (optional).</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_dat">dat</code></td>
<td>
<p>sample vector of excesses, unless <code>threshold</code> is provided (in which case user provides original data)</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. Required only for <code>args</code> values <code>'VaR'</code> or <code>'ES'</code></p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_n">N</code></td>
<td>
<p>size of block over which to take maxima. Required only for <code>args</code> <code>Nmean</code> and <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_p">p</code></td>
<td>
<p>tail probability, equivalent to <code class="reqn">1/m</code>. Required only for <code>args</code> <code>quant</code>.</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_q">q</code></td>
<td>
<p>level of quantile for N-block maxima. Required only for <code>args</code> <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_correction">correction</code></td>
<td>
<p>logical indicating whether to use <code>spline.corr</code> to smooth the tem approximation.</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_threshold">threshold</code></td>
<td>
<p>numerical threshold above which to fit the generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_plot">plot</code></td>
<td>
<p>logical; should the profile likelihood be displayed? Default to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="gpd.pll_+3A_...">...</code></td>
<td>
<p>additional arguments such as output from call to <code>Vfun</code> if <code>mode='tem'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three <code>mod</code> available are <code>profile</code> (the default), <code>tem</code>, the tangent exponential model (TEM) approximation and
<code>modif</code> for the penalized profile likelihood based on <code class="reqn">p^*</code> approximation proposed by Severini.
For the latter, the penalization is based on the TEM or an empirical covariance adjustment term.
</p>


<h3>Value</h3>

<p>a list with components
</p>

<ul>
<li> <p><code>mle</code>: maximum likelihood estimate
</p>
</li>
<li> <p><code>psi.max</code>: maximum profile likelihood estimate
</p>
</li>
<li> <p><code>param</code>: string indicating the parameter to profile over
</p>
</li>
<li> <p><code>std.error</code>: standard error of <code>psi.max</code>
</p>
</li>
<li> <p><code>psi</code>: vector of parameter <code class="reqn">\psi</code> given in <code>psi</code>
</p>
</li>
<li> <p><code>pll</code>: values of the profile log likelihood at <code>psi</code>
</p>
</li>
<li> <p><code>maxpll</code>: value of maximum profile log likelihood
</p>
</li>
<li> <p><code>family</code>: a string indicating &quot;gpd&quot;
</p>
</li>
<li> <p><code>threshold</code>: value of the threshold, by default zero
</p>
</li></ul>

<p>In addition, if <code>mod</code> includes <code>tem</code>
</p>

<ul>
<li> <p><code>normal</code>: maximum likelihood estimate and standard error of the interest parameter <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>r</code>: values of likelihood root corresponding to <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>q</code>: vector of likelihood modifications
</p>
</li>
<li> <p><code>rstar</code>: modified likelihood root vector
</p>
</li>
<li> <p><code>rstar.old</code>: uncorrected modified likelihood root vector
</p>
</li>
<li> <p><code>tem.psimax</code>: maximum of the tangent exponential model likelihood
</p>
</li></ul>

<p>In addition, if <code>mod</code> includes <code>modif</code>
</p>

<ul>
<li> <p><code>tem.mle</code>: maximum of tangent exponential modified profile log likelihood
</p>
</li>
<li> <p><code>tem.profll</code>: values of the modified profile log likelihood at <code>psi</code>
</p>
</li>
<li> <p><code>tem.maxpll</code>: value of maximum modified profile log likelihood
</p>
</li>
<li> <p><code>empcov.mle</code>: maximum of Severini's empirical covariance modified profile log likelihood
</p>
</li>
<li> <p><code>empcov.profll</code>: values of the modified profile log likelihood at <code>psi</code>
</p>
</li>
<li> <p><code>empcov.maxpll</code>: value of maximum modified profile log likelihood
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- rgp(n = 100, scale = 2, shape = 0.3)
gpd.pll(psi = seq(-0.5, 1, by=0.01), param = 'shape', dat = dat)
gpd.pll(psi = seq(0.1, 5, by=0.1), param = 'scale', dat = dat)
gpd.pll(psi = seq(20, 35, by=0.1), param = 'quant', dat = dat, p = 0.01)
gpd.pll(psi = seq(20, 80, by=0.1), param = 'ES', dat = dat, m = 100)
gpd.pll(psi = seq(15, 100, by=1), param = 'Nmean', N = 100, dat = dat)
gpd.pll(psi = seq(15, 90, by=1), param = 'Nquant', N = 100, dat = dat, q = 0.5)

## End(Not run)
</code></pre>

<hr>
<h2 id='gpd.score'>Score vector for the generalized Pareto distribution</h2><span id='topic+gpd.score'></span>

<h3>Description</h3>

<p>Score vector for the generalized Pareto distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.score(par, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.score_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>
</p>

<hr>
<h2 id='gpd.tem'>Tangent exponential model approximation for the GP distribution</h2><span id='topic+gpd.tem'></span>

<h3>Description</h3>

<p>The function <code>gpd.tem</code> provides a tangent exponential model (TEM) approximation
for higher order likelihood inference for a scalar parameter for the generalized Pareto distribution. Options include
scale and shape parameters as well as value-at-risk (also referred to as quantiles, or return levels)
and expected shortfall. The function attempts to find good values for <code>psi</code> that will
cover the range of options, but the fit may fail and return an error. In such cases, the user can try to find good
grid of starting values and provide them to the routine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.tem(
  dat,
  param = c("scale", "shape", "quant", "VaR", "ES", "Nmean", "Nquant"),
  psi = NULL,
  m = NULL,
  threshold = 0,
  n.psi = 50,
  N = NULL,
  p = NULL,
  q = NULL,
  plot = FALSE,
  correction = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.tem_+3A_dat">dat</code></td>
<td>
<p>sample vector for the GP distribution</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_param">param</code></td>
<td>
<p>parameter over which to profile</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_psi">psi</code></td>
<td>
<p>scalar or ordered vector of values for the interest parameter. If <code>NULL</code> (default), a grid of values centered at the MLE is selected. If <code>psi</code> is of length 2 and <code>n.psi</code>&gt;2, it is assumed to be the minimal and maximal values at which to evaluate the profile log likelihood.</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong>. Required only for <code>param = 'VaR'</code> or <code>param = 'ES'</code>.</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_threshold">threshold</code></td>
<td>
<p>threshold value corresponding to the lower bound of the support or the location parameter of the generalized Pareto distribution.</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_n.psi">n.psi</code></td>
<td>
<p>number of values of <code>psi</code> at which the likelihood is computed, if <code>psi</code> is not supplied (<code>NULL</code>). Odd values are more prone to give rise to numerical instabilities near the MLE</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_n">N</code></td>
<td>
<p>size of block over which to take maxima. Required only for <code>args</code> <code>Nmean</code> and <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_p">p</code></td>
<td>
<p>tail probability, equivalent to <code class="reqn">1/m</code>. Required only for <code>args</code> <code>quant</code>.</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_q">q</code></td>
<td>
<p>level of quantile for N-block maxima. Required only for <code>args</code> <code>Nquant</code>.</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_plot">plot</code></td>
<td>
<p>logical indicating whether <code>plot.fr</code> should be called upon exit</p>
</td></tr>
<tr><td><code id="gpd.tem_+3A_correction">correction</code></td>
<td>
<p>logical indicating whether <a href="#topic+spline.corr">spline.corr</a> should be called.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As of version 1.11, this function is a wrapper around <code>gpd.pll</code>.
</p>
<p>The interpretation for <code>m</code> is as follows: if there are on average <code class="reqn">m_y</code> observations per year above the threshold, then  <code class="reqn">m = Tm_y</code> corresponds to <code class="reqn">T</code>-year return level.
</p>


<h3>Value</h3>

<p>an invisible object of class <code>fr</code> (see <code>tem</code> in package <code>hoa</code>) with elements
</p>

<ul>
<li> <p><code>normal</code>: maximum likelihood estimate and standard error of the interest parameter <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>par.hat</code>: maximum likelihood estimates
</p>
</li>
<li> <p><code>par.hat.se</code>: standard errors of maximum likelihood estimates
</p>
</li>
<li> <p><code>th.rest</code>: estimated maximum profile likelihood at (<code class="reqn">\psi</code>, <code class="reqn">\hat{\lambda}</code>)
</p>
</li>
<li> <p><code>r</code>: values of likelihood root corresponding to <code class="reqn">\psi</code>
</p>
</li>
<li> <p><code>psi</code>: vector of interest parameter
</p>
</li>
<li> <p><code>q</code>: vector of likelihood modifications
</p>
</li>
<li> <p><code>rstar</code>: modified likelihood root vector
</p>
</li>
<li> <p><code>rstar.old</code>: uncorrected modified likelihood root vector
</p>
</li>
<li> <p><code>param</code>: parameter
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
dat &lt;- rgp(n = 40, scale = 1, shape = -0.1)
#with plots
m1 &lt;- gpd.tem(param = 'shape', n.psi = 50, dat = dat, plot = TRUE)
## Not run: 
m2 &lt;- gpd.tem(param = 'scale', n.psi = 50, dat = dat)
m3 &lt;- gpd.tem(param = 'VaR', n.psi = 50, dat = dat, m = 100)
#Providing psi
psi &lt;- c(seq(2, 5, length = 15), seq(5, 35, length = 45))
m4 &lt;- gpd.tem(param = 'ES', dat = dat, m = 100, psi = psi, correction = FALSE)
mev:::plot.fr(m4, which = c(2, 4))
plot(fr4 &lt;- spline.corr(m4))
confint(m1)
confint(m4, parm = 2, warn = FALSE)
m5 &lt;- gpd.tem(param = 'Nmean', dat = dat, N = 100, psi = psi, correction = FALSE)
m6 &lt;- gpd.tem(param = 'Nquant', dat = dat, N = 100, q = 0.7, correction = FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='gpd.temstat'>Tangent exponential model statistics for the generalized Pareto distribution</h2><span id='topic+gpd.temstat'></span><span id='topic+gpd.Vfun'></span><span id='topic+gpd.phi'></span><span id='topic+gpd.dphi'></span>

<h3>Description</h3>

<p>Matrix of approximate ancillary statistics, sample space derivative of the
log likelihood and mixed derivative for the generalized Pareto distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpd.Vfun(par, dat)

gpd.phi(par, dat, V)

gpd.dphi(par, dat, V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd.temstat_+3A_par">par</code></td>
<td>
<p>vector of <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="gpd.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpd.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpd.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpd">gpd</a></code>
</p>

<hr>
<h2 id='gpde'>Generalized Pareto distribution (expected shortfall parametrization)</h2><span id='topic+gpde'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix,
approximate ancillary statistics and sample space derivative
for the generalized Pareto distribution parametrized in terms of expected shortfall.
</p>
<p>The parameter <code>m</code> corresponds to <code class="reqn">\zeta_u</code>/(1-<code class="reqn">\alpha</code>), where <code class="reqn">\zeta_u</code> is the rate of exceedance over the threshold
<code>u</code> and <code class="reqn">\alpha</code> is the percentile of the expected shortfall.
Note that the actual parametrization is in terms of excess expected shortfall, meaning expected shortfall minus threshold.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpde_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">e_m</code> and <code class="reqn">\xi</code>, respectively the expected shortfall at probability 1/(1-<code class="reqn">\alpha</code>) and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpde_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpde_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gpde_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for the exponential model</p>
</td></tr>
<tr><td><code id="gpde_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gpde_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="gpde_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpde.Vfun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed information matrix was calculated from the Hessian using symbolic calculus in Sage.
</p>


<h3>Usage</h3>

<pre>gpde.ll(par, dat, m, tol=1e-5)
gpde.ll.optim(par, dat, m, tol=1e-5)
gpde.score(par, dat, m)
gpde.infomat(par, dat, m, method = c('obs', 'exp'), nobs = length(dat))
gpde.Vfun(par, dat, m)
gpde.phi(par, dat, V, m)
gpde.dphi(par, dat, V, m)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gpde.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gpde.ll.optim</code>: negative log likelihood parametrized in terms of log expected
shortfall and shape in order to perform unconstrained optimization
</p>
</li>
<li> <p><code>gpde.score</code>: score vector
</p>
</li>
<li> <p><code>gpde.infomat</code>: observed information matrix for GPD parametrized in terms of rate of expected shortfall and shape
</p>
</li>
<li> <p><code>gpde.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gpde.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gpde.dphi</code>: derivative matrix of the canonical parameter in the local exponential family approximation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>

<hr>
<h2 id='gpde.infomat'>Observed information matrix for the GP distribution (expected shortfall)</h2><span id='topic+gpde.infomat'></span>

<h3>Description</h3>

<p>The information matrix is parametrized in terms of excess expected shortfall and shape
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpde.infomat(par, dat, m, method = c("obs", "exp"), nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpde.infomat_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">e_m</code> and <code class="reqn">\xi</code>, respectively the expected shortfall at probability 1/(1-<code class="reqn">\alpha</code>) and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpde.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpde.infomat_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gpde.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gpde.infomat_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpde">gpde</a></code>
</p>

<hr>
<h2 id='gpde.ll'>Negative log likelihood of the generalized Pareto distribution (expected shortfall)</h2><span id='topic+gpde.ll'></span><span id='topic+gpde.ll.optim'></span>

<h3>Description</h3>

<p>Negative log likelihood of the generalized Pareto distribution (expected shortfall)
</p>
<p>Negative log likelihood of the generalized Pareto distribution (expected shortfall) - optimization
The negative log likelihood is parametrized in terms of log expected shortfall and shape in order to perform unconstrained optimization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpde.ll(par, dat, m)

gpde.ll.optim(par, dat, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpde.ll_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">e_m</code> and <code class="reqn">\xi</code>, respectively the expected shortfall at probability 1/(1-<code class="reqn">\alpha</code>) and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpde.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpde.ll_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpde">gpde</a></code>
</p>

<hr>
<h2 id='gpde.score'>Score vector for the GP distribution (expected shortfall)</h2><span id='topic+gpde.score'></span>

<h3>Description</h3>

<p>Score vector for the GP distribution (expected shortfall)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpde.score(par, dat, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpde.score_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">e_m</code> and <code class="reqn">\xi</code>, respectively the expected shortfall at probability 1/(1-<code class="reqn">\alpha</code>) and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpde.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpde.score_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpde">gpde</a></code>
</p>

<hr>
<h2 id='gpde.temstat'>Tangent exponential model statistics for the generalized Pareto distribution (expected shortfall)</h2><span id='topic+gpde.temstat'></span><span id='topic+gpde.Vfun'></span><span id='topic+gpde.phi'></span><span id='topic+gpde.dphi'></span>

<h3>Description</h3>

<p>Vector implementing conditioning on approximate ancillary statistics for the TEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpde.Vfun(par, dat, m)

gpde.phi(par, dat, V, m)

gpde.dphi(par, dat, V, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpde.temstat_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">e_m</code> and <code class="reqn">\xi</code>, respectively the expected shortfall at probability 1/(1-<code class="reqn">\alpha</code>) and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpde.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpde.temstat_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gpde.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpde.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpde">gpde</a></code>
</p>

<hr>
<h2 id='gpdist'>Generalized Pareto distribution</h2><span id='topic+gpdist'></span><span id='topic+pgp'></span><span id='topic+dgp'></span><span id='topic+qgp'></span><span id='topic+rgp'></span>

<h3>Description</h3>

<p>Density function, distribution function, quantile function and
random number generation for the generalized Pareto
distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pgp(q, loc = 0, scale = 1, shape = 0, lower.tail = TRUE, log.p = FALSE)

dgp(x, loc = 0, scale = 1, shape = 0, log = FALSE)

qgp(p, loc = 0, scale = 1, shape = 0, lower.tail = TRUE)

rgp(n, loc = 0, scale = 1, shape = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdist_+3A_loc">loc</code></td>
<td>
<p>location parameter.</p>
</td></tr>
<tr><td><code id="gpdist_+3A_scale">scale</code></td>
<td>
<p>scale parameter, strictly positive.</p>
</td></tr>
<tr><td><code id="gpdist_+3A_shape">shape</code></td>
<td>
<p>shape parameter.</p>
</td></tr>
<tr><td><code id="gpdist_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), the lower tail probability <code class="reqn">\Pr(X \leq x)</code> is returned.</p>
</td></tr>
<tr><td><code id="gpdist_+3A_log.p">log.p</code>, <code id="gpdist_+3A_log">log</code></td>
<td>
<p>logical; if <code>FALSE</code> (default), values are returned on the probability scale.</p>
</td></tr>
<tr><td><code id="gpdist_+3A_x">x</code>, <code id="gpdist_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="gpdist_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="gpdist_+3A_n">n</code></td>
<td>
<p>scalar number of observations</p>
</td></tr>
</table>


<h3>References</h3>

<p>Coles, S. G. (2001) <em>An Introduction to Statistical
Modeling of Extreme Values</em>, Springer-Verlag, London.
<a href="https://doi.org/10.1007/978-1-4471-3675-0_3">doi:10.1007/978-1-4471-3675-0_3</a>
</p>

<hr>
<h2 id='gpdN'>Generalized Pareto distribution (mean of maximum of N exceedances parametrization)</h2><span id='topic+gpdN'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix,
approximate ancillary statistics and sample space derivative
for the generalized Pareto distribution parametrized in terms of average maximum of <code>N</code> exceedances.
</p>
<p>The parameter <code>N</code> corresponds to the number of threshold exceedances of interest over which the maxima is taken.
<code class="reqn">z</code> is the corresponding expected value of this block maxima.
Note that the actual parametrization is in terms of excess expected mean, meaning expected mean minus threshold.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdN_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
<tr><td><code id="gpdN_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for the exponential model</p>
</td></tr>
<tr><td><code id="gpdN_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpdN.Vfun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed information matrix was calculated from the Hessian using symbolic calculus in Sage.
</p>


<h3>Usage</h3>

<pre>gpdN.ll(par, dat, N, tol=1e-5)
gpdN.score(par, dat, N)
gpdN.infomat(par, dat, N, method = c('obs', 'exp'), nobs = length(dat))
gpdN.Vfun(par, dat, N)
gpdN.phi(par, dat, N, V)
gpdN.dphi(par, dat, N, V)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gpdN.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gpdN.score</code>: score vector
</p>
</li>
<li> <p><code>gpdN.infomat</code>: observed information matrix for GP parametrized in terms of mean of the maximum of <code>N</code> exceedances and shape
</p>
</li>
<li> <p><code>gpdN.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gpdN.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gpdN.dphi</code>: derivative matrix of the canonical parameter in the local exponential family approximation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>

<hr>
<h2 id='gpdN.infomat'>Information matrix of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</h2><span id='topic+gpdN.infomat'></span>

<h3>Description</h3>

<p>Information matrix of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdN.infomat(par, dat, N, method = c("obs", "exp"), nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN.infomat_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdN.infomat_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdN">gpdN</a></code>
</p>

<hr>
<h2 id='gpdN.ll'>Negative log likelihood of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</h2><span id='topic+gpdN.ll'></span>

<h3>Description</h3>

<p>Negative log likelihood of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdN.ll(par, dat, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN.ll_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdN.ll_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdN">gpdN</a></code>
</p>

<hr>
<h2 id='gpdN.mean'>This function returns the mean of N maxima from the GP.</h2><span id='topic+gpdN.mean'></span>

<h3>Description</h3>

<p>This function returns the mean of N maxima from the GP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdN.mean(par, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN.mean_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN.mean_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdN">gpdN</a></code>
</p>

<hr>
<h2 id='gpdN.quant'>This function returns the qth percentile of N maxima from the GP.</h2><span id='topic+gpdN.quant'></span>

<h3>Description</h3>

<p>This function returns the qth percentile of N maxima from the GP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdN.quant(par, q, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN.quant_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN.quant_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdN">gpdN</a></code>
</p>

<hr>
<h2 id='gpdN.score'>Score vector of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</h2><span id='topic+gpdN.score'></span>

<h3>Description</h3>

<p>Score vector of the generalized Pareto distribution (mean of maximum of N exceedances parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdN.score(par, dat, N)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN.score_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdN.score_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdN">gpdN</a></code>
</p>

<hr>
<h2 id='gpdN.temstat'>Tangent exponential model statistics for the generalized Pareto distribution (mean of maximum of N exceedances parametrization)</h2><span id='topic+gpdN.temstat'></span><span id='topic+gpdN.Vfun'></span><span id='topic+gpdN.phi'></span><span id='topic+gpdN.dphi'></span>

<h3>Description</h3>

<p>Vector implementing conditioning on approximate ancillary statistics for the TEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdN.Vfun(par, dat, N)

gpdN.phi(par, dat, N, V)

gpdN.dphi(par, dat, N, V)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdN.temstat_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">z</code> and <code class="reqn">\xi</code>, respectively the mean excess of the maxima of N exceedances above the threshold and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdN.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdN.temstat_+3A_n">N</code></td>
<td>
<p>block size for threshold exceedances.</p>
</td></tr>
<tr><td><code id="gpdN.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpdN.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdN">gpdN</a></code>
</p>

<hr>
<h2 id='gpdr'>Generalized Pareto distribution (return level parametrization)</h2><span id='topic+gpdr'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix,
approximate ancillary statistics and sample space derivative
for the generalized Pareto distribution parametrized in terms of return levels.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdr_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">y_m</code> and <code class="reqn">\xi</code>, respectively the <code class="reqn">m</code>-year return level and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdr_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdr_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gpdr_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance for the exponential model</p>
</td></tr>
<tr><td><code id="gpdr_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gpdr_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="gpdr_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpdr.Vfun</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The observed information matrix was calculated from the Hessian using symbolic calculus in Sage.
</p>
<p>The interpretation for <code>m</code> is as follows: if there are on average <code class="reqn">m_y</code> observations per year above the threshold, then  <code class="reqn">m=Tm_y</code> corresponds to <code class="reqn">T</code>-year return level.
</p>


<h3>Usage</h3>

<pre>gpdr.ll(par, dat, m, tol=1e-5)
gpdr.ll.optim(par, dat, m, tol=1e-5)
gpdr.score(par, dat, m)
gpdr.infomat(par, dat, m, method = c('obs', 'exp'), nobs = length(dat))
gpdr.Vfun(par, dat, m)
gpdr.phi(par, V, dat, m)
gpdr.dphi(par, V, dat, m)</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>gpdr.ll</code>: log likelihood
</p>
</li>
<li> <p><code>gpdr.ll.optim</code>: negative log likelihood parametrized in terms of <code>log(scale)</code> and shape
in order to perform unconstrained optimization
</p>
</li>
<li> <p><code>gpdr.score</code>: score vector
</p>
</li>
<li> <p><code>gpdr.infomat</code>: observed information matrix for GPD parametrized in terms of rate of <code class="reqn">m</code>-year return level and shape
</p>
</li>
<li> <p><code>gpdr.Vfun</code>: vector implementing conditioning on approximate ancillary statistics for the TEM
</p>
</li>
<li> <p><code>gpdr.phi</code>: canonical parameter in the local exponential family approximation
</p>
</li>
<li> <p><code>gpdr.dphi</code>: derivative matrix of the canonical parameter in the local exponential family approximation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>

<hr>
<h2 id='gpdr.infomat'>Observed information matrix for GP distribution (return levels)</h2><span id='topic+gpdr.infomat'></span>

<h3>Description</h3>

<p>The information matrix is parametrized in terms of rate of <code>m</code>-year return level and shape
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdr.infomat(par, dat, m, method = c("obs", "exp"), nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdr.infomat_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">y_m</code> and <code class="reqn">\xi</code>, respectively the <code class="reqn">m</code>-year return level and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdr.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdr.infomat_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gpdr.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="gpdr.infomat_+3A_nobs">nobs</code></td>
<td>
<p>number of observations</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdr">gpdr</a></code>
</p>

<hr>
<h2 id='gpdr.ll'>Negative log likelihood of the generalized Pareto distribution (return levels)</h2><span id='topic+gpdr.ll'></span><span id='topic+gpdr.ll.optim'></span>

<h3>Description</h3>

<p>Negative log likelihood of the generalized Pareto distribution (return levels)
</p>
<p>Negative log likelihood parametrized in terms of log return level and shape in order to perform unconstrained optimization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdr.ll(par, dat, m)

gpdr.ll.optim(par, dat, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdr.ll_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">y_m</code> and <code class="reqn">\xi</code>, respectively the <code class="reqn">m</code>-year return level and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdr.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdr.ll_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdr">gpdr</a></code>
</p>

<hr>
<h2 id='gpdr.score'>Score of the profile log likelihood for the GP distribution (return levels parametrization)</h2><span id='topic+gpdr.score'></span>

<h3>Description</h3>

<p>Score of the profile log likelihood for the GP distribution (return levels parametrization)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdr.score(par, dat, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdr.score_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">y_m</code> and <code class="reqn">\xi</code>, respectively the <code class="reqn">m</code>-year return level and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdr.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdr.score_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdr">gpdr</a></code>
</p>

<hr>
<h2 id='gpdr.temstat'>Tangent exponential model statistics for the generalized Pareto distribution (return level)</h2><span id='topic+gpdr.temstat'></span><span id='topic+gpdr.Vfun'></span><span id='topic+gpdr.phi'></span><span id='topic+gpdr.dphi'></span>

<h3>Description</h3>

<p>Vector implementing conditioning on approximate ancillary statistics for the TEM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdr.Vfun(par, dat, m)

gpdr.phi(par, dat, V, m)

gpdr.dphi(par, dat, V, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdr.temstat_+3A_par">par</code></td>
<td>
<p>vector of length 2 containing <code class="reqn">y_m</code> and <code class="reqn">\xi</code>, respectively the <code class="reqn">m</code>-year return level and the shape parameter.</p>
</td></tr>
<tr><td><code id="gpdr.temstat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="gpdr.temstat_+3A_m">m</code></td>
<td>
<p>number of observations of interest for return levels. See <strong>Details</strong></p>
</td></tr>
<tr><td><code id="gpdr.temstat_+3A_v">V</code></td>
<td>
<p>vector calculated by <code>gpdr.Vfun</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+gpdr">gpdr</a></code>
</p>
<p><code><a href="#topic+gpdr">gpdr</a></code>
</p>

<hr>
<h2 id='gpdtopar'>Transformation from the generalized Pareto to unit Pareto</h2><span id='topic+gpdtopar'></span>

<h3>Description</h3>

<p>Transformation from the generalized Pareto to unit Pareto
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdtopar(dat, loc = 0, scale, shape, lambdau = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdtopar_+3A_dat">dat</code></td>
<td>
<p>vector or matrix of data</p>
</td></tr>
<tr><td><code id="gpdtopar_+3A_loc">loc</code></td>
<td>
<p>vector of location parameters</p>
</td></tr>
<tr><td><code id="gpdtopar_+3A_scale">scale</code></td>
<td>
<p>vector of scale parameters, strictly positive</p>
</td></tr>
<tr><td><code id="gpdtopar_+3A_shape">shape</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="gpdtopar_+3A_lambdau">lambdau</code></td>
<td>
<p>vector of probability of marginal threshold exceedance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of the same dimension as <code>dat</code> with unit Pareto observations
</p>

<hr>
<h2 id='ibvpot'>Interpret bivariate threshold exceedance models</h2><span id='topic+ibvpot'></span>

<h3>Description</h3>

<p>This is an adaptation of the <code>evir</code> package <code>interpret.gpdbiv</code> function.
<code>interpret.fbvpot</code> deals with the output of a call to
<code>fbvpot</code> from the <span class="pkg">evd</span> and to handle families other than the logistic distribution.
The likelihood derivation comes from expression 2.10 in Smith et al. (1997).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ibvpot(fitted, q, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ibvpot_+3A_fitted">fitted</code></td>
<td>
<p>the output of <code><a href="evd.html#topic+fbvpot">fbvpot</a></code> or a list. See Details.</p>
</td></tr>
<tr><td><code id="ibvpot_+3A_q">q</code></td>
<td>
<p>a vector of quantiles to consider, on the data scale. Must be greater than the thresholds.</p>
</td></tr>
<tr><td><code id="ibvpot_+3A_silent">silent</code></td>
<td>
<p>boolean; whether to print the interpretation of the result. Default to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The list <code>fitted</code> must contain
</p>

<ul>
<li> <p><code>model</code> a string; see <code>bvevd</code> from package <code>evd</code> for options
</p>
</li>
<li> <p><code>param</code> a named vector containing the parameters of the <code>model</code>, as well as parameters
<code>scale1</code>, <code>shape1</code>,<code>scale2</code> and <code>shape2</code>, corresponding to marginal GPD parameters.
</p>
</li>
<li> <p><code>threshold</code> a vector of length 2 containing the two thresholds.
</p>
</li>
<li> <p><code>pat</code> the proportion of observations above the corresponding <code>threshold</code>
</p>
</li></ul>



<h3>Value</h3>

<p>an invisible numeric vector containing marginal, joint and conditional exceedance probabilities.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile, adapting original S code by Alexander McNeil
</p>


<h3>References</h3>

<p>Smith, Tawn and Coles (1997), Markov chain models for threshold exceedances. <em>Biometrika</em>,
<strong>84</strong>(2), 249&ndash;268.
</p>


<h3>See Also</h3>

<p><code>interpret.gpdbiv</code> in package <code>evir</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("evd", quietly = TRUE)) {
y &lt;- rgp(1000,1,1,1)
x &lt;- y*rmevspec(n=1000,d=2,sigma=cbind(c(0,0.5),c(0.5,0)), model='hr')
mod &lt;- evd::fbvpot(x, threshold = c(1,1), model = 'hr', likelihood ='censored')
ibvpot(mod, c(20,20))
}
</code></pre>

<hr>
<h2 id='infomat.test'>Information matrix test statistic and MLE for the extremal index</h2><span id='topic+infomat.test'></span>

<h3>Description</h3>

<p>The Information Matrix Test (IMT), proposed by Suveges and Davison (2010), is based
on the difference between the expected quadratic score and the second derivative of
the log-likelihood. The asymptotic distribution for each threshold <code>u</code> and gap <code>K</code>
is asymptotically <code class="reqn">\chi^2</code> with one degree of freedom. The approximation is good for
<code class="reqn">N&gt;80</code> and conservative for smaller sample sizes. The test assumes independence between gaps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>infomat.test(xdat, thresh, q, K, plot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="infomat.test_+3A_xdat">xdat</code></td>
<td>
<p>data vector</p>
</td></tr>
<tr><td><code id="infomat.test_+3A_thresh">thresh</code></td>
<td>
<p>threshold vector</p>
</td></tr>
<tr><td><code id="infomat.test_+3A_q">q</code></td>
<td>
<p>vector of probability levels to define threshold if <code>thresh</code> is missing.</p>
</td></tr>
<tr><td><code id="infomat.test_+3A_k">K</code></td>
<td>
<p>int specifying the largest K-gap</p>
</td></tr>
<tr><td><code id="infomat.test_+3A_plot">plot</code></td>
<td>
<p>logical: should the graphical diagnostic be plotted?</p>
</td></tr>
<tr><td><code id="infomat.test_+3A_...">...</code></td>
<td>
<p>additional arguments, currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure proposed in Suveges &amp; Davison (2010) was corrected for erratas.
The maximum likelihood is based on the limiting mixture distribution of
the intervals between exceedances (an exponential with a point mass at zero).
The condition <code class="reqn">D^{(K)}(u_n)</code> should be checked by the user.
</p>
<p>Fukutome et al. (2015) propose an ad hoc automated procedure
</p>

<ol>
<li><p> Calculate the interexceedance times for each K-gap and each threshold, along with the number of clusters
</p>
</li>
<li><p>  Select the (<code>u</code>, <code>K</code>) pairs for which IMT &lt; 0.05 (corresponding to a P-value of 0.82)
</p>
</li>
<li><p> Among those, select the pair (<code>u</code>, <code>K</code>) for which the number of clusters is the largest
</p>
</li></ol>



<h3>Value</h3>

<p>an invisible list of matrices containing
</p>

<ul>
<li> <p><code>IMT</code> a matrix of test statistics
</p>
</li>
<li> <p><code>pvals</code> a matrix of approximate p-values (corresponding to probabilities under a <code class="reqn">\chi^2_1</code> distribution)
</p>
</li>
<li> <p><code>mle</code> a matrix of maximum likelihood estimates for each given pair (<code>u</code>, <code>K</code>)
</p>
</li>
<li> <p><code>loglik</code> a matrix of log-likelihood values at MLE for each given pair (<code>u</code>, <code>K</code>)
</p>
</li>
<li> <p><code>threshold</code> a vector of thresholds based on empirical quantiles at supplied levels.
</p>
</li>
<li> <p><code>q</code> the vector <code>q</code> supplied by the user
</p>
</li>
<li> <p><code>K</code> the largest gap number, supplied by the user
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Fukutome, Liniger and Suveges (2015), Automatic threshold and run parameter selection: a climatology for extreme hourly precipitation in Switzerland. <em>Theoretical and Applied Climatology</em>, <strong>120</strong>(3), 403-416.
</p>
<p>Suveges and Davison (2010), Model misspecification in peaks over threshold analysis. <em>Annals of Applied Statistics</em>, <strong>4</strong>(1), 203-221.
</p>
<p>White (1982), Maximum Likelihood Estimation of Misspecified Models. <em>Econometrica</em>, <strong>50</strong>(1), 1-25.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>infomat.test(xdat = rgp(n = 10000),
             q = seq(0.1, 0.9, length = 10),
             K = 3)
</code></pre>

<hr>
<h2 id='intensBR'>Intensity function for the Brown-Resnick model</h2><span id='topic+intensBR'></span>

<h3>Description</h3>

<p>The intensity function includes the normalizing constants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intensBR(tdat, Lambda, cholPrecis = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intensBR_+3A_tdat">tdat</code></td>
<td>
<p>matrix of unit Pareto observations</p>
</td></tr>
<tr><td><code id="intensBR_+3A_lambda">Lambda</code></td>
<td>
<p>conditionally negative definite parameter matrix of the Huesler&ndash;Reiss model</p>
</td></tr>
<tr><td><code id="intensBR_+3A_cholprecis">cholPrecis</code></td>
<td>
<p>Cholesky root of the corresponding precision matrix <code>solve(Sigma)</code>. Default to <code>NULL</code>, meaning the latter is calculated within the function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log intensity contribution
</p>

<hr>
<h2 id='intensXstud'>Intensity function for the extremal Student model</h2><span id='topic+intensXstud'></span>

<h3>Description</h3>

<p>The intensity function includes the normalizing constants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intensXstud(tdat, df, Sigma, cholPrecis = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="intensXstud_+3A_tdat">tdat</code></td>
<td>
<p>matrix of unit Pareto observations</p>
</td></tr>
<tr><td><code id="intensXstud_+3A_df">df</code></td>
<td>
<p>degrees of freedom, must be larger than 1</p>
</td></tr>
<tr><td><code id="intensXstud_+3A_sigma">Sigma</code></td>
<td>
<p>scale matrix</p>
</td></tr>
<tr><td><code id="intensXstud_+3A_cholprecis">cholPrecis</code></td>
<td>
<p>Cholesky root of the precision matrix <code>solve(Sigma)</code>. Default to <code>NULL</code>, meaning the latter is calculated within the function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log intensity contribution
</p>

<hr>
<h2 id='jac'>Jacobian of the transformation from generalized Pareto to unit Pareto distribution</h2><span id='topic+jac'></span>

<h3>Description</h3>

<p>If <code>dat</code> is a vector, the arguments <code>loc</code>, <code>scale</code> and <code>shape</code> should be numericals of length 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jac(dat, loc = 0, scale, shape, lambdau = 1, censored)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="jac_+3A_dat">dat</code></td>
<td>
<p>vector or matrix of data</p>
</td></tr>
<tr><td><code id="jac_+3A_loc">loc</code></td>
<td>
<p>vector of location parameters</p>
</td></tr>
<tr><td><code id="jac_+3A_scale">scale</code></td>
<td>
<p>vector of scale parameters, strictly positive</p>
</td></tr>
<tr><td><code id="jac_+3A_shape">shape</code></td>
<td>
<p>shape parameter</p>
</td></tr>
<tr><td><code id="jac_+3A_lambdau">lambdau</code></td>
<td>
<p>vector of probability of marginal threshold exceedance</p>
</td></tr>
<tr><td><code id="jac_+3A_censored">censored</code></td>
<td>
<p>a matrix of logical indicating whether the observations are censored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log-likelihood contribution for the Jacobian
</p>

<hr>
<h2 id='Lambda2cov'>Transform variogram matrix to covariance of conditional random field</h2><span id='topic+Lambda2cov'></span>

<h3>Description</h3>

<p>The matrix <code>Lambda</code> is half the semivariogram matrix. The function
returns the conditional covariance with respect to entries in <code>co</code>,
restricted to the <code>subA</code> rows and the <code>subB</code> columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda2cov(Lambda, co, subA, subB)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lambda2cov_+3A_lambda">Lambda</code></td>
<td>
<p>Negative definite matrix for the Huesler&ndash;Reiss model</p>
</td></tr>
<tr><td><code id="Lambda2cov_+3A_co">co</code></td>
<td>
<p>vector of integer with conditioning sites</p>
</td></tr>
<tr><td><code id="Lambda2cov_+3A_suba">subA</code></td>
<td>
<p>vector of integers with sub-entries (not in <code>co</code>) for rows</p>
</td></tr>
<tr><td><code id="Lambda2cov_+3A_subb">subB</code></td>
<td>
<p>vector of integers with sub-entries (not in <code>co</code>) for columns. If missing, default to <code>subA</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='lambdadep'>Estimation of the bivariate angular dependence function of Wadsworth and Tawn (2013)</h2><span id='topic+lambdadep'></span>

<h3>Description</h3>

<p>Estimation of the bivariate angular dependence function of Wadsworth and Tawn (2013)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambdadep(dat, qu = 0.95, method = c("hill", "mle", "bayes"), plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lambdadep_+3A_dat">dat</code></td>
<td>
<p>an <code class="reqn">n</code> by <code class="reqn">2</code> matrix of multivariate observations</p>
</td></tr>
<tr><td><code id="lambdadep_+3A_qu">qu</code></td>
<td>
<p>quantile level on uniform scale at which to threshold data. Default to 0.95</p>
</td></tr>
<tr><td><code id="lambdadep_+3A_method">method</code></td>
<td>
<p>string indicating the estimation method</p>
</td></tr>
<tr><td><code id="lambdadep_+3A_plot">plot</code></td>
<td>
<p>logical indicating whether to return the graph of <code>lambda</code>
</p>
<p>The confidence intervals are based on normal quantiles. The standard errors for the <code>hill</code>
are based on the asymptotic covariance and that of the <code>mle</code> derived using the delta-method.
Bayesian posterior predictive interval estimates are obtained using ratio-of-uniform sampling with flat priors:
the shape parameters are constrained to lie within the triangle, as are frequentist point estimates
which are adjusted post-inference.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a plot of the lambda function if <code>plot=TRUE</code>, plus an invisible list with components
</p>

<ul>
<li> <p><code>w</code> the sequence of angles in (0,1) at which the <code>lambda</code> values are evaluated
</p>
</li>
<li> <p><code>lambda</code> point estimates of lambda
</p>
</li>
<li> <p><code>lower.confint</code> 95
</p>
</li>
<li> <p><code>upper.confint</code> 95
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(12)
dat &lt;- mev::rmev(n = 1000, d = 2, model = "log", param = 0.1)
lambdadep(dat, method = 'hill')
## Not run: 
lambdadep(dat, method = 'bayes')
lambdadep(dat, method = 'mle')
# With independent observations
dat &lt;- matrix(runif(n = 2000), ncol = 2)
lambdadep(dat, method = 'hill')

## End(Not run)
</code></pre>

<hr>
<h2 id='likmgp'>Likelihood for multivariate peaks over threshold models</h2><span id='topic+likmgp'></span>

<h3>Description</h3>

<p>Likelihood for the various parametric limiting models over region determined by
</p>
<p style="text-align: center;"><code class="reqn">\{y \in F: \max_{j=1}^D \sigma_j \frac{y^\xi_j-1}{\xi_j}+\mu_j  &gt; u\};</code>
</p>

<p>where <code class="reqn">\mu</code> is <code>loc</code>, <code class="reqn">\sigma</code> is <code>scale</code> and <code class="reqn">\xi</code> is <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likmgp(
  dat,
  thresh,
  loc,
  scale,
  shape,
  par,
  model = c("log", "br", "xstud"),
  likt = c("mgp", "pois", "binom"),
  lambdau = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="likmgp_+3A_dat">dat</code></td>
<td>
<p>matrix of observations</p>
</td></tr>
<tr><td><code id="likmgp_+3A_thresh">thresh</code></td>
<td>
<p>functional threshold for the maximum</p>
</td></tr>
<tr><td><code id="likmgp_+3A_loc">loc</code></td>
<td>
<p>vector of location parameter for the marginal generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="likmgp_+3A_scale">scale</code></td>
<td>
<p>vector of scale parameter for the marginal generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="likmgp_+3A_shape">shape</code></td>
<td>
<p>vector of shape parameter for the marginal generalized Pareto distribution</p>
</td></tr>
<tr><td><code id="likmgp_+3A_par">par</code></td>
<td>
<p>list of parameters: <code>alpha</code> for the logistic model, <code>Lambda</code> for the Brown&ndash;Resnick model or else <code>Sigma</code> and <code>df</code> for the extremal Student.</p>
</td></tr>
<tr><td><code id="likmgp_+3A_model">model</code></td>
<td>
<p>string indicating the model family, one of <code>"log"</code>, <code>"neglog"</code>, <code>"br"</code> or <code>"xstud"</code></p>
</td></tr>
<tr><td><code id="likmgp_+3A_likt">likt</code></td>
<td>
<p>string indicating the type of likelihood, with an additional contribution for the non-exceeding components: one of  <code>"mgp"</code>, <code>"binom"</code> and <code>"pois"</code>.</p>
</td></tr>
<tr><td><code id="likmgp_+3A_lambdau">lambdau</code></td>
<td>
<p>vector of marginal rate of marginal threshold exceedance.</p>
</td></tr>
<tr><td><code id="likmgp_+3A_...">...</code></td>
<td>
<p>additional arguments (see Details)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Optional arguments can be passed to the function via <code>...</code>
</p>

<ul>
<li> <p><code>cl</code> cluster instance  created by <code>makeCluster</code> (default to <code>NULL</code>)
</p>
</li>
<li> <p><code>ncors</code> number of cores for parallel computing of the likelihood
</p>
</li>
<li> <p><code>mmax</code> maximum per column
</p>
</li>
<li> <p><code>B1</code> number of replicates for quasi Monte Carlo integral for the exponent measure
</p>
</li>
<li> <p><code>genvec1</code> generating vector for the quasi Monte Carlo routine (exponent measure), associated with <code>B1</code>
</p>
</li></ul>



<h3>Value</h3>

<p>the value of the log-likelihood with <code>attributes</code> <code>expme</code>, giving the exponent measure
</p>


<h3>Note</h3>

<p>The location and scale parameters are not identifiable unless one of them is fixed.
</p>

<hr>
<h2 id='maiquetia'>Maiquetia Daily Rainfall</h2><span id='topic+maiquetia'></span>

<h3>Description</h3>

<p>Daily cumulated rainfall (in mm) at Maiquetia airport, Venezuela.
The observations cover the period from January 1961 to December 1999.
The original series had missing days in February 1996 (during which there were
2 days with 1hr each of light rain) and January 1998 (no rain). These were replaced by zeros.
</p>


<h3>Format</h3>

<p>a vector of size 14244 containing daily rainfall (in mm),
</p>


<h3>Source</h3>

<p>J.R. Cordova and M. Gonzlez, accessed 25.11.2018 from &lt;https://rss.onlinelibrary.wiley.com/hub/journal/14679876/series-c-datasets&gt;
</p>


<h3>References</h3>

<p>Coles, S. and L.R. Pericchi (2003). Anticipating Catastrophes through Extreme Value Modelling, <em>Applied Statistics</em>, <b>52</b>(4), 405-416.
</p>
<p>Coles, S., Pericchi L.R. and S. Sisson (2003). A fully probabilistic approach to extreme rainfall modeling, <em>Journal of Hydrology</em>, <b>273</b>, 35-50.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(maiquetia, package = "mev")
day &lt;- seq.Date(from = as.Date("1961-01-01"), to = as.Date("1999-12-31"), by = "day")
nzrain &lt;- maiquetia[substr(day, 1, 4) &lt; 1999 &amp; maiquetia &gt; 0]
fit.gpd(nzrain, threshold = 30, show = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='maxstabtest'>P-P plot for testing max stability</h2><span id='topic+maxstabtest'></span>

<h3>Description</h3>

<p>The diagnostic, proposed by Gabda, Towe, Wadsworth and Tawn,
relies on the fact that, for max-stable vectors on the unit Gumbel scale,
the distribution of the maxima is Gumbel distribution with a location parameter equal to the exponent measure.
One can thus consider tuples of size <code>m</code> and estimate the location parameter via maximum likelihood
and transforming observations to the standard Gumbel scale. Replicates are then pooled and empirical quantiles are defined.
The number of combinations of <code>m</code> vectors can be prohibitively large, hence only <code>nmax</code> randomly selected
tuples are selected from all possible combinations. The confidence intervals are obtained by a
nonparametric bootstrap, by resampling observations with replacement observations for the selected tuples and re-estimating the
location parameter. The procedure can be computationally intensive as a result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maxstabtest(
  dat,
  m = prod(dim(dat)[-1]),
  nmax = 500L,
  B = 1000L,
  ties.method = "random",
  plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maxstabtest_+3A_dat">dat</code></td>
<td>
<p>matrix or array of max-stable observations, typically block maxima. The first dimension should consist of replicates</p>
</td></tr>
<tr><td><code id="maxstabtest_+3A_m">m</code></td>
<td>
<p>integer indicating how many tuples should be aggregated.</p>
</td></tr>
<tr><td><code id="maxstabtest_+3A_nmax">nmax</code></td>
<td>
<p>maximum number of pairs. Default to 500L.</p>
</td></tr>
<tr><td><code id="maxstabtest_+3A_b">B</code></td>
<td>
<p>number of nonparametric bootstrap replications. Default to 1000L.</p>
</td></tr>
<tr><td><code id="maxstabtest_+3A_ties.method">ties.method</code></td>
<td>
<p>string indicating the method for <code><a href="base.html#topic+rank">rank</a></code>. Default to <code>"random"</code>.</p>
</td></tr>
<tr><td><code id="maxstabtest_+3A_plot">plot</code></td>
<td>
<p>logical indicating whether a graph should be produced (default to <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a Tukey probability-probability plot with 95
</p>


<h3>References</h3>

<p>Gabda, D.; Towe, R. Wadsworth, J. and J. Tawn, Discussion of &ldquo;Statistical Modeling of Spatial Extremes&rdquo; by A. C. Davison, S. A. Padoan and M. Ribatet. <em>Statist. Sci.</em> <b>27</b> (2012), no. 2, 189&ndash;192.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- mev::rmev(n = 250, d = 100, param = 0.5, model = "log")
maxstabtest(dat, m = 100)
maxstabtest(dat, m = 2, nmax = 100)
dat &lt;- mev::mvrnorm(n = 250, Sigma = diag(0.5, 10) + matrix(0.5, 10, 10), mu = rep(0, 10))
maxstabtest(dat, m = 2, nmax = 100)
maxstabtest(dat, m = ncol(dat))

## End(Not run)
</code></pre>

<hr>
<h2 id='mvrnorm'>Multivariate Normal distribution sampler</h2><span id='topic+mvrnorm'></span>

<h3>Description</h3>

<p>Sampler derived using the eigendecomposition of the covariance
matrix <code>Sigma</code>. The function uses the Armadillo random normal generator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrnorm(n, mu, Sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvrnorm_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_mu">mu</code></td>
<td>
<p>mean vector. Will set the dimension</p>
</td></tr>
<tr><td><code id="mvrnorm_+3A_sigma">Sigma</code></td>
<td>
<p>a square covariance matrix, of same dimension as <code>mu</code>.
No sanity check is performed to validate that the matrix is p.s.d., so use at own risk</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> sample from a multivariate Normal distribution
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mvrnorm(n=10, mu=c(0,2), Sigma=diag(2))
</code></pre>

<hr>
<h2 id='NC.diag'>Score and likelihood ratio tests fit of equality of shape over multiple thresholds</h2><span id='topic+NC.diag'></span>

<h3>Description</h3>

<p>The function returns a P-value path for the score testand/or likelihood ratio
test for equality of the shape parameters over
multiple thresholds under the generalized Pareto model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NC.diag(
  xdat,
  u,
  GP.fit = c("Grimshaw", "nlm", "optim", "ismev"),
  do.LRT = FALSE,
  size = NULL,
  plot = TRUE,
  ...,
  xi.tol = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NC.diag_+3A_xdat">xdat</code></td>
<td>
<p>numeric vector of raw data</p>
</td></tr>
<tr><td><code id="NC.diag_+3A_u">u</code></td>
<td>
<p><code>m</code>-vector of thresholds (sorted from smallest to largest)</p>
</td></tr>
<tr><td><code id="NC.diag_+3A_gp.fit">GP.fit</code></td>
<td>
<p>function used to optimize the generalized Pareto model.</p>
</td></tr>
<tr><td><code id="NC.diag_+3A_do.lrt">do.LRT</code></td>
<td>
<p>boolean indicating whether to perform the likelihood ratio test (in addition to the score test)</p>
</td></tr>
<tr><td><code id="NC.diag_+3A_size">size</code></td>
<td>
<p>level at which a horizontal line is drawn on multiple threshold plot</p>
</td></tr>
<tr><td><code id="NC.diag_+3A_plot">plot</code></td>
<td>
<p>logical; if <code>TRUE</code>, return a plot of p-values against threshold.</p>
</td></tr>
<tr><td><code id="NC.diag_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code>plot</code></p>
</td></tr>
<tr><td><code id="NC.diag_+3A_xi.tol">xi.tol</code></td>
<td>
<p>numerical tolerance for threshold distance; if the absolute value of <code>xi1.hat</code> is less than <code>xi.tol</code> use linear interpolation
to evaluate score vectors, expected Fisher information matrices, Hessians</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default method is <code>'Grimshaw'</code> using the reduction of the parameters to a one-dimensional
maximization. Other options are one-dimensional maximization of the profile the <code>nlm</code> function or <code>optim</code>.
Two-dimensional optimisation using 2D-optimization <code><a href="ismev.html#topic+ismev">ismev</a></code> using the routine
from <code>gpd.fit</code> from the <code>ismev</code> library, with the addition of the algebraic gradient.
The choice of <code>GP.fit</code> should make no difference but the options were kept.
<b>Warning</b>: the function will not recover from failure of the maximization routine, returning various error messages.
</p>


<h3>Value</h3>

<p>a plot of P-values for the test at the different thresholds <code>u</code>
</p>


<h3>Author(s)</h3>

<p>Paul J. Northrop and Claire L. Coleman
</p>


<h3>References</h3>

<p>Grimshaw (1993). Computing Maximum Likelihood Estimates for the Generalized
Pareto Distribution, <em>Technometrics</em>, <b>35</b>(2), 185&ndash;191.
</p>
<p>Northrop &amp; Coleman (2014). Improved threshold diagnostic plots for extreme value
analyses, <em>Extremes</em>, <b>17</b>(2), 289&ndash;303.
</p>
<p>Wadsworth &amp; Tawn (2012). Likelihood-based procedures for threshold
diagnostics and uncertainty in extreme value modelling, <em>J. R. Statist. Soc. B</em>, <b>74</b>(3), 543&ndash;567.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(nidd)
u &lt;- seq(65,90, by = 1L)
NC.diag(nidd, u, size = 0.05)

## End(Not run)
</code></pre>

<hr>
<h2 id='nidd'>River Nidd Flow</h2><span id='topic+nidd'></span>

<h3>Description</h3>

<p>The data consists of exceedances over the threshold 65 cubic meter per second of the River Nidd at Hunsingore Weir, for 35 years of data between 1934 and 1969.
</p>


<h3>Format</h3>

<p>a vector of size 154
</p>


<h3>Source</h3>

<p>Natural Environment Research Council (1975). <em>Flood Studies Report</em>, volume 4.  pp. 235&ndash;236.
</p>


<h3>References</h3>

<p>Davison, A.C. and R.L. Smith (1990). Models for Exceedances over High Thresholds, <em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <b>52</b>(3), 393&ndash;442. With discussion.
</p>


<h3>See Also</h3>

<p><code>nidd.thresh</code> from the <code>evir</code> package
</p>

<hr>
<h2 id='nutrients'>Nutrient data</h2><span id='topic+nutrients'></span>

<h3>Description</h3>

<p>Interview component of survey 'What we eat in
America'. These are extracted from the 20152016 National Health and Nutrition Examination Survey (NHANES, <a href="https://wwwn.cdc.gov/nchs/nhanes/Default.aspx">https://wwwn.cdc.gov/nchs/nhanes/Default.aspx</a>) report and consist of the total nutrients for all food and beverage intake ingested over a 24 hours period.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nutrients
</code></pre>


<h3>Format</h3>

<p>A data frame with 9544 rows and 38 variables:
</p>

<dl>
<dt><code>prot</code></dt><dd><p>proteins (in grams)</p>
</dd>
<dt><code>carb</code></dt><dd><p>carbonhydrate (in gram)</p>
</dd>
<dt><code>sugr</code></dt><dd><p>total sugars (in gram)</p>
</dd>
<dt><code>fibe</code></dt><dd><p>dietary fibers (in grams)</p>
</dd>
<dt><code>tfat</code></dt><dd><p>total fat (in grams)</p>
</dd>
<dt><code>sfat</code></dt><dd><p>saturated fat (in grams)</p>
</dd>
<dt><code>mfat</code></dt><dd><p>monounsaturated fat (in grams)</p>
</dd>
<dt><code>pfat</code></dt><dd><p>polyunsaturated fat (in grams)</p>
</dd>
<dt><code>chol</code></dt><dd><p>cholesterol (in milligrams)</p>
</dd>
<dt><code>atoc</code></dt><dd><p>vitamin E as alpha-tocopherol (in milligrams)</p>
</dd>
<dt><code>ret</code></dt><dd><p>retinol (in micrograms)</p>
</dd>
<dt><code>vara</code></dt><dd><p>Vitamin A as retinol activity equivalents (in micrograms).</p>
</dd>
<dt><code>acar</code></dt><dd><p>alpha-carotene (in micrograms)</p>
</dd>
<dt><code>bcar</code></dt><dd><p>beta-carotene (in micrograms)</p>
</dd>
<dt><code>cryp</code></dt><dd><p>beta-cryptoxanthin (in micrograms)</p>
</dd>
<dt><code>lyco</code></dt><dd><p>lycopene (in micrograms)</p>
</dd>
<dt><code>lz</code></dt><dd><p>lutein and zeaxanthin (in micrograms).</p>
</dd>
<dt><code>vb1</code></dt><dd><p>thiamin (vitamin B1, in milligrams)</p>
</dd>
<dt><code>vb2</code></dt><dd><p>riboflavin (vitamin B2, in milligrams)</p>
</dd>
<dt><code>niac</code></dt><dd><p>niacin (in milligrams)</p>
</dd>
<dt><code>vb6</code></dt><dd><p>vitamin B5 (in milligrams)</p>
</dd>
<dt><code>fola</code></dt><dd><p>total folate (in micrograms)</p>
</dd>
<dt><code>fa</code></dt><dd><p>folic acid (in micrograms)</p>
</dd>
<dt><code>ff</code></dt><dd><p>food folate (in micrograms)</p>
</dd>
<dt><code>chl</code></dt><dd><p>total choline (in milligrams)</p>
</dd>
<dt><code>vb12</code></dt><dd><p>vitamin B12 (in micrograms)</p>
</dd>
<dt><code>vc</code></dt><dd><p>vitamin C (in milligrams)</p>
</dd>
<dt><code>vd</code></dt><dd><p>vitamin D (comprising D2 and D3, in micrograms)</p>
</dd>
<dt><code>vk</code></dt><dd><p>vitamin K (in micrograms)</p>
</dd>
<dt><code>calc</code></dt><dd><p>calcium (in milligrams)</p>
</dd>
<dt><code>phos</code></dt><dd><p>phosphorus (in milligrams)</p>
</dd>
<dt><code>magn</code></dt><dd><p>magnesium (in milligrams)</p>
</dd>
<dt><code>iron</code></dt><dd><p>iron (in milligrams)</p>
</dd>
<dt><code>zinc</code></dt><dd><p>zinc (in milligrams)</p>
</dd>
<dt><code>copp</code></dt><dd><p>copper (in milligrams)</p>
</dd>
<dt><code>sodi</code></dt><dd><p>sodium (in milligrams)</p>
</dd>
<dt><code>pota</code></dt><dd><p>potassium (in milligrams)</p>
</dd>
<dt><code>sele</code></dt><dd><p>selenium (in micrograms)</p>
</dd>
</dl>



<h3>Details</h3>

<p>Note that the sample design oversampled specific population targets and that only respondants are provided. The website contains more information about sampling weights. There are multiple missing records.
</p>


<h3>Note</h3>

<p>These data are subject to a data user agreement, available at <a href="https://www.cdc.gov/nchs/data_access/restrictions.htm">https://www.cdc.gov/nchs/data_access/restrictions.htm</a>
</p>


<h3>Source</h3>

<p>National Center for Health Statistics, <a href="https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DR1TOT_I.XPT">https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DR1TOT_I.XPT</a>
</p>

<hr>
<h2 id='pandemics'>Deaths from pandemics</h2><span id='topic+pandemics'></span>

<h3>Description</h3>

<p>The data base contains estimated records of the number of deaths from pandemics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pandemics
</code></pre>


<h3>Format</h3>

<p>A data frame with 72 rows and 8 variables:
</p>

<dl>
<dt><code>event</code></dt><dd><p>name of the event</p>
</dd>
<dt><code>startyear</code></dt><dd><p>start year of the event</p>
</dd>
<dt><code>endyear</code></dt><dd><p>end year of the event</p>
</dd>
<dt><code>lower</code></dt><dd><p>lower bound on estimated deaths (in thousands)</p>
</dd>
<dt><code>average</code></dt><dd><p>average estimated deaths (in thousands)</p>
</dd>
<dt><code>upper</code></dt><dd><p>upper bound on estimated deaths (in thousands)</p>
</dd>
<dt><code>saverage</code></dt><dd><p>scaled average of estimated deaths (in thousands)</p>
</dd>
<dt><code>population</code></dt><dd><p>estimated population at risk (in thousands)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cirillo, P. and N.N. Taleb (2020). <em>Tail risk of contagious diseases</em>. Nat. Phys. <b>16</b>, 606613 (2020). &lt;doi:10.1038/s41567-020-0921-x&gt;
</p>

<hr>
<h2 id='pextgp.G'>Extended GP functions</h2><span id='topic+pextgp.G'></span><span id='topic+dextgp.G'></span><span id='topic+qextgp.G'></span><span id='topic+rextgp.G'></span><span id='topic+extgp-functions'></span><span id='topic+pextgp'></span><span id='topic+dextgp'></span><span id='topic+qextgp'></span><span id='topic+rextgp'></span>

<h3>Description</h3>

<p>These functions are documented in <code><a href="#topic+extgp">extgp</a></code> and in <code><a href="#topic+extgp.G">extgp.G</a></code> for the carrier distributions supported in the unit interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pextgp.G(u, type = 1, prob, kappa, delta)

dextgp.G(u, type = 1, prob = NA, kappa = NA, delta = NA, log = FALSE)

qextgp.G(u, type = 1, prob = NA, kappa = NA, delta = NA)

rextgp.G(
  n,
  prob = NA,
  kappa = NA,
  delta = NA,
  type = 1,
  unifsamp = NULL,
  direct = FALSE,
  censoring = c(0, 1)
)

pextgp(q, prob = NA, kappa = NA, delta = NA, sigma = NA, xi = NA, type = 1)

dextgp(
  x,
  prob = NA,
  kappa = NA,
  delta = NA,
  sigma = NA,
  xi = NA,
  type = 1,
  log = FALSE
)

qextgp(
  p,
  prob = NA,
  kappa = NA,
  delta = NA,
  sigma = NA,
  xi = NA,
  type = 1,
  step = 0
)

rextgp(
  n,
  prob = NA,
  kappa = NA,
  delta = NA,
  sigma = NA,
  xi = NA,
  type = 1,
  unifsamp = NULL,
  censoring = c(0, Inf)
)
</code></pre>


<h3>See Also</h3>

<p><code><a href="#topic+extgp">extgp</a></code>, <code><a href="#topic+extgp.G">extgp.G</a></code>
</p>

<hr>
<h2 id='PickandsXU'>Extreme U-statistic Pickands estimator</h2><span id='topic+PickandsXU'></span>

<h3>Description</h3>

<p>Given a random sample of exceedances, the estimator
returns an estimator of the shape parameter or extreme
value index using a kernel of order 3, based on
<code>m</code> largest exceedances of <code>xdat</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PickandsXU(xdat, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PickandsXU_+3A_xdat">xdat</code></td>
<td>
<p>vector of observations of length <code class="reqn">n</code></p>
</td></tr>
<tr><td><code id="PickandsXU_+3A_m">m</code></td>
<td>
<p>number of largest order statistics <code class="reqn">3 \leq m \leq n</code>. Choosing <code class="reqn">m = n</code> amounts to using only the three largest observations in the sample.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The calculations are based on the recursions provided in Lemma 4.3 of Oorschot et al.
</p>


<h3>References</h3>

<p>Oorschot, J, J. Segers and C. Zhou (2023), Tail inference using extreme U-statistics,  Electron. J. Statist. 17(1): 1113-1159. <a href="https://doi.org/10.1214/23-EJS2129">doi:10.1214/23-EJS2129</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>samp &lt;- rgp(n = 1000, shape = 0.2)
PickandsXU(samp, m = 3)
</code></pre>

<hr>
<h2 id='plot.eprof'>Plot of (modified) profile likelihood</h2><span id='topic+plot.eprof'></span>

<h3>Description</h3>

<p>The function plots the (modified) profile likelihood and the tangent exponential profile likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'eprof'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.eprof_+3A_x">x</code></td>
<td>
<p>an object of class <code>eprof</code> returned by <code><a href="#topic+gpd.pll">gpd.pll</a></code> or <code><a href="#topic+gev.pll">gev.pll</a></code>.</p>
</td></tr>
<tr><td><code id="plot.eprof_+3A_...">...</code></td>
<td>
<p>further arguments to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a graph of the (modified) profile likelihoods
</p>


<h3>References</h3>

<p>Brazzale, A. R., Davison, A. C. and Reid, N. (2007). <em>Applied Asymptotics: Case Studies in Small-Sample Statistics</em>. Cambridge University Press, Cambridge.
</p>
<p>Severini, T. A. (2000). <em>Likelihood Methods in Statistics</em>. Oxford University Press, Oxford.
</p>

<hr>
<h2 id='plot.fr'>Plot of tangent exponential model profile likelihood</h2><span id='topic+plot.fr'></span>

<h3>Description</h3>

<p>This function is adapted from the <code>plot.fr</code> function from the <code>hoa</code> package bundle.
It differs from the latter mostly in the placement of legends.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fr'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fr_+3A_x">x</code></td>
<td>
<p>an object of class <code>fr</code> returned by <code><a href="#topic+gpd.tem">gpd.tem</a></code> or <code><a href="#topic+gev.tem">gev.tem</a></code>.</p>
</td></tr>
<tr><td><code id="plot.fr_+3A_...">...</code></td>
<td>
<p>further arguments to <code>plot</code> currently ignored. Providing a numeric vector <code>which</code> allows for custom selection of the plots. A logical <code>all</code>. See <strong>Details</strong>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots produced depend on the integers provided in <code>which</code>. <code>1</code> displays the Wald pivot, the likelihood root <code>r</code>, the modified likelihood root <code>rstar</code> and the likelihood modification <code>q</code> as functions of the parameter <code>psi</code>. <code>2</code> gives the renormalized profile log likelihood and adjusted form, with the maximum likelihood having ordinate value of zero. <code>3</code> provides the significance function, a transformation of <code>1</code>. Lastly, <code>4</code> plots the correction factor as a function of the likelihood root; it is a diagnostic plot aimed for detecting failure of
the asymptotic approximation, often due to poor numerics in a neighborhood of <code>r=0</code>; the function should be smooth. The function <code><a href="#topic+spline.corr">spline.corr</a></code> is designed to handle this by correcting numerically unstable estimates, replacing outliers and missing values with the fitted values from the fit.
</p>


<h3>Value</h3>

<p>graphs depending on argument <code>which</code>
</p>


<h3>References</h3>

<p>Brazzale, A. R., Davison, A. C. and Reid, N. (2007). <em>Applied Asymptotics: Case Studies in Small-Sample Statistics</em>. Cambridge University Press, Cambridge.
</p>

<hr>
<h2 id='power.vario'>Power variogram model</h2><span id='topic+power.vario'></span>

<h3>Description</h3>

<p>The power variogram model is
</p>
<p style="text-align: center;"><code class="reqn">\gamma(h) = (\|h\|/\lambda)^\alpha, \quad \lambda&gt;0, \alpha \in [0,2).</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>power.vario(h, alpha, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power.vario_+3A_h">h</code></td>
<td>
<p>vector or matrix of pairwise distances</p>
</td></tr>
<tr><td><code id="power.vario_+3A_alpha">alpha</code></td>
<td>
<p>smoothness parameter</p>
</td></tr>
<tr><td><code id="power.vario_+3A_scale">scale</code></td>
<td>
<p>scale parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of variogram values of the same length as <code>h</code>
</p>

<hr>
<h2 id='powerexp.cor'>Power exponential correlation model</h2><span id='topic+powerexp.cor'></span>

<h3>Description</h3>

<p>The power correlation model is
</p>
<p style="text-align: center;"><code class="reqn">\rho(h) = \exp\{-(\|h\|/\lambda)^\alpha\}, \quad \lambda&gt;0, \alpha \in [0,2).</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>powerexp.cor(h, alpha = 1, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="powerexp.cor_+3A_h">h</code></td>
<td>
<p>vector or matrix of pairwise distances</p>
</td></tr>
<tr><td><code id="powerexp.cor_+3A_alpha">alpha</code></td>
<td>
<p>smoothness parameter</p>
</td></tr>
<tr><td><code id="powerexp.cor_+3A_scale">scale</code></td>
<td>
<p>scale parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of correlations of the same dimensions as <code>h</code>
</p>

<hr>
<h2 id='pp'>Poisson process of extremes.</h2><span id='topic+pp'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix for the Poisson process likelihood.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pp_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="pp_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="pp_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="pp_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="pp_+3A_np">np</code></td>
<td>
<p>number of periods of observations. This is a <em>post hoc</em> adjustment for the intensity so that the parameters of the model coincide with those of a generalized extreme value distribution with block size <code>length(dat)/np</code>.</p>
</td></tr>
<tr><td><code id="pp_+3A_nobs">nobs</code></td>
<td>
<p>number of observations for the expected information matrix. Default to <code>length(dat)</code> if <code>dat</code> is provided.</p>
</td></tr>
</table>


<h3>Usage</h3>

<pre>pp.ll(par, dat)
pp.ll(par, dat, u, np)
pp.score(par, dat)
pp.infomat(par, dat, method = c('obs', 'exp'))</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>pp.ll</code>: log likelihood
</p>
</li>
<li> <p><code>pp.score</code>: score vector
</p>
</li>
<li> <p><code>pp.infomat</code>: observed or expected information matrix
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer, 209 p.
</p>
<p>Wadsworth, J.L. (2016). Exploiting Structure of Maximum Likelihood Estimators for Extreme Value Threshold Selection, <em>Technometrics</em>, <b>58</b>(1), 116-126, <code>http://dx.doi.org/10.1080/00401706.2014.998345</code>.
</p>
<p>Sharkey, P. and J.A. Tawn (2017). A Poisson process reparameterisation for Bayesian inference for extremes, <em>Extremes</em>, <b>20</b>(2), 239-263, <code>http://dx.doi.org/10.1007/s10687-016-0280-2</code>.
</p>

<hr>
<h2 id='pp.infomat'>Information matrix for the Poisson process likelihood</h2><span id='topic+pp.infomat'></span>

<h3>Description</h3>

<p>The function returns the expected or observed information matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.infomat(par, dat, method = c("obs", "exp"), u, np = 1, nobs = length(dat))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pp.infomat_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="pp.infomat_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="pp.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="pp.infomat_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="pp.infomat_+3A_np">np</code></td>
<td>
<p>number of periods of observations. This is a <em>post hoc</em> adjustment for the intensity so that the parameters of the model coincide with those of a generalized extreme value distribution with block size <code>length(dat)/np</code>.</p>
</td></tr>
<tr><td><code id="pp.infomat_+3A_nobs">nobs</code></td>
<td>
<p>number of observations for the expected information matrix. Default to <code>length(dat)</code> if <code>dat</code> is provided.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>information matrix of the NHPP
</p>


<h3>Note</h3>

<p>For the expected information matrix, the number of points above the threshold is random, but should correspond to
<code>np</code><code class="reqn">\Lambda</code>. The parametrization for <code>np</code> is shared between <code>fit.pp</code>, <code>pp.ll</code>, etc.
The entries for the information matrix are given in Sharkey and Tawn (2017), but contains some typos which were corrected.
</p>


<h3>References</h3>

<p>Sharkey, P. and J.A. Tawn (2017). A Poisson process reparameterisation for Bayesian inference for extremes, <em>Extremes</em>, <b>20</b>(2), 239-263, <code>http://dx.doi.org/10.1007/s10687-016-0280-2</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pp">pp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- rgp(n &lt;- 1e3, 0.1, 2, -0.1)
np &lt;- 10
mle &lt;- fit.pp(dat, threshold = 0, np =  np)$par
info_obs &lt;- pp.infomat(par = mle, dat = dat, method = "obs", u = 0, np = np)
info_exp &lt;- pp.infomat(par = mle, dat = dat, method = "exp", u = 0, np = np)
info_obs/info_exp

## End(Not run)
</code></pre>

<hr>
<h2 id='pp.ll'>Log-likelihood of Poisson process of threshold exceedances</h2><span id='topic+pp.ll'></span>

<h3>Description</h3>

<p>This function returns the log-likelihood of the non-homogeneous Poisson process
of exceedances above threshold <code>u</code>, adjusted so that there are <code>np</code> periods
of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.ll(par, dat, u, np = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pp.ll_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="pp.ll_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="pp.ll_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="pp.ll_+3A_np">np</code></td>
<td>
<p>number of periods of observations. This is a <em>post hoc</em> adjustment for the intensity so that the parameters of the model coincide with those of a generalized extreme value distribution with block size <code>length(dat)/np</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>log-likelihood of the NHPP
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pp">pp</a></code>
</p>

<hr>
<h2 id='pp.score'>Score vector for the Poisson process of threshold exceedances</h2><span id='topic+pp.score'></span>

<h3>Description</h3>

<p>Returns the score vector of the NHPP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pp.score(par, dat, u, np = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pp.score_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="pp.score_+3A_dat">dat</code></td>
<td>
<p>sample vector</p>
</td></tr>
<tr><td><code id="pp.score_+3A_u">u</code></td>
<td>
<p>threshold</p>
</td></tr>
<tr><td><code id="pp.score_+3A_np">np</code></td>
<td>
<p>number of periods of observations. This is a <em>post hoc</em> adjustment for the intensity so that the parameters of the model coincide with those of a generalized extreme value distribution with block size <code>length(dat)/np</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>score vector of NHPP
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pp">pp</a></code>
</p>

<hr>
<h2 id='rdir'>Random variate generation for Dirichlet distribution on <code class="reqn">S_{d}</code></h2><span id='topic+rdir'></span>

<h3>Description</h3>

<p>A function to sample Dirichlet random variables, based on the representation as ratios of Gamma.
Note that the RNG will generate on the full simplex and the sum to one constraint is respected
here
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdir(n, alpha, normalize = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rdir_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rdir_+3A_alpha">alpha</code></td>
<td>
<p>vector of parameter</p>
</td></tr>
<tr><td><code id="rdir_+3A_normalize">normalize</code></td>
<td>
<p>boolean. If <code>FALSE</code>, the function returns Gamma variates with parameter <code>alpha</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>sample of dimension <code>d</code> (size of alpha) from the Dirichlet distribution.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rdir(n=100, alpha=c(0.5,0.5,2),TRUE)
rdir(n=100, alpha=c(3,1,2),FALSE)
</code></pre>

<hr>
<h2 id='rgparp'>Simulation from generalized R-Pareto processes</h2><span id='topic+rgparp'></span>

<h3>Description</h3>

<p>The generalized R-Pareto process is supported on <code>(loc - scale / shape, Inf)</code> if <code>shape &gt; 0</code>,
or <code>(-Inf, loc - scale / shape)</code> for negative shape parameters, conditional on <code class="reqn">(X-r(loc))/r(scale)&gt;0</code>.
The standard Pareto process corresponds to <code>scale = loc = rep(1, d)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rgparp(
  n,
  shape = 1,
  thresh = 1,
  risk = c("mean", "sum", "site", "max", "min", "l2"),
  siteindex = NULL,
  d,
  loc,
  scale,
  param,
  sigma,
  model = c("log", "neglog", "bilog", "negbilog", "hr", "br", "xstud", "smith",
    "schlather", "ct", "sdir", "dirmix"),
  weights,
  vario,
  coord = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rgparp_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="rgparp_+3A_shape">shape</code></td>
<td>
<p>shape parameter of the generalized Pareto variable</p>
</td></tr>
<tr><td><code id="rgparp_+3A_thresh">thresh</code></td>
<td>
<p>univariate threshold for the exceedances of risk functional</p>
</td></tr>
<tr><td><code id="rgparp_+3A_risk">risk</code></td>
<td>
<p>string indicating the risk functional.</p>
</td></tr>
<tr><td><code id="rgparp_+3A_siteindex">siteindex</code></td>
<td>
<p>integer between 1 and d specifying the index of the site or variable</p>
</td></tr>
<tr><td><code id="rgparp_+3A_d">d</code></td>
<td>
<p>dimension of sample</p>
</td></tr>
<tr><td><code id="rgparp_+3A_loc">loc</code></td>
<td>
<p>location vector</p>
</td></tr>
<tr><td><code id="rgparp_+3A_scale">scale</code></td>
<td>
<p>scale vector</p>
</td></tr>
<tr><td><code id="rgparp_+3A_param">param</code></td>
<td>
<p>parameter vector for the logistic, bilogistic, negative bilogistic and extremal Dirichlet (Coles and Tawn) model.
Parameter matrix for the Dirichlet mixture. Degree of freedoms for extremal student model. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="rgparp_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick and extremal Student-t distributions. Symmetric matrix of squared  coefficients <code class="reqn">\lambda^2</code> for the Husler-Reiss model, with zero diagonal elements.</p>
</td></tr>
<tr><td><code id="rgparp_+3A_model">model</code></td>
<td>
<p>for multivariate extreme value distributions, users can choose between 1-parameter logistic and negative logistic, asymmetric logistic and negative logistic, bilogistic, Husler-Reiss, extremal Dirichlet model (Coles and Tawn) or the Dirichlet mixture. Spatial models include
the Brown-Resnick, Smith, Schlather and extremal Student max-stable processes. Max linear models are also supported</p>
</td></tr>
<tr><td><code id="rgparp_+3A_weights">weights</code></td>
<td>
<p>vector of length <code>m</code> for the <code>m</code> mixture components that sum to one. For the <code>"maxlin"</code> model, weights should be a matrix with <code>d</code> columns that represent the weight of the components and whose column sum to one (if provided, this argument overrides <code>asy</code>).</p>
</td></tr>
<tr><td><code id="rgparp_+3A_vario">vario</code></td>
<td>
<p>semivariogram function whose first argument must be distance. Used only if provided in conjunction with <code>coord</code> and if <code>sigma</code> is missing</p>
</td></tr>
<tr><td><code id="rgparp_+3A_coord">coord</code></td>
<td>
<p><code>d</code> by <code>k</code> matrix of coordinates, used as input in the variogram <code>vario</code> or as parameter for the Smith model. If <code>grid</code> is <code>TRUE</code>, unique entries should be supplied.</p>
</td></tr>
<tr><td><code id="rgparp_+3A_...">...</code></td>
<td>
<p>additional arguments for the <code>vario</code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the generalized R-Pareto process, with <code>attributes</code>
<code>accept.rate</code> if the procedure uses rejection sampling.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rgparp(n = 10, risk = 'site', siteindex = 2, d = 3, param = 2.5,
   model = 'log', scale = c(1, 2, 3), loc = c(2, 3, 4))
rgparp(n = 10, risk = 'max', d = 4, param = c(0.2, 0.1, 0.9, 0.5),
   scale = 1:4, loc = 1:4, model = 'bilog')
rgparp(n = 10, risk = 'sum', d = 3, param = c(0.8, 1.2, 0.6, -0.5),
   scale = 1:3, loc = 1:3, model = 'sdir')
vario &lt;- function(x, scale = 0.5, alpha = 0.8){ scale*x^alpha }
grid.coord &lt;- as.matrix(expand.grid(runif(4), runif(4)))
rgparp(n = 10, risk = 'max', vario = vario, coord = grid.coord,
   model = 'br', scale = runif(16), loc = rnorm(16))
</code></pre>

<hr>
<h2 id='rlarg'>Distribution of the r-largest observations</h2><span id='topic+rlarg'></span>

<h3>Description</h3>

<p>Likelihood, score function and information matrix for the r-largest observations likelihood.
</p>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rlarg_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="rlarg_+3A_dat">dat</code></td>
<td>
<p>an <code>n</code> by <code>r</code> sample matrix, ordered from largest to smallest in each row</p>
</td></tr>
<tr><td><code id="rlarg_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="rlarg_+3A_nobs">nobs</code></td>
<td>
<p>number of observations for the expected information matrix. Default to <code>nrow(dat)</code> if <code>dat</code> is provided.</p>
</td></tr>
<tr><td><code id="rlarg_+3A_r">r</code></td>
<td>
<p>number of order statistics kept. Default to <code>ncol(dat)</code></p>
</td></tr>
</table>


<h3>Usage</h3>

<pre>
rlarg.ll(par, dat, u, np)
rlarg.score(par, dat)
rlarg.infomat(par, dat, method = c('obs', 'exp'), nobs = nrow(dat), r = ncol(dat))</pre>


<h3>Functions</h3>


<ul>
<li> <p><code>rlarg.ll</code>: log likelihood
</p>
</li>
<li> <p><code>rlarg.score</code>: score vector
</p>
</li>
<li> <p><code>rlarg.infomat</code>: observed or expected information matrix
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Coles, S. (2001). <em>An Introduction to Statistical Modeling of Extreme Values</em>, Springer, 209 p.
</p>
<p>Smith, R.L. (1986).  Extreme value theory based on the r largest annual events, <em>Journal of Hydrology</em>, <b>86</b>(1-2), 27&ndash;43, <code>http://dx.doi.org/10.1016/0022-1694(86)90004-1</code>.
</p>

<hr>
<h2 id='rlarg.infomat'>Information matrix for the r-largest observations.</h2><span id='topic+rlarg.infomat'></span>

<h3>Description</h3>

<p>The function returns the expected or observed information matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlarg.infomat(
  par,
  dat,
  method = c("obs", "exp"),
  nobs = nrow(dat),
  r = ncol(dat)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rlarg.infomat_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="rlarg.infomat_+3A_dat">dat</code></td>
<td>
<p>an <code>n</code> by <code>r</code> sample matrix, ordered from largest to smallest in each row</p>
</td></tr>
<tr><td><code id="rlarg.infomat_+3A_method">method</code></td>
<td>
<p>string indicating whether to use the expected  (<code>'exp'</code>) or the observed (<code>'obs'</code> - the default) information matrix.</p>
</td></tr>
<tr><td><code id="rlarg.infomat_+3A_nobs">nobs</code></td>
<td>
<p>number of observations for the expected information matrix. Default to <code>nrow(dat)</code> if <code>dat</code> is provided.</p>
</td></tr>
<tr><td><code id="rlarg.infomat_+3A_r">r</code></td>
<td>
<p>number of order statistics kept. Default to <code>ncol(dat)</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+rlarg">rlarg</a></code>
</p>

<hr>
<h2 id='rlarg.ll'>Log-likelihood of the point process of r-largest observations</h2><span id='topic+rlarg.ll'></span>

<h3>Description</h3>

<p>The function returns the log-likelihood for an <code>n</code> by <code>r</code> matrix of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlarg.ll(par, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rlarg.ll_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="rlarg.ll_+3A_dat">dat</code></td>
<td>
<p>an <code>n</code> by <code>r</code> sample matrix, ordered from largest to smallest in each row</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+rlarg">rlarg</a></code>
</p>

<hr>
<h2 id='rlarg.score'>Score of the r-largest observations</h2><span id='topic+rlarg.score'></span>

<h3>Description</h3>

<p>The score is computed via linear interpolation for the shape parameter in a neighborhood of zero
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlarg.score(par, dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rlarg.score_+3A_par">par</code></td>
<td>
<p>vector of <code>loc</code>, <code>scale</code> and <code>shape</code></p>
</td></tr>
<tr><td><code id="rlarg.score_+3A_dat">dat</code></td>
<td>
<p>an <code>n</code> by <code>r</code> sample matrix, ordered from largest to smallest in each row</p>
</td></tr>
</table>


<h3>Value</h3>

<p>score vector of size 3
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rlarg">rlarg</a></code>
</p>

<hr>
<h2 id='rmev'>Exact simulations of multivariate extreme value distributions</h2><span id='topic+rmev'></span>

<h3>Description</h3>

<p>Implementation of the random number generators for multivariate extreme-value distributions
and max-stable processes based on the two algorithms described in Dombry, Engelke and Oesting (2016).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmev(
  n,
  d,
  param,
  asy,
  sigma,
  model = c("log", "alog", "neglog", "aneglog", "bilog", "negbilog", "hr", "br", "xstud",
    "smith", "schlather", "ct", "sdir", "dirmix", "pairbeta", "pairexp", "wdirbs",
    "wexpbs", "maxlin"),
  alg = c("ef", "sm"),
  weights = NULL,
  vario = NULL,
  coord = NULL,
  grid = FALSE,
  dist = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmev_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="rmev_+3A_d">d</code></td>
<td>
<p>dimension of sample</p>
</td></tr>
<tr><td><code id="rmev_+3A_param">param</code></td>
<td>
<p>parameter vector for the logistic, bilogistic, negative bilogistic and extremal Dirichlet (Coles and Tawn) model.
Parameter matrix for the Dirichlet mixture. Degree of freedoms for extremal student model. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="rmev_+3A_asy">asy</code></td>
<td>
<p>list of asymmetry parameters, as in function <code>rmvevd</code> from package <code>evd</code>, of <code class="reqn">2^d-1</code> vectors of size corresponding to the power set of <code>d</code>, with sum to one constraints.</p>
</td></tr>
<tr><td><code id="rmev_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick and extremal Student-t distributions. Symmetric matrix of squared  coefficients <code class="reqn">\lambda^2</code> for the Husler-Reiss model, with zero diagonal elements.</p>
</td></tr>
<tr><td><code id="rmev_+3A_model">model</code></td>
<td>
<p>for multivariate extreme value distributions, users can choose between 1-parameter logistic and negative logistic, asymmetric logistic and negative logistic, bilogistic, Husler-Reiss, extremal Dirichlet model (Coles and Tawn) or the Dirichlet mixture. Spatial models include
the Brown-Resnick, Smith, Schlather and extremal Student max-stable processes. Max linear models are also supported</p>
</td></tr>
<tr><td><code id="rmev_+3A_alg">alg</code></td>
<td>
<p>algorithm, either simulation via extremal function (<code>'ef'</code>) or via the spectral measure (<code>'sm'</code>). Default to <code>ef</code>.</p>
</td></tr>
<tr><td><code id="rmev_+3A_weights">weights</code></td>
<td>
<p>vector of length <code>m</code> for the <code>m</code> mixture components that sum to one. For the <code>"maxlin"</code> model, weights should be a matrix with <code>d</code> columns that represent the weight of the components and whose column sum to one (if provided, this argument overrides <code>asy</code>).</p>
</td></tr>
<tr><td><code id="rmev_+3A_vario">vario</code></td>
<td>
<p>semivariogram function whose first argument must be distance. Used only if provided in conjunction with <code>coord</code> and if <code>sigma</code> is missing</p>
</td></tr>
<tr><td><code id="rmev_+3A_coord">coord</code></td>
<td>
<p><code>d</code> by <code>k</code> matrix of coordinates, used as input in the variogram <code>vario</code> or as parameter for the Smith model. If <code>grid</code> is <code>TRUE</code>, unique entries should be supplied.</p>
</td></tr>
<tr><td><code id="rmev_+3A_grid">grid</code></td>
<td>
<p>Logical. <code>TRUE</code> if the coordinates are two-dimensional grid points (spatial models).</p>
</td></tr>
<tr><td><code id="rmev_+3A_dist">dist</code></td>
<td>
<p>symmetric matrix of pairwise distances. Default to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="rmev_+3A_...">...</code></td>
<td>
<p>additional arguments for the <code>vario</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector param differs depending on the model
</p>

<ul>
<li> <p><code>log</code>: one dimensional parameter greater than 1
</p>
</li>
<li> <p><code>alog</code>: <code class="reqn">2^d-d-1</code> dimensional parameter for <code>dep</code>. Values are recycled if needed.
</p>
</li>
<li> <p><code>neglog</code>: one dimensional positive parameter
</p>
</li>
<li> <p><code>aneglog</code>: <code class="reqn">2^d-d-1</code> dimensional parameter for <code>dep</code>. Values are recycled if needed.
</p>
</li>
<li> <p><code>bilog</code>: <code>d</code>-dimensional vector of parameters in <code class="reqn">[0,1]</code>
</p>
</li>
<li> <p><code>negbilog</code>: <code>d</code>-dimensional vector of negative parameters
</p>
</li>
<li> <p><code>ct, dir, negdir, sdir</code>: <code>d</code>-dimensional vector of positive (a)symmetry parameters. For <code>dir</code> and <code>negdir</code>, a <code class="reqn">d+1</code>
vector consisting of the <code>d</code> Dirichlet parameters and the last entry is an index of regular variation in <code class="reqn">(-\min(\alpha_1, \ldots, \alpha_d), 1]</code> treated as shape parameter
</p>
</li>
<li> <p><code>xstud</code>: one dimensional parameter corresponding to degrees of freedom <code>alpha</code>
</p>
</li>
<li> <p><code>dirmix</code>: <code>d</code> by <code>m</code>-dimensional matrix of positive (a)symmetry parameters
</p>
</li>
<li> <p><code>pairbeta, pairexp</code>: <code>d(d-1)/2+1</code> vector of parameters, containing the concentration parameter and the coefficients of the pairwise beta, in lexicographical order e.g., <code class="reqn">\beta_{12}, \beta_{13}, \ldots</code>
</p>
</li>
<li> <p><code>wdirbs, wexpbs</code>: <code>2d</code> vector of <code>d</code> concentration parameters followed by the <code>d</code> Dirichlet parameters
</p>
</li></ul>

<p>Stephenson points out that the multivariate asymmetric negative logistic model given in e.g. Coles and Tawn (1991) is not a valid distribution function in dimension <code class="reqn">d&gt;3</code> unless additional constraints are imposed on the parameter values.
The implementation in <code>mev</code> uses the same construction as the asymmetric logistic distribution (see the vignette). As such it does not match the bivariate implementation of <a href="evd.html#topic+rbvevd">rbvevd</a>.
</p>
<p>The dependence parameter of the <code>evd</code> package for the Husler-Reiss distribution can be recovered taking
for the Brown&ndash;Resnick model  <code class="reqn">2/r=\sqrt(2\gamma(h))</code> where <code class="reqn">h</code> is the lag vector between sites and <code class="reqn">r=1/\lambda</code> for the Husler&ndash;Reiss.
</p>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> exact sample from the corresponding multivariate extreme value model
</p>


<h3>Warning</h3>

<p>As of version 1.8 (August 16, 2016), there is a distinction between models <code>hr</code> and <code>br</code>. The latter is meant to be used in conjunction with variograms. The parametrization differs between the two models.
</p>
<p>The family of scaled Dirichlet is now parametrized by a parameter in <code class="reqn">-\min(\alpha)</code> appended to the the <code>d</code> vector <code>param</code> containing the parameter <code>alpha</code>
of the Dirichlet model. Arguments <code>model='dir'</code> and <code>model='negdir'</code> are still supported internally, but not listed in the options.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes, <em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>


<h3>See Also</h3>

<p><a href="#topic+rmevspec">rmevspec</a>, <a href="evd.html#topic+rmvevd">rmvevd</a>, <a href="evd.html#topic+rbvevd">rbvevd</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
rmev(n=100, d=3, param=2.5, model='log', alg='ef')
rmev(n=100, d=4, param=c(0.2,0.1,0.9,0.5), model='bilog', alg='sm')
## Spatial example using power variogram
#NEW: Semi-variogram must take distance as argument
semivario &lt;- function(x, scale, alpha){ scale*x^alpha }
#grid specification
grid.coord &lt;- as.matrix(expand.grid(runif(4), runif(4)))
rmev(n=100, vario=semivario, coord=grid.coord, model='br', scale = 0.5, alpha = 1)
#using the Brown-Resnick model with a covariance matrix
vario2cov &lt;- function(coord, semivario,...){
 sapply(1:nrow(coord), function(i) sapply(1:nrow(coord), function(j)
  semivario(sqrt(sum((coord[i,])^2)), ...) +
  semivario(sqrt(sum((coord[j,])^2)), ...) -
  semivario(sqrt(sum((coord[i,]-coord[j,])^2)), ...)))
}
rmev(n=100, sigma=vario2cov(grid.coord, semivario = semivario, scale = 0.5, alpha = 1), model='br')
# asymmetric logistic model - see function 'rmvevd' from package 'evd '
asy &lt;- list(0, 0, 0, 0, c(0,0), c(0,0), c(0,0), c(0,0), c(0,0), c(0,0),
  c(.2,.1,.2), c(.1,.1,.2), c(.3,.4,.1), c(.2,.2,.2), c(.4,.6,.2,.5))
rmev(n=1, d=4, param=0.3, asy=asy, model="alog")
#Example with a grid (generating an array)
rmev(n=10, sigma=cbind(c(2,1), c(1,3)), coord=cbind(runif(4), runif(4)), model='smith', grid=TRUE)
## Example with Dirichlet mixture
alpha.mat &lt;- cbind(c(2,1,1),c(1,2,1),c(1,1,2))
rmev(n=100, param=alpha.mat, weights=rep(1/3,3), model='dirmix')
rmev(n=10, param=c(0.1,1,2,3), d=3, model='pairbeta')
</code></pre>

<hr>
<h2 id='rmevspec'>Random samples from spectral distributions of multivariate extreme value models.</h2><span id='topic+rmevspec'></span>

<h3>Description</h3>

<p>Generate from <code class="reqn">Q_i</code>, the spectral measure of a given multivariate extreme value model based on the L1 norm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rmevspec(
  n,
  d,
  param,
  sigma,
  model = c("log", "neglog", "bilog", "negbilog", "hr", "br", "xstud", "smith",
    "schlather", "ct", "sdir", "dirmix", "pairbeta", "pairexp", "wdirbs", "wexpbs",
    "maxlin"),
  weights = NULL,
  vario = NULL,
  coord = NULL,
  grid = FALSE,
  dist = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rmevspec_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_d">d</code></td>
<td>
<p>dimension of sample</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_param">param</code></td>
<td>
<p>parameter vector for the logistic, bilogistic, negative bilogistic and extremal Dirichlet (Coles and Tawn) model.
Parameter matrix for the Dirichlet mixture. Degree of freedoms for extremal student model. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick and extremal Student-t distributions. Symmetric matrix of squared  coefficients <code class="reqn">\lambda^2</code> for the Husler-Reiss model, with zero diagonal elements.</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_model">model</code></td>
<td>
<p>for multivariate extreme value distributions, users can choose between 1-parameter logistic and negative logistic, asymmetric logistic and negative logistic, bilogistic, Husler-Reiss, extremal Dirichlet model (Coles and Tawn) or the Dirichlet mixture. Spatial models include
the Brown-Resnick, Smith, Schlather and extremal Student max-stable processes. Max linear models are also supported</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_weights">weights</code></td>
<td>
<p>vector of length <code>m</code> for the <code>m</code> mixture components that sum to one. For the <code>"maxlin"</code> model, weights should be a matrix with <code>d</code> columns that represent the weight of the components and whose column sum to one (if provided, this argument overrides <code>asy</code>).</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_vario">vario</code></td>
<td>
<p>semivariogram function whose first argument must be distance. Used only if provided in conjunction with <code>coord</code> and if <code>sigma</code> is missing</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_coord">coord</code></td>
<td>
<p><code>d</code> by <code>k</code> matrix of coordinates, used as input in the variogram <code>vario</code> or as parameter for the Smith model. If <code>grid</code> is <code>TRUE</code>, unique entries should be supplied.</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_grid">grid</code></td>
<td>
<p>Logical. <code>TRUE</code> if the coordinates are two-dimensional grid points (spatial models).</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_dist">dist</code></td>
<td>
<p>symmetric matrix of pairwise distances. Default to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="rmevspec_+3A_...">...</code></td>
<td>
<p>additional arguments for the <code>vario</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vector param differs depending on the model
</p>

<ul>
<li> <p><code>log</code>: one dimensional parameter greater than 1
</p>
</li>
<li> <p><code>neglog</code>: one dimensional positive parameter
</p>
</li>
<li> <p><code>bilog</code>: <code>d</code>-dimensional vector of parameters in <code class="reqn">[0,1]</code>
</p>
</li>
<li> <p><code>negbilog</code>: <code>d</code>-dimensional vector of negative parameters
</p>
</li>
<li> <p><code>ct</code>, <code>dir</code>, <code>negdir</code>: <code>d</code>-dimensional vector of positive (a)symmetry parameters. Alternatively, a <code class="reqn">d+1</code>
vector consisting of the <code>d</code> Dirichlet parameters and the last entry is an index of regular variation in <code class="reqn">(0, 1]</code> treated as scale
</p>
</li>
<li> <p><code>xstud</code>: one dimensional parameter corresponding to degrees of freedom <code>alpha</code>
</p>
</li>
<li> <p><code>dirmix</code>: <code>d</code> by <code>m</code>-dimensional matrix of positive (a)symmetry parameters
</p>
</li>
<li> <p><code>pairbeta, pairexp</code>: <code>d(d-1)/2+1</code> vector of parameters, containing the concentration parameter and the coefficients of the pairwise beta, in lexicographical order e.g., <code class="reqn">\beta_{1,2}, \beta_{1,3}, \ldots</code>
</p>
</li>
<li> <p><code>wdirbs, wexpbs</code>: <code>2d</code> vector of <code>d</code> concentration parameters followed by the <code>d</code> Dirichlet parameters
</p>
</li></ul>



<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> exact sample from the corresponding multivariate extreme value model
</p>


<h3>Note</h3>

<p>This functionality can be useful to generate for example Pareto processes with marginal exceedances.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Dombry, Engelke and Oesting (2016). Exact simulation of max-stable processes, <em>Biometrika</em>, <b>103</b>(2), 303&ndash;317.
</p>
<p>Boldi (2009). A note on the representation of parametric models for multivariate extremes.
<em>Extremes</em> <b>12</b>, 211&ndash;218.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
rmevspec(n=100, d=3, param=2.5, model='log')
rmevspec(n=100, d=3, param=2.5, model='neglog')
rmevspec(n=100, d=4, param=c(0.2,0.1,0.9,0.5), model='bilog')
rmevspec(n=100, d=2, param=c(0.8,1.2), model='ct') #Dirichlet model
rmevspec(n=100, d=2, param=c(0.8,1.2,0.5), model='sdir') #with additional scale parameter
#Variogram gamma(h) = scale*||h||^alpha
#NEW: Variogram must take distance as argument
vario &lt;- function(x, scale=0.5, alpha=0.8){ scale*x^alpha }
#grid specification
grid.coord &lt;- as.matrix(expand.grid(runif(4), runif(4)))
rmevspec(n=100, vario=vario,coord=grid.coord, model='br')
## Example with Dirichlet mixture
alpha.mat &lt;- cbind(c(2,1,1),c(1,2,1),c(1,1,2))
rmevspec(n=100, param=alpha.mat, weights=rep(1/3,3), model='dirmix')
</code></pre>

<hr>
<h2 id='rparp'>Simulation from R-Pareto processes</h2><span id='topic+rparp'></span>

<h3>Description</h3>

<p>Simulation from R-Pareto processes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rparp(
  n,
  shape = 1,
  risk = c("sum", "site", "max", "min", "l2"),
  siteindex = NULL,
  d,
  param,
  sigma,
  model = c("log", "neglog", "bilog", "negbilog", "hr", "br", "xstud", "smith",
    "schlather", "ct", "sdir", "dirmix"),
  weights,
  vario,
  coord = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rparp_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="rparp_+3A_shape">shape</code></td>
<td>
<p>shape tail index of Pareto variable</p>
</td></tr>
<tr><td><code id="rparp_+3A_risk">risk</code></td>
<td>
<p>string indicating risk functional.</p>
</td></tr>
<tr><td><code id="rparp_+3A_siteindex">siteindex</code></td>
<td>
<p>integer between 1 and d specifying the index of the site or variable</p>
</td></tr>
<tr><td><code id="rparp_+3A_d">d</code></td>
<td>
<p>dimension of sample</p>
</td></tr>
<tr><td><code id="rparp_+3A_param">param</code></td>
<td>
<p>parameter vector for the logistic, bilogistic, negative bilogistic and extremal Dirichlet (Coles and Tawn) model.
Parameter matrix for the Dirichlet mixture. Degree of freedoms for extremal student model. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="rparp_+3A_sigma">sigma</code></td>
<td>
<p>covariance matrix for Brown-Resnick and extremal Student-t distributions. Symmetric matrix of squared  coefficients <code class="reqn">\lambda^2</code> for the Husler-Reiss model, with zero diagonal elements.</p>
</td></tr>
<tr><td><code id="rparp_+3A_model">model</code></td>
<td>
<p>for multivariate extreme value distributions, users can choose between 1-parameter logistic and negative logistic, asymmetric logistic and negative logistic, bilogistic, Husler-Reiss, extremal Dirichlet model (Coles and Tawn) or the Dirichlet mixture. Spatial models include
the Brown-Resnick, Smith, Schlather and extremal Student max-stable processes. Max linear models are also supported</p>
</td></tr>
<tr><td><code id="rparp_+3A_weights">weights</code></td>
<td>
<p>vector of length <code>m</code> for the <code>m</code> mixture components that sum to one. For the <code>"maxlin"</code> model, weights should be a matrix with <code>d</code> columns that represent the weight of the components and whose column sum to one (if provided, this argument overrides <code>asy</code>).</p>
</td></tr>
<tr><td><code id="rparp_+3A_vario">vario</code></td>
<td>
<p>semivariogram function whose first argument must be distance. Used only if provided in conjunction with <code>coord</code> and if <code>sigma</code> is missing</p>
</td></tr>
<tr><td><code id="rparp_+3A_coord">coord</code></td>
<td>
<p><code>d</code> by <code>k</code> matrix of coordinates, used as input in the variogram <code>vario</code> or as parameter for the Smith model. If <code>grid</code> is <code>TRUE</code>, unique entries should be supplied.</p>
</td></tr>
<tr><td><code id="rparp_+3A_...">...</code></td>
<td>
<p>additional arguments for the <code>vario</code> function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>riskf=max</code> and <code>riskf=min</code>, the procedure uses rejection sampling based on Pareto variates
sampled from <code>sum</code> and may be slow if <code>d</code> is large.
</p>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> sample from the R-Pareto process, with <code>attributes</code>
<code>accept.rate</code> if the procedure uses rejection sampling.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rparp(n=10, risk = 'site', siteindex=2, d=3, param=2.5, model='log')
rparp(n=10, risk = 'min', d=3, param=2.5, model='neglog')
rparp(n=10, risk = 'max', d=4, param=c(0.2,0.1,0.9,0.5), model='bilog')
rparp(n=10, risk = 'sum', d=3, param=c(0.8,1.2,0.6, -0.5), model='sdir')
vario &lt;- function(x, scale=0.5, alpha=0.8){ scale*x^alpha }
grid.coord &lt;- as.matrix(expand.grid(runif(4), runif(4)))
rparp(n=10, risk = 'max', vario=vario, coord=grid.coord, model='br')
</code></pre>

<hr>
<h2 id='rparpcs'>Simulation from Pareto processes using composition sampling</h2><span id='topic+rparpcs'></span>

<h3>Description</h3>

<p>The algorithm performs forward sampling by simulating first from a
mixture, then sample angles conditional on them being less than (max) or greater than (min) one.
The resulting sample from the angular distribution is then multiplied by
Pareto variates with tail index <code>shape</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rparpcs(
  n,
  model = c("log", "neglog", "br", "xstud"),
  risk = c("max", "min"),
  param = NULL,
  d,
  Lambda = NULL,
  Sigma = NULL,
  df = NULL,
  shape = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rparpcs_+3A_n">n</code></td>
<td>
<p>sample size.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_model">model</code></td>
<td>
<p>string indicating the model family.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_risk">risk</code></td>
<td>
<p>string indicating the risk functional. Only <code>max</code> and <code>min</code> are currently supported.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_param">param</code></td>
<td>
<p>parameter value for the logistic or negative logistic model</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate model, only needed for logistic or negative logistic models</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_lambda">Lambda</code></td>
<td>
<p>parameter matrix for the Brown&ndash;Resnick model. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_sigma">Sigma</code></td>
<td>
<p>correlation matrix if <code>model = 'xstud'</code>, otherwise
the covariance matrix formed from the stationary Brown-Resnick process.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_df">df</code></td>
<td>
<p>degrees of freedom for extremal Student process.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_shape">shape</code></td>
<td>
<p>tail index of the Pareto variates (reciprocal shape parameter). Must be strictly positive.</p>
</td></tr>
<tr><td><code id="rparpcs_+3A_...">...</code></td>
<td>
<p>additional parameters, currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the moment, only exchangeable models and models based n elliptical processes are handled.
</p>
<p>The parametrization of the Brown&ndash;Resnick is in terms of the matrix <code>Lambda</code>, which
is formed by evaluating the semivariogram <code class="reqn">\gamma</code> at sites <code class="reqn">s_i, s_j</code>, meaning that
<code class="reqn">\Lambda_{i,j} = \gamma(s_i, s_j)/2</code>.
</p>
<p>The argument <code>Sigma</code> is ignored for the Brown-Resnick model
if <code>Lambda</code> is provided by the user.
</p>


<h3>Value</h3>

<p>an <code>n</code> by <code>d</code> matrix of samples, where <code>d = ncol(Sigma)</code>, with <code>attributes</code> <code>mixt.weights</code>.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rparp">rparp</a></code> for general simulation of Pareto processes based on an accept-reject algorithm.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Brown-Resnick, Wadsworth and Tawn (2014) parametrization
D &lt;- 20L
coord &lt;- cbind(runif(D), runif(D))
semivario &lt;- function(d, alpha = 1.5, lambda = 1){0.5 * (d/lambda)^alpha}
Lambda &lt;- semivario(as.matrix(dist(coord))) / 2
rparpcs(n = 10, Lambda = Lambda, model = 'br', shape = 0.1)
#Extremal Student
Sigma &lt;- stats::rWishart(n = 1, df = 20, Sigma = diag(10))[,,1]
rparpcs(n = 10, Sigma = cov2cor(Sigma), df = 3, model = 'xstud')

## End(Not run)
</code></pre>

<hr>
<h2 id='rparpcshr'>Simulation of generalized Huesler-Reiss Pareto vectors via composition sampling</h2><span id='topic+rparpcshr'></span>

<h3>Description</h3>

<p>Sample from the generalized Pareto process associated to Huesler-Reiss spectral profiles.
For the Huesler-Reiss Pareto vectors, the matrix <code>Sigma</code> is utilized to build <code class="reqn">Q</code> viz.
</p>
<p style="text-align: center;"><code class="reqn">Q = \Sigma^{-1} - \frac{\Sigma^{-1}\mathbf{1}_d\mathbf{1}_d^\top\Sigma^{-1}}{\mathbf{1}_d^\top\Sigma^{-1}\mathbf{1}_d}.</code>
</p>

<p>The location vector <code>m</code> and <code>Sigma</code> are the parameters of the underlying log-Gaussian process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rparpcshr(n, u, alpha, Sigma, m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rparpcshr_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rparpcshr_+3A_u">u</code></td>
<td>
<p>vector of marginal location parameters (must be strictly positive)</p>
</td></tr>
<tr><td><code id="rparpcshr_+3A_alpha">alpha</code></td>
<td>
<p>vector of shape parameters (must be strictly positive).</p>
</td></tr>
<tr><td><code id="rparpcshr_+3A_sigma">Sigma</code></td>
<td>
<p>covariance matrix of process, used to define <code class="reqn">Q</code>. See <b>Details</b>.</p>
</td></tr>
<tr><td><code id="rparpcshr_+3A_m">m</code></td>
<td>
<p>location vector of Gaussian distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>n</code> by d matrix of observations
</p>


<h3>References</h3>

<p>Ho, Z. W. O and C. Dombry (2019), Simple models for multivariate regular variations and the
Huesler-Reiss Pareto distribution, Journal of Multivariate Analysis (<b>173</b>), p. 525-550, <a href="https://doi.org/10.1016/j.jmva.2019.04.008">doi:10.1016/j.jmva.2019.04.008</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>D &lt;- 20L
coord &lt;- cbind(runif(D), runif(D))
di &lt;- as.matrix(dist(rbind(c(0, ncol(coord)), coord)))
semivario &lt;- function(d, alpha = 1.5, lambda = 1){(d/lambda)^alpha}
Vmat &lt;- semivario(di)
Sigma &lt;- outer(Vmat[-1, 1], Vmat[1, -1], '+') - Vmat[-1, -1]
m &lt;- Vmat[-1,1]
## Not run: 
samp &lt;- rparpcshr(n = 100, u = c(rep(1, 10), rep(2, 10)),
          alpha = seq(0.1, 1, length = 20), Sigma = Sigma, m = m)

## End(Not run)
</code></pre>

<hr>
<h2 id='rrlarg'>Simulate r-largest observations from point process of extremes</h2><span id='topic+rrlarg'></span>

<h3>Description</h3>

<p>Simulate the <code>r</code>-largest observations from a Poisson point process with intensity
</p>
<p style="text-align: center;"><code class="reqn">\Lambda(x) = (1+\xi(x-\mu)/\sigma)^{-1/\xi}</code>
</p>
<p>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrlarg(n, r, loc = 0, scale = 1, shape = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rrlarg_+3A_n">n</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="rrlarg_+3A_r">r</code></td>
<td>
<p>number of observations per block</p>
</td></tr>
<tr><td><code id="rrlarg_+3A_loc">loc</code></td>
<td>
<p>location parameter</p>
</td></tr>
<tr><td><code id="rrlarg_+3A_scale">scale</code></td>
<td>
<p>scale parameter</p>
</td></tr>
<tr><td><code id="rrlarg_+3A_shape">shape</code></td>
<td>
<p>shape parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an <code>n</code> by <code>r</code> matrix of samples from the point process, ordered from largest to smallest in each row.
</p>

<hr>
<h2 id='schlather.vario'>Variogram model of Schlather and Moreva</h2><span id='topic+schlather.vario'></span>

<h3>Description</h3>

<p>The variogram model is
</p>
<p style="text-align: center;"><code class="reqn">\gamma(h) = \frac{[1+\{(\|h\|/\lambda\}^\alpha]^{\beta/\alpha}-1}{2^{\beta/\alpha}-1}, \quad 0 &lt; \alpha \leq 2, \beta \leq 2.</code>
</p>

<p>The model is defined at <code class="reqn">\beta=0</code> by continuity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>schlather.vario(h, alpha, beta, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="schlather.vario_+3A_h">h</code></td>
<td>
<p>vector or matrix of pairwise distances</p>
</td></tr>
<tr><td><code id="schlather.vario_+3A_alpha">alpha</code></td>
<td>
<p>smoothness parameter</p>
</td></tr>
<tr><td><code id="schlather.vario_+3A_beta">beta</code></td>
<td>
<p>shape parameter, must be less than 2</p>
</td></tr>
<tr><td><code id="schlather.vario_+3A_scale">scale</code></td>
<td>
<p>scale parameter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector or matrix of variogram values of the same length as <code>h</code>
</p>

<hr>
<h2 id='scoreindep'>Ramos and Ledford test of independence</h2><span id='topic+scoreindep'></span>

<h3>Description</h3>

<p>The Ramos and Ledford (2005) score test of independence is a modification of tests by Tawn (1988) and Ledford and Tawn (1996) for a logistic model parameter <code class="reqn">\alpha=1</code>; the latter two have scores with zero expectation, but the variance of the score are infinite, which produces non-regularity and yield test, once suitably normalized, that converge slowly to their asymptotic null distribution. The test, designed for bivariate samples, transforms observations to have unit Frechet margins and considers a bivariate censored likelihood approach for the logistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreindep(xdat, p, test = c("ledford", "tawn"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scoreindep_+3A_xdat">xdat</code></td>
<td>
<p>a <code>n</code> by 2 matrix of observations</p>
</td></tr>
<tr><td><code id="scoreindep_+3A_p">p</code></td>
<td>
<p>probability level for the marginal threshold</p>
</td></tr>
<tr><td><code id="scoreindep_+3A_test">test</code></td>
<td>
<p>string; if <code>tawn</code>, only censor observations in the upper quadrant when both variables are large as in Tawn (1988), otherwise censor marginally for <code>ledford</code> as in Ledford and Tawn (1996).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements
</p>

<dl>
<dt><code>stat</code></dt><dd><p>value of the score test statistic</p>
</dd>
<dt><code>pval</code></dt><dd><p>asymptotic p-value</p>
</dd>
<dt><code>test</code></dt><dd><p><code>test</code> argument</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>samp &lt;- rmev(n = 1000, d = 2,
    param = 0.99, model = "log")
scoreindep(samp, p = 0.9)
</code></pre>

<hr>
<h2 id='smith.penult'>Smith's penultimate approximations</h2><span id='topic+smith.penult'></span>

<h3>Description</h3>

<p>The function takes as arguments the distribution and density functions. There are two options:
<code>method='bm'</code> yields block maxima and <code>method='pot'</code> threshold exceedances.
For <code>method='bm'</code>, the user should provide in such case the block sizes via the
argument <code>m</code>, whereas if <code>method='pot'</code>, a vector of threshold values should be
provided. The other argument (<code>u</code> or <code>m</code> depending on the method) is ignored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smith.penult(family, method = c("bm", "pot"), u, qu, m, returnList = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smith.penult_+3A_family">family</code></td>
<td>
<p>the name of the parametric family. Will be used to obtain <code>dfamily</code>, <code>pfamily</code>, <code>qfamily</code></p>
</td></tr>
<tr><td><code id="smith.penult_+3A_method">method</code></td>
<td>
<p>either block maxima (<code>'bm'</code>) or peaks-over-threshold (<code>'pot'</code>) are supported</p>
</td></tr>
<tr><td><code id="smith.penult_+3A_u">u</code></td>
<td>
<p>vector of thresholds for method <code>'pot'</code></p>
</td></tr>
<tr><td><code id="smith.penult_+3A_qu">qu</code></td>
<td>
<p>vector of quantiles for method <code>'pot'</code>. Ignored if argument <code>u</code> is provided.</p>
</td></tr>
<tr><td><code id="smith.penult_+3A_m">m</code></td>
<td>
<p>vector of block sizes for method <code>'bm'</code></p>
</td></tr>
<tr><td><code id="smith.penult_+3A_returnlist">returnList</code></td>
<td>
<p>logical; should the arguments be returned as a list or as a matrix of parameter</p>
</td></tr>
<tr><td><code id="smith.penult_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>densF</code> and <code>distF</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Alternatively, the user can provide functions <code>densF</code>, <code>quantF</code> and <code>distF</code> for the density,
quantile function and distribution functions, respectively. The user can also supply the derivative
of the density function, <code>ddensF</code>. If the latter is missing, it will be approximated using finite-differences.
</p>
<p>For <code>method = "pot"</code>, the function computes the reciprocal hazard and its derivative on the log scale to avoid numerical overflow. Thus, the density function should have argument <code>log</code> and the distribution function arguments <code>log.p</code> and <code>lower.tail</code>, respectively.
</p>


<h3>Value</h3>

<p>either a vector, a matrix if either <code>length(m)&gt;1</code> or <code>length(u)&gt;1</code> or a list (if <code>returnList</code>) containing
</p>

<ul>
<li> <p><code>loc</code>: location parameters (<code>method='bm'</code>)
</p>
</li>
<li> <p><code>scale</code>: scale parameters
</p>
</li>
<li> <p><code>shape</code>: shape parameters
</p>
</li>
<li> <p><code>u</code>: thresholds (if <code>method='pot'</code>), percentile corresponding to threshold (if <code>method='pot'</code>)
</p>
</li>
<li> <p><code>m</code>: block sizes (if <code>method='bm'</code>)
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>References</h3>

<p>Smith, R.L. (1987). Approximations in extreme value theory. <em>Technical report 205</em>, Center for Stochastic Process, University of North Carolina, 1&ndash;34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Threshold exceedance for Normal variables
qu &lt;- seq(1,5,by=0.02)
penult &lt;- smith.penult(family = "norm", ddensF=function(x){-x*dnorm(x)},
   method = 'pot', u = qu)
plot(qu, penult$shape, type='l', xlab='Quantile',
   ylab='Penultimate shape', ylim=c(-0.5,0))
#Block maxima for Gamma variables -
#User must provide arguments for shape (or rate)
m &lt;- seq(30, 3650, by=30)
penult &lt;- smith.penult(family = 'gamma', method = 'bm', m=m, shape=0.1)
plot(m, penult$shape, type='l', xlab='Quantile', ylab='Penultimate shape')

#Comparing density of GEV approximation with true density of maxima
m &lt;- 100 #block of size 100
p &lt;- smith.penult(family='norm',
   ddensF=function(x){-x*dnorm(x)}, method='bm', m=m, returnList=FALSE)
x &lt;- seq(1, 5, by = 0.01)
plot(x, m*dnorm(x)*exp((m-1)*pnorm(x,log.p=TRUE)),type='l', ylab='Density',
main='Distribution of the maxima of\n 100 standard normal variates')
lines(x, mev::dgev(x,loc=p[1], scale=p[2], shape=0),col=2)
lines(x, mev::dgev(x,loc=p[1], scale=p[2], shape=p[3]),col=3)
legend(x = 'topright',lty = c(1,1,1,1), col = c(1,2,3,4),
   legend = c('exact', 'ultimate', 'penultimate'), bty = 'n')
</code></pre>

<hr>
<h2 id='smith.penult.fn'>Smith's third penultimate approximation</h2><span id='topic+smith.penult.fn'></span>

<h3>Description</h3>

<p>This function returns the density and distribution functions
of the 3rd penultimate approximation for extremes of Smith (1987). It requires
knowledge of the exact constants <code class="reqn">\epsilon</code> and <code class="reqn">\rho</code> described in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smith.penult.fn(
  loc,
  scale,
  shape,
  eps,
  rho = NULL,
  method = c("bm", "pot"),
  mdaGumbel = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="smith.penult.fn_+3A_loc">loc</code></td>
<td>
<p>location parameter returned by <code><a href="#topic+smith.penult">smith.penult</a></code> or threshold vector</p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_scale">scale</code></td>
<td>
<p>scale parameter returned by <code><a href="#topic+smith.penult">smith.penult</a></code></p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_shape">shape</code></td>
<td>
<p>shape parameter returned by <code><a href="#topic+smith.penult">smith.penult</a></code></p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_eps">eps</code></td>
<td>
<p>parameter vector, see <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_rho">rho</code></td>
<td>
<p>second-order parameter, model dependent</p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_method">method</code></td>
<td>
<p>one of <code>pot</code> for the generalized Pareto or <code>bm</code> for the generalized extreme value distribution</p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_mdagumbel">mdaGumbel</code></td>
<td>
<p>logical indicating whether the function <code class="reqn">H_{\rho}</code> should be replaced by <code class="reqn">x^3/6</code>; see <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="smith.penult.fn_+3A_...">...</code></td>
<td>
<p>additional parameters, currently ignored. These are used for backward compatibility due to a change in the names of the arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">F</code>, <code class="reqn">f</code> denote respectively the distribution and density functions and define the function <code class="reqn">\phi(x)</code>  as
</p>
<p style="text-align: center;"><code class="reqn">\phi(x)=-\frac{F(x)\log F(x)}{f(x)}</code>
</p>

<p>for block maxima.
The sequence <code>loc</code> corresponds to <code class="reqn">b_n</code> otherwise, defined as the solution of <code class="reqn">F(b_n)=\exp(-1/n)</code>.
</p>
<p>The <code>scale</code> is given by <code class="reqn">a_n=\phi(b_n)</code>, the <code>shape</code> as <code class="reqn">\gamma_n=\phi'(b_n)</code>. These are returned by a call to <a href="#topic+smith.penult">smith.penult</a>.
</p>
<p>For threshold exceedances, <code class="reqn">b_n</code> is replaced by the sequence of thresholds <code class="reqn">u</code> and we
take instead <code class="reqn">\phi(x)</code> to be the reciprocal hazard function <code class="reqn">\phi(x)=(1-F(x))/f(x)</code>.
</p>
<p>In cases where the distribution function is in the maximum domain of
attraction of the Gumbel distribution, <code class="reqn">\rho</code> is possibly undetermined and
<code class="reqn">\epsilon</code> can be equal to <code class="reqn">\phi(b_n)\phi''(b_n)</code>.
</p>
<p>For distributions in the maximum domain of
attraction of the Gumbel distribution and that are class N, it is also possible to abstract from the <code class="reqn">\rho</code> parameter by substituting the function <code class="reqn">H_{\rho}</code> by <code class="reqn">x^3/6</code> without affecting the rate of convergence. This can be done by setting <code>mdaGumbel=TRUE</code> in the function call.
</p>


<h3>Warning</h3>

<p>The third penultimate approximation does not yield a valid distribution function over the whole range of the original distribution, but is rather valid in a neighborhood of the true support of the distribution of maxima/threshold exceedance.
The function handles the most standard failure (decreasing distribution function and negative densities), but any oscillatory behaviour will not necessarily be captured.
This is inherent to the method and can be resolved by &lsquo;not&rsquo; evaluating the functions <code class="reqn">F</code> and <code class="reqn">f</code> at the faulty points.
</p>


<h3>References</h3>

<p>Smith, R.L. (1987). Approximations in extreme value theory. <em>Technical report 205</em>, Center for Stochastic Process, University of North Carolina, 1&ndash;34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Normal maxima example from Smith (1987)
m &lt;- 100 #block of size 100
p &lt;- smith.penult(family='norm',
   ddensF=function(x){-x*dnorm(x)}, method='bm', m=m, returnList=FALSE)
approx &lt;- smith.penult.fn(loc=p[1], scale=p[2], shape=p[3],
   eps=p[3]^2+p[3]+p[2]^2, mdaGumbel=TRUE, method='bm')
x &lt;- seq(0.5,6,by=0.001)
#First penultimate approximation
plot(x, exp(m*pnorm(x, log.p=TRUE)),type='l', ylab='CDF',
main='Distribution of the maxima of\n 100 standard normal variates')
lines(x, mev::pgev(x,loc=p[1], scale=p[2], shape=0),col=2)
lines(x, mev::pgev(x,loc=p[1], scale=p[2], shape=p[3]),col=3)
lines(x, approx$F(x),col=4)
legend(x='bottomright',lty=c(1,1,1,1),col=c(1,2,3,4),
   legend=c('Exact','1st approx.','2nd approx.','3rd approx'),bty='n')
plot(x, m*dnorm(x)*exp((m-1)*pnorm(x,log.p=TRUE)),type='l', ylab='Density',
main='Distribution of the maxima of\n 100 standard normal variates')
lines(x, mev::dgev(x,loc=p[1], scale=p[2], shape=0),col=2)
lines(x, mev::dgev(x,loc=p[1], scale=p[2], shape=p[3]),col=3)
lines(x, approx$f(x),col=4)
legend(x='topright',lty=c(1,1,1,1),col=c(1,2,3,4),
 legend=c('Exact','1st approx.','2nd approx.','3rd approx'),bty='n')

#Threshold exceedances
par &lt;- smith.penult(family = "norm", ddensF=function(x){-x*dnorm(x)},
method='pot', u=4, returnList=FALSE)
approx &lt;- smith.penult.fn(loc=par[1], scale=par[2], shape=par[3],
 eps=par[3]^2+par[3]+par[2]^2, mdaGumbel=TRUE, method='pot')
x &lt;- seq(4.01,7,by=0.01)
#Distribution function
plot(x, 1-(1-pnorm(x))/(1-pnorm(par[1])),type='l', ylab='Conditional CDF',
main='Exceedances over 4\n for standard normal variates')
lines(x, mev::pgp(x, loc=par[1], scale=par[2], shape=0),col=2)
lines(x, mev::pgp(x, loc=par[1], scale=par[2], shape=par[3]),col=3)
lines(x, approx$F(x),col=4)
#Density
plot(x, dnorm(x)/(1-pnorm(par[1])),type='l', ylab='Conditional density',
main='Exceedances over 4\n for standard normal variates')
lines(x, dgp(x, loc=par[1], scale=par[2], shape=0),col=2)
lines(x, dgp(x, loc=par[1], scale=par[2], shape=par[3]),col=3)
lines(x, approx$f(x),col=4)
</code></pre>

<hr>
<h2 id='spline.corr'>Spline correction for Fraser-Reid approximations</h2><span id='topic+spline.corr'></span>

<h3>Description</h3>

<p>The tangent exponential model can be numerically unstable for values close to <code class="reqn">r = 0</code>.
This function corrects these incorrect values, which are interpolated using splines.
The function takes as input an object of class <code>fr</code> and returns the same object with
different <code>rstar</code> values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spline.corr(fr, method = c("cobs", "smooth.spline"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spline.corr_+3A_fr">fr</code></td>
<td>
<p>an object of class <code>fr</code>, normally the output of <a href="#topic+gpd.tem">gpd.tem</a> or <a href="#topic+gev.tem">gev.tem</a>.</p>
</td></tr>
<tr><td><code id="spline.corr_+3A_method">method</code></td>
<td>
<p>string for the method, either <code>cobs</code> (constrained robust B-spline from eponym package) or <code>smooth.spline</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If available, the function uses <code>cobs</code> from the eponym package. The latter handles constraints and smoothness penalties, and is more robust than the equivalent <code><a href="stats.html#topic+smooth.spline">smooth.spline</a></code>.
</p>


<h3>Value</h3>

<p>an object of class <code>fr</code>, containing as additional arguments <code>spline</code> and a modified <code>rstar</code> argument.
</p>


<h3>Warning</h3>

<p>While penalized (robust) splines often do a good job at capturing and correcting for numerical outliers and <code>NA</code>, it
may also be driven by unusual values lying on the profile log-likelihood the curve or fail to detect outliers (or falsely identifying &lsquo;correct&rsquo; values as outliers). The user should always validate by comparing the plots of both the uncorrected (raw) output of the object with that of <code>spline.corr</code>.
</p>

<hr>
<h2 id='spunif'>Semi-parametric marginal transformation to uniform</h2><span id='topic+spunif'></span>

<h3>Description</h3>

<p>The function <code>spunif</code> transforms a matrix or vector of data <code>x</code>
to the pseudo-uniform scale using a semiparametric transform. Data below the threshold
are transformed to pseudo-uniforms using a rank transform, while data above the threshold
are assumed to follow a generalized Pareto distribution. The parameters of the latter are
estimated using maximum likelihood if either <code>scale = NULL</code> or <code>shape = NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spunif(x, thresh, scale = NULL, shape = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="spunif_+3A_x">x</code></td>
<td>
<p>matrix or vector of data</p>
</td></tr>
<tr><td><code id="spunif_+3A_thresh">thresh</code></td>
<td>
<p>vector of marginal thresholds</p>
</td></tr>
<tr><td><code id="spunif_+3A_scale">scale</code></td>
<td>
<p>vector of marginal scale parameters for the generalized Pareto</p>
</td></tr>
<tr><td><code id="spunif_+3A_shape">shape</code></td>
<td>
<p>vector of marginal shape parameters for the generalized Pareto</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix or vector of the same dimension as <code>x</code>, with pseudo-uniform observations
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- rmev(1000, d = 3, param = 2, model = 'log')
thresh &lt;- apply(x, 2, quantile, 0.95)
spunif(x, thresh)
</code></pre>

<hr>
<h2 id='taildep'>Coefficient of tail correlation and tail dependence</h2><span id='topic+taildep'></span>

<h3>Description</h3>

<p>For data with unit Pareto margins, the coefficient of tail dependence <code class="reqn">\eta</code> is defined  via </p>
<p style="text-align: center;"><code class="reqn">\Pr(\min(X) &gt; x) = L(x)x^{-1/\eta},</code>
</p>

<p>where <code class="reqn">L(x)</code> is a slowly varying function. Ignoring the latter, several estimators of <code class="reqn">\eta</code> can be defined. In unit Pareto margins, <code class="reqn">\eta</code> is a nonnegative shape parameter that can be estimated by fitting a generalized Pareto distribution above a high threshold. In exponential margins, <code class="reqn">\eta</code> is a scale parameter and the maximum likelihood estimator of the latter is the Hill estimator. Both methods are based on peaks-over-threshold and the user can choose between pointwise confidence confint obtained through a likelihood ratio test statistic (<code>"lrt"</code>) or the Wald statistic (<code>"wald"</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>taildep(
  data,
  u = NULL,
  nq = 40,
  qlim = c(0.8, 0.99),
  depmeas = c("eta", "chi"),
  method = list(eta = c("emp", "betacop", "gpd", "hill"), chi = c("emp", "betacop")),
  confint = c("wald", "lrt"),
  level = 0.95,
  trunc = TRUE,
  empirical.transformation = TRUE,
  ties.method = "random",
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="taildep_+3A_data">data</code></td>
<td>
<p>an <code class="reqn">n</code> by <code class="reqn">d</code> matrix of multivariate observations</p>
</td></tr>
<tr><td><code id="taildep_+3A_u">u</code></td>
<td>
<p>vector of percentiles between 0 and 1</p>
</td></tr>
<tr><td><code id="taildep_+3A_nq">nq</code></td>
<td>
<p>number of quantiles of the structural variable at which to form a grid; only used if <code>u = NULL</code>.</p>
</td></tr>
<tr><td><code id="taildep_+3A_qlim">qlim</code></td>
<td>
<p>limits for the sequence <code>u</code> of the structural variable</p>
</td></tr>
<tr><td><code id="taildep_+3A_depmeas">depmeas</code></td>
<td>
<p>dependence measure, either of <code>"eta"</code> or <code>"chi"</code></p>
</td></tr>
<tr><td><code id="taildep_+3A_method">method</code></td>
<td>
<p>named list giving the estimation method for <code>eta</code> and <code>chi</code>. Default to <code>"emp"</code> for both.</p>
</td></tr>
<tr><td><code id="taildep_+3A_confint">confint</code></td>
<td>
<p>string indicating the type of confidence interval for <code class="reqn">\eta</code>, one of <code>"wald"</code> or <code>"lrt"</code></p>
</td></tr>
<tr><td><code id="taildep_+3A_level">level</code></td>
<td>
<p>the confidence level required (default to 0.95).</p>
</td></tr>
<tr><td><code id="taildep_+3A_trunc">trunc</code></td>
<td>
<p>logical indicating whether the estimates and confidence intervals should be truncated in <code class="reqn">[0,1]</code></p>
</td></tr>
<tr><td><code id="taildep_+3A_empirical.transformation">empirical.transformation</code></td>
<td>
<p>logical indicating whether observations should be transformed to pseudo-uniform scale (default to <code>TRUE</code>); otherwise, they are assumed to be uniform</p>
</td></tr>
<tr><td><code id="taildep_+3A_ties.method">ties.method</code></td>
<td>
<p>string indicating the type of method for <code>rank</code>; see <code><a href="base.html#topic+rank">rank</a></code> for a list of options. Default to <code>"random"</code></p>
</td></tr>
<tr><td><code id="taildep_+3A_plot">plot</code></td>
<td>
<p>logical; should graphs be plotted?</p>
</td></tr>
<tr><td><code id="taildep_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>plot</code>; current support for <code>main</code>, <code>xlab</code>, <code>ylab</code>, <code>add</code> and further <code>pch</code>, <code>lty</code>, <code>type</code>, <code>col</code> for points; additional arguments for confidence intervals are handled via <code>cipch</code>, <code>cilty</code>, <code>citype</code>, <code>cicol</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The most common approach for estimation is the empirical survival copula, by evaluating the proportion of sample minima with uniform margins that exceed a given <code class="reqn">x</code>. An alternative estimator uses a smoothed estimator of the survival copula using Bernstein polynomial, resulting in the so-called <code>betacop</code> estimator. Approximate pointwise confidence confint for the latter are obtained by assuming the proportion of points is binomial.
</p>
<p>The coefficient of tail correlation <code class="reqn">\chi</code> is
</p>
<p style="text-align: center;"><code class="reqn">\chi = \lim_{u \to 1} \frac{\Pr(F_1(X_1)&gt;u, \ldots, F_D(X_D)&gt;u)}{1-u}.</code>
</p>

<p>Asymptotically independent vectors have <code class="reqn">\chi = 0</code>. The estimator uses an estimator of the survival copula
</p>


<h3>Value</h3>

<p>a named list with elements
</p>

<ul>
<li> <p><code>u</code>: a <code>K</code> vector of percentile levels
</p>
</li>
<li> <p><code>eta</code>: a <code>K</code> by 3 matrix with point estimates, lower and upper confidence intervals
</p>
</li>
<li> <p><code>chi</code>: a <code>K</code> by 3 matrix with point estimates, lower and upper confidence intervals
</p>
</li></ul>



<h3>Note</h3>

<p>As of version 1.15, the percentiles used are from the minimum variable. This ensures that, regardless of the number of variables,
there is no error message returned because the quantile levels are too low for there to be observations
</p>


<h3>See Also</h3>

<p><code><a href="evd.html#topic+chiplot">chiplot</a></code> for bivariate empirical estimates of <code class="reqn">\chi</code> and <code class="reqn">\bar{\chi}</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(765)
# Max-stable model
dat &lt;- rmev(n = 1000, d = 4, param = 0.7, model = "log")
taildep(dat, confint = 'wald')

## End(Not run)
</code></pre>

<hr>
<h2 id='tem.corr'>Bridging the singularity for higher order asymptotics</h2><span id='topic+tem.corr'></span>

<h3>Description</h3>

<p>The correction factor <code class="reqn">\log(q/r)/r</code> for the
likelihood root is unbounded in the vincinity of
the maximum likelihood estimator. The thesis of
Rongcai Li (University of Toronto, 2001)
explores different ways of bridging this
singularity, notably using asymptotic expansions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tem.corr(fr, print.warning = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tem.corr_+3A_fr">fr</code></td>
<td>
<p>an object of class <code>fr</code></p>
</td></tr>
<tr><td><code id="tem.corr_+3A_print.warning">print.warning</code></td>
<td>
<p>logical; should warning message be printed? Default to <code>FALSE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The poor man's method used here consists in
fitting a robust regression to <code class="reqn">1/q-1/r</code>
as a function of <code class="reqn">r</code> and using predictions
from the model to solve for <code class="reqn">q</code>. This
approach is seemingly superior to that
previously used in <a href="#topic+spline.corr">spline.corr</a>.
</p>


<h3>Value</h3>

<p>an object of class <code>fr</code>, containing as additional arguments <code>spline</code> and a modified <code>rstar</code> argument.
</p>

<hr>
<h2 id='tstab.gpd'>Parameter stability plots for peaks-over-threshold</h2><span id='topic+tstab.gpd'></span>

<h3>Description</h3>

<p>This function computes the maximum likelihood estimate
at each provided threshold and plots the estimates (pointwise),
along with 95
or else from 1000 independent draws from the posterior distribution under
vague independent normal prior on the log-scale and shape.
The latter two methods better reflect the asymmetry of the estimates than the Wald confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tstab.gpd(
  xdat,
  thresh,
  method = c("wald", "profile", "post"),
  level = 0.95,
  plot = TRUE,
  which = c("scale", "shape"),
  changepar = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tstab.gpd_+3A_xdat">xdat</code></td>
<td>
<p>a vector of observations</p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_thresh">thresh</code></td>
<td>
<p>a vector of candidate thresholds at which to compute the estimates.</p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_method">method</code></td>
<td>
<p>string indicating the method for computing confidence or credible intervals.
Must be one of <code>"wald"</code>, <code>"profile"</code> or <code>"post"</code>.</p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_level">level</code></td>
<td>
<p>confidence level of the intervals. Default to 0.95.</p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_plot">plot</code></td>
<td>
<p>logical; should parameter stability plots be displayed? Default to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_which">which</code></td>
<td>
<p>character vector with elements <code>scale</code> or <code>shape</code></p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_changepar">changepar</code></td>
<td>
<p>logical; if <code>TRUE</code>, changes the graphical parameters.</p>
</td></tr>
<tr><td><code id="tstab.gpd_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with components
</p>

<ul>
<li><p><code>threshold</code>: vector of numerical threshold values.
</p>
</li>
<li><p><code>mle</code>: matrix of modified scale and shape maximum likelihood estimates.
</p>
</li>
<li><p><code>lower</code>: matrix of lower bounds for the confidence or credible intervals.
</p>
</li>
<li><p><code>upper</code>: matrix of lower bounds for the confidence or credible intervals.
</p>
</li>
<li><p><code>method</code>: method for the confidence or coverage intervals.
</p>
</li></ul>

<p>plots of the modified scale and shape parameters, with pointwise confidence/credible intervals
and an invisible data frame containing the threshold <code>thresh</code> and the modified scale and shape parameters.
</p>


<h3>Note</h3>

<p>The function is hard coded to prevent fitting a generalized Pareto distribution to samples of size less than 10. If the estimated shape parameters are all on the boundary of the parameter space (meaning <code class="reqn">\hat{\xi}=-1</code>), then the plots return one-sided confidence intervals for both the modified scale and shape parameters: these typically suggest that the chosen thresholds are too high for estimation to be reliable.
</p>


<h3>Author(s)</h3>

<p>Leo Belzile
</p>


<h3>See Also</h3>

<p><code><a href="ismev.html#topic+gpd.fitrange">gpd.fitrange</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- abs(rnorm(10000))
u &lt;- qnorm(seq(0.9,0.99, by= 0.01))
par(mfrow = c(1,2))
tstab.gpd(xdat = dat, thresh = u, changepar = FALSE)
## Not run: 
tstab.gpd(xdat = dat, thresh = u, method = "profile")
tstab.gpd(xdat = dat, thresh = u, method = "post")

## End(Not run)
</code></pre>

<hr>
<h2 id='venice'>Venice Sea Levels</h2><span id='topic+venice'></span>

<h3>Description</h3>

<p>The <code>venice</code> data contains the 10 largest yearly sea levels (in cm)
from 1887 until 2019. Only the yearly maximum is available for 1922
and the six largest observations for 1936.
</p>


<h3>Format</h3>

<p>a data frame with 133 rows and 11 columns containing the year of the measurement (first column)
and ordered 10-largest yearly observations, reported in decreasing order from largest (<code>r1</code>) to smallest (<code>r10</code>).
</p>


<h3>Note</h3>

<p>Smith (1986) notes that the annual maxima seems to fluctuate around a constant sea level
up to 1930 or so, after which there is potential linear trend. Records of threshold exceedances above
80 cm (reported on the website) indicate that observations are temporally clustered.
</p>
<p>The observations from 1931 until 1981 can be found in
Table 1 in Smith (1986), who reported data from Pirazzoli (1982).
The values from 1983 until 2019 were extracted by Anthony Davison from the City
of Venice website (accessed in May 2020) and are licensed under the CC BY-NC-SA 3.0 license.
The Venice City website indicates
that later measurements were recorded by an instrument located in Punta Salute.
</p>


<h3>Source</h3>

<p>City of Venice, Historical archive &lt;https://www.comune.venezia.it/node/6214&gt;. Last accessed November 5th, 2020.
</p>


<h3>References</h3>

<p>Smith, R. L. (1986) Extreme value theory based on the <em>r</em>
largest annual events. <em>Journal of Hydrology</em> <b>86</b>, 2743.
</p>
<p>Pirazzoli, P., 1982. Maree estreme a Venezia (periodo 1872-1981). <em>Acqua Aria</em> <b>10</b>, 1023-1039.
</p>
<p>Coles, S. G. (2001) <em>An Introduction to Statistical Modelling of Extreme Values</em>. London: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="ismev.html#topic+venice">venice</a></code>
</p>

<hr>
<h2 id='vmetric.diag'>Metric-based threshold selection</h2><span id='topic+vmetric.diag'></span>

<h3>Description</h3>

<p>Adaptation of Varty et al.'s metric-based threshold
automated diagnostic for the  independent and identically distributed case with no rounding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vmetric.diag(
  xdat,
  thresh,
  B = 199L,
  type = c("qq", "pp"),
  dist = c("l1", "l2"),
  neval = 1000L,
  ci = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vmetric.diag_+3A_xdat">xdat</code></td>
<td>
<p>vector of observations</p>
</td></tr>
<tr><td><code id="vmetric.diag_+3A_thresh">thresh</code></td>
<td>
<p>vector of thresholds</p>
</td></tr>
<tr><td><code id="vmetric.diag_+3A_b">B</code></td>
<td>
<p>number of bootstrap replications</p>
</td></tr>
<tr><td><code id="vmetric.diag_+3A_type">type</code></td>
<td>
<p>string indicating scale, either <code>qq</code> for exponential quantile-quantile plot or <code>pp</code> for probability-probability plot (uniform)</p>
</td></tr>
<tr><td><code id="vmetric.diag_+3A_dist">dist</code></td>
<td>
<p>string indicating norm, either <code>l1</code> for absolute error or <code>l2</code> for quadratic error</p>
</td></tr>
<tr><td><code id="vmetric.diag_+3A_neval">neval</code></td>
<td>
<p>number of points at which to estimate the metric. Default to 1000L</p>
</td></tr>
<tr><td><code id="vmetric.diag_+3A_ci">ci</code></td>
<td>
<p>level of symmetric confidence interval. Default to 0.95</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm proceeds by first computing the maximum
likelihood algorithm and then simulating datasets from
replication with parameters drawn from a bivariate normal
approximation to the maximum likelihood estimator distribution.
</p>
<p>For each bootstrap sample, we refit the
model and convert the quantiles to
exponential or uniform variates.
The mean absolute or mean squared distance
is calculated on these. The threshold
returned is the one with the lowest value
of the metric.
</p>


<h3>Value</h3>

<p>an invisible list with components
</p>

<ul>
<li> <p><code>thresh</code>: scalar threshold minimizing criterion
</p>
</li>
<li> <p><code>cthresh</code>: vector of candidate thresholds
</p>
</li>
<li> <p><code>metric</code>: value of the metric criterion evaluated at each threshold
</p>
</li>
<li> <p><code>type</code>: argument <code>type</code>
</p>
</li>
<li> <p><code>dist</code>: argument <code>dist</code>
</p>
</li></ul>



<h3>References</h3>

<p>Varty, Z. and J.A. Tawn and P.M. Atkinson and S. Bierman (2021+), Inference for extreme earthquake magnitudes accounting for a time-varying measurement process
</p>

<hr>
<h2 id='W.diag'>Wadsworth's univariate and bivariate exponential threshold diagnostics</h2><span id='topic+W.diag'></span>

<h3>Description</h3>

<p>Function to produce diagnostic plots and test statistics for the
threshold diagnostics exploiting structure of maximum likelihood estimators
based on the non-homogeneous Poisson process likelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>W.diag(
  xdat,
  model = c("nhpp", "exp", "invexp"),
  u = NULL,
  k,
  q1 = 0,
  q2 = 1,
  par = NULL,
  M = NULL,
  nbs = 1000,
  alpha = 0.05,
  plots = c("LRT", "WN", "PS"),
  UseQuantiles = FALSE,
  changepar = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="W.diag_+3A_xdat">xdat</code></td>
<td>
<p>a numeric vector of data to be fitted.</p>
</td></tr>
<tr><td><code id="W.diag_+3A_model">model</code></td>
<td>
<p>string specifying whether the univariate or bivariate diagnostic should be used. Either <code>nhpp</code>
for the univariate model, <code>exp</code> (<code>invexp</code>) for the bivariate exponential model with rate (inverse rate) parametrization. See details.</p>
</td></tr>
<tr><td><code id="W.diag_+3A_u">u</code></td>
<td>
<p>optional; vector of candidate thresholds.</p>
</td></tr>
<tr><td><code id="W.diag_+3A_k">k</code></td>
<td>
<p>number of thresholds to consider (if <code>u</code> unspecified).</p>
</td></tr>
<tr><td><code id="W.diag_+3A_q1">q1</code></td>
<td>
<p>lowest quantile for the threshold sequence.</p>
</td></tr>
<tr><td><code id="W.diag_+3A_q2">q2</code></td>
<td>
<p>upper quantile limit for the threshold sequence (<code>q2</code> itself is not used as a threshold,
but rather the uppermost threshold will be at the <code class="reqn">(q_2-1/k): q2-1/k</code> quantile).</p>
</td></tr>
<tr><td><code id="W.diag_+3A_par">par</code></td>
<td>
<p>parameters of the NHPP likelihood. If <code>missing</code>, the <code><a href="#topic+fit.pp">fit.pp</a></code> routine will be run to obtain values</p>
</td></tr>
<tr><td><code id="W.diag_+3A_m">M</code></td>
<td>
<p>number of superpositions or 'blocks' / 'years' the process corresponds to (can affect the optimization)</p>
</td></tr>
<tr><td><code id="W.diag_+3A_nbs">nbs</code></td>
<td>
<p>number of simulations used to assess the null distribution of the LRT, and produce the p-value</p>
</td></tr>
<tr><td><code id="W.diag_+3A_alpha">alpha</code></td>
<td>
<p>significance level of the LRT</p>
</td></tr>
<tr><td><code id="W.diag_+3A_plots">plots</code></td>
<td>
<p>vector of strings indicating which plots to produce; <code>LRT</code>= likelihood ratio test, <code>WN</code> = white noise, <code>PS</code> = parameter stability. Use <code>NULL</code> if you do not want plots to be produced</p>
</td></tr>
<tr><td><code id="W.diag_+3A_usequantiles">UseQuantiles</code></td>
<td>
<p>logical; use quantiles as the thresholds in the plot?</p>
</td></tr>
<tr><td><code id="W.diag_+3A_changepar">changepar</code></td>
<td>
<p>logical; if <code>TRUE</code>, the graphical parameters (via a call to <code>par</code>) are modified.</p>
</td></tr>
<tr><td><code id="W.diag_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code>plot</code>, overriding defaults including</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is a wrapper for the univariate (non-homogeneous Poisson process model) and bivariate exponential dependence model.
For the latter, the user can select either the rate or inverse rate parameter  (the inverse rate parametrization  works better for uniformity
of the p-value distribution under the <code>LR</code> test.
</p>
<p>There are two options for the bivariate diagnostic: either provide pairwise minimum of marginally
exponentially distributed margins or provide a <code>n</code> times 2 matrix with the original data, which
is transformed to exponential margins using the empirical distribution function.
</p>


<h3>Value</h3>

<p>plots of the requested diagnostics and an invisible list with components
</p>

<ul>
<li> <p><code>MLE</code>: maximum likelihood estimates from all thresholds
</p>
</li>
<li> <p><code>Cov</code>: joint asymptotic covariance matrix for <code class="reqn">\xi</code>, <code class="reqn">\eta</code> or <code class="reqn">1/\eta</code>.
</p>
</li>
<li> <p><code>WN</code>: values of the white noise process
</p>
</li>
<li> <p><code>LRT</code>: values of the likelihood ratio test statistic vs threshold
</p>
</li>
<li> <p><code>pval</code>: <em>P</em>-value of the likelihood ratio test
</p>
</li>
<li> <p><code>k</code>: final number of thresholds used
</p>
</li>
<li> <p><code>thresh</code>: threshold selected by the likelihood ratio procedure
</p>
</li>
<li> <p><code>qthresh</code>: quantile level of threshold selected by the likelihood ratio procedure
</p>
</li>
<li> <p><code>cthresh</code>: vector of candidate thresholds
</p>
</li>
<li> <p><code>qcthresh</code>: quantile level of candidate thresholds
</p>
</li>
<li> <p><code>mle.u</code>: maximum likelihood estimates for the selected threshold
</p>
</li>
<li> <p><code>model</code>: model fitted
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Jennifer L. Wadsworth
</p>


<h3>References</h3>

<p>Wadsworth, J.L. (2016). Exploiting Structure of Maximum Likelihood Estimators for Extreme Value Threshold Selection, <em>Technometrics</em>, <b>58</b>(1), 116-126, <code>http://dx.doi.org/10.1080/00401706.2014.998345</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(123)
# Parameter stability only
W.diag(xdat = abs(rnorm(5000)), model = 'nhpp',
       k = 30, q1 = 0, plots = "PS")
W.diag(rexp(1000), model = 'nhpp', k = 20, q1 = 0)
xbvn &lt;- mvrnorm(n = 6000,
                mu = rep(0, 2),
                Sigma = cbind(c(1, 0.7), c(0.7, 1)))
# Transform margins to exponential manually
xbvn.exp &lt;- -log(1 - pnorm(xbvn))
#rate parametrization
W.diag(xdat = apply(xbvn.exp, 1, min), model = 'exp',
       k = 30, q1 = 0)
W.diag(xdat = xbvn, model = 'exp', k = 30, q1 = 0)
#inverse rate parametrization
W.diag(xdat = apply(xbvn.exp, 1, min), model = 'invexp',
       k = 30, q1 = 0)

## End(Not run)
</code></pre>

<hr>
<h2 id='w1500m'>Best 200 times of Women 1500m Track</h2><span id='topic+w1500m'></span>

<h3>Description</h3>

<p>200 all-time best performance (in seconds) of women 1500-meter run.
</p>


<h3>Format</h3>

<p>a vector of size 200
</p>


<h3>Source</h3>

<p>&lt;http://www.alltime-athletics.com/w_1500ok.htm&gt;, accessed 14.08.2018
</p>

<hr>
<h2 id='xasym'>Coefficient of extremal asymmetry</h2><span id='topic+xasym'></span>

<h3>Description</h3>

<p>This function implements estimators of the bivariate
coefficient of extremal asymmetry proposed in
Semadeni's (2021) PhD thesis.
Two estimators are implemented: one based on empirical distributions, the second using empirical likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xasym(
  data,
  u = NULL,
  nq = 40,
  qlim = c(0.8, 0.99),
  method = c("empirical", "emplik"),
  confint = c("none", "wald", "bootstrap"),
  level = 0.95,
  B = 999L,
  ties.method = "random",
  plot = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="xasym_+3A_data">data</code></td>
<td>
<p>an <code>n</code> by 2 matrix of observations</p>
</td></tr>
<tr><td><code id="xasym_+3A_u">u</code></td>
<td>
<p>vector of probability levels at which to evaluate extremal asymmetry</p>
</td></tr>
<tr><td><code id="xasym_+3A_nq">nq</code></td>
<td>
<p>integer; number of quantiles at which to evaluate the coefficient if <code>u</code> is <code>NULL</code></p>
</td></tr>
<tr><td><code id="xasym_+3A_qlim">qlim</code></td>
<td>
<p>a vector of length 2 with the probability limits for the quantiles</p>
</td></tr>
<tr><td><code id="xasym_+3A_method">method</code></td>
<td>
<p>string indicating the estimation method, one of <code>empirical</code> or empirical likelihood (<code>emplik</code>)</p>
</td></tr>
<tr><td><code id="xasym_+3A_confint">confint</code></td>
<td>
<p>string for the method used to derive confidence intervals, either <code>none</code> (default) or a nonparametric <code>bootstrap</code></p>
</td></tr>
<tr><td><code id="xasym_+3A_level">level</code></td>
<td>
<p>probability level for confidence intervals, default to 0.95 or bounds for the interval</p>
</td></tr>
<tr><td><code id="xasym_+3A_b">B</code></td>
<td>
<p>integer; number of bootstrap replicates (if applicable)</p>
</td></tr>
<tr><td><code id="xasym_+3A_ties.method">ties.method</code></td>
<td>
<p>string; method for handling ties. See the documentation of <a href="base.html#topic+rank">rank</a> for available options.</p>
</td></tr>
<tr><td><code id="xasym_+3A_plot">plot</code></td>
<td>
<p>logical; if <code>TRUE</code>, return a plot.</p>
</td></tr>
<tr><td><code id="xasym_+3A_...">...</code></td>
<td>
<p>additional parameters for plots</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code>U</code>, <code>V</code> be uniform random variables and define the partial extremal dependence coefficients
<code class="reqn">\varphi_{+}(u) = \Pr(V &gt; U | U &gt; u, V &gt; u)</code>,
<code class="reqn">\varphi_{-}(u) = \Pr(V &lt; U | U &gt; u, V &gt; u)</code> and
<code class="reqn">\varphi_0(u) = \Pr(V = U | U &gt; u, V &gt; u)</code>
Define
</p>
<p style="text-align: center;"><code class="reqn"> \varphi(u) = \frac{\varphi_{+} - \varphi_{-}}{\varphi_{+} + \varphi_{-}}</code>
</p>

<p>The empirical likelihood estimator, derived for max-stable vectors with unit Frechet margins, is
</p>
<p style="text-align: center;"><code class="reqn">\frac{\sum_i p_i I(w_i \leq 0.5) - 0.5}{0.5 - 2\sum_i p_i(0.5-w_i) I(w_i \leq 0.5)}</code>
</p>

<p>where <code class="reqn">p_i</code> is the empirical likelihood weight for observation <code class="reqn">i</code> and <code class="reqn">w_i</code> is the pseudo-angle associated to the first coordinate.
</p>


<h3>Value</h3>

<p>an invisible data frame with columns
</p>

<dl>
<dt><code>threshold</code></dt><dd><p>vector of thresholds on the probability scale</p>
</dd>
<dt><code>coef</code></dt><dd><p>extremal asymmetry coefficient estimates</p>
</dd>
<dt><code>confint</code></dt><dd><p>either <code>NULL</code> or a matrix with two columns containing the lower and upper bounds for each threshold</p>
</dd>
</dl>



<h3>References</h3>

<p>Semadeni, C. (2020). Inference on the Angular Distribution of Extremes, PhD thesis, EPFL, no. 8168.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
samp &lt;- rmev(n = 1000,
             d = 2,
             param = 0.2,
             model = "log")
xasym(samp, confint = "wald")
xasym(samp, method = "emplik")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
