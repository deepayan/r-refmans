<!DOCTYPE html><html><head><title>Help for package sentiment.ai</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sentiment.ai}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sentiment.ai-package'><p>sentiment.ai: Simple Sentiment Analysis Using Deep Learning</p></a></li>
<li><a href='#airline_tweets'><p>Airline Tweet Data</p></a></li>
<li><a href='#as_py_list'><p>as py list</p>
because R to Python conversion doesn't work with list is of length 1</a></li>
<li><a href='#default'><p>Default sentiment matching dictionary</p></a></li>
<li><a href='#embed_text'><p>Create Text Embedding Matrix</p></a></li>
<li><a href='#get_default_embedding'><p>get default embedding</p>
If it exists, return the object.
If not, try downloading it.
If download works, return object.
Else return <code>NULL</code> (to be handles in <code>embed_topics()</code>).</a></li>
<li><a href='#install_default_embeddings'><p>Function to grab the default embeddings for <code>sentiment_match()</code></p>
Necessary to keep package size under 5Mb.
Will check if they're there, if so return TRUE.
If they are not there, try download and return TRUE.
Otherwise, return FALSE (and generate them - will take a few seconds!).</a></li>
<li><a href='#install_scoring_model'><p>Install a Scoring Model</p></a></li>
<li><a href='#install_sentiment.ai'><p>setup</p></a></li>
<li><a href='#matrix_similarity'><p>Cosine Similarity</p></a></li>
<li><a href='#read_embedding'><p>Read embedding file.</p>
Take json path, return single embedding object for specific model.</a></li>
<li><a href='#sentiment_match'><p>Sentiment Matching</p></a></li>
<li><a href='#sentiment_score'><p>Simple Sentiment Scores</p></a></li>
<li><a href='#sentiment.env'><p>Sentiment AI Embedding Environment</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Simple Sentiment Analysis Using Deep Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ben Wiseman &lt;benjamin.h.wiseman@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Sentiment Analysis via deep learning and gradient boosting models with a lot of the underlying hassle taken care of to make the process as simple as possible. 
  In addition to out-performing traditional, lexicon-based sentiment analysis (see <a href="https://benwiseman.github.io/sentiment.ai/#Benchmarks">https://benwiseman.github.io/sentiment.ai/#Benchmarks</a>),
  it also allows the user to create embedding vectors for text which can be used in other analyses.
  GPU acceleration is supported on Windows and Linux.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://benwiseman.github.io/sentiment.ai/">https://benwiseman.github.io/sentiment.ai/</a>,
<a href="https://github.com/BenWiseman/sentiment.ai">https://github.com/BenWiseman/sentiment.ai</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>data.table (&ge; 1.12.8), jsonlite, reticulate (&ge; 1.16),
roperators (&ge; 1.2.0), stats, tensorflow (&ge; 2.2.0), tfhub (&ge;
0.8.0), utils, xgboost</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, magrittr, microbenchmark, prettydoc,
rappdirs, rstudioapi, text2vec (&ge; 0.6)</td>
</tr>
<tr>
<td>Collate:</td>
<td>'package-sentiment_ai.R' 'init_and_install.R' 'sentiment.R'
'choose_model.R' 'data-default_data.R' 'data-example_data.R'
'object-sentiment_env.R' 'matrix_helpers.R' 'constants.R'
'create_error_text.R' 'utils-data-table.R' 'globals.R'
'local_from_reticulate.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-03-18 19:01:00 UTC; benaparte</td>
</tr>
<tr>
<td>Author:</td>
<td>Ben Wiseman [cre, aut, ccp],
  Steven Nydick <a href="https://orcid.org/0000-0002-2908-1188"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Tristan Wisner [aut],
  Fiona Lodge [ctb],
  Yu-Ann Wang [ctb],
  Veronica Ge [art],
  Korn Ferry Institute [fnd]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-03-19 00:00:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='sentiment.ai-package'>sentiment.ai: Simple Sentiment Analysis Using Deep Learning</h2><span id='topic+sentiment.ai'></span><span id='topic+sentiment.ai-package'></span>

<h3>Description</h3>

<p>This package uses Google's Universal Sentence Encoder, simplifies all the
difficulties, and turns it into a sentiment analysis package.
</p>
<p>Main Benefits:
</p>

<ul>
<li><p>Tolerates spelling mitsakes
</p>
</li>
<li><p>Not dependent on exactly matching a fixed dictionary
</p>
</li>
<li><p>Requires less pre-processing
</p>
</li>
<li><p>More powerful than dictionary-based methods
</p>
</li></ul>

<p>Main Drawbacks:
</p>

<ul>
<li><p>Requires a lot of RAM
</p>
</li>
<li><p>Can be slow on larger datasets (unless using GPU)
</p>
</li></ul>

<p>Effectively, if you have a reasonably powerful computer, you can use
sentiment.ai as a more flexible, powerful, and modern approach to sentiment
analysis.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Ben Wiseman <a href="mailto:benjamin.h.wiseman@gmail.com">benjamin.h.wiseman@gmail.com</a> [conceptor]
</p>
<p>Authors:
</p>

<ul>
<li><p> Steven Nydick <a href="mailto:swnydick@gmail.com">swnydick@gmail.com</a> (<a href="https://orcid.org/0000-0002-2908-1188">ORCID</a>)
</p>
</li>
<li><p> Tristan Wisner <a href="mailto:tristan.wisner@kornferry.com">tristan.wisner@kornferry.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Fiona Lodge <a href="mailto:fiona.lodge@kornferry.com">fiona.lodge@kornferry.com</a> [contributor]
</p>
</li>
<li><p> Yu-Ann Wang <a href="mailto:yu-ann-wang@kornferry.com">yu-ann-wang@kornferry.com</a> [contributor]
</p>
</li>
<li><p> Veronica Ge <a href="mailto:veronica.ge@kornferry.com">veronica.ge@kornferry.com</a> [artist]
</p>
</li>
<li><p> Korn Ferry Institute <a href="mailto:KFInstituteRequests@KornFerry.com">KFInstituteRequests@KornFerry.com</a> [funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://benwiseman.github.io/sentiment.ai/">https://benwiseman.github.io/sentiment.ai/</a>
</p>
</li>
<li> <p><a href="https://github.com/BenWiseman/sentiment.ai">https://github.com/BenWiseman/sentiment.ai</a>
</p>
</li></ul>


<hr>
<h2 id='airline_tweets'>Airline Tweet Data</h2><span id='topic+airline_tweets'></span>

<h3>Description</h3>

<p>This is a basic data that can be used to test out the installation and make
sure that the model is running correctly. The current data is based on airline
tweets with corresponding sentiment labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(airline_tweets)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.table</code> with the &quot;text&quot; column required for
text processing and the &quot;sentiment&quot; column for checking positive
or negative predictions of the model.
</p>

<hr>
<h2 id='as_py_list'>as py list
because R to Python conversion doesn't work with list is of length 1</h2><span id='topic+as_py_list'></span>

<h3>Description</h3>

<p>as py list
because R to Python conversion doesn't work with list is of length 1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_py_list(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_py_list_+3A_x">x</code></td>
<td>
<p>character vector that is to be passed into tensorflowtext via reticulate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List if x is length 1 else x.
</p>

<hr>
<h2 id='default'>Default sentiment matching dictionary</h2><span id='topic+default'></span>

<h3>Description</h3>

<p>This is a default sentiment matching dictionary with over 100 pairs of
positive:negative examples. Feel free to use as-is or use as an example to
create your own. The main point is that there needs to be a corresponding
negative for each positive.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(default)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>"data.table"</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For Example
pos &lt;- c("good apples", "fresh", "delicious")
neg &lt;- c("bad apples", "not fresh", "not delicious")

# If positive was:
c("good", "fresh", "delicious")

# Then "These were some good apples" would be seen as closer to a negative example!

</code></pre>

<hr>
<h2 id='embed_text'>Create Text Embedding Matrix</h2><span id='topic+embed_text'></span>

<h3>Description</h3>

<p>turns character vector into <code style="white-space: pre;">&#8288;length(text) x 512&#8288;</code> embedding matrix.
For power users. Requires <code>init_sentiment.ai()</code> to have been called!
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embed_text(text, batch_size = NULL, model = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="embed_text_+3A_text">text</code></td>
<td>
<p>character vector to be embedded. Note that longer comments take longer.</p>
</td></tr>
<tr><td><code id="embed_text_+3A_batch_size">batch_size</code></td>
<td>
<p>integer - how many to embed at once. Higher numbers are faster but use more memory.</p>
</td></tr>
<tr><td><code id="embed_text_+3A_model">model</code></td>
<td>
<p>character - the embedding model to use (same as <code>sentiment_score()</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric matrix of <code style="white-space: pre;">&#8288;length(text) x 512&#8288;</code>. Original text is stored in the row names attribute.
</p>

<hr>
<h2 id='get_default_embedding'>get default embedding
If it exists, return the object.
If not, try downloading it.
If download works, return object.
Else return <code>NULL</code> (to be handles in <code>embed_topics()</code>).</h2><span id='topic+get_default_embedding'></span>

<h3>Description</h3>

<p>get default embedding
If it exists, return the object.
If not, try downloading it.
If download works, return object.
Else return <code>NULL</code> (to be handles in <code>embed_topics()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_default_embedding(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_default_embedding_+3A_model">model</code></td>
<td>
<p>character - whic model's default embeddings are needed</p>
</td></tr>
</table>

<hr>
<h2 id='install_default_embeddings'>Function to grab the default embeddings for <code>sentiment_match()</code>
Necessary to keep package size under 5Mb.
Will check if they're there, if so return TRUE.
If they are not there, try download and return TRUE.
Otherwise, return FALSE (and generate them - will take a few seconds!).</h2><span id='topic+install_default_embeddings'></span>

<h3>Description</h3>

<p>Function to grab the default embeddings for <code>sentiment_match()</code>
Necessary to keep package size under 5Mb.
Will check if they're there, if so return TRUE.
If they are not there, try download and return TRUE.
Otherwise, return FALSE (and generate them - will take a few seconds!).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_default_embeddings()
</code></pre>

<hr>
<h2 id='install_scoring_model'>Install a Scoring Model</h2><span id='topic+install_scoring_model'></span>

<h3>Description</h3>

<p>Install a Scoring Model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_scoring_model(
  model = c("en.large", "en", "multi.large", "multi"),
  scoring = c("xgb", "glm"),
  scoring_version = "1.0",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_scoring_model_+3A_model">model</code></td>
<td>
<p>The embedding model, one of c(&quot;en.large&quot;, &quot;en&quot;, &quot;multi.large&quot;,
&quot;multi&quot;).</p>
</td></tr>
<tr><td><code id="install_scoring_model_+3A_scoring">scoring</code></td>
<td>
<p>The scoring model, currently one of:
</p>

<ul>
<li><p> &quot;xgb&quot; does default xgboost
</p>
</li>
<li><p> &quot;glm&quot; does generalized linear model (if you can't run xgboost)
</p>
</li></ul>
</td></tr>
<tr><td><code id="install_scoring_model_+3A_scoring_version">scoring_version</code></td>
<td>
<p>Version of scoring model (will add more over time)</p>
</td></tr>
<tr><td><code id="install_scoring_model_+3A_...">...</code></td>
<td>
<p>Additional options to the function, including:
</p>

<ul>
<li><p> repo_url: OPTIONAL custom github repo blob url for external scoring models.
The default repo_url is &quot;https://github.com/BenWiseman/sentiment.ai/blob/main/models&quot;
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This downloads the scoring models from a set repository in order to keep the
main package within CRAN size limits.
</p>
<p>In the future, this will also make it possible for the community to add new
and improved models!
</p>


<h3>Value</h3>

<p>0 if model did not need to be downloaded.
1 if model needed to be downloaded.
</p>

<hr>
<h2 id='install_sentiment.ai'>setup</h2><span id='topic+install_sentiment.ai'></span><span id='topic+init_sentiment.ai'></span><span id='topic+check_sentiment.ai'></span>

<h3>Description</h3>

<p>Install and Setup sentiment.ai package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_sentiment.ai(
  envname = "r-sentiment-ai",
  method = c("auto", "virtualenv", "conda"),
  gpu = FALSE,
  python_version = "3.8.10",
  modules = list(numpy = "1.19.5", sentencepiece = "0.1.95", tensorflow = "2.4.1",
    tensorflow_hub = "0.12.0", `tensorflow-text` = "2.4.3"),
  fresh_install = TRUE,
  restart_session = TRUE,
  ...
)

init_sentiment.ai(
  model = c("en.large", "multi.large", "en", "multi"),
  envname = "r-sentiment-ai",
  method = c("auto", "virtualenv", "conda"),
  silent = FALSE
)

check_sentiment.ai(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_sentiment.ai_+3A_envname">envname</code></td>
<td>
<p>The name, or full path, of the environment in which Python
packages are to be installed. When <code>NULL</code> (the default), the active
environment as set by the <code>RETICULATE_PYTHON_ENV</code> variable will be used;
if that is unset, then the <code>r-reticulate</code> environment will be used.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_method">method</code></td>
<td>
<p>Installation method. By default, &quot;auto&quot; automatically finds a
method that will work in the local environment. Change the default to
force a specific installation method. Note that the &quot;virtualenv&quot;
method may not available on Windows due to a tensorflow issue. Note
also that since this command runs without privilege the &quot;system&quot;
method is available only on Windows.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_gpu">gpu</code></td>
<td>
<p>Whether GPU should be enabled when installing TensorFlow</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_python_version">python_version</code></td>
<td>
<p>The requested Python version. Ignored when attempting
to install with a Python virtual environment.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_modules">modules</code></td>
<td>
<p>A list of modules needed for installing tensorflow. See
details for more information. Only change this argument if you know
what you are doing!</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_fresh_install">fresh_install</code></td>
<td>
<p>Whether to create the Python environment prior to
installing the modules or to install everything in an existing
environment (if one exists). Only change this argument if you know what
you are doing! If the environment does not already exist, will create
the environment first.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_restart_session">restart_session</code></td>
<td>
<p>Whether to restart the R session after finishing
installation. Only works on Rstudio.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="reticulate.html#topic+conda-tools">conda_install()</a></code>
or <code><a href="reticulate.html#topic+virtualenv-tools">virtualenv_install()</a></code>.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_model">model</code></td>
<td>
<p>path to tensorflow hub embedding model. default is both universal
sentence encoder en (default) and multi.</p>
</td></tr>
<tr><td><code id="install_sentiment.ai_+3A_silent">silent</code></td>
<td>
<p>logical - do you want to suppress console logging? Can't affect tensorflow/GPU/python/c++ output, unfortunately.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sets up environment specific for sentiment.ai. The packages that it currently
needs are as follows:</p>

<table>
<tr>
 <td style="text-align: left;">
   Module </td><td style="text-align: center;"> Version </td>
</tr>
<tr>
 <td style="text-align: left;">
   python </td><td style="text-align: center;"> 3.8.10 </td>
</tr>
<tr>
 <td style="text-align: left;">
   numpy </td><td style="text-align: center;"> 1.19.5 </td>
</tr>
<tr>
 <td style="text-align: left;">
   tensorflow </td><td style="text-align: center;"> 2.4.1 </td>
</tr>
<tr>
 <td style="text-align: left;">
   tensorflow_hub </td><td style="text-align: center;"> 0.12.0 </td>
</tr>
<tr>
 <td style="text-align: left;">
   tensorflow-text </td><td style="text-align: center;"> 2.4.3 </td>
</tr>
<tr>
 <td style="text-align: left;">
   sentencepiece </td><td style="text-align: center;"> 0.1.95 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>Please do not change these unless you know what you are doing.
</p>
<p>Note that it installs with like <code>tensorflow::install_tensorflow</code> and
<code>pip = TRUE</code>
</p>


<h3>Value</h3>

<p>NULL this function simply installs the required python dependencies and default scoring models and pre-calculated embedding vectors.
</p>
<p>python function to embed text can be returned, but is not necessary.
<code>embed_text()</code> does this for you.
</p>
<p>NULL this function checks if <code>init_sentiment.ai()</code> has been called
successfully, if not, it is called.
</p>


<h3>Note</h3>

<p>Setting environments with <code>reticulate</code> is notoriously difficult. If the
RETICULATE_PYTHON environment is set, then reticulate will not let you change
the Python binary used (or the Python environment) using <code>use_condaenv</code>
<strong>or</strong> <code>use_virtualenv</code>. This environment can be accidentally set in
the following ways:
</p>

<ol>
<li><p> If RETICULATE_PYTHON is in your .Renviron file or bash/zsh rc files. This is
the most obvious place that this environment will be set.
</p>
</li>
<li><p> Using Project Options or Global Options under &quot;Python&gt;Python Interpreter&quot;.
If this is set, then reticulate will almost always use this version of Python
and will not let you change.
</p>
</li>
<li><p> If you have already loaded reticulate and have run <code>py_config</code>. Once a Python
version/environment is instantiated, you will not be able to change it and
will have to restart R.
</p>
</li>
<li><p> If you are in <strong>any</strong> project, at all! Currently (as of <code>reticulate</code> version
1.22), every project automatically sets the RETICULATE_PYTHON environment
variable, either through the Global or Project Options or by using heuristics.
If you are in an RStudio project, you <strong>must</strong> update Global/Project Options
with the specific version/environment of Python that you want to use, or
you will not be able to change it!
</p>
</li></ol>

<p>Manually setting the environment variable to NULL (using
<code>Sys.unsetenv("RETICULATE_PYTHON")</code>, updating your Project/Global options going
Tools&gt;Project Options or Tools&gt;Global Options and then select Python in the
left menu bar and click the &quot;Select&quot; button to manually set the Python
interpreter, and/or restarting your R session <strong>might</strong> fix the problem.
</p>
<p>We know this is a pain, and we would like to fix this for you, but we are
dependent on the RStudio/reticulate team to update how they determine the
allowable Python versions/environments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
install_sentiment.ai(envname = "r-sentiment-ai",
                     method  = "conda",
                     python_version = "3.8.10")
init_sentiment.ai(model   = "en.large",
                  envname = "r-sentiment-ai")
check_sentiment.ai()

# if you run into an issue, follow the instructions/see the note and retry!

## End(Not run)
</code></pre>

<hr>
<h2 id='matrix_similarity'>Cosine Similarity</h2><span id='topic+matrix_similarity'></span><span id='topic+cosine'></span><span id='topic+cosine_match'></span>

<h3>Description</h3>

<p>Cosine Similarity
</p>
<p>cosine_match()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cosine(x, y = NULL)

cosine_match(target, reference, keep_target_order = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matrix_similarity_+3A_x">x</code></td>
<td>
<p>A numeric vector or matrix</p>
</td></tr>
<tr><td><code id="matrix_similarity_+3A_y">y</code></td>
<td>
<p>A numeric vector or matrix of the same dimensions as x</p>
</td></tr>
<tr><td><code id="matrix_similarity_+3A_target">target</code></td>
<td>
<p>numeric matrix of j values where each row is one observation. Use row names as ID.</p>
</td></tr>
<tr><td><code id="matrix_similarity_+3A_reference">reference</code></td>
<td>
<p>numeric matrix of j values where each row is one observation. Use row names as ID.</p>
</td></tr>
<tr><td><code id="matrix_similarity_+3A_keep_target_order">keep_target_order</code></td>
<td>
<p>logical include column indicating original row order of target matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.table containing ranked (1 = top) pairwise similarities between target and reference
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n &lt;- 5
y &lt;- matrix(rnorm(n * 512), ncol = 512)
x &lt;- matrix(rnorm(n * 512), ncol = 512)

all.equal(cosine(x, y),
          text2vec::sim2(x, y))

## End(Not run)

</code></pre>

<hr>
<h2 id='read_embedding'>Read embedding file.
Take json path, return single embedding object for specific model.</h2><span id='topic+read_embedding'></span>

<h3>Description</h3>

<p>Read embedding file.
Take json path, return single embedding object for specific model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_embedding(file, model = "en.large", version = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_embedding_+3A_file">file</code></td>
<td>
<p>character - the filepath to the json object.</p>
</td></tr>
<tr><td><code id="read_embedding_+3A_model">model</code></td>
<td>
<p>character - which model's default embeddings are needed.</p>
</td></tr>
<tr><td><code id="read_embedding_+3A_version">version</code></td>
<td>
<p>PLACEHOLDER - may be necessary in future.</p>
</td></tr>
</table>

<hr>
<h2 id='sentiment_match'>Sentiment Matching</h2><span id='topic+sentiment_match'></span>

<h3>Description</h3>

<p>Provides score and explanation, returns a single vector, and runs relatively
fast.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment_match(
  x = NULL,
  phrases = NULL,
  model = names(default_models),
  batch_size = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiment_match_+3A_x">x</code></td>
<td>
<p>A plain text vector or column name if data is supplied.
If you know what you're doing, you can also pass in a 512-D numeric
embedding.</p>
</td></tr>
<tr><td><code id="sentiment_match_+3A_phrases">phrases</code></td>
<td>
<p>A named list of examples phrases with each element of the list
being words/terms that are indications of the name of that element
(such as positive words/terms under the name &quot;positive&quot; and negative
words/terms under the name &quot;negative&quot;, all within the same list).</p>
</td></tr>
<tr><td><code id="sentiment_match_+3A_model">model</code></td>
<td>
<p>An embedding name from tensorflow-hub, some of which are
&quot;en&quot; (english large or not) and &quot;multi&quot; (multi-lingual large or not).</p>
</td></tr>
<tr><td><code id="sentiment_match_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of batches to use. Larger numbers will be faster than
smaller numbers, but do not exhaust your system memory!</p>
</td></tr>
<tr><td><code id="sentiment_match_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="reticulate.html#topic+conda-tools">conda_install()</a></code>
or <code><a href="reticulate.html#topic+virtualenv-tools">virtualenv_install()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.table containing text, sentiment, phrase, class, and similarity.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
envname   &lt;- "r-sentiment-ai"

# make sure to install sentiment ai (install_sentiment.ai)
# install_sentiment.ai(envname = envname,
#                      method  = "conda")

# running the model
mod_match &lt;- sentiment_match(x       = airline_tweets$text,
                             model   = "en.large",
                             envname = envname)

# checking performance
pos_neg &lt;- factor(airline_tweets$airline_sentiment,
                  levels = c("negative", "neutral", "positive"))
pos_neg &lt;- (as.numeric(pos_neg) - 1) / 2
cosine(mod_match$sentiment, pos_neg)

# you could also calculate accuracy/kappa

## End(Not run)

</code></pre>

<hr>
<h2 id='sentiment_score'>Simple Sentiment Scores</h2><span id='topic+sentiment_score'></span>

<h3>Description</h3>

<p>This uses a simple model (xgboost or glm) to return a simple predictive score,
where numbers closer to 1 are more positive and numbers closer to -1 are more
negative. This can be used to determine whether the sentiment is positive
or negative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment_score(
  x = NULL,
  model = names(default_models),
  scoring = c("xgb", "glm"),
  scoring_version = "1.0",
  batch_size = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sentiment_score_+3A_x">x</code></td>
<td>
<p>A plain text vector or column name if data is supplied.
If you know what you're doing, you can also pass in a 512-D numeric
embedding.</p>
</td></tr>
<tr><td><code id="sentiment_score_+3A_model">model</code></td>
<td>
<p>An embedding name from tensorflow-hub, some of which are
&quot;en&quot; (english large or not) and &quot;multi&quot; (multi-lingual large or not).</p>
</td></tr>
<tr><td><code id="sentiment_score_+3A_scoring">scoring</code></td>
<td>
<p>Model to use for scoring the embedding matrix (currently
either &quot;xgb&quot; or &quot;glm&quot;).</p>
</td></tr>
<tr><td><code id="sentiment_score_+3A_scoring_version">scoring_version</code></td>
<td>
<p>The scoring version to use, currently only 1.0, but
other versions might be supported in the future.</p>
</td></tr>
<tr><td><code id="sentiment_score_+3A_batch_size">batch_size</code></td>
<td>
<p>Size of batches to use. Larger numbers will be faster than
smaller numbers, but do not exhaust your system memory!</p>
</td></tr>
<tr><td><code id="sentiment_score_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="reticulate.html#topic+conda-tools">conda_install()</a></code>
or <code><a href="reticulate.html#topic+virtualenv-tools">virtualenv_install()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses simple preditive models on embeddings to provide probability of positive
score (rescaled to -1:1 for consistency with other packages).
</p>


<h3>Value</h3>

<p>numeric vector of length(x) containing a re-scaled sentiment probabilities.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
envname &lt;- "r-sentiment-ai"

# make sure to install sentiment ai (install_sentiment.ai)
# install_sentiment.ai(envname = envname,
#                      method  = "conda")

# running the model
mod_xgb &lt;- sentiment_score(x       = airline_tweets$text,
                           model   = "en.large",
                           scoring = "xgb",
                           envname = envname)
mod_glm &lt;- sentiment_score(x       = airline_tweets$text,
                           model   = "en.large",
                           scoring = "glm",
                           envname = envname)

# checking performance
pos_neg &lt;- factor(airline_tweets$airline_sentiment,
                  levels = c("negative", "neutral", "positive"))
pos_neg &lt;- (as.numeric(pos_neg) - 1) / 2
cosine(mod_xgb, pos_neg)
cosine(mod_glm, pos_neg)

# you could also calculate accuracy/kappa



## End(Not run)

</code></pre>

<hr>
<h2 id='sentiment.env'>Sentiment AI Embedding Environment</h2><span id='topic+sentiment.env'></span>

<h3>Description</h3>

<p>This is the embedding envirnoment for the sentiment.ai model. On package load,
this object should be NULL. When the model is initialized, this should be
updated based on the required embedding model. The embedding function will
be stored in the &quot;f&quot; slot of this environment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sentiment.env
</code></pre>


<h3>Format</h3>

<p>An object of class <code>environment</code> of length 0.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
