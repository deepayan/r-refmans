<!DOCTYPE html><html><head><title>Help for package metrica</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {metrica}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#metrica-package'><p>metrica: Prediction Performance Metrics</p></a></li>
<li><a href='#AC'><p>Ji and Gallo's Agreement Coefficient (AC)</p></a></li>
<li><a href='#accuracy'><p>Accuracy</p></a></li>
<li><a href='#agf'><p>Adjusted F-score</p></a></li>
<li><a href='#AUC_roc'><p>Area Under the ROC Curve</p></a></li>
<li><a href='#B0_sma'><p>Intercept of standardized major axis regression (SMA).</p></a></li>
<li><a href='#B1_sma'><p>Slope of standardized major axis regression (SMA).</p></a></li>
<li><a href='#balacc'><p>Balanced Accuracy</p></a></li>
<li><a href='#barley'><p>Barley grain number</p></a></li>
<li><a href='#bland_altman_plot'><p>Bland-Altman plot</p></a></li>
<li><a href='#bmi'><p>Bookmaker Informedness</p></a></li>
<li><a href='#CCC'><p>Concordance correlation coefficient (CCC)</p></a></li>
<li><a href='#chickpea'><p>Chickpea dry mass</p></a></li>
<li><a href='#confusion_matrix'><p>Confusion Matrix</p></a></li>
<li><a href='#csi'><p>Critical Success Index | Jaccard's Index</p></a></li>
<li><a href='#d'><p>Willmott's Index of Agreement (d)</p></a></li>
<li><a href='#d1'><p>Modified Index of Agreement (d1).</p></a></li>
<li><a href='#d1r'><p>Refined Index of Agreement (d1).</p></a></li>
<li><a href='#dcorr'><p>Distance Correlation</p></a></li>
<li><a href='#deltap'><p>deltaP or Markedness</p></a></li>
<li><a href='#density_plot'><p>Density plot of predicted and observed values</p></a></li>
<li><a href='#E1'><p>Absolute Model Efficiency (E1)</p></a></li>
<li><a href='#Erel'><p>Relative Model Efficiency (Erel)</p></a></li>
<li><a href='#error_rate'><p>Error rate</p></a></li>
<li><a href='#fmi'><p>Fowlkes-Mallows Index</p></a></li>
<li><a href='#fscore'><p>F-score</p></a></li>
<li><a href='#gmean'><p>Geometric Mean</p></a></li>
<li><a href='#import_apsim_db'><p>Import SQLite databases generated by APSIM NextGen</p></a></li>
<li><a href='#import_apsim_out'><p>import_apsim_out</p></a></li>
<li><a href='#iqRMSE'><p>Inter-Quartile Root Mean Squared Error</p></a></li>
<li><a href='#KGE'><p>Kling-Gupta Model Efficiency (KGE).</p></a></li>
<li><a href='#khat'><p>K-hat (Cohen's Kappa Coefficient)</p></a></li>
<li><a href='#lambda'><p>Duveiller's Agreement Coefficient</p></a></li>
<li><a href='#land_cover'><p>Binary Land Cover Data</p></a></li>
<li><a href='#LCS'><p>Lack of Correlation (LCS)</p></a></li>
<li><a href='#likelihood_ratios'><p>Likelihood Ratios (Classification)</p></a></li>
<li><a href='#MAE'><p>Mean Absolute Error (MAE)</p></a></li>
<li><a href='#maize_phenology'><p>Multi Class Phenology</p></a></li>
<li><a href='#MAPE'><p>Mean Absolute Percentage Error (MAPE)</p></a></li>
<li><a href='#MASE'><p>Mean Absolute Scaled Error (MASE)</p></a></li>
<li><a href='#MBE'><p>Mean Bias Error (MBE)</p></a></li>
<li><a href='#mcc'><p>Matthews Correlation Coefficient | Phi Coefficient</p></a></li>
<li><a href='#metrics_summary'><p>Prediction Performance Summary</p></a></li>
<li><a href='#MIC'><p>Maximal Information Coefficient</p></a></li>
<li><a href='#MLA'><p>Mean Lack of Accuracy (MLA)</p></a></li>
<li><a href='#MLP'><p>Mean Lack of Precision (MLP)</p></a></li>
<li><a href='#MSE'><p>Mean Squared Error (MSE)</p></a></li>
<li><a href='#npv'><p>Negative Predictive Value</p></a></li>
<li><a href='#NSE'><p>Nash-Sutcliffe Model Efficiency (NSE)</p></a></li>
<li><a href='#PAB'><p>Percentage Additive Bias (PAB)</p></a></li>
<li><a href='#PBE'><p>Percentage Bias Error (PBE).</p></a></li>
<li><a href='#PLA'><p>Percentage Lack of Accuracy (PLA)</p></a></li>
<li><a href='#PLP'><p>Percentage Lack of Precision (PLP)</p></a></li>
<li><a href='#PPB'><p>Percentage Proportional Bias (PPB)</p></a></li>
<li><a href='#precision'><p>Precision | Positive Predictive Value</p></a></li>
<li><a href='#prevalence'><p>Prevalence</p></a></li>
<li><a href='#r'><p>Sample Correlation Coefficient (r)</p></a></li>
<li><a href='#R2'><p>Coefficient of determination (R2).</p></a></li>
<li><a href='#RAC'><p>Robinson's Agreement Coefficient (RAC).</p></a></li>
<li><a href='#RAE'><p>Relative Absolute Error (RAE)</p></a></li>
<li><a href='#recall'><p>Recall | Sensitivity | True Positive Rate | Hit rate</p></a></li>
<li><a href='#RMAE'><p>Relative Mean Absolute Error (RMAE)</p></a></li>
<li><a href='#RMLA'><p>Root Mean Lack of Accuracy (RMLA)</p></a></li>
<li><a href='#RMLP'><p>Root Mean Lack of Precision (RMLP)</p></a></li>
<li><a href='#RMSE'><p>Root Mean Squared Error (RMSE)</p></a></li>
<li><a href='#RRMSE'><p>Relative Root Mean Squared Error (RMSE)</p></a></li>
<li><a href='#RSE'><p>Relative Squared Error (RSE)</p></a></li>
<li><a href='#RSR'><p>Root Mean Standard Deviation Ratio (RSR)</p></a></li>
<li><a href='#RSS'><p>Residual Sum of Squares (RSS)</p></a></li>
<li><a href='#SB'><p>Squared bias (SB)</p></a></li>
<li><a href='#scatter_plot'><p>Scatter plot of predicted and observed values</p></a></li>
<li><a href='#SDSD'><p>Squared difference between standard deviations (SDSD)</p></a></li>
<li><a href='#SMAPE'><p>Symmetric Mean Absolute Percentage Error (SMAPE).</p></a></li>
<li><a href='#sorghum'><p>Sorghum grain number</p></a></li>
<li><a href='#specificity'><p>Specificity  | Selectivity | True Negative Rate</p></a></li>
<li><a href='#tiles_plot'><p>Tiles plot of predicted and observed values</p></a></li>
<li><a href='#TSS'><p>Total Sum of Squares (TSS)</p></a></li>
<li><a href='#Ub'><p>Mean Bias Error Proportion (Ub)</p></a></li>
<li><a href='#Uc'><p>Lack of Consistency (Uc)</p></a></li>
<li><a href='#Ue'><p>Lack of Consistency (Ue)</p></a></li>
<li><a href='#uSD'><p>Uncorrected Standard Deviation</p></a></li>
<li><a href='#var_u'><p>Uncorrected Variance (var_u)</p></a></li>
<li><a href='#wheat'><p>Wheat grain nitrogen</p></a></li>
<li><a href='#Xa'><p>Accuracy Component (Xa) of CCC</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Prediction Performance Metrics</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-12</td>
</tr>
<tr>
<td>Description:</td>
<td>A compilation of more than 80 functions designed to quantitatively and visually evaluate prediction performance of regression (continuous variables) and classification (categorical variables) of point-forecast models (e.g. APSIM, DSSAT, DNDC, supervised Machine Learning). For regression, it includes functions to generate plots (scatter, tiles, density, &amp; Bland-Altman plot), and to estimate error metrics (e.g. MBE, MAE, RMSE), error decomposition (e.g. lack of accuracy-precision), model efficiency (e.g. NSE, E1, KGE), indices of agreement (e.g. d, RAC), goodness of fit (e.g. r, R2), adjusted correlation coefficients (e.g. CCC, dcorr), symmetric regression coefficients (intercept, slope), and mean absolute scaled error (MASE) for time series predictions. For classification (binomial and multinomial), it offers functions to generate and plot confusion matrices, and to estimate performance metrics such as accuracy, precision, recall, specificity, F-score, Cohen's Kappa, G-mean, and many more. For more details visit the vignettes <a href="https://adriancorrendo.github.io/metrica/">https://adriancorrendo.github.io/metrica/</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>purrr, knitr, rmarkdown, apsimx, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, ggplot2, dplyr, rlang, tidyr, utils, DBI, RSQLite,
ggpp, minerva, energy</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://adriancorrendo.github.io/metrica/">https://adriancorrendo.github.io/metrica/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/adriancorrendo/metrica/issues">https://github.com/adriancorrendo/metrica/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-14 04:29:36 UTC; correndo</td>
</tr>
<tr>
<td>Author:</td>
<td>Adrian A. Correndo
    <a href="https://orcid.org/0000-0002-4172-289X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre, cph],
  Adrian A. Correndo
    <a href="https://orcid.org/0000-0002-4172-289X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Luiz H. Moro Rosso
    <a href="https://orcid.org/0000-0002-8642-911X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Rai Schwalbert <a href="https://orcid.org/0000-0001-8488-7507"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Carlos Hernandez <a href="https://orcid.org/0000-0001-5171-2516"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Leonardo M. Bastos
    <a href="https://orcid.org/0000-0001-8958-6527"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Luciana Nieto <a href="https://orcid.org/0000-0002-7172-0799"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Dean Holzworth [aut],
  Ignacio A. Ciampitti
    <a href="https://orcid.org/0000-0001-9619-5129"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adrian A. Correndo &lt;correndo@ksu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-14 04:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='metrica-package'>metrica: Prediction Performance Metrics</h2><span id='topic+metrica'></span><span id='topic+metrica-package'></span>

<h3>Description</h3>

<p>A compilation of more than 80 functions designed to quantitatively and visually evaluate prediction performance of regression (continuous variables) and classification (categorical variables) of point-forecast models (e.g. APSIM, DSSAT, DNDC, supervised Machine Learning). For regression, it includes functions to generate plots (scatter, tiles, density, &amp; Bland-Altman plot), and to estimate error metrics (e.g. MBE, MAE, RMSE), error decomposition (e.g. lack of accuracy-precision), model efficiency (e.g. NSE, E1, KGE), indices of agreement (e.g. d, RAC), goodness of fit (e.g. r, R2), adjusted correlation coefficients (e.g. CCC, dcorr), symmetric regression coefficients (intercept, slope), and mean absolute scaled error (MASE) for time series predictions. For classification (binomial and multinomial), it offers functions to generate and plot confusion matrices, and to estimate performance metrics such as accuracy, precision, recall, specificity, F-score, Cohen's Kappa, G-mean, and many more. For more details visit the vignettes <a href="https://adriancorrendo.github.io/metrica/">https://adriancorrendo.github.io/metrica/</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Adrian A. Correndo <a href="mailto:correndo@ksu.edu">correndo@ksu.edu</a> (<a href="https://orcid.org/0000-0002-4172-289X">ORCID</a>) [copyright holder]
</p>
<p>Authors:
</p>

<ul>
<li><p> Adrian A. Correndo <a href="mailto:correndo@ksu.edu">correndo@ksu.edu</a> (<a href="https://orcid.org/0000-0002-4172-289X">ORCID</a>)
</p>
</li>
<li><p> Luiz H. Moro Rosso <a href="mailto:lhmrosso@ksu.edu">lhmrosso@ksu.edu</a> (<a href="https://orcid.org/0000-0002-8642-911X">ORCID</a>)
</p>
</li>
<li><p> Rai Schwalbert <a href="mailto:rai.schwalbert@hotmail.com">rai.schwalbert@hotmail.com</a> (<a href="https://orcid.org/0000-0001-8488-7507">ORCID</a>)
</p>
</li>
<li><p> Carlos Hernandez <a href="mailto:carlosh92@ksu.edu">carlosh92@ksu.edu</a> (<a href="https://orcid.org/0000-0001-5171-2516">ORCID</a>)
</p>
</li>
<li><p> Leonardo M. Bastos <a href="mailto:leonardombastos@gmail.com">leonardombastos@gmail.com</a> (<a href="https://orcid.org/0000-0001-8958-6527">ORCID</a>)
</p>
</li>
<li><p> Luciana Nieto <a href="mailto:lnieto@ksu.edu">lnieto@ksu.edu</a> (<a href="https://orcid.org/0000-0002-7172-0799">ORCID</a>)
</p>
</li>
<li><p> Dean Holzworth <a href="mailto:dean.holzworth@csiro.au">dean.holzworth@csiro.au</a>
</p>
</li>
<li><p> Ignacio A. Ciampitti <a href="mailto:ciampitti@ksu.edu">ciampitti@ksu.edu</a> (<a href="https://orcid.org/0000-0001-9619-5129">ORCID</a>)
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://adriancorrendo.github.io/metrica/">https://adriancorrendo.github.io/metrica/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/adriancorrendo/metrica/issues">https://github.com/adriancorrendo/metrica/issues</a>
</p>
</li></ul>


<hr>
<h2 id='AC'>Ji and Gallo's Agreement Coefficient (AC)</h2><span id='topic+AC'></span>

<h3>Description</h3>

<p>It estimates the agreement coefficient suggested by Ji &amp; Gallo (2006)
for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AC(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AC_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="AC_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="AC_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="AC_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="AC_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Ji and Gallo's AC measures general agreement, including both accuracy and precision.
It is normalized, dimensionless, positively bounded (-infinity;1), and symmetric.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Ji &amp; Gallo (2006). An agreement coefficient for image comparison.
<em>Photogramm. Eng. Remote Sensing 7, 823–833</em> <a href="https://doi.org/10.14358/PERS.72.7.823">doi:10.14358/PERS.72.7.823</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
df &lt;- data.frame(obs = X, pred = Y)
AC(df, obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='accuracy'>Accuracy</h2><span id='topic+accuracy'></span>

<h3>Description</h3>

<p>It estimates the accuracy for a nominal/categorical predicted-observed
dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accuracy(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="accuracy_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="accuracy_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="accuracy_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="accuracy_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE returns a data.frame, FALSE returns a list (default).</p>
</td></tr>
<tr><td><code id="accuracy_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values (NA).
Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Accuracy is the simplest and most popular classification metric in literature.
It refers to a measure of the degree to which the predictions of a model matches the
reality being modeled. The classification accuracy is calculated as the ratio between
the number of correctly classified objects with respect to the total number of cases.
</p>
<p>It is bounded between 0 and 1. The closer to 1 the better. Values towards zero
indicate low accuracy of predictions. It can be also expressed as percentage if
multiplied by 100. It is estimated at a global level (not at the class level).
</p>
<p>Accuracy presents limitations to address classification quality under unbalanced classes,
and it is not able to distinguish among misclassification distributions. For those cases,
it is advised to apply other metrics such as balanced accuracy (baccu), F-score (fscore),
Matthews Correlation Coefficient (mcc), or Cohen's Kappa Coefficient (cohen_kappa).
</p>
<p>Accuracy is directly related to the error_rate, since accuracy = 1 – error_rate.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Sammut &amp; Webb (2017).
Accuracy.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_3">doi:10.1007/978-1-4899-7687-1_3</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+balacc">balacc</a></code> <code><a href="#topic+fscore">fscore</a></code> <code><a href="#topic+mcc">mcc</a></code> <code><a href="#topic+khat">khat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE) )

# Get accuracy estimate for two-class case
accuracy(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get accuracy estimate for multi-class case
accuracy(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='agf'>Adjusted F-score</h2><span id='topic+agf'></span>

<h3>Description</h3>

<p>It estimates the Adjusted F-score for a nominal/categorical
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agf(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="agf_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="agf_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="agf_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="agf_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="agf_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="agf_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="agf_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Adjusted F-score (or Adjusted F-measure) is an improvement over the
F1-score especially when the data classes are imbalanced. This metric more properly
accounts for the different misclassification costs across classes. It weights more
the sensitivity (recall) metric than precision and gives strength to the false negative
values. This index accounts for all elements of the original confusion matrix and
provides more weight to patterns correctly classified in the minority class (positive).
</p>
<p>It is bounded between 0 and 1.
The closer to 1 the better. Values towards zero indicate low performance.
For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Maratea, A., Petrosino, A., Manzo, M. (2014).
Adjusted-F measure and kernel scaling for imbalanced data learning.
<em>Inf. Sci. 257: 331-341.</em> <a href="https://doi.org/10.1016/j.ins.2013.04.016">doi:10.1016/j.ins.2013.04.016</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get F-score estimate for two-class case
agf(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get F-score estimate for each class for the multi-class case
agf(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get F-score estimate for the multi-class case at a global level
agf(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='AUC_roc'>Area Under the ROC Curve</h2><span id='topic+AUC_roc'></span>

<h3>Description</h3>

<p>The AUC estimates the area under the receiver operator
curve (ROC) for a nominal/categorical predicted-observed dataset using the
Mann-Whitney U-statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AUC_roc(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AUC_roc_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="AUC_roc_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="AUC_roc_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="AUC_roc_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return.
TRUE returns a data.frame, FALSE returns a list (default).</p>
</td></tr>
<tr><td><code id="AUC_roc_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values (NA).
Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AUC tests whether positives are ranked higher than negatives. It is
simply the area under the ROC curve.
</p>
<p>The AUC estimation of this function follows the procedure described by
Hand &amp; Till (2001). The AUC_roc estimated following the trapezoid approach is
equivalent to the average between recall and specificity (Powers, 2011), which is
equivalent to the balanced accuracy (<code>balacc</code>):
</p>
<p><code class="reqn">AUC_roc = \frac{(recall - FPR + 1)}{2} = \frac{recall+specificity}{2} = 1-\frac{FPR+FNR}{2}</code>
</p>
<p>Interpretation: the AUC is equivalent to the probability that a randomly case
from a given class (positive for binary) will have a smaller estimated probability
of belonging to another class (negative for binary) compared to a randomly
chosen member of the another class.
</p>
<p>Values: the AUC is bounded between 0 and 1. The closer to 1 the better.
Values close to 0 indicate inaccurate predictions. An AUC = 0.5 suggests no
discrimination ability between classes; 0.7 &lt; AUC &lt; 0.8 is considered acceptable,
0.8 &lt; AUC &lt; 0.5 is considered excellent, and AUC &gt; 0.9 is outstanding
(Mandrekar, 2010).
</p>
<p>For the multiclass cases, the AUC is equivalent to the average of AUC of each class
(Hand &amp; Till, 2001).
</p>
<p>Finally, the AUC is directly related to the Gini-index (a.k.a. G1) since Gini + 1 = 2*AUC.
(Hand &amp; Till, 2001).
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Hanley, J.A., McNeil, J.A. (2017).
The meaning and use of the area under a receiver operating characteristic (ROC) curve.
_ Radiology 143(1): 29-36_ <a href="https://doi.org/10.1148/radiology.143.1.7063747">doi:10.1148/radiology.143.1.7063747</a>
</p>
<p>Hand, D.J., Till, R.J. (2001).
A simple generalisation of the area under the ROC curve for multiple class
classification problems.
_ Machine Learning 45: 171-186_ <a href="https://doi.org/10.1023/A%3A1010920819831">doi:10.1023/A:1010920819831</a>
</p>
<p>Mandrekar, J.N. (2010).
Receiver operating characteristic curve in diagnostic test assessment.
_ J. Thoracic Oncology 5(9): 1315-1316_ <a href="https://doi.org/10.1097/JTO.0b013e3181ec173d">doi:10.1097/JTO.0b013e3181ec173d</a>
</p>
<p>Powers, D.M.W. (2011).
Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation.
<em>Journal of Machine Learning Technologies 2(1): 37–63.</em> <a href="https://doi.org/10.48550/arXiv.2010.16061">doi:10.48550/arXiv.2010.16061</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE) )

# Get AUC estimate for two-class case
AUC_roc(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get AUC estimate for multi-class case
AUC_roc(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='B0_sma'>Intercept of standardized major axis regression (SMA).</h2><span id='topic+B0_sma'></span>

<h3>Description</h3>

<p>It calculates the intercept (B0) for the bivariate linear relationship
between predicted and observed values following the SMA regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>B0_sma(data = NULL, obs, pred, orientation = "PO", tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="B0_sma_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="B0_sma_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="B0_sma_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="B0_sma_+3A_orientation">orientation</code></td>
<td>
<p>Argument of class <code>string</code> specifying the axis
orientation, PO for predicted vs observed, and OP for
observed vs predicted. Default is orientation = &quot;PO&quot;.</p>
</td></tr>
<tr><td><code id="B0_sma_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="B0_sma_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na_rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SMA is a symmetric linear regression (invariant results/interpretation to axis orientation)
recommended to describe the bivariate scatter instead of OLS regression
(classic linear model, which results vary with the axis orientation).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Warton et al. (2006).
Bivariate line-fitting methods for allometry.
<em>Biol. Rev. Camb. Philos. Soc. 81, 259–291.</em> <a href="https://doi.org/10.1002/1521-4036%28200203%2944%3A2%3C161%3A%3AAID-BIMJ161%3E3.0.CO%3B2-N">doi:10.1002/1521-4036(200203)44:2&lt;161::AID-BIMJ161&gt;3.0.CO;2-N</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
B0_sma(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='B1_sma'>Slope of standardized major axis regression (SMA).</h2><span id='topic+B1_sma'></span>

<h3>Description</h3>

<p>It calculates the slope (B1) for the bivariate linear relationship
between predicted and observed values following the SMA regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>B1_sma(data = NULL, obs, pred, tidy = FALSE, orientation = "PO", na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="B1_sma_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="B1_sma_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="B1_sma_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="B1_sma_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="B1_sma_+3A_orientation">orientation</code></td>
<td>
<p>Argument of class string specifying the axis
orientation, PO for predicted vs observed, and OP for
observed vs predicted. Default is orientation = &quot;PO&quot;.</p>
</td></tr>
<tr><td><code id="B1_sma_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values (NA). Default is na_rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SMA is a symmetric linear regression (invariant results/interpretation to axis orientation)
recommended to describe the bivariate scatter instead of OLS regression
(classic linear model, which results vary with the axis orientation).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Warton et al. (2006).
Bivariate line-fitting methods for allometry.
<em>Biol. Rev. Camb. Philos. Soc. 81, 259–291.</em> <a href="https://doi.org/10.1002/1521-4036%28200203%2944%3A2%3C161%3A%3AAID-BIMJ161%3E3.0.CO%3B2-N">doi:10.1002/1521-4036(200203)44:2&lt;161::AID-BIMJ161&gt;3.0.CO;2-N</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
B1_sma(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='balacc'>Balanced Accuracy</h2><span id='topic+balacc'></span>

<h3>Description</h3>

<p>It estimates the balanced accuracy for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>balacc(data = NULL, obs, pred, pos_level = 2, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="balacc_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="balacc_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="balacc_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="balacc_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="balacc_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="balacc_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The balanced accuracy is the average between recall and specificity.
It is particularly useful when the number of observation belonging to each class
is despair or imbalanced, and when especial attention is given to the negative
cases. It is bounded between 0 and 1. Values towards zero indicate low performance.
The closer to 1 the better.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>García, V., Mollineda, R.A., Sánchez, J.S. (2009). Index of Balanced Accuracy:
A Performance Measure for Skewed Class Distributions.
<em>In: Araujo, H., Mendonça, A.M., Pinho, A.J., Torres, M.I. (eds) Pattern Recognition and Image Analysis.</em>
<em>IbPRIA 2009. Lecture Notes in Computer Science, vol 5524.</em>
<em>Springer-Verlag Berlin Heidelberg.</em> <a href="https://doi.org/10.1007/978-3-642-02172-5_57">doi:10.1007/978-3-642-02172-5_57</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get balanced accuracy estimate for two-class case
balacc(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get balanced accuracy estimate for the multi-class case
balacc(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='barley'>Barley grain number</h2><span id='topic+barley'></span>

<h3>Description</h3>

<p>This example dataset is a set of APSIM simulations of
barley grain number (x1000 grains per squared meter), which presents high
accuracy but medium precision. The experimental trials come from 11
site-years in 2 countries (Australia, and New Zealand).
These data correspond to the latest, up-to-date, documentation and
validation of version number 2020.03.27.4956. Data available at:
<a href="https://doi.org/10.7910/DVN/EJS4M0">doi:10.7910/DVN/EJS4M0</a>.
Further details can be found at the official APSIM Next Generation
website:
<a href="https://APSIMnextgeneration.netlify.app/modeldocumentation/">https://APSIMnextgeneration.netlify.app/modeldocumentation/</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>barley
</code></pre>


<h3>Format</h3>

<p>This data frame has 69 rows and the following 2 columns:
</p>

<dl>
<dt>pred</dt><dd><p>predicted values</p>
</dd>
<dt>obs</dt><dd><p>observed values</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/adriancorrendo/metrica">https://github.com/adriancorrendo/metrica</a>
</p>

<hr>
<h2 id='bland_altman_plot'>Bland-Altman plot</h2><span id='topic+bland_altman_plot'></span>

<h3>Description</h3>

<p>It creates a scatter plot of the difference between observed and predicted
values (obs-pred) vs. observed values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bland_altman_plot(
  data = NULL,
  obs,
  pred,
  shape_type = NULL,
  shape_size = NULL,
  shape_color = NULL,
  zeroline_type = NULL,
  zeroline_size = NULL,
  zeroline_color = NULL,
  limitsline_type = NULL,
  limitsline_size = NULL,
  limitsline_color = NULL,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bland_altman_plot_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_shape_type">shape_type</code></td>
<td>
<p>number indicating the shape type for the data points.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_shape_size">shape_size</code></td>
<td>
<p>number indicating the shape size for the data points.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_shape_color">shape_color</code></td>
<td>
<p>string indicating the shape color for the data points.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_zeroline_type">zeroline_type</code></td>
<td>
<p>string or integer indicating the zero line-type.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_zeroline_size">zeroline_size</code></td>
<td>
<p>number indicating the zero line size.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_zeroline_color">zeroline_color</code></td>
<td>
<p>string indicating the zero line color.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_limitsline_type">limitsline_type</code></td>
<td>
<p>string or integer indicating the limits (+/- 1.96*SD) line-type.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_limitsline_size">limitsline_size</code></td>
<td>
<p>number indicating the limits (+/- 1.96*SD) line size.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_limitsline_color">limitsline_color</code></td>
<td>
<p>string indicating the limits (+/- 1.96*SD) line color.</p>
</td></tr>
<tr><td><code id="bland_altman_plot_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details, see <a href="https://adriancorrendo.github.io/metrica/">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>ggplot</code>.
</p>


<h3>References</h3>

<p>Bland &amp; Altman (1986).
Statistical methods for assessing agreement between two methods of clinical measurement
<em>The Lancet 327(8476), 307-310</em> <a href="https://doi.org/10.1016/S0140-6736%2886%2990837-8">doi:10.1016/S0140-6736(86)90837-8</a>
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,<code><a href="ggplot2.html#topic+geom_point">geom_point</a></code>,<code><a href="ggplot2.html#topic+aes">aes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 10)
bland_altman_plot(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='bmi'>Bookmaker Informedness</h2><span id='topic+bmi'></span><span id='topic+jindex'></span>

<h3>Description</h3>

<p>It estimates the Bookmaker Informedness (a.k.a. Youden's J-index)
for a nominal/categorical predicted-observed dataset.
</p>
<p><code>jindex</code> estimates the Youden's J statistic or
Youden's J Index (equivalent to Bookmaker Informedness <code>bmi</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bmi(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)

jindex(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bmi_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="bmi_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="bmi_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="bmi_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="bmi_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="bmi_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="bmi_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bookmaker Informedness (or Youden's J index) it is a suitable metric when the
number of cases for each class is uneven.
</p>
<p>The general formula applied to both binary and multiclass cases is:
</p>
<p><code class="reqn">bmi = recall + specificity - 1 </code>
</p>
<p>It is bounded between 0 and 1.
The closer to 1 the better. Values towards zero indicate low performance.
For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Youden, W.J. (1950).
Index for rating diagnostic tests.
<em>. Cancer 3: 32-35.</em>
<a href="https://doi.org/10.1002/1097-0142%281950%293%3A1%3C32%3A%3AAID-CNCR2820030106%3E3.0.CO%3B2-3">doi:10.1002/1097-0142(1950)3:1&lt;32::AID-CNCR2820030106&gt;3.0.CO;2-3</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get Informedness estimate for two-class case
bmi(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get Informedness estimate for each class for the multi-class case
bmi(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

# Get Informedness estimate for the multi-class case at a global level
bmi(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='CCC'>Concordance correlation coefficient (CCC)</h2><span id='topic+CCC'></span>

<h3>Description</h3>

<p>It estimates the Concordance Correlation Coefficient (CCC) for
a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCC(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CCC_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="CCC_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="CCC_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="CCC_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="CCC_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The CCC it is a normalized coefficient that tests general agreement.
It presents both precision (r) and accuracy (Xa) components. It is positively bounded to 1.
The closer to 1 the better. Values towards zero indicate low correlation between observations and predictions.
Negative values would indicate a negative relationship between predicted and observed.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Lin (1989).
A concordance correlation coefficient to evaluate reproducibility.
<em>Biometrics 45 (1), 255–268.</em> <a href="https://doi.org/10.2307/2532051">doi:10.2307/2532051</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
CCC(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='chickpea'>Chickpea dry mass</h2><span id='topic+chickpea'></span>

<h3>Description</h3>

<p>This example dataset is a set of APSIM simulations of
chickpea aboveground dry mass (kg per hectare), which exhibits low
accuracy and medium-low precision as it represents a model still under
development. The experimental trials come from 7 site-years in
3 countries (Australia, India, and New Zealand).
These data correspond to the latest, up-to-date, documentation and
validation of version number 2020.03.27.4956. Data available at:
<a href="https://doi.org/10.7910/DVN/EJS4M0">doi:10.7910/DVN/EJS4M0</a>.
Further details can be found at the official APSIM Next Generation
website:
<a href="https://APSIMnextgeneration.netlify.app/modeldocumentation/">https://APSIMnextgeneration.netlify.app/modeldocumentation/</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chickpea
</code></pre>


<h3>Format</h3>

<p>This data frame has 39 rows and the following 2 columns:
</p>

<dl>
<dt>pred</dt><dd><p>predicted values</p>
</dd>
<dt>obs</dt><dd><p>observed values</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/adriancorrendo/metrica">https://github.com/adriancorrendo/metrica</a>
</p>

<hr>
<h2 id='confusion_matrix'>Confusion Matrix</h2><span id='topic+confusion_matrix'></span>

<h3>Description</h3>

<p>It creates a confusion matrix table or plot displaying the agreement
between the observed and the predicted classes by the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion_matrix(
  data = NULL,
  obs,
  pred,
  plot = FALSE,
  unit = "count",
  colors = c(low = NULL, high = NULL),
  print_metrics = FALSE,
  metrics_list = c("accuracy", "precision", "recall"),
  position_metrics = "top",
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion_matrix_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character or factor).</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character or factor).</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_plot">plot</code></td>
<td>
<p>Logical operator (TRUE/FALSE) that controls the output as a
<code>data.frame</code> (plot = FALSE) or as a plot of type <code>ggplot</code> (plot = TRUE), Default: FALSE</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_unit">unit</code></td>
<td>
<p>String (text) indicating the type of unit (&quot;count&quot; or &quot;proportion&quot;)
to show in the confusion matrix, Default: 'count'</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_colors">colors</code></td>
<td>
<p>Vector or list with two colors indicating how to paint the gradient
between &quot;low&quot; and &quot;high&quot;, Default: c(low = NULL, high = NULL) uses the standard
blue gradient of ggplot2.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_print_metrics">print_metrics</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_metrics_list">metrics_list</code></td>
<td>
<p>vector or list of selected metrics to print on the plot.
Default: c(&quot;accuracy&quot;, &quot;precision&quot;, &quot;recall&quot;).</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_position_metrics">position_metrics</code></td>
<td>
<p>string specifying the position to print the performance
<code>metrics_list</code>. Options are &quot;top&quot; (as a subtitle) or &quot;bottom&quot; (as a caption).
Default: &quot;bottom&quot;.</p>
</td></tr>
<tr><td><code id="confusion_matrix_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A confusion matrix is a method for summarizing the predictive performance of a classification algorithm.
It is particularly useful if you have an unbalanced number of observations belonging to each class or if you have
a multinomial dataset (more than two classes in your dataset. A confusion matrix can give you a good hint about
the types of errors that your model is making.
See <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>An object of class <code>data.frame</code> when plot = FALSE, or of type <code>ggplot</code>
when plot = TRUE.
</p>


<h3>References</h3>

<p>Ting K.M. (2017).
Confusion Matrix. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_50">doi:10.1007/978-1-4899-7687-1_50</a>
</p>


<h3>See Also</h3>

<p><code><a href="rlang.html#topic+eval_tidy">eval_tidy</a></code>, <code><a href="rlang.html#topic+defusing-advanced">defusing-advanced</a></code>
<code><a href="dplyr.html#topic+select">select</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(183)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE),
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100,
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Plot two-class confusion matrix
confusion_matrix(data = binomial_case, obs = labels, pred = predictions, 
plot = TRUE, colors = c(low="pink" , high="steelblue"), unit = "count")

# Plot multi-class confusion matrix
confusion_matrix(data = multinomial_case, obs = labels, pred = predictions, 
plot = TRUE, colors = c(low="#f9dbbd" , high="#735d78"), unit = "count")

</code></pre>

<hr>
<h2 id='csi'>Critical Success Index | Jaccard's Index</h2><span id='topic+csi'></span><span id='topic+jaccardindex'></span>

<h3>Description</h3>

<p>It estimates the Critical Success Index (a.k.a. threat score,
Jaccard Index) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>jaccardindex</code> estimates the Jaccard similarity coefficient
or Jaccard's Index (equivalent to the Critical Success Index <code>csi</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>csi(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)

jaccardindex(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="csi_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="csi_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="csi_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="csi_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="csi_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="csi_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="csi_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>csi</code> is also known as the threat score or the Jaccard Index.
It is a metric especially useful for binary classification tasks, representing the
proportion of true positive (TP) cases with respect to the sum of predicted positive
(PP = TP + FP) and true negative (TN) cases.
</p>
<p><code class="reqn">csi = \frac{TP}{TP + TN + FP} </code>
</p>
<p>It is bounded between 0 and 1. The closer to 1 the better the classification performance,
while zero represents the worst result.
</p>
<p>It has been extensively used in meteorology (NOOA) as a verification measure
of categorical forecast performance equal to the total number of correct event forecast
(hits = TP) divided by the total number of event forecasts plus the number of misses (hits +
false alarms + misses = TP + FP + TN). However, the csi has been criticized for
not representing an unbiased measure of forecast skill (Schaefer, 1990).
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>NOOA.
Forecast Verification Glossary.
<em>Space Weather Prediction Center, NOOA.</em> <a href="https://www.swpc.noaa.gov/sites/default/files/images/u30/Forecast%20Verification%20Glossary.pdf">https://www.swpc.noaa.gov/sites/default/files/images/u30/Forecast%20Verification%20Glossary.pdf</a>
</p>
<p>Schaefer, J.T. (1990).
The critical success index as an indicator of warning skill.
<em>Weather and Forecasting 5(4): 570-575.</em> <a href="https://doi.org/10.1175/1520-0434%281990%29005%3C0570%3ATCSIAA%3E2.0.CO%3B2">doi:10.1175/1520-0434(1990)005&lt;0570:TCSIAA&gt;2.0.CO;2</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Get csi estimate for two-class case
csi(data = binomial_case, obs = labels, pred = predictions)


</code></pre>

<hr>
<h2 id='d'>Willmott's Index of Agreement (d)</h2><span id='topic+d'></span>

<h3>Description</h3>

<p>It estimates the Willmott's index of agreement (d) for a
continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="d_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="d_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="d_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="d_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The d index it is a normalized, dimensionless metric that tests general agreement.
It measures both accuracy and precision using squared residuals. It is bounded between 0 and 1.
The disadvantage is that d is an asymmetric index, that is, dependent to what is orientation of
predicted and observed values.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Willmott (1981).
On the validation of models.
<em>Phys. Geogr. 2, 184–194.</em> <a href="https://doi.org/10.1080/02723646.1981.10642213">doi:10.1080/02723646.1981.10642213</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
d(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='d1'>Modified Index of Agreement (d1).</h2><span id='topic+d1'></span>

<h3>Description</h3>

<p>It estimates the modified index of agreement (d1) using absolute
differences following Willmott et al. (1985).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d1(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d1_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="d1_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="d1_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="d1_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="d1_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to d, the d1 index it is a normalized, dimensionless metric that tests general agreement.
The difference with d, is that d1 uses absolute residuals instead of squared residuals. It is bounded between 0 and 1.
The disadvantage is that d is an asymmetric index, that is, dependent to the orientation of
predicted and observed values.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Willmott et al. (1985).
Statistics for the evaluation and comparison of models.
<em>J. Geophys. Res. 90, 8995.</em> <a href="https://doi.org/10.1029/jc090ic05p08995">doi:10.1029/jc090ic05p08995</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
d1(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='d1r'>Refined Index of Agreement (d1).</h2><span id='topic+d1r'></span>

<h3>Description</h3>

<p>It estimates the refined index of agreement (d1r) following
Willmott et al. (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d1r(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d1r_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="d1r_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="d1r_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="d1r_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="d1r_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Similar to d, and d1, the d1r index it is a normalized, dimensionless
metric that tests general agreement. The difference is that d1r modifies the
denominator of the formula (potential error), normalizing the mean absolute error
(numerator) by two-times the mean absolute deviation of observed values. It is
bounded between 0 and 1. The disadvantage is that d1r is an asymmetric index,
that is, dependent to the orientation of predicted and observed values.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Willmott et al. (2012).
A refined index of model performance.
<em>Int. J. Climatol. 32, 2088–2094.</em> <a href="https://doi.org/10.1002/joc.2419">doi:10.1002/joc.2419</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
d1r(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='dcorr'>Distance Correlation</h2><span id='topic+dcorr'></span>

<h3>Description</h3>

<p>It estimates the Distance Correlation coefficient (dcorr) for
a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcorr(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dcorr_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the
data.</p>
</td></tr>
<tr><td><code id="dcorr_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="dcorr_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="dcorr_+3A_tidy">tidy</code></td>
<td>
<p>logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list (default).</p>
</td></tr>
<tr><td><code id="dcorr_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <strong>dcorr</strong> function is a wrapper for the <code>dcor</code> function
from the <strong>energy</strong>-package. See Rizzo &amp; Szekely (2022). The distance
correlation (dcorr) coefficient is a novel measure of dependence
between random vectors introduced by Szekely et al. (2007).
</p>
<p>The dcorr is characterized for being symmetric, which is relevant for the
predicted-observed case (PO).
</p>
<p>For all distributions with finite first moments, distance correlation
<code class="reqn">\mathcal R</code> generalizes the idea of correlation in two fundamental ways:
</p>
<p>(1) <code class="reqn">\mathcal R(P,O)</code> is defined for <code class="reqn">P</code> and <code class="reqn">O</code> in arbitrary
dimension.
</p>
<p>(2) <code class="reqn">\mathcal R(P,O)=0</code> characterizes independence of <code class="reqn">P</code> and
<code class="reqn">O</code>.
</p>
<p>Distance correlation satisfies <code class="reqn">0 \le \mathcal R \le 1</code>, and
<code class="reqn">\mathcal R = 0</code> only if <code class="reqn">P</code> and <code class="reqn">O</code> are independent. Distance
covariance <code class="reqn">\mathcal V</code> provides a new approach to the problem of
testing the joint independence of random vectors. The formal definitions of the
population coefficients <code class="reqn">\mathcal V</code> and
<code class="reqn">\mathcal R</code> are given in Szekely et al. (2007).
</p>
<p>The empirical distance correlation <code class="reqn">\mathcal{R}_n(\mathbf{P,O})</code> is
the square root of
</p>
<p style="text-align: center;"><code class="reqn"> \mathcal{R}^2_n(\mathbf{P,O})= \frac {\mathcal{V}^2_n(\mathbf{P,O})} 
{\sqrt{ \mathcal{V}^2_n (\mathbf{P}) \mathcal{V}^2_n(\mathbf{O})}}. </code>
</p>

<p>For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
and the <a href="https://CRAN.R-project.org/package=energy">energy-package</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Szekely, G.J., Rizzo, M.L., and Bakirov, N.K. (2007).
<em>Measuring and testing dependence by correaltion of distances. Annals of Statistics, Vol. 35(6): 2769-2794</em>.
<a href="https://doi.org/10.1214/009053607000000505">doi:10.1214/009053607000000505</a>.<br />
</p>
<p>Rizzo, M., and Szekely, G. (2022).
energy: E-Statistics: Multivariate Inference via the Energy of Data.
<em>R package version 1.7-10.</em>
<a href="https://CRAN.R-project.org/package=energy">https://CRAN.R-project.org/package=energy</a>.<br />
</p>


<h3>See Also</h3>

<p><code><a href="rlang.html#topic+eval_tidy">eval_tidy</a></code>, <code><a href="rlang.html#topic+defusing-advanced">defusing-advanced</a></code>
<code><a href="energy.html#topic+dcor">dcor</a></code>, <code><a href="energy.html#topic+energy">energy</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
P &lt;- rnorm(n = 100, mean = 0, sd = 10)
O &lt;- P + rnorm(n=100, mean = 0, sd = 3)
dcorr(obs = P, pred = O)

</code></pre>

<hr>
<h2 id='deltap'>deltaP or Markedness</h2><span id='topic+deltap'></span><span id='topic+mk'></span>

<h3>Description</h3>

<p><code>deltap</code> estimates the Markedness or deltaP for a nominal/categorical
predicted-observed dataset.
</p>
<p><code>mk</code> estimates the Markedness (equivalent
to deltaP) for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deltap(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)

mk(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deltap_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="deltap_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="deltap_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="deltap_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="deltap_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="deltap_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="deltap_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>deltap</code> is also known as the markedness. It is a metric
that quantifies the probability that a condition is marked by the predictor with
respect to a random chance (Powers, 2011).
</p>
<p>The deltap is related to <code>precision</code> (or positive predictive values -ppv-)
and its inverse (the negative predictive value -<code>npv</code>-) as follows:
</p>
<p><code class="reqn">deltap = PPV + NPV - 1  = precision + npv - 1</code>
</p>
<p>The higher the deltap the better the classification performance.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Powers, D.M.W. (2011).
Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation.
<em>Journal of Machine Learning Technologies 2(1): 37–63.</em> <a href="https://doi.org/10.48550/arXiv.2010.16061">doi:10.48550/arXiv.2010.16061</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Get deltap estimate for two-class case
deltap(data = binomial_case, obs = labels, pred = predictions)


</code></pre>

<hr>
<h2 id='density_plot'>Density plot of predicted and observed values</h2><span id='topic+density_plot'></span>

<h3>Description</h3>

<p>It draws a density area plot of predictions and observations with alternative
axis orientation (P vs. O; O vs. P).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>density_plot(
  data = NULL,
  obs,
  pred,
  n = 10,
  colors = c(low = NULL, high = NULL),
  orientation = "PO",
  print_metrics = FALSE,
  metrics_list = NULL,
  position_metrics = c(x = NULL, y = NULL),
  print_eq = TRUE,
  position_eq = c(x = NULL, y = NULL),
  eq_color = NULL,
  regline_type = NULL,
  regline_size = NULL,
  regline_color = NULL,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="density_plot_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="density_plot_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="density_plot_+3A_n">n</code></td>
<td>
<p>Argument of class numeric specifying the number of data points in each group.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_colors">colors</code></td>
<td>
<p>Vector or list with two colors '(low, high)' to paint the density gradient.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_orientation">orientation</code></td>
<td>
<p>Argument of class string specifying the axis
orientation, PO for predicted vs observed, and OP for
observed vs predicted. Default is orientation = &quot;PO&quot;.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_print_metrics">print_metrics</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_metrics_list">metrics_list</code></td>
<td>
<p>vector or list of selected metrics to print on the plot.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_position_metrics">position_metrics</code></td>
<td>
<p>vector or list with '(x,y)' coordinates to locate the metrics_table into the plot.
Default : c(x = min(obs), y = 1.05*max(pred)).</p>
</td></tr>
<tr><td><code id="density_plot_+3A_print_eq">print_eq</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_position_eq">position_eq</code></td>
<td>
<p>vector or list with '(x,y)' coordinates to locate the SMA equation into the plot.
Default : c(x = 0.70 max(x), y = 1.25*min(y)).</p>
</td></tr>
<tr><td><code id="density_plot_+3A_eq_color">eq_color</code></td>
<td>
<p>string indicating the color of the SMA-regression text.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_regline_type">regline_type</code></td>
<td>
<p>string or integer indicating the SMA-regression line-type.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_regline_size">regline_size</code></td>
<td>
<p>number indicating the SMA-regression line size.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_regline_color">regline_color</code></td>
<td>
<p>string indicating the SMA-regression line color.</p>
</td></tr>
<tr><td><code id="density_plot_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It creates a density plot of predicted vs. observed values. The plot also includes
the 1:1 line (solid line) and the linear regression line (dashed line). By default,
it places the observed on the x-axis and the predicted on the y-axis (orientation = &quot;PO&quot;).
This can be inverted by changing the argument orientation = “OP&quot;.
For more details, see <a href="https://adriancorrendo.github.io/metrica/">online-documentation</a>
</p>


<h3>Value</h3>

<p>Object of class <code>ggplot</code>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,<code><a href="ggplot2.html#topic+geom_point">geom_point</a></code>,<code><a href="ggplot2.html#topic+aes">aes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 10)
density_plot(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='E1'>Absolute Model Efficiency (E1)</h2><span id='topic+E1'></span>

<h3>Description</h3>

<p>It estimates the E1 model efficiency using absolute differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>E1(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="E1_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="E1_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="E1_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="E1_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="E1_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The E1 is a type of model efficiency that modifies the Nash-Sutcliffe model efficiency
by using absolute residuals instead of squared residuals. The E1 is used to overcome the NSE
over-sensitivity to extreme values caused by the used of squared residuals.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Legates &amp; McCabe (1999).
Evaluating the use of “goodness-of-fit” measures in hydrologic and hydroclimatic model validation.
<em>Water Resour. Res.</em> <a href="https://doi.org/10.1029/1998WR900018">doi:10.1029/1998WR900018</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
E1(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='Erel'>Relative Model Efficiency (Erel)</h2><span id='topic+Erel'></span>

<h3>Description</h3>

<p>It estimates the Erel model efficiency using differences to observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Erel(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Erel_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="Erel_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="Erel_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="Erel_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="Erel_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Erel model efficiency normalizes both residuals (numerator) and observed
deviations (denominator) by observed values before squaring them. Compared to the NSE, the Erel is suggested as
more sensitive to systematic over- or under-predictions.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Krause et al. (2005).
Comparison of different efficiency criteria for hydrological model assessment.
<em>Adv. Geosci. 5, 89–97.</em> <a href="https://doi.org/10.5194/adgeo-5-89-2005">doi:10.5194/adgeo-5-89-2005</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
Erel(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='error_rate'>Error rate</h2><span id='topic+error_rate'></span>

<h3>Description</h3>

<p>It estimates the error rate for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error_rate(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="error_rate_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="error_rate_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="error_rate_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="error_rate_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list (default).</p>
</td></tr>
<tr><td><code id="error_rate_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The error rate represents the opposite of accuracy, referring to a
measure of the degree to which the predictions miss-classify the reality.
The classification error_rate is calculated as the ratio between the number of
incorrectly classified objects with respect to the total number of objects.
It is bounded between 0 and 1. The closer to 1 the worse. Values towards zero
indicate low error_rate of predictions. It can be also expressed as percentage
if multiplied by 100. It is estimated at a global level (not at the class level).
The error rate is directly related to the accuracy, since error_rate = 1 – accuracy' .
For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>(2017) Accuracy. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_3">doi:10.1007/978-1-4899-7687-1_3</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get error_rate estimate for two-class case
error_rate(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get error_rate estimate for multi-class case
error_rate(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='fmi'>Fowlkes-Mallows Index</h2><span id='topic+fmi'></span>

<h3>Description</h3>

<p>It estimates the Fowlkes-Mallows Index for a nominal/categorical
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmi(data = NULL, obs, pred, pos_level = 2, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fmi_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="fmi_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="fmi_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="fmi_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="fmi_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="fmi_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fmi has gained popularity within the machine learning community
to summarize into a single value the confusion matrix of a binary classification.
It is particularly useful when the number of observations belonging to each class
is uneven or imbalanced. It is characterized for being symmetric (i.e. no class
has more relevance than the other). It is bounded between -1 and 1.
The closer to 1 the better the classification performance.
</p>
<p>The fmi is only available for the evaluation of binary cases (two classes). For
multiclass cases, fmi will produce a <code>NA</code> and display a warning.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Fowlkes, Edward B; Mallows, Colin L (1983).
A method for comparing two hierarchical clusterings.
<em>Journal of the American Statistical Association. 78 (383): 553–569.</em>
<a href="https://doi.org/10.1080/01621459.1983.10478008">doi:10.1080/01621459.1983.10478008</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Get fmi estimate for two-class case
fmi(data = binomial_case, obs = labels, pred = predictions)

</code></pre>

<hr>
<h2 id='fscore'>F-score</h2><span id='topic+fscore'></span>

<h3>Description</h3>

<p>It estimates the F-score for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fscore(
  data = NULL,
  obs,
  pred,
  B = 1,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fscore_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="fscore_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="fscore_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="fscore_+3A_b">B</code></td>
<td>
<p>Numeric value indicating the weight (a.k.a. B or beta) to be applied to the
relationship between recall and precision. B &lt; 1 weights more precision than recall.
B &gt; 1 gives B times more importance to recall than precision. Default: 1.</p>
</td></tr>
<tr><td><code id="fscore_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="fscore_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="fscore_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="fscore_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The F-score (or F-measure) it is a more robust metric than the classic accuracy,
especially when the number of cases for each class is uneven. It represents the harmonic
mean of precision and recall. Thus, to achieve high values of F-score it is necessary
to have both high precision and high recall.
</p>
<p>The universal version of F-score employs a coefficient B, by which we can tune the
precision-recall ratio. Values of B &gt; 1 give more weight to recall, and B &lt; 1 give more
weight to precision.
</p>
<p>For binomial/binary cases, fscore  =  TP / (TP + 0.5*(FP + FN))
</p>
<p>The generalized formula applied to multiclass cases is:
</p>
<p><code class="reqn">fscore = \frac{(1 + B ^ 2) * (precision * recall)} {((B ^ 2 * precision) + recall)} </code>
</p>
<p>It is bounded between 0 and 1.
The closer to 1 the better. Values towards zero indicate low performance.
For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Goutte, C., Gaussier, E. (2005).
A Probabilistic Interpretation of Precision, Recall and F-Score, with Implication for Evaluation.
<em>In: D.E. Losada and J.M. Fernandez-Luna (Eds.): ECIR 2005</em>
<em>. Advances in Information Retrieval LNCS 3408, pp. 345–359, 2.</em>
<em>Springer-Verlag Berlin Heidelberg.</em> <a href="https://doi.org/10.1007/978-3-540-31865-1_25">doi:10.1007/978-3-540-31865-1_25</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get F-score estimate for two-class case
fscore(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get F-score estimate for each class for the multi-class case
fscore(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get F-score estimate for the multi-class case at a global level
fscore(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='gmean'>Geometric Mean</h2><span id='topic+gmean'></span>

<h3>Description</h3>

<p>It estimates the Geometric Mean score for a nominal/categorical
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gmean(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gmean_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="gmean_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="gmean_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="gmean_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="gmean_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="gmean_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="gmean_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The gmean is a metric especially useful for imbalanced classes because it
measures the balance between the classification performance on both major (over-represented)
as well as on minor (under-represented) classes. As stated above, it is particularly
useful when the number of observations belonging to each class is uneven.
</p>
<p>The gmean score is equivalent to the square-root of the product of specificity
and recall (a.k.a. sensitivity).
</p>
<p><code class="reqn">gmean = \sqrt{recall * specificity} </code>
</p>
<p>It is bounded between 0 and 1. The closer to 1 the better the classification performance,
while zero represents the worst.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>De Diego, I.M., Redondo, A.R., Fernández, R.R., Navarro, J., Moguerza, J.M. (2022).
General Performance Score for classification problems.
_ Appl. Intell. (2022)._ <a href="https://doi.org/10.1007/s10489-021-03041-7">doi:10.1007/s10489-021-03041-7</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Get gmean estimate for two-class case
gmean(data = binomial_case, obs = labels, pred = predictions)


</code></pre>

<hr>
<h2 id='import_apsim_db'>Import SQLite databases generated by APSIM NextGen</h2><span id='topic+import_apsim_db'></span>

<h3>Description</h3>

<p>Imports data from SQLite databases (*.db) applied by APSIM
Next Generation. It reads one file at a time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_apsim_db(filename = "", folder = ".", value = "report", simplify = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_apsim_db_+3A_filename">filename</code></td>
<td>
<p>file name including the file extension (&quot;*.db&quot;), as a string (&quot;&quot;).</p>
</td></tr>
<tr><td><code id="import_apsim_db_+3A_folder">folder</code></td>
<td>
<p>source folder/directory containing the file, as a string (&quot;&quot;).</p>
</td></tr>
<tr><td><code id="import_apsim_db_+3A_value">value</code></td>
<td>
<p>either &lsquo;report&rsquo;, &lsquo;all&rsquo; (list) or user-defined for a specific report.</p>
</td></tr>
<tr><td><code id="import_apsim_db_+3A_simplify">simplify</code></td>
<td>
<p>if TRUE will attempt to simplify multiple reports into a single data.frame.
If FALSE it will return a list. Default: TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>data.frame</code>, but it depends on the argument &lsquo;value&rsquo; above
</p>


<h3>Note</h3>

<p>This function was adapted from apsimx package (Miguez, 2022).
For reference, we recommend to check and use the function
apsimx::read_apsimx() as an alternative.
Source: https://github.com/femiguez/apsimx by F. Miguez.
</p>


<h3>References</h3>

<p>Miguez, F. (2022)
apsimx: Inspect, Read, Edit and Run 'APSIM' &quot;Next Generation&quot; and 'APSIM' Classic.
<em>R package version 2.3.1,</em> <a href="https://CRAN.R-project.org/package=apsimx">https://CRAN.R-project.org/package=apsimx</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See [documentation](https://adriancorrendo.github.io/metrica/index.html)

</code></pre>

<hr>
<h2 id='import_apsim_out'>import_apsim_out</h2><span id='topic+import_apsim_out'></span>

<h3>Description</h3>

<p>Function to import *.out files generated by APSIM Classic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_apsim_out(filepath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_apsim_out_+3A_filepath">filepath</code></td>
<td>
<p>Argument to specify the location path to the *.out file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will generate a data frame object from an APSIM Classic *.out file.
</p>


<h3>Value</h3>

<p>Element of class <code>data.frame</code>.
</p>


<h3>Note</h3>

<p>Note: It imports one file at a time.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See [documentation](https://adriancorrendo.github.io/metrica/index.html)

</code></pre>

<hr>
<h2 id='iqRMSE'>Inter-Quartile Root Mean Squared Error</h2><span id='topic+iqRMSE'></span>

<h3>Description</h3>

<p>It estimates the IqRMSE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iqRMSE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iqRMSE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="iqRMSE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="iqRMSE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="iqRMSE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="iqRMSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The iqRMSE normalizes the RMSE by the length of the inter-quartile range of
observations (percentiles 25th to 75th). As an error metric, the lower the values the better.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
iqRMSE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='KGE'>Kling-Gupta Model Efficiency (KGE).</h2><span id='topic+KGE'></span>

<h3>Description</h3>

<p>It estimates the KGE for a predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KGE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KGE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="KGE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="KGE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="KGE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="KGE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The KGE is a normalized, dimensionless, model efficiency that measures general agreement.
It presents accuracy, precision, and consistency components. It is symmetric
(invariant to predicted observed orientation). It is positively bounded up to 1.
The closer to 1 the better.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Kling et al. (2012).
Runoff conditions in the upper Danube basin under an ensemble of climate change scenarios.
<em>Journal of Hydrology 424-425, 264-277.</em> <a href="https://doi.org/10.1016/j.jhydrol.2012.01.011">doi:10.1016/j.jhydrol.2012.01.011</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
KGE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='khat'>K-hat (Cohen's Kappa Coefficient)</h2><span id='topic+khat'></span>

<h3>Description</h3>

<p>It estimates the Cohen's Kappa Coefficient for a nominal/categorical
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>khat(data = NULL, obs, pred, pos_level = 2, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="khat_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="khat_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="khat_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="khat_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="khat_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="khat_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cohen's Kappa Coefficient is the accuracy normalized by the possibility
of agreement by chance. Thus, it is considered a more robust agreement measure than
simply the accuracy. The kappa coefficient was originally described for evaluating
agreement of classification between different &quot;raters&quot; (inter-rater reliability).
</p>
<p>It is positively bounded to 1, but it is not negatively bounded.
The closer to 1 the better as Kappa assumes its theoretical maximum value of 1
(perfect agreement) only when both observed and predicted values are equally
distributed across the classes (i.e. identical row and column sums). Thus,
the lower the kappa the lower the prediction quality.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Cohen, J. (1960).
A coefficient of agreement for nominal scales.
_ Educational and Psychological Measurement 20 (1): 37–46._
<a href="https://doi.org/10.1177/001316446002000104">doi:10.1177/001316446002000104</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Get Cohen's Kappa Coefficient estimate for two-class case
khat(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get Cohen's Kappa Coefficient estimate for each class for the multi-class case
khat(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get Cohen's Kappa Coefficient estimate for the multi-class case at a global level
khat(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='lambda'>Duveiller's Agreement Coefficient</h2><span id='topic+lambda'></span>

<h3>Description</h3>

<p>It estimates the agreement coefficient (lambda) suggested by
Duveiller et al. (2016) for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambda(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lambda_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="lambda_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="lambda_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="lambda_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="lambda_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>lambda measures both accuracy and precision. It is normalized, dimensionless,
bounded (-1;1), and symmetric (invariant to predicted-observed orientation).
lambda is equivalent to CCC when r is greater or equal to 0. The closer to 1 the better.
Values towards zero indicate low correlation between observations and predictions.
Negative values would indicate a negative relationship between predicted and observed.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Duveiller et al. (2016).
Revisiting the concept of a symmetric index of agreement for continuous datasets.
<em>Sci. Rep. 6, 1-14.</em> <a href="https://doi.org/10.1038/srep19401">doi:10.1038/srep19401</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
lambda(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='land_cover'>Binary Land Cover Data</h2><span id='topic+land_cover'></span>

<h3>Description</h3>

<p>This example dataset was obtained in 2022 over a small region in Kansas,
using visual interpretation.
The predicted values were the result of a Random Forest classification,
with a 70/30 % split.
Values equal to 1 are associated to vegetation, and values equal to 0 are other type of land cover.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>land_cover
</code></pre>


<h3>Format</h3>

<p>This data frame has 284 rows and the following 2 columns:
</p>

<dl>
<dt>predicted</dt><dd><p>predicted values</p>
</dd>
<dt>actual</dt><dd><p>observed values</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/adriancorrendo/metrica">https://github.com/adriancorrendo/metrica</a>
</p>

<hr>
<h2 id='LCS'>Lack of Correlation (LCS)</h2><span id='topic+LCS'></span>

<h3>Description</h3>

<p>It estimates the lack of correlation (LCS) component of the Mean
Squared Error (MSE) proposed by Kobayashi &amp; Salam (2000).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LCS(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LCS_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="LCS_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="LCS_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="LCS_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="LCS_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LCS represents the random component of the prediction error following
Kobayashi &amp; Salam (2000). The lower the value the less contribution to the MSE.
However, it needs to be compared to MSE as its benchmark.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Kobayashi &amp; Salam (2000).
Comparing simulated and measured values using mean squared deviation and its components.
<em>Agron. J. 92, 345–352.</em> <a href="https://doi.org/10.2134/agronj2000.922345x">doi:10.2134/agronj2000.922345x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
LCS(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='likelihood_ratios'>Likelihood Ratios (Classification)</h2><span id='topic+likelihood_ratios'></span><span id='topic+posLr'></span><span id='topic+negLr'></span><span id='topic+dor'></span>

<h3>Description</h3>

<p>It estimates the positive likelihood ratio <code>posLr</code>,
negative likelihood ratio <code>negLr</code>, and diagnostic odds ratio <code>dor</code>
for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posLr(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)

negLr(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)

dor(
  data = NULL,
  obs,
  pred,
  pos_level = 2,
  atom = FALSE,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="likelihood_ratios_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="likelihood_ratios_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="likelihood_ratios_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="likelihood_ratios_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="likelihood_ratios_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="likelihood_ratios_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="likelihood_ratios_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The likelihood ratios are metrics designed to assess the expectations of
classification tasks. They are highly related to recall (sensitivity or true positive rate)
and specificity (selectivity or true negative rate).
</p>
<p>For a multiclass case, positive and negative results are class-wise. We can either
hit the actual class, or the actual non-class. For example, a classification
may have 3 potential results: cat, dog, or fish. Thus, when the actual value is dog,
the only true positive is dog, but we can obtain a true negative either by classifying
it as a cat or a fish. The posLr, negLr, and dor estimates are the mean across all classes.
</p>
<p>The positive likelihood ratio (posLr) measures the odds of obtaining a positive
prediction in cases that are actual positives.
</p>
<p>The negative likelihood ratio (negLr) relates the odds of obtaining a negative
prediction for actual non-negatives relative to the probability of actual negative
cases obtaining a negative prediction result.
</p>
<p>Finally, the diagnostic odds ratio (dor) measures the effectiveness of classification.
It represents the odds of a positive prediction result in actual (observed) positive
cases with respect to the odds of a positive prediction for the actual negative cases.
</p>
<p>The ratios are define as follows:
</p>
<p><code class="reqn">posLr = \frac{recall}{1+specificity} = \frac{TPR}{FPR}</code>
</p>
<p><code class="reqn">negLr = \frac{1-recall}{specificity} = \frac{FNR}{TNR}</code>
</p>
<p><code class="reqn">dor = \frac{posLr}{negLr}</code>
</p>
<p>For more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>GlasaJeroen, A.S., Lijmer, G., Prins, M.H., Bonsel, G.J., Bossuyta, P.M.M. (2009).
The diagnostic odds ratio: a single indicator of test performance.
<em>Journal of Clinical Epidemiology 56(11): 1129-1135.</em> <a href="https://doi.org/10.1016/S0895-4356%2803%2900177-X">doi:10.1016/S0895-4356(03)00177-X</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get posLr, negLr, and dor for a two-class case
posLr(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)
negLr(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)
dor(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)


</code></pre>

<hr>
<h2 id='MAE'>Mean Absolute Error (MAE)</h2><span id='topic+MAE'></span>

<h3>Description</h3>

<p>It estimates the MAE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MAE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MAE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MAE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MAE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MAE measures both lack of accuracy and precision in absolute scale.
It keeps the same units than the response variable. It is less sensitive to outliers
than the MSE or RMSE. The lower the better.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Willmott &amp; Matsuura (2005).
Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance.
<em>Clim. Res. 30, 79–82.</em> <a href="https://doi.org/10.3354/cr030079">doi:10.3354/cr030079</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
MAE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='maize_phenology'>Multi Class Phenology</h2><span id='topic+maize_phenology'></span>

<h3>Description</h3>

<p>This example data set includes maize phenology classes collected in Kansas during the 2018 growing season.
The predicted values were obtained using a Random Forest classifier with a 70/30 split.
The dataset includes 16 phenology stages from VT to R6.
For more information please visit
<a href="https://doi.org/10.3390/rs14030469">doi:10.3390/rs14030469</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maize_phenology
</code></pre>


<h3>Format</h3>

<p>This data frame has 103 rows and the following 2 columns:
</p>

<dl>
<dt>predicted</dt><dd><p>predicted values</p>
</dd>
<dt>actual</dt><dd><p>observed values</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/adriancorrendo/metrica">https://github.com/adriancorrendo/metrica</a>
</p>

<hr>
<h2 id='MAPE'>Mean Absolute Percentage Error (MAPE)</h2><span id='topic+MAPE'></span>

<h3>Description</h3>

<p>It estimates the MAPE of a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MAPE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MAPE_+3A_data">data</code></td>
<td>
<p>(optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MAPE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MAPE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MAPE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MAPE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MAPE is expressed in percentage units (independent scale), which it
makes easy to explain and to compare performance across models with different response variables.
MAPE is asymmetric (sensitive to axis orientation). The lower the better.
As main disadvantage, MAPE produces infinite or undefined values for zero or close-to-zero observed values.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Kim &amp; Kim (2016).
A new metric of absolute percentage error for intermittent demand forecast.
_Int. J. Forecast. 32, 669-679._<a href="https://doi.org/10.1016/j.ijforecast.2015.12.003">doi:10.1016/j.ijforecast.2015.12.003</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
MAPE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='MASE'>Mean Absolute Scaled Error (MASE)</h2><span id='topic+MASE'></span>

<h3>Description</h3>

<p>It estimates the mean absolute error using the naive-error approach
for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MASE(
  data = NULL,
  obs,
  pred,
  time = NULL,
  naive_step = 1,
  oob_mae = NULL,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MASE_+3A_data">data</code></td>
<td>
<p>(Required) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MASE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MASE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MASE_+3A_time">time</code></td>
<td>
<p>(Optional) String with the &quot;name&quot; of the vector containing the time variable
to sort observations. &quot;Optional&quot; to ensure an appropriate MASE estimation.
Default: NULL, assumes observations are already sorted by time.</p>
</td></tr>
<tr><td><code id="MASE_+3A_naive_step">naive_step</code></td>
<td>
<p>A positive number specifying how many observed values to recall
back in time when computing the naive expectation. Default = 1</p>
</td></tr>
<tr><td><code id="MASE_+3A_oob_mae">oob_mae</code></td>
<td>
<p>A numeric value indicating the out-of-bag (out-of-sample) MAE.
By default, an <em>in-sample</em> MAE is calculated using the naive forecast method.
See Hyndman &amp; Koehler (2006). Default : NULL.</p>
</td></tr>
<tr><td><code id="MASE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MASE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MASE is especially well suited for time series predictions.
It can be used to compare forecast methods on a single series and also to
compare forecast accuracy between series.
</p>
<p>This metric never gives an infinite or undefined values (unless all observations
over time are exactly the same!).
</p>
<p>By default, the MASE scales the error based on <em>in-sample</em> MAE from the naive forecast
method (random walk). The in-sample MAE is used in the denominator because it is
always available and it effectively scales the errors.Since it is based on
absolute error, it is less sensitive to outliers compared to the classic MSE.
</p>
<p><code class="reqn">MASE = \frac{1}{n}(\frac{|O_i-P_i|}{ \frac{1}{T-1} \sum^T_{t=2}~|O_t - O_{t-1}| })</code>
</p>
<p>If available, users may use and out-of-bag error from an independent dataset, which
can be specified with the <code>oob_mae</code> arg. and will replace the denominator into the MASE
equation.
</p>
<p>MASE measures total error (i.e. both lack of accuracy and precision.). The lower
the MASE below 1, the better the prediction quality. MASE = indicates no difference
between the model and the naive forecast (or oob predictions). MASE &gt; 1 indicate
poor performance.
</p>
<p>For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Hyndman, R.J., Koehler, A.B. (2006).
Another look at measures of forecast accuracy.
_ Int. J. Forecast_ <a href="https://doi.org/10.3354/cr030079">doi:10.3354/cr030079</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
# Create a fake dataset
X &lt;- rnorm(n = 100, mean = 8, sd = 10)
Y &lt;- rnorm(n = 100, mean = 8.2, sd = 15)
Z &lt;- seq(1, 100, by = 1)

time_data &lt;- as.data.frame(list("observed" = X, "predicted" = Y, "time" = Z))
 
MASE(data = time_data, obs = observed, pred = predicted, time = time)

</code></pre>

<hr>
<h2 id='MBE'>Mean Bias Error (MBE)</h2><span id='topic+MBE'></span>

<h3>Description</h3>

<p>It estimates the MBE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MBE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MBE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MBE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MBE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MBE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MBE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MBE is one of the most widely used error metrics. It presents the
same units than the response variable, and it is unbounded. It can be simply
estimated as the difference between the means of predictions and observations.
The closer to zero the better. Negative values indicate overestimation.
Positive values indicate general underestimation. The disadvantages are that is
only sensitive to additional bias, so the MBE may mask a poor performance if
overestimation and underestimation co-exist (a type of proportional bias).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
MBE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='mcc'>Matthews Correlation Coefficient | Phi Coefficient</h2><span id='topic+mcc'></span><span id='topic+phi_coef'></span>

<h3>Description</h3>

<p>It estimates the <code>mcc</code> for a nominal/categorical predicted-observed dataset.
</p>
<p><code>phi_coef</code> estimates the Phi coefficient
(equivalent to the Matthews Correlation Coefficient <code>mcc</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcc(data = NULL, obs, pred, pos_level = 2, tidy = FALSE, na.rm = TRUE)

phi_coef(data = NULL, obs, pred, pos_level = 2, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcc_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="mcc_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="mcc_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="mcc_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="mcc_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="mcc_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>mcc</code> it is also known as the phi-coefficient. It has gained
popularity within the machine learning community to summarize into a single
value the confusion matrix of a binary classification.
</p>
<p>It is particularly useful when the number of observations belonging to each class
is uneven or imbalanced. It is characterized for being symmetric (i.e. no class
has more relevance than the other). It is bounded between -1 and 1.
The closer to 1 the better the classification performance.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Chicco, D., Jurman, G. (2020)
The advantages of the Matthews correlation coefficient (MCC) over F1 score and
accuracy in binary classification evaluation.
<em>BMC Genomics 21, 6 (2020).</em> <a href="https://doi.org/10.1186/s12864-019-6413-7">doi:10.1186/s12864-019-6413-7</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))

# Get mcc estimate for two-class case
mcc(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='metrics_summary'>Prediction Performance Summary</h2><span id='topic+metrics_summary'></span>

<h3>Description</h3>

<p>It estimates a group of metrics characterizing the prediction performance
for a continuous (regression) or categorical (classification) predicted-observed dataset.
By default, it calculates all available metrics for either regression or classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metrics_summary(
  data = NULL,
  obs,
  pred,
  type = NULL,
  metrics_list = NULL,
  orientation = "PO",
  pos_level = 2,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="metrics_summary_+3A_data">data</code></td>
<td>
<p>argument to call an existing data frame containing the data (optional).</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_obs">obs</code></td>
<td>
<p>vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_pred">pred</code></td>
<td>
<p>vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_type">type</code></td>
<td>
<p>argument of class string specifying the type of model. For continuous
variables use <em>type = 'regression'</em>. For categorical variables use <em>type = 'classification'</em>.</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_metrics_list">metrics_list</code></td>
<td>
<p>vector or list of specific selected metrics. Default is = NULL,
which will estimate all metrics available for either regression or classification.</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_orientation">orientation</code></td>
<td>
<p>argument of class string specifying the axis
orientation to estimate slope(B1) and intercept(B0). It only applies when type = &quot;regression&quot;.
&quot;PO&quot; is for predicted vs observed, and &quot;OP&quot; for observed vs predicted.
Default is orientation = &quot;PO&quot;.</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_pos_level">pos_level</code></td>
<td>
<p>(for classification only). Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="metrics_summary_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can choose to calculate a single metric, or to calculate all metrics at once.
This function creates a data.frame with all (or selected) metrics in the <code>metrica</code>-package.
If looking for specific metrics, the user can pass a list of desired metrics using the
argument “metrics_list” (e.g. metrics_list = c(&quot;R2&quot;,&quot;MAE&quot;, &quot;RMSE&quot;, &quot;RSR&quot;, &quot;NSE&quot;, &quot;KGE&quot;)).
For the entire list of available metrics with formula,
see <a href="https://adriancorrendo.github.io/metrica/">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>data.frame</code> containing all (or selected) metrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Continuous variable (regression)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 10)
regression_case &lt;- data.frame(obs = X, pred = Y)

# Get a metrics summary for a regression problem
metrics_summary(regression_case, obs = X, pred = Y, type = "regression")

# Categorical variable (classification)
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))

#' # Get a metrics summary for a regression problem
metrics_summary(binomial_case, obs = labels, pred = predictions,
type = "classification")

</code></pre>

<hr>
<h2 id='MIC'>Maximal Information Coefficient</h2><span id='topic+MIC'></span>

<h3>Description</h3>

<p>It estimates the Maximal Information Coefficient (MIC) for
a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MIC(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MIC_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MIC_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MIC_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MIC_+3A_tidy">tidy</code></td>
<td>
<p>logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list (default).</p>
</td></tr>
<tr><td><code id="MIC_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <strong>MIC</strong> function is a wrapper for the <code>mine_stat</code> function of the
<strong>minerva</strong>-package, a collection of Maximal Information-Based Nonparametric statistics (MINE).
See Reshef et al. (2011).
</p>
<p>For the predicted-observed case (PO), the <strong>MIC</strong> is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">\textrm{MIC}(D)=\max_{PO&lt;B(n)} M(D)_{X,Y} = \max_{PO&lt;B(n)} \frac{I^ * (D,P,O)} {log(\min{P,O})},</code>
</p>
<p> where
<code class="reqn">B(n)=n^{\alpha}</code> is the search-grid size,
<code class="reqn">I^*(D,P,O)</code>
is the maximum mutual information over all grids <em>P-by-O</em>, of the distribution
induced by D on a grid having <em>P</em> and <em>O</em> bins (where the probability
mass on a cell of the grid is the fraction of points of D falling in that cell).
Albanese et al. (2013).
</p>
<p>For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Reshef, D., Reshef, Y., Finucane, H., Grossman, S., McVean, G., Turnbaugh, P.,
Lander, R., Mitzenmacher, M., and Sabeti, P. (2011). Detecting novel associations
in large datasets.
<em>Science 334, 6062</em>. <a href="https://doi.org/10.1126/science.1205438">doi:10.1126/science.1205438</a>. <br />
</p>
<p>Albanese, D., M. Filosi, R. Visintainer, S. Riccadonna, G. Jurman, C. Furlanello.
minerva and minepy: a C engine for the MINE suite and its R, Python and MATLAB wrappers.
<em>Bioinformatics (2013) 29(3):407-408</em>. <a href="https://doi.org/10.1093/bioinformatics/bts707">doi:10.1093/bioinformatics/bts707</a>. <br />
</p>


<h3>See Also</h3>

<p><code><a href="rlang.html#topic+eval_tidy">eval_tidy</a></code>, <code><a href="rlang.html#topic+defusing-advanced">defusing-advanced</a></code>
<code><a href="minerva.html#topic+mine_stat">mine_stat</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
MIC(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='MLA'>Mean Lack of Accuracy (MLA)</h2><span id='topic+MLA'></span>

<h3>Description</h3>

<p>It estimates the MLA, the systematic error component to
the Mean Squared Error (MSE), for a continuous predicted-observed dataset
following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLA(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLA_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MLA_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MLA_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MLA_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MLA_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MLA represents the systematic (bias) component of the MSE.
It is obtained via a symmetric decomposition of the MSE (invariant to
predicted-observed orientation) using a symmetric regression line.
The MLA is equal to the sum of systematic differences divided by the sample size (n).
The greater the value the greater the bias of the predictions.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
MLA(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='MLP'>Mean Lack of Precision (MLP)</h2><span id='topic+MLP'></span>

<h3>Description</h3>

<p>It estimates the MLP, the unsystematic error component to
the Mean Squared Error (MSE), for a continuous predicted-observed dataset
following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLP(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLP_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MLP_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MLP_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MLP_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MLP_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MLP represents the unsystematic (random) component of the MSE.
It is obtained via a symmetric decomposition of the MSE (invariant to
predicted-observed orientation) using a symmetric regression line.
The MLP is equal to the sum of unsystematic differences divided by the sample size (n).
The greater the value the greater the random noise of the predictions.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
MLP(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='MSE'>Mean Squared Error (MSE)</h2><span id='topic+MSE'></span>

<h3>Description</h3>

<p>It estimates the MSE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="MSE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="MSE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="MSE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="MSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MSE, also known as MSD, measures general agreement, as includes both
variance (lack of precision) and bias (lack of accuracy). The MSE of predictions
could be decomposed following a variety of approaches (e.g. Willmott et al. 1981; Correndo et al. 2021).
Its calculation is simple, the sum of squared differences between predictions and observations
divided by the sample size (n). The greater the value the worse the predicted performance.
Unfortunately, the units of MSE do not have a direct interpretation. For a more direct interpretation,
the square root of MSE (RMSE) has the same units as the variable of interest.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Willmott (1981).
On the validation of models.
<em>Phys. Geogr. 2, 184–194.</em> <a href="https://doi.org/10.1080/02723646.1981.10642213">doi:10.1080/02723646.1981.10642213</a>
</p>
<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
MSE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='npv'>Negative Predictive Value</h2><span id='topic+npv'></span><span id='topic+FOR'></span>

<h3>Description</h3>

<p><code>npv</code> estimates the npv (a.k.a. positive predictive
value -PPV-) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>FOR</code> estimates the false omission rate, which is the complement
of the negative predictive value for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npv(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

FOR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="npv_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="npv_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="npv_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="npv_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.</p>
</td></tr>
<tr><td><code id="npv_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="npv_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="npv_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The npv is a non-normalized coefficient that represents the
ratio between the correctly predicted cases (or true positive -TP- for binary cases)
to the total predicted observations for a given class (or total predicted positive
-PP- for binary cases) or at overall level.
</p>
<p>For binomial cases, <code class="reqn">npv = \frac{TP}{PP} = \frac{TP}{TP + FP} </code>
</p>
<p>The <code>npv</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low npv of predictions. It can be estimated
for each particular class or at a global level.
</p>
<p>The false omission rate (FOR) represents the proportion
of false negatives with respect to the number of negative predictions (PN).
</p>
<p>For binomial cases, <code class="reqn">FOR = 1 - npv = \frac{FN}{PN} = \frac{FN}{TN + FN} </code>
</p>
<p>The <code>npv</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low npv of predictions.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Wang H., Zheng H. (2013).
Negative Predictive Value.
<em>In: Dubitzky W., Wolkenhauer O., Cho KH., Yokota H. (eds) Encyclopedia of Systems Biology.</em>
_ Springer, New York, NY._ <a href="https://doi.org/10.1007/978-1-4419-9863-7_234">doi:10.1007/978-1-4419-9863-7_234</a>
</p>
<p>Trevethan, R. (2017).
<em>Sensitivity, Specificity, and Predictive Values: Foundations, Pliabilities, and Pitfalls</em>
_ in Research and Practice. Front. Public Health 5:307_ <a href="https://doi.org/10.3389/fpubh.2017.00307">doi:10.3389/fpubh.2017.00307</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Get npv estimate for two-class case
npv(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get fdr estimate for two-class case
FDR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get npv estimate for each class for the multi-class case
npv(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

# Get npv estimate for the multi-class case at a global level
npv(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

</code></pre>

<hr>
<h2 id='NSE'>Nash-Sutcliffe Model Efficiency (NSE)</h2><span id='topic+NSE'></span>

<h3>Description</h3>

<p>It estimates the model efficiency suggested by Nash &amp; Sutcliffe (1970)
for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NSE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="NSE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="NSE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="NSE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="NSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The NSE measures general agreement. It is normalized (by the variance of the observations) and dimensionless.
It is calculated using the absolute squared differences between the predictions and observations,
which has been suggested as an issue due to over-sensitivity to outliers.
It goes form -infinity to 1. The closer to 1 the better the prediction performance.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Nash &amp; Sutcliffe (1970).
River flow forecasting through conceptual models part I - A discussion of principles.
<em>J. Hydrol. 10(3), 292-290.</em> <a href="https://doi.org/10.1016/0022-1694%2870%2990255-6">doi:10.1016/0022-1694(70)90255-6</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
NSE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='PAB'>Percentage Additive Bias (PAB)</h2><span id='topic+PAB'></span>

<h3>Description</h3>

<p>It estimates the contribution of the proportional bias to the Mean Squared Error (MSE)
following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PAB(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PAB_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="PAB_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="PAB_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="PAB_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="PAB_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PAB represents contribution of additive bias () component of the MSE.
The PAB = 100*((mO-mP)^2/MSE), where mO, and mP represent the mean of observations
and predictions, respectively.
The greater the value the greater the contribution of additive bias to the prediction error.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
PAB(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='PBE'>Percentage Bias Error (PBE).</h2><span id='topic+PBE'></span>

<h3>Description</h3>

<p>It estimates the PBE for a continuous predicted-observed dataset
following Gupta et al. (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PBE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PBE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="PBE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="PBE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="PBE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="PBE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PBE (%) is useful to identify systematic over or under predictions.
It is an unbounded metric. The closer to zero the bias of predictions.
Negative values indicate overestimation, while positive values indicate underestimation.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Gupta et al. (1999).
Status of automatic calibration for hydrologic models: Comparison with multilevel expert calibration.
<em>J. Hydrologic Eng. 4(2): 135-143.</em> <a href="https://doi.org/10.1061/%28ASCE%291084-0699%281999%294%3A2%28135%29">doi:10.1061/(ASCE)1084-0699(1999)4:2(135)</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
PBE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='PLA'>Percentage Lack of Accuracy (PLA)</h2><span id='topic+PLA'></span>

<h3>Description</h3>

<p>It estimates the PLA, the contribution of the systematic error to
the Mean Squared Error (MSE) for a continuous predicted-observed dataset
following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLA(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLA_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="PLA_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="PLA_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="PLA_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="PLA_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PLA (%, 0-100) represents the  contribution of the Mean Lack of Accuracy (MLA),
the systematic (bias) component of the MSE. It is obtained via a symmetric decomposition of
the MSE (invariant to predicted-observed orientation). The PLA can be further segregated
into percentage additive bias (PAB) and percentage proportional bias (PPB).
The greater the value the greater the contribution of systematic error to the MSE.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
PLA(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='PLP'>Percentage Lack of Precision (PLP)</h2><span id='topic+PLP'></span>

<h3>Description</h3>

<p>It estimates the PLP, the contribution of the unsystematic error to
the Mean Squared Error (MSE) for a continuous predicted-observed dataset
following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLP(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLP_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="PLP_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="PLP_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="PLP_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="PLP_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PLP (%, 0-100) represents the  contribution of the Mean Lack of Precision (MLP),
the  unsystematic (random) component of the MSE. It is obtained via a symmetric decomposition
of the MSE (invariant to predicted-observed orientation).
The greater the value the greater the contribution of unsystematic error to the MSE.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
PLP(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='PPB'>Percentage Proportional Bias (PPB)</h2><span id='topic+PPB'></span>

<h3>Description</h3>

<p>It estimates the contribution of the proportional bias to the Mean Squared Error (MSE)
following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PPB(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PPB_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="PPB_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="PPB_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="PPB_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="PPB_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The PPB (%) measures the contribution of proportional bias to the MSE.
The PPB = 100*(((sO - sP)^2)/MSE), where sO, and sP are the sample variances
of observations and predictions, respectively.
The greater the value the greater the contribution of proportional bias to the prediction error.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
PPB(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='precision'>Precision | Positive Predictive Value</h2><span id='topic+precision'></span><span id='topic+ppv'></span><span id='topic+FDR'></span>

<h3>Description</h3>

<p><code>precision</code> estimates the precision (a.k.a. positive predictive
value -ppv-) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>ppv</code> estimates the Positive Predictive Value (equivalent
to precision) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>FDR</code> estimates the complement of precision (a.k.a. positive predictive
value -PPV-) for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>precision(
  data = NULL,
  obs,
  pred,
  tidy = FALSE,
  atom = FALSE,
  na.rm = TRUE,
  pos_level = 2
)

ppv(
  data = NULL,
  obs,
  pred,
  tidy = FALSE,
  atom = FALSE,
  na.rm = TRUE,
  pos_level = 2
)

FDR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="precision_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="precision_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="precision_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="precision_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="precision_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.</p>
</td></tr>
<tr><td><code id="precision_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
<tr><td><code id="precision_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The precision is a non-normalized coefficient that represents the
ratio between the correctly predicted cases (or true positive -TP- for binary cases)
to the total predicted observations for a given class (or total predicted positive
-PP- for binary cases) or at overall level.
</p>
<p>For binomial cases, <code class="reqn">precision = \frac{TP}{PP} = \frac{TP}{TP + FP} </code>
</p>
<p>The <code>precision</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low precision of predictions. It can be estimated
for each particular class or at a global level.
</p>
<p>The false detection rate or false discovery rate (FDR) represents the proportion
of false positives with respect to the total number of cases predicted as positive.
</p>
<p>For binomial cases, <code class="reqn">FDR = 1 - precision = \frac{FP}{PP} = \frac{FP}{TP + FP} </code>
</p>
<p>The <code>precision</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low precision of predictions.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Ting K.M. (2017)
Precision and Recall.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_659">doi:10.1007/978-1-4899-7687-1_659</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Get precision estimate for two-class case
precision(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get FDR estimate for two-class case
FDR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get precision estimate for each class for the multi-class case
precision(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

# Get precision estimate for the multi-class case at a global level
precision(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, atom = TRUE)

</code></pre>

<hr>
<h2 id='prevalence'>Prevalence</h2><span id='topic+prevalence'></span><span id='topic+preval'></span><span id='topic+preval_t'></span>

<h3>Description</h3>

<p><code>preval</code> estimates the prevalence of positive cases
for a nominal/categorical predicted-observed dataset.
</p>
<p><code>preval_t</code> estimates the prevalence threshold for a binary
predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preval(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

preval_t(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prevalence_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="prevalence_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="prevalence_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="prevalence_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The prevalence measures the overall proportion of actual positives with
respect to the total number of observations. Currently, it is defined for binary cases only.
</p>
<p>The general formula is:
</p>
<p><code class="reqn">preval = \frac{positive}{positive + negative} </code>
</p>
<p>The prevalence threshold represents an point on the ROC curve (function of
sensitivity (recall) and specificity) below which the precision (or PPV)
dramatically drops.
</p>
<p><code class="reqn">preval_t = \frac{\sqrt{TPR * FPR} - FPR}{TPR - FPR} </code>
</p>
<p>It is bounded between 0 and 1.
The closer to 1 the better. Values towards zero indicate low performance.
For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Freeman, E.A., Moisen, G.G. (2008).
A comparison of the performance of threshold criteria for binary classification in terms of predicted prevalence and kappa.
<em>. Ecol. Modell. 217(1-2): 45-58.</em> <a href="https://doi.org/10.1016/j.ecolmodel.2008.05.015">doi:10.1016/j.ecolmodel.2008.05.015</a>
</p>
<p>Balayla, J. (2020).
Prevalence threshold and the geometry of screening curves.
_Plos one, 15(10):e0240215, _ <a href="https://doi.org/10.1371/journal.pone.0240215">doi:10.1371/journal.pone.0240215</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, replace = TRUE), 
predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, replace = TRUE),
predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get prevalence estimate for two-class case
preval(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get prevalence estimate for each class for the multi-class case
preval(data = multinomial_case, obs = labels, pred = predictions, atom = TRUE)


</code></pre>

<hr>
<h2 id='r'>Sample Correlation Coefficient (r)</h2><span id='topic+r'></span>

<h3>Description</h3>

<p>It estimates the Pearson's coefficient of correlation (r) for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="r_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="r_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="r_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="r_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The r coefficient measures the strength of linear relationship between two variables.
It only accounts for precision, but it is not sensitive to lack of prediction accuracy.
It is a normalized, dimensionless coefficient, that ranges between -1 to 1. It is expected that
predicted and observed values will show 0 &lt; r &lt; 1.
It is also known as the Pearson Product Moment Correlation, among other names.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Kirch (2008)
Pearson’s Correlation Coefficient.
<em>In: Kirch W. (eds) Encyclopedia of Public Health. Springer, Dordrecht.</em>
<a href="https://doi.org/10.1007/978-1-4020-5614-7_2569">doi:10.1007/978-1-4020-5614-7_2569</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
r(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='R2'>Coefficient of determination (R2).</h2><span id='topic+R2'></span>

<h3>Description</h3>

<p>It estimates the R2 for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>R2(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="R2_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="R2_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="R2_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="R2_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="R2_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The R2 is one of the most widely used metrics evaluating models performance.
R2 is appropriate to estimate the strength of linear association between two variables.
It is positively bounded to 1, but it may produce negative values.
The closer to 1 the better linear association between predictions and observations.
However, R2 presents a major flaw for prediction performance evaluation:
it is not sensitive to lack of accuracy (additive or proportional bias). Thus, R2
only measures precision, but it does not account for accuracy of the predictions.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Yang et al. (2014).
An evaluation of the statistical methods for testing the performance of crop models with observed data.
<em>Agric. Syst. 127, 81-89.</em> <a href="https://doi.org/10.1016/j.agsy.2014.01.008">doi:10.1016/j.agsy.2014.01.008</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
R2(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RAC'>Robinson's Agreement Coefficient (RAC).</h2><span id='topic+RAC'></span>

<h3>Description</h3>

<p>It estimates the agreement coefficient suggested by
Robinson (1957; 1959) for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAC(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RAC_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RAC_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RAC_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RAC_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RAC_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RAC measures both accuracy and precision (general agreement). It is
normalized, dimensionless, bounded (0 to 1), and symmetric (invariant to predicted-observed orientation).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Robinson (1957).
The statistical measurement of agreement.
<em>Am. Sociol. Rev. 22(1), 17-25</em> <a href="https://doi.org/10.2307/2088760">doi:10.2307/2088760</a>
</p>
<p>Robinson (1959).
The geometric interpretation of agreement.
<em>Am. Sociol. Rev. 24(3), 338-345</em> <a href="https://doi.org/10.2307/2089382">doi:10.2307/2089382</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RAC(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RAE'>Relative Absolute Error (RAE)</h2><span id='topic+RAE'></span>

<h3>Description</h3>

<p>It estimates the RAC for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RAE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RAE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RAE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RAE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RAE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RAE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RAE normalizes the Mean Absolute Error (MAE) with respect to the
total absolute error. It is calculated as the ratio between the sum of absolute
residuals (error of predictions with respect to observations) and the sum of
absolute errors of observations with respect to its mean.
It presents its lower bound at 0 (perfect fit), and has no upper bound.
It can be used to compare models using different units.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RAE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='recall'>Recall | Sensitivity | True Positive Rate | Hit rate</h2><span id='topic+recall'></span><span id='topic+TPR'></span><span id='topic+sensitivity'></span><span id='topic+hitrate'></span><span id='topic+FNR'></span>

<h3>Description</h3>

<p><code>recall</code> estimates the recall (a.k.a. sensitivity, true
positive rate -TPR-, or hit rate) for a nominal/categorical predicted-observed dataset.
</p>
<p><code>TPR</code> alternative to <code>recall()</code>.
</p>
<p><code>sensitivity</code> alternative to <code>recall()</code>.
</p>
<p><code>hitrate</code> alternative to <code>recall()</code>.
</p>
<p><code>FNR</code> estimates false negative rate (or false alarm, or fall-out)
for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recall(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

TPR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

sensitivity(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

hitrate(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

FNR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recall_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="recall_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="recall_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="recall_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="recall_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="recall_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="recall_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>recall</code> (a.k.a. sensitivity or true positive rate -TPR-) is a
non-normalized coefficient that represents the ratio between the correctly
predicted cases (true positives -TP-) to the total number of actual observations
that belong to a given class (actual positives -P-).
</p>
<p>For binomial cases, <code class="reqn">recall  =  \frac{TP}{P} = \frac{TP}{TP + FN} </code>
</p>
<p>The <code>recall</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low performance. It can be either estimated for
each particular class or at a global level.
</p>
<p>Metrica offers 4 identical alternative functions that do the same job: i) <code>recall</code>,
ii) <code>sensitivity</code>, iii) <code>TPR</code>, and iv) <code>hitrate</code>. However, consider
when using <code>metrics_summary</code>, only the <code>recall</code> alternative is used.
</p>
<p>The false negative rate (or false alarm, or fall-out) is the complement of the
recall, representing the ratio between the number of false negatives (FN)
to the actual number of positives (P). The <code>FNR</code> formula is:
</p>
<p><code class="reqn">FNR = 1 - recall = 1 - TPR = \frac{FN}{P}</code>
</p>
<p>The <code>fpr</code> is bounded between 0 and 1. The closer to 0 the better. Low performance
is indicated with fpr &gt; 0.5.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Ting K.M. (2017)
Precision and Recall.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_659">doi:10.1007/978-1-4899-7687-1_659</a>
</p>
<p>Ting K.M. (2017).
Sensitivity.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-1-4899-7687-1_751">doi:10.1007/978-1-4899-7687-1_751</a>
</p>
<p>Trevethan, R. (2017).
<em>Sensitivity, Specificity, and Predictive Values: Foundations, Pliabilities, and Pitfalls</em>
_ in Research and Practice. Front. Public Health 5:307_ <a href="https://doi.org/10.3389/fpubh.2017.00307">doi:10.3389/fpubh.2017.00307</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))

# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE))

# Get recall estimate for two-class case at global level
recall(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get FNR estimate for two-class case at global level
FNR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get recall estimate for each class for the multi-class case at global level
recall(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE, 
atom = FALSE)

# Get recall estimate for the multi-class case at a class-level
recall(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE,
atom = TRUE)

</code></pre>

<hr>
<h2 id='RMAE'>Relative Mean Absolute Error (RMAE)</h2><span id='topic+RMAE'></span>

<h3>Description</h3>

<p>It estimates the RMAE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMAE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMAE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RMAE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RMAE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RMAE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RMAE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RMAE normalizes the Mean Absolute Error (MAE) by the mean of observations.
The closer to zero the lower the prediction error.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RMAE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RMLA'>Root Mean Lack of Accuracy (RMLA)</h2><span id='topic+RMLA'></span>

<h3>Description</h3>

<p>It estimates the RMLA, the square root of the systematic error
component to the Mean Squared Error (MSE), for a continuous predicted-observed
dataset following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMLA(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMLA_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RMLA_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RMLA_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RMLA_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RMLA_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RMLA represents the systematic (bias) component of the MSE
expressed into the original variable units.
It is obtained via a symmetric decomposition of the MSE (invariant to
predicted-observed orientation) using a symmetric regression line (SMA).
The RMLA is equal to the square-root of the sum of systematic differences
divided by the sample size (n).
The greater the value the greater the bias of the predictions.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RMLA(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RMLP'>Root Mean Lack of Precision (RMLP)</h2><span id='topic+RMLP'></span>

<h3>Description</h3>

<p>It estimates the RMLP, the square root of the unsystematic error
component to the Mean Squared Error (MSE), for a continuous predicted-observed
dataset following Correndo et al. (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMLP(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMLP_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RMLP_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RMLP_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RMLP_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RMLP_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RMLP represents the unsystematic (random) component of the MSE
expressed on the original variables units <code class="reqn"> \sqrt{MLP} </code>.
It is obtained via a symmetric decomposition of the MSE (invariant to
predicted-observed orientation) using a symmetric regression line (SMA).
The RMLP is equal to the square-root of the sum of unsystematic differences
divided by the sample size (n). The greater the value the greater the random
noise of the predictions.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Correndo et al. (2021).
Revisiting linear regression to test agreement in continuous predicted-observed datasets.
<em>Agric. Syst. 192, 103194.</em> <a href="https://doi.org/10.1016/j.agsy.2021.103194">doi:10.1016/j.agsy.2021.103194</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RMLP(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RMSE'>Root Mean Squared Error (RMSE)</h2><span id='topic+RMSE'></span>

<h3>Description</h3>

<p>It estimates the RMSE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RMSE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RMSE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RMSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RMSE is one of the most widely used error metrics in literature to
evaluate prediction performance. It measures general agreement, being sensitive to
both lack of precision and lack of accuracy. It is simply the square root of
the Mean Squared Error (MSE). Thus, it presents the same units as the variable of
interest, facilitating the interpretation. It goes from 0 to infinity. The lower
the value the better the prediction performance. Its counterpart is being very
sensitive to outliers.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RMSE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RRMSE'>Relative Root Mean Squared Error (RMSE)</h2><span id='topic+RRMSE'></span>

<h3>Description</h3>

<p>It estimates the RRMSE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RRMSE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RRMSE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RRMSE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RRMSE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RRMSE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RRMSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RRMSE normalizes the Root Mean Squared Error (RMSE) by the mean
of observations. It goes from 0 to infinity. The lower the better the prediction performance.
In literature, it can be also found as NRMSE (normalized root mean squared error).
However, here we use RRMSE since several other alternatives to
&quot;normalize&quot; the RMSE exist (e.g., RSR, iqRMSE).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RRMSE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RSE'>Relative Squared Error (RSE)</h2><span id='topic+RSE'></span>

<h3>Description</h3>

<p>It estimates the RSE for a continuous predicted-observer dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RSE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RSE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RSE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RSE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RSE is the ratio between the residual sum of squares (RSS, error of
predictions with respect to observations) and the total sum of squares (TSS,
error of observations with respect to its mean). RSE is dimensionless, so it can be
used to compared models with different units.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RSE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RSR'>Root Mean Standard Deviation Ratio (RSR)</h2><span id='topic+RSR'></span>

<h3>Description</h3>

<p>It estimates the MSE normalized by the standard deviation of observed values
following Moriasi et al. (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSR(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSR_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RSR_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RSR_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RSR_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RSR_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RSR normalizes the Root Mean Squared Error (RMSE) using the standard
deviation of observed values. It goes from an optimal value of 0 to infinity.
Based on RSR, Moriasi et al. (2007) indicates performance ratings as:
i) very-good (0-0.50), ii) good (0.50-0.60), iii) satisfactory (0.60-0.70), or
iv) unsatisfactory (&gt;0.70).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Moriasi et al. (2007).
Model Evaluation Guidelines for Systematic Quantification of Accuracy in Watershed Simulations.
<em>Trans. ASABE 50, 885–900.</em> <a href="https://doi.org/10.13031/2013.23153">doi:10.13031/2013.23153</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RSR(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='RSS'>Residual Sum of Squares (RSS)</h2><span id='topic+RSS'></span>

<h3>Description</h3>

<p>It estimates the RSS for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSS(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSS_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="RSS_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="RSS_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="RSS_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="RSS_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RSS is the sum of the squared differences between predictions and observations.
It represents the base of many error metrics using squared scale such as the Mean Squared Error (MSE).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
RSS(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='SB'>Squared bias (SB)</h2><span id='topic+SB'></span>

<h3>Description</h3>

<p>It estimates the SB component of the Mean Squared Error (MSE)
proposed by Kobayashi &amp; Salam (2000).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SB(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SB_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="SB_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="SB_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="SB_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="SB_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SB represents the additive bias component of the prediction error
following Kobayashi &amp; Salam (2000). It is in square units of the variable of interest, so
it does not have a direct interpretation. The lower the value the less contribution to the MSE.
However, it needs to be compared to MSE as its benchmark.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Kobayashi &amp; Salam (2000).
Comparing simulated and measured values using mean squared deviation and its components.
<em>Agron. J. 92, 345–352.</em> <a href="https://doi.org/10.2134/agronj2000.922345x">doi:10.2134/agronj2000.922345x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 9)
SB(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='scatter_plot'>Scatter plot of predicted and observed values</h2><span id='topic+scatter_plot'></span>

<h3>Description</h3>

<p>It draws a scatter plot of predictions and observations with alternative
axis orientation (P vs. O; O vs. P).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scatter_plot(
  data = NULL,
  obs,
  pred,
  orientation = "PO",
  print_metrics = FALSE,
  metrics_list = NULL,
  position_metrics = c(x = NULL, y = NULL),
  print_eq = TRUE,
  position_eq = c(x = NULL, y = NULL),
  eq_color = NULL,
  shape_type = NULL,
  shape_size = NULL,
  shape_color = NULL,
  regline_type = NULL,
  regline_size = NULL,
  regline_color = NULL,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scatter_plot_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame with the data.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_orientation">orientation</code></td>
<td>
<p>Argument of class string specifying the axis
orientation, PO for predicted vs observed, and OP for
observed vs predicted. Default is orientation = &quot;PO&quot;.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_print_metrics">print_metrics</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_metrics_list">metrics_list</code></td>
<td>
<p>vector or list of selected metrics to print on the plot.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_position_metrics">position_metrics</code></td>
<td>
<p>vector or list with '(x,y)' coordinates to locate the
metrics_table into the plot.
Default : c(x = min(obs), y = 1.05*max(pred)).</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_print_eq">print_eq</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_position_eq">position_eq</code></td>
<td>
<p>vector or list with '(x,y)' coordinates to locate the
SMA equation into the plot.
Default : c(x = 0.70 max(x), y = 1.25*min(y)).</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_eq_color">eq_color</code></td>
<td>
<p>string indicating the color of the SMA-regression text.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_shape_type">shape_type</code></td>
<td>
<p>integer indicating the shape type for the data points.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_shape_size">shape_size</code></td>
<td>
<p>number indicating the shape size for the data points.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_shape_color">shape_color</code></td>
<td>
<p>string indicating the shape color for the data points.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_regline_type">regline_type</code></td>
<td>
<p>string or integer indicating the SMA-regression line-type.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_regline_size">regline_size</code></td>
<td>
<p>number indicating the SMA-regression line size.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_regline_color">regline_color</code></td>
<td>
<p>string indicating the SMA-regression line color.</p>
</td></tr>
<tr><td><code id="scatter_plot_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It creates a scatter plot of predicted vs. observed values. The plot also includes
the 1:1 line (solid line) and the linear regression line (dashed line). By default,
it places the observed on the x-axis and the predicted on the y-axis (orientation = &quot;PO&quot;).
This can be inverted by changing the argument orientation = “OP&quot;.
For more details, see <a href="https://adriancorrendo.github.io/metrica/">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>ggplot</code>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,<code><a href="ggplot2.html#topic+geom_point">geom_point</a></code>,<code><a href="ggplot2.html#topic+aes">aes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 10)
scatter_plot(obs = X, pre = Y)

</code></pre>

<hr>
<h2 id='SDSD'>Squared difference between standard deviations (SDSD)</h2><span id='topic+SDSD'></span>

<h3>Description</h3>

<p>It estimates the SDSD component of the Mean Squared Error (MSE)
proposed by Kobayashi &amp; Salam (2000).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SDSD(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SDSD_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="SDSD_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="SDSD_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="SDSD_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="SDSD_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SDSD represents the proportional bias component of the prediction error
following Kobayashi &amp; Salam (2000). It is in square units of the variable of interest, so
it does not have a direct interpretation. The lower the value the less contribution to the MSE.
However, it needs to be compared to MSE as its benchmark.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Kobayashi &amp; Salam (2000).
Comparing simulated and measured values using mean squared deviation and its components.
<em>Agron. J. 92, 345–352.</em> <a href="https://doi.org/10.2134/agronj2000.922345x">doi:10.2134/agronj2000.922345x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
SDSD(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='SMAPE'>Symmetric Mean Absolute Percentage Error (SMAPE).</h2><span id='topic+SMAPE'></span>

<h3>Description</h3>

<p>It estimates the SMAPE for a continuous predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SMAPE(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SMAPE_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="SMAPE_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="SMAPE_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="SMAPE_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="SMAPE_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The SMAPE (%) is a normalized, dimensionless, and bounded (0% to 200%).
It is a modification of the MAPE where the denominator is half
of the sum of absolute differences between observations and predictions.
This modification solves the problem of MAPE of producing negative or undefined values.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Makridakis (1993).
Accuracy measures: theoretical and practical concerns.
<em>Int. J. Forecast. 9, 527-529.</em> <a href="https://doi.org/10.1016/0169-2070%2893%2990079-3">doi:10.1016/0169-2070(93)90079-3</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
SMAPE(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='sorghum'>Sorghum grain number</h2><span id='topic+sorghum'></span>

<h3>Description</h3>

<p>This example dataset is a set of APSIM simulations of
sorghum grain number (x1000 grains per squared meter), which exhibits
both low accuracy and low precision as it represents a model still
under development. The experimental trials come from 6 site-years in
1 country (Australia).
These data correspond to the latest, up-to-date, documentation and
validation of version number 2020.03.27.4956. Data available at:
<a href="https://doi.org/10.7910/DVN/EJS4M0">doi:10.7910/DVN/EJS4M0</a>.
Further details can be found at the official APSIM Next Generation
website:
<a href="https://APSIMnextgeneration.netlify.app/modeldocumentation/">https://APSIMnextgeneration.netlify.app/modeldocumentation/</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sorghum
</code></pre>


<h3>Format</h3>

<p>This data frame has 36 rows and the following 2 columns:
</p>

<dl>
<dt>pred</dt><dd><p>predicted values</p>
</dd>
<dt>obs</dt><dd><p>observed values</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/adriancorrendo/metrica">https://github.com/adriancorrendo/metrica</a>
</p>

<hr>
<h2 id='specificity'>Specificity  | Selectivity | True Negative Rate</h2><span id='topic+specificity'></span><span id='topic+selectivity'></span><span id='topic+TNR'></span><span id='topic+FPR'></span>

<h3>Description</h3>

<p><code>specificity</code> estimates the specificity (a.k.a. selectivity,
or true negative rate -TNR-)
for a nominal/categorical predicted-observed dataset.
</p>
<p><code>selectivity</code> alternative to <code>specificity()</code>.
</p>
<p><code>TNR</code> alternative to <code>specificity()</code>.
</p>
<p><code>FPR</code> estimates the false positive rate (a.k.a fall-out or false alarm)
for a nominal/categorical predicted-observed dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>specificity(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

selectivity(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

TNR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)

FPR(
  data = NULL,
  obs,
  pred,
  atom = FALSE,
  pos_level = 2,
  tidy = FALSE,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="specificity_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="specificity_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (character | factor).</p>
</td></tr>
<tr><td><code id="specificity_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (character | factor).</p>
</td></tr>
<tr><td><code id="specificity_+3A_atom">atom</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide if the estimate is made for
each class (atom = TRUE) or at a global level (atom = FALSE); Default : FALSE.
When dataset is &quot;binomial&quot; atom does not apply.</p>
</td></tr>
<tr><td><code id="specificity_+3A_pos_level">pos_level</code></td>
<td>
<p>Integer, for binary cases, indicating the order (1|2) of the level
corresponding to the positive. Generally, the positive level is the second (2)
since following an alpha-numeric order, the most common pairs are
<code>(Negative | Positive)</code>, <code>(0 | 1)</code>, <code>(FALSE | TRUE)</code>. Default : 2.</p>
</td></tr>
<tr><td><code id="specificity_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="specificity_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The specificity (or selectivity, or true negative rate-TNR-) is a non-normalized
coefficient that represents the ratio between the correctly negative predicted
cases (or true negative -TN- for binary cases) to the total number of actual
observations not belonging to a given class (actual negatives -N- for binary cases).
</p>
<p>For binomial cases, <code class="reqn">specificity  =  \frac{TN}{N} = \frac{TN}{TN+FP}</code>
</p>
<p>The <code>specificity</code> metric is bounded between 0 and 1. The closer to 1 the better.
Values towards zero indicate low performance. For multinomial cases, it can be
either estimated for each particular class or at a global level.
</p>
<p>Metrica offers 3 identical alternative functions that do the same job: i) <code>specificity</code>,
ii) <code>selectivity</code>, and iii) <code>TNR</code>. However, consider
when using <code>metrics_summary</code>, only the <code>specificity</code> alternative is used.
</p>
<p>The false positive rate (or false alarm, or fall-out) is the complement of the
specificity, representing the ratio between the number of false positives (FP)
to the actual number of negatives (N). The <code>FPR</code> formula is:
</p>
<p><code class="reqn">FPR = 1 - specificity = 1 - TNR = \frac{FP}{N}</code>
</p>
<p>The <code>FPR</code> is bounded between 0 and 1. The closer to 0 the better. Low performance
is indicated with FPR &gt; 0.5.
</p>
<p>For the formula and more details, see
<a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_classification.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Ting K.M. (2017)
Sensitivity and Specificity.
<em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining.</em>
<em>Springer, Boston, MA.</em> <a href="https://doi.org/10.1007/978-0-387-30164-8_752">doi:10.1007/978-0-387-30164-8_752</a>
</p>
<p>Trevethan, R. (2017).
<em>Sensitivity, Specificity, and Predictive Values: Foundations, Pliabilities, and Pitfalls</em>
_ in Research and Practice. Front. Public Health 5:307_ <a href="https://doi.org/10.3389/fpubh.2017.00307">doi:10.3389/fpubh.2017.00307</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
# Two-class
binomial_case &lt;- data.frame(labels = sample(c("True","False"), 100, 
replace = TRUE), predictions = sample(c("True","False"), 100, replace = TRUE))
# Multi-class
multinomial_case &lt;- data.frame(labels = sample(c("Red","Blue", "Green"), 100, 
replace = TRUE), predictions = sample(c("Red","Blue", "Green"), 100, replace = TRUE)    )

# Get specificity and FPR estimates for two-class case
specificity(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)
FPR(data = binomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get specificity estimate for each class for the multi-class case
specificity(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

# Get specificity estimate for the multi-class case at a global level
specificity(data = multinomial_case, obs = labels, pred = predictions, tidy = TRUE)

</code></pre>

<hr>
<h2 id='tiles_plot'>Tiles plot of predicted and observed values</h2><span id='topic+tiles_plot'></span>

<h3>Description</h3>

<p>It draws a tiles plot of predictions and observations with alternative
axis orientation (P vs. O; O vs. P).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tiles_plot(
  data = NULL,
  obs,
  pred,
  bins = 10,
  colors = c(low = NULL, high = NULL),
  orientation = "PO",
  print_metrics = FALSE,
  metrics_list = NULL,
  position_metrics = c(x = NULL, y = NULL),
  print_eq = TRUE,
  position_eq = c(x = NULL, y = NULL),
  eq_color = NULL,
  regline_type = NULL,
  regline_size = NULL,
  regline_color = NULL,
  na.rm = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tiles_plot_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_bins">bins</code></td>
<td>
<p>Argument of class numeric specifying the number of bins to create the tiles.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_colors">colors</code></td>
<td>
<p>Vector or list with two colors '(low, high)' to paint the density gradient.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_orientation">orientation</code></td>
<td>
<p>Argument of class string specifying the axis
orientation, PO for predicted vs observed, and OP for
observed vs predicted. Default is orientation = &quot;PO&quot;.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_print_metrics">print_metrics</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_metrics_list">metrics_list</code></td>
<td>
<p>vector or list of selected metrics to print on the plot.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_position_metrics">position_metrics</code></td>
<td>
<p>vector or list with '(x,y)' coordinates to locate the metrics_table into the plot.
Default : c(x = min(obs), y = 1.05*max(pred)).</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_print_eq">print_eq</code></td>
<td>
<p>boolean TRUE/FALSE to embed metrics in the plot. Default is FALSE.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_position_eq">position_eq</code></td>
<td>
<p>vector or list with '(x,y)' coordinates to locate the SMA equation into the plot.
Default : c(x = 0.70 max(x), y = 1.25*min(y)).</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_eq_color">eq_color</code></td>
<td>
<p>string indicating the color of the SMA-regression text.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_regline_type">regline_type</code></td>
<td>
<p>string or integer indicating the SMA-regression line-type.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_regline_size">regline_size</code></td>
<td>
<p>number indicating the SMA-regression line size.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_regline_color">regline_color</code></td>
<td>
<p>string indicating the SMA-regression line color.</p>
</td></tr>
<tr><td><code id="tiles_plot_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It creates a tiles plot of predicted vs. observed values. The plot also includes
the 1:1 line (solid line) and the linear regression line (dashed line). By default,
it places the observed on the x-axis and the predicted on the y-axis (orientation = &quot;PO&quot;).
This can be inverted by changing the argument orientation = “OP&quot;.
For more details, see <a href="https://adriancorrendo.github.io/metrica/">online-documentation</a>
</p>


<h3>Value</h3>

<p>Object of class <code>ggplot</code>.
</p>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+ggplot">ggplot</a></code>,<code><a href="ggplot2.html#topic+geom_point">geom_point</a></code>,<code><a href="ggplot2.html#topic+aes">aes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- rnorm(n = 100, mean = 0, sd = 10)
tiles_plot(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='TSS'>Total Sum of Squares (TSS)</h2><span id='topic+TSS'></span>

<h3>Description</h3>

<p>It estimates the TSS for observed vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSS(data = NULL, obs, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSS_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="TSS_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="TSS_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="TSS_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The TSS sum of the squared differences between the observations and its mean.
It is used as a reference error, for example, to estimate explained variance.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
TSS(obs = X)

</code></pre>

<hr>
<h2 id='Ub'>Mean Bias Error Proportion (Ub)</h2><span id='topic+Ub'></span>

<h3>Description</h3>

<p>It estimates the Ub component from the sum of squares decomposition
described by Smith &amp; Rose (1995).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ub(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ub_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="Ub_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="Ub_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="Ub_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="Ub_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Ub estimates the proportion of the total sum of squares related to the
mean bias following the sum of squares decomposition suggested by Smith and
Rose (1995) also known as Theil's partial inequalities.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Smith &amp; Rose (1995).
Model goodness-of-fit analysis using regression and related techniques.
<em>Ecol. Model. 77, 49–64.</em> <a href="https://doi.org/10.1016/0304-3800%2893%29E0074-D">doi:10.1016/0304-3800(93)E0074-D</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
Ub(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='Uc'>Lack of Consistency (Uc)</h2><span id='topic+Uc'></span>

<h3>Description</h3>

<p>It estimates the Uc component from the sum of squares decomposition
described by Smith &amp; Rose (1995).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Uc(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Uc_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="Uc_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="Uc_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="Uc_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="Uc_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Uc estimates the proportion of the total sum of squares related to the
lack of consistency (proportional bias) following the sum of squares decomposition
suggested by Smith and Rose (1995) also known as Theil's partial inequalities.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Smith &amp; Rose (1995).
Model goodness-of-fit analysis using regression and related techniques.
<em>Ecol. Model. 77, 49–64.</em> <a href="https://doi.org/10.1016/0304-3800%2893%29E0074-D">doi:10.1016/0304-3800(93)E0074-D</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
Uc(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='Ue'>Lack of Consistency (Ue)</h2><span id='topic+Ue'></span>

<h3>Description</h3>

<p>It estimates the Ue component from the sum of squares decomposition
described by Smith &amp; Rose (1995).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ue(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ue_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="Ue_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="Ue_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="Ue_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="Ue_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
The Ue estimates the proportion of the total sum of squares related to the
random error (unsystematic error or variance) following the sum of squares decomposition
suggested by Smith and Rose (1995) also known as Theil's partial inequalities.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>References</h3>

<p>Smith &amp; Rose (1995).
Model goodness-of-fit analysis using regression and related techniques.
<em>Ecol. Model. 77, 49–64.</em> <a href="https://doi.org/10.1016/0304-3800%2893%29E0074-D">doi:10.1016/0304-3800(93)E0074-D</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
Ue(obs = X, pred = Y)

</code></pre>

<hr>
<h2 id='uSD'>Uncorrected Standard Deviation</h2><span id='topic+uSD'></span>

<h3>Description</h3>

<p>It estimates the (uSD) of observed or predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uSD(data = NULL, x, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uSD_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="uSD_+3A_x">x</code></td>
<td>
<p>Vector with numeric observed or predicted values.</p>
</td></tr>
<tr><td><code id="uSD_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="uSD_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The uSD is the sample, uncorrected standard deviation. The square root of
the mean of sum of squared differences between vector values with respect to their mean.
It is uncorrected because it is divided by the sample size (n), not n-1.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
uSD(x = X)

</code></pre>

<hr>
<h2 id='var_u'>Uncorrected Variance (var_u)</h2><span id='topic+var_u'></span>

<h3>Description</h3>

<p>It estimates the var_u of observed or predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>var_u(data = NULL, x, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="var_u_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="var_u_+3A_x">x</code></td>
<td>
<p>Vector with numeric elements.</p>
</td></tr>
<tr><td><code id="var_u_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="var_u_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The var_u is the sample, uncorrected variance. It is calculated as the mean
of sum of squared differences between values of an x and its mean, divided by the sample size (n).
It is uncorrected because it is divided by n, and by not n-1 (traditional variance).
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
var_u(x = X)

</code></pre>

<hr>
<h2 id='wheat'>Wheat grain nitrogen</h2><span id='topic+wheat'></span>

<h3>Description</h3>

<p>This example dataset is a set of APSIM simulations of
wheat grain N (grams per squared meter), which presents both high
accuracy and high precision. The experimental trials come from 11
site-years in 4 countries (Australia, Ethiopia, New Zealand, and
Turkey).
These data correspond to the latest, up-to-date, documentation and
validation of version number 2020.03.27.4956. Data available at:
<a href="https://doi.org/10.7910/DVN/EJS4M0">doi:10.7910/DVN/EJS4M0</a>.
Further details can be found at the official APSIM Next Generation
website:
<a href="https://APSIMnextgeneration.netlify.app/modeldocumentation/">https://APSIMnextgeneration.netlify.app/modeldocumentation/</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wheat
</code></pre>


<h3>Format</h3>

<p>This data frame has 137 rows and the following 2 columns:
</p>

<dl>
<dt>pred</dt><dd><p>predicted values</p>
</dd>
<dt>obs</dt><dd><p>observed values</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://github.com/adriancorrendo/metrica">https://github.com/adriancorrendo/metrica</a>
</p>

<hr>
<h2 id='Xa'>Accuracy Component (Xa) of CCC</h2><span id='topic+Xa'></span>

<h3>Description</h3>

<p>It estimates the Xa component for the calculation of the Concordance
Correlation Coefficient (CCC) following Lin (1989).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Xa(data = NULL, obs, pred, tidy = FALSE, na.rm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Xa_+3A_data">data</code></td>
<td>
<p>(Optional) argument to call an existing data frame containing the data.</p>
</td></tr>
<tr><td><code id="Xa_+3A_obs">obs</code></td>
<td>
<p>Vector with observed values (numeric).</p>
</td></tr>
<tr><td><code id="Xa_+3A_pred">pred</code></td>
<td>
<p>Vector with predicted values (numeric).</p>
</td></tr>
<tr><td><code id="Xa_+3A_tidy">tidy</code></td>
<td>
<p>Logical operator (TRUE/FALSE) to decide the type of return. TRUE
returns a data.frame, FALSE returns a list; Default : FALSE.</p>
</td></tr>
<tr><td><code id="Xa_+3A_na.rm">na.rm</code></td>
<td>
<p>Logic argument to remove rows with missing values
(NA). Default is na.rm = TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Xa measures accuracy of prediction. It goes from 0 (completely inaccurate) to 1 (perfectly accurate).
It is used to adjust the precision measured by the correlation coefficient (r)
in order to evaluate agreement through the CCC.
For the formula and more details, see <a href="https://adriancorrendo.github.io/metrica/articles/available_metrics_regression.html">online-documentation</a>
</p>


<h3>Value</h3>

<p>an object of class <code>numeric</code> within a <code>list</code> (if tidy = FALSE) or within a
<code style="white-space: pre;">&#8288;data frame&#8288;</code> (if tidy = TRUE).
</p>


<h3>References</h3>

<p>Lin (1989).
A concordance correlation coefficient to evaluate reproducibility.
<em>Biometrics 45 (1), 255–268.</em> <a href="https://doi.org/10.2307/2532051">doi:10.2307/2532051</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(1)
X &lt;- rnorm(n = 100, mean = 0, sd = 10)
Y &lt;- X + rnorm(n=100, mean = 0, sd = 3)
Xa(obs = X, pred = Y)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
