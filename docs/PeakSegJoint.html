<!DOCTYPE html><html><head><title>Help for package PeakSegJoint</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PeakSegJoint}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#binSum'><p>binSum</p></a></li>
<li><a href='#chr7.peaks'>
<p>chr7 peaks</p></a></li>
<li><a href='#clusterPeaks'><p>clusterPeaks</p></a></li>
<li><a href='#ConvertModelList'><p>ConvertModelList</p></a></li>
<li><a href='#demo.profiles'>
<p>Demo profiles</p></a></li>
<li><a href='#featureMatrixJoint'><p>featureMatrixJoint</p></a></li>
<li><a href='#GeomTallRect'><p>GeomTallRect</p></a></li>
<li><a href='#H3K27ac.TDH.MMM4'>
<p>Some histone ChIP-seq data</p></a></li>
<li><a href='#H3K36me3.AM.immune.chunk21'>
<p>H3K36me3_AM_immune chunk 21</p></a></li>
<li><a href='#H3K36me3.TDH.other.chunk1'>
<p>H3K36me3 TDH other chunk 1</p></a></li>
<li><a href='#H3K4me3.PGP.immune.chunk2'>
<p>H3K4me3 PGP immune chunk 2</p></a></li>
<li><a href='#H3K4me3.TDH.other.chunk8'>
<p>H3K4me3_TDH_other chunk 8 subset</p></a></li>
<li><a href='#multiClusterPeaks'><p>multiClusterPeaks</p></a></li>
<li><a href='#overflow.list'>
<p>Data set that caused integer overflow</p></a></li>
<li><a href='#peak.at.profile.end'>
<p>peak at profile end</p></a></li>
<li><a href='#peak1.infeasible'>
<p>data where the PeakSegJoint model with 1 peak is infeasible</p></a></li>
<li><a href='#PeakErrorSamples'><p>PeakErrorSamples</p></a></li>
<li><a href='#PeakSegJointError'><p>PeakSegJointError</p></a></li>
<li><a href='#PeakSegJointFaster'><p>PeakSegJointFaster</p></a></li>
<li><a href='#PeakSegJointFasterOne'><p>PeakSegJointFasterOne</p></a></li>
<li><a href='#PeakSegJointHeuristic'><p>PeakSegJointHeuristic</p></a></li>
<li><a href='#PeakSegJointHeuristicStep1'><p>PeakSegJointHeuristicStep1</p></a></li>
<li><a href='#PeakSegJointHeuristicStep2'><p>PeakSegJointHeuristicStep2</p></a></li>
<li><a href='#PeakSegJointSeveral'><p>PeakSegJointSeveral</p></a></li>
<li><a href='#PoissonLoss'><p>PoissonLoss</p></a></li>
<li><a href='#ProfileList'><p>ProfileList</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Toby Dylan Hocking &lt;toby.hocking@r-project.org&gt;</td>
</tr>
<tr>
<td>Author:</td>
<td>Toby Dylan Hocking</td>
</tr>
<tr>
<td>Version:</td>
<td>2024.1.24</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tdhock/PeakSegJoint">https://github.com/tdhock/PeakSegJoint</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tdhock/PeakSegJoint/issues">https://github.com/tdhock/PeakSegJoint/issues</a></td>
</tr>
<tr>
<td>Title:</td>
<td>Joint Peak Detection in Several ChIP-Seq Samples</td>
</tr>
<tr>
<td>Description:</td>
<td>Jointly segment several ChIP-seq samples to find the peaks 
 which are the same and different across samples. The fast approximate
 maximum Poisson likelihood algorithm is described in
 "PeakSegJoint: fast supervised peak detection via joint segmentation
 of multiple count data samples"
 &lt;<a href="https://doi.org/10.48550/arXiv.1506.01286">doi:10.48550/arXiv.1506.01286</a>&gt; by TD Hocking and G Bourque.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, ggplot2 (&ge; 2.0), microbenchmark</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14)</td>
</tr>
<tr>
<td>Imports:</td>
<td>PeakError, parallel, penaltyLearning</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-24 18:17:40 UTC; th798</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-24 19:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='binSum'>binSum</h2><span id='topic+binSum'></span>

<h3>Description</h3>

<p>Compute sum of <code>compressed</code> coverage profile in bins, using fast C
code.</p>


<h3>Usage</h3>

<pre><code class='language-R'>binSum(compressed, bin.chromStart = 0L, 
    bin.size = 1L, n.bins = 2000L, 
    empty.as.zero = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binSum_+3A_compressed">compressed</code></td>
<td>
<p>data.frame with integer columns chromStart, chromEnd, count.</p>
</td></tr>
<tr><td><code id="binSum_+3A_bin.chromstart">bin.chromStart</code></td>
<td>
<p>Base before first bin.</p>
</td></tr>
<tr><td><code id="binSum_+3A_bin.size">bin.size</code></td>
<td>
<p>Bin size.</p>
</td></tr>
<tr><td><code id="binSum_+3A_n.bins">n.bins</code></td>
<td>
<p>Number of bins.</p>
</td></tr>
<tr><td><code id="binSum_+3A_empty.as.zero">empty.as.zero</code></td>
<td>
<p>Sometimes the last few bins do not have any overlapping data in
<code>compressed</code>. If TRUE, set these counts to 0. If FALSE, ignore these
bins (returning a data.frame with fewer than <code>n.bins</code> rows).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame with <code>n.bins</code> rows and columns chromStart, chromEnd,
count, mean.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>## bins of size 3bp.
## -1-   -3-   -5-
##    -2-   -4-
## 123456789012345 base index.
## --2---
##       --1-
##           --0-------
## Coverage profile.
profile &lt;- data.frame(chromStart=as.integer(c(0, 6, 10)),
                      chromEnd=as.integer(c(6, 10, 10000)),
                      count=as.integer(c(2, 1, 0)))
library(PeakSegJoint)
bins &lt;- binSum(profile,
               bin.chromStart=0L,
               bin.size=3L,
               n.bins=2000L)
library(ggplot2)
bases &lt;- data.frame(position=1:15, base="N")
ggplot()+
  ylab("")+
  geom_text(aes(position, 0, label=base),
            data=bases)+
  geom_step(aes(chromStart+0.5, count, color=what),
            data=data.frame(profile, what="profile"),
            size=2)+
  geom_step(aes(chromStart+0.5, count, color=what),
            data=data.frame(bins, what="bin total"))+
  geom_step(aes(chromStart+0.5, mean, color=what),
            data=data.frame(bins, what="bin mean"))+
  coord_cartesian(xlim=c(0, max(bases$position)))
</code></pre>

<hr>
<h2 id='chr7.peaks'>
chr7 peaks
</h2><span id='topic+chr7.peaks'></span>

<h3>Description</h3>

<p>peaks predicted by PeakSegFPOP on chr7:50410631-53200000 in the
H3K36me3_TDH_immune data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("chr7.peaks")</code></pre>


<h3>Format</h3>

<p>A data frame with 41 observations on the following 3 variables.
</p>

<dl>
<dt><code>sample.id</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>chromStart</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>chromEnd</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='clusterPeaks'>clusterPeaks</h2><span id='topic+clusterPeaks'></span>

<h3>Description</h3>

<p>Cluster <code>peaks</code> into overlapping groups.</p>


<h3>Usage</h3>

<pre><code class='language-R'>clusterPeaks(peaks)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clusterPeaks_+3A_peaks">peaks</code></td>
<td>
<p>data.frame with columns chromStart, chromEnd.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>peaks</code> data.frame, sorted by chromStart, with an additional column
cluster.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>unordered &lt;-
  data.frame(chromStart=c(11, 12, 1, 2, 3, 6, 7),
             chromEnd=c(13, 14, 5, 8, 4, 9, 10),
             sample.id=factor(paste0("sample.", c(1, 2, 1, 2, 3, 4, 5))))
clustered &lt;- clusterPeaks(unordered)
library(ggplot2)
bases &lt;- geom_text(aes(position, "base", label=base),
                   data=data.frame(position=1:20, base="N"))
gg &lt;- ggplot()+bases+ylab("")+
  scale_x_continuous(breaks=1:20)

gg+
  geom_segment(aes(chromStart+1/2, sample.id,
                   xend=chromEnd+1/2, yend=sample.id),
                   data=clustered)+
  theme_bw()+
  theme(panel.margin=grid::unit(0, "cm"))+
  facet_grid(.~cluster, labeller=label_both, scales="free", space="free")

gg+
  geom_segment(aes(chromStart+1/2, sample.id,
                   xend=chromEnd+1/2, yend=sample.id, color=factor(cluster)),
                   data=clustered)
</code></pre>

<hr>
<h2 id='ConvertModelList'>ConvertModelList</h2><span id='topic+ConvertModelList'></span>

<h3>Description</h3>

<p>Convert a model list from the non-repetitive format that we get
from the C code to the repetitive format that is more useful for
plotting.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConvertModelList(model.list)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConvertModelList_+3A_model.list">model.list</code></td>
<td>
<p>List from PeakSegJointHeuristic(...) or PeakSegJointSeveral(...).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of data.frames: segments has 1 row for each segment mean,
sample, and model size (peaks, sample.id, sample.group,
chromStart, chromEnd, mean); peaks is the same kind of data.frame
as segments, but with only the second/peak segments; loss has one
row for each model size; modelSelection has one row for each model
size that can be selected, see exactModelSelection.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>

<hr>
<h2 id='demo.profiles'>
Demo profiles
</h2><span id='topic+demo.profiles'></span>

<h3>Description</h3>

<p>These profiles resulted in negative means in a buggy version of the
PeakSegJointFaster code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("demo.profiles")</code></pre>


<h3>Format</h3>

<p>A data frame with 51204 observations on the following 5 variables.
</p>

<dl>
<dt><code>sample.id</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>sample.group</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>chromStart</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>chromEnd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>count</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='featureMatrixJoint'>featureMatrixJoint</h2><span id='topic+featureMatrixJoint'></span>

<h3>Description</h3>

<p>Compute the feature matrix for this joint segmentation problem.</p>


<h3>Usage</h3>

<pre><code class='language-R'>featureMatrixJoint(profile.list)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="featureMatrixJoint_+3A_profile.list">profile.list</code></td>
<td>
<p>profile.list </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric feature matrix (samples x features).</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(PeakSegJoint)
data(H3K36me3.TDH.other.chunk1, envir=environment())
lims &lt;- c(43000000, 43200000) # left
some.counts &lt;-
  subset(H3K36me3.TDH.other.chunk1$counts,
         lims[1] &lt; chromEnd &amp; chromStart &lt; lims[2])
profile.list &lt;- ProfileList(some.counts)
featureMatrixJoint(profile.list)
</code></pre>

<hr>
<h2 id='GeomTallRect'>GeomTallRect</h2><span id='topic+GeomTallRect'></span>

<h3>Description</h3>

<p>ggproto object for geom_tallrect</p>


<h3>Usage</h3>

<pre><code class='language-R'>"GeomTallRect"</code></pre>

<hr>
<h2 id='H3K27ac.TDH.MMM4'>
Some histone ChIP-seq data
</h2><span id='topic+H3K27ac.TDH.MMM4'></span>

<h3>Description</h3>

<p>This is used in the package tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("H3K27ac.TDH.MMM4")</code></pre>


<h3>Format</h3>

<p>A data frame with 29905 observations on the following 5 variables.
</p>

<dl>
<dt><code>sample.id</code></dt><dd><p>a factor</p>
</dd>
<dt><code>chrom</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>chromStart</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>chromEnd</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>count</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='H3K36me3.AM.immune.chunk21'>
H3K36me3_AM_immune chunk 21
</h2><span id='topic+H3K36me3.AM.immune.chunk21'></span>

<h3>Description</h3>

<p>Should be able to detect a peak in all 21 samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("H3K36me3.AM.immune.chunk21")</code></pre>


<h3>Format</h3>

<p>A profile data frame with 198142 observations.
</p>


<h3>Source</h3>

<p>http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/ data set
H3K36me3_AM_immune chunk 21:
http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/H3K36me3_AM_immune/21/regions.png
</p>

<hr>
<h2 id='H3K36me3.TDH.other.chunk1'>
H3K36me3 TDH other chunk 1
</h2><span id='topic+H3K36me3.TDH.other.chunk1'></span>

<h3>Description</h3>

<p>8 ChIP-seq samples, some with peaks in some regions, some without.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("H3K36me3.TDH.other.chunk1")</code></pre>


<h3>Format</h3>

<p>named list of 2 data.frames: &quot;count&quot; contains the noisy data,
&quot;regions&quot; 
contains
the labels.
</p>


<h3>Source</h3>

<p>http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/
data set H3K36me3_TDH_other
chunk 1.
</p>

<hr>
<h2 id='H3K4me3.PGP.immune.chunk2'>
H3K4me3 PGP immune chunk 2
</h2><span id='topic+H3K4me3.PGP.immune.chunk2'></span>

<h3>Description</h3>

<p>In these data the heuristic algorithm does not recover a segmentation
with a peak for all samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("H3K4me3.PGP.immune.chunk2")</code></pre>


<h3>Format</h3>

<p>A profile data frame with 36760 observations.
</p>


<h3>Source</h3>

<p>http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/H3K4me3_PGP_immune/2/regions.png
</p>

<hr>
<h2 id='H3K4me3.TDH.other.chunk8'>
H3K4me3_TDH_other chunk 8 subset
</h2><span id='topic+H3K4me3.TDH.other.chunk8'></span>

<h3>Description</h3>

<p>It should be easy to recover a joint peak in at least 8 of the 10 samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("H3K4me3.TDH.other.chunk8")</code></pre>


<h3>Format</h3>

<p>A profile data frame (sample.id, chromStart, chromEnd, count)
with 19866 observations.
</p>


<h3>Source</h3>

<p>http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/ data set
H3K4me3_TDH_other, chunk 8.
http://cbio.ensmp.fr/~thocking/chip-seq-chunk-db/H3K4me3_TDH_other/8/regions.png 
</p>

<hr>
<h2 id='multiClusterPeaks'>multiClusterPeaks</h2><span id='topic+multiClusterPeaks'></span>

<h3>Description</h3>

<p>Cluster <code>peaks</code> into overlapping groups.</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiClusterPeaks(peaks)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multiClusterPeaks_+3A_peaks">peaks</code></td>
<td>
<p>data.frame with columns chromStart, chromEnd.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>peaks</code> data.frame, sorted by chromStart, with an additional column
cluster.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(PeakSegJoint)
data(chr7.peaks, envir=environment())
library(ggplot2)
ggplot()+
  geom_segment(aes(
    chromStart/1e3, sample.id,
    xend=chromEnd/1e3, yend=sample.id),
    data=chr7.peaks)

clustered &lt;- multiClusterPeaks(chr7.peaks)
clustered.list &lt;- split(clustered, clustered$cluster)
clusters.list &lt;- list()
for(cluster.name in names(clustered.list)){
  clusters.list[[cluster.name]] &lt;- with(
    clustered.list[[cluster.name]], data.frame(
      cluster=cluster[1],
      clusterStart=as.integer(median(chromStart)),
      clusterEnd=as.integer(median(chromEnd))))
}
clusters &lt;- do.call(rbind, clusters.list)
ggplot()+
  geom_segment(aes(
    chromStart/1e3, sample.id,
    color=factor(cluster),
    xend=chromEnd/1e3, yend=sample.id),
    data=clustered)+
geom_segment(aes(
  clusterStart/1e3, "clusters",
  color=factor(cluster),
  xend=clusterEnd/1e3, yend="clusters"),
  data=clusters)

</code></pre>

<hr>
<h2 id='overflow.list'>
Data set that caused integer overflow
</h2><span id='topic+overflow.list'></span>

<h3>Description</h3>

<p>that resulted in NaN in the flat_loss_vec.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("overflow.list")</code></pre>


<h3>Format</h3>

<p>List of 2 data frames.
</p>

<hr>
<h2 id='peak.at.profile.end'>
peak at profile end
</h2><span id='topic+peak.at.profile.end'></span>

<h3>Description</h3>

<p>data set for which a peak chromEnd was identical to the data chromEnd
in an initial buggy version of the solver.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("peak.at.profile.end")</code></pre>


<h3>Format</h3>

<p>a list of 27 profile data.frames.
</p>

<hr>
<h2 id='peak1.infeasible'>
data where the PeakSegJoint model with 1 peak is infeasible
</h2><span id='topic+peak1.infeasible'></span>

<h3>Description</h3>

<p>these data are used to test Step3.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("peak1.infeasible")</code></pre>


<h3>Format</h3>

<p>A profile data frame with 4800 observations.
</p>

<hr>
<h2 id='PeakErrorSamples'>PeakErrorSamples</h2><span id='topic+PeakErrorSamples'></span>

<h3>Description</h3>

<p>Compute PeakError for several samples.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakErrorSamples(peaks, 
    regions)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakErrorSamples_+3A_peaks">peaks</code></td>
<td>
<p>data.frame of <code>peaks</code> with sample.id.</p>
</td></tr>
<tr><td><code id="PeakErrorSamples_+3A_regions">regions</code></td>
<td>
<p>data.frame of annotated region labels with sample.id.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame of error <code>regions</code> with sample.id.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>

<hr>
<h2 id='PeakSegJointError'>PeakSegJointError</h2><span id='topic+PeakSegJointError'></span>

<h3>Description</h3>

<p>Compute number of incorrect regions for every PeakSegJoint model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointError(converted, 
    problem.regions)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointError_+3A_converted">converted</code></td>
<td>
<p>Result of <code><a href="#topic+ConvertModelList">ConvertModelList</a></code>.</p>
</td></tr>
<tr><td><code id="PeakSegJointError_+3A_problem.regions">problem.regions</code></td>
<td>
<p>data.frame of annotated region labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of error.totals (data.frame with one row for each model size,
with counts of incorrect labels), error.regions (list of
data.frames with labels and error status for each model size),
modelSelection (data.frame with one row for each model from
exactModelSelection), target (numeric vector of length 2, lower
and upper limits of target interval of log.lambda penalty values
in the interval regression problem).</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(PeakSegJoint)
data(H3K36me3.TDH.other.chunk1, envir=environment())
lims &lt;- c(43000000, 43200000) # left
some.counts &lt;-
  subset(H3K36me3.TDH.other.chunk1$counts,
         lims[1] &lt; chromEnd &amp; chromStart &lt; lims[2])
some.regions &lt;-
  subset(H3K36me3.TDH.other.chunk1$regions,
         lims[1] &lt; chromEnd &amp; chromStart &lt; lims[2])
fit &lt;- PeakSegJointSeveral(some.counts)
converted &lt;- ConvertModelList(fit)
error.list &lt;- PeakSegJointError(converted, some.regions)

peaks.int.vec &lt;- 1:3
show.peaks &lt;- subset(converted$peaks, peaks %in% peaks.int.vec)
show.labels &lt;- do.call(rbind, error.list$error.regions[paste(peaks.int.vec)])

if(interactive() &amp;&amp; require(ggplot2)){
  ann.colors &lt;-
    c(noPeaks="#f6f4bf",
      peakStart="#ffafaf",
      peakEnd="#ff4c4c",
      peaks="#a445ee")
  ggplot()+
    penaltyLearning::geom_tallrect(aes(
      xmin=chromStart/1e3, xmax=chromEnd/1e3, fill=annotation),
      alpha=0.5,
      color="grey",
      data=some.regions)+
    scale_fill_manual(values=ann.colors)+
    scale_linetype_manual("error type",
                          limits=c("correct", 
                                   "false negative",
                                   "false positive"
                                   ),
                          values=c(correct=0,
                                   "false negative"=3,
                                   "false positive"=1))+
    geom_step(aes(chromStart/1e3, count),
              color="grey50",
              data=some.counts)+
    penaltyLearning::geom_tallrect(aes(
      xmin=chromStart/1e3, xmax=chromEnd/1e3, linetype=status),
      fill=NA,
      color="black",
      size=1,
      data=show.labels)+
    geom_segment(aes(chromStart/1e3, 0,
                     xend=chromEnd/1e3, yend=0),
                 size=3,
                 color="deepskyblue",
                 data=show.peaks)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id ~ peaks, scales="free")
}

</code></pre>

<hr>
<h2 id='PeakSegJointFaster'>PeakSegJointFaster</h2><span id='topic+PeakSegJointFaster'></span>

<h3>Description</h3>

<p>Run the PeakSegJointFaster heuristic optimization algorithm, for
several bin.factor parameter values, keeping only the most likely
model found. This gives an approximate solution to a multi-sample
Poisson maximum likelihood segmentation problem. Given S samples,
this function computes a sequence of S+1 PeakSegJoint models, with
0, ..., S samples with an overlapping peak (maximum of one peak
per sample). It also computes for G groups, the seq of G+1
models, with 0, ..., G groups with an overlapping peak.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointFaster(profiles, 
    bin.factor.vec = 2:7)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointFaster_+3A_profiles">profiles</code></td>
<td>
<p>data.frame with columns sample.id, sample.group, chromStart,
chromEnd, count.</p>
</td></tr>
<tr><td><code id="PeakSegJointFaster_+3A_bin.factor.vec">bin.factor.vec</code></td>
<td>
<p>Size of bin pyramid. Bigger values result in slower computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of model fit results.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(PeakSegJoint)
data(H3K36me3.TDH.other.chunk1, envir=environment())
some.counts &lt;- subset(
  H3K36me3.TDH.other.chunk1$counts,
  43000000 &lt; chromEnd &amp;
  chromStart &lt; 43200000)
some.counts$sample.group &lt;- some.counts$cell.type

fit &lt;- PeakSegJointFaster(some.counts, 2:7)

if(interactive() &amp;&amp; require(ggplot2)){

  both &lt;- with(fit, rbind(
    data.frame(model="sample", sample.modelSelection),
  data.frame(model="group", group.modelSelection)))
  ggplot()+
    ggtitle("model selection functions")+
    scale_size_manual(values=c(sample=2, group=1))+
    geom_segment(aes(min.log.lambda, complexity,
                     color=model, size=model,
                     xend=max.log.lambda, yend=complexity),
                 data=both)+
    xlab("log(penalty)")+
    ylab("model complexity (samples or groups with a common peak)")

}

</code></pre>

<hr>
<h2 id='PeakSegJointFasterOne'>PeakSegJointFasterOne</h2><span id='topic+PeakSegJointFasterOne'></span>

<h3>Description</h3>

<p>Run the <code><a href="#topic+PeakSegJointFaster">PeakSegJointFaster</a></code> heuristic optimization algorithm, which
gives an approximate solution to a multi-sample Poisson maximum
likelihood segmentation problem. Given S samples, this function
computes a sequence of S+1 PeakSegJoint models, with 0, ..., S
samples with an overlapping peak (maximum of one peak per
sample). </p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointFasterOne(profiles, 
    bin.factor = 2L)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointFasterOne_+3A_profiles">profiles</code></td>
<td>
<p>List of data.frames with columns chromStart, chromEnd, count, or
single data.frame with additional column sample.id.</p>
</td></tr>
<tr><td><code id="PeakSegJointFasterOne_+3A_bin.factor">bin.factor</code></td>
<td>
<p>Size of bin pyramid. Bigger values result in slower computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of model fit results, see examples to see how to use it.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(PeakSegJoint)
data(H3K36me3.TDH.other.chunk1, envir=environment())

some.counts &lt;- subset(
  H3K36me3.TDH.other.chunk1$counts,
  43000000 &lt; chromEnd &amp;
  chromStart &lt; 43200000 &amp;
  sample.id %in% c("McGill0023", "McGill0022", "McGill0016", "McGill0013"))

id.df &lt;- unique(some.counts[, c("cell.type", "sample.id")])
group.list &lt;- split(paste(id.df$sample.id), id.df$cell.type, drop=TRUE)

loss.df.list &lt;- list()
fit.list &lt;- list()
for(bin.factor in 2:7){
  fit.fast &lt;- PeakSegJointFasterOne(some.counts, bin.factor)
  fit.fast$min.loss &lt;- sum(fit.fast$peak_loss_vec)
  fit.fast$sample.loss.diff.vec &lt;- sort(with(fit.fast, structure(
    peak_loss_vec-flat_loss_vec, names=sample.id)))
  fit.fast$group.loss.diff.vec &lt;- sort(sapply(group.list, function(sid.vec){
    sum(fit.fast$sample.loss.diff.vec[sid.vec])
  }))
  fit.fast$sample.loss.vec &lt;- with(fit.fast, structure(
    sum(flat_loss_vec)+cumsum(c(0, sample.loss.diff.vec)),
    names=paste0(0:length(sample.loss.diff.vec), "samples")))
  fit.fast$group.loss.vec &lt;- with(fit.fast, structure(
    sum(flat_loss_vec)+cumsum(c(0, group.loss.diff.vec)),
    names=paste0(0:length(group.loss.diff.vec), "groups")))
  loss.df.list[[paste(bin.factor)]] &lt;- with(fit.fast, data.frame(
    bin.factor,
    loss=sample.loss.vec,
    peaks=0:length(sample.loss.diff.vec)))
  fit.list[[paste(bin.factor)]] &lt;- fit.fast
}
loss.df &lt;- do.call(rbind, loss.df.list)
fit.best &lt;- fit.list[[which.min(sapply(fit.list, "[[", "min.loss"))]]

norm.list &lt;- list()
profile.list &lt;- split(some.counts, some.counts$sample.id, drop=TRUE)
for(sample.id in names(profile.list)){
  one &lt;- profile.list[[sample.id]]
  max.count &lt;- max(one$count)
  one$count.norm &lt;- one$count/max.count
  norm.list[[sample.id]] &lt;- one
}
norm.df &lt;- do.call(rbind, norm.list)

if(interactive() &amp;&amp; require(ggplot2)){
  
  peaks.df.list &lt;- list()
  for(n.samples in 1:length(fit.best$sample.loss.diff.vec)){
    peaks.df.list[[paste(n.samples)]] &lt;- with(fit.best, data.frame(
      samples=n.samples,
      sample.id=names(sample.loss.diff.vec)[1:n.samples],
      chromStart=peak_start_end[1],
      chromEnd=peak_start_end[2]))
  }
  peaks &lt;- do.call(rbind, peaks.df.list)
  best.peaks &lt;- transform(peaks, y=samples*-0.1, what="peaks")
  ggplot()+
    ggtitle("model for each sample")+
    scale_color_manual(values=c(data="grey50",
                         peaks="deepskyblue",
                         bins="black", segments="green"))+
    geom_step(aes(chromStart/1e3, count.norm, color=what),
              data=data.frame(norm.df, what="data"))+
    geom_segment(aes(chromStart/1e3, y,
                     xend=chromEnd/1e3, yend=y,
                     color=what),
                 size=1,
                 data=best.peaks)+
    geom_text(aes(chromStart/1e3, y,
                  label=paste0(samples, " sample",
                    ifelse(samples==1, "", "s"), " "),
                  color=what),
              hjust=1,
              size=3,
              vjust=0.5,
              data=best.peaks)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id ~ ., scales="free")

  ## same thing but for each group.
  peaks.df.list &lt;- list()
  for(n.groups in 1:length(fit.best$group.loss.diff.vec)){
    group.vec &lt;- names(fit.best$group.loss.diff.vec[1:n.groups])
    meta.df &lt;- do.call(rbind, lapply(group.vec, function(cell.type){
      data.frame(cell.type, sample.id=group.list[[cell.type]])
    }))
    peaks.df.list[[paste(n.groups)]] &lt;- with(fit.best, data.frame(
      groups=n.groups,
      meta.df,
      chromStart=peak_start_end[1],
      chromEnd=peak_start_end[2]))
  }
  peaks &lt;- do.call(rbind, peaks.df.list)
  best.peaks &lt;- transform(peaks, y=groups*-0.1, what="peaks")
  ggplot()+
    ggtitle("model for each group")+
    scale_color_manual(values=c(data="grey50",
                         peaks="deepskyblue",
                         bins="black", segments="green"))+
    geom_step(aes(chromStart/1e3, count.norm, color=what),
              data=data.frame(norm.df, what="data"))+
    geom_segment(aes(chromStart/1e3, y,
                     xend=chromEnd/1e3, yend=y,
                     color=what),
                 size=1,
                 data=best.peaks)+
    geom_text(aes(chromStart/1e3, y,
                  label=paste0(groups, " group",
                    ifelse(groups==1, "", "s"), " "),
                  color=what),
              hjust=1,
              size=3,
              vjust=0.5,
              data=best.peaks)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id + cell.type ~ ., scales="free")

  min.df &lt;- subset(loss.df, peaks==max(peaks))
  ggplot()+
    geom_line(aes(peaks, loss, group=bin.factor), data=loss.df)+
    geom_text(aes(peaks, loss, label=bin.factor), data=min.df, hjust=0)

  if(require(microbenchmark)){

    N.samples.vec &lt;- 10^seq(1, 3, by=0.5)
    max.N &lt;- max(N.samples.vec)
    N.bases &lt;- 10
    rmat &lt;- function(Nr, Nc, mu){
      matrix(rpois(Nr*Nc, mu), Nr, Nc)
    }
    set.seed(1)
    big.mat &lt;- cbind(
      rmat(max.N, N.bases, 5),
      rmat(max.N, N.bases, 10),
      rmat(max.N, N.bases, 5))
    big.df &lt;- data.frame(
      sample.id=as.integer(row(big.mat)),
      chromStart=as.integer(col(big.mat)-1),
      chromEnd=as.integer(col(big.mat)),
      count=as.integer(big.mat))
    full.list &lt;- ProfileList(big.df)
    time.df.list &lt;- list()
    for(N.samples in N.samples.vec){
      partial.list &lt;- full.list[1:N.samples]
      result &lt;- microbenchmark(
        Heuristic=PeakSegJointHeuristicStep2(partial.list, 2L),
        Faster=PeakSegJointFasterOne(partial.list, 2L),
        times=2L)
      time.df.list[[paste(N.samples)]] &lt;- data.frame(
        N.samples,
        result)
    }
    time.df &lt;- do.call(rbind, time.df.list)

    ggplot()+
      geom_point(aes(
        N.samples, time/1e9, color=expr),
        data=time.df)+
      scale_x_log10()+
      scale_y_log10("seconds")
    
  }

}

</code></pre>

<hr>
<h2 id='PeakSegJointHeuristic'>PeakSegJointHeuristic</h2><span id='topic+PeakSegJointHeuristic'></span>

<h3>Description</h3>

<p>Run the PeakSegJoint fast heuristic optimization algorithm, which
gives an approximate solution to a multi-sample Poisson maximum
likelihood segmentation problem. Given S samples, this function
computes a sequence of S+1 PeakSegJoint models, with 0, ..., S
samples with an overlapping peak (maximum of one peak per
sample). This solver runs steps 1-3, and Step3 checks if there are
any more likely models in samples with peak locations which are
the same as all the models detected in Step2. This is guaranteed
as of 24 July 2015 to return a feasible segmentation (seg1 &lt; seg2
&gt; seg3). NB: this function is mostly for internal testing purposes
(search tests/testthat/*.R for 'Heuristic('). For real data use
<code><a href="#topic+PeakSegJointSeveral">PeakSegJointSeveral</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointHeuristic(profiles, 
    bin.factor = 2L)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointHeuristic_+3A_profiles">profiles</code></td>
<td>
<p>List of data.frames with columns chromStart, chromEnd, count, or
single data.frame with additional column sample.id.</p>
</td></tr>
<tr><td><code id="PeakSegJointHeuristic_+3A_bin.factor">bin.factor</code></td>
<td>
<p>Size of bin pyramid. Bigger values result in slower computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of model fit results, which can be passed to <code><a href="#topic+ConvertModelList">ConvertModelList</a></code>
for easier interpretation.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(PeakSegJoint)
data(H3K36me3.TDH.other.chunk1, envir=environment())
lims &lt;- c(43000000, 43200000) # left
some.counts &lt;-
  subset(H3K36me3.TDH.other.chunk1$counts,
         lims[1] &lt; chromEnd &amp; chromStart &lt; lims[2])
fit &lt;- PeakSegJointHeuristic(some.counts)
converted &lt;- ConvertModelList(fit)
## Normalize profile counts to [0,1].
profile.list &lt;- split(some.counts, some.counts$sample.id)
norm.list &lt;- list()
for(sample.id in names(profile.list)){
  one &lt;- profile.list[[sample.id]]
  max.count &lt;- max(one$count)
  one$count.norm &lt;- one$count/max.count
  norm.list[[sample.id]] &lt;- one
}
norm.df &lt;- do.call(rbind, norm.list)
best.peaks &lt;- transform(converted$peaks, y=peaks*-0.1, what="peaks")

if(interactive() &amp;&amp; require(ggplot2)){
  
  ggplot()+
    scale_color_manual(values=c(data="grey50",
                         peaks="deepskyblue",
                         bins="black", segments="green"))+
    geom_step(aes(chromStart/1e3, count.norm, color=what),
              data=data.frame(norm.df, what="data"))+
    geom_segment(aes(chromStart/1e3, y,
                     xend=chromEnd/1e3, yend=y,
                     color=what),
                 size=1,
                 data=best.peaks)+
    geom_text(aes(chromStart/1e3, y,
                  label=paste0(peaks, " peak",
                    ifelse(peaks==1, "", "s"), " "),
                  color=what),
              hjust=1,
              size=3,
              vjust=0.5,
              data=best.peaks)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id ~ ., scales="free")

  ggplot(converted$loss, aes(peaks, loss))+
    geom_point()+
    geom_line()

}

</code></pre>

<hr>
<h2 id='PeakSegJointHeuristicStep1'>PeakSegJointHeuristicStep1</h2><span id='topic+PeakSegJointHeuristicStep1'></span>

<h3>Description</h3>

<p>Run the first step of the PeakSegJoint fast heuristic optimization
algorithm. This is the GridSearch subroutine of the JointZoom algorithm
in arXiv:1506.01286. NB: this function is only for testing the C code
against the R implementation (search tests/testthat/*.R for Step1).
For real data see
<code><a href="#topic+PeakSegJointSeveral">PeakSegJointSeveral</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointHeuristicStep1(profiles, 
    bin.factor = 2L)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointHeuristicStep1_+3A_profiles">profiles</code></td>
<td>
<p>List of data.frames with columns chromStart, chromEnd, count, or
single data.frame with additional column sample.id.</p>
</td></tr>
<tr><td><code id="PeakSegJointHeuristicStep1_+3A_bin.factor">bin.factor</code></td>
<td>
<p>Size of bin pyramid. Bigger values result in slower computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of model fit results, which can be passed to <code><a href="#topic+ConvertModelList">ConvertModelList</a></code>
for easier interpretation.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(PeakSegJoint)
library(ggplot2)
data(H3K36me3.TDH.other.chunk1, envir=environment())
lims &lt;- c(43000000, 43200000) # left
some.counts &lt;-
  subset(H3K36me3.TDH.other.chunk1$counts,
         lims[1] &lt; chromEnd &amp; chromStart &lt; lims[2])
fit &lt;- PeakSegJointHeuristicStep1(some.counts)
## Compute bins to show on plot as well.
profile.list &lt;- split(some.counts, some.counts$sample.id)
bin.list &lt;- list()
norm.list &lt;- list()
for(sample.id in names(profile.list)){
  one &lt;- profile.list[[sample.id]]
  max.count &lt;- max(one$count)
  bins &lt;- binSum(one, fit$bin_start_end[1], fit$bases_per_bin, fit$n_bins)
  stopifnot(fit$n_bins == nrow(bins))
  bins$mean &lt;- with(bins, count/(chromEnd-chromStart))
  bins$mean.norm &lt;- bins$mean/max.count
  stopifnot(bins$count &gt;= 0)
  one$count.norm &lt;- one$count/max.count
  norm.list[[sample.id]] &lt;- one
  bin.list[[sample.id]] &lt;- data.frame(sample.id, bins)
}
bin.df &lt;- do.call(rbind, bin.list)
norm.df &lt;- do.call(rbind, norm.list)
converted &lt;- ConvertModelList(fit)
best.peaks &lt;- transform(converted$peaks, y=peaks*-0.1, what="peaks")

if(require(ggplot2) &amp;&amp; interactive()){

  ggplot()+
    scale_color_manual(values=c(data="grey50",
                                peaks="deepskyblue",
                                bins="black", segments="green"))+
    geom_step(aes(chromStart/1e3, count.norm, color=what),
              data=data.frame(norm.df, what="data"))+
    geom_segment(aes(chromStart/1e3, mean.norm,
                     xend=chromEnd/1e3, yend=mean.norm,
                     color=what),
                 data=data.frame(bin.df, what="bins"))+
    geom_segment(aes(chromStart/1e3, y,
                     xend=chromEnd/1e3, yend=y,
                     color=what),
                 size=1,
                 data=best.peaks)+
    geom_text(aes(chromStart/1e3, y,
                  label=paste0(peaks, " peak",
                               ifelse(peaks==1, "", "s"), " "),
                  color=what),
              hjust=1,
              size=3,
              vjust=0.5,
              data=best.peaks)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id ~ ., scales="free")

}

</code></pre>

<hr>
<h2 id='PeakSegJointHeuristicStep2'>PeakSegJointHeuristicStep2</h2><span id='topic+PeakSegJointHeuristicStep2'></span>

<h3>Description</h3>

<p>Run the first and second steps of the PeakSegJoint fast heuristic
optimization algorithm. Step2 the SearchNearPeak subroutine
described in the JointZoom Algorithm of arXiv:1506.01286, and it
is guaranteed to return feasible segmentations (seg1 &lt; seg2 &gt;
seg3). NB: this function is only for testing the C code against
the R implementation (search tests/testthat/*.R files for
Step2). For real data see <code><a href="#topic+PeakSegJointSeveral">PeakSegJointSeveral</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointHeuristicStep2(profiles, 
    bin.factor = 2L)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointHeuristicStep2_+3A_profiles">profiles</code></td>
<td>
<p>List of data.frames with columns chromStart, chromEnd, count, or
single data.frame with additional column sample.id.</p>
</td></tr>
<tr><td><code id="PeakSegJointHeuristicStep2_+3A_bin.factor">bin.factor</code></td>
<td>
<p>Size of bin pyramid. Bigger values result in slower computation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of model fit results, which can be passed to <code><a href="#topic+ConvertModelList">ConvertModelList</a></code>
for easier interpretation.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>

<hr>
<h2 id='PeakSegJointSeveral'>PeakSegJointSeveral</h2><span id='topic+PeakSegJointSeveral'></span>

<h3>Description</h3>

<p>Run the PeakSegJoint heuristic segmentation algorithm with several
different bin.factor values, keeping only the models with lowest
Poisson loss for each peak size. This algorithm gives an
approximate solution to the following multi-sample constrained
maximum likelihood segmentation problem. If there are S samples
total, we look for the most likely common peak in <code class="reqn">s\in{0, ..., S}</code>
samples. We solve the equivalent minimization problem using the
Poisson loss seg.mean - count.data * log(seg.mean), from the first
base to the last base of <code>profiles</code>. The optimization variables are
the segment means, of which there can be either 1 value (no peak)
or 3 values (peak) in each sample. If there are 3 segments then
two constraints are applied: (1) the changes in mean must occur at
the same position in each sample, and (2) the changes must be up
and then down (mean1 &lt; mean2 &gt; mean3).</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeakSegJointSeveral(profiles, 
    bin.factors = 2:7)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeakSegJointSeveral_+3A_profiles">profiles</code></td>
<td>
<p>data.frame or list of them from <code><a href="#topic+ProfileList">ProfileList</a></code>.</p>
</td></tr>
<tr><td><code id="PeakSegJointSeveral_+3A_bin.factors">bin.factors</code></td>
<td>
<p>integer vector of optimization parameters &gt;= 2. Larger values are
slower. Using more values is slower since it tells the algorithm
to search more of the model space, yielding solution which is
closer to the global optimum.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of model fit results, which can be passed to <code><a href="#topic+ConvertModelList">ConvertModelList</a></code>
for easier interpretation.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(PeakSegJoint)
data(H3K4me3.TDH.other.chunk8, envir=environment())
bf.vec &lt;- c(2, 3, 5)
fit.list &lt;-
  list(several=PeakSegJointSeveral(H3K4me3.TDH.other.chunk8, bf.vec))
for(bf in bf.vec){
  fit.list[[paste(bf)]] &lt;-
    PeakSegJointHeuristicStep2(H3K4me3.TDH.other.chunk8, bf)
}
loss.list &lt;- list()
segs.by.peaks.fit &lt;- list()
for(fit.name in names(fit.list)){
  fit &lt;- fit.list[[fit.name]]
  loss.list[[fit.name]] &lt;- sapply(fit$models, "[[", "loss")
  converted &lt;- ConvertModelList(fit)
  segs.by.peaks &lt;- with(converted, split(segments, segments$peaks))
  for(peaks in names(segs.by.peaks)){
    model.segs &lt;- segs.by.peaks[[peaks]]
    if(is.data.frame(model.segs)){
      segs.by.peaks.fit[[peaks]][[fit.name]] &lt;-
        data.frame(fit.name, model.segs)
    }
  }
}
do.call(rbind, loss.list)

segs1 &lt;- do.call(rbind, segs.by.peaks.fit[["10"]])
breaks1 &lt;- subset(segs1, min(chromStart) &lt; chromStart)
if(interactive() &amp;&amp; require(ggplot2)){
  ggplot()+
    ggtitle(paste("PeakSegJointSeveral runs PeakSegJointHeuristic",
                  "and keeps only the most likely model"))+
    geom_step(aes(chromStart/1e3, count),
              color="grey50",
              data=H3K4me3.TDH.other.chunk8)+
    geom_vline(aes(xintercept=chromStart/1e3),
               data=breaks1,
               color="green",
               linetype="dashed")+
    geom_segment(aes(chromStart/1e3, mean,
                     xend=chromEnd/1e3, yend=mean),
                 size=1,
                 color="green",
                 data=segs1)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id ~ fit.name, scales="free")
}

segs.by.peaks &lt;- list()
for(peaks in 8:10){
  segs.by.peaks[[paste(peaks)]] &lt;-
    data.frame(peaks, segs.by.peaks.fit[[paste(peaks)]][["several"]])
}
segs &lt;- do.call(rbind, segs.by.peaks)
breaks &lt;- subset(segs, min(chromStart) &lt; chromStart)
if(interactive() &amp;&amp; require(ggplot2)){
  ggplot()+
    ggtitle("PeakSegJoint models with 8-10 peaks")+
    geom_step(aes(chromStart/1e3, count),
              color="grey50",
              data=H3K4me3.TDH.other.chunk8)+
    geom_vline(aes(xintercept=chromStart/1e3),
               data=breaks,
               color="green",
               linetype="dashed")+
    geom_segment(aes(chromStart/1e3, mean,
                     xend=chromEnd/1e3, yend=mean),
                 size=1,
                 color="green",
                 data=segs)+
    theme_bw()+
    theme(panel.margin=grid::unit(0, "cm"))+
    facet_grid(sample.id ~ peaks, scales="free")
}

</code></pre>

<hr>
<h2 id='PoissonLoss'>PoissonLoss</h2><span id='topic+PoissonLoss'></span>

<h3>Description</h3>

<p>Compute the weighted Poisson loss function, which is <code>seg.mean</code> -
<code>count</code> * log(<code>seg.mean</code>). The edge case is when the mean is zero, in
which case the probability mass function takes a value of 1 when
the data is 0 (and 0 otherwise). Thus the log-likelihood of a
maximum likelihood segment with mean zero must be zero.</p>


<h3>Usage</h3>

<pre><code class='language-R'>PoissonLoss(count, seg.mean, 
    weight = 1)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PoissonLoss_+3A_count">count</code></td>
<td>
<p>count </p>
</td></tr>
<tr><td><code id="PoissonLoss_+3A_seg.mean">seg.mean</code></td>
<td>
<p>seg.mean </p>
</td></tr>
<tr><td><code id="PoissonLoss_+3A_weight">weight</code></td>
<td>
<p>weight </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>


<h3>Examples</h3>

<pre><code class='language-R'>PoissonLoss(1, 1)
PoissonLoss(0, 0)
PoissonLoss(1, 0)
PoissonLoss(0, 1)
</code></pre>

<hr>
<h2 id='ProfileList'>ProfileList</h2><span id='topic+ProfileList'></span>

<h3>Description</h3>

<p>Convert a data.frame or list of <code>profiles</code> to a list that can be
passed to .Call(&quot;PeakSegJointHeuristic...&quot;).</p>


<h3>Usage</h3>

<pre><code class='language-R'>ProfileList(profiles)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ProfileList_+3A_profiles">profiles</code></td>
<td>
<p>List of data.frames with columns chromStart, chromEnd, count, or
single data.frame with additional column sample.id.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Named list of data.frames with columns chromStart, chromEnd,
count.</p>


<h3>Author(s)</h3>

<p>Toby Dylan Hocking</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
