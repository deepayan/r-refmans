<!DOCTYPE html><html><head><title>Help for package HDCI</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HDCI}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bootLasso'>
<p>Bootstrap Lasso</p></a></li>
<li><a href='#bootLassoOLS'>
<p>Bootstrap Lasso OLS</p></a></li>
<li><a href='#bootLOPR'>
<p>Bootstrap Lasso OLS Partial Ridge</p></a></li>
<li><a href='#bootLPR'>
<p>Bootstrap Lasso Partial Ridge</p></a></li>
<li><a href='#ci'>
<p>Confidence Interval</p></a></li>
<li><a href='#escv.glmnet'>
<p>escv glmnet</p></a></li>
<li><a href='#Lasso'>
<p>Lasso</p></a></li>
<li><a href='#LassoOLS'>
<p>Lasso OLS</p></a></li>
<li><a href='#LPR'>
<p>Lasso Partial Ridge</p></a></li>
<li><a href='#mls'>
<p>Modified Least Squares</p></a></li>
<li><a href='#mypredict'>
<p>My Predict</p></a></li>
<li><a href='#PartRidge'>
<p>Partial Ridge</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>High Dimensional Confidence Interval Based on Lasso and
Bootstrap</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2017-06-06</td>
</tr>
<tr>
<td>Author:</td>
<td>Hanzhong Liu, Xin Xu, Jingyi Jessica Li</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Xin Xu &lt;xin.xu@yale.edu&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, slam, parallel, foreach, iterators, doParallel,
lattice, Matrix, mvtnorm</td>
</tr>
<tr>
<td>Description:</td>
<td>Fits regression models on high dimensional data to estimate coefficients and use bootstrap method to obtain confidence intervals. Choices for regression models are Lasso, Lasso+OLS, Lasso partial ridge, Lasso+OLS partial ridge. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GNU General Public License version 2</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-06-06 18:45:06 UTC; xin</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-06-06 22:34:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='bootLasso'>
Bootstrap Lasso
</h2><span id='topic+bootLasso'></span>

<h3>Description</h3>

<p>Does residual (or paired) bootstrap Lasso and produces confidence intervals for regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootLasso(x, y, B = 500, type.boot = "residual", alpha = 0.05, 
          cv.method = "cv", nfolds = 10, foldid, cv.OLS = FALSE, tau = 0, 
          parallel = FALSE, standardize = TRUE, intercept = TRUE, 
          parallel.boot = FALSE, ncores.boot = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootLasso_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_b">B</code></td>
<td>

<p>Number of replications in the bootstrap &ndash; default is 500.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_type.boot">type.boot</code></td>
<td>

<p>Bootstrap method which can take one of the following two values: &quot;residual&quot; or &quot;paired&quot;. The default is residual.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_alpha">alpha</code></td>
<td>

<p>Significance level &ndash; default is 0.05.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda in the Lasso &ndash; can be cv, cv1se, and escv; the default is cv.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_nfolds">nfolds</code>, <code id="bootLasso_+3A_foldid">foldid</code>, <code id="bootLasso_+3A_cv.ols">cv.OLS</code>, <code id="bootLasso_+3A_tau">tau</code>, <code id="bootLasso_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_parallel.boot">parallel.boot</code></td>
<td>

<p>If TRUE, use parallel foreach to run the bootstrap replication. Must register parallel before hand, such as doParallel or others. See the example below.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_ncores.boot">ncores.boot</code></td>
<td>

<p>Number of cores used in the bootstrap replication.
</p>
</td></tr>
<tr><td><code id="bootLasso_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs residual (type.boot=&quot;residual&quot;) or paired (type.boot=&quot;paired&quot;) bootstrap Lasso procedure, and produces confidence interval for each individual regression coefficient. Note that there are two arguments related to parallel, &quot;parallel&quot; and &quot;parallel.boot&quot;: &quot;parallel&quot; is used for parallel foreach in the escv.glmnet; while, &quot;paralle.boot&quot; is used for the parallel foreach in the bootstrap replication precodure.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>lambda.opt</code></td>
<td>

<p>The optimal value of lambda selected by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>

<p>An estimate of the regression coefficients.
</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>

<p>A 2 by p matrix containing the confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## residual bootstrap Lasso
set.seed(0)
obj &lt;- bootLasso(x = x, y = y, B = 10)
# confidence interval
obj$interval
sum((obj$interval[1,]&lt;=beta) &amp; (obj$interval[2,]&gt;=beta))

## using parallel in the bootstrap replication
#library("doParallel")
#registerDoParallel(2)
#set.seed(0)
#system.time(obj &lt;- bootLasso(x = x, y = y))
#system.time(obj &lt;- bootLasso(x = x, y = y, parallel.boot = TRUE, ncores.boot = 2))

</code></pre>

<hr>
<h2 id='bootLassoOLS'>
Bootstrap Lasso OLS
</h2><span id='topic+bootLassoOLS'></span>

<h3>Description</h3>

<p>Does residual (or paired) bootstrap Lasso+OLS and produces confidence intervals for regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootLassoOLS(x, y, B = 500, type.boot = "residual", alpha = 0.05, OLS = TRUE,
             cv.method = "cv", nfolds = 10, foldid, cv.OLS = TRUE, tau = 0,
             parallel = FALSE, standardize = TRUE, intercept = TRUE, 
             parallel.boot = FALSE, ncores.boot = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootLassoOLS_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector. 
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_b">B</code></td>
<td>

<p>Number of replications in the bootstrap &ndash; default is 500.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_type.boot">type.boot</code></td>
<td>

<p>Bootstrap method which can take one of the following two values: &quot;residual&quot; or &quot;paired&quot;. The default is &quot;residual&quot;. 
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_alpha">alpha</code></td>
<td>

<p>Significance level &ndash; default is 0.05.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_ols">OLS</code></td>
<td>

<p>If TRUE, this function runs residual (or paired) bootstrap Lasso+OLS; if FALSE, it runs residual (or paired) bootstrap Lasso. The default value is TRUE.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda in the Lasso+OLS &ndash; can be cv, cv1se, and escv; the default is cv.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_nfolds">nfolds</code>, <code id="bootLassoOLS_+3A_foldid">foldid</code>, <code id="bootLassoOLS_+3A_cv.ols">cv.OLS</code>, <code id="bootLassoOLS_+3A_tau">tau</code>, <code id="bootLassoOLS_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_parallel.boot">parallel.boot</code></td>
<td>

<p>If TRUE, use parallel foreach to run the bootstrap replication. Must register parallel before hand, such as doParallel or others. See the example below.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_ncores.boot">ncores.boot</code></td>
<td>

<p>Number of cores used in the bootstrap replication.
</p>
</td></tr>
<tr><td><code id="bootLassoOLS_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs residual (type.boot=&quot;residual&quot;) or paired (type.boot=&quot;paired&quot;) bootstrap Lasso+OLS (if OLS=TRUE) procedure, and produces confidence interval for each individual regression coefficient. When the argument OLS=FALSE, it is the same as the function bootLasso, which runs residual (type.boot=&quot;residual&quot;) or paired (type.boot=&quot;paired&quot;) bootstrap Lasso procedure.  Note that there are two arguments related to parallel, &quot;parallel&quot; and &quot;parallel.boot&quot;: &quot;parallel&quot; is used for parallel foreach in the escv.glmnet; while, &quot;paralle.boot&quot; is used for the parallel foreach in the bootstrap replication precodure.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>lambda.opt</code></td>
<td>

<p>The optimal value of lambda selected by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code>Beta.Lasso</code></td>
<td>

<p>Lasso estimate of the regression coefficients.
</p>
</td></tr>
<tr><td><code>Beta.LassoOLS</code></td>
<td>

<p>Lasso+OLS estimate of the regression coefficients. It gives back to Lasso estimate if the argument OLS=FALSE.
</p>
</td></tr>
<tr><td><code>interval.Lasso</code></td>
<td>

<p>A 2 by p matrix containing the bootstrap Lasso confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals.
</p>
</td></tr>
<tr><td><code>interval.LassoOLS</code></td>
<td>

<p>A 2 by p matrix containing the bootstrap Lasso+OLS confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals. It equals interval.Lasso if the argument OLS=FALSE. 
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## residual bootstrap Lasso+OLS
set.seed(0)
obj &lt;- bootLassoOLS(x = x, y = y, B = 10)
# confidence interval
obj$interval
sum((obj$interval[1,]&lt;=beta) &amp; (obj$interval[2,]&gt;=beta))

## using parallel in the bootstrap replication
#library("doParallel")
#registerDoParallel(2)
#set.seed(0)
#system.time(obj &lt;- bootLassoOLS(x = x, y = y))
#system.time(obj &lt;- bootLassoOLS(x = x, y = y, parallel.boot = TRUE, ncores.boot = 2))

</code></pre>

<hr>
<h2 id='bootLOPR'>
Bootstrap Lasso OLS Partial Ridge
</h2><span id='topic+bootLOPR'></span>

<h3>Description</h3>

<p>Combines residual (or paired) bootstrap Lasso+Partial Ridge and residual (or paired) bootstrap Lasso+OLS, and produces confidence intervals for regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootLOPR(x, y, lambda2, B = 500, type.boot = "residual", thres = 0.5, alpha = 0.05, 
         OLS = TRUE, cv.method = "cv", nfolds = 10, foldid, cv.OLS = TRUE, tau = 0, 
         parallel = FALSE, standardize = TRUE, intercept = TRUE, parallel.boot = 
         FALSE, ncores.boot = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootLOPR_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_lambda2">lambda2</code></td>
<td>

<p>Tuning parameter in the Partial Ridge. If missing, lambda2 will be set to 1/nobs, where nobs is the number of observations.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_b">B</code></td>
<td>

<p>Number of replications in the bootstrap &ndash; default is 500.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_type.boot">type.boot</code></td>
<td>

<p>Bootstrap method which can take one of the following two values: &quot;residual&quot; or &quot;paired&quot;. The default is residual.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_thres">thres</code></td>
<td>

<p>A threshold parameter. For the variables/predictors with selection probability (obtained by bootstrap) larger than thres, this function uses bootstrap Lasso+OLS (if OLS=TRUE) or bootstrap Lasso (if OLS=FALSE) to produce confidence intervals; while, for the variables/predictors with selection probability (obtained by bootstrap) smaller than thres, this function uses bootstrap Lasso+Partial Ridge to produce confidence intervals.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_alpha">alpha</code></td>
<td>

<p>Significance level &ndash; default is 0.05.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_ols">OLS</code></td>
<td>

<p>If TRUE, this function uses Lasso+OLS estimator to compute the residuals for residual bootstrap Lasso+Partial Ridge; otherwise, it uses Lasso estimator to compute the residuals for residual bootstrap Lasso+Partial Ridge. The default value is TRUE. This argument can be ignored for paired bootstrap Lasso+Partial Ridge.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda in the Lasso &ndash; can be cv, cv1se, and escv; the default is cv.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_nfolds">nfolds</code>, <code id="bootLOPR_+3A_foldid">foldid</code>, <code id="bootLOPR_+3A_cv.ols">cv.OLS</code>, <code id="bootLOPR_+3A_tau">tau</code>, <code id="bootLOPR_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_parallel.boot">parallel.boot</code></td>
<td>

<p>If TRUE, use parallel foreach to run the bootstrap replication. Must register parallel before hand, such as doParallel or others. See the example below.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_ncores.boot">ncores.boot</code></td>
<td>

<p>Number of cores used in the bootstrap replication.
</p>
</td></tr>
<tr><td><code id="bootLOPR_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function combines the performance of bootstrap Lasso+Partial Ridge and bootstrap Lasso+OLS (if OLS=TRUE). For &quot;large&quot; regression coefficient in the sense that their selection probability (obtained by bootstrap) is larger than a threshold value (thres), it uses bootstrap Lasso+OLS to produce confidence intervals which can decrease the interval length ; while, for &quot;small&quot; regression coefficients meaning that their selection probability (obtained by bootstrap) is smaller than a threshold value (thres), it uses bootstrap Lasso+Partial Ridge to produce confidence intervals which can guarantee coverage. Note that there are two arguments related to parallel, &quot;parallel&quot; and &quot;parallel.boot&quot;: &quot;parallel&quot; is used for parallel foreach in the escv.glmnet; while, &quot;paralle.boot&quot; is used for the parallel foreach in the bootstrap replication precodure.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>lambda.opt</code></td>
<td>

<p>The optimal value of lambda selected by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>

<p>Lasso+OLS (if OLS=TRUE) or Lasso (if OLS=FALSE) estimate of the regression coefficients.
</p>
</td></tr>
<tr><td><code>Beta.LPR</code></td>
<td>

<p>Lasso+Partial Ridge estimate of the regression coefficients. 
</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>

<p>A 2 by p matrix containing the bootstrap Lasso+OLS (if OLS=TRUE) or bootstrap Lasso (if OLS=FALSE) confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals.
</p>
</td></tr>
<tr><td><code>interval.LPR</code></td>
<td>

<p>A 2 by p matrix containing the bootstrap Lasso+Partial Ridge confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals. 
</p>
</td></tr>
<tr><td><code>interval.LOPR</code></td>
<td>

<p>A 2 by p matrix containing the combining confidence intervals of bootstrap Lasso+Partial Ridge and bootstrap Lasso+OLS (or bootstrap Lasso if OLS=FALSE) &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## residual bootstrap Lasso OLS + Partial Ridge
set.seed(0)
obj &lt;- bootLOPR(x = x, y = y, B = 10)
# confidence interval
obj$interval
sum((obj$interval[1,]&lt;=beta) &amp; (obj$interval[2,]&gt;=beta))

## using parallel in the bootstrap replication
#library("doParallel")
#registerDoParallel(2)
#set.seed(0)
#system.time(obj &lt;- bootLOPR(x = x, y = y))
#system.time(obj &lt;- bootLOPR(x = x, y = y, parallel.boot = TRUE, ncores.boot = 2))

</code></pre>

<hr>
<h2 id='bootLPR'>
Bootstrap Lasso Partial Ridge
</h2><span id='topic+bootLPR'></span>

<h3>Description</h3>

<p>Does residual (or paired) bootstrap Lasso+Partial Ridge and produces confidence intervals for regression coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootLPR(x, y, lambda2, B = 500, type.boot = "paired", alpha = 0.05, OLS = TRUE,
        cv.method = "cv", nfolds = 10, foldid, cv.OLS = TRUE, tau = 0, 
        parallel = FALSE, standardize = TRUE, intercept = TRUE, 
        parallel.boot = FALSE, ncores.boot = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootLPR_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_lambda2">lambda2</code></td>
<td>

<p>Tuning parameter in the Partial Ridge. If missing, lambda2 will be set to 1/nobs, where nobs is the number of observations.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_b">B</code></td>
<td>

<p>Number of replications in the bootstrap &ndash; default is 500.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_type.boot">type.boot</code></td>
<td>

<p>Bootstrap method which can take one of the following two values: &quot;residual&quot; or &quot;paired&quot;. The default is residual.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_alpha">alpha</code></td>
<td>

<p>Significance level &ndash; default is 0.05.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_ols">OLS</code></td>
<td>

<p>If TRUE, this function uses Lasso+OLS estimator to compute the residuals for residual bootstrap Lasso+Partial Ridge; otherwise, it uses Lasso estimator to compute the residuals for residual bootstrap Lasso+Partial Ridge. The default value is TRUE. This argument can be ignored for paired bootstrap Lasso+Partial Ridge.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda in the Lasso &ndash; can be cv, cv1se, and escv; the default is cv.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_nfolds">nfolds</code>, <code id="bootLPR_+3A_foldid">foldid</code>, <code id="bootLPR_+3A_cv.ols">cv.OLS</code>, <code id="bootLPR_+3A_tau">tau</code>, <code id="bootLPR_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_parallel.boot">parallel.boot</code></td>
<td>

<p>If TRUE, use parallel foreach to run the bootstrap replication. Must register parallel before hand, such as doParallel or others. See the example below.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_ncores.boot">ncores.boot</code></td>
<td>

<p>Number of cores used in the bootstrap replication.
</p>
</td></tr>
<tr><td><code id="bootLPR_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function runs residual (type.boot=&quot;residual&quot;) or paired (type.boot=&quot;paired&quot;) bootstrap Lasso+Partial Ridge procedure, and produces confidence interval for each individual regression coefficient. If the argument OLS=TRUE, it uses Lasso+OLS estimator to compute the residuals for residual bootstrap Lasso+Partial Ridge; otherwise, it uses Lasso estimator to compute the residuals. Note that there are two arguments related to parallel, &quot;parallel&quot; and &quot;parallel.boot&quot;: &quot;parallel&quot; is used for parallel foreach in the escv.glmnet; while, &quot;paralle.boot&quot; is used for the parallel foreach in the bootstrap replication precodure.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>lambda.opt</code></td>
<td>

<p>The optimal value of lambda selected by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>

<p>Lasso+OLS (if OLS=TRUE) or Lasso (if OLS=FALSE) estimate of the regression coefficients.
</p>
</td></tr>
<tr><td><code>Beta.LPR</code></td>
<td>

<p>Lasso+Partial Ridge estimate of the regression coefficients. 
</p>
</td></tr>
<tr><td><code>interval</code></td>
<td>

<p>A 2 by p matrix containing the bootstrap Lasso+OLS (if OLS=TRUE) or bootstrap Lasso (if OLS=FALSE) confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals.
</p>
</td></tr>
<tr><td><code>interval.LPR</code></td>
<td>

<p>A 2 by p matrix containing the bootstrap Lasso+Partial Ridge confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals. 
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## residual bootstrap Lasso+Partial Ridge
set.seed(0)
obj &lt;- bootLPR(x = x, y = y, type.boot = "residual", B = 10)
# confidence interval
obj$interval
sum((obj$interval[1,]&lt;=beta) &amp; (obj$interval[2,]&gt;=beta))

## using parallel in the bootstrap replication
#library("doParallel")
#registerDoParallel(2)
#set.seed(0)
#system.time(obj &lt;- bootLPR(x = x, y = y))
#system.time(obj &lt;- bootLPR(x = x, y = y, parallel.boot = TRUE, ncores.boot = 2))

</code></pre>

<hr>
<h2 id='ci'>
Confidence Interval
</h2><span id='topic+ci'></span>

<h3>Description</h3>

<p>Gets bootstrap confidence intervals for each of the coefficients of variables/predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ci(Beta, Beta_bootstrap, alpha = 0.05, type = c("basic", "quantile", "bca", "basic2"), 
   a, Beta2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ci_+3A_beta">Beta</code></td>
<td>

<p>An estimate of the coefficients.
</p>
</td></tr>
<tr><td><code id="ci_+3A_beta_bootstrap">Beta_bootstrap</code></td>
<td>

<p>Bootstrap estimates of the coefficients &ndash; a B by p matrix, where B is the number of replications in the bootstrap and p is number of variables/predictors.
</p>
</td></tr>
<tr><td><code id="ci_+3A_alpha">alpha</code></td>
<td>

<p>Significance level &ndash; default is 0.05.
</p>
</td></tr>
<tr><td><code id="ci_+3A_type">type</code></td>
<td>

<p>Different type of confidence interval: basic, quantile, bca (adjusted bootstrap confidence intervals) and basic2 (a modified basic confidence interval).
</p>
</td></tr>
<tr><td><code id="ci_+3A_a">a</code></td>
<td>

<p>Parameter in the bca confidence interval.
</p>
</td></tr>
<tr><td><code id="ci_+3A_beta2">Beta2</code></td>
<td>

<p>An estimator of the coefficients used in the basic2 confidence interval.
</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>interval</code></td>
<td>

<p>A 2 by p matrix containing the confidence intervals &ndash; the first row is the lower bounds of the confidence intervals for each of the coefficients and the second row is the upper bounds of the confidence intervals.
</p>
</td></tr> 
</table>

<hr>
<h2 id='escv.glmnet'>
escv glmnet
</h2><span id='topic+escv.glmnet'></span>

<h3>Description</h3>

<p>Does k-fold estimation stability with cross-validation (escv) for glmnet and returns optimal values for lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>escv.glmnet(x, y, lambda = NULL, nfolds = 10, foldid, cv.OLS = FALSE, tau = 0, parallel 
            = FALSE, standardize = TRUE, intercept = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="escv.glmnet_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector. Can be in sparse matrix format (inherit from class &quot;sparseMatrix&quot; as in package Matrix).
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_lambda">lambda</code></td>
<td>

<p>Optional user-supplied lambda sequence for the Lasso; default is NULL, and glmnet chooses its own sequence.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_nfolds">nfolds</code></td>
<td>

<p>Number of folds - default is 10.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_foldid">foldid</code></td>
<td>

<p>An optional vector of values between 1 and nfold identifying what fold each observation is in. If supplied, nfolds can be missing.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_cv.ols">cv.OLS</code></td>
<td>

<p>If TRUE, uses two-stage estimator Lasso+OLS in the fits (using Lasso to select variables/predictors and then using OLS to refit the coefficients for the selected variables/predictors. The default value is FALSE.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_tau">tau</code></td>
<td>

<p>Tuning parameter in modified Least Squares (mls). Default value is 0, which corresponds to OLS.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_parallel">parallel</code></td>
<td>

<p>If TRUE, use parallel foreach to fit each fold. Must register parallel before hand, such as doParallel or others. See the example below.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model sequence. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="escv.glmnet_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is similar to cv.glmnet, and returns the values of lambda selected by cross-validation (cv), by cross-validation within 1 standard error (cv1se) and by estimation stability with cross-validation (escv). The function runs glmnet nfolds+1 times; the first to get the lambda sequence, and then the remainder to compute the first stage fit (i.e., Lasso) with each of the folds omitted. The error (cv and also es) is accumulated, and the average error and standard deviation over the folds is computed. Note that, similar to cv.glmnet,  the results of escv.glmnet are random, since the folds are selected at random. Users can reduce this randomness by running escv.glmnet many times, and averaging the error curves.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>lambda</code></td>
<td>

<p>The values of lambda used in the fits.
</p>
</td></tr>  
<tr><td><code>glmnet.fit</code></td>
<td>

<p>A fitted glmnet object for the full data.
</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>

<p>The mean cross-validated error - a vector of length length(lambda).
</p>
</td></tr>
<tr><td><code>cv.error</code></td>
<td>

<p>Estimate of standard error of cv.
</p>
</td></tr>
<tr><td><code>es</code></td>
<td>

<p>The mean estimation stability (es) value - a vector of length length(lambda).
</p>
</td></tr>
<tr><td><code>es.error</code></td>
<td>

<p>Estimate of standard error of es.
</p>
</td></tr>
<tr><td><code>lambda.cv</code></td>
<td>

<p>Value of lambda that gives minimum cv.
</p>
</td></tr>
<tr><td><code>lambda.cv1se</code></td>
<td>

<p>Largest value of lambda such that cross-validated error is within 1 standard error of the minimum.
</p>
</td></tr>
<tr><td><code>lambda.escv</code></td>
<td>

<p>Value of lambda selected by escv &ndash; giving the minimum es within the range of lambdas which are no less than lambda.cv.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## escv without parallel
# using Lasso+OLS in the cv fit.
set.seed(0)
obj &lt;- escv.glmnet(x, y, cv.OLS = TRUE) 

# using Lasso in the cv fit.
set.seed(0)
obj &lt;- escv.glmnet(x, y)

## escv with parallel
#library("doParallel")
#library("doRNG")
#registerDoParallel(2)

# using Lasso+OLS in the cv fit.
#registerDoRNG(seed = 0)
#obj &lt;- escv.glmnet(x, y, cv.OLS = TRUE, nfolds = 4, parallel = TRUE)

# using Lasso in the cv fit.
#registerDoRNG(seed = 0) 
#obj &lt;- escv.glmnet(x, y, parallel = TRUE)

</code></pre>

<hr>
<h2 id='Lasso'>
Lasso
</h2><span id='topic+Lasso'></span>

<h3>Description</h3>

<p>Gets Lasso estimator for a given value of lambda or for the value of lambda choosing by cross-validation (or escv).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lasso(x, y, lambda = NULL, fix.lambda = TRUE, cv.method = "cv", nfolds = 10, foldid, 
      cv.OLS = FALSE, tau = 0, parallel = FALSE, standardize = TRUE, intercept = TRUE   
      , ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Lasso_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_lambda">lambda</code></td>
<td>
  
<p>A value of lambda - default is NULL. lambda should be given a value when fix.lambda=TRUE.
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_fix.lambda">fix.lambda</code></td>
<td>

<p>If TRUE, computes Lasso+OLS (or Lasso) for a fix value of lambda given by the argument &quot;lambda&quot;; otherwise, computes Lasso+OLS (or Lasso) for the value of lambda choosing by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda &ndash; can be cv, cv1se, and escv; the default is cv. cv.method is useful only when fix.lambda=FALSE.
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_nfolds">nfolds</code>, <code id="Lasso_+3A_foldid">foldid</code>, <code id="Lasso_+3A_cv.ols">cv.OLS</code>, <code id="Lasso_+3A_tau">tau</code>, <code id="Lasso_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet (useful only when fix.lambda=FALSE).  
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="Lasso_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the Lasso estimator for a give value of lambda (if fix.lambda=TRUE) or for the value of lambda choosing by cv/cv1se/escv (if fix.lambda=FALSE).
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>The Lasso estimate for the coefficients of variables/predictors.
</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>

<p>A value of intercept term.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>The value/values of lambda.
</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>

<p>The mean vector of variables/predictors if intercept=TRUE, otherwise is a vector of 0's.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean of the response if intercept=TRUE, otherwise is 0.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## Lasso estimator
# for a given value of lambda
set.seed(0)
obj.escv &lt;- escv.glmnet(x, y)
obj &lt;- Lasso(x, y, lambda = obj.escv$lambda.cv)
# Lasso estimate of the regression coefficients
obj$beta
# intercept term
obj$beta0
# prediction
mypredict(obj, newx = matrix(rnorm(10*p), 10, p))

# for lambda choosing by cross-validation (cv) which uses Lasso in the cv fit
set.seed(0)
obj &lt;- Lasso(x, y, fix.lambda = FALSE)

# for lambda choosing by cross-validation (cv) which uses Lasso+OLS in the cv fit
set.seed(0)
obj &lt;- Lasso(x, y, fix.lambda = FALSE, cv.OLS = TRUE)

</code></pre>

<hr>
<h2 id='LassoOLS'>
Lasso OLS
</h2><span id='topic+LassoOLS'></span>

<h3>Description</h3>

<p>Computes the two-stage estimator Lasso+OLS (default) or the Lasso estimator (if OLS=FALSE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LassoOLS(x, y, OLS = TRUE, lambda = NULL, fix.lambda = TRUE, cv.method = "cv", nfolds 
         = 10, foldid, cv.OLS = TRUE, tau = 0, parallel = FALSE, standardize = TRUE, 
         intercept = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LassoOLS_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_ols">OLS</code></td>
<td>

<p>If TRUE, computes Lasso+OLS; otherwise, computes Lasso estimator. The default is TRUE.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_lambda">lambda</code></td>
<td>
  
<p>A value of lambda - default is NULL. lambda should be given a value when fix.lambda=TRUE.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_fix.lambda">fix.lambda</code></td>
<td>

<p>If TRUE, computes Lasso+OLS (or Lasso) for a fix value of lambda given by the argument &quot;lambda&quot;; otherwise, computes Lasso+OLS (or Lasso) for the value of lambda choosing by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda &ndash; can be cv, cv1se, and escv; the default is cv. cv.method is useful only when fix.lambda=FALSE.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_nfolds">nfolds</code>, <code id="LassoOLS_+3A_foldid">foldid</code>, <code id="LassoOLS_+3A_cv.ols">cv.OLS</code>, <code id="LassoOLS_+3A_tau">tau</code>, <code id="LassoOLS_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet (useful only when fix.lambda=FALSE). Note that, the default value of cv.OLS is TRUE, which means using Lasso+OLS in the cv fits.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="LassoOLS_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If OLS=TRUE (default), this function computes the Lasso+OLS estimator for a give value of lambda (if fix.lambda=TRUE) or for the value of lambda choosing by cv/cv1se/escv (if fix.lambda=FALSE). If OLS=FALSE, this function computes the Lasso estimator in the same way as the function &quot;Lasso&quot;. Note that, we use the easy-to-understand notation &quot;Lasso+OLS&quot; denoting the &quot;Lasso+mLS&quot; estimator defined in the paper: Liu H, Yu B. Asymptotic Properties of Lasso+mLS and Lasso+Ridge in Sparse High-dimensional Linear Regression. Electronic Journal of Statistics, 2013, 7.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>The Lasso+OLS (or Lasso when OLS=FALSE) estimate for the coefficients of variables/predictors.
</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>

<p>A value of intercept term.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>The value/values of lambda.
</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>

<p>The mean vector of variables/predictors if intercept=TRUE, otherwise is a vector of 0's.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean of the response if intercept=TRUE, otherwise is 0.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>Tuning parameter in modified Least Squares (mls).
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## Lasso+OLS estimator
# for a given value of lambda
set.seed(0)
obj.escv &lt;- escv.glmnet(x, y)
obj &lt;- LassoOLS(x, y, lambda = obj.escv$lambda.cv)
# Lasso+OLS estimate of the regression coefficients
obj$beta
# intercept term
obj$beta0
# prediction
mypredict(obj, newx = matrix(rnorm(10*p), 10, p))

# for lambda choosing by cross-validation (cv) which uses Lasso+OLS in the cv fit
set.seed(0)
obj &lt;- LassoOLS(x, y, fix.lambda = FALSE)

# for lambda choosing by cross-validation (cv) which uses Lasso in the cv fit
set.seed(0)
obj &lt;- LassoOLS(x, y, fix.lambda = FALSE, cv.OLS = FALSE)

</code></pre>

<hr>
<h2 id='LPR'>
Lasso Partial Ridge
</h2><span id='topic+LPR'></span>

<h3>Description</h3>

<p>Computes the two-stage estimator Lasso+Partial Ridge.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LPR(x, y, lambda = NULL, fix.lambda = TRUE, lambda2, cv.method = "cv", nfolds = 10, 
    foldid, cv.OLS = TRUE, tau = 0, parallel = FALSE, standardize = TRUE, intercept = 
    TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LPR_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_lambda">lambda</code></td>
<td>

<p>lambda: A value of lambda - default is NULL. lambda should be given a value when fix.lambda=TRUE.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_fix.lambda">fix.lambda</code></td>
<td>

<p>If TRUE, computes Lasso+Partial Ridge estimator for a fix value of lambda given by the argument &quot;lambda&quot;; otherwise, computes Lasso+Partial Ridge estimator for the value of lambda choosing by cv/cv1se/escv.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_lambda2">lambda2</code></td>
<td>

<p>Tuning parameter in the Partial Ridge. If missing, lambda2 will be set to 1/nobs, where nobs is the number of observations.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_cv.method">cv.method</code></td>
<td>

<p>The method used to select lambda &ndash; can be cv, cv1se, and escv; the default is cv. cv.method is useful only when fix.lambda=FALSE.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_nfolds">nfolds</code>, <code id="LPR_+3A_foldid">foldid</code>, <code id="LPR_+3A_cv.ols">cv.OLS</code>, <code id="LPR_+3A_tau">tau</code>, <code id="LPR_+3A_parallel">parallel</code></td>
<td>

<p>Arguments that can be passed to escv.glmnet (useful only when fix.lambda=FALSE). Note that, the default value of cv.OLS is TRUE, which means using Lasso+OLS in the cv fits.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="LPR_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
<tr><td><code id="LPR_+3A_...">...</code></td>
<td>

<p>Other arguments that can be passed to glmnet.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Lasso+Partial Ridge estimator for a give value of lambda (if fix.lambda=TRUE) or for the value of lambda choosing by cv/cv1se/escv (if fix.lambda=FALSE).
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>The Lasso+Partial Ridge estimator for the coefficients of variables/predictors.
</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>

<p>A value of intercept term.
</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>

<p>The value/values of lambda.
</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>

<p>The value of lambda2.
</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>

<p>The mean vector of variables/predictors if intercept=TRUE, otherwise is a vector of 0's.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean of the response if intercept=TRUE, otherwise is 0.
</p>
</td></tr>
<tr><td><code>normx</code></td>
<td>

<p>The vector of standard error of variables/predictors if standardize=TRUE, otherwise is a vector of 1's.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>Tuning parameter in modified Least Squares (mls).
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## Lasso+Partial Ridge estimator
# for a given value of lambda
set.seed(0)
obj.escv &lt;- escv.glmnet(x, y)
obj &lt;- LPR(x, y, lambda = obj.escv$lambda.cv)
# Lasso+OLS estimate of the regression coefficients
obj$beta
# intercept term
obj$beta0
# prediction
mypredict(obj, newx = matrix(rnorm(10*p), 10, p))

# for lambda choosing by cross-validation (cv) which uses Lasso+OLS in the cv fit
set.seed(0)
obj &lt;- LPR(x, y, fix.lambda = FALSE)

# for lambda choosing by cross-validation (cv) which uses Lasso in the cv fit
set.seed(0)
obj &lt;- LPR(x, y, fix.lambda = FALSE, cv.OLS = FALSE)

</code></pre>

<hr>
<h2 id='mls'>
Modified Least Squares
</h2><span id='topic+mls'></span>

<h3>Description</h3>

<p>Computes modified Least Squares estimate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mls(x, y, tau = 0, standardize = TRUE, intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mls_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector.
</p>
</td></tr>
<tr><td><code id="mls_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="mls_+3A_tau">tau</code></td>
<td>

<p>Tuning parameter in modified Least Squares (mls). Default value is 0, which corresponds to Ordinary Least Squares (OLS).
</p>
</td></tr>
<tr><td><code id="mls_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="mls_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is used to compute the modified Least Squares (mLS) estimator defined in the paper: Liu H, Yu B. Asymptotic Properties of Lasso+mLS and Lasso+Ridge in Sparse High-dimensional Linear Regression. Electronic Journal of Statistics, 2013, 7.
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>The mLS coefficient of variables/predictors.
</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>

<p>A value of intercept term.
</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>

<p>The mean vector of variables/predictors if intercept=TRUE, otherwise is a vector of 0's.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
  
<p>The mean of the response if intercept=TRUE, otherwise is 0.
</p>
</td></tr>
<tr><td><code>normx</code></td>
<td>

<p>The vector of standard error of variables/predictors if standardize=TRUE, otherwise is a vector of 1's.
</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>

<p>The tuning parameter in mLS.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## modified Least Squares
set.seed(0)
obj &lt;- mls(x = x[, 1:20], y = y)
# the OLS estimate of the regression coefficients
obj$beta
# intercept term
obj$beta0
# prediction
mypredict(obj, newx = matrix(rnorm(10*20), 10, 20))

</code></pre>

<hr>
<h2 id='mypredict'>
My Predict
</h2><span id='topic+mypredict'></span>

<h3>Description</h3>

<p>Returns the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mypredict(object, newx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mypredict_+3A_object">object</code></td>
<td>

<p>An object from mls, Lasso, LassoOLS or PartialRidge. 
</p>
</td></tr>
<tr><td><code id="mypredict_+3A_newx">newx</code></td>
<td>

<p>Matrix of the values of variables/predictors for doing prediction; each row is an observation vector.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted values for a give newx matrix is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## modified Least Squares
set.seed(0)
obj &lt;- mls(x = x[, 1:20], y = y)
# the OLS estimate of the regression coefficients
obj$beta
# intercept term
obj$beta0
# prediction
mypredict(obj, newx = matrix(rnorm(10*20), 10, 20))

</code></pre>

<hr>
<h2 id='PartRidge'>
Partial Ridge
</h2><span id='topic+PartRidge'></span>

<h3>Description</h3>

<p>Computes the Partial Ridge estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PartRidge(x, y, lambda2 = 0, varset, standardize = TRUE, intercept = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PartRidge_+3A_x">x</code></td>
<td>

<p>Input matrix as in glmnet, of dimension nobs x nvars; each row is an observation vector. 
</p>
</td></tr>
<tr><td><code id="PartRidge_+3A_y">y</code></td>
<td>

<p>Response variable.
</p>
</td></tr>
<tr><td><code id="PartRidge_+3A_lambda2">lambda2</code></td>
<td>

<p>Tuning parameter for the Partial Ridge. The default value is 0, which gives back to the OLS estimator.
</p>
</td></tr>
<tr><td><code id="PartRidge_+3A_varset">varset</code></td>
<td>

<p>A set indicating which variable/predictors are not penalized. Partial Ridge puts l2 penalty only on the coefficients of the variables/predictors not included in the varset.
</p>
</td></tr>
<tr><td><code id="PartRidge_+3A_standardize">standardize</code></td>
<td>

<p>Logical flag for x variable standardization, prior to fitting the model. Default is standardize=TRUE.
</p>
</td></tr>
<tr><td><code id="PartRidge_+3A_intercept">intercept</code></td>
<td>

<p>Should intercept be fitted (default is TRUE) or set to zero (FALSE).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes the Partial Ridge estimator, which adds l2 penalty only on the coefficients of variabels/predictors not included in the set varset, to the loss function (residual sum of squares).
</p>


<h3>Value</h3>

<p>A list consisting of the following elements is returned.
</p>
<table>
<tr><td><code>beta</code></td>
<td>

<p>The Lasso+Partial Ridge estimator for the coefficients of variables/predictors.
</p>
</td></tr>
<tr><td><code>beta0</code></td>
<td>

<p>A value of intercept term.
</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>
 
<p>The mean vector of variables/predictors if intercept=TRUE, otherwise is a vector of 0's.
</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>

<p>The mean of the response if intercept=TRUE, otherwise is 0.
</p>
</td></tr>
<tr><td><code>normx</code></td>
<td>

<p>The vector of standard error of variables/predictors if standardize=TRUE, otherwise is a vector of 1's.
</p>
</td></tr>
<tr><td><code>lambda2</code></td>
<td>

<p>The value of lambda2.
</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>library("glmnet")
library("mvtnorm") 

## generate the data
set.seed(2015)
n &lt;- 200      # number of obs
p &lt;- 500
s &lt;- 10
beta &lt;- rep(0, p)
beta[1:s] &lt;- runif(s, 1/3, 1)
x &lt;- rmvnorm(n = n, mean = rep(0, p), method = "svd")
signal &lt;- sqrt(mean((x %*% beta)^2))
sigma &lt;- as.numeric(signal / sqrt(10))  # SNR=10
y &lt;- x %*% beta + rnorm(n)

## Partial Ridge Regression
# Lasso
set.seed(0)
obj.escv &lt;- escv.glmnet(x, y)
obj &lt;- Lasso(x, y, lambda = obj.escv$lambda.cv)
# variable set
betalasso &lt;- obj$beta
selectvar &lt;- betalasso != 0
# partial ridge 
PR.obj &lt;- PartRidge(x = x, y = y, lambda2 = 1/n, varset = selectvar)
# parial ridge estimate of the regression coefficients
beta &lt;- PR.obj$beta
# intercept term
beta0 &lt;- PR.obj$beta0
# prediction
mypredict(PR.obj, newx = matrix(rnorm(10*p), 10, p))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
