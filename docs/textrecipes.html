<!DOCTYPE html><html><head><title>Help for package textrecipes</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {textrecipes}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#textrecipes-package'><p>textrecipes: Extra 'Recipes' for Text Processing</p></a></li>
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#all_tokenized'><p>Role Selection</p></a></li>
<li><a href='#count_functions'><p>List of all feature counting functions</p></a></li>
<li><a href='#emoji_samples'><p>Sample sentences with emojis</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#required_pkgs.step_clean_levels'><p>S3 methods for tracking which additional packages are needed for steps.</p></a></li>
<li><a href='#show_tokens'><p>Show token output of recipe</p></a></li>
<li><a href='#step_clean_levels'><p>Clean Categorical Levels</p></a></li>
<li><a href='#step_clean_names'><p>Clean Variable Names</p></a></li>
<li><a href='#step_dummy_hash'><p>Indicator Variables via Feature Hashing</p></a></li>
<li><a href='#step_lda'><p>Calculate LDA Dimension Estimates of Tokens</p></a></li>
<li><a href='#step_lemma'><p>Lemmatization of Token Variables</p></a></li>
<li><a href='#step_ngram'><p>Generate n-grams From Token Variables</p></a></li>
<li><a href='#step_pos_filter'><p>Part of Speech Filtering of Token Variables</p></a></li>
<li><a href='#step_sequence_onehot'><p>Positional One-Hot encoding of Tokens</p></a></li>
<li><a href='#step_stem'><p>Stemming of Token Variables</p></a></li>
<li><a href='#step_stopwords'><p>Filtering of Stop Words for Tokens Variables</p></a></li>
<li><a href='#step_text_normalization'><p>Normalization of Character Variables</p></a></li>
<li><a href='#step_textfeature'><p>Calculate Set of Text Features</p></a></li>
<li><a href='#step_texthash'><p>Feature Hashing of Tokens</p></a></li>
<li><a href='#step_tf'><p>Term frequency of Tokens</p></a></li>
<li><a href='#step_tfidf'><p>Term Frequency-Inverse Document Frequency of Tokens</p></a></li>
<li><a href='#step_tokenfilter'><p>Filter Tokens Based on Term Frequency</p></a></li>
<li><a href='#step_tokenize'><p>Tokenization of Character Variables</p></a></li>
<li><a href='#step_tokenize_bpe'><p>BPE Tokenization of Character Variables</p></a></li>
<li><a href='#step_tokenize_sentencepiece'><p>Sentencepiece Tokenization of Character Variables</p></a></li>
<li><a href='#step_tokenize_wordpiece'><p>Wordpiece Tokenization of Character Variables</p></a></li>
<li><a href='#step_tokenmerge'><p>Combine Multiple Token Variables Into One</p></a></li>
<li><a href='#step_untokenize'><p>Untokenization of Token Variables</p></a></li>
<li><a href='#step_word_embeddings'><p>Pretrained Word Embeddings of Tokens</p></a></li>
<li><a href='#tidy.step_clean_levels'><p>Tidy the Result of a Recipe</p></a></li>
<li><a href='#tokenlist'><p>Create Token Object</p></a></li>
<li><a href='#tunable.step_dummy_hash'><p>tunable methods for textrecipes</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Extra 'Recipes' for Text Processing</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.6</td>
</tr>
<tr>
<td>Description:</td>
<td>Converting text to numerical features requires specifically
    created procedures, which are implemented as steps according to the
    'recipes' package. These steps allows for tokenization, filtering,
    counting (tf and tfidf) and feature hashing.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tidymodels/textrecipes">https://github.com/tidymodels/textrecipes</a>,
<a href="https://textrecipes.tidymodels.org/">https://textrecipes.tidymodels.org/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tidymodels/textrecipes/issues">https://github.com/tidymodels/textrecipes/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6), recipes (&ge; 1.0.7)</td>
</tr>
<tr>
<td>Imports:</td>
<td>lifecycle, dplyr, generics (&ge; 0.1.0), magrittr, Matrix,
purrr, rlang, SnowballC, tibble, tokenizers, vctrs, glue</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, data.table, dials (&ge; 1.2.0), hardhat, janitor, knitr,
modeldata, rmarkdown, sentencepiece, spacyr, stopwords,
stringi, testthat (&ge; 3.0.0), text2vec, tokenizers.bpe, udpipe,
wordpiece</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>cpp11</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse/tidytemplate, reticulate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>"GNU make"</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-14 23:57:36 UTC; emilhvitfeldt</td>
</tr>
<tr>
<td>Author:</td>
<td>Emil Hvitfeldt <a href="https://orcid.org/0000-0002-0679-1945"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Michael W. Kearney [cph] (author of count_functions),
  Posit Software, PBC [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Emil Hvitfeldt &lt;emil.hvitfeldt@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-15 10:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='textrecipes-package'>textrecipes: Extra 'Recipes' for Text Processing</h2><span id='topic+textrecipes'></span><span id='topic+textrecipes-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Converting text to numerical features requires specifically created procedures, which are implemented as steps according to the 'recipes' package. These steps allows for tokenization, filtering, counting (tf and tfidf) and feature hashing.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Emil Hvitfeldt <a href="mailto:emil.hvitfeldt@posit.co">emil.hvitfeldt@posit.co</a> (<a href="https://orcid.org/0000-0002-0679-1945">ORCID</a>)
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Michael W. Kearney <a href="mailto:kearneymw@missouri.edu">kearneymw@missouri.edu</a> (author of count_functions) [copyright holder]
</p>
</li>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/tidymodels/textrecipes">https://github.com/tidymodels/textrecipes</a>
</p>
</li>
<li> <p><a href="https://textrecipes.tidymodels.org/">https://textrecipes.tidymodels.org/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/tidymodels/textrecipes/issues">https://github.com/tidymodels/textrecipes/issues</a>
</p>
</li></ul>


<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='all_tokenized'>Role Selection</h2><span id='topic+all_tokenized'></span><span id='topic+all_tokenized_predictors'></span>

<h3>Description</h3>

<p><code>all_tokenized()</code> selects all <code><a href="#topic+tokenlist">token</a></code> variables,
<code>all_tokenized_predictors()</code> selects all predictor <code><a href="#topic+tokenlist">token</a></code>
variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>all_tokenized()

all_tokenized_predictors()
</code></pre>


<h3>See Also</h3>

<p><code><a href="recipes.html#topic+has_role">recipes::has_role()</a></code>
</p>

<hr>
<h2 id='count_functions'>List of all feature counting functions</h2><span id='topic+count_functions'></span>

<h3>Description</h3>

<p>List of all feature counting functions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_functions
</code></pre>


<h3>Format</h3>

<p>Named list of all ferature counting functions
</p>

<dl>
<dt><code>n_words</code></dt><dd><p>Number of words.</p>
</dd>
<dt><code>n_uq_words</code></dt><dd><p>Number of unique words.</p>
</dd>
<dt><code>n_charS</code></dt><dd><p>Number of characters. Not counting urls, hashtags, mentions or white spaces.</p>
</dd>
<dt><code>n_uq_charS</code></dt><dd><p>Number of unique characters. Not counting urls, hashtags, mentions or white spaces.</p>
</dd>
<dt><code>n_digits</code></dt><dd><p>Number of digits.</p>
</dd>
<dt><code>n_hashtags</code></dt><dd><p>Number of hashtags, word preceded by a '#'.</p>
</dd>
<dt><code>n_uq_hashtags</code></dt><dd><p>Number of unique hashtags, word preceded by a '#'.</p>
</dd>
<dt><code>n_mentions</code></dt><dd><p>Number of mentions, word preceded by a '@'.</p>
</dd>
<dt><code>n_uq_mentions</code></dt><dd><p>Number of unique mentions, word preceded by a '@'.</p>
</dd>
<dt><code>n_commas</code></dt><dd><p>Number of commas.</p>
</dd>
<dt><code>n_periods</code></dt><dd><p>Number of periods.</p>
</dd>
<dt><code>n_exclaims</code></dt><dd><p>Number of exclamation points.</p>
</dd>
<dt><code>n_extraspaces</code></dt><dd><p>Number of times more then 1 consecutive space have been used.</p>
</dd>
<dt><code>n_caps</code></dt><dd><p>Number of upper case characters.</p>
</dd>
<dt><code>n_lowers</code></dt><dd><p>Number of lower case characters.</p>
</dd>
<dt><code>n_urls</code></dt><dd><p>Number of urls.</p>
</dd>
<dt><code>n_uq_urls</code></dt><dd><p>Number of unique urls.</p>
</dd>
<dt><code>n_nonasciis</code></dt><dd><p>Number of non ascii characters.</p>
</dd>
<dt><code>n_puncts</code></dt><dd><p>Number of punctuations characters, not including exclamation points, periods and commas.</p>
</dd>
<dt><code>first_person</code></dt><dd><p>Number of &quot;first person&quot; words.</p>
</dd>
<dt><code>first_personp</code></dt><dd><p>Number of &quot;first person plural&quot; words.</p>
</dd>
<dt><code>second_person</code></dt><dd><p>Number of &quot;second person&quot; words.</p>
</dd>
<dt><code>second_personp</code></dt><dd><p>Number of &quot;second person plural&quot; words.</p>
</dd>
<dt><code>third_person</code></dt><dd><p>Number of &quot;third person&quot; words.</p>
</dd>
<dt><code>to_be</code></dt><dd><p>Number of &quot;to be&quot; words.</p>
</dd>
<dt><code>prepositions</code></dt><dd><p>Number of preposition words.</p>
</dd>
</dl>



<h3>Details</h3>

<p>In this function we refer to &quot;first person&quot;, &quot;first person plural&quot; and
so on. This list describes what words are contained in each group.
</p>

<dl>
<dt>first person</dt><dd><p>I, me, myself, my, mine, this.</p>
</dd>
<dt>first person plural</dt><dd><p>we, us, our, ours, these.</p>
</dd>
<dt>second person</dt><dd><p>you, yours, your, yourself.</p>
</dd>
<dt>second person plural</dt><dd><p>he, she, it, its, his, hers.</p>
</dd>
<dt>third person</dt><dd><p>they, them, theirs, their, they're, their's, those, that.</p>
</dd>
<dt>to be</dt><dd><p>am, is, are, was, were, being, been, be, were, be.</p>
</dd>
<dt>prepositions</dt><dd><p>about, below,
excepting, off, toward, above, beneath, on, under, across, from, onto,
underneath, after, between, in, out, until, against, beyond, outside, up,
along, but, inside, over, upon, among, by, past, around, concerning,
regarding, with, at, despite, into, since, within, down, like, through,
without, before, during, near, throughout, behind, except, of, to, for.</p>
</dd>
</dl>


<hr>
<h2 id='emoji_samples'>Sample sentences with emojis</h2><span id='topic+emoji_samples'></span>

<h3>Description</h3>

<p>This data set is primarily used for examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emoji_samples
</code></pre>


<h3>Format</h3>

<p>tibble with 1 column
</p>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+tidy'></span><span id='topic+required_pkgs'></span><span id='topic+tunable'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>generics</dt><dd><p><code><a href="generics.html#topic+required_pkgs">required_pkgs</a></code>, <code><a href="generics.html#topic+tidy">tidy</a></code>, <code><a href="generics.html#topic+tunable">tunable</a></code></p>
</dd>
</dl>

<hr>
<h2 id='required_pkgs.step_clean_levels'>S3 methods for tracking which additional packages are needed for steps.</h2><span id='topic+required_pkgs.step_clean_levels'></span><span id='topic+required_pkgs.step_clean_names'></span><span id='topic+required_pkgs.step_dummy_hash'></span><span id='topic+required_pkgs.step_lda'></span><span id='topic+required_pkgs.step_lemma'></span><span id='topic+required_pkgs.step_ngram'></span><span id='topic+required_pkgs.step_pos_filter'></span><span id='topic+required_pkgs.step_sequence_onehot'></span><span id='topic+required_pkgs.step_stem'></span><span id='topic+required_pkgs.step_stopwords'></span><span id='topic+required_pkgs.step_text_normalization'></span><span id='topic+required_pkgs.step_textfeature'></span><span id='topic+required_pkgs.step_texthash'></span><span id='topic+required_pkgs.step_tf'></span><span id='topic+required_pkgs.step_tfidf'></span><span id='topic+required_pkgs.step_tokenfilter'></span><span id='topic+required_pkgs.step_tokenize'></span><span id='topic+required_pkgs.step_tokenize_bpe'></span><span id='topic+required_pkgs.step_tokenize_sentencepiece'></span><span id='topic+required_pkgs.step_tokenize_wordpiece'></span><span id='topic+required_pkgs.step_tokenmerge'></span><span id='topic+required_pkgs.step_untokenize'></span><span id='topic+required_pkgs.step_word_embeddings'></span>

<h3>Description</h3>

<p>Recipe-adjacent packages always list themselves as a required package so that
the steps can function properly within parallel processing schemes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'step_clean_levels'
required_pkgs(x, ...)

## S3 method for class 'step_clean_names'
required_pkgs(x, ...)

## S3 method for class 'step_dummy_hash'
required_pkgs(x, ...)

## S3 method for class 'step_lda'
required_pkgs(x, ...)

## S3 method for class 'step_lemma'
required_pkgs(x, ...)

## S3 method for class 'step_ngram'
required_pkgs(x, ...)

## S3 method for class 'step_pos_filter'
required_pkgs(x, ...)

## S3 method for class 'step_sequence_onehot'
required_pkgs(x, ...)

## S3 method for class 'step_stem'
required_pkgs(x, ...)

## S3 method for class 'step_stopwords'
required_pkgs(x, ...)

## S3 method for class 'step_text_normalization'
required_pkgs(x, ...)

## S3 method for class 'step_textfeature'
required_pkgs(x, ...)

## S3 method for class 'step_texthash'
required_pkgs(x, ...)

## S3 method for class 'step_tf'
required_pkgs(x, ...)

## S3 method for class 'step_tfidf'
required_pkgs(x, ...)

## S3 method for class 'step_tokenfilter'
required_pkgs(x, ...)

## S3 method for class 'step_tokenize'
required_pkgs(x, ...)

## S3 method for class 'step_tokenize_bpe'
required_pkgs(x, ...)

## S3 method for class 'step_tokenize_sentencepiece'
required_pkgs(x, ...)

## S3 method for class 'step_tokenize_wordpiece'
required_pkgs(x, ...)

## S3 method for class 'step_tokenmerge'
required_pkgs(x, ...)

## S3 method for class 'step_untokenize'
required_pkgs(x, ...)

## S3 method for class 'step_word_embeddings'
required_pkgs(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="required_pkgs.step_clean_levels_+3A_x">x</code></td>
<td>
<p>A recipe step</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector
</p>

<hr>
<h2 id='show_tokens'>Show token output of recipe</h2><span id='topic+show_tokens'></span>

<h3>Description</h3>

<p>Returns the tokens as a list of character vector of a recipe. This function
can be useful for diagnostics doing recipe construction but should not be
used in final recipe steps. Note that this function will both prep() and
bake() the recipe it is used on.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show_tokens(rec, var, n = 6L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show_tokens_+3A_rec">rec</code></td>
<td>
<p>A recipe object</p>
</td></tr>
<tr><td><code id="show_tokens_+3A_var">var</code></td>
<td>
<p>name of variable</p>
</td></tr>
<tr><td><code id="show_tokens_+3A_n">n</code></td>
<td>
<p>Number of elements to return.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of character vectors
</p>


<h3>Examples</h3>

<pre><code class='language-R'>text_tibble &lt;- tibble(text = c("This is words", "They are nice!"))

recipe(~text, data = text_tibble) %&gt;%
  step_tokenize(text) %&gt;%
  show_tokens(text)

library(modeldata)
data(tate_text)

recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  show_tokens(medium)
</code></pre>

<hr>
<h2 id='step_clean_levels'>Clean Categorical Levels</h2><span id='topic+step_clean_levels'></span>

<h3>Description</h3>

<p><code>step_clean_levels()</code> creates a <em>specification</em> of a recipe step that will
clean nominal data (character or factor) so the levels consist only of
letters, numbers, and the underscore.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_clean_levels(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  clean = NULL,
  skip = FALSE,
  id = rand_id("clean_levels")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_clean_levels_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_clean_levels_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_clean_levels_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_clean_levels_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_clean_levels_+3A_clean">clean</code></td>
<td>
<p>A named character vector to clean and recode categorical levels.
This is <code>NULL</code> until computed by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>. Note that if the
original variable is a character vector, it will be converted to a factor.</p>
</td></tr>
<tr><td><code id="step_clean_levels_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_clean_levels_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The new levels are cleaned and then reset with <code><a href="dplyr.html#topic+recode">dplyr::recode_factor()</a></code>. When
data to be processed contains novel levels (i.e., not contained in the
training set), they are converted to missing.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected), <code>original</code> (the original levels) and
<code>value</code> (the cleaned levels) is returned.
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_clean_names">step_clean_names()</a></code>, <code><a href="recipes.html#topic+step_factor2string">recipes::step_factor2string()</a></code>,
<code><a href="recipes.html#topic+step_string2factor">recipes::step_string2factor()</a></code>, <code><a href="recipes.html#topic+step_regex">recipes::step_regex()</a></code>,
<code><a href="recipes.html#topic+step_unknown">recipes::step_unknown()</a></code>, <code><a href="recipes.html#topic+step_novel">recipes::step_novel()</a></code>, <code><a href="recipes.html#topic+step_other">recipes::step_other()</a></code>
</p>
<p>Other Steps for Text Cleaning: 
<code><a href="#topic+step_clean_names">step_clean_names</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(Smithsonian)

smith_tr &lt;- Smithsonian[1:15, ]
smith_te &lt;- Smithsonian[16:20, ]

rec &lt;- recipe(~., data = smith_tr)

rec &lt;- rec %&gt;%
  step_clean_levels(name)
rec &lt;- prep(rec, training = smith_tr)

cleaned &lt;- bake(rec, smith_tr)

tidy(rec, number = 1)

# novel levels are replaced with missing
bake(rec, smith_te)

</code></pre>

<hr>
<h2 id='step_clean_names'>Clean Variable Names</h2><span id='topic+step_clean_names'></span>

<h3>Description</h3>

<p><code>step_clean_names()</code> creates a <em>specification</em> of a recipe step that will
clean variable names so the names consist only of letters, numbers, and the
underscore.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_clean_names(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  clean = NULL,
  skip = FALSE,
  id = rand_id("clean_names")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_clean_names_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_clean_names_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_clean_names_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_clean_names_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_clean_names_+3A_clean">clean</code></td>
<td>
<p>A named character vector to clean variable names. This is <code>NULL</code>
until computed by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_clean_names_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_clean_names_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the new clean variable names) and <code>value</code> (the original variable names).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_clean_levels">step_clean_levels()</a></code>, <code><a href="recipes.html#topic+step_factor2string">recipes::step_factor2string()</a></code>,
<code><a href="recipes.html#topic+step_string2factor">recipes::step_string2factor()</a></code>, <code><a href="recipes.html#topic+step_regex">recipes::step_regex()</a></code>,
<code><a href="recipes.html#topic+step_unknown">recipes::step_unknown()</a></code>, <code><a href="recipes.html#topic+step_novel">recipes::step_novel()</a></code>, <code><a href="recipes.html#topic+step_other">recipes::step_other()</a></code>
</p>
<p>Other Steps for Text Cleaning: 
<code><a href="#topic+step_clean_levels">step_clean_levels</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
data(airquality)

air_tr &lt;- tibble(airquality[1:100, ])
air_te &lt;- tibble(airquality[101:153, ])

rec &lt;- recipe(~., data = air_tr)

rec &lt;- rec %&gt;%
  step_clean_names(all_predictors())
rec &lt;- prep(rec, training = air_tr)
tidy(rec, number = 1)

bake(rec, air_tr)
bake(rec, air_te)

</code></pre>

<hr>
<h2 id='step_dummy_hash'>Indicator Variables via Feature Hashing</h2><span id='topic+step_dummy_hash'></span>

<h3>Description</h3>

<p><code>step_dummy_hash()</code> creates a <em>specification</em> of a recipe step that will
convert factors or character columns into a series of binary (or signed
binary) indicator columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_dummy_hash(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  signed = TRUE,
  num_terms = 32L,
  collapse = FALSE,
  prefix = "dummyhash",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("dummy_hash")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_dummy_hash_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_signed">signed</code></td>
<td>
<p>A logical, indicating whether to use a signed hash-function
(generating values of -1, 0, or 1), to reduce collisions when hashing.
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_num_terms">num_terms</code></td>
<td>
<p>An integer, the number of variables to output. Defaults to
32.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_collapse">collapse</code></td>
<td>
<p>A logical; should all of the selected columns be collapsed
into a single column to create a single set of hashed features?</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_prefix">prefix</code></td>
<td>
<p>A character string that will be the prefix to the
resulting new variables. See notes below.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_dummy_hash_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Feature hashing, or the hashing trick, is a transformation of a text variable
into a new set of numerical variables. This is done by applying a hashing
function over the values of the factor levels and using the hash values as
feature indices. This allows for a low memory representation of the data and
can be very helpful when a qualitative predictor has many levels or is
expected to have new levels during prediction. This implementation is done
using the MurmurHash3 method.
</p>
<p>The argument <code>num_terms</code> controls the number of indices that the hashing
function will map to. This is the tuning parameter for this transformation.
Since the hashing function can map two different tokens to the same index,
will a higher value of <code>num_terms</code> result in a lower chance of collision.
</p>
<p>The new components will have names that begin with <code>prefix</code>, then
the name of the variable, followed by the tokens all separated by
<code>-</code>. The variable names are padded with zeros. For example if
<code>prefix = "hash"</code>, and if <code>num_terms &lt; 10</code>, their names will be
<code>hash1</code> - <code>hash9</code>. If <code>num_terms = 101</code>, their names will be
<code>hash001</code> - <code>hash101</code>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected), <code>value</code> (whether a signed hashing was
performed), <code>num_terms</code> (number of terms), and <code>collapse</code> (where columns
collapsed).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 2 tuning parameters:
</p>

<ul>
<li> <p><code>signed</code>: Signed Hash Value (type: logical, default: TRUE)
</p>
</li>
<li> <p><code>num_terms</code>: # Hash Features (type: integer, default: 32)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>References</h3>

<p>Kilian Weinberger; Anirban Dasgupta; John Langford; Alex Smola;
Josh Attenberg (2009).
</p>
<p>Kuhn and Johnson (2019), Chapter 7,
<a href="https://bookdown.org/max/FES/encoding-predictors-with-many-categories.html">https://bookdown.org/max/FES/encoding-predictors-with-many-categories.html</a>
</p>


<h3>See Also</h3>

<p><code><a href="recipes.html#topic+step_dummy">recipes::step_dummy()</a></code>
</p>
<p>Other Steps for Numeric Variables From Characters: 
<code><a href="#topic+step_sequence_onehot">step_sequence_onehot</a>()</code>,
<code><a href="#topic+step_textfeature">step_textfeature</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>













library(recipes)
library(modeldata)
data(grants)

grants_rec &lt;- recipe(~sponsor_code, data = grants_other) %&gt;%
  step_dummy_hash(sponsor_code)

grants_obj &lt;- grants_rec %&gt;%
  prep()

bake(grants_obj, grants_test)

tidy(grants_rec, number = 1)
tidy(grants_obj, number = 1)

</code></pre>

<hr>
<h2 id='step_lda'>Calculate LDA Dimension Estimates of Tokens</h2><span id='topic+step_lda'></span>

<h3>Description</h3>

<p><code>step_lda()</code> creates a <em>specification</em> of a recipe step that will return the
lda dimension estimates of a text variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_lda(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  lda_models = NULL,
  num_topics = 10L,
  prefix = "lda",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("lda")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_lda_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_lda_models">lda_models</code></td>
<td>
<p>A WarpLDA model object from the text2vec package. If left
to NULL, the default, will it train its model based on the training data.
Look at the examples for how to fit a WarpLDA model.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_num_topics">num_topics</code></td>
<td>
<p>integer desired number of latent topics.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_prefix">prefix</code></td>
<td>
<p>A prefix for generated column names, default to &quot;lda&quot;.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_lda_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>num_topics</code> (number of topics).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>Source</h3>

<p><a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a>
</p>


<h3>See Also</h3>

<p>Other Steps for Numeric Variables From Tokens: 
<code><a href="#topic+step_texthash">step_texthash</a>()</code>,
<code><a href="#topic+step_tfidf">step_tfidf</a>()</code>,
<code><a href="#topic+step_tf">step_tf</a>()</code>,
<code><a href="#topic+step_word_embeddings">step_word_embeddings</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>



library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_lda(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL) %&gt;%
  slice(1:2)
tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)

# Changing the number of topics.
recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium, artist) %&gt;%
  step_lda(medium, artist, num_topics = 20) %&gt;%
  prep() %&gt;%
  bake(new_data = NULL) %&gt;%
  slice(1:2)

# Supplying A pre-trained LDA model trained using text2vec
library(text2vec)
tokens &lt;- word_tokenizer(tolower(tate_text$medium))
it &lt;- itoken(tokens, ids = seq_along(tate_text$medium))
v &lt;- create_vocabulary(it)
dtm &lt;- create_dtm(it, vocab_vectorizer(v))
lda_model &lt;- LDA$new(n_topics = 15)

recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium, artist) %&gt;%
  step_lda(medium, artist, lda_models = lda_model) %&gt;%
  prep() %&gt;%
  bake(new_data = NULL) %&gt;%
  slice(1:2)

</code></pre>

<hr>
<h2 id='step_lemma'>Lemmatization of Token Variables</h2><span id='topic+step_lemma'></span>

<h3>Description</h3>

<p><code>step_lemma()</code> creates a <em>specification</em> of a recipe step that will extract
the lemmatization of a <code><a href="#topic+tokenlist">token</a></code> variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_lemma(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  skip = FALSE,
  id = rand_id("lemma")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_lemma_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_lemma_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_lemma_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_lemma_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_lemma_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_lemma_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_lemma_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This stem doesn't perform lemmatization by itself, but rather lets you
extract the lemma attribute of the <code><a href="#topic+tokenlist">token</a></code> variable. To be
able to use <code>step_lemma</code> you need to use a tokenization method that includes
lemmatization. Currently using the <code>"spacyr"</code> engine in <code><a href="#topic+step_tokenize">step_tokenize()</a></code>
provides lemmatization and works well with <code>step_lemma</code>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_ngram">step_ngram</a>()</code>,
<code><a href="#topic+step_pos_filter">step_pos_filter</a>()</code>,
<code><a href="#topic+step_stem">step_stem</a>()</code>,
<code><a href="#topic+step_stopwords">step_stopwords</a>()</code>,
<code><a href="#topic+step_tokenfilter">step_tokenfilter</a>()</code>,
<code><a href="#topic+step_tokenmerge">step_tokenmerge</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(recipes)

short_data &lt;- data.frame(text = c(
  "This is a short tale,",
  "With many cats and ladies."
))

rec_spec &lt;- recipe(~text, data = short_data) %&gt;%
  step_tokenize(text, engine = "spacyr") %&gt;%
  step_lemma(text) %&gt;%
  step_tf(text)

rec_prepped &lt;- prep(rec_spec)

bake(rec_prepped, new_data = NULL)

## End(Not run)

</code></pre>

<hr>
<h2 id='step_ngram'>Generate n-grams From Token Variables</h2><span id='topic+step_ngram'></span>

<h3>Description</h3>

<p><code>step_ngram()</code> creates a <em>specification</em> of a recipe step that will convert a
<code><a href="#topic+tokenlist">token</a></code> variable into a <code><a href="#topic+tokenlist">token</a></code> variable of
ngrams.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_ngram(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  num_tokens = 3L,
  min_num_tokens = 3L,
  delim = "_",
  skip = FALSE,
  id = rand_id("ngram")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_ngram_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_num_tokens">num_tokens</code></td>
<td>
<p>The number of tokens in the n-gram. This must be an integer
greater than or equal to 1. Defaults to 3.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_min_num_tokens">min_num_tokens</code></td>
<td>
<p>The minimum number of tokens in the n-gram. This must
be an integer greater than or equal to 1 and smaller than <code>n</code>. Defaults to
3.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_delim">delim</code></td>
<td>
<p>The separator between words in an n-gram. Defaults to &quot;_&quot;.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_ngram_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The use of this step will leave the ordering of the tokens meaningless. If
<code>min_num_tokens &lt;  num_tokens</code> then the tokens order in increasing fashion
with respect to the number of tokens in the n-gram. If <code>min_num_tokens = 1</code>
and <code>num_tokens = 3</code> then the output contains all the 1-grams followed by all
the 2-grams followed by all the 3-grams.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 1 tuning parameters:
</p>

<ul>
<li> <p><code>num_tokens</code>: Number of tokens (type: integer, default: 3)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_lemma">step_lemma</a>()</code>,
<code><a href="#topic+step_pos_filter">step_pos_filter</a>()</code>,
<code><a href="#topic+step_stem">step_stem</a>()</code>,
<code><a href="#topic+step_stopwords">step_stopwords</a>()</code>,
<code><a href="#topic+step_tokenfilter">step_tokenfilter</a>()</code>,
<code><a href="#topic+step_tokenmerge">step_tokenmerge</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_ngram(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)
</code></pre>

<hr>
<h2 id='step_pos_filter'>Part of Speech Filtering of Token Variables</h2><span id='topic+step_pos_filter'></span>

<h3>Description</h3>

<p><code>step_pos_filter()</code> creates a <em>specification</em> of a recipe step that will
filter a <code><a href="#topic+tokenlist">token</a></code> variable based on part of speech tags.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_pos_filter(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  keep_tags = "NOUN",
  skip = FALSE,
  id = rand_id("pos_filter")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_pos_filter_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_keep_tags">keep_tags</code></td>
<td>
<p>Character variable of part of speech tags to keep. See
details for complete list of tags. Defaults to &quot;NOUN&quot;.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_pos_filter_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible part of speech tags for <code>spacyr</code> engine are: &quot;ADJ&quot;, &quot;ADP&quot;, &quot;ADV&quot;,
&quot;AUX&quot;, &quot;CONJ&quot;, &quot;CCONJ&quot;, &quot;DET&quot;, &quot;INTJ&quot;, &quot;NOUN&quot;, &quot;NUM&quot;, &quot;PART&quot;, &quot;PRON&quot;,
&quot;PROPN&quot;, &quot;PUNCT&quot;, &quot;SCONJ&quot;, &quot;SYM&quot;, &quot;VERB&quot;, &quot;X&quot; and &quot;SPACE&quot;. For more
information look here
<a href="https://github.com/explosion/spaCy/blob/master/spacy/glossary.py">https://github.com/explosion/spaCy/blob/master/spacy/glossary.py</a>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>num_topics</code> (number of topics).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_lemma">step_lemma</a>()</code>,
<code><a href="#topic+step_ngram">step_ngram</a>()</code>,
<code><a href="#topic+step_stem">step_stem</a>()</code>,
<code><a href="#topic+step_stopwords">step_stopwords</a>()</code>,
<code><a href="#topic+step_tokenfilter">step_tokenfilter</a>()</code>,
<code><a href="#topic+step_tokenmerge">step_tokenmerge</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(recipes)

short_data &lt;- data.frame(text = c(
  "This is a short tale,",
  "With many cats and ladies."
))

rec_spec &lt;- recipe(~text, data = short_data) %&gt;%
  step_tokenize(text, engine = "spacyr") %&gt;%
  step_pos_filter(text, keep_tags = "NOUN") %&gt;%
  step_tf(text)

rec_prepped &lt;- prep(rec_spec)

bake(rec_prepped, new_data = NULL)

## End(Not run)

</code></pre>

<hr>
<h2 id='step_sequence_onehot'>Positional One-Hot encoding of Tokens</h2><span id='topic+step_sequence_onehot'></span>

<h3>Description</h3>

<p><code>step_sequence_onehot()</code> creates a <em>specification</em> of a recipe step that will
take a string and do one hot encoding for each character by position.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_sequence_onehot(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  sequence_length = 100,
  padding = "pre",
  truncating = "pre",
  vocabulary = NULL,
  prefix = "seq1hot",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("sequence_onehot")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_sequence_onehot_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_sequence_length">sequence_length</code></td>
<td>
<p>A numeric, number of characters to keep before
discarding. Defaults to 100.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_padding">padding</code></td>
<td>
<p>'pre' or 'post', pad either before or after each sequence.
defaults to 'pre'.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_truncating">truncating</code></td>
<td>
<p>'pre' or 'post', remove values from sequences larger than
sequence_length either in the beginning or in the end of the sequence.
Defaults too 'pre'.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_vocabulary">vocabulary</code></td>
<td>
<p>A character vector, characters to be mapped to integers.
Characters not in the vocabulary will be encoded as 0. Defaults to
<code>letters</code>.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_prefix">prefix</code></td>
<td>
<p>A prefix for generated column names, default to &quot;seq1hot&quot;.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_sequence_onehot_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The string will be capped by the sequence_length argument, strings shorter
then sequence_length will be padded with empty characters. The encoding will
assign a integer to each character in the vocabulary, and will encode
accordingly. Characters not in the vocabulary will be encoded as 0.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected), <code>vocabulary</code> (index) and <code>token</code> (text
correspoding to the index).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>Source</h3>

<p><a href="https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf">https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf</a>
</p>


<h3>See Also</h3>

<p>Other Steps for Numeric Variables From Characters: 
<code><a href="#topic+step_dummy_hash">step_dummy_hash</a>()</code>,
<code><a href="#topic+step_textfeature">step_textfeature</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~medium, data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_tokenfilter(medium) %&gt;%
  step_sequence_onehot(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL)

tidy(tate_rec, number = 3)
tidy(tate_obj, number = 3)
</code></pre>

<hr>
<h2 id='step_stem'>Stemming of Token Variables</h2><span id='topic+step_stem'></span>

<h3>Description</h3>

<p><code>step_stem()</code> creates a <em>specification</em> of a recipe step that will convert a
<code><a href="#topic+tokenlist">token</a></code> variable to have its stemmed version.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_stem(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  options = list(),
  custom_stemmer = NULL,
  skip = FALSE,
  id = rand_id("stem")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_stem_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_options">options</code></td>
<td>
<p>A list of options passed to the stemmer function.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_custom_stemmer">custom_stemmer</code></td>
<td>
<p>A custom stemming function. If none is provided it will
default to &quot;SnowballC&quot;.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_stem_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Words tend to have different forms depending on context, such as organize,
organizes, and organizing. In many situations it is beneficial to have these
words condensed into one to allow for a smaller pool of words. Stemming is
the act of chopping off the end of words using a set of heuristics.
</p>
<p>Note that the stemming will only be done at the end of the word and will
therefore not work reliably on ngrams or sentences.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>is_custom_stemmer</code> (indicate if
custom stemmer was used).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_lemma">step_lemma</a>()</code>,
<code><a href="#topic+step_ngram">step_ngram</a>()</code>,
<code><a href="#topic+step_pos_filter">step_pos_filter</a>()</code>,
<code><a href="#topic+step_stopwords">step_stopwords</a>()</code>,
<code><a href="#topic+step_tokenfilter">step_tokenfilter</a>()</code>,
<code><a href="#topic+step_tokenmerge">step_tokenmerge</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_stem(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)

# Using custom stemmer. Here a custom stemmer that removes the last letter
# if it is a "s".
remove_s &lt;- function(x) gsub("s$", "", x)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_stem(medium, custom_stemmer = remove_s)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)
</code></pre>

<hr>
<h2 id='step_stopwords'>Filtering of Stop Words for Tokens Variables</h2><span id='topic+step_stopwords'></span>

<h3>Description</h3>

<p><code>step_stopwords()</code> creates a <em>specification</em> of a recipe step that will
filter a <code><a href="#topic+tokenlist">token</a></code> variable for stop words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_stopwords(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  language = "en",
  keep = FALSE,
  stopword_source = "snowball",
  custom_stopword_source = NULL,
  skip = FALSE,
  id = rand_id("stopwords")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_stopwords_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_language">language</code></td>
<td>
<p>A character to indicate the language of stop words by ISO
639-1 coding scheme.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_keep">keep</code></td>
<td>
<p>A logical. Specifies whether to keep the stop words or discard
them.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_stopword_source">stopword_source</code></td>
<td>
<p>A character to indicate the stop words source as
listed in <code>stopwords::stopwords_getsources</code>.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_custom_stopword_source">custom_stopword_source</code></td>
<td>
<p>A character vector to indicate a custom list of
words that cater to the users specific problem.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_stopwords_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stop words are words which sometimes are remove before natural language
processing tasks. While stop words usually refers to the most common words in
the language there is no universal stop word list.
</p>
<p>The argument <code>custom_stopword_source</code> allows you to pass a character vector
to filter against. With the <code>keep</code> argument one can specify to keep the words
instead of removing thus allowing you to select words with a combination of
these two arguments.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected), <code>value</code> (name of stop word list), and
<code>keep</code> (whether stop words are removed or kept).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_lemma">step_lemma</a>()</code>,
<code><a href="#topic+step_ngram">step_ngram</a>()</code>,
<code><a href="#topic+step_pos_filter">step_pos_filter</a>()</code>,
<code><a href="#topic+step_stem">step_stem</a>()</code>,
<code><a href="#topic+step_tokenfilter">step_tokenfilter</a>()</code>,
<code><a href="#topic+step_tokenmerge">step_tokenmerge</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(tate_text)
tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_stopwords(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)

# With a custom stop words list

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_stopwords(medium, custom_stopword_source = c("twice", "upon"))
tate_obj &lt;- tate_rec %&gt;%
  prep(traimomg = tate_text)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

</code></pre>

<hr>
<h2 id='step_text_normalization'>Normalization of Character Variables</h2><span id='topic+step_text_normalization'></span>

<h3>Description</h3>

<p><code>step_text_normalization()</code> creates a <em>specification</em> of a recipe step that
will perform Unicode Normalization on character variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_text_normalization(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  normalization_form = "nfc",
  skip = FALSE,
  id = rand_id("text_normalization")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_text_normalization_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_normalization_form">normalization_form</code></td>
<td>
<p>A single character string determining the Unicode
Normalization. Must be one of &quot;nfc&quot;, &quot;nfd&quot;, &quot;nfkd&quot;, &quot;nfkc&quot;, or
&quot;nfkc_casefold&quot;. Defaults to &quot;nfc&quot;. See <code><a href="stringi.html#topic+stri_trans_nf">stringi::stri_trans_nfc()</a></code> for
more details.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_text_normalization_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>normalization_form</code> (type of
normalization).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_texthash">step_texthash()</a></code> for feature hashing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)

sample_data &lt;- tibble(text = c("sch\U00f6n", "scho\U0308n"))

rec &lt;- recipe(~., data = sample_data) %&gt;%
  step_text_normalization(text)

prepped &lt;- rec %&gt;%
  prep()

bake(prepped, new_data = NULL, text) %&gt;%
  slice(1:2)

bake(prepped, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(text)

tidy(rec, number = 1)
tidy(prepped, number = 1)

</code></pre>

<hr>
<h2 id='step_textfeature'>Calculate Set of Text Features</h2><span id='topic+step_textfeature'></span>

<h3>Description</h3>

<p><code>step_textfeature()</code> creates a <em>specification</em> of a recipe step that will
extract a number of numeric features of a text column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_textfeature(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  extract_functions = count_functions,
  prefix = "textfeature",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("textfeature")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_textfeature_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_extract_functions">extract_functions</code></td>
<td>
<p>A named list of feature extracting functions.
default to <code>count_functions</code>. See details for more information.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_prefix">prefix</code></td>
<td>
<p>A prefix for generated column names, default to &quot;textfeature&quot;.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_textfeature_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This step will take a character column and returns a number of numeric
columns equal to the number of functions in the list passed to the
<code>extract_functions</code> argument.
</p>
<p>All the functions passed to <code>extract_functions</code> must take a character vector
as input and return a numeric vector of the same length, otherwise an error
will be thrown.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>functions</code> (name of feature
functions).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p>Other Steps for Numeric Variables From Characters: 
<code><a href="#topic+step_dummy_hash">step_dummy_hash</a>()</code>,
<code><a href="#topic+step_sequence_onehot">step_sequence_onehot</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_textfeature(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  pull(textfeature_medium_n_words)

tidy(tate_rec, number = 1)
tidy(tate_obj, number = 1)

# Using custom extraction functions
nchar_round_10 &lt;- function(x) round(nchar(x) / 10) * 10

recipe(~., data = tate_text) %&gt;%
  step_textfeature(medium,
    extract_functions = list(nchar10 = nchar_round_10)
  ) %&gt;%
  prep() %&gt;%
  bake(new_data = NULL)
</code></pre>

<hr>
<h2 id='step_texthash'>Feature Hashing of Tokens</h2><span id='topic+step_texthash'></span>

<h3>Description</h3>

<p><code>step_texthash()</code> creates a <em>specification</em> of a recipe step that will
convert a <code><a href="#topic+tokenlist">token</a></code> variable into multiple numeric variables
using the hashing trick.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_texthash(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  signed = TRUE,
  num_terms = 1024L,
  prefix = "texthash",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("texthash")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_texthash_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_signed">signed</code></td>
<td>
<p>A logical, indicating whether to use a signed hash-function to
reduce collisions when hashing. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_num_terms">num_terms</code></td>
<td>
<p>An integer, the number of variables to output. Defaults to
1024.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_prefix">prefix</code></td>
<td>
<p>A character string that will be the prefix to the
resulting new variables. See notes below.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_texthash_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Feature hashing, or the hashing trick, is a transformation of a text variable
into a new set of numerical variables. This is done by applying a hashing
function over the tokens and using the hash values as feature indices. This
allows for a low memory representation of the text. This implementation is
done using the MurmurHash3 method.
</p>
<p>The argument <code>num_terms</code> controls the number of indices that the hashing
function will map to. This is the tuning parameter for this transformation.
Since the hashing function can map two different tokens to the same index,
will a higher value of <code>num_terms</code> result in a lower chance of collision.
</p>
<p>The new components will have names that begin with <code>prefix</code>, then
the name of the variable, followed by the tokens all separated by
<code>-</code>. The variable names are padded with zeros. For example if
<code>prefix = "hash"</code>, and if <code>num_terms &lt; 10</code>, their names will be
<code>hash1</code> - <code>hash9</code>. If <code>num_terms = 101</code>, their names will be
<code>hash001</code> - <code>hash101</code>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>value</code> (number of terms).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 2 tuning parameters:
</p>

<ul>
<li> <p><code>signed</code>: Signed Hash Value (type: logical, default: TRUE)
</p>
</li>
<li> <p><code>num_terms</code>: # Hash Features (type: integer, default: 1024)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>References</h3>

<p>Kilian Weinberger; Anirban Dasgupta; John Langford; Alex Smola;
Josh Attenberg (2009).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
<code><a href="#topic+step_text_normalization">step_text_normalization()</a></code> to perform text normalization.
</p>
<p>Other Steps for Numeric Variables From Tokens: 
<code><a href="#topic+step_lda">step_lda</a>()</code>,
<code><a href="#topic+step_tfidf">step_tfidf</a>()</code>,
<code><a href="#topic+step_tf">step_tf</a>()</code>,
<code><a href="#topic+step_word_embeddings">step_word_embeddings</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>



library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_tokenfilter(medium, max_tokens = 10) %&gt;%
  step_texthash(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, tate_text)

tidy(tate_rec, number = 3)
tidy(tate_obj, number = 3)

</code></pre>

<hr>
<h2 id='step_tf'>Term frequency of Tokens</h2><span id='topic+step_tf'></span>

<h3>Description</h3>

<p><code>step_tf()</code> creates a <em>specification</em> of a recipe step that will convert a
<code><a href="#topic+tokenlist">token</a></code> variable into multiple variables containing the token
counts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tf(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  weight_scheme = "raw count",
  weight = 0.5,
  vocabulary = NULL,
  res = NULL,
  prefix = "tf",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("tf")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tf_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_weight_scheme">weight_scheme</code></td>
<td>
<p>A character determining the weighting scheme for the
term frequency calculations. Must be one of &quot;binary&quot;, &quot;raw count&quot;, &quot;term
frequency&quot;, &quot;log normalization&quot; or &quot;double normalization&quot;. Defaults to &quot;raw
count&quot;.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_weight">weight</code></td>
<td>
<p>A numeric weight used if <code>weight_scheme</code> is set to &quot;double
normalization&quot;. Defaults to 0.5.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_vocabulary">vocabulary</code></td>
<td>
<p>A character vector of strings to be considered.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_res">res</code></td>
<td>
<p>The words that will be used to calculate the term frequency will
be stored here once this preprocessing step has be trained by
<code><a href="recipes.html#topic+prep.recipe">prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_prefix">prefix</code></td>
<td>
<p>A character string that will be the prefix to the
resulting new variables. See notes below.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tf_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is strongly advised to use <a href="#topic+step_tokenfilter">step_tokenfilter</a> before using <a href="#topic+step_tf">step_tf</a> to
limit the number of variables created, otherwise you might run into memory
issues. A good strategy is to start with a low token count and go up
according to how much RAM you want to use.
</p>
<p>Term frequency is a weight of how many times each token appear in each
observation. There are different ways to calculate the weight and this step
can do it in a couple of ways. Setting the argument <code>weight_scheme</code> to
&quot;binary&quot; will result in a set of binary variables denoting if a token is
present in the observation. &quot;raw count&quot; will count the times a token is
present in the observation. &quot;term frequency&quot; will divide the count with the
total number of words in the document to limit the effect of the document
length as longer documents tends to have the word present more times but not
necessarily at a higher percentage. &quot;log normalization&quot; takes the log of 1
plus the count, adding 1 is done to avoid taking log of 0. Finally &quot;double
normalization&quot; is the raw frequency divided by the raw frequency of the most
occurring term in the document. This is then multiplied by <code>weight</code> and
<code>weight</code> is added to the result. This is again done to prevent a bias towards
longer documents.
</p>
<p>The new components will have names that begin with <code>prefix</code>, then
the name of the variable, followed by the tokens all separated by
<code>-</code>. The variable names are padded with zeros. For example if
<code>prefix = "hash"</code>, and if <code>num_terms &lt; 10</code>, their names will be
<code>hash1</code> - <code>hash9</code>. If <code>num_terms = 101</code>, their names will be
<code>hash001</code> - <code>hash101</code>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>value</code> (the weighting scheme).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 2 tuning parameters:
</p>

<ul>
<li> <p><code>weight_scheme</code>: Term Frequency Weight Method (type: character, default: raw count)
</p>
</li>
<li> <p><code>weight</code>: Weight (type: double, default: 0.5)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Numeric Variables From Tokens: 
<code><a href="#topic+step_lda">step_lda</a>()</code>,
<code><a href="#topic+step_texthash">step_texthash</a>()</code>,
<code><a href="#topic+step_tfidf">step_tfidf</a>()</code>,
<code><a href="#topic+step_word_embeddings">step_word_embeddings</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_tf(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, tate_text)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)


</code></pre>

<hr>
<h2 id='step_tfidf'>Term Frequency-Inverse Document Frequency of Tokens</h2><span id='topic+step_tfidf'></span>

<h3>Description</h3>

<p><code>step_tfidf()</code> creates a <em>specification</em> of a recipe step that will convert a
<code><a href="#topic+tokenlist">token</a></code> variable into multiple variables containing the term
frequency-inverse document frequency of tokens.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tfidf(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  vocabulary = NULL,
  res = NULL,
  smooth_idf = TRUE,
  norm = "l1",
  sublinear_tf = FALSE,
  prefix = "tfidf",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("tfidf")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tfidf_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_vocabulary">vocabulary</code></td>
<td>
<p>A character vector of strings to be considered.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_res">res</code></td>
<td>
<p>The words that will be used to calculate the term frequency will
be stored here once this preprocessing step has be trained by
<code><a href="recipes.html#topic+prep.recipe">prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_smooth_idf">smooth_idf</code></td>
<td>
<p>TRUE smooth IDF weights by adding one to document
frequencies, as if an extra document was seen containing every term in the
collection exactly once. This prevents division by zero.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_norm">norm</code></td>
<td>
<p>A character, defines the type of normalization to apply to term
vectors. &quot;l1&quot; by default, i.e., scale by the number of words in the
document. Must be one of c(&quot;l1&quot;, &quot;l2&quot;, &quot;none&quot;).</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_sublinear_tf">sublinear_tf</code></td>
<td>
<p>A logical, apply sublinear term-frequency scaling, i.e.,
replace the term frequency with 1 + log(TF). Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_prefix">prefix</code></td>
<td>
<p>A character string that will be the prefix to the
resulting new variables. See notes below.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tfidf_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is strongly advised to use <a href="#topic+step_tokenfilter">step_tokenfilter</a> before using <a href="#topic+step_tfidf">step_tfidf</a> to
limit the number of variables created; otherwise you may run into memory
issues. A good strategy is to start with a low token count and increase
depending on how much RAM you want to use.
</p>
<p>Term frequency-inverse document frequency is the product of two statistics:
the term frequency (TF) and the inverse document frequency (IDF).
</p>
<p>Term frequency measures how many times each token appears in each
observation.
</p>
<p>Inverse document frequency is a measure of how informative a word is, e.g.,
how common or rare the word is across all the observations. If a word appears
in all the observations it might not give that much insight, but if it only
appears in some it might help differentiate between observations.
</p>
<p>The IDF is defined as follows: idf = log(1 + (# documents in the corpus) / (#
documents where the term appears))
</p>
<p>The new components will have names that begin with <code>prefix</code>, then
the name of the variable, followed by the tokens all separated by
<code>-</code>. The variable names are padded with zeros. For example if
<code>prefix = "hash"</code>, and if <code>num_terms &lt; 10</code>, their names will be
<code>hash1</code> - <code>hash9</code>. If <code>num_terms = 101</code>, their names will be
<code>hash001</code> - <code>hash101</code>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected), <code>token</code> (name of the tokens),
<code>weight</code> (the calculated IDF weight) is returned.
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Numeric Variables From Tokens: 
<code><a href="#topic+step_lda">step_lda</a>()</code>,
<code><a href="#topic+step_texthash">step_texthash</a>()</code>,
<code><a href="#topic+step_tf">step_tf</a>()</code>,
<code><a href="#topic+step_word_embeddings">step_word_embeddings</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_tfidf(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, tate_text)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)


</code></pre>

<hr>
<h2 id='step_tokenfilter'>Filter Tokens Based on Term Frequency</h2><span id='topic+step_tokenfilter'></span>

<h3>Description</h3>

<p><code>step_tokenfilter()</code> creates a <em>specification</em> of a recipe step that will
convert a <code><a href="#topic+tokenlist">token</a></code> variable to be filtered based on frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tokenfilter(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  max_times = Inf,
  min_times = 0,
  percentage = FALSE,
  max_tokens = 100,
  filter_fun = NULL,
  res = NULL,
  skip = FALSE,
  id = rand_id("tokenfilter")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tokenfilter_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_max_times">max_times</code></td>
<td>
<p>An integer. Maximal number of times a word can appear before
getting removed.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_min_times">min_times</code></td>
<td>
<p>An integer. Minimum number of times a word can appear before
getting removed.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_percentage">percentage</code></td>
<td>
<p>A logical. Should max_times and min_times be interpreted as
a percentage instead of count.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_max_tokens">max_tokens</code></td>
<td>
<p>An integer. Will only keep the top max_tokens tokens after
filtering done by max_times and min_times. Defaults to 100.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_filter_fun">filter_fun</code></td>
<td>
<p>A function. This function should take a vector of
characters, and return a logical vector of the same length. This function
will be applied to each observation of the data set. Defaults to <code>NULL</code>.
All other arguments will be ignored if this argument is used.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_res">res</code></td>
<td>
<p>The words that will be keep will be stored here once this
preprocessing step has be trained by <code><a href="recipes.html#topic+prep.recipe">prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenfilter_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This step allow you to limit the tokens you are looking at by filtering on
their occurrence in the corpus. You are able to exclude tokens if they appear
too many times or too few times in the data. It can be specified as counts
using <code>max_times</code> and <code>min_times</code> or as percentages by setting <code>percentage</code>
as <code>TRUE</code>. In addition one can filter to only use the top <code>max_tokens</code> used
tokens. If <code>max_tokens</code> is set to <code>Inf</code> then all the tokens will be used.
This will generally lead to very large data sets when then tokens are words
or trigrams. A good strategy is to start with a low token count and go up
according to how much RAM you want to use.
</p>
<p>It is strongly advised to filter before using <a href="#topic+step_tf">step_tf</a> or <a href="#topic+step_tfidf">step_tfidf</a> to
limit the number of variables created.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>value</code> (number of unique tokens).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 3 tuning parameters:
</p>

<ul>
<li> <p><code>max_times</code>: Maximum Token Frequency (type: integer, default: Inf)
</p>
</li>
<li> <p><code>min_times</code>: Minimum Token Frequency (type: integer, default: 0)
</p>
</li>
<li> <p><code>max_tokens</code>: # Retained Tokens (type: integer, default: 100)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_lemma">step_lemma</a>()</code>,
<code><a href="#topic+step_ngram">step_ngram</a>()</code>,
<code><a href="#topic+step_pos_filter">step_pos_filter</a>()</code>,
<code><a href="#topic+step_stem">step_stem</a>()</code>,
<code><a href="#topic+step_stopwords">step_stopwords</a>()</code>,
<code><a href="#topic+step_tokenmerge">step_tokenmerge</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_tokenfilter(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)
</code></pre>

<hr>
<h2 id='step_tokenize'>Tokenization of Character Variables</h2><span id='topic+step_tokenize'></span>

<h3>Description</h3>

<p><code>step_tokenize()</code> creates a <em>specification</em> of a recipe step that will
convert a character predictor into a <code><a href="#topic+tokenlist">token</a></code> variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tokenize(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  training_options = list(),
  options = list(),
  token = "words",
  engine = "tokenizers",
  custom_token = NULL,
  skip = FALSE,
  id = rand_id("tokenize")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tokenize_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_training_options">training_options</code></td>
<td>
<p>A list of options passed to the tokenizer when it is
being trained. Only applicable for engine == &quot;tokenizers.bpe&quot;.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_options">options</code></td>
<td>
<p>A list of options passed to the tokenizer.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_token">token</code></td>
<td>
<p>Unit for tokenizing. See details for options. Defaults to
&quot;words&quot;.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_engine">engine</code></td>
<td>
<p>Package that will be used for tokenization. See details for
options. Defaults to &quot;tokenizers&quot;.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_custom_token">custom_token</code></td>
<td>
<p>User supplied tokenizer. Use of this argument will
overwrite the token and engine arguments. Must take a character vector as
input and output a list of character vectors.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Tokenization is the act of splitting a character string into smaller parts to
be further analyzed. This step uses the <code>tokenizers</code> package which includes
heuristics on how to to split the text into paragraphs tokens, word tokens,
among others. <code>textrecipes</code> keeps the tokens as a <code><a href="#topic+tokenlist">token</a></code>
variable and other steps will do their tasks on those <code><a href="#topic+tokenlist">token</a></code>
variable before transforming them back to numeric variables.
</p>
<p>Working will <code>textrecipes</code> will almost always start by calling
<code>step_tokenize</code> followed by modifying and filtering steps. This is not always
the case as you sometimes want to do apply pre-tokenization steps, this can
be done with <code><a href="recipes.html#topic+step_mutate">recipes::step_mutate()</a></code>.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Engines</h3>

<p>The choice of <code>engine</code> determines the possible choices of <code>token</code>.
</p>
<p>The following is some small example data used in the following examples
</p>
<div class="sourceCode r"><pre>text_tibble &lt;- tibble(
  text = c("This is words", "They are nice!")
)
</pre></div>


<h4>tokenizers</h4>

<p>The tokenizers package is the default <code>engine</code> and it comes with the
following unit of <code>token</code>. All of these options correspond to a function in
the tokenizers package.
</p>

<ul>
<li><p> &quot;words&quot; (default)
</p>
</li>
<li><p> &quot;characters&quot;
</p>
</li>
<li><p> &quot;character_shingles&quot;
</p>
</li>
<li><p> &quot;ngrams&quot;
</p>
</li>
<li><p> &quot;skip_ngrams&quot;
</p>
</li>
<li><p> &quot;sentences&quot;
</p>
</li>
<li><p> &quot;lines&quot;
</p>
</li>
<li><p> &quot;paragraphs&quot;
</p>
</li>
<li><p> &quot;regex&quot;
</p>
</li>
<li><p> &quot;ptb&quot; (Penn Treebank)
</p>
</li>
<li><p> &quot;skip_ngrams&quot;
</p>
</li>
<li><p> &quot;word_stems&quot;
</p>
</li></ul>

<p>The default tokenizer is <code>"word"</code> which splits the text into a series of
words. By using <code>step_tokenize()</code> without setting any arguments you get word
tokens
</p>
<div class="sourceCode r"><pre>recipe(~ text, data = text_tibble) %&gt;%
  step_tokenize(text) %&gt;%
  show_tokens(text)
#&gt; [[1]]
#&gt; [1] "this"  "is"    "words"
#&gt; 
#&gt; [[2]]
#&gt; [1] "they" "are"  "nice"
</pre></div>
<p>This tokenizer has arguments that change how the tokenization occurs and can
accessed using the <code>options</code> argument by passing a named list. Here we are
telling <a href="tokenizers.html#topic+basic-tokenizers">tokenizers::tokenize_words</a> that we don't want to turn the words to
lowercase
</p>
<div class="sourceCode r"><pre>recipe(~ text, data = text_tibble) %&gt;%
  step_tokenize(text,
                options = list(lowercase = FALSE)) %&gt;%
  show_tokens(text)
#&gt; [[1]]
#&gt; [1] "This"  "is"    "words"
#&gt; 
#&gt; [[2]]
#&gt; [1] "They" "are"  "nice"
</pre></div>
<p>We can also stop removing punctuation.
</p>
<div class="sourceCode r"><pre>recipe(~ text, data = text_tibble) %&gt;%
  step_tokenize(text,
                options = list(strip_punct = FALSE,
                               lowercase = FALSE)) %&gt;%
  show_tokens(text)
#&gt; [[1]]
#&gt; [1] "This"  "is"    "words"
#&gt; 
#&gt; [[2]]
#&gt; [1] "They" "are"  "nice" "!"
</pre></div>
<p>The tokenizer can be changed by setting a different <code>token</code>. Here we change
it to return character tokens.
</p>
<div class="sourceCode r"><pre>recipe(~ text, data = text_tibble) %&gt;%
  step_tokenize(text, token = "characters") %&gt;%
  show_tokens(text)
#&gt; [[1]]
#&gt;  [1] "t" "h" "i" "s" "i" "s" "w" "o" "r" "d" "s"
#&gt; 
#&gt; [[2]]
#&gt;  [1] "t" "h" "e" "y" "a" "r" "e" "n" "i" "c" "e"
</pre></div>
<p>It is worth noting that not all these token methods are appropriate but are
included for completeness.
</p>



<h4>spacyr</h4>


<ul>
<li><p> &quot;words&quot;
</p>
</li></ul>




<h4>tokenizers.bpe</h4>

<p>The tokeenizers.bpe engine performs Byte Pair Encoding Text Tokenization.
</p>

<ul>
<li><p> &quot;words&quot;
</p>
</li></ul>

<p>This tokenizer is trained on the training set and will thus need to be passed
training arguments. These are passed to the <code>training_options</code> argument and
the most important one is <code>vocab_size</code>. The determines the number of unique
tokens the tokenizer will produce. It is generally set to a much higher
value, typically in the thousands, but is set to 22 here for demonstration
purposes.
</p>
<div class="sourceCode r"><pre>recipe(~ text, data = text_tibble) %&gt;%
  step_tokenize(
    text,
    engine = "tokenizers.bpe",
    training_options = list(vocab_size = 22)
  ) %&gt;%
  show_tokens(text)
</pre></div>
<div class="sourceCode"><pre>#&gt; [[1]]
#&gt;  [1] "_Th" "is"  "_"   "is"  "_"   "w"   "o"   "r"   "d"   "s"  
#&gt; 
#&gt; [[2]]
#&gt;  [1] "_Th" "e"   "y"   "_"   "a"   "r"   "e"   "_"   "n"   "i"   "c"   "e"  
#&gt; [13] "!"
</pre></div>



<h4>udpipe</h4>


<ul>
<li><p> &quot;words&quot;
</p>
</li></ul>




<h4>custom_token</h4>

<p>Sometimes you need to perform tokenization that is not covered by the
supported engines. In that case you can use the <code>custom_token</code> argument to
pass a function in that performs the tokenization you want.
</p>
<p>Below is an example of a very simple space tokenization. This is a very fast
way of tokenizing.
</p>
<div class="sourceCode r"><pre>space_tokenizer &lt;- function(x) {
  strsplit(x, " +")
}

recipe(~ text, data = text_tibble) %&gt;%
  step_tokenize(
    text,
    custom_token = space_tokenizer
  ) %&gt;%
  show_tokens(text)
#&gt; [[1]]
#&gt; [1] "This"  "is"    "words"
#&gt; 
#&gt; [[2]]
#&gt; [1] "They"  "are"   "nice!"
</pre></div>



<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>value</code> (unit of tokenization).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 1 tuning parameters:
</p>

<ul>
<li> <p><code>token</code>: Token Unit (type: character, default: words)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_untokenize">step_untokenize()</a></code> to untokenize.
</p>
<p>Other Steps for Tokenization: 
<code><a href="#topic+step_tokenize_bpe">step_tokenize_bpe</a>()</code>,
<code><a href="#topic+step_tokenize_sentencepiece">step_tokenize_sentencepiece</a>()</code>,
<code><a href="#topic+step_tokenize_wordpiece">step_tokenize_wordpiece</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 1)
tidy(tate_obj, number = 1)

tate_obj_chars &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium, token = "characters") %&gt;%
  prep()

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)
</code></pre>

<hr>
<h2 id='step_tokenize_bpe'>BPE Tokenization of Character Variables</h2><span id='topic+step_tokenize_bpe'></span>

<h3>Description</h3>

<p><code>step_tokenize_bpe()</code> creates a <em>specification</em> of a recipe step that will
convert a character predictor into a <code><a href="#topic+tokenlist">token</a></code> variable using
Byte Pair Encoding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tokenize_bpe(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  vocabulary_size = 1000,
  options = list(),
  res = NULL,
  skip = FALSE,
  id = rand_id("tokenize_bpe")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tokenize_bpe_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_vocabulary_size">vocabulary_size</code></td>
<td>
<p>Integer, indicating the number of tokens in the final
vocabulary. Defaults to 1000. Highly encouraged to be tuned.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_options">options</code></td>
<td>
<p>A list of options passed to the tokenizer.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_res">res</code></td>
<td>
<p>The fitted <code><a href="tokenizers.bpe.html#topic+bpe">tokenizers.bpe::bpe()</a></code> model tokenizer will be stored
here once this preprocessing step has be trained by <code><a href="recipes.html#topic+prep.recipe">prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_bpe_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected).
</p>


<h3>Tuning Parameters</h3>

<p>This step has 1 tuning parameters:
</p>

<ul>
<li> <p><code>vocabulary_size</code>: # Unique Tokens in Vocabulary (type: integer, default: 1000)
</p>
</li></ul>



<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_untokenize">step_untokenize()</a></code> to untokenize.
</p>
<p>Other Steps for Tokenization: 
<code><a href="#topic+step_tokenize_sentencepiece">step_tokenize_sentencepiece</a>()</code>,
<code><a href="#topic+step_tokenize_wordpiece">step_tokenize_wordpiece</a>()</code>,
<code><a href="#topic+step_tokenize">step_tokenize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize_bpe(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 1)
tidy(tate_obj, number = 1)

</code></pre>

<hr>
<h2 id='step_tokenize_sentencepiece'>Sentencepiece Tokenization of Character Variables</h2><span id='topic+step_tokenize_sentencepiece'></span>

<h3>Description</h3>

<p><code>step_tokenize_sentencepiece()</code> creates a <em>specification</em> of a recipe step
that will convert a character predictor into a <code><a href="#topic+tokenlist">token</a></code>
variable using SentencePiece tokenization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tokenize_sentencepiece(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  vocabulary_size = 1000,
  options = list(),
  res = NULL,
  skip = FALSE,
  id = rand_id("tokenize_sentencepiece")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tokenize_sentencepiece_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_vocabulary_size">vocabulary_size</code></td>
<td>
<p>Integer, indicating the number of tokens in the final
vocabulary. Defaults to 1000. Highly encouraged to be tuned.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_options">options</code></td>
<td>
<p>A list of options passed to the tokenizer.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_res">res</code></td>
<td>
<p>The fitted <code><a href="sentencepiece.html#topic+sentencepiece">sentencepiece::sentencepiece()</a></code> model tokenizer will
be stored here once this preprocessing step has be trained by
<code><a href="recipes.html#topic+prep.recipe">prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_sentencepiece_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you are running into errors, you can investigate the progress of the
compiled code by setting <code>options = list(verbose = TRUE)</code>. This can reveal if
sentencepiece ran correctly or not.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_untokenize">step_untokenize()</a></code> to untokenize.
</p>
<p>Other Steps for Tokenization: 
<code><a href="#topic+step_tokenize_bpe">step_tokenize_bpe</a>()</code>,
<code><a href="#topic+step_tokenize_wordpiece">step_tokenize_wordpiece</a>()</code>,
<code><a href="#topic+step_tokenize">step_tokenize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize_sentencepiece(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 1)
tidy(tate_obj, number = 1)

</code></pre>

<hr>
<h2 id='step_tokenize_wordpiece'>Wordpiece Tokenization of Character Variables</h2><span id='topic+step_tokenize_wordpiece'></span>

<h3>Description</h3>

<p><code>step_tokenize_wordpiece()</code> creates a <em>specification</em> of a recipe step that
will convert a character predictor into a <code><a href="#topic+tokenlist">token</a></code> variable
using WordPiece tokenization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tokenize_wordpiece(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  vocab = wordpiece::wordpiece_vocab(),
  unk_token = "[UNK]",
  max_chars = 100,
  skip = FALSE,
  id = rand_id("tokenize_wordpiece")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tokenize_wordpiece_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_vocab">vocab</code></td>
<td>
<p>Character of Character vector of vocabulary tokens. Defaults to
<code>wordpiece_vocab()</code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_unk_token">unk_token</code></td>
<td>
<p>Token to represent unknown words. Defaults to <code>"[UNK]"</code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_max_chars">max_chars</code></td>
<td>
<p>Integer, Maximum length of word recognized. Defaults to 100.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenize_wordpiece_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_untokenize">step_untokenize()</a></code> to untokenize.
</p>
<p>Other Steps for Tokenization: 
<code><a href="#topic+step_tokenize_bpe">step_tokenize_bpe</a>()</code>,
<code><a href="#topic+step_tokenize_sentencepiece">step_tokenize_sentencepiece</a>()</code>,
<code><a href="#topic+step_tokenize">step_tokenize</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize_wordpiece(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 1)
tidy(tate_obj, number = 1)

</code></pre>

<hr>
<h2 id='step_tokenmerge'>Combine Multiple Token Variables Into One</h2><span id='topic+step_tokenmerge'></span>

<h3>Description</h3>

<p><code>step_tokenmerge()</code> creates a <em>specification</em> of a recipe step that will take
multiple <code><a href="#topic+tokenlist">token</a></code> variables and combine them into one
<code><a href="#topic+tokenlist">token</a></code> variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_tokenmerge(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  prefix = "tokenmerge",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("tokenmerge")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_tokenmerge_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_prefix">prefix</code></td>
<td>
<p>A prefix for generated column names, default to &quot;tokenmerge&quot;.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_tokenmerge_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Token Modification: 
<code><a href="#topic+step_lemma">step_lemma</a>()</code>,
<code><a href="#topic+step_ngram">step_ngram</a>()</code>,
<code><a href="#topic+step_pos_filter">step_pos_filter</a>()</code>,
<code><a href="#topic+step_stem">step_stem</a>()</code>,
<code><a href="#topic+step_stopwords">step_stopwords</a>()</code>,
<code><a href="#topic+step_tokenfilter">step_tokenfilter</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium, artist) %&gt;%
  step_tokenmerge(medium, artist)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)
</code></pre>

<hr>
<h2 id='step_untokenize'>Untokenization of Token Variables</h2><span id='topic+step_untokenize'></span>

<h3>Description</h3>

<p><code>step_untokenize()</code> creates a <em>specification</em> of a recipe step that will
convert a <code><a href="#topic+tokenlist">token</a></code> variable into a character predictor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_untokenize(
  recipe,
  ...,
  role = NA,
  trained = FALSE,
  columns = NULL,
  sep = " ",
  skip = FALSE,
  id = rand_id("untokenize")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_untokenize_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_role">role</code></td>
<td>
<p>Not used by this step since no new variables are
created.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_sep">sep</code></td>
<td>
<p>a character to determine how the tokens should be separated when
pasted together. Defaults to <code>" "</code>.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_untokenize_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This steps will turn a <code><a href="#topic+tokenlist">token</a></code> vector back into a character
vector. This step is calling <code>paste</code> internally to put the tokens back
together to a character.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected) and <code>value</code> (seperator used for
collapsing).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)
library(modeldata)
data(tate_text)

tate_rec &lt;- recipe(~., data = tate_text) %&gt;%
  step_tokenize(medium) %&gt;%
  step_untokenize(medium)

tate_obj &lt;- tate_rec %&gt;%
  prep()

bake(tate_obj, new_data = NULL, medium) %&gt;%
  slice(1:2)

bake(tate_obj, new_data = NULL) %&gt;%
  slice(2) %&gt;%
  pull(medium)

tidy(tate_rec, number = 2)
tidy(tate_obj, number = 2)
</code></pre>

<hr>
<h2 id='step_word_embeddings'>Pretrained Word Embeddings of Tokens</h2><span id='topic+step_word_embeddings'></span>

<h3>Description</h3>

<p><code>step_word_embeddings()</code> creates a <em>specification</em> of a recipe step that will
convert a <code><a href="#topic+tokenlist">token</a></code> variable into word-embedding dimensions by
aggregating the vectors of each token from a pre-trained embedding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>step_word_embeddings(
  recipe,
  ...,
  role = "predictor",
  trained = FALSE,
  columns = NULL,
  embeddings,
  aggregation = c("sum", "mean", "min", "max"),
  aggregation_default = 0,
  prefix = "wordembed",
  keep_original_cols = FALSE,
  skip = FALSE,
  id = rand_id("word_embeddings")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="step_word_embeddings_+3A_recipe">recipe</code></td>
<td>
<p>A <a href="recipes.html#topic+recipe">recipe</a> object. The step will be added to the
sequence of operations for this recipe.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_...">...</code></td>
<td>
<p>One or more selector functions to choose which
variables are affected by the step. See <code><a href="recipes.html#topic+selections">recipes::selections()</a></code>
for more details.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_role">role</code></td>
<td>
<p>For model terms created by this step, what analysis
role should they be assigned?. By default, the function assumes
that the new columns created by the original variables will be
used as predictors in a model.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_trained">trained</code></td>
<td>
<p>A logical to indicate if the quantities for
preprocessing have been estimated.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_columns">columns</code></td>
<td>
<p>A character string of variable names that will
be populated (eventually) by the <code>terms</code> argument. This is <code>NULL</code>
until the step is trained by <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code>.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_embeddings">embeddings</code></td>
<td>
<p>A tibble of pre-trained word embeddings, such as those
returned by the embedding_glove function from the textdata package. The
first column should contain tokens, and additional columns should contain
embeddings vectors.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_aggregation">aggregation</code></td>
<td>
<p>A character giving the name of the aggregation function to
use. Must be one of &quot;sum&quot;, &quot;mean&quot;, &quot;min&quot;, and &quot;max&quot;. Defaults to &quot;sum&quot;.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_aggregation_default">aggregation_default</code></td>
<td>
<p>A numeric denoting the default value for case with
no words are matched in embedding. Defaults to 0.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_prefix">prefix</code></td>
<td>
<p>A character string that will be the prefix to the
resulting new variables. See notes below.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_keep_original_cols">keep_original_cols</code></td>
<td>
<p>A logical to keep the original variables in the
output. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_skip">skip</code></td>
<td>
<p>A logical. Should the step be skipped when the
recipe is baked by <code><a href="recipes.html#topic+bake">recipes::bake.recipe()</a></code>? While all operations are baked
when <code><a href="recipes.html#topic+prep">recipes::prep.recipe()</a></code> is run, some operations may not be able to be
conducted on new data (e.g. processing the outcome variable(s)).
Care should be taken when using <code>skip = FALSE</code>.</p>
</td></tr>
<tr><td><code id="step_word_embeddings_+3A_id">id</code></td>
<td>
<p>A character string that is unique to this step to identify it.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Word embeddings map words (or other tokens) into a high-dimensional feature
space. This function maps pre-trained word embeddings onto the tokens in your
data.
</p>
<p>The argument <code>embeddings</code> provides the pre-trained vectors. Each dimension
present in this tibble becomes a new feature column, with each column
aggregated across each row of your text using the function supplied in the
<code>aggregation</code> argument.
</p>
<p>The new components will have names that begin with <code>prefix</code>, then the name of
the aggregation function, then the name of the variable from the embeddings
tibble (usually something like &quot;d7&quot;). For example, using the default
&quot;wordembedding&quot; prefix, and the GloVe embeddings from the textdata package
(where the column names are <code>d1</code>, <code>d2</code>, etc), new columns would be
<code>wordembedding_d1</code>, <code>wordembedding_d1</code>, etc.
</p>


<h3>Value</h3>

<p>An updated version of <code>recipe</code> with the new step added
to the sequence of existing steps (if any).
</p>


<h3>Tidying</h3>

<p>When you <code><a href="#topic+tidy.recipe">tidy()</a></code> this step, a tibble with columns <code>terms</code>
(the selectors or variables selected), <code>embedding_rows</code> (number of rows in
embedding), and <code>aggregation</code> (the aggregation method).
</p>


<h3>Case weights</h3>

<p>The underlying operation does not allow for case weights.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+step_tokenize">step_tokenize()</a></code> to turn characters into <code><a href="#topic+tokenlist">tokens</a></code>
</p>
<p>Other Steps for Numeric Variables From Tokens: 
<code><a href="#topic+step_lda">step_lda</a>()</code>,
<code><a href="#topic+step_texthash">step_texthash</a>()</code>,
<code><a href="#topic+step_tfidf">step_tfidf</a>()</code>,
<code><a href="#topic+step_tf">step_tf</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(recipes)

embeddings &lt;- tibble(
  tokens = c("the", "cat", "ran"),
  d1 = c(1, 0, 0),
  d2 = c(0, 1, 0),
  d3 = c(0, 0, 1)
)

sample_data &lt;- tibble(
  text = c(
    "The.",
    "The cat.",
    "The cat ran."
  ),
  text_label = c("fragment", "fragment", "sentence")
)

rec &lt;- recipe(text_label ~ ., data = sample_data) %&gt;%
  step_tokenize(text) %&gt;%
  step_word_embeddings(text, embeddings = embeddings)

obj &lt;- rec %&gt;%
  prep()

bake(obj, sample_data)

tidy(rec, number = 2)
tidy(obj, number = 2)
</code></pre>

<hr>
<h2 id='tidy.step_clean_levels'>Tidy the Result of a Recipe</h2><span id='topic+tidy.step_clean_levels'></span><span id='topic+tidy.step_clean_names'></span><span id='topic+tidy.step_dummy_hash'></span><span id='topic+tidy.step_lda'></span><span id='topic+tidy.step_lemma'></span><span id='topic+tidy.step_ngram'></span><span id='topic+tidy.step_pos_filter'></span><span id='topic+tidy.step_sequence_onehot'></span><span id='topic+tidy.step_stem'></span><span id='topic+tidy.step_stopwords'></span><span id='topic+tidy.step_text_normalization'></span><span id='topic+tidy.step_textfeature'></span><span id='topic+tidy.step_texthash'></span><span id='topic+tidy.step_tf'></span><span id='topic+tidy.step_tfidf'></span><span id='topic+tidy.recipe'></span><span id='topic+tidy.step_tokenfilter'></span><span id='topic+tidy.step_tokenize'></span><span id='topic+tidy.step_tokenize_bpe'></span><span id='topic+tidy.step_tokenize_sentencepiece'></span><span id='topic+tidy.step_tokenize_wordpiece'></span><span id='topic+tidy.step_tokenmerge'></span><span id='topic+tidy.step_untokenize'></span><span id='topic+tidy.step_word_embeddings'></span>

<h3>Description</h3>

<p><code>tidy</code> will return a data frame that contains information regarding a recipe
or operation within the recipe (when a <code>tidy</code> method for the operation
exists). See <a href="recipes.html#topic+tidy.recipe">recipes::tidy.recipe</a> for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'step_clean_levels'
tidy(x, ...)

## S3 method for class 'step_clean_names'
tidy(x, ...)

## S3 method for class 'step_dummy_hash'
tidy(x, ...)

## S3 method for class 'step_lda'
tidy(x, ...)

## S3 method for class 'step_lemma'
tidy(x, ...)

## S3 method for class 'step_ngram'
tidy(x, ...)

## S3 method for class 'step_pos_filter'
tidy(x, ...)

## S3 method for class 'step_sequence_onehot'
tidy(x, ...)

## S3 method for class 'step_stem'
tidy(x, ...)

## S3 method for class 'step_stopwords'
tidy(x, ...)

## S3 method for class 'step_text_normalization'
tidy(x, ...)

## S3 method for class 'step_textfeature'
tidy(x, ...)

## S3 method for class 'step_texthash'
tidy(x, ...)

## S3 method for class 'step_tf'
tidy(x, ...)

## S3 method for class 'step_tfidf'
tidy(x, ...)

## S3 method for class 'step_tokenfilter'
tidy(x, ...)

## S3 method for class 'step_tokenize'
tidy(x, ...)

## S3 method for class 'step_tokenize_bpe'
tidy(x, ...)

## S3 method for class 'step_tokenize_sentencepiece'
tidy(x, ...)

## S3 method for class 'step_tokenize_wordpiece'
tidy(x, ...)

## S3 method for class 'step_tokenmerge'
tidy(x, ...)

## S3 method for class 'step_untokenize'
tidy(x, ...)

## S3 method for class 'step_word_embeddings'
tidy(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tidy.step_clean_levels_+3A_x">x</code></td>
<td>
<p>A <code>step_word_embeddings</code> object.</p>
</td></tr>
<tr><td><code id="tidy.step_clean_levels_+3A_...">...</code></td>
<td>
<p>Not currently used.</p>
</td></tr>
</table>

<hr>
<h2 id='tokenlist'>Create Token Object</h2><span id='topic+tokenlist'></span>

<h3>Description</h3>

<p>A <a href="#topic+tokenlist">tokenlist</a> object is a thin wrapper around a list of character vectors,
with a few attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenlist(tokens = list(), lemma = NULL, pos = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokenlist_+3A_tokens">tokens</code></td>
<td>
<p>List of character vectors</p>
</td></tr>
<tr><td><code id="tokenlist_+3A_lemma">lemma</code></td>
<td>
<p>List of character vectors, must be same size and shape as <code>x</code>.</p>
</td></tr>
<tr><td><code id="tokenlist_+3A_pos">pos</code></td>
<td>
<p>List of character vectors, must be same size and shape as <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <a href="#topic+tokenlist">tokenlist</a> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>abc &lt;- list(letters, LETTERS)
tokenlist(abc)

unclass(tokenlist(abc))

tibble(text = tokenlist(abc))

library(tokenizers)
library(modeldata)
data(tate_text)
tokens &lt;- tokenize_words(as.character(tate_text$medium))

tokenlist(tokens)
</code></pre>

<hr>
<h2 id='tunable.step_dummy_hash'>tunable methods for textrecipes</h2><span id='topic+tunable.step_dummy_hash'></span><span id='topic+tunable.step_ngram'></span><span id='topic+tunable.step_texthash'></span><span id='topic+tunable.step_tf'></span><span id='topic+tunable.step_tokenfilter'></span><span id='topic+tunable.step_tokenize'></span><span id='topic+tunable.step_tokenize_bpe'></span><span id='topic+tunable_textrecipes'></span>

<h3>Description</h3>

<p>These functions define what parameters <em>can</em> be tuned for specific steps.
They also define the recommended objects from the <code>dials</code> package that can
be used to generate new parameter values and other characteristics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'step_dummy_hash'
tunable(x, ...)

## S3 method for class 'step_ngram'
tunable(x, ...)

## S3 method for class 'step_texthash'
tunable(x, ...)

## S3 method for class 'step_tf'
tunable(x, ...)

## S3 method for class 'step_tokenfilter'
tunable(x, ...)

## S3 method for class 'step_tokenize'
tunable(x, ...)

## S3 method for class 'step_tokenize_bpe'
tunable(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tunable.step_dummy_hash_+3A_x">x</code></td>
<td>
<p>A recipe step object</p>
</td></tr>
<tr><td><code id="tunable.step_dummy_hash_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble object.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
