<!DOCTYPE html><html lang="en"><head><title>Help for package BiDAG</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BiDAG}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Asia'><p>Asia dataset</p></a></li>
<li><a href='#Asiamat'><p>Asiamat</p></a></li>
<li><a href='#bidag2coda'><p>Converting a single BiDAG chain to mcmc object</p></a></li>
<li><a href='#bidag2codalist'><p>Converting multiple BiDAG chains to mcmc.list</p></a></li>
<li><a href='#Boston'><p>Boston housing data</p></a></li>
<li><a href='#compact2full'><p>Deriving an adjecency matrix of a full DBN</p></a></li>
<li><a href='#compareDAGs'><p>Comparing two graphs</p></a></li>
<li><a href='#compareDBNs'><p>Comparing two DBNs</p></a></li>
<li><a href='#connectedSubGraph'><p>Deriving connected subgraph</p></a></li>
<li><a href='#DAGscore'><p>Calculating the BGe/BDe score of a single DAG</p></a></li>
<li><a href='#DBNdata'><p>Simulated data set from a 2-step dynamic Bayesian network</p></a></li>
<li><a href='#DBNmat'><p>An adjacency matrix of a dynamic Bayesian network</p></a></li>
<li><a href='#DBNscore'><p>Calculating the BGe/BDe score of a single DBN</p></a></li>
<li><a href='#DBNunrolled'><p>An unrolled adjacency matrix of a dynamic Bayesian network</p></a></li>
<li><a href='#edgep'><p>Estimating posterior probabilities of single edges</p></a></li>
<li><a href='#full2compact'><p>Deriving a compact adjacency matrix of a DBN</p></a></li>
<li><a href='#getDAG'><p>Extracting adjacency matrix (DAG) from MCMC object</p></a></li>
<li><a href='#getMCMCscore'><p>Extracting score from MCMC object</p></a></li>
<li><a href='#getRuntime'><p>Extracting runtime</p></a></li>
<li><a href='#getSpace'><p>Extracting scorespace from MCMC object</p></a></li>
<li><a href='#getSubGraph'><p>Deriving subgraph</p></a></li>
<li><a href='#getTrace'><p>Extracting trace from MCMC object</p></a></li>
<li><a href='#graph2m'><p>Deriving an adjacency matrix of a graph</p></a></li>
<li><a href='#gsim'><p>A simulated data set from a Gaussian continuous Bayesian network</p></a></li>
<li><a href='#gsim100'><p>A simulated data set from a Gaussian continuous Bayesian network</p></a></li>
<li><a href='#gsimmat'><p>An adjacency matrix of a simulated dataset</p></a></li>
<li><a href='#interactions'><p>interactions dataset</p></a></li>
<li><a href='#iterativeMCMC'><p>Structure learning with an iterative order MCMC algorithm on an expanded search space</p></a></li>
<li><a href='#iterativeMCMC+20class'><p>iterativeMCMC class structure</p></a></li>
<li><a href='#itercomp'><p>Performance assessment of iterative MCMC scheme against a known Bayesian network</p></a></li>
<li><a href='#kirc'><p>kirc dataset</p></a></li>
<li><a href='#kirp'><p>kirp dataset</p></a></li>
<li><a href='#learnBN'><p>Bayesian network structure learning</p></a></li>
<li><a href='#m2graph'><p>Deriving a graph from an adjacancy matrix</p></a></li>
<li><a href='#mapping'><p>mapping dataset</p></a></li>
<li><a href='#modelp'><p>Estimating a graph corresponding to a posterior probability threshold</p></a></li>
<li><a href='#orderMCMC'><p>Structure learning with the order MCMC algorithm</p></a></li>
<li><a href='#orderMCMC+20class'><p>orderMCMC class structure</p></a></li>
<li><a href='#partitionMCMC'><p>DAG structure sampling with partition MCMC</p></a></li>
<li><a href='#partitionMCMC+20class'><p>partitionMCMC class structure</p></a></li>
<li><a href='#plot2in1'><p>Highlighting similarities between two graphs</p></a></li>
<li><a href='#plotDBN'><p>Plotting a DBN</p></a></li>
<li><a href='#plotdiffs'><p>Plotting difference between two graphs</p></a></li>
<li><a href='#plotdiffsDBN'><p>Plotting difference between two DBNs</p></a></li>
<li><a href='#plotpcor'><p>Comparing posterior probabilitites of single edges</p></a></li>
<li><a href='#plotpedges'><p>Plotting posterior probabilities of single edges</p></a></li>
<li><a href='#sampleBN'><p>Bayesian network structure sampling from the posterior distribution</p></a></li>
<li><a href='#samplecomp'><p>Performance assessment of sampling algorithms against a known Bayesian network</p></a></li>
<li><a href='#scoreagainstDAG'><p>Calculating the score of a sample against a DAG</p></a></li>
<li><a href='#scoreagainstDBN'><p>Score against DBN</p></a></li>
<li><a href='#scoreparameters'><p>Initializing score object</p></a></li>
<li><a href='#scorespace'><p>Prints 'scorespace' object</p></a></li>
<li><a href='#scorespace+20class'><p>scorespace class structure</p></a></li>
<li><a href='#string2mat'><p>Deriving interactions matrix</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Bayesian Inference for Directed Acyclic Graphs</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.4</td>
</tr>
<tr>
<td>Author:</td>
<td>Polina Suter [aut, cre], Jack Kuipers [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Polina Suter &lt;polina.suter@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of a collection of MCMC methods for Bayesian structure learning
    of directed acyclic graphs (DAGs), both from continuous and discrete data. For efficient
    inference on larger DAGs, the space of DAGs is pruned according to the data. To filter
    the search space, the algorithm employs a hybrid approach, combining constraint-based 
    learning with search and score. A reduced search space is initially defined on the basis
    of a skeleton obtained by means of the PC-algorithm, and then iteratively improved with
    search and score. Search and score is then performed following two approaches:
    Order MCMC, or Partition MCMC.
    The BGe score is implemented for continuous data and the BDe score is implemented
    for binary data or categorical data. The algorithms may provide the maximum a posteriori 
    (MAP) graph or a sample (a collection of DAGs) from the posterior distribution given the data.
    All algorithms are also applicable for structure learning and sampling for dynamic Bayesian networks.
    References:
    J. Kuipers, P. Suter, G. Moffa (2022) &lt;<a href="https://doi.org/10.1080%2F10618600.2021.2020127">doi:10.1080/10618600.2021.2020127</a>&gt;,
    N. Friedman and D. Koller (2003) &lt;<a href="https://doi.org/10.1023%2FA%3A1020249912095">doi:10.1023/A:1020249912095</a>&gt;, 
    J. Kuipers and G. Moffa (2017) &lt;<a href="https://doi.org/10.1080%2F01621459.2015.1133426">doi:10.1080/01621459.2015.1133426</a>&gt;, 
    M. Kalisch et al. (2012) &lt;<a href="https://doi.org/10.18637%2Fjss.v047.i11">doi:10.18637/jss.v047.i11</a>&gt;,
    D. Geiger and D. Heckerman (2002) &lt;<a href="https://doi.org/10.1214%2Faos%2F1035844981">doi:10.1214/aos/1035844981</a>&gt;, 
    P. Suter, J. Kuipers, G. Moffa, N.Beerenwinkel (2023) &lt;<a href="https://doi.org/10.18637%2Fjss.v105.i09">doi:10.18637/jss.v105.i09</a>&gt;.</td>
</tr>
<tr>
<td>Acknowledgments:</td>
<td>We would like to thank Giusi Moffa for discussion and
comments on the package and its manual.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.7), methods, graph, Rgraphviz, RBGL, pcalg,
graphics, Matrix, coda</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-15 11:04:33 UTC; polinasuter</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-16 12:46:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Asia'>Asia dataset</h2><span id='topic+Asia'></span>

<h3>Description</h3>

<p>A synthetic dataset from Lauritzen and Spiegelhalter (1988) about lung
diseases (tuberculosis, lung cancer or bronchitis) and visits to Asia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Asia
</code></pre>


<h3>Format</h3>

<p>A data frame with 5000 rows and 8 binary variables:
</p>

<ul>
<li><p> D (dyspnoea), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> T (tuberculosis), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> L (lung cancer), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> B (bronchitis), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> A (visit to Asia), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> S (smoking), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> X (chest X-ray), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> E (tuberculosis versus lung cancer/bronchitis), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://www.bnlearn.com/bnrepository/">https://www.bnlearn.com/bnrepository/</a>
</p>


<h3>References</h3>

<p>Lauritzen S, Spiegelhalter D (1988). &lsquo;Local Computation with Probabilities on Graphical Structures and their Application to Expert Systems (with discussion)&rsquo;.
Journal of the Royal Statistical Society: Series B 50, 157-224.
</p>

<hr>
<h2 id='Asiamat'>Asiamat</h2><span id='topic+Asiamat'></span>

<h3>Description</h3>

<p>An adjacency matrix representing the ground truth DAG used to generate a synthetic dataset from 
Lauritzen and Spiegelhalter (1988) about lung
diseases (tuberculosis, lung cancer or bronchitis) and visits to Asia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Asiamat
</code></pre>


<h3>Format</h3>

<p>A binary matrix with 8 rows and 8 columns representing an adjacency matrix of a DAG with 8 nodes:
</p>

<ul>
<li><p> D (dyspnoea), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> T (tuberculosis), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> L (lung cancer), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> B (bronchitis), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> A (visit to Asia), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> S (smoking), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> X (chest X-ray), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li>
<li><p> E (tuberculosis versus lung cancer/bronchitis), binary 1/0 corresponding to &quot;yes&quot; and &quot;no&quot;
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://www.bnlearn.com/bnrepository/">https://www.bnlearn.com/bnrepository/</a>
</p>


<h3>References</h3>

<p>Lauritzen S, Spiegelhalter D (1988). &lsquo;Local Computation with Probabilities on Graphical Structures and their Application to Expert Systems (with discussion)&rsquo;.
Journal of the Royal Statistical Society: Series B 50, 157-224.
</p>

<hr>
<h2 id='bidag2coda'>Converting a single BiDAG chain to mcmc object</h2><span id='topic+bidag2coda'></span>

<h3>Description</h3>

<p>This function converts a single object of one of the BiDAG classes,
namely 'orderMCMC' or 'partitionMCMC' to an object of class 'mcmc'. This object can
be further used for convergence and mixing diagnostics implemented in the package coda
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bidag2coda(
  MCMCtrace,
  edges = FALSE,
  pdag = TRUE,
  p = 0.1,
  burnin = 0.2,
  window = 100,
  cumulative = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bidag2coda_+3A_mcmctrace">MCMCtrace</code></td>
<td>
<p>object of class <code>orderMCMC</code> or <code>partitionMCMC</code></p>
</td></tr>
<tr><td><code id="bidag2coda_+3A_edges">edges</code></td>
<td>
<p>logical, when FALSE (default), then only DAG score trace is extracted; when TRUE, a trace of posterior probabilities is extracted for every edge (based on the sampled DAGs defined by parameters 'window' and 'cumulative') resulting in up to n^2 trace vectors, where n is the number of nodes in the network</p>
</td></tr>
<tr><td><code id="bidag2coda_+3A_pdag">pdag</code></td>
<td>
<p>logical, when edges=TRUE, defines if the DAGs are converted to CPDAGs prior to computing posterior probabilities; ignored otherwise</p>
</td></tr>
<tr><td><code id="bidag2coda_+3A_p">p</code></td>
<td>
<p>numeric, between 0 and 1; defines the minimum probability for including posterior traces in the returned objects (for probabilities close to 0 PRSF diagnostics maybe too conservative)</p>
</td></tr>
<tr><td><code id="bidag2coda_+3A_burnin">burnin</code></td>
<td>
<p>numeric between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be discarded as 'burn-in' of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
<tr><td><code id="bidag2coda_+3A_window">window</code></td>
<td>
<p>integer, defines a number of DAG samples for averaging and computing edges' posterior probabilities; ignored when edges=FALSE</p>
</td></tr>
<tr><td><code id="bidag2coda_+3A_cumulative">cumulative</code></td>
<td>
<p>logical, indicates if posterior probabilities should be calculated based on a cumulative sample of DAGs, where 25% of the first samples are discarded</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>mcmc</code> from the package <span class="pkg">coda</span>
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(coda)
myscore&lt;-scoreparameters("bde",Asia)
ordersample&lt;-sampleBN(myscore,"order")
order_mcmc&lt;-bidag2coda(ordersample)
par(mfrow=c(1,2))
densplot(order_mcmc)
traceplot(order_mcmc)

## End(Not run)
</code></pre>

<hr>
<h2 id='bidag2codalist'>Converting multiple BiDAG chains to mcmc.list</h2><span id='topic+bidag2codalist'></span>

<h3>Description</h3>

<p>This function converts a list of objects of classes
'orderMCMC' or 'partitionMCMC' to an object of class 'mcmc.list'. This object can
be further used for convergence and mixing diagnostics implemented in the R-package coda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bidag2codalist(
  MCMClist,
  edges = FALSE,
  pdag = TRUE,
  p = 0.1,
  burnin = 0.2,
  window = 10,
  cumulative = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bidag2codalist_+3A_mcmclist">MCMClist</code></td>
<td>
<p>a list of objects of classes <code>orderMCMC</code> or <code>partitionMCMC</code></p>
</td></tr>
<tr><td><code id="bidag2codalist_+3A_edges">edges</code></td>
<td>
<p>logical, when FALSE (default), then only DAG score trace is extracted; when TRUE, a trace of posterior probabilities is extracted for every edge (based on the sampled DAGs defined by parameters 'window' and 'cumulative') resulting in up to n^2 trace vectors, where n is the number of nodes in the network</p>
</td></tr>
<tr><td><code id="bidag2codalist_+3A_pdag">pdag</code></td>
<td>
<p>logical, when edges=TRUE, defines if the DAGs are converted to CPDAGs prior to computing posterior probabilities; ignored otherwise</p>
</td></tr>
<tr><td><code id="bidag2codalist_+3A_p">p</code></td>
<td>
<p>numeric, between 0 and 1; defines the minimum probability for including posterior traces in the returned objects (for probabilities close to 0, PRSF diagnostics maybe too conservative; the threshold above 0 is recommended)</p>
</td></tr>
<tr><td><code id="bidag2codalist_+3A_burnin">burnin</code></td>
<td>
<p>numeric between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be discarded as 'burn-in' of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
<tr><td><code id="bidag2codalist_+3A_window">window</code></td>
<td>
<p>integer, defines a number of DAG samples for averaging and computing edges' posterior probabilities; ignored when edges=FALSE</p>
</td></tr>
<tr><td><code id="bidag2codalist_+3A_cumulative">cumulative</code></td>
<td>
<p>logical, indicates if posterior probabilities should be calculated based on a cumulative sample of DAGs, where 25% of the first samples are discarded</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>mcmc.list</code> from the package <span class="pkg">coda</span>
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>References</h3>

<p>Robert J. B. Goudie and Sach Mukherjee (2016). A Gibbs Sampler for Learning DAGs. J Mach Learn Res. 2016 Apr; 17(30): 1â€“39.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(coda)
scoreBoston&lt;-scoreparameters("bge",Boston)
ordershort&lt;-list()
#run very short chains -&gt; convergence issues
ordershort[[1]] &lt;- sampleBN(scoreBoston, algorithm = "order", iterations=2000)
ordershort[[2]] &lt;- sampleBN(scoreBoston, algorithm = "order", iterations=2000)
codashort_edges&lt;-bidag2codalist(ordershort,edges=TRUE,pdag=TRUE,p=0.05,burnin=0.2,window=10)
gd_short&lt;-gelman.diag(codashort_edges, transform=FALSE, autoburnin=FALSE, multivariate=FALSE)
length(which(gd_short$psrf[,1]&gt;1.1))/(length(gd_short$psrf[,1]))
#=&gt;more MCMC iterations are needed, try 100000

## End(Not run)
</code></pre>

<hr>
<h2 id='Boston'>Boston housing data</h2><span id='topic+Boston'></span>

<h3>Description</h3>

<p>A dataset containing information collected by the U.S Census Service concerning housing
in the area of Boston, originally published by Harrison and Rubinfeld (1978).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Boston
</code></pre>


<h3>Format</h3>

<p>A data frame with 506 rows and 14 variables:
</p>

<ul>
<li><p> CRIM - per capita crime rate by town
</p>
</li>
<li><p> ZN - proportion of residential land zoned for lots over 25,000 sq.ft.
</p>
</li>
<li><p> INDUS - proportion of non-retail business acres per town.
</p>
</li>
<li><p> CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)
</p>
</li>
<li><p> NOX - nitric oxides concentration (parts per 10 million)
</p>
</li>
<li><p> RM - average number of rooms per dwelling
</p>
</li>
<li><p> AGE - proportion of owner-occupied units built prior to 1940
</p>
</li>
<li><p> DIS - weighted distances to five Boston employment centres
</p>
</li>
<li><p> TAX - full-value property-tax rate per $10,000
</p>
</li>
<li><p> RAD - index of accessibility to radial highways
</p>
</li>
<li><p> PTRATIO - pupil-teacher ratio by town
</p>
</li>
<li><p> B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
</p>
</li>
<li><p> LSTAT - percentage lower status of the population
</p>
</li>
<li><p> MEDV - Median value of owner-occupied homes in $1000's
</p>
</li></ul>



<h3>Source</h3>

<p><a href="http://lib.stat.cmu.edu/datasets/boston">http://lib.stat.cmu.edu/datasets/boston</a>
</p>


<h3>References</h3>

<p>Harrison, D and Rubinfeld, DL (1978)
&lsquo;Hedonic prices and the demand for clean air&rsquo;,
Journal of Environmental Economics and Management 5, 81-102.
</p>

<hr>
<h2 id='compact2full'>Deriving an adjecency matrix of a full DBN</h2><span id='topic+compact2full'></span>

<h3>Description</h3>

<p>This function transforms a compact 2-slice adjacency matrix of DBN into full T-slice adjacency matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compact2full(DBNmat, slices, b = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compact2full_+3A_dbnmat">DBNmat</code></td>
<td>
<p>a square matrix, representing initial and transitional structure of a DBN; the size of matrix is 2*dyn+b</p>
</td></tr>
<tr><td><code id="compact2full_+3A_slices">slices</code></td>
<td>
<p>integer, number of slices in an unrolled DBN</p>
</td></tr>
<tr><td><code id="compact2full_+3A_b">b</code></td>
<td>
<p>integer, number of static variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an adjacency matrix of an unrolled DBN
</p>


<h3>Examples</h3>

<pre><code class='language-R'>compact2full(DBNmat, slices=5, b=3)
</code></pre>

<hr>
<h2 id='compareDAGs'>Comparing two graphs</h2><span id='topic+compareDAGs'></span>

<h3>Description</h3>

<p>This function compares one (estimated) graph to another graph (true graph), returning a vector of 8 values: 
</p>

<ul>
<li><p> the number of true positive edges ('TP') is the number of edges in the skeleton of 'egraph' which are also present in the skeleton of 'truegraph'
</p>
</li>
<li><p> the number of false positive edges ('FP') is the number of edges in the skeleton of 'egraph' which are absent in the skeleton of 'truegraph'
</p>
</li>
<li><p> the number of fralse negative edges ('FN') is the number of edges in the skeleton of 'truegraph' which are absent in the skeleton of 'egraph'
</p>
</li>
<li><p> structural Hamming distance ('SHD') between 2 graphs is computed as TP+FP+the number of edges with an error in direction
</p>
</li>
<li><p> TPR equals TP/(TP+FN)
</p>
</li>
<li><p> FPR equals FP/(TN+FP) (TN stands for true negative edges)
</p>
</li>
<li><p> FPRn equals FP/(TP+FN)
</p>
</li>
<li><p> FDR equals FP/(TP+FP)
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>compareDAGs(egraph, truegraph, cpdag = FALSE, rnd = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareDAGs_+3A_egraph">egraph</code></td>
<td>
<p>an object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> (package &lsquo;graph&rsquo;), representing the graph which should be compared to a ground truth graph or an ajecency matrix corresponding to the graph</p>
</td></tr>
<tr><td><code id="compareDAGs_+3A_truegraph">truegraph</code></td>
<td>
<p>an object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> (package &lsquo;graph&rsquo;), representing the ground truth graph or an ajecency matrix corresponding to this graph</p>
</td></tr>
<tr><td><code id="compareDAGs_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if TRUE (FALSE by default) both graphs are first converted to their respective equivalence class (CPDAG); this affects SHD calculation</p>
</td></tr>
<tr><td><code id="compareDAGs_+3A_rnd">rnd</code></td>
<td>
<p>integer, rounding integer indicating the number of decimal places (round) when computing TPR, FPR, FPRn and FDR</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a named numeric vector 8 elements: SHD, number of true positive edges (TP), number of false positive edges (FP), number of false negative edges (FN), true positive rate (TPR),
false positive rate (FPR), false positive rate normalized to the true number of edges (FPRn) and false discovery rate (FDR)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Asiascore&lt;-scoreparameters("bde", Asia)
## Not run: 
eDAG&lt;-learnBN(Asiascore,algorithm="order")
compareDAGs(eDAG$DAG,Asiamat)

## End(Not run)
</code></pre>

<hr>
<h2 id='compareDBNs'>Comparing two DBNs</h2><span id='topic+compareDBNs'></span>

<h3>Description</h3>

<p>This function compares one (estimated) DBN structure to another DBN (true DBN). Comparisons for initial and transitional structures are returned separately if <code>equalstruct</code> equals <code>TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareDBNs(eDBN, trueDBN, struct = c("init", "trans"), b = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareDBNs_+3A_edbn">eDBN</code></td>
<td>
<p>an object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> (or an ajacency matrix corresponding to this DBN), representing the DBN which should be compared to a ground truth DBN</p>
</td></tr>
<tr><td><code id="compareDBNs_+3A_truedbn">trueDBN</code></td>
<td>
<p>an object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> (or an ajacency matrix corresponding to this DBN), representing the ground truth DBN</p>
</td></tr>
<tr><td><code id="compareDBNs_+3A_struct">struct</code></td>
<td>
<p>option used to determine if the initial or the transitional structure should be compared; accaptable values are init or trans</p>
</td></tr>
<tr><td><code id="compareDBNs_+3A_b">b</code></td>
<td>
<p>number of static variables in one time slice of a DBN; note that for function to work correctly all static variables have to be in the first b columns of the matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of 5: SHD, number of true positive edges, number of false positive edges, number of false negative edges and true positive rate
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testscore&lt;-scoreparameters("bge", DBNdata, DBN=TRUE, 
dbnpar=list(samestruct=TRUE, slices=5, b=3))
## Not run: 
DBNfit&lt;-learnBN(testscore, algorithm="orderIter",moveprobs=c(0.11,0.84,0.04,0.01))
compareDBNs(DBNfit$DAG,DBNmat, struct="trans", b=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='connectedSubGraph'>Deriving connected subgraph</h2><span id='topic+connectedSubGraph'></span>

<h3>Description</h3>

<p>This function derives an adjacency matrix of a subgraph whose nodes are connected to at least one other node in a graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>connectedSubGraph(adj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="connectedSubGraph_+3A_adj">adj</code></td>
<td>
<p>square adjacency matrix with elements in <code>{0,1}</code>, representing a graph</p>
</td></tr>
</table>


<h3>Value</h3>

<p>adjacency matrix of a subgraph of graph represented by 'adj' whose nodes have at least one connection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dim(gsimmat) #full graph contains 100 nodes
gconn&lt;-connectedSubGraph(gsimmat) #removing disconnected nodes
dim(gconn) #connected subgraph contains 93 nodes
</code></pre>

<hr>
<h2 id='DAGscore'>Calculating the BGe/BDe score of a single DAG</h2><span id='topic+DAGscore'></span>

<h3>Description</h3>

<p>This function calculates the score of a DAG defined by its adjacency matrix. 
Acceptable data matrices are homogeneous with all variables of the same type: 
continuous, binary or categorical.  The BGe score is evaluated in the case of 
continuous data and the BDe score is evaluated for binary and categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DAGscore(scorepar, incidence)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DAGscore_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and
scoring parameters; see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="DAGscore_+3A_incidence">incidence</code></td>
<td>
<p>a square matrix of dimensions equal to the number of nodes, representing the adjacency matrix of a DAG;  the matrix entries are in <code>{0,1}</code> such that <code>incidence[i,j]</code> equals 1 if there is a directed edge from node <code>i</code> to node <code>j</code> in the DAG and 
<code>incidence[i,j]</code> equals 0 otherwise</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the log of the BGe or BDe score of the DAG
</p>


<h3>Author(s)</h3>

<p>Jack Kuipers, Polina Suter, the code partly derived from the order MCMC implementation from Kuipers J, Moffa G (2017) &lt;doi:10.1080/01621459.2015.1133426&gt;
</p>


<h3>References</h3>

<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Heckerman D and Geiger D (1995). Learning Bayesian networks: A unification for discrete and Gaussian domains. In Eleventh Conference on Uncertainty in Artificial Intelligence, pages 274-284.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian directed acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myScore&lt;-scoreparameters("bde", Asia)
DAGscore(myScore, Asiamat)
</code></pre>

<hr>
<h2 id='DBNdata'>Simulated data set from a 2-step dynamic Bayesian network</h2><span id='topic+DBNdata'></span>

<h3>Description</h3>

<p>A synthetic dataset containing 100 observations generated from a random dynamic Bayesian network with 12 continuous dynamic nodes and 3 static nodes.
The DBN includes observations from 5 time slices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DBNdata
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows and 63 (3+12*5) columns representing observations of 15 variables: 3 static variables (first 3 columns) which do not change over time and 12 dynamic variables observed in 5 conseecutive time slices.
</p>

<hr>
<h2 id='DBNmat'>An adjacency matrix of a dynamic Bayesian network</h2><span id='topic+DBNmat'></span>

<h3>Description</h3>

<p>An adjacency matrix representing the ground truth DBN used to generate a synthetic dataset <code><a href="#topic+DBNdata">DBNdata</a></code>. The matrix is a compact representation of a 2-step DBN, such that initial structure is stored in the first 15 columns of the matrix and transitional structure is stored in the last 12 columns of the matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DBNmat
</code></pre>


<h3>Format</h3>

<p>A binary matrix with 27 rows and 27 columns representing an adjacency matrix of a DBN. Rows and columns of the matrix correspond to 15 variables of a DBN across 2 time slices.
</p>

<hr>
<h2 id='DBNscore'>Calculating the BGe/BDe score of a single DBN</h2><span id='topic+DBNscore'></span>

<h3>Description</h3>

<p>This function calculates the score of a DBN defined by its compact adjacency matrix. 
Acceptable data matrices are homogeneous with all variables of the same type: continuous,
binary or categorical.  The BGe score is evaluated in the case of continuous data and the BDe score is evaluated for binary and categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DBNscore(scorepar, incidence)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DBNscore_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and scoring parameters; see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="DBNscore_+3A_incidence">incidence</code></td>
<td>
<p>a square matrix, representing initial and transitional structure of a DBN; the size of matrix is 2*nsmall+bgn, where nsmall is the number of variables per time slice excluding static nodes and bgn is the number of static variables
the matrix entries are in <code>{0,1}</code> such that <code>incidence[i,j]</code> equals
1 if there is a directed edge from node <code>i</code> to node <code>j</code> in the DAG and 
<code>incidence[i,j]</code> equals 0 otherwise</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the log of the BGe or BDe score of the DBN
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack Kuipers
</p>


<h3>Examples</h3>

<pre><code class='language-R'>testscore&lt;-scoreparameters("bge", DBNdata, DBN=TRUE, dbnpar=list(slices=5, b=3))
DBNscore(testscore, DBNmat)

</code></pre>

<hr>
<h2 id='DBNunrolled'>An unrolled adjacency matrix of a dynamic Bayesian network</h2><span id='topic+DBNunrolled'></span>

<h3>Description</h3>

<p>An adjacency matrix representing the ground truth DBN used to generate a synthetic dataset <code><a href="#topic+DBNdata">DBNdata</a></code>. The matrix is an unrolled representation of a 2-step DBN, such that the static variables are represented in the first 3 columns/rows of the matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DBNunrolled
</code></pre>


<h3>Format</h3>

<p>A binary matrix with 63 rows and 63 columns representing an adjacency matrix of a DBN. Rows and columns of the matrix correspond to 15 variables (s1, s2, s3, v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12) of a DBN across 5 time slices.
</p>

<hr>
<h2 id='edgep'>Estimating posterior probabilities of single edges</h2><span id='topic+edgep'></span>

<h3>Description</h3>

<p>This function estimates the posterior probabilities of edges by averaging over a sample of DAGs
obtained via an MCMC scheme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>edgep(MCMCchain, pdag = FALSE, burnin = 0.2, endstep = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="edgep_+3A_mcmcchain">MCMCchain</code></td>
<td>
<p>an object of class <code>partitionMCMC</code>, <code>orderMCMC</code> or <code>iterativeMCMC</code>, representing the output of structure sampling function <code><a href="#topic+partitionMCMC">partitionMCMC</a></code> or <code><a href="#topic+orderMCMC">orderMCMC</a></code> (the latter when parameter <code>chainout</code>=TRUE;</p>
</td></tr>
<tr><td><code id="edgep_+3A_pdag">pdag</code></td>
<td>
<p>logical, if TRUE (FALSE by default) all DAGs in the MCMCchain are first converted to equivalence class (CPDAG) before the averaging</p>
</td></tr>
<tr><td><code id="edgep_+3A_burnin">burnin</code></td>
<td>
<p>number between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be discarded as &lsquo;burn-in&rsquo; of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
<tr><td><code id="edgep_+3A_endstep">endstep</code></td>
<td>
<p>number between <code>0</code> and <code>1</code>; 1 by default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a square matrix with dimensions equal to the number of variables; each entry <code>[i,j]</code> is an estimate of the posterior probability of the edge from node <code>i</code> to node <code>j</code>
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Bostonscore&lt;-scoreparameters("bge", Boston)
## Not run: 
samplefit&lt;-sampleBN(Bostonscore, "order")
edgesposterior&lt;-edgep(samplefit, pdag=TRUE, burnin=0.2)

## End(Not run)
</code></pre>

<hr>
<h2 id='full2compact'>Deriving a compact adjacency matrix of a DBN</h2><span id='topic+full2compact'></span>

<h3>Description</h3>

<p>This function transforms an unrolled adjacency matrix of DBN into a compact representation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>full2compact(DBNmat, b = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="full2compact_+3A_dbnmat">DBNmat</code></td>
<td>
<p>a square matrix, representing the structure of an unrolled DBN; the size of matrix is slices*dyn+b; all static variables are assumed to be in the first b rows and columns of the matrix</p>
</td></tr>
<tr><td><code id="full2compact_+3A_b">b</code></td>
<td>
<p>integer, number of static variables; 0 by default</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>full2compact(DBNunrolled,b=3)
</code></pre>

<hr>
<h2 id='getDAG'>Extracting adjacency matrix (DAG) from MCMC object</h2><span id='topic+getDAG'></span>

<h3>Description</h3>

<p>This function extracts an adjacency matrix of
a maximum scoring DAG from the result of the MCMC run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getDAG(x, amat = TRUE, cp = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getDAG_+3A_x">x</code></td>
<td>
<p>object of class 'orderMCMC','partitionMCMC' or 'iterativeMCMC'</p>
</td></tr>
<tr><td><code id="getDAG_+3A_amat">amat</code></td>
<td>
<p>logical, when TRUE adjacency matrix is returned and object of class 'graphNEL' otherwise</p>
</td></tr>
<tr><td><code id="getDAG_+3A_cp">cp</code></td>
<td>
<p>logical, when TRUE the CPDAG (equivalence class) is returned and DAG otherwise; FALSE by default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>adjacency matrix of a maximum scoring DAG (or CPDAG) discovered/sampled in one MCMC run
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myscore&lt;-scoreparameters("bge", Boston)
## Not run: 
itfit&lt;-learnBN(myscore,algorithm="orderIter")
maxEC&lt;-getDAG(itfit,cp=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='getMCMCscore'>Extracting score from MCMC object</h2><span id='topic+getMCMCscore'></span>

<h3>Description</h3>

<p>This function extracts the score of a maximum DAG sampled in the MCMC run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMCMCscore(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getMCMCscore_+3A_x">x</code></td>
<td>
<p>object of class 'orderMCMC','partitionMCMC' or 'iterativeMCMC'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a score of a maximum-scoring DAG found/sampled in one MCMC run
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myscore&lt;-scoreparameters("bge", Boston)
## Not run: 
itfit&lt;-learnBN(myscore,algorithm="orderIter")
getMCMCscore(itfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='getRuntime'>Extracting runtime</h2><span id='topic+getRuntime'></span>

<h3>Description</h3>

<p>This function extracts runtime of a particular step of order and partition MCMC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRuntime(x, which = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getRuntime_+3A_x">x</code></td>
<td>
<p>object of class 'orderMCMC'or 'partitionMCMC'</p>
</td></tr>
<tr><td><code id="getRuntime_+3A_which">which</code></td>
<td>
<p>integer, defines if the runtime is extracted for: computing score tables (which = 1), running MCMC chain (which = 2)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>runtime of a particular step of MCMC scheme or total runtime
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myscore&lt;-scoreparameters("bge",Boston)
## Not run: 
orderfit&lt;-sampleBN(myscore,algorithm="order")
(getRuntime(orderfit,1))
(getRuntime(orderfit,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='getSpace'>Extracting scorespace from MCMC object</h2><span id='topic+getSpace'></span>

<h3>Description</h3>

<p>This function extracts an object of class 'scorespace'
from the result of the MCMC run when the parameter 'scoreout' was set to TRUE; otherwise extracts
only adjacency matrix of the final search space without the score tables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSpace(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSpace_+3A_x">x</code></td>
<td>
<p>object of class 'orderMCMC','partitionMCMC' or 'iterativeMCMC'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class 'scorespace' or an adjacency binary matrix corresponding to a search space last used in MCMC
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myscore&lt;-scoreparameters("bge", Boston)
## Not run: 
itfit&lt;-learnBN(myscore,algorithm="orderIter",scoreout=TRUE)
itspace&lt;-getSpace(itfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='getSubGraph'>Deriving subgraph</h2><span id='topic+getSubGraph'></span>

<h3>Description</h3>

<p>This function derives an adjacency matrix of a subgraph based on the adjacency matrix of a full graph and a list of nodes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getSubGraph(adj, nodes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getSubGraph_+3A_adj">adj</code></td>
<td>
<p>square adjacency matrix with elements in <code>{0,1}</code>, representing a graph</p>
</td></tr>
<tr><td><code id="getSubGraph_+3A_nodes">nodes</code></td>
<td>
<p>vector of node names of the subgraph; should be a subset of column names of 'adj'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>adjacency matrix of a subgraph which includes all 'nodes'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>getSubGraph(Asiamat,c("E","B","D","X"))
</code></pre>

<hr>
<h2 id='getTrace'>Extracting trace from MCMC object</h2><span id='topic+getTrace'></span>

<h3>Description</h3>

<p>This function extracts a trace of
</p>

<ul>
<li><p> DAG scores 
</p>
</li>
<li><p> DAG adjacency matrices
</p>
</li>
<li><p> orders
</p>
</li>
<li><p> order scores 
</p>
</li></ul>

<p>from the result of the MCMC run. Note that the last three options
work only when the parameter 'scoreout' was set to TRUE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTrace(x, which = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="getTrace_+3A_x">x</code></td>
<td>
<p>object of class 'orderMCMC','partitionMCMC' or 'iterativeMCMC'</p>
</td></tr>
<tr><td><code id="getTrace_+3A_which">which</code></td>
<td>
<p>integer, indication which trace is returned: DAG scores (which = 0), DAGs (which = 1),
orders (which = 2), order scores (which = 3)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list or a vector of objects representing MCMC trace, depends on parameter 'which'; by default, the trace of DAG scores is returned
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myscore&lt;-scoreparameters("bge",Boston)
## Not run: 
orderfit&lt;-sampleBN(myscore,algorithm="order")
DAGscores&lt;-getTrace(orderfit,which=0)
DAGtrace&lt;-getTrace(orderfit,which=1)
orderscores&lt;-getTrace(orderfit,which=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='graph2m'>Deriving an adjacency matrix of a graph</h2><span id='topic+graph2m'></span>

<h3>Description</h3>

<p>This function derives the adjacency matrix corresponding to a graph object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>graph2m(g)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="graph2m_+3A_g">g</code></td>
<td>
<p>graph, object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> (package &lsquo;graph&rsquo;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a square matrix whose dimensions are the number of nodes in the graph g, where element
<code>[i,j]</code> equals <code>1</code> if there is a directed edge from node <code>i</code> to node <code>j</code> in the graph <code>g</code>,
and <code>0</code> otherwise
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Asiagraph&lt;-m2graph(Asiamat)
Asia.adj&lt;-graph2m(Asiagraph)
</code></pre>

<hr>
<h2 id='gsim'>A simulated data set from a Gaussian continuous Bayesian network</h2><span id='topic+gsim'></span>

<h3>Description</h3>

<p>A synthetic dataset containing 1000 observations generated from a random DAG with 100 continuous nodes.
Functions 'randomDAG' and 'rmvDAG' from R-packages 'pcalg' were used to generate the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsim
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows representing observations of 100 continuous variables: V1, ..., V100
</p>

<hr>
<h2 id='gsim100'>A simulated data set from a Gaussian continuous Bayesian network</h2><span id='topic+gsim100'></span>

<h3>Description</h3>

<p>A synthetic dataset containing 100 observations generated from a random DAG with 100 continuous nodes. 
Functions 'randomDAG' and 'rmvDAG' from R-packages 'pcalg' were used to generate the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsim100
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows representing observations of 100 continuous variables: V1, ..., V100
</p>

<hr>
<h2 id='gsimmat'>An adjacency matrix of a simulated dataset</h2><span id='topic+gsimmat'></span>

<h3>Description</h3>

<p>An adjacency matrix representing the ground truth DAG used to generate a synthetic dataset with observations of 100 continuous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gsimmat
</code></pre>


<h3>Format</h3>

<p>A binary matrix with 100 rows and 100 columns representing an adjacency matrix of a DAG with 100 nodes: V1, ..., V100
</p>

<hr>
<h2 id='interactions'>interactions dataset</h2><span id='topic+interactions'></span>

<h3>Description</h3>

<p>A data frame containing possible interactions between genes from <code>kirp</code> and <code>kirc</code>
data sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interactions
</code></pre>


<h3>Format</h3>

<p>A data frame with 179 rows and 3 columns; 
</p>

<ul>
<li><p> node1 character, name of a gene 
</p>
</li>
<li><p> node2 character, name of a gene 
</p>
</li>
<li><p> combined_score interaction score, reflecting confidence in the fact that interaction between gene1 and gene2 is possible
</p>
</li></ul>

<p>each row represents a possible interaction between two genes
</p>


<h3>Source</h3>

<p><a href="https://string-db.org/">https://string-db.org/</a>
</p>

<hr>
<h2 id='iterativeMCMC'>Structure learning with an iterative order MCMC algorithm on an expanded search space</h2><span id='topic+iterativeMCMC'></span><span id='topic+plot.iterativeMCMC'></span><span id='topic+print.iterativeMCMC'></span><span id='topic+summary.iterativeMCMC'></span>

<h3>Description</h3>

<p>This function implements an iterative search for the maximum a posteriori (MAP) DAG, 
by means of order MCMC (arXiv:1803.07859v3).  At each iteration, the current search space is expanded by 
allowing each node to have up to one additional parent not already included in the search space. 
By default the initial search space is obtained through the PC-algorithm (using the functions <code><a href="pcalg.html#topic+skeleton">skeleton</a></code> and <code><a href="pcalg.html#topic+pc">pc</a></code> from the &lsquo;pcalg&rsquo; package [Kalisch et al, 2012]).  
At each iteration order MCMC is employed to search for the MAP DAG.  
The edges in the MAP DAG are added to the initial search space to provide 
the search space for the next iteration.  The algorithm iterates until no 
further score improvements can be achieved by expanding the search space.  
The final search space may be used for the sampling versions of <code><a href="#topic+orderMCMC">orderMCMC</a></code> and <code><a href="#topic+partitionMCMC">partitionMCMC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterativeMCMC(
  scorepar,
  MAP = TRUE,
  posterior = 0.5,
  softlimit = 9,
  hardlimit = 12,
  alpha = 0.05,
  gamma = 1,
  verbose = TRUE,
  chainout = FALSE,
  scoreout = FALSE,
  cpdag = FALSE,
  mergetype = "skeleton",
  iterations = NULL,
  moveprobs = NULL,
  stepsave = NULL,
  startorder = NULL,
  accum = FALSE,
  compress = TRUE,
  plus1it = NULL,
  startspace = NULL,
  blacklist = NULL,
  addspace = NULL,
  scoretable = NULL,
  alphainit = NULL
)

## S3 method for class 'iterativeMCMC'
plot(
  x,
  ...,
  main = "iterative MCMC, DAG scores",
  xlab = "MCMC step",
  ylab = "DAG logscore",
  type = "l",
  col = "blue"
)

## S3 method for class 'iterativeMCMC'
print(x, ...)

## S3 method for class 'iterativeMCMC'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterativeMCMC_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and scoring parameters; see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_map">MAP</code></td>
<td>
<p>logical, if TRUE (default) the search targets the MAP DAG (a DAG with maximum score),
if FALSE at each MCMC step a DAG is sampled from the order proportionally to its score; when expanding a search space when MAP=TRUE all edges from the maximum scoring DAG are added
to the new space, when MAP=FALSE only edges with posterior probability higher than defined by parameter <code>posterior</code> are added to the search space</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_posterior">posterior</code></td>
<td>
<p>logical, when <code>MAP</code> set to FALSE defines posterior probability threshold for adding the edges to the search space</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_softlimit">softlimit</code></td>
<td>
<p>integer, limit on the size of parent sets beyond which adding undirected edges is restricted; below this
limit edges are added to expand the parent sets based on the undirected skeleton of the MAP DAG (or from its CPDAG, depending
on the parameter <code>mergecp</code>), above the limit only the directed edges are added from the MAP DAG;  the limit is 9 by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_hardlimit">hardlimit</code></td>
<td>
<p>integer, limit on the size of parent sets beyond which the search space is not further expanded to prevent long runtimes; the limit is 12 by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_alpha">alpha</code></td>
<td>
<p>numerical significance value in <code>{0,1}</code> for the conditional independence tests in the PC-stage</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter which transforms the score by raising it to this power, 1 by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE (default) prints messages on the progress of execution</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_chainout">chainout</code></td>
<td>
<p>logical, if TRUE the saved MCMC steps are returned, FALSE by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_scoreout">scoreout</code></td>
<td>
<p>logical, if TRUE the search space from the last plus1 iterations and the corresponding score tables are returned, FALSE by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if set to TRUE the equivalence class (CPDAG) found by the PC algorithm is used as a search
space, when FALSE (default) the undirected skeleton used as a search space</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_mergetype">mergetype</code></td>
<td>
<p>defines which edges are added to the search space at each expansion iteration; three options are available 'dag', 'cpdag', 'skeleton'; 'skeleton' by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_iterations">iterations</code></td>
<td>
<p>integer, the number of MCMC steps, the default value is <code class="reqn">3.5n^{2}\log{n}</code></p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_moveprobs">moveprobs</code></td>
<td>
<p>a numerical vector of 4 values in <code>{0,1}</code> corresponding to the probabilities of the following MCMC moves in the order space:
</p>

<ul>
<li><p> exchanging 2 random nodes in the order
</p>
</li>
<li><p> exchanging 2 adjacent nodes in the order
</p>
</li>
<li><p> placing a single node elsewhere in the order
</p>
</li>
<li><p> staying still
</p>
</li></ul>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_stepsave">stepsave</code></td>
<td>
<p>integer, thinning interval for the MCMC chain, indicating the number of steps between two output iterations, the default is <code>iterations</code>/1000</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_startorder">startorder</code></td>
<td>
<p>integer vector of length n, which will be used as the starting order in the MCMC algorithm, the default order is random</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_accum">accum</code></td>
<td>
<p>logical, when TRUE at each search step expansion new edges are added to the current search space; when FALSE (default) the new edges are added to the starting space</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_compress">compress</code></td>
<td>
<p>logical, if TRUE adjacency matrices representing sampled graphs will be stored as a sparse Matrix (recommended); TRUE by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_plus1it">plus1it</code></td>
<td>
<p>(optional) integer, a number of iterations of search space expansion; by default the algorithm iterates until no score improvement can be achieved by further expanding the search space</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_startspace">startspace</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines the search space for the order MCMC in the form of an adjacency matrix; if NULL, the skeleton obtained from the PC-algorithm will be used; if <code>startspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space; to include an edge in both directions, both <code>startspace[i,j]</code> and <code>startspace[j,i]</code> should be 1</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_blacklist">blacklist</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines edges to exclude from the search space; if <code>blacklist[i,j]</code> equals to 1 it means that the edge from node <code>i</code> to node <code>j</code> is excluded from the search space
</p>

<ul>
<li><p> &quot;dag&quot;, then edges from maximum scoring DAG are added;
</p>
</li>
<li><p> &quot;cpdag&quot;, then the maximum scoring DAG is first converted to the CPDAG, from which all edges are added to the search space;
</p>
</li>
<li><p> &quot;skeleton&quot;, then the maximum scoring DAG is first converted to the skeleton, from which all edges are added to the search space
</p>
</li></ul>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_addspace">addspace</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines the edges, which are added at to the search space only at the first iteration of iterative seach and do not necessarily stay afterwards; defined in the form of an adjacency matrix;  if <code>addspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space; to include an edge in both directions, both <code>addspace[i,j]</code> and <code>addspace[j,i]</code> should be 1</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_scoretable">scoretable</code></td>
<td>
<p>(optional) object of class <code>scorespace</code>. When not NULL, parameters <code>startspace</code> and <code>addspace</code> are ignored.</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_alphainit">alphainit</code></td>
<td>
<p>(optional) numerical, defines alpha that is used by the PC algorithm to learn initial structure of a DBN, ignored in static case</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_x">x</code></td>
<td>
<p>object of class 'iterativeMCMC'</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_main">main</code></td>
<td>
<p>name of the graph; &quot;iterative MCMC, DAG scores&quot; by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_xlab">xlab</code></td>
<td>
<p>name of x-axis; &quot;MCMC step&quot;</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_ylab">ylab</code></td>
<td>
<p>name of y-axis; &quot;DAG logscore&quot;</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_type">type</code></td>
<td>
<p>type of line in the plot; &quot;l&quot; by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_col">col</code></td>
<td>
<p>colour of line in the plot; &quot;blue&quot; by default</p>
</td></tr>
<tr><td><code id="iterativeMCMC_+3A_object">object</code></td>
<td>
<p>object of class 'iterativeMCMC'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>iterativeMCMC</code>, which contains log-score trace as well as adjacency matrix of the maximum scoring DAG, its score and the order score. 
The output can optionally include DAGs sampled in MCMC iterations and the score tables. Optional output is regulated by the parameters <code>chainout</code> and <code>scoreout</code>. See <code><a href="#topic+iterativeMCMC+20class">iterativeMCMC class</a></code> for a detailed class structure.
</p>


<h3>Note</h3>

<p>see also extractor functions <code><a href="#topic+getDAG">getDAG</a></code>, <code><a href="#topic+getTrace">getTrace</a></code>, <code><a href="#topic+getSpace">getSpace</a></code>, <code><a href="#topic+getMCMCscore">getMCMCscore</a></code>.
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack Kuipers
</p>


<h3>References</h3>

<p>P. Suter, J. Kuipers, G. Moffa, N.Beerenwinkel (2023) &lt;doi:10.18637/jss.v105.i09&gt;
</p>
<p>Kuipers J, Super P and Moffa G (2020). Efficient Sampling and Structure Learning of Bayesian Networks. (arXiv:1803.07859v3)
</p>
<p>Friedman N and Koller D (2003). A Bayesian approach to structure discovery in bayesian networks. Machine Learning 50, 95-125.
</p>
<p>Kalisch M, Maechler M, Colombo D, Maathuis M and Buehlmann P (2012). Causal inference using graphical models with the R package pcalg. Journal of Statistical Software 47, 1-26.
</p>
<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian directed acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>
<p>Spirtes P, Glymour C and Scheines R (2000). Causation, Prediction, and Search, 2nd edition. The MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Bostonpar&lt;-scoreparameters("bge",Boston)
itfit&lt;-iterativeMCMC(Bostonpar, chainout=TRUE, scoreout=TRUE)
plot(itfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='iterativeMCMC+20class'>iterativeMCMC class structure</h2><span id='topic+iterativeMCMC+20class'></span>

<h3>Description</h3>

<p>The structure of an object of S3 class <code>iterativeMCMC</code>.
</p>


<h3>Details</h3>

<p>An object of class <code>iterativeMCMC</code> is a list containing at least the following
components:
</p>

<ul>
<li><p> DAG: adjacency matrix of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> CPDAG: adjacency matrix representing equivalence class of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> score: score of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> maxorder: order of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> maxtrace: a list of maximum score graphs uncovered at each expansion of the search space; their scores and orders 
</p>
</li>
<li><p> info: a list containing information about parameters and results of MCMC
</p>
</li>
<li><p> trace: a list of vectors containing log-scores of sampled DAGs, each element of the list corresponds to a single expansion of a search space
</p>
</li>
<li><p> startspace: adjacency matrix representing the initial core space where MCMC was ran
</p>
</li>
<li><p> endspace: adjacency matrix representing the final core space where MCMC was ran
</p>
<p>Optional components:
</p>

<ul>
<li> <p><code>traceadd</code>: list which  consists of three elements:
</p>

<ul>
<li><p> incidence: list containg adjacency matrices of sampled DAGs
</p>
</li>
<li><p> order: list of orders from which the DAGs were sampled
</p>
</li>
<li><p> orderscores: a list of vectors with order log-scores 
</p>
</li></ul>

</li>
<li> <p><code>scoretable</code>: object of class <code><a href="#topic+scorespace+20class">scorespace class</a></code>
</p>
</li></ul>

</li></ul>



<h3>Author(s)</h3>

<p>Polina Suter</p>

<hr>
<h2 id='itercomp'>Performance assessment of iterative MCMC scheme against a known Bayesian network</h2><span id='topic+itercomp'></span><span id='topic+plot.itercomp'></span><span id='topic+print.itercomp'></span><span id='topic+summary.itercomp'></span>

<h3>Description</h3>

<p>This function compute 8 different metrics of structure fit of an object of class <code>iterativeMCMC</code> to the ground truth DAG (or CPDAG). Object of class
<code>iterativeMCMC</code> stores MAP graph at from each search space expansion step. This function computes structure fit of
each of the stored graphs to the ground truth one. Computed metrics include: TP, FP, TPR, FPR, FPRn, FDR, SHD. See metrics description in
see also <code><a href="#topic+compareDAGs">compareDAGs</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itercomp(MCMCmult, truedag, cpdag = TRUE, p = 0.5, trans = TRUE)

## S3 method for class 'itercomp'
plot(x, ..., vars = c("FP", "TP"), type = "b", col = "blue", showit = c())

## S3 method for class 'itercomp'
print(x, ...)

## S3 method for class 'itercomp'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="itercomp_+3A_mcmcmult">MCMCmult</code></td>
<td>
<p>an object which of class <code>iterativeMCMC</code>, see also <code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="itercomp_+3A_truedag">truedag</code></td>
<td>
<p>ground truth DAG which generated the data used in the search procedure; represented by an object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> or an adjacency matrix</p>
</td></tr>
<tr><td><code id="itercomp_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if TRUE (FALSE by default) all DAGs are first converted to their respective equivalence classes (CPDAG)</p>
</td></tr>
<tr><td><code id="itercomp_+3A_p">p</code></td>
<td>
<p>threshold such that only edges with a higher posterior probability will be retained in the directed graph summarising the sample of DAGs at each iteration from <code>MCMCmult</code> if parameter <code>sample</code> set to TRUE</p>
</td></tr>
<tr><td><code id="itercomp_+3A_trans">trans</code></td>
<td>
<p>logical, for DBNs indicates if model comparions are performed for transition structure; when <code>trans</code> equals FALSE the comparison is performed for initial structures of estimated models and the ground truth DBN; for usual BNs the parameter is disregarded</p>
</td></tr>
<tr><td><code id="itercomp_+3A_x">x</code></td>
<td>
<p>object of class 'itercomp'</p>
</td></tr>
<tr><td><code id="itercomp_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="itercomp_+3A_vars">vars</code></td>
<td>
<p>a tuple of variables which will be used for 'x' and 'y' axes; possible values: &quot;SHD&quot;, &quot;TP&quot;, &quot;FP&quot;, &quot;TPR&quot;, &quot;FPR&quot;, &quot;FPRn&quot;, &quot;FDR&quot;, &quot;score&quot;</p>
</td></tr>
<tr><td><code id="itercomp_+3A_type">type</code></td>
<td>
<p>type of line in the plot;&quot;b&quot; by default</p>
</td></tr>
<tr><td><code id="itercomp_+3A_col">col</code></td>
<td>
<p>colour of line in the plot; &quot;blue&quot; by default</p>
</td></tr>
<tr><td><code id="itercomp_+3A_showit">showit</code></td>
<td>
<p>(optional) vector of integers specifying indices of search expansion iterations to be labelled; by default no iterations are labelled</p>
</td></tr>
<tr><td><code id="itercomp_+3A_object">object</code></td>
<td>
<p>object of class 'itercomp'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object if class <code>itersim</code>, a matrix with the number of rows equal to the number of expansion iterations in <code>iterativeMCMC</code>, and 8 columns reporting for 
the maximally scoring DAG uncovered at each iteration: the number of true positive edges ('TP'), the number of false positive edges ('FP'), 
the true positive rate ('TPR'), the structural Hamming distance ('SHD'), false positive rate ('FPR'),
false discovery rate ('FDR') and the score of the DAG (&lsquo;score&rsquo;).
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gsim.score&lt;-scoreparameters("bge", gsim)
## Not run: 
MAPestimate&lt;-learnBN(gsim.score,"orderIter")
itercomp(MAPestimate, gsimmat)

## End(Not run)
</code></pre>

<hr>
<h2 id='kirc'>kirc dataset</h2><span id='topic+kirc'></span>

<h3>Description</h3>

<p>Mutation data from TCGA kidney renal clear cell cohort (KIRC). 
Mutations are picked according to q-value computed 
by MutSig2CV (q&lt;0.1) or connected in networks discovered by Kuipers et al. 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kirc
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 476 rows and 70 columns.
</p>


<h3>Details</h3>

 
<p>Each variable represents a gene. If in sample i gene j contains a mutation, than j-th element in 
row i equals 1, and 0 otherwise.
The rows are named according to sample names in TCGA.
The columns are named according to gene symbols.

</p>


<h3>References</h3>

<p><a href="https://portal.gdc.cancer.gov/">https://portal.gdc.cancer.gov/</a>
</p>
<p><a href="http://firebrowse.org/iCoMut/?cohort=kirc">http://firebrowse.org/iCoMut/?cohort=kirc</a>
</p>
<p>Lawrence, M. et al. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature 499, 214-218 (2013)
</p>

<hr>
<h2 id='kirp'>kirp dataset</h2><span id='topic+kirp'></span>

<h3>Description</h3>

<p>Mutation data from TCGA kidney renal papillary cell cohort (KIRP). 
Mutations are picked according to q-value computed 
by MutSigCV (q&lt;0.1) or connected in networks discovered by Kuipers et al. 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kirp
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 282 rows and 70 columns.
</p>


<h3>Details</h3>


<p>Each variable represents a gene. If in sample i gene j contains a mutation, than j-th element in 
row i equals 1, and 0 otherwise.
The rows are named according to sample names in TCGA.
The columns are named according to gene symbols.

</p>


<h3>References</h3>

<p><a href="https://portal.gdc.cancer.gov/">https://portal.gdc.cancer.gov/</a>
</p>
<p><a href="http://firebrowse.org/iCoMut/?cohort=kirp">http://firebrowse.org/iCoMut/?cohort=kirp</a>
</p>
<p>Lawrence, M. et al. Mutational heterogeneity in cancer and the search for new cancer-associated genes. Nature 499, 214-218 (2013)
</p>

<hr>
<h2 id='learnBN'>Bayesian network structure learning</h2><span id='topic+learnBN'></span>

<h3>Description</h3>

<p>This function can be used finding the maximum a posteriori (MAP) DAG using stochastic search relying on MCMC schemes. Due to the superexponential size of the search space, it 
must be reduced. By default the search space is limited to the skeleton found through the PC algorithm by means of conditional independence tests 
(using the functions <code><a href="pcalg.html#topic+skeleton">skeleton</a></code> and <code><a href="pcalg.html#topic+pc">pc</a></code> from the &lsquo;pcalg&rsquo; package [Kalisch et al, 2012]).
It is also possible to define an arbitrary search space by inputting an adjacency matrix, for example estimated by partial correlations or other network algorithms. Order MCMC scheme (<code>algorithm="order"</code>)
performs the search of a maximum scoring order and selects a maximum scoring DAG from this order as MAP. To avoid discovering a suboptimal graph due to the absence
of some of the true positive edges in the search space, the function includes the possibility to expand the default or input search space, by allowing each node in the network to have one additional parent (<code>plus1="TRUE"</code>).  
This offers improvements in the learning of Bayesian networks. The iterative MCMC (<code>algorithm="orderIter"</code>) scheme allows for iterative expansions of the search space.
This is useful in cases when the initial search space is poor in a sense that it contains only a limited number of true positive edges. Iterative expansions of the search space
efficiently solve this issue. However this scheme requires longer runtimes due to the need of running multiple consecutive MCMC chains.  
This function is a wrapper for the individual structure learning functions that implement each of the described algorithms; for details see <code><a href="#topic+orderMCMC">orderMCMC</a></code>,
and <code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>learnBN(
  scorepar,
  algorithm = c("order", "orderIter"),
  chainout = FALSE,
  scoreout = ifelse(algorithm == "orderIter", TRUE, FALSE),
  alpha = 0.05,
  moveprobs = NULL,
  iterations = NULL,
  stepsave = NULL,
  gamma = 1,
  verbose = FALSE,
  compress = TRUE,
  startspace = NULL,
  blacklist = NULL,
  scoretable = NULL,
  startpoint = NULL,
  plus1 = TRUE,
  iterpar = list(softlimit = 9, mergetype = "skeleton", accum = FALSE, plus1it = NULL,
    addspace = NULL, alphainit = NULL),
  cpdag = FALSE,
  hardlimit = 12
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="learnBN_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and score parameters, see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="learnBN_+3A_algorithm">algorithm</code></td>
<td>
<p>MCMC scheme to be used for MAP structure learning; possible options are &quot;order&quot; (<code><a href="#topic+orderMCMC">orderMCMC</a></code>) or &quot;orderIter&quot; (<code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="learnBN_+3A_chainout">chainout</code></td>
<td>
<p>logical, if TRUE the saved MCMC steps are returned, TRUE by default</p>
</td></tr>
<tr><td><code id="learnBN_+3A_scoreout">scoreout</code></td>
<td>
<p>logical, if TRUE the search space and score tables are returned; FALSE by default for &quot;order&quot;, TRUE for &quot;orderIter&quot;</p>
</td></tr>
<tr><td><code id="learnBN_+3A_alpha">alpha</code></td>
<td>
<p>numerical significance value in <code>{0,1}</code> for the conditional independence tests at the PC algorithm stage</p>
</td></tr>
<tr><td><code id="learnBN_+3A_moveprobs">moveprobs</code></td>
<td>
<p>a numerical vector of 4 (for &quot;order&quot; and &quot;orderIter&quot; algorithms) or 5 values (for &quot;partition&quot; algorithm) representing probabilities of the different moves in the space of
order and partitions accordingly. The moves are described in the corresponding algorithm specific functions <code><a href="#topic+orderMCMC">orderMCMC</a></code> and <code><a href="#topic+partitionMCMC">partitionMCMC</a></code></p>
</td></tr>
<tr><td><code id="learnBN_+3A_iterations">iterations</code></td>
<td>
<p>integer, the number of MCMC steps, the default value is <code class="reqn">6n^{2}\log{n}</code> orderMCMC, <code class="reqn">20n^{2}\log{n}</code> for partitionMCMC and <code class="reqn">3.5n^{2}\log{n}</code> for iterativeMCMC; where n is the number of nodes in the Bayesian network</p>
</td></tr>
<tr><td><code id="learnBN_+3A_stepsave">stepsave</code></td>
<td>
<p>integer, thinning interval for the MCMC chain, indicating the number of steps between two output iterations, the default is <code>iterations/1000</code></p>
</td></tr>
<tr><td><code id="learnBN_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter which transforms the score by raising it to this power, 1 by default</p>
</td></tr>
<tr><td><code id="learnBN_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE messages about the algorithm's progress will be printed, FALSE by default</p>
</td></tr>
<tr><td><code id="learnBN_+3A_compress">compress</code></td>
<td>
<p>logical, if TRUE adjacency matrices representing sampled graphs will be stored as a sparse Matrix (recommended); TRUE by default</p>
</td></tr>
<tr><td><code id="learnBN_+3A_startspace">startspace</code></td>
<td>
<p>(optional) a square sparse or ordinary matrix, of dimensions equal to the number of nodes, which defines the search space for the order MCMC in the form of an adjacency matrix. If NULL, the skeleton obtained from the PC-algorithm will be used. If <code>startspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space. To include an edge in both directions, both <code>startspace[i,j]</code> and <code>startspace[j,i]</code> should be 1.</p>
</td></tr>
<tr><td><code id="learnBN_+3A_blacklist">blacklist</code></td>
<td>
<p>(optional) a square sparse or ordinary matrix, of dimensions equal to the number of nodes, which defines edges to exclude from the search space. If <code>blacklist[i,j]</code> equals to 1 it means that the edge from node <code>i</code> to node <code>j</code> is excluded from the search space.</p>
</td></tr>
<tr><td><code id="learnBN_+3A_scoretable">scoretable</code></td>
<td>
<p>(optional) object of class <code>scorespace</code> containing list of score tables calculated for example by the last iteration of the function <code>iterativeMCMC</code>. When not NULL, parameter <code>startspace</code> is ignored.</p>
</td></tr>
<tr><td><code id="learnBN_+3A_startpoint">startpoint</code></td>
<td>
<p>(optional) integer vector of length n (representing an order when <code>algorithm="order"</code> or <code>algorithm="orderIter"</code>) or an adjacency matrix or sparse adjacency matrix (representing a DAG when <code>algorithm="partition"</code>), which will be used as the starting point in the MCMC algorithm, the default starting point is random</p>
</td></tr>
<tr><td><code id="learnBN_+3A_plus1">plus1</code></td>
<td>
<p>logical, if TRUE (default) the search is performed on the extended search space; only changable for orderMCMC; for other algorithms is fixed to TRUE</p>
</td></tr>
<tr><td><code id="learnBN_+3A_iterpar">iterpar</code></td>
<td>
<p>addition list of parameters for the MCMC scheme implemeting iterative expansions of the search space; for more details see <code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>; list(posterior = 0.5, softlimit = 9, mergetype = &quot;skeleton&quot;, accum = FALSE, 
plus1it = NULL, addspace = NULL, alphainit = NULL)</p>
</td></tr>
<tr><td><code id="learnBN_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if TRUE the CPDAG returned by the PC algorithm will be used as the search
space, if FALSE (default) the full undirected skeleton will be used as the search space</p>
</td></tr>
<tr><td><code id="learnBN_+3A_hardlimit">hardlimit</code></td>
<td>
<p>integer, limit on the size of parent sets in the search space; by default 14 when MAP=TRUE and 20 when MAP=FALSE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the value or the parameter <code>algorithm</code> returns an object of class <code>orderMCMC</code> or <code>iterativeMCMC</code> which contains log-score trace of sampled DAGs as well 
as adjacency matrix of the maximum scoring DAG(s), its score and the order or partition score. The output can optionally include DAGs sampled in MCMC iterations and the score tables. 
Optional output is regulated by the parameters <code>chainout</code> and <code>scoreout</code>. See <code><a href="#topic+orderMCMC+20class">orderMCMC class</a></code>, <code><a href="#topic+iterativeMCMC+20class">iterativeMCMC class</a></code> for a detailed description of the classes' structures.
</p>


<h3>Note</h3>

<p>see also extractor functions <code><a href="#topic+getDAG">getDAG</a></code>, <code><a href="#topic+getTrace">getTrace</a></code>, <code><a href="#topic+getSpace">getSpace</a></code>, <code><a href="#topic+getMCMCscore">getMCMCscore</a></code>.
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack Kuipers, the code partly derived from the order MCMC implementation from Kuipers J, Moffa G (2017) &lt;doi:10.1080/01621459.2015.1133426&gt;
</p>


<h3>References</h3>

<p>P. Suter, J. Kuipers, G. Moffa, N.Beerenwinkel (2023) &lt;doi:10.18637/jss.v105.i09&gt;
</p>
<p>Friedman N and Koller D (2003). A Bayesian approach to structure discovery in bayesian networks. Machine Learning 50, 95-125.
</p>
<p>Kalisch M, Maechler M, Colombo D, Maathuis M and Buehlmann P (2012). Causal inference using graphical models with the R package pcalg. Journal of Statistical Software 47, 1-26.
</p>
<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>
<p>Spirtes P, Glymour C and Scheines R (2000). Causation, Prediction, and Search, 2nd edition. The MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
myScore&lt;-scoreparameters("bge",Boston)
mapfit&lt;-learnBN(myScore,"orderIter")
summary(mapfit)
plot(mapfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='m2graph'>Deriving a graph from an adjacancy matrix</h2><span id='topic+m2graph'></span>

<h3>Description</h3>

<p>This function derives a graph object corresponding to an adjacency matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m2graph(adj, nodes = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m2graph_+3A_adj">adj</code></td>
<td>
<p>square adjacency matrix with elements in <code>{0,1}</code>, representing a graph</p>
</td></tr>
<tr><td><code id="m2graph_+3A_nodes">nodes</code></td>
<td>
<p>(optional) labels of the nodes, <code>c(1:n)</code> are used by default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class <code><a href="graph.html#topic+graphNEL">graphNEL</a></code> (package &lsquo;graph&rsquo;); if element <code>adj[i,j]</code> equals <code>1</code>, then there is a directed edge from node <code>i</code> to node <code>j</code> in the graph, and no edge otherwise
</p>


<h3>Examples</h3>

<pre><code class='language-R'>m2graph(Asiamat)
</code></pre>

<hr>
<h2 id='mapping'>mapping dataset</h2><span id='topic+mapping'></span>

<h3>Description</h3>

<p>A data frame containing mapping between names of genes used in <code>kirp</code>/<code>kirc</code>
data sets and names used in STRING interactions list (see <code><a href="#topic+interactions">interactions</a></code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mapping
</code></pre>


<h3>Format</h3>

<p>A data frame with 46 rows and two columns:
</p>

<ul>
<li><p> queryItem character, name used for structure learning 
</p>
</li>
<li><p> preferredName character, name used in STRING interactions data set
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://string-db.org/">https://string-db.org/</a>
</p>

<hr>
<h2 id='modelp'>Estimating a graph corresponding to a posterior probability threshold</h2><span id='topic+modelp'></span>

<h3>Description</h3>

<p>This function constructs a directed graph (not necessarily acyclic) including all edges with a posterior probability above a certain threshold.  The posterior probability is evaluated as the Monte Carlo estimate from a sample of DAGs obtained via an MCMC scheme.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modelp(MCMCchain, p, pdag = FALSE, burnin = 0.2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modelp_+3A_mcmcchain">MCMCchain</code></td>
<td>
<p>object of class <code>partitionMCMC</code>, <code>orderMCMC</code> or <code>iterativeMCMC</code>, representing the output of structure sampling function <code><a href="#topic+partitionMCMC">partitionMCMC</a></code> or <code><a href="#topic+orderMCMC">orderMCMC</a></code> (the latter when parameter <code>chainout</code>=TRUE;</p>
</td></tr>
<tr><td><code id="modelp_+3A_p">p</code></td>
<td>
<p>threshold such that only edges with a higher posterior probability will be retained in the directed graph summarising the sample of DAGs</p>
</td></tr>
<tr><td><code id="modelp_+3A_pdag">pdag</code></td>
<td>
<p>logical, if TRUE (FALSE by default) all DAGs in the MCMCchain are first converted to equivalence class (CPDAG) before the averaging</p>
</td></tr>
<tr><td><code id="modelp_+3A_burnin">burnin</code></td>
<td>
<p>number between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be  the discarded as &lsquo;burn-in&rsquo; of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a square matrix with dimensions equal to the number of variables representing the adjacency matrix of the directed graph summarising the sample of DAGs
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Bostonscore&lt;-scoreparameters("bge", Boston)
## Not run: 
partfit&lt;-sampleBN(Bostonscore, "partition")
hdag&lt;-modelp(partfit, p=0.9)

## End(Not run)
</code></pre>

<hr>
<h2 id='orderMCMC'>Structure learning with the order MCMC algorithm</h2><span id='topic+orderMCMC'></span><span id='topic+plot.orderMCMC'></span><span id='topic+print.orderMCMC'></span><span id='topic+summary.orderMCMC'></span>

<h3>Description</h3>

<p>This function implements the order MCMC algorithm for the structure learning of Bayesian networks. This function can be used
for MAP discovery and for sampling from the posterior distribution of DAGs given the data.
Due to the superexponential size of the search space as the number of nodes increases, the 
MCMC search is performed on a reduced search space.
By default the search space is limited to the skeleton found through the PC algorithm by means of conditional independence tests 
(using the functions <code><a href="pcalg.html#topic+skeleton">skeleton</a></code> and <code><a href="pcalg.html#topic+pc">pc</a></code> from the &lsquo;pcalg&rsquo; package [Kalisch et al, 2012]).
It is also possible to define an arbitrary search space by inputting an adjacency matrix, for example estimated by partial correlations or other network algorithms.
Also implemented is the possibility to expand the default or input search space, by allowing each node in the network to have one additional parent.  This offers improvements in the learning and sampling of Bayesian networks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orderMCMC(
  scorepar,
  MAP = TRUE,
  plus1 = TRUE,
  chainout = FALSE,
  scoreout = FALSE,
  moveprobs = NULL,
  iterations = NULL,
  stepsave = NULL,
  alpha = 0.05,
  cpdag = FALSE,
  gamma = 1,
  hardlimit = ifelse(plus1, 14, 20),
  verbose = FALSE,
  compress = TRUE,
  startspace = NULL,
  blacklist = NULL,
  startorder = NULL,
  scoretable = NULL
)

## S3 method for class 'orderMCMC'
plot(
  x,
  ...,
  burnin = 0.2,
  main = "DAG logscores",
  xlab = "iteration",
  ylab = "logscore",
  type = "l",
  col = "#0c2c84"
)

## S3 method for class 'orderMCMC'
print(x, ...)

## S3 method for class 'orderMCMC'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="orderMCMC_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and score parameters, see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_map">MAP</code></td>
<td>
<p>logical, if TRUE (default) the search targets the MAP DAG (a DAG with maximum score),
if FALSE at each MCMC step a DAG is sampled from the order proportionally to its score</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_plus1">plus1</code></td>
<td>
<p>logical, if TRUE (default) the search is performed on the extended search space</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_chainout">chainout</code></td>
<td>
<p>logical, if TRUE the saved MCMC steps are returned, TRUE by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_scoreout">scoreout</code></td>
<td>
<p>logical, if TRUE the search space and score tables are returned, FALSE by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_moveprobs">moveprobs</code></td>
<td>
<p>a numerical vector of 4 values in <code>{0,1}</code> corresponding to the probabilities of the following MCMC moves in the order space
</p>

<ul>
<li><p> exchanging 2 random nodes in the order
</p>
</li>
<li><p> exchanging 2 adjacent nodes in the order
</p>
</li>
<li><p> placing a single node elsewhere in the order
</p>
</li>
<li><p> staying still
</p>
</li></ul>
</td></tr>
<tr><td><code id="orderMCMC_+3A_iterations">iterations</code></td>
<td>
<p>integer, the number of MCMC steps, the default value is <code class="reqn">6n^{2}\log{n}</code></p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_stepsave">stepsave</code></td>
<td>
<p>integer, thinning interval for the MCMC chain, indicating the number of steps between two output iterations, the default is <code>iterations/1000</code></p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_alpha">alpha</code></td>
<td>
<p>numerical significance value in <code>{0,1}</code> for the conditional independence tests at the PC algorithm stage</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if TRUE the CPDAG returned by the PC algorithm will be used as the search
space, if FALSE (default) the full undirected skeleton will be used as the search space</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter which transforms the score by raising it to this power, 1 by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_hardlimit">hardlimit</code></td>
<td>
<p>integer, limit on the size of parent sets in the search space; by default 14 when MAP=TRUE and 20 when MAP=FALSE</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE messages about the algorithm's progress will be printed, FALSE by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_compress">compress</code></td>
<td>
<p>logical, if TRUE adjacency matrices representing sampled graphs will be stored as a sparse Matrix (recommended); TRUE by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_startspace">startspace</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines the search space for the order MCMC in the form of an adjacency matrix. If NULL, the skeleton obtained from the PC-algorithm will be used. If <code>startspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space. To include an edge in both directions, both <code>startspace[i,j]</code> and <code>startspace[j,i]</code> should be 1.</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_blacklist">blacklist</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines edges to exclude from the search space. If <code>blacklist[i,j]</code> equals to 1 it means that the edge from node <code>i</code> to node <code>j</code> is excluded from the search space.</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_startorder">startorder</code></td>
<td>
<p>(optional) integer vector of length n, which will be used as the starting order in the MCMC algorithm, the default order is random</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_scoretable">scoretable</code></td>
<td>
<p>(optional) object of class <code>scorespace</code> containing list of score tables calculated for example by the last iteration of the function <code>iterativeMCMC</code>. When not NULL, parameter <code>startspace</code> is ignored.</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_x">x</code></td>
<td>
<p>object of class 'orderMCMC'</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_burnin">burnin</code></td>
<td>
<p>number between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be discarded as &lsquo;burn-in&rsquo; of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_main">main</code></td>
<td>
<p>name of the graph; &quot;DAG logscores&quot; by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_xlab">xlab</code></td>
<td>
<p>name of x-axis; &quot;iteration&quot;</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_ylab">ylab</code></td>
<td>
<p>name of y-axis; &quot;logscore&quot;</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_type">type</code></td>
<td>
<p>type of line in the plot; &quot;l&quot; by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_col">col</code></td>
<td>
<p>colour of line in the plot; &quot;#0c2c84&quot; by default</p>
</td></tr>
<tr><td><code id="orderMCMC_+3A_object">object</code></td>
<td>
<p>object of class 'orderMCMC'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>orderMCMC</code>, which contains log-score trace of sampled DAGs as well 
as adjacency matrix of the maximum scoring DAG, its score and the order score. The output can optionally include DAGs sampled in MCMC iterations and the score tables. 
Optional output is regulated by the parameters <code>chainout</code> and <code>scoreout</code>. See <code><a href="#topic+orderMCMC+20class">orderMCMC class</a></code> for a detailed class structure.
</p>


<h3>Note</h3>

<p>see also extractor functions <code><a href="#topic+getDAG">getDAG</a></code>, <code><a href="#topic+getTrace">getTrace</a></code>, <code><a href="#topic+getSpace">getSpace</a></code>, <code><a href="#topic+getMCMCscore">getMCMCscore</a></code>.
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack Kuipers, the code partly derived from the order MCMC implementation from Kuipers J, Moffa G (2017) &lt;doi:10.1080/01621459.2015.1133426&gt;
</p>


<h3>References</h3>

<p>P. Suter, J. Kuipers, G. Moffa, N.Beerenwinkel (2023) &lt;doi:10.18637/jss.v105.i09&gt;
</p>
<p>Friedman N and Koller D (2003). A Bayesian approach to structure discovery in bayesian networks. Machine Learning 50, 95-125.
</p>
<p>Kalisch M, Maechler M, Colombo D, Maathuis M and Buehlmann P (2012). Causal inference using graphical models with the R package pcalg. Journal of Statistical Software 47, 1-26.
</p>
<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>
<p>Spirtes P, Glymour C and Scheines R (2000). Causation, Prediction, and Search, 2nd edition. The MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#find a MAP DAG with search space defined by PC and plus1 neighbourhood
Bostonscore&lt;-scoreparameters("bge",Boston)
#estimate MAP DAG
orderMAPfit&lt;-orderMCMC(Bostonscore)
summary(orderMAPfit)
#sample DAGs from the posterior distribution
ordersamplefit&lt;-orderMCMC(Bostonscore,MAP=FALSE,chainout=TRUE)
plot(ordersamplefit)

## End(Not run)
</code></pre>

<hr>
<h2 id='orderMCMC+20class'>orderMCMC class structure</h2><span id='topic+orderMCMC+20class'></span>

<h3>Description</h3>

<p>The structure of an object of S3 class <code>orderMCMC</code>.
</p>


<h3>Details</h3>

<p>An object of class <code>orderMCMC</code> is a list containing at least the following
components:
</p>

<ul>
<li><p> DAG: adjacency matrix of a maximum scoring DAG found/sampled in the MCMC scheme.
</p>
</li>
<li><p> CPDAG: adjacency matrix representing equivalence class of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> score: score of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> maxorder: order of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> info: a list containing information about parameters and results of MCMC.
</p>
</li>
<li><p> trace: a vector containing log-scores of sampled DAGs.
</p>
<p>Optional components:
</p>

<ul>
<li> <p><code>traceadd</code>: list which  consists of three or four elements (depending on MCMC scheme used for sampling):
</p>

<ul>
<li><p> incidence: list containg adjacency matrices of sampled DAGs
</p>
</li>
<li><p> order: list of orders from which the DAGs were sampled
</p>
</li>
<li><p> orderscores: order log-scores 
</p>
</li></ul>

</li>
<li> <p><code>scoretable</code>: object of class <code><a href="#topic+scorespace+20class">scorespace class</a></code>
</p>
</li></ul>

</li></ul>



<h3>Author(s)</h3>

<p>Polina Suter</p>

<hr>
<h2 id='partitionMCMC'>DAG structure sampling with partition MCMC</h2><span id='topic+partitionMCMC'></span><span id='topic+plot.partitionMCMC'></span><span id='topic+print.partitionMCMC'></span><span id='topic+summary.partitionMCMC'></span>

<h3>Description</h3>

<p>This function implements the partition MCMC algorithm for the structure learning of Bayesian networks.  This procedure provides an unbiased sample from the posterior distribution of DAGs given the data. 
The search space can be defined either by a preliminary run of the function <code>iterativeMCMC</code> or by a given adjacency matrix (which can be the full matrix with zero on the diagonal, to consider the entire space of DAGs, feasible only for a limited number of nodes).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partitionMCMC(
  scorepar,
  moveprobs = NULL,
  iterations = NULL,
  stepsave = NULL,
  alpha = 0.05,
  gamma = 1,
  verbose = FALSE,
  scoreout = FALSE,
  compress = TRUE,
  startspace = NULL,
  blacklist = NULL,
  scoretable = NULL,
  startDAG = NULL
)

## S3 method for class 'partitionMCMC'
plot(
  x,
  ...,
  burnin = 0.2,
  main = "DAG logscores",
  xlab = "iteration",
  ylab = "logscore",
  type = "l",
  col = "#0c2c84"
)

## S3 method for class 'partitionMCMC'
print(x, ...)

## S3 method for class 'partitionMCMC'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partitionMCMC_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and scoring parameters;  see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code>.</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_moveprobs">moveprobs</code></td>
<td>
<p>(optional) a numerical vector of 5 values in <code>{0,1}</code> corresponding to the following MCMC move probabilities in the space of partitions:
</p>

<ul>
<li><p> swap any two elements from different partition elements
</p>
</li>
<li><p> swap any two elements in adjacent partition elements
</p>
</li>
<li><p> split a partition element or join one
</p>
</li>
<li><p> move a single node into another partition element or into a new one
</p>
</li>
<li><p> stay still
</p>
</li></ul>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_iterations">iterations</code></td>
<td>
<p>integer, the number of MCMC steps, the default value is <code class="reqn">20n^{2}\log{n}</code></p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_stepsave">stepsave</code></td>
<td>
<p>integer, thinning interval for the MCMC chain, indicating the number of steps between two output iterations, the default is <code>iterations/1000</code></p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_alpha">alpha</code></td>
<td>
<p>numerical significance value in <code>{0,1}</code> for the conditional independence tests at the PC algorithm stage</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter which transforms the score by raising it to this power, 1 by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_verbose">verbose</code></td>
<td>
<p>logical, if set to TRUE (default) messages about progress will be printed</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_scoreout">scoreout</code></td>
<td>
<p>logical, if TRUE the search space and score tables are returned, FALSE by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_compress">compress</code></td>
<td>
<p>logical, if TRUE adjacency matrices representing sampled graphs will be stored as a sparse Matrix (recommended); TRUE by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_startspace">startspace</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines the search space for the order MCMC in the form of an adjacency matrix; if NULL, the skeleton obtained from the PC-algorithm will be used. If <code>startspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space. To include an edge in both directions, both <code>startspace[i,j]</code> and <code>startspace[j,i]</code> should be 1.</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_blacklist">blacklist</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines edges to exclude from the search space; if <code>blacklist[i,j]=1</code> it means that the edge from node <code>i</code> to node <code>j</code> is excluded from the search space</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_scoretable">scoretable</code></td>
<td>
<p>(optional) object of class <code>scorespace</code> containing list of score tables calculated for example by the last iteration of the function <code>iterativeMCMC</code>. When not NULL, parameter <code>startspace</code> is ignored</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_startdag">startDAG</code></td>
<td>
<p>(optional) an adjacency matrix of dimensions equal to the number of nodes, representing a DAG in the search space defined by startspace.  If startspace is defined but <code>startDAG</code> is not, an empty DAG will be used by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_x">x</code></td>
<td>
<p>object of class 'partitionMCMC'</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_burnin">burnin</code></td>
<td>
<p>number between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be discarded as &lsquo;burn-in&rsquo; of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_main">main</code></td>
<td>
<p>name of the graph; &quot;DAG logscores&quot; by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_xlab">xlab</code></td>
<td>
<p>name of x-axis; &quot;iteration&quot;</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_ylab">ylab</code></td>
<td>
<p>name of y-axis; &quot;logscore&quot;</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_type">type</code></td>
<td>
<p>type of line in the plot; &quot;l&quot; by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_col">col</code></td>
<td>
<p>colour of line in the plot; &quot;#0c2c84&quot; by default</p>
</td></tr>
<tr><td><code id="partitionMCMC_+3A_object">object</code></td>
<td>
<p>object of class 'partitionMCMC'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>partitionMCMC</code>, which contains log-score trace as well 
as adjacency matrix of the maximum scoring DAG, its score and the order score. Additionally, returns all sampled DAGs (represented by their adjacency matrices), their scores,
orders and partitions See <code><a href="#topic+partitionMCMC+20class">partitionMCMC class</a></code>.
</p>


<h3>Note</h3>

<p>see also extractor functions <code><a href="#topic+getDAG">getDAG</a></code>, <code><a href="#topic+getTrace">getTrace</a></code>, <code><a href="#topic+getSpace">getSpace</a></code>, <code><a href="#topic+getMCMCscore">getMCMCscore</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jack Kuipers, Polina Suter, the code partly derived from the partition MCMC implementation from Kuipers J, Moffa G (2017) &lt;doi:10.1080/01621459.2015.1133426&gt;
</p>


<h3>References</h3>

<p>P. Suter, J. Kuipers, G. Moffa, N.Beerenwinkel (2023) &lt;doi:10.18637/jss.v105.i09&gt;
</p>
<p>Kuipers J and Moffa G (2017). Partition MCMC for inference on acyclic digraphs. Journal of the American Statistical Association 112, 282-299.
</p>
<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Heckerman D and Geiger D (1995). Learning Bayesian networks: A unification for discrete and Gaussian domains. In Eleventh Conference on Uncertainty in Artificial Intelligence, pages 274-284.
</p>
<p>Kalisch M, Maechler M, Colombo D, Maathuis M and Buehlmann P (2012). Causal inference using graphical models with the R package pcalg. Journal of Statistical Software 47, 1-26.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian directed acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
myScore&lt;-scoreparameters("bge", Boston)
partfit&lt;-partitionMCMC(myScore)
plot(partfit)

## End(Not run)
</code></pre>

<hr>
<h2 id='partitionMCMC+20class'>partitionMCMC class structure</h2><span id='topic+partitionMCMC+20class'></span>

<h3>Description</h3>

<p>The structure of an object of S3 class <code>partitionMCMC</code>.
</p>


<h3>Details</h3>

<p>An object of class <code>partitionMCMC</code> is a list containing at least the following
components:
</p>

<ul>
<li><p> DAG: adjacency matrix of a maximum scoring DAG found/sampled in the MCMC scheme.
</p>
</li>
<li><p> CPDAG: adjacency matrix representing equivalence class of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> score: score of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> maxorder: order of a maximum scoring DAG found/sampled in MCMC.
</p>
</li>
<li><p> info: a list containing information about parameters and results of MCMC.
</p>
</li>
<li><p> trace: a vector containing log-scores of sampled DAGs.
</p>
<p>Optional components:
</p>

<ul>
<li> <p><code>traceadd</code>: list which  consists of three or four elements (depending on MCMC scheme used for sampling):
</p>

<ul>
<li><p> incidence: list containg adjacency matrices of sampled DAGs
</p>
</li>
<li><p> order: list of orders from which the DAGs were sampled
</p>
</li>
<li><p> partition: list of partition from which the DAGs were sampled 
</p>
</li>
<li><p> partitionscores: partition log-scores
</p>
</li></ul>

</li>
<li> <p><code>scoretable</code>: object of class <code><a href="#topic+scorespace+20class">scorespace class</a></code>
</p>
</li></ul>

</li></ul>



<h3>Author(s)</h3>

<p>Polina Suter</p>

<hr>
<h2 id='plot2in1'>Highlighting similarities between two graphs</h2><span id='topic+plot2in1'></span>

<h3>Description</h3>

<p>This function plots nodes and edges from two graphs in one and indicates similarities between these graphs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot2in1(graph1, graph2, name1 = NULL, name2 = NULL, bidir = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot2in1_+3A_graph1">graph1</code></td>
<td>
<p>binary adjacency matrix of a graph</p>
</td></tr>
<tr><td><code id="plot2in1_+3A_graph2">graph2</code></td>
<td>
<p>binary adjacency matrix of a graph, column names should coincide with column names of 'graph1'</p>
</td></tr>
<tr><td><code id="plot2in1_+3A_name1">name1</code></td>
<td>
<p>character, custom name for 'graph1'; when NULL no legend will be plotted</p>
</td></tr>
<tr><td><code id="plot2in1_+3A_name2">name2</code></td>
<td>
<p>character, custom name for 'graph2'</p>
</td></tr>
<tr><td><code id="plot2in1_+3A_bidir">bidir</code></td>
<td>
<p>logical, defines if arrows of bidirected edges are drawn; FALSE by defauls.</p>
</td></tr>
<tr><td><code id="plot2in1_+3A_...">...</code></td>
<td>
<p>optional parameters passed to <span class="pkg">Rgraphviz</span> plotting functions e.g. <code>main</code>, <code>fontsize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots the graph which includes nodes and edges two graphs; nodes which are connected to at least one other node in both graphs are plotted only once and coloured orange, edges which are shared by two graphs
are coloured orange; all other nodes and edges a plotted once for each 'graph1' and 'graph2' and coloured blue and green accordingly.
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>

<hr>
<h2 id='plotDBN'>Plotting a DBN</h2><span id='topic+plotDBN'></span>

<h3>Description</h3>

<p>This function can be used for plotting initial and transition structures of a dynamic Bayesian network.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDBN(DBN, struct = c("init", "trans"), b = 0, shape = "circle", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDBN_+3A_dbn">DBN</code></td>
<td>
<p>binary matrix (or a graph object) representing a 2-step DBN (compact or unrolled)</p>
</td></tr>
<tr><td><code id="plotDBN_+3A_struct">struct</code></td>
<td>
<p>option used to determine if the initial or the transition structure should be plotted; acceptable values are init or trans</p>
</td></tr>
<tr><td><code id="plotDBN_+3A_b">b</code></td>
<td>
<p>number of static variables in the DBN, 0 by default; note that for function to work correctly all static variables have to be in the first b columns of the matrix</p>
</td></tr>
<tr><td><code id="plotDBN_+3A_shape">shape</code></td>
<td>
<p>string, defining the shape of the box around each node; possible values are circle, ellipse, box</p>
</td></tr>
<tr><td><code id="plotDBN_+3A_...">...</code></td>
<td>
<p>optional parameters passed to <code>Rgraphviz</code> plotting functions e.g. <code>main</code>, <code>fontsize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots the DBN defined by the adjacency matrix 'DBN' and number of static and dynamic variables. When 'struct' equals &quot;trans&quot; the transition structure is plotted,
otherwise initial structure is plotted
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plotDBN(DBNmat, "init", b=3)
plotDBN(DBNmat, "trans", b=3)

</code></pre>

<hr>
<h2 id='plotdiffs'>Plotting difference between two graphs</h2><span id='topic+plotdiffs'></span>

<h3>Description</h3>

<p>This function plots edges from two graphs in one and indicates similarities and differences between these graphs.
It is also possible to use this function for plotting mistakes in estimated graph when the ground truth graph is known.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotdiffs(
  graph1,
  graph2,
  estimated = TRUE,
  name1 = "graph1",
  name2 = "graph2",
  clusters = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotdiffs_+3A_graph1">graph1</code></td>
<td>
<p>object of class graphNEL or its adjacency matrix</p>
</td></tr>
<tr><td><code id="plotdiffs_+3A_graph2">graph2</code></td>
<td>
<p>object of class graphNEL or its adjacency matrix</p>
</td></tr>
<tr><td><code id="plotdiffs_+3A_estimated">estimated</code></td>
<td>
<p>logical, indicates if graph1 is estimated graph and graph2 is ground truth DAG, TRUE by default; this affects the legend and colouring of the edges</p>
</td></tr>
<tr><td><code id="plotdiffs_+3A_name1">name1</code></td>
<td>
<p>character, custom name for 'graph1'</p>
</td></tr>
<tr><td><code id="plotdiffs_+3A_name2">name2</code></td>
<td>
<p>character, custom name for 'graph2'</p>
</td></tr>
<tr><td><code id="plotdiffs_+3A_clusters">clusters</code></td>
<td>
<p>(optional) a list of nodes to be represented on the graph as clusters</p>
</td></tr>
<tr><td><code id="plotdiffs_+3A_...">...</code></td>
<td>
<p>optional parameters passed to <code>Rgraphviz</code> plotting functions e.g. <code>main</code>, <code>fontsize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots the graph which includes edges from graph1 and graph2; edges which are different in graph1 compared to graph2 are coloured according to the type of a difference
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Asiascore&lt;-scoreparameters("bde",Asia)
Asiamap&lt;-orderMCMC(Asiascore)
plotdiffs(Asiamap$DAG,Asiamat)
Asiacp&lt;-pcalg::dag2cpdag(m2graph(Asiamat))
mapcp&lt;-pcalg::dag2cpdag(m2graph(Asiamap$DAG))
plotdiffs(mapcp,Asiacp)
</code></pre>

<hr>
<h2 id='plotdiffsDBN'>Plotting difference between two DBNs</h2><span id='topic+plotdiffsDBN'></span>

<h3>Description</h3>

<p>This function plots an estimated DBN such that the edges which are different to the ground truth DBN are highlighted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotdiffsDBN(
  eDBN,
  trueDBN,
  struct = c("init", "trans"),
  b = 0,
  showcl = TRUE,
  orientation = "TB",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotdiffsDBN_+3A_edbn">eDBN</code></td>
<td>
<p>object of class graphNEL (or its adjacency matrix), representing estimated structure (not necessarily acyclic) to be compared to the ground truth graph</p>
</td></tr>
<tr><td><code id="plotdiffsDBN_+3A_truedbn">trueDBN</code></td>
<td>
<p>object of class graphNEL (or its adjacency matrix), representing the ground truth structure (not necessarily acyclic)</p>
</td></tr>
<tr><td><code id="plotdiffsDBN_+3A_struct">struct</code></td>
<td>
<p>option used to determine if the initial or the transition structure should be plotted; accaptable values are init or trans</p>
</td></tr>
<tr><td><code id="plotdiffsDBN_+3A_b">b</code></td>
<td>
<p>number of static variables in one time slice of a DBN; note that for function to work correctly all static variables have to be in the first b columns of the matrix</p>
</td></tr>
<tr><td><code id="plotdiffsDBN_+3A_showcl">showcl</code></td>
<td>
<p>logical, when TRUE (default) nodes are shown in clusters according to the time slice the belong to</p>
</td></tr>
<tr><td><code id="plotdiffsDBN_+3A_orientation">orientation</code></td>
<td>
<p>orientation of the graph layout, possible options are 'TB' (top-bottom) and 'LR' (left-right)</p>
</td></tr>
<tr><td><code id="plotdiffsDBN_+3A_...">...</code></td>
<td>
<p>optional parameters passed to <code>Rgraphviz</code> plotting functions e.g. <code>main</code>, <code>fontsize</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots the graph highlights differences between 'eDBN' (estimated DBN) and 'trueDBN' (ground truth); edges which are different in 'eDBN' compared to 'trueDBN' are coloured according to the type of a difference: false-positive, false-negative and error in direction.
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dbnscore&lt;-scoreparameters("bge",DBNdata,
dbnpar = list(samestruct=TRUE, slices=5, b=3),
DBN=TRUE)
## Not run: 
orderDBNfit&lt;-learnBN(dbnscore,algorithm="order")
iterDBNfit&lt;-learnBN(dbnscore,algorithm="orderIter")
plotdiffsDBN(getDAG(orderDBNfit),DBNmat,struct="trans",b=3)
plotdiffsDBN(getDAG(iterDBNfit),DBNmat,struct="trans",b=3)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotpcor'>Comparing posterior probabilitites of single edges</h2><span id='topic+plotpcor'></span>

<h3>Description</h3>

<p>This function can be used to compare posterior probabilities of edges in a graph
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotpcor(pmat, highlight = 0.3, printedges = FALSE, cut = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotpcor_+3A_pmat">pmat</code></td>
<td>
<p>a list of square matrices, representing posterior probabilities of single edges in a Bayesian network; see <code><a href="#topic+edgep">edgep</a></code> for obtaining such a matrix from a single MCMC run</p>
</td></tr>
<tr><td><code id="plotpcor_+3A_highlight">highlight</code></td>
<td>
<p>numeric, defines maximum acceptable difference between posterior probabilities of an edge in two samples; points corresponding to higher differences are highlighted in red</p>
</td></tr>
<tr><td><code id="plotpcor_+3A_printedges">printedges</code></td>
<td>
<p>when TRUE the function also returns squared correlation and RMSE of posterior probabilities higher than the value defined 
by the argument 'cut' as well as the list of all edges whose posterior probabilities in the first two matrices differ more than 'highlight'; FALSE by default</p>
</td></tr>
<tr><td><code id="plotpcor_+3A_cut">cut</code></td>
<td>
<p>numeric value corresponding to a minimum posterior probabilitity which is included into calculation of squared correlation and MSE when 'printedges' equals TRUE</p>
</td></tr>
<tr><td><code id="plotpcor_+3A_...">...</code></td>
<td>
<p>prameters passed further to the <code>plot</code> function (e.g. <code>xlab</code>, <code>ylab</code>, <code>main</code>) in case when the length of <code>pmat</code> equals 2</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots concordance of posterior probabilitites of single edges based on several matrices (minimum 2 matrices); highlights the edges whose posterior probabilities in a pair of matrices differ by more than 'highlight'; 
when 'printedges' set to TRUE, the function returns also squared correlation and RMSE of posterior probabilities 
higher than the value defined by the argument 'cut' as well as the list of all edges whose posterior probabilities in the first two matrices differ by more than 'highlight'.
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Asiascore&lt;-scoreparameters("bde", Asia)
## Not run: 
orderfit&lt;-list()
orderfit[[1]]&lt;-sampleBN(Asiascore,algorithm="order")
orderfit[[2]]&lt;-sampleBN(Asiascore,algorithm="order")
orderfit[[3]]&lt;-sampleBN(Asiascore,algorithm="order")
pedges&lt;-lapply(orderfit,edgep,pdag=TRUE)
plotpcor(pedges, xlab="run1", ylab="run2",printedges=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotpedges'>Plotting posterior probabilities of single edges</h2><span id='topic+plotpedges'></span>

<h3>Description</h3>

<p>This function plots posterior probabilities of all possible edges in the graph as a function of MCMC iterations. It can be used for convergence diagnostics of MCMC
sampling algorithms order MCMC and partition MCMC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotpedges(
  MCMCtrace,
  cutoff = 0.2,
  pdag = FALSE,
  onlyedges = NULL,
  highlight = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotpedges_+3A_mcmctrace">MCMCtrace</code></td>
<td>
<p>an object of class MCMCres</p>
</td></tr>
<tr><td><code id="plotpedges_+3A_cutoff">cutoff</code></td>
<td>
<p>number representing a threshold of posterior probability below which lines will not be plotted</p>
</td></tr>
<tr><td><code id="plotpedges_+3A_pdag">pdag</code></td>
<td>
<p>logical, when true DAGs in a sample will be first coverted to CPDAGs</p>
</td></tr>
<tr><td><code id="plotpedges_+3A_onlyedges">onlyedges</code></td>
<td>
<p>(optional) binary matrix, only edges corresponding to entries which equal 1 will be plotted</p>
</td></tr>
<tr><td><code id="plotpedges_+3A_highlight">highlight</code></td>
<td>
<p>(optional) binary matrix, edges corresponding to entries which equal 1 are highlighted with &quot;red&quot;</p>
</td></tr>
<tr><td><code id="plotpedges_+3A_...">...</code></td>
<td>
<p>(optional) parameters passed to the plot function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plots posterior probabilities of edges in the graph as a function of MCMC iterations
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>score100&lt;-scoreparameters("bde", Asia[1:100,])
orderfit100&lt;-orderMCMC(score100,plus1=TRUE,chainout=TRUE)
## Not run: 
score5000&lt;-scoreparameters("bde", Asia)
orderfit5000&lt;-orderMCMC(score5000,plus1=TRUE,chainout=TRUE)
plotpedges(orderfit100, pdag=TRUE)
plotpedges(orderfit5000, pdag=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='sampleBN'>Bayesian network structure sampling from the posterior distribution</h2><span id='topic+sampleBN'></span>

<h3>Description</h3>

<p>This function can be used for structure sampling using three different MCMC schemes. Order MCMC scheme (<code>algorithm="order"</code>) is the most computationally
efficient however it imposes a non-uniform prior in the space of DAGs. Partition MCMC (<code>algorithm="partition"</code>) is less computationally efficient and requires more iterations
to reach convergence, however it implements sampling using a uniform prior in the space of DAGs.
Due to the superexponential size of the search space as the number of nodes increases, the 
MCMC search is performed on a reduced search space. By default the search space is limited to the skeleton found through the PC algorithm by means of conditional independence tests 
(using the functions <code><a href="pcalg.html#topic+skeleton">skeleton</a></code> and <code><a href="pcalg.html#topic+pc">pc</a></code> from the &lsquo;pcalg&rsquo; package [Kalisch et al, 2012]).
It is also possible to define an arbitrary search space by inputting an adjacency matrix, for example estimated by partial correlations or other network algorithms.
Also implemented is the possibility to expand the default or input search space, by allowing each node in the network to have one additional parent.  
This offers improvements in the learning and sampling of Bayesian networks. The iterative MCMC scheme (<code>algorithm="orderIter"</code>) allows for iterative expansions of the search space.
This is useful in cases when the initial search space is poor in a sense that it contains only a limited number of true positive edges. Iterative expansions of the search space
efficiently solve this issue. However this scheme requires longer runtimes due to the need of running multiple consecutive MCMC chains.  
This function is a wrapper for the three individual structure learning and sampling functions that implement each of the described algorithms; for details see <code><a href="#topic+orderMCMC">orderMCMC</a></code>,
<code><a href="#topic+partitionMCMC">partitionMCMC</a></code>,<code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleBN(
  scorepar,
  algorithm = c("order", "orderIter", "partition"),
  chainout = TRUE,
  scoreout = FALSE,
  alpha = 0.05,
  moveprobs = NULL,
  iterations = NULL,
  stepsave = NULL,
  gamma = 1,
  verbose = FALSE,
  compress = TRUE,
  startspace = NULL,
  blacklist = NULL,
  scoretable = NULL,
  startpoint = NULL,
  plus1 = TRUE,
  cpdag = FALSE,
  hardlimit = 12,
  iterpar = list(posterior = 0.5, softlimit = 9, mergetype = "skeleton", accum = FALSE,
    plus1it = NULL, addspace = NULL, alphainit = NULL)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sampleBN_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and score parameters, see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="sampleBN_+3A_algorithm">algorithm</code></td>
<td>
<p>MCMC scheme to be used for sampling from posterior distribution; possible options are &quot;order&quot; (<code><a href="#topic+orderMCMC">orderMCMC</a></code>), &quot;orderIter&quot; (<code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>) or &quot;partition&quot; (<code><a href="#topic+partitionMCMC">partitionMCMC</a></code>)</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_chainout">chainout</code></td>
<td>
<p>logical, if TRUE the saved MCMC steps are returned, TRUE by default</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_scoreout">scoreout</code></td>
<td>
<p>logical, if TRUE the search space and score tables are returned, FALSE by default</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_alpha">alpha</code></td>
<td>
<p>numerical significance value in <code>{0,1}</code> for the conditional independence tests at the PC algorithm stage</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_moveprobs">moveprobs</code></td>
<td>
<p>a numerical vector of 4 (for &quot;order&quot; and &quot;orderIter&quot; algorithms) or 5 values (for &quot;partition&quot; algorithm) representing probabilities of the different moves in the space of
order and partitions accordingly. The moves are described in the corresponding algorithm specific functions <code><a href="#topic+orderMCMC">orderMCMC</a></code> and <code><a href="#topic+partitionMCMC">partitionMCMC</a></code></p>
</td></tr>
<tr><td><code id="sampleBN_+3A_iterations">iterations</code></td>
<td>
<p>integer, the number of MCMC steps, the default value is <code class="reqn">6n^{2}\log{n}</code> orderMCMC, <code class="reqn">20n^{2}\log{n}</code> for partitionMCMC and <code class="reqn">3.5n^{2}\log{n}</code> for iterativeMCMC; where n is the number of nodes in the Bayesian network</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_stepsave">stepsave</code></td>
<td>
<p>integer, thinning interval for the MCMC chain, indicating the number of steps between two output iterations, the default is <code>iterations/1000</code></p>
</td></tr>
<tr><td><code id="sampleBN_+3A_gamma">gamma</code></td>
<td>
<p>tuning parameter which transforms the score by raising it to this power, 1 by default</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE messages about the algorithm's progress will be printed, FALSE by default</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_compress">compress</code></td>
<td>
<p>logical, if TRUE adjacency matrices representing sampled graphs will be stored as a sparse Matrix (recommended); TRUE by default</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_startspace">startspace</code></td>
<td>
<p>(optional) a square sparse or ordinary matrix, of dimensions equal to the number of nodes, which defines the search space for the order MCMC in the form of an adjacency matrix. If NULL, the skeleton obtained from the PC-algorithm will be used. If <code>startspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space. To include an edge in both directions, both <code>startspace[i,j]</code> and <code>startspace[j,i]</code> should be 1.</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_blacklist">blacklist</code></td>
<td>
<p>(optional) a square sparse or ordinary matrix, of dimensions equal to the number of nodes, which defines edges to exclude from the search space. If <code>blacklist[i,j]</code> equals to 1 it means that the edge from node <code>i</code> to node <code>j</code> is excluded from the search space.</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_scoretable">scoretable</code></td>
<td>
<p>(optional) object of class <code>scorespace</code> containing list of score tables calculated for example by the last iteration of the function <code>iterativeMCMC</code>. When not NULL, parameter <code>startspace</code> is ignored.</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_startpoint">startpoint</code></td>
<td>
<p>(optional) integer vector of length n (representing an order when <code>algorithm="order"</code> or <code>algorithm="orderIter"</code>) or an adjacency matrix or sparse adjacency matrix (representing a DAG when <code>algorithm="partition"</code>), which will be used as the starting point in the MCMC algorithm, the default starting point is random</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_plus1">plus1</code></td>
<td>
<p>logical, if TRUE (default) the search is performed on the extended search space; only changable for orderMCMC; for other algorithms is fixed to TRUE</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if TRUE the CPDAG returned by the PC algorithm will be used as the search
space, if FALSE (default) the full undirected skeleton will be used as the search space</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_hardlimit">hardlimit</code></td>
<td>
<p>integer, limit on the size of parent sets in the search space;</p>
</td></tr>
<tr><td><code id="sampleBN_+3A_iterpar">iterpar</code></td>
<td>
<p>addition list of parameters for the MCMC scheme implemeting iterative expansions of the search space; for more details see <code><a href="#topic+iterativeMCMC">iterativeMCMC</a></code>; list(posterior = 0.5, softlimit = 9, mergetype = &quot;skeleton&quot;, accum = FALSE, 
plus1it = NULL, addspace = NULL, alphainit = NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Depending on the value or the parameter <code>algorithm</code> returns an object of class <code>orderMCMC</code>, <code>partitionMCMC</code> or <code>iterativeMCMC</code> which contains log-score trace of sampled DAGs as well 
as adjacency matrix of the maximum scoring DAG(s), its score and the order or partition score. The output can optionally include DAGs sampled in MCMC iterations and the score tables. 
Optional output is regulated by the parameters <code>chainout</code> and <code>scoreout</code>. See <code><a href="#topic+orderMCMC+20class">orderMCMC class</a></code>, <code><a href="#topic+partitionMCMC+20class">partitionMCMC class</a></code>, <code><a href="#topic+iterativeMCMC+20class">iterativeMCMC class</a></code> for a detailed description of the classes' structures.
</p>


<h3>Note</h3>

<p>see also extractor functions <code><a href="#topic+getDAG">getDAG</a></code>, <code><a href="#topic+getTrace">getTrace</a></code>, <code><a href="#topic+getSpace">getSpace</a></code>, <code><a href="#topic+getMCMCscore">getMCMCscore</a></code>.
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack Kuipers, the code partly derived from the order MCMC implementation from Kuipers J, Moffa G (2017) &lt;doi:10.1080/01621459.2015.1133426&gt;
</p>


<h3>References</h3>

<p>P. Suter, J. Kuipers, G. Moffa, N.Beerenwinkel (2023) &lt;doi:10.18637/jss.v105.i09&gt;
</p>
<p>Friedman N and Koller D (2003). A Bayesian approach to structure discovery in bayesian networks. Machine Learning 50, 95-125.
</p>
<p>Kalisch M, Maechler M, Colombo D, Maathuis M and Buehlmann P (2012). Causal inference using graphical models with the R package pcalg. Journal of Statistical Software 47, 1-26.
</p>
<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>
<p>Spirtes P, Glymour C and Scheines R (2000). Causation, Prediction, and Search, 2nd edition. The MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
Asiascore &lt;- scoreparameters("bde", Asia)
iterativefit &lt;- learnBN(Asiascore, algorithm = "orderIter")
orderfit &lt;- sampleBN(Asiascore, scoretable = iterativefit)

myScore&lt;-scoreparameters("bge",Boston)
MCMCchains&lt;-list()
MCMCchains[[1]]&lt;-sampleBN(myScore,"partition")
MCMCchains[[2]]&lt;-sampleBN(myScore,"partition")
edge_posterior&lt;-lapply(MCMCchains,edgep,pdag=TRUE)
plotpcor(edge_posterior)

## End(Not run)
</code></pre>

<hr>
<h2 id='samplecomp'>Performance assessment of sampling algorithms against a known Bayesian network</h2><span id='topic+samplecomp'></span><span id='topic+plot.samplecomp'></span><span id='topic+print.samplecomp'></span><span id='topic+summary.samplecomp'></span>

<h3>Description</h3>

<p>This function compute 8 different metrics of structure fit of an object of classes <code>orderMCMC</code> and <code>partitionMCMC</code> to the ground truth DAG (or CPDAG). First posterior probabilities
of single edges are calculated based on a sample stores in the object of class <code>orderMCMC</code> or <code>partitionMCMC</code>. This function computes structure fit of
each of the consensus graphs to the ground truth one based on a defined range of posterior thresholds. Computed metrics include: TP, FP, TPR, FPR, FPRn, FDR, SHD. See metrics description in
see also <code><a href="#topic+compareDAGs">compareDAGs</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>samplecomp(
  MCMCchain,
  truedag,
  p = c(0.99, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2),
  pdag = TRUE,
  burnin = 0.2,
  trans = TRUE
)

## S3 method for class 'samplecomp'
plot(x, ..., vars = c("FP", "TP"), type = "b", col = "blue", showp = NULL)

## S3 method for class 'samplecomp'
print(x, ...)

## S3 method for class 'samplecomp'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samplecomp_+3A_mcmcchain">MCMCchain</code></td>
<td>
<p>an object of class <code>partitionMCMC</code> or <code>orderMCMC</code>, representing the output of structure sampling function <code><a href="#topic+partitionMCMC">partitionMCMC</a></code> or <code><a href="#topic+orderMCMC">orderMCMC</a></code> (the latter when parameter <code>chainout</code>=TRUE;</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_truedag">truedag</code></td>
<td>
<p>ground truth DAG which generated the data used in the search procedure; represented by an object of class  <code><a href="graph.html#topic+graphNEL">graphNEL</a></code></p>
</td></tr>
<tr><td><code id="samplecomp_+3A_p">p</code></td>
<td>
<p>a vector of numeric values between 0 and 1, defining posterior probabilities according to which the edges of assessed structures are drawn, please note very low barriers can lead to very dense structures; by default 
<code class="reqn">p=c(0.99, 0.95, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2)</code></p>
</td></tr>
<tr><td><code id="samplecomp_+3A_pdag">pdag</code></td>
<td>
<p>logical, if TRUE (default) all DAGs in the MCMCchain are first converted to equivalence class (CPDAG) before the averaging</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_burnin">burnin</code></td>
<td>
<p>number between <code>0</code> and <code>1</code>, indicates the percentage of the samples which will be  the discarded as &lsquo;burn-in&rsquo; of the MCMC chain; the rest  of the samples will be used to calculate the posterior probabilities; 0.2 by default</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_trans">trans</code></td>
<td>
<p>logical, for DBNs indicates if model comparions are performed for transition structure; when <code>trans</code> equals FALSE the comparison is performed for initial structures of estimated models and the ground truth DBN; for usual BNs the parameter is disregarded</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_x">x</code></td>
<td>
<p>object of class 'samplecomp'</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_vars">vars</code></td>
<td>
<p>a tuple of variables which will be used for 'x' and 'y' axes; possible values: &quot;SHD&quot;, &quot;TP&quot;, &quot;FP&quot;, &quot;TPR&quot;, &quot;FPR&quot;, &quot;FPRn&quot;, &quot;FDR&quot;</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_type">type</code></td>
<td>
<p>type of line in the plot; &quot;b&quot; by default</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_col">col</code></td>
<td>
<p>colour of line in the plotl; &quot;blue&quot; by default</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_showp">showp</code></td>
<td>
<p>logical, defines if points are labelled with the posterior threshold corresponding to the assessed model</p>
</td></tr>
<tr><td><code id="samplecomp_+3A_object">object</code></td>
<td>
<p>object of class 'samplecomp'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object if class <code>samplesim</code>, a matrix with the number of rows equal to the number of elements in 'p', and 8 columns reporting for 
the consensus graphss (corresponfing to each of the values in 'p') the number of true positive edges ('TP'), the number of false positive edges ('FP'), the number of false negative edges ('FN'),
the true positive rate ('TPR'), the structural Hamming distance ('SHD'), false positive rate ('FPR'),
false discovery rate ('FDR') and false positive rate normalized by TP+FN ('FPRn').
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gsim.score&lt;-scoreparameters("bge", gsim)
## Not run: 
MAPestimate&lt;-learnBN(gsim.score,"orderIter",scoreout=TRUE)
ordersample&lt;-sampleBN(gsim.score, "order", scoretable=getSpace(MAPestimate))
samplecomp(ordersample, gsimmat)

## End(Not run)
</code></pre>

<hr>
<h2 id='scoreagainstDAG'>Calculating the score of a sample against a DAG</h2><span id='topic+scoreagainstDAG'></span>

<h3>Description</h3>

<p>This function calculates the score of a given sample against a DAG represented by its incidence matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreagainstDAG(
  scorepar,
  incidence,
  datatoscore = NULL,
  marginalise = FALSE,
  onlymain = FALSE,
  bdecatCvec = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scoreagainstDAG_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>; see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="scoreagainstDAG_+3A_incidence">incidence</code></td>
<td>
<p>a square matrix of dimensions equal to the number of variables with entries in <code>{0,1}</code>, representing the adjacency matrix of the DAG against which the score is calculated</p>
</td></tr>
<tr><td><code id="scoreagainstDAG_+3A_datatoscore">datatoscore</code></td>
<td>
<p>(optional) a matrix (vector) containing binary (for BDe score) or continuous (for the BGe score) observations (or just one observation)  to be scored; the number of columns should be equal to the number of variables in the Bayesian network, the number of rows should be equal to the number of observations; by default all data from <code>scorepar</code> parameter is used</p>
</td></tr>
<tr><td><code id="scoreagainstDAG_+3A_marginalise">marginalise</code></td>
<td>
<p>(optional for continuous data) defines, whether to use the posterior mean for scoring (default) or to marginalise over the posterior distribution (more computationally costly)</p>
</td></tr>
<tr><td><code id="scoreagainstDAG_+3A_onlymain">onlymain</code></td>
<td>
<p>(optional), defines the the score is computed for nodes excluding 'bgnodes'; FALSE by default</p>
</td></tr>
<tr><td><code id="scoreagainstDAG_+3A_bdecatcvec">bdecatCvec</code></td>
<td>
<p>(optional for categorical data)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the log of the BDe/BGe score of given observations against a DAG
</p>


<h3>Author(s)</h3>

<p>Jack Kuipers, Polina Suter
</p>


<h3>References</h3>

<p>Heckerman D and Geiger D, (1995). Learning Bayesian networks: A unification for discrete and Gaussian domains. In Eleventh Conference on Uncertainty in Artificial Intelligence, pages 274-284, 1995.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> Asiascore&lt;-scoreparameters("bde", Asia[1:100,]) #we wish to score only first 100 observations
 scoreagainstDAG(Asiascore, Asiamat) 

</code></pre>

<hr>
<h2 id='scoreagainstDBN'>Score against DBN</h2><span id='topic+scoreagainstDBN'></span>

<h3>Description</h3>

<p>Scoring observations against a DBN structure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreagainstDBN(
  scorepar,
  incidence,
  datatoscore = NULL,
  marginalise = FALSE,
  onlymain = FALSE,
  datainit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scoreagainstDBN_+3A_scorepar">scorepar</code></td>
<td>
<p>object of class 'scoreparameters'</p>
</td></tr>
<tr><td><code id="scoreagainstDBN_+3A_incidence">incidence</code></td>
<td>
<p>adjacency matrix of a DAG</p>
</td></tr>
<tr><td><code id="scoreagainstDBN_+3A_datatoscore">datatoscore</code></td>
<td>
<p>matrix or vector containing observations to be scored</p>
</td></tr>
<tr><td><code id="scoreagainstDBN_+3A_marginalise">marginalise</code></td>
<td>
<p>(logical) should marginal score be used?</p>
</td></tr>
<tr><td><code id="scoreagainstDBN_+3A_onlymain">onlymain</code></td>
<td>
<p>(logical) should static nodes be included in the score?</p>
</td></tr>
<tr><td><code id="scoreagainstDBN_+3A_datainit">datainit</code></td>
<td>
<p>optional, in case of unbalanced design, the mean score of available samples for T0 are computed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of log-scores
</p>


<h3>Author(s)</h3>

<p>Polina Suter
</p>

<hr>
<h2 id='scoreparameters'>Initializing score object</h2><span id='topic+scoreparameters'></span><span id='topic+print.scoreparameters'></span><span id='topic+summary.scoreparameters'></span>

<h3>Description</h3>

<p>This function returns an object of class scoreparameters containing the data and parameters needed for calculation of the BDe/BGe score, or a user defined score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scoreparameters(
  scoretype = c("bge", "bde", "bdecat", "usr"),
  data,
  bgepar = list(am = 1, aw = NULL, edgepf = 1),
  bdepar = list(chi = 0.5, edgepf = 2),
  bdecatpar = list(chi = 0.5, edgepf = 2),
  dbnpar = list(samestruct = TRUE, slices = 2, b = 0, stationary = TRUE, rowids = NULL,
    datalist = NULL, learninit = TRUE),
  usrpar = list(pctesttype = c("bge", "bde", "bdecat")),
  mixedpar = list(nbin = 0),
  MDAG = FALSE,
  DBN = FALSE,
  weightvector = NULL,
  bgnodes = NULL,
  edgepmat = NULL,
  nodeslabels = NULL
)

## S3 method for class 'scoreparameters'
print(x, ...)

## S3 method for class 'scoreparameters'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scoreparameters_+3A_scoretype">scoretype</code></td>
<td>
<p>the score to be used to assess the DAG structure:
&quot;bge&quot; for Gaussian data, &quot;bde&quot; for binary data, 
&quot;bdecat&quot; for categorical data,
&quot;usr&quot; for a user defined score; when &quot;usr&quot; score is chosen, one must define a function (which evaluates the log score of a node given its parents) in the following format: usrDAGcorescore(j,parentnodes,n,param), where 'j' is node to be scores, 'parentnodes' are the parents of this node, 'n' number of nodes in the netwrok and 'param' is an object of class 'scoreparameters'</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_data">data</code></td>
<td>
<p>the data matrix with n columns (the number of variables) and a number of rows equal to the number of observations</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_bgepar">bgepar</code></td>
<td>
<p>a list which contains parameters for BGe score:
</p>

<ul>
<li><p> am (optional) a positive numerical value, 1 by default
</p>
</li>
<li><p> aw (optional) a positive numerical value should be more than <code>n+1</code>, <code>n+am+1</code> by default
</p>
</li>
<li><p> edgepf (optional) a positive numerical value providing the edge penalization factor to be combined with the BGe score, 1 by default (no penalization)
</p>
</li></ul>
</td></tr>
<tr><td><code id="scoreparameters_+3A_bdepar">bdepar</code></td>
<td>
<p>a list which contains parameters for BDe score for binary data:
</p>

<ul>
<li><p> chi (optional) a positive number of prior pseudo counts used by the BDe score, 0.5 by default
</p>
</li>
<li><p> edgepf (optional) a positive numerical value providing the edge penalization factor to be combined with the BDe score, 2 by default
</p>
</li></ul>
</td></tr>
<tr><td><code id="scoreparameters_+3A_bdecatpar">bdecatpar</code></td>
<td>
<p>a list which contains parameters for BDe score for categorical data:
</p>

<ul>
<li><p> chi (optional) a positive number of prior pseudo counts used by the BDe score, 0.5 by default
</p>
</li>
<li><p> edgepf (optional) a positive numerical value providing the edge penalization factor to be combined with the BDe score, 2 by default
</p>
</li></ul>
</td></tr>
<tr><td><code id="scoreparameters_+3A_dbnpar">dbnpar</code></td>
<td>
<p>which type of score to use for the slices
</p>

<ul>
<li><p> samestruct logical, when TRUE the structure of the first time slice is assumed to be the same as internal structure of all other time slices
</p>
</li>
<li><p> slices integer representing the number of time slices in a DBN
</p>
</li>
<li><p> b the number of static variables; all static variables have to be in the first b columns of the data;  for DBNs static variables have the same meaning as bgnodes for usual Bayesian networks; for DBNs parameters parameter <code>bgnodes</code> is ignored
</p>
</li>
<li><p> rowids optional vector of time IDs; usefull for identifying data for initial time slice
</p>
</li>
<li><p> datalist indicates is data is passed as a list for a two step DBN; useful for unbalanced number of samples in timi slices
</p>
</li></ul>
</td></tr>
<tr><td><code id="scoreparameters_+3A_usrpar">usrpar</code></td>
<td>
<p>a list which contains parameters for the user defined score
</p>

<ul>
<li><p> pctesttype (optional) conditional independence test (&quot;bde&quot;,&quot;bge&quot;,&quot;bdecat&quot;)
</p>
</li></ul>
</td></tr>
<tr><td><code id="scoreparameters_+3A_mixedpar">mixedpar</code></td>
<td>
<p>a list which contains parameters for the BGe and BDe score for mixed data
</p>

<ul>
<li><p> nbin a positive integer number of binary nodes in the network (the binary nodes are always assumed in first nbin columns of the data)
</p>
</li></ul>
</td></tr>
<tr><td><code id="scoreparameters_+3A_mdag">MDAG</code></td>
<td>
<p>logical, when TRUE the score is initialized for a model with multiple sets of parameters but the same structure</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_dbn">DBN</code></td>
<td>
<p>logical, when TRUE the score is initialized for a dynamic Baysian network; FALSE by default</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_weightvector">weightvector</code></td>
<td>
<p>(optional) a numerical vector of positive values representing the weight of each observation; should be NULL(default) for non-weighted data</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_bgnodes">bgnodes</code></td>
<td>
<p>(optional) a vector that contains  column indices in the data defining the nodes that are forced to be root nodes in the sampled graphs; root nodes are nodes which have no parents but can be parents of other nodes in the network; in case of DBNs bgnodes represent static variables and defined via element <code>b</code> of the parameters <code>dbnpar</code>; parameter <code>bgnodes</code> is ignored for DBNs</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_edgepmat">edgepmat</code></td>
<td>
<p>(optional) a matrix of positive numerical values providing the per edge penalization factor to be added to the score, NULL by default</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_nodeslabels">nodeslabels</code></td>
<td>
<p>(optional) a vector of characters which denote the names of nodes in the Bayesian network; by default column names of the data will be taken</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_x">x</code></td>
<td>
<p>object of class 'scoreparameters'</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="scoreparameters_+3A_object">object</code></td>
<td>
<p>object of class 'scoreparameters'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object of class <code>scoreparameters</code>, which includes all necessary information for calculating the BDe/BGe score
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack kuipers
</p>


<h3>References</h3>

<p>Geiger D and Heckerman D (2002). Parameter priors for directed acyclic graphical models and the characterization of several probability distributions. The Annals of Statistics 30, 1412-1440.
</p>
<p>Kuipers J, Moffa G and Heckerman D (2014). Addendum on the scoring of Gaussian acyclic graphical models. The Annals of Statistics 42, 1689-1691.
</p>
<p>Heckerman D and Geiger D (1995). Learning Bayesian networks: A unification for discrete and Gaussian domains. In Eleventh Conference on Uncertainty in Artificial Intelligence, pages 274-284.
</p>
<p>Scutari M (2016). An Empirical-Bayes Score for Discrete Bayesian Networks. Journal of Machine Learning Research 52, 438-448
</p>


<h3>Examples</h3>

<pre><code class='language-R'>myDAG&lt;-pcalg::randomDAG(20, prob=0.15, lB = 0.4, uB = 2) 
myData&lt;-pcalg::rmvDAG(200, myDAG) 
myScore&lt;-scoreparameters("bge", myData)
</code></pre>

<hr>
<h2 id='scorespace'>Prints 'scorespace' object</h2><span id='topic+scorespace'></span><span id='topic+print.scorespace'></span><span id='topic+summary.scorespace'></span>

<h3>Description</h3>

<p>Prints 'scorespace' object
</p>
<p>Summary of object of class 'scorespace'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scorespace(
  scorepar,
  alpha = 0.05,
  hardlimit = 14,
  plus1 = TRUE,
  cpdag = TRUE,
  startspace = NULL,
  blacklist = NULL,
  verbose = FALSE
)

## S3 method for class 'scorespace'
print(x, ...)

## S3 method for class 'scorespace'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scorespace_+3A_scorepar">scorepar</code></td>
<td>
<p>an object of class <code>scoreparameters</code>, containing the data and score scorepareters, see constructor function <code><a href="#topic+scoreparameters">scoreparameters</a></code></p>
</td></tr>
<tr><td><code id="scorespace_+3A_alpha">alpha</code></td>
<td>
<p>numerical significance value in <code>{0,1}</code> for the conditional independence tests at the PC algorithm stage (by default <code class="reqn">0.4</code> for <code class="reqn">n&lt;50</code>, <code class="reqn">20/n</code> for <code class="reqn">n&gt;50</code>)</p>
</td></tr>
<tr><td><code id="scorespace_+3A_hardlimit">hardlimit</code></td>
<td>
<p>integer, limit on the size of parent sets in the search space; by default 14 when MAP=TRUE and 20 when MAP=FALSE</p>
</td></tr>
<tr><td><code id="scorespace_+3A_plus1">plus1</code></td>
<td>
<p>logical, if TRUE (default) the search is performed on the extended search space</p>
</td></tr>
<tr><td><code id="scorespace_+3A_cpdag">cpdag</code></td>
<td>
<p>logical, if TRUE the CPDAG returned by the PC algorithm will be used as the search
space, if FALSE (default) the full undirected skeleton will be used as the search space</p>
</td></tr>
<tr><td><code id="scorespace_+3A_startspace">startspace</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines the search space for the order MCMC in the form of an adjacency matrix. If NULL, the skeleton obtained from the PC-algorithm will be used. If <code>startspace[i,j]</code> equals to 1 (0) it means that the edge from node <code>i</code> to node <code>j</code> is included (excluded) from the search space. To include an edge in both directions, both <code>startspace[i,j]</code> and <code>startspace[j,i]</code> should be 1.</p>
</td></tr>
<tr><td><code id="scorespace_+3A_blacklist">blacklist</code></td>
<td>
<p>(optional) a square matrix, of dimensions equal to the number of nodes, which defines edges to exclude from the search space. If <code>blacklist[i,j]</code> equals to 1 it means that the edge from node <code>i</code> to node <code>j</code> is excluded from the search space.</p>
</td></tr>
<tr><td><code id="scorespace_+3A_verbose">verbose</code></td>
<td>
<p>logical, if TRUE messages about the algorithm's progress will be printed, FALSE by default</p>
</td></tr>
<tr><td><code id="scorespace_+3A_x">x</code></td>
<td>
<p>object of class 'scorespace'</p>
</td></tr>
<tr><td><code id="scorespace_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="scorespace_+3A_object">object</code></td>
<td>
<p>object of class 'scorespace'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>scorespace</code>, a list of three objects: 'adjacency' matrix representiong the search space, 'blacklist' used to exclude edges from the search space and 'tables' containing score quantities for each node
needed to run MCMC schemes
</p>


<h3>Author(s)</h3>

<p>Polina Suter, Jack Kuipers
</p>


<h3>References</h3>

<p>Friedman N and Koller D (2003). A Bayesian approach to structure discovery in bayesian networks. Machine Learning 50, 95-125.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#' #find a MAP DAG with search space defined by PC and plus1 neighbourhood
Bostonscore&lt;-scoreparameters("bge",Boston)
Bostonspace&lt;-scorespace(Bostonscore, 0.05, 14)
## Not run: 
orderfit&lt;-orderMCMC(Bostonscore, scoretable=Bostonspace)
partitionfit&lt;-orderMCMC(Bostonscore, scoretable=Bostonspace)

## End(Not run)
</code></pre>

<hr>
<h2 id='scorespace+20class'>scorespace class structure</h2><span id='topic+scorespace+20class'></span>

<h3>Description</h3>

<p>The structure of an object of S3 class <code>scorespace</code>.
</p>


<h3>Details</h3>

<p>An object of class <code>scorespace</code> is a list containing at least the following
components:
</p>

<ul>
<li><p> adjacency: adjacency martrix representing the core search space
</p>
</li>
<li><p> blacklist: adjacency martrix representing the blacklist used for computing score tables tables
</p>
</li>
<li><p> tables: a list of matrices (for core search space) or a list of lists of matrices (for extended search space) containing quantities needed for scoring orders and sampling DAGs in MCMC schemes; this list corresponds to adjacency and blacklist
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Polina Suter</p>

<hr>
<h2 id='string2mat'>Deriving interactions matrix</h2><span id='topic+string2mat'></span>

<h3>Description</h3>

<p>This transforms a list of possible interactions between proteins downloaded from STRING database
into a matrix which can be used for blacklisting/penalization in BiDAG.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>string2mat(curnames, int, mapping = NULL, type = c("int"), pf = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="string2mat_+3A_curnames">curnames</code></td>
<td>
<p>character vector with gene names which will be used in <code>BiDAG</code> learning function</p>
</td></tr>
<tr><td><code id="string2mat_+3A_int">int</code></td>
<td>
<p>data frame, representing a interactions between genes/proteins downloaded from STRING (<a href="https://string-db.org/">https://string-db.org/</a>); two columns are necessary 'node1' and 'node2'</p>
</td></tr>
<tr><td><code id="string2mat_+3A_mapping">mapping</code></td>
<td>
<p>(optional) data frame, representing a mapping between 'curnames' (gene names, usually the column names of 'data') and gene names used in interactions downloaded from STRING (<a href="https://string-db.org/">https://string-db.org/</a>); two columns are necessary 'queryItem' and 'preferredName'</p>
</td></tr>
<tr><td><code id="string2mat_+3A_type">type</code></td>
<td>
<p>character, defines how interactions will be reflected in the output matrix; <code>int</code> will result in a matrix whose entries equal 1 if interaction is present in the list of interactions <code>int</code> and 0 otherwise; <code>blacklist</code> results in a matrix whose entries equal 0 when interaction is present in the list of interactions and 1 otherwise;
<code>pf</code> results in a matrix results in a matrix whose entries equal 1 is interaction is present in the list of interactions <code>int</code> and <code>pf</code> otherwise$ &quot;int&quot; by default</p>
</td></tr>
<tr><td><code id="string2mat_+3A_pf">pf</code></td>
<td>
<p>penalization factor for interactions, needed if <code>type</code>=pf</p>
</td></tr>
</table>


<h3>Value</h3>

<p>square matrix whose entries  correspond to the list of interactions and parameter <code>type</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>curnames&lt;-colnames(kirp)
intmat&lt;-string2mat(curnames, mapping, interactions, type="pf")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
