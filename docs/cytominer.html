<!DOCTYPE html><html lang="en"><head><title>Help for package cytominer</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cytominer}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregate'><p>Aggregate data based on given grouping.</p></a></li>
<li><a href='#correlation_threshold'><p>Remove redundant variables.</p></a></li>
<li><a href='#count_na_rows'><p>Count the number of <code>NA</code>s per variable.</p></a></li>
<li><a href='#covariance'><p>Compute covariance matrix and vectorize.</p></a></li>
<li><a href='#drop_na_columns'><p>Remove variables with NA values.</p></a></li>
<li><a href='#drop_na_rows'><p>Drop rows that are <code>NA</code> in all specified variables.</p></a></li>
<li><a href='#extract_subpopulations'><p>Extract subpopulations.</p></a></li>
<li><a href='#generalized_log'><p>Generalized log transform data.</p></a></li>
<li><a href='#generate_component_matrix'><p>A sparse matrix for sparse random projection.</p></a></li>
<li><a href='#normalize'><p>Normalize observation variables.</p></a></li>
<li><a href='#replicate_correlation'><p>Measure replicate correlation of variables.</p></a></li>
<li><a href='#sparse_random_projection'><p>Reduce the dimensionality of a population using sparse random projection.</p></a></li>
<li><a href='#svd_entropy'><p>Feature importance based on data entropy.</p></a></li>
<li><a href='#transform'><p>Transform observation variables.</p></a></li>
<li><a href='#variable_importance'><p>Measure variable importance.</p></a></li>
<li><a href='#variable_select'><p>Select observation variables.</p></a></li>
<li><a href='#variance_threshold'><p>Remove variables with near-zero variance.</p></a></li>
<li><a href='#whiten'><p>Whiten data.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods for Image-Based Cell Profiling</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Typical morphological profiling datasets have millions of cells
    and hundreds of features per cell. When working with this data, you must
    clean the data, normalize the features to make them comparable across
    experiments, transform the features, select features based on their
    quality, and aggregate the single-cell data, if needed. 'cytominer' makes
    these steps fast and easy. Methods used in practice in the field are
    discussed in Caicedo (2017) &lt;<a href="https://doi.org/10.1038%2Fnmeth.4397">doi:10.1038/nmeth.4397</a>&gt;. An overview of the
    field is presented in Caicedo (2016) &lt;<a href="https://doi.org/10.1016%2Fj.copbio.2016.04.003">doi:10.1016/j.copbio.2016.04.003</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret (&ge; 6.0.76), doParallel (&ge; 1.0.10), dplyr (&ge; 0.8.5),
foreach (&ge; 1.4.3), futile.logger (&ge; 1.4.3), magrittr (&ge;
1.5), Matrix (&ge; 1.2), purrr (&ge; 0.3.3), rlang (&ge; 0.4.5),
tibble (&ge; 2.1.3), tidyr (&ge; 1.0.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>DBI (&ge; 0.7), dbplyr (&ge; 1.4.2), knitr (&ge; 1.17), lazyeval
(&ge; 0.2.0), readr (&ge; 1.1.1), rmarkdown (&ge; 1.6), RSQLite (&ge;
2.0), stringr (&ge; 1.2.0), testthat (&ge; 1.0.2)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/cytomining/cytominer">https://github.com/cytomining/cytominer</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cytomining/cytominer/issues">https://github.com/cytomining/cytominer/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-05-09 03:40:43 UTC; shsingh</td>
</tr>
<tr>
<td>Author:</td>
<td>Tim Becker [aut],
  Allen Goodman [aut],
  Claire McQuin [aut],
  Mohammad Rohban [aut],
  Shantanu Singh [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Shantanu Singh &lt;shsingh@broadinstitute.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-05-09 05:00:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregate'>Aggregate data based on given grouping.</h2><span id='topic+aggregate'></span>

<h3>Description</h3>

<p><code>aggregate</code> aggregates data based on the specified aggregation method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate(
  population,
  variables,
  strata,
  operation = "mean",
  univariate = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_strata">strata</code></td>
<td>
<p>character vector specifying grouping variables for aggregation.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_operation">operation</code></td>
<td>
<p>optional character string specifying method for aggregation,
e.g. <code>"mean"</code>, <code>"median"</code>, <code>"mean+sd"</code>. A sequence can
comprise only of univariate functions.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_univariate">univariate</code></td>
<td>
<p>boolean specifying whether the aggregation function is
univariate or multivariate.</p>
</td></tr>
<tr><td><code id="aggregate_+3A_...">...</code></td>
<td>
<p>optional arguments passed to aggregation operation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>aggregated data of the same class as <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_group = c(
    "control", "control", "control", "control",
    "experiment", "experiment", "experiment",
    "experiment"
  ),
  Metadata_batch = c("a", "a", "b", "b", "a", "a", "b", "b"),
  AreaShape_Area = c(10, 12, 15, 16, 8, 8, 7, 7)
)
variables &lt;- c("AreaShape_Area")
strata &lt;- c("Metadata_group", "Metadata_batch")
aggregate(population, variables, strata, operation = "mean")
</code></pre>

<hr>
<h2 id='correlation_threshold'>Remove redundant variables.</h2><span id='topic+correlation_threshold'></span>

<h3>Description</h3>

<p><code>correlation_threshold</code> returns list of variables such that no two variables have a correlation greater than a specified threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlation_threshold(variables, sample, cutoff = 0.9, method = "pearson")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="correlation_threshold_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="correlation_threshold_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample used to estimate parameters.</p>
</td></tr>
<tr><td><code id="correlation_threshold_+3A_cutoff">cutoff</code></td>
<td>
<p>threshold between [0,1] that defines the minimum correlation of a selected feature.</p>
</td></tr>
<tr><td><code id="correlation_threshold_+3A_method">method</code></td>
<td>
<p>optional character string specifying method for calculating correlation. This must be one of the strings <code>"pearson"</code> (default), <code>"kendall"</code>, <code>"spearman"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>correlation_threshold</code> is a wrapper for <code>caret::findCorrelation</code>.
</p>


<h3>Value</h3>

<p>character vector specifying observation variables to be excluded.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
suppressMessages(suppressWarnings(library(magrittr)))
sample &lt;- tibble::tibble(
  x = rnorm(30),
  y = rnorm(30) / 1000
)

sample %&lt;&gt;% dplyr::mutate(z = x + rnorm(30) / 10)
variables &lt;- c("x", "y", "z")

head(sample)
cor(sample)

# `x` and `z` are highly correlated; one of them will be removed

correlation_threshold(variables, sample)
</code></pre>

<hr>
<h2 id='count_na_rows'>Count the number of <code>NA</code>s per variable.</h2><span id='topic+count_na_rows'></span>

<h3>Description</h3>

<p><code>count_na_rows</code> counts the number of <code>NA</code>s per variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>count_na_rows(population, variables)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="count_na_rows_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="count_na_rows_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame with frequency of <code>NA</code>s per variable.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
population &lt;- tibble::tibble(
  Metadata_group = c(
    "control", "control", "control", "control",
    "experiment", "experiment", "experiment", "experiment"
  ),
  Metadata_batch = c("a", "a", "b", "b", "a", "a", "b", "b"),
  AreaShape_Area = c(10, 12, 15, 16, 8, 8, 7, 7),
  AreaShape_length = c(2, 3, NA, NA, 4, 5, 1, 5)
)
variables &lt;- c("AreaShape_Area", "AreaShape_length")
count_na_rows(population, variables)
</code></pre>

<hr>
<h2 id='covariance'>Compute covariance matrix and vectorize.</h2><span id='topic+covariance'></span>

<h3>Description</h3>

<p><code>covariance</code> computes the covariance matrix and vectorize it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covariance(population, variables)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="covariance_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="covariance_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame of 1 row comprising vectorized covariance matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
population &lt;- tibble::tibble(
  x = rnorm(30),
  y = rnorm(30),
  z = rnorm(30)
)

variables &lt;- c("x", "y")

covariance(population, variables)
</code></pre>

<hr>
<h2 id='drop_na_columns'>Remove variables with NA values.</h2><span id='topic+drop_na_columns'></span>

<h3>Description</h3>

<p><code>drop_na_columns</code> returns list of variables which have greater than a specified threshold number of <code>NA</code>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop_na_columns(population, variables, cutoff = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drop_na_columns_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="drop_na_columns_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="drop_na_columns_+3A_cutoff">cutoff</code></td>
<td>
<p>threshold between [0,1]. Variables with an <code>NA</code> frequency &gt; <code>cutoff</code> are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>character vector specifying observation variables to be excluded.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_group = c(
    "control", "control", "control", "control",
    "experiment", "experiment", "experiment", "experiment"
  ),
  Metadata_batch = c("a", "a", "b", "b", "a", "a", "b", "b"),
  AreaShape_Area = c(10, 12, 15, 16, 8, 8, 7, 7),
  AreaShape_Length = c(2, 3, NA, NA, 4, 5, 1, 5)
)
variables &lt;- c("AreaShape_Area", "AreaShape_Length")
drop_na_columns(population, variables)
</code></pre>

<hr>
<h2 id='drop_na_rows'>Drop rows that are <code>NA</code> in all specified variables.</h2><span id='topic+drop_na_rows'></span>

<h3>Description</h3>

<p><code>drop_na_rows</code> drops rows that are <code>NA</code> in all specified variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop_na_rows(population, variables)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="drop_na_rows_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="drop_na_rows_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>population</code> without rows that have <code>NA</code> in all specified variables.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_group = c(
    "control", "control", "control", "control",
    "experiment", "experiment", "experiment", "experiment"
  ),
  Metadata_batch = c("a", "a", "b", "b", "a", "a", "b", "b"),
  AreaShape_Area = c(10, 12, NA, 16, 8, 8, 7, 7),
  AreaShape_Length = c(2, 3, NA, NA, 4, 5, 1, 5)
)
variables &lt;- c("AreaShape_Area", "AreaShape_Length")
drop_na_rows(population, variables)
</code></pre>

<hr>
<h2 id='extract_subpopulations'>Extract subpopulations.</h2><span id='topic+extract_subpopulations'></span>

<h3>Description</h3>

<p><code>extract_subpopulations</code> identifies clusters in the reference and
population sets and reports the frequency of points in each cluster for the
two sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_subpopulations(population, reference, variables, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extract_subpopulations_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="extract_subpopulations_+3A_reference">reference</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables. Columns of <code>population</code> and <code>reference</code> should be identical.</p>
</td></tr>
<tr><td><code id="extract_subpopulations_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="extract_subpopulations_+3A_k">k</code></td>
<td>
<p>scalar specifying number of clusters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list containing clusters centers (<code>subpop_centers</code>), two
normalized histograms specifying frequency of each clusters in population
and reference (<code>subpop_profiles</code>), and cluster prediction and distance to
the predicted cluster for all input data (<code>population_clusters</code> and
<code>reference_clusters</code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data &lt;- tibble::tibble(
  Metadata_group = c(
    "control", "control", "control", "control",
    "experiment", "experiment", "experiment", "experiment"
  ),
  AreaShape_Area = c(10, 12, NA, 16, 8, 8, 7, 7),
  AreaShape_Length = c(2, 3, NA, NA, 4, 5, 1, 5)
)
variables &lt;- c("AreaShape_Area", "AreaShape_Length")
population &lt;- dplyr::filter(data, Metadata_group == "experiment")
reference &lt;- dplyr::filter(data, Metadata_group == "control")
extract_subpopulations(
  population = population,
  reference = reference,
  variables = variables,
  k = 3
)
</code></pre>

<hr>
<h2 id='generalized_log'>Generalized log transform data.</h2><span id='topic+generalized_log'></span>

<h3>Description</h3>

<p><code>generalized_log</code> transforms specified observation variables using <code class="reqn">x = log( (x + sqrt(x ^ 2 + offset ^ 2 )) / 2 )</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generalized_log(population, variables, offset = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generalized_log_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="generalized_log_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="generalized_log_+3A_offset">offset</code></td>
<td>
<p>optional offset parameter for the transformation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>transformed data of the same class as <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_Well = c("A01", "A02", "B01", "B02"),
  Intensity_DNA = c(8, 20, 12, 32)
)
variables &lt;- c("Intensity_DNA")
generalized_log(population, variables)
</code></pre>

<hr>
<h2 id='generate_component_matrix'>A sparse matrix for sparse random projection.</h2><span id='topic+generate_component_matrix'></span>

<h3>Description</h3>

<p><code>generate_component_matrix</code> generates the sparse random component matrix
for performing sparse random projection. If <code>density</code> is the density of
the sparse matrix and <code>n_components</code> is the size of the projected space,
the elements of the random matrix are drawn from
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_component_matrix(n_features, n_components, density)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_component_matrix_+3A_n_features">n_features</code></td>
<td>
<p>the dimensionality of the original space.</p>
</td></tr>
<tr><td><code id="generate_component_matrix_+3A_n_components">n_components</code></td>
<td>
<p>the dimensionality of the projected space.</p>
</td></tr>
<tr><td><code id="generate_component_matrix_+3A_density">density</code></td>
<td>
<p>the density of the sparse random matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>-sqrt(1 / (density * n_components))</code> with probability <code>density / 2</code>
<code>0</code>                                   with probability <code>1 - density</code>
<code>sqrt(1 / (density * n_components))</code>  with probability <code>density / 2</code>
</p>


<h3>Value</h3>

<p>A sparse random matrix of size <code>(n_features, n_components)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>generate_component_matrix(500, 100, 0.3)
</code></pre>

<hr>
<h2 id='normalize'>Normalize observation variables.</h2><span id='topic+normalize'></span>

<h3>Description</h3>

<p><code>normalize</code> normalizes observation variables based on the specified normalization method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize(
  population,
  variables,
  strata,
  sample,
  operation = "standardize",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="normalize_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="normalize_+3A_strata">strata</code></td>
<td>
<p>character vector specifying grouping variables for grouping prior to normalization.</p>
</td></tr>
<tr><td><code id="normalize_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample that is used by normalization methods to estimate parameters. <code>sample</code> has same structure as <code>population</code>. Typically, <code>sample</code> corresponds to controls in the experiment.</p>
</td></tr>
<tr><td><code id="normalize_+3A_operation">operation</code></td>
<td>
<p>optional character string specifying method for normalization. This must be one of the strings <code>"standardize"</code> (default), <code>"robustize"</code>.</p>
</td></tr>
<tr><td><code id="normalize_+3A_...">...</code></td>
<td>
<p>arguments passed to normalization operation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>normalized data of the same class as <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>suppressMessages(suppressWarnings(library(magrittr)))
population &lt;- tibble::tibble(
  Metadata_group = c(
    "control", "control", "control", "control",
    "experiment", "experiment", "experiment", "experiment"
  ),
  Metadata_batch = c("a", "a", "b", "b", "a", "a", "b", "b"),
  AreaShape_Area = c(10, 12, 15, 16, 8, 8, 7, 7)
)
variables &lt;- c("AreaShape_Area")
strata &lt;- c("Metadata_batch")
sample &lt;- population %&gt;% dplyr::filter(Metadata_group == "control")
cytominer::normalize(population, variables, strata, sample, operation = "standardize")
</code></pre>

<hr>
<h2 id='replicate_correlation'>Measure replicate correlation of variables.</h2><span id='topic+replicate_correlation'></span>

<h3>Description</h3>

<p>'replicate_correlation' measures replicate correlation of variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replicate_correlation(
  sample,
  variables,
  strata,
  replicates,
  replicate_by = NULL,
  split_by = NULL,
  cores = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="replicate_correlation_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample used to estimate parameters.</p>
</td></tr>
<tr><td><code id="replicate_correlation_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="replicate_correlation_+3A_strata">strata</code></td>
<td>
<p>character vector specifying grouping variables for grouping prior to normalization.</p>
</td></tr>
<tr><td><code id="replicate_correlation_+3A_replicates">replicates</code></td>
<td>
<p>number of replicates.</p>
</td></tr>
<tr><td><code id="replicate_correlation_+3A_replicate_by">replicate_by</code></td>
<td>
<p>optional character string specifying column containing the replicate id.</p>
</td></tr>
<tr><td><code id="replicate_correlation_+3A_split_by">split_by</code></td>
<td>
<p>optional character string specifying column  by which to split the sample into batches; replicate correlations will be calculate per batch.</p>
</td></tr>
<tr><td><code id="replicate_correlation_+3A_cores">cores</code></td>
<td>
<p>optional integer specifying number of CPU cores used for parallel computing using <code>doParallel</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame of variable quality measurements
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x1 &lt;- rnorm(10)
x2 &lt;- x1 + rnorm(10) / 100
y1 &lt;- rnorm(10)
y2 &lt;- y1 + rnorm(10) / 10
z1 &lt;- rnorm(10)
z2 &lt;- z1 + rnorm(10) / 1

batch &lt;- rep(rep(1:2, each = 5), 2)

treatment &lt;- rep(1:10, 2)

replicate_id &lt;- rep(1:2, each = 10)

sample &lt;-
  tibble::tibble(
    x = c(x1, x2), y = c(y1, y2), z = c(z1, z2),
    Metadata_treatment = treatment,
    Metadata_replicate_id = replicate_id,
    Metadata_batch = batch
  )

head(sample)

# `replicate_correlation`` returns the median, min, and max
# replicate correlation (across batches) per variable
replicate_correlation(
  sample = sample,
  variables = c("x", "y", "z"),
  strata = c("Metadata_treatment"),
  replicates = 2,
  split_by = "Metadata_batch",
  replicate_by = "Metadata_replicate_id",
  cores = 1
)
</code></pre>

<hr>
<h2 id='sparse_random_projection'>Reduce the dimensionality of a population using sparse random projection.</h2><span id='topic+sparse_random_projection'></span>

<h3>Description</h3>

<p><code>sparse_random_projection</code> reduces the dimensionality of a population by projecting
the original data with a sparse random matrix. Generally more efficient and faster to
compute than a Gaussian random projection matrix, while providing similar embedding quality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparse_random_projection(population, variables, n_components)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sparse_random_projection_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="sparse_random_projection_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="sparse_random_projection_+3A_n_components">n_components</code></td>
<td>
<p>size of the projected feature space.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dimensionality reduced <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_Well = c("A01", "A02", "B01", "B02"),
  AreaShape_Area_DNA = c(10, 12, 7, 7),
  AreaShape_Length_DNA = c(2, 3, 1, 5),
  Intensity_DNA = c(8, 20, 12, 32),
  Texture_DNA = c(5, 2, 43, 13)
)
variables &lt;- c("AreaShape_Area_DNA", "AreaShape_Length_DNA", "Intensity_DNA", "Texture_DNA")
sparse_random_projection(population, variables, 2)
</code></pre>

<hr>
<h2 id='svd_entropy'>Feature importance based on data entropy.</h2><span id='topic+svd_entropy'></span>

<h3>Description</h3>

<p><code>svd_entropy</code> measures the contribution of each feature in decreasing the data entropy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svd_entropy(variables, sample, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="svd_entropy_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="svd_entropy_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample used to estimate parameters.</p>
</td></tr>
<tr><td><code id="svd_entropy_+3A_cores">cores</code></td>
<td>
<p>optional integer specifying number of CPU cores used for parallel computing using <code>doParallel</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame specifying the contribution of each feature in decreasing the data entropy.
Higher values indicate more information.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample &lt;- tibble::tibble(
  AreaShape_MinorAxisLength = c(10, 12, 15, 16, 8, 8, 7, 7, 13, 18),
  AreaShape_MajorAxisLength = c(35, 18, 22, 16, 9, 20, 11, 15, 18, 42),
  AreaShape_Area = c(245, 151, 231, 179, 50, 112, 53, 73, 164, 529)
)
variables &lt;- c("AreaShape_MinorAxisLength", "AreaShape_MajorAxisLength", "AreaShape_Area")
svd_entropy(variables, sample, cores = 1)
</code></pre>

<hr>
<h2 id='transform'>Transform observation variables.</h2><span id='topic+transform'></span>

<h3>Description</h3>

<p><code>transform</code> transforms observation variables based on the specified transformation method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform(population, variables, operation = "generalized_log", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="transform_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="transform_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="transform_+3A_operation">operation</code></td>
<td>
<p>optional character string specifying method for transform. This must be one of the strings <code>"generalized_log"</code> (default), <code>"whiten"</code>.</p>
</td></tr>
<tr><td><code id="transform_+3A_...">...</code></td>
<td>
<p>arguments passed to transformation operation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>transformed data of the same class as <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_Well = c("A01", "A02", "B01", "B02"),
  Intensity_DNA = c(8, 20, 12, 32)
)
variables &lt;- c("Intensity_DNA")
transform(population, variables, operation = "generalized_log")
</code></pre>

<hr>
<h2 id='variable_importance'>Measure variable importance.</h2><span id='topic+variable_importance'></span>

<h3>Description</h3>

<p><code>variable_importance</code> measures importance of variables based on specified methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_importance(
  sample,
  variables,
  operation = "replicate_correlation",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variable_importance_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample used to estimate parameters.</p>
</td></tr>
<tr><td><code id="variable_importance_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="variable_importance_+3A_operation">operation</code></td>
<td>
<p>optional character string specifying method for computing variable importance. Currently, only <code>"replicate_correlation"</code> (default) is implemented.</p>
</td></tr>
<tr><td><code id="variable_importance_+3A_...">...</code></td>
<td>
<p>arguments passed to variable importance operation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data frame containing variable importance measures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(123)
x1 &lt;- rnorm(10)
x2 &lt;- x1 + rnorm(10) / 100
y1 &lt;- rnorm(10)
y2 &lt;- y1 + rnorm(10) / 10
z1 &lt;- rnorm(10)
z2 &lt;- z1 + rnorm(10) / 1

batch &lt;- rep(rep(1:2, each = 5), 2)

treatment &lt;- rep(1:10, 2)

replicate_id &lt;- rep(1:2, each = 10)

sample &lt;-
  tibble::tibble(
    x = c(x1, x2), y = c(y1, y2), z = c(z1, z2),
    Metadata_treatment = treatment,
    Metadata_replicate_id = replicate_id,
    Metadata_batch = batch
  )

head(sample)

# `replicate_correlation`` returns the median, min, and max
# replicate correlation (across batches) per variable
variable_importance(
  sample = sample,
  variables = c("x", "y", "z"),
  operation = "replicate_correlation",
  strata = c("Metadata_treatment"),
  replicates = 2,
  split_by = "Metadata_batch",
  replicate_by = "Metadata_replicate_id",
  cores = 1
)
</code></pre>

<hr>
<h2 id='variable_select'>Select observation variables.</h2><span id='topic+variable_select'></span>

<h3>Description</h3>

<p><code>variable_select</code> selects observation variables based on the specified variable selection method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variable_select(
  population,
  variables,
  sample = NULL,
  operation = "variance_threshold",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variable_select_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="variable_select_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="variable_select_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample that is used by some variable selection methods. <code>sample</code> has same structure as <code>population</code>.</p>
</td></tr>
<tr><td><code id="variable_select_+3A_operation">operation</code></td>
<td>
<p>optional character string specifying method for variable selection. This must be one of the strings <code>"variance_threshold"</code>, <code>"correlation_threshold"</code>, <code>"drop_na_columns"</code>.</p>
</td></tr>
<tr><td><code id="variable_select_+3A_...">...</code></td>
<td>
<p>arguments passed to selection operation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>variable-selected data of the same class as <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# In this example, we use `correlation_threshold` as the operation for
# variable selection.

suppressMessages(suppressWarnings(library(magrittr)))
population &lt;- tibble::tibble(
  x = rnorm(100),
  y = rnorm(100) / 1000
)

population %&lt;&gt;% dplyr::mutate(z = x + rnorm(100) / 10)

sample &lt;- population %&gt;% dplyr::slice(1:30)

variables &lt;- c("x", "y", "z")

operation &lt;- "correlation_threshold"

cor(sample)

# `x` and `z` are highly correlated; one of them will be removed

head(population)

futile.logger::flog.threshold(futile.logger::ERROR)

variable_select(population, variables, sample, operation) %&gt;% head()
</code></pre>

<hr>
<h2 id='variance_threshold'>Remove variables with near-zero variance.</h2><span id='topic+variance_threshold'></span>

<h3>Description</h3>

<p><code>variance_threshold</code> returns list of variables that have near-zero variance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variance_threshold(variables, sample)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variance_threshold_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="variance_threshold_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample used to estimate parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>variance_threshold</code> is a reimplementation of <code>caret::nearZeroVar</code>, using
the default values for <code>freqCut</code> and <code>uniqueCut</code>.
</p>


<h3>Value</h3>

<p>character vector specifying observation variables to be excluded.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sample &lt;- tibble::tibble(
  AreaShape_Area = c(10, 12, 15, 16, 8, 8, 7, 7, 13, 18),
  AreaShape_Euler = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
)
variables &lt;- c("AreaShape_Area", "AreaShape_Euler")
variance_threshold(variables, sample)
</code></pre>

<hr>
<h2 id='whiten'>Whiten data.</h2><span id='topic+whiten'></span>

<h3>Description</h3>

<p><code>whiten</code> transforms specified observation variables by estimating a whitening transformation on a sample and applying it to the population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>whiten(population, variables, sample, regularization_param = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="whiten_+3A_population">population</code></td>
<td>
<p>tbl with grouping (metadata) and observation variables.</p>
</td></tr>
<tr><td><code id="whiten_+3A_variables">variables</code></td>
<td>
<p>character vector specifying observation variables.</p>
</td></tr>
<tr><td><code id="whiten_+3A_sample">sample</code></td>
<td>
<p>tbl containing sample that is used by the method to estimate whitening parameters. <code>sample</code> has same structure as <code>population</code>. Typically, <code>sample</code> corresponds to controls in the experiment.</p>
</td></tr>
<tr><td><code id="whiten_+3A_regularization_param">regularization_param</code></td>
<td>
<p>optional parameter used in whitening to offset eigenvalues to avoid division by zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>transformed data of the same class as <code>population</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>population &lt;- tibble::tibble(
  Metadata_Well = c("A01", "A02", "B01", "B02"),
  Intensity_DNA = c(8, 20, 12, 32),
  Texture_DNA = c(5, 2, 43, 13)
)
variables &lt;- c("Intensity_DNA", "Texture_DNA")
whiten(population, variables, population, 0.01)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
