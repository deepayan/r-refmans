<!DOCTYPE html><html lang="en"><head><title>Help for package live</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {live}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_predictions'><p>Add black box predictions to generated dataset</p></a></li>
<li><a href='#euclidean_kernel'><p>LIME kernel equal to the inverse of euclidean distance.</p></a></li>
<li><a href='#fit_explanation'><p>Fit white box model to the simulated data.</p></a></li>
<li><a href='#gaussian_kernel'><p>LIME kernel from the original article with sigma = 1.</p></a></li>
<li><a href='#identity_kernel'><p>LIME kernel that treats all observations as equally similar to</p>
observation of interest.</a></li>
<li><a href='#live'><p>live: visualizing interpretable models to explain black box models.</p></a></li>
<li><a href='#live_shiny'><p>Function that starts a Shiny app which helps use LIVE.</p></a></li>
<li><a href='#local_approximation'><p>Fit local model around the observation: shortcut for DALEX explainer objects</p></a></li>
<li><a href='#local_permutation_importance'><p>Local permutation variable importance</p></a></li>
<li><a href='#plot.live_explainer'><p>Plotting white box models.</p></a></li>
<li><a href='#plot.local_permutation_importance'><p>Plot local permutation importance</p></a></li>
<li><a href='#print.live_explainer'><p>Generic print function for live explainer</p></a></li>
<li><a href='#print.live_explorer'><p>Generic print function for class live_explorer</p></a></li>
<li><a href='#print.local_permutation_importance'><p>Print method for local_permutation_importance class</p></a></li>
<li><a href='#sample_locally'><p>Generate dataset for local exploration.</p></a></li>
<li><a href='#wine'><p>Red wine characteristics and quality.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Local Interpretable (Model-Agnostic) Visual Explanations</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.13</td>
</tr>
<tr>
<td>Description:</td>
<td>Interpretability of complex machine learning models is a growing concern.
    This package helps to understand key factors that drive the 
    decision made by complicated predictive model (so called black box model). 
    This is achieved through local approximations that are either based on 
    additive regression like model or CART like model that allows for 
    higher interactions. The methodology is based on Tulio Ribeiro, Singh, Guestrin (2016) &lt;<a href="https://doi.org/10.1145%2F2939672.2939778">doi:10.1145/2939672.2939778</a>&gt;.
    More details can be found in Staniak, Biecek (2018) &lt;<a href="https://doi.org/10.32614%2FRJ-2018-072">doi:10.32614/RJ-2018-072</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/ModelOriented/live">https://github.com/ModelOriented/live</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ModelOriented/live/issues">https://github.com/ModelOriented/live/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, glmnet, covr, DALEX, RWeka, mda,
modeltools</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>mlr, dplyr, breakDown, data.table, forestmodel, shiny, MASS,
ggplot2, gower, e1071</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-01-15 00:08:42 UTC; mtst</td>
</tr>
<tr>
<td>Author:</td>
<td>Mateusz Staniak [cre, aut],
  Przemys≈Çaw Biecek [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mateusz Staniak &lt;mateusz.staniak@math.uni.wroc.pl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-01-15 06:30:17 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_predictions'>Add black box predictions to generated dataset</h2><span id='topic+add_predictions'></span>

<h3>Description</h3>

<p>Add black box predictions to generated dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_predictions(
  to_explain,
  black_box_model,
  data = NULL,
  predict_fun = predict,
  hyperparams = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="add_predictions_+3A_to_explain">to_explain</code></td>
<td>
<p>List return by sample_locally function.</p>
</td></tr>
<tr><td><code id="add_predictions_+3A_black_box_model">black_box_model</code></td>
<td>
<p>String with mlr signature of a learner or a model with predict interface.</p>
</td></tr>
<tr><td><code id="add_predictions_+3A_data">data</code></td>
<td>
<p>Original data frame used to generate new dataset.
Need not be provided when a trained model is passed in
black_box_model argument.</p>
</td></tr>
<tr><td><code id="add_predictions_+3A_predict_fun">predict_fun</code></td>
<td>
<p>Either a &quot;predict&quot; function that returns a vector of the
same type as response or custom function that takes a model as a first argument,
and data used to calculate predictions as a second argument
and returns a vector of the same type as respone.
Will be used only if a model object was provided in the black_box argument.</p>
</td></tr>
<tr><td><code id="add_predictions_+3A_hyperparams">hyperparams</code></td>
<td>
<p>Optional list of (hyper)parameters to be passed to mlr::makeLearner.</p>
</td></tr>
<tr><td><code id="add_predictions_+3A_...">...</code></td>
<td>
<p>Additional parameters to be passed to predict function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of class &quot;live_explorer&quot; consisting of
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Dataset generated by sample_locally function with response variable.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>Name of the response variable.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Black box model which is being explained.</p>
</td></tr>
<tr><td><code>explained_instance</code></td>
<td>
<p>Instance that is being explained.</p>
</td></tr>
<tr><td><code>sampling_method</code></td>
<td>
<p>Name of used sampling method</p>
</td></tr>
<tr><td><code>fixed_variables</code></td>
<td>
<p>Names of variables which were not sampled</p>
</td></tr>
<tr><td><code>sdevations</code></td>
<td>
<p>Standard deviations of numerical variables</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Train a model inside add_predictions call.
local_exploration1 &lt;- add_predictions(dataset_for_local_exploration,
                                      black_box_model = "regr.svm",
                                      data = wine)
# Pass trained model to the function.
svm_model &lt;- svm(quality ~., data = wine)
local_exploration2 &lt;- add_predictions(dataset_for_local_exploration,
                                      black_box_model = svm_model)

## End(Not run)

</code></pre>

<hr>
<h2 id='euclidean_kernel'>LIME kernel equal to the inverse of euclidean distance.</h2><span id='topic+euclidean_kernel'></span>

<h3>Description</h3>

<p>LIME kernel equal to the inverse of euclidean distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>euclidean_kernel(explained_instance, simulated_instance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="euclidean_kernel_+3A_explained_instance">explained_instance</code></td>
<td>
<p>explained instance</p>
</td></tr>
<tr><td><code id="euclidean_kernel_+3A_simulated_instance">simulated_instance</code></td>
<td>
<p>new observation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>

<hr>
<h2 id='fit_explanation'>Fit white box model to the simulated data.</h2><span id='topic+fit_explanation'></span>

<h3>Description</h3>

<p>Fit white box model to the simulated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_explanation(
  live_object,
  white_box = "regr.lm",
  kernel = gaussian_kernel,
  standardize = FALSE,
  selection = FALSE,
  response_family = "gaussian",
  predict_type = "response",
  hyperpars = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_explanation_+3A_live_object">live_object</code></td>
<td>
<p>List return by add_predictions function.</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_white_box">white_box</code></td>
<td>
<p>String, learner name recognized by mlr package.</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_kernel">kernel</code></td>
<td>
<p>function which will be used to calculate distance between simulated
observations and explained instance.</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_standardize">standardize</code></td>
<td>
<p>If TRUE, numerical variables will be scaled to have mean 0, variance 1
before fitting explanation model.</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_selection">selection</code></td>
<td>
<p>If TRUE, variable selection based on glmnet implementation of LASSO
will be performed.</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_response_family">response_family</code></td>
<td>
<p>family argument to glmnet (and then glm) function.
Default value is &quot;gaussian&quot;</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_predict_type">predict_type</code></td>
<td>
<p>Argument passed to mlr::makeLearner() argument &quot;predict.type&quot;.
Defaults to &quot;response&quot;.</p>
</td></tr>
<tr><td><code id="fit_explanation_+3A_hyperpars">hyperpars</code></td>
<td>
<p>Optional list of values of hyperparameteres of a model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of class &quot;live_explainer&quot; that consists of
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Dataset used to fit explanation model (may have less column than the original)</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Fitted explanation model</p>
</td></tr>
<tr><td><code>explained_instance</code></td>
<td>
<p>Instance that is being explained</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>Weights used in model fitting</p>
</td></tr>
<tr><td><code>selected_variables</code></td>
<td>
<p>Names of selected variables</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fitted_explanation &lt;- fit_explanation(local_exploration1, "regr.lm", selection = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='gaussian_kernel'>LIME kernel from the original article with sigma = 1.</h2><span id='topic+gaussian_kernel'></span>

<h3>Description</h3>

<p>LIME kernel from the original article with sigma = 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussian_kernel(explained_instance, simulated_instance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gaussian_kernel_+3A_explained_instance">explained_instance</code></td>
<td>
<p>explained instance</p>
</td></tr>
<tr><td><code id="gaussian_kernel_+3A_simulated_instance">simulated_instance</code></td>
<td>
<p>new observation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>

<hr>
<h2 id='identity_kernel'>LIME kernel that treats all observations as equally similar to 
observation of interest.</h2><span id='topic+identity_kernel'></span>

<h3>Description</h3>

<p>LIME kernel that treats all observations as equally similar to 
observation of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>identity_kernel(explained_instance, simulated_instance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="identity_kernel_+3A_explained_instance">explained_instance</code></td>
<td>
<p>explained instance</p>
</td></tr>
<tr><td><code id="identity_kernel_+3A_simulated_instance">simulated_instance</code></td>
<td>
<p>new observation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric
</p>

<hr>
<h2 id='live'>live: visualizing interpretable models to explain black box models.</h2><span id='topic+live'></span>

<h3>Description</h3>

<p>This package aims to help locally fit and visualize interpretable models similarly to LIME methodology.
Interface provided by mlr package is used. Tools are provided to create a simulated dataset of
similar observations, fit chosen white box models (GLM and CART in particular) and visualize
them. The methodology is based on Tulio Ribeiro, Singh, Guestrin (2016) &lt;doi:10.1145/2939672.2939778&gt;.
More details can be found in Staniak, Biecek (2018) &lt;doi:10.32614/RJ-2018-072&gt;.
</p>


<h3>Important functions</h3>

<p><code><a href="#topic+sample_locally">sample_locally</a></code> generates a dataset that will be used for local exploration.
<code><a href="#topic+add_predictions">add_predictions</a></code> adds black box model predictions to simulated dataset.
<code><a href="#topic+fit_explanation">fit_explanation</a></code> fits a chosen white box model to simulated dataset.
generic <code><a href="base.html#topic+plot">plot</a></code> function visualizes fitted model.
<code><a href="#topic+local_approximation">local_approximation</a></code> function can be used with DALEX explainers to perform 
all the steps of local model exploration.
</p>


<h3>Example datasets</h3>

<p><code>wine</code> Data on wine quality taken from
Modeling wine preferences by data mining from physicochemical properties
</p>

<hr>
<h2 id='live_shiny'>Function that starts a Shiny app which helps use LIVE.</h2><span id='topic+live_shiny'></span>

<h3>Description</h3>

<p>Function that starts a Shiny app which helps use LIVE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>live_shiny(train_data, black_box_model, target, explained_data = train_data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="live_shiny_+3A_train_data">train_data</code></td>
<td>
<p>dataset from which observations will be sampled.</p>
</td></tr>
<tr><td><code id="live_shiny_+3A_black_box_model">black_box_model</code></td>
<td>
<p>Pre-trained  model with predict interface.</p>
</td></tr>
<tr><td><code id="live_shiny_+3A_target">target</code></td>
<td>
<p>character, name of the response variable.</p>
</td></tr>
<tr><td><code id="live_shiny_+3A_explained_data">explained_data</code></td>
<td>
<p>Data frame with predictions to explain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>shiny app
</p>

<hr>
<h2 id='local_approximation'>Fit local model around the observation: shortcut for DALEX explainer objects</h2><span id='topic+local_approximation'></span>

<h3>Description</h3>

<p>Fit local model around the observation: shortcut for DALEX explainer objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local_approximation(
  explainer,
  observation,
  target_variable_name,
  n_new_obs,
  local_model = "regr.lm",
  select_variables = F,
  predict_type = "response",
  kernel_type = gaussian_kernel,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="local_approximation_+3A_explainer">explainer</code></td>
<td>
<p>a model to be explained, preprocessed by the DALEX::explain function</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_observation">observation</code></td>
<td>
<p>a new observation for which predictions need to be explained</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_target_variable_name">target_variable_name</code></td>
<td>
<p>name of the response variablea as a character</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_n_new_obs">n_new_obs</code></td>
<td>
<p>Number of observation in the simulated dataset</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_local_model">local_model</code></td>
<td>
<p>Character specyfing mlr learner to be used as a local model</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_select_variables">select_variables</code></td>
<td>
<p>If TRUE, variable selection will be performed while
fitting the local linear model</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_predict_type">predict_type</code></td>
<td>
<p>Argument passed to mlr::makeLearner() argument &quot;predict.type&quot;
while fitting the local model. Defaults to &quot;response&quot;</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_kernel_type">kernel_type</code></td>
<td>
<p>Function which will be used to calculate distances from
simulated observation to explained instance</p>
</td></tr>
<tr><td><code id="local_approximation_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to sample_locally function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>object of class live_explainer. More details in fit_explanation function help.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data('wine')
library(randomForest)
library(DALEX)
rf &lt;- randomForest(quality~., data = wine)
expl &lt;- explain(rf, wine, wine$quality)
live_expl &lt;- local_approximation(expl, wine[5, ], "quality", 500)

## End(Not run)

</code></pre>

<hr>
<h2 id='local_permutation_importance'>Local permutation variable importance</h2><span id='topic+local_permutation_importance'></span>

<h3>Description</h3>

<p>This function calculates local variable importance (variable drop-out)
by finding top_n observations closest to the explained instance,
performing permutation variable importance and using weighted mean square
error as loss function with weights equal to 1 - Gower distances of the
closest observations to the explainedi instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>local_permutation_importance(
  explained_instance,
  data,
  explained_var,
  model,
  top_n = nrow(data)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="local_permutation_importance_+3A_explained_instance">explained_instance</code></td>
<td>
<p>Data frame with one observation for which
prediction will be explained</p>
</td></tr>
<tr><td><code id="local_permutation_importance_+3A_data">data</code></td>
<td>
<p>Data from with the same columns as explained_instance</p>
</td></tr>
<tr><td><code id="local_permutation_importance_+3A_explained_var">explained_var</code></td>
<td>
<p>Character with the names of response variable</p>
</td></tr>
<tr><td><code id="local_permutation_importance_+3A_model">model</code></td>
<td>
<p>Model to be explained</p>
</td></tr>
<tr><td><code id="local_permutation_importance_+3A_top_n">top_n</code></td>
<td>
<p>Number of observation that will be used to calculate 
local variable importance</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of class &quot;local_permutation_importance&quot; that consists of
</p>
<table role = "presentation">
<tr><td><code>residuals</code></td>
<td>
<p>Data frame with names of variables in the dataset (&quot;label&quot;) and
values of drop-out loss (&quot;dropout_loss&quot;)</p>
</td></tr>
<tr><td><code>weighted_local_mse</code></td>
<td>
<p>Value of weighted MSE for the whole dataset with weights
given by 1 - Gower distance from the explained instance</p>
</td></tr>
<tr><td><code>explained_instance</code></td>
<td>
<p>Explained instance as a data frame</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
local_permutation_importance(wine[5, ], wine, 
                             randomForest(quality~., data = wine),
                             top_n = 1000)

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.live_explainer'>Plotting white box models.</h2><span id='topic+plot.live_explainer'></span>

<h3>Description</h3>

<p>Plotting white box models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'live_explainer'
plot(x, type = "waterfall", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.live_explainer_+3A_x">x</code></td>
<td>
<p>List returned by fit_explanation function.</p>
</td></tr>
<tr><td><code id="plot.live_explainer_+3A_type">type</code></td>
<td>
<p>Chr, &quot;forest&quot; or &quot;waterfall&quot; depending
on which type of plot is to be created.
if lm/glm model is used as interpretable approximation.</p>
</td></tr>
<tr><td><code id="plot.live_explainer_+3A_...">...</code></td>
<td>
<p>Additional parameters that will be passed to plot.broken or plot method.
In particular, when number of features is large, top_features argument can
be set in plot.broken.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>plot (ggplot2 or base)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Forest plot for regression
plot(fitted_explanation1, type = "forest")
# Waterfall plot
plot(fitted_explanation1, type = "waterfall")
# Plot decision tree
plot(fitted_explanation2)

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.local_permutation_importance'>Plot local permutation importance</h2><span id='topic+plot.local_permutation_importance'></span>

<h3>Description</h3>

<p>Plot local permutation importance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'local_permutation_importance'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.local_permutation_importance_+3A_x">x</code></td>
<td>
<p>Object of class local_permutation_importance</p>
</td></tr>
<tr><td><code id="plot.local_permutation_importance_+3A_...">...</code></td>
<td>
<p>Optional arguments, currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ggplot2 object
</p>

<hr>
<h2 id='print.live_explainer'>Generic print function for live explainer</h2><span id='topic+print.live_explainer'></span>

<h3>Description</h3>

<p>Generic print function for live explainer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'live_explainer'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.live_explainer_+3A_x">x</code></td>
<td>
<p>Object created using fit_explanation function</p>
</td></tr>
<tr><td><code id="print.live_explainer_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>

<hr>
<h2 id='print.live_explorer'>Generic print function for class live_explorer</h2><span id='topic+print.live_explorer'></span>

<h3>Description</h3>

<p>Generic print function for class live_explorer
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'live_explorer'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.live_explorer_+3A_x">x</code></td>
<td>
<p>Object created by sample_locally function or add_predictions function</p>
</td></tr>
<tr><td><code id="print.live_explorer_+3A_...">...</code></td>
<td>
<p>Other arguments</p>
</td></tr>
</table>

<hr>
<h2 id='print.local_permutation_importance'>Print method for local_permutation_importance class</h2><span id='topic+print.local_permutation_importance'></span>

<h3>Description</h3>

<p>Print method for local_permutation_importance class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'local_permutation_importance'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.local_permutation_importance_+3A_x">x</code></td>
<td>
<p>Object of class local_permutation_importance</p>
</td></tr>
<tr><td><code id="print.local_permutation_importance_+3A_...">...</code></td>
<td>
<p>Optional arguments, currently ignored</p>
</td></tr>
</table>

<hr>
<h2 id='sample_locally'>Generate dataset for local exploration.</h2><span id='topic+sample_locally'></span>

<h3>Description</h3>

<p>Generate dataset for local exploration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_locally(
  data,
  explained_instance,
  explained_var,
  size,
  method = "live",
  fixed_variables = NULL,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_locally_+3A_data">data</code></td>
<td>
<p>Data frame from which new dataset will be simulated.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_explained_instance">explained_instance</code></td>
<td>
<p>One row data frame with the same variables
as in data argument. Local exploration will be performed around this observation.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_explained_var">explained_var</code></td>
<td>
<p>Name of a column with the variable to be predicted.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_size">size</code></td>
<td>
<p>Number of observations is a simulated dataset.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_method">method</code></td>
<td>
<p>If &quot;live&quot;, new observations will be created by changing one value
per observation. If &quot;permute&quot;, new observation will be created by permuting  all
columns of data. If &quot;normal&quot;, numerical features will be sampled from multivariate
normal distribution specified by ... arguments mu and Sigma.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_fixed_variables">fixed_variables</code></td>
<td>
<p>names or numeric indexes of columns which will not be changed
while sampling.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_seed">seed</code></td>
<td>
<p>Seed to set before sampling. If NULL, results will not be reproducible.</p>
</td></tr>
<tr><td><code id="sample_locally_+3A_...">...</code></td>
<td>
<p>Mean and covariance matrix for normal sampling method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of class &quot;live_explorer&quot; consisting of
</p>
<table role = "presentation">
<tr><td><code>data</code></td>
<td>
<p>Dataset generated by sample_locally function with response variable.</p>
</td></tr>
<tr><td><code>target</code></td>
<td>
<p>Name of the response variable.</p>
</td></tr>
<tr><td><code>explained_instance</code></td>
<td>
<p>Instance that is being explained.</p>
</td></tr>
<tr><td><code>sampling_method</code></td>
<td>
<p>Name of used sampling method</p>
</td></tr>
<tr><td><code>fixed_variables</code></td>
<td>
<p>Names of variables which were not sampled</p>
</td></tr>
<tr><td><code>sdevations</code></td>
<td>
<p>Standard deviations of numerical variables</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dataset_for_local_exploration &lt;- sample_locally(data = wine,
                                                explained_instance = wine[5, ],
                                                explained_var = "quality",
                                                size = 50)

## End(Not run)

</code></pre>

<hr>
<h2 id='wine'>Red wine characteristics and quality.</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>Popular dataset related to wine samples from north Portugal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wine
</code></pre>


<h3>Format</h3>

<p>Data frame with 1599 rows and 12 columns.</p>


<h3>References</h3>

<p>P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.
Modeling wine preferences by data mining from physicochemical properties.
In Decision Support Systems, Elsevier, 47(4):547-553, 2009.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
