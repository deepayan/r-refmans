<!DOCTYPE html><html><head><title>Help for package bagged.outliertrees</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bagged.outliertrees}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bagged.outliertrees'><p>Bagged OutlierTrees</p></a></li>
<li><a href='#hypothyroid'><p>Hypothyroid</p></a></li>
<li><a href='#predict.bagged.outliertrees'><p>Predict method for Bagged OutlierTrees</p></a></li>
<li><a href='#print.bagged.outlieroutputs'><p>Print outliers in human-readable format</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Rafael Santos &lt;rafael.jpsantos@outlook.com&gt;</td>
</tr>
<tr>
<td>Title:</td>
<td>Robust Explainable Outlier Detection Based on OutlierTree</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Bagged OutlierTrees is an explainable unsupervised outlier detection method based on an ensemble implementation of the existing OutlierTree procedure (Cortes, 2020). This implementation takes advantage of bootstrap aggregating (bagging) to improve robustness by reducing the possible masking effect and subsequent high variance (similarly to Isolation Forest), hence the name "Bagged OutlierTrees". To learn more about the base procedure OutlierTree (Cortes, 2020), please refer to &lt;<a href="https://doi.org/10.48550/arXiv.2001.00636">doi:10.48550/arXiv.2001.00636</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>outliertree, dplyr, doSNOW, parallel, foreach, rlist,
data.table</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/RafaJPSantos/bagged.outliertrees">https://github.com/RafaJPSantos/bagged.outliertrees</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/RafaJPSantos/bagged.outliertrees/issues">https://github.com/RafaJPSantos/bagged.outliertrees/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-07-05 09:07:11 UTC; ptrafjossan</td>
</tr>
<tr>
<td>Author:</td>
<td>Rafael Santos [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-07-06 09:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bagged.outliertrees'>Bagged OutlierTrees</h2><span id='topic+bagged.outliertrees'></span>

<h3>Description</h3>

<p>Fit Bagged OutlierTrees ensemble model to normal data with perhaps some outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bagged.outliertrees(
  df,
  ntrees = 100L,
  subsampling_rate = 0.25,
  max_depth = 4L,
  min_gain = 0.01,
  z_norm = 2.67,
  z_outlier = 8,
  pct_outliers = 0.01,
  min_size_numeric = 25L,
  min_size_categ = 50L,
  categ_split = "binarize",
  categ_outliers = "tail",
  numeric_split = "raw",
  cols_ignore = NULL,
  follow_all = FALSE,
  gain_as_pct = TRUE,
  nthreads = parallel::detectCores()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bagged.outliertrees_+3A_df">df</code></td>
<td>
<p>Data Frame with normal data that might contain some outliers. See details for allowed column types.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_ntrees">ntrees</code></td>
<td>
<p>Controls the ensemble size (i.e. the number of OutlierTrees or bootstrapped training sets).
A large value is always recommended to build a robust and stable ensemble.
Should be decreased if training is taking too much time.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_subsampling_rate">subsampling_rate</code></td>
<td>
<p>Sub-sampling rate used for bootstrapping.
A small rate results in smaller bootstrapped training sets, which should not suffer from the masking effect.
This parameter should be adjusted given the size of the training data (perhaps a smaller value for large training data and conversely).</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_max_depth">max_depth</code></td>
<td>
<p>Maximum depth of the trees to grow. Can also pass zero, in which case it will only look
for outliers with no conditions (i.e. takes each column as a 1-d distribution and looks for outliers in
there independently of the values in other columns).</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_min_gain">min_gain</code></td>
<td>
<p>Minimum gain that a split has to produce in order to consider it (both in terms of looking
for outliers in each branch, and in considering whether to continue branching from them). Note that default
value for GritBot is 1e-6, with <code>gain_as_pct</code> = <code>FALSE</code>, but it's recommended to pass higher values (e.g. 1e-1) when using
<code>gain_as_pct</code> = <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_z_norm">z_norm</code></td>
<td>
<p>Maximum Z-value (from standard normal distribution) that can be considered as a normal
observation. Note that simply having values above this will not automatically flag observations as outliers,
nor does it assume that columns follow normal distributions. Also used for categorical and ordinal columns
for building approximate confidence intervals of proportions.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_z_outlier">z_outlier</code></td>
<td>
<p>Minimum Z-value that can be considered as an outlier. There must be a large gap in the
Z-value of the next observation in sorted order to consider it as outlier, given by (z_outlier - z_norm).
Decreasing this parameter is likely to result in more observations being flagged as outliers.
Ignored for categorical and ordinal columns.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_pct_outliers">pct_outliers</code></td>
<td>
<p>Approximate max percentage of outliers to expect in a given branch.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_min_size_numeric">min_size_numeric</code></td>
<td>
<p>Minimum size that branches need to have when splitting a numeric column. In order to look for
outliers in a given branch for a numeric column, it must have a minimum of twice this number
of observations.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_min_size_categ">min_size_categ</code></td>
<td>
<p>Minimum size that branches need to have when splitting a categorical or ordinal column. In order to
look for outliers in a given branch for a categorical, ordinal, or boolean column, it must have a minimum of twice
this number of observations.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_categ_split">categ_split</code></td>
<td>
<p>How to produce categorical-by-categorical splits. Options are:
</p>

<ul>
<li> <p><code>"binarize"</code> : Will binarize the target variable according to whether it's equal to each present category
within it (greater/less for ordinal), and split each binarized variable separately.
</p>
</li>
<li> <p><code>"bruteforce"</code> : Will evaluate each possible binary split of the categories (that is, it evaluates 2^n potential
splits every time). Note that trying this when there are many categories in a column will result
in exponential computation time that might never finish.
</p>
</li>
<li> <p><code>"separate"</code> : Will create one branch per category of the splitting variable (this is how GritBot handles them).
</p>
</li></ul>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_categ_outliers">categ_outliers</code></td>
<td>
<p>How to look for outliers in categorical variables. Options are:
</p>

<ul>
<li> <p><code>"tail"</code> : Will try to flag outliers if there is a large gap between proportions in sorted order, and this
gap is unexpected given the prior probabilities. Such criteria tends to sometimes flag too many
uninteresting outliers, but is able to detect more cases and recognize outliers when there is no
single dominant category.
</p>
</li>
<li> <p><code>"majority"</code> : Will calculate an equivalent to z-value according to the number of observations that do not
belong to the non-majority class, according to formula '(n-n_maj)/(n * p_prior) &lt; 1/z_outlier^2'.
Such criteria  tends to miss many interesting outliers and will only be able to flag outliers in
large sample sizes. This is the approach used by GritBot.
</p>
</li></ul>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_numeric_split">numeric_split</code></td>
<td>
<p>How to determine the split point in numeric variables. Options are:
</p>

<ul>
<li> <p><code>"mid"</code> : Will calculate the midpoint between the largest observation that goes to the '&lt;=' branch and the
smallest observation that goes to the '&gt;' branch.
</p>
</li>
<li> <p><code>"raw"</code> : Will set the split point as the value of the largest observation that goes to the '&lt;=' branch.
</p>
</li></ul>

<p>This doesn't affect how outliers are determined in the training data passed in <code>df</code>, but it does
affect the way in which they are presented and the way in which new outliers are detected when
using <code>predict</code>. <code>"mid"</code> is recommended for continuous-valued variables, while <code>"raw"</code> will
provide more readable explanations for counts data at the expense of perhaps slightly worse
generalizability to unseen data.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_cols_ignore">cols_ignore</code></td>
<td>
<p>Vector containing columns which will not be split, but will be evaluated for usage
in splitting other columns. Can pass either a logical (boolean) vector with the same number of columns
as <code>df</code>, or a character vector of column names (must match with those of <code>df</code>).
Pass <code>NULL</code> to use all columns.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_follow_all">follow_all</code></td>
<td>
<p>Whether to continue branching from each split that meets the size and gain criteria.
This will produce exponentially many more branches, and if depth is large, might take forever to finish.
Will also produce a lot more spurious outiers. Not recommended.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_gain_as_pct">gain_as_pct</code></td>
<td>
<p>Whether the minimum gain above should be taken in absolute terms, or as a percentage of
the standard deviation (for numerical columns) or shannon entropy (for categorical columns). Taking it in
absolute terms will prefer making more splits on columns that have a large variance, while taking it as a
percentage might be more restrictive on them and might create deeper trees in some columns. For GritBot
this parameter would always be <code>FALSE</code>. Recommended to pass higher values for <code>min_gain</code> when passing <code>FALSE</code>
here. Not that when <code>gain_as_pct</code> = <code>FALSE</code>, the results will be sensitive to the scales of variables.</p>
</td></tr>
<tr><td><code id="bagged.outliertrees_+3A_nthreads">nthreads</code></td>
<td>
<p>Number of parallel threads to use when fitting the model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with the fitted model that can be used to detect more outliers in new data.
</p>


<h3>References</h3>


<ul>
<li><p> GritBot software: <a href="https://www.rulequest.com/gritbot-info.html">https://www.rulequest.com/gritbot-info.html</a>
</p>
</li>
<li><p> Cortes, David. &quot;Explainable outlier detection through decision tree conditioning.&quot; arXiv preprint arXiv:2001.00636 (2020).
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="#topic+predict.bagged.outliertrees">predict.bagged.outliertrees</a> <a href="#topic+print.bagged.outlieroutputs">print.bagged.outlieroutputs</a> <a href="#topic+hypothyroid">hypothyroid</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(bagged.outliertrees)

### example dataset with interesting outliers
data(hypothyroid)

### fit a Bagged OutlierTrees model
model &lt;- bagged.outliertrees(hypothyroid,
  ntrees = 10,
  subsampling_rate = 0.5,
  z_outlier = 6,
  nthreads = 1
)

### use the fitted model to find outliers in the training dataset
outliers &lt;- predict(model,
  newdata = hypothyroid,
  min_outlier_score = 0.5,
  nthreads = 1
)

### print the top-10 outliers in human-readable format
print(outliers, outliers_print = 10)
</code></pre>

<hr>
<h2 id='hypothyroid'>Hypothyroid</h2><span id='topic+hypothyroid'></span>

<h3>Description</h3>

<p>Hypothyroid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hypothyroid
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 2772 rows and 23 columns.
</p>

<hr>
<h2 id='predict.bagged.outliertrees'>Predict method for Bagged OutlierTrees</h2><span id='topic+predict.bagged.outliertrees'></span>

<h3>Description</h3>

<p>Predict method for Bagged OutlierTrees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagged.outliertrees'
predict(
  object,
  newdata,
  min_outlier_score = 0.95,
  nthreads = parallel::detectCores(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.bagged.outliertrees_+3A_object">object</code></td>
<td>
<p>A Bagged OutlierTrees object as returned by <code>bagged.outliertrees</code>.</p>
</td></tr>
<tr><td><code id="predict.bagged.outliertrees_+3A_newdata">newdata</code></td>
<td>
<p>A Data Frame in which to look for outliers according to the fitted model.</p>
</td></tr>
<tr><td><code id="predict.bagged.outliertrees_+3A_min_outlier_score">min_outlier_score</code></td>
<td>
<p>Minimum outlier score to use when finding outliers.</p>
</td></tr>
<tr><td><code id="predict.bagged.outliertrees_+3A_nthreads">nthreads</code></td>
<td>
<p>Number of threads to use when predicting.</p>
</td></tr>
<tr><td><code id="predict.bagged.outliertrees_+3A_...">...</code></td>
<td>
<p>No use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Will return a list of lists with the outliers and their
information (each row is an entry in the first list, with the same names as the rows in the input data
frame), which can be printed into a human-readable format after-the-fact through functions
<code>print</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+bagged.outliertrees">bagged.outliertrees</a> <a href="#topic+print.bagged.outlieroutputs">print.bagged.outlieroutputs</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(bagged.outliertrees)

### example dataset with interesting outliers
data(hypothyroid)

### fit a Bagged OutlierTrees model
model &lt;- bagged.outliertrees(hypothyroid,
  ntrees = 10,
  subsampling_rate = 0.5,
  z_outlier = 6,
  nthreads = 1
)

### use the fitted model to find outliers in the training dataset
outliers &lt;- predict(model,
  newdata = hypothyroid,
  min_outlier_score = 0.5,
  nthreads = 1
)

### print the top-10 outliers in human-readable format
print(outliers, outliers_print = 10)
</code></pre>

<hr>
<h2 id='print.bagged.outlieroutputs'>Print outliers in human-readable format</h2><span id='topic+print.bagged.outlieroutputs'></span>

<h3>Description</h3>

<p>Pretty-prints outliers as output by the <code>predict</code> function from a Bagged OutlierTrees
model (as generated by function <code>bagged.outliertrees</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bagged.outlieroutputs'
print(x, outliers_print = 15, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.bagged.outlieroutputs_+3A_x">x</code></td>
<td>
<p>Outliers as returned by predict method on an object from <code>bagged.outliertrees</code>.</p>
</td></tr>
<tr><td><code id="print.bagged.outlieroutputs_+3A_outliers_print">outliers_print</code></td>
<td>
<p>Maximum number of outliers to print.</p>
</td></tr>
<tr><td><code id="print.bagged.outlieroutputs_+3A_...">...</code></td>
<td>
<p>No use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The same input <code>x</code> that was passed (as <code>invisible</code>).
</p>


<h3>See Also</h3>

<p><a href="#topic+bagged.outliertrees">bagged.outliertrees</a> <a href="#topic+predict.bagged.outliertrees">predict.bagged.outliertrees</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(bagged.outliertrees)

### example dataset with interesting outliers
data(hypothyroid)

### fit a Bagged OutlierTrees model
model &lt;- bagged.outliertrees(hypothyroid,
  ntrees = 10,
  subsampling_rate = 0.5,
  z_outlier = 6,
  nthreads = 1
)

### use the fitted model to find outliers in the training dataset
outliers &lt;- predict(model,
  newdata = hypothyroid,
  min_outlier_score = 0.5,
  nthreads = 1
)

### print the top-10 outliers in human-readable format
print(outliers, outliers_print = 10)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
