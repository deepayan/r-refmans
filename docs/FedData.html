<!DOCTYPE html><html><head><title>Help for package FedData</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FedData}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#+25+26gt+3B+25'><p>Pipe operator</p></a></li>
<li><a href='#check_service'><p>Check whether a web service is unavailable, and stop function if necessary.</p></a></li>
<li><a href='#download_data'><p>Use curl to download a file.</p></a></li>
<li><a href='#download_daymet_thredds'><p>Download the 1-km DAYMET daily weather dataset for a region as a netcdf.</p></a></li>
<li><a href='#download_ghcn_daily_station'><p>Download the daily data for a GHCN weather station.</p></a></li>
<li><a href='#download_itrdb'><p>Download the latest version of the ITRDB.</p></a></li>
<li><a href='#download_ssurgo_inventory'><p>Download a zipped directory containing a shapefile of the SSURGO study areas.</p></a></li>
<li><a href='#download_ssurgo_study_area'><p>Download a zipped directory containing the spatial and tabular data for a SSURGO study area.</p></a></li>
<li><a href='#extract_ssurgo_data'><p>Extract data from a SSURGO database pertaining to a set of mapunits.</p></a></li>
<li><a href='#get_daymet'><p>Download and crop the 1-km DAYMET v4 daily weather dataset.</p></a></li>
<li><a href='#get_ghcn_daily'><p>Download and crop the Global Historical Climate Network-Daily data.</p></a></li>
<li><a href='#get_ghcn_daily_station'><p>Download and extract the daily data for a GHCN weather station.</p></a></li>
<li><a href='#get_ghcn_inventory'><p>Download and crop the inventory of GHCN stations.</p></a></li>
<li><a href='#get_itrdb'><p>Download the latest version of the ITRDB, and extract given parameters.</p></a></li>
<li><a href='#get_nass_cdl'><p>Download and crop the NASS Cropland Data Layer.</p></a></li>
<li><a href='#get_ned'><p>Download and crop the 1 (~30 meter) or 1/3 (~10 meter) arc-second National Elevation Dataset.</p></a></li>
<li><a href='#get_ned_tile'><p>Load and crop tile from the 1 (~30 meter) or 1/3 (~10 meter) arc-second National Elevation Dataset.</p></a></li>
<li><a href='#get_nhd'><p>Download and crop the National Hydrography Dataset.</p></a></li>
<li><a href='#get_nlcd'><p>Download and crop the National Land Cover Database.</p></a></li>
<li><a href='#get_padus'><p>Download and crop the PAD-US Dataset.</p></a></li>
<li><a href='#get_ssurgo'><p>Download and crop data from the NRCS SSURGO soils database.</p></a></li>
<li><a href='#get_ssurgo_inventory'><p>Download and crop a shapefile of the SSURGO study areas.</p></a></li>
<li><a href='#get_ssurgo_study_area'><p>Download and crop the spatial and tabular data for a SSURGO study area.</p></a></li>
<li><a href='#get_wbd'><p>Download and crop the Watershed Boundary Dataset.</p></a></li>
<li><a href='#meve'><p>The boundary of Mesa Verde National Park</p></a></li>
<li><a href='#plot_nhd'><p>A basic plotting function for NHD data.</p></a></li>
<li><a href='#polygon_from_extent'><p>Turn an extent object into a polygon</p></a></li>
<li><a href='#read_crn'><p>Read a Tucson-format chronology file.</p></a></li>
<li><a href='#read_crn_data'><p>Read chronology data from a Tucson-format chronology file.</p></a></li>
<li><a href='#read_crn_metadata'><p>Read metadata from a Tucson-format chronology file.</p></a></li>
<li><a href='#replace_null'><p>Replace NULLs</p></a></li>
<li><a href='#sequential_duplicated'><p>Get a logical vector of which elements in a vector are sequentially duplicated.</p></a></li>
<li><a href='#soils_query'><p>Submit a Soil Data Access (SDA) Query</p></a></li>
<li><a href='#split_bbox'><p>Splits a bbox into a list of bboxes less than a certain size</p></a></li>
<li><a href='#station_to_data_frame'><p>Convert a list of station data to a single data frame.</p></a></li>
<li><a href='#substr_right'><p>Get the rightmost 'n' characters of a character string.</p></a></li>
<li><a href='#unwrap_rows'><p>Unwraps a matrix and only keep the first n elements.</p></a></li>
<li><a href='#url_base'><p>Strip query parameters from a URL</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functions to Automate Downloading Geospatial Data Available from
Several Federated Data Sources</td>
</tr>
<tr>
<td>Version:</td>
<td>4.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-14</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to automate downloading geospatial data available
    from several federated data sources (mainly sources maintained by the
    US Federal government). Currently, the package enables extraction from
    nine datasets: The National Elevation Dataset digital elevation
    models (1 and 1/3 arc-second; USGS); The National Hydrography Dataset
    (USGS); The Soil Survey Geographic (SSURGO) database from the National
    Cooperative Soil Survey (NCSS), which is led by the Natural Resources
    Conservation Service (NRCS) under the USDA; the Global Historical
    Climatology Network (GHCN), coordinated by National Climatic Data
    Center at NOAA; the Daymet gridded estimates of daily weather
    parameters for North America, version 4, available from the Oak Ridge
    National Laboratory's Distributed Active Archive Center (DAAC); the
    International Tree Ring Data Bank; the National Land Cover
    Database (NLCD); the Cropland Data Layer from the National Agricultural 
    Statistics Service; and the PAD-US dataset of protected area boundaries 
    from the USGS.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://docs.ropensci.org/FedData/">https://docs.ropensci.org/FedData/</a>,
<a href="https://github.com/ropensci/FedData">https://github.com/ropensci/FedData</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ropensci/FedData/issues">https://github.com/ropensci/FedData/issues</a></td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GDAL (&gt;= 3.1.0)</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>curl, httr, dplyr, tibble, tidyr, stringr, igraph, xml2,
lifecycle, lubridate, magrittr, progress, purrr, readr, terra
(&ge; 1.0), sf (&ge; 1.0), arcgislayers (&ge; 0.2.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, ggplot2, testthat, ncdf4, usethis, styler, mapview,
knitr, rmarkdown, leaflet, rmapshaper</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-16 23:28:49 UTC; bocinsky</td>
</tr>
<tr>
<td>Author:</td>
<td>R. Kyle Bocinsky <a href="https://orcid.org/0000-0003-1862-3428"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre, cph],
  Dylan Beaudette [ctb],
  Scott Chamberlain [ctb, rev],
  Jeffrey Hollister [ctb],
  Julia Gustavsen [rev]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>R. Kyle Bocinsky &lt;bocinsky@gmail.com&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-17 00:40:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>

<hr>
<h2 id='check_service'>Check whether a web service is unavailable, and stop function if necessary.</h2><span id='topic+check_service'></span>

<h3>Description</h3>

<p>Check whether a web service is unavailable, and stop function if necessary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check_service(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="check_service_+3A_x">x</code></td>
<td>
<p>The path to the web service.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Error if service unavailable.
</p>

<hr>
<h2 id='download_data'>Use curl to download a file.</h2><span id='topic+download_data'></span>

<h3>Description</h3>

<p>This function makes it easy to implement timestamping and no-clobber of files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_data(
  url,
  destdir = getwd(),
  timestamping = TRUE,
  nc = FALSE,
  verbose = FALSE,
  progress = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_data_+3A_url">url</code></td>
<td>
<p>The location of a file.</p>
</td></tr>
<tr><td><code id="download_data_+3A_destdir">destdir</code></td>
<td>
<p>Where the file should be downloaded to.</p>
</td></tr>
<tr><td><code id="download_data_+3A_timestamping">timestamping</code></td>
<td>
<p>Should only newer files be downloaded?</p>
</td></tr>
<tr><td><code id="download_data_+3A_nc">nc</code></td>
<td>
<p>Should files of the same type not be clobbered?</p>
</td></tr>
<tr><td><code id="download_data_+3A_verbose">verbose</code></td>
<td>
<p>Should cURL output be shown?</p>
</td></tr>
<tr><td><code id="download_data_+3A_progress">progress</code></td>
<td>
<p>Should a progress bar be shown with cURL output?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If both <code>timestamping</code> and <code>nc</code> are TRUE, nc behavior trumps timestamping.
</p>


<h3>Value</h3>

<p>A character string of the file path to the downloaded file.
</p>

<hr>
<h2 id='download_daymet_thredds'>Download the 1-km DAYMET daily weather dataset for a region as a netcdf.</h2><span id='topic+download_daymet_thredds'></span>

<h3>Description</h3>

<p>Data are downloaded in the NetCDF format. <code>download_daymet_thredds</code> returns the path to the downloaded NetCDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_daymet_thredds(bbox, element, year, region, tempo)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_daymet_thredds_+3A_bbox">bbox</code></td>
<td>
<p>the bounding box in WGS84 coordinates as a comma-separated character vector
&quot;xmin,ymin,xmax,ymax&quot;</p>
</td></tr>
<tr><td><code id="download_daymet_thredds_+3A_element">element</code></td>
<td>
<p>An element to extract.<br />
The available elements are:<br />
dayl = Duration of the daylight period in seconds per day. This calculation is based on the period of the day during which the sun is above a hypothetical flat horizon.<br />
prcp = Daily total precipitation in millimeters per day, sum of all forms converted to water-equivalent. Precipitation occurrence on any given day may be ascertained.<br />
srad = Incident shortwave radiation flux density in watts per square meter, taken as an average over the daylight period of the day. NOTE: Daily total radiation (MJ/m2/day) can be calculated as follows: ((srad (W/m2) * dayl (s/day)) / l,000,000)<br />
swe = Snow water equivalent in kilograms per square meter. The amount of water contained within the snowpack.<br />
tmax = Daily maximum 2-meter air temperature in degrees Celsius.<br />
tmin = Daily minimum 2-meter air temperature in degrees Celsius.<br />
vp = Water vapor pressure in pascals. Daily average partial pressure of water vapor.<br /></p>
</td></tr>
<tr><td><code id="download_daymet_thredds_+3A_year">year</code></td>
<td>
<p>An integer year to extract.</p>
</td></tr>
<tr><td><code id="download_daymet_thredds_+3A_region">region</code></td>
<td>
<p>The name of a region. The available regions are:<br />
na = North America<br />
hi = Hawaii<br />
pr = Puerto Rico<br /></p>
</td></tr>
<tr><td><code id="download_daymet_thredds_+3A_tempo">tempo</code></td>
<td>
<p>The frequency of the data. The available tempos are:<br />
day = Daily data<br />
mon = Monthly summary data<br />
ann = Annual summary data<br /></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of character vectors, each representing the full local paths of the tile downloads.
</p>

<hr>
<h2 id='download_ghcn_daily_station'>Download the daily data for a GHCN weather station.</h2><span id='topic+download_ghcn_daily_station'></span>

<h3>Description</h3>

<p>Download the daily data for a GHCN weather station.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_ghcn_daily_station(ID, raw.dir, force.redo = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_ghcn_daily_station_+3A_id">ID</code></td>
<td>
<p>A character string giving the station ID.</p>
</td></tr>
<tr><td><code id="download_ghcn_daily_station_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.</p>
</td></tr>
<tr><td><code id="download_ghcn_daily_station_+3A_force.redo">force.redo</code></td>
<td>
<p>If this weather station has been downloaded before, should it be updated? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string representing the full local path of the GHCN station data.
</p>

<hr>
<h2 id='download_itrdb'>Download the latest version of the ITRDB.</h2><span id='topic+download_itrdb'></span>

<h3>Description</h3>

<p>Downloads and parses the latest zipped (numbered) version of the ITRDB.
This function includes improvements to the <code><a href="#topic+read_crn">read_crn</a></code> function from the
<span class="pkg">dplR</span> library. The principle changes are better parsing of metadata, and support
for the Schweingruber-type Tucson format. Chronologies that are unable to be read
are reported to the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_itrdb(
  raw.dir = paste0(tempdir(), "/FedData/raw/itrdb"),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_itrdb_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing. Defaults to './RAW/ITRDB/'.</p>
</td></tr>
<tr><td><code id="download_itrdb_+3A_force.redo">force.redo</code></td>
<td>
<p>If a download already exists, should a new one be created? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing all of the ITRDB data.
</p>

<hr>
<h2 id='download_ssurgo_inventory'>Download a zipped directory containing a shapefile of the SSURGO study areas.</h2><span id='topic+download_ssurgo_inventory'></span>

<h3>Description</h3>

<p>Download a zipped directory containing a shapefile of the SSURGO study areas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_ssurgo_inventory(raw.dir, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_ssurgo_inventory_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string representing the full local path of the SSURGO study areas zipped directory.
</p>

<hr>
<h2 id='download_ssurgo_study_area'>Download a zipped directory containing the spatial and tabular data for a SSURGO study area.</h2><span id='topic+download_ssurgo_study_area'></span>

<h3>Description</h3>

<p><code>download_ssurgo_study_area</code> first tries to download data including a state-specific Access
template, then the general US template.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_ssurgo_study_area(area, date, raw.dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_ssurgo_study_area_+3A_area">area</code></td>
<td>
<p>A character string indicating the SSURGO study area to be downloaded.</p>
</td></tr>
<tr><td><code id="download_ssurgo_study_area_+3A_date">date</code></td>
<td>
<p>A character string indicating the date of the most recent update to the SSURGO
area for these data. This information may be gleaned from the SSURGO Inventory (<code><a href="#topic+get_ssurgo_inventory">get_ssurgo_inventory</a></code>).</p>
</td></tr>
<tr><td><code id="download_ssurgo_study_area_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string representing the full local path of the SSURGO study areas zipped directory.
</p>

<hr>
<h2 id='extract_ssurgo_data'>Extract data from a SSURGO database pertaining to a set of mapunits.</h2><span id='topic+extract_ssurgo_data'></span>

<h3>Description</h3>

<p><code>extract_ssurgo_data</code> creates a directed graph of the joins in a SSURGO tabular dataset,
and then iterates through the tables, only retaining data pertinent to a set of mapunits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_ssurgo_data(tables, mapunits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_ssurgo_data_+3A_tables">tables</code></td>
<td>
<p>A list of SSURGO tabular data.</p>
</td></tr>
<tr><td><code id="extract_ssurgo_data_+3A_mapunits">mapunits</code></td>
<td>
<p>A character vector of mapunits (likely dropped from SSURGO spatial data)
defining which mapunits to retain.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of extracted SSURGO tabular data.
</p>

<hr>
<h2 id='get_daymet'>Download and crop the 1-km DAYMET v4 daily weather dataset.</h2><span id='topic+get_daymet'></span>

<h3>Description</h3>

<p><code>get_daymet</code> returns a <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> of weather data cropped to a given
template study area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_daymet(
  template,
  label,
  elements = c("dayl", "prcp", "srad", "swe", "tmax", "tmin", "vp"),
  years = 1980:(lubridate::year(Sys.time()) - 1),
  region = "na",
  tempo = "day",
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "daymet", label),
  raster.options = c("COMPRESS=DEFLATE", "ZLEVEL=9", "INTERLEAVE=BAND"),
  force.redo = FALSE,
  progress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_daymet_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_daymet_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_daymet_+3A_elements">elements</code></td>
<td>
<p>A character vector of elements to extract.<br />
The available elements are:<br />
dayl = Duration of the daylight period in seconds per day. This calculation is based on the period of the day during which the sun is above a hypothetical flat horizon.<br />
prcp = Daily total precipitation in millimeters per day, sum of all forms converted to water-equivalent. Precipitation occurrence on any given day may be ascertained.<br />
srad = Incident shortwave radiation flux density in watts per square meter, taken as an average over the daylight period of the day. NOTE: Daily total radiation (MJ/m2/day) can be calculated as follows: ((srad (W/m2) * dayl (s/day)) / l,000,000)<br />
swe = Snow water equivalent in kilograms per square meter. The amount of water contained within the snowpack.<br />
tmax = Daily maximum 2-meter air temperature in degrees Celsius.<br />
tmin = Daily minimum 2-meter air temperature in degrees Celsius.<br />
vp = Water vapor pressure in pascals. Daily average partial pressure of water vapor.<br /></p>
</td></tr>
<tr><td><code id="get_daymet_+3A_years">years</code></td>
<td>
<p>A numeric vector of years to extract.</p>
</td></tr>
<tr><td><code id="get_daymet_+3A_region">region</code></td>
<td>
<p>The name of a region. The available regions are:<br />
na = North America<br />
hi = Hawaii<br />
pr = Puerto Rico<br /></p>
</td></tr>
<tr><td><code id="get_daymet_+3A_tempo">tempo</code></td>
<td>
<p>The frequency of the data. The available tempos are:<br />
day = Daily data<br />
mon = Monthly summary data<br />
ann = Annual summary data<br /></p>
</td></tr>
<tr><td><code id="get_daymet_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped DEM should be put.
Defaults to a temporary directory.</p>
</td></tr>
<tr><td><code id="get_daymet_+3A_raster.options">raster.options</code></td>
<td>
<p>a vector of GDAL options passed to <a href="terra.html#topic+writeRaster">terra::writeRaster</a>.</p>
</td></tr>
<tr><td><code id="get_daymet_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists in extraction.dir,
should a new one be created?</p>
</td></tr>
<tr><td><code id="get_daymet_+3A_progress">progress</code></td>
<td>
<p>Draw a progress bar when downloading?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of <code>SpatRaster</code>s of weather data cropped to the extent of the template.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Get the DAYMET (North America only)
# Returns a list of raster bricks
DAYMET &lt;- get_daymet(
  template = FedData::meve,
  label = "meve",
  elements = c("prcp", "tmin", "tmax"),
  years = 1980:1985
)

# Plot with terra::plot
plot(DAYMET$tmin$X1985.10.23)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_ghcn_daily'>Download and crop the Global Historical Climate Network-Daily data.</h2><span id='topic+get_ghcn_daily'></span>

<h3>Description</h3>

<p><code>get_ghcn_daily</code> returns a named list of length 2:
</p>

<ol>
<li><p> 'spatial': A <code><a href="sf.html#topic+sf">Simple Feature</a></code> of the locations of GHCN weather stations
in the template, and
</p>
</li>
<li><p> 'tabular': A named list of type <code><a href="base.html#topic+data.frame">data.frame()</a></code> with the daily weather data for each station.
The name of each list item is the station ID.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>get_ghcn_daily(
  template = NULL,
  label = NULL,
  elements = NULL,
  years = NULL,
  raw.dir = file.path(tempdir(), "FedData", "raw", "ghcn"),
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "ned", label),
  standardize = F,
  force.redo = F
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ghcn_daily_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.
Alternatively, a character vector providing GHCN station IDs. If missing, all stations
will be downloaded!</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_elements">elements</code></td>
<td>
<p>A character vector of elements to extract.<br />
The five core elements are:<br />
PRCP = Precipitation (tenths of mm)<br />
SNOW = Snowfall (mm)<br />
SNWD = Snow depth (mm)<br />
TMAX = Maximum temperature (tenths of degrees C)<br />
TMIN = Minimum temperature (tenths of degrees C)<br />
<br />
The other elements are:<br />
</p>
<p>ACMC = Average cloudiness midnight to midnight from 30-second
ceilometer data (percent)<br />
ACMH = Average cloudiness midnight to midnight from
manual observations (percent)<br />
ACSC = Average cloudiness sunrise to sunset from 30-second
ceilometer data (percent)<br />
ACSH = Average cloudiness sunrise to sunset from manual
observations (percent)<br />
AWDR = Average daily wind direction (degrees)<br />
AWND = Average daily wind speed (tenths of meters per second)<br />
DAEV = Number of days included in the multiday evaporation
total (MDEV)<br />
DAPR = Number of days included in the multiday precipitation
total (MDPR)<br />
DASF = Number of days included in the multiday snowfall
total (MDSF)<br />
DATN = Number of days included in the multiday minimum temperature
(MDTN)<br />
DATX = Number of days included in the multiday maximum temperature
(MDTX)<br />
DAWM = Number of days included in the multiday wind movement
(MDWM)<br />
DWPR = Number of days with non-zero precipitation included in
multiday precipitation total (MDPR)<br />
EVAP = Evaporation of water from evaporation pan (tenths of mm)<br />
FMTM = Time of fastest mile or fastest 1-minute wind
(hours and minutes, i.e., HHMM)<br />
FRGB = Base of frozen ground layer (cm)<br />
FRGT = Top of frozen ground layer (cm)<br />
FRTH = Thickness of frozen ground layer (cm)<br />
GAHT = Difference between river and gauge height (cm)<br />
MDEV = Multiday evaporation total (tenths of mm; use with DAEV)<br />
MDPR = Multiday precipitation total (tenths of mm; use with DAPR and
DWPR, if available)<br />
MDSF = Multiday snowfall total <br />
MDTN = Multiday minimum temperature (tenths of degrees C; use with DATN)<br />
MDTX = Multiday maximum temperature (tenths of degrees C; use with DATX)<br />
MDWM = Multiday wind movement (km)<br />
MNPN = Daily minimum temperature of water in an evaporation pan
(tenths of degrees C)<br />
MXPN = Daily maximum temperature of water in an evaporation pan
(tenths of degrees C)<br />
PGTM = Peak gust time (hours and minutes, i.e., HHMM)<br />
PSUN = Daily percent of possible sunshine (percent)<br />
SN*# = Minimum soil temperature (tenths of degrees C)
where * corresponds to a code
for ground cover and # corresponds to a code for soil
depth.<br />
<br />
Ground cover codes include the following:<br />
0 = unknown<br />
1 = grass<br />
2 = fallow<br />
3 = bare ground<br />
4 = brome grass<br />
5 = sod<br />
6 = straw multch<br />
7 = grass muck<br />
8 = bare muck<br />
<br />
Depth codes include the following:<br />
1 = 5 cm<br />
2 = 10 cm<br />
3 = 20 cm<br />
4 = 50 cm<br />
5 = 100 cm<br />
6 = 150 cm<br />
7 = 180 cm<br />
<br />
SX*# = Maximum soil temperature (tenths of degrees C)
where * corresponds to a code for ground cover
and # corresponds to a code for soil depth.<br />
See SN*# for ground cover and depth codes. <br />
TAVG = Average temperature (tenths of degrees C)
(Note that TAVG from source 'S' corresponds
to an average for the period ending at
2400 UTC rather than local midnight)<br />
THIC = Thickness of ice on water (tenths of mm)<br />
TOBS = Temperature at the time of observation (tenths of degrees C)<br />
TSUN = Daily total sunshine (minutes)<br />
WDF1 = Direction of fastest 1-minute wind (degrees)<br />
WDF2 = Direction of fastest 2-minute wind (degrees)<br />
WDF5 = Direction of fastest 5-second wind (degrees)<br />
WDFG = Direction of peak wind gust (degrees)<br />
WDFI = Direction of highest instantaneous wind (degrees)<br />
WDFM = Fastest mile wind direction (degrees)<br />
WDMV = 24-hour wind movement (km)<br />
WESD = Water equivalent of snow on the ground (tenths of mm)<br />
WESF = Water equivalent of snowfall (tenths of mm)<br />
WSF1 = Fastest 1-minute wind speed (tenths of meters per second)<br />
WSF2 = Fastest 2-minute wind speed (tenths of meters per second)<br />
WSF5 = Fastest 5-second wind speed (tenths of meters per second)<br />
WSFG = Peak gust wind speed (tenths of meters per second)<br />
WSFI = Highest instantaneous wind speed (tenths of meters per second)<br />
WSFM = Fastest mile wind speed (tenths of meters per second)<br />
WT** = Weather Type where ** has one of the following values:<br />
<br />
01 = Fog, ice fog, or freezing fog (may include heavy fog)<br />
02 = Heavy fog or heaving freezing fog (not always
distinguished from fog)<br />
03 = Thunder<br />
04 = Ice pellets, sleet, snow pellets, or small hail <br />
05 = Hail (may include small hail)<br />
06 = Glaze or rime <br />
07 = Dust, volcanic ash, blowing dust, blowing sand, or
blowing obstruction<br />
08 = Smoke or haze <br />
09 = Blowing or drifting snow<br />
10 = Tornado, waterspout, or funnel cloud <br />
11 = High or damaging winds<br />
12 = Blowing spray<br />
13 = Mist<br />
14 = Drizzle<br />
15 = Freezing drizzle <br />
16 = Rain (may include freezing rain, drizzle, and freezing drizzle) <br />
17 = Freezing rain <br />
18 = Snow, snow pellets, snow grains, or ice crystals<br />
19 = Unknown source of precipitation <br />
21 = Ground fog <br />
22 = Ice fog or freezing fog<br />
<br />
WV** = Weather in the Vicinity where ** has one of the following
values:<br />
01 = Fog, ice fog, or freezing fog (may include heavy fog)<br />
03 = Thunder<br />
07 = Ash, dust, sand, or other blowing obstruction<br />
18 = Snow or ice crystals<br />
20 = Rain or snow shower</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_years">years</code></td>
<td>
<p>A numeric vector indicating which years to get.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing. Defaults to './RAW/GHCN/'.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped GHCN shapefiles should be put.
The directory will be created if missing. Defaults to './EXTRACTIONS/GHCN/'.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_standardize">standardize</code></td>
<td>
<p>Select only common year/month/day? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing the 'spatial' and 'tabular' data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the daily GHCN data (GLOBAL)
# Returns a list: the first element is the spatial locations of stations,
# and the second is a list of the stations and their daily data
GHCN.prcp &lt;-
  get_ghcn_daily(
    template = FedData::meve,
    label = "meve",
    elements = c("prcp")
  )

# Plot the VEP polygon
plot(meve$geometry)

# Plot the spatial locations
plot(GHCN.prcp$spatial, pch = 1, add = T)
legend("bottomleft", pch = 1, legend = "GHCN Precipitation Records")

# Elements for which you require the same data
# (i.e., minimum and maximum temperature for the same days)
# can be standardized using standardize==T
GHCN.temp &lt;- get_ghcn_daily(
  template = FedData::meve,
  label = "meve",
  elements = c("tmin", "tmax"),
  standardize = T
)

# Plot the VEP polygon
plot(meve$geometry)

# Plot the spatial locations
plot(GHCN.temp$spatial, pch = 1, add = T)
legend("bottomleft", pch = 1, legend = "GHCN Temperature Records")

## End(Not run)
</code></pre>

<hr>
<h2 id='get_ghcn_daily_station'>Download and extract the daily data for a GHCN weather station.</h2><span id='topic+get_ghcn_daily_station'></span>

<h3>Description</h3>

<p><code>get_ghcn_daily_station</code> returns a named list of <code><a href="base.html#topic+data.frame">data.frame</a>s</code>, one for
each <code>elements</code>. If <code>elements</code> is undefined, it returns all available weather
tables for the station
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ghcn_daily_station(
  ID,
  elements = NULL,
  years = NULL,
  raw.dir,
  standardize = F,
  force.redo = F
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ghcn_daily_station_+3A_id">ID</code></td>
<td>
<p>A character string giving the station ID.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_station_+3A_elements">elements</code></td>
<td>
<p>A character vector of elements to extract.<br />
The five core elements are:<br />
PRCP = Precipitation (tenths of mm)<br />
SNOW = Snowfall (mm)<br />
SNWD = Snow depth (mm)<br />
TMAX = Maximum temperature (tenths of degrees C)<br />
TMIN = Minimum temperature (tenths of degrees C)<br />
<br />
The other elements are:<br />
</p>
<p>ACMC = Average cloudiness midnight to midnight from 30-second
ceilometer data (percent)<br />
ACMH = Average cloudiness midnight to midnight from
manual observations (percent)<br />
ACSC = Average cloudiness sunrise to sunset from 30-second
ceilometer data (percent)<br />
ACSH = Average cloudiness sunrise to sunset from manual
observations (percent)<br />
AWDR = Average daily wind direction (degrees)<br />
AWND = Average daily wind speed (tenths of meters per second)<br />
DAEV = Number of days included in the multiday evaporation
total (MDEV)<br />
DAPR = Number of days included in the multiday precipitation
total (MDPR)<br />
DASF = Number of days included in the multiday snowfall
total (MDSF)<br />
DATN = Number of days included in the multiday minimum temperature
(MDTN)<br />
DATX = Number of days included in the multiday maximum temperature
(MDTX)<br />
DAWM = Number of days included in the multiday wind movement
(MDWM)<br />
DWPR = Number of days with non-zero precipitation included in
multiday precipitation total (MDPR)<br />
EVAP = Evaporation of water from evaporation pan (tenths of mm)<br />
FMTM = Time of fastest mile or fastest 1-minute wind
(hours and minutes, i.e., HHMM)<br />
FRGB = Base of frozen ground layer (cm)<br />
FRGT = Top of frozen ground layer (cm)<br />
FRTH = Thickness of frozen ground layer (cm)<br />
GAHT = Difference between river and gauge height (cm)<br />
MDEV = Multiday evaporation total (tenths of mm; use with DAEV)<br />
MDPR = Multiday precipitation total (tenths of mm; use with DAPR and
DWPR, if available)<br />
MDSF = Multiday snowfall total <br />
MDTN = Multiday minimum temperature (tenths of degrees C; use with DATN)<br />
MDTX = Multiday maximum temperature (tenths of degrees C; use with DATX)<br />
MDWM = Multiday wind movement (km)<br />
MNPN = Daily minimum temperature of water in an evaporation pan
(tenths of degrees C)<br />
MXPN = Daily maximum temperature of water in an evaporation pan
(tenths of degrees C)<br />
PGTM = Peak gust time (hours and minutes, i.e., HHMM)<br />
PSUN = Daily percent of possible sunshine (percent)<br />
SN*# = Minimum soil temperature (tenths of degrees C)
where * corresponds to a code
for ground cover and # corresponds to a code for soil
depth.<br />
<br />
Ground cover codes include the following:<br />
0 = unknown<br />
1 = grass<br />
2 = fallow<br />
3 = bare ground<br />
4 = brome grass<br />
5 = sod<br />
6 = straw multch<br />
7 = grass muck<br />
8 = bare muck<br />
<br />
Depth codes include the following:<br />
1 = 5 cm<br />
2 = 10 cm<br />
3 = 20 cm<br />
4 = 50 cm<br />
5 = 100 cm<br />
6 = 150 cm<br />
7 = 180 cm<br />
<br />
SX*# = Maximum soil temperature (tenths of degrees C)
where * corresponds to a code for ground cover
and # corresponds to a code for soil depth.<br />
See SN*# for ground cover and depth codes. <br />
TAVG = Average temperature (tenths of degrees C)
(Note that TAVG from source 'S' corresponds
to an average for the period ending at
2400 UTC rather than local midnight)<br />
THIC = Thickness of ice on water (tenths of mm)<br />
TOBS = Temperature at the time of observation (tenths of degrees C)<br />
TSUN = Daily total sunshine (minutes)<br />
WDF1 = Direction of fastest 1-minute wind (degrees)<br />
WDF2 = Direction of fastest 2-minute wind (degrees)<br />
WDF5 = Direction of fastest 5-second wind (degrees)<br />
WDFG = Direction of peak wind gust (degrees)<br />
WDFI = Direction of highest instantaneous wind (degrees)<br />
WDFM = Fastest mile wind direction (degrees)<br />
WDMV = 24-hour wind movement (km)<br />
WESD = Water equivalent of snow on the ground (tenths of mm)<br />
WESF = Water equivalent of snowfall (tenths of mm)<br />
WSF1 = Fastest 1-minute wind speed (tenths of meters per second)<br />
WSF2 = Fastest 2-minute wind speed (tenths of meters per second)<br />
WSF5 = Fastest 5-second wind speed (tenths of meters per second)<br />
WSFG = Peak gust wind speed (tenths of meters per second)<br />
WSFI = Highest instantaneous wind speed (tenths of meters per second)<br />
WSFM = Fastest mile wind speed (tenths of meters per second)<br />
WT** = Weather Type where ** has one of the following values:<br />
<br />
01 = Fog, ice fog, or freezing fog (may include heavy fog)<br />
02 = Heavy fog or heaving freezing fog (not always
distinguished from fog)<br />
03 = Thunder<br />
04 = Ice pellets, sleet, snow pellets, or small hail <br />
05 = Hail (may include small hail)<br />
06 = Glaze or rime <br />
07 = Dust, volcanic ash, blowing dust, blowing sand, or
blowing obstruction<br />
08 = Smoke or haze <br />
09 = Blowing or drifting snow<br />
10 = Tornado, waterspout, or funnel cloud <br />
11 = High or damaging winds<br />
12 = Blowing spray<br />
13 = Mist<br />
14 = Drizzle<br />
15 = Freezing drizzle <br />
16 = Rain (may include freezing rain, drizzle, and freezing drizzle) <br />
17 = Freezing rain <br />
18 = Snow, snow pellets, snow grains, or ice crystals<br />
19 = Unknown source of precipitation <br />
21 = Ground fog <br />
22 = Ice fog or freezing fog<br />
<br />
WV** = Weather in the Vicinity where ** has one of the following
values:<br />
01 = Fog, ice fog, or freezing fog (may include heavy fog)<br />
03 = Thunder<br />
07 = Ash, dust, sand, or other blowing obstruction<br />
18 = Snow or ice crystals<br />
20 = Rain or snow shower</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_station_+3A_years">years</code></td>
<td>
<p>A numeric vector indicating which years to get.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_station_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_station_+3A_standardize">standardize</code></td>
<td>
<p>Select only common year/month/day? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="get_ghcn_daily_station_+3A_force.redo">force.redo</code></td>
<td>
<p>If this weather station has been downloaded before, should it be updated? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list of <code><a href="base.html#topic+data.frame">data.frame</a>s</code>, one for each <code>elements</code>.
</p>

<hr>
<h2 id='get_ghcn_inventory'>Download and crop the inventory of GHCN stations.</h2><span id='topic+get_ghcn_inventory'></span>

<h3>Description</h3>

<p><code>get_ghcn_inventory</code> returns a <code>SpatialPolygonsDataFrame</code> of the GHCN stations within
the specified <code>template</code>. If template is not provided, returns the entire GHCN inventory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ghcn_inventory(template = NULL, elements = NULL, raw.dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ghcn_inventory_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_ghcn_inventory_+3A_elements">elements</code></td>
<td>
<p>A character vector of elements to extract.
Common elements include 'tmin', 'tmax', and 'prcp'.</p>
</td></tr>
<tr><td><code id="get_ghcn_inventory_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stations with multiple elements will have multiple points. This allows for easy mapping of stations
by element availability.
</p>


<h3>Value</h3>

<p>A <code><a href="sf.html#topic+sf">Simple Feature</a></code> of the GHCN stations within
the specified <code>template</code>
</p>

<hr>
<h2 id='get_itrdb'>Download the latest version of the ITRDB, and extract given parameters.</h2><span id='topic+get_itrdb'></span>

<h3>Description</h3>

<p><code>get_itrdb</code> returns a named list of length 3:
</p>

<ol>
<li><p> 'metadata': A data frame or <code><a href="sf.html#topic+sf">Simple Feature</a></code> (if <code>makeSpatial==TRUE</code>) of the locations
and names of extracted ITRDB chronologies,
</p>
</li>
<li><p> 'widths': A matrix of tree-ring widths/densities given user selection, and
</p>
</li>
<li><p> 'depths': A matrix of tree-ring sample depths.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>get_itrdb(
  template = NULL,
  label = NULL,
  recon.years = NULL,
  calib.years = NULL,
  species = NULL,
  measurement.type = NULL,
  chronology.type = NULL,
  raw.dir = paste0(tempdir(), "/FedData/raw/itrdb"),
  extraction.dir = ifelse(!is.null(label), paste0(tempdir(),
    "/FedData/extractions/itrdb/", label, "/"), paste0(tempdir(),
    "/FedData/extractions/itrdb")),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_itrdb_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.
If missing,
all available global chronologies are returned.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_recon.years">recon.years</code></td>
<td>
<p>A numeric vector of years over which reconstructions are needed;
if missing, the union of all years in the available chronologies are given.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_calib.years">calib.years</code></td>
<td>
<p>A numeric vector of all required years&mdash;chronologies without these years will be discarded;
if missing, all available chronologies are given.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_species">species</code></td>
<td>
<p>A character vector of 4-letter tree species identifiers;
if missing, all available chronologies are given.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_measurement.type">measurement.type</code></td>
<td>
<p>A character vector of measurement type identifiers. Options include:
</p>

<ul>
<li><p> 'Total Ring Density'
</p>
</li>
<li><p> 'Earlywood Width'
</p>
</li>
<li><p> 'Earlywood Density'
</p>
</li>
<li><p> 'Latewood Width'
</p>
</li>
<li><p> 'Minimum Density'
</p>
</li>
<li><p> 'Ring Width'
</p>
</li>
<li><p> 'Latewood Density'
</p>
</li>
<li><p> 'Maximum Density'
</p>
</li>
<li><p> 'Latewood Percent'
</p>
</li></ul>

<p>if missing, all available chronologies are given.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_chronology.type">chronology.type</code></td>
<td>
<p>A character vector of chronology type identifiers. Options include:
</p>

<ul>
<li><p> 'ARSTND'
</p>
</li>
<li><p> 'Low Pass Filter'
</p>
</li>
<li><p> 'Residual'
</p>
</li>
<li><p> 'Standard'
</p>
</li>
<li><p> 'Re-Whitened Residual'
</p>
</li>
<li><p> 'Measurements Only'
</p>
</li></ul>

<p>if missing, all available chronologies are given.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped ITRDB dataset should be put.
The directory will be created if missing.</p>
</td></tr>
<tr><td><code id="get_itrdb_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction already exists, should a new one be created? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list containing the 'metadata', 'widths', and 'depths' data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the ITRDB records
ITRDB &lt;- get_itrdb(template = FedData::meve, label = "meve", makeSpatial = T)

# Plot the VEP polygon
plot(meve$geometry)

# Map the locations of the tree ring chronologies
plot(ITRDB$metadata, pch = 1, add = T)
legend("bottomleft", pch = 1, legend = "ITRDB chronologies")

## End(Not run)
</code></pre>

<hr>
<h2 id='get_nass_cdl'>Download and crop the NASS Cropland Data Layer.</h2><span id='topic+get_nass_cdl'></span><span id='topic+get_nass'></span><span id='topic+get_cdl'></span><span id='topic+cdl_colors'></span>

<h3>Description</h3>

<p><code>get_nass_cdl</code> returns a <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> of NASS Cropland Data Layer cropped to a given
template study area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nass_cdl(
  template,
  label,
  year = 2019,
  extraction.dir = paste0(tempdir(), "/FedData/"),
  raster.options = c("COMPRESS=DEFLATE", "ZLEVEL=9", "INTERLEAVE=BAND"),
  force.redo = FALSE,
  progress = TRUE
)

get_nass(template, label, ...)

get_cdl(template, label, ...)

cdl_colors()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_nass_cdl_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_year">year</code></td>
<td>
<p>An integer representing the year of desired NASS Cropland Data Layer product.
Acceptable values are 2007&ndash;the last year.</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped NASS data should be put.
The directory will be created if missing.</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_raster.options">raster.options</code></td>
<td>
<p>a vector of options for terra::writeRaster.</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created?</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_progress">progress</code></td>
<td>
<p>Draw a progress bar when downloading?</p>
</td></tr>
<tr><td><code id="get_nass_cdl_+3A_...">...</code></td>
<td>
<p>Other parameters passed on to <a href="#topic+get_nass_cdl">get_nass_cdl</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> cropped to the bounding box of the template.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Extract data for the Mesa Verde National Park:

# Get the NASS CDL (USA ONLY)
# Returns a raster
NASS &lt;-
  get_nass_cdl(
    template = FedData::meve,
    label = "meve",
    year = 2011
  )

# Plot with terra::plot
plot(NASS)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_ned'>Download and crop the 1 (~30 meter) or 1/3 (~10 meter) arc-second National Elevation Dataset.</h2><span id='topic+get_ned'></span>

<h3>Description</h3>

<p><code>get_ned</code> returns a <code>SpatRaster</code> of elevation data cropped to a given
template study area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ned(
  template,
  label,
  res = "1",
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "ned", label),
  raster.options = c("COMPRESS=DEFLATE", "ZLEVEL=9"),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ned_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_ned_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_ned_+3A_res">res</code></td>
<td>
<p>A character string representing the desired resolution of the NED. '1'
indicates the 1 arc-second NED (the default), while '13' indicates the 1/3 arc-second dataset.</p>
</td></tr>
<tr><td><code id="get_ned_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped DEM should be put.
The directory will be created if missing.</p>
</td></tr>
<tr><td><code id="get_ned_+3A_raster.options">raster.options</code></td>
<td>
<p>a vector of GDAL options passed to <a href="terra.html#topic+writeRaster">terra::writeRaster</a>.</p>
</td></tr>
<tr><td><code id="get_ned_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>SpatRaster</code> DEM cropped to the extent of the template.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the NED (USA ONLY)
# Returns a `SpatRaster`
NED &lt;-
  get_ned(
    template = FedData::meve,
    label = "meve"
  )

# Plot with terra::plot
plot(NED)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_ned_tile'>Load and crop tile from the 1 (~30 meter) or 1/3 (~10 meter) arc-second National Elevation Dataset.</h2><span id='topic+get_ned_tile'></span>

<h3>Description</h3>

<p><code>get_ned_tile</code> returns a<code>SpatRaster</code> cropped within the specified <code>template</code>.
If template is not provided, returns the entire NED tile.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ned_tile(template = NULL, res = "1", tileNorthing, tileWesting)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ned_tile_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.
If missing, entire tile is returned.</p>
</td></tr>
<tr><td><code id="get_ned_tile_+3A_res">res</code></td>
<td>
<p>A character string representing the desired resolution of the NED. '1'
indicates the 1 arc-second NED (the default), while '13' indicates the 1/3 arc-second dataset.</p>
</td></tr>
<tr><td><code id="get_ned_tile_+3A_tilenorthing">tileNorthing</code></td>
<td>
<p>An integer representing the northing (latitude, in degrees north of the equator) of the northwest corner of the tile to
be downloaded.</p>
</td></tr>
<tr><td><code id="get_ned_tile_+3A_tilewesting">tileWesting</code></td>
<td>
<p>An integer representing the westing (longitude, in degrees west of the prime meridian) of the northwest corner of the tile to
be downloaded.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>SpatRaster</code> cropped to the extent of the template.
</p>

<hr>
<h2 id='get_nhd'>Download and crop the National Hydrography Dataset.</h2><span id='topic+get_nhd'></span>

<h3>Description</h3>

<p><code>get_nhd</code> returns a list of <code><a href="sf.html#topic+sf">Simple Feature</a></code> objects extracted
from the National Hydrography Dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nhd(
  template,
  label,
  nhdplus = FALSE,
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "nhd", label),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_nhd_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_nhd_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_nhd_+3A_nhdplus">nhdplus</code></td>
<td>
<p>Extract data from the USGS NHDPlus High Resolution service (experimental)</p>
</td></tr>
<tr><td><code id="get_nhd_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped NHD data should be put.</p>
</td></tr>
<tr><td><code id="get_nhd_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code>sf</code> collections extracted from the National Hydrography Dataset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the NHD (USA ONLY)
NHD &lt;- get_nhd(
  template = FedData::meve,
  label = "meve"
)
NHD
NHD %&gt;%
  plot_nhd(template = FedData::meve)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_nlcd'>Download and crop the National Land Cover Database.</h2><span id='topic+get_nlcd'></span><span id='topic+nlcd_colors'></span><span id='topic+pal_nlcd'></span>

<h3>Description</h3>

<p><code>get_nlcd</code> returns a <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> of NLCD data cropped to a given
template study area. <code>nlcd_colors</code> and <code>pal_nlcd</code> return the NLCD
legend and color palette, as available through the
<a href="https://www.mrlc.gov/data/legends/national-land-cover-database-class-legend-and-description">MLRC website</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nlcd(
  template,
  label,
  year = 2021,
  dataset = "landcover",
  landmass = "L48",
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "nlcd", label),
  raster.options = c("COMPRESS=DEFLATE", "ZLEVEL=9"),
  force.redo = FALSE
)

nlcd_colors()

pal_nlcd()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_nlcd_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">terra</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_year">year</code></td>
<td>
<p>An integer representing the year of desired NLCD product.
Acceptable values are 2021 (default), 2019, 2016, 2011, 2008, 2006, 2004, and 2001.</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_dataset">dataset</code></td>
<td>
<p>A character string representing type of the NLCD product.
Acceptable values are 'landcover' (default), 'impervious', and
'canopy'.</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_landmass">landmass</code></td>
<td>
<p>A character string representing the landmass to be extracted
Acceptable values are 'L48' (lower 48 US states, the default),
'AK' (Alaska, 2011 and 2016 only), 'HI' (Hawaii, 2001 only), and
'PR' (Puerto Rico, 2001 only).</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted
and cropped NLCD data should be put. The directory will be created if missing.</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_raster.options">raster.options</code></td>
<td>
<p>a vector of GDAL options passed to <a href="terra.html#topic+writeRaster">terra::writeRaster</a>.</p>
</td></tr>
<tr><td><code id="get_nlcd_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists,
should a new one be created?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>RasterLayer</code> cropped to the bounding box of the template.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Extract data for the Mesa Verde National Park:

# Get the NLCD (USA ONLY)
# Returns a raster
NLCD &lt;-
  get_nlcd(
    template = FedData::meve,
    label = "meve",
    year = 2016
  )

# Plot with terra::plot
plot(NLCD)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_padus'>Download and crop the PAD-US Dataset.</h2><span id='topic+get_padus'></span>

<h3>Description</h3>

<p><code>get_padus</code> returns a list of <code>sf</code> objects extracted
from the PAD-US Dataset. Data are retrieved directly from
<a href="https://www.usgs.gov/programs/gap-analysis-project/science/pad-us-web-services">PAD-US ArcGIS Web Services</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_padus(
  template,
  label,
  layer = c("Manager_Name"),
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "padus", label),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_padus_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.
Optionally, a vector of unit names, e.g., <code>c('Mesa Verde National Park','Ute Mountain Reservation')</code> may be provided.</p>
</td></tr>
<tr><td><code id="get_padus_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_padus_+3A_layer">layer</code></td>
<td>
<p>A character vector containing one or more PAD-US Layers.
By default, the <strong>Manager_Name</strong> layer is downloaded.
</p>

<ul>
<li> <p><strong>Protection_Status_by_GAP_Status_Code</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=b7a09e6c95a846fe82970c70195a2739">PAD-US 3.0 Protection Status by GAP Status Code</a> — Service representing a measure of management intent to permanently protect biodiversity. GAP 1&amp;2 areas are primarily managed for biodiversity, GAP 3 are managed for multiple uses including conservation and extraction, GAP 4 no known mandate for biodiversity protection. GAP Status Codes 1-3 are displayed, GAP 4 areas included but not displayed.
</p>
</li>
<li> <p><strong>Public_Access</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=3687ff551d7e4f0992f08419c2b29dd5">PAD-US 3.0 Public Access</a> — Service representing general level of public access permitted in the area - Open, Restricted (permit, seasonal), Closed. Public Access Unknown areas not displayed. Use to show general categories of public access (however, not all areas have been locally reviewed).
</p>
</li>
<li> <p><strong>Fee_Manager</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=0739a72a622443c98253d766c5416fc5">PAD-US 3.0 Fee Manager</a> — Manager or administrative agency names standardized nationally. Use for categorization by manager name, with detailed federal managers and generic state/local/other managers. Where available this layer includes fee simple parcels from the Fee feature class plus DOD and Tribal areas from the Proclamation feature class.
</p>
</li>
<li> <p><strong>Manager_Name</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=ff6f75a7f4b148cb97e9d755299edded">PAD-US 3.0 Manager Name</a> — Service representing coarse level land manager description from &quot;Agency Type&quot; Domain, &quot;Manager Type&quot; Field (for example, Federal, Tribal, State, Local Gov, Private). Use for broad categorization of manager levels, for general depictions of who manages what areas.
</p>
</li>
<li> <p><strong>Manager_Type</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=f0c68c83c88a46dcbb80fd33780ee9f5">PAD-US 3.0 Manager Type</a> — Service representing coarse level land manager description from &quot;Agency Type&quot; Domain, &quot;Manager Type&quot; Field (for example, Federal, Tribal, State, Local Gov, Private). Use for broad categorization of manager levels, for general depictions of who manages what areas.
</p>
</li>
<li> <p><strong>Federal_Fee_Managers_Authoritative</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=3fb354192e92407b9b86979669c47e4c">PAD-US 3.0 Federal Fee Managers Authoritative</a> — An ArcGIS WebService describing authoritative fee data for federal managers or administrative agencies by name. U.S. Department of Defense and Tribal areas shown from the Proclamation feature class. Use to depict authoritative fee data for individual federal management agencies (no state, local or private lands). This service does not include designations that often overlap state, private or other inholdings. U.S. Department of Defense internal land ownership is not represented but is implied Federal. See the Federal Management Agencies service for a combined view of fee ownership, designations, and easements.
</p>
</li>
<li> <p><strong>Federal_Management_Agencies</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=562afaf9385a45598f919739bac474e9">PAD-US 3.0 Federal Management Agencies</a> — Federal managers or administrative agencies by name. Use to depict individual federal management agencies (no state, local or private lands). This map is based on the Combined Proclamation, Marine, Fee, Designation, Easement feature class.
</p>
</li>
<li> <p><strong>Protection_Mechanism_Category</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=22670023fd124c799d5ddd08297dde85">PAD-US 3.0 Protection Mechanism Category</a> — Service representing the protection mechanism category including fee simple, internal management designations, easements, leases and agreements, and Marine Areas. Use to show categories of land tenure for all protected areas, including marine areas.
</p>
</li>
<li> <p><strong>Proclamation_and_Other_Planning_Boundaries</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=960df4c1bb7849809b82e185dffe9cdb">PAD-US 3.0 Proclamation and Other Planning Boundaries</a> — Service representing boundaries that provide additional context. Administrative agency name standardized for the nation (DOD, FWS, NPS, USFS, Tribal). Boundaries shown with outline only, as proclamation data do not depict actual ownership or management. Use to show outline of agency proclamation, approved acquisition or other planning boundaries where internal ownership is not depicted.
</p>
</li>
<li> <p><strong>Fee_Topology_Overlaps</strong>: <a href="https://usgs.maps.arcgis.com/home/item.html?id=b8068025827b4aa0866955fd9ae38321">PAD-US 3.0 Topology Overlaps</a> — Topology assessment of the Fee feature class. Use to identify overlaps in Fee data between Federal agencies and between Federal/State lands.
</p>
</li></ul>
</td></tr>
<tr><td><code id="get_padus_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped PAD-US data should be put.</p>
</td></tr>
<tr><td><code id="get_padus_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><a href="https://www.usgs.gov/programs/gap-analysis-project/science/pad-us-data-overview">PAD-US</a> is America’s official national inventory of U.S. terrestrial and
marine protected areas that are dedicated to the preservation of biological
diversity and to other natural, recreation and cultural uses, managed for
these purposes through legal or other effective means. PAD-US also includes
the best available aggregation of federal land and marine areas provided
directly by managing agencies, coordinated through the Federal Geographic
Data Committee Federal Lands Working Group.
</p>


<h3>Value</h3>

<p>A list of <a href="sf.html#topic+sf">sf::sf</a> collections extracted from the PAD-US Dataset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the PAD-US (USA ONLY)
PADUS &lt;- get_padus(
  template = FedData::meve,
  label = "meve"
)
PADUS

## End(Not run)
</code></pre>

<hr>
<h2 id='get_ssurgo'>Download and crop data from the NRCS SSURGO soils database.</h2><span id='topic+get_ssurgo'></span>

<h3>Description</h3>

<p>This is an efficient method for spatially merging several different soil survey areas
as well as merging their tabular data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ssurgo(
  template,
  label,
  raw.dir = paste0(tempdir(), "/FedData/raw/ssurgo"),
  extraction.dir = paste0(tempdir(), "/FedData/"),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ssurgo_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.
Optionally, a vector of area names, e.g., <code>c('IN087','IN088')</code> may be provided.</p>
</td></tr>
<tr><td><code id="get_ssurgo_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_ssurgo_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing. Defaults to './RAW/SSURGO/'.</p>
</td></tr>
<tr><td><code id="get_ssurgo_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped SSURGO shapefiles should be put.
The directory will be created if missing. Defaults to './EXTRACTIONS/SSURGO/'.</p>
</td></tr>
<tr><td><code id="get_ssurgo_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>get_ssurgo</code> returns a named list of length 2:
</p>

<ol>
<li><p> 'spatial': A <code><a href="sf.html#topic+sf">Simple Feature</a></code> of soil mapunits
in the template, and
</p>
</li>
<li><p> 'tabular': A named list of <code><a href="base.html#topic+data.frame">data.frame</a>s</code> with the SSURGO tabular data.
</p>
</li></ol>



<h3>Value</h3>

<p>A named list containing the 'spatial' and 'tabular' data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the NRCS SSURGO data (USA ONLY)
SSURGO.MEVE &lt;- get_ssurgo(template = FedData::meve, label = "meve")

# Plot the VEP polygon
plot(meve$geometry)

# Plot the SSURGO mapunit polygons
plot(SSURGO.MEVE$spatial, lwd = 0.1, add = T)

# Or, download by Soil Survey Area names
SSURGO.areas &lt;- get_ssurgo(template = c("CO670", "CO075"), label = "CO_TEST")

# Let's just look at spatial data for CO675
SSURGO.areas.CO675 &lt;- SSURGO.areas$spatial[SSURGO.areas$spatial$AREASYMBOL == "CO075", ]

# And get the NED data under them for pretty plotting
NED.CO675 &lt;- get_ned(template = SSURGO.areas.CO675, label = "SSURGO_CO675")

# Plot the SSURGO mapunit polygons, but only for CO675
plot(NED.CO675)
plot(SSURGO.areas.CO675, lwd = 0.1, add = T)

## End(Not run)
</code></pre>

<hr>
<h2 id='get_ssurgo_inventory'>Download and crop a shapefile of the SSURGO study areas.</h2><span id='topic+get_ssurgo_inventory'></span>

<h3>Description</h3>

<p><code>get_ssurgo_inventory</code> returns a <code>SpatialPolygonsDataFrame</code> of the SSURGO study areas within
the specified <code>template</code>. If template is not provided, returns the entire SSURGO inventory of study areas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_ssurgo_inventory(template = NULL, raw.dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ssurgo_inventory_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_ssurgo_inventory_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>SpatialPolygonsDataFrame</code> of the SSURGO study areas within
the specified <code>template</code>.
</p>

<hr>
<h2 id='get_ssurgo_study_area'>Download and crop the spatial and tabular data for a SSURGO study area.</h2><span id='topic+get_ssurgo_study_area'></span>

<h3>Description</h3>

<p><code>get_ssurgo_study_area</code> returns a named list of length 2:
</p>

<ol>
<li><p> 'spatial': A <code><a href="sf.html#topic+sf">Simple Feature</a></code> of soil mapunits
in the template, and
</p>
</li>
<li><p> 'tabular': A named list of <code><a href="base.html#topic+data.frame">data.frame</a>s</code> with the SSURGO tabular data.
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>get_ssurgo_study_area(template = NULL, area, date, raw.dir)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_ssurgo_study_area_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.
If missing, whose study area is returned</p>
</td></tr>
<tr><td><code id="get_ssurgo_study_area_+3A_area">area</code></td>
<td>
<p>A character string indicating the SSURGO study area to be downloaded.</p>
</td></tr>
<tr><td><code id="get_ssurgo_study_area_+3A_date">date</code></td>
<td>
<p>A character string indicating the date of the most recent update to the SSURGO
area for these data. This information may be gleaned from the SSURGO Inventory (<code><a href="#topic+get_ssurgo_inventory">get_ssurgo_inventory</a></code>).</p>
</td></tr>
<tr><td><code id="get_ssurgo_study_area_+3A_raw.dir">raw.dir</code></td>
<td>
<p>A character string indicating where raw downloaded files should be put.
The directory will be created if missing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>SpatialPolygonsDataFrame</code> of the SSURGO study areas within
the specified <code>template</code>.
</p>

<hr>
<h2 id='get_wbd'>Download and crop the Watershed Boundary Dataset.</h2><span id='topic+get_wbd'></span>

<h3>Description</h3>

<p><code>get_wbd</code> returns an <code><a href="sf.html#topic+sf">Simple Feature</a></code> collection of the HUC 12 regions within
the specified <code>template</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_wbd(
  template,
  label,
  extraction.dir = file.path(tempdir(), "FedData", "extractions", "nhd", label),
  force.redo = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_wbd_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
<tr><td><code id="get_wbd_+3A_label">label</code></td>
<td>
<p>A character string naming the study area.</p>
</td></tr>
<tr><td><code id="get_wbd_+3A_extraction.dir">extraction.dir</code></td>
<td>
<p>A character string indicating where the extracted and cropped NHD data should be put.</p>
</td></tr>
<tr><td><code id="get_wbd_+3A_force.redo">force.redo</code></td>
<td>
<p>If an extraction for this template and label already exists, should a new one be created?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code>sf</code> collection of the HUC 12 regions within
the specified <code>template</code>.
</p>

<hr>
<h2 id='meve'>The boundary of Mesa Verde National Park</h2><span id='topic+meve'></span>

<h3>Description</h3>

<p>A dataset containing the spatial polygon defining the boundary
of Mesa Verde National Park in Montana.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meve
</code></pre>


<h3>Format</h3>

<p>Simple feature collection with 1 feature and a geometry field.
</p>

<hr>
<h2 id='plot_nhd'>A basic plotting function for NHD data.</h2><span id='topic+plot_nhd'></span>

<h3>Description</h3>

<p>This is more of an example than anything
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_nhd(x, template = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_nhd_+3A_x">x</code></td>
<td>
<p>The result of <a href="#topic+get_nhd">get_nhd</a>.</p>
</td></tr>
<tr><td><code id="plot_nhd_+3A_template">template</code></td>
<td>
<p>An <code><a href="sf.html#topic+sf">Simple Feature</a></code>
or <code><a href="terra.html#topic+SpatRaster-class">SpatRaster</a></code> object to serve as a template for cropping.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> panel of plots
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Get the NHD (USA ONLY)
NHD &lt;- get_nhd(
  template = FedData::meve,
  label = "meve"
)
NHD
NHD %&gt;%
  plot_nhd(template = FedData::meve)

## End(Not run)
</code></pre>

<hr>
<h2 id='polygon_from_extent'>Turn an extent object into a polygon</h2><span id='topic+polygon_from_extent'></span>

<h3>Description</h3>

<p>Turn an extent object into a polygon
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polygon_from_extent(x, proj4string = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="polygon_from_extent_+3A_x">x</code></td>
<td>
<p>An object from which an bounding box object can be retrieved.</p>
</td></tr>
<tr><td><code id="polygon_from_extent_+3A_proj4string">proj4string</code></td>
<td>
<p>A PROJ.4 formatted string defining the required projection.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="sf.html#topic+sf">Simple Feature</a></code> object.
</p>

<hr>
<h2 id='read_crn'>Read a Tucson-format chronology file.</h2><span id='topic+read_crn'></span>

<h3>Description</h3>

<p>This function includes improvements to the <code>read.crn</code> function from the
<span class="pkg">dplR</span> library. The principle changes are better parsing of metadata, and support
for the Schweingruber-type Tucson format. Chronologies that are unable to be read
are reported to the user. This function automatically recognizes Schweingruber-type files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_crn(file)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_crn_+3A_file">file</code></td>
<td>
<p>A character string path pointing to a <code>*.crn</code> file to be read.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This wraps two other functions: <code><a href="#topic+read_crn_metadata">read_crn_metadata</a></code> <code><a href="#topic+read_crn_data">read_crn_data</a></code>.
</p>


<h3>Value</h3>

<p>A list containing the metadata and chronology.
</p>

<hr>
<h2 id='read_crn_data'>Read chronology data from a Tucson-format chronology file.</h2><span id='topic+read_crn_data'></span>

<h3>Description</h3>

<p>This function includes improvements to the <code><a href="#topic+read_crn">read_crn</a></code> function from the
<span class="pkg">dplR</span> library. The principle changes are better parsing of metadata, and support
for the Schweingruber-type Tucson format. Chronologies that are unable to be read
are reported to the user. The user (or <code><a href="#topic+read_crn">read_crn</a></code>) must tell the function whether
the file is a Schweingruber-type chronology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_crn_data(file, SCHWEINGRUBER)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_crn_data_+3A_file">file</code></td>
<td>
<p>A character string path pointing to a <code>*.crn</code> file to be read.</p>
</td></tr>
<tr><td><code id="read_crn_data_+3A_schweingruber">SCHWEINGRUBER</code></td>
<td>
<p>Is the file in the Schweingruber-type Tucson format?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame containing the data, or if <code>SCHWEINGRUBER==T</code>, a list containing four types of data.
</p>

<hr>
<h2 id='read_crn_metadata'>Read metadata from a Tucson-format chronology file.</h2><span id='topic+read_crn_metadata'></span>

<h3>Description</h3>

<p>This function includes improvements to the <code><a href="#topic+read_crn">read_crn</a></code> function from the
<span class="pkg">dplR</span> library. The principle changes are better parsing of metadata, and support
for the Schweingruber-type Tucson format. Chronologies that are unable to be read
are reported to the user. The user (or <code><a href="#topic+read_crn">read_crn</a></code>) must tell the function whether
the file is a Schweingruber-type chronology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_crn_metadata(file, SCHWEINGRUBER)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_crn_metadata_+3A_file">file</code></td>
<td>
<p>A character string path pointing to a <code>*.crn</code> file to be read.</p>
</td></tr>
<tr><td><code id="read_crn_metadata_+3A_schweingruber">SCHWEINGRUBER</code></td>
<td>
<p>Is the file in the Schweingruber-type Tucson format?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Location information is converted to decimal degrees.
</p>


<h3>Value</h3>

<p>A data.frame containing the metadata.
</p>

<hr>
<h2 id='replace_null'>Replace NULLs</h2><span id='topic+replace_null'></span>

<h3>Description</h3>

<p>Replace all the empty values in a list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_null(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_null_+3A_x">x</code></td>
<td>
<p>A list</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>list(a = NULL, b = 1, c = list(foo = NULL, bar = NULL)) %&gt;% replace_null()
</code></pre>

<hr>
<h2 id='sequential_duplicated'>Get a logical vector of which elements in a vector are sequentially duplicated.</h2><span id='topic+sequential_duplicated'></span>

<h3>Description</h3>

<p>Get a logical vector of which elements in a vector are sequentially duplicated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sequential_duplicated(x, rows = F)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sequential_duplicated_+3A_x">x</code></td>
<td>
<p>An vector of any type, or, if <code>rows</code>, a matrix.</p>
</td></tr>
<tr><td><code id="sequential_duplicated_+3A_rows">rows</code></td>
<td>
<p>Is x a matrix?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector of the same length as x.
</p>

<hr>
<h2 id='soils_query'>Submit a Soil Data Access (SDA) Query</h2><span id='topic+soils_query'></span>

<h3>Description</h3>

<p><code>soils_query</code> submit an SQL query to retrieve data from the Soil Data Mart.
Please see https://sdmdataaccess.sc.egov.usda.gov/Query.aspx for guidelines
</p>


<h3>Usage</h3>

<pre><code class='language-R'>soils_query(q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="soils_query_+3A_q">q</code></td>
<td>
<p>A character string representing a SQL query to the SDA service</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble returned from the SDA service
</p>

<hr>
<h2 id='split_bbox'>Splits a bbox into a list of bboxes less than a certain size</h2><span id='topic+split_bbox'></span>

<h3>Description</h3>

<p>Splits a bbox into a list of bboxes less than a certain size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_bbox(bbox, x, y = x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_bbox_+3A_x">x</code></td>
<td>
<p>The maximum x size of the resulting bounding boxes</p>
</td></tr>
<tr><td><code id="split_bbox_+3A_y">y</code></td>
<td>
<p>The maximum y size of the resulting bounding boxes; defaults to x</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of bbox objects
</p>

<hr>
<h2 id='station_to_data_frame'>Convert a list of station data to a single data frame.</h2><span id='topic+station_to_data_frame'></span>

<h3>Description</h3>

<p><code>station_to_data_frame</code> returns a <code>data.frame</code> of the GHCN station data list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>station_to_data_frame(station.data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="station_to_data_frame_+3A_station.data">station.data</code></td>
<td>
<p>A named list containing station data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function unwraps the station data and merges all data into a single data frame,
with the first column being in the <code>Date</code> class.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> of the containing the unwrapped station data
</p>

<hr>
<h2 id='substr_right'>Get the rightmost 'n' characters of a character string.</h2><span id='topic+substr_right'></span>

<h3>Description</h3>

<p>Get the rightmost 'n' characters of a character string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>substr_right(x, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="substr_right_+3A_x">x</code></td>
<td>
<p>A character string.</p>
</td></tr>
<tr><td><code id="substr_right_+3A_n">n</code></td>
<td>
<p>The number of characters to retrieve.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character string.
</p>

<hr>
<h2 id='unwrap_rows'>Unwraps a matrix and only keep the first n elements.</h2><span id='topic+unwrap_rows'></span>

<h3>Description</h3>

<p>A function that unwraps a matrix and only keeps the first n elements
n can be either a constant (in which case it will be repeated), or a vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>unwrap_rows(mat, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="unwrap_rows_+3A_mat">mat</code></td>
<td>
<p>A matrix</p>
</td></tr>
<tr><td><code id="unwrap_rows_+3A_n">n</code></td>
<td>
<p>A numeric vector</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector of the same length as x
</p>

<hr>
<h2 id='url_base'>Strip query parameters from a URL</h2><span id='topic+url_base'></span>

<h3>Description</h3>

<p>Strip query parameters from a URL
</p>


<h3>Usage</h3>

<pre><code class='language-R'>url_base(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="url_base_+3A_x">x</code></td>
<td>
<p>The URL to be modified</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The URL without parameters
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
