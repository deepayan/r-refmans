<!DOCTYPE html><html><head><title>Help for package torchaudio</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {torchaudio}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#av_loader'><p>av_loader</p></a></li>
<li><a href='#cmuarctic_dataset'><p>CMU Arctic Dataset</p></a></li>
<li><a href='#extract_archive'><p>Extract Archive</p></a></li>
<li><a href='#functional__combine_max'><p>Combine Max (functional)</p></a></li>
<li><a href='#functional__compute_nccf'><p>Normalized Cross-Correlation Function (functional)</p></a></li>
<li><a href='#functional__find_max_per_frame'><p>Find Max Per Frame (functional)</p></a></li>
<li><a href='#functional__generate_wave_table'><p>Wave Table Generator (functional)</p></a></li>
<li><a href='#functional__median_smoothing'><p>Median Smoothing (functional)</p></a></li>
<li><a href='#functional_add_noise_shaping'><p>Noise Shaping (functional)</p></a></li>
<li><a href='#functional_allpass_biquad'><p>All-pass Biquad Filter (functional)</p></a></li>
<li><a href='#functional_amplitude_to_db'><p>Amplitude to DB (functional)</p></a></li>
<li><a href='#functional_angle'><p>Angle (functional)</p></a></li>
<li><a href='#functional_apply_probability_distribution'><p>Probability Distribution Apply (functional)</p></a></li>
<li><a href='#functional_band_biquad'><p>Two-pole Band Filter (functional)</p></a></li>
<li><a href='#functional_bandpass_biquad'><p>Band-pass Biquad Filter (functional)</p></a></li>
<li><a href='#functional_bandreject_biquad'><p>Band-reject Biquad Filter (functional)</p></a></li>
<li><a href='#functional_bass_biquad'><p>Bass Tone-control Effect (functional)</p></a></li>
<li><a href='#functional_biquad'><p>Biquad Filter (functional)</p></a></li>
<li><a href='#functional_complex_norm'><p>Complex Norm (functional)</p></a></li>
<li><a href='#functional_compute_deltas'><p>Delta Coefficients (functional)</p></a></li>
<li><a href='#functional_contrast'><p>Contrast Effect (functional)</p></a></li>
<li><a href='#functional_create_dct'><p>DCT transformation matrix (functional)</p></a></li>
<li><a href='#functional_create_fb_matrix'><p>Frequency Bin Conversion Matrix (functional)</p></a></li>
<li><a href='#functional_db_to_amplitude'><p>DB to Amplitude (functional)</p></a></li>
<li><a href='#functional_dcshift'><p>DC Shift (functional)</p></a></li>
<li><a href='#functional_deemph_biquad'><p>ISO 908 CD De-emphasis IIR Filter (functional)</p></a></li>
<li><a href='#functional_detect_pitch_frequency'><p>Detect Pitch Frequency (functional)</p></a></li>
<li><a href='#functional_dither'><p>Dither (functional)</p></a></li>
<li><a href='#functional_equalizer_biquad'><p>Biquad Peaking Equalizer Filter (functional)</p></a></li>
<li><a href='#functional_flanger'><p>Flanger Effect (functional)</p></a></li>
<li><a href='#functional_gain'><p>Gain (functional)</p></a></li>
<li><a href='#functional_griffinlim'><p>Griffin-Lim Transformation (functional)</p></a></li>
<li><a href='#functional_highpass_biquad'><p>High-pass Biquad Filter (functional)</p></a></li>
<li><a href='#functional_lfilter'><p>An IIR Filter (functional)</p></a></li>
<li><a href='#functional_lowpass_biquad'><p>Low-pass Biquad Filter (functional)</p></a></li>
<li><a href='#functional_magphase'><p>Magnitude and Phase (functional)</p></a></li>
<li><a href='#functional_mask_along_axis'><p>Mask Along Axis (functional)</p></a></li>
<li><a href='#functional_mask_along_axis_iid'><p>Mask Along Axis IID (functional)</p></a></li>
<li><a href='#functional_mel_scale'><p>Mel Scale (functional)</p></a></li>
<li><a href='#functional_mu_law_decoding'><p>Mu Law Decoding (functional)</p></a></li>
<li><a href='#functional_mu_law_encoding'><p>Mu Law Encoding (functional)</p></a></li>
<li><a href='#functional_overdrive'><p>Overdrive Effect (functional)</p></a></li>
<li><a href='#functional_phase_vocoder'><p>Phase Vocoder</p></a></li>
<li><a href='#functional_phaser'><p>Phasing Effect (functional)</p></a></li>
<li><a href='#functional_riaa_biquad'><p>RIAA Vinyl Playback Equalisation (functional)</p></a></li>
<li><a href='#functional_sliding_window_cmn'><p>sliding-window Cepstral Mean Normalization (functional)</p></a></li>
<li><a href='#functional_spectrogram'><p>Spectrogram (functional)</p></a></li>
<li><a href='#functional_treble_biquad'><p>Treble Tone-control Effect (functional)</p></a></li>
<li><a href='#functional_vad'><p>Voice Activity Detector (functional)</p></a></li>
<li><a href='#internal__normalize_audio'><p>Audio Normalization</p></a></li>
<li><a href='#kaldi__get_lr_indices_and_weights'><p>Linear Resample Indices And Weights</p></a></li>
<li><a href='#kaldi__get_num_lr_output_samples'><p>Linear Resample Output Samples</p></a></li>
<li><a href='#kaldi_resample_waveform'><p>Kaldi's Resample Waveform</p></a></li>
<li><a href='#linear_to_mel_frequency'><p>Linear to mel frequency</p></a></li>
<li><a href='#list_audio_backends'><p>List available audio backends</p></a></li>
<li><a href='#mel_to_linear_frequency'><p>Mel to linear frequency</p></a></li>
<li><a href='#model_melresnet'><p>MelResNet</p></a></li>
<li><a href='#model_resblock'><p>ResBlock</p></a></li>
<li><a href='#model_stretch2d'><p>Stretch2d</p></a></li>
<li><a href='#model_upsample_network'><p>UpsampleNetwork</p></a></li>
<li><a href='#model_wavernn'><p>WaveRNN</p></a></li>
<li><a href='#speechcommand_dataset'><p>Speech Commands Dataset</p></a></li>
<li><a href='#strip'><p>Strip</p></a></li>
<li><a href='#torchaudio_info'><p>Audio Information</p></a></li>
<li><a href='#torchaudio_load'><p>Load Audio File</p></a></li>
<li><a href='#transform__axismasking'><p>Axis Masking</p></a></li>
<li><a href='#transform_amplitude_to_db'><p>Amplitude to DB</p></a></li>
<li><a href='#transform_complex_norm'><p>Complex Norm</p></a></li>
<li><a href='#transform_compute_deltas'><p>Delta Coefficients</p></a></li>
<li><a href='#transform_fade'><p>Fade In/Out</p></a></li>
<li><a href='#transform_frequencymasking'><p>Frequency-domain Masking</p></a></li>
<li><a href='#transform_inverse_mel_scale'><p>Inverse Mel Scale</p></a></li>
<li><a href='#transform_mel_scale'><p>Mel Scale</p></a></li>
<li><a href='#transform_mel_spectrogram'><p>Mel Spectrogram</p></a></li>
<li><a href='#transform_mfcc'><p>Mel-frequency Cepstrum Coefficients</p></a></li>
<li><a href='#transform_mu_law_decoding'><p>Mu Law Decoding</p></a></li>
<li><a href='#transform_mu_law_encoding'><p>Mu Law Encoding</p></a></li>
<li><a href='#transform_resample'><p>Signal Resample</p></a></li>
<li><a href='#transform_sliding_window_cmn'><p>sliding-window Cepstral Mean Normalization</p></a></li>
<li><a href='#transform_spectrogram'><p>Spectrogram</p></a></li>
<li><a href='#transform_time_stretch'><p>Time Stretch</p></a></li>
<li><a href='#transform_timemasking'><p>Time-domain Masking</p></a></li>
<li><a href='#transform_to_tensor'><p>Convert an audio object into a tensor</p></a></li>
<li><a href='#transform_vad'><p>Voice Activity Detector</p></a></li>
<li><a href='#transform_vol'><p>Add a volume to an waveform.</p></a></li>
<li><a href='#tuneR_loader'><p>tuneR_loader</p></a></li>
<li><a href='#walk_files'><p>List recursively all files ending with a suffix at a given root</p></a></li>
<li><a href='#yesno_dataset'><p>YesNo Dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>R Interface to 'pytorch&rdquo;s 'torchaudio'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides access to datasets, models and processing
    facilities for deep learning in audio.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, tuneR, knitr, rmarkdown, stringr, numbers, purrr,
scales, httr, viridis</td>
</tr>
<tr>
<td>Imports:</td>
<td>torch (&ge; 0.3.0), av, fs, rlang, utils, tools, glue, methods</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-02-06 20:25:46 UTC; key</td>
</tr>
<tr>
<td>Author:</td>
<td>Sigrid Keydana [aut, cre],
  Athos Damiani [aut],
  Daniel Falbel [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sigrid Keydana &lt;sigrid@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-02-08 08:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='av_loader'>av_loader</h2><span id='topic+av_loader'></span>

<h3>Description</h3>

<p>av_loader
</p>


<h3>Usage</h3>

<pre><code class='language-R'>av_loader(filepath, offset = 0L, duration = Inf, unit = "samples")
</code></pre>

<hr>
<h2 id='cmuarctic_dataset'>CMU Arctic Dataset</h2><span id='topic+cmuarctic_dataset'></span>

<h3>Description</h3>

<p>Create a Dataset for CMU_ARCTIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmuarctic_dataset(
  root,
  url = "aew",
  folder_in_archive = "ARCTIC",
  download = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmuarctic_dataset_+3A_root">root</code></td>
<td>
<p>(str): Path to the directory where the dataset is found or downloaded.</p>
</td></tr>
<tr><td><code id="cmuarctic_dataset_+3A_url">url</code></td>
<td>
<p>(str, optional): The URL to download the dataset from or the type of the dataset to dowload.
(default: <code>"aew"</code>)
Allowed type values are <code>"aew"</code>, <code>"ahw"</code>, <code>"aup"</code>, <code>"awb"</code>, <code>"axb"</code>, <code>"bdl"</code>,
<code>"clb"</code>, <code>"eey"</code>, <code>"fem"</code>, <code>"gka"</code>, <code>"jmk"</code>, <code>"ksp"</code>, <code>"ljm"</code>, <code>"lnh"</code>,
<code>"rms"</code>, <code>"rxr"</code>, <code>"slp"</code> or <code>"slt"</code>.</p>
</td></tr>
<tr><td><code id="cmuarctic_dataset_+3A_folder_in_archive">folder_in_archive</code></td>
<td>
<p>(str, optional): The top-level directory of the dataset.  (default: <code>"ARCTIC"</code>)</p>
</td></tr>
<tr><td><code id="cmuarctic_dataset_+3A_download">download</code></td>
<td>
<p>(bool, optional): Whether to download the dataset if it is not found at root path.  (default: <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a torch::dataset()
</p>

<hr>
<h2 id='extract_archive'>Extract Archive</h2><span id='topic+extract_archive'></span>

<h3>Description</h3>

<p>Extract Archive
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_archive(from_path, to_path = NULL, overwrite = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_archive_+3A_from_path">from_path</code></td>
<td>
<p>(str): the path of the archive.</p>
</td></tr>
<tr><td><code id="extract_archive_+3A_to_path">to_path</code></td>
<td>
<p>(str, optional): the root path of the extraced files (directory of from_path) (Default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="extract_archive_+3A_overwrite">overwrite</code></td>
<td>
<p>(bool, optional): overwrite existing files (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list: List of paths to extracted files even if not overwritten.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
url = 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz'
d &lt;- fs::dir_create(tempdir(), "torchaudio")
from_path &lt;- fs::path(d, basename(url))
utils::download.file(url = url, destfile = from_path)
torchaudio::extract_archive (from_path, d)
}

</code></pre>

<hr>
<h2 id='functional__combine_max'>Combine Max (functional)</h2><span id='topic+functional__combine_max'></span>

<h3>Description</h3>

<p>Take value from first if bigger than a multiplicative factor of the second, elementwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional__combine_max(a, b, thresh = 0.99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional__combine_max_+3A_a">a</code></td>
<td>
<p>(list(tensor, tensor))</p>
</td></tr>
<tr><td><code id="functional__combine_max_+3A_b">b</code></td>
<td>
<p>(list(tensor, tensor))</p>
</td></tr>
<tr><td><code id="functional__combine_max_+3A_thresh">thresh</code></td>
<td>
<p>(float) Default: 0.99</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list(tensor, tensor)</code>: a list with values tensor and indices tensor.
</p>

<hr>
<h2 id='functional__compute_nccf'>Normalized Cross-Correlation Function (functional)</h2><span id='topic+functional__compute_nccf'></span>

<h3>Description</h3>

<p>Compute Normalized Cross-Correlation Function  (NCCF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional__compute_nccf(waveform, sample_rate, frame_time, freq_low)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional__compute_nccf_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., time)</p>
</td></tr>
<tr><td><code id="functional__compute_nccf_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional__compute_nccf_+3A_frame_time">frame_time</code></td>
<td>
<p>(float)</p>
</td></tr>
<tr><td><code id="functional__compute_nccf_+3A_freq_low">freq_low</code></td>
<td>
<p>(float)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code> of nccf&ldquo;
</p>

<hr>
<h2 id='functional__find_max_per_frame'>Find Max Per Frame (functional)</h2><span id='topic+functional__find_max_per_frame'></span>

<h3>Description</h3>

<p>For each frame, take the highest value of NCCF,
apply centered median smoothing, and convert to frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional__find_max_per_frame(nccf, sample_rate, freq_high)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional__find_max_per_frame_+3A_nccf">nccf</code></td>
<td>
<p>(tensor): Usually a tensor returned by <a href="#topic+functional__compute_nccf">functional__compute_nccf</a></p>
</td></tr>
<tr><td><code id="functional__find_max_per_frame_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional__find_max_per_frame_+3A_freq_high">freq_high</code></td>
<td>
<p>(int): Highest frequency that can be detected (Hz)
</p>
<p>Note: If the max among all the lags is very close
to the first half of lags, then the latter is taken.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code> with indices
</p>

<hr>
<h2 id='functional__generate_wave_table'>Wave Table Generator (functional)</h2><span id='topic+functional__generate_wave_table'></span>

<h3>Description</h3>

<p>A helper function for phaser. Generates a table with given parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional__generate_wave_table(
  wave_type,
  data_type,
  table_size,
  min,
  max,
  phase,
  device
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional__generate_wave_table_+3A_wave_type">wave_type</code></td>
<td>
<p>(str): 'SINE' or 'TRIANGULAR'</p>
</td></tr>
<tr><td><code id="functional__generate_wave_table_+3A_data_type">data_type</code></td>
<td>
<p>(str): desired data_type ( <code>INT</code> or <code>FLOAT</code> )</p>
</td></tr>
<tr><td><code id="functional__generate_wave_table_+3A_table_size">table_size</code></td>
<td>
<p>(int): desired table size</p>
</td></tr>
<tr><td><code id="functional__generate_wave_table_+3A_min">min</code></td>
<td>
<p>(float): desired min value</p>
</td></tr>
<tr><td><code id="functional__generate_wave_table_+3A_max">max</code></td>
<td>
<p>(float): desired max value</p>
</td></tr>
<tr><td><code id="functional__generate_wave_table_+3A_phase">phase</code></td>
<td>
<p>(float): desired phase</p>
</td></tr>
<tr><td><code id="functional__generate_wave_table_+3A_device">device</code></td>
<td>
<p>(torch_device): Torch device on which table must be generated</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: A 1D tensor with wave table values
</p>

<hr>
<h2 id='functional__median_smoothing'>Median Smoothing (functional)</h2><span id='topic+functional__median_smoothing'></span>

<h3>Description</h3>

<p>Apply median smoothing to the 1D tensor over the given window.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional__median_smoothing(indices, win_length)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional__median_smoothing_+3A_indices">indices</code></td>
<td>
<p>(Tensor)</p>
</td></tr>
<tr><td><code id="functional__median_smoothing_+3A_win_length">win_length</code></td>
<td>
<p>(int)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>
</p>

<hr>
<h2 id='functional_add_noise_shaping'>Noise Shaping (functional)</h2><span id='topic+functional_add_noise_shaping'></span>

<h3>Description</h3>

<p>Noise shaping is calculated by error:
error[n] = dithered[n] - original[n]
noise_shaped_waveform[n] = dithered[n] + error[n-1]
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_add_noise_shaping(dithered_waveform, waveform)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_add_noise_shaping_+3A_dithered_waveform">dithered_waveform</code></td>
<td>
<p>(Tensor) dithered</p>
</td></tr>
<tr><td><code id="functional_add_noise_shaping_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor) original</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code> of the noise shaped waveform
</p>

<hr>
<h2 id='functional_allpass_biquad'>All-pass Biquad Filter (functional)</h2><span id='topic+functional_allpass_biquad'></span>

<h3>Description</h3>

<p>Design two-pole all-pass filter. Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_allpass_biquad(waveform, sample_rate, central_freq, Q = 0.707)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_allpass_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_allpass_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_allpass_biquad_+3A_central_freq">central_freq</code></td>
<td>
<p>(float): central frequency (in Hz)</p>
</td></tr>
<tr><td><code id="functional_allpass_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_amplitude_to_db'>Amplitude to DB (functional)</h2><span id='topic+functional_amplitude_to_db'></span>

<h3>Description</h3>

<p>Turn a tensor from the power/amplitude scale to the decibel scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_amplitude_to_db(x, multiplier, amin, db_multiplier, top_db = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_amplitude_to_db_+3A_x">x</code></td>
<td>
<p>(Tensor): Input tensor before being converted to decibel scale</p>
</td></tr>
<tr><td><code id="functional_amplitude_to_db_+3A_multiplier">multiplier</code></td>
<td>
<p>(float): Use 10.0 for power and 20.0 for amplitude (Default: <code>10.0</code>)</p>
</td></tr>
<tr><td><code id="functional_amplitude_to_db_+3A_amin">amin</code></td>
<td>
<p>(float): Number to clamp <code>x</code> (Default: <code>1e-10</code>)</p>
</td></tr>
<tr><td><code id="functional_amplitude_to_db_+3A_db_multiplier">db_multiplier</code></td>
<td>
<p>(float): Log10(max(ref_value and amin))</p>
</td></tr>
<tr><td><code id="functional_amplitude_to_db_+3A_top_db">top_db</code></td>
<td>
<p>(float or NULL, optional): Minimum negative cut-off in decibels. A reasonable number
is 80. (Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This output depends on the maximum value in the input tensor, and so
may return different values for an audio clip split into snippets vs. a
a full clip.
</p>


<h3>Value</h3>

<p><code>tensor</code>: Output tensor in decibel scale
</p>

<hr>
<h2 id='functional_angle'>Angle (functional)</h2><span id='topic+functional_angle'></span>

<h3>Description</h3>

<p>Compute the angle of complex tensor input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_angle(complex_tensor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_angle_+3A_complex_tensor">complex_tensor</code></td>
<td>
<p>(Tensor): Tensor shape of <code style="white-space: pre;">&#8288;(..., complex=2)&#8288;</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Angle of a complex tensor. Shape of <code style="white-space: pre;">&#8288;(..., )&#8288;</code>
</p>

<hr>
<h2 id='functional_apply_probability_distribution'>Probability Distribution Apply (functional)</h2><span id='topic+functional_apply_probability_distribution'></span>

<h3>Description</h3>

<p>Apply a probability distribution function on a waveform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_apply_probability_distribution(waveform, density_function = "TPDF")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_apply_probability_distribution_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., time)</p>
</td></tr>
<tr><td><code id="functional_apply_probability_distribution_+3A_density_function">density_function</code></td>
<td>
<p>(str, optional): The density function of a
continuous random variable  (Default: <code>"TPDF"</code>)
Options: Triangular Probability Density Function - <code>TPDF</code>
Rectangular Probability Density Function - <code>RPDF</code>
Gaussian Probability Density Function - <code>GPDF</code></p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><strong>Triangular</strong> probability density function  (TPDF) dither noise has a
triangular distribution; values in the center of the range have a higher
probability of occurring.
</p>
</li>
<li> <p><strong>Rectangular</strong> probability density function  (RPDF) dither noise has a
uniform distribution; any value in the specified range has the same
probability of occurring.
</p>
</li>
<li> <p><strong>Gaussian</strong> probability density function  (GPDF) has a normal distribution.
The relationship of probabilities of results follows a bell-shaped,
or Gaussian curve, typical of dither generated by analog sources.
</p>
</li></ul>



<h3>Value</h3>

<p><code>tensor</code>: waveform dithered with TPDF
</p>

<hr>
<h2 id='functional_band_biquad'>Two-pole Band Filter (functional)</h2><span id='topic+functional_band_biquad'></span>

<h3>Description</h3>

<p>Design two-pole band filter.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_band_biquad(
  waveform,
  sample_rate,
  central_freq,
  Q = 0.707,
  noise = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_band_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_band_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_band_biquad_+3A_central_freq">central_freq</code></td>
<td>
<p>(float): central frequency (in Hz)</p>
</td></tr>
<tr><td><code id="functional_band_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): https://en.wikipedia.org/wiki/Q_factor (Default: <code>0.707</code>).</p>
</td></tr>
<tr><td><code id="functional_band_biquad_+3A_noise">noise</code></td>
<td>
<p>(bool, optional) : If <code>TRUE</code>, uses the alternate mode for un-pitched audio
(e.g. percussion). If <code>FALSE</code>, uses mode oriented to pitched audio, i.e. voice, singing,
or instrumental music  (Default: <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_bandpass_biquad'>Band-pass Biquad Filter (functional)</h2><span id='topic+functional_bandpass_biquad'></span>

<h3>Description</h3>

<p>Design two-pole band-pass filter.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_bandpass_biquad(
  waveform,
  sample_rate,
  central_freq,
  Q = 0.707,
  const_skirt_gain = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_bandpass_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_bandpass_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_bandpass_biquad_+3A_central_freq">central_freq</code></td>
<td>
<p>(float): central frequency (in Hz)</p>
</td></tr>
<tr><td><code id="functional_bandpass_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>)</p>
</td></tr>
<tr><td><code id="functional_bandpass_biquad_+3A_const_skirt_gain">const_skirt_gain</code></td>
<td>
<p>(bool, optional) : If <code>TRUE</code>, uses a constant skirt gain (peak gain = Q).
If <code>FALSE</code>, uses a constant 0dB peak gain.  (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_bandreject_biquad'>Band-reject Biquad Filter (functional)</h2><span id='topic+functional_bandreject_biquad'></span>

<h3>Description</h3>

<p>Design two-pole band-reject filter.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_bandreject_biquad(waveform, sample_rate, central_freq, Q = 0.707)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_bandreject_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_bandreject_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_bandreject_biquad_+3A_central_freq">central_freq</code></td>
<td>
<p>(float): central frequency (in Hz)</p>
</td></tr>
<tr><td><code id="functional_bandreject_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_bass_biquad'>Bass Tone-control Effect (functional)</h2><span id='topic+functional_bass_biquad'></span>

<h3>Description</h3>

<p>Design a bass tone-control effect.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_bass_biquad(
  waveform,
  sample_rate,
  gain,
  central_freq = 100,
  Q = 0.707
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_bass_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_bass_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_bass_biquad_+3A_gain">gain</code></td>
<td>
<p>(float): desired gain at the boost (or attenuation) in dB.</p>
</td></tr>
<tr><td><code id="functional_bass_biquad_+3A_central_freq">central_freq</code></td>
<td>
<p>(float, optional): central frequency (in Hz). (Default: <code>100</code>)</p>
</td></tr>
<tr><td><code id="functional_bass_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_biquad'>Biquad Filter (functional)</h2><span id='topic+functional_biquad'></span>

<h3>Description</h3>

<p>Perform a biquad filter of input tensor.  Initial conditions set to 0.
<a href="https://en.wikipedia.org/wiki/Digital_biquad_filter">https://en.wikipedia.org/wiki/Digital_biquad_filter</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_biquad(waveform, b0, b1, b2, a0, a1, a2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_biquad_+3A_b0">b0</code></td>
<td>
<p>(float): numerator coefficient of current input, x[n]</p>
</td></tr>
<tr><td><code id="functional_biquad_+3A_b1">b1</code></td>
<td>
<p>(float): numerator coefficient of input one time step ago x[n-1]</p>
</td></tr>
<tr><td><code id="functional_biquad_+3A_b2">b2</code></td>
<td>
<p>(float): numerator coefficient of input two time steps ago x[n-2]</p>
</td></tr>
<tr><td><code id="functional_biquad_+3A_a0">a0</code></td>
<td>
<p>(float): denominator coefficient of current output y[n], typically 1</p>
</td></tr>
<tr><td><code id="functional_biquad_+3A_a1">a1</code></td>
<td>
<p>(float): denominator coefficient of current output y[n-1]</p>
</td></tr>
<tr><td><code id="functional_biquad_+3A_a2">a2</code></td>
<td>
<p>(float): denominator coefficient of current output y[n-2]</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform with dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>

<hr>
<h2 id='functional_complex_norm'>Complex Norm (functional)</h2><span id='topic+functional_complex_norm'></span>

<h3>Description</h3>

<p>Compute the norm of complex tensor input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_complex_norm(complex_tensor, power = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_complex_norm_+3A_complex_tensor">complex_tensor</code></td>
<td>
<p>(tensor): Tensor shape of <code style="white-space: pre;">&#8288;(..., complex=2)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_complex_norm_+3A_power">power</code></td>
<td>
<p>(numeric): Power of the norm. (Default: <code>1.0</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Power of the normed input tensor. Shape of <code style="white-space: pre;">&#8288;(..., )&#8288;</code>
</p>

<hr>
<h2 id='functional_compute_deltas'>Delta Coefficients (functional)</h2><span id='topic+functional_compute_deltas'></span>

<h3>Description</h3>

<p>Compute delta coefficients of a tensor, usually a spectrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_compute_deltas(specgram, win_length = 5, mode = "replicate")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_compute_deltas_+3A_specgram">specgram</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., freq, time)</p>
</td></tr>
<tr><td><code id="functional_compute_deltas_+3A_win_length">win_length</code></td>
<td>
<p>(int, optional): The window length used for computing delta (Default: <code>5</code>)</p>
</td></tr>
<tr><td><code id="functional_compute_deltas_+3A_mode">mode</code></td>
<td>
<p>(str, optional): Mode parameter passed to padding (Default: <code>"replicate"</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>math:
</p>
<p style="text-align: center;"><code class="reqn">d_t = \frac{\sum_{n=1}^{N} n  (c_{t+n} - c_{t-n})}{2 \sum_{n=1}^{N} n^2}</code>
</p>

<p>where <code>d_t</code> is the deltas at time <code>t</code>, <code>c_t</code> is the spectrogram coeffcients at time <code>t</code>,
<code>N</code> is <code> (win_length-1) %/% 2</code>.
</p>


<h3>Value</h3>

<p><code>tensor</code>: Tensor of deltas of dimension (..., freq, time)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
library(torch)
library(torchaudio)
specgram = torch_randn(1, 40, 1000)
delta = functional_compute_deltas(specgram)
delta2 = functional_compute_deltas(delta)
}

</code></pre>

<hr>
<h2 id='functional_contrast'>Contrast Effect (functional)</h2><span id='topic+functional_contrast'></span>

<h3>Description</h3>

<p>Apply contrast effect.  Similar to SoX implementation.
Comparable with compression, this effect modifies an audio signal to
make it sound louder
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_contrast(waveform, enhancement_amount = 75)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_contrast_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_contrast_+3A_enhancement_amount">enhancement_amount</code></td>
<td>
<p>(float): controls the amount of the enhancement
Allowed range of values for enhancement_amount : 0-100
Note that enhancement_amount = 0 still gives a significant contrast enhancement</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_create_dct'>DCT transformation matrix (functional)</h2><span id='topic+functional_create_dct'></span>

<h3>Description</h3>

<p>Create a DCT transformation matrix with shape (<code>n_mels</code>, <code>n_mfcc</code>),
normalized depending on norm.
<a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">https://en.wikipedia.org/wiki/Discrete_cosine_transform</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_create_dct(n_mfcc, n_mels, norm = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_create_dct_+3A_n_mfcc">n_mfcc</code></td>
<td>
<p>(int): Number of mfc coefficients to retain</p>
</td></tr>
<tr><td><code id="functional_create_dct_+3A_n_mels">n_mels</code></td>
<td>
<p>(int): Number of mel filterbanks</p>
</td></tr>
<tr><td><code id="functional_create_dct_+3A_norm">norm</code></td>
<td>
<p>(chr or NULL): Norm to use (either 'ortho' or NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: The transformation matrix, to be right-multiplied to
row-wise data of size (<code>n_mels</code>, <code>n_mfcc</code>).
</p>

<hr>
<h2 id='functional_create_fb_matrix'>Frequency Bin Conversion Matrix (functional)</h2><span id='topic+functional_create_fb_matrix'></span>

<h3>Description</h3>

<p>Create a frequency bin conversion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_create_fb_matrix(
  n_freqs,
  f_min,
  f_max,
  n_mels,
  sample_rate,
  norm = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_create_fb_matrix_+3A_n_freqs">n_freqs</code></td>
<td>
<p>(int): Number of frequencies to highlight/apply</p>
</td></tr>
<tr><td><code id="functional_create_fb_matrix_+3A_f_min">f_min</code></td>
<td>
<p>(float): Minimum frequency (Hz)</p>
</td></tr>
<tr><td><code id="functional_create_fb_matrix_+3A_f_max">f_max</code></td>
<td>
<p>(float or NULL): Maximum frequency (Hz). If NULL defaults to sample_rate %/% 2</p>
</td></tr>
<tr><td><code id="functional_create_fb_matrix_+3A_n_mels">n_mels</code></td>
<td>
<p>(int): Number of mel filterbanks</p>
</td></tr>
<tr><td><code id="functional_create_fb_matrix_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): Sample rate of the audio waveform</p>
</td></tr>
<tr><td><code id="functional_create_fb_matrix_+3A_norm">norm</code></td>
<td>
<p>(chr) (Optional): If 'slaney', divide the triangular
mel weights by the width of the mel band (area normalization). (Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Triangular filter banks (fb matrix) of size (<code>n_freqs</code>, <code>n_mels</code>)
meaning number of frequencies to highlight/apply to x the number of filterbanks.
Each column is a filterbank so that assuming there is a matrix A of
size (..., <code>n_freqs</code>), the applied result would be
<code>A * functional_create_fb_matrix(A.size(-1), ...)</code>.
</p>

<hr>
<h2 id='functional_db_to_amplitude'>DB to Amplitude (functional)</h2><span id='topic+functional_db_to_amplitude'></span>

<h3>Description</h3>

<p>Turn a tensor from the decibel scale to the power/amplitude scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_db_to_amplitude(x, ref, power)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_db_to_amplitude_+3A_x">x</code></td>
<td>
<p>(Tensor): Input tensor before being converted to power/amplitude scale.</p>
</td></tr>
<tr><td><code id="functional_db_to_amplitude_+3A_ref">ref</code></td>
<td>
<p>(float): Reference which the output will be scaled by. (Default: <code>1.0</code>)</p>
</td></tr>
<tr><td><code id="functional_db_to_amplitude_+3A_power">power</code></td>
<td>
<p>(float): If power equals 1, will compute DB to power. If 0.5, will compute
DB to amplitude. (Default: <code>1.0</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Output tensor in power/amplitude scale.
</p>

<hr>
<h2 id='functional_dcshift'>DC Shift (functional)</h2><span id='topic+functional_dcshift'></span>

<h3>Description</h3>

<p>Apply a DC shift to the audio. Similar to SoX implementation.
This can be useful to remove a DC offset (caused perhaps by a
hardware problem in the recording chain) from the audio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_dcshift(waveform, shift, limiter_gain = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_dcshift_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_dcshift_+3A_shift">shift</code></td>
<td>
<p>(float): indicates the amount to shift the audio
Allowed range of values for shift : -2.0 to +2.0</p>
</td></tr>
<tr><td><code id="functional_dcshift_+3A_limiter_gain">limiter_gain</code></td>
<td>
<p>(float): It is used only on peaks to prevent clipping
It should have a value much less than 1  (e.g. 0.05 or 0.02)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_deemph_biquad'>ISO 908 CD De-emphasis IIR Filter (functional)</h2><span id='topic+functional_deemph_biquad'></span>

<h3>Description</h3>

<p>Apply ISO 908 CD de-emphasis (shelving) IIR filter.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_deemph_biquad(waveform, sample_rate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_deemph_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_deemph_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, Allowed sample rate <code>44100</code> or <code>48000</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_detect_pitch_frequency'>Detect Pitch Frequency (functional)</h2><span id='topic+functional_detect_pitch_frequency'></span>

<h3>Description</h3>

<p>It is implemented using normalized cross-correlation function and median smoothing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_detect_pitch_frequency(
  waveform,
  sample_rate,
  frame_time = 10^(-2),
  win_length = 30,
  freq_low = 85,
  freq_high = 3400
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_detect_pitch_frequency_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., freq, time)</p>
</td></tr>
<tr><td><code id="functional_detect_pitch_frequency_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): The sample rate of the waveform (Hz)</p>
</td></tr>
<tr><td><code id="functional_detect_pitch_frequency_+3A_frame_time">frame_time</code></td>
<td>
<p>(float, optional): Duration of a frame (Default: <code>10 ** (-2)</code>).</p>
</td></tr>
<tr><td><code id="functional_detect_pitch_frequency_+3A_win_length">win_length</code></td>
<td>
<p>(int, optional): The window length for median smoothing (in number of frames) (Default: <code>30</code>).</p>
</td></tr>
<tr><td><code id="functional_detect_pitch_frequency_+3A_freq_low">freq_low</code></td>
<td>
<p>(int, optional): Lowest frequency that can be detected (Hz) (Default: <code>85</code>).</p>
</td></tr>
<tr><td><code id="functional_detect_pitch_frequency_+3A_freq_high">freq_high</code></td>
<td>
<p>(int, optional): Highest frequency that can be detected (Hz) (Default: <code>3400</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor: Tensor of freq of dimension (..., frame)
</p>

<hr>
<h2 id='functional_dither'>Dither (functional)</h2><span id='topic+functional_dither'></span>

<h3>Description</h3>

<p>Dither increases the perceived dynamic range of audio stored at a
particular bit-depth by eliminating nonlinear truncation distortion
(i.e. adding minimally perceived noise to mask distortion caused by quantization).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_dither(waveform, density_function = "TPDF", noise_shaping = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_dither_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., time)</p>
</td></tr>
<tr><td><code id="functional_dither_+3A_density_function">density_function</code></td>
<td>
<p>(str, optional): The density function of a continuous random variable (Default: <code>"TPDF"</code>)
Options: Triangular Probability Density Function - <code>TPDF</code>
Rectangular Probability Density Function - <code>RPDF</code>
Gaussian Probability Density Function - <code>GPDF</code></p>
</td></tr>
<tr><td><code id="functional_dither_+3A_noise_shaping">noise_shaping</code></td>
<td>
<p>(bool, optional): a filtering process that shapes the spectral
energy of quantisation error  (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: waveform dithered
</p>

<hr>
<h2 id='functional_equalizer_biquad'>Biquad Peaking Equalizer Filter (functional)</h2><span id='topic+functional_equalizer_biquad'></span>

<h3>Description</h3>

<p>Design biquad peaking equalizer filter and perform filtering.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_equalizer_biquad(
  waveform,
  sample_rate,
  center_freq,
  gain,
  Q = 0.707
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_equalizer_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_equalizer_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_equalizer_biquad_+3A_center_freq">center_freq</code></td>
<td>
<p>(float): filter's central frequency</p>
</td></tr>
<tr><td><code id="functional_equalizer_biquad_+3A_gain">gain</code></td>
<td>
<p>(float): desired gain at the boost (or attenuation) in dB</p>
</td></tr>
<tr><td><code id="functional_equalizer_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>

<hr>
<h2 id='functional_flanger'>Flanger Effect (functional)</h2><span id='topic+functional_flanger'></span>

<h3>Description</h3>

<p>Apply a flanger effect to the audio. Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_flanger(
  waveform,
  sample_rate,
  delay = 0,
  depth = 2,
  regen = 0,
  width = 71,
  speed = 0.5,
  phase = 25,
  modulation = "sinusoidal",
  interpolation = "linear"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_flanger_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., channel, time)&#8288;</code> .
Max 4 channels allowed</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_delay">delay</code></td>
<td>
<p>(float): desired delay in milliseconds(ms).
Allowed range of values are 0 to 30</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_depth">depth</code></td>
<td>
<p>(float): desired delay depth in milliseconds(ms).
Allowed range of values are 0 to 10</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_regen">regen</code></td>
<td>
<p>(float): desired regen(feeback gain) in dB.
Allowed range of values are -95 to 95</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_width">width</code></td>
<td>
<p>(float):  desired width(delay gain) in dB.
Allowed range of values are 0 to 100</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_speed">speed</code></td>
<td>
<p>(float):  modulation speed in Hz.
Allowed range of values are 0.1 to 10</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_phase">phase</code></td>
<td>
<p>(float):  percentage phase-shift for multi-channel.
Allowed range of values are 0 to 100</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_modulation">modulation</code></td>
<td>
<p>(str):  Use either &quot;sinusoidal&quot; or &quot;triangular&quot; modulation. (Default: <code>sinusoidal</code>)</p>
</td></tr>
<tr><td><code id="functional_flanger_+3A_interpolation">interpolation</code></td>
<td>
<p>(str): Use either &quot;linear&quot; or &quot;quadratic&quot; for delay-line interpolation. (Default: <code>linear</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., channel, time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li><p> Scott Lehman, Effects Explained, <a href="https://web.archive.org/web/20051125072557/http://www.harmony-central.com/Effects/effects-explained.html">https://web.archive.org/web/20051125072557/http://www.harmony-central.com/Effects/effects-explained.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_gain'>Gain (functional)</h2><span id='topic+functional_gain'></span>

<h3>Description</h3>

<p>Apply amplification or attenuation to the whole waveform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_gain(waveform, gain_db = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_gain_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., time).</p>
</td></tr>
<tr><td><code id="functional_gain_+3A_gain_db">gain_db</code></td>
<td>
<p>(float, optional) Gain adjustment in decibels (dB) (Default: <code>1.0</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: the whole waveform amplified by gain_db.
</p>

<hr>
<h2 id='functional_griffinlim'>Griffin-Lim Transformation (functional)</h2><span id='topic+functional_griffinlim'></span>

<h3>Description</h3>

<p>Compute waveform from a linear scale magnitude spectrogram using the Griffin-Lim transformation.
Implementation ported from <code>librosa</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_griffinlim(
  specgram,
  window,
  n_fft,
  hop_length,
  win_length,
  power,
  normalized,
  n_iter,
  momentum,
  length,
  rand_init
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_griffinlim_+3A_specgram">specgram</code></td>
<td>
<p>(Tensor): A magnitude-only STFT spectrogram of dimension (..., freq, frames)
where freq is <code>n_fft %/% 2 + 1</code>.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_window">window</code></td>
<td>
<p>(Tensor): Window tensor that is applied/multiplied to each frame/window</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_n_fft">n_fft</code></td>
<td>
<p>(int): Size of FFT, creates <code>n_fft %/% 2 + 1</code> bins</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_hop_length">hop_length</code></td>
<td>
<p>(int): Length of hop between STFT windows.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_win_length">win_length</code></td>
<td>
<p>(int): Window size.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_power">power</code></td>
<td>
<p>(float): Exponent for the magnitude spectrogram,
(must be &gt; 0) e.g., 1 for energy, 2 for power, etc.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_normalized">normalized</code></td>
<td>
<p>(bool): Whether to normalize by magnitude after stft.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_n_iter">n_iter</code></td>
<td>
<p>(int): Number of iteration for phase recovery process.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_momentum">momentum</code></td>
<td>
<p>(float): The momentum parameter for fast Griffin-Lim.
Setting this to 0 recovers the original Griffin-Lim method.
Values near 1 can lead to faster convergence, but above 1 may not converge.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_length">length</code></td>
<td>
<p>(int or NULL): Array length of the expected output.</p>
</td></tr>
<tr><td><code id="functional_griffinlim_+3A_rand_init">rand_init</code></td>
<td>
<p>(bool): Initializes phase randomly if TRUE, to zero otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: waveform of (..., time), where time equals the <code>length</code> parameter if given.
</p>

<hr>
<h2 id='functional_highpass_biquad'>High-pass Biquad Filter (functional)</h2><span id='topic+functional_highpass_biquad'></span>

<h3>Description</h3>

<p>Design biquad highpass filter and perform filtering.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_highpass_biquad(waveform, sample_rate, cutoff_freq, Q = 0.707)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_highpass_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_highpass_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_highpass_biquad_+3A_cutoff_freq">cutoff_freq</code></td>
<td>
<p>(float): filter cutoff frequency</p>
</td></tr>
<tr><td><code id="functional_highpass_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>

<hr>
<h2 id='functional_lfilter'>An IIR Filter (functional)</h2><span id='topic+functional_lfilter'></span>

<h3>Description</h3>

<p>Perform an IIR filter by evaluating difference equation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_lfilter(waveform, a_coeffs, b_coeffs, clamp = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_lfilter_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>.  Must be normalized to -1 to 1.</p>
</td></tr>
<tr><td><code id="functional_lfilter_+3A_a_coeffs">a_coeffs</code></td>
<td>
<p>(Tensor): denominator coefficients of difference equation of dimension of <code>(n_order + 1)</code>.
Lower delays coefficients are first, e.g. <code style="white-space: pre;">&#8288;[a0, a1, a2, ...]&#8288;</code>.
Must be same size as b_coeffs (pad with 0's as necessary).</p>
</td></tr>
<tr><td><code id="functional_lfilter_+3A_b_coeffs">b_coeffs</code></td>
<td>
<p>(Tensor): numerator coefficients of difference equation of dimension of <code>(n_order + 1)</code>.
Lower delays coefficients are first, e.g. <code style="white-space: pre;">&#8288;[b0, b1, b2, ...]&#8288;</code>.
Must be same size as a_coeffs (pad with 0's as necessary).</p>
</td></tr>
<tr><td><code id="functional_lfilter_+3A_clamp">clamp</code></td>
<td>
<p>(bool, optional): If <code>TRUE</code>, clamp the output signal to be in the range [-1, 1] (Default: <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform with dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>.
</p>

<hr>
<h2 id='functional_lowpass_biquad'>Low-pass Biquad Filter (functional)</h2><span id='topic+functional_lowpass_biquad'></span>

<h3>Description</h3>

<p>Design biquad lowpass filter and perform filtering.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_lowpass_biquad(waveform, sample_rate, cutoff_freq, Q = 0.707)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_lowpass_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(torch.Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_lowpass_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_lowpass_biquad_+3A_cutoff_freq">cutoff_freq</code></td>
<td>
<p>(float): filter cutoff frequency</p>
</td></tr>
<tr><td><code id="functional_lowpass_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>

<hr>
<h2 id='functional_magphase'>Magnitude and Phase (functional)</h2><span id='topic+functional_magphase'></span>

<h3>Description</h3>

<p>Separate a complex-valued spectrogram with shape <code style="white-space: pre;">&#8288;(.., 2)&#8288;</code> into its magnitude and phase.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_magphase(complex_tensor, power = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_magphase_+3A_complex_tensor">complex_tensor</code></td>
<td>
<p>(Tensor): Tensor shape of <code style="white-space: pre;">&#8288;(.., complex=2)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_magphase_+3A_power">power</code></td>
<td>
<p>(float): Power of the norm. (Default: <code>1.0</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>list(<code>tensor</code>, <code>tensor</code>): The magnitude and phase of the complex tensor
</p>

<hr>
<h2 id='functional_mask_along_axis'>Mask Along Axis (functional)</h2><span id='topic+functional_mask_along_axis'></span>

<h3>Description</h3>

<p>Apply a mask along <code>axis</code>. Mask will be applied from indices <code style="white-space: pre;">&#8288;[v_0, v_0 + v)&#8288;</code>, where
<code>v</code> is sampled from <code>uniform (0, mask_param)</code>, and <code>v_0</code> from <code>uniform(0, max_v - v)</code>.
All examples will have the same mask interval.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_mask_along_axis(specgram, mask_param, mask_value, axis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_mask_along_axis_+3A_specgram">specgram</code></td>
<td>
<p>(Tensor): Real spectrogram (channel, freq, time)</p>
</td></tr>
<tr><td><code id="functional_mask_along_axis_+3A_mask_param">mask_param</code></td>
<td>
<p>(int): Number of columns to be masked will be uniformly sampled from <code style="white-space: pre;">&#8288;[0, mask_param]&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_mask_along_axis_+3A_mask_value">mask_value</code></td>
<td>
<p>(float): Value to assign to the masked columns</p>
</td></tr>
<tr><td><code id="functional_mask_along_axis_+3A_axis">axis</code></td>
<td>
<p>(int): Axis to apply masking on (2 -&gt; frequency, 3 -&gt; time)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor: Masked spectrogram of dimensions (channel, freq, time)
</p>

<hr>
<h2 id='functional_mask_along_axis_iid'>Mask Along Axis IID (functional)</h2><span id='topic+functional_mask_along_axis_iid'></span>

<h3>Description</h3>

<p>Apply a mask along <code>axis</code>. Mask will be applied from indices <code style="white-space: pre;">&#8288;[v_0, v_0 + v)&#8288;</code>, where
<code>v</code> is sampled from <code>uniform (0, mask_param)</code>, and <code>v_0</code> from <code>uniform(0, max_v - v)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_mask_along_axis_iid(specgrams, mask_param, mask_value, axis)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_mask_along_axis_iid_+3A_specgrams">specgrams</code></td>
<td>
<p>(Tensor): Real spectrograms (batch, channel, freq, time)</p>
</td></tr>
<tr><td><code id="functional_mask_along_axis_iid_+3A_mask_param">mask_param</code></td>
<td>
<p>(int): Number of columns to be masked will be uniformly sampled from <code style="white-space: pre;">&#8288;[0, mask_param]&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_mask_along_axis_iid_+3A_mask_value">mask_value</code></td>
<td>
<p>(float): Value to assign to the masked columns</p>
</td></tr>
<tr><td><code id="functional_mask_along_axis_iid_+3A_axis">axis</code></td>
<td>
<p>(int): Axis to apply masking on (3 -&gt; frequency, 4 -&gt; time)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Masked spectrograms of dimensions (batch, channel, freq, time)
</p>

<hr>
<h2 id='functional_mel_scale'>Mel Scale (functional)</h2><span id='topic+functional_mel_scale'></span>

<h3>Description</h3>

<p>Turn a normal STFT into a mel frequency STFT, using a conversion
matrix. This uses triangular filter banks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_mel_scale(
  specgram,
  n_mels = 128,
  sample_rate = 16000,
  f_min = 0,
  f_max = NULL,
  n_stft = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_mel_scale_+3A_specgram">specgram</code></td>
<td>
<p>(Tensor): A spectrogram STFT of dimension (..., freq, time).</p>
</td></tr>
<tr><td><code id="functional_mel_scale_+3A_n_mels">n_mels</code></td>
<td>
<p>(int, optional): Number of mel filterbanks. (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="functional_mel_scale_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int, optional): Sample rate of audio signal. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="functional_mel_scale_+3A_f_min">f_min</code></td>
<td>
<p>(float, optional): Minimum frequency. (Default: <code>0.</code>)</p>
</td></tr>
<tr><td><code id="functional_mel_scale_+3A_f_max">f_max</code></td>
<td>
<p>(float or NULL, optional): Maximum frequency. (Default: <code>sample_rate %/% 2</code>)</p>
</td></tr>
<tr><td><code id="functional_mel_scale_+3A_n_stft">n_stft</code></td>
<td>
<p>(int, optional): Number of bins in STFT. Calculated from first input
if NULL is given.  See <code>n_fft</code> in :class:<code>Spectrogram</code>. (Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Mel frequency spectrogram of size (..., <code>n_mels</code>, time).
</p>

<hr>
<h2 id='functional_mu_law_decoding'>Mu Law Decoding (functional)</h2><span id='topic+functional_mu_law_decoding'></span>

<h3>Description</h3>

<p>Decode mu-law encoded signal.  For more info see the
<a href="https://en.wikipedia.org/wiki/M-law_algorithm">Wikipedia Entry</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_mu_law_decoding(x_mu, quantization_channels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_mu_law_decoding_+3A_x_mu">x_mu</code></td>
<td>
<p>(Tensor): Input tensor</p>
</td></tr>
<tr><td><code id="functional_mu_law_decoding_+3A_quantization_channels">quantization_channels</code></td>
<td>
<p>(int): Number of channels</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This expects an input with values between 0 and quantization_channels - 1
and returns a signal scaled between -1 and 1.
</p>


<h3>Value</h3>

<p><code>tensor</code>: Input after mu-law decoding
</p>

<hr>
<h2 id='functional_mu_law_encoding'>Mu Law Encoding (functional)</h2><span id='topic+functional_mu_law_encoding'></span>

<h3>Description</h3>

<p>Encode signal based on mu-law companding.  For more info see
the <a href="https://en.wikipedia.org/wiki/M-law_algorithm">Wikipedia Entry</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_mu_law_encoding(x, quantization_channels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_mu_law_encoding_+3A_x">x</code></td>
<td>
<p>(Tensor): Input tensor</p>
</td></tr>
<tr><td><code id="functional_mu_law_encoding_+3A_quantization_channels">quantization_channels</code></td>
<td>
<p>(int): Number of channels</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm assumes the signal has been scaled to between -1 and 1 and
returns a signal encoded with values from 0 to quantization_channels - 1.
</p>


<h3>Value</h3>

<p><code>tensor</code>: Input after mu-law encoding
</p>

<hr>
<h2 id='functional_overdrive'>Overdrive Effect (functional)</h2><span id='topic+functional_overdrive'></span>

<h3>Description</h3>

<p>Apply a overdrive effect to the audio. Similar to SoX implementation.
This effect applies a non linear distortion to the audio signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_overdrive(waveform, gain = 20, colour = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_overdrive_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_overdrive_+3A_gain">gain</code></td>
<td>
<p>(float): desired gain at the boost (or attenuation) in dB
Allowed range of values are 0 to 100</p>
</td></tr>
<tr><td><code id="functional_overdrive_+3A_colour">colour</code></td>
<td>
<p>(float):  controls the amount of even harmonic content in
the over-driven output. Allowed range of values are 0 to 100</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Tensor: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_phase_vocoder'>Phase Vocoder</h2><span id='topic+functional_phase_vocoder'></span>

<h3>Description</h3>

<p>Given a STFT tensor, speed up in time without modifying pitch by a factor of <code>rate</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_phase_vocoder(complex_specgrams, rate, phase_advance)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_phase_vocoder_+3A_complex_specgrams">complex_specgrams</code></td>
<td>
<p>(Tensor): Dimension of <code style="white-space: pre;">&#8288;(..., freq, time, complex=2)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_phase_vocoder_+3A_rate">rate</code></td>
<td>
<p>(float): Speed-up factor</p>
</td></tr>
<tr><td><code id="functional_phase_vocoder_+3A_phase_advance">phase_advance</code></td>
<td>
<p>(Tensor): Expected phase advance in each bin. Dimension of (freq, 1)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Complex Specgrams Stretch with dimension of <code style="white-space: pre;">&#8288;(..., freq, ceiling(time/rate), complex=2)&#8288;</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
library(torch)
library(torchaudio)

freq = 1025
hop_length = 512

#  (channel, freq, time, complex=2)
complex_specgrams = torch_randn(2, freq, 300, 2)
rate = 1.3 # Speed up by 30%
phase_advance = torch_linspace(0, pi * hop_length, freq)[.., NULL]
x = functional_phase_vocoder(complex_specgrams, rate, phase_advance)
x$shape # with 231 == ceil (300 / 1.3)
# torch.Size ([2, 1025, 231, 2])
}

</code></pre>

<hr>
<h2 id='functional_phaser'>Phasing Effect (functional)</h2><span id='topic+functional_phaser'></span>

<h3>Description</h3>

<p>Apply a phasing effect to the audio. Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_phaser(
  waveform,
  sample_rate,
  gain_in = 0.4,
  gain_out = 0.74,
  delay_ms = 3,
  decay = 0.4,
  mod_speed = 0.5,
  sinusoidal = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_phaser_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_gain_in">gain_in</code></td>
<td>
<p>(float): desired input gain at the boost (or attenuation) in dB.
Allowed range of values are 0 to 1</p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_gain_out">gain_out</code></td>
<td>
<p>(float): desired output gain at the boost (or attenuation) in dB.
Allowed range of values are 0 to 1e9</p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_delay_ms">delay_ms</code></td>
<td>
<p>(float): desired delay in milli seconds.
Allowed range of values are 0 to 5.0</p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_decay">decay</code></td>
<td>
<p>(float):  desired decay relative to gain-in. Allowed range of values are 0 to 0.99</p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_mod_speed">mod_speed</code></td>
<td>
<p>(float):  modulation speed in Hz.
Allowed range of values are 0.1 to 2</p>
</td></tr>
<tr><td><code id="functional_phaser_+3A_sinusoidal">sinusoidal</code></td>
<td>
<p>(bool):  If <code>TRUE</code>, uses sinusoidal modulation (preferable for multiple instruments).
If <code>FALSE</code>, uses triangular modulation  (gives single instruments a sharper phasing effect)
(Default: <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_riaa_biquad'>RIAA Vinyl Playback Equalisation (functional)</h2><span id='topic+functional_riaa_biquad'></span>

<h3>Description</h3>

<p>Apply RIAA vinyl playback equalisation.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_riaa_biquad(waveform, sample_rate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_riaa_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_riaa_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz).
Allowed sample rates in Hz : <code>44100</code>,<code>48000</code>,<code>88200</code>,<code>96000</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_sliding_window_cmn'>sliding-window Cepstral Mean Normalization (functional)</h2><span id='topic+functional_sliding_window_cmn'></span>

<h3>Description</h3>

<p>Apply sliding-window cepstral mean  (and optionally variance) normalization per utterance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_sliding_window_cmn(
  waveform,
  cmn_window = 600,
  min_cmn_window = 100,
  center = FALSE,
  norm_vars = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_sliding_window_cmn_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension (..., freq, time)</p>
</td></tr>
<tr><td><code id="functional_sliding_window_cmn_+3A_cmn_window">cmn_window</code></td>
<td>
<p>(int, optional): Window in frames for running average CMN computation (int, default = 600)</p>
</td></tr>
<tr><td><code id="functional_sliding_window_cmn_+3A_min_cmn_window">min_cmn_window</code></td>
<td>
<p>(int, optional):  Minimum CMN window used at start of decoding (adds latency only at start).
Only applicable if center == <code>FALSE</code>, ignored if center==<code>TRUE</code>  (int, default = 100)</p>
</td></tr>
<tr><td><code id="functional_sliding_window_cmn_+3A_center">center</code></td>
<td>
<p>(bool, optional): If <code>TRUE</code>, use a window centered on the current frame
(to the extent possible, modulo end effects). If <code>FALSE</code>, window is to the left. (bool, default = <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="functional_sliding_window_cmn_+3A_norm_vars">norm_vars</code></td>
<td>
<p>(bool, optional): If <code>TRUE</code>, normalize variance to one. (bool, default = <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Tensor of freq of dimension (..., frame)
</p>

<hr>
<h2 id='functional_spectrogram'>Spectrogram (functional)</h2><span id='topic+functional_spectrogram'></span>

<h3>Description</h3>

<p>Create a spectrogram or a batch of spectrograms from a raw audio signal.
The spectrogram can be either magnitude-only or complex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_spectrogram(
  waveform,
  pad,
  window,
  n_fft,
  hop_length,
  win_length,
  power,
  normalized
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_spectrogram_+3A_waveform">waveform</code></td>
<td>
<p>(tensor): Tensor of audio of dimension (..., time)</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_pad">pad</code></td>
<td>
<p>(integer): Two sided padding of signal</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_window">window</code></td>
<td>
<p>(tensor or function): Window tensor that is applied/multiplied to each
frame/window or a function that generates the window tensor.</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_n_fft">n_fft</code></td>
<td>
<p>(integer): Size of FFT</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_hop_length">hop_length</code></td>
<td>
<p>(integer): Length of hop between STFT windows</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_win_length">win_length</code></td>
<td>
<p>(integer): Window size</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_power">power</code></td>
<td>
<p>(numeric): Exponent for the magnitude spectrogram, (must be &gt; 0) e.g.,
1 for energy, 2 for power, etc. If NULL, then the complex spectrum is returned instead.</p>
</td></tr>
<tr><td><code id="functional_spectrogram_+3A_normalized">normalized</code></td>
<td>
<p>(logical): Whether to normalize by magnitude after stft</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Dimension (..., freq, time), freq is n_fft %/% 2 + 1 and n_fft is the
number of Fourier bins, and time is the number of window hops (n_frame).
</p>

<hr>
<h2 id='functional_treble_biquad'>Treble Tone-control Effect (functional)</h2><span id='topic+functional_treble_biquad'></span>

<h3>Description</h3>

<p>Design a treble tone-control effect.  Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_treble_biquad(
  waveform,
  sample_rate,
  gain,
  central_freq = 3000,
  Q = 0.707
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_treble_biquad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): audio waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_treble_biquad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): sampling rate of the waveform, e.g. 44100 (Hz)</p>
</td></tr>
<tr><td><code id="functional_treble_biquad_+3A_gain">gain</code></td>
<td>
<p>(float): desired gain at the boost (or attenuation) in dB.</p>
</td></tr>
<tr><td><code id="functional_treble_biquad_+3A_central_freq">central_freq</code></td>
<td>
<p>(float, optional): central frequency (in Hz). (Default: <code>3000</code>)</p>
</td></tr>
<tr><td><code id="functional_treble_biquad_+3A_q">Q</code></td>
<td>
<p>(float, optional): <a href="https://en.wikipedia.org/wiki/Q_factor">https://en.wikipedia.org/wiki/Q_factor</a> (Default: <code>0.707</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>: Waveform of dimension of <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li>
<li> <p><a href="https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html">https://webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html</a>
</p>
</li></ul>


<hr>
<h2 id='functional_vad'>Voice Activity Detector (functional)</h2><span id='topic+functional_vad'></span>

<h3>Description</h3>

<p>Voice Activity Detector. Similar to SoX implementation.
Attempts to trim silence and quiet background sounds from the ends of recordings of speech.
The algorithm currently uses a simple cepstral power measurement to detect voice,
so may be fooled by other things, especially music.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>functional_vad(
  waveform,
  sample_rate,
  trigger_level = 7,
  trigger_time = 0.25,
  search_time = 1,
  allowed_gap = 0.25,
  pre_trigger_time = 0,
  boot_time = 0.35,
  noise_up_time = 0.1,
  noise_down_time = 0.01,
  noise_reduction_amount = 1.35,
  measure_freq = 20,
  measure_duration = NULL,
  measure_smooth_time = 0.4,
  hp_filter_freq = 50,
  lp_filter_freq = 6000,
  hp_lifter_freq = 150,
  lp_lifter_freq = 2000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="functional_vad_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): Tensor of audio of dimension <code style="white-space: pre;">&#8288;(..., time)&#8288;</code></p>
</td></tr>
<tr><td><code id="functional_vad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): Sample rate of audio signal.</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_trigger_level">trigger_level</code></td>
<td>
<p>(float, optional): The measurement level used to trigger activity detection.
This may need to be cahnged depending on the noise level, signal level,
and other characteristics of the input audio.  (Default: 7.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_trigger_time">trigger_time</code></td>
<td>
<p>(float, optional): The time constant (in seconds)
used to help ignore short bursts of sound.  (Default: 0.25)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_search_time">search_time</code></td>
<td>
<p>(float, optional): The amount of audio (in seconds)
to search for quieter/shorter bursts of audio to include prior
to the detected trigger point.  (Default: 1.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_allowed_gap">allowed_gap</code></td>
<td>
<p>(float, optional): The allowed gap (in seconds) between
quiteter/shorter bursts of audio to include prior
to the detected trigger point.  (Default: 0.25)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_pre_trigger_time">pre_trigger_time</code></td>
<td>
<p>(float, optional): The amount of audio (in seconds) to preserve
before the trigger point and any found quieter/shorter bursts.  (Default: 0.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_boot_time">boot_time</code></td>
<td>
<p>(float, optional) The algorithm (internally) uses adaptive noise
estimation/reduction in order to detect the start of the wanted audio.
This option sets the time for the initial noise estimate.  (Default: 0.35)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_noise_up_time">noise_up_time</code></td>
<td>
<p>(float, optional) Time constant used by the adaptive noise estimator
for when the noise level is increasing.  (Default: 0.1)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_noise_down_time">noise_down_time</code></td>
<td>
<p>(float, optional) Time constant used by the adaptive noise estimator
for when the noise level is decreasing.  (Default: 0.01)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_noise_reduction_amount">noise_reduction_amount</code></td>
<td>
<p>(float, optional) Amount of noise reduction to use in
the detection algorithm  (e.g. 0, 0.5, ...). (Default: 1.35)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_measure_freq">measure_freq</code></td>
<td>
<p>(float, optional) Frequency of the algorithms
processing/measurements.  (Default: 20.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_measure_duration">measure_duration</code></td>
<td>
<p>(float, optional) Measurement duration.
(Default: Twice the measurement period; i.e. with overlap.)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_measure_smooth_time">measure_smooth_time</code></td>
<td>
<p>(float, optional) Time constant used to smooth
spectral measurements.  (Default: 0.4)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_hp_filter_freq">hp_filter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of high-pass filter applied
at the input to the detector algorithm.  (Default: 50.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_lp_filter_freq">lp_filter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of low-pass filter applied
at the input to the detector algorithm.  (Default: 6000.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_hp_lifter_freq">hp_lifter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of high-pass lifter used
in the detector algorithm.  (Default: 150.0)</p>
</td></tr>
<tr><td><code id="functional_vad_+3A_lp_lifter_freq">lp_lifter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of low-pass lifter used
in the detector algorithm.  (Default: 2000.0)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The effect can trim only from the front of the audio,
so in order to trim from the back, the reverse effect must also be used.
</p>


<h3>Value</h3>

<p>Tensor: Tensor of audio of dimension (..., time).
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li></ul>


<hr>
<h2 id='internal__normalize_audio'>Audio Normalization</h2><span id='topic+internal__normalize_audio'></span>

<h3>Description</h3>

<p>Audio normalization of a tensor in-place.  The normalization can be a bool,
a number, or a function that takes the audio tensor as an input. SoX uses
32-bit signed integers internally, thus bool normalizes based on that assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>internal__normalize_audio(signal, normalization = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="internal__normalize_audio_+3A_signal">signal</code></td>
<td>
<p>(Tensor): waveform</p>
</td></tr>
<tr><td><code id="internal__normalize_audio_+3A_normalization">normalization</code></td>
<td>
<p>(bool, int or function): Optional normalization.
If boolean <code>TRUE</code>, then output is divided by <code>2^31</code>.
Assuming the input is signed 32-bit audio, this normalizes to <code style="white-space: pre;">&#8288;[-1, 1]&#8288;</code>.
If <code>numeric</code>, then output is divided by that number.
If <code>function</code>, then the output is passed as a paramete to the given function,
then the output is divided by the result. (Default: <code>TRUE</code>)</p>
</td></tr>
</table>

<hr>
<h2 id='kaldi__get_lr_indices_and_weights'>Linear Resample Indices And Weights</h2><span id='topic+kaldi__get_lr_indices_and_weights'></span>

<h3>Description</h3>

<p>Based on LinearResample::SetIndexesAndWeights where it retrieves the weights for
resampling as well as the indices in which they are valid. LinearResample  (LR) means
that the output signal is at linearly spaced intervals  (i.e the output signal has a
frequency of <code>new_freq</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kaldi__get_lr_indices_and_weights(
  orig_freq,
  new_freq,
  output_samples_in_unit,
  window_width,
  lowpass_cutoff,
  lowpass_filter_width,
  device,
  dtype
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_orig_freq">orig_freq</code></td>
<td>
<p>(float): The original frequency of the signal</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_new_freq">new_freq</code></td>
<td>
<p>(float): The desired frequency</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_output_samples_in_unit">output_samples_in_unit</code></td>
<td>
<p>(int): The number of output samples in the
smallest repeating unit: num_samp_out = new_freq / Gcd (orig_freq, new_freq)</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_window_width">window_width</code></td>
<td>
<p>(float): The width of the window which is nonzero</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_lowpass_cutoff">lowpass_cutoff</code></td>
<td>
<p>(float): The filter cutoff in Hz. The filter cutoff needs to be less
than samp_rate_in_hz/2 and less than samp_rate_out_hz/2.</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_lowpass_filter_width">lowpass_filter_width</code></td>
<td>
<p>(int): Controls the sharpness of the filter, more == sharper but less
efficient. We suggest around 4 to 10 for normal use.</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_device">device</code></td>
<td>
<p>(torch_device): Torch device on which output must be generated.</p>
</td></tr>
<tr><td><code id="kaldi__get_lr_indices_and_weights_+3A_dtype">dtype</code></td>
<td>
<p>(torch::torch_\&lt;dtype\&gt;): Torch dtype such as <a href="torch.html#topic+torch_dtype">torch::torch_float</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>It uses sinc/bandlimited interpolation to upsample/downsample
the signal.
</p>
<p>The reason why the same filter is not used for multiple convolutions is because the
sinc function could sampled at different points in time. For example, suppose
a signal is sampled at the timestamps  (seconds)
0         16        32
and we want it to be sampled at the timestamps  (seconds)
0 5 10 15   20 25 30  35
at the timestamp of 16, the delta timestamps are
16 11 6 1   4  9  14  19
at the timestamp of 32, the delta timestamps are
32 27 22 17 12 8 2    3
</p>
<p>As we can see from deltas, the sinc function is sampled at different points of time
assuming the center of the sinc function is at 0, 16, and 32  (the deltas [..., 6, 1, 4, ....]
for 16 vs [...., 2, 3, ....] for 32)
</p>
<p>Example, one case is when the <code>orig_freq</code> and <code>new_freq</code> are multiples of each other then
there needs to be one filter.
</p>
<p>A windowed filter function  (i.e. Hanning * sinc) because the ideal case of sinc function
has infinite support  (non-zero for all values) so instead it is truncated and multiplied by
a window function which gives it less-than-perfect rolloff [1].
</p>
<p>[1] Chapter 16: Windowed-Sinc Filters, https://www.dspguide.com/ch16/1.htm
</p>


<h3>Value</h3>

<p>Tensor, Tensor): A tuple of <code>min_input_index</code> (which is the minimum indices
where the window is valid, size  (<code>output_samples_in_unit</code>)) and <code>weights</code> (which is the weights
which correspond with min_input_index, size  (<code>output_samples_in_unit</code>, <code>max_weight_width</code>)).
</p>

<hr>
<h2 id='kaldi__get_num_lr_output_samples'>Linear Resample Output Samples</h2><span id='topic+kaldi__get_num_lr_output_samples'></span>

<h3>Description</h3>

<p>Based on LinearResample::GetNumOutputSamples. LinearResample  (LR) means that
the output signal is at linearly spaced intervals  (i.e the output signal has a
frequency of <code>new_freq</code>). It uses sinc/bandlimited interpolation to upsample/downsample
the signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kaldi__get_num_lr_output_samples(input_num_samp, samp_rate_in, samp_rate_out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kaldi__get_num_lr_output_samples_+3A_input_num_samp">input_num_samp</code></td>
<td>
<p>(int): The number of samples in the input</p>
</td></tr>
<tr><td><code id="kaldi__get_num_lr_output_samples_+3A_samp_rate_in">samp_rate_in</code></td>
<td>
<p>(float): The original frequency of the signal</p>
</td></tr>
<tr><td><code id="kaldi__get_num_lr_output_samples_+3A_samp_rate_out">samp_rate_out</code></td>
<td>
<p>(float): The desired frequency</p>
</td></tr>
</table>


<h3>Value</h3>

<p>int: The number of output samples
</p>

<hr>
<h2 id='kaldi_resample_waveform'>Kaldi's Resample Waveform</h2><span id='topic+kaldi_resample_waveform'></span>

<h3>Description</h3>

<p>Resamples the waveform at the new frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kaldi_resample_waveform(
  waveform,
  orig_freq,
  new_freq,
  lowpass_filter_width = 6
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kaldi_resample_waveform_+3A_waveform">waveform</code></td>
<td>
<p>(Tensor): The input signal of size (c, n)</p>
</td></tr>
<tr><td><code id="kaldi_resample_waveform_+3A_orig_freq">orig_freq</code></td>
<td>
<p>(float): The original frequency of the signal</p>
</td></tr>
<tr><td><code id="kaldi_resample_waveform_+3A_new_freq">new_freq</code></td>
<td>
<p>(float): The desired frequency</p>
</td></tr>
<tr><td><code id="kaldi_resample_waveform_+3A_lowpass_filter_width">lowpass_filter_width</code></td>
<td>
<p>(int, optional): Controls the sharpness of the filter, more == sharper
but less efficient. We suggest around 4 to 10 for normal use.  (Default: <code>6</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This matches Kaldi's OfflineFeatureTpl ResampleWaveform
which uses a LinearResample (resample a signal at linearly spaced intervals to upsample/downsample
a signal). LinearResample (LR) means that the output signal is at linearly spaced intervals (i.e
the output signal has a frequency of <code>new_freq</code>). It uses sinc/bandlimited interpolation to
upsample/downsample the signal.
</p>


<h3>Value</h3>

<p>Tensor: The waveform at the new frequency
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://ccrma.stanford.edu/~jos/resample/Theory_Ideal_Bandlimited_Interpolation.html">https://ccrma.stanford.edu/~jos/resample/Theory_Ideal_Bandlimited_Interpolation.html</a>
</p>
</li>
<li> <p><a href="https://github.com/kaldi-asr/kaldi/blob/master/src/feat/resample.h#L56">https://github.com/kaldi-asr/kaldi/blob/master/src/feat/resample.h#L56</a>
</p>
</li></ul>


<hr>
<h2 id='linear_to_mel_frequency'>Linear to mel frequency</h2><span id='topic+linear_to_mel_frequency'></span>

<h3>Description</h3>

<p>Converts frequencies from the linear scale to mel scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linear_to_mel_frequency(
  frequency_in_hertz,
  mel_break_frequency_hertz = 2595,
  mel_high_frequency_q = 700
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="linear_to_mel_frequency_+3A_frequency_in_hertz">frequency_in_hertz</code></td>
<td>
<p>(numeric) tensor of frequencies in hertz to be converted to mel scale.</p>
</td></tr>
<tr><td><code id="linear_to_mel_frequency_+3A_mel_break_frequency_hertz">mel_break_frequency_hertz</code></td>
<td>
<p>(numeric) scalar. (Default to 2595.0)</p>
</td></tr>
<tr><td><code id="linear_to_mel_frequency_+3A_mel_high_frequency_q">mel_high_frequency_q</code></td>
<td>
<p>(numeric) scalar. (Default to 700.0)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>
</p>

<hr>
<h2 id='list_audio_backends'>List available audio backends</h2><span id='topic+list_audio_backends'></span>

<h3>Description</h3>

<p>List available audio backends
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_audio_backends()
</code></pre>


<h3>Value</h3>

<p>character vector with the list of available backends.
</p>

<hr>
<h2 id='mel_to_linear_frequency'>Mel to linear frequency</h2><span id='topic+mel_to_linear_frequency'></span>

<h3>Description</h3>

<p>Converts frequencies from the mel scale to linear scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mel_to_linear_frequency(
  frequency_in_mel,
  mel_break_frequency_hertz = 2595,
  mel_high_frequency_q = 700
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mel_to_linear_frequency_+3A_frequency_in_mel">frequency_in_mel</code></td>
<td>
<p>(numeric) tensor of frequencies in mel to be converted to linear scale.</p>
</td></tr>
<tr><td><code id="mel_to_linear_frequency_+3A_mel_break_frequency_hertz">mel_break_frequency_hertz</code></td>
<td>
<p>(numeric) scalar. (Default to 2595.0)</p>
</td></tr>
<tr><td><code id="mel_to_linear_frequency_+3A_mel_high_frequency_q">mel_high_frequency_q</code></td>
<td>
<p>(numeric) scalar. (Default to 700.0)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>tensor</code>
</p>

<hr>
<h2 id='model_melresnet'>MelResNet</h2><span id='topic+model_melresnet'></span>

<h3>Description</h3>

<p>MelResNet layer uses a stack of ResBlocks on spectrogram.
Pass the input through the MelResNet layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_melresnet(
  n_res_block = 10,
  n_freq = 128,
  n_hidden = 128,
  n_output = 128,
  kernel_size = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_melresnet_+3A_n_res_block">n_res_block</code></td>
<td>
<p>the number of ResBlock in stack.  (Default: <code>10</code>)</p>
</td></tr>
<tr><td><code id="model_melresnet_+3A_n_freq">n_freq</code></td>
<td>
<p>the number of bins in a spectrogram.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_melresnet_+3A_n_hidden">n_hidden</code></td>
<td>
<p>the number of hidden dimensions of resblock.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_melresnet_+3A_n_output">n_output</code></td>
<td>
<p>the number of output dimensions of melresnet.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_melresnet_+3A_kernel_size">kernel_size</code></td>
<td>
<p>the number of kernel size in the first Conv1d layer.  (Default: <code>5</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): the input sequence to the MelResNet layer (n_batch, n_freq, n_time).
</p>


<h3>Value</h3>

<p>Tensor shape:  (n_batch, n_output, n_time - kernel_size + 1)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(torch::torch_is_installed()) {
 melresnet = model_melresnet()
 input = torch::torch_rand(10, 128, 512)  # a random spectrogram
 output = melresnet(input)  # shape: (10, 128, 508)
}

</code></pre>

<hr>
<h2 id='model_resblock'>ResBlock</h2><span id='topic+model_resblock'></span>

<h3>Description</h3>

<p>ResNet block based on &quot;Deep Residual Learning for Image Recognition&quot;.
Pass the input through the ResBlock layer. The paper link is <a href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_resblock(n_freq = 128)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_resblock_+3A_n_freq">n_freq</code></td>
<td>
<p>the number of bins in a spectrogram.  (Default: <code>128</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): the input sequence to the ResBlock layer (n_batch, n_freq, n_time).
</p>


<h3>Value</h3>

<p>Tensor shape:  (n_batch, n_freq, n_time)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
resblock = model_resblock()
input = torch::torch_rand(10, 128, 512)  # a random spectrogram
output = resblock(input)  # shape: (10, 128, 512)
}
</code></pre>

<hr>
<h2 id='model_stretch2d'>Stretch2d</h2><span id='topic+model_stretch2d'></span>

<h3>Description</h3>

<p>Upscale the frequency and time dimensions of a spectrogram.
Pass the input through the Stretch2d layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_stretch2d(time_scale, freq_scale)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_stretch2d_+3A_time_scale">time_scale</code></td>
<td>
<p>the scale factor in time dimension</p>
</td></tr>
<tr><td><code id="model_stretch2d_+3A_freq_scale">freq_scale</code></td>
<td>
<p>the scale factor in frequency dimension</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): the input sequence to the Stretch2d layer (..., n_freq, n_time).
</p>


<h3>Value</h3>

<p>Tensor shape:  (..., n_freq * freq_scale, n_time * time_scale)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
 stretch2d = model_stretch2d(time_scale=10, freq_scale=5)

 input = torch::torch_rand(10, 100, 512)  # a random spectrogram
 output = stretch2d(input)  # shape: (10, 500, 5120)
}

</code></pre>

<hr>
<h2 id='model_upsample_network'>UpsampleNetwork</h2><span id='topic+model_upsample_network'></span>

<h3>Description</h3>

<p>Upscale the dimensions of a spectrogram.
Pass the input through the UpsampleNetwork layer.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_upsample_network(
  upsample_scales,
  n_res_block = 10,
  n_freq = 128,
  n_hidden = 128,
  n_output = 128,
  kernel_size = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_upsample_network_+3A_upsample_scales">upsample_scales</code></td>
<td>
<p>the list of upsample scales.</p>
</td></tr>
<tr><td><code id="model_upsample_network_+3A_n_res_block">n_res_block</code></td>
<td>
<p>the number of ResBlock in stack.  (Default: <code>10</code>)</p>
</td></tr>
<tr><td><code id="model_upsample_network_+3A_n_freq">n_freq</code></td>
<td>
<p>the number of bins in a spectrogram.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_upsample_network_+3A_n_hidden">n_hidden</code></td>
<td>
<p>the number of hidden dimensions of resblock.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_upsample_network_+3A_n_output">n_output</code></td>
<td>
<p>the number of output dimensions of melresnet.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_upsample_network_+3A_kernel_size">kernel_size</code></td>
<td>
<p>the number of kernel size in the first Conv1d layer.  (Default: <code>5</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): the input sequence to the UpsampleNetwork layer (n_batch, n_freq, n_time)
</p>


<h3>Value</h3>

<p>Tensor shape:  (n_batch, n_freq, (n_time - kernel_size + 1) * total_scale),
(n_batch, n_output, (n_time - kernel_size + 1) * total_scale)
where total_scale is the product of all elements in upsample_scales.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
 upsamplenetwork = model_upsample_network(upsample_scales=c(4, 4, 16))
 input = torch::torch_rand (10, 128, 10)  # a random spectrogram
 output = upsamplenetwork (input)  # shape: (10, 1536, 128), (10, 1536, 128)
}

</code></pre>

<hr>
<h2 id='model_wavernn'>WaveRNN</h2><span id='topic+model_wavernn'></span>

<h3>Description</h3>

<p>WaveRNN model based on the implementation from <a href="https://github.com/fatchord/WaveRNN">fatchord</a>.
The original implementation was introduced in <a href="https://arxiv.org/pdf/1802.08435.pdf">&quot;Efficient Neural Audio Synthesis&quot;</a>.
#' Pass the input through the WaveRNN model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_wavernn(
  upsample_scales,
  n_classes,
  hop_length,
  n_res_block = 10,
  n_rnn = 512,
  n_fc = 512,
  kernel_size = 5,
  n_freq = 128,
  n_hidden = 128,
  n_output = 128
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_wavernn_+3A_upsample_scales">upsample_scales</code></td>
<td>
<p>the list of upsample scales.</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_classes">n_classes</code></td>
<td>
<p>the number of output classes.</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_hop_length">hop_length</code></td>
<td>
<p>the number of samples between the starts of consecutive frames.</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_res_block">n_res_block</code></td>
<td>
<p>the number of ResBlock in stack.  (Default: <code>10</code>)</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_rnn">n_rnn</code></td>
<td>
<p>the dimension of RNN layer.  (Default: <code>512</code>)</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_fc">n_fc</code></td>
<td>
<p>the dimension of fully connected layer.  (Default: <code>512</code>)</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_kernel_size">kernel_size</code></td>
<td>
<p>the number of kernel size in the first Conv1d layer.  (Default: <code>5</code>)</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_freq">n_freq</code></td>
<td>
<p>the number of bins in a spectrogram.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_hidden">n_hidden</code></td>
<td>
<p>the number of hidden dimensions of resblock.  (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="model_wavernn_+3A_n_output">n_output</code></td>
<td>
<p>the number of output dimensions of melresnet.  (Default: <code>128</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
</p>
<p>waveform the input waveform to the WaveRNN layer  (n_batch, 1, (n_time - kernel_size + 1) * hop_length)
</p>
<p>specgram the input spectrogram to the WaveRNN layer  (n_batch, 1, n_freq, n_time)
</p>
<p>The input channels of waveform and spectrogram have to be 1. The product of
<code>upsample_scales</code> must equal <code>hop_length</code>.
</p>


<h3>Value</h3>

<p>Tensor shape:  (n_batch, 1, (n_time - kernel_size + 1) * hop_length, n_classes)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(torch::torch_is_installed()) {
wavernn &lt;- model_wavernn(upsample_scales=c(2,2,3), n_classes=5, hop_length=12)

waveform &lt;- torch::torch_rand(3,1,(10 - 5 + 1)*12)
spectrogram &lt;- torch::torch_rand(3,1,128,10)
# waveform shape:  (n_batch, n_channel, (n_time - kernel_size + 1) * hop_length)
output &lt;- wavernn(waveform, spectrogram)
}
</code></pre>

<hr>
<h2 id='speechcommand_dataset'>Speech Commands Dataset</h2><span id='topic+speechcommand_dataset'></span>

<h3>Description</h3>

<p>Speech Commands Dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>speechcommand_dataset(
  root,
  url = "speech_commands_v0.02",
  folder_in_archive = "SpeechCommands",
  download = FALSE,
  normalization = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="speechcommand_dataset_+3A_root">root</code></td>
<td>
<p>(str): Path to the directory where the dataset is found or downloaded.</p>
</td></tr>
<tr><td><code id="speechcommand_dataset_+3A_url">url</code></td>
<td>
<p>(str, optional): The URL to download the dataset from,
or the type of the dataset to dowload.
Allowed type values are <code>"speech_commands_v0.01"</code> and <code>"speech_commands_v0.02"</code>
(default: <code>"speech_commands_v0.02"</code>)</p>
</td></tr>
<tr><td><code id="speechcommand_dataset_+3A_folder_in_archive">folder_in_archive</code></td>
<td>
<p>(str, optional): The top-level directory of the dataset.  (default: <code>"SpeechCommands"</code>)</p>
</td></tr>
<tr><td><code id="speechcommand_dataset_+3A_download">download</code></td>
<td>
<p>(bool, optional): Whether to download the dataset if it is not found at root path.  (default: <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="speechcommand_dataset_+3A_normalization">normalization</code></td>
<td>
<p>(NULL, bool, int or function): Optional normalization.
If boolean TRUE, then output is divided by 2^31. Assuming the input is signed 32-bit audio,
this normalizes to [-1, 1]. If numeric, then output is divided by that number.
If function, then the output is passed as a paramete to the given function,
then the output is divided by the result. (Default: NULL)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a torch::dataset()
</p>

<hr>
<h2 id='strip'>Strip</h2><span id='topic+strip'></span>

<h3>Description</h3>

<p>removes any leading (spaces at the beginning) and trailing (spaces at the end) characters.
Analog to strip() string method from Python.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>strip(str)
</code></pre>

<hr>
<h2 id='torchaudio_info'>Audio Information</h2><span id='topic+torchaudio_info'></span>

<h3>Description</h3>

<p>Retrieve audio metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torchaudio_info(filepath)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="torchaudio_info_+3A_filepath">filepath</code></td>
<td>
<p>(str) path to the audio file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>AudioMetaData: an R6 class with fields sample_rate, channels, samples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- system.file("waves_yesno/1_1_0_1_1_0_1_1.wav", package = "torchaudio")
torchaudio_info(path)

</code></pre>

<hr>
<h2 id='torchaudio_load'>Load Audio File</h2><span id='topic+torchaudio_load'></span>

<h3>Description</h3>

<p>Loads an audio file from disk using the default loader (getOption(&quot;torchaudio.loader&quot;)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torchaudio_load(
  filepath,
  offset = 0L,
  duration = -1L,
  unit = c("samples", "time")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="torchaudio_load_+3A_filepath">filepath</code></td>
<td>
<p>(str): Path to audio file</p>
</td></tr>
<tr><td><code id="torchaudio_load_+3A_offset">offset</code></td>
<td>
<p>(int): Number of frames (or seconds) from the start of the file to begin data loading. (Default: <code>0</code>)</p>
</td></tr>
<tr><td><code id="torchaudio_load_+3A_duration">duration</code></td>
<td>
<p>(int): Number of frames (or seconds) to load.  <code>-1</code> to load everything after the offset. (Default: <code>-1</code>)</p>
</td></tr>
<tr><td><code id="torchaudio_load_+3A_unit">unit</code></td>
<td>
<p>(str): &quot;sample&quot; or &quot;time&quot;. If &quot;sample&quot; duration and offset will be interpreted as frames, and as seconds otherwise.</p>
</td></tr>
</table>

<hr>
<h2 id='transform__axismasking'>Axis Masking</h2><span id='topic+transform__axismasking'></span>

<h3>Description</h3>

<p>Apply masking to a spectrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform__axismasking(mask_param, axis, iid_masks)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform__axismasking_+3A_mask_param">mask_param</code></td>
<td>
<p>(int): Maximum possible length of the mask.</p>
</td></tr>
<tr><td><code id="transform__axismasking_+3A_axis">axis</code></td>
<td>
<p>(int): What dimension the mask is applied on.</p>
</td></tr>
<tr><td><code id="transform__axismasking_+3A_iid_masks">iid_masks</code></td>
<td>
<p>(bool): Applies iid masks to each of the examples in the batch dimension.
This option is applicable only when the input tensor is 4D.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): Tensor of dimension (..., freq, time).
</p>
<p>mask_value  (float): Value to assign to the masked columns.
</p>


<h3>Value</h3>

<p>Tensor: Masked spectrogram of dimensions (..., freq, time).
</p>

<hr>
<h2 id='transform_amplitude_to_db'>Amplitude to DB</h2><span id='topic+transform_amplitude_to_db'></span>

<h3>Description</h3>

<p>Turn a tensor from the power/amplitude scale to the decibel scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_amplitude_to_db(stype = "power", top_db = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_amplitude_to_db_+3A_stype">stype</code></td>
<td>
<p>(str, optional): scale of input tensor ('power' or 'magnitude'). The
power being the elementwise square of the magnitude. (Default: <code>'power'</code>)</p>
</td></tr>
<tr><td><code id="transform_amplitude_to_db_+3A_top_db">top_db</code></td>
<td>
<p>(float or NULL, optional): Minimum negative cut-off in decibels. A reasonable number
is 80. (Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This output depends on the maximum value in the input tensor, and so
may return different values for an audio clip split into snippets vs. a
a full clip.
</p>
<p>forward param:
x (Tensor): Input tensor before being converted to decibel scale
</p>


<h3>Value</h3>

<p><code>tensor</code>: Output tensor in decibel scale
</p>

<hr>
<h2 id='transform_complex_norm'>Complex Norm</h2><span id='topic+transform_complex_norm'></span>

<h3>Description</h3>

<p>Compute the norm of complex tensor input.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_complex_norm(power = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_complex_norm_+3A_power">power</code></td>
<td>
<p>(float, optional): Power of the norm. (Default: to <code>1.0</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
complex_tensor  (Tensor): Tensor shape of <code style="white-space: pre;">&#8288;(..., complex=2)&#8288;</code>.
</p>


<h3>Value</h3>

<p>Tensor: norm of the input tensor, shape of <code style="white-space: pre;">&#8288;(..., )&#8288;</code>.
</p>

<hr>
<h2 id='transform_compute_deltas'>Delta Coefficients</h2><span id='topic+transform_compute_deltas'></span>

<h3>Description</h3>

<p>Compute delta coefficients of a tensor, usually a spectrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_compute_deltas(win_length = 5, mode = "replicate")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_compute_deltas_+3A_win_length">win_length</code></td>
<td>
<p>(int): The window length used for computing delta. (Default: <code>5</code>)</p>
</td></tr>
<tr><td><code id="transform_compute_deltas_+3A_mode">mode</code></td>
<td>
<p>(str): Mode parameter passed to padding. (Default: <code>'replicate'</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): Tensor of audio of dimension (..., freq, time).
</p>
<p>See <a href="#topic+functional_compute_deltas">functional_compute_deltas</a> for more details.
</p>


<h3>Value</h3>

<p>Tensor: Tensor of deltas of dimension (..., freq, time).
</p>

<hr>
<h2 id='transform_fade'>Fade In/Out</h2><span id='topic+transform_fade'></span>

<h3>Description</h3>

<p>Add a fade in and/or fade out to an waveform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_fade(fade_in_len = 0, fade_out_len = 0, fade_shape = "linear")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_fade_+3A_fade_in_len">fade_in_len</code></td>
<td>
<p>(int, optional): Length of fade-in (time frames). (Default: <code>0</code>)</p>
</td></tr>
<tr><td><code id="transform_fade_+3A_fade_out_len">fade_out_len</code></td>
<td>
<p>(int, optional): Length of fade-out (time frames). (Default: <code>0</code>)</p>
</td></tr>
<tr><td><code id="transform_fade_+3A_fade_shape">fade_shape</code></td>
<td>
<p>(str, optional): Shape of fade. Must be one of: &quot;quarter_sine&quot;,
&quot;half_sine&quot;, &quot;linear&quot;, &quot;logarithmic&quot;, &quot;exponential&quot;.  (Default: <code>"linear"</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform  (Tensor): Tensor of audio of dimension (..., time).
</p>


<h3>Value</h3>

<p>Tensor: Tensor of audio of dimension (..., time).
</p>

<hr>
<h2 id='transform_frequencymasking'>Frequency-domain Masking</h2><span id='topic+transform_frequencymasking'></span>

<h3>Description</h3>

<p>Apply masking to a spectrogram in the frequency domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_frequencymasking(freq_mask_param, iid_masks)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_frequencymasking_+3A_freq_mask_param">freq_mask_param</code></td>
<td>
<p>(int): maximum possible length of the mask.
Indices uniformly sampled from [0, freq_mask_param).</p>
</td></tr>
<tr><td><code id="transform_frequencymasking_+3A_iid_masks">iid_masks</code></td>
<td>
<p>(bool, optional): whether to apply different masks to each
example/channel in the batch.  (Default: <code>FALSE</code>)
This option is applicable only when the input tensor is 4D.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>not implemented yet.
</p>

<hr>
<h2 id='transform_inverse_mel_scale'>Inverse Mel Scale</h2><span id='topic+transform_inverse_mel_scale'></span>

<h3>Description</h3>

<p>Solve for a normal STFT from a mel frequency STFT, using a conversion
matrix.  This uses triangular filter banks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_inverse_mel_scale(
  n_stft,
  n_mels = 128,
  sample_rate = 16000,
  f_min = 0,
  f_max = NULL,
  max_iter = 1e+05,
  tolerance_loss = 1e-05,
  tolerance_change = 1e-08,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_inverse_mel_scale_+3A_n_stft">n_stft</code></td>
<td>
<p>(int): Number of bins in STFT. See <code>n_fft</code> in <a href="#topic+transform_spectrogram">transform_spectrogram</a>.</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_n_mels">n_mels</code></td>
<td>
<p>(int, optional): Number of mel filterbanks. (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int, optional): Sample rate of audio signal. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_f_min">f_min</code></td>
<td>
<p>(float, optional): Minimum frequency. (Default: <code>0.</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_f_max">f_max</code></td>
<td>
<p>(float or NULL, optional): Maximum frequency. (Default: <code>sample_rate %/% 2</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_max_iter">max_iter</code></td>
<td>
<p>(int, optional): Maximum number of optimization iterations. (Default: <code>100000</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_tolerance_loss">tolerance_loss</code></td>
<td>
<p>(float, optional): Value of loss to stop optimization at. (Default: <code>1e-5</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_tolerance_change">tolerance_change</code></td>
<td>
<p>(float, optional): Difference in losses to stop optimization at. (Default: <code>1e-8</code>)</p>
</td></tr>
<tr><td><code id="transform_inverse_mel_scale_+3A_...">...</code></td>
<td>
<p>(optional): Arguments passed to the SGD optimizer. Argument lr will default to 0.1 if not specied.(Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
melspec  (Tensor): A Mel frequency spectrogram of dimension (..., <code>n_mels</code>, time)
</p>
<p>It minimizes the euclidian norm between the input mel-spectrogram and the product between
the estimated spectrogram and the filter banks using SGD.
</p>


<h3>Value</h3>

<p>Tensor: Linear scale spectrogram of size (..., freq, time)
</p>

<hr>
<h2 id='transform_mel_scale'>Mel Scale</h2><span id='topic+transform_mel_scale'></span>

<h3>Description</h3>

<p>Turn a normal STFT into a mel frequency STFT, using a conversion
matrix. This uses triangular filter banks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_mel_scale(
  n_mels = 128,
  sample_rate = 16000,
  f_min = 0,
  f_max = NULL,
  n_stft = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_mel_scale_+3A_n_mels">n_mels</code></td>
<td>
<p>(int, optional): Number of mel filterbanks. (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_scale_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int, optional): Sample rate of audio signal. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_scale_+3A_f_min">f_min</code></td>
<td>
<p>(float, optional): Minimum frequency. (Default: <code>0.</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_scale_+3A_f_max">f_max</code></td>
<td>
<p>(float or NULL, optional): Maximum frequency. (Default: <code style="white-space: pre;">&#8288;sample_rate // 2&#8288;</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_scale_+3A_n_stft">n_stft</code></td>
<td>
<p>(int, optional): Number of bins in STFT. Calculated from first input
if NULL is given.  See <code>n_fft</code> in :class:<code>Spectrogram</code>. (Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
specgram  (Tensor): Tensor of audio of dimension (..., freq, time).
</p>


<h3>Value</h3>

<p><code>tensor</code>: Mel frequency spectrogram of size (..., <code>n_mels</code>, time).
</p>

<hr>
<h2 id='transform_mel_spectrogram'>Mel Spectrogram</h2><span id='topic+transform_mel_spectrogram'></span>

<h3>Description</h3>

<p>Create MelSpectrogram for a raw audio signal. This is a composition of Spectrogram
and MelScale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_mel_spectrogram(
  sample_rate = 16000,
  n_fft = 400,
  win_length = NULL,
  hop_length = NULL,
  f_min = 0,
  f_max = NULL,
  pad = 0,
  n_mels = 128,
  window_fn = torch::torch_hann_window,
  power = 2,
  normalized = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_mel_spectrogram_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int, optional): Sample rate of audio signal. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_n_fft">n_fft</code></td>
<td>
<p>(int, optional): Size of FFT, creates <code style="white-space: pre;">&#8288;n_fft // 2 + 1&#8288;</code> bins. (Default: <code>400</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_win_length">win_length</code></td>
<td>
<p>(int or NULL, optional): Window size. (Default: <code>n_fft</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_hop_length">hop_length</code></td>
<td>
<p>(int or NULL, optional): Length of hop between STFT windows. (Default: <code style="white-space: pre;">&#8288;win_length // 2&#8288;</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_f_min">f_min</code></td>
<td>
<p>(float, optional): Minimum frequency. (Default: <code>0.</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_f_max">f_max</code></td>
<td>
<p>(float or NULL, optional): Maximum frequency. (Default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_pad">pad</code></td>
<td>
<p>(int, optional): Two sided padding of signal. (Default: <code>0</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_n_mels">n_mels</code></td>
<td>
<p>(int, optional): Number of mel filterbanks. (Default: <code>128</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_window_fn">window_fn</code></td>
<td>
<p>(function, optional): A function to create a window tensor
that is applied/multiplied to each frame/window. (Default: <code>torch_hann_window</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_power">power</code></td>
<td>
<p>(float, optional): Power of the norm. (Default: to <code>2.0</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_normalized">normalized</code></td>
<td>
<p>(logical): Whether to normalize by magnitude after stft (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="transform_mel_spectrogram_+3A_...">...</code></td>
<td>
<p>(optional): Arguments for window function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform (Tensor): Tensor of audio of dimension (..., time).
</p>


<h3>Value</h3>

<p><code>tensor</code>: Mel frequency spectrogram of size (..., <code>n_mels</code>, time).
</p>


<h3>Sources</h3>


<ul>
<li> <p><a href="https://gist.github.com/kastnerkyle/179d6e9a88202ab0a2fe">https://gist.github.com/kastnerkyle/179d6e9a88202ab0a2fe</a>
</p>
</li>
<li> <p><a href="https://timsainb.github.io/spectrograms-mfccs-and-inversion-in-python.html">https://timsainb.github.io/spectrograms-mfccs-and-inversion-in-python.html</a>
</p>
</li>
<li> <p><a href="https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html">https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>#'   Example
## Not run: 

if(torch::torch_is_installed()) {
mp3_path &lt;- system.file("sample_audio_1.mp3", package = "torchaudio")
sample_mp3 &lt;- transform_to_tensor(tuneR_loader(mp3_path))
# (channel, n_mels, time)
mel_specgram &lt;- transform_mel_spectrogram(sample_rate = sample_mp3[[2]])(sample_mp3[[1]])
}

## End(Not run)

</code></pre>

<hr>
<h2 id='transform_mfcc'>Mel-frequency Cepstrum Coefficients</h2><span id='topic+transform_mfcc'></span>

<h3>Description</h3>

<p>Create the Mel-frequency cepstrum coefficients from an audio signal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_mfcc(
  sample_rate = 16000,
  n_mfcc = 40,
  dct_type = 2,
  norm = "ortho",
  log_mels = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_mfcc_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int, optional): Sample rate of audio signal. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="transform_mfcc_+3A_n_mfcc">n_mfcc</code></td>
<td>
<p>(int, optional): Number of mfc coefficients to retain. (Default: <code>40</code>)</p>
</td></tr>
<tr><td><code id="transform_mfcc_+3A_dct_type">dct_type</code></td>
<td>
<p>(int, optional): type of DCT (discrete cosine transform) to use. (Default: <code>2</code>)</p>
</td></tr>
<tr><td><code id="transform_mfcc_+3A_norm">norm</code></td>
<td>
<p>(str, optional): norm to use. (Default: <code>'ortho'</code>)</p>
</td></tr>
<tr><td><code id="transform_mfcc_+3A_log_mels">log_mels</code></td>
<td>
<p>(bool, optional): whether to use log-mel spectrograms instead of db-scaled. (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="transform_mfcc_+3A_...">...</code></td>
<td>
<p>(optional): arguments for <a href="#topic+transform_mel_spectrogram">transform_mel_spectrogram</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform (tensor): Tensor of audio of dimension (..., time)
</p>
<p>By default, this calculates the MFCC on the DB-scaled Mel spectrogram.
This output depends on the maximum value in the input spectrogram, and so
may return different values for an audio clip split into snippets vs. a
a full clip.
</p>


<h3>Value</h3>

<p><code>tensor</code>: specgram_mel_db of size (..., <code>n_mfcc</code>, time).
</p>

<hr>
<h2 id='transform_mu_law_decoding'>Mu Law Decoding</h2><span id='topic+transform_mu_law_decoding'></span>

<h3>Description</h3>

<p>Decode mu-law encoded signal.  For more info see the
<a href="https://en.wikipedia.org/wiki/M-law_algorithm">Wikipedia Entry</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_mu_law_decoding(quantization_channels = 256)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_mu_law_decoding_+3A_quantization_channels">quantization_channels</code></td>
<td>
<p>(int, optional): Number of channels. (Default: <code>256</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This expects an input with values between 0 and quantization_channels - 1
and returns a signal scaled between -1 and 1.
</p>
<p>forward param:
x_mu  (Tensor): A mu-law encoded signal which needs to be decoded.
</p>


<h3>Value</h3>

<p>Tensor: The signal decoded.
</p>

<hr>
<h2 id='transform_mu_law_encoding'>Mu Law Encoding</h2><span id='topic+transform_mu_law_encoding'></span>

<h3>Description</h3>

<p>Encode signal based on mu-law companding.  For more info see
the <a href="https://en.wikipedia.org/wiki/M-law_algorithm">Wikipedia Entry</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_mu_law_encoding(quantization_channels = 256)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_mu_law_encoding_+3A_quantization_channels">quantization_channels</code></td>
<td>
<p>(int, optional): Number of channels. (Default: <code>256</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
x  (Tensor): A signal to be encoded.
</p>
<p>This algorithm assumes the signal has been scaled to between -1 and 1 and
returns a signal encoded with values from 0 to quantization_channels - 1.
</p>


<h3>Value</h3>

<p>x_mu (Tensor): An encoded signal.
</p>

<hr>
<h2 id='transform_resample'>Signal Resample</h2><span id='topic+transform_resample'></span>

<h3>Description</h3>

<p>Resample a signal from one frequency to another. A resampling method can be given.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_resample(
  orig_freq = 16000,
  new_freq = 16000,
  resampling_method = "sinc_interpolation"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_resample_+3A_orig_freq">orig_freq</code></td>
<td>
<p>(float, optional): The original frequency of the signal. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="transform_resample_+3A_new_freq">new_freq</code></td>
<td>
<p>(float, optional): The desired frequency. (Default: <code>16000</code>)</p>
</td></tr>
<tr><td><code id="transform_resample_+3A_resampling_method">resampling_method</code></td>
<td>
<p>(str, optional): The resampling method. (Default: <code>'sinc_interpolation'</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform  (Tensor): Tensor of audio of dimension (..., time).
</p>


<h3>Value</h3>

<p>Tensor: Output signal of dimension (..., time).
</p>

<hr>
<h2 id='transform_sliding_window_cmn'>sliding-window Cepstral Mean Normalization</h2><span id='topic+transform_sliding_window_cmn'></span>

<h3>Description</h3>

<p>Apply sliding-window cepstral mean  (and optionally variance) normalization per utterance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_sliding_window_cmn(
  cmn_window = 600,
  min_cmn_window = 100,
  center = FALSE,
  norm_vars = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_sliding_window_cmn_+3A_cmn_window">cmn_window</code></td>
<td>
<p>(int, optional): Window in frames for running average CMN computation (int, default = 600)</p>
</td></tr>
<tr><td><code id="transform_sliding_window_cmn_+3A_min_cmn_window">min_cmn_window</code></td>
<td>
<p>(int, optional):  Minimum CMN window used at start of decoding (adds latency only at start).
Only applicable if center == <code>FALSE</code>, ignored if center==<code>TRUE</code>  (int, default = 100)</p>
</td></tr>
<tr><td><code id="transform_sliding_window_cmn_+3A_center">center</code></td>
<td>
<p>(bool, optional): If <code>TRUE</code>, use a window centered on the current frame
(to the extent possible, modulo end effects). If <code>FALSE</code>, window is to the left. (bool, default = <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="transform_sliding_window_cmn_+3A_norm_vars">norm_vars</code></td>
<td>
<p>(bool, optional): If <code>TRUE</code>, normalize variance to one. (bool, default = <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform  (Tensor): Tensor of audio of dimension (..., time).
</p>


<h3>Value</h3>

<p>Tensor: Tensor of audio of dimension (..., time).
</p>

<hr>
<h2 id='transform_spectrogram'>Spectrogram</h2><span id='topic+transform_spectrogram'></span>

<h3>Description</h3>

<p>Create a spectrogram or a batch of spectrograms from a raw audio signal.
The spectrogram can be either magnitude-only or complex.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_spectrogram(
  n_fft = 400,
  win_length = NULL,
  hop_length = NULL,
  pad = 0L,
  window_fn = torch::torch_hann_window,
  power = 2,
  normalized = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_spectrogram_+3A_n_fft">n_fft</code></td>
<td>
<p>(integer): Size of FFT</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_win_length">win_length</code></td>
<td>
<p>(integer): Window size</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_hop_length">hop_length</code></td>
<td>
<p>(integer): Length of hop between STFT windows</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_pad">pad</code></td>
<td>
<p>(integer): Two sided padding of signal</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_window_fn">window_fn</code></td>
<td>
<p>(tensor or function): Window tensor that is applied/multiplied to each
frame/window or a function that generates the window tensor.</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_power">power</code></td>
<td>
<p>(numeric): Exponent for the magnitude spectrogram, (must be &gt; 0) e.g.,
1 for energy, 2 for power, etc. If NULL, then the complex spectrum is returned instead.</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_normalized">normalized</code></td>
<td>
<p>(logical): Whether to normalize by magnitude after stft</p>
</td></tr>
<tr><td><code id="transform_spectrogram_+3A_...">...</code></td>
<td>
<p>(optional) Arguments for window function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform (tensor): Tensor of audio of dimension (..., time)
</p>


<h3>Value</h3>

<p>tensor: Dimension (..., freq, time), freq is n_fft %/% 2 + 1 and n_fft is the
number of Fourier bins, and time is the number of window hops (n_frame).
</p>

<hr>
<h2 id='transform_time_stretch'>Time Stretch</h2><span id='topic+transform_time_stretch'></span>

<h3>Description</h3>

<p>Stretch stft in time without modifying pitch for a given rate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_time_stretch(hop_length = NULL, n_freq = 201, fixed_rate = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_time_stretch_+3A_hop_length">hop_length</code></td>
<td>
<p>(int or NULL, optional): Length of hop between STFT windows. (Default: <code style="white-space: pre;">&#8288;win_length // 2&#8288;</code>)</p>
</td></tr>
<tr><td><code id="transform_time_stretch_+3A_n_freq">n_freq</code></td>
<td>
<p>(int, optional): number of filter banks from stft. (Default: <code>201</code>)</p>
</td></tr>
<tr><td><code id="transform_time_stretch_+3A_fixed_rate">fixed_rate</code></td>
<td>
<p>(float or NULL, optional): rate to speed up or slow down by.
If NULL is provided, rate must be passed to the forward method.  (Default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
complex_specgrams  (Tensor): complex spectrogram (..., freq, time, complex=2).
</p>
<p>overriding_rate  (float or NULL, optional): speed up to apply to this batch.
If no rate is passed, use <code>self$fixed_rate</code>.  (Default: <code>NULL</code>)
</p>


<h3>Value</h3>

<p>Tensor: Stretched complex spectrogram of dimension (..., freq, ceil(time/rate), complex=2).
</p>

<hr>
<h2 id='transform_timemasking'>Time-domain Masking</h2><span id='topic+transform_timemasking'></span>

<h3>Description</h3>

<p>Apply masking to a spectrogram in the time domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_timemasking(time_mask_param, iid_masks)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_timemasking_+3A_time_mask_param">time_mask_param</code></td>
<td>
<p>(int): maximum possible length of the mask.
Indices uniformly sampled from [0, time_mask_param).</p>
</td></tr>
<tr><td><code id="transform_timemasking_+3A_iid_masks">iid_masks</code></td>
<td>
<p>(bool, optional): whether to apply different masks to each
example/channel in the batch.  (Default: <code>FALSE</code>)
This option is applicable only when the input tensor is 4D.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>not implemented yet.
</p>

<hr>
<h2 id='transform_to_tensor'>Convert an audio object into a tensor</h2><span id='topic+transform_to_tensor'></span>

<h3>Description</h3>

<p>Converts a numeric vector, as delivered by the backend, into a <code>torch_tensor</code> of shape (channels x samples).
If provided by the backend, attributes &quot;channels&quot; and &quot;sample_rate&quot; will be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_to_tensor(
  audio,
  out = NULL,
  normalization = TRUE,
  channels_first = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_to_tensor_+3A_audio">audio</code></td>
<td>
<p>(numeric): A numeric vector, as delivered by the backend.</p>
</td></tr>
<tr><td><code id="transform_to_tensor_+3A_out">out</code></td>
<td>
<p>(Tensor): An optional output tensor to use instead of creating one. (Default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="transform_to_tensor_+3A_normalization">normalization</code></td>
<td>
<p>(bool, float or function): Optional normalization.
If boolean <code>TRUE</code>, then output is divided by <code>2^(bits-1)</code>.
If <code>bits</code> info is not available it assumes the input is signed 32-bit audio.
If <code>numeric</code>, then output is divided by that number.
If <code>function</code>, then the output is passed as a parameter to the given function,
then the output is divided by the result. (Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="transform_to_tensor_+3A_channels_first">channels_first</code></td>
<td>
<p>(bool): Set channels first or length first in result. (Default: <code>TRUE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>list(Tensor, int), containing
- the audio content, encoded as `[C x L]` or `[L x C]` where L is the number of audio frames and
    C is the number of channels
- the sample rate of the audio (as listed in the metadata of the file)
</pre></div>

<hr>
<h2 id='transform_vad'>Voice Activity Detector</h2><span id='topic+transform_vad'></span>

<h3>Description</h3>

<p>Voice Activity Detector. Similar to SoX implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_vad(
  sample_rate,
  trigger_level = 7,
  trigger_time = 0.25,
  search_time = 1,
  allowed_gap = 0.25,
  pre_trigger_time = 0,
  boot_time = 0.35,
  noise_up_time = 0.1,
  noise_down_time = 0.01,
  noise_reduction_amount = 1.35,
  measure_freq = 20,
  measure_duration = NULL,
  measure_smooth_time = 0.4,
  hp_filter_freq = 50,
  lp_filter_freq = 6000,
  hp_lifter_freq = 150,
  lp_lifter_freq = 2000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_vad_+3A_sample_rate">sample_rate</code></td>
<td>
<p>(int): Sample rate of audio signal.</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_trigger_level">trigger_level</code></td>
<td>
<p>(float, optional): The measurement level used to trigger activity detection.
This may need to be cahnged depending on the noise level, signal level,
and other characteristics of the input audio.  (Default: 7.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_trigger_time">trigger_time</code></td>
<td>
<p>(float, optional): The time constant (in seconds)
used to help ignore short bursts of sound.  (Default: 0.25)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_search_time">search_time</code></td>
<td>
<p>(float, optional): The amount of audio (in seconds)
to search for quieter/shorter bursts of audio to include prior
the detected trigger point.  (Default: 1.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_allowed_gap">allowed_gap</code></td>
<td>
<p>(float, optional): The allowed gap (in seconds) between
quiteter/shorter bursts of audio to include prior
to the detected trigger point.  (Default: 0.25)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_pre_trigger_time">pre_trigger_time</code></td>
<td>
<p>(float, optional): The amount of audio (in seconds) to preserve
before the trigger point and any found quieter/shorter bursts.  (Default: 0.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_boot_time">boot_time</code></td>
<td>
<p>(float, optional) The algorithm (internally) uses adaptive noise
estimation/reduction in order to detect the start of the wanted audio.
This option sets the time for the initial noise estimate.  (Default: 0.35)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_noise_up_time">noise_up_time</code></td>
<td>
<p>(float, optional) Time constant used by the adaptive noise estimator
for when the noise level is increasing.  (Default: 0.1)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_noise_down_time">noise_down_time</code></td>
<td>
<p>(float, optional) Time constant used by the adaptive noise estimator
for when the noise level is decreasing.  (Default: 0.01)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_noise_reduction_amount">noise_reduction_amount</code></td>
<td>
<p>(float, optional) Amount of noise reduction to use in
the detection algorithm  (e.g. 0, 0.5, ...). (Default: 1.35)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_measure_freq">measure_freq</code></td>
<td>
<p>(float, optional) Frequency of the algorithms
processing/measurements.  (Default: 20.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_measure_duration">measure_duration</code></td>
<td>
<p>(float, optional) Measurement duration. (Default: Twice the measurement period; i.e. with overlap.)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_measure_smooth_time">measure_smooth_time</code></td>
<td>
<p>(float, optional) Time constant used to smooth spectral measurements.  (Default: 0.4)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_hp_filter_freq">hp_filter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of high-pass filter applied
at the input to the detector algorithm.  (Default: 50.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_lp_filter_freq">lp_filter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of low-pass filter applied
at the input to the detector algorithm.  (Default: 6000.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_hp_lifter_freq">hp_lifter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of high-pass lifter used
in the detector algorithm.  (Default: 150.0)</p>
</td></tr>
<tr><td><code id="transform_vad_+3A_lp_lifter_freq">lp_lifter_freq</code></td>
<td>
<p>(float, optional) &quot;Brick-wall&quot; frequency of low-pass lifter used
in the detector algorithm.  (Default: 2000.0)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Attempts to trim silence and quiet background sounds from the ends of recordings of speech.
The algorithm currently uses a simple cepstral power measurement to detect voice,
so may be fooled by other things, especially music.
</p>
<p>The effect can trim only from the front of the audio,
so in order to trim from the back, the reverse effect must also be used.
</p>
<p>forward param:
waveform  (Tensor): Tensor of audio of dimension <code style="white-space: pre;">&#8288;(..., time)&#8288;</code>
</p>


<h3>Value</h3>

<p>torch::nn_module()
</p>


<h3>References</h3>


<ul>
<li> <p><a href="https://sox.sourceforge.net/sox.html">https://sox.sourceforge.net/sox.html</a>
</p>
</li></ul>


<hr>
<h2 id='transform_vol'>Add a volume to an waveform.</h2><span id='topic+transform_vol'></span>

<h3>Description</h3>

<p>Add a volume to an waveform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transform_vol(gain, gain_type = "amplitude")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transform_vol_+3A_gain">gain</code></td>
<td>
<p>(float): Interpreted according to the given gain_type:
If <code>gain_type</code> = <code>amplitude</code>, <code>gain</code> is a positive amplitude ratio.
If <code>gain_type</code> = <code>power</code>, <code>gain</code> is a power  (voltage squared).
If <code>gain_type</code> = <code>db</code>, <code>gain</code> is in decibels.</p>
</td></tr>
<tr><td><code id="transform_vol_+3A_gain_type">gain_type</code></td>
<td>
<p>(str, optional): Type of gain. One of: <code>amplitude</code>, <code>power</code>, <code>db</code> (Default: <code>amplitude</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>forward param:
waveform  (Tensor): Tensor of audio of dimension (..., time).
</p>


<h3>Value</h3>

<p>Tensor: Tensor of audio of dimension (..., time).
</p>

<hr>
<h2 id='tuneR_loader'>tuneR_loader</h2><span id='topic+tuneR_loader'></span>

<h3>Description</h3>

<p>tuneR_loader
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tuneR_loader(filepath, offset = 0L, duration = Inf, unit = "samples")
</code></pre>

<hr>
<h2 id='walk_files'>List recursively all files ending with a suffix at a given root</h2><span id='topic+walk_files'></span>

<h3>Description</h3>

<p>List recursively all files ending with a suffix at a given root
</p>


<h3>Usage</h3>

<pre><code class='language-R'>walk_files(root, suffix, prefix = FALSE, remove_suffix = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="walk_files_+3A_root">root</code></td>
<td>
<p>(str): Path to directory whose folders need to be listed</p>
</td></tr>
<tr><td><code id="walk_files_+3A_suffix">suffix</code></td>
<td>
<p>(str or tuple): Suffix of the files to match, e.g. '.png' or ('.jpg', '.png').
It uses the Python &quot;str.endswith&quot; method and is passed directly</p>
</td></tr>
<tr><td><code id="walk_files_+3A_prefix">prefix</code></td>
<td>
<p>(bool, optional): If TRUE, prepends the full path to each result, otherwise
only returns the name of the files found  (Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="walk_files_+3A_remove_suffix">remove_suffix</code></td>
<td>
<p>(bool, optional): If TRUE, removes the suffix to each result defined in suffix,
otherwise will return the result as found  (Default: <code>FALSE</code>).</p>
</td></tr>
</table>

<hr>
<h2 id='yesno_dataset'>YesNo Dataset</h2><span id='topic+yesno_dataset'></span>

<h3>Description</h3>

<p>Create a Dataset for YesNo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yesno_dataset(
  root,
  url = "http://www.openslr.org/resources/1/waves_yesno.tar.gz",
  folder_in_archive = "waves_yesno",
  download = FALSE,
  transform = NULL,
  target_transform = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yesno_dataset_+3A_root">root</code></td>
<td>
<p>(str): Path to the directory where the dataset is found or downloaded.</p>
</td></tr>
<tr><td><code id="yesno_dataset_+3A_url">url</code></td>
<td>
<p>(str, optional): The URL to download the dataset from.
(default: <code>"[http://www.openslr.org/resources/1/waves_yesno.tar.gz]()"</code>)</p>
</td></tr>
<tr><td><code id="yesno_dataset_+3A_folder_in_archive">folder_in_archive</code></td>
<td>
<p>(str, optional): The top-level directory of the dataset.  (default: <code>"waves_yesno"</code>)</p>
</td></tr>
<tr><td><code id="yesno_dataset_+3A_download">download</code></td>
<td>
<p>(bool, optional): Whether to download the dataset if it is not found at root path.  (default: <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="yesno_dataset_+3A_transform">transform</code></td>
<td>
<p>(callable, optional): Optional transform applied on waveform. (default: <code>NULL</code>)</p>
</td></tr>
<tr><td><code id="yesno_dataset_+3A_target_transform">target_transform</code></td>
<td>
<p>(callable, optional): Optional transform applied on utterance. (default: <code>NULL</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>tuple: <code style="white-space: pre;">&#8288;(waveform, sample_rate, labels)&#8288;</code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
