<!DOCTYPE html><html lang="en"><head><title>Help for package ibr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ibr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ibr-package'>
<p>Iterative Bias Reduction</p></a></li>
<li><a href='#AIC.ibr'><p>Summarizing iterative bias reduction fits</p></a></li>
<li><a href='#betaA'><p>Calculates coefficients for iterative bias reduction smoothers</p></a></li>
<li><a href='#betaS1'><p>Coefficients for iterative bias reduction method.</p></a></li>
<li><a href='#betaS1lr'><p>Coefficients for iterative bias reduction method.</p></a></li>
<li><a href='#BIC'><p>Information Criterion for ibr</p></a></li>
<li><a href='#bwchoice'><p>Choice of bandwidth achieving a prescribed effective degree of freedom</p></a></li>
<li><a href='#calcA'><p>Decomposition of the kernel smoother</p></a></li>
<li><a href='#cvobs'><p>Selection of the number of iterations for iterative bias reduction smoothers</p></a></li>
<li><a href='#departnoyau'><p>Trace of the product kernel smoother</p></a></li>
<li><a href='#dssmoother'><p>Evaluate the smoothing matrix, the radial basis matrix, the</p>
polynomial matrix and their associated coefficients</a></li>
<li><a href='#dsSx'><p>Evaluate the smoothing matrix at any point</p></a></li>
<li><a href='#DuchonQ'><p>Computes the semi-kernel of Duchon splines</p></a></li>
<li><a href='#DuchonS'><p>Computes the semi-kernel of Duchon splines</p></a></li>
<li><a href='#fittedA'><p>Evaluates the fits for iterative bias reduction method</p></a></li>
<li><a href='#fittedS1'><p>Evaluate the fit for iterative bias reduction model</p></a></li>
<li><a href='#fittedS1lr'><p>Evaluate the fit for iterative bias reduction model</p></a></li>
<li><a href='#forward'><p>Iterative bias reduction smoothing</p></a></li>
<li><a href='#ibr'><p>Iterative bias reduction smoothing</p></a></li>
<li><a href='#ibr.fit'><p>Iterative bias reduction smoothing</p></a></li>
<li><a href='#iterchoiceA'><p>Selection of the number of iterations for iterative bias reduction smoothers</p></a></li>
<li><a href='#iterchoiceAcv'><p>Selection of the number of iterations for iterative bias reduction smoothers</p></a></li>
<li><a href='#iterchoiceAcve'><p>Selection of the number of iterations for iterative bias reduction smoothers</p></a></li>
<li><a href='#iterchoiceAe'><p>Selection of the number of iterations for iterative bias reduction smoothers</p></a></li>
<li><a href='#iterchoiceS1'><p>Number of iterations selection for iterative bias reduction model</p></a></li>
<li><a href='#iterchoiceS1cv'><p>Selection of the number of iterations for iterative bias</p>
reduction smoothers with base thin-plate splines or duchon splines smoother</a></li>
<li><a href='#iterchoiceS1cve'><p>Selection of the number of iterations for iterative bias</p>
reduction smoothers with base thin-plate splines smoother or duchon splines smoother</a></li>
<li><a href='#iterchoiceS1e'><p>Number of iterations selection for iterative bias reduction model</p></a></li>
<li><a href='#iterchoiceS1lrcv'><p>Selection of the number of iterations for iterative bias</p>
reduction smoothers with base lowrank thin-plate splines or duchon splines smoother</a></li>
<li><a href='#iterchoiceS1lrcve'><p>Selection of the number of iterations for iterative bias</p>
reduction smoothers with base lowrank thin-plate splines smoother or duchon splines smoother</a></li>
<li><a href='#kernel'><p>Kernel evaluation</p></a></li>
<li><a href='#kernelSx'><p>Evaluates the smoothing matrix at x*</p></a></li>
<li><a href='#lambdachoice'><p>Choice of bandwidth according to a given effective degree of freedom</p></a></li>
<li><a href='#lambdachoicelr'><p>Choice of bandwidth according to a given effective degree of freedom</p></a></li>
<li><a href='#lrsmoother'><p>Evaluate the lowrank spline</p></a></li>
<li><a href='#npregress'><p>Local polynomials smoothing</p></a></li>
<li><a href='#ozone'><p>Los Angeles ozone pollution data, 1976.</p></a></li>
<li><a href='#plot.forwardibr'><p>Plot diagnostic for an ibr object</p></a></li>
<li><a href='#plot.ibr'><p>Plot diagnostic for an ibr object</p></a></li>
<li><a href='#poids'><p>Product kernel evaluation</p></a></li>
<li><a href='#predict.ibr'><p>Predicted values using iterative bias reduction smoothers</p></a></li>
<li><a href='#predict.npregress'><p>Predicted values using using local polynomials</p>
</p></a></li>
<li><a href='#print.summary.ibr'><p>Printing iterative bias reduction summaries</p></a></li>
<li><a href='#print.summary.npregress'><p>Printing iterative bias reduction summaries</p></a></li>
<li><a href='#summary.ibr'><p>Summarizing iterative bias reduction fits</p></a></li>
<li><a href='#summary.npregress'><p>Summarizing local polynomial fits</p></a></li>
<li><a href='#sumvalpr'><p>Sum of a geometric series</p></a></li>
<li><a href='#tracekernel'><p>Trace of product kernel smoother</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>2.0-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-09-12</td>
</tr>
<tr>
<td>Title:</td>
<td>Iterative Bias Reduction</td>
</tr>
<tr>
<td>Author:</td>
<td>Pierre-Andre Cornillon, Nicolas Hengartner, Eric Matzner-Lober</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>"Pierre-Andre Cornillon" &lt;pierre-andre.cornillon@univ-rennes2.fr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.11.1), mgcv</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics</td>
</tr>
<tr>
<td>Description:</td>
<td>Multivariate smoothing using iterative bias reduction with kernel, thin plate splines, Duchon splines or low rank splines. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-09-13 09:28:01 UTC; pac</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-09-13 15:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ibr-package'>
Iterative Bias Reduction
</h2><span id='topic+ibr-package'></span>

<h3>Description</h3>

<p>an R package for multivariate smoothing using Iterative Bias Reduction smoother.
</p>


<h3>Details</h3>

<ul>
<li><p> We are interested in smoothing (the values of) a vector of
<code class="reqn">n</code> observations <code class="reqn">y</code> by  <code class="reqn">d</code> covariates measured at the
same <code class="reqn">n</code> observations (gathered in the matrix <code class="reqn">X</code>).
The iterated Bias Reduction produces a sequence of smoothers
</p>
<p style="text-align: center;"><code class="reqn">\hat y=S_k y =(I - (I-S)^k)y,</code>
</p>

<p>where <code class="reqn">S</code> is the pilot smoother which can be either a kernel or a
thin plate spline smoother. In case of a kernel smoother, the kernel
is built as a product of univariate kernels.
</p>
</li>
<li><p> The most important parameter of the iterated bias reduction is
<code class="reqn">k</code> the
number of 
iterationsr. Usually this parameter is unknown and is
chosen from the search grid <code>K</code> to minimize the criterion (GCV,
AIC, AICc, BIC or gMDL).<br /> 
The user must choose the pilot smoother
(kernel <code>"k"</code>, thin plate splines <code>"tps"</code> or Duchon splines <code>"ds"</code>)
plus the values of bandwidths (kernel)
or <code class="reqn">\lambda</code> thin plate splines). As the choice of these raw
values depend on each particular dataset, one
can rely on effective degrees of freedom or default values given as degree of
freedom, see argument <code>df</code> of the main function <code><a href="#topic+ibr">ibr</a></code>.</p>
</li></ul>

<p><b>Index of functions to be used by end user:</b>
</p>
<pre>
ibr:               Iterative bias reduction smoothing
plot.ibr:          Plot diagnostic for an ibr object
predict.ibr:       Predicted values using iterative bias reduction
                   smoothers
forward:           Variable selection for ibr (forward method)
print.summary.ibr: Printing iterative bias reduction summaries
summary.ibr:       Summarizing iterative bias reduction fits
</pre>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner, Eric Matzner-Lober
</p>
<p>Maintainer: Pierre-Andre Cornillon &lt;pierre-andre.cornillon@supagro.inra.fr&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1],smoother="k",df=1.1)
summary(res.ibr)
predict(res.ibr)
plot(res.ibr)

## End(Not run)
</code></pre>

<hr>
<h2 id='AIC.ibr'>Summarizing iterative bias reduction fits</h2><span id='topic+AIC.ibr'></span>

<h3>Description</h3>

<p>Generic function calculating the Akaike information criterion for
one model objects of ibr class for which a log-likelihood value
can be obtained, according to the formula
<code class="reqn">-2 \log(sigma^2) + k df/n</code>,
where <code class="reqn">df</code> represents the effective degree of freedom (trace) of the
smoother in the
fitted model, and <code class="reqn">k = 2</code> for the usual AIC, or <code class="reqn">k = \log(n)</code>
(<code class="reqn">n</code> the number of observations) for the so-called BIC or SBC
(Schwarz's Bayesian criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ibr'
AIC(object, ..., k = 2)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AIC.ibr_+3A_object">object</code></td>
<td>
<p>A fitted model object of class ibr.</p>
</td></tr>
<tr><td><code id="AIC.ibr_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="AIC.ibr_+3A_k">k</code></td>
<td>
<p>Numeric, the <em>penalty</em> per parameter to be used; the
default <code>k = 2</code> is the classical AIC.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ibr method for <code>AIC</code>, <code>AIC.ibr()</code> calculates
<code class="reqn">\log(sigma^2)+2*df/n</code>, where <em>df</em> is the trace
of the smoother.
</p>


<h3>Value</h3>

<p>returns a numeric value
with the corresponding AIC (or BIC, or ..., depending on <code>k</code>).
</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Hurvich, C. M., Simonoff J. S. and Tsai, C. L. (1998) Smoothing
Parameter Selection in Nonparametric Regression Using an Improved Akaike
Information Criterion. <em>Journal of the Royal Statistical Society, Series B</em>, 60, 271-293 . 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1],df=1.2)
summary(res.ibr)
predict(res.ibr)
## End(Not run)
</code></pre>

<hr>
<h2 id='betaA'>Calculates coefficients for iterative bias reduction smoothers</h2><span id='topic+betaA'></span>

<h3>Description</h3>

<p>Calculates the coefficients for the iterative bias reduction  smoothers. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaA(n, eigenvaluesA, tPADmdemiY, DdemiPA, ddlmini, k, index0)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betaA_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="betaA_+3A_eigenvaluesa">eigenvaluesA</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="betaA_+3A_tpadmdemiy">tPADmdemiY</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric matrix <em>A</em> times the inverse of the square root of the diagonal matrix <em>D</em>.</p>
</td></tr>
<tr><td><code id="betaA_+3A_ddemipa">DdemiPA</code></td>
<td>
<p>The square root of the diagonal matrix <em>D</em> times
the eigen vectors of the symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="betaA_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues (numerically) equals to 1.</p>
</td></tr>
<tr><td><code id="betaA_+3A_k">k</code></td>
<td>
<p>A scalar which gives the number of iterations.</p>
</td></tr>
<tr><td><code id="betaA_+3A_index0">index0</code></td>
<td>
<p>The index of the first eigen values of <em>S</em>
numerically equal to 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for detailed explanation of <em>A</em> and
<em>D</em> and the meaning of coefficients.</p>


<h3>Value</h3>

<p>Returns the  vector of coefficients (of length <em>n</em>, the number of observations.)</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='betaS1'>Coefficients for iterative bias reduction method. </h2><span id='topic+betaS1'></span>

<h3>Description</h3>

<p>The function evaluates the smoothing matrix <code>H</code>, the
matrices <em>Q</em> and <em>S</em> and their associated
coefficients <code>c</code> and <code>s</code>. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaS1(n,U,tUy,eigenvaluesS1,ddlmini,k,lambda,Sgu,Qgu,index0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betaS1_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_u">U</code></td>
<td>
<p>The the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_tuy">tUy</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em> times the vector of observation <em>y</em>.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_eigenvaluess1">eigenvaluesS1</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigen values of <em>S</em> equal to 1.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_k">k</code></td>
<td>
<p>A numeric vector which give the number of iterations.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_lambda">lambda</code></td>
<td>
<p>The smoothness coefficient lambda for thin plate splines of
order <code>m</code>.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_sgu">Sgu</code></td>
<td>
<p>The matrix of the polynomial null space <em>S</em>.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_qgu">Qgu</code></td>
<td>
<p>The matrix of the semi kernel (or radial basis) <em>Q</em>.</p>
</td></tr>
<tr><td><code id="betaS1_+3A_index0">index0</code></td>
<td>
<p>The index of the first eigen values of <em>S</em>
numerically equal to 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for detailed explanation of <em>Q</em> (the
semi kernel or radial basis) and
<em>S</em> (the polynomial null space).</p>


<h3>Value</h3>

<p>Returns a list containing of coefficients for the null space <code>dgub</code>
and the semi-kernel <code>cgub</code></p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>C. Gu (2002) <em>Smoothing spline anova models</em>. New York: Springer-Verlag.</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='betaS1lr'>Coefficients for iterative bias reduction method. </h2><span id='topic+betaS1lr'></span>

<h3>Description</h3>

<p>The function evaluates the smoothing matrix <code>H</code>, the
matrices <em>Q</em> and <em>S</em> and their associated
coefficients <code>c</code> and <code>s</code>. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>betaS1lr(n,U,tUy,eigenvaluesS1,ddlmini,k,lambda,rank,Rm1U,index0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betaS1lr_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_u">U</code></td>
<td>
<p>The the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_tuy">tUy</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em> times the vector of observation <em>y</em>.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_eigenvaluess1">eigenvaluesS1</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigen values of <em>S</em> equal to 1.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_k">k</code></td>
<td>
<p>A numeric vector which give the number of iterations.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_lambda">lambda</code></td>
<td>
<p>The smoothness coefficient lambda for thin plate splines of
order <code>m</code>.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_rank">rank</code></td>
<td>
<p>The rank of lowrank splines.</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_rm1u">Rm1U</code></td>
<td>
<p>matrix R^-1U (see reference).</p>
</td></tr>
<tr><td><code id="betaS1lr_+3A_index0">index0</code></td>
<td>
<p>The index of the first eigen values of <em>S</em>
numerically equal to 0.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for detailed explanation of <em>Q</em> (the
semi kernel or radial basis) and
<em>S</em> (the polynomial null space).</p>


<h3>Value</h3>

<p>Returns <code>beta</code></p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='BIC'>Information Criterion for ibr</h2><span id='topic+BIC'></span><span id='topic+GCV'></span><span id='topic+AICc'></span><span id='topic+BIC.ibr'></span><span id='topic+GCV.ibr'></span><span id='topic+AICc.ibr'></span>

<h3>Description</h3>

<p>Functions calculating the  Bayesian Informative Criterion , the
Generalized Cross Validation criterion and the Corrected Akaike information criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ibr'
BIC(object, ...)

## S3 method for class 'ibr'
GCV(object, ...)

## S3 method for class 'ibr'
AICc(object, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BIC_+3A_object">object</code></td>
<td>
<p>A fitted model object of class ibr.</p>
</td></tr>
<tr><td><code id="BIC_+3A_...">...</code></td>
<td>
<p>Only for compatibility purpose with <code>BIC</code> of
<code>nlme</code> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ibr method for <code>BIC</code>, <code>BIC.ibr()</code> calculates
<code class="reqn">\log(sigma^2)+log(n)*df/n</code>, where <em>df</em> is the trace
of the smoother.
</p>
<p>The ibr method for <code>GCV</code>, <code>GCV.ibr()</code> calculates
<code class="reqn">\log(sigma^2)-2*\log(1-df/n)</code>
</p>
<p>The ibr method for <code>AICc</code>, <code>AICc.ibr()</code> calculates
<code class="reqn">\log(sigma^2)+1+(2*(df+1))/(n-df-2)</code>.
</p>


<h3>Value</h3>

<p>Returns a numeric value
with the corresponding BIC, GCV or AICc.
</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Hurvich, C. M., Simonoff J. S. and Tsai, C. L. (1998) Smoothing
Parameter Selection in Nonparametric Regression Using an Improved Akaike
Information Criterion. <em>Journal of the Royal Statistical Society, Series B</em>, 60, 271-293 . 
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1])
BIC(res.ibr)
GCV(res.ibr)
AICc(res.ibr)

## End(Not run)
</code></pre>

<hr>
<h2 id='bwchoice'>Choice of bandwidth achieving a prescribed effective degree of freedom</h2><span id='topic+bwchoice'></span>

<h3>Description</h3>

<p>Perform a search for the bandwidths in the given grid. For each explanatory
variable, the bandwidth is chosen such that the trace of the smoothing
matrix according to that variable (effective degree of freedom) is equal to a
prescribed value.
This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>bwchoice(X,objectif,kernelx="g",itermax=1000)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bwchoice_+3A_x">X</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> rows (individuals) and <code class="reqn">p</code> columns (numeric variables).</p>
</td></tr>
<tr><td><code id="bwchoice_+3A_objectif">objectif</code></td>
<td>
<p>A numeric vector of either length 1 or length equal to the
number of columns of <code>X</code>. It indicates the  desired effective degree of
freedom (trace) of the smoothing   matrix for
each variable. <code>objectif</code> is repeated when the length of vector
<code>objectif</code> is 1.</p>
</td></tr>
<tr><td><code id="bwchoice_+3A_kernelx">kernelx</code></td>
<td>
<p>String which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
<tr><td><code id="bwchoice_+3A_itermax">itermax</code></td>
<td>
<p>A scalar which controls the number of iterations for
that search.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of length d, the number of explanatory variable, where
each coordinate is the value of the selected bandwidth for each
explanatory variable</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='calcA'>Decomposition of the kernel smoother</h2><span id='topic+calcA'></span>

<h3>Description</h3>

<p>Calculates the decomposition of the kernel smoothing matrix in two part: a
diagonal matrix <em>D</em> and a symmetric matrix <em>A</em>.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calcA(X,bx,kernelx="g")</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calcA_+3A_x">X</code></td>
<td>
<p>The matrix of explanatory variables, size <em>n</em>, <em>p</em>.</p>
</td></tr>
<tr><td><code id="calcA_+3A_bx">bx</code></td>
<td>
<p>The vector of bandwidth of length <em>p</em>.</p>
</td></tr>
<tr><td><code id="calcA_+3A_kernelx">kernelx</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see the reference for detailed explanation of <em>A</em> and
<em>D</em> and the meaning of coefficients.</p>


<h3>Value</h3>

<p>Returns a list containing two matrices: the symmetric matrix <em>A</em>
in component <code>A</code>) and the square root of the diagonal matrix
<em>D</em> in the component <code>Ddemi</code> and the trace of the smoother
in the component <code>df</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='cvobs'>Selection of the number of iterations for iterative bias reduction smoothers</h2><span id='topic+cvobs'></span>

<h3>Description</h3>

<p>The function <code>cvobs</code> gives the index of observations in each test set. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvobs(n,ntest,ntrain,Kfold,type=
c("random", "timeseries", "consecutive", "interleaved"), npermut, seed)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cvobs_+3A_n">n</code></td>
<td>
<p>The total number of observations.</p>
</td></tr>
<tr><td><code id="cvobs_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="cvobs_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="cvobs_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="cvobs_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="cvobs_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="cvobs_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with in each component the index of observations to be
used as a test set.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='departnoyau'>Trace of the product kernel smoother</h2><span id='topic+departnoyau'></span>

<h3>Description</h3>

<p>Search bandwidth for each univariate kernel smoother such that the
product of these univariate kernel gives a kernel smoother with a
chosen effective degree of freedom (trace of the smoother). The bandwidths are
constrained to give, for each explanatory
variable, a kernel smoother with same trace as the others.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>departnoyau(df, x, kernel, dftobwitmax, n, p, dfobjectif)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="departnoyau_+3A_df">df</code></td>
<td>
<p>A numeric vector giving the effective degree of freedom (trace) of the
univariate smoothing  matrix  for each variable of 
<code>x</code>.</p>
</td></tr>
<tr><td><code id="departnoyau_+3A_x">x</code></td>
<td>
<p>Matrix of explanatory variables, size <em>n</em>, <em>p</em>.</p>
</td></tr>
<tr><td><code id="departnoyau_+3A_kernel">kernel</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
<tr><td><code id="departnoyau_+3A_dftobwitmax">dftobwitmax</code></td>
<td>
<p>Specifies the maximum number of iterations
transmitted   to <code><a href="stats.html#topic+uniroot">uniroot</a></code> function.</p>
</td></tr>
<tr><td><code id="departnoyau_+3A_n">n</code></td>
<td>
<p>Number of rows of data matrix <em>x</em>.</p>
</td></tr>
<tr><td><code id="departnoyau_+3A_p">p</code></td>
<td>
<p>Number of columns of data matrix <em>x</em>.</p>
</td></tr>
<tr><td><code id="departnoyau_+3A_dfobjectif">dfobjectif</code></td>
<td>
<p>A numeric vector of length 1 which indicates
the  desired effective degree of freedom (trace) of the smoothing
matrix (product kernel smoother) for <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the desired bandwidths.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='dssmoother'>Evaluate the smoothing matrix, the radial basis matrix, the
polynomial matrix and their associated coefficients</h2><span id='topic+dssmoother'></span>

<h3>Description</h3>

<p>The function evaluates the smoothing matrix <code>H</code>, the
matrices <em>Q</em> and <em>S</em> and their associated
coefficients <code>c</code> and <code>s</code>. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dssmoother(X,Y=NULL,lambda,m,s)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dssmoother_+3A_x">X</code></td>
<td>
<p>Matrix of explanatory variables, size n,p.</p>
</td></tr>
<tr><td><code id="dssmoother_+3A_y">Y</code></td>
<td>
<p>Vector of  response variable. If null, only the smoothing
matrix is returned.</p>
</td></tr>
<tr><td><code id="dssmoother_+3A_lambda">lambda</code></td>
<td>
<p>The smoothness coefficient lambda for thin plate splines of
order <code>m</code>.</p>
</td></tr>
<tr><td><code id="dssmoother_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="dssmoother_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>see the reference for detailed explanation of <em>Q</em> (the
semi kernel or radial basis) and
<em>S</em> (the polynomial null space).</p>


<h3>Value</h3>

<p> Returns a list containing the smoothing matrix <code>H</code>, and two
matrices denoted <code>Sgu</code> (for null space) and <code>Qgu</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. 
</p>
<p>C. Gu (2002) <em>Smoothing spline anova models</em>. New York:
Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='dsSx'>Evaluate the smoothing matrix at any point</h2><span id='topic+dsSx'></span>

<h3>Description</h3>

<p>The function evaluates the matrix <em>Q</em> and <em>S</em> related to
the explanatory variables <code class="reqn">X</code> at any points. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dsSx(X,Xetoile,m=2,s=0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dsSx_+3A_x">X</code></td>
<td>
<p>Matrix of explanatory variables, size n,p.</p>
</td></tr>
<tr><td><code id="dsSx_+3A_xetoile">Xetoile</code></td>
<td>
<p>Matrix of new observations with the same number of
variables as <code class="reqn">X</code>, size m,p.</p>
</td></tr>
<tr><td><code id="dsSx_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="dsSx_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>see the reference for detailed explanation of <em>Q</em> (the
semi kernel) and
<em>S</em> (the polynomial null space).</p>


<h3>Value</h3>

<p>Returns a list containing two matrices denoted <code>Sgu</code> (for null
space) and <code>Qgu</code></p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin.
</p>
<p>C. Gu (2002) <em>Smoothing spline anova models</em>. New York:
Springer-Verlag.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='DuchonQ'>Computes the semi-kernel of Duchon splines</h2><span id='topic+DuchonQ'></span>

<h3>Description</h3>

<p>The function <code>DuchonQ</code> computes the semi-kernel of Duchon splines. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DuchonQ(x,xk,m=2,s=0,symmetric=TRUE)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DuchonQ_+3A_x">x</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="DuchonQ_+3A_xk">xk</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>nk</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="DuchonQ_+3A_m">m</code></td>
<td>
<p>Order of derivatives.</p>
</td></tr>
<tr><td><code id="DuchonQ_+3A_s">s</code></td>
<td>
<p>Exponent for the weight function.</p>
</td></tr>
<tr><td><code id="DuchonQ_+3A_symmetric">symmetric</code></td>
<td>
<p>Boolean: if <code>TRUE</code> only <code>x</code> is used and it
computes the semi-kernel at observations of <code>x</code> (it should give the
same result as <code>DuchonQ(x,xk,m,s,FALSE)</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The semi-kernel evaluated.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. </p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='DuchonS'>Computes the semi-kernel of Duchon splines</h2><span id='topic+DuchonS'></span>

<h3>Description</h3>

<p>The function <code>DuchonS</code> computes the semi-kernel of Duchon splines. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DuchonS(x,m=2)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DuchonS_+3A_x">x</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="DuchonS_+3A_m">m</code></td>
<td>
<p>Order of derivatives.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The polynomial part evaluated.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. </p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='fittedA'>Evaluates the fits for iterative bias reduction method</h2><span id='topic+fittedA'></span>

<h3>Description</h3>

<p>Evaluates the fits for the iterative bias reduction smoother, using a kernel
smoother and its decomposition into a symmetric matrix and a diagonal
matrix. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fittedA(n, eigenvaluesA, tPADmdemiY, DdemiPA, ddlmini, k)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fittedA_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="fittedA_+3A_eigenvaluesa">eigenvaluesA</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="fittedA_+3A_tpadmdemiy">tPADmdemiY</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric matrix <em>A</em> times the inverse of the square root of the diagonal matrix <em>D</em>.</p>
</td></tr>
<tr><td><code id="fittedA_+3A_ddemipa">DdemiPA</code></td>
<td>
<p>The square root of the diagonal matrix <em>D</em> times
the eigen vectors of the symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="fittedA_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues (numerically) equals to 1.</p>
</td></tr>
<tr><td><code id="fittedA_+3A_k">k</code></td>
<td>
<p>A scalar which gives the number of iterations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for detailed explanation of <em>A</em> and <em>D</em>.</p>


<h3>Value</h3>

<p>Returns a list of two components: <code>fitted</code> contains fitted values
and <code>trace</code> contains the trace (effective degree of freedom) of the iterated
bias reduction smoother.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='fittedS1'>Evaluate the fit for iterative bias reduction model</h2><span id='topic+fittedS1'></span>

<h3>Description</h3>

<p>The function evaluates the fit for iterative bias reduction
model for iteration <code>k</code>. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>fittedS1(n,U,tUy,eigenvaluesS1,ddlmini,k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fittedS1_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="fittedS1_+3A_u">U</code></td>
<td>
<p>The the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="fittedS1_+3A_tuy">tUy</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em> times the vector of observation <em>y</em>.</p>
</td></tr>
<tr><td><code id="fittedS1_+3A_eigenvaluess1">eigenvaluesS1</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="fittedS1_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigen values of <em>S</em> equal to 1.</p>
</td></tr>
<tr><td><code id="fittedS1_+3A_k">k</code></td>
<td>
<p>A numeric vector which gives the number of iterations</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see the reference for detailed explanation of computation of iterative bias reduction smoother</p>


<h3>Value</h3>

<p>Returns a vector containing the fit</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='fittedS1lr'>Evaluate the fit for iterative bias reduction model</h2><span id='topic+fittedS1lr'></span>

<h3>Description</h3>

<p>The function evaluates the fit for iterative bias reduction
model for iteration <code>k</code>. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>fittedS1lr(n,U,tUy,eigenvaluesS1,ddlmini,k,rank)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fittedS1lr_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="fittedS1lr_+3A_u">U</code></td>
<td>
<p>The the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="fittedS1lr_+3A_tuy">tUy</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em> times the vector of observation <em>y</em>.</p>
</td></tr>
<tr><td><code id="fittedS1lr_+3A_eigenvaluess1">eigenvaluesS1</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="fittedS1lr_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigen values of <em>S</em> equal to 1.</p>
</td></tr>
<tr><td><code id="fittedS1lr_+3A_k">k</code></td>
<td>
<p>A numeric vector which gives the number of iterations</p>
</td></tr>
<tr><td><code id="fittedS1lr_+3A_rank">rank</code></td>
<td>
<p>The rank of lowrank splines.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see the reference for detailed explanation of computation of iterative bias reduction smoother</p>


<h3>Value</h3>

<p>Returns a vector containing the fit</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='forward'>Iterative bias reduction smoothing</h2><span id='topic+forward'></span><span id='topic+forwardibr'></span>

<h3>Description</h3>

<p> Performs a forward variable selection for iterative bias
reduction using kernel, thin plate splines or low rank splines.
Missing values are not allowed.</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward(formula,data,subset,criterion="gcv",df=1.5,Kmin=1,Kmax=1e+06,
   smoother="k",kernel="g",rank=NULL,control.par=list(),cv.options=list(),
   varcrit=criterion)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="forward_+3A_formula">formula</code></td>
<td>
<p>An object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted. </p>
</td></tr>
<tr><td><code id="forward_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>forward</code> is called.</p>
</td></tr>
<tr><td><code id="forward_+3A_subset">subset</code></td>
<td>
<p>An optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="forward_+3A_criterion">criterion</code></td>
<td>
<p>Character string. If the number of iterations
(<code>iter</code>) is missing or 
<code>NULL</code> the number of iterations is chosen using
<code>criterion</code>. The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>), gMDL  (<code>"gmdl"</code>), map (<code>"map"</code>) or rmse
(<code>"rmse"</code>). The last two are designed for cross-validation.</p>
</td></tr>
<tr><td><code id="forward_+3A_df">df</code></td>
<td>
<p>A numeric vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>, it indicates
the  desired degree of
freedom (trace) of the smoothing   matrix for
each variable or for the initial smoother (see <code>contr.sp$dftotal</code>); <code>df</code> is repeated when the length of vector
<code>df</code> is 1. If <code>smoother="tps"</code>, the minimum df of thin
plate splines is multiplied by <code>df</code>. This argument is useless if
<code>bandwidth</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="forward_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="forward_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="forward_+3A_smoother">smoother</code></td>
<td>
<p>Character string which allows to choose between thine plate
splines <code>"tps"</code> or kernel (<code>"k"</code>).</p>
</td></tr>
<tr><td><code id="forward_+3A_kernel">kernel</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>). The default (gaussian kernel) is strongly advised.</p>
</td></tr>
<tr><td><code id="forward_+3A_rank">rank</code></td>
<td>
<p>Numeric value that control the rank of low rank splines
(denoted as <code>k</code> in mgcv package ; see also <a href="mgcv.html#topic+choose.k">choose.k</a>
for further details or <a href="mgcv.html#topic+gam">gam</a> for another smoothing approach with
reduced rank smoother.</p>
</td></tr>
<tr><td><code id="forward_+3A_control.par">control.par</code></td>
<td>
<p>a named list that control optional parameters. The
components are <code>bandwidth</code> (default to NULL), <code>iter</code>
(default to NULL), <code>really.big</code> (default to <code>FALSE</code>),
<code>dftobwitmax</code> (default to 1000), <code>exhaustive</code> (default to
<code>FALSE</code>),<code>m</code> (default to NULL), <code>dftotal</code> (default to
<code>FALSE</code>), <code>accuracy</code> (default to 0.01), <code>ddlmaxi</code>
(default to 2n/3) and <code>fraction</code> (default to <code>c(100, 200, 500, 1000, 5000,10^4,5e+04,1e+05,5e+05,1e+06)</code>).
</p>
<p><code>bandwidth</code>: a vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>,
it indicates the bandwidth used for
each variable, bandwidth is repeated when the length of vector
<code>bandwidth</code> is 1. If <code>smoother="tps"</code>, it indicates the
amount of penalty (coefficient lambda).
The default (missing) indicates, for <code>smoother="k"</code>, that
bandwidth for each variable is
chosen such that each univariate kernel
smoother (for each explanatory variable) has <code>df</code> degrees of
freedom and for <code>smoother="tps"</code> that lambda is chosen such that
the df of the smoothing matrix is <code>df</code> times the minimum df.
</p>
<p><code>iter</code>: the number of iterations. If null or missing, an optimal number of
iterations is chosen from 
the search grid (integer from <code>Kmin</code> to <code>Kmax</code>) to minimize the <code>criterion</code>.
</p>
<p><code>really.big</code>: a boolean: if <code>TRUE</code> it overides the limitation
at 500 observations. Expect long computation times if <code>TRUE</code>.
</p>
<p><code>dftobwitmax</code>: When bandwidth is chosen by specifying the degree
of freedom (see <code>df</code>) a search is done by
<code><a href="stats.html#topic+uniroot">uniroot</a></code>. This argument specifies the maximum number of iterations transmitted to <code><a href="stats.html#topic+uniroot">uniroot</a></code> function.
</p>
<p><code>exhaustive</code>: boolean, if <code>TRUE</code> an exhaustive search of
optimal number of iteration on the
grid <code>Kmin:Kmax</code> is performed. If <code>FALSE</code> the minimum  of
criterion is searched using <code><a href="stats.html#topic+optimize">optimize</a></code> between <code>Kmin</code>
and <code>Kmax</code>.
</p>
<p><code>m</code>: the order of thin plate splines. This integer <em>m</em> must verifies
2<em>m</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.  The missing default to choose the order <em>m</em> as the first integer
such that 2<em>m</em>/<em>d</em>&gt;1, where <em>d</em> is the number of
explanatory variables (same for <code>NULL</code>). 
</p>
<p><code>dftotal</code>: a boolean wich indicates when <code>FAlSE</code> that the
argument <code>df</code> is the objective df for each univariate kernel (the
default) calculated for each explanatory variable or for the overall
(product) kernel, that is the base smoother (when <code>TRUE</code>).
</p>
<p><code>accuracy</code>: tolerance when searching bandwidths which lead to a
chosen overall intial df.
</p>
<p><code>dfmaxi</code>: the maximum degree of freedom allowed for iterated
biased reduction smoother. 
</p>
<p><code>fraction</code>: the subdivistion of interval <code>Kmin</code>,<code>Kmax</code>
if non exhaustive search is performed (see also <code><a href="#topic+iterchoiceA">iterchoiceA</a></code> or <code><a href="#topic+iterchoiceS1">iterchoiceS1</a></code>). 
</p>
</td></tr>
<tr><td><code id="forward_+3A_cv.options">cv.options</code></td>
<td>
<p>A named list which controls the way to do cross
validation with component <code>bwchange</code>,
<code>ntest</code>, <code>ntrain</code>, <code>Kfold</code>, <code>type</code>,
<code>seed</code>, <code>method</code> and <code>npermut</code>. <code>bwchange</code> is a boolean (default to <code>FALSE</code>)
which indicates if bandwidth have to be recomputed each
time. <code>ntest</code> is the number of observations in test set and
<code>ntrain</code> is the number of observations in training set. Actually,
only one of these is needed the other can be <code>NULL</code> or missing. <code>Kfold</code> a boolean or an integer. If
<code>Kfold</code> is <code>TRUE</code> then the number of fold is deduced from
<code>ntest</code> (or <code>ntrain</code>).  <code>type</code> is a character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.  <code>seed</code> controls the seed of
random generator. <code>method</code> is either <code>"inmemory"</code> or
<code>"outmemory"</code>; <code>"inmemory"</code> induces some calculations outside
the loop saving computational time but leading to an increase of the required
memory. <code>npermut</code> is the number of random draws.   If
<code>cv.options</code> is <code>list()</code>, then component <code>ntest</code> is set to
<code>floor(nrow(x)/10)</code>, <code>type</code> is random, <code>npermut</code> is 20
and <code>method</code> is <code>"inmemory"</code>, and the other components are
<code>NULL</code></p>
</td></tr>
<tr><td><code id="forward_+3A_varcrit">varcrit</code></td>
<td>
<p>Character string. Criterion used for variable
selection. The criteria available are GCV,
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>) and gMDL  (<code>"gmdl"</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p> Returns an object of class <code>forwardibr</code> which is a matrix
with <code>p</code> columns. In the first row, each entry <em>j</em> contains
the value of the chosen criterion for the univariate smoother using
the jth explanatory variable. The variable which realize the minimum
of the first row is included in the model. All the column of this
variable will be <code>Inf</code> except the first row. In the second row,
each entry <em>j</em> contains the bivariate smoother using the jth
explanatory variable and the variable already included. The variable
which realize the minimum of the second row is included in the
model. All the column of this variable will be <code>Inf</code> except the
two first row. This forward selection process continue until the
chosen criterion increases.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+plot.forwardibr">plot.forwardibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(ozone, package = "ibr")
res.ibr &lt;- forward(ozone[,-1],ozone[,1],df=1.2)
apply(res.ibr,1,which.min)

## End(Not run)
</code></pre>

<hr>
<h2 id='ibr'>Iterative bias reduction smoothing</h2><span id='topic+ibr'></span><span id='topic+print.ibr'></span><span id='topic+residuals.ibr'></span>

<h3>Description</h3>

<p>Performs iterative bias reduction using kernel, thin plate
splines Duchon splines or low rank splines. 
Missing values are not allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ibr(formula, data, subset, criterion="gcv", df=1.5, Kmin=1, Kmax=1e+06, smoother="k",
 kernel="g", rank=NULL, control.par=list(), cv.options=list())</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ibr_+3A_formula">formula</code></td>
<td>
<p>An object of class <code>"<a href="stats.html#topic+formula">formula</a>"</code> (or one that
can be coerced to that class): a symbolic description of the
model to be fitted. </p>
</td></tr>
<tr><td><code id="ibr_+3A_data">data</code></td>
<td>
<p>An optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>ibr</code> is called.</p>
</td></tr>
<tr><td><code id="ibr_+3A_subset">subset</code></td>
<td>
<p>An optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="ibr_+3A_criterion">criterion</code></td>
<td>
<p>A vector of string. If the number of iterations
(<code>iter</code>) is missing or 
<code>NULL</code> the number of iterations is chosen using the either one
criterion (the first
coordinate of <code>criterion</code>) or several (see component
<code>criterion</code> of argument list <code>control.par</code>). The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>), gMDL  (<code>"gmdl"</code>), map (<code>"map"</code>) or rmse
(<code>"rmse"</code>). The last two are designed for cross-validation.</p>
</td></tr>
<tr><td><code id="ibr_+3A_df">df</code></td>
<td>
<p>A numeric vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>, it indicates
the  desired effective degree of
freedom (trace) of the smoothing   matrix for
each variable or for the initial smoother (see <code>contr.sp$dftotal</code>); <code>df</code> is repeated when the length of vector
<code>df</code> is 1. If <code>smoother="tps"</code> or  <code>smoother="ds"</code>, the
minimum df of splines is multiplied by <code>df</code>. This argument is useless if
<code>bandwidth</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="ibr_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="ibr_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="ibr_+3A_smoother">smoother</code></td>
<td>
<p>Character string which allows to choose between thin plate
splines <code>"tps"</code>, Duchon
splines <code>"tps"</code> (see Duchon, 1977) or kernel (<code>"k"</code>). </p>
</td></tr>
<tr><td><code id="ibr_+3A_kernel">kernel</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>). The default (gaussian kernel) is strongly advised.</p>
</td></tr>
<tr><td><code id="ibr_+3A_rank">rank</code></td>
<td>
<p>Numeric value that control the rank of low rank splines
(denoted as <code>k</code> in mgcv package ; see also <a href="mgcv.html#topic+choose.k">choose.k</a>
for further details or <a href="mgcv.html#topic+gam">gam</a> for another smoothing approach with
reduced rank smoother.</p>
</td></tr>
<tr><td><code id="ibr_+3A_control.par">control.par</code></td>
<td>
<p>A named list that control optional parameters. The
components are <code>bandwidth</code> (default to NULL), <code>iter</code>
(default to NULL), <code>really.big</code> (default to <code>FALSE</code>),
<code>dftobwitmax</code> (default to 1000), <code>exhaustive</code> (default to
<code>FALSE</code>),<code>m</code> (default to NULL), ,<code>s</code> (default to NULL),
<code>dftotal</code> (default to <code>FALSE</code>), <code>accuracy</code> (default to
0.01), <code>ddlmaxi</code> (default to 2n/3), <code>fraction</code> (default
to <code>c(100, 200, 500, 1000, 5000, 10^4, 5e+04, 1e+05, 5e+05,
    1e+06)</code>), <code>scale</code> (default to <code>FALSE</code>),
<code>criterion</code> (default to <code>"strict"</code>) and
<code>aggregfun</code> (default to 10^(floor(log10(x[2]))+2)).
</p>
<p><code>bandwidth</code>: a vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>,
it indicates the bandwidth used for
each variable, bandwidth is repeated when the length of vector
<code>bandwidth</code> is 1. If <code>smoother="tps"</code>, it indicates the
amount of penalty (coefficient lambda).
The default (missing) indicates, for <code>smoother="k"</code>, that
bandwidth for each variable is
chosen such that each univariate kernel
smoother (for each explanatory variable) has <code>df</code> effective degrees of
freedom and for <code>smoother="tps"</code> or <code>smoother="ds"</code> that lambda is chosen such that
the df of the smoothing matrix is <code>df</code> times the minimum df.
</p>
<p><code>iter</code>: the number of iterations. If null or missing, an optimal number of
iterations is chosen from 
the search grid (integer from <code>Kmin</code> to <code>Kmax</code>) to minimize the <code>criterion</code>.
</p>
<p><code>really.big</code>: a boolean: if <code>TRUE</code> it overides the limitation
at 500 observations. Expect long computation times if <code>TRUE</code>.
</p>
<p><code>dftobwitmax</code>: When bandwidth is chosen by specifying the effective
degree
of freedom (see <code>df</code>) a search is done by
<code><a href="stats.html#topic+uniroot">uniroot</a></code>. This argument specifies the maximum number of iterations transmitted to <code><a href="stats.html#topic+uniroot">uniroot</a></code> function.
</p>
<p><code>exhaustive</code>: boolean, if <code>TRUE</code> an exhaustive search of
optimal number of iteration on the grid <code>Kmin:Kmax</code> is
performed. All criteria for all iterations in the same class (class
one: GCV, AIC, corrected AIC, BIC, gMDL ; class two : MAP, RMSE) are
returned in argument <code>allcrit</code>. If <code>FALSE</code> the minimum of
criterion is searched using <code><a href="stats.html#topic+optimize">optimize</a></code> between <code>Kmin</code>
and <code>Kmax</code>.
</p>
<p><code>m</code>: The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of
explanatory variables. The default (for <code>smoother="tps"</code>) is to
choose the order <em>m</em> as the first integer such that
2<em>m</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables. The default (for <code>smoother="ds"</code>) is to choose
<em>m</em>=2 (p
seudo cubic splines).
</p>
<p><code>s</code>: the power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines (the default),
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).the order of thin plate splines. This integer <em>m</em> must verifies
2<em>m</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables. 
</p>
<p><code>dftotal</code>: a boolean wich indicates when <code>FAlSE</code> that the
argument <code>df</code> is the objective df for each univariate kernel (the
default) calculated for each explanatory variable or for the overall
(product) kernel, that is the base smoother (when <code>TRUE</code>).
</p>
<p><code>accuracy</code>: tolerance when searching bandwidths which lead to a
chosen overall intial df.
</p>
<p><code>dfmaxi</code>: the maximum effective degree of freedom allowed for iterated
biased reduction smoother. 
</p>
<p><code>fraction</code>: the subdivision of interval <code>Kmin</code>,<code>Kmax</code>
if non exhaustive search is performed (see also <code><a href="#topic+iterchoiceA">iterchoiceA</a></code> or <code><a href="#topic+iterchoiceS1">iterchoiceS1</a></code>). 
</p>
<p><code>scale</code>: boolean. If <code>TRUE</code> <code>x</code> is scaled (using
<code><a href="base.html#topic+scale">scale</a></code>); default to <code>FALSE</code>.
</p>
<p><code>criterion</code> Character string. Possible choices are <code>strict</code>,
<code>aggregation</code> or <code>recalc</code>. <code>strict</code>
allows to select the number of iterations according to
the first coordinate of argument <code>criterion</code>.
<code>aggregation</code>
allows to select the number of iterations by applying the
function <code>control.par$aggregfun</code> to the number of iterations
selected by all the criteria chosen in argument <code>criterion</code>.
<code>recalc</code>
allows to select the number of iterations by first calculating the
optimal number of the second coordinate of argument
<code>criterion</code>, then applying the function
<code>control.par$aggregfun</code> (to add some number to
it) resulting in a new <code>Kmax</code> and then doing the optimal selction
between  <code>Kmin</code> and this new <code>Kmax</code> using the first coordinate of argument
<code>criterion</code>.
; default to <code>strict</code>.
</p>
<p><code>aggregfun</code> function to be applied when
<code>control.par$criterion</code> is either <code>recalc</code> or
<code>aggregation</code>. 
</p>
</td></tr>
<tr><td><code id="ibr_+3A_cv.options">cv.options</code></td>
<td>
<p>A named list which controls the way to do cross
validation with component <code>bwchange</code>,
<code>ntest</code>, <code>ntrain</code>, <code>Kfold</code>, <code>type</code>,
<code>seed</code>, <code>method</code> and <code>npermut</code>. <code>bwchange</code> is a boolean (default to <code>FALSE</code>)
which indicates if bandwidth have to be recomputed each
time. <code>ntest</code> is the number of observations in test set and
<code>ntrain</code> is the number of observations in training set. Actually,
only one of these is needed the other can be <code>NULL</code> or missing. <code>Kfold</code> a boolean or an integer. If
<code>Kfold</code> is <code>TRUE</code> then the number of fold is deduced from
<code>ntest</code> (or <code>ntrain</code>).  <code>type</code> is a character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.  <code>seed</code> controls the seed of
random generator. <code>method</code> is either <code>"inmemory"</code> or
<code>"outmemory"</code>; <code>"inmemory"</code> induces some calculations outside
the loop saving computational time but leading to an increase of the required
memory. <code>npermut</code> is the number of random draws.   If
<code>cv.options</code> is <code>list()</code>, then component <code>ntest</code> is set to
<code>floor(nrow(x)/10)</code>, <code>type</code> is random, <code>npermut</code> is 20
and <code>method</code> is <code>"inmemory"</code>, and the other components are <code>NULL</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>ibr</code> which is a list including:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>Vector of residuals.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>Vector of fitted values.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iterations used.</p>
</td></tr>
<tr><td><code>initialdf</code></td>
<td>
<p>The initial effective degree of freedom of the pilot (or base) smoother.</p>
</td></tr>
<tr><td><code>finaldf</code></td>
<td>
<p>The effective degree of freedom of the iterated bias reduction
smoother at the <code>iter</code> iterations.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>Vector of bandwith for each explanatory variable</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call</p>
</td></tr>
<tr><td><code>parcall</code></td>
<td>
<p>A list containing several components: 
<code>p</code> contains the number of explanatory variables and <code>m</code>
the order of the splines (if relevant), <code>s</code>
the power of weights, <code>scaled</code> boolean which is <code>TRUE</code>
when explanatory variables are scaled, <code>mean</code> mean of explanatory
variables if <code>scaled=TRUE</code>, <code>sd</code> standard deviation of
explanatory variables if <code>scaled=TRUE</code>,  <code>critmethod</code> that indicates the method chosen
for criteria <code>strict</code>,
<code>rank</code> the rank of low rank splines if relevant,
<code>criterion</code> the chosen criterion,
<code>smoother</code> the chosen smoother,
<code>kernel</code> the chosen kernel,
<code>smoothobject</code> the smoothobject returned by
<a href="mgcv.html#topic+smoothCon">smoothCon</a>,
<code>exhaustive</code> a boolean which indicates if an exhaustive
search was chosen</p>
</td></tr>
<tr><td><code>criteria</code></td>
<td>
<p>Value
of the chosen criterion at the given iteration, <code>NA</code> is
returned when aggregation of criteria is chosen (see component
<code>criterion</code> of list <code>control.par</code>). If the number of iterations
<code>iter</code> is given by the user, <code>NULL</code> is returned</p>
</td></tr>
<tr><td><code>alliter</code></td>
<td>
<p>Numeric vector giving all the optimal number of iterations
selected by  the chosen criteria.</p>
</td></tr>
<tr><td><code>allcriteria</code></td>
<td>
<p>either a list containing all the criteria evaluated on the
grid <code>Kmin:Kmax</code> (along with the effective degree of freedom of the
smoother and the sigma squared on this grid) if an exhaustive search is chosen (see the
value of function 
<code><a href="#topic+iterchoiceAe">iterchoiceAe</a></code> or <code><a href="#topic+iterchoiceS1e">iterchoiceS1e</a></code>) 
or all the values
of criteria at the given optimal iteration if a non exhaustive
search is chosen (see also <code>exhaustive</code> component of list
<code>control.par</code>).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>The 'terms' object used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.ibr">predict.ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code>, <a href="mgcv.html#topic+gam">gam</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x, y) { .75*exp(-((9*x-2)^2 + (9*y-2)^2)/4) +
                      .75*exp(-((9*x+1)^2/49 + (9*y+1)^2/10)) +
                      .50*exp(-((9*x-7)^2 + (9*y-3)^2)/4) -
                      .20*exp(-((9*x-4)^2 + (9*y-7)^2)) }
# define a (fine) x-y grid and calculate the function values on the grid
ngrid &lt;- 50; xf &lt;- seq(0,1, length=ngrid+2)[-c(1,ngrid+2)]
yf &lt;- xf ; zf &lt;- outer(xf, yf, f)
grid &lt;- cbind.data.frame(x=rep(xf, ngrid),y=rep(xf, rep(ngrid, ngrid)),z=as.vector(zf))
persp(xf, yf, zf, theta=130, phi=20, expand=0.45,main="True Function")
#generate a data set with function f and noise to signal ratio 5
noise &lt;- .2 ; N &lt;- 100 
xr &lt;- seq(0.05,0.95,by=0.1) ; yr &lt;- xr ; zr &lt;- outer(xr,yr,f) ; set.seed(25)
std &lt;- sqrt(noise*var(as.vector(zr))) ; noise &lt;- rnorm(length(zr),0,std)
Z &lt;- zr + matrix(noise,sqrt(N),sqrt(N))
# transpose the data to a column format 
xc &lt;- rep(xr, sqrt(N)) ; yc &lt;- rep(yr, rep(sqrt(N),sqrt(N)))
data &lt;- cbind.data.frame(x=xc,y=yc,z=as.vector(Z))
# fit by thin plate splines (of order 2) ibr
res.ibr &lt;- ibr(z~x+y,data=data,df=1.1,smoother="tps")
fit &lt;- matrix(predict(res.ibr,grid),ngrid,ngrid)
persp(xf, yf, fit ,theta=130,phi=20,expand=0.45,main="Fit",zlab="fit")

## Not run: 
data(ozone, package = "ibr")
res.ibr &lt;- ibr(Ozone~.,data=ozone,df=1.1)
summary(res.ibr)
predict(res.ibr)
## End(Not run)
</code></pre>

<hr>
<h2 id='ibr.fit'>Iterative bias reduction smoothing</h2><span id='topic+ibr.fit'></span>

<h3>Description</h3>

<p>Performs iterative bias reduction using kernel, thin plate
splines, Duchon splines or low rank splines. 
Missing values are not allowed. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ibr.fit(x, y, criterion="gcv", df=1.5, Kmin=1, Kmax=1e+06, smoother="k",
 kernel="g", rank=NULL, control.par=list(), cv.options=list())</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ibr.fit_+3A_x">x</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_criterion">criterion</code></td>
<td>
<p>A vector of string. If the number of iterations
(<code>iter</code>) is missing or 
<code>NULL</code> the number of iterations is chosen using the either one
criterion (the first
coordinate of <code>criterion</code>) or several (see component
<code>criterion</code> of argument list <code>control.par</code>). The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>), gMDL  (<code>"gmdl"</code>), map (<code>"map"</code>) or rmse
(<code>"rmse"</code>). The last two are designed for cross-validation.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_df">df</code></td>
<td>
<p>A numeric vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>, it indicates
the  desired effective degree of
freedom (trace) of the smoothing   matrix for
each variable or for the initial smoother (see <code>contr.sp$dftotal</code>); <code>df</code> is repeated when the length of vector
<code>df</code> is 1. If <code>smoother="tps"</code> or  <code>smoother="ds"</code>, the
minimum df of splines is multiplied by <code>df</code>. This argument is useless if
<code>bandwidth</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_smoother">smoother</code></td>
<td>
<p>Character string which allows to choose between thin plate
splines <code>"tps"</code>, Duchon
splines <code>"tps"</code> (see Duchon, 1977) or kernel (<code>"k"</code>). </p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_kernel">kernel</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>). The default (gaussian kernel) is strongly advised.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_rank">rank</code></td>
<td>
<p>Numeric value that control the rank of low rank splines
(denoted as <code>k</code> in mgcv package ; see also <a href="mgcv.html#topic+choose.k">choose.k</a>
for further details or <a href="mgcv.html#topic+gam">gam</a> for another smoothing approach with
reduced rank smoother.</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_control.par">control.par</code></td>
<td>
<p>A named list that control optional parameters. The
components are <code>bandwidth</code> (default to NULL), <code>iter</code>
(default to NULL), <code>really.big</code> (default to <code>FALSE</code>),
<code>dftobwitmax</code> (default to 1000), <code>exhaustive</code> (default to
<code>FALSE</code>),<code>m</code> (default to NULL), ,<code>s</code> (default to NULL),
<code>dftotal</code> (default to <code>FALSE</code>), <code>accuracy</code> (default to
0.01), <code>ddlmaxi</code> (default to 2n/3), <code>fraction</code> (default
to <code>c(100, 200, 500, 1000, 5000, 10^4, 5e+04, 1e+05, 5e+05,
    1e+06)</code>), <code>scale</code> (default to <code>FALSE</code>),
<code>criterion</code> (default to <code>"strict"</code>) and
<code>aggregfun</code> (default to 10^(floor(log10(x[2]))+2)).
</p>
<p><code>bandwidth</code>: a vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>,
it indicates the bandwidth used for
each variable, bandwidth is repeated when the length of vector
<code>bandwidth</code> is 1. If <code>smoother="tps"</code>, it indicates the
amount of penalty (coefficient lambda).
The default (missing) indicates, for <code>smoother="k"</code>, that
bandwidth for each variable is
chosen such that each univariate kernel
smoother (for each explanatory variable) has <code>df</code> effective degrees of
freedom and for <code>smoother="tps"</code> or <code>smoother="ds"</code> that lambda is chosen such that
the df of the smoothing matrix is <code>df</code> times the minimum df.
</p>
<p><code>iter</code>: the number of iterations. If null or missing, an optimal number of
iterations is chosen from 
the search grid (integer from <code>Kmin</code> to <code>Kmax</code>) to minimize the <code>criterion</code>.
</p>
<p><code>really.big</code>: a boolean: if <code>TRUE</code> it overides the limitation
at 500 observations. Expect long computation times if <code>TRUE</code>.
</p>
<p><code>dftobwitmax</code>: When bandwidth is chosen by specifying the effective
degree
of freedom (see <code>df</code>) a search is done by
<code><a href="stats.html#topic+uniroot">uniroot</a></code>. This argument specifies the maximum number of iterations transmitted to <code><a href="stats.html#topic+uniroot">uniroot</a></code> function.
</p>
<p><code>exhaustive</code>: boolean, if <code>TRUE</code> an exhaustive search of
optimal number of iteration on the grid <code>Kmin:Kmax</code> is
performed. All criteria for all iterations in the same class (class
one: GCV, AIC, corrected AIC, BIC, gMDL ; class two : MAP, RMSE) are
returned in argument <code>allcrit</code>. If <code>FALSE</code> the minimum of
criterion is searched using <code><a href="stats.html#topic+optimize">optimize</a></code> between <code>Kmin</code>
and <code>Kmax</code>.
</p>
<p><code>m</code>: The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of
explanatory variables. The default (for <code>smoother="tps"</code>) is to
choose the order <em>m</em> as the first integer such that
2<em>m</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables. The default (for <code>smoother="ds"</code>) is to choose
<em>m</em>=2 (p
seudo cubic splines).
</p>
<p><code>s</code>: the power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines (the default),
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).the order of thin plate splines. This integer <em>m</em> must verifies
2<em>m</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables. 
</p>
<p><code>dftotal</code>: a boolean wich indicates when <code>FAlSE</code> that the
argument <code>df</code> is the objective df for each univariate kernel (the
default) calculated for each explanatory variable or for the overall
(product) kernel, that is the base smoother (when <code>TRUE</code>).
</p>
<p><code>accuracy</code>: tolerance when searching bandwidths which lead to a
chosen overall intial df.
</p>
<p><code>dfmaxi</code>: the maximum effective degree of freedom allowed for iterated
biased reduction smoother. 
</p>
<p><code>fraction</code>: the subdivision of interval <code>Kmin</code>,<code>Kmax</code>
if non exhaustive search is performed (see also <code><a href="#topic+iterchoiceA">iterchoiceA</a></code> or <code><a href="#topic+iterchoiceS1">iterchoiceS1</a></code>). 
</p>
<p><code>scale</code>: boolean. If <code>TRUE</code> <code>x</code> is scaled (using
<code><a href="base.html#topic+scale">scale</a></code>); default to <code>FALSE</code>.
</p>
<p><code>criterion</code> Character string. Possible choices are <code>strict</code>,
<code>aggregation</code> or <code>recalc</code>. <code>strict</code>
allows to select the number of iterations according to
the first coordinate of argument <code>criterion</code>.
<code>aggregation</code>
allows to select the number of iterations by applying the
function <code>control.par$aggregfun</code> to the number of iterations
selected by all the criteria chosen in argument <code>criterion</code>.
<code>recalc</code>
allows to select the number of iterations by first calculating the
optimal number of the second coordinate of argument
<code>criterion</code>, then applying the function
<code>control.par$aggregfun</code> (to add some number to
it) resulting in a new <code>Kmax</code> and then doing the optimal selction
between  <code>Kmin</code> and this new <code>Kmax</code> using the first coordinate of argument
<code>criterion</code>.
; default to <code>strict</code>.
</p>
<p><code>aggregfun</code> function to be applied when
<code>control.par$criterion</code> is either <code>recalc</code> or
<code>aggregation</code>. 
</p>
</td></tr>
<tr><td><code id="ibr.fit_+3A_cv.options">cv.options</code></td>
<td>
<p>A named list which controls the way to do cross
validation with component <code>bwchange</code>,
<code>ntest</code>, <code>ntrain</code>, <code>Kfold</code>, <code>type</code>,
<code>seed</code>, <code>method</code> and <code>npermut</code>. <code>bwchange</code> is a boolean (default to <code>FALSE</code>)
which indicates if bandwidth have to be recomputed each
time. <code>ntest</code> is the number of observations in test set and
<code>ntrain</code> is the number of observations in training set. Actually,
only one of these is needed the other can be <code>NULL</code> or missing. <code>Kfold</code> a boolean or an integer. If
<code>Kfold</code> is <code>TRUE</code> then the number of fold is deduced from
<code>ntest</code> (or <code>ntrain</code>).  <code>type</code> is a character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.  <code>seed</code> controls the seed of
random generator. <code>method</code> is either <code>"inmemory"</code> or
<code>"outmemory"</code>; <code>"inmemory"</code> induces some calculations outside
the loop saving computational time but leading to an increase of the required
memory. <code>npermut</code> is the number of random draws.   If
<code>cv.options</code> is <code>list()</code>, then component <code>ntest</code> is set to
<code>floor(nrow(x)/10)</code>, <code>type</code> is random, <code>npermut</code> is 20
and <code>method</code> is <code>"inmemory"</code>, and the other components are <code>NULL</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list including:
</p>
<table role = "presentation">
<tr><td><code>beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>Vector of residuals.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>Vector of fitted values.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iterations used.</p>
</td></tr>
<tr><td><code>initialdf</code></td>
<td>
<p>The initial effective degree of freedom of the pilot (or base) smoother.</p>
</td></tr>
<tr><td><code>finaldf</code></td>
<td>
<p>The effective degree of freedom of the iterated bias reduction
smoother at the <code>iter</code> iterations.</p>
</td></tr>
<tr><td><code>bandwidth</code></td>
<td>
<p>Vector of bandwith for each explanatory variable</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>The matched call</p>
</td></tr>
<tr><td><code>parcall</code></td>
<td>
<p>A list containing several components: 
<code>p</code> contains the number of explanatory variables and <code>m</code>
the order of the splines (if relevant), <code>s</code>
the power of weights, <code>scaled</code> boolean which is <code>TRUE</code>
when explanatory variables are scaled, <code>mean</code> mean of explanatory
variables if <code>scaled=TRUE</code>, <code>sd</code> standard deviation of
explanatory variables if <code>scaled=TRUE</code>,  <code>critmethod</code> that indicates the method chosen
for criteria <code>strict</code>,
<code>rank</code> the rank of low rank splines if relevant,
<code>criterion</code> the chosen criterion,
<code>smoother</code> the chosen smoother,
<code>kernel</code> the chosen kernel,
<code>smoothobject</code> the smoothobject returned by
<a href="mgcv.html#topic+smoothCon">smoothCon</a>,
<code>exhaustive</code> a boolean which indicates if an exhaustive
search was chosen</p>
</td></tr>
<tr><td><code>criteria</code></td>
<td>
<p>Value
of the chosen criterion at the given iteration, <code>NA</code> is
returned when aggregation of criteria is chosen (see component
<code>criterion</code> of list <code>control.par</code>). If the number of iterations
<code>iter</code> is given by the user, <code>NULL</code> is returned</p>
</td></tr>
<tr><td><code>alliter</code></td>
<td>
<p>Numeric vector giving all the optimal number of iterations
selected by  the chosen criteria.</p>
</td></tr>
<tr><td><code>allcriteria</code></td>
<td>
<p>either a list containing all the criteria evaluated on the
grid <code>Kmin:Kmax</code> (along with the effective degree of freedom of the
smoother and the sigma squared on this grid) if an exhaustive search is chosen (see the
value of function 
<code><a href="#topic+iterchoiceAe">iterchoiceAe</a></code> or <code><a href="#topic+iterchoiceS1e">iterchoiceS1e</a></code>) 
or all the values
of criteria at the given optimal iteration if a non exhaustive
search is chosen (see also <code>exhaustive</code> component of list
<code>control.par</code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+predict.ibr">predict.ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code>, <a href="mgcv.html#topic+gam">gam</a></p>

<hr>
<h2 id='iterchoiceA'>Selection of the number of iterations for iterative bias reduction smoothers</h2><span id='topic+iterchoiceA'></span><span id='topic+critAgcv'></span><span id='topic+critAaic'></span><span id='topic+critAbic'></span><span id='topic+critAaicc'></span><span id='topic+critAgmdl'></span>

<h3>Description</h3>

<p> The function <code>iterchoiceA</code> searches the interval from
<code>mini</code> to <code>maxi</code> for a minimum of the function
which calculates the chosen
<code>criterion</code> (<code>critAgcv</code>, <code>critAaic</code>, <code>critAbic</code>,
<code>critAaicc</code> or <code>critAgmdl</code>)  with respect to its first
argument (a given iteration <code>k</code>) using <code><a href="stats.html#topic+optimize">optimize</a></code>. This function is not
intended to be used directly.  </p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceA(n, mini, maxi, eigenvaluesA, tPADmdemiY, DdemiPA, 
ddlmini, ddlmaxi, y, criterion, fraction)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceA_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_mini">mini</code></td>
<td>
<p>The lower end point of the interval to be searched.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_maxi">maxi</code></td>
<td>
<p>The upper end point of the interval to be searched.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_eigenvaluesa">eigenvaluesA</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_tpadmdemiy">tPADmdemiY</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric matrix <em>A</em> times the inverse of the square root of the diagonal matrix <em>D</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_ddemipa">DdemiPA</code></td>
<td>
<p>The square root of the diagonal matrix <em>D</em> times
the eigen vectors of the symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues (numerically) equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_ddlmaxi">ddlmaxi</code></td>
<td>
<p>The  maximum df. No criterion is calculated and
<code>Inf</code> is returned.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_y">y</code></td>
<td>
<p>The vector of observations of dependant variable.</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_criterion">criterion</code></td>
<td>
<p>The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>) or gMDL  (<code>"gmdl"</code>).</p>
</td></tr>
<tr><td><code id="iterchoiceA_+3A_fraction">fraction</code></td>
<td>
<p>The subdivision of the interval [<code>mini</code>,<code>maxi</code>].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for detailed explanation of <em>A</em> and
<em>D</em>. The interval [<code>mini</code>,<code>maxi</code>] is splitted into
subintervals using <code>fraction</code>. In each subinterval the function
<code>fcriterion</code> is minimzed  using <code><a href="stats.html#topic+optimize">optimize</a></code> (with respect
to its first argument) and the minimum (and its argument) of the
result of these optimizations is returned.</p>


<h3>Value</h3>

<p>A list with components <code>iter</code> and <code>objective</code> which give the
(rounded) optimum number of iterations (between
<code>Kmin</code> and <code>Kmax</code>) and the value
of the function at that real point (not rounded).</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+iterchoiceA">iterchoiceA</a></code></p>

<hr>
<h2 id='iterchoiceAcv'>Selection of the number of iterations for iterative bias reduction smoothers</h2><span id='topic+iterchoiceAcv'></span>

<h3>Description</h3>

<p>The function <code>iterchoiceAcv</code> searches the interval from <code>mini</code> to
<code>maxi</code> for a minimum of the function <code>criterion</code> with respect
to its first argument using <code><a href="stats.html#topic+optimize">optimize</a></code>. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceAcv(X, y, bx, df, kernelx, ddlmini, ntest, ntrain, Kfold,
type, npermut, seed, Kmin, Kmax, criterion, fraction)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceAcv_+3A_x">X</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_bx">bx</code></td>
<td>
<p>The vector of different bandwidths, length <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_df">df</code></td>
<td>
<p>A numeric vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>, it indicates
the  desired effective degree of
freedom (trace) of the smoothing   matrix for
each variable ; <code>df</code> is repeated when the length of vector
<code>df</code> is 1. This argument is useless if
<code>bandwidth</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_kernelx">kernelx</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>). The default (gaussian kernel) is strongly advised.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues (numerically) equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_criterion">criterion</code></td>
<td>
<p>The criteria available are map (<code>"map"</code>) or rmse
(<code>"rmse"</code>).</p>
</td></tr>
<tr><td><code id="iterchoiceAcv_+3A_fraction">fraction</code></td>
<td>
<p>The subdivision of the interval [<code>Kmin</code>,<code>Kmax</code>].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the optimum number of iterations (between <code>Kmin</code> and <code>Kmax</code>).</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='iterchoiceAcve'>Selection of the number of iterations for iterative bias reduction smoothers</h2><span id='topic+iterchoiceAcve'></span>

<h3>Description</h3>

<p>Evaluates at each iteration proposed in the grid the cross-validated
root mean squared error (RMSE) and mean of the relative absolute error (MAP). The minimum of these
criteria gives an estimate of the optimal number of iterations.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceAcve(X, y, bx, df, kernelx, ddlmini, ntest, ntrain,
Kfold, type, npermut, seed, Kmin, Kmax)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceAcve_+3A_x">X</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_bx">bx</code></td>
<td>
<p>The vector of different bandwidths, length <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_df">df</code></td>
<td>
<p>A numeric vector of either length 1 or length equal to the
number of columns of <code>x</code>. If <code>smoother="k"</code>, it indicates
the  desired effective degree of
freedom (trace) of the smoothing   matrix for
each variable ; <code>df</code> is repeated when the length of vector
<code>df</code> is 1. This argument is useless if
<code>bandwidth</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_kernelx">kernelx</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>). The default (gaussian kernel) is strongly advised.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues (numerically) equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceAcve_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the values of RMSE and MAP for each
value of the grid <code>K</code>. <code>Inf</code> are returned if the iteration leads
to a smoother with a df bigger than <code>ddlmaxi</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='iterchoiceAe'>Selection of the number of iterations for iterative bias reduction smoothers</h2><span id='topic+iterchoiceAe'></span>

<h3>Description</h3>

<p>Evaluates at each iteration proposed in the grid the value of different
criteria: GCV, AIC, corrected AIC, BIC and gMDL (along with the ddl and sigma
squared). The minimum of these
criteria gives an estimate of the optimal number of iterations.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceAe(Y, K, eigenvaluesA, tPADmdemiY, DdemiPA, ddlmini,
ddlmaxi)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceAe_+3A_y">Y</code></td>
<td>
<p>The response variable.</p>
</td></tr>
<tr><td><code id="iterchoiceAe_+3A_k">K</code></td>
<td>
<p>A numeric vector which give the search grid for iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceAe_+3A_eigenvaluesa">eigenvaluesA</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceAe_+3A_tpadmdemiy">tPADmdemiY</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric matrix <em>A</em> times the inverse of the square root of the diagonal matrix <em>D</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceAe_+3A_ddemipa">DdemiPA</code></td>
<td>
<p>The square root of the diagonal matrix <em>D</em> times
the eigen vectors of the symmetric matrix <em>A</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceAe_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues (numerically) which are equal to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceAe_+3A_ddlmaxi">ddlmaxi</code></td>
<td>
<p>The maximum df. No criteria are calculated beyond the
number of iterations that leads to df bigger than this bound.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the reference for detailed explanation of <em>A</em> and <em>D</em></p>


<h3>Value</h3>

<p>Returns the values of GCV, AIC, corrected AIC, BIC, gMDL, df and sigma squared for each
value of the grid <code>K</code>. <code>Inf</code> are returned if the iteration leads
to a smoother with a df bigger than <code>ddlmaxi</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+iterchoiceA">iterchoiceA</a></code></p>

<hr>
<h2 id='iterchoiceS1'>Number of iterations selection for iterative bias reduction model</h2><span id='topic+iterchoiceS1'></span><span id='topic+critS1gcv'></span><span id='topic+critS1aic'></span><span id='topic+critS1bic'></span><span id='topic+critS1aicc'></span><span id='topic+critS1gmdl'></span>

<h3>Description</h3>

<p>The function <code>iterchoiceS1</code> searches the interval from <code>mini</code> to
<code>maxi</code> for a minimum of the function which calculates the chosen
<code>criterion</code> (<code>critS1gcv</code>, <code>critS1aic</code>, <code>critS1bic</code>,
<code>critS1aicc</code> or <code>critS1gmdl</code>)  with respect to its first
argument (a given iteration <code>k</code>) using <code><a href="stats.html#topic+optimize">optimize</a></code>. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceS1(n, mini, maxi, tUy, eigenvaluesS1, ddlmini, ddlmaxi,
y, criterion, fraction)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceS1_+3A_n">n</code></td>
<td>
<p>The number of observations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_mini">mini</code></td>
<td>
<p>The lower end point of the interval to be searched.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_maxi">maxi</code></td>
<td>
<p>The upper end point of the interval to be searched.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_eigenvaluess1">eigenvaluesS1</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_tuy">tUy</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em> times the vector of observation <em>y</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigen values of <em>S</em> equal to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_ddlmaxi">ddlmaxi</code></td>
<td>
<p>The  maximum df. No criterion is calculated and
<code>Inf</code> is returned.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_y">y</code></td>
<td>
<p>The vector of observations of dependant variable.</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_criterion">criterion</code></td>
<td>
<p>The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>) or gMDL  (<code>"gmdl"</code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1_+3A_fraction">fraction</code></td>
<td>
<p>The subdivision of the interval [<code>mini</code>,<code>maxi</code>].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The interval [<code>mini</code>,<code>maxi</code>] is splitted into
subintervals using <code>fraction</code>. In each subinterval the function
<code>fcriterion</code> is minimzed  using <code><a href="stats.html#topic+optimize">optimize</a></code> (with respect
to its first argument) and the minimum (and its argument) of the
result of these optimizations is returned.</p>


<h3>Value</h3>

<p>A list with components <code>iter</code> and <code>objective</code> which give the
(rounded) optimum number of iterations (between
<code>Kmin</code> and <code>Kmax</code>) and the value
of the function at that real point (not rounded).</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+iterchoiceS1">iterchoiceS1</a></code></p>

<hr>
<h2 id='iterchoiceS1cv'>Selection of the number of iterations for iterative bias
reduction smoothers with base thin-plate splines or duchon splines smoother</h2><span id='topic+iterchoiceS1cv'></span>

<h3>Description</h3>

<p>The function <code>iterchoiceS1cv</code> searches the interval from <code>mini</code> to
<code>maxi</code> for a minimum of the function <code>criterion</code> with respect
to its first argument using <code><a href="stats.html#topic+optimize">optimize</a></code>. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceS1cv(X, y, lambda, df, ddlmini, ntest, ntrain,
Kfold, type, npermut, seed, Kmin, Kmax, criterion, m, s,
fraction)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceS1cv_+3A_x">X</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_lambda">lambda</code></td>
<td>
<p>A numeric positive coefficient that governs the
amount of penalty (coefficient lambda).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_df">df</code></td>
<td>
<p>A numeric vector of length 1 which is multiplied by the minimum df of thin
plate splines ; This argument is useless if
<code>lambda</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_criterion">criterion</code></td>
<td>
<p>The criteria available are map (<code>"map"</code>) or rmse
(<code>"rmse"</code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cv_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="iterchoiceS1cv_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr> 
<tr><td><code id="iterchoiceS1cv_+3A_fraction">fraction</code></td>
<td>
<p>The subdivision of the interval [<code>Kmin</code>,<code>Kmax</code>].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the optimum number of iterations (between <code>Kmin</code> and <code>Kmax</code>).</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. </p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='iterchoiceS1cve'>Selection of the number of iterations for iterative bias
reduction smoothers with base thin-plate splines smoother or duchon splines smoother</h2><span id='topic+iterchoiceS1cve'></span>

<h3>Description</h3>

<p>Evaluates at each iteration proposed in the grid the cross-validated
root mean squared error (RMSE) and mean of the relative absolute error (MAP). The minimum of these
criteria gives an estimate of the optimal number of iterations.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceS1cve(X, y, lambda, df, ddlmini, ntest, ntrain,
Kfold, type, npermut, seed, Kmin, Kmax, m, s)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceS1cve_+3A_x">X</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_lambda">lambda</code></td>
<td>
<p>A numeric positive coefficient that governs the
amount of penalty (coefficient lambda).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_df">df</code></td>
<td>
<p>A numeric vector of length 1 which is multiplied by the minimum df of thin
plate splines ; This argument is useless if
<code>lambda</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1cve_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="iterchoiceS1cve_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon).</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>Returns the values of RMSE and MAP for each
value of the grid <code>K</code>. <code>Inf</code> are returned if the iteration leads
to a smoother with a df bigger than <code>ddlmaxi</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>   Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. </p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='iterchoiceS1e'>Number of iterations selection for iterative bias reduction model</h2><span id='topic+iterchoiceS1e'></span>

<h3>Description</h3>

<p>Evaluate at each iteration proposed in the grid the value of different
criteria: GCV, AIC, corrected AIC, BIC and gMDL (along with the ddl and sigma
squared). The minimum of these
criteria gives an estimate of the optimal number of iterations.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceS1e(y, K, tUy, eigenvaluesS1, ddlmini, ddlmaxi)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceS1e_+3A_y">y</code></td>
<td>
<p>The response variable</p>
</td></tr>
<tr><td><code id="iterchoiceS1e_+3A_k">K</code></td>
<td>
<p>A numeric vector which give the search grid for iterations</p>
</td></tr>
<tr><td><code id="iterchoiceS1e_+3A_eigenvaluess1">eigenvaluesS1</code></td>
<td>
<p>Vector of the eigenvalues of the
symmetric smoothing matrix <em>S</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1e_+3A_tuy">tUy</code></td>
<td>
<p>The transpose of the matrix of eigen vectors of the
symmetric smoothing matrix <em>S</em> times the vector of observation <em>y</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1e_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigen values of <em>S</em> equal to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceS1e_+3A_ddlmaxi">ddlmaxi</code></td>
<td>
<p>The maximum df. No criteria are calculated beyond the
number of iterations that leads to df bigger than this bound.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> Returns the values of GCV, AIC, corrected AIC, BIC, gMDL, df
and sigma squared for each value of the grid <code>K</code>. <code>Inf</code> are
returned if the iteration leads to a smoother with a df bigger than
<code>ddlmaxi</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+iterchoiceS1">iterchoiceS1</a></code></p>

<hr>
<h2 id='iterchoiceS1lrcv'>Selection of the number of iterations for iterative bias
reduction smoothers with base lowrank thin-plate splines or duchon splines smoother</h2><span id='topic+iterchoiceS1lrcv'></span>

<h3>Description</h3>

<p>The function <code>iterchoiceS1cv</code> searches the interval from <code>mini</code> to
<code>maxi</code> for a minimum of the function <code>criterion</code> with respect
to its first argument using <code><a href="stats.html#topic+optimize">optimize</a></code>. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceS1lrcv(X, y, lambda, rank, bs, listvarx, df, ddlmini, ntest, ntrain,
Kfold, type, npermut, seed, Kmin, Kmax, criterion, m, s,
fraction)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceS1lrcv_+3A_x">X</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_lambda">lambda</code></td>
<td>
<p>A numeric positive coefficient that governs the
amount of penalty (coefficient lambda).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_df">df</code></td>
<td>
<p>A numeric vector of length 1 which is multiplied by the minimum df of thin
plate splines ; This argument is useless if
<code>lambda</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_rank">rank</code></td>
<td>
<p>The rank of lowrank splines.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_bs">bs</code></td>
<td>
<p>The type rank of lowrank splines: <code>tps</code> or <code>ds</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_listvarx">listvarx</code></td>
<td>
<p>The vector of the names of explanatory variables</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_criterion">criterion</code></td>
<td>
<p>The criteria available are map (<code>"map"</code>) or rmse
(<code>"rmse"</code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcv_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="iterchoiceS1lrcv_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr> 
<tr><td><code id="iterchoiceS1lrcv_+3A_fraction">fraction</code></td>
<td>
<p>The subdivision of the interval [<code>Kmin</code>,<code>Kmax</code>].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the optimum number of iterations (between <code>Kmin</code> and <code>Kmax</code>).</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin.
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='iterchoiceS1lrcve'>Selection of the number of iterations for iterative bias
reduction smoothers with base lowrank thin-plate splines smoother or duchon splines smoother</h2><span id='topic+iterchoiceS1lrcve'></span>

<h3>Description</h3>

<p>Evaluates at each iteration proposed in the grid the cross-validated
root mean squared error (RMSE) and mean of the relative absolute error (MAP). The minimum of these
criteria gives an estimate of the optimal number of iterations.
This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iterchoiceS1lrcve(X, y, lambda, rank, bs, listvarx, df, ddlmini, ntest, ntrain,
Kfold, type, npermut, seed, Kmin, Kmax, m, s)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iterchoiceS1lrcve_+3A_x">X</code></td>
<td>
<p>A numeric matrix of explanatory variables, with <em>n</em> rows
and <em>p</em> columns.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_lambda">lambda</code></td>
<td>
<p>A numeric positive coefficient that governs the
amount of penalty (coefficient lambda).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_rank">rank</code></td>
<td>
<p>The rank of lowrank splines.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_bs">bs</code></td>
<td>
<p>The type rank of lowrank splines: <code>tps</code> or <code>ds</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_listvarx">listvarx</code></td>
<td>
<p>The vector of the names of explanatory variables</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_df">df</code></td>
<td>
<p>A numeric vector of length 1 which is multiplied by the minimum df of thin
plate splines ; This argument is useless if
<code>lambda</code> is supplied (non null).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_ddlmini">ddlmini</code></td>
<td>
<p>The number of eigenvalues equals to 1.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_ntest">ntest</code></td>
<td>
<p>The number of observations in test set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_ntrain">ntrain</code></td>
<td>
<p>The number of observations in training set.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_kfold">Kfold</code></td>
<td>
<p>Either the number of folds or a boolean or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_type">type</code></td>
<td>
<p>A character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_npermut">npermut</code></td>
<td>
<p>The number of random draw (with replacement), used for
<code>type="random"</code>.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_seed">seed</code></td>
<td>
<p>Controls the seed of random generator
(via <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_kmin">Kmin</code></td>
<td>
<p>The minimum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of bias correction  iterations of the
search grid considered by
the model selection procedure for selecting the optimal number of iterations.</p>
</td></tr>
<tr><td><code id="iterchoiceS1lrcve_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="iterchoiceS1lrcve_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon).</p>
</td></tr> 
</table>


<h3>Value</h3>

<p>Returns the values of RMSE and MAP for each
value of the grid <code>K</code>. <code>Inf</code> are returned if the iteration leads
to a smoother with a df bigger than <code>ddlmaxi</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>   Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>
<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin.
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='kernel'>Kernel evaluation</h2><span id='topic+kernel'></span><span id='topic+gaussien'></span><span id='topic+epane'></span><span id='topic+uniform'></span><span id='topic+quartic'></span>

<h3>Description</h3>

<p>Evaluate the kernel function at <em>x</em>: Gaussian, Epanechnikov,
Uniform, Quartic. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussien(X)
epane(X)
uniform(X)
quartic(X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernel_+3A_x">X</code></td>
<td>
<p>The value where the function has to be evaluate, should be a
numeric and can be a scalar, a vector or a matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a scalar, a vector or a matrix which coordinates are the values of
the kernel at the given coordinate</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='kernelSx'>Evaluates the smoothing matrix at x*</h2><span id='topic+kernelSx'></span>

<h3>Description</h3>

<p>The function evaluates the matrix of design weights to
predict the response at arbitrary locations <em>x</em>.
This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>kernelSx(kernelx="g",X,Xetoile,bx)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kernelSx_+3A_kernelx">kernelx</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
<tr><td><code id="kernelSx_+3A_x">X</code></td>
<td>
<p>Matrix of explanatory variables, size <em>n</em>, <em>p</em>.</p>
</td></tr>
<tr><td><code id="kernelSx_+3A_xetoile">Xetoile</code></td>
<td>
<p>Matrix of new design points <em>x</em>* at which to predict the
response variable, size <em>n*</em>, <em>p</em>.</p>
</td></tr>
<tr><td><code id="kernelSx_+3A_bx">bx</code></td>
<td>
<p>The vector of different bandwidths, length <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the matrix denoted in the paper by <code class="reqn">Sx</code>, <em>n*</em>, <em>n</em>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='lambdachoice'>Choice of bandwidth according to a given effective degree of freedom</h2><span id='topic+lambdachoice'></span>

<h3>Description</h3>

<p>Perform a search for the different bandwidths in the given grid. For each explanatory
variable, the bandwidth is chosen such that the trace of the smoothing
matrix according to that variable (effective degree of freedom) is equal to a given value.
This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambdachoice(X,ddlobjectif,m=2,s=0,itermax,smoother="tps")</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lambdachoice_+3A_x">X</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> rows (individuals) and <code class="reqn">p</code> columns (numeric variables)</p>
</td></tr>
<tr><td><code id="lambdachoice_+3A_ddlobjectif">ddlobjectif</code></td>
<td>
<p>A numeric vector of length 1 which indicates the  desired effective degree of
freedom (trace) of the smoothing   matrix for
thin plate splines of order <code>m</code>.</p>
</td></tr>
<tr><td><code id="lambdachoice_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="lambdachoice_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr>
<tr><td><code id="lambdachoice_+3A_itermax">itermax</code></td>
<td>
<p>A scalar which controls the number of iterations for
that search</p>
</td></tr>
<tr><td><code id="lambdachoice_+3A_smoother">smoother</code></td>
<td>
<p>Character string which allows to choose between thin plate
splines <code>"tps"</code> or Duchon
splines <code>"tps"</code> (see Duchon, 1977).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the coefficient lambda that control smoothness for the desired
effective degree of freedom</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. 
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='lambdachoicelr'>Choice of bandwidth according to a given effective degree of freedom</h2><span id='topic+lambdachoicelr'></span>

<h3>Description</h3>

<p>Perform a search for the different bandwidths in the given grid. For each explanatory
variable, the bandwidth is chosen such that the trace of the smoothing
matrix according to that variable (effective degree of freedom) is equal to a given value.
This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lambdachoicelr(x,ddlobjectif,m=2,s=0,rank,itermax,bs,listvarx)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lambdachoicelr_+3A_x">x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> rows (individuals) and <code class="reqn">p</code> columns (numeric variables)</p>
</td></tr>
<tr><td><code id="lambdachoicelr_+3A_ddlobjectif">ddlobjectif</code></td>
<td>
<p>A numeric vector of length 1 which indicates the  desired effective degree of
freedom (trace) of the smoothing   matrix for
thin plate splines of order <code>m</code>.</p>
</td></tr>
<tr><td><code id="lambdachoicelr_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="lambdachoicelr_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr>
<tr><td><code id="lambdachoicelr_+3A_itermax">itermax</code></td>
<td>
<p>A scalar which controls the number of iterations for
that search</p>
</td></tr>
<tr><td><code id="lambdachoicelr_+3A_rank">rank</code></td>
<td>
<p>The rank of lowrank splines.</p>
</td></tr>
<tr><td><code id="lambdachoicelr_+3A_bs">bs</code></td>
<td>
<p>The type rank of lowrank splines: <code>tps</code> or <code>ds</code>.</p>
</td></tr>
<tr><td><code id="lambdachoicelr_+3A_listvarx">listvarx</code></td>
<td>
<p>The vector of the names of explanatory variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the coefficient lambda that control smoothness for the desired
effective degree of freedom</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. 
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='lrsmoother'>Evaluate the lowrank spline</h2><span id='topic+lrsmoother'></span>

<h3>Description</h3>

<p>The function evaluates all the features needed for a
lowrank spline smoothing. This function is not intended to be used directly.</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrsmoother(x,bs,listvarx,lambda,m,s,rank)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lrsmoother_+3A_x">x</code></td>
<td>
<p>Matrix of explanatory variables, size n,p.</p>
</td></tr>
<tr><td><code id="lrsmoother_+3A_bs">bs</code></td>
<td>
<p>The type rank of lowrank splines: <code>tps</code> or <code>ds</code>.</p>
</td></tr>
<tr><td><code id="lrsmoother_+3A_listvarx">listvarx</code></td>
<td>
<p>The vector of the names of explanatory variables</p>
</td></tr>
<tr><td><code id="lrsmoother_+3A_lambda">lambda</code></td>
<td>
<p>The smoothness coefficient lambda for thin plate splines of
order <code>m</code>.</p>
</td></tr>
<tr><td><code id="lrsmoother_+3A_m">m</code></td>
<td>
<p>The order of derivatives for the penalty (for thin plate
splines it is the order). This integer <em>m</em> must verify
2<em>m</em>+2<em>s</em>/<em>d</em>&gt;1, where <em>d</em> is the number of explanatory
variables.</p>
</td></tr> 
<tr><td><code id="lrsmoother_+3A_s">s</code></td>
<td>
<p>The power of weighting function. For thin plate splines
<em>s</em> is equal to 0. This real must be strictly smaller than <em>d</em>/2
(where <em>d</em> is the number of explanatory  variables) and must
verify 2<em>m</em>+2<em>s</em>/<em>d</em>. To get pseudo-cubic splines,
choose <em>m</em>=2 and <em>s</em>=(<em>d</em>-1)/2 (See Duchon, 1977).</p>
</td></tr> 
<tr><td><code id="lrsmoother_+3A_rank">rank</code></td>
<td>
<p>The rank of lowrank splines.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>see the reference for detailed explanation of the matrix matrix
R^-1U (see reference) and <a href="mgcv.html#topic+smoothCon">smoothCon</a> for the definition of smoothobject</p>


<h3>Value</h3>

<p> Returns a list containing the smoothing matrix eigenvectors and eigenvalues
<code>vectors</code> and <code>values</code>,  and one
matrix denoted <code>Rm1U</code> and one smoothobject <code>smoothobject</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober</p>


<h3>References</h3>

<p>Duchon, J. (1977) Splines minimizing rotation-invariant semi-norms in
Solobev spaces. in W. Shemp and K. Zeller (eds) <em>Construction theory of
functions of several variables</em>, 85-100, Springer, Berlin. 
</p>
<p>Wood, S.N. (2003) Thin plate regression
splines. <em>J. R. Statist. Soc. B</em>, <em>65</em>, 95-114.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='npregress'>Local polynomials smoothing</h2><span id='topic+npregress'></span><span id='topic+print.npregress'></span><span id='topic+residuals.npregress'></span>

<h3>Description</h3>

<p>Predicted values from a local polynomials of degree less than 2.  <br />
Missing values are not allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>npregress(x, y, criterion="rmse", bandwidth=NULL,kernel="g",
             control.par=list(), cv.options=list())</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="npregress_+3A_x">x</code></td>
<td>
<p>A numeric vector of explanatory variable of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="npregress_+3A_y">y</code></td>
<td>
<p>A numeric vector of variable to be explained of length <em>n</em>.</p>
</td></tr>
<tr><td><code id="npregress_+3A_criterion">criterion</code></td>
<td>
<p>Character string. If the bandwidth 
(<code>bandwidth</code>) is missing or 
<code>NULL</code> the number of iterations is chosen using
<code>criterion</code>. The criterion available is (cross-validated) rmse
(<code>"rmse"</code>) and mean (relative) absolute error.</p>
</td></tr>
<tr><td><code id="npregress_+3A_bandwidth">bandwidth</code></td>
<td>
<p>The kernel bandwidth smoothing parameter (a numeric vector of either length 1).</p>
</td></tr>
<tr><td><code id="npregress_+3A_kernel">kernel</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
<tr><td><code id="npregress_+3A_control.par">control.par</code></td>
<td>
<p>A named list that control optional parameters. The
two components are <code>bandwidth</code> for compatibility with <code><a href="#topic+ibr">ibr</a></code>
arguments and <code>degree</code> which controls the degree of the local
polynomial regression. If argument <code>bandwidth</code> is not null or missing, its
value is used instead <code>control.par$bandwidth</code>. <code>degree</code> must
be smaller than 2. For (gaussian binned) local polynomial see
<code><a href="KernSmooth.html#topic+locpoly">locpoly</a></code></p>
</td></tr>
<tr><td><code id="npregress_+3A_cv.options">cv.options</code></td>
<td>
<p>A named list which controls the way to do cross
validation with component <code>gridbw</code>,
<code>ntest</code>, <code>ntrain</code>, <code>Kfold</code>, <code>type</code>,
<code>seed</code>, <code>method</code> and <code>npermut</code>. <code>gridbw</code> is
numeric vector which contains the search grid for optimal bandwidth  (default
to <code>1/n*(1+1/n)^(0:kmax)</code>, with <code>kmax=floor(log(n*diff(range(x))/3)/log(1+1/n))</code>). <code>ntest</code> is the number of observations in test set and
<code>ntrain</code> is the number of observations in training set. Actually,
only one of these is needed the other can be <code>NULL</code> or missing. <code>Kfold</code> a boolean or an integer. If
<code>Kfold</code> is <code>TRUE</code> then the number of fold is deduced from
<code>ntest</code> (or <code>ntrain</code>).  <code>type</code> is a character string in
<code>random</code>,<code>timeseries</code>,<code>consecutive</code>, <code>interleaved</code>
and give the type of segments.  <code>seed</code> controls the seed of
random generator. <code>npermut</code> is the number of random draws.   If
<code>cv.options</code> is <code>list()</code>, then component <code>ntest</code> is set to
<code>1</code>, <code>type</code> is consecutive, <code>Kfold</code> is <code>TRUE</code>, and
the other components are <code>NULL</code>, which leads to leave-one-out
cross-validation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>npregress</code> which is a list including:
</p>
<table role = "presentation">
<tr><td><code>bandwidth</code></td>
<td>
<p>The kernel bandwidth smoothing parameter.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>Vector of residuals.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>Vector of fitted values.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>The effective degree of freedom of the smoother.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>A list containing four components: <code>x</code> contains the
initial explanatory variables, <code>y</code> contains the
initial dependant variables, 
<code>criterion</code> contains the chosen criterion, <code>kernel</code> the
kernel and <code>degree</code> the chosen degree</p>
</td></tr>
<tr><td><code>criteria</code></td>
<td>
<p>either a named list containing the bandwidth search
grid and all the criteria (<code>rmse</code> and <code>mae</code>) evaluated on the
grid <code>gridbw</code>. If the bandwidth
<code>bandwidth</code> is given by the user <code>NULL</code> is returned</p>
</td></tr>
</table>


<h3>Note</h3>

<p>See <code><a href="KernSmooth.html#topic+locpoly">locpoly</a></code> for fast binned implementation
over an equally-spaced grid of local polynomial. See <code><a href="#topic+ibr">ibr</a></code>
for univariate and <strong>multivariate</strong> smoothing. 
</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Wand, M. P. and Jones, M. C. (1995). <em>Kernel Smoothing</em>. Chapman and Hall, London.</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.npregress">predict.npregress</a></code>,
<code><a href="#topic+summary.npregress">summary.npregress</a></code>,
<code><a href="KernSmooth.html#topic+locpoly">locpoly</a></code>, <code><a href="#topic+ibr">ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x){sin(5*pi*x)}
n &lt;- 100
x &lt;- runif(n)
z &lt;- f(x)
sigma2 &lt;- 0.05*var(z)
erreur &lt;- rnorm(n,0,sqrt(sigma2))
y &lt;- z+erreur
res &lt;- npregress(x,y,bandwidth=0.02)
summary(res)
ord &lt;- order(x)
plot(x,y)
lines(x[ord],predict(res)[ord])
</code></pre>

<hr>
<h2 id='ozone'>Los Angeles ozone pollution data, 1976.</h2><span id='topic+ozone'></span>

<h3>Description</h3>

<p>Los Angeles ozone pollution data, 1976.  
We deleted from the original data, the first 3 columns which were the  
<code>Month</code>, <code>Day of the month</code> and <code>Day of the week</code>. Each
observation is one day, so there is 366 rows.
The <code>ozone</code> data is a matrix with 9 columns.
</p>


<h3>Format</h3>

<p>This data set is a matrix containing the following columns: 
</p>

<table>
<tr>
 <td style="text-align: right;">
         [,1] </td><td style="text-align: left;"> Ozone   </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Daily maximum
	 one-hour-average ozone reading 
	 (parts per million) at Upland, CA.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,2] </td><td style="text-align: left;"> Pressure.Vand </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 500 millibar pressure height (m) measured at Vandenberg AFB.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,3] </td><td style="text-align: left;"> Wind    </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Wind speed (mph) at Los Angeles International Airport (LAX).</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,4] </td><td style="text-align: left;"> Humidity </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Humidity in percentage at LAX.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,5] </td><td style="text-align: left;"> Temp.Sand </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Temperature (degrees F) measured at Sandburg, CA.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,6] </td><td style="text-align: left;"> Inv.Base.height </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Inversion base height (feet) at LAX.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,7] </td><td style="text-align: left;"> Pressure.Grad   </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Pressure gradient (mm Hg) from LAX to Daggett, CA.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,8] </td><td style="text-align: left;"> Inv.Base.Temp   </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Inversion base temperature (degrees F) at LAX.</td>
</tr>
<tr>
 <td style="text-align: right;">
         [,9] </td><td style="text-align: left;"> Visilibity     </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> Visibility (miles) measured at LAX.
       </td>
</tr>

</table>



<h3>Source</h3>

<p>Leo Breiman, Department of Statistics, UC Berkeley.  Data used in
Breiman, L. and  Friedman, J. H. (1985). Estimating optimal
transformations for multiple regression and correlation,
<em>Journal of American Statistical Association</em>, <b>80</b>,
580&ndash;598.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='plot.forwardibr'>Plot diagnostic for an ibr object</h2><span id='topic+plot.forwardibr'></span>

<h3>Description</h3>

<p>One plot  is  currently available: a plot
of residuals against fitted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'forwardibr'
plot(x,global=FALSE,... )</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.forwardibr_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+forwardibr">forwardibr</a></code>.</p>
</td></tr>
<tr><td><code id="plot.forwardibr_+3A_global">global</code></td>
<td>
<p>Boolean: if <code>global</code> is <code>TRUE</code> the color code
is between the min and the max of <code>x</code> (except infinite value); if
<code>global</code> is <code>FALSE</code> the color code is between the min and
the max of each row.</p>
</td></tr>
<tr><td><code id="plot.forwardibr_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code><a href="graphics.html#topic+image">image</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> The function <code>plot.forwardibr</code> give an image plot of the
values of the criterion obtained by the forward selection process. Image
is read from the bottom to the top. At the bottom row, there are all the
univariate models and the selected variable is given by the lowest
criterion. This variable is selected for the second row. At the second
(bottom) row the second variable included is those which give the lowest
criterion for this row etc. All the variables included in the final
model (selected by forward search) are numbered on the image (by order of
inclusion).</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+forward">forward</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
ibrsel &lt;- forward(ibr(ozone[,-1],ozone[,1],df=1.2)
plot(ibrsel)
plot(apply(ibrsel,1,min,na.rm=TRUE),type="l")

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.ibr'>Plot diagnostic for an ibr object</h2><span id='topic+plot.ibr'></span>

<h3>Description</h3>

<p>One plot  is  currently available: a plot
of residuals against fitted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ibr'
plot(x,... )</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.ibr_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+ibr">ibr</a></code>.</p>
</td></tr>
<tr><td><code id="plot.ibr_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>plot.ibr</code> computes and returns a list of summary
statistics of the fitted  iterative bias reduction smoother given in <code>object</code></p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1],df=1.2)
plot(res.ibr)
## End(Not run)
</code></pre>

<hr>
<h2 id='poids'>Product kernel evaluation</h2><span id='topic+poids'></span>

<h3>Description</h3>

<p>Evaluate the product of kernel function at <em>(X-valx)/bx</em>: Gaussian, Epanechnikov,
Uniform, Quartic. This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poids(kernelx,X,bx,valx,n,p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="poids_+3A_kernelx">kernelx</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
<tr><td><code id="poids_+3A_x">X</code></td>
<td>
<p>Matrix of explanatory variables, size <em>n</em>, <em>p</em>.</p>
</td></tr>
<tr><td><code id="poids_+3A_bx">bx</code></td>
<td>
<p>The vector of different bandwidths, length <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="poids_+3A_valx">valx</code></td>
<td>
<p>The vector of length <code class="reqn">p</code> at which the product kernel is evaluated.</p>
</td></tr>
<tr><td><code id="poids_+3A_n">n</code></td>
<td>
<p>Number of rows of <em>X</em>.</p>
</td></tr>
<tr><td><code id="poids_+3A_p">p</code></td>
<td>
<p>Number of columns of <em>X</em>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector which coordinates are the values of
the product kernel at the given coordinate</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='predict.ibr'>Predicted values using iterative bias reduction smoothers</h2><span id='topic+predict.ibr'></span>

<h3>Description</h3>

<p>Predicted values from iterative bias reduction object.
<br />
Missing values are not allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ibr'
predict(object, newdata, interval=
 c("none", "confidence", "prediction"), ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.ibr_+3A_object">object</code></td>
<td>
<p>Object of class <code><a href="#topic+ibr">ibr</a></code>.</p>
</td></tr>
<tr><td><code id="predict.ibr_+3A_newdata">newdata</code></td>
<td>
<p>An optional matrix in which to look for variables with which to predict. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict.ibr_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation. Only <code>none</code> is
currently avalaible.</p>
</td></tr>
<tr><td><code id="predict.ibr_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Produces a vector of predictions.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1],df=1.2,K=1:500)
summary(res.ibr)
predict(res.ibr)
## End(Not run)
</code></pre>

<hr>
<h2 id='predict.npregress'>Predicted values using using local polynomials
</h2><span id='topic+predict.npregress'></span>

<h3>Description</h3>

<p>Predicted values from a local polynomials of degree less than 2. See
<code><a href="KernSmooth.html#topic+locpoly">locpoly</a></code> for fast binned implementation
over an equally-spaced grid of local polynomial (gaussian kernel only) 
<br />
Missing values are not allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'npregress'
predict(object, newdata, interval=
 c("none", "confidence", "prediction"), deriv=FALSE, ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.npregress_+3A_object">object</code></td>
<td>
<p>Object of class <code><a href="#topic+npregress">npregress</a></code>.</p>
</td></tr>
<tr><td><code id="predict.npregress_+3A_newdata">newdata</code></td>
<td>
<p>An optional vector of values to be predicted. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict.npregress_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation. Only <code>none</code> is
currently avalaible.</p>
</td></tr>
<tr><td><code id="predict.npregress_+3A_deriv">deriv</code></td>
<td>
<p>Bolean. If <code>TRUE</code> it returns the first derivative of
the local  polynomial (of degree1).</p>
</td></tr>
<tr><td><code id="predict.npregress_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p> Produces a vector of predictions. If <code>deriv</code>
is <code>TRUE</code> the value is a named list with components: <code>yhat</code>
which contains predictions and (if relevant) <code>deriv</code> the
first derivative of the local polynomial of degree 1.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Wand, M. P. and Jones, M. C. (1995). <em>Kernel Smoothing</em>. Chapman and Hall, London.</p>


<h3>See Also</h3>

<p><code><a href="#topic+npregress">npregress</a></code>, <code><a href="#topic+summary.npregress">summary.npregress</a></code>,
<code><a href="KernSmooth.html#topic+locpoly">locpoly</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x){sin(5*pi*x)}
n &lt;- 100
x &lt;- runif(n)
z &lt;- f(x)
sigma2 &lt;- 0.05*var(z)
erreur&lt;-rnorm(n,0,sqrt(sigma2))
y&lt;-z+erreur
grid &lt;- seq(min(x),max(x),length=500)
res &lt;- npregress(x,y,bandwidth=0.02,control.par=list(degree=1))
plot(x,y)
lines(grid,predict(res,grid))
</code></pre>

<hr>
<h2 id='print.summary.ibr'>Printing iterative bias reduction summaries</h2><span id='topic+print.summary.ibr'></span>

<h3>Description</h3>

<p><code>print</code> method for class  &ldquo;<code>summary.ibr</code>&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.ibr'
print(x,displaybw=FALSE, digits =
max(3, getOption("digits") - 3), ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.ibr_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+ibr">ibr</a></code>.</p>
</td></tr>
<tr><td><code id="print.summary.ibr_+3A_displaybw">displaybw</code></td>
<td>
<p>Boolean that indicates if bandwidth are printed or not.</p>
</td></tr>
<tr><td><code id="print.summary.ibr_+3A_digits">digits</code></td>
<td>
<p>Rounds the values in its first argument to the specified
number of significant digits.</p>
</td></tr>
<tr><td><code id="print.summary.ibr_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>print.summary.ibr</code> prints a list of summary
statistics of the fitted  iterative bias reduction model given in <code>x</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1],df=1.2)
summary(res.ibr)
predict(res.ibr)
## End(Not run)
</code></pre>

<hr>
<h2 id='print.summary.npregress'>Printing iterative bias reduction summaries</h2><span id='topic+print.summary.npregress'></span>

<h3>Description</h3>

<p><code>print</code> method for class  &ldquo;<code>summary.npregress</code>&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.npregress'
print(x,digits =
max(3, getOption("digits") - 3), ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.summary.npregress_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+npregress">npregress</a></code>.</p>
</td></tr>
<tr><td><code id="print.summary.npregress_+3A_digits">digits</code></td>
<td>
<p>Rounds the values in its first argument to the specified
number of significant digits.</p>
</td></tr>
<tr><td><code id="print.summary.npregress_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>print.summary.npregress</code> prints a list of summary
statistics of the fitted  iterative bias reduction model given in <code>x</code>.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Wand, M. P. and Jones, M. C. (1995). <em>Kernel Smoothing</em>. Chapman and Hall, London.</p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x){sin(5*pi*x)}
n &lt;- 100
x &lt;- runif(n)
z &lt;- f(x)
sigma2 &lt;- 0.05*var(z)
erreur &lt;- rnorm(n,0,sqrt(sigma2))
y &lt;- z+erreur
res &lt;- npregress(x,y,bandwidth=0.02)
summary(res)
</code></pre>

<hr>
<h2 id='summary.ibr'>Summarizing iterative bias reduction fits</h2><span id='topic+summary.ibr'></span>

<h3>Description</h3>

<p><code>summary</code> method for class  &ldquo;<code>ibr</code>&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ibr'
summary(object,  criteria="call", ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.ibr_+3A_object">object</code></td>
<td>
<p>Object of class <code><a href="#topic+ibr">ibr</a></code>.</p>
</td></tr>
<tr><td><code id="summary.ibr_+3A_criteria">criteria</code></td>
<td>
<p>Character string which gives the criteria evaluated for the model. The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>) or gMDL  (<code>"gmdl"</code>). The string <code>"call"</code>
return the criterion used in the call of <code>ibr</code>.</p>
</td></tr>
<tr><td><code id="summary.ibr_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.ibr</code> computes and returns a list of summary
statistics of the fitted  iterative bias reduction smoother given in <code>object</code></p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>. Doi: 10.1007/s11222-012-9346-4
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code>, <code><a href="#topic+summary.ibr">summary.ibr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: data(ozone, package = "ibr")
res.ibr &lt;- ibr(ozone[,-1],ozone[,1],df=1.2)
summary(res.ibr)
predict(res.ibr)
## End(Not run)
</code></pre>

<hr>
<h2 id='summary.npregress'>Summarizing local polynomial fits</h2><span id='topic+summary.npregress'></span>

<h3>Description</h3>

<p><code>summary</code> method for class  &ldquo;<code>npregress</code>&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'npregress'
summary(object,  criteria="call", ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.npregress_+3A_object">object</code></td>
<td>
<p>Object of class <code><a href="#topic+npregress">npregress</a></code>.</p>
</td></tr>
<tr><td><code id="summary.npregress_+3A_criteria">criteria</code></td>
<td>
<p>Character string which gives the criteria evaluated for the model. The criteria available are GCV (default, <code>"gcv"</code>),
AIC (<code>"aic"</code>), corrected AIC  (<code>"aicc"</code>),   BIC
(<code>"bic"</code>) or gMDL  (<code>"gmdl"</code>). The string <code>"call"</code>
return the criterion used in the call of <code>npregress</code>.</p>
</td></tr>
<tr><td><code id="summary.npregress_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code>summary.npregress</code> computes and returns a list of summary
statistics of the local polynomial smoother given in <code>object</code></p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Wand, M. P. and Jones, M. C. (1995). <em>Kernel Smoothing</em>. Chapman and Hall, London.</p>


<h3>See Also</h3>

<p><code><a href="#topic+npregress">npregress</a></code>, <code><a href="#topic+summary.npregress">summary.npregress</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>f &lt;- function(x){sin(5*pi*x)}
n &lt;- 100
x &lt;- runif(n)
z &lt;- f(x)
sigma2 &lt;- 0.05*var(z)
erreur &lt;- rnorm(n,0,sqrt(sigma2))
y &lt;- z+erreur
res &lt;- npregress(x,y,bandwidth=0.02)
summary(res)
</code></pre>

<hr>
<h2 id='sumvalpr'>Sum of a geometric series</h2><span id='topic+sumvalpr'></span>

<h3>Description</h3>

<p>Calculates the sum of the first (k+1) terms of a geometric series with initial term 1
and common ratio equal to <code>valpr</code> (lower or equal to 1).</p>


<h3>Usage</h3>

<pre><code class='language-R'>sumvalpr(k,n,valpr,index1,index0)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sumvalpr_+3A_k">k</code></td>
<td>
<p>The number of terms minus 1.</p>
</td></tr>
<tr><td><code id="sumvalpr_+3A_n">n</code></td>
<td>
<p>The length of <code>valpr</code>.</p>
</td></tr>
<tr><td><code id="sumvalpr_+3A_valpr">valpr</code></td>
<td>
<p>Vector of common ratio in decreasing order.</p>
</td></tr>
<tr><td><code id="sumvalpr_+3A_index1">index1</code></td>
<td>
<p>The index of the last common ratio equal to 1.</p>
</td></tr>
<tr><td><code id="sumvalpr_+3A_index0">index0</code></td>
<td>
<p>The index of the first common ratio equal to 0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the vector of the sums of the first (k+1) terms of the geometric series.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner and Eric Matzner-Lober.</p>


<h3>References</h3>

<p>Cornillon, P.-A.; Hengartner, N.; Jegou, N. and Matzner-Lober, E. (2012)
Iterative bias reduction: a comparative study.
<em>Statistics and Computing</em>, <em>23</em>, 777-791.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2013)
Recursive bias estimation for multivariate regression smoothers Recursive 
bias estimation for multivariate regression smoothers.
<em>ESAIM: Probability and Statistics</em>, <em>18</em>, 483-502.
</p>
<p>Cornillon, P.-A.; Hengartner, N. and Matzner-Lober, E. (2017)
Iterative Bias Reduction Multivariate Smoothing in R: The ibr Package.
<em>Journal of Statistical Software</em>, <em>77</em>, 1&ndash;26.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ibr">ibr</a></code></p>

<hr>
<h2 id='tracekernel'>Trace of product kernel smoother</h2><span id='topic+tracekernel'></span>

<h3>Description</h3>

<p>Evaluate the trace of the product of kernel smoother (Gaussian, Epanechnikov,
Uniform, Quartic). This function is not intended to be used directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tracekernel(X,bx,kernelx,n,p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tracekernel_+3A_x">X</code></td>
<td>
<p>Matrix of explanatory variables, size <em>n</em>, <em>p</em>.</p>
</td></tr>
<tr><td><code id="tracekernel_+3A_bx">bx</code></td>
<td>
<p>The vector of different bandwidths, length <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="tracekernel_+3A_kernelx">kernelx</code></td>
<td>
<p>Character string which allows to choose between gaussian kernel
(<code>"g"</code>), Epanechnikov (<code>"e"</code>), uniform (<code>"u"</code>),
quartic (<code>"q"</code>).</p>
</td></tr>
<tr><td><code id="tracekernel_+3A_n">n</code></td>
<td>
<p>Number of rows of <em>X</em>.</p>
</td></tr>
<tr><td><code id="tracekernel_+3A_p">p</code></td>
<td>
<p>Number of columns of <em>X</em>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Evaluate the trace (effective degree of freedom) of the product kernel smoother.</p>


<h3>Author(s)</h3>

<p>Pierre-Andre Cornillon, Nicolas Hengartner  and Eric Matzner-Lober.</p>


<h3>See Also</h3>

 <p><code><a href="#topic+ibr">ibr</a></code></p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
