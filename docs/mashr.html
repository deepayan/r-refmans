<!DOCTYPE html><html lang="en"><head><title>Help for package mashr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mashr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bovy_wrapper'><p>Fit extreme deconvolution to mash data using Bovy et al 2011</p></a></li>
<li><a href='#calc_lik_matrix'><p>Compute matrix of conditional likelihoods.</p></a></li>
<li><a href='#calc_lik_matrix_common_cov'><p>calc_lik_matrix_common_cov</p></a></li>
<li><a href='#calc_lik_vector'><p>Compute conditional likelihoods for bhat vector.</p></a></li>
<li><a href='#calc_relative_lik_matrix'><p>Calculate matrix of relative likelihoods.</p></a></li>
<li><a href='#compute_alt_loglik_from_matrix_and_pi'><p>Compute vector of alternative loglikelihoods from a matrix</p>
of log-likelihoods and fitted pi</a></li>
<li><a href='#compute_loglik_from_matrix_and_pi'><p>Compute the total loglikelihood from a matrix of</p>
log-likelihoods and fitted pi</a></li>
<li><a href='#compute_null_loglik_from_matrix'><p>Compute a vector of null loglikelihoods from a matrix of</p>
log-likelihoods</a></li>
<li><a href='#compute_posterior_matrices'><p>Compute posterior matrices.</p></a></li>
<li><a href='#compute_posterior_matrices_common_cov_R'><p>Compute posterior matrices (when error covariance V_j is</p>
equal for all observations j)</a></li>
<li><a href='#compute_posterior_matrices_general_R'><p>Compute posterior matrices (general version)</p></a></li>
<li><a href='#compute_posterior_weights'><p>Compute posterior probabilities that each effect came from</p>
each component</a></li>
<li><a href='#compute_vloglik_from_matrix_and_pi'><p>Computes a vector of loglikelihoods from a matrix of</p>
log-likelihoods and fitted pi</a></li>
<li><a href='#contrast_matrix'><p>Create contrast matrix</p></a></li>
<li><a href='#cov_all_zeros'><p>Compute an R by R matrix of all 0s</p></a></li>
<li><a href='#cov_canonical'><p>Compute a list of canonical covariance matrices</p></a></li>
<li><a href='#cov_ed'><p>Perform &quot;extreme deconvolution&quot; (Bovy et al) on a subset of</p>
the data</a></li>
<li><a href='#cov_equal_effects'><p>Compute an R by R matrix of all 1s</p></a></li>
<li><a href='#cov_first_singleton'><p>Compute all the singleton matrices corresponding to</p>
condition-specific effects in first condition only; used for
testing purposes</a></li>
<li><a href='#cov_flash'><p>Perform Empirical Bayes Matrix Factorization using flashier, and</p>
return a list of candidate covariance matrices</a></li>
<li><a href='#cov_from_factors'><p>produce list of rank-1 covariance matrices corresponding to rows of f</p></a></li>
<li><a href='#cov_pca'><p>Perform PCA on data and return list of candidate covariance</p>
matrices</a></li>
<li><a href='#cov_simple_het'><p>Compute covariance matrices with diagonal element 1 and</p>
off-diagonal element corr</a></li>
<li><a href='#cov_udi'><p>Compute a list of covariance matrices corresponding to the</p>
&quot;Unassociated&quot;, &quot;Directly associated&quot; and &quot;Indirectly associated&quot;
models</a></li>
<li><a href='#cov_udi_single'><p>Computes the covariance matrix for a single UDI model</p></a></li>
<li><a href='#estimate_null_correlation_simple'><p>Estimate null correlations (simple)</p></a></li>
<li><a href='#expand_cov'><p>Create expanded list of covariance matrices expanded by grid</p></a></li>
<li><a href='#extreme_deconvolution'><p>Density estimation using Gaussian mixtures in the presence</p>
of noisy, heterogeneous and incomplete data</a></li>
<li><a href='#get_estimated_pi'><p>Return the estimated mixture proportions</p></a></li>
<li><a href='#get_log10bf'><p>Return the Bayes Factor for each effect</p></a></li>
<li><a href='#get_n_significant_conditions'><p>Count number of conditions each effect is significant in</p></a></li>
<li><a href='#get_pairwise_sharing'><p>Compute the proportion of (significant) signals shared by</p>
magnitude in each pair of conditions, based on the poterior mean</a></li>
<li><a href='#get_pairwise_sharing_from_samples'><p>Compute the proportion of (significant) signals shared by</p>
magnitude in each pair of conditions</a></li>
<li><a href='#get_samples'><p>Return samples from a mash object</p></a></li>
<li><a href='#get_significant_results'><p>Find effects that are significant in at least one condition</p></a></li>
<li><a href='#make_names'><p>Create names for covariance matrices</p></a></li>
<li><a href='#mash'><p>Apply mash method to data</p></a></li>
<li><a href='#mash_1by1'><p>Perform condition-by-condition analyses</p></a></li>
<li><a href='#mash_compute_loglik'><p>Compute loglikelihood for fitted mash object on new data.</p></a></li>
<li><a href='#mash_compute_posterior_matrices'><p>Compute posterior matrices for fitted mash object on new</p>
data</a></li>
<li><a href='#mash_compute_vloglik'><p>Compute vector of loglikelihood for fitted mash object on</p>
new data</a></li>
<li><a href='#mash_estimate_corr_em'><p>Fit mash model and estimate residual correlations using EM algorithm</p></a></li>
<li><a href='#mash_plot_meta'><p>Plot metaplot for an effect based on posterior from mash</p></a></li>
<li><a href='#mash_set_data'><p>Create a data object for mash analysis.</p></a></li>
<li><a href='#mash_set_data_contrast'><p>Create a data object for mash contrast analysis</p></a></li>
<li><a href='#mash_update_data'><p>Update the data object for mash analysis.</p></a></li>
<li><a href='#optimize_pi'><p>Estimate mixture weights by maximum (penalized) likelihood</p></a></li>
<li><a href='#posterior_cov'><p>posterior_cov</p></a></li>
<li><a href='#posterior_mean'><p>posterior_mean</p></a></li>
<li><a href='#posterior_mean_matrix'><p>posterior_mean_matrix</p></a></li>
<li><a href='#scale_cov'><p>Scale each covariance matrix in list Ulist by a scalar in</p>
vector grid</a></li>
<li><a href='#sim_contrast1'><p>Create simplest simulation, cj = mu 1 data used for contrast</p>
analysis</a></li>
<li><a href='#sim_contrast2'><p>Create simulation with signal data used for contrast</p>
analysis.</a></li>
<li><a href='#simple_sims'><p>Create some simple simulated data for testing purposes</p></a></li>
<li><a href='#simple_sims2'><p>Create some more simple simulated data for testing purposes</p></a></li>
<li><a href='#teem_wrapper'><p>Fit extreme deconvolution to mash data using TEEM method</p>
developed by Y. Yang and M Stephens</a></li>
<li><a href='#udi_model_matrix'><p>Create a matrix whose rows contain all possible</p>
combinations of the U,D,I models that are allowed.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Multivariate Adaptive Shrinkage</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.79</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-18</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the multivariate adaptive shrinkage (mash)
    method of Urbut et al (2019) &lt;<a href="https://doi.org/10.1038%2Fs41588-018-0268-8">doi:10.1038/s41588-018-0268-8</a>&gt; for
    estimating and testing large numbers of effects in many conditions
    (or many outcomes). Mash takes an empirical Bayes approach to
    testing and effect estimation; it estimates patterns of similarity
    among conditions, then exploits these patterns to improve accuracy
    of the effect estimates. The core linear algebra is implemented in
    C++ for fast model fitting and posterior computation.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/stephenslab/mashr">https://github.com/stephenslab/mashr</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/stephenslab/mashr/issues">https://github.com/stephenslab/mashr/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Copyright:</td>
<td>file COPYRIGHTS</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0), ashr (&ge; 2.2-22)</td>
</tr>
<tr>
<td>Imports:</td>
<td>assertthat, utils, stats, plyr, rmeta, Rcpp (&ge; 1.0.8),
mvtnorm, abind, softImpute</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo, RcppGSL (&ge; 0.3.8)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, REBayes, corrplot (&ge; 0.90), testthat, kableExtra,
knitr, rmarkdown, profmem, flashier, ebnm</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-18 13:05:18 UTC; pcarbo</td>
</tr>
<tr>
<td>Author:</td>
<td>Matthew Stephens [aut],
  Sarah Urbut [aut],
  Gao Wang [aut],
  Yuxin Zou [aut],
  Yunqi Yang [ctb],
  Sam Roweis [cph],
  David Hogg [cph],
  Jo Bovy [cph],
  Peter Carbonetto [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Peter Carbonetto &lt;peter.carbonetto@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-18 16:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bovy_wrapper'>Fit extreme deconvolution to mash data using Bovy et al 2011</h2><span id='topic+bovy_wrapper'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bovy_wrapper(data, Ulist_init, subset = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bovy_wrapper_+3A_data">data</code></td>
<td>
<p>mash data object</p>
</td></tr>
<tr><td><code id="bovy_wrapper_+3A_ulist_init">Ulist_init</code></td>
<td>
<p>a list of covariance matrices to initialize to</p>
</td></tr>
<tr><td><code id="bovy_wrapper_+3A_subset">subset</code></td>
<td>
<p>the indices of the observations to be used (defaults
to all of them)</p>
</td></tr>
<tr><td><code id="bovy_wrapper_+3A_...">...</code></td>
<td>
<p>arguments to be passed to <code>extreme_deconvolution</code>
function, such as <code>tol</code>, <code>maxiter</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper to ExtremeDeconvolution::extreme_deconvolution
It fixes the projection to be the identity, and the means to be 0
</p>


<h3>Value</h3>

<p>the fitted mixture: a list of mixture proportions and
covariance matrices
</p>

<hr>
<h2 id='calc_lik_matrix'>Compute matrix of conditional likelihoods.</h2><span id='topic+calc_lik_matrix'></span>

<h3>Description</h3>

<p>computes matrix of condition likelihoods for each of J
rows of Bhat for each of P prior covariances.
</p>
<p>This is an internal (non-exported) function. This help page
provides additional documentation mainly intended for developers
and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_lik_matrix(
  data,
  Ulist,
  log = FALSE,
  mc.cores = 1,
  algorithm.version = c("Rcpp", "R")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_lik_matrix_+3A_data">data</code></td>
<td>
<p>A <code>mash</code> data object; e.g., created by
<code><a href="#topic+mash_set_data">mash_set_data</a></code>.</p>
</td></tr>
<tr><td><code id="calc_lik_matrix_+3A_ulist">Ulist</code></td>
<td>
<p>List containing the prior covariance matrices.</p>
</td></tr>
<tr><td><code id="calc_lik_matrix_+3A_log">log</code></td>
<td>
<p>If <code>TRUE</code>, the return value is a matrix of log-
likelihoods.</p>
</td></tr>
<tr><td><code id="calc_lik_matrix_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The argument supplied to
<code>openmp</code> specifying the number of cores
to use. Note that this is only has an effect for the Rcpp version.</p>
</td></tr>
<tr><td><code id="calc_lik_matrix_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>Indicate R or Rcpp version</p>
</td></tr>
</table>


<h3>Value</h3>

<p>J x P matrix of multivariate normal likelihoods, p(bhat |
Ulist[p], V).
</p>

<hr>
<h2 id='calc_lik_matrix_common_cov'>calc_lik_matrix_common_cov</h2><span id='topic+calc_lik_matrix_common_cov'></span>

<h3>Description</h3>

<p>computes matrix of likelihoods for each of J rows of
Bhat for each of P prior covariances; special case when standard
errors and variances are all same across j.
</p>
<p>This is an internal (non-exported) function. This help page
provides additional documentation mainly intended for developers
and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_lik_matrix_common_cov(data, Ulist, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_lik_matrix_common_cov_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="calc_lik_matrix_common_cov_+3A_ulist">Ulist</code></td>
<td>
<p>list of prior covariance matrices</p>
</td></tr>
<tr><td><code id="calc_lik_matrix_common_cov_+3A_log">log</code></td>
<td>
<p>if true computes log-likelihood</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compared with <code>calc_lik_matrix</code> this function
exploits fact that observations are iid in this case, so the
inverse covariance matrices only need to be done once, reducing
computation to R^3 + JR^2 instead of JR^3
</p>


<h3>Value</h3>

<p>J x P vector of multivariate normal likelihoods, p(bhat |
Ulist[p], V), where V is same for each bhat
</p>

<hr>
<h2 id='calc_lik_vector'>Compute conditional likelihoods for bhat vector.</h2><span id='topic+calc_lik_vector'></span>

<h3>Description</h3>

<p>Computes vector of likelihoods for bhat for each of P
prior covariances.
</p>
<p>This is an internal (non-exported) function. This help page
provides additional documentation mainly intended for developers
and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_lik_vector(bhat, V, Ulist, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_lik_vector_+3A_bhat">bhat</code></td>
<td>
<p>bhat vector (length R)</p>
</td></tr>
<tr><td><code id="calc_lik_vector_+3A_v">V</code></td>
<td>
<p>R x R covariance matrix for likelihood.</p>
</td></tr>
<tr><td><code id="calc_lik_vector_+3A_ulist">Ulist</code></td>
<td>
<p>list of prior covariance matrices.</p>
</td></tr>
<tr><td><code id="calc_lik_vector_+3A_log">log</code></td>
<td>
<p>If <code>TRUE</code>, the return value is a matrix of
log-likelihoods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of length P in which the pth element contains the
multivariate normal likelihood p(bhat | Ulist[[p]], V).
</p>

<hr>
<h2 id='calc_relative_lik_matrix'>Calculate matrix of relative likelihoods.</h2><span id='topic+calc_relative_lik_matrix'></span>

<h3>Description</h3>

<p>Computes matrix of relative likelihoods for each of J
rows of Bhat for each of P prior covariances.
</p>
<p>This is an internal (non-exported) function. This help page
provides additional documentation mainly intended for developers
and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_relative_lik_matrix(data, Ulist, algorithm.version = c("Rcpp", "R"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_relative_lik_matrix_+3A_data">data</code></td>
<td>
<p>A <code>mash</code> data object; e.g., created by
<code><a href="#topic+mash_set_data">mash_set_data</a></code>.</p>
</td></tr>
<tr><td><code id="calc_relative_lik_matrix_+3A_ulist">Ulist</code></td>
<td>
<p>List containing the prior covariance matrices.</p>
</td></tr>
<tr><td><code id="calc_relative_lik_matrix_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>indicates R or Rcpp</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value is a list containing the following components:
</p>
<table role = "presentation">
<tr><td><code>lik_matrix</code></td>
<td>
<p>J x P matrix containing likelihoods p(bhat[j]
+ Ulist[p], V), but normalized so that the largest entry in
each row is 1.</p>
</td></tr>
<tr><td><code>lfactors</code></td>
<td>
<p>Vector which will recover the original
likelihoods; for example, <code>lfactors[i] +
      log(lik_matrix[i,])</code> yields the log-likelihoods corresponding
to row i of the Bhat data matrix.</p>
</td></tr>
</table>

<hr>
<h2 id='compute_alt_loglik_from_matrix_and_pi'>Compute vector of alternative loglikelihoods from a matrix
of log-likelihoods and fitted pi</h2><span id='topic+compute_alt_loglik_from_matrix_and_pi'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_alt_loglik_from_matrix_and_pi(pi_s, lm, Shat_alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_alt_loglik_from_matrix_and_pi_+3A_pi_s">pi_s</code></td>
<td>
<p>the vector of mixture proportions, with first element
corresponding to null</p>
</td></tr>
<tr><td><code id="compute_alt_loglik_from_matrix_and_pi_+3A_lm">lm</code></td>
<td>
<p>the results of a likelihood matrix calculation from
<code>calc_relative_lik_matrix</code> whose first column corresponds to
null</p>
</td></tr>
<tr><td><code id="compute_alt_loglik_from_matrix_and_pi_+3A_shat_alpha">Shat_alpha</code></td>
<td>
<p>matrix of Shat^alpha</p>
</td></tr>
</table>

<hr>
<h2 id='compute_loglik_from_matrix_and_pi'>Compute the total loglikelihood from a matrix of
log-likelihoods and fitted pi</h2><span id='topic+compute_loglik_from_matrix_and_pi'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_loglik_from_matrix_and_pi(pi_s, lm, Shat_alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_loglik_from_matrix_and_pi_+3A_pi_s">pi_s</code></td>
<td>
<p>the vector of mixture proportions</p>
</td></tr>
<tr><td><code id="compute_loglik_from_matrix_and_pi_+3A_lm">lm</code></td>
<td>
<p>the results of a likelihood matrix calculation from
<code>calc_relative_lik_matrix</code></p>
</td></tr>
<tr><td><code id="compute_loglik_from_matrix_and_pi_+3A_shat_alpha">Shat_alpha</code></td>
<td>
<p>matrix of Shat^alpha</p>
</td></tr>
</table>

<hr>
<h2 id='compute_null_loglik_from_matrix'>Compute a vector of null loglikelihoods from a matrix of
log-likelihoods</h2><span id='topic+compute_null_loglik_from_matrix'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_null_loglik_from_matrix(lm, Shat_alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_null_loglik_from_matrix_+3A_lm">lm</code></td>
<td>
<p>the results of a likelihood matrix calculation from
<code>calc_relative_lik_matrix</code> whose first column corresponds to
null</p>
</td></tr>
<tr><td><code id="compute_null_loglik_from_matrix_+3A_shat_alpha">Shat_alpha</code></td>
<td>
<p>matrix of Shat^alpha</p>
</td></tr>
</table>

<hr>
<h2 id='compute_posterior_matrices'>Compute posterior matrices.</h2><span id='topic+compute_posterior_matrices'></span>

<h3>Description</h3>

<p>Compute posterior matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_posterior_matrices(
  data,
  Ulist,
  posterior_weights,
  algorithm.version = c("Rcpp", "R"),
  A = NULL,
  output_posterior_cov = FALSE,
  mc.cores = 1,
  posterior_samples = 0,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_posterior_matrices_+3A_data">data</code></td>
<td>
<p>A <code>mash</code> data object; e.g., created by
<code><a href="#topic+mash_set_data">mash_set_data</a></code> or <code><a href="#topic+mash_set_data_contrast">mash_set_data_contrast</a></code>.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_ulist">Ulist</code></td>
<td>
<p>List containing the prior covariance matrices.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_posterior_weights">posterior_weights</code></td>
<td>
<p>Vector containing the posterior
probability of each mixture component in Ulist for the data.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>Indicates whether to use R or Rcpp version.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_a">A</code></td>
<td>
<p>the linear transformation matrix, Q x R matrix. This is
used to compute the posterior for Ab.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_output_posterior_cov">output_posterior_cov</code></td>
<td>
<p>whether or not to output posterior
covariance matrices for all effects.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_mc.cores">mc.cores</code></td>
<td>
<p>The argument supplied to
<code>openmp</code> specifying the number of cores
to use. Note that this is only has an effect for the Rcpp version.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_posterior_samples">posterior_samples</code></td>
<td>
<p>the number of samples to be drawn from the
posterior distribution of each effect.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_+3A_seed">seed</code></td>
<td>
<p>a random number seed to use when sampling from the
posteriors. It is used when <code>posterior_samples &gt; 0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The return value is a list containing the following
components:
</p>
<table role = "presentation">
<tr><td><code>PosteriorMean</code></td>
<td>
<p>J x Q matrix of posterior means.</p>
</td></tr>
<tr><td><code>PosteriorSD</code></td>
<td>
<p>J x Q matrix of posterior (marginal) standard
deviations.</p>
</td></tr>
<tr><td><code>NegativeProb</code></td>
<td>
<p>J x Q matrix of posterior (marginal)
probability of being negative.</p>
</td></tr>
<tr><td><code>ZeroProb</code></td>
<td>
<p>J x Q matrix of posterior (marginal) probability
of being zero.</p>
</td></tr>
<tr><td><code>lfsr</code></td>
<td>
<p>J x Q matrix of local false sign rate estimates.</p>
</td></tr>
<tr><td><code>lfdr</code></td>
<td>
<p>J x Q matrix of local false discovery rate
estimates.</p>
</td></tr>
<tr><td><code>PosteriorCov</code></td>
<td>
<p>Q x Q x J array of posterior covariance
matrices, if the <code>output_posterior_cov = TRUE</code>.</p>
</td></tr>
<tr><td><code>PosteriorSamples</code></td>
<td>
<p>M x Q x J array of samples, if the
<code>posterior_samples = M &gt; 0</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='compute_posterior_matrices_common_cov_R'>Compute posterior matrices (when error covariance V_j is
equal for all observations j)</h2><span id='topic+compute_posterior_matrices_common_cov_R'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_posterior_matrices_common_cov_R(
  data,
  A,
  Ulist,
  posterior_weights,
  output_posterior_cov = FALSE,
  posterior_samples = 0,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by
<code>mash_set_data</code> or <code>mash_set_data_contrast</code></p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_a">A</code></td>
<td>
<p>the linear transformation matrix, Q x R matrix. This is
used to compute the posterior for Ab.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_ulist">Ulist</code></td>
<td>
<p>a list of P covariance matrices for each mixture component</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_posterior_weights">posterior_weights</code></td>
<td>
<p>the JxP posterior probabilities of each
mixture component in Ulist for the data</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_output_posterior_cov">output_posterior_cov</code></td>
<td>
<p>whether or not to output posterior
covariance matrices for all effects</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_posterior_samples">posterior_samples</code></td>
<td>
<p>the number of samples to be drawn from the
posterior distribution of each effect.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_common_cov_R_+3A_seed">seed</code></td>
<td>
<p>a random number seed to use when sampling from the
posteriors. It is used when <code>posterior_samples &gt; 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computations are performed without allocating an
excessive amount of memory.
</p>


<h3>Value</h3>

<p>PosteriorMean JxQ matrix of posterior means
</p>
<p>PosteriorSD JxQ matrix of posterior (marginal) standard deviations
</p>
<p>NegativeProb JxQ matrix of posterior (marginal) probability
of being negative
</p>
<p>ZeroProb JxQ matrix of posterior (marginal) probability of
being zero
</p>
<p>lfsr JxQ matrix of local false sign rates
</p>
<p>PosteriorCov QxQxJ array of posterior covariance matrices,
if the <code>output_posterior_cov = TRUE</code>
</p>
<p>PosteriorSamples JxQxM array of samples, if the
<code>posterior_samples = M &gt; 0</code>
</p>

<hr>
<h2 id='compute_posterior_matrices_general_R'>Compute posterior matrices (general version)</h2><span id='topic+compute_posterior_matrices_general_R'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_posterior_matrices_general_R(
  data,
  A,
  Ulist,
  posterior_weights,
  output_posterior_cov = FALSE,
  posterior_samples = 0,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_posterior_matrices_general_R_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by
<code>mash_set_data</code> or <code>mash_set_data_contrast</code></p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_general_R_+3A_a">A</code></td>
<td>
<p>the linear transformation matrix, Q x R matrix. This is
used to compute the posterior for Ab.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_general_R_+3A_ulist">Ulist</code></td>
<td>
<p>a list of P covariance matrices for each mixture
component</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_general_R_+3A_posterior_weights">posterior_weights</code></td>
<td>
<p>the JxP posterior probabilities of each
mixture component in Ulist for the data</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_general_R_+3A_output_posterior_cov">output_posterior_cov</code></td>
<td>
<p>whether or not to output posterior
covariance matrices for all effects</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_general_R_+3A_posterior_samples">posterior_samples</code></td>
<td>
<p>the number of samples to be drawn from the
posterior distribution of each effect.</p>
</td></tr>
<tr><td><code id="compute_posterior_matrices_general_R_+3A_seed">seed</code></td>
<td>
<p>a random number seed to use when sampling from the
posteriors. It is used when <code>posterior_samples &gt; 0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computations are performed without allocating an
excessive amount of memory.
</p>


<h3>Value</h3>

<p>PosteriorMean JxQ matrix of posterior means
</p>
<p>PosteriorSD JxQ matrix of posterior (marginal) standard
deviations
</p>
<p>NegativeProb JxQ matrix of posterior (marginal) probability
of being negative
</p>
<p>ZeroProb JxQ matrix of posterior (marginal) probability of
being zero
</p>
<p>lfsr JxQ matrix of local false sign rates
</p>
<p>PosteriorCov QxQxJ array of posterior covariance matrices,
if the <code>output_posterior_cov = TRUE</code>
</p>
<p>PosteriorSamples JxQxM array of samples, if the
<code>posterior_samples = M &gt; 0</code>
</p>

<hr>
<h2 id='compute_posterior_weights'>Compute posterior probabilities that each effect came from
each component</h2><span id='topic+compute_posterior_weights'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_posterior_weights(pi, lik_mat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_posterior_weights_+3A_pi">pi</code></td>
<td>
<p>a K vector of mixture proportions</p>
</td></tr>
<tr><td><code id="compute_posterior_weights_+3A_lik_mat">lik_mat</code></td>
<td>
<p>a JxK matrix of likelihoods</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a JxK matrix of posterior probabilities, the jth row
contains posteriors for jth effect
</p>

<hr>
<h2 id='compute_vloglik_from_matrix_and_pi'>Computes a vector of loglikelihoods from a matrix of
log-likelihoods and fitted pi</h2><span id='topic+compute_vloglik_from_matrix_and_pi'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_vloglik_from_matrix_and_pi(pi_s, lm, Shat_alpha)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_vloglik_from_matrix_and_pi_+3A_pi_s">pi_s</code></td>
<td>
<p>the vector of mixture proportions</p>
</td></tr>
<tr><td><code id="compute_vloglik_from_matrix_and_pi_+3A_lm">lm</code></td>
<td>
<p>the results of a likelihood matrix calculation from
<code>calc_relative_lik_matrix</code></p>
</td></tr>
<tr><td><code id="compute_vloglik_from_matrix_and_pi_+3A_shat_alpha">Shat_alpha</code></td>
<td>
<p>matrix of Shat^alpha</p>
</td></tr>
</table>

<hr>
<h2 id='contrast_matrix'>Create contrast matrix</h2><span id='topic+contrast_matrix'></span>

<h3>Description</h3>

<p>Create contrast matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>contrast_matrix(R, ref, name = 1:R)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="contrast_matrix_+3A_r">R</code></td>
<td>
<p>the number of column for the contrast matrix</p>
</td></tr>
<tr><td><code id="contrast_matrix_+3A_ref">ref</code></td>
<td>
<p>the reference group. It could be a number between 1,...,
R, R is number of conditions, or the name of reference group. If
there is no reference group, it can be the string 'mean'.</p>
</td></tr>
<tr><td><code id="contrast_matrix_+3A_name">name</code></td>
<td>
<p>a length R vector contains the name for conditions</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>contrast_matrix(5, 'mean')

</code></pre>

<hr>
<h2 id='cov_all_zeros'>Compute an R by R matrix of all 0s</h2><span id='topic+cov_all_zeros'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_all_zeros(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_all_zeros_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with 1 entry, the R by R matrix of all 0s
</p>

<hr>
<h2 id='cov_canonical'>Compute a list of canonical covariance matrices</h2><span id='topic+cov_canonical'></span>

<h3>Description</h3>

<p>Compute a list of canonical covariance matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_canonical(
  data,
  cov_methods = c("identity", "singletons", "equal_effects", "simple_het")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_canonical_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="cov_canonical_+3A_cov_methods">cov_methods</code></td>
<td>
<p>a vector of strings indicating the matrices to
be used: &quot;identity&quot; for the identity (effects are independent among
conditions); &quot;singletons&quot; for the set of matrices with just one
non-zero entry <code class="reqn">x_{jj} = 1, j = 1,...,R</code>; (effect specific to
condition j); &quot;equal_effects&quot; for the matrix of all 1s (effects are
equal among conditions); &quot;simple_het&quot; for a set of matrices with 1s
on the diagonal and all off-diagonal elements equal to 0.25, 0.5 or
0.75; see <code>cov_simple_het</code> for details; (effects are
correlated among conditions).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default is that this function computes covariance matrices corresponding
to the &quot;bmalite&quot; models.
</p>


<h3>Value</h3>

<p>a list of covariance matrices
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = mash_set_data(Bhat = cbind(c(1,2),c(3,4)), Shat = cbind(c(1,1),c(1,1)))
 cov_canonical(data)
 cov_canonical(data,"singletons")
 cov_canonical(data,c("id","sing")) # can use partial matching of names

</code></pre>

<hr>
<h2 id='cov_ed'>Perform &quot;extreme deconvolution&quot; (Bovy et al) on a subset of
the data</h2><span id='topic+cov_ed'></span>

<h3>Description</h3>

<p>Perform &quot;extreme deconvolution&quot; (Bovy et al) on a subset of
the data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_ed(data, Ulist_init, subset = NULL, algorithm = c("bovy", "teem"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_ed_+3A_data">data</code></td>
<td>
<p>a mash data object</p>
</td></tr>
<tr><td><code id="cov_ed_+3A_ulist_init">Ulist_init</code></td>
<td>
<p>a named list of covariance matrices to use to
initialize ED; default is to use matrices from PCs</p>
</td></tr>
<tr><td><code id="cov_ed_+3A_subset">subset</code></td>
<td>
<p>a subset of data to be used when ED is run (set to
NULL for all the data)</p>
</td></tr>
<tr><td><code id="cov_ed_+3A_algorithm">algorithm</code></td>
<td>
<p>algorithm to run ED</p>
</td></tr>
<tr><td><code id="cov_ed_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to ED algorith, see
<code><a href="#topic+extreme_deconvolution">extreme_deconvolution</a></code> for algorithm 'bovy', or
<code><a href="#topic+teem_wrapper">teem_wrapper</a></code> for algorithm 'teem'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Runs the extreme deconvolution algorithm from Bovy et al
(Annals of Applied Statistics) to estimate data-driven covariance
matrices. It can be initialized with, for example running <code>cov_pca</code> with,
say, 5 PCs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data = mash_set_data(Bhat = cbind(c(1,2),c(3,4)), Shat = cbind(c(1,1),c(1,1)))
U_pca = cov_pca(data,2)
U_x = apply(data$Bhat, 2, function(x) x - mean(x))
U_xx = t(U_x) %*% U_x / nrow(U_x)
cov_ed(data,c(U_pca, list(xx = U_xx)))

## End(Not run)

</code></pre>

<hr>
<h2 id='cov_equal_effects'>Compute an R by R matrix of all 1s</h2><span id='topic+cov_equal_effects'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_equal_effects(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_equal_effects_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with 1 entry, the R by R matrix of all 1s
</p>

<hr>
<h2 id='cov_first_singleton'>Compute all the singleton matrices corresponding to
condition-specific effects in first condition only; used for
testing purposes</h2><span id='topic+cov_first_singleton'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_first_singleton(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_first_singleton_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>an R by R matrix with all 0s except the (1,1) element is 1
</p>

<hr>
<h2 id='cov_flash'>Perform Empirical Bayes Matrix Factorization using flashier, and
return a list of candidate covariance matrices</h2><span id='topic+cov_flash'></span>

<h3>Description</h3>

<p>Perform Empirical Bayes Matrix Factorization using flashier, and
return a list of candidate covariance matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_flash(
  data,
  factors = c("default", "nonneg"),
  subset = NULL,
  remove_singleton = FALSE,
  tag = NULL,
  output_model = NULL,
  greedy_args = list(),
  backfit_args = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_flash_+3A_data">data</code></td>
<td>
<p>A &ldquo;mash&rdquo; data object.</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_factors">factors</code></td>
<td>
<p>If <code>factors = "default"</code>, the factors and
loadings are both unconstrained. If <code>factors = "nonneg"</code>, the
factors are constrained to be non-negative, and the loadings are
unconstrained.</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_subset">subset</code></td>
<td>
<p>Data samples (rows) used to estimate the
covariances. Sset to <code>NULL</code> to use all the data.</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_remove_singleton">remove_singleton</code></td>
<td>
<p>If <code>remove_singleton = TRUE</code>, factors
corresponding to singleton matrices will be removed from the output.</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_tag">tag</code></td>
<td>
<p>How to name the covariance matrices.</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_output_model">output_model</code></td>
<td>
<p>The fitted flash model will be saved to this file
(using <code><a href="base.html#topic+saveRDS">saveRDS</a></code>).</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_greedy_args">greedy_args</code></td>
<td>
<p>List containing additional parameters passed to
<code>flashier::flash_greedy</code>.</p>
</td></tr>
<tr><td><code id="cov_flash_+3A_backfit_args">backfit_args</code></td>
<td>
<p>List containing additional parameters passed
to <code>flashier::flash_backfit</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of covariance matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See https://stephenslab.github.io/mashr/articles/flash_mash.html
# for an example

</code></pre>

<hr>
<h2 id='cov_from_factors'>produce list of rank-1 covariance matrices corresponding to rows of f</h2><span id='topic+cov_from_factors'></span>

<h3>Description</h3>

<p>produce list of rank-1 covariance matrices corresponding to rows of f
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_from_factors(f, name)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_from_factors_+3A_f">f</code></td>
<td>
<p>a matrix of factors (each row is a factor)</p>
</td></tr>
<tr><td><code id="cov_from_factors_+3A_name">name</code></td>
<td>
<p>a string indicating the name to use</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of rank one matrices whose kth element is f[k,]
f[k,]' and named name_k
</p>

<hr>
<h2 id='cov_pca'>Perform PCA on data and return list of candidate covariance
matrices</h2><span id='topic+cov_pca'></span>

<h3>Description</h3>

<p>Perform PCA on data and return list of candidate covariance
matrices
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_pca(data, npc, subset = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_pca_+3A_data">data</code></td>
<td>
<p>a mash data object</p>
</td></tr>
<tr><td><code id="cov_pca_+3A_npc">npc</code></td>
<td>
<p>the number of PCs to use</p>
</td></tr>
<tr><td><code id="cov_pca_+3A_subset">subset</code></td>
<td>
<p>indices of the subset of data to use (set to NULL for
all data)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list of covariance matrices: the npc rank-one
covariance matrices based on the first npc PCs, and the rank npc
covariance matrix. If flashier did not identify any factors,
<code>NULL</code> is returned.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = mash_set_data(Bhat = cbind(c(1,2),c(3,4)), Shat = cbind(c(1,1),c(1,1)))
cov_pca(data,2)

</code></pre>

<hr>
<h2 id='cov_simple_het'>Compute covariance matrices with diagonal element 1 and
off-diagonal element corr</h2><span id='topic+cov_simple_het'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_simple_het(data, corr = c(0.25, 0.5, 0.75))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_simple_het_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="cov_simple_het_+3A_corr">corr</code></td>
<td>
<p>a vector containing the correlations to be used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of matrices, one for each value in corr
</p>

<hr>
<h2 id='cov_udi'>Compute a list of covariance matrices corresponding to the
&quot;Unassociated&quot;, &quot;Directly associated&quot; and &quot;Indirectly associated&quot;
models</h2><span id='topic+cov_udi'></span>

<h3>Description</h3>

<p>Compute a list of covariance matrices corresponding to the
&quot;Unassociated&quot;, &quot;Directly associated&quot; and &quot;Indirectly associated&quot;
models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_udi(data, model = udi_model_matrix(n_conditions(data)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_udi_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="cov_udi_+3A_model">model</code></td>
<td>
<p>a model matrix with R columns, where R is the number
of conditions in the data; each row should be a vector of length R
with elements &quot;U&quot;,&quot;D&quot; and &quot;I&quot; indicating whether each effect is
Unassociated, Directly associated or Indirectly associated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If model is specified then this returns the covariance
matrices for those models. The default creates all possible models.
For a desription of the &quot;Unassociated&quot;, &quot;Directly associated&quot; and
&quot;Indirectly associated&quot; models see Stephens M (2013), A unified
framework for Association Analysis with Multiple Related
Phenotypes, PloS ONE.
</p>


<h3>Value</h3>

<p>a named list of covariance matrices
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data = mash_set_data(Bhat = cbind(c(1,2),c(3,4)), Shat = cbind(c(1,1),c(1,1)))
cov_udi(data)
cov_udi(data,c('I','D'))

</code></pre>

<hr>
<h2 id='cov_udi_single'>Computes the covariance matrix for a single UDI model</h2><span id='topic+cov_udi_single'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cov_udi_single(data, model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cov_udi_single_+3A_data">data</code></td>
<td>
<p>a mash data object</p>
</td></tr>
<tr><td><code id="cov_udi_single_+3A_model">model</code></td>
<td>
<p>a vector of length R of &quot;U&quot;,&quot;D&quot; and &quot;I&quot;</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a named list of one element
</p>

<hr>
<h2 id='estimate_null_correlation_simple'>Estimate null correlations (simple)</h2><span id='topic+estimate_null_correlation_simple'></span>

<h3>Description</h3>

<p>Estimates a null correlation matrix from data using
simple z score threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_null_correlation_simple(data, z_thresh = 2, est_cor = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate_null_correlation_simple_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="estimate_null_correlation_simple_+3A_z_thresh">z_thresh</code></td>
<td>
<p>the z score threshold below which to call an effect null</p>
</td></tr>
<tr><td><code id="estimate_null_correlation_simple_+3A_est_cor">est_cor</code></td>
<td>
<p>whether to estimate correlation matrix (TRUE) or the
covariance matrix (FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a simple estimate of the correlation matrix (or
covariance matrix) among conditions under the null.  Specifically,
the simple estimate is the empirical correlation (or covariance)
matrix of the z scores for those effects that have (absolute) z
score &lt; z_thresh in all conditions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
estimate_null_correlation_simple(data)

</code></pre>

<hr>
<h2 id='expand_cov'>Create expanded list of covariance matrices expanded by grid</h2><span id='topic+expand_cov'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand_cov(Ulist, grid, usepointmass = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="expand_cov_+3A_ulist">Ulist</code></td>
<td>
<p>a list of covarance matrices</p>
</td></tr>
<tr><td><code id="expand_cov_+3A_grid">grid</code></td>
<td>
<p>a grid of scalar values by which the covariance
matrices are to be sc</p>
</td></tr>
<tr><td><code id="expand_cov_+3A_usepointmass">usepointmass</code></td>
<td>
<p>if TRUE adds a point mass at 0 (null component)
to the list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This takes the covariance matrices in Ulist and multiplies
them by the grid values If usepointmass is TRUE then it adds a null
component.
</p>

<hr>
<h2 id='extreme_deconvolution'>Density estimation using Gaussian mixtures in the presence
of noisy, heterogeneous and incomplete data</h2><span id='topic+extreme_deconvolution'></span>

<h3>Description</h3>

<p>We present a general algorithm to infer a
d-dimensional distribution function given a set of heterogeneous,
noisy observations or samples. This algorithm reconstructs the
error-deconvolved or 'underlying' distribution function common to
all samples, even when the individual samples have unique error and
missing-data properties. The underlying distribution is modeled as
a mixture of Gaussians, which is completely general. Model
parameters are chosen to optimize a justified, scalar objective
function: the logarithm of the probability of the data under the
error-convolved model, where the error convolution is different for
each data point. Optimization is performed by an Expectation
Maximization (EM) algorithm, extended by a regularization technique
and 'split-and-merge' procedure. These extensions mitigate problems
with singularities and local maxima, which are often encountered
when using the EM algorithm to estimate Gaussian density mixtures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extreme_deconvolution(
  ydata,
  ycovar,
  xamp,
  xmean,
  xcovar,
  projection = NULL,
  weight = NULL,
  fixamp = NULL,
  fixmean = NULL,
  fixcovar = NULL,
  tol = 1e-06,
  maxiter = 1e+09,
  w = 0,
  logfile = NULL,
  splitnmerge = 0,
  maxsnm = FALSE,
  likeonly = FALSE,
  logweight = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="extreme_deconvolution_+3A_ydata">ydata</code></td>
<td>
<p>[ndata,dy] matrix of observed quantities</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_ycovar">ycovar</code></td>
<td>
<p>[ndata,dy] / [ndata,dy,dy] / [dy,dy,ndata] matrix,
list or 3D array of observational error covariances (if [ndata,dy]
then the error correlations are assumed to vanish)</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_xamp">xamp</code></td>
<td>
<p>[ngauss] array of initial amplitudes (*not* [1,ngauss])</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_xmean">xmean</code></td>
<td>
<p>[ngauss,dx] matrix of initial means</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_xcovar">xcovar</code></td>
<td>
<p>[ngauss,dx,dx] list of matrices of initial covariances</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_projection">projection</code></td>
<td>
<p>[ndata,dy,dx] list of projection matrices</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_weight">weight</code></td>
<td>
<p>[ndata] array of weights to be applied to the data points</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_fixamp">fixamp</code></td>
<td>
<p>(default=None) None, True/False, or list of bools</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_fixmean">fixmean</code></td>
<td>
<p>(default=None) None, True/False, or list of bools</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_fixcovar">fixcovar</code></td>
<td>
<p>(default=None) None, True/False, or list of bools</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_tol">tol</code></td>
<td>
<p>(double, default=1.e-6) tolerance for convergence</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_maxiter">maxiter</code></td>
<td>
<p>(long, default= 10**9) maximum number of iterations to
perform</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_w">w</code></td>
<td>
<p>(double, default=0.) covariance regularization parameter (of the
conjugate prior)</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_logfile">logfile</code></td>
<td>
<p>basename for several logfiles (_c.log has output
from the c-routine; _loglike.log has the log likelihood path of all
the accepted routes, i.e. only parts which increase the likelihood
are included, during splitnmerge)</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_splitnmerge">splitnmerge</code></td>
<td>
<p>(int, default=0) depth to go down the splitnmerge path</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_maxsnm">maxsnm</code></td>
<td>
<p>(Bool, default=False) use the maximum number of split 'n'
merge steps, K*(K-1)*(K-2)/2</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_likeonly">likeonly</code></td>
<td>
<p>(Bool, default=False) only compute the total log
likelihood of the data</p>
</td></tr>
<tr><td><code id="extreme_deconvolution_+3A_logweight">logweight</code></td>
<td>
<p>(bool, default=False) if True, weight is actually
log(weight)</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>avgloglikedata</code></td>
<td>
<p>avgloglikedata after convergence</p>
</td></tr>
<tr><td><code>xamp</code></td>
<td>
<p>updated xamp</p>
</td></tr> <tr><td><code>xmean</code></td>
<td>
<p>updated xmean</p>
</td></tr>
<tr><td><code>xcovar</code></td>
<td>
<p>updated xcovar</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jo Bovy, David W. Hogg, &amp; Sam T. Roweis
</p>


<h3>References</h3>

<p>Inferring complete distribution functions from noisy,
heterogeneous and incomplete observations Jo Bovy, David W. Hogg, &amp; Sam T.
Roweis, Submitted to AOAS (2009) [arXiv/0905.2979]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
ydata &lt;-
c(2.62434536, 0.38824359, 0.47182825, -0.07296862, 1.86540763,
  -1.30153870, 2.74481176, 0.23879310, 1.31903910, 0.75062962,
  2.46210794, -1.06014071, 0.67758280, 0.61594565, 2.13376944,
  -0.09989127, 0.82757179, 0.12214158, 1.04221375, 1.58281521,
  -0.10061918, 2.14472371, 1.90159072, 1.50249434, 1.90085595,
  0.31627214, 0.87710977, 0.06423057, 0.73211192, 1.53035547,
  0.30833925, 0.60324647, 0.31282730, 0.15479436, 0.32875387,
  0.98733540, -0.11731035, 1.23441570, 2.65980218, 1.74204416,
  0.80816445, 0.11237104, 0.25284171, 2.69245460, 1.05080775,
  0.36300435, 1.19091548, 3.10025514, 1.12015895, 1.61720311,
  1.30017032, 0.64775015, -0.14251820, 0.65065728, 0.79110577,
  1.58662319, 1.83898341, 1.93110208, 1.28558733, 1.88514116,
  0.24560206, 2.25286816, 1.51292982, 0.70190717, 1.48851815,
  0.92442829, 2.13162939, 2.51981682, 3.18557541, -0.39649633,
  -0.44411380, 0.49553414, 1.16003707, 1.87616892, 1.31563495,
  -1.02220122, 0.69379599, 1.82797464, 1.23009474, 1.76201118,
  0.77767186, 0.79924193, 1.18656139, 1.41005165, 1.19829972,
  1.11900865, 0.32933771, 1.37756379, 1.12182127, 2.12948391,
  2.19891788, 1.18515642, 0.62471505, 0.36126959, 1.42349435,
  1.07734007, 0.65614632, 1.04359686, 0.37999916, 1.69803203,
  0.55287144, 2.22450770, 1.40349164, 1.59357852, -0.09491185,
  1.16938243, 1.74055645, 0.04629940, 0.73378149, 1.03261455,
  -0.37311732, 1.31515939, 1.84616065, 0.14048406, 1.35054598,
  -0.31228341, 0.96130449, -0.61577236, 2.12141771, 1.40890054,
  0.97538304, 0.22483838, 2.27375593, 2.96710175, -0.85798186,
  2.23616403, 2.62765075, 1.33801170, -0.19926803, 1.86334532,
  0.81907970, 0.39607937, -0.23005814, 1.55053750, 1.79280687,
  0.37646927, 1.52057634, -0.14434139, 1.80186103, 1.04656730,
  0.81343023, 0.89825413, 1.86888616, 1.75041164, 1.52946532,
  1.13770121, 1.07782113, 1.61838026, 1.23249456, 1.68255141,
  0.68988323, -1.43483776, 2.03882460, 3.18697965, 1.44136444,
  0.89984477, 0.86355526, 0.88094581, 1.01740941, -0.12201873,
  0.48290554, 0.00297317, 1.24879916, 0.70335885, 1.49521132,
  0.82529684, 1.98633519, 1.21353390, 3.19069973, -0.89636092,
  0.35308331, 1.90148689, 3.52832571, 0.75136522, 1.04366899,
  0.77368576, 2.33145711, 0.71269214, 1.68006984, 0.68019840,
  -0.27255875, 1.31354772, 1.50318481, 2.29322588, 0.88955297,
  0.38263794, 1.56276110, 1.24073709, 1.28066508, 0.92688730,
  2.16033857, 1.36949272, 2.90465871, 2.11105670, 1.65904980,
  -0.62743834, 1.60231928, 1.42028220, 1.81095167, 2.04444209)

ydata  &lt;- matrix(ydata,length(ydata),1)
N      &lt;- dim(ydata)[1]
ycovar &lt;- ydata*0 + 0.01
xamp   &lt;- c(0.5,0.5)
xmean  &lt;- matrix(c(0.86447943, 0.67078879, 0.322681, 0.45087394),2,2)
xcovar &lt;-
  list(matrix(c(0.03821028, 0.04014796, 0.04108113, 0.03173839),2,2),
       matrix(c(0.06219194, 0.09738021, 0.04302473, 0.06778009),2,2))
projection &lt;- list()
for (i in 1:N)
  projection[[i]] = matrix(c(i%%2,(i+1)%%2),1,2)
res &lt;- extreme_deconvolution(ydata, ycovar, xamp, xmean, xcovar,
         projection=projection, logfile="ExDeconDemo")

## End(Not run)

</code></pre>

<hr>
<h2 id='get_estimated_pi'>Return the estimated mixture proportions</h2><span id='topic+get_estimated_pi'></span>

<h3>Description</h3>

<p>Return the estimated mixture proportions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_estimated_pi(m, dimension = c("cov", "grid", "all"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_estimated_pi_+3A_m">m</code></td>
<td>
<p>the mash result</p>
</td></tr>
<tr><td><code id="get_estimated_pi_+3A_dimension">dimension</code></td>
<td>
<p>indicates whether you want the mixture proportions for the covariances, grid, or all</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the fit was done with 'usepointmass=TRUE' then the
first element of the returned vector will correspond to the null,
and the remaining elements to the non-null covariance matrices.
Suppose the fit was done with $K$ covariances and a grid of length
$L$. If 'dimension=cov' then the returned vector will be of length
$K$ (or $K+1$ if 'usepointmass=TRUE').  If 'dimension=grid' then
the returned vector will be of length $L$ (or $L+1$).  If
'dimension=all' then the returned vector will be of length $LK$ (or
$LK+1$). The names of the vector will be informative for which
combination each element corresponds to.
</p>


<h3>Value</h3>

<p>a named vector containing the estimated mixture proportions.
</p>

<hr>
<h2 id='get_log10bf'>Return the Bayes Factor for each effect</h2><span id='topic+get_log10bf'></span>

<h3>Description</h3>

<p>Return the Bayes Factor for each effect
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_log10bf(m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_log10bf_+3A_m">m</code></td>
<td>
<p>the mash result (from joint or 1by1 analysis); must have
been computed using usepointmass=TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if m was fitted using usepointmass=TRUE then returns a
vector of the log10(bf) values for each effect. That is, the jth
element lbf[j] is log10(Pr(Bj | g=ghat-nonnull)/Pr(Bj | g = 0))
where ghat-nonnull is the non-null part of ghat.  Otherwise returns
NULL.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
get_log10bf(m)

</code></pre>

<hr>
<h2 id='get_n_significant_conditions'>Count number of conditions each effect is significant in</h2><span id='topic+get_n_significant_conditions'></span>

<h3>Description</h3>

<p>Count number of conditions each effect is significant in
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_n_significant_conditions(
  m,
  thresh = 0.05,
  conditions = NULL,
  sig_fn = get_lfsr
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_n_significant_conditions_+3A_m">m</code></td>
<td>
<p>the mash result (from joint or 1by1 analysis)</p>
</td></tr>
<tr><td><code id="get_n_significant_conditions_+3A_thresh">thresh</code></td>
<td>
<p>indicates the threshold below which to call signals
significant</p>
</td></tr>
<tr><td><code id="get_n_significant_conditions_+3A_conditions">conditions</code></td>
<td>
<p>which conditions to include in check (default to
all)</p>
</td></tr>
<tr><td><code id="get_n_significant_conditions_+3A_sig_fn">sig_fn</code></td>
<td>
<p>the significance function used to extract
significance from mash object; eg could be ashr::get_lfsr or
ashr::get_lfdr</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector containing the number of significant conditions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
get_n_significant_conditions(m)
</code></pre>

<hr>
<h2 id='get_pairwise_sharing'>Compute the proportion of (significant) signals shared by
magnitude in each pair of conditions, based on the poterior mean</h2><span id='topic+get_pairwise_sharing'></span>

<h3>Description</h3>

<p>Compute the proportion of (significant) signals shared by
magnitude in each pair of conditions, based on the poterior mean
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pairwise_sharing(m, factor = 0.5, lfsr_thresh = 0.05, FUN = identity)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pairwise_sharing_+3A_m">m</code></td>
<td>
<p>the mash fit</p>
</td></tr>
<tr><td><code id="get_pairwise_sharing_+3A_factor">factor</code></td>
<td>
<p>a number in [0,1] the factor within which effects are
considered to be shared</p>
</td></tr>
<tr><td><code id="get_pairwise_sharing_+3A_lfsr_thresh">lfsr_thresh</code></td>
<td>
<p>the lfsr threshold for including an effect in
the assessment</p>
</td></tr>
<tr><td><code id="get_pairwise_sharing_+3A_fun">FUN</code></td>
<td>
<p>a function to be applied to the estimated effect sizes
before assessing sharing. The most obvious choice beside the
default 'FUN=identity' would be 'FUN=abs' if you want to ignore the
sign of the effects when assesing sharing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each pair of tissues, first identify the effects that
are significant (by lfsr&lt;lfsr_thresh) in at least one of the two
tissues. Then compute what fraction of these have an estimated
(posterior mean) effect size within a factor 'factor' of one
another. The results are returned as an R by R matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
get_pairwise_sharing(m) # sharing by magnitude (same sign)
get_pairwise_sharing(m, factor=0) # sharing by sign
get_pairwise_sharing(m, FUN=abs) # sharing by magnitude when sign is ignored
</code></pre>

<hr>
<h2 id='get_pairwise_sharing_from_samples'>Compute the proportion of (significant) signals shared by
magnitude in each pair of conditions</h2><span id='topic+get_pairwise_sharing_from_samples'></span>

<h3>Description</h3>

<p>Compute the proportion of (significant) signals shared by
magnitude in each pair of conditions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pairwise_sharing_from_samples(
  m,
  factor = 0.5,
  lfsr_thresh = 0.05,
  FUN = identity
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pairwise_sharing_from_samples_+3A_m">m</code></td>
<td>
<p>the mash fit with samples from posteriors</p>
</td></tr>
<tr><td><code id="get_pairwise_sharing_from_samples_+3A_factor">factor</code></td>
<td>
<p>a number in [0,1] the factor within which effects are
considered to be shared</p>
</td></tr>
<tr><td><code id="get_pairwise_sharing_from_samples_+3A_lfsr_thresh">lfsr_thresh</code></td>
<td>
<p>the lfsr threshold for including an effect in
the assessment</p>
</td></tr>
<tr><td><code id="get_pairwise_sharing_from_samples_+3A_fun">FUN</code></td>
<td>
<p>a function to be applied to the estimated effect sizes
before assessing sharing. The most obvious choice beside the
default 'FUN=identity' would be 'FUN=abs' if you want to ignore the
sign of the effects when assesing sharing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each pair of conditions, compute the fraction of
effects that are within a factor 'factor' of one another. The
results are returned as an R by R matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data), posterior_samples=5, algorithm='R')
get_pairwise_sharing_from_samples(m) # sharing by magnitude (same sign)
get_pairwise_sharing_from_samples(m, factor=0) # sharing by sign
get_pairwise_sharing_from_samples(m, FUN=abs) # sharing by magnitude when sign is ignored
</code></pre>

<hr>
<h2 id='get_samples'>Return samples from a mash object</h2><span id='topic+get_samples'></span>

<h3>Description</h3>

<p>Return samples from a mash object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_samples(m)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_samples_+3A_m">m</code></td>
<td>
<p>The mash fit.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data), posterior_samples=5, algorithm='R')
get_samples(m)
</code></pre>

<hr>
<h2 id='get_significant_results'>Find effects that are significant in at least one condition</h2><span id='topic+get_significant_results'></span>

<h3>Description</h3>

<p>Find effects that are significant in at least one condition
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_significant_results(m, thresh = 0.05, conditions = NULL, sig_fn = get_lfsr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_significant_results_+3A_m">m</code></td>
<td>
<p>the mash result (from joint or 1by1 analysis)</p>
</td></tr>
<tr><td><code id="get_significant_results_+3A_thresh">thresh</code></td>
<td>
<p>indicates the threshold below which to call signals
significant</p>
</td></tr>
<tr><td><code id="get_significant_results_+3A_conditions">conditions</code></td>
<td>
<p>which conditions to include in check (default to all)</p>
</td></tr>
<tr><td><code id="get_significant_results_+3A_sig_fn">sig_fn</code></td>
<td>
<p>the significance function used to extract
significance from mash object; eg could be ashr::get_lfsr or
ashr::get_lfdr. (Small values must indicate significant.)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector containing the indices of the significant effects,
by order of most significant to least
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
get_significant_results(m)
</code></pre>

<hr>
<h2 id='make_names'>Create names for covariance matrices</h2><span id='topic+make_names'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>
<p>Adds _suffixes to names for each element of suffixes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_names(names, suffixes)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_names_+3A_names">names</code></td>
<td>
<p>a string</p>
</td></tr>
<tr><td><code id="make_names_+3A_suffixes">suffixes</code></td>
<td>
</td></tr>
</table>

<hr>
<h2 id='mash'>Apply mash method to data</h2><span id='topic+mash'></span>

<h3>Description</h3>

<p>Apply mash method to data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash(
  data,
  Ulist = NULL,
  gridmult = sqrt(2),
  grid = NULL,
  normalizeU = TRUE,
  usepointmass = TRUE,
  g = NULL,
  fixg = FALSE,
  prior = c("nullbiased", "uniform"),
  nullweight = 10,
  optmethod = c("mixSQP", "mixIP", "mixEM", "cxxMixSquarem"),
  control = list(),
  verbose = TRUE,
  add.mem.profile = FALSE,
  algorithm.version = c("Rcpp", "R"),
  pi_thresh = 1e-10,
  A = NULL,
  posterior_samples = 0,
  seed = 123,
  outputlevel = 2,
  output_lfdr = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_+3A_data">data</code></td>
<td>
<p>a mash data object containing the Bhat matrix, standard
errors, alpha value; created using <code>mash_set_data</code> or
<code>mash_set_data_contrast</code></p>
</td></tr>
<tr><td><code id="mash_+3A_ulist">Ulist</code></td>
<td>
<p>a list of covariance matrices to use
(see <code>normalizeU</code> for rescaling these matrices)</p>
</td></tr>
<tr><td><code id="mash_+3A_gridmult">gridmult</code></td>
<td>
<p>scalar indicating factor by which adjacent grid
values should differ; close to 1 for fine grid</p>
</td></tr>
<tr><td><code id="mash_+3A_grid">grid</code></td>
<td>
<p>vector of grid values to use (scaling factors omega in
paper)</p>
</td></tr>
<tr><td><code id="mash_+3A_normalizeu">normalizeU</code></td>
<td>
<p>whether or not to normalize the U covariances to
have maximum of 1 on diagonal</p>
</td></tr>
<tr><td><code id="mash_+3A_usepointmass">usepointmass</code></td>
<td>
<p>whether to include a point mass at 0,
corresponding to null in every condition</p>
</td></tr>
<tr><td><code id="mash_+3A_g">g</code></td>
<td>
<p>the value of g obtained from a previous mash fit - an
alternative to supplying Ulist, grid and usepointmass</p>
</td></tr>
<tr><td><code id="mash_+3A_fixg">fixg</code></td>
<td>
<p>if g is supplied, allows the mixture proportions to be
fixed rather than estimated; e.g., useful for fitting mash to test
data after fitting it to training data</p>
</td></tr>
<tr><td><code id="mash_+3A_prior">prior</code></td>
<td>
<p>indicates what penalty to use on the likelihood, if any</p>
</td></tr>
<tr><td><code id="mash_+3A_nullweight">nullweight</code></td>
<td>
<p>scalar, the weight put on the prior under
&ldquo;nullbiased&rdquo; specification, see &ldquo;prior&rdquo;.</p>
</td></tr>
<tr><td><code id="mash_+3A_optmethod">optmethod</code></td>
<td>
<p>name of optimization method to use</p>
</td></tr>
<tr><td><code id="mash_+3A_control">control</code></td>
<td>
<p>A list of control parameters passed to optmethod.</p>
</td></tr>
<tr><td><code id="mash_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, print progress to R console.</p>
</td></tr>
<tr><td><code id="mash_+3A_add.mem.profile">add.mem.profile</code></td>
<td>
<p>If <code>TRUE</code>, print memory usage to R
console (requires R library 'profmem').</p>
</td></tr>
<tr><td><code id="mash_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>Indicates whether to use R or Rcpp version</p>
</td></tr>
<tr><td><code id="mash_+3A_pi_thresh">pi_thresh</code></td>
<td>
<p>threshold below which mixture components are
ignored in computing posterior summaries (to speed calculations by
ignoring negligible components)</p>
</td></tr>
<tr><td><code id="mash_+3A_a">A</code></td>
<td>
<p>the linear transformation matrix, Q x R matrix. This is
used to compute the posterior for Ab.</p>
</td></tr>
<tr><td><code id="mash_+3A_posterior_samples">posterior_samples</code></td>
<td>
<p>the number of samples to be drawn from the
posterior distribution of each effect.</p>
</td></tr>
<tr><td><code id="mash_+3A_seed">seed</code></td>
<td>
<p>A random number seed to use when sampling from the
posteriors. It is used when <code>posterior_samples &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="mash_+3A_outputlevel">outputlevel</code></td>
<td>
<p>controls amount of computation / output; 1:
output only estimated mixture component proportions, 2: and
posterior estimates, 3: and posterior covariance matrices, 4: and
likelihood matrices</p>
</td></tr>
<tr><td><code id="mash_+3A_output_lfdr">output_lfdr</code></td>
<td>
<p>If <code>output_lfdr = TRUE</code>, output local false
discovery rate estimates. The lfdr tends to be sensitive to
mis-estimated covariance matrices, and generally we do not
recommend using them; we recommend using the local false sign rate
(lfsr) instead, which is always returned, even when
<code>output_lfdr = TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with elements result, loglik and fitted_g
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Bhat     = matrix(rnorm(100),ncol=5) # create some simulated data
Shat     = matrix(rep(1,100),ncol=5)
data     = mash_set_data(Bhat,Shat, alpha=1)
U.c      = cov_canonical(data)
res.mash = mash(data,U.c)

# Run mash with penalty exponent on null term equal to 100.
# See "False disovery rates: a new deal" (M. Stephens 2017),
# supplementary material S.2.5 for more details.
set.seed(1)
simdata = simple_sims(500,5,1)
data    = mash_set_data(simdata$Bhat,simdata$Shat)
U.c     = cov_canonical(data)
res0    = mash(data,U.c)
res1    = mash(data,U.c,prior = "nullbiased",nullweight = 101)
plot(res0$fitted_g$pi,res1$fitted_g$pi,pch = 20)
abline(a = 0,b = 1,col = "skyblue",lty = "dashed")

</code></pre>

<hr>
<h2 id='mash_1by1'>Perform condition-by-condition analyses</h2><span id='topic+mash_1by1'></span>

<h3>Description</h3>

<p>Performs simple &quot;condition-by-condition&quot; analysis by
running <code>ash</code> from package <code>ashr</code> on data from each
condition, one at a time. May be a useful first step to identify
top hits in each condition before a mash analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_1by1(data, alpha = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_1by1_+3A_data">data</code></td>
<td>
<p>A list with the following two elements: <code>Bhat</code> an
n by R matrix of observations (n units in R conditions); and
<code>Shat</code>, an n by R matrix of standard errors (n units in R
conditions),</p>
</td></tr>
<tr><td><code id="mash_1by1_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value of alpha parameter in the model. alpha =
0 for Exchangeable Effects (EE), alpha = 1 for Exchangeable
Z-scores (EZ).</p>
</td></tr>
<tr><td><code id="mash_1by1_+3A_...">...</code></td>
<td>
<p>optionally, other parameters to be passed to ash</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list similar to the output of mash, particularly
including posterior matrices.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
mash_1by1(simdata)

</code></pre>

<hr>
<h2 id='mash_compute_loglik'>Compute loglikelihood for fitted mash object on new data.</h2><span id='topic+mash_compute_loglik'></span>

<h3>Description</h3>

<p>Compute loglikelihood for fitted mash object on new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_compute_loglik(g, data, algorithm.version = c("Rcpp", "R"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_compute_loglik_+3A_g">g</code></td>
<td>
<p>A mash object or the fitted_g from a mash object.</p>
</td></tr>
<tr><td><code id="mash_compute_loglik_+3A_data">data</code></td>
<td>
<p>A set of data on which to compute the loglikelihood.</p>
</td></tr>
<tr><td><code id="mash_compute_loglik_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>Indicate R or Rcpp version</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood for each element is <code class="reqn">p(Bhat_j |
  Shat_j,g,\alpha)</code> where <code class="reqn">Bhat_j | B_j, Shat_j \sim N(B_j,
  Shat_j)</code> and <code class="reqn">B_j/Shat_j^\alpha | Shat_j \sim g</code>.
</p>


<h3>Value</h3>

<p>The log-likelihood for data computed using g.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
mash_compute_loglik(m,data)

</code></pre>

<hr>
<h2 id='mash_compute_posterior_matrices'>Compute posterior matrices for fitted mash object on new
data</h2><span id='topic+mash_compute_posterior_matrices'></span>

<h3>Description</h3>

<p>Compute posterior matrices for fitted mash object on new
data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_compute_posterior_matrices(
  g,
  data,
  pi_thresh = 1e-10,
  algorithm.version = c("Rcpp", "R"),
  A = NULL,
  output_posterior_cov = FALSE,
  posterior_samples = 0,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_compute_posterior_matrices_+3A_g">g</code></td>
<td>
<p>a mash object or the fitted_g from a mash object.</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_data">data</code></td>
<td>
<p>a set of data on which to compute the posterior
matrices</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_pi_thresh">pi_thresh</code></td>
<td>
<p>threshold below which mixture components are
ignored in computing posterior summaries (to speed calculations by
ignoring negligible components)</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>Indicates whether to use R or Rcpp version</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_a">A</code></td>
<td>
<p>the linear transformation matrix, Q x R matrix. This is
used to compute the posterior for Ab.</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_output_posterior_cov">output_posterior_cov</code></td>
<td>
<p>whether or not to output posterior
covariance matrices for all effects</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_posterior_samples">posterior_samples</code></td>
<td>
<p>the number of samples to be drawn from the
posterior distribution of each effect.</p>
</td></tr>
<tr><td><code id="mash_compute_posterior_matrices_+3A_seed">seed</code></td>
<td>
<p>a random number seed to use when sampling from the
posteriors. It is used when <code>posterior_samples &gt; 0</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of posterior matrices
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
mash_compute_posterior_matrices(m,data)

</code></pre>

<hr>
<h2 id='mash_compute_vloglik'>Compute vector of loglikelihood for fitted mash object on
new data</h2><span id='topic+mash_compute_vloglik'></span>

<h3>Description</h3>

<p>Compute vector of loglikelihood for fitted mash object on
new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_compute_vloglik(g, data, algorithm.version = c("Rcpp", "R"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_compute_vloglik_+3A_g">g</code></td>
<td>
<p>A mash object.</p>
</td></tr>
<tr><td><code id="mash_compute_vloglik_+3A_data">data</code></td>
<td>
<p>A set of data on which to compute the loglikelihood.</p>
</td></tr>
<tr><td><code id="mash_compute_vloglik_+3A_algorithm.version">algorithm.version</code></td>
<td>
<p>Indicate R or Rcpp version</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The log-likelihood for each element is <code class="reqn">p(Bhat_j |
Shat_j,g,\alpha)</code> where <code class="reqn">Bhat_j | B_j, Shat_j \sim N(B_j,
Shat_j)</code> and <code class="reqn">B_j/Shat_j^\alpha | Shat_j \sim g</code> Here the value
of <code class="reqn">\alpha</code> is set when setting up the data object in
'mash_set_data'. If g is a mash object (safest!) then the function
will check that this value matches the <code class="reqn">\alpha</code> used when
fitting 'mash'. Note: as a convenience, this function can also be
called with g a mixture distribution with same structure as the
fitted_g from a mash object. This is mostly useful when doing
simulations, where you might want to compute the likelihood under
the &quot;true&quot; g. When used in this way the user is responsible for
making sure that the g makes sense with the alpha set in data.
</p>


<h3>Value</h3>

<p>The vector of log-likelihoods for each data point computed
using g.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
mash_compute_vloglik(m,data)

</code></pre>

<hr>
<h2 id='mash_estimate_corr_em'>Fit mash model and estimate residual correlations using EM algorithm</h2><span id='topic+mash_estimate_corr_em'></span>

<h3>Description</h3>

<p>Estimates a residual correlation matrix from data using an ad hoc EM
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_estimate_corr_em(
  data,
  Ulist,
  init,
  max_iter = 30,
  tol = 1,
  est_cor = TRUE,
  track_fit = FALSE,
  prior = c("nullbiased", "uniform"),
  details = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_estimate_corr_em_+3A_data">data</code></td>
<td>
<p>a mash data object, eg as created by <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_ulist">Ulist</code></td>
<td>
<p>a list of covariance matrices to use</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_init">init</code></td>
<td>
<p>the initial value for the residual correlation. If it is
not given, we use result from
<code>estimate_null_correlation_simple</code></p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of iterations to perform</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_est_cor">est_cor</code></td>
<td>
<p>whether to estimate correlation matrix (TRUE) or the
covariance matrix (FALSE)</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_track_fit">track_fit</code></td>
<td>
<p>add an attribute <code>trace</code> to output that saves
current values of all iterations</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_prior">prior</code></td>
<td>
<p>indicates what penalty to use on the likelihood, if any</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_details">details</code></td>
<td>
<p>whether to return details of the model, if it is
TRUE, the mash model, the number of iterations and the value of
objective functions will be returned</p>
</td></tr>
<tr><td><code id="mash_estimate_corr_em_+3A_...">...</code></td>
<td>
<p>other parameters pass to <code>mash</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the estimated residual correlation matrix among conditions.
We estimate the residual correlation matrix using an ad hoc em algorithm.
The update in the ad hoc M step is not guaranteed to increase the likelihood,
therefore, the EM algorithm is stopped before the likelihood drops.
The residual correlation matrix V is estimated using the posterior
second moment of the noise.
</p>
<p>Warning: This method could take some time.  The
<code><a href="#topic+estimate_null_correlation_simple">estimate_null_correlation_simple</a></code> gives a quick
approximation for the null correlation matrix.
</p>


<h3>Value</h3>

<p>the estimated correlation matrix and the
fitted mash model <br />
</p>
<table role = "presentation">
<tr><td><code>V</code></td>
<td>
<p>estimated residual correlation matrix</p>
</td></tr>
<tr><td><code>mash.model</code></td>
<td>
<p>fitted mash model</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(100,5,1)
m.1by1 = mash_1by1(mash_set_data(simdata$Bhat,simdata$Shat))
strong.subset = get_significant_results(m.1by1,0.05)
random.subset = sample(1:nrow(simdata$Bhat),20)
data.strong = mash_set_data(simdata$Bhat[strong.subset,], simdata$Shat[strong.subset,])
data.tmp = mash_set_data(simdata$Bhat[random.subset,], simdata$Shat[random.subset,])
U_pca = cov_pca(data.strong, 3)
U_ed = cov_ed(data.strong, U_pca)
Vhat = mash_estimate_corr_em(data.tmp, U_ed)
</code></pre>

<hr>
<h2 id='mash_plot_meta'>Plot metaplot for an effect based on posterior from mash</h2><span id='topic+mash_plot_meta'></span>

<h3>Description</h3>

<p>Plot metaplot for an effect based on posterior from mash
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_plot_meta(m, i, xlab = "Effect size", ylab = "Condition", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_plot_meta_+3A_m">m</code></td>
<td>
<p>the result of a mash fit</p>
</td></tr>
<tr><td><code id="mash_plot_meta_+3A_i">i</code></td>
<td>
<p>index of the effect to plot</p>
</td></tr>
<tr><td><code id="mash_plot_meta_+3A_xlab">xlab</code></td>
<td>
<p>Character string specifying x-axis label.</p>
</td></tr>
<tr><td><code id="mash_plot_meta_+3A_ylab">ylab</code></td>
<td>
<p>Character string specifying y-axis label.</p>
</td></tr>
<tr><td><code id="mash_plot_meta_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="rmeta.html#topic+metaplot">metaplot</a></code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
m = mash(data, cov_canonical(data))
mash_plot_meta(m,1)

</code></pre>

<hr>
<h2 id='mash_set_data'>Create a data object for mash analysis.</h2><span id='topic+mash_set_data'></span>

<h3>Description</h3>

<p>Create a data object for mash analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_set_data(
  Bhat,
  Shat = NULL,
  alpha = 0,
  df = Inf,
  pval = NULL,
  V = diag(ncol(Bhat)),
  zero_check_tol = .Machine$double.eps,
  zero_Bhat_Shat_reset = 0,
  zero_Shat_reset = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_set_data_+3A_bhat">Bhat</code></td>
<td>
<p>An N by R matrix of observed estimates.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_shat">Shat</code></td>
<td>
<p>An N by R matrix of corresponding standard errors. Shat
can be a scalar if all standard errors are equal. This is most
useful if Bhat is a matrix of Z scores, so elements of Shat are all
1. Default is 1.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value of alpha parameter in the model. alpha =
0 for Exchangeable Effects (EE), alpha = 1 for Exchangeable
Z-scores (EZ). Default is 0. Please refer to equation (3.2) of
M. Stephens 2016, Biostatistics for a discussion on alpha.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_df">df</code></td>
<td>
<p>An N by R matrix of corresponding degrees of freedom of
the t-statistic Bhat/Shat. Can be a scalar if all degrees of
freedom are equal. Default is inf (for large samples).</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_pval">pval</code></td>
<td>
<p>An N by R matrix of p-values of t-statistic
Bhat/Shat. Shat and df should not be specified when pval is
provided.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_v">V</code></td>
<td>
<p>an R by R matrix / [R x R x N] array of effect specific
correlation matrix of error correlations; must be positive
definite. [So Bhat_j distributed as N(B_j,diag(Shat_j) V[,,j]
diag(Shat_j)) where _j denotes the jth row of a matrix]. Defaults
to identity.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_zero_check_tol">zero_check_tol</code></td>
<td>
<p>a small positive number as threshold for Shat
to be considered zero if any Shat is smaller or equal to this
number.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_zero_bhat_shat_reset">zero_Bhat_Shat_reset</code></td>
<td>
<p>Replace zeros in Shat matrix to given
value if the corresponding Bhat are also zeros.</p>
</td></tr>
<tr><td><code id="mash_set_data_+3A_zero_shat_reset">zero_Shat_reset</code></td>
<td>
<p>Replace zeros in Shat matrix to given value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data object for passing into mash functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)

</code></pre>

<hr>
<h2 id='mash_set_data_contrast'>Create a data object for mash contrast analysis</h2><span id='topic+mash_set_data_contrast'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_set_data_contrast(mashdata, L)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_set_data_contrast_+3A_mashdata">mashdata</code></td>
<td>
<p>a mash data object containing the Bhat matrix,
standard errors, V; created using <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="mash_set_data_contrast_+3A_l">L</code></td>
<td>
<p>the contrast matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data object after the contrast transfermation
</p>

<hr>
<h2 id='mash_update_data'>Update the data object for mash analysis.</h2><span id='topic+mash_update_data'></span>

<h3>Description</h3>

<p>This function can update two parts of the mash
data. The first one is setting the reference group, so the mash
data can be used for commonbaseline analysis. The other one is
updating the null correlation matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mash_update_data(mashdata, ref = NULL, V = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mash_update_data_+3A_mashdata">mashdata</code></td>
<td>
<p>mash data object ontaining the Bhat matrix,
standard errors, V; created using <code>mash_set_data</code></p>
</td></tr>
<tr><td><code id="mash_update_data_+3A_ref">ref</code></td>
<td>
<p>the reference group. It could be a number between 1,...,
R, R is number of conditions, or the name of reference group. If
there is no reference group, it can be the string 'mean'.</p>
</td></tr>
<tr><td><code id="mash_update_data_+3A_v">V</code></td>
<td>
<p>an R by R matrix / [R x R x N] array of correlation matrix
of error correlations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a updated mash data object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simdata = simple_sims(50,5,1)
data = mash_set_data(simdata$Bhat, simdata$Shat)
mash_update_data(data, 'mean')

</code></pre>

<hr>
<h2 id='optimize_pi'>Estimate mixture weights by maximum (penalized) likelihood</h2><span id='topic+optimize_pi'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimize_pi(
  matrix_lik,
  pi_init = NULL,
  prior = NULL,
  optmethod = c("mixSQP", "mixIP", "mixEM", "cxxMixSquarem"),
  control = list()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimize_pi_+3A_matrix_lik">matrix_lik</code></td>
<td>
<p>a matrix of likelihoods, where the (i,k)th entry
is the probability of observation i given it came from component k
of g</p>
</td></tr>
<tr><td><code id="optimize_pi_+3A_pi_init">pi_init</code></td>
<td>
<p>numeric vector specifying value from which to
initialize optimization</p>
</td></tr>
<tr><td><code id="optimize_pi_+3A_prior">prior</code></td>
<td>
<p>numeric vector specifying prior to use in the
penalized likelihood</p>
</td></tr>
<tr><td><code id="optimize_pi_+3A_optmethod">optmethod</code></td>
<td>
<p>a string, giving name of optimization function to
use</p>
</td></tr>
<tr><td><code id="optimize_pi_+3A_control">control</code></td>
<td>
<p>a list of parameters to be passed to optmethod</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector specifying the optimal mixture weights
</p>

<hr>
<h2 id='posterior_cov'>posterior_cov</h2><span id='topic+posterior_cov'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posterior_cov(Vinv, U)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="posterior_cov_+3A_vinv">Vinv</code></td>
<td>
<p>R x R inverse covariance matrix for the likelihood</p>
</td></tr>
<tr><td><code id="posterior_cov_+3A_u">U</code></td>
<td>
<p>R x R prior covariance matrix</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If bhat is N(b,V) and b is N(0,U) then b|bhat N(mu1,U1). This
function returns U1.
</p>


<h3>Value</h3>

<p>R x R posterior covariance matrix
</p>

<hr>
<h2 id='posterior_mean'>posterior_mean</h2><span id='topic+posterior_mean'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posterior_mean(bhat, Vinv, U1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="posterior_mean_+3A_bhat">bhat</code></td>
<td>
<p>R vector of observation</p>
</td></tr>
<tr><td><code id="posterior_mean_+3A_vinv">Vinv</code></td>
<td>
<p>R x R inverse covariance matrix for the likelihood</p>
</td></tr>
<tr><td><code id="posterior_mean_+3A_u1">U1</code></td>
<td>
<p>R x R posterior covariance matrix, computed using posterior_cov</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If bhat is N(b,V) and b is N(0,U) then b|bhat
N(mu1,U1). This function returns mu1.
</p>


<h3>Value</h3>

<p>R vector of posterior mean
</p>

<hr>
<h2 id='posterior_mean_matrix'>posterior_mean_matrix</h2><span id='topic+posterior_mean_matrix'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>posterior_mean_matrix(Bhat, Vinv, U1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="posterior_mean_matrix_+3A_bhat">Bhat</code></td>
<td>
<p>J by R matrix of observations</p>
</td></tr>
<tr><td><code id="posterior_mean_matrix_+3A_vinv">Vinv</code></td>
<td>
<p>R x R inverse covariance matrix for the likelihood</p>
</td></tr>
<tr><td><code id="posterior_mean_matrix_+3A_u1">U1</code></td>
<td>
<p>R x R posterior covariance matrix, computed using
posterior_cov</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes posterior mean under multivariate normal model
for each row of matrix Bhat. Note that if bhat is N_R(b,V) and b
is N_R(0,U) then b|bhat N_R(mu1,U1). This function returns a
matrix with jth row equal to mu1(bhat) for bhat= Bhat[j,].
</p>


<h3>Value</h3>

<p>R vector of posterior mean
</p>

<hr>
<h2 id='scale_cov'>Scale each covariance matrix in list Ulist by a scalar in
vector grid</h2><span id='topic+scale_cov'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scale_cov(Ulist, grid)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="scale_cov_+3A_ulist">Ulist</code></td>
<td>
<p>a list of matrices</p>
</td></tr>
<tr><td><code id="scale_cov_+3A_grid">grid</code></td>
<td>
<p>a vector of scaling factors (standard deviaions)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with length length(Ulist)*length(grid), with values
grid[i]^2*Ulist[[j]]
</p>

<hr>
<h2 id='sim_contrast1'>Create simplest simulation, cj = mu 1 data used for contrast
analysis</h2><span id='topic+sim_contrast1'></span>

<h3>Description</h3>

<p>Create simplest simulation, cj = mu 1 data used for contrast
analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_contrast1(nsamp = 100, ncond = 5, err_sd = sqrt(0.5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_contrast1_+3A_nsamp">nsamp</code></td>
<td>
<p>number of samples of each type</p>
</td></tr>
<tr><td><code id="sim_contrast1_+3A_ncond">ncond</code></td>
<td>
<p>number of conditions</p>
</td></tr>
<tr><td><code id="sim_contrast1_+3A_err_sd">err_sd</code></td>
<td>
<p>the standard deviation of the errors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There is no true deviation exists in this case
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim_contrast1(100,5)

</code></pre>

<hr>
<h2 id='sim_contrast2'>Create simulation with signal data used for contrast
analysis.</h2><span id='topic+sim_contrast2'></span>

<h3>Description</h3>

<p>Create simulation with signal data used for contrast
analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sim_contrast2(nsamp = 1000, ncond = 5, err_sd = sqrt(0.5))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sim_contrast2_+3A_nsamp">nsamp</code></td>
<td>
<p>Number of samples of each type.</p>
</td></tr>
<tr><td><code id="sim_contrast2_+3A_ncond">ncond</code></td>
<td>
<p>Number of conditions.</p>
</td></tr>
<tr><td><code id="sim_contrast2_+3A_err_sd">err_sd</code></td>
<td>
<p>The standard deviation of the errors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first condition is the reference group. The deviations
are the difference between the subsequent conditions with the
reference group.  The simulation consists of 90
10
different types of deviations: equal among conditions, present only
in the first subsequent condition, independent across conditions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sim_contrast2(100,5)

</code></pre>

<hr>
<h2 id='simple_sims'>Create some simple simulated data for testing purposes</h2><span id='topic+simple_sims'></span>

<h3>Description</h3>

<p>Create some simple simulated data for testing purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple_sims(nsamp = 100, ncond = 5, err_sd = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simple_sims_+3A_nsamp">nsamp</code></td>
<td>
<p>number of samples of each type</p>
</td></tr>
<tr><td><code id="simple_sims_+3A_ncond">ncond</code></td>
<td>
<p>number of conditions</p>
</td></tr>
<tr><td><code id="simple_sims_+3A_err_sd">err_sd</code></td>
<td>
<p>the standard deviation of the errors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation consists of equal numbers of four different
types of effects: null, equal among conditions, present only in
first condition, independent across conditions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simple_sims(100, 5)

</code></pre>

<hr>
<h2 id='simple_sims2'>Create some more simple simulated data for testing purposes</h2><span id='topic+simple_sims2'></span>

<h3>Description</h3>

<p>Create some more simple simulated data for testing purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simple_sims2(nsamp = 100, err_sd = 0.01)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="simple_sims2_+3A_nsamp">nsamp</code></td>
<td>
<p>number of samples of each type</p>
</td></tr>
<tr><td><code id="simple_sims2_+3A_err_sd">err_sd</code></td>
<td>
<p>the standard deviation of the errors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The simulation consists of five conditions with two types
of effecc those present (and identical) in first two conditions and
those present (and identical) in last three conditions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simple_sims2(100, 5)

</code></pre>

<hr>
<h2 id='teem_wrapper'>Fit extreme deconvolution to mash data using TEEM method
developed by Y. Yang and M Stephens</h2><span id='topic+teem_wrapper'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>teem_wrapper(
  data,
  Ulist_init,
  subset = NULL,
  w_init = NULL,
  maxiter = 5000,
  converge_tol = 1e-07,
  eigen_tol = 1e-07,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="teem_wrapper_+3A_data">data</code></td>
<td>
<p>mash data object</p>
</td></tr>
<tr><td><code id="teem_wrapper_+3A_ulist_init">Ulist_init</code></td>
<td>
<p>a list of covariance matrices to initialize to</p>
</td></tr>
<tr><td><code id="teem_wrapper_+3A_subset">subset</code></td>
<td>
<p>the indices of the observations to be used (defaults
to all of them)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the fitted mixture: a list of mixture proportions and
covariance matrices
</p>

<hr>
<h2 id='udi_model_matrix'>Create a matrix whose rows contain all possible
combinations of the U,D,I models that are allowed.</h2><span id='topic+udi_model_matrix'></span>

<h3>Description</h3>

<p>This is an internal (non-exported) function. This help
page provides additional documentation mainly intended for
developers and expert users.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>udi_model_matrix(R)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="udi_model_matrix_+3A_r">R</code></td>
<td>
<p>the number of conditions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix that is Nmodel by R with each row containing a
vector of &quot;U&quot;, &quot;D&quot; and &quot;I&quot; characters corresponding to a valide
model. Constraint is that there is at least one &quot;D&quot; in each row
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
