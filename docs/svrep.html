<!DOCTYPE html><html><head><title>Help for package svrep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {svrep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#svrep-package'><p>svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights</p></a></li>
<li><a href='#add_inactive_replicates'><p>Add inactive replicates to a survey design object</p></a></li>
<li><a href='#as_bootstrap_design'><p>Convert a survey design object to a bootstrap replicate design</p></a></li>
<li><a href='#as_data_frame_with_weights'><p>Convert a survey design object to a data frame with weights stored as columns</p></a></li>
<li><a href='#as_fays_gen_rep_design'><p>Convert a survey design object to a replication design</p>
using Fay's generalized replication method</a></li>
<li><a href='#as_gen_boot_design'><p>Convert a survey design object to a generalized bootstrap replicate design</p></a></li>
<li><a href='#as_random_group_jackknife_design'><p>Convert a survey design object to a random-groups jackknife design</p></a></li>
<li><a href='#calibrate_to_estimate'><p>Calibrate weights from a primary survey to estimated totals from a control survey,</p>
with replicate-weight adjustments that account for variance of the control totals</a></li>
<li><a href='#calibrate_to_sample'><p>Calibrate weights from a primary survey to estimated totals from a control survey,</p>
with replicate-weight adjustments that account for variance of the control totals</a></li>
<li><a href='#compress_design'><p>Produce a compressed representation of a survey design object</p></a></li>
<li><a href='#distribute_matrix_across_clusters'><p>Helper function to turn a cluster-level matrix into an element-level matrix</p>
by duplicating rows or columns of the matrix</a></li>
<li><a href='#estimate_boot_reps_for_target_cv'><p>Estimate the number of bootstrap replicates needed to reduce the bootstrap simulation error to a target level</p></a></li>
<li><a href='#estimate_boot_sim_cv'><p>Estimate the bootstrap simulation error</p></a></li>
<li><a href='#get_design_quad_form'><p>Determine the quadratic form matrix of a variance estimator for a survey design object</p></a></li>
<li><a href='#get_nearest_psd_matrix'><p>Approximates a symmetric, real matrix by the nearest positive</p>
semidefinite matrix.</a></li>
<li><a href='#getvars'><p>Get variables from a database</p></a></li>
<li><a href='#ht_matrix_to_joint_probs'><p>Compute the matrix of joint inclusion probabilities</p>
from the quadratic form of a Horvitz-Thompson variance estimator.</a></li>
<li><a href='#is_psd_matrix'><p>Check whether a matrix is positive semidefinite</p></a></li>
<li><a href='#libraries'><p>Public Libraries Survey (PLS): A Census of U.S. Public Libraries in FY2020</p></a></li>
<li><a href='#lou_pums_microdata'><p>ACS PUMS Data for Louisville</p></a></li>
<li><a href='#lou_vax_survey'><p>Louisville Vaccination Survey</p></a></li>
<li><a href='#lou_vax_survey_control_totals'><p>Control totals for the Louisville Vaccination Survey</p></a></li>
<li><a href='#make_deville_tille_matrix'><p>Create a quadratic form's matrix</p>
for a Deville-Tillé variance estimator for balanced samples</a></li>
<li><a href='#make_fays_gen_rep_factors'><p>Form replication factors using Fay's generalized replication method</p></a></li>
<li><a href='#make_gen_boot_factors'><p>Creates replicate factors for the generalized survey bootstrap</p></a></li>
<li><a href='#make_ppswor_approx_matrix'><p>Create a quadratic form's matrix to represent a variance estimator</p>
for PPSWOR designs, based on commonly-used approximations</a></li>
<li><a href='#make_quad_form_matrix'><p>Represent a variance estimator as a quadratic form</p></a></li>
<li><a href='#make_rwyb_bootstrap_weights'><p>Create bootstrap replicate weights for a general survey design,</p>
using the Rao-Wu-Yue-Beaumont bootstrap method</a></li>
<li><a href='#make_sd_matrix'><p>Create a quadratic form's matrix to represent a successive-difference variance estimator</p></a></li>
<li><a href='#make_srswor_matrix'><p>Create a quadratic form's matrix to represent the basic variance estimator</p>
for a total under simple random sampling without replacement</a></li>
<li><a href='#make_twophase_quad_form'><p>Combine quadratic forms from each phase of a two phase design</p></a></li>
<li><a href='#redistribute_weights'><p>Redistribute weight from one group to another</p></a></li>
<li><a href='#rescale_reps'><p>Rescale replicate factors</p></a></li>
<li><a href='#shift_weight'><p>(Internal function) Shift weight from one set of cases to another</p></a></li>
<li><a href='#shuffle_replicates'><p>Shuffle the order of replicates in a survey design object</p></a></li>
<li><a href='#stack_replicate_designs'><p>Stack replicate designs, combining data and weights into a single object</p></a></li>
<li><a href='#subsample_replicates'><p>Retain only a random subset of the replicates in a design</p></a></li>
<li><a href='#summarize_rep_weights'><p>Summarize the replicate weights</p></a></li>
<li><a href='#svyby_repwts'><p>Compare survey statistics calculated separately from different sets of replicate weights</p></a></li>
<li><a href='#variance-estimators'><p>Variance Estimators</p></a></li>
<li><a href='#wls_hat_matrix'><p>Create the &quot;hat matrix&quot; for weighted least squares regression</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Creating, Updating, and Analyzing Survey Replicate
Weights</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides tools for creating and working with survey replicate weights,
  extending functionality of the 'survey' package from Lumley (2004) &lt;<a href="https://doi.org/10.18637%2Fjss.v009.i08">doi:10.18637/jss.v009.i08</a>&gt;.
  Implements bootstrap methods for complex surveys, including the generalized survey bootstrap
  as described by Beaumont and Patak (2012) &lt;<a href="https://doi.org/10.1111%2Fj.1751-5823.2011.00166.x">doi:10.1111/j.1751-5823.2011.00166.x</a>&gt;.
  Methods are provided for applying nonresponse adjustments to
  both full-sample and replicate weights as described by 
  Rust and Rao (1996) &lt;<a href="https://doi.org/10.1177%2F096228029600500305">doi:10.1177/096228029600500305</a>&gt;.
  Implements methods for sample-based calibration described by Opsomer and Erciulescu (2021) 
  <a href="https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm">https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm</a>.
  Diagnostic functions are included to compare weights and weighted estimates
  from different sets of replicate weights.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bschneidr.github.io/svrep/">https://bschneidr.github.io/svrep/</a>,
<a href="https://github.com/bschneidr/svrep">https://github.com/bschneidr/svrep</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bschneidr/svrep/issues">https://github.com/bschneidr/svrep/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>DBI, Matrix, methods, mvtnorm, stats, survey (&ge; 4.1), utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, covr, testthat (&ge; 3.0.0), rmarkdown, tidycensus,
dplyr, srvyr, withr, sampling, prettydoc, RSQLite</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-26 18:08:58 UTC; benja</td>
</tr>
<tr>
<td>Author:</td>
<td>Ben Schneider <a href="https://orcid.org/0000-0002-0406-8470"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ben Schneider &lt;benjamin.julius.schneider@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-26 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='svrep-package'>svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights</h2><span id='topic+svrep'></span><span id='topic+svrep-package'></span>

<h3>Description</h3>

<p>Provides tools for creating and working with survey replicate weights, extending functionality of the 'survey' package from Lumley (2004) <a href="https://doi.org/10.18637/jss.v009.i08">doi:10.18637/jss.v009.i08</a>. Implements bootstrap methods for complex surveys, including the generalized survey bootstrap as described by Beaumont and Patak (2012) <a href="https://doi.org/10.1111/j.1751-5823.2011.00166.x">doi:10.1111/j.1751-5823.2011.00166.x</a>. Methods are provided for applying nonresponse adjustments to both full-sample and replicate weights as described by Rust and Rao (1996) <a href="https://doi.org/10.1177/096228029600500305">doi:10.1177/096228029600500305</a>. Implements methods for sample-based calibration described by Opsomer and Erciulescu (2021) <a href="https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm">https://www150.statcan.gc.ca/n1/pub/12-001-x/2021002/article/00006-eng.htm</a>. Diagnostic functions are included to compare weights and weighted estimates from different sets of replicate weights.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Ben Schneider <a href="mailto:benjamin.julius.schneider@gmail.com">benjamin.julius.schneider@gmail.com</a> (<a href="https://orcid.org/0000-0002-0406-8470">ORCID</a>)
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://bschneidr.github.io/svrep/">https://bschneidr.github.io/svrep/</a>
</p>
</li>
<li> <p><a href="https://github.com/bschneidr/svrep">https://github.com/bschneidr/svrep</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/bschneidr/svrep/issues">https://github.com/bschneidr/svrep/issues</a>
</p>
</li></ul>


<hr>
<h2 id='add_inactive_replicates'>Add inactive replicates to a survey design object</h2><span id='topic+add_inactive_replicates'></span>

<h3>Description</h3>

<p>Adds inactive replicates to a survey design object. An inactive
replicate is a replicate that does not contribute to variance estimates but
adds to the matrix of replicate weights so that the matrix has the desired
number of columns. The new replicates' values are simply equal to the full-sample weights.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_inactive_replicates(design, n_total, n_to_add, location = "last")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_inactive_replicates_+3A_design">design</code></td>
<td>
<p>A survey design object, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="add_inactive_replicates_+3A_n_total">n_total</code></td>
<td>
<p>The total number of replicates
that the result should contain. If the design already contains <code>n_total</code>
replicates (or more), then no update is made.</p>
</td></tr>
<tr><td><code id="add_inactive_replicates_+3A_n_to_add">n_to_add</code></td>
<td>
<p>The number of additional replicates to add.
Can only use the <code>n_total</code> argument OR the <code>n_to_add</code> argument,
not both.</p>
</td></tr>
<tr><td><code id="add_inactive_replicates_+3A_location">location</code></td>
<td>
<p>Either <code>"first"</code>, <code>"last"</code> (the default), or <code>"random"</code>.
Specifies where the columns of new replicates should be located in the
matrix of replicate weights. Use <code>"first"</code>
to place new replicates first (i.e., in the leftmost part of the matrix),
<code>"last"</code> to place the new replicates last (i.e., in the rightmost part
of the matrix). Use <code>"random"</code> to intersperse the new replicates
in random column locations of the matrix; the original replicates will
still be in their original order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated survey design object, where the number of columns
of replicate weights has potentially increased. The increase only happens
if the user specifies the <code>n_to_add</code> argument instead of <code>n_total</code>,
of if the user specifies <code>n_total</code> and <code>n_total</code> is less than the number
of columns of replicate weights that the design already had.
</p>


<h3>Statistical Details</h3>

<p>Inactive replicates are also sometimes referred to as &quot;dead replicates&quot;,
for example in Ash (2014). The purpose of adding inactive replicates
is to increase the number of columns of replicate weights without impacting
variance estimates. This can be useful, for example, when combining data
from a survey across multiple years, where different years use different number
of replicates, but a consistent number of replicates is desired in the combined
data file.
</p>
<p>Suppose the initial replicate design has <code class="reqn">L</code> replicates, with
respective constants <code class="reqn">c_k</code> for <code class="reqn">k=1,\dots,L</code> used to estimate variance
with the formula
</p>
<p style="text-align: center;"><code class="reqn">v_{R} = \sum_{k=1}^L c_k\left(\hat{T}_y^{(k)}-\hat{T}_y\right)^2</code>
</p>

<p>where <code class="reqn">\hat{T}_y</code> is the estimate produced using the full-sample weights
and <code class="reqn">\hat{T}_y^{(k)}</code> is the estimate from replicate <code class="reqn">k</code>.
</p>
<p>Inactive replicates are simply replicates that are exactly equal to the full sample:
that is, the replicate <code class="reqn">k</code> is called &quot;inactive&quot; if its vector of replicate
weights exactly equals the full-sample weights. In this case, when using the formula
above to estimate variances, these replicates contribute nothing to the variance estimate.
</p>
<p>If the analyst uses the variant of the formula above where the full-sample estimate
<code class="reqn">\hat{T}_y</code> is replaced by the average replicate estimate (i.e., <code class="reqn">L^{-1}\sum_{k=1}^{L}\hat{T}_y^{(k)}</code>),
then variance estimates will differ before vs. after adding the inactive replicates.
For this reason, it is strongly recommend to explicitly specify <code>mse=TRUE</code>
when creating a replicate design object in R with functions such as <code>svrepdesign()</code>,
<code>as_bootstrap_design()</code>, etc. If working with an already existing replicate design,
you can update the <code>mse</code> option to <code>TRUE</code> simply by using code such as
<code>my_design$mse &lt;- TRUE</code>.
</p>


<h3>References</h3>

<p>Ash, S. (2014). &quot;<em>Using successive difference replication for estimating variances</em>.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 40(1), 47–59.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survey)
set.seed(2023)

# Create an example survey design object

  sample_data &lt;- data.frame(
    PSU     = c(1,2,3)
  )

  survey_design &lt;- svydesign(
    data = sample_data,
    ids = ~ PSU,
    weights = ~ 1
  )

  rep_design &lt;- survey_design |&gt;
    as.svrepdesign(type = "JK1", mse = TRUE)

# Inspect replicates before subsampling

  rep_design |&gt; weights(type = "analysis")

# Inspect replicates after adding inactive replicates

  rep_design |&gt;
    add_inactive_replicates(n_total = 5, location = "first") |&gt;
    weights(type = "analysis")

  rep_design |&gt;
    add_inactive_replicates(n_to_add = 2, location = "last") |&gt;
    weights(type = "analysis")

  rep_design |&gt;
    add_inactive_replicates(n_to_add = 5, location = "random") |&gt;
    weights(type = "analysis")

</code></pre>

<hr>
<h2 id='as_bootstrap_design'>Convert a survey design object to a bootstrap replicate design</h2><span id='topic+as_bootstrap_design'></span>

<h3>Description</h3>

<p>Converts a survey design object to a replicate design object
with replicate weights formed using a bootstrap method. Supports stratified,
cluster samples with one or more stages of sampling. At each stage of sampling,
either simple random sampling (with or without replacement)
or unequal probability sampling (with or without replacement) may be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_bootstrap_design(
  design,
  type = "Rao-Wu-Yue-Beaumont",
  replicates = 500,
  compress = TRUE,
  mse = getOption("survey.replicates.mse"),
  samp_method_by_stage = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_bootstrap_design_+3A_design">design</code></td>
<td>
<p>A survey design object created using the 'survey' (or 'srvyr') package,
with class <code>'survey.design'</code> or <code>'svyimputationList'</code>.</p>
</td></tr>
<tr><td><code id="as_bootstrap_design_+3A_type">type</code></td>
<td>
<p>The type of bootstrap to use, which should be chosen based
on its applicability to the sampling method used for the survey.
The available types are the following: <br />
</p>

<ul>
<li> <p><strong>&quot;Rao-Wu-Yue-Beaumont&quot;</strong> (the default): <br />
The bootstrap method of Beaumont and Émond (2022), which is a generalization of the Rao-Wu-Yue bootstrap,
and is applicable to a wide variety of designs, including single-stage and multistage stratified designs.
The design may have different sampling methods used at different stages.
Each stage of sampling may potentially be PPS (i.e., use unequal probabilities), with or without replacement,
and may potentially use Poisson sampling. <br /> <br />
For a stratum with a fixed sample size of <code class="reqn">n</code> sampling units, resampling in each replicate resamples <code class="reqn">(n-1)</code> sampling units with replacement.
</p>
</li>
<li> <p><strong>&quot;Rao-Wu&quot;</strong>: <br />
The basic Rao-Wu <code class="reqn">(n-1)</code> bootstrap method, which is only applicable to single-stage designs or
multistage designs where the first-stage sampling fractions are small (and can thus be ignored).
Accommodates stratified designs. All sampling within a stratum must be simple random sampling with or without replacement,
although the first-stage sampling is effectively treated as sampling without replacement.
</p>
</li>
<li> <p><strong>&quot;Preston&quot;</strong>: <br />
Preston's multistage rescaled bootstrap, which is applicable to single-stage designs or multistage designs
with arbitrary sampling fractions. Accommodates stratified designs. All sampling within a stratum must be
simple random sampling with or without replacement.
</p>
</li>
<li> <p><strong>&quot;Canty-Davison&quot;</strong>: <br />
The Canty-Davison bootstrap, which is only applicable to single-stage designs, with arbitrary sampling fractions.
Accommodates stratified designs. All sampling with a stratum must be simple random sampling with or without replacement.
</p>
</li></ul>
</td></tr>
<tr><td><code id="as_bootstrap_design_+3A_replicates">replicates</code></td>
<td>
<p>Number of bootstrap replicates (should be as large as possible, given computer memory/storage limitations).
A commonly-recommended default is 500.</p>
</td></tr>
<tr><td><code id="as_bootstrap_design_+3A_compress">compress</code></td>
<td>
<p>Use a compressed representation of the replicate weights matrix.
This reduces the computer memory required to represent the replicate weights and has no
impact on estimates.</p>
</td></tr>
<tr><td><code id="as_bootstrap_design_+3A_mse">mse</code></td>
<td>
<p>If <code>TRUE</code>, compute variances from sums of squares around the point estimate from the full-sample weights,
If <code>FALSE</code>, compute variances from sums of squares around the mean estimate from the replicate weights.</p>
</td></tr>
<tr><td><code id="as_bootstrap_design_+3A_samp_method_by_stage">samp_method_by_stage</code></td>
<td>
<p>(Optional). By default, this function will automatically determine the sampling method used at each stage.
However, this argument can be used to ensure the correct sampling method is identified for each stage. <br />
Accepts a vector with length equal to the number of stages of sampling.
Each element should be one of the following: <br />
</p>

<ul>
<li> <p><code>"SRSWOR"</code> - Simple random sampling, without replacement
</p>
</li>
<li> <p><code>"SRSWR"</code> - Simple random sampling, with replacement
</p>
</li>
<li> <p><code>"PPSWOR"</code> - Unequal probabilities of selection, without replacement
</p>
</li>
<li> <p><code>"PPSWR"</code> - Unequal probabilities of selection, with replacement
</p>
</li>
<li> <p><code>"Poisson"</code> -  Poisson sampling: each sampling unit is selected into the sample at most once, with potentially different probabilities of inclusion for each sampling unit.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>A replicate design object, with class <code>svyrep.design</code>, which can be used with the usual functions,
such as <code>svymean()</code> or <code>svyglm()</code>.
</p>
<p>Use <code>weights(..., type = 'analysis')</code> to extract the matrix of replicate weights. <br />
Use <code>as_data_frame_with_weights()</code> to convert the design object to a data frame with columns
for the full-sample and replicate weights.
</p>


<h3>References</h3>

<p>Beaumont, J.-F.; Émond, N. (2022).
&quot;A Bootstrap Variance Estimation Method for Multistage Sampling and Two-Phase Sampling When Poisson Sampling Is Used at the Second Phase.&quot;
<strong>Stats</strong>, <em>5</em>: 339–357.
https://doi.org/10.3390/stats5020019
</p>
<p>Canty, A.J.; Davison, A.C. (1999).
&quot;Resampling-based variance estimation for labour force surveys.&quot;
<strong>The Statistician</strong>, <em>48</em>: 379-391.
</p>
<p>Preston, J. (2009).
&quot;Rescaled bootstrap for stratified multistage sampling.&quot;
<strong>Survey Methodology</strong>, <em>35</em>(2): 227-234.
</p>
<p>Rao, J.N.K.; Wu, C.F.J.; Yue, K. (1992).
&quot;Some recent work on resampling methods for complex surveys.&quot;
<strong>Survey Methodology</strong>, <em>18</em>: 209–217.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+estimate_boot_reps_for_target_cv">estimate_boot_reps_for_target_cv</a></code> to help choose the number of bootstrap replicates.
</p>
<p>The underlying function for the Rao-Wu-Yue-Beaumont bootstrap
is <code><a href="#topic+make_rwyb_bootstrap_weights">make_rwyb_bootstrap_weights</a></code>.
Other bootstrap methods are implemented using functions from the 'survey' package,
including: <code><a href="survey.html#topic+bootweights">bootweights</a></code> (Canty-Davison),
<code><a href="survey.html#topic+subbootweights">subbootweights</a></code> (Rao-Wu),
and <code><a href="survey.html#topic+mrbweights">mrbweights</a></code> (Preston).
</p>
<p>For systematic samples, one-PSU-per-stratum designs, or other especially complex sample designs,
one can use the generalized survey bootstrap method. See <code><a href="#topic+as_gen_boot_design">as_gen_boot_design</a></code> or <code><a href="#topic+make_gen_boot_factors">make_gen_boot_factors</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survey)
# Example 1: A multistage sample with two stages of SRSWOR

  ## Load an example dataset from a multistage sample, with two stages of SRSWOR
  data("mu284", package = 'survey')
  multistage_srswor_design &lt;- svydesign(data = mu284,
                                        ids = ~ id1 + id2,
                                        fpc = ~ n1 + n2)

  ## Convert the survey design object to a bootstrap design
  set.seed(2022)
  bootstrap_rep_design &lt;- as_bootstrap_design(multistage_srswor_design,
                                              replicates = 500)

  ## Compare std. error estimates from bootstrap versus linearization
  data.frame(
    'Statistic' = c('total', 'mean', 'median'),
    'SE (bootstrap)' = c(SE(svytotal(x = ~ y1, design = bootstrap_rep_design)),
                         SE(svymean(x = ~ y1, design = bootstrap_rep_design)),
                         SE(svyquantile(x = ~ y1, quantile = 0.5,
                                        design = bootstrap_rep_design))),
    'SE (linearization)' = c(SE(svytotal(x = ~ y1, design = multistage_srswor_design)),
                             SE(svymean(x = ~ y1, design = multistage_srswor_design)),
                             SE(svyquantile(x = ~ y1, quantile = 0.5,
                                            design = multistage_srswor_design))),
    check.names = FALSE
  )

# Example 2: A multistage-sample,
# first stage selected with unequal probabilities without replacement
# second stage selected with simple random sampling without replacement

  data("library_multistage_sample", package = "svrep")

  multistage_pps &lt;- svydesign(data = library_multistage_sample,
                              ids = ~ PSU_ID + SSU_ID,
                              fpc = ~ PSU_SAMPLING_PROB + SSU_SAMPLING_PROB,
                              pps = "brewer")

  bootstrap_rep_design &lt;- as_bootstrap_design(
    multistage_pps, replicates = 500,
    samp_method_by_stage = c("PPSWOR", "SRSWOR")
  )

  ## Compare std. error estimates from bootstrap versus linearization
  data.frame(
      'Statistic' = c('total', 'mean'),
      'SE (bootstrap)' = c(
          SE(svytotal(x = ~ TOTCIR, na.rm = TRUE,
                      design = bootstrap_rep_design)),
          SE(svymean(x = ~ TOTCIR, na.rm = TRUE,
                     design = bootstrap_rep_design))),
      'SE (linearization)' = c(
          SE(svytotal(x = ~ TOTCIR, na.rm = TRUE,
                      design = multistage_pps)),
          SE(svymean(x = ~ TOTCIR, na.rm = TRUE,
                     design = multistage_pps))),
      check.names = FALSE
  )
</code></pre>

<hr>
<h2 id='as_data_frame_with_weights'>Convert a survey design object to a data frame with weights stored as columns</h2><span id='topic+as_data_frame_with_weights'></span>

<h3>Description</h3>

<p>Convert a survey design object to a data frame with weights stored as columns
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_data_frame_with_weights(
  design,
  full_wgt_name = "FULL_SAMPLE_WGT",
  rep_wgt_prefix = "REP_WGT_",
  vars_to_keep = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_data_frame_with_weights_+3A_design">design</code></td>
<td>
<p>A survey design object, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="as_data_frame_with_weights_+3A_full_wgt_name">full_wgt_name</code></td>
<td>
<p>The column name to use for the full-sample weights</p>
</td></tr>
<tr><td><code id="as_data_frame_with_weights_+3A_rep_wgt_prefix">rep_wgt_prefix</code></td>
<td>
<p>For replicate design objects, a prefix to use for the column names
of the replicate weights. The column names will be created by appending
the replicate number after the prefix.</p>
</td></tr>
<tr><td><code id="as_data_frame_with_weights_+3A_vars_to_keep">vars_to_keep</code></td>
<td>
<p>By default, all variables in the data will be kept.
To select only a subset of the non-weight variables,
you can supply a character vector of variable names to keep.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame, with new columns containing the weights from the survey design object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("lou_vax_survey", package = 'svrep')

library(survey)
# Create a survey design object
survey_design &lt;- svydesign(data = lou_vax_survey,
                           weights = ~ SAMPLING_WEIGHT,
                           ids = ~ 1)

rep_survey_design &lt;- as.svrepdesign(survey_design,
                                    type = "boot",
                                    replicates = 10)

# Adjust the weights for nonresponse
nr_adjusted_design &lt;- redistribute_weights(
  design = rep_survey_design,
  reduce_if = RESPONSE_STATUS == "Nonrespondent",
  increase_if = RESPONSE_STATUS == "Respondent",
  by = c("RACE_ETHNICITY", "EDUC_ATTAINMENT")
)

# Save the survey design object as a data frame
nr_adjusted_data &lt;- as_data_frame_with_weights(
  nr_adjusted_design,
  full_wgt_name = "NR_ADJUSTED_WGT",
  rep_wgt_prefix = "NR_ADJUSTED_REP_WGT_"
)
head(nr_adjusted_data)

# Check the column names of the result
colnames(nr_adjusted_data)

</code></pre>

<hr>
<h2 id='as_fays_gen_rep_design'>Convert a survey design object to a replication design
using Fay's generalized replication method</h2><span id='topic+as_fays_gen_rep_design'></span>

<h3>Description</h3>

<p>Converts a survey design object to a replicate design object
with replicate weights formed using the generalized replication method of Fay (1989).
The generalized replication method forms replicate weights
from a textbook variance estimator, provided that the variance estimator
can be represented as a quadratic form whose matrix is positive semidefinite
(this covers a large class of variance estimators).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_fays_gen_rep_design(
  design,
  variance_estimator = NULL,
  aux_var_names = NULL,
  max_replicates = 500,
  balanced = TRUE,
  psd_option = "warn",
  mse = TRUE,
  compress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_fays_gen_rep_design_+3A_design">design</code></td>
<td>
<p>A survey design object created using the 'survey' (or 'srvyr') package,
with class <code>'survey.design'</code> or <code>'svyimputationList'</code>.</p>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_variance_estimator">variance_estimator</code></td>
<td>
<p>The name of the variance estimator
whose quadratic form matrix should be created.
See <a href="#topic+variance-estimators">variance-estimators</a> for a
detailed description of each variance estimator.
Options include:
</p>

<ul>
<li> <p><strong>&quot;Yates-Grundy&quot;</strong>: <br /> The Yates-Grundy variance estimator based on
first-order and second-order inclusion probabilities.
</p>
</li>
<li> <p><strong>&quot;Horvitz-Thompson&quot;</strong>: <br /> The Horvitz-Thompson variance estimator based on
first-order and second-order inclusion probabilities.
</p>
</li>
<li> <p><strong>&quot;Poisson Horvitz-Thompson&quot;</strong>: <br /> The Horvitz-Thompson variance estimator
based on assuming Poisson sampling, with first-order inclusion probabilities
inferred from the sampling probabilities of the survey design object.
</p>
</li>
<li> <p><strong>&quot;Stratified Multistage SRS&quot;</strong>: <br /> The usual stratified multistage variance estimator
based on estimating the variance of cluster totals within strata at each stage.
</p>
</li>
<li> <p><strong>&quot;Ultimate Cluster&quot;</strong>: <br /> The usual variance estimator based on estimating
the variance of first-stage cluster totals within first-stage strata.
</p>
</li>
<li> <p><strong>&quot;Deville-1&quot;</strong>: <br /> A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005)
as &quot;Deville 1&quot;.
</p>
</li>
<li> <p><strong>&quot;Deville-2&quot;</strong>: <br /> A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005) as &quot;Deville 2&quot;.
</p>
</li>
<li> <p><strong>&quot;Deville-Tille&quot;: </strong> <br /> A variance estimator useful
for balanced sampling designs, proposed by Deville and Tillé (2005).
</p>
</li>
<li> <p><strong>&quot;SD1&quot;</strong>: <br /> The non-circular successive-differences variance estimator described by Ash (2014),
sometimes used for variance estimation for systematic sampling.
</p>
</li>
<li><p><strong>&quot;SD2&quot;</strong>:  <br /> The circular successive-differences variance estimator described by Ash (2014).
This estimator is the basis of the &quot;successive-differences replication&quot; estimator commonly used
for variance estimation for systematic sampling.
</p>
</li></ul>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_aux_var_names">aux_var_names</code></td>
<td>
<p>(Only used if <code>variance_estimator = "Deville-Tille")</code>.
A vector of the names of auxiliary variables used in sampling.</p>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_max_replicates">max_replicates</code></td>
<td>
<p>The maximum number of replicates to allow (should be as large as possible, given computer memory/storage limitations).
A commonly-recommended default is 500. If the number of replicates needed
for a balanced, fully-efficient estimator is less than <code>max_replicates</code>,
then only the number of replicates needed will be created.
If more replicates are needed than <code>max_replicates</code>, then the full number of replicates
needed will be created, but only a random subsample will be retained.</p>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_balanced">balanced</code></td>
<td>
<p>If <code>balanced=TRUE</code>, the replicates
will all contribute equally to variance estimates, but
the number of replicates needed may slightly increase.</p>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_psd_option">psd_option</code></td>
<td>
<p>Either <code>"warn"</code> (the default) or <code>"error"</code>.
This option specifies what will happen if the target variance estimator
has a quadratic form matrix which is not positive semidefinite. This
can occasionally happen, particularly for two-phase designs. <br />
If <code>psd_option="error"</code>, then an error message will be displayed. <br />
If <code>psd_option="warn"</code>, then a warning message will be displayed,
and the quadratic form matrix will be approximated by the most similar
positive semidefinite matrix.
This approximation was suggested by Beaumont and Patak (2012),
who note that this is conservative in the sense of producing
overestimates of variance.
Beaumont and Patak (2012) argue that this overestimation is expected to be
small in magnitude. See <code><a href="#topic+get_nearest_psd_matrix">get_nearest_psd_matrix</a></code>
for details of the approximation.</p>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_mse">mse</code></td>
<td>
<p>If <code>TRUE</code> (the default), compute variances from sums of squares around the point estimate from the full-sample weights,
If <code>FALSE</code>, compute variances from sums of squares around the mean estimate from the replicate weights.
For Fay's generalized replication method, setting <code>mse = FALSE</code> can potentially
lead to large underestimates of variance.</p>
</td></tr>
<tr><td><code id="as_fays_gen_rep_design_+3A_compress">compress</code></td>
<td>
<p>This reduces the computer memory required to represent the replicate weights and has no
impact on estimates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A replicate design object, with class <code>svyrep.design</code>, which can be used with the usual functions,
such as <code>svymean()</code> or <code>svyglm()</code>.
</p>
<p>Use <code>weights(..., type = 'analysis')</code> to extract the matrix of replicate weights.
</p>
<p>Use <code>as_data_frame_with_weights()</code> to convert the design object to a data frame with columns
for the full-sample and replicate weights.
</p>


<h3>Statistical Details</h3>

<p>See Fay (1989) for a full description of this replication method,
or see the documentation in <a href="#topic+make_fays_gen_rep_factors">make_fays_gen_rep_factors</a> for implementation details.
</p>
<p>See <a href="#topic+variance-estimators">variance-estimators</a> for a
description of each variance estimator available for use with
this function.
</p>
<p>Use <code><a href="#topic+rescale_reps">rescale_reps</a></code> to eliminate negative adjustment factors.
</p>


<h3>Two-Phase Designs</h3>

<p>For a two-phase design, <code>variance_estimator</code> should be a list of variance estimators' names,
with two elements, such as <code>list('Ultimate Cluster', 'Poisson Horvitz-Thompson')</code>.
In two-phase designs, only the following estimators may be used for the second phase:
</p>

<ul>
<li><p> &quot;Ultimate Cluster&quot;
</p>
</li>
<li><p> &quot;Stratified Multistage SRS&quot;
</p>
</li>
<li><p> &quot;Poisson Horvitz-Thompson&quot;
</p>
</li></ul>

<p>For statistical details on the handling of two-phase designs,
see the documentation for <a href="#topic+make_twophase_quad_form">make_twophase_quad_form</a>.
</p>


<h3>References</h3>

<p>The generalized replication method was first proposed in
Fay (1984). Fay (1989) refined the generalized replication method
to produce &quot;balanced&quot; replicates, in the sense that
each replicate contributes equally to variance estimates.
The advantage of balanced replicates is that one can
still obtain a reasonable variance estimate
by using only a random subset of the replicates.
</p>
<p>- Ash, S. (2014). &quot;<em>Using successive difference replication for estimating variances</em>.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 40(1), 47–59.
<br /> <br />
- Deville, J.‐C., and Tillé, Y. (2005). &quot;<em>Variance approximation under balanced sampling.</em>&quot;
<strong>Journal of Statistical Planning and Inference</strong>, 128, 569–591.
<br /> <br />
- Dippo, Cathryn, Robert Fay, and David Morganstein. 1984. “Computing Variances from Complex Samples with Replicate Weights.” In, 489–94. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1984_094.pdf.
<br /> <br />
- Fay, Robert. 1984. “Some Properties of Estimates of Variance Based on Replication Methods.” In, 495–500. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1984_095.pdf.
<br /> <br />
- Fay, Robert. 1989. “Theory And Application Of Replicate Weighting For Variance Calculations.” In, 495–500. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1989_033.pdf
<br /> <br />
- Matei, Alina, and Yves Tillé. (2005).
“<em>Evaluation of Variance Approximations and Estimators
in Maximum Entropy Sampling with Unequal Probability and Fixed Sample Size.</em>”
<strong>Journal of Official Statistics</strong>, 21(4):543–70.
</p>


<h3>See Also</h3>

<p>For greater customization of the method, <code><a href="#topic+make_quad_form_matrix">make_quad_form_matrix</a></code> can be used to
represent several common variance estimators as a quadratic form's matrix,
which can then be used as an input to <code><a href="#topic+make_fays_gen_rep_factors">make_fays_gen_rep_factors</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (FALSE) {

  library(survey)

  ## Load an example systematic sample ----
  data('library_stsys_sample', package = 'svrep')

  ## First, ensure data are sorted in same order as was used in sampling
  library_stsys_sample &lt;- library_stsys_sample[
    order(library_stsys_sample$SAMPLING_SORT_ORDER),
  ]

  ## Create a survey design object
  design_obj &lt;- svydesign(
    data = library_stsys_sample,
    strata = ~ SAMPLING_STRATUM,
    ids = ~ 1,
    fpc = ~ STRATUM_POP_SIZE
  )

  ## Convert to generalized replicate design

  gen_rep_design_sd2 &lt;- as_fays_gen_rep_design(
    design = design_obj,
    variance_estimator = "SD2",
    max_replicates = 250,
    mse = TRUE
  )

  svytotal(x = ~ TOTSTAFF, na.rm = TRUE, design = gen_rep_design_sd2)
}
</code></pre>

<hr>
<h2 id='as_gen_boot_design'>Convert a survey design object to a generalized bootstrap replicate design</h2><span id='topic+as_gen_boot_design'></span>

<h3>Description</h3>

<p>Converts a survey design object to a replicate design object
with replicate weights formed using the generalized bootstrap method.
The generalized survey bootstrap is a method for forming bootstrap replicate weights
from a textbook variance estimator, provided that the variance estimator
can be represented as a quadratic form whose matrix is positive semidefinite
(this covers a large class of variance estimators).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_gen_boot_design(
  design,
  variance_estimator = NULL,
  aux_var_names = NULL,
  replicates = 500,
  tau = "auto",
  exact_vcov = FALSE,
  psd_option = "warn",
  mse = getOption("survey.replicates.mse"),
  compress = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_gen_boot_design_+3A_design">design</code></td>
<td>
<p>A survey design object created using the 'survey' (or 'srvyr') package,
with class <code>'survey.design'</code> or <code>'svyimputationList'</code>.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_variance_estimator">variance_estimator</code></td>
<td>
<p>The name of the variance estimator
whose quadratic form matrix should be created.
See <a href="#topic+variance-estimators">variance-estimators</a> for a
detailed description of each variance estimator.
Options include:
</p>

<ul>
<li> <p><strong>&quot;Yates-Grundy&quot;</strong>: <br /> The Yates-Grundy variance estimator based on
first-order and second-order inclusion probabilities.
</p>
</li>
<li> <p><strong>&quot;Horvitz-Thompson&quot;</strong>: <br /> The Horvitz-Thompson variance estimator based on
first-order and second-order inclusion probabilities.
</p>
</li>
<li> <p><strong>&quot;Poisson Horvitz-Thompson&quot;</strong>: <br /> The Horvitz-Thompson variance estimator
based on assuming Poisson sampling, with first-order inclusion probabilities
inferred from the sampling probabilities of the survey design object.
</p>
</li>
<li> <p><strong>&quot;Stratified Multistage SRS&quot;</strong>: <br /> The usual stratified multistage variance estimator
based on estimating the variance of cluster totals within strata at each stage.
</p>
</li>
<li> <p><strong>&quot;Ultimate Cluster&quot;</strong>: <br /> The usual variance estimator based on estimating
the variance of first-stage cluster totals within first-stage strata.
</p>
</li>
<li> <p><strong>&quot;Deville-1&quot;</strong>: <br /> A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005)
as &quot;Deville 1&quot;.
</p>
</li>
<li> <p><strong>&quot;Deville-2&quot;</strong>: <br /> A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005) as &quot;Deville 2&quot;.
</p>
</li>
<li> <p><strong>&quot;Deville-Tille&quot;: </strong> <br /> A variance estimator useful
for balanced sampling designs, proposed by Deville and Tillé (2005).
</p>
</li>
<li> <p><strong>&quot;SD1&quot;</strong>: <br /> The non-circular successive-differences variance estimator described by Ash (2014),
sometimes used for variance estimation for systematic sampling.
</p>
</li>
<li><p><strong>&quot;SD2&quot;</strong>:  <br /> The circular successive-differences variance estimator described by Ash (2014).
This estimator is the basis of the &quot;successive-differences replication&quot; estimator commonly used
for variance estimation for systematic sampling.
</p>
</li></ul>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_aux_var_names">aux_var_names</code></td>
<td>
<p>(Only used if <code>variance_estimator = "Deville-Tille")</code>.
A vector of the names of auxiliary variables used in sampling.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_replicates">replicates</code></td>
<td>
<p>Number of bootstrap replicates (should be as large as possible, given computer memory/storage limitations).
A commonly-recommended default is 500.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_tau">tau</code></td>
<td>
<p>Either <code>"auto"</code>, or a single number. This is the rescaling constant
used to avoid negative weights through the transformation <code class="reqn">\frac{w + \tau - 1}{\tau}</code>,
where <code class="reqn">w</code> is the original weight and <code class="reqn">\tau</code> is the rescaling constant <code>tau</code>. <br />
If <code>tau="auto"</code>, the rescaling factor is determined automatically as follows:
if all of the adjustment factors are nonnegative, then <code>tau</code> is set equal to 1;
otherwise, <code>tau</code> is set to the smallest value needed to rescale
the adjustment factors such that they are all at least <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_exact_vcov">exact_vcov</code></td>
<td>
<p>If <code>exact_vcov=TRUE</code>, the replicate factors will be generated
such that variance estimates for totals exactly match the results from the target variance estimator.
This requires that <code>num_replicates</code> exceeds the rank of <code>Sigma</code>.
The replicate factors are generated by applying PCA-whitening to a collection of draws
from a multivariate Normal distribution, then applying a coloring transformation
to the whitened collection of draws.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_psd_option">psd_option</code></td>
<td>
<p>Either <code>"warn"</code> (the default) or <code>"error"</code>.
This option specifies what will happen if the target variance estimator
has a quadratic form matrix which is not positive semidefinite. This
can occasionally happen, particularly for two-phase designs. <br />
If <code>psd_option="error"</code>, then an error message will be displayed. <br />
If <code>psd_option="warn"</code>, then a warning message will be displayed,
and the quadratic form matrix will be approximated by the most similar
positive semidefinite matrix.
This approximation was suggested by Beaumont and Patak (2012),
who note that this is conservative in the sense of producing
overestimates of variance.
Beaumont and Patak (2012) argue that this overestimation is expected to be
small in magnitude. See <code><a href="#topic+get_nearest_psd_matrix">get_nearest_psd_matrix</a></code>
for details of the approximation.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_mse">mse</code></td>
<td>
<p>If <code>TRUE</code>, compute variances from sums of squares around the point estimate from the full-sample weights,
If <code>FALSE</code>, compute variances from sums of squares around the mean estimate from the replicate weights.</p>
</td></tr>
<tr><td><code id="as_gen_boot_design_+3A_compress">compress</code></td>
<td>
<p>This reduces the computer memory required to represent the replicate weights and has no
impact on estimates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A replicate design object, with class <code>svyrep.design</code>, which can be used with the usual functions,
such as <code>svymean()</code> or <code>svyglm()</code>.
</p>
<p>Use <code>weights(..., type = 'analysis')</code> to extract the matrix of replicate weights.
</p>
<p>Use <code>as_data_frame_with_weights()</code> to convert the design object to a data frame with columns
for the full-sample and replicate weights.
</p>


<h3>Statistical Details</h3>

<p>Let <code class="reqn">v( \hat{T_y})</code> be the textbook variance estimator for an estimated population total <code class="reqn">\hat{T}_y</code> of some variable <code class="reqn">y</code>.
The base weight for case <code class="reqn">i</code> in our sample is <code class="reqn">w_i</code>, and we let <code class="reqn">\breve{y}_i</code> denote the weighted value <code class="reqn">w_iy_i</code>.
Suppose we can represent our textbook variance estimator as a quadratic form: <code class="reqn">v(\hat{T}_y) = \breve{y}\Sigma\breve{y}^T</code>,
for some <code class="reqn">n \times n</code> matrix <code class="reqn">\Sigma</code>.
The only constraint on <code class="reqn">\Sigma</code> is that, for our sample, it must be symmetric and positive semidefinite.
</p>
<p>The bootstrapping process creates <code class="reqn">B</code> sets of replicate weights, where the <code class="reqn">b</code>-th set of replicate weights is a vector of length <code class="reqn">n</code> denoted <code class="reqn">\mathbf{a}^{(b)}</code>, whose <code class="reqn">k</code>-th value is denoted <code class="reqn">a_k^{(b)}</code>.
This yields <code class="reqn">B</code> replicate estimates of the population total, <code class="reqn">\hat{T}_y^{*(b)}=\sum_{k \in s} a_k^{(b)} \breve{y}_k</code>, for <code class="reqn">b=1, \ldots B</code>, which can be used to estimate sampling variance.
</p>
<p style="text-align: center;"><code class="reqn">
  v_B\left(\hat{T}_y\right)=\frac{\sum_{b=1}^B\left(\hat{T}_y^{*(b)}-\hat{T}_y\right)^2}{B}
</code>
</p>

<p>This bootstrap variance estimator can be written as a quadratic form:
</p>
<p style="text-align: center;"><code class="reqn">
    v_B\left(\hat{T}_y\right) =\mathbf{\breve{y}}^{\prime}\Sigma_B \mathbf{\breve{y}}
  </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
    \boldsymbol{\Sigma}_B = \frac{\sum_{b=1}^B\left(\mathbf{a}^{(b)}-\mathbf{1}_n\right)\left(\mathbf{a}^{(b)}-\mathbf{1}_n\right)^{\prime}}{B}
  </code>
</p>

<p>Note that if the vector of adjustment factors <code class="reqn">\mathbf{a}^{(b)}</code> has expectation <code class="reqn">\mathbf{1}_n</code> and variance-covariance matrix <code class="reqn">\boldsymbol{\Sigma}</code>,
then we have the bootstrap expectation <code class="reqn">E_{*}\left( \boldsymbol{\Sigma}_B \right) = \boldsymbol{\Sigma}</code>. Since the bootstrap process takes the sample values <code class="reqn">\breve{y}</code> as fixed, the bootstrap expectation of the variance estimator is <code class="reqn">E_{*} \left( \mathbf{\breve{y}}^{\prime}\Sigma_B \mathbf{\breve{y}}\right)= \mathbf{\breve{y}}^{\prime}\Sigma \mathbf{\breve{y}}</code>.
Thus, we can produce a bootstrap variance estimator with the same expectation as the textbook variance estimator simply by randomly generating <code class="reqn">\mathbf{a}^{(b)}</code> from a distribution with the following two conditions:
<br />
<strong>Condition 1</strong>: <code class="reqn">\quad \mathbf{E}_*(\mathbf{a})=\mathbf{1}_n</code>
<br />
<strong>Condition 2</strong>: <code class="reqn">\quad \mathbf{E}_*\left(\mathbf{a}-\mathbf{1}_n\right)\left(\mathbf{a}-\mathbf{1}_n\right)^{\prime}=\mathbf{\Sigma}</code>
<br /> <br />
While there are multiple ways to generate adjustment factors satisfying these conditions,
the simplest general method is to simulate from a multivariate normal distribution: <code class="reqn">\mathbf{a} \sim MVN(\mathbf{1}_n, \boldsymbol{\Sigma})</code>.
This is the method used by this function.
</p>


<h3>Details on Rescaling to Avoid Negative Adjustment Factors</h3>

<p>Let <code class="reqn">\mathbf{A} = \left[ \mathbf{a}^{(1)} \cdots \mathbf{a}^{(b)} \cdots \mathbf{a}^{(B)} \right]</code> denote the <code class="reqn">(n \times B)</code> matrix of bootstrap adjustment factors.
To eliminate negative adjustment factors, Beaumont and Patak (2012) propose forming a rescaled matrix of nonnegative replicate factors <code class="reqn">\mathbf{A}^S</code> by rescaling each adjustment factor <code class="reqn">a_k^{(b)}</code> as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   a_k^{S,(b)} = \frac{a_k^{(b)} + \tau - 1}{\tau}
 </code>
</p>

<p>where <code class="reqn">\tau \geq 1 - a_k^{(b)} \geq 1</code> for all <code class="reqn">k</code> in <code class="reqn">\left\{ 1,\ldots,n \right\}</code> and all <code class="reqn">b</code> in <code class="reqn">\left\{1, \ldots, B\right\}</code>.
</p>
<p>The value of <code class="reqn">\tau</code> can be set based on the realized adjustment factor matrix <code class="reqn">\mathbf{A}</code> or by choosing <code class="reqn">\tau</code> prior to generating the adjustment factor matrix <code class="reqn">\mathbf{A}</code> so that <code class="reqn">\tau</code> is likely to be large enough to prevent negative bootstrap weights.
</p>
<p>If the adjustment factors are rescaled in this manner, it is important to adjust the scale factor used in estimating the variance with the bootstrap replicates, which becomes <code class="reqn">\frac{\tau^2}{B}</code> instead of <code class="reqn">\frac{1}{B}</code>.
</p>
<p style="text-align: center;"><code class="reqn">
 \textbf{Prior to rescaling: } v_B\left(\hat{T}_y\right) = \frac{1}{B}\sum_{b=1}^B\left(\hat{T}_y^{*(b)}-\hat{T}_y\right)^2
 </code>
</p>

<p style="text-align: center;"><code class="reqn">
 \textbf{After rescaling: } v_B\left(\hat{T}_y\right) = \frac{\tau^2}{B}\sum_{b=1}^B\left(\hat{T}_y^{S*(b)}-\hat{T}_y\right)^2
</code>
</p>

<p>When sharing a dataset that uses rescaled weights from a generalized survey bootstrap, the documentation for the dataset should instruct the user to use replication scale factor <code class="reqn">\frac{\tau^2}{B}</code> rather than <code class="reqn">\frac{1}{B}</code> when estimating sampling variances.
</p>


<h3>Two-Phase Designs</h3>

<p>For a two-phase design, <code>variance_estimator</code> should be a list of variance estimators' names,
with two elements, such as <code>list('Ultimate Cluster', 'Poisson Horvitz-Thompson')</code>.
In two-phase designs, only the following estimators may be used for the second phase:
</p>

<ul>
<li><p> &quot;Ultimate Cluster&quot;
</p>
</li>
<li><p> &quot;Stratified Multistage SRS&quot;
</p>
</li>
<li><p> &quot;Poisson Horvitz-Thompson&quot;
</p>
</li></ul>

<p>For statistical details on the handling of two-phase designs,
see the documentation for <a href="#topic+make_twophase_quad_form">make_twophase_quad_form</a>.
</p>


<h3>References</h3>

<p>The generalized survey bootstrap was first proposed by Bertail and Combris (1997).
See Beaumont and Patak (2012) for a clear overview of the generalized survey bootstrap.
The generalized survey bootstrap represents one strategy for forming replication variance estimators
in the general framework proposed by Fay (1984) and Dippo, Fay, and Morganstein (1984).
<br /> <br />
- Ash, S. (2014). &quot;<em>Using successive difference replication for estimating variances</em>.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 40(1), 47–59.
<br /> <br />
- Bellhouse, D.R. (1985). &quot;<em>Computing Methods for Variance Estimation in Complex Surveys</em>.&quot;
<strong>Journal of Official Statistics</strong>, Vol.1, No.3.
<br /> <br />
- Beaumont, Jean-François, and Zdenek Patak. 2012. “On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling: Generalized Bootstrap for Sample Surveys.” International Statistical Review 80 (1): 127–48. https://doi.org/10.1111/j.1751-5823.2011.00166.x.
<br /> <br />
- Bertail, and Combris. 1997. “Bootstrap Généralisé d’un Sondage.” Annales d’Économie Et de Statistique, no. 46: 49. https://doi.org/10.2307/20076068.
<br /> <br />
- Deville, J.‐C., and Tillé, Y. (2005). &quot;<em>Variance approximation under balanced sampling.</em>&quot;
<strong>Journal of Statistical Planning and Inference</strong>, 128, 569–591.
<br /> <br />
- Dippo, Cathryn, Robert Fay, and David Morganstein. 1984. “Computing Variances from Complex Samples with Replicate Weights.” In, 489–94. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1984_094.pdf.
<br /> <br />
- Fay, Robert. 1984. “Some Properties of Estimates of Variance Based on Replication Methods.” In, 495–500. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1984_095.pdf.
<br /> <br />
- Matei, Alina, and Yves Tillé. (2005).
“<em>Evaluation of Variance Approximations and Estimators
in Maximum Entropy Sampling with Unequal Probability and Fixed Sample Size.</em>”
<strong>Journal of Official Statistics</strong>, 21(4):543–70.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+estimate_boot_reps_for_target_cv">estimate_boot_reps_for_target_cv</a></code> to help choose the number of bootstrap replicates. <br />
</p>
<p>For greater customization of the method, <code><a href="#topic+make_quad_form_matrix">make_quad_form_matrix</a></code> can be used to
represent several common variance estimators as a quadratic form's matrix,
which can then be used as an input to <code><a href="#topic+make_gen_boot_factors">make_gen_boot_factors</a></code>.
The function <code><a href="#topic+rescale_reps">rescale_reps</a></code> is used to implement
the rescaling of the bootstrap adjustment factors.
</p>
<p>See <a href="#topic+variance-estimators">variance-estimators</a> for a
description of each variance estimator.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(survey)

# Example 1: Bootstrap based on the Yates-Grundy estimator ----
   set.seed(2014)

   data('election', package = 'survey')

   ## Create survey design object
   pps_design_yg &lt;- svydesign(
     data = election_pps,
     id = ~1, fpc = ~p,
     pps = ppsmat(election_jointprob),
     variance = "YG"
   )

   ## Convert to generalized bootstrap replicate design
   gen_boot_design_yg &lt;- pps_design_yg |&gt;
     as_gen_boot_design(variance_estimator = "Yates-Grundy",
                        replicates = 1000, tau = "auto")

   svytotal(x = ~ Bush + Kerry, design = pps_design_yg)
   svytotal(x = ~ Bush + Kerry, design = gen_boot_design_yg)

# Example 2: Bootstrap based on the successive-difference estimator ----

   data('library_stsys_sample', package = 'svrep')

   ## First, ensure data are sorted in same order as was used in sampling
   library_stsys_sample &lt;- library_stsys_sample[
     order(library_stsys_sample$SAMPLING_SORT_ORDER),
   ]

   ## Create a survey design object
   design_obj &lt;- svydesign(
     data = library_stsys_sample,
     strata = ~ SAMPLING_STRATUM,
     ids = ~ 1,
     fpc = ~ STRATUM_POP_SIZE
   )

   ## Convert to generalized bootstrap replicate design
   gen_boot_design_sd2 &lt;- as_gen_boot_design(
     design = design_obj,
     variance_estimator = "SD2",
     replicates = 2000
   )

   ## Estimate sampling variances
   svytotal(x = ~ TOTSTAFF, na.rm = TRUE, design = gen_boot_design_sd2)
   svytotal(x = ~ TOTSTAFF, na.rm = TRUE, design = design_obj)

# Example 3: Two-phase sample ----
# -- First stage is stratified systematic sampling,
# -- second stage is response/nonresponse modeled as Poisson sampling

  nonresponse_model &lt;- glm(
    data = library_stsys_sample,
    family = quasibinomial('logit'),
    formula = I(RESPONSE_STATUS == "Survey Respondent") ~ 1,
    weights = 1/library_stsys_sample$SAMPLING_PROB
  )

  library_stsys_sample[['RESPONSE_PROPENSITY']] &lt;- predict(
    nonresponse_model,
    newdata = library_stsys_sample,
    type = "response"
  )

  twophase_design &lt;- twophase(
    data = library_stsys_sample,
    # Identify cases included in second phase sample
    subset = ~ I(RESPONSE_STATUS == "Survey Respondent"),
    strata = list(~ SAMPLING_STRATUM, NULL),
    id = list(~ 1, ~ 1),
    probs = list(NULL, ~ RESPONSE_PROPENSITY),
    fpc = list(~ STRATUM_POP_SIZE, NULL),
  )

  twophase_boot_design &lt;- as_gen_boot_design(
    design = twophase_design,
    variance_estimator = list(
      "SD2", "Poisson Horvitz-Thompson"
    )
  )

  svytotal(x = ~ LIBRARIA, design = twophase_boot_design)


## End(Not run)
</code></pre>

<hr>
<h2 id='as_random_group_jackknife_design'>Convert a survey design object to a random-groups jackknife design</h2><span id='topic+as_random_group_jackknife_design'></span>

<h3>Description</h3>

<p>Forms a specified number of jackknife replicates
based on grouping primary sampling units (PSUs)
into random, (approximately) equal-sized groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_random_group_jackknife_design(
  design,
  replicates = 50,
  var_strat = NULL,
  var_strat_frac = NULL,
  sort_var = NULL,
  adj_method = "variance-stratum-psus",
  scale_method = "variance-stratum-psus",
  group_var_name = ".random_group",
  compress = TRUE,
  mse = getOption("survey.replicates.mse")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_random_group_jackknife_design_+3A_design">design</code></td>
<td>
<p>A survey design object created using the 'survey' (or 'srvyr') package,
with class <code>'survey.design'</code> or <code>'svyimputationList'</code>.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_replicates">replicates</code></td>
<td>
<p>The number of replicates to create
for each variance stratum. The total number of replicates
created is the number of variance strata times <code>replicates</code>.
Every design stratum must have at least as many primary sampling units (PSUs),
as <code>replicates</code>.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_var_strat">var_strat</code></td>
<td>
<p>Specifies the name of a variable
in the data that defines variance strata to use
for the grouped jackknife. If <code>var_strat = NULL</code>,
then there is effectively only one variance stratum.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_var_strat_frac">var_strat_frac</code></td>
<td>
<p>Specifies the sampling fraction
to use for finite population corrections in each
value of <code>var_strat</code>. Can use either a single number
or a variable in the data corresponding to <code>var_strat</code>.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_sort_var">sort_var</code></td>
<td>
<p>(Optional) Specifies the name of a variable
in the data which should be used to sort the data before
assigning random groups. If a variable is specified for
<code>var_strat</code>, the sorting will happen within values of
that variable.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_adj_method">adj_method</code></td>
<td>
<p>Specifies how to calculate the
replicate weight adjustment factor.
Available options for <code>adj_method</code> include:
</p>

<ul>
<li> <p><code>"variance-stratum-psus"</code> (the default) <br />
The replicate weight adjustment for a unit
is based on the number of PSUs in its variance stratum.
</p>
</li>
<li> <p><code>"variance-units"</code> <br />
The replicate weight adjustment for a unit
is based on the number of variance units
in its variance stratum.
</p>
</li></ul>

<p>See the section &quot;Adjustment and Scale Methods&quot; for details.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_scale_method">scale_method</code></td>
<td>
<p>Specifies how to calculate the
scale factor for each replicate.
Available options for <code>scale_method</code> include:
</p>

<ul>
<li> <p><code>"variance-stratum-psus"</code> <br />
The scale factor for a variance unit
is based on its number of PSUs compared
to the number of PSUs in its variance stratum.
</p>
</li>
<li> <p><code>"variance-units"</code> <br />
The scale factor for a variance unit is
based on the number of variance units in
its variance stratum.
</p>
</li></ul>

<p>See the section &quot;Adjustment and Scale Methods&quot; for details.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_group_var_name">group_var_name</code></td>
<td>
<p>(Optional) The name of a new variable created to save
identifiers for which random group each PSU was grouped into
for the purpose of forming replicates.
Specify <code>group_var_name = NULL</code> to avoid creating the variable in the data.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_compress">compress</code></td>
<td>
<p>Use a compressed representation of the replicate weights matrix.
This reduces the computer memory required to represent the replicate weights and has no
impact on estimates.</p>
</td></tr>
<tr><td><code id="as_random_group_jackknife_design_+3A_mse">mse</code></td>
<td>
<p>If <code>TRUE</code>, compute variances from sums of squares around the point estimate from the full-sample weights,
If <code>FALSE</code>, compute variances from sums of squares around the mean estimate from the replicate weights.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A replicate design object, with class <code>svyrep.design</code>, which can be used with the usual functions,
such as <code>svymean()</code> or <code>svyglm()</code>.
</p>
<p>Use <code>weights(..., type = 'analysis')</code> to extract the matrix of replicate weights. <br />
Use <code>as_data_frame_with_weights()</code> to convert the design object to a data frame with columns
for the full-sample and replicate weights.
</p>


<h3>Formation of Random Groups</h3>

<p>Within each value of <code>VAR_STRAT</code>,
the data are sorted by first-stage sampling strata,
and then the PSUs in each stratum are randomly arranged.
Groups are then formed by serially placing PSUs
into each group.
The first PSU in the <code>VAR_STRAT</code> is placed into the first group,
the second PSU into the second group, and so on.
Once a PSU has been assigned to the last group,
the process begins again by assigning the next PSU to the first group,
the PSU after that to the second group, and so on.
</p>
<p>The random group that each observation is assigned to
can be saved as a variable in the data
by using the function argument <code>group_var_name</code>.
</p>


<h3>Adjustment and Scale Methods</h3>

<p>The jackknife replication variance estimator based on <code class="reqn">R</code> replicates takes the following form:
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{\theta}) = \sum_{r=1}^{R} (1 - f_r) \times c_r \times \left(\hat{\theta}_r - \hat{\theta}\right)^2
</code>
</p>

<p>where <code class="reqn">r</code> indexes one of the <code class="reqn">R</code> sets of replicate weights,
<code class="reqn">c_r</code> is a corresponding scale factor for the <code class="reqn">r</code>-th replicate,
and <code class="reqn">1 - f_r</code> is an optional finite population correction factor
that can potentially differ across variance strata.
</p>
<p>To form the replicate weights, the PSUs are divided into <code class="reqn">\tilde{H}</code> variance strata,
and the <code class="reqn">\tilde{h}</code>-th variance stratum contains <code class="reqn">G_{\tilde{h}}</code>
random groups. The number of replicates <code class="reqn">R</code> equals the total number
of random groups across all variance strata:
<code class="reqn">R = \sum_{\tilde{h}}^{\tilde{H}} G_{\tilde{h}}</code>. In other words,
each replicate corresponds to one of the random groups from one of the variance strata.
</p>
<p>The weights for replicate <code class="reqn">r</code> corresponding to random group <code class="reqn">g</code> within
variance stratum <code class="reqn">\tilde{h}</code> is defined as follows.
</p>
<p>If case <code class="reqn">i</code>
is not in variance stratum <code class="reqn">\tilde{h}</code>, then <code class="reqn">w_{i}^{(r)} = w_i</code>.
</p>
<p>If case <code class="reqn">i</code> is in variance stratum <code class="reqn">\tilde{h}</code> but in random group <code class="reqn">g</code>,
then <code class="reqn">w_{i}^{(r)} = a_{\tilde{h}g} w_i</code>.
</p>
<p>Otherwise, if case <code class="reqn">i</code> is in
in random group <code class="reqn">g</code> of variance stratum <code class="reqn">\tilde{h}</code>, then <code class="reqn">w_{i}^{(r)} = 0</code>.
</p>
<p>The R function argument <code>adj_method</code> determines how
the adjustment factor <code class="reqn">a_{\tilde{h} g}</code> is calculated.
When <code>adj_method = "variance-units"</code>, then
<code class="reqn">a_{\tilde{h} g}</code> is calculated based on <code class="reqn">G_{\tilde{h}}</code>,
which is the number of random groups in variance stratum <code class="reqn">\tilde{h}</code>.
When <code>adj_method = "variance-stratum-psus"</code>, then
<code class="reqn">a_{\tilde{h} g}</code> is calculated based on <code class="reqn">n_{\tilde{h}g}</code>,
which is the number of PSUs in random group <code class="reqn">g</code> in variance stratum <code class="reqn">\tilde{h}</code>,
as well as <code class="reqn">n_{\tilde{h}}</code>, the total number of PSUs in variance stratum <code class="reqn">\tilde{h}</code>.
</p>
<p>If <code>adj_method = "variance-units"</code>, then: </p>
<p style="text-align: center;"><code class="reqn">a_{\tilde{h}g} = \frac{G_{\tilde{h}}}{G_{\tilde{h}} - 1}</code>
</p>

<p>If <code>adj_method = "variance-stratum-psus"</code>, then: </p>
<p style="text-align: center;"><code class="reqn">a_{\tilde{h}g} = \frac{n_{\tilde{h}}}{n_{\tilde{h}} - n_{\tilde{h}g}}</code>
</p>

<p>The scale factor <code class="reqn">c_r</code> for replicate <code class="reqn">r</code>
corresponding to random group <code class="reqn">g</code> within variance stratum <code class="reqn">\tilde{h}</code> is
calculated according to the function argument <code>scale_method</code>.
</p>
<p>If <code>scale_method = "variance-units"</code>, then: </p>
<p style="text-align: center;"><code class="reqn">c_r = \frac{G_{\tilde{h}} - 1}{G_{\tilde{h}}}</code>
</p>

<p>If <code>scale_method = "variance-stratum-psus"</code>, then: </p>
<p style="text-align: center;"><code class="reqn">c_r = \frac{n_{\tilde{h}} - n_{\tilde{h}g}}{n_{\tilde{h}}}</code>
</p>

<p>The sampling fraction <code class="reqn">f_r</code> used for finite population correction <code class="reqn">1 - f_r</code>
is by default assumed to equal 0. However, the user can supply a sampling fraction
for each variance stratum using the argument <code>var_strat_frac</code>.
</p>
<p>When variance units in a variance stratum
have differing numbers of PSUs,
the combination <code>adj_method = "variance-stratum-psus"</code>
and <code>scale_method = "variance-units"</code> is
recommended by Valliant, Brick, and Dever (2008),
corresponding to their method <code>"GJ2"</code>.
</p>
<p>The random-groups jackknife method often referred to as &quot;DAGJK&quot;
corresponds to the options <code>var_strat = NULL</code>,
<code>adj_method = "variance-units"</code>, and <code>scale_method = "variance-units"</code>.
The DAGJK method will yield upwardly-biased variance estimates for totals
if the total number of PSUs is not a multiple of the total number of replicates (Valliant, Brick, and Dever 2008).
</p>


<h3>References</h3>

<p>See Section 15.5 of Valliant, Dever, and Kreuter (2018)
for an introduction to the grouped jackknife and
guidelines for creating the random groups.
</p>
<p>- Valliant, R., Dever, J., Kreuter, F. (2018).
&quot;Practical Tools for Designing and Weighting Survey Samples, 2nd edition.&quot; New York: Springer.
</p>
<p>See Valliant, Brick, and Dever (2008)
for statistical details related to the
<code>adj_method</code> and <code>scale_method</code> arguments.
</p>
<p>- Valliant, Richard, Michael Brick, and Jill Dever. 2008.
&quot;Weight Adjustments for the Grouped Jackknife Variance Estimator.&quot;
<em>Journal of Official Statistics</em>. 24: 469–88.
</p>
<p>See Chapter 4 of Wolter (2007) for additional details of the jackknife,
including the method based on random groups.
</p>
<p>- Wolter, Kirk. 2007. &quot;Introduction to Variance Estimation.&quot; New York, NY: Springer New York. https://doi.org/10.1007/978-0-387-35099-8.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survey)

# Load example data

 data('api', package = 'survey')

 api_strat_design &lt;- svydesign(
   data = apistrat,
   id = ~ 1,
   strata = ~stype,
   weights = ~pw
 )

# Create a random-groups jackknife design

 jk_design &lt;- as_random_group_jackknife_design(
   api_strat_design,
   replicates = 15
 )
 print(jk_design)
</code></pre>

<hr>
<h2 id='calibrate_to_estimate'>Calibrate weights from a primary survey to estimated totals from a control survey,
with replicate-weight adjustments that account for variance of the control totals</h2><span id='topic+calibrate_to_estimate'></span>

<h3>Description</h3>

<p>Calibrate the weights of a primary survey to match estimated totals from a control survey,
using adjustments to the replicate weights to account for the variance of the estimated control totals.
The adjustments to replicate weights are conducted using the method proposed by Fuller (1998).
This method can be used to implement general calibration as well as post-stratification or raking specifically
(see the details for the <code>calfun</code> parameter).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate_to_estimate(
  rep_design,
  estimate,
  vcov_estimate,
  cal_formula,
  calfun = survey::cal.linear,
  bounds = list(lower = -Inf, upper = Inf),
  verbose = FALSE,
  maxit = 50,
  epsilon = 1e-07,
  variance = NULL,
  col_selection = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate_to_estimate_+3A_rep_design">rep_design</code></td>
<td>
<p>A replicate design object for the primary survey, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_estimate">estimate</code></td>
<td>
<p>A vector of estimated control totals.
The names of entries must match the names from calling <code>svytotal(x = cal_formula, design = rep_design)</code>.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_vcov_estimate">vcov_estimate</code></td>
<td>
<p>A variance-covariance matrix for the estimated control totals.
The column names and row names must match the names of <code>estimate</code>.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_cal_formula">cal_formula</code></td>
<td>
<p>A formula listing the variables to use for calibration.
All of these variables must be included in <code>rep_design</code>.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_calfun">calfun</code></td>
<td>
<p>A calibration function from the <code>survey</code> package,
such as <a href="survey.html#topic+cal.linear">cal.linear</a>, <a href="survey.html#topic+cal.raking">cal.raking</a>, or <a href="survey.html#topic+cal.logit">cal.logit</a>.
Use <code>cal.linear</code> for ordinary post-stratification, and <code>cal.raking</code> for raking.
See <a href="survey.html#topic+calibrate">calibrate</a> for additional details.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_bounds">bounds</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_verbose">verbose</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_maxit">maxit</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_epsilon">epsilon</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. <br />
After calibration, the absolute difference between each calibration target and the calibrated estimate
will be no larger than <code>epsilon</code> times (1 plus the absolute value of the target).
See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_variance">variance</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_estimate_+3A_col_selection">col_selection</code></td>
<td>
<p>Optional parameter to determine which replicate columns
will have their control totals perturbed. If supplied, <code>col_selection</code> must be an integer vector
with length equal to the length of <code>estimate</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With the Fuller method, each of <code>k</code> randomly-selected replicate columns from the primary survey
are calibrated to control totals formed by perturbing the <code>k</code>-dimensional vector of
estimated control totals using a spectral decomposition of the variance-covariance matrix
of the estimated control totals. Other replicate columns are simply calibrated to the unperturbed control totals.
<br />
</p>
<p>Because the set of replicate columns whose control totals are perturbed should be random,
there are multiple ways to ensure that this matching is reproducible.
The user can either call <a href="base.html#topic+set.seed">set.seed</a> before using the function,
or supply a vector of randomly-selected column indices to the argument <code>col_selection</code>.
</p>


<h3>Value</h3>

<p>A replicate design object, with full-sample weights calibrated to totals from <code>estimate</code>,
and replicate weights adjusted to account for variance of the control totals.
The element <code>col_selection</code> indicates, for each replicate column of the calibrated primary survey,
which column of replicate weights it was matched to from the control survey.
</p>


<h3>Syntax for Common Types of Calibration</h3>

<p>For ratio estimation with an auxiliary variable <code>X</code>,
use the following options: <br />
- <code>cal_formula = ~ -1 + X</code> <br />
- <code>variance = 1</code>, <br />
- <code>cal.fun = survey::cal.linear</code>
</p>
<p>For post-stratification, use the following option:
</p>
<p>- <code>cal.fun = survey::cal.linear</code>
</p>
<p>For raking, use the following option:
</p>
<p>- <code>cal.fun = survey::cal.raking</code>
</p>


<h3>References</h3>

<p>Fuller, W.A. (1998).
&quot;Replication variance estimation for two-phase samples.&quot;
<strong>Statistica Sinica</strong>, <em>8</em>: 1153-1164.
</p>
<p>Opsomer, J.D. and A. Erciulescu (2021).
&quot;Replication variance estimation after sample-based calibration.&quot;
<strong>Survey Methodology</strong>, <em>47</em>: 265-277.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load example data for primary survey ----

  suppressPackageStartupMessages(library(survey))
  data(api)

  primary_survey &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) |&gt;
    as.svrepdesign(type = "JK1")

# Load example data for control survey ----

  control_survey &lt;- svydesign(id = ~ 1, fpc = ~fpc, data = apisrs) |&gt;
    as.svrepdesign(type = "JK1")

# Estimate control totals ----

  estimated_controls &lt;- svytotal(x = ~ stype + enroll,
                                 design = control_survey)
  control_point_estimates &lt;- coef(estimated_controls)
  control_vcov_estimate &lt;- vcov(estimated_controls)

# Calibrate totals for one categorical variable and one numeric ----

  calibrated_rep_design &lt;- calibrate_to_estimate(
    rep_design = primary_survey,
    estimate = control_point_estimates,
    vcov_estimate = control_vcov_estimate,
    cal_formula = ~ stype + enroll
  )

# Inspect estimates before and after calibration ----

  ##_ For the calibration variables, estimates and standard errors
  ##_ from calibrated design will match those of the control survey

    svytotal(x = ~ stype + enroll, design = primary_survey)
    svytotal(x = ~ stype + enroll, design = control_survey)
    svytotal(x = ~ stype + enroll, design = calibrated_rep_design)

  ##_ Estimates from other variables will be changed as well

    svymean(x = ~ api00 + api99, design = primary_survey)
    svymean(x = ~ api00 + api99, design = control_survey)
    svymean(x = ~ api00 + api99, design = calibrated_rep_design)

# Inspect weights before and after calibration ----

  summarize_rep_weights(primary_survey, type = 'overall')
  summarize_rep_weights(calibrated_rep_design, type = 'overall')

# For reproducibility, specify which columns are randomly selected for Fuller method ----

  column_selection &lt;- calibrated_rep_design$col_selection
  print(column_selection)

  calibrated_rep_design &lt;- calibrate_to_estimate(
    rep_design = primary_survey,
    estimate = control_point_estimates,
    vcov_estimate = control_vcov_estimate,
    cal_formula = ~ stype + enroll,
    col_selection = column_selection
  )

## End(Not run)
</code></pre>

<hr>
<h2 id='calibrate_to_sample'>Calibrate weights from a primary survey to estimated totals from a control survey,
with replicate-weight adjustments that account for variance of the control totals</h2><span id='topic+calibrate_to_sample'></span>

<h3>Description</h3>

<p>Calibrate the weights of a primary survey to match estimated totals from a control survey,
using adjustments to the replicate weights to account for the variance of the estimated control totals.
The adjustments to replicate weights are conducted using the method proposed by Opsomer and Erciulescu (2021).
This method can be used to implement general calibration as well as post-stratification or raking specifically
(see the details for the <code>calfun</code> parameter).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calibrate_to_sample(
  primary_rep_design,
  control_rep_design,
  cal_formula,
  calfun = survey::cal.linear,
  bounds = list(lower = -Inf, upper = Inf),
  verbose = FALSE,
  maxit = 50,
  epsilon = 1e-07,
  variance = NULL,
  control_col_matches = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calibrate_to_sample_+3A_primary_rep_design">primary_rep_design</code></td>
<td>
<p>A replicate design object for the primary survey, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_control_rep_design">control_rep_design</code></td>
<td>
<p>A replicate design object for the control survey.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_cal_formula">cal_formula</code></td>
<td>
<p>A formula listing the variables to use for calibration.
All of these variables must be included in both <code>primary_rep_design</code> and <code>control_rep_design</code>.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_calfun">calfun</code></td>
<td>
<p>A calibration function from the <code>survey</code> package,
such as <a href="survey.html#topic+cal.linear">cal.linear</a>, <a href="survey.html#topic+cal.raking">cal.raking</a>, or <a href="survey.html#topic+cal.logit">cal.logit</a>.
Use <code>cal.linear</code> for ordinary post-stratification, and <code>cal.raking</code> for raking.
See <a href="survey.html#topic+calibrate">calibrate</a> for additional details.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_bounds">bounds</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_verbose">verbose</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_maxit">maxit</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_epsilon">epsilon</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. <br />
After calibration, the absolute difference between each calibration target and the calibrated estimate
will be no larger than <code>epsilon</code> times (1 plus the absolute value of the target).
See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_variance">variance</code></td>
<td>
<p>Parameter passed to <a href="survey.html#topic+grake">grake</a> for calibration. See <a href="survey.html#topic+calibrate">calibrate</a> for details.</p>
</td></tr>
<tr><td><code id="calibrate_to_sample_+3A_control_col_matches">control_col_matches</code></td>
<td>
<p>Optional parameter to specify which control survey replicate
is matched to each primary survey replicate. If the <code class="reqn">i-th</code> entry of <code>control_col_matches</code>
equals <code class="reqn">k</code>, then replicate <code class="reqn">i</code> in <code>primary_rep_design</code> is matched
to replicate <code class="reqn">k</code> in <code>control_rep_design.</code>
Entries of <code>NA</code> denote a primary survey replicate not matched to any control survey replicate.
If this parameter is not used, matching is done at random.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With the Opsomer-Erciulescu method, each column of replicate weights from the control survey
is randomly matched to a column of replicate weights from the primary survey,
and then the column from the primary survey is calibrated to control totals estimated by
perturbing the control sample's full-sample estimates using the estimates from the
matched column of replicate weights from the control survey.
<br /> <br />
If there are fewer columns of replicate weights in the control survey than in the primary survey,
then not all primary replicate columns will be matched to a replicate column from the control survey. <br />
</p>
<p>If there are more columns of replicate weights in the control survey than in the primary survey,
then the columns of replicate weights in the primary survey will be duplicated <code>k</code> times, where <code>k</code> is the smallest
positive integer such that the resulting number of columns of replicate weights for the primary survey is greater than or equal
to the number of columns of replicate weights in the control survey. <br />
</p>
<p>Because replicate columns of the control survey are matched <em>at random</em> to primary survey replicate columns,
there are multiple ways to ensure that this matching is reproducible.
The user can either call <a href="base.html#topic+set.seed">set.seed</a> before using the function,
or supply a mapping to the argument <code>control_col_matches</code>.
</p>


<h3>Value</h3>

<p>A replicate design object, with full-sample weights calibrated to totals from <code>control_rep_design</code>,
and replicate weights adjusted to account for variance of the control totals.
If <code>primary_rep_design</code> had fewer columns of replicate weights than <code>control_rep_design</code>,
then the number of replicate columns and the length of <code>rscales</code> will be increased by a multiple <code>k</code>,
and the <code>scale</code> will be updated by dividing by <code>k</code>. <br /> <br />
The element <code>control_column_matches</code> indicates, for each replicate column of the calibrated primary survey,
which column of replicate weights it was matched to from the control survey.
Columns which were not matched to control survey replicate column are indicated by <code>NA</code>. <br /> <br />
The element <code>degf</code> will be set to match that of the primary survey
to ensure that the degrees of freedom are not erroneously inflated by
potential increases in the number of columns of replicate weights.
</p>


<h3>Syntax for Common Types of Calibration</h3>

<p>For ratio estimation with an auxiliary variable <code>X</code>,
use the following options: <br />
- <code>cal_formula = ~ -1 + X</code> <br />
- <code>variance = 1</code>, <br />
- <code>cal.fun = survey::cal.linear</code>
</p>
<p>For post-stratification, use the following option:
</p>
<p>- <code>cal.fun = survey::cal.linear</code>
</p>
<p>For raking, use the following option:
</p>
<p>- <code>cal.fun = survey::cal.raking</code>
</p>


<h3>References</h3>

<p>Opsomer, J.D. and A. Erciulescu (2021).
&quot;Replication variance estimation after sample-based calibration.&quot;
<strong>Survey Methodology</strong>, <em>47</em>: 265-277.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load example data for primary survey ----

  suppressPackageStartupMessages(library(survey))
  data(api)

  primary_survey &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc) |&gt;
    as.svrepdesign(type = "JK1")

# Load example data for control survey ----

  control_survey &lt;- svydesign(id = ~ 1, fpc = ~fpc, data = apisrs) |&gt;
    as.svrepdesign(type = "JK1")

# Calibrate totals for one categorical variable and one numeric ----

  calibrated_rep_design &lt;- calibrate_to_sample(
    primary_rep_design = primary_survey,
    control_rep_design = control_survey,
    cal_formula = ~ stype + enroll,
  )

# Inspect estimates before and after calibration ----

  ##_ For the calibration variables, estimates and standard errors
  ##_ from calibrated design will match those of the control survey

    svytotal(x = ~ stype + enroll, design = primary_survey)
    svytotal(x = ~ stype + enroll, design = control_survey)
    svytotal(x = ~ stype + enroll, design = calibrated_rep_design)

  ##_ Estimates from other variables will be changed as well

    svymean(x = ~ api00 + api99, design = primary_survey)
    svymean(x = ~ api00 + api99, design = control_survey)
    svymean(x = ~ api00 + api99, design = calibrated_rep_design)

# Inspect weights before and after calibration ----

  summarize_rep_weights(primary_survey, type = 'overall')
  summarize_rep_weights(calibrated_rep_design, type = 'overall')

# For reproducibility, specify how to match replicates between surveys ----

  column_matching &lt;- calibrated_rep_design$control_col_matches
  print(column_matching)

  calibrated_rep_design &lt;- calibrate_to_sample(
    primary_rep_design = primary_survey,
    control_rep_design = control_survey,
    cal_formula = ~ stype + enroll,
    control_col_matches = column_matching
  )

## End(Not run)
</code></pre>

<hr>
<h2 id='compress_design'>Produce a compressed representation of a survey design object</h2><span id='topic+compress_design'></span>

<h3>Description</h3>

<p>Produce a compressed representation of a survey design object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compress_design(design, vars_to_keep = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compress_design_+3A_design">design</code></td>
<td>
<p>A survey design object</p>
</td></tr>
<tr><td><code id="compress_design_+3A_vars_to_keep">vars_to_keep</code></td>
<td>
<p>(Optional) A character vector
of variables in the design to keep in the compressed design.
By default, none of the variables are retained.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two elements. The <code>design_subset</code>
element is a a design object with only the minimal rows
needed to represent the survey design.
The <code>index</code> element links each row of the original design
to a row of <code>design_subset</code>, so that the design can be &quot;uncompressed.&quot;
</p>

<hr>
<h2 id='distribute_matrix_across_clusters'>Helper function to turn a cluster-level matrix into an element-level matrix
by duplicating rows or columns of the matrix</h2><span id='topic+distribute_matrix_across_clusters'></span>

<h3>Description</h3>

<p>Turns a cluster-level matrix into an element-level matrix
by suitably duplicating rows or columns of the matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distribute_matrix_across_clusters(
  cluster_level_matrix,
  cluster_ids,
  rows = TRUE,
  cols = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distribute_matrix_across_clusters_+3A_cluster_level_matrix">cluster_level_matrix</code></td>
<td>
<p>A square matrix, whose number of rows/columns matches the number of clusters.</p>
</td></tr>
<tr><td><code id="distribute_matrix_across_clusters_+3A_cluster_ids">cluster_ids</code></td>
<td>
<p>A vector of cluster identifiers.
If <code>rows=TRUE</code>, the number of unique elements of <code>cluster_ids</code>
must match the number of rows of <code>cluster_level_matrix</code>.
If <code>cols=TRUE</code>, the number of unique elements of <code>cluster_ids</code>
must match the number of columns of <code>cluster_level_matrix</code>.</p>
</td></tr>
<tr><td><code id="distribute_matrix_across_clusters_+3A_rows">rows</code></td>
<td>
<p>Whether to duplicate rows of the <code>cluster_level_matrix</code> for elements from the same cluster.</p>
</td></tr>
<tr><td><code id="distribute_matrix_across_clusters_+3A_cols">cols</code></td>
<td>
<p>Whether to duplicate columns of the <code>cluster_level_matrix</code> for elements from the same cluster.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>cluster_level_matrix</code> has its rows/columns
duplicated so that the number of rows (if <code>rows=TRUE</code>) or columns (if <code>cols=TRUE</code>)
equals the length of <code>cluster_ids</code>.
</p>

<hr>
<h2 id='estimate_boot_reps_for_target_cv'>Estimate the number of bootstrap replicates needed to reduce the bootstrap simulation error to a target level</h2><span id='topic+estimate_boot_reps_for_target_cv'></span>

<h3>Description</h3>

<p>This function estimates the number of bootstrap replicates
needed to reduce the simulation error of a bootstrap variance estimator to a target level,
where &quot;simulation error&quot; is defined as error caused by using only a finite number of bootstrap replicates
and this simulation error is measured as a simulation coefficient of variation (&quot;simulation CV&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_boot_reps_for_target_cv(svrepstat, target_cv = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_boot_reps_for_target_cv_+3A_svrepstat">svrepstat</code></td>
<td>
<p>An estimate obtained from a bootstrap replicate survey design object,
with a function such as <code>svymean(..., return.replicates = TRUE)</code> or <code>withReplicates(..., return.replicates = TRUE)</code>.</p>
</td></tr>
<tr><td><code id="estimate_boot_reps_for_target_cv_+3A_target_cv">target_cv</code></td>
<td>
<p>A numeric value (or vector of numeric values) between 0 and 1.
This is the target simulation CV for the bootstrap variance estimator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with one row for each value of <code>target_cv</code>.
The column <code>TARGET_CV</code> gives the target coefficient of variation.
The column <code>MAX_REPS</code> gives the maximum number of replicates needed
for all of the statistics included in <code>svrepstat</code>. The remaining columns
give the number of replicates needed for each statistic.
</p>


<h3>Suggested Usage</h3>

<p>- <strong>Step 1</strong>: Determine the largest acceptable level of simulation error for key survey estimates,
where the level of simulation error is measured in terms of the simulation CV. We refer to this as the &quot;target CV.&quot;
A conventional value for the target CV is 5%.
</p>
<p>- <strong>Step 2</strong>: Estimate key statistics of interest using a large number of bootstrap replicates (such as 5,000)
and save the estimates from each bootstrap replicate. This can be conveniently done using a function
from the survey package such as <code>svymean(..., return.replicates = TRUE)</code> or <code>withReplicates(..., return.replicates = TRUE)</code>.
</p>
<p>- <strong>Step 3</strong>: Use the function <code>estimate_boot_reps_for_target_cv()</code> to estimate the minimum number of bootstrap
replicates needed to attain the target CV.
</p>


<h3>Statistical Details</h3>

<p>Unlike other replication methods such as the jackknife or balanced repeated replication,
the bootstrap variance estimator's precision can always be improved by using a
larger number of replicates, as the use of only a finite number of bootstrap replicates
introduces simulation error to the variance estimation process.
Simulation error can be measured as a &quot;simulation coefficient of variation&quot; (CV), which is
the ratio of the standard error of a bootstrap estimator to the expectation of that bootstrap estimator,
where the expectation and standard error are evaluated with respect to the bootstrapping process
given the selected sample.
</p>
<p>For a statistic <code class="reqn">\hat{\theta}</code>, the simulation CV of the bootstrap variance estimator
<code class="reqn">v_{B}(\hat{\theta})</code> based on <code class="reqn">B</code> replicate estimates <code class="reqn">\hat{\theta}^{\star}_1,\dots,\hat{\theta}^{\star}_B</code> is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   CV_{\star}(v_{B}(\hat{\theta})) = \frac{\sqrt{var_{\star}(v_B(\hat{\theta}))}}{E_{\star}(v_B(\hat{\theta}))} = \frac{CV_{\star}(E_2)}{\sqrt{B}}
 </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
   E_2 = (\hat{\theta}^{\star} - \hat{\theta})^2
 </code>
</p>

<p style="text-align: center;"><code class="reqn">
   CV_{\star}(E_2) = \frac{\sqrt{var_{\star}(E_2)}}{E_{\star}(E_2)}
 </code>
</p>

<p>and <code class="reqn">var_{\star}</code> and <code class="reqn">E_{\star}</code> are evaluated with respect to
the bootstrapping process, given the selected sample.
<br /> <br />
The simulation CV, denoted <code class="reqn">CV_{\star}(v_{B}(\hat{\theta}))</code>, is estimated for a given number of replicates <code class="reqn">B</code>
by estimating <code class="reqn">CV_{\star}(E_2)</code> using observed values and dividing this by <code class="reqn">\sqrt{B}</code>. If the bootstrap errors
are assumed to be normally distributed, then <code class="reqn">CV_{\star}(E_2)=\sqrt{2}</code> and so <code class="reqn">CV_{\star}(v_{B}(\hat{\theta}))</code> would not need to be estimated.
Using observed replicate estimates to estimate the simulation CV instead of assuming normality allows simulation CV to be
used for a a wide array of bootstrap methods.
</p>


<h3>References</h3>

<p>See Section 3.3 and Section 8 of Beaumont and Patak (2012) for details and an example where the simulation CV is used
to determine the number of bootstrap replicates needed for various alternative bootstrap methods in an empirical illustration.
</p>
<p>Beaumont, J.-F. and Z. Patak. (2012),
&quot;On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling.&quot;
<strong>International Statistical Review</strong>, <em>80</em>: 127-148. <a href="https://doi.org/10.1111/j.1751-5823.2011.00166.x">doi:10.1111/j.1751-5823.2011.00166.x</a>.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+estimate_boot_sim_cv">estimate_boot_sim_cv</a></code> to estimate the simulation CV for the number of bootstrap replicates actually used.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(2022)

# Create an example bootstrap survey design object ----
library(survey)
data('api', package = 'survey')

boot_design &lt;- svydesign(id=~1,strata=~stype, weights=~pw,
                         data=apistrat, fpc=~fpc) |&gt;
 svrep::as_bootstrap_design(replicates = 5000)

# Calculate estimates of interest and retain estimates from each replicate ----

estimated_means_and_proportions &lt;- svymean(x = ~ api00 + api99 + stype, design = boot_design,
                                           return.replicates = TRUE)
custom_statistic &lt;- withReplicates(design = boot_design,
                                   return.replicates = TRUE,
                                   theta = function(wts, data) {
                                      numerator &lt;- sum(data$api00 * wts)
                                      denominator &lt;- sum(data$api99 * wts)
                                      statistic &lt;- numerator/denominator
                                      return(statistic)
                                   })
# Determine minimum number of bootstrap replicates needed to obtain given simulation CVs ----

  estimate_boot_reps_for_target_cv(
    svrepstat = estimated_means_and_proportions,
    target_cv = c(0.01, 0.05, 0.10)
  )

  estimate_boot_reps_for_target_cv(
    svrepstat = custom_statistic,
    target_cv = c(0.01, 0.05, 0.10)
  )

## End(Not run)
</code></pre>

<hr>
<h2 id='estimate_boot_sim_cv'>Estimate the bootstrap simulation error</h2><span id='topic+estimate_boot_sim_cv'></span>

<h3>Description</h3>

<p>Estimates the bootstrap simulation error, expressed as a &quot;simulation coefficient of variation&quot; (CV).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate_boot_sim_cv(svrepstat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimate_boot_sim_cv_+3A_svrepstat">svrepstat</code></td>
<td>
<p>An estimate obtained from a bootstrap replicate survey design object,
with a function such as <code>svymean(..., return.replicates = TRUE)</code> or <code>withReplicates(..., return.replicates = TRUE)</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with one row for each statistic.
The column <code>STATISTIC</code> gives the name of the statistic.
The column <code>SIMULATION_CV</code> gives the estimated simulation CV of the statistic.
The column <code>N_REPLICATES</code> gives the number of bootstrap replicates.
</p>


<h3>Statistical Details</h3>

<p>Unlike other replication methods such as the jackknife or balanced repeated replication,
the bootstrap variance estimator's precision can always be improved by using a
larger number of replicates, as the use of only a finite number of bootstrap replicates
introduces simulation error to the variance estimation process.
Simulation error can be measured as a &quot;simulation coefficient of variation&quot; (CV), which is
the ratio of the standard error of a bootstrap estimator to the expectation of that bootstrap estimator,
where the expectation and standard error are evaluated with respect to the bootstrapping process
given the selected sample.
</p>
<p>For a statistic <code class="reqn">\hat{\theta}</code>, the simulation CV of the bootstrap variance estimator
<code class="reqn">v_{B}(\hat{\theta})</code> based on <code class="reqn">B</code> replicate estimates <code class="reqn">\hat{\theta}^{\star}_1,\dots,\hat{\theta}^{\star}_B</code> is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   CV_{\star}(v_{B}(\hat{\theta})) = \frac{\sqrt{var_{\star}(v_B(\hat{\theta}))}}{E_{\star}(v_B(\hat{\theta}))} = \frac{CV_{\star}(E_2)}{\sqrt{B}}
 </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
   E_2 = (\hat{\theta}^{\star} - \hat{\theta})^2
 </code>
</p>

<p style="text-align: center;"><code class="reqn">
   CV_{\star}(E_2) = \frac{\sqrt{var_{\star}(E_2)}}{E_{\star}(E_2)}
 </code>
</p>

<p>and <code class="reqn">var_{\star}</code> and <code class="reqn">E_{\star}</code> are evaluated with respect to
the bootstrapping process, given the selected sample.
<br /> <br />
The simulation CV, denoted <code class="reqn">CV_{\star}(v_{B}(\hat{\theta}))</code>, is estimated for a given number of replicates <code class="reqn">B</code>
by estimating <code class="reqn">CV_{\star}(E_2)</code> using observed values and dividing this by <code class="reqn">\sqrt{B}</code>. If the bootstrap errors
are assumed to be normally distributed, then <code class="reqn">CV_{\star}(E_2)=\sqrt{2}</code> and so <code class="reqn">CV_{\star}(v_{B}(\hat{\theta}))</code> would not need to be estimated.
Using observed replicate estimates to estimate the simulation CV instead of assuming normality allows simulation CV to be
used for a a wide array of bootstrap methods.
</p>


<h3>References</h3>

<p>See Section 3.3 and Section 8 of Beaumont and Patak (2012) for details and an example where the simulation CV is used
to determine the number of bootstrap replicates needed for various alternative bootstrap methods in an empirical illustration.
</p>
<p>Beaumont, J.-F. and Z. Patak. (2012),
&quot;On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling.&quot;
<strong>International Statistical Review</strong>, <em>80</em>: 127-148. <a href="https://doi.org/10.1111/j.1751-5823.2011.00166.x">doi:10.1111/j.1751-5823.2011.00166.x</a>.
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+estimate_boot_reps_for_target_cv">estimate_boot_reps_for_target_cv</a></code> to help choose the number of bootstrap replicates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(2022)

# Create an example bootstrap survey design object ----
library(survey)
data('api', package = 'survey')

boot_design &lt;- svydesign(id=~1,strata=~stype, weights=~pw,
                         data=apistrat, fpc=~fpc) |&gt;
 svrep::as_bootstrap_design(replicates = 5000)

# Calculate estimates of interest and retain estimates from each replicate ----

estimated_means_and_proportions &lt;- svymean(x = ~ api00 + api99 + stype, design = boot_design,
                                           return.replicates = TRUE)
custom_statistic &lt;- withReplicates(design = boot_design,
                                   return.replicates = TRUE,
                                   theta = function(wts, data) {
                                      numerator &lt;- sum(data$api00 * wts)
                                      denominator &lt;- sum(data$api99 * wts)
                                      statistic &lt;- numerator/denominator
                                      return(statistic)
                                   })
# Estimate simulation CV of bootstrap estimates ----

  estimate_boot_sim_cv(
    svrepstat = estimated_means_and_proportions
  )

  estimate_boot_sim_cv(
    svrepstat = custom_statistic
  )

## End(Not run)
</code></pre>

<hr>
<h2 id='get_design_quad_form'>Determine the quadratic form matrix of a variance estimator for a survey design object</h2><span id='topic+get_design_quad_form'></span>

<h3>Description</h3>

<p>Determines the quadratic form matrix of a specified variance estimator,
by parsing the information stored in a survey design object created using
the 'survey' package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_design_quad_form(
  design,
  variance_estimator,
  ensure_psd = FALSE,
  aux_var_names = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_design_quad_form_+3A_design">design</code></td>
<td>
<p>A survey design object created using the 'survey' (or 'srvyr') package,
with class <code>'survey.design'</code> or <code>'svyimputationList'</code>. Also accepts two-phase design objects
with class <code>'twophase2'</code>; see the section below titled &quot;Two-Phase Designs&quot; for
more information about handling of two-phase designs.</p>
</td></tr>
<tr><td><code id="get_design_quad_form_+3A_variance_estimator">variance_estimator</code></td>
<td>
<p>The name of the variance estimator
whose quadratic form matrix should be created. <br />
See the section &quot;Variance Estimators&quot; below.
Options include:
</p>

<ul>
<li> <p><strong>&quot;Yates-Grundy&quot;</strong>: <br /> The Yates-Grundy variance estimator based on
first-order and second-order inclusion probabilities.
</p>
</li>
<li> <p><strong>&quot;Horvitz-Thompson&quot;</strong>: <br /> The Horvitz-Thompson variance estimator based on
first-order and second-order inclusion probabilities.
</p>
</li>
<li> <p><strong>&quot;Poisson Horvitz-Thompson&quot;</strong>: <br /> The Horvitz-Thompson variance estimator
based on assuming Poisson sampling, with first-order inclusion probabilities
inferred from the sampling probabilities of the survey design object.
</p>
</li>
<li> <p><strong>&quot;Stratified Multistage SRS&quot;</strong>: <br /> The usual stratified multistage variance estimator
based on estimating the variance of cluster totals within strata at each stage.
</p>
</li>
<li> <p><strong>&quot;Ultimate Cluster&quot;</strong>: <br /> The usual variance estimator based on estimating
the variance of first-stage cluster totals within first-stage strata.
</p>
</li>
<li> <p><strong>&quot;Deville-1&quot;</strong>: <br /> A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005)
as &quot;Deville 1&quot;.
</p>
</li>
<li> <p><strong>&quot;Deville-2&quot;</strong>: <br /> A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005) as &quot;Deville 2&quot;.
</p>
</li>
<li> <p><strong>&quot;Deville-Tille&quot;: </strong> <br /> A variance estimator useful
for balanced sampling designs, proposed by Deville and Tillé (2005).
</p>
</li>
<li> <p><strong>&quot;SD1&quot;</strong>: <br /> The non-circular successive-differences variance estimator described by Ash (2014),
sometimes used for variance estimation for systematic sampling.
</p>
</li>
<li><p><strong>&quot;SD2&quot;</strong>:  <br /> The circular successive-differences variance estimator described by Ash (2014).
This estimator is the basis of the &quot;successive-differences replication&quot; estimator commonly used
for variance estimation for systematic sampling.
</p>
</li></ul>
</td></tr>
<tr><td><code id="get_design_quad_form_+3A_ensure_psd">ensure_psd</code></td>
<td>
<p>If <code>TRUE</code> (the default), ensures
that the result is a positive semidefinite matrix. This
is necessary if the quadratic form is used as an input for
replication methods such as the generalized bootstrap.
For mathematical details, please see the documentation for the function <code>get_nearest_psd_matrix()</code>.
The approximation method is discussed by Beaumont and Patak (2012)
in the context of forming replicate weights for two-phase samples.
The authors argue that this approximation should
lead to only a small overestimation of variance.</p>
</td></tr>
<tr><td><code id="get_design_quad_form_+3A_aux_var_names">aux_var_names</code></td>
<td>
<p>Only required if <code>variance_estimator = "Deville-Tille"</code>.
Should be a character vector of variable names for auxiliary variables
to be used in the Breidt and Chauvet (2011) variance estimator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix representing the quadratic form of a specified variance estimator,
based on extracting information about clustering, stratification,
and selection probabilities from the survey design object.
</p>


<h3>Variance Estimators</h3>

<p>See <a href="#topic+variance-estimators">variance-estimators</a> for a
description of each variance estimator.
</p>


<h3>Two-Phase Designs</h3>

<p>For a two-phase design, <code>variance_estimator</code> should be a list of variance estimators' names,
with two elements, such as <code>list('Ultimate Cluster', 'Poisson Horvitz-Thompson')</code>.
In two-phase designs, only the following estimators may be used for the second phase:
</p>

<ul>
<li><p> &quot;Ultimate Cluster&quot;
</p>
</li>
<li><p> &quot;Stratified Multistage SRS&quot;
</p>
</li>
<li><p> &quot;Poisson Horvitz-Thompson&quot;
</p>
</li></ul>

<p>For statistical details on the handling of two-phase designs,
see the documentation for <a href="#topic+make_twophase_quad_form">make_twophase_quad_form</a>.
</p>


<h3>References</h3>

<p>- Ash, S. (2014). &quot;<em>Using successive difference replication for estimating variances</em>.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 40(1), 47–59.
<br /> <br />
- Beaumont, Jean-François, and Zdenek Patak. (2012). &quot;<em>On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling: Generalized Bootstrap for Sample Surveys.</em>&quot;
<strong>International Statistical Review</strong> 80 (1): 127–48.
<br /> <br />
- Bellhouse, D.R. (1985). &quot;<em>Computing Methods for Variance Estimation in Complex Surveys</em>.&quot;
<strong>Journal of Official Statistics</strong>, Vol.1, No.3.
<br /> <br />
- Deville, J.‐C., and Tillé, Y. (2005). &quot;<em>Variance approximation under balanced sampling.</em>&quot;
<strong>Journal of Statistical Planning and Inference</strong>, 128, 569–591.
<br /> <br />
- Särndal, C.-E., Swensson, B., &amp; Wretman, J. (1992). &quot;<em>Model Assisted Survey Sampling</em>.&quot; Springer New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: Quadratic form for successive-difference variance estimator ----

   data('library_stsys_sample', package = 'svrep')

   ## First, ensure data are sorted in same order as was used in sampling
   library_stsys_sample &lt;- library_stsys_sample[
     order(library_stsys_sample$SAMPLING_SORT_ORDER),
   ]

   ## Create a survey design object
   design_obj &lt;- svydesign(
     data = library_stsys_sample,
     strata = ~ SAMPLING_STRATUM,
     ids = ~ 1,
     fpc = ~ STRATUM_POP_SIZE
   )

   ## Obtain quadratic form
   quad_form_matrix &lt;- get_design_quad_form(
     design = design_obj,
     variance_estimator = "SD2"
   )

   ## Estimate variance of estimated population total
   y &lt;- design_obj$variables$LIBRARIA
   wts &lt;- weights(design_obj, type = 'sampling')
   y_wtd &lt;- as.matrix(y) * wts
   y_wtd[is.na(y_wtd)] &lt;- 0

   pop_total &lt;- sum(y_wtd)

   var_est &lt;- t(y_wtd) %*% quad_form_matrix %*% y_wtd
   std_error &lt;- sqrt(var_est)

   print(pop_total); print(std_error)

   # Compare to estimate from assuming SRS
   svytotal(x = ~ LIBRARIA, na.rm = TRUE,
            design = design_obj)

# Example 2: Two-phase design (second phase is nonresponse) ----

  ## Estimate response propensities, separately by stratum
  library_stsys_sample[['RESPONSE_PROB']] &lt;- svyglm(
    design = design_obj,
    formula = I(RESPONSE_STATUS == "Survey Respondent") ~ SAMPLING_STRATUM,
    family = quasibinomial('logistic')
  ) |&gt; predict(type = 'response')

  ## Create a survey design object,
  ## where nonresponse is treated as a second phase of sampling
  twophase_design &lt;- twophase(
    data = library_stsys_sample,
    strata = list(~ SAMPLING_STRATUM, NULL),
    id = list(~ 1, ~ 1),
    fpc = list(~ STRATUM_POP_SIZE, NULL),
    probs = list(NULL, ~ RESPONSE_PROB),
    subset = ~ I(RESPONSE_STATUS == "Survey Respondent")
  )

  ## Obtain quadratic form for the two-phase variance estimator,
  ## where first phase variance contribution estimated
  ## using the successive differences estimator
  ## and second phase variance contribution estimated
  ## using the Horvitz-Thompson estimator
  ## (with joint probabilities based on assumption of Poisson sampling)
  get_design_quad_form(
    design = twophase_design,
    variance_estimator = list(
      "SD2",
      "Poisson Horvitz-Thompson"
    )
  )

## End(Not run)
</code></pre>

<hr>
<h2 id='get_nearest_psd_matrix'>Approximates a symmetric, real matrix by the nearest positive
semidefinite matrix.</h2><span id='topic+get_nearest_psd_matrix'></span>

<h3>Description</h3>

<p>Approximates a symmetric, real matrix by the nearest positive
semidefinite matrix in the Frobenius norm, using the method of Higham (1988).
For a real, symmetric matrix, this is equivalent to &quot;zeroing out&quot; negative eigenvalues.
See the &quot;Details&quot; section for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_nearest_psd_matrix(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_nearest_psd_matrix_+3A_x">X</code></td>
<td>
<p>A symmetric, real matrix with no missing values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">A</code> denote a symmetric, real matrix which is not positive semidefinite.
Then we can form the spectral decomposition <code class="reqn">A=\Gamma \Lambda \Gamma^{\prime}</code>,
where <code class="reqn">\Lambda</code> is the diagonal matrix
whose entries are eigenvalues of <code class="reqn">A</code>.
The method of Higham (1988) is to  approximate
<code class="reqn">A</code> with <code class="reqn">\tilde{A} = \Gamma \Lambda_{+} \Gamma^{\prime}</code>,
where the <code class="reqn">ii</code>-th entry of <code class="reqn">\Lambda_{+}</code> is <code class="reqn">\max(\Lambda_{ii}, 0)</code>.
</p>


<h3>Value</h3>

<p>The nearest positive semidefinite matrix
of the same dimension as <code>X</code>.
</p>


<h3>References</h3>

<p>- Higham, N. J. (1988). &quot;<em>Computing a nearest symmetric positive semidefinite matrix.</em>&quot; Linear Algebra and Its Applications, 103, 103–118.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(
  c(2, 5, 5,
    5, 2, 5,
    5, 5, 2),
  nrow = 3, byrow = TRUE
)
get_nearest_psd_matrix(X)
</code></pre>

<hr>
<h2 id='getvars'>Get variables from a database</h2><span id='topic+getvars'></span>

<h3>Description</h3>

<p>A database helper function copied from the 'survey' package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getvars(
  formula,
  dbconnection,
  tables,
  db.only = TRUE,
  updates = NULL,
  subset = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getvars_+3A_formula">formula</code></td>
<td>
<p>Either a formula or a character vector giving names of variables</p>
</td></tr>
<tr><td><code id="getvars_+3A_dbconnection">dbconnection</code></td>
<td>
<p>A database connection</p>
</td></tr>
<tr><td><code id="getvars_+3A_tables">tables</code></td>
<td>
<p>Name(s) of table(s) to pull from</p>
</td></tr>
<tr><td><code id="getvars_+3A_db.only">db.only</code></td>
<td>
<p>Unclear parameter inherited from the 'survey' package</p>
</td></tr>
<tr><td><code id="getvars_+3A_updates">updates</code></td>
<td>
<p>Updates to potentially make</p>
</td></tr>
<tr><td><code id="getvars_+3A_subset">subset</code></td>
<td>
<p>Optional indices of data to subset when returning result</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame
</p>

<hr>
<h2 id='ht_matrix_to_joint_probs'>Compute the matrix of joint inclusion probabilities
from the quadratic form of a Horvitz-Thompson variance estimator.</h2><span id='topic+ht_matrix_to_joint_probs'></span>

<h3>Description</h3>

<p>Compute the matrix of joint inclusion probabilities
from the quadratic form of a Horvitz-Thompson variance estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ht_matrix_to_joint_probs(ht_quad_form)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ht_matrix_to_joint_probs_+3A_ht_quad_form">ht_quad_form</code></td>
<td>
<p>The matrix of the quadratic form
representing the Horvitz-Thompson variance estimator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The quadratic form matrix of the Horvitz-Thompson variance estimator
has <code class="reqn">ij</code>-th entry equal to <code class="reqn">(1-\frac{\pi_i \pi_j}{\pi_{ij}})</code>.
The matrix of joint probabilties has <code class="reqn">ij</code>-th entry equal to <code class="reqn">\pi_{ij}</code>.
</p>


<h3>Value</h3>

<p>The matrix of joint inclusion probabilities
</p>

<hr>
<h2 id='is_psd_matrix'>Check whether a matrix is positive semidefinite</h2><span id='topic+is_psd_matrix'></span>

<h3>Description</h3>

<p>Check whether a matrix is positive semidefinite, based on checking for symmetric and negative eigenvalues.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_psd_matrix(X, tolerance = sqrt(.Machine$double.eps))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_psd_matrix_+3A_x">X</code></td>
<td>
<p>A matrix with no missing or infinite values.</p>
</td></tr>
<tr><td><code id="is_psd_matrix_+3A_tolerance">tolerance</code></td>
<td>
<p>Tolerance for controlling whether
a tiny computed eigenvalue will actually be considered negative.
Computed negative eigenvalues will be considered
negative if they are less than which are less than
<code>-abs(tolerance * max(eigen(X)$values))</code>.
A small nonzero tolerance is recommended
since eigenvalues are nearly always computed with some floating-point error.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical value. <code>TRUE</code> if the matrix is deemed positive semidefinite.
Negative otherwise (including if <code>X</code> is not symmetric).
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+get_nearest_psd_matrix">get_nearest_psd_matrix</a>()</code>
can be used to approximate a symmetric matrix which is not positive semidefinite,
by a similar positive semidefinite matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(
  c(2, 5, 5,
    5, 2, 5,
    5, 5, 2),
  nrow = 3, byrow = TRUE
)

is_psd_matrix(X)

eigen(X)$values
</code></pre>

<hr>
<h2 id='libraries'>Public Libraries Survey (PLS): A Census of U.S. Public Libraries in FY2020</h2><span id='topic+libraries'></span><span id='topic+library_census'></span><span id='topic+library_multistage_sample'></span><span id='topic+library_stsys_sample'></span>

<h3>Description</h3>

<p>Data taken from a complete census of public libraries in the United States in FY2020 (April 2020 to March 2021).
The Public Libraries Survey (PLS) is an annual census of public libraries in the U.S.,
including all public libraries identified by state library administrative
agencies in the 50 states, the District of Columbia, and the outlying territories
of American Samoa, Guam, the Northern Mariana Islands, and the U.S. Virgin Islands
(Puerto Rico did not participate in FY2020). <br /> <br />
The primary dataset, <code>library_census</code>, represents the full microdata from the census.
The datasets <code>library_multistage_sample</code> and <code>library_stsys_sample</code>
are samples drawn from <code>library_census</code> using different sampling methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(library_census)

data(library_multistage_sample)

data(library_stsys_sample)
</code></pre>


<h3>Format</h3>

<p><em>Library Census (<code>library_census</code>): </em> <br /> <br />
The dataset includes 9,245 records (one per library) and 23 variables.
Each column has a variable label, accessible using the function <code>var_label()</code> from the 'labelled' package
or simply by calling <code>attr(x, 'label')</code> to a given column.
These data include a subset of the variables included in the public-use data published by PLS,
specifically from the Public Library System Data File. Particularly relevant variables include:
<br /> <br />
Identifier variables and survey response status:
</p>

<ul>
<li><p> FSCSKEY: A unique identifier for libraries.
</p>
</li>
<li><p> LIBNAME: The name of the library.
</p>
</li>
<li><p> RESPONSE_STATUS: Response status for the Public Library Survey:
indicates whether the library was a respondent, nonrespondent, or was closed.
</p>
</li></ul>

<p>Numeric summaries:
</p>

<ul>
<li><p> TOTCIR: Total circulation
</p>
</li>
<li><p> VISITS: Total visitors
</p>
</li>
<li><p> REGBOR: Total number of registered users
</p>
</li>
<li><p> TOTSTAFF: Total staff (measured in full-time equivalent staff)
</p>
</li>
<li><p> LIBRARIA: Total librarians (measured in full-time equivalent staff)
</p>
</li>
<li><p> TOTOPEXP: Total operating expenses
</p>
</li>
<li><p> TOTINCM: Total income
</p>
</li>
<li><p> BRANLIB: Number of library branches
</p>
</li>
<li><p> CENTLIB: Number of central library locations
</p>
</li></ul>

<p>Location:
</p>

<ul>
<li><p> LONGITUD: Geocoded longitude (in WGS84 CRS)
</p>
</li>
<li><p> LATITUD: Geocoded latitude (in WGS84 CRS)
</p>
</li>
<li><p> STABR: Two-letter state abbreviation
</p>
</li>
<li><p> CBSA: Five-digit identifer for a core-based statistical area (CBSA)
</p>
</li>
<li><p> MICROF: Flag for a metropolitan or micropolitan statistical area
</p>
</li></ul>

<p><em>Library Multistage Sample (<code>library_multistage_sample</code>): </em> <br /> <br />
These data represent a two-stage sample (PSUs and SSUs),
where the first stage sample is selected using unequal probability sampling
without replacement (PPSWOR) and the second stage sample is selected
using simple random sampling without replacement (SRSWOR). <br /> <br />
Includes the same variables as <code>library_census</code>,
but with additional design variables.
</p>

<ul>
<li><p> PSU_ID: A unique identifier for primary sampling units
</p>
</li>
<li><p> SSU_ID: A unique identifer for secondary sampling units
</p>
</li>
<li><p> SAMPLING_PROB: Overall inclusion probability
</p>
</li>
<li><p> PSU_SAMPLING_PROB: Inclusion probability for the PSU
</p>
</li>
<li><p> SSU_SAMPLING_PROB: Inclusion probability for the SSU
</p>
</li>
<li><p> PSU_POP_SIZE: The number of PSUs in the population
</p>
</li>
<li><p> SSU_POP_SIZE: The number of population SSUs within the PSU
</p>
</li></ul>

<p><em>Library Stratified Systematic Sample (<code>library_stsys_sample</code>): </em> <br /> <br />
These data represent a stratified systematic sample. <br /> <br />
Includes the same variables as <code>library_census</code>,
but with additional design variables.
</p>

<ul>
<li><p> SAMPLING_STRATUM: Unique identifier for sampling strata
</p>
</li>
<li><p> STRATUM_POP_SIZE: The population size in the stratum
</p>
</li>
<li><p> SAMPLING_SORT_ORDER: The sort order used before selecting a random systematic sample
</p>
</li>
<li><p> SAMPLING_PROB: Overall inclusion probability
</p>
</li></ul>



<h3>References</h3>

<p>Pelczar, M., Soffronoff, J., Nielsen, E., Li, J., &amp; Mabile, S. (2022). Data File Documentation: Public
Libraries in the United States Fiscal Year 2020. Institute of Museum and Library Services: Washington,
D.C.
</p>

<hr>
<h2 id='lou_pums_microdata'>ACS PUMS Data for Louisville</h2><span id='topic+lou_pums_microdata'></span>

<h3>Description</h3>

<p>Person-level microdata from the American Community Survey (ACS) 2015-2019
public-use microdata sample (PUMS) data for Louisville, KY. This microdata sample
represents all adults (persons aged 18 or over) in Louisville, KY. <br />
</p>
<p>These data include replicate weights to use for variance estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lou_pums_microdata)
</code></pre>


<h3>Format</h3>

<p>A data frame with 80 rows and 85 variables
</p>

<ul>
<li><p> UNIQUE_ID: Unique identifier for records
</p>
</li>
<li><p> AGE: Age in years (copied from the AGEP variable in the ACS microdata)
</p>
</li>
<li><p> RACE_ETHNICITY: Race and Hispanic/Latino ethnicity
derived from RAC1P and HISP variables
of ACS microdata and collapsed to a smaller number of categories.
</p>
</li>
<li><p> SEX: Male or Female
</p>
</li>
<li><p> EDUC_ATTAINMENT: Highest level of education attained ('Less than high school' or 'High school or beyond')
derived from SCHL variable in ACS microdata and collapsed to a smaller number of categories.
</p>
</li>
<li><p> PWGTP: Weights for the full-sample
</p>
</li>
<li><p> PWGTP1-PWGTP80: 80 columns of replicate weights
created using the Successive Differences Replication (SDR) method.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(lou_pums_microdata)

# Prepare the data for analysis with the survey package
  library(survey)

  lou_pums_rep_design &lt;- survey::svrepdesign(
    data = lou_pums_microdata,
    variables = ~ UNIQUE_ID + AGE + SEX + RACE_ETHNICITY + EDUC_ATTAINMENT,
    weights = ~ PWGTP, repweights = "PWGTP\\d{1,2}",
    type = "successive-difference",
    mse = TRUE
  )

# Estimate population proportions
  svymean(~ SEX, design = lou_pums_rep_design)

## End(Not run)
</code></pre>

<hr>
<h2 id='lou_vax_survey'>Louisville Vaccination Survey</h2><span id='topic+lou_vax_survey'></span>

<h3>Description</h3>

<p>A survey measuring Covid-19 vaccination status and a handful of demographic variables,
based on a simple random sample of 1,000 residents of Louisville, Kentucky
with an approximately 50% response rate. <br />
</p>
<p>These data were created using simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lou_vax_survey)
</code></pre>


<h3>Format</h3>

<p>A data frame with 1,000 rows and 6 variables
</p>

<dl>
<dt>RESPONSE_STATUS</dt><dd><p>Response status to the survey ('Respondent' or 'Nonrespondent')</p>
</dd>
<dt>RACE_ETHNICITY</dt><dd><p>Race and Hispanic/Latino ethnicity
derived from RAC1P and HISP variables
of ACS microdata and collapsed to a smaller number of categories.</p>
</dd>
<dt>SEX</dt><dd><p>Male or Female</p>
</dd>
<dt>EDUC_ATTAINMENT</dt><dd><p>Highest level of education attained ('Less than high school' or 'High school or beyond')
derived from SCHL variable in ACS microdata and collapsed to a smaller number of categories.</p>
</dd>
<dt>VAX_STATUS</dt><dd><p>Covid-19 vaccination status ('Vaccinated' or 'Unvaccinated')</p>
</dd>
<dt>SAMPLING_WEIGHT</dt><dd><p>Sampling weight: equal for all cases since data come from a simple random sample</p>
</dd>
</dl>


<hr>
<h2 id='lou_vax_survey_control_totals'>Control totals for the Louisville Vaccination Survey</h2><span id='topic+lou_vax_survey_control_totals'></span>

<h3>Description</h3>

<p>Control totals to use for raking or post-stratification
for the Louisville Vaccination Survey data. Control totals are population size estimates
from the ACS 2015-2019 5-year Public Use Microdata Sample (PUMS)
for specific demographic categories among adults in Jefferson County, KY. <br />
</p>
<p>These data were created using simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lou_vax_survey_control_totals)
</code></pre>


<h3>Format</h3>

<p>A nested list object with two lists, <code>poststratification</code> and <code>raking</code>,
each of which contains two elements: <code>estimates</code> and <code>variance-covariance</code>.
</p>

<dl>
<dt>poststratification</dt><dd><p>Control totals for the combination of
<code>RACE_ETHNICITY</code>, <code>SEX</code>, and <code>EDUC_ATTAINMENT</code>.
</p>

<ul>
<li><p> estimates: A numeric vector of estimated population totals.
</p>
</li>
<li><p> variance-covariance: A variance-covariance matrix for the estimated population totals.
</p>
</li></ul>

</dd>
<dt>raking</dt><dd><p>Separate control totals for each of
<code>RACE_ETHNICITY</code>, <code>SEX</code>, and <code>EDUC_ATTAINMENT</code>.
</p>

<ul>
<li><p> estimates: A numeric vector of estimated population totals.
</p>
</li>
<li><p> variance-covariance: A variance-covariance matrix for the estimated population totals.
</p>
</li></ul>

</dd>
</dl>


<hr>
<h2 id='make_deville_tille_matrix'>Create a quadratic form's matrix
for a Deville-Tillé variance estimator for balanced samples</h2><span id='topic+make_deville_tille_matrix'></span>

<h3>Description</h3>

<p>Creates the quadratic form matrix for a
variance estimator for balanced samples,
proposed by Deville and Tillé (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_deville_tille_matrix(probs, aux_vars)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_deville_tille_matrix_+3A_probs">probs</code></td>
<td>
<p>A vector of first-order inclusion probabilities</p>
</td></tr>
<tr><td><code id="make_deville_tille_matrix_+3A_aux_vars">aux_vars</code></td>
<td>
<p>A matrix of auxiliary variables,
with the number of rows matching the number of elements of <code>probs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Section 6.8 of Tillé (2020) for more detail on this estimator,
including an explanation of its quadratic form.
See Deville and Tillé (2005) for the results of a simulation study
comparing this and other alternative estimators for balanced sampling.
</p>
<p>The estimator can be written as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{Y})=\sum_{k \in S} \frac{c_k}{\pi_k^2}\left(y_k-\hat{y}_k^*\right)^2,
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{y}_k^*=\mathbf{z}_k^{\top}\left(\sum_{\ell \in S} c_{\ell} \frac{\mathbf{z}_{\ell} \mathbf{z}_{\ell}^{\prime}}{\pi_{\ell}^2}\right)^{-1} \sum_{\ell \in S} c_{\ell} \frac{\mathbf{z}_{\ell} y_{\ell}}{\pi_{\ell}^2}
</code>
</p>

<p>and <code class="reqn">\mathbf{z}_k</code> denotes the vector of auxiliary variables for observation <code class="reqn">k</code>
included in sample <code class="reqn">S</code>, with inclusion probability <code class="reqn">\pi_k</code>. The value <code class="reqn">c_k</code> is set to <code class="reqn">\frac{n}{n-q}(1-\pi_k)</code>,
where <code class="reqn">n</code> is the number of observations and <code class="reqn">q</code> is the number of auxiliary variables.
</p>
<p>See Li, Chen, and Krenzke (2014) for an example of this estimator's use
as the basis for a generalized replication estimator. See Breidt and Chauvet (2011)
for a discussion of alternative simulation-based estimators for the specific
application of variance estimation for balanced samples selected using the cube method.
</p>


<h3>Value</h3>

<p>A symmetric matrix whose dimension matches the length of <code>probs</code>.
</p>


<h3>References</h3>

<p>- Breidt, F.J. and Chauvet, G. (2011).
&quot;Improved variance estimation for balanced samples drawn via the cube method.&quot;
Journal of Statistical Planning and Inference, 141, 411-425.
</p>
<p>- Deville, J.‐C., and Tillé, Y. (2005). &quot;<em>Variance approximation under balanced sampling.</em>&quot;
<strong>Journal of Statistical Planning and Inference</strong>, 128, 569–591.
</p>
<p>- Li, J., Chen, S., and Krenzke, T. (2014).
&quot;Replication Variance Estimation for Balanced Sampling: An Application to the PIAAC Study.&quot;
Proceedings of the Survey Research Methods Section, 2014: 985–994. Alexandria, VA: American Statistical Association.
http://www.asasrms.org/Proceedings/papers/1984_094.pdf.
</p>
<p>- Tillé, Y. (2020). &quot;<em>Sampling and estimation from finite populations</em>.&quot; (I. Hekimi, Trans.). Wiley.
</p>

<hr>
<h2 id='make_fays_gen_rep_factors'>Form replication factors using Fay's generalized replication method</h2><span id='topic+make_fays_gen_rep_factors'></span>

<h3>Description</h3>

<p>Generate a matrix of replication factors
using Fay's generalized replication method.
This method yields a fully efficient variance estimator
if a sufficient number of replicates is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_fays_gen_rep_factors(
  Sigma,
  max_replicates = Matrix::rankMatrix(Sigma) + 4,
  balanced = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_fays_gen_rep_factors_+3A_sigma">Sigma</code></td>
<td>
<p>A quadratic form matrix corresponding to
a target variance estimator. Must be positive semidefinite.</p>
</td></tr>
<tr><td><code id="make_fays_gen_rep_factors_+3A_max_replicates">max_replicates</code></td>
<td>
<p>The maximum number of replicates to allow.
The function will attempt to create the minimum number of replicates
needed to produce a fully-efficient variance estimator.
If more replicates are needed than <code>max_replicates</code>, then the full number of replicates
needed will be created, but only a random subsample will be retained.</p>
</td></tr>
<tr><td><code id="make_fays_gen_rep_factors_+3A_balanced">balanced</code></td>
<td>
<p>If <code>balanced=TRUE</code>, the replicates
will all contribute equally to variance estimates, but
the number of replicates needed may slightly increase.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of replicate factors,
with the number of rows matching the number of rows of <code>Sigma</code>
and the number of columns less than or equal to <code>max_replicates</code>.
To calculate variance estimates using these factors,
use the overall scale factor given by calling
<code>attr(x, "scale")</code> on the result.
</p>


<h3>Statistical Details</h3>

<p>See Fay (1989) for a full explanation of Fay's generalized replication method.
This documentation provides a brief overview.
</p>
<p>Let <code class="reqn">\boldsymbol{\Sigma}</code> be the quadratic form matrix for a target variance estimator,
which is assumed to be positive semidefinite.
Suppose the rank of <code class="reqn">\boldsymbol{\Sigma}</code> is <code class="reqn">k</code>,
and so <code class="reqn">\boldsymbol{\Sigma}</code> can be represented by the spectral decomposition
of <code class="reqn">k</code> eigenvectors and eigenvalues, where the <code class="reqn">r</code>-th eigenvector and eigenvalue
are denoted <code class="reqn">\mathbf{v}_{(r)}</code> and <code class="reqn">\lambda_r</code>, respectively.
</p>
<p style="text-align: center;"><code class="reqn">
\boldsymbol{\Sigma} = \sum_{r=1}^k \lambda_r \mathbf{v}_{(r)} \mathbf{v^{\prime}}_{(r)}
</code>
</p>

<p>If <code>balanced = FALSE</code>, then we let <code class="reqn">\mathbf{H}</code> denote an identity matrix
with <code class="reqn">k' = k</code> rows/columns. If <code>balanced = TRUE</code>, then we let <code class="reqn">\mathbf{H}</code> be a Hadamard matrix (with all entries equal to <code class="reqn">1</code> or <code class="reqn">-1</code>),
of order <code class="reqn">k^{\prime} \geq k</code>. Let <code class="reqn">\mathbf{H}_{mr}</code> denote the entry in row
<code class="reqn">m</code> and column <code class="reqn">r</code> of <code class="reqn">\mathbf{H}</code>.
</p>
<p>Then <code class="reqn">k^{\prime}</code> replicates are formed as follows.
Let <code class="reqn">r</code> denote a given replicate, with <code class="reqn">r = 1, ..., k^{\prime}</code>,
and let <code class="reqn">c</code> denote some positive constant (yet to be specified).
</p>
<p>The <code class="reqn">r</code>-th replicate adjustment factor <code class="reqn">\mathbf{f}_{r}</code> is formed as:
</p>
<p style="text-align: center;"><code class="reqn">
  \mathbf{f}_{r} = 1 + c \sum_{m=1}^k H_{m r} \lambda_{(m)}^{\frac{1}{2}} \mathbf{v}_{(m)}
</code>
</p>

<p>If <code>balanced = FALSE</code>, then <code class="reqn">c = 1</code>. If <code>balanced = TRUE</code>,
then <code class="reqn">c = \frac{1}{\sqrt{k^{\prime}}}</code>.
</p>
<p>If any of the replicates
are negative, you can use <code><a href="#topic+rescale_reps">rescale_reps</a></code>,
which recalculates the replicate factors with a smaller value of <code class="reqn">c</code>.
</p>
<p>If all <code class="reqn">k^{\prime}</code> replicates are used, then variance estimates are calculated as:
</p>
<p style="text-align: center;"><code class="reqn">
  v_{rep}\left(\hat{T}_y\right) = \sum_{r=1}^{k^{\prime}}\left(\hat{T}_y^{*(r)}-\hat{T}_y\right)^2
</code>
</p>

<p>For population totals, this replication variance estimator
will <em>exactly</em> match the target variance estimator
if the number of replicates <code class="reqn">k^{\prime}</code> matches the rank of <code class="reqn">\Sigma</code>.
</p>


<h3>The Number of Replicates</h3>

<p>If <code>balanced=TRUE</code>, the number of replicates created
may need to increase slightly.
This is due to the fact that a Hadamard matrix
of order <code class="reqn">k^{\prime} \geq k</code> is used to balance the replicates,
and it may be necessary to use order <code class="reqn">k^{\prime} &gt; k</code>.
</p>
<p>If the number of replicates <code class="reqn">k^{\prime}</code> is too large for practical purposes,
then one can simply retain only a random subset of <code class="reqn">R</code> of the <code class="reqn">k^{\prime}</code> replicates.
In this case, variances are calculated as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  v_{rep}\left(\hat{T}_y\right) = \frac{k^{\prime}}{R} \sum_{r=1}^{R}\left(\hat{T}_y^{*(r)}-\hat{T}_y\right)^2
</code>
</p>

<p>This is what happens if <code>max_replicates</code> is less than the
matrix rank of <code>Sigma</code>: only a random subset
of the created replicates will be retained.
</p>
<p>Subsampling replicates is only recommended when
using <code>balanced=TRUE</code>, since in this case every replicate
contributes equally to variance estimates. If <code>balanced=FALSE</code>,
then randomly subsampling replicates is valid but may
produce large variation in variance estimates since replicates
in that case may vary greatly in their contribution to variance
estimates.
</p>


<h3>Reproducibility</h3>

<p>If <code>balanced=TRUE</code>, a Hadamard matrix
is used as described above. The Hadamard matrix is
deterministically created using the function
<code><a href="survey.html#topic+hadamard">hadamard</a>()</code> from the 'survey' package.
However, the order of rows/columns is randomly permuted
before forming replicates.
</p>
<p>In general, column-ordering of the replicate weights is random.
To ensure exact reproducibility, it is recommended to call
<code><a href="base.html#topic+set.seed">set.seed</a>()</code> before using this function.
</p>


<h3>References</h3>

<p>Fay, Robert. 1989.
&quot;Theory And Application Of Replicate Weighting For Variance Calculations.&quot;
In, 495–500. Alexandria, VA: American Statistical Association.
http://www.asasrms.org/Proceedings/papers/1989_033.pdf
</p>


<h3>See Also</h3>

<p>Use <code><a href="#topic+rescale_reps">rescale_reps</a></code> to eliminate negative adjustment factors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(survey)

# Load an example dataset that uses unequal probability sampling ----
  data('election', package = 'survey')

# Create matrix to represent the Horvitz-Thompson estimator as a quadratic form ----
  n &lt;- nrow(election_pps)
  pi &lt;- election_jointprob
  horvitz_thompson_matrix &lt;- matrix(nrow = n, ncol = n)
  for (i in seq_len(n)) {
    for (j in seq_len(n)) {
      horvitz_thompson_matrix[i,j] &lt;- 1 - (pi[i,i] * pi[j,j])/pi[i,j]
    }
  }

  ## Equivalently:

  horvitz_thompson_matrix &lt;- make_quad_form_matrix(
    variance_estimator = "Horvitz-Thompson",
    joint_probs = election_jointprob
  )

# Make generalized replication adjustment factors ----

  adjustment_factors &lt;- make_fays_gen_rep_factors(
    Sigma = horvitz_thompson_matrix,
    max_replicates = 50
  )
  attr(adjustment_factors, 'scale')

# Compute the Horvitz-Thompson estimate and the replication estimate

ht_estimate &lt;- svydesign(data = election_pps, ids = ~ 1,
                         prob = diag(election_jointprob),
                         pps = ppsmat(election_jointprob)) |&gt;
  svytotal(x = ~ Kerry)

rep_estimate &lt;- svrepdesign(
  data = election_pps,
  weights = ~ wt,
  repweights = adjustment_factors,
  combined.weights = FALSE,
  scale = attr(adjustment_factors, 'scale'),
  rscales = rep(1, times = ncol(adjustment_factors)),
  type = "other",
  mse = TRUE
) |&gt;
  svytotal(x = ~ Kerry)

SE(rep_estimate)
SE(ht_estimate)
SE(rep_estimate) / SE(ht_estimate)

## End(Not run)
</code></pre>

<hr>
<h2 id='make_gen_boot_factors'>Creates replicate factors for the generalized survey bootstrap</h2><span id='topic+make_gen_boot_factors'></span>

<h3>Description</h3>

<p>Creates replicate factors for the generalized survey bootstrap method.
The generalized survey bootstrap is a method for forming bootstrap replicate weights
from a textbook variance estimator, provided that the variance estimator
can be represented as a quadratic form whose matrix is positive semidefinite
(this covers a large class of variance estimators).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_gen_boot_factors(Sigma, num_replicates, tau = "auto", exact_vcov = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_gen_boot_factors_+3A_sigma">Sigma</code></td>
<td>
<p>The matrix of the quadratic form used to represent the variance estimator.
Must be positive semidefinite.</p>
</td></tr>
<tr><td><code id="make_gen_boot_factors_+3A_num_replicates">num_replicates</code></td>
<td>
<p>The number of bootstrap replicates to create.</p>
</td></tr>
<tr><td><code id="make_gen_boot_factors_+3A_tau">tau</code></td>
<td>
<p>Either <code>"auto"</code>, or a single number. This is the rescaling constant
used to avoid negative weights through the transformation <code class="reqn">\frac{w + \tau - 1}{\tau}</code>,
where <code class="reqn">w</code> is the original weight and <code class="reqn">\tau</code> is the rescaling constant <code>tau</code>. <br />
If <code>tau="auto"</code>, the rescaling factor is determined automatically as follows:
if all of the adjustment factors are nonnegative, then <code>tau</code> is set equal to 1;
otherwise, <code>tau</code> is set to the smallest value needed to rescale
the adjustment factors such that they are all at least <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="make_gen_boot_factors_+3A_exact_vcov">exact_vcov</code></td>
<td>
<p>If <code>exact_vcov=TRUE</code>, the replicate factors will be generated
such that their variance-covariance matrix exactly matches the target variance estimator's
quadratic form (within numeric precision).
This is desirable as it causes variance estimates for totals to closely match
the values from the target variance estimator.
This requires that <code>num_replicates</code> exceeds the rank of <code>Sigma</code>.
The replicate factors are generated by applying PCA-whitening to a collection of draws
from a multivariate Normal distribution, then applying a coloring transformation
to the whitened collection of draws.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the same number of rows as <code>Sigma</code>, and the number of columns
equal to <code>num_replicates</code>. The object has an attribute named <code>tau</code> which can be retrieved
by calling <code>attr(which = 'tau')</code> on the object. The value <code>tau</code> is a rescaling factor
which was used to avoid negative weights.
</p>
<p>In addition, the object has attributes named <code>scale</code> and <code>rscales</code> which can be
passed directly to <a href="survey.html#topic+svrepdesign">svrepdesign</a>. Note that the value of <code>scale</code> is <code class="reqn">\tau^2/B</code>,
while the value of <code>rscales</code> is vector of length <code class="reqn">B</code>, with every entry equal to <code class="reqn">1</code>.
</p>


<h3>Statistical Details</h3>

<p>Let <code class="reqn">v( \hat{T_y})</code> be the textbook variance estimator for an estimated population total <code class="reqn">\hat{T}_y</code> of some variable <code class="reqn">y</code>.
The base weight for case <code class="reqn">i</code> in our sample is <code class="reqn">w_i</code>, and we let <code class="reqn">\breve{y}_i</code> denote the weighted value <code class="reqn">w_iy_i</code>.
Suppose we can represent our textbook variance estimator as a quadratic form: <code class="reqn">v(\hat{T}_y) = \breve{y}\Sigma\breve{y}^T</code>,
for some <code class="reqn">n \times n</code> matrix <code class="reqn">\Sigma</code>.
The only constraint on <code class="reqn">\Sigma</code> is that, for our sample, it must be symmetric and positive semidefinite.
</p>
<p>The bootstrapping process creates <code class="reqn">B</code> sets of replicate weights, where the <code class="reqn">b</code>-th set of replicate weights is a vector of length <code class="reqn">n</code> denoted <code class="reqn">\mathbf{a}^{(b)}</code>, whose <code class="reqn">k</code>-th value is denoted <code class="reqn">a_k^{(b)}</code>.
This yields <code class="reqn">B</code> replicate estimates of the population total, <code class="reqn">\hat{T}_y^{*(b)}=\sum_{k \in s} a_k^{(b)} \breve{y}_k</code>, for <code class="reqn">b=1, \ldots B</code>, which can be used to estimate sampling variance.
</p>
<p style="text-align: center;"><code class="reqn">
  v_B\left(\hat{T}_y\right)=\frac{\sum_{b=1}^B\left(\hat{T}_y^{*(b)}-\hat{T}_y\right)^2}{B}
</code>
</p>

<p>This bootstrap variance estimator can be written as a quadratic form:
</p>
<p style="text-align: center;"><code class="reqn">
    v_B\left(\hat{T}_y\right) =\mathbf{\breve{y}}^{\prime}\Sigma_B \mathbf{\breve{y}}
  </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
    \boldsymbol{\Sigma}_B = \frac{\sum_{b=1}^B\left(\mathbf{a}^{(b)}-\mathbf{1}_n\right)\left(\mathbf{a}^{(b)}-\mathbf{1}_n\right)^{\prime}}{B}
  </code>
</p>

<p>Note that if the vector of adjustment factors <code class="reqn">\mathbf{a}^{(b)}</code> has expectation <code class="reqn">\mathbf{1}_n</code> and variance-covariance matrix <code class="reqn">\boldsymbol{\Sigma}</code>,
then we have the bootstrap expectation <code class="reqn">E_{*}\left( \boldsymbol{\Sigma}_B \right) = \boldsymbol{\Sigma}</code>. Since the bootstrap process takes the sample values <code class="reqn">\breve{y}</code> as fixed, the bootstrap expectation of the variance estimator is <code class="reqn">E_{*} \left( \mathbf{\breve{y}}^{\prime}\Sigma_B \mathbf{\breve{y}}\right)= \mathbf{\breve{y}}^{\prime}\Sigma \mathbf{\breve{y}}</code>.
Thus, we can produce a bootstrap variance estimator with the same expectation as the textbook variance estimator simply by randomly generating <code class="reqn">\mathbf{a}^{(b)}</code> from a distribution with the following two conditions:
<br /> <br />
<strong>Condition 1</strong>: <code class="reqn">\quad \mathbf{E}_*(\mathbf{a})=\mathbf{1}_n</code>
<br />
<strong>Condition 2</strong>: <code class="reqn">\quad \mathbf{E}_*\left(\mathbf{a}-\mathbf{1}_n\right)\left(\mathbf{a}-\mathbf{1}_n\right)^{\prime}=\mathbf{\Sigma}</code>
<br /> <br />
While there are multiple ways to generate adjustment factors satisfying these conditions,
the simplest general method is to simulate from a multivariate normal distribution: <code class="reqn">\mathbf{a} \sim MVN(\mathbf{1}_n, \boldsymbol{\Sigma})</code>.
This is the method used by this function.
</p>


<h3>Details on Rescaling to Avoid Negative Adjustment Factors</h3>

<p>Let <code class="reqn">\mathbf{A} = \left[ \mathbf{a}^{(1)} \cdots \mathbf{a}^{(b)} \cdots \mathbf{a}^{(B)} \right]</code> denote the <code class="reqn">(n \times B)</code> matrix of bootstrap adjustment factors.
To eliminate negative adjustment factors, Beaumont and Patak (2012) propose forming a rescaled matrix of nonnegative replicate factors <code class="reqn">\mathbf{A}^S</code> by rescaling each adjustment factor <code class="reqn">a_k^{(b)}</code> as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   a_k^{S,(b)} = \frac{a_k^{(b)} + \tau - 1}{\tau}
 </code>
</p>

<p>where <code class="reqn">\tau \geq 1 - a_k^{(b)} \geq 1</code> for all <code class="reqn">k</code> in <code class="reqn">\left\{ 1,\ldots,n \right\}</code> and all <code class="reqn">b</code> in <code class="reqn">\left\{1, \ldots, B\right\}</code>.
</p>
<p>The value of <code class="reqn">\tau</code> can be set based on the realized adjustment factor matrix <code class="reqn">\mathbf{A}</code> or by choosing <code class="reqn">\tau</code> prior to generating the adjustment factor matrix <code class="reqn">\mathbf{A}</code> so that <code class="reqn">\tau</code> is likely to be large enough to prevent negative bootstrap weights.
</p>
<p>If the adjustment factors are rescaled in this manner, it is important to adjust the scale factor used in estimating the variance with the bootstrap replicates, which becomes <code class="reqn">\frac{\tau^2}{B}</code> instead of <code class="reqn">\frac{1}{B}</code>.
</p>
<p style="text-align: center;"><code class="reqn">
 \textbf{Prior to rescaling: } v_B\left(\hat{T}_y\right) = \frac{1}{B}\sum_{b=1}^B\left(\hat{T}_y^{*(b)}-\hat{T}_y\right)^2
 </code>
</p>

<p style="text-align: center;"><code class="reqn">
 \textbf{After rescaling: } v_B\left(\hat{T}_y\right) = \frac{\tau^2}{B}\sum_{b=1}^B\left(\hat{T}_y^{S*(b)}-\hat{T}_y\right)^2
</code>
</p>

<p>When sharing a dataset that uses rescaled weights from a generalized survey bootstrap, the documentation for the dataset should instruct the user to use replication scale factor <code class="reqn">\frac{\tau^2}{B}</code> rather than <code class="reqn">\frac{1}{B}</code> when estimating sampling variances.
</p>


<h3>References</h3>

<p>The generalized survey bootstrap was first proposed by Bertail and Combris (1997).
See Beaumont and Patak (2012) for a clear overview of the generalized survey bootstrap.
The generalized survey bootstrap represents one strategy for forming replication variance estimators
in the general framework proposed by Fay (1984) and Dippo, Fay, and Morganstein (1984).
<br /> <br />
- Beaumont, Jean-François, and Zdenek Patak. 2012. “On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling: Generalized Bootstrap for Sample Surveys.” International Statistical Review 80 (1): 127–48. https://doi.org/10.1111/j.1751-5823.2011.00166.x.
<br /> <br />
- Bertail, and Combris. 1997. “Bootstrap Généralisé d’un Sondage.” Annales d’Économie Et de Statistique, no. 46: 49. https://doi.org/10.2307/20076068.
<br /> <br />
- Dippo, Cathryn, Robert Fay, and David Morganstein. 1984. “Computing Variances from Complex Samples with Replicate Weights.” In, 489–94. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1984_094.pdf.
<br /> <br />
- Fay, Robert. 1984. “Some Properties of Estimates of Variance Based on Replication Methods.” In, 495–500. Alexandria, VA: American Statistical Association. http://www.asasrms.org/Proceedings/papers/1984_095.pdf.
<br />
</p>


<h3>See Also</h3>

<p>The function <code><a href="#topic+make_quad_form_matrix">make_quad_form_matrix</a></code> can be used to
represent several common variance estimators as a quadratic form's matrix,
which can then be used as an input to <code>make_gen_boot_factors()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(survey)

# Load an example dataset that uses unequal probability sampling ----
  data('election', package = 'survey')

# Create matrix to represent the Horvitz-Thompson estimator as a quadratic form ----
  n &lt;- nrow(election_pps)
  pi &lt;- election_jointprob
  horvitz_thompson_matrix &lt;- matrix(nrow = n, ncol = n)
  for (i in seq_len(n)) {
    for (j in seq_len(n)) {
      horvitz_thompson_matrix[i,j] &lt;- 1 - (pi[i,i] * pi[j,j])/pi[i,j]
    }
  }

  ## Equivalently:

  horvitz_thompson_matrix &lt;- make_quad_form_matrix(
    variance_estimator = "Horvitz-Thompson",
    joint_probs = election_jointprob
  )

# Make generalized bootstrap adjustment factors ----

  bootstrap_adjustment_factors &lt;- make_gen_boot_factors(
    Sigma = horvitz_thompson_matrix,
    num_replicates = 80,
    tau = 'auto'
  )

# Determine replication scale factor for variance estimation ----
  tau &lt;- attr(bootstrap_adjustment_factors, 'tau')
  B &lt;- ncol(bootstrap_adjustment_factors)
  replication_scaling_constant &lt;- tau^2 / B

# Create a replicate design object ----
  election_pps_bootstrap_design &lt;- svrepdesign(
    data = election_pps,
    weights = 1 / diag(election_jointprob),
    repweights = bootstrap_adjustment_factors,
    combined.weights = FALSE,
    type = "other",
    scale = attr(bootstrap_adjustment_factors, 'scale'),
    rscales = attr(bootstrap_adjustment_factors, 'rscales')
  )

# Compare estimates to Horvitz-Thompson estimator ----

  election_pps_ht_design &lt;- svydesign(
    id = ~1,
    fpc = ~p,
    data = election_pps,
    pps = ppsmat(election_jointprob),
    variance = "HT"
  )

svytotal(x = ~ Bush + Kerry,
         design = election_pps_bootstrap_design)
svytotal(x = ~ Bush + Kerry,
         design = election_pps_ht_design)

## End(Not run)
</code></pre>

<hr>
<h2 id='make_ppswor_approx_matrix'>Create a quadratic form's matrix to represent a variance estimator
for PPSWOR designs, based on commonly-used approximations</h2><span id='topic+make_ppswor_approx_matrix'></span>

<h3>Description</h3>

<p>Several variance estimators for designs that use
unequal probability sampling without replacement (i.e., PPSWOR),
variance estimation tends to be more accurate
when using an approximation estimator that uses the first-order
inclusion probabilities (i.e., the basic sampling weights)
and ignores the joint inclusion probabilities.
This function returns the matrix of the quadratic form used
to represent such variance estimators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_ppswor_approx_matrix(probs, method = "Deville-1")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_ppswor_approx_matrix_+3A_probs">probs</code></td>
<td>
<p>A vector of first-order inclusion probabilities</p>
</td></tr>
<tr><td><code id="make_ppswor_approx_matrix_+3A_method">method</code></td>
<td>
<p>A string specifying the approximation method to use.
See the &quot;Details&quot; section below.
Options include:
</p>

<ul>
<li><p> &quot;Deville-1&quot;
</p>
</li>
<li><p> &quot;Deville-2&quot;
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>These variance estimators have been shown to be effective
for designs that use a fixed sample size with a high-entropy sampling method.
This includes most PPSWOR sampling methods,
but unequal-probability systematic sampling is an important exception.
</p>
<p>These variance estimators generally take the following form:
</p>
<p style="text-align: center;"><code class="reqn">
\hat{v}(\hat{Y}) = \sum_{i=1}^{n} c_i (\breve{y}_i - \frac{1}{\sum_{i=k}^{n}c_k}\sum_{k=1}^{n}c_k \breve{y}_k)^2
</code>
</p>

<p>where <code class="reqn">\breve{y}_i = y_i/\pi_i</code> is the weighted value of the the variable of interest,
and <code class="reqn">c_i</code> are constants that depend on the approximation method used.  <br /> <br />
The matrix of the quadratic form, denoted <code class="reqn">\Sigma</code>, has
its <code class="reqn">ij</code>-th entry defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  \sigma_{ii} = c_i (1 - \frac{c_i}{\sum_{k=1}^{n}c_k}) \textit{ when } i = j \\
  \sigma_{ij}=\frac{-c_i c_j}{\sum_{k=1}^{n}c_k} \textit{ when } i \neq j \\
</code>
</p>

<p>When <code class="reqn">\pi_{i} = 1</code> for every unit, then <code class="reqn">\sigma_{ij}=0</code> for all <code class="reqn">i,j</code>.
If there is only one sampling unit, then <code class="reqn">\sigma_{11}=0</code>; that is, the unit is treated as if it was sampled with certainty.
</p>
<p>The constants <code class="reqn">c_i</code> are defined for each approximation method as follows,
with the names taken directly from Matei and Tillé (2005).
</p>

<ul>
<li> <p><strong>&quot;Deville-1&quot;</strong>:
</p>
<p style="text-align: center;"><code class="reqn">c_i=\left(1-\pi_i\right) \frac{n}{n-1}</code>
</p>

</li>
<li> <p><strong>&quot;Deville-2&quot;</strong>:
</p>
<p style="text-align: center;"><code class="reqn">c_i = (1-\pi_i) \left[1 - \sum_{k=1}^{n} \left(\frac{1-\pi_k}{\sum_{k=1}^{n}(1-\pi_k)}\right)^2 \right]^{-1}</code>
</p>

</li></ul>

<p>Both of the approximations <strong>&quot;Deville-1&quot;</strong> and <strong>&quot;Deville-2&quot;</strong> were shown
in the simulation studies of Matei and Tillé (2005) to perform much better
in terms of MSE compared to the strictly-unbiased
Horvitz-Thompson and Yates-Grundy variance estimators.
In the case of simple random sampling without replacement (SRSWOR),
these estimators are identical to the usual Horvitz-Thompson variance estimator.
</p>


<h3>Value</h3>

<p>A symmetric matrix whose dimension matches the length of <code>probs</code>.
</p>


<h3>References</h3>

<p>Matei, Alina, and Yves Tillé. 2005.
“Evaluation of Variance Approximations and Estimators
in Maximum Entropy Sampling with Unequal Probability and Fixed Sample Size.”
Journal of Official Statistics 21(4):543–70.
</p>

<hr>
<h2 id='make_quad_form_matrix'>Represent a variance estimator as a quadratic form</h2><span id='topic+make_quad_form_matrix'></span>

<h3>Description</h3>

<p>Common variance estimators for estimated population totals can be represented as a quadratic form.
Given a choice of variance estimator and information about the sample design,
this function constructs the matrix of the quadratic form.
<br /> <br />
In notation, let
<code class="reqn">v(\hat{Y}) = \mathbf{\breve{y}}^{\prime}\mathbf{\Sigma}\mathbf{\breve{y}}</code>,
where <code class="reqn">\breve{y}</code> is the vector of weighted values, <code class="reqn">y_i/\pi_i, \space i=1,\dots,n</code>.
This function constructs the <code class="reqn">n \times n</code> matrix of the quadratic form, <code class="reqn">\mathbf{\Sigma}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_quad_form_matrix(
  variance_estimator = "Yates-Grundy",
  probs = NULL,
  joint_probs = NULL,
  cluster_ids = NULL,
  strata_ids = NULL,
  strata_pop_sizes = NULL,
  sort_order = NULL,
  aux_vars = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_quad_form_matrix_+3A_variance_estimator">variance_estimator</code></td>
<td>
<p>The name of the variance estimator
whose quadratic form matrix should be created. See the section &quot;Variance Estimators&quot; below.
Options include:
</p>

<ul>
<li> <p><strong>&quot;Yates-Grundy&quot;</strong>: The Yates-Grundy variance estimator based on
first-order and second-order inclusion probabilities. If this is used,
the argument <code>joint_probs</code> must also be used.
</p>
</li>
<li> <p><strong>&quot;Horvitz-Thompson&quot;</strong>: The Horvitz-Thompson variance estimator based on
first-order and second-order inclusion probabilities. If this is used,
the argument <code>joint_probs</code> must also be used.
</p>
</li>
<li> <p><strong>&quot;Stratified Multistage SRS&quot;</strong>: The usual stratified multistage variance estimator
based on estimating the variance of cluster totals within strata at each stage.
If this option is used, then it is necessary to also use the arguments
<code>strata_ids</code>, <code>cluster_ids</code>, <code>strata_pop_sizes</code>, and <code>strata_pop_sizes</code>.
</p>
</li>
<li> <p><strong>&quot;Ultimate Cluster&quot;</strong>: The usual variance estimator based on estimating
the variance of first-stage cluster totals within first-stage strata.
If this option is used, then it is necessary to also use the arguments
<code>strata_ids</code>, <code>cluster_ids</code>, <code>strata_pop_sizes</code>.
Optionally, to use finite population correction factors, one can also use the argument <code>strata_pop_sizes</code>.
</p>
</li>
<li> <p><strong>&quot;Deville-1&quot;</strong>: A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005)
as &quot;Deville 1&quot;. If this option is used, then it is necessary to also use the arguments
<code>strata_ids</code>, <code>cluster_ids</code>, and <code>probs</code>.
</p>
</li>
<li> <p><strong>&quot;Deville-2&quot;</strong>:  A variance estimator for unequal-probability
sampling without replacement, described in Matei and Tillé (2005)
as &quot;Deville 2&quot;. If this option is used, then it is necessary to also use the arguments
<code>strata_ids</code>, <code>cluster_ids</code>, and <code>probs</code>.
</p>
</li>
<li> <p><strong>&quot;SD1&quot;</strong>: The non-circular successive-differences variance estimator described by Ash (2014),
sometimes used for variance estimation for systematic sampling.
</p>
</li>
<li> <p><strong>&quot;SD2&quot;</strong>: The circular successive-differences variance estimator described by Ash (2014).
This estimator is the basis of the &quot;successive-differences replication&quot; estimator commonly used
for variance estimation for systematic sampling.
</p>
</li>
<li> <p><strong>&quot;Deville-Tille&quot;</strong>: The estimator of Deville and Tillé (2005),
developed for balanced sampling using the cube method.
</p>
</li></ul>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_probs">probs</code></td>
<td>
<p>Required if <code>variance_estimator</code> equals <code>"Deville-1"</code>, <code>"Deville-2"</code>, or <code>"Breidt-Chauvet"</code>.
This should be a matrix or data frame of sampling probabilities.
If there are multiple stages of sampling,
then <code>probs</code> can have multiple columns,
with one column for each level of sampling to be accounted for by the variance estimator.</p>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_joint_probs">joint_probs</code></td>
<td>
<p>Only used if <code>variance_estimator = "Horvitz-Thompson"</code> or <code>variance_estimator = "Yates-Grundy"</code>.
This should be a matrix of joint inclusion probabilities.
Element <code>[i,i]</code> of the matrix is the first-order inclusion probability of unit <code>i</code>,
while element <code>[i,j]</code> is the joint inclusion probability of units <code>i</code> and <code>j</code>.</p>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_cluster_ids">cluster_ids</code></td>
<td>
<p>Required unless <code>variance_estimator</code> equals <code>"Horvitz-Thompson"</code> or <code>"Yates-Grundy"</code>.
This should be a matrix or data frame of cluster IDs. If there are multiple stages of sampling,
then <code>cluster_ids</code> can have multiple columns,
with one column for each level of sampling to be accounted for by the variance estimator.</p>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_strata_ids">strata_ids</code></td>
<td>
<p>Required if <code>variance_estimator</code> equals <code>"Stratified Multistage SRS"</code>
or <code>"Ultimate Cluster"</code>.
This should be a matrix or data frame of strata IDs. If there are multiple stages of sampling,
then <code>strata_ids</code> can have multiple columns,
with one column for each level of sampling to be accounted for by the variance estimator.</p>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_strata_pop_sizes">strata_pop_sizes</code></td>
<td>
<p>Required if <code>variance_estimator</code> equals <code>"Stratified Multistage SRS"</code>,
but can optionally be used if <code>variance_estimator</code> equals <code>"Ultimate Cluster"</code>, <code>"SD1"</code>, or <code>"SD2"</code>.
If there are multiple stages of sampling,
then <code>strata_pop_sizes</code> can have multiple columns,
with one column for each level of sampling to be accounted for by the variance estimator.</p>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_sort_order">sort_order</code></td>
<td>
<p>Required if <code>variance_estimator</code> equals <code>"SD1"</code> or <code>"SD2"</code>.
This should be a vector that orders the rows of data into the order used for sampling.</p>
</td></tr>
<tr><td><code id="make_quad_form_matrix_+3A_aux_vars">aux_vars</code></td>
<td>
<p>Required if <code>variance_estimator</code> equals <code>"Deville-Tille"</code>.
A matrix of auxiliary variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The matrix of the quadratic form representing the variance estimator.
</p>


<h3>Variance Estimators</h3>

<p>See <a href="#topic+variance-estimators">variance-estimators</a> for a
description of each variance estimator.
</p>


<h3>Arguments required for each variance estimator</h3>

<p>Below are the arguments that are required or optional for each variance estimator.</p>

<table>
<tr>
 <td style="text-align: left;">
   variance_estimator </td><td style="text-align: right;"> probs </td><td style="text-align: right;"> joint_probs </td><td style="text-align: right;"> cluster_ids </td><td style="text-align: right;"> strata_ids </td><td style="text-align: right;"> strata_pop_sizes </td><td style="text-align: right;"> sort_order </td><td style="text-align: right;"> aux_vars </td>
</tr>
<tr>
 <td style="text-align: left;">
   Stratified Multistage SRS </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   Ultimate Cluster </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Optional </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   SD1 </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Optional </td><td style="text-align: right;"> Optional </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   SD2 </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Optional </td><td style="text-align: right;"> Optional </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   Deville-1 </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Optional </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   Deville-2 </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Optional </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   Deville-Tille </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;"> Optional </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td>
</tr>
<tr>
 <td style="text-align: left;">
   Yates-Grundy </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   Horvitz-Thompson </td><td style="text-align: right;">  </td><td style="text-align: right;"> Required </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td><td style="text-align: right;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>See Also</h3>

<p>See <a href="#topic+variance-estimators">variance-estimators</a> for a
description of each variance estimator.
</p>
<p>For a two-phase design, the function
<a href="#topic+make_twophase_quad_form">make_twophase_quad_form</a> combines
the quadratic form matrix from each phase.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example 1: The Horvitz-Thompson Estimator
  library(survey)
  data("election", package = "survey")

  ht_quad_form_matrix &lt;- make_quad_form_matrix(variance_estimator = "Horvitz-Thompson",
                                               joint_probs = election_jointprob)
  ##_ Produce variance estimate
  wtd_y &lt;- as.matrix(election_pps$wt * election_pps$Bush)
  t(wtd_y) %*% ht_quad_form_matrix %*% wtd_y

  ##_ Compare against result from 'survey' package
  svytotal(x = ~ Bush,
           design = svydesign(data=election_pps,
                              variance = "HT",
                              pps = ppsmat(election_jointprob),
                              ids = ~ 1, fpc = ~ p)) |&gt; vcov()

# Example 2: Stratified multistage Sample ----

  data("mu284", package = 'survey')
  multistage_srswor_design &lt;- svydesign(data = mu284,
                                        ids = ~ id1 + id2,
                                        fpc = ~ n1 + n2)

  multistage_srs_quad_form &lt;- make_quad_form_matrix(
    variance_estimator = "Stratified Multistage SRS",
    cluster_ids = mu284[,c('id1', 'id2')],
    strata_ids = matrix(1, nrow = nrow(mu284), ncol = 2),
    strata_pop_sizes = mu284[,c('n1', 'n2')]
  )

  wtd_y &lt;- as.matrix(weights(multistage_srswor_design) * mu284$y1)
  t(wtd_y) %*% multistage_srs_quad_form %*% wtd_y

  ##_ Compare against result from 'survey' package
  svytotal(x = ~ y1, design = multistage_srswor_design) |&gt; vcov()

# Example 3: Successive-differences estimator ----

  data('library_stsys_sample', package = 'svrep')

  sd1_quad_form &lt;- make_quad_form_matrix(
    variance_estimator = 'SD1',
    cluster_ids = library_stsys_sample[,'FSCSKEY',drop=FALSE],
    strata_ids = library_stsys_sample[,'SAMPLING_STRATUM',drop=FALSE],
    strata_pop_sizes = library_stsys_sample[,'STRATUM_POP_SIZE',drop=FALSE],
    sort_order = library_stsys_sample[['SAMPLING_SORT_ORDER']]
  )

  wtd_y &lt;- as.matrix(library_stsys_sample[['TOTCIR']] /
                      library_stsys_sample$SAMPLING_PROB)
  wtd_y[is.na(wtd_y)] &lt;- 0

  t(wtd_y) %*% sd1_quad_form %*% wtd_y

# Example 4: Deville estimators ----

 data('library_multistage_sample', package = 'svrep')

 deville_quad_form &lt;- make_quad_form_matrix(
     variance_estimator = 'Deville-1',
     cluster_ids = library_multistage_sample[,c("PSU_ID", "SSU_ID")],
     strata_ids = cbind(rep(1, times = nrow(library_multistage_sample)),
                        library_multistage_sample$PSU_ID),
     probs = library_multistage_sample[,c("PSU_SAMPLING_PROB",
                                          "SSU_SAMPLING_PROB")]
 )

## End(Not run)
</code></pre>

<hr>
<h2 id='make_rwyb_bootstrap_weights'>Create bootstrap replicate weights for a general survey design,
using the Rao-Wu-Yue-Beaumont bootstrap method</h2><span id='topic+make_rwyb_bootstrap_weights'></span>

<h3>Description</h3>

<p>Creates bootstrap replicate weights for a multistage stratified sample design
using the method of Beaumont and Émond (2022), which is a generalization of the Rao-Wu-Yue bootstrap. <br /> <br />
The design may have different sampling methods used at different stages.
Each stage of sampling may potentially use unequal probabilities (with or without replacement)
and may potentially use Poisson sampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_rwyb_bootstrap_weights(
  num_replicates = 100,
  samp_unit_ids,
  strata_ids,
  samp_unit_sel_probs,
  samp_method_by_stage = rep("PPSWOR", times = ncol(samp_unit_ids)),
  allow_final_stage_singletons = TRUE,
  output = "weights"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_num_replicates">num_replicates</code></td>
<td>
<p>Positive integer giving the number of bootstrap replicates to create</p>
</td></tr>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_samp_unit_ids">samp_unit_ids</code></td>
<td>
<p>Matrix or data frame of sampling unit IDs for each stage of sampling</p>
</td></tr>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_strata_ids">strata_ids</code></td>
<td>
<p>Matrix or data frame of strata IDs for each sampling unit at each stage of sampling</p>
</td></tr>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_samp_unit_sel_probs">samp_unit_sel_probs</code></td>
<td>
<p>Matrix or data frame of selection probabilities for each sampling unit
at each stage of sampling.</p>
</td></tr>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_samp_method_by_stage">samp_method_by_stage</code></td>
<td>
<p>A vector with length equal to the number of stages of sampling,
corresponding to the number of columns in <code>samp_unit_ids</code>.
This describes the method of sampling used at each stage.
Each element should be one of the following: <br />
</p>

<ul>
<li><p> &quot;SRSWOR&quot; - Simple random sampling, without replacement
</p>
</li>
<li><p> &quot;SRSWR&quot; - Simple random sampling, with replacement
</p>
</li>
<li><p> &quot;PPSWOR&quot; - Unequal probabilities of selection, without replacement
</p>
</li>
<li><p> &quot;PPSWR&quot; - Unequal probabilities of selection, with replacement
</p>
</li>
<li><p> &quot;Poisson&quot; -  Poisson sampling: each sampling unit is selected into the sample at most once, with potentially different probabilities of inclusion for each sampling unit.
</p>
</li></ul>
</td></tr>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_allow_final_stage_singletons">allow_final_stage_singletons</code></td>
<td>
<p>Logical value indicating whether to allow
non-certainty singleton strata at the final sampling stage (rather than throw an error message). <br />
If <code>TRUE</code>, the sampling unit in a non-certainty singleton stratum will have its final-stage adjustment factor
calculated as if it was selected with certainty at the final stage (i.e., its adjustment factor will be 1),
and then its final bootstrap weight will be calculated by combining this adjustment factor
with its final-stage selection probability.</p>
</td></tr>
<tr><td><code id="make_rwyb_bootstrap_weights_+3A_output">output</code></td>
<td>
<p>Either <code>"weights"</code> (the default) or <code>"factors"</code>.
Specifying <code>output = "factors"</code> returns a matrix of replicate adjustment factors which can later be multiplied by
the full-sample weights to produce a matrix of replicate weights. Specifying <code>output = "weights"</code>
returns the matrix of replicate weights, where the full-sample weights are inferred using <code>samp_unit_sel_probs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Beaumont and Émond (2022) describe a general algorithm for forming bootstrap replicate weights
for multistage stratified samples, based on the method of Rao-Wu-Yue, with extensions
to sampling without replacement and use of unequal probabilities of selection
(i.e., sampling with probability proportional to size) as well as Poisson sampling. These methods
are guaranteed to produce nonnegative replicate weights and provide design-unbiased and design-consistent variance estimates for totals,
for designs where sampling uses one or more of the following methods:
</p>

<ul>
<li><p> &quot;SRSWOR&quot; - Simple random sampling, without replacement
</p>
</li>
<li><p> &quot;SRSWR&quot; - Simple random sampling, with replacement
</p>
</li>
<li><p> &quot;PPSWR&quot; - Unequal probabilities of selection, with replacement
</p>
</li>
<li><p> &quot;Poisson&quot; -  Poisson sampling: each sampling unit is selected into the sample at most once, with potentially different probabilities of inclusion for each sampling unit.
</p>
</li></ul>

<p>For designs where at least one stage's strata have sampling without replacement with unequal probabilities of selection (&quot;PPSWOR&quot;),
the bootstrap method of Beaumont and Émond (2022) is guaranteed to produce nonnegative weights, but is not design-unbiased,
since the method only approximates the joint selection probabilities which would be needed for unbiased estimation.
<br /> <br />
Unless any stages use simple random sampling without replacement, the resulting bootstrap replicate weights
are guaranteed to all be strictly positive, which may be useful for calibration or analyses of domains with small sample sizes.
If any stages use simple random sampling without replacement, it is possible for some replicate weights to be zero.
<br /> <br />
If there is survey nonresponse, it may be useful to represent the response/nonresponse as an additional
stage of sampling, where sampling is conducted with Poisson sampling
where each unit's &quot;selection probability&quot; at that stage is its response propensity (which typically has to be estimated).
</p>


<h3>Value</h3>

<p>A matrix of with the same number of rows as <code>samp_unit_ids</code>
and the number of columns equal to the value of the argument <code>num_replicates</code>.
Specifying <code>output = "factors"</code> returns a matrix of replicate adjustment factors which can later be multiplied by
the full-sample weights to produce a matrix of replicate weights.
Specifying <code>output = "weights"</code> returns the matrix of replicate weights,
where the full-sample weights are inferred using <code>samp_unit_sel_probs</code>.
</p>


<h3>References</h3>

<p>Beaumont, J.-F.; Émond, N. (2022).
&quot;A Bootstrap Variance Estimation Method for Multistage Sampling and Two-Phase Sampling When Poisson Sampling Is Used at the Second Phase.&quot;
<strong>Stats</strong>, <em>5</em>: 339–357.
https://doi.org/10.3390/stats5020019
</p>
<p>Rao, J.N.K.; Wu, C.F.J.; Yue, K. (1992).
&quot;Some recent work on resampling methods for complex surveys.&quot;
<strong>Surv. Methodol.</strong>, <em>18</em>: 209–217.
</p>


<h3>See Also</h3>

<p>If the survey design can be accurately represented using <code><a href="survey.html#topic+svydesign">svydesign</a></code>,
then it is easier to simply use <code><a href="#topic+as_bootstrap_design">as_bootstrap_design</a></code> with argument <code>type = "Rao-Wu-Yue-Beaumont"</code>.
</p>
<p>Use <code><a href="#topic+estimate_boot_reps_for_target_cv">estimate_boot_reps_for_target_cv</a></code> to help choose the number of bootstrap replicates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 library(survey)

 # Example 1: A multistage sample with two stages of SRSWOR

     ## Load an example dataset from a multistage sample, with two stages of SRSWOR
     data("mu284", package = 'survey')
     multistage_srswor_design &lt;- svydesign(data = mu284,
                                           ids = ~ id1 + id2,
                                           fpc = ~ n1 + n2)

     ## Create bootstrap replicate weights
     set.seed(2022)
     bootstrap_replicate_weights &lt;- make_rwyb_bootstrap_weights(
       num_replicates = 5000,
       samp_unit_ids = multistage_srswor_design$cluster,
       strata_ids = multistage_srswor_design$strata,
       samp_unit_sel_probs = multistage_srswor_design$fpc$sampsize /
                             multistage_srswor_design$fpc$popsize,
       samp_method_by_stage = c("SRSWOR", "SRSWOR")
     )

     ## Create a replicate design object with the survey package
     bootstrap_rep_design &lt;- svrepdesign(
       data = multistage_srswor_design$variables,
       repweights = bootstrap_replicate_weights,
       weights = weights(multistage_srswor_design, type = "sampling"),
       type = "bootstrap"
     )

     ## Compare std. error estimates from bootstrap versus linearization
     data.frame(
       'Statistic' = c('total', 'mean', 'median'),
       'SE (bootstrap)' = c(SE(svytotal(x = ~ y1, design = bootstrap_rep_design)),
                            SE(svymean(x = ~ y1, design = bootstrap_rep_design)),
                            SE(svyquantile(x = ~ y1, quantile = 0.5,
                                           design = bootstrap_rep_design))),
       'SE (linearization)' = c(SE(svytotal(x = ~ y1, design = multistage_srswor_design)),
                                SE(svymean(x = ~ y1, design = multistage_srswor_design)),
                                SE(svyquantile(x = ~ y1, quantile = 0.5,
                                               design = multistage_srswor_design))),
       check.names = FALSE
     )

 # Example 2: A single-stage sample selected with unequal probabilities, without replacement

     ## Load an example dataset of U.S. counties states with 2004 Presidential vote counts
     data("election", package = 'survey')
     pps_wor_design &lt;- svydesign(data = election_pps,
                                 pps = "overton",
                                 fpc = ~ p, # Inclusion probabilities
                                 ids = ~ 1)

     ## Create bootstrap replicate weights
     set.seed(2022)
     bootstrap_replicate_weights &lt;- make_rwyb_bootstrap_weights(
       num_replicates = 5000,
       samp_unit_ids = pps_wor_design$cluster,
       strata_ids = pps_wor_design$strata,
       samp_unit_sel_probs = pps_wor_design$prob,
       samp_method_by_stage = c("PPSWOR")
     )

     ## Create a replicate design object with the survey package
     bootstrap_rep_design &lt;- svrepdesign(
       data = pps_wor_design$variables,
       repweights = bootstrap_replicate_weights,
       weights = weights(pps_wor_design, type = "sampling"),
       type = "bootstrap"
     )

     ## Compare std. error estimates from bootstrap versus linearization
     data.frame(
       'Statistic' = c('total', 'mean'),
       'SE (bootstrap)' = c(SE(svytotal(x = ~ Bush, design = bootstrap_rep_design)),
                            SE(svymean(x = ~ I(Bush/votes),
                                       design = bootstrap_rep_design))),
       'SE (Overton\'s PPS approximation)' = c(SE(svytotal(x = ~ Bush,
                                                           design = pps_wor_design)),
                                               SE(svymean(x = ~ I(Bush/votes),
                                                          design = pps_wor_design))),
       check.names = FALSE
     )

## End(Not run)
</code></pre>

<hr>
<h2 id='make_sd_matrix'>Create a quadratic form's matrix to represent a successive-difference variance estimator</h2><span id='topic+make_sd_matrix'></span>

<h3>Description</h3>

<p>A successive-difference variance estimator can be represented
as a quadratic form. This function determines the matrix of the quadratic form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_sd_matrix(n, f = 0, type = "SD1")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_sd_matrix_+3A_n">n</code></td>
<td>
<p>Number of rows or columns for the matrix</p>
</td></tr>
<tr><td><code id="make_sd_matrix_+3A_f">f</code></td>
<td>
<p>A single number between <code>0</code> and <code>1</code>,
representing the sampling fraction. Default value is <code>0</code>.</p>
</td></tr>
<tr><td><code id="make_sd_matrix_+3A_type">type</code></td>
<td>
<p>Either &quot;SD1&quot; or &quot;SD2&quot;. See the &quot;Details&quot; section for definitions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Ash (2014) describes each estimator as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{v}_{SD1}(\hat{Y}) = (1-f) \frac{n}{2(n-1)} \sum_{k=2}^n\left(\breve{y}_k-\breve{y}_{k-1}\right)^2
</code>
</p>

<p style="text-align: center;"><code class="reqn">
  \hat{v}_{SD2}(\hat{Y}) = \frac{1}{2}(1-f)\left[\sum_{k=2}^n\left(\breve{y}_k-\breve{y}_{k-1}\right)^2+\left(\breve{y}_n-\breve{y}_1\right)^2\right]
</code>
</p>

<p>where <code class="reqn">\breve{y}_k</code> is the weighted value <code class="reqn">y_k/\pi_k</code> of unit <code class="reqn">k</code>
with selection probability <code class="reqn">\pi_k</code>, and <code class="reqn">f</code> is the sampling fraction <code class="reqn">\frac{n}{N}</code>.
</p>


<h3>Value</h3>

<p>A matrix of dimension <code>n</code>
</p>


<h3>References</h3>

<p>Ash, S. (2014). &quot;<em>Using successive difference replication for estimating variances</em>.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 40(1), 47–59.
</p>

<hr>
<h2 id='make_srswor_matrix'>Create a quadratic form's matrix to represent the basic variance estimator
for a total under simple random sampling without replacement</h2><span id='topic+make_srswor_matrix'></span>

<h3>Description</h3>

<p>The usual variance estimator for simple random sampling without replacement
can be represented as a quadratic form.
This function determines the matrix of the quadratic form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_srswor_matrix(n, f = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_srswor_matrix_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="make_srswor_matrix_+3A_f">f</code></td>
<td>
<p>A single number between <code>0</code> and <code>1</code>,
representing the sampling fraction. Default value is <code>0</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The basic variance estimator of a total for simple random sampling without replacement is as follows:
</p>
<p style="text-align: center;"><code class="reqn">
\hat{v}(\hat{Y}) = (1 - f)\frac{n}{n - 1} \sum_{i=1}^{n} (y_i - \bar{y})^2
</code>
</p>

<p>where <code class="reqn">f</code> is the sampling fraction <code class="reqn">\frac{n}{N}</code>. <br /> <br />
If <code class="reqn">f=0</code>, then the matrix of the quadratic form has all non-diagonal elements equal to <code class="reqn">-(n-1)^{-1}</code>,
and all diagonal elements equal to <code class="reqn">1</code>. If <code class="reqn">f &gt; 0</code>, then each element
is multiplied by <code class="reqn">(1-f)</code>. <br /> <br />
If <code class="reqn">n=1</code>, then this function returns a <code class="reqn">1 \times 1</code> matrix whose sole element equals <code class="reqn">0</code>
(essentially treating the sole sampled unit as a selection made with probability <code class="reqn">1</code>).
</p>


<h3>Value</h3>

<p>A symmetric matrix of dimension <code>n</code>
</p>

<hr>
<h2 id='make_twophase_quad_form'>Combine quadratic forms from each phase of a two phase design</h2><span id='topic+make_twophase_quad_form'></span>

<h3>Description</h3>

<p>This function combines quadratic forms from each phase of a two phase design,
so that the combined variance of the entire two-phase sampling design can be estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_twophase_quad_form(
  sigma_1,
  sigma_2,
  phase_2_joint_probs,
  ensure_psd = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_twophase_quad_form_+3A_sigma_1">sigma_1</code></td>
<td>
<p>The quadratic form for the first phase variance estimator,
subsetted to only include cases selected in the phase two sample.</p>
</td></tr>
<tr><td><code id="make_twophase_quad_form_+3A_sigma_2">sigma_2</code></td>
<td>
<p>The quadratic form for the second phase variance estimator,
conditional on the selection of the first phase sample.</p>
</td></tr>
<tr><td><code id="make_twophase_quad_form_+3A_phase_2_joint_probs">phase_2_joint_probs</code></td>
<td>
<p>The matrix of conditional joint
inclusion probabilities for the second phase, given the selected
first phase sample.</p>
</td></tr>
<tr><td><code id="make_twophase_quad_form_+3A_ensure_psd">ensure_psd</code></td>
<td>
<p>If <code>TRUE</code> (the default), ensures
that the result is a positive semidefinite matrix. This
is necessary if the quadratic form is used as an input for
replication methods such as the generalized bootstrap.
For details, see the help section entitled
&quot;Ensuring the Result is Positive Semidefinite&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A quadratic form matrix that can be used to estimate
the sampling variance from a two-phase sample design.
</p>


<h3>Statistical Details</h3>

<p>The two-phase variance estimator has a quadratic form matrix <code class="reqn">\boldsymbol{\Sigma}_{ab}</code> given by:
</p>
<p style="text-align: center;"><code class="reqn">
  \boldsymbol{\Sigma}_{ab} = {W}^{-1}_b(\boldsymbol{\Sigma}_{a^\prime} \circ D_b ){W}^{-1}_b + \boldsymbol{\Sigma}_b
</code>
</p>

<p>The first term estimates the variance contribution from the first phase of sampling,
while the second term estimates the variance contribution from the second phase of sampling. <br />
</p>
<p>The full quadratic form of the variance estimator is:
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{t_y}) = \breve{\breve{y^{'}}} \boldsymbol{\Sigma}_{ab} \breve{\breve{y}}
</code>
</p>

<p>where the weighted variable <code class="reqn">\breve{\breve{y}}_k = \frac{y_k}{\pi_{ak}\pi_{bk}}</code>,
is formed using the first phase inclusion probability, denoted <code class="reqn">\pi_{ak}</code>, and
the conditional second phase inclusion probability (given the selected first phase sample),
denoted <code class="reqn">\pi_{bk}</code>. <br />
</p>
<p>The notation for this estimator is as follows: <br />
</p>

<ul>
<li> <p><code class="reqn">n_a</code> denotes the first phase sample size.
</p>
</li>
<li> <p><code class="reqn">n_b</code> denotes the second phase sample size.
</p>
</li>
<li> <p><code class="reqn">\boldsymbol{\Sigma}_a</code> denotes the matrix of dimension <code class="reqn">n_a \times n_a</code>
representing the quadratic form for the variance estimator
used for the full first-phase design.
</p>
</li>
<li> <p><code class="reqn">\boldsymbol{\Sigma}_{a^\prime}</code> denotes the matrix of dimension <code class="reqn">n_b \times n_b</code>
formed by subsetting the rows and columns of <code class="reqn">\boldsymbol{\Sigma}_a</code> to only include
cases selected in the second-phase sample.
</p>
</li>
<li> <p><code class="reqn">\boldsymbol{\Sigma}_{b}</code> denotes
the matrix of dimension <code class="reqn">n_b \times n_b</code> representing the Horvitz-Thompson
estimator of variance for the second-phase sample, conditional on the selected
first-phase sample.
</p>
</li>
<li> <p><code class="reqn">\boldsymbol{D}_b</code> denotes the <code class="reqn">n_b \times n_b</code> matrix of weights formed by the inverses of
the second-phase joint inclusion probabilities, with element <code class="reqn">kl</code> equal to <code class="reqn">\pi_{bkl}^{-1}</code>,
where <code class="reqn">\pi_{bkl}</code> is the conditional probability that units <code class="reqn">k</code> and <code class="reqn">l</code> are included
in the second-phase sample, given the selected first-phase sample. Note that this
matrix will often not be positive semidefinite, and so the two-phase variance estimator
has a quadratic form which is not necessarily positive semidefinite.
</p>
</li>
<li> <p><code class="reqn">\boldsymbol{W}_b</code> denotes the diagonal <code class="reqn">n_b \times n_b</code> matrix
whose <code class="reqn">k</code>-th diagonal entry is the second-phase weight <code class="reqn">\pi_{bk}^{-1}</code>,
where <code class="reqn">\pi_{bk}</code> is the conditional probability that unit <code class="reqn">k</code>
is included in the second-phase sample, given the selected first-phase sample.
</p>
</li></ul>



<h3>Ensuring the Result is Positive Semidefinite</h3>

<p>Note that the matrix <code class="reqn">(\boldsymbol{\Sigma}_{a^\prime} \circ D_b )</code> may not be
positive semidefinite, since the matrix <code class="reqn">D_b</code> is not guaranteed to be positive semidefinite.
If <code class="reqn">(\boldsymbol{\Sigma}_{a^\prime} \circ D_b )</code> is found not to be positive semidefinite,
then it is approximated by the nearest positive semidefinite matrix in the Frobenius norm,
using the method of Higham (1988). <br /> <br />
This approximation is discussed by Beaumont and Patak (2012) in the context
of forming replicate weights for two-phase samples. The authors argue that
this approximation should lead to only a small overestimation of variance. <br /> <br />
Since <code class="reqn">(\boldsymbol{\Sigma}_{a^\prime} \circ D_b )</code>
is a real, symmetric matrix, this is equivalent to &quot;zeroing out&quot; negative eigenvalues.
To be more precise, denote <code class="reqn">A=(\boldsymbol{\Sigma}_{a^\prime} \circ D_b )</code>.
Then we can form the spectral decomposition <code class="reqn">A=\Gamma \Lambda \Gamma^{\prime}</code>, where <code class="reqn">\Lambda</code> is the diagonal matrix
whose entries are eigenvalues of <code class="reqn">A</code>. The method of Higham (1988)
is to  approximate
<code class="reqn">A</code> with <code class="reqn">\tilde{A} = \Gamma \Lambda_{+} \Gamma^{\prime}</code>,
where the <code class="reqn">ii</code>-th entry of <code class="reqn">\Lambda_{+}</code> is <code class="reqn">\max(\Lambda_{ii}, 0)</code>.
</p>


<h3>References</h3>

<p>See Section 7.5 of Tillé (2020) or Section 9.3 of Särndal, Swensson, and Wretman (1992)
for an overview of variance estimation for two-phase sampling. In the case where
the Horvitz-Thompson variance estimator is used for both phases, the method used in this function
is equivalent to equation (9.3.8) of Särndal, Swensson, and Wretman (1992)
and equation (7.7) of Tillé (2020). However, this function can be used
for any combination of first-phase and second-phase variance estimators,
provided that the joint inclusion probabilities from the second-phase design
are available and are all nonzero.
<br /> <br />
</p>

<ul>
<li><p> Beaumont, Jean-François, and Zdenek Patak. (2012). “On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling: Generalized Bootstrap for Sample Surveys.”
International Statistical Review 80 (1): 127–48.
<br /> <br />
</p>
</li>
<li><p> Higham, N. J. (1988). &quot;<em>Computing a nearest symmetric positive semidefinite matrix.</em>&quot; Linear Algebra and Its Applications, 103, 103–118.
<br /> <br />
</p>
</li>
<li><p> Särndal, C.-E., Swensson, B., &amp; Wretman, J. (1992). &quot;<em>Model Assisted Survey Sampling</em>.&quot; Springer New York.
<br /> <br />
</p>
</li>
<li><p> Tillé, Y. (2020). &quot;<em>Sampling and estimation from finite populations</em>.&quot; (I. Hekimi, Trans.). Wiley.
</p>
</li></ul>



<h3>See Also</h3>

<p>For each phase of sampling, the function
<a href="#topic+make_quad_form_matrix">make_quad_form_matrix</a> can be used to create
the appropriate quadratic form matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## ---------------------- Example 1 ------------------------##
## First phase is a stratified multistage sample            ##
## Second phase is a simple random sample                   ##
##----------------------------------------------------------##
data('library_multistage_sample', package = 'svrep')

# Load first-phase sample
  twophase_sample &lt;- library_multistage_sample

# Select second-phase sample
  set.seed(2022)

  twophase_sample[['SECOND_PHASE_SELECTION']] &lt;- sampling::srswor(
    n = 100,
    N = nrow(twophase_sample)
  ) |&gt; as.logical()

# Declare survey design
  twophase_design &lt;- twophase(
    method = "full",
    data = twophase_sample,
    # Identify the subset of first-phase elements
    # which were selected into the second-phase sample
    subset = ~ SECOND_PHASE_SELECTION,
    # Describe clusters, probabilities, and population sizes
    # at each phase of sampling
    id = list(~ PSU_ID + SSU_ID,
              ~ 1),
    probs = list(~ PSU_SAMPLING_PROB + SSU_SAMPLING_PROB,
                 NULL),
    fpc = list(~ PSU_POP_SIZE + SSU_POP_SIZE,
               NULL)
  )

# Get quadratic form matrix for the first phase design
  first_phase_sigma &lt;- get_design_quad_form(
    design = twophase_design$phase1$full,
    variance_estimator = "Stratified Multistage SRS"
  )

# Subset to only include cases sampled in second phase

  first_phase_sigma &lt;- first_phase_sigma[twophase_design$subset,
                                         twophase_design$subset]

# Get quadratic form matrix for the second-phase design
  second_phase_sigma &lt;- get_design_quad_form(
    design = twophase_design$phase2,
    variance_estimator = "Ultimate Cluster"
  )

# Get second-phase joint probabilities
  n &lt;- twophase_design$phase2$fpc$sampsize[1,1]
  N &lt;- twophase_design$phase2$fpc$popsize[1,1]

  second_phase_joint_probs &lt;- Matrix::Matrix((n/N)*((n-1)/(N-1)),
                                     nrow = n, ncol = n)
  diag(second_phase_joint_probs) &lt;- rep(n/N, times = n)

# Get quadratic form for entire two-phase variance estimator
  twophase_quad_form &lt;- make_twophase_quad_form(
   sigma_1 = first_phase_sigma,
   sigma_2 = second_phase_sigma,
   phase_2_joint_probs = second_phase_joint_probs
 )

 # Use for variance estimation

   rep_factors &lt;- make_gen_boot_factors(
     Sigma = twophase_quad_form,
     num_replicates = 500
   )

   library(survey)

   combined_weights &lt;- 1/twophase_design$prob

   twophase_rep_design &lt;- svrepdesign(
     data = twophase_sample |&gt;
       subset(SECOND_PHASE_SELECTION),
     type = 'other',
     repweights = rep_factors,
     weights = combined_weights,
     combined.weights = FALSE,
     scale = attr(rep_factors, 'scale'),
     rscales = attr(rep_factors, 'rscales')
   )

   svymean(x = ~ LIBRARIA, design = twophase_rep_design)


## ---------------------- Example 2 ------------------------##
## First phase is a stratified systematic sample            ##
## Second phase is nonresponse, modeled as Poisson sampling ##
##----------------------------------------------------------##

data('library_stsys_sample', package = 'svrep')

# Determine quadratic form for full first-phase sample variance estimator

  full_phase1_quad_form &lt;- make_quad_form_matrix(
    variance_estimator = "SD2",
    cluster_ids = library_stsys_sample[,'FSCSKEY',drop=FALSE],
    strata_ids = library_stsys_sample[,'SAMPLING_STRATUM',drop=FALSE],
    strata_pop_sizes = library_stsys_sample[,'STRATUM_POP_SIZE',drop=FALSE],
    sort_order = library_stsys_sample$SAMPLING_SORT_ORDER
  )

# Identify cases included in phase two sample
# (in this example, respondents)
  phase2_inclusion &lt;- (
    library_stsys_sample$RESPONSE_STATUS == "Survey Respondent"
  )
  phase2_sample &lt;- library_stsys_sample[phase2_inclusion,]

# Estimate response propensities

  response_propensities &lt;- glm(
    data = library_stsys_sample,
    family = quasibinomial('logit'),
    formula = phase2_inclusion ~ 1,
    weights = 1/library_stsys_sample$SAMPLING_PROB
  ) |&gt;
    predict(type = "response",
            newdata = phase2_sample)

# Estimate conditional joint inclusion probabilities for second phase

  phase2_joint_probs &lt;- outer(response_propensities, response_propensities)
  diag(phase2_joint_probs) &lt;- response_propensities

# Determine quadratic form for variance estimator of second phase
# (Horvitz-Thompson estimator for nonresponse modeled as Poisson sampling)

  phase2_quad_form &lt;- make_quad_form_matrix(
    variance_estimator = "Horvitz-Thompson",
    joint_probs = phase2_joint_probs
  )

# Create combined quadratic form for entire design

 twophase_quad_form &lt;- make_twophase_quad_form(
   sigma_1 = full_phase1_quad_form[phase2_inclusion, phase2_inclusion],
   sigma_2 = phase2_quad_form,
   phase_2_joint_probs = phase2_joint_probs
 )

 combined_weights &lt;- 1/(phase2_sample$SAMPLING_PROB * response_propensities)

# Use for variance estimation

  rep_factors &lt;- make_gen_boot_factors(
    Sigma = twophase_quad_form,
    num_replicates = 500
  )

  library(survey)

  twophase_rep_design &lt;- svrepdesign(
    data = phase2_sample,
    type = 'other',
    repweights = rep_factors,
    weights = combined_weights,
    combined.weights = FALSE,
    scale = attr(rep_factors, 'scale'),
    rscales = attr(rep_factors, 'rscales')
  )

  svymean(x = ~ LIBRARIA, design = twophase_rep_design)

## End(Not run)
</code></pre>

<hr>
<h2 id='redistribute_weights'>Redistribute weight from one group to another</h2><span id='topic+redistribute_weights'></span>

<h3>Description</h3>

<p>Redistributes weight from one group to another: for example, from non-respondents to respondents.
Redistribution is conducted for the full-sample weights as well as each set of replicate weights.
This can be done separately for each combination of a set of grouping variables, for example to implement a nonresponse weighting class adjustment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>redistribute_weights(design, reduce_if, increase_if, by)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="redistribute_weights_+3A_design">design</code></td>
<td>
<p>A survey design object, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="redistribute_weights_+3A_reduce_if">reduce_if</code></td>
<td>
<p>An expression indicating which cases should have their weights set to zero.
Must evaluate to a logical vector with only values of TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="redistribute_weights_+3A_increase_if">increase_if</code></td>
<td>
<p>An expression indicating which cases should have their weights increased.
Must evaluate to a logical vector with only values of TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="redistribute_weights_+3A_by">by</code></td>
<td>
<p>(Optional) A character vector with the names of variables used to group the redistribution of weights.
For example, if the data include variables named <code>"stratum"</code> and <code>"wt_class"</code>, one could specify <code>by = c("stratum", "wt_class")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The survey design object, but with updated full-sample weights and updated replicate weights.
The resulting survey design object always has its value of <code>combined.weights</code> set to <code>TRUE</code>.
</p>


<h3>References</h3>

<p>See Chapter 2 of Heeringa, West, and Berglund (2017) or Chapter 13 of Valliant, Dever, and Kreuter (2018)
for an overview of nonresponse adjustment methods based on redistributing weights.
</p>
<p>- Heeringa, S., West, B., Berglund, P. (2017). Applied Survey Data Analysis, 2nd edition. Boca Raton, FL: CRC Press.
&quot;Applied Survey Data Analysis, 2nd edition.&quot; Boca Raton, FL: CRC Press.
</p>
<p>- Valliant, R., Dever, J., Kreuter, F. (2018).
&quot;Practical Tools for Designing and Weighting Survey Samples, 2nd edition.&quot; New York: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Load example data
suppressPackageStartupMessages(library(survey))
data(api)

dclus1 &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1$variables$response_status &lt;- sample(x = c("Respondent", "Nonrespondent",
                                                 "Ineligible", "Unknown eligibility"),
                                           size = nrow(dclus1),
                                           replace = TRUE)
rep_design &lt;- as.svrepdesign(dclus1)

# Adjust weights for cases with unknown eligibility
ue_adjusted_design &lt;- redistribute_weights(
    design = rep_design,
    reduce_if = response_status %in% c("Unknown eligibility"),
    increase_if = !response_status %in% c("Unknown eligibility"),
    by = c("stype")
)

# Adjust weights for nonresponse
nr_adjusted_design &lt;- redistribute_weights(
    design = ue_adjusted_design,
    reduce_if = response_status %in% c("Nonrespondent"),
    increase_if = response_status == "Respondent",
    by = c("stype")
)
</code></pre>

<hr>
<h2 id='rescale_reps'>Rescale replicate factors</h2><span id='topic+rescale_reps'></span>

<h3>Description</h3>

<p>Rescale replicate factors.
The main application of this rescaling is to ensure
that all replicate weights are strictly positive.
</p>
<p>Note that this rescaling has no impact on variance estimates for totals (or other linear statistics),
but variance estimates for nonlinear statistics will be affected by the rescaling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rescale_reps(x, tau = NULL, min_wgt = 0.01, digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rescale_reps_+3A_x">x</code></td>
<td>
<p>Either a replicate survey design object,
or a numeric matrix of replicate weights.</p>
</td></tr>
<tr><td><code id="rescale_reps_+3A_tau">tau</code></td>
<td>
<p>Either a single positive number, or <code>NULL</code>. 
This is the rescaling constant <code class="reqn">\tau</code> used in the transformation 
<code class="reqn">\frac{w + \tau - 1}{\tau}</code>,
where <code class="reqn">w</code> is the original weight. <br />
If <code>tau=NULL</code> or is left unspecified, 
then the argument <code>min_wgt</code> should be used instead,
in which case, <code class="reqn">\tau</code> is automatically set to the smallest value needed to rescale
the replicate weights such that they are all at least <code>min_wgt</code>.</p>
</td></tr>
<tr><td><code id="rescale_reps_+3A_min_wgt">min_wgt</code></td>
<td>
<p>Should only be used if <code>tau=NULL</code> or <code>tau</code> is left unspecified. 
Specifies the minimum acceptable value for the rescaled weights,
which will be used to automatically determine the value <code class="reqn">\tau</code> used
in the transformation <code class="reqn">\frac{w + \tau - 1}{\tau}</code>,
where <code class="reqn">w</code> is the original weight.
Must be at least zero and must be less than one.</p>
</td></tr>
<tr><td><code id="rescale_reps_+3A_digits">digits</code></td>
<td>
<p>Only used if the argument <code>min_wgt</code> is used. 
Specifies the number of decimal places
to use for choosing <code>tau</code>. Using a smaller number of <code>digits</code>
is useful simply for producing easier-to-read documentation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">\mathbf{A} = \left[ \mathbf{a}^{(1)} \cdots \mathbf{a}^{(b)} \cdots \mathbf{a}^{(B)} \right]</code> denote the <code class="reqn">(n \times B)</code> matrix of replicate adjustment factors.
To eliminate negative adjustment factors, Beaumont and Patak (2012) propose forming a rescaled matrix of nonnegative replicate factors <code class="reqn">\mathbf{A}^S</code> by rescaling each adjustment factor <code class="reqn">a_k^{(b)}</code> as follows:
</p>
<p style="text-align: center;"><code class="reqn">
   a_k^{S,(b)} = \frac{a_k^{(b)} + \tau - 1}{\tau}
 </code>
</p>

<p>where <code class="reqn">\tau \geq 1 - a_k^{(b)} \geq 1</code> for all <code class="reqn">k</code> in <code class="reqn">\left\{ 1,\ldots,n \right\}</code> and all <code class="reqn">b</code> in <code class="reqn">\left\{1, \ldots, B\right\}</code>.
</p>
<p>The value of <code class="reqn">\tau</code> can be set based on the realized adjustment factor matrix <code class="reqn">\mathbf{A}</code> or by choosing <code class="reqn">\tau</code> prior to generating the adjustment factor matrix <code class="reqn">\mathbf{A}</code> so that <code class="reqn">\tau</code> is likely to be large enough to prevent negative adjustment factors.
</p>
<p>If the adjustment factors are rescaled in this manner, it is important to adjust the scale factor used in estimating the variance with the bootstrap replicates.
For example, for bootstrap replicates, the adjustment factor becomes <code class="reqn">\frac{\tau^2}{B}</code> instead of <code class="reqn">\frac{1}{B}</code>.
</p>
<p style="text-align: center;"><code class="reqn">
 \textbf{Prior to rescaling: } v_B\left(\hat{T}_y\right) = \frac{1}{B}\sum_{b=1}^B\left(\hat{T}_y^{*(b)}-\hat{T}_y\right)^2
 </code>
</p>

<p style="text-align: center;"><code class="reqn">
 \textbf{After rescaling: } v_B\left(\hat{T}_y\right) = \frac{\tau^2}{B}\sum_{b=1}^B\left(\hat{T}_y^{S*(b)}-\hat{T}_y\right)^2
</code>
</p>



<h3>Value</h3>

<p>If the input is a numeric matrix, returns the rescaled matrix.
If the input is a replicate survey design object, returns an updated replicate survey design object.
</p>
<p>For a replicate survey design object, results depend on
whether the object has a matrix of replicate factors rather than
a matrix of replicate weights (which are the product of replicate factors and sampling weights).
If the design object has <code>combined.weights=FALSE</code>,
then the replication factors are adjusted.
If the design object has <code>combined.weights=TRUE</code>,
then the replicate weights are adjusted. It is strongly
recommended to only use the rescaling method for replication factors
rather than the weights.
</p>
<p>For a replicate survey design object, the <code>scale</code> element
of the design object will be updated appropriately,
and an element <code>tau</code> will also be added.
If the input is a matrix instead of a survey design object,
the result matrix will have an attribute named <code>tau</code>
which can be retrieved using <code>attr(x, 'tau')</code>.
</p>


<h3>References</h3>

<p>This method was suggested by Fay (1989) for the specific application
of creating replicate factors using his generalized replication method.
Beaumont and Patak (2012) provided an extended discussion on this rescaling
method in the context of rescaling generalized bootstrap replication factors
to avoid negative replicate weights.
</p>
<p>The notation used in this documentation is taken from Beaumont and Patak (2012).
</p>
<p>- Beaumont, Jean-François, and Zdenek Patak. 2012.
&quot;On the Generalized Bootstrap for Sample Surveys with Special Attention to Poisson Sampling: Generalized Bootstrap for Sample Surveys.&quot;
International Statistical Review 80 (1): 127–48.
https://doi.org/10.1111/j.1751-5823.2011.00166.x.
<br /> <br />
- Fay, Robert. 1989. &quot;Theory And Application Of Replicate Weighting For Variance Calculations.&quot;
In, 495–500. Alexandria, VA: American Statistical Association.
http://www.asasrms.org/Proceedings/papers/1989_033.pdf
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example 1: Rescaling a matrix of replicate weights to avoid negative weights

 rep_wgts &lt;- matrix(
   c(1.69742746694909, -0.230761178913411, 1.53333377634192,
     0.0495043413294782, 1.81820367441039, 1.13229198793703,
     1.62482013925955, 1.0866133494029, 0.28856654131668,
     0.581930729719006, 0.91827012312825, 1.49979905894482,
     1.26281337410693, 1.99327362761477, -0.25608700039304),
   nrow = 3, ncol = 5
 )

 rescaled_wgts &lt;- rescale_reps(rep_wgts, min_wgt = 0.01)

 print(rep_wgts)
 print(rescaled_wgts)
 
 # Example 2: Rescaling replicate weights with a specified value of 'tau'
 
 rescaled_wgts &lt;- rescale_reps(rep_wgts, tau = 2)
 print(rescaled_wgts)

 # Example 3: Rescaling replicate weights of a survey design object
 set.seed(2023)
 library(survey)
 data('mu284', package = 'survey')

 ## First create a bootstrap design object
 svy_design_object &lt;- svydesign(
   data = mu284,
   ids = ~ id1 + id2,
   fpc = ~ n1 + n2
 )

 boot_design &lt;- as_gen_boot_design(
   design = svy_design_object,
   variance_estimator = "Stratified Multistage SRS",
   replicates = 5, tau = 1
 )

 ## Rescale the weights
 rescaled_boot_design &lt;- boot_design |&gt;
   rescale_reps(min_wgt = 0.01)

 boot_wgts &lt;- weights(boot_design, "analysis")
 rescaled_boot_wgts &lt;- weights(rescaled_boot_design, 'analysis')

 print(boot_wgts)
 print(rescaled_boot_wgts)
</code></pre>

<hr>
<h2 id='shift_weight'>(Internal function) Shift weight from one set of cases to another</h2><span id='topic+shift_weight'></span>

<h3>Description</h3>

<p>You likely want to use <code>redistribute_weights</code> instead.
The function <code>shift_weight</code> is internal to this package and is used only &quot;under-the-hood.&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shift_weight(wt_set, is_upweight_case, is_downweight_case)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shift_weight_+3A_wt_set">wt_set</code></td>
<td>
<p>A numeric vector of weights</p>
</td></tr>
<tr><td><code id="shift_weight_+3A_is_upweight_case">is_upweight_case</code></td>
<td>
<p>A logical vector indicating cases whose weight should be increased</p>
</td></tr>
<tr><td><code id="shift_weight_+3A_is_downweight_case">is_downweight_case</code></td>
<td>
<p>A logical vector indicating cases whose weight should be decreased</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of adjusted weights, of the same length as <code>wt_set</code>.
</p>

<hr>
<h2 id='shuffle_replicates'>Shuffle the order of replicates in a survey design object</h2><span id='topic+shuffle_replicates'></span>

<h3>Description</h3>

<p>Shuffle the order of replicates in a survey design object.
In other words, the order of the columns of replicate weights is randomly permuted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shuffle_replicates(design)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shuffle_replicates_+3A_design">design</code></td>
<td>
<p>A survey design object, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated survey design object, where the order of the replicates
has been shuffled (i.e., the order has been randomly permuted).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survey)
set.seed(2023)

# Create an example survey design object

  sample_data &lt;- data.frame(
    STRATUM = c(1,1,1,1,2,2,2,2),
    PSU     = c(1,2,3,4,5,6,7,8)
  )

  survey_design &lt;- svydesign(
    data = sample_data,
    strata = ~ STRATUM,
    ids = ~ PSU,
    weights = ~ 1
  )

  rep_design &lt;- survey_design |&gt;
    as_fays_gen_rep_design(variance_estimator = "Ultimate Cluster")

# Inspect replicates before shuffling

  rep_design |&gt; getElement("repweights")

# Inspect replicates after shuffling

  rep_design |&gt;
    shuffle_replicates() |&gt;
    getElement("repweights")
</code></pre>

<hr>
<h2 id='stack_replicate_designs'>Stack replicate designs, combining data and weights into a single object</h2><span id='topic+stack_replicate_designs'></span>

<h3>Description</h3>

<p>Stack replicate designs: combine rows of data, rows of replicate weights, and the respective full-sample weights.
This can be useful when comparing estimates before and after a set of adjustments made to the weights.
Another more delicate application is when combining sets of replicate weights from multiple years of data for a survey, although this must be done carefully based on guidance from a data provider.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stack_replicate_designs(..., .id = "Design_Name")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stack_replicate_designs_+3A_...">...</code></td>
<td>
<p>Replicate-weights survey design objects to combine. These can be supplied in one of two ways. <br />
</p>

<ul>
<li><p> Option 1 - A series of design objects, for example <code>'adjusted' = adjusted_design, 'orig' = orig_design</code>.
</p>
</li>
<li><p> Option 2 - A list object containing design objects, for example  <code>list('nr' = nr_adjusted_design, 'ue' = ue_adjusted_design)</code>.
</p>
</li></ul>

<p>All objects must have the same specifications for <code>type</code>, <code>rho</code>,
<code>mse</code>, <code>scales</code>, and <code>rscales</code>.</p>
</td></tr>
<tr><td><code id="stack_replicate_designs_+3A_.id">.id</code></td>
<td>
<p>A single character value, which becomes the name of a new column of identifiers
created in the output data to link each row to the design from which it was taken. <br />
The labels used for the identifiers are taken from named arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A replicate-weights survey design object, with class <code>svyrep.design</code> and <code>svyrep.stacked</code>.
The resulting survey design object always has its value of <code>combined.weights</code> set to <code>TRUE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Load example data, creating a replicate design object
suppressPackageStartupMessages(library(survey))
data(api)

dclus1 &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1$variables$response_status &lt;- sample(x = c("Respondent", "Nonrespondent",
                                                 "Ineligible", "Unknown eligibility"),
                                           size = nrow(dclus1),
                                           replace = TRUE)
orig_rep_design &lt;- as.svrepdesign(dclus1)

# Adjust weights for cases with unknown eligibility
ue_adjusted_design &lt;- redistribute_weights(
    design = orig_rep_design,
    reduce_if = response_status %in% c("Unknown eligibility"),
    increase_if = !response_status %in% c("Unknown eligibility"),
    by = c("stype")
)

# Adjust weights for nonresponse
nr_adjusted_design &lt;- redistribute_weights(
    design = ue_adjusted_design,
    reduce_if = response_status %in% c("Nonrespondent"),
    increase_if = response_status == "Respondent",
    by = c("stype")
)

# Stack the three designs, using any of the following syntax options
stacked_design &lt;- stack_replicate_designs(orig_rep_design, ue_adjusted_design, nr_adjusted_design,
                                          .id = "which_design")
stacked_design &lt;- stack_replicate_designs('original' = orig_rep_design,
                                          'unknown eligibility adjusted' = ue_adjusted_design,
                                          'nonresponse adjusted' = nr_adjusted_design,
                                          .id = "which_design")
list_of_designs &lt;- list('original' = orig_rep_design,
                        'unknown eligibility adjusted' = ue_adjusted_design,
                        'nonresponse adjusted' = nr_adjusted_design)
stacked_design &lt;- stack_replicate_designs(list_of_designs, .id = "which_design")
</code></pre>

<hr>
<h2 id='subsample_replicates'>Retain only a random subset of the replicates in a design</h2><span id='topic+subsample_replicates'></span>

<h3>Description</h3>

<p>Randomly subsamples the replicates of a survey design object,
to keep only a subset. The scale factor used in estimation is increased
to account for the subsampling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subsample_replicates(design, n_reps)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subsample_replicates_+3A_design">design</code></td>
<td>
<p>A survey design object, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="subsample_replicates_+3A_n_reps">n_reps</code></td>
<td>
<p>The number of replicates to keep after subsampling</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An updated survey design object, where only a random selection
of the replicates has been retained. The overall 'scale' factor for the design
(accessed with <code>design$scale</code>) is increased to account for the sampling of replicates.
</p>


<h3>Statistical Details</h3>

<p>Suppose the initial replicate design has <code class="reqn">L</code> replicates, with
respective constants <code class="reqn">c_k</code> for <code class="reqn">k=1,\dots,L</code> used to estimate variance
with the formula
</p>
<p style="text-align: center;"><code class="reqn">v_{R} = \sum_{k=1}^L c_k\left(\hat{T}_y^{(k)}-\hat{T}_y\right)^2</code>
</p>

<p>With subsampling of replicates, <code class="reqn">L_0</code> of the original <code class="reqn">L</code> replicates
are randomly selected, and then variances are estimated using the formula:
</p>
<p style="text-align: center;"><code class="reqn">v_{R} = \frac{L}{L_0} \sum_{k=1}^{L_0} c_k\left(\hat{T}_y^{(k)}-\hat{T}_y\right)^2</code>
</p>

<p>This subsampling is suggested for certain replicate designs in Fay (1989).
Kim and Wu (2013) provide a detailed theoretical justification and
also propose alternative methods of subsampling replicates.
</p>


<h3>References</h3>

<p>Fay, Robert. 1989.
&quot;Theory And Application Of Replicate Weighting For Variance Calculations.&quot;
In, 495–500. Alexandria, VA: American Statistical Association.
http://www.asasrms.org/Proceedings/papers/1989_033.pdf
</p>
<p>Kim, J.K. and Wu, C. 2013.
&quot;Sparse and Efficient Replication Variance Estimation for Complex Surveys.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 39(1), 91-120.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(survey)
set.seed(2023)

# Create an example survey design object

  sample_data &lt;- data.frame(
    STRATUM = c(1,1,1,1,2,2,2,2),
    PSU     = c(1,2,3,4,5,6,7,8)
  )

  survey_design &lt;- svydesign(
    data = sample_data,
    strata = ~ STRATUM,
    ids = ~ PSU,
    weights = ~ 1
  )

  rep_design &lt;- survey_design |&gt;
    as_fays_gen_rep_design(variance_estimator = "Ultimate Cluster")

# Inspect replicates before subsampling

  rep_design |&gt; getElement("repweights")

# Inspect replicates after subsampling

  rep_design |&gt;
    subsample_replicates(n_reps = 4) |&gt;
    getElement("repweights")
</code></pre>

<hr>
<h2 id='summarize_rep_weights'>Summarize the replicate weights</h2><span id='topic+summarize_rep_weights'></span>

<h3>Description</h3>

<p>Summarize the replicate weights of a design
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarize_rep_weights(rep_design, type = "both", by)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarize_rep_weights_+3A_rep_design">rep_design</code></td>
<td>
<p>A replicate design object, created with either the <code>survey</code> or <code>srvyr</code> packages.</p>
</td></tr>
<tr><td><code id="summarize_rep_weights_+3A_type">type</code></td>
<td>
<p>Default is <code>"both"</code>. Use <code>type = "overall"</code>, for an overall summary of the replicate weights.
Use <code>type = "specific"</code> for a summary of each column of replicate weights,
with each column of replicate weights summarized in a given row of the summary. <br />
<br />
Use <code>type = "both"</code> for a list containing both summaries,
with the list containing the names <code>"overall"</code> and <code>"both"</code>.</p>
</td></tr>
<tr><td><code id="summarize_rep_weights_+3A_by">by</code></td>
<td>
<p>(Optional) A character vector with the names of variables used to group the summaries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>type = "both"</code> (the default), the result is a list of data frames
with names <code>"overall"</code> and <code>"specific"</code>. If <code>type = "overall"</code>, the result is
a data frame providing an overall summary of the replicate weights. <br />
<br />
The contents of the <code>"overall"</code> summary are the following:
</p>

<ul>
<li><p> &quot;nrows&quot;: Number of rows for the weights
</p>
</li>
<li><p> &quot;ncols&quot;: Number of columns of replicate weights
</p>
</li>
<li><p> &quot;degf_svy_pkg&quot;: The degrees of freedom according to the survey package in R
</p>
</li>
<li><p> &quot;rank&quot;: The matrix rank as determined by a QR decomposition
</p>
</li>
<li><p> &quot;avg_wgt_sum&quot;: The average column sum
</p>
</li>
<li><p> &quot;sd_wgt_sums&quot;: The standard deviation of the column sums
</p>
</li>
<li><p> &quot;min_rep_wgt&quot;: The minimum value of any replicate weight
</p>
</li>
<li><p> &quot;max_rep_wgt&quot;: The maximum value of any replicate weight
</p>
</li></ul>

<p>If <code>type = "specific"</code>, the result is a data frame providing a
summary of each column of replicate weights, with each column of replicate weights
described in a given row of the data frame.
The contents of the <code>"specific"</code> summary are the following:
</p>

<ul>
<li><p> &quot;Rep_Column&quot;: The name of a given column of replicate weights.
If columns are unnamed, the column number is used instead
</p>
</li>
<li><p> &quot;N&quot;: The number of entries
</p>
</li>
<li><p> &quot;N_NONZERO&quot;: The number of nonzero entries
</p>
</li>
<li><p> &quot;SUM&quot;: The sum of the weights
</p>
</li>
<li><p> &quot;MEAN&quot;: The average of the weights
</p>
</li>
<li><p> &quot;CV&quot;: The coefficient of variation of the weights (standard deviation divided by mean)
</p>
</li>
<li><p> &quot;MIN&quot;: The minimum weight
</p>
</li>
<li><p> &quot;MAX&quot;: The maximum weight
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
# Load example data
suppressPackageStartupMessages(library(survey))
data(api)

dclus1 &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1$variables$response_status &lt;- sample(x = c("Respondent", "Nonrespondent",
                                                 "Ineligible", "Unknown eligibility"),
                                           size = nrow(dclus1),
                                           replace = TRUE)
rep_design &lt;- as.svrepdesign(dclus1)

# Adjust weights for cases with unknown eligibility
ue_adjusted_design &lt;- redistribute_weights(
    design = rep_design,
    reduce_if = response_status %in% c("Unknown eligibility"),
    increase_if = !response_status %in% c("Unknown eligibility"),
    by = c("stype")
)

# Summarize replicate weights

summarize_rep_weights(rep_design, type = "both")

# Summarize replicate weights by grouping variables

summarize_rep_weights(ue_adjusted_design, type = 'overall',
                      by = c("response_status"))

summarize_rep_weights(ue_adjusted_design, type = 'overall',
                      by = c("stype", "response_status"))

# Compare replicate weights

rep_wt_summaries &lt;- lapply(list('original' = rep_design,
                                'adjusted' = ue_adjusted_design),
                           summarize_rep_weights,
                           type = "overall")
print(rep_wt_summaries)

</code></pre>

<hr>
<h2 id='svyby_repwts'>Compare survey statistics calculated separately from different sets of replicate weights</h2><span id='topic+svyby_repwts'></span>

<h3>Description</h3>

<p>A modified version of the <code>svyby()</code> function from the <code>survey</code> package.
Whereas <code>svyby()</code> calculates statistics separately for each subset formed by a specified grouping variable,
<code>svyby_repwts()</code> calculates statistics separately for each replicate design, in addition to any additional user-specified grouping variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>svyby_repwts(
  rep_designs,
  formula,
  by,
  FUN,
  ...,
  deff = FALSE,
  keep.var = TRUE,
  keep.names = TRUE,
  verbose = FALSE,
  vartype = c("se", "ci", "ci", "cv", "cvpct", "var"),
  drop.empty.groups = TRUE,
  return.replicates = FALSE,
  na.rm.by = FALSE,
  na.rm.all = FALSE,
  multicore = getOption("survey.multicore")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="svyby_repwts_+3A_rep_designs">rep_designs</code></td>
<td>
<p>The replicate-weights survey designs to be compared. Supplied either as:
</p>

<ul>
<li><p> A named list of replicate-weights survey design objects, for example <code>list('nr' = nr_adjusted_design, 'ue' = ue_adjusted_design)</code>.
</p>
</li>
<li><p> A 'stacked' replicate-weights survey design object created by <code>stack_replicate_designs()</code>.
</p>
</li></ul>

<p>The designs must all have the same number of columns of replicate weights, of the same type (bootstrap, JKn, etc.)</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_formula">formula</code></td>
<td>
<p>A formula specifying the variables to pass to <code>FUN</code></p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_by">by</code></td>
<td>
<p>A formula specifying factors that define subsets</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_fun">FUN</code></td>
<td>
<p>A function taking a formula and survey design object as its first two arguments.
Usually a function from the <code>survey</code> package, such as <code>svytotal</code> or <code>svymean</code>.</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_...">...</code></td>
<td>
<p>Other arguments to <code>FUN</code></p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_deff">deff</code></td>
<td>
<p>A value of <code>TRUE</code> or <code>FALSE</code>, indicating whether design effects should be estimated if possible.</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_keep.var">keep.var</code></td>
<td>
<p>A value of <code>TRUE</code> or <code>FALSE</code>. If <code>FUN</code> returns a <code>svystat</code> object, indicates whether to extract standard errors from it.</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_keep.names">keep.names</code></td>
<td>
<p>Define row names based on the subsets</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, print a label for each subset as it is processed.</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_vartype">vartype</code></td>
<td>
<p>Report variability as one or more of standard error, confidence interval, coefficient of variation,  percent coefficient of variation, or variance</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_drop.empty.groups">drop.empty.groups</code></td>
<td>
<p>If <code>FALSE</code>, report <code>NA</code> for empty groups, if <code>TRUE</code> drop them from the output</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_return.replicates">return.replicates</code></td>
<td>
<p>If <code>TRUE</code>, return all the replicates as the &quot;replicates&quot; attribute of the result.
This can be useful if you want to produce custom summaries of the estimates from each replicate.</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_na.rm.by">na.rm.by</code></td>
<td>
<p>If true, omit groups defined by <code>NA</code> values of the <code>by</code> variables</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_na.rm.all">na.rm.all</code></td>
<td>
<p>If true, check for groups with no non-missing observations for variables defined by <code>formula</code> and treat these groups as empty</p>
</td></tr>
<tr><td><code id="svyby_repwts_+3A_multicore">multicore</code></td>
<td>
<p>Use <code>multicore</code> package to distribute subsets over multiple processors?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"svyby"</code>: a data frame showing the grouping factors and results of <code>FUN</code> for each combination of the grouping factors.
The first grouping factor always consists of indicators for which replicate design was used for an estimate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
suppressPackageStartupMessages(library(survey))
data(api)

dclus1 &lt;- svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
dclus1$variables$response_status &lt;- sample(x = c("Respondent", "Nonrespondent",
                                                 "Ineligible", "Unknown eligibility"),
                                           size = nrow(dclus1),
                                           replace = TRUE)
orig_rep_design &lt;- as.svrepdesign(dclus1)

# Adjust weights for cases with unknown eligibility
ue_adjusted_design &lt;- redistribute_weights(
    design = orig_rep_design,
    reduce_if = response_status %in% c("Unknown eligibility"),
    increase_if = !response_status %in% c("Unknown eligibility"),
    by = c("stype")
)

# Adjust weights for nonresponse
nr_adjusted_design &lt;- redistribute_weights(
    design = ue_adjusted_design,
    reduce_if = response_status %in% c("Nonrespondent"),
    increase_if = response_status == "Respondent",
    by = c("stype")
)

# Compare estimates from the three sets of replicate weights

  list_of_designs &lt;- list('original' = orig_rep_design,
                          'unknown eligibility adjusted' = ue_adjusted_design,
                          'nonresponse adjusted' = nr_adjusted_design)

  ##_ First compare overall means for two variables
  means_by_design &lt;- svyby_repwts(formula = ~ api00 + api99,
                                  FUN = svymean,
                                  rep_design = list_of_designs)

  print(means_by_design)

  ##_ Next compare domain means for two variables
  domain_means_by_design &lt;- svyby_repwts(formula = ~ api00 + api99,
                                         by = ~ stype,
                                         FUN = svymean,
                                         rep_design = list_of_designs)

  print(domain_means_by_design)

# Calculate confidence interval for difference between estimates

ests_by_design &lt;- svyby_repwts(rep_designs = list('NR-adjusted' = nr_adjusted_design,
                                                  'Original' = orig_rep_design),
                               FUN = svymean, formula = ~ api00 + api99)

differences_in_estimates &lt;- svycontrast(stat = ests_by_design, contrasts = list(
  'Mean of api00: NR-adjusted vs. Original' = c(1,-1,0,0),
  'Mean of api99: NR-adjusted vs. Original' = c(0,0,1,-1)
))

print(differences_in_estimates)

confint(differences_in_estimates, level = 0.95)

## End(Not run)
</code></pre>

<hr>
<h2 id='variance-estimators'>Variance Estimators</h2><span id='topic+variance-estimators'></span>

<h3>Description</h3>

<p>This help page describes variance estimators
which are commonly used for survey samples. These variance estimators
can be used as the basis of the generalized replication methods, implemented
with the functions <code><a href="#topic+as_fays_gen_rep_design">as_fays_gen_rep_design</a>()</code>,
<code><a href="#topic+as_gen_boot_design">as_gen_boot_design</a>()</code>,
<code><a href="#topic+make_fays_gen_rep_factors">make_fays_gen_rep_factors</a>()</code>,
or <code><a href="#topic+make_gen_boot_factors">make_gen_boot_factors</a>()</code>
</p>


<h3>Shared Notation</h3>

<p>Let <code class="reqn">s</code> denote the selected sample of size <code class="reqn">n</code>, with elements <code class="reqn">i=1,\dots,n</code>.
Element <code class="reqn">i</code> in the sample had probability <code class="reqn">\pi_i</code> of being included in the sample.
The <em>pair</em> of elements <code class="reqn">ij</code> was sampled with probability <code class="reqn">\pi_{ij}</code>.
</p>
<p>The population total for a variable is denoted <code class="reqn">Y = \sum_{i \in U}y_i</code>,
and the Horvitz-Thompson estimator for <code class="reqn">\hat{Y}</code> is
denoted <code class="reqn">\hat{Y} = \sum_{i \in s} y_i/\pi_i</code>. For convenience,
we denote <code class="reqn">\breve{y}_i = y_i/\pi_i</code>.
</p>
<p>The true sampling variance of <code class="reqn">\hat{Y}</code> is denoted <code class="reqn">V(\hat{Y})</code>,
while an estimator of this sampling variance is denoted <code class="reqn">v(\hat{Y})</code>.
</p>


<h3>Horvitz-Thompson</h3>

<p>The <strong>Horvitz-Thompson</strong> variance estimator:
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{Y}) = \sum_{i \in s}\sum_{j \in s} (1 - \frac{\pi_i \pi_j}{\pi_{ij}}) \frac{y_i}{\pi_i} \frac{y_j}{\pi_j}
</code>
</p>



<h3>Yates-Grundy</h3>

<p>The <strong>Yates-Grundy</strong> variance estimator:
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{Y}) = -\frac{1}{2}\sum_{i \in s}\sum_{j \in s} (1 - \frac{\pi_i \pi_j}{\pi_{ij}}) (\frac{y_i}{\pi_i} - \frac{y_j}{\pi_j})^2
</code>
</p>



<h3>Poisson Horvitz-Thompson</h3>

<p>The <strong>Poisson Horvitz-Thompson</strong> variance estimator
is simply the Horvitz-Thompson variance estimator, but
where <code class="reqn">\pi_{ij}=\pi_i \times \pi_j</code>, which is the case for Poisson sampling.
<br /> <br />
</p>


<h3>Stratified Multistage SRS</h3>

<p>The <strong>Stratified Multistage SRS</strong> variance estimator is the recursive variance estimator
proposed by Bellhouse (1985) and used in the 'survey' package's function <a href="survey.html#topic+svyrecvar">svyrecvar</a>.
In the case of simple random sampling without replacement (with one or more stages),
this estimator exactly matches the Horvitz-Thompson estimator.
</p>
<p>The estimator can be used for any number of sampling stages. For illustration, we describe its use
for two sampling stages.
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{Y}) = \hat{V}_1 + \hat{V}_2
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{V}_1 = \sum_{h=1}^{H} (1 - \frac{n_h}{N_h})\frac{n_h}{n_h - 1} \sum_{i=1}^{n_h} (y_{hi.} - \bar{y}_{hi.})^2
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{V}_2 = \sum_{h=1}^{H} \frac{n_h}{N_h} \sum_{i=1}^{n_h}v_{hi}(y_{hi.})
</code>
</p>

<p>where <code class="reqn">n_h</code> is the number of sampled clusters in stratum <code class="reqn">h</code>,
<code class="reqn">N_h</code> is the number of population clusters in stratum <code class="reqn">h</code>,
<code class="reqn">y_{hi.}</code> is the weighted cluster total in cluster <code class="reqn">i</code> of stratum <code class="reqn">h</code>,
<code class="reqn">\bar{y}_{hi.}</code> is the mean weighted cluster total of stratum <code class="reqn">h</code>,
(<code class="reqn">\bar{y}_{hi.} = \frac{1}{n_h}\sum_{i=1}^{n_h}y_{hi.}</code>), and
<code class="reqn">v_{hi}(y_{hi.})</code> is the estimated sampling variance of <code class="reqn">y_{hi.}</code>.
<br /> <br />
</p>


<h3>Ultimate Cluster</h3>

<p>The <strong>Ultimate Cluster</strong> variance estimator is simply the stratified multistage SRS
variance estimator, but ignoring variances from later stages of sampling.
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{Y}) = \hat{V}_1
</code>
</p>

<p>This is the variance estimator used in the 'survey' package when the user specifies
<code>option(survey.ultimate.cluster = TRUE)</code> or uses <code>svyrecvar(..., one.stage = TRUE)</code>.
When the first-stage sampling fractions are small, analysts often omit the finite population corrections <code class="reqn">(1-\frac{n_h}{N_h})</code>
when using the ultimate cluster estimator.
</p>


<h3>SD1 and SD2 (Successive Difference Estimators)</h3>

<p>The <strong>SD1</strong> and <strong>SD2</strong> variance estimators are &quot;successive difference&quot;
estimators sometimes used for systematic sampling designs.
Ash (2014) describes each estimator as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{v}_{S D 1}(\hat{Y}) = \left(1-\frac{n}{N}\right) \frac{n}{2(n-1)} \sum_{k=2}^n\left(\breve{y}_k-\breve{y}_{k-1}\right)^2
</code>
</p>

<p style="text-align: center;"><code class="reqn">
  \hat{v}_{S D 2}(\hat{Y}) = \left(1-\frac{n}{N}\right) \frac{1}{2}\left[\sum_{k=2}^n\left(\breve{y}_k-\breve{y}_{k-1}\right)^2+\left(\breve{y}_n-\breve{y}_1\right)^2\right]
</code>
</p>

<p>where <code class="reqn">\breve{y}_k = y_k/\pi_k</code> is the weighted value of unit <code class="reqn">k</code>
with selection probability <code class="reqn">\pi_k</code>. The SD1 estimator is recommended by Wolter (1984).
The SD2 estimator is the basis of the successive difference replication estimator commonly
used for systematic sampling designs and is more conservative. See Ash (2014) for details.
<br /> <br />
For multistage samples, SD1 and SD2 are applied to the clusters at each stage, separately by stratum.
For later stages of sampling, the variance estimate from a stratum is multiplied by the product
of sampling fractions from earlier stages of sampling. For example, at a third stage of sampling,
the variance estimate from a third-stage stratum is multiplied by <code class="reqn">\frac{n_1}{N_1}\frac{n_2}{N_2}</code>,
which is the product of sampling fractions from the first-stage stratum and second-stage stratum.
</p>


<h3>Deville 1 and Deville 2</h3>

<p>The <strong>&quot;Deville-1&quot;</strong> and <strong>&quot;Deville-2&quot;</strong> variance estimators
are clearly described in Matei and Tillé (2005),
and are intended for designs that use
fixed-size, unequal-probability random sampling without replacement.
These variance estimators have been shown to be effective
for designs that use a fixed sample size with a high-entropy sampling method.
This includes most PPSWOR sampling methods,
but unequal-probability systematic sampling is an important exception.
</p>
<p>These variance estimators take the following form:
</p>
<p style="text-align: center;"><code class="reqn">
\hat{v}(\hat{Y}) = \sum_{i=1}^{n} c_i (\breve{y}_i - \frac{1}{\sum_{i=k}^{n}c_k}\sum_{k=1}^{n}c_k \breve{y}_k)^2
</code>
</p>

<p>where <code class="reqn">\breve{y}_i = y_i/\pi_i</code> is the weighted value of the the variable of interest,
and <code class="reqn">c_i</code> depend on the method used:
</p>

<ul>
<li> <p><strong>&quot;Deville-1&quot;</strong>: 
</p>
<p style="text-align: center;"><code class="reqn">c_i=\left(1-\pi_i\right) \frac{n}{n-1}</code>
</p>

</li>
<li> <p><strong>&quot;Deville-2&quot;</strong>: 
</p>
<p style="text-align: center;"><code class="reqn">c_i = (1-\pi_i) \left[1 - \sum_{k=1}^{n} \left(\frac{1-\pi_k}{\sum_{k=1}^{n}(1-\pi_k)}\right)^2 \right]^{-1}</code>
</p>

</li></ul>

<p>In the case of simple random sampling without replacement (SRSWOR),
these estimators are both identical to the usual stratified multistage SRS estimator
(which is itself a special case of the Horvitz-Thompson estimator).
</p>
<p>For multistage samples, &quot;Deville-1&quot; and &quot;Deville-2&quot; are applied to the clusters at each stage, separately by stratum.
For later stages of sampling, the variance estimate from a stratum is multiplied by the product
of sampling probabilities from earlier stages of sampling. For example, at a third stage of sampling,
the variance estimate from a third-stage stratum is multiplied by <code class="reqn">\pi_1 \times \pi_{(2 | 1)}</code>,
where <code class="reqn">\pi_1</code> is the sampling probability of the first-stage unit
and <code class="reqn">\pi_{(2|1)}</code> is the sampling probability of the second-stage unit
within the first-stage unit.
</p>


<h3>Deville-Tillé</h3>

<p>See Section 6.8 of Tillé (2020) for more detail on this estimator,
including an explanation of its quadratic form.
See Deville and Tillé (2005) for the results of a simulation study
comparing this and other alternative estimators for balanced sampling.
</p>
<p>The estimator can be written as follows:
</p>
<p style="text-align: center;"><code class="reqn">
  v(\hat{Y})=\sum_{k \in S} \frac{c_k}{\pi_k^2}\left(y_k-\hat{y}_k^*\right)^2,
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
  \hat{y}_k^*=\mathbf{z}_k^{\top}\left(\sum_{\ell \in S} c_{\ell} \frac{\mathbf{z}_{\ell} \mathbf{z}_{\ell}^{\prime}}{\pi_{\ell}^2}\right)^{-1} \sum_{\ell \in S} c_{\ell} \frac{\mathbf{z}_{\ell} y_{\ell}}{\pi_{\ell}^2}
</code>
</p>

<p>and <code class="reqn">\mathbf{z}_k</code> denotes the vector of auxiliary variables for observation <code class="reqn">k</code>
included in sample <code class="reqn">S</code>, with inclusion probability <code class="reqn">\pi_k</code>. The value <code class="reqn">c_k</code> is set to <code class="reqn">\frac{n}{n-q}(1-\pi_k)</code>,
where <code class="reqn">n</code> is the number of observations and <code class="reqn">q</code> is the number of auxiliary variables.
</p>


<h3>References</h3>

<p>Ash, S. (2014). &quot;<em>Using successive difference replication for estimating variances</em>.&quot;
<strong>Survey Methodology</strong>, Statistics Canada, 40(1), 47–59.
</p>
<p>Bellhouse, D.R. (1985). &quot;<em>Computing Methods for Variance Estimation in Complex Surveys</em>.&quot;
<strong>Journal of Official Statistics</strong>, Vol.1, No.3.
</p>
<p>Deville, J.‐C., and Tillé, Y. (2005). &quot;<em>Variance approximation under balanced sampling.</em>&quot;
<strong>Journal of Statistical Planning and Inference</strong>, 128, 569–591.
</p>
<p>Tillé, Y. (2020). &quot;<em>Sampling and estimation from finite populations</em>.&quot; (I. Hekimi, Trans.). Wiley.
</p>
<p>Matei, Alina, and Yves Tillé. (2005).
“<em>Evaluation of Variance Approximations and Estimators
in Maximum Entropy Sampling with Unequal Probability and Fixed Sample Size.</em>”
<strong>Journal of Official Statistics</strong>, 21(4):543–70.
</p>

<hr>
<h2 id='wls_hat_matrix'>Create the &quot;hat matrix&quot; for weighted least squares regression</h2><span id='topic+wls_hat_matrix'></span>

<h3>Description</h3>

<p>Create the &quot;hat matrix&quot; for weighted least squares regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wls_hat_matrix(X, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wls_hat_matrix_+3A_x">X</code></td>
<td>
<p>Matrix of predictor variables, with <code>n</code> rows</p>
</td></tr>
<tr><td><code id="wls_hat_matrix_+3A_w">w</code></td>
<td>
<p>Vector of weights (should all be nonnegative), of length <code>n</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code class="reqn">n \times n</code> matrix. This is the &quot;hat matrix&quot; for a WLS regression.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
