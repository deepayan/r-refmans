<!DOCTYPE html><html lang="en"><head><title>Help for package bdsvd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bdsvd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bdsvd'><p>Block Detection Using Singular Vectors (BD-SVD).</p></a></li>
<li><a href='#bdsvd.cov.sim'><p>Covariance Matrix Simulation for BD-SVD</p></a></li>
<li><a href='#bdsvd.ht'><p>Hyperparameter Tuning for BD-SVD</p></a></li>
<li><a href='#bdsvd.structure'><p>Data Matrix Structure According to the Detected Block Structure.</p></a></li>
<li><a href='#block-class'><p>Block</p></a></li>
<li><a href='#detect.blocks'><p>Block Detection</p></a></li>
<li><a href='#hcsvd'><p>Hierarchical Variable Clustering Using Singular Vectors (HC-SVD).</p></a></li>
<li><a href='#hcsvd.cor.sim'><p>Correlation Matrix Simulation for HC-SVD</p></a></li>
<li><a href='#single.bdsvd'><p>Single Iteration of Block Detection Using Singular Vectors (BD-SVD).</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Block Structure Detection Using Singular Vectors</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jan O. Bauer &lt;j.bauer@vu.nl&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs block diagonal covariance matrix detection using singular vectors (BD-SVD), which can be extended to hierarchical variable clustering (HC-SVD). The methods are described in Bauer (2024) &lt;<a href="https://doi.org/10.1080%2F10618600.2024.2422985">doi:10.1080/10618600.2024.2422985</a>&gt; and Bauer (202X) &lt;<a href="https://doi.org/10.48550%2FarXiv.2308.06820">doi:10.48550/arXiv.2308.06820</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>irlba, methods, stats</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cvCovEst, mvtnorm, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-01-08 10:20:58 UTC; jan</td>
</tr>
<tr>
<td>Author:</td>
<td>Jan O. Bauer <a href="https://orcid.org/0000-0001-7123-4507"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Ron Holzapfel [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-01-08 11:10:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='bdsvd'>Block Detection Using Singular Vectors (BD-SVD).</h2><span id='topic+bdsvd'></span>

<h3>Description</h3>

<p>Performs BD-SVD iteratively to reveal the block structure. Splits the data matrix into one (i.e., no split)
or two submatrices, depending on the structure of the first sparse loading <code class="reqn">v</code> (which is a sparse approximation of the
first right singular vector, i.e., a vector with many zero values) that mirrors the shape of the covariance matrix. This
procedure is continued iteratively until the block diagonal structure has been revealed.
</p>
<p>The data matrix ordered according to this revealed block diagonal structure can be obtained by <code><a href="#topic+bdsvd.structure">bdsvd.structure</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdsvd(X, dof.lim, anp = "2", standardize = TRUE, max.iter, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bdsvd_+3A_x">X</code></td>
<td>
<p>Data matrix of dimension <code class="reqn">n</code>x<code class="reqn">p</code> with possibly <code class="reqn">p &gt;&gt; n</code>.</p>
</td></tr>
<tr><td><code id="bdsvd_+3A_dof.lim">dof.lim</code></td>
<td>
<p>Interval limits for the number of non-zero components in the sparse loading (degrees of freedom).
If <code class="reqn">S</code> denotes the support of <code class="reqn">v</code>, then the cardinality of the support, <code class="reqn">|S|</code>,
corresponds to the degrees of freedom. Default is <code>dof.lim &lt;- c(0, p-1)</code> which is highly recommended to check for
all levels of sparsity.</p>
</td></tr>
<tr><td><code id="bdsvd_+3A_anp">anp</code></td>
<td>
<p>Which regularization function should be used for the HBIC. <code>anp = "1"</code> implements <code class="reqn">a_{np} = 1</code> which corresponds
to the BIC, <code>anp = "2"</code> implements <code class="reqn">a_{np} = 1/2 log(np)</code> which corresponds to the regularization used by Bauer (2024), and <code>anp = "3"</code>
implements <code class="reqn">a_{np} = log(log(np))</code> which corresponds to the regularization used by Wang et al. (2009) and Wang et al. (2013).</p>
</td></tr>
<tr><td><code id="bdsvd_+3A_standardize">standardize</code></td>
<td>
<p>Standardize the data to have unit variance. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bdsvd_+3A_max.iter">max.iter</code></td>
<td>
<p>How many iterations should be performed for computing the sparse loading.
Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="bdsvd_+3A_trace">trace</code></td>
<td>
<p>Print out progress as iterations are performed. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sparse loadings are computed using the method by Shen &amp; Huang (2008), implemented by Baglama, Reichel, and Lewis in <code><a href="irlba.html#topic+ssvd">ssvd</a></code> {<a href="irlba.html#topic+irlba">irlba</a>}.
</p>


<h3>Value</h3>

<p>A list containing the feature names of the submatrices of <code>X</code>. The length of the list equals
the number of submatrices.
</p>


<h3>References</h3>

<p><cite>Bauer, J.O. (2024). High-dimensional block diagonal covariance structure detection using singular vectors, J. Comput. Graph. Stat.</cite>
</p>
<p><cite>Wang, H., B. Li, and C. Leng (2009). Shrinkage tuning parameter selection with a diverging number of parameters, J. R. Stat. Soc. B 71 (3), 671–683.</cite>
</p>
<p><cite>Wang, L., Y. Kim, and R. Li (2013). Calibrating nonconvex penalized regression in ultra-high dimension, Ann. Stat. 41 (5), 2505–2536.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bdsvd.structure">bdsvd.structure</a></code>, <code><a href="#topic+bdsvd.ht">bdsvd.ht</a></code>, <code><a href="#topic+single.bdsvd">single.bdsvd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Replicate the simulation study (c) from Bauer (2024).

## Not run: 
p &lt;- 500 #Number of variables
n &lt;- 500 #Number of observations
b &lt;- 10  #Number of blocks
design &lt;- "c" #Simulation design "a", "b", "c", or "d".

#Simulate data matrix X
set.seed(1)
Sigma &lt;- bdsvd.cov.sim(p = p, b = b, design = design)
X &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = Sigma)
colnames(X) &lt;- seq_len(p)

bdsvd(X, standardize = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='bdsvd.cov.sim'>Covariance Matrix Simulation for BD-SVD</h2><span id='topic+bdsvd.cov.sim'></span>

<h3>Description</h3>

<p>This function generates covariance matrices based on the simulation studies described in Bauer (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdsvd.cov.sim(p = p, b, design = design)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bdsvd.cov.sim_+3A_p">p</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code id="bdsvd.cov.sim_+3A_b">b</code></td>
<td>
<p>Number of blocks. Only required for simulation design &quot;c&quot; and &quot;d&quot;.</p>
</td></tr>
<tr><td><code id="bdsvd.cov.sim_+3A_design">design</code></td>
<td>
<p>Simulation design &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, or &quot;d&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A covariance matrix according to the chosen simulation design.
</p>


<h3>References</h3>

<p><cite>Bauer, J.O. (2024). High-dimensional block diagonal covariance structure detection using singular vectors, J. Comput. Graph. Stat.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The covariance matrix for simulation design (a) is given by
Sigma &lt;- bdsvd.cov.sim(p = 500, b = 500, design = "a")

</code></pre>

<hr>
<h2 id='bdsvd.ht'>Hyperparameter Tuning for BD-SVD</h2><span id='topic+bdsvd.ht'></span>

<h3>Description</h3>

<p>Finds the number of non-zero elements of the sparse loading according to the high-dimensional
Bayesian information criterion (HBIC).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdsvd.ht(X, dof.lim, standardize = TRUE, anp = "2", max.iter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bdsvd.ht_+3A_x">X</code></td>
<td>
<p>Data matrix of dimension <code class="reqn">n x p</code> with possibly <code class="reqn">p &gt;&gt; n</code>.</p>
</td></tr>
<tr><td><code id="bdsvd.ht_+3A_dof.lim">dof.lim</code></td>
<td>
<p>Interval limits for the number of non-zero components in the sparse loading (degrees of freedom).
If <code class="reqn">S</code> denotes the support of <code class="reqn">v</code>, then the cardinality of the support, <code class="reqn">|S|</code>,
corresponds to the degrees of freedom. Default is <code>dof.lim &lt;- c(0, p-1)</code> which is highly recommended to check for
all levels of sparsity.</p>
</td></tr>
<tr><td><code id="bdsvd.ht_+3A_standardize">standardize</code></td>
<td>
<p>Standardize the data to have unit variance. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bdsvd.ht_+3A_anp">anp</code></td>
<td>
<p>Which regularization function should be used for the HBIC. <code>anp = "1"</code> implements <code class="reqn">a_{np} = 1</code> which corresponds
to the BIC, <code>anp = "2"</code> implements <code class="reqn">a_{np} = 1/2 log(np)</code> which corresponds to the regularization used by Bauer (2024), and <code>anp = "3"</code>
implements <code class="reqn">a_{np} = log(log(np))</code> which corresponds to the regularization used by Wang et al. (2009) and Wang et al. (2013).</p>
</td></tr>
<tr><td><code id="bdsvd.ht_+3A_max.iter">max.iter</code></td>
<td>
<p>How many iterations should be performed for computing the sparse loading.
Default is <code>200</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sparse loadings are computed using the method by Shen &amp; Huang (2008), implemented in
the <code>irlba</code> package. The computation of the HBIC is outlined in Bauer (2024).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>dof</code></td>
<td>

<p>The optimal number of nonzero components (degrees of freedom) according to the HBIC.
</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>

<p>The HBIC for the different numbers of nonzero components.
</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Bauer, J.O. (2024). High-dimensional block diagonal covariance structure detection using singular vectors, J. Comput. Graph. Stat.</cite>
</p>
<p><cite>Shen, H. and Huang, J.Z. (2008). Sparse principal component analysis via regularized low rank matrix approximation, J. Multivar. Anal. 99, 1015–1034.</cite>
</p>
<p><cite>Wang, H., B. Li, and C. Leng (2009). Shrinkage tuning parameter selection with a diverging number of parameters, J. R. Stat. Soc. B 71 (3), 671–683.</cite>
</p>
<p><cite>Wang, L., Y. Kim, and R. Li (2013). Calibrating nonconvex penalized regression in ultra-high dimension, Ann. Stat. 41 (5), 2505–2536.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bdsvd">bdsvd</a></code>, <code><a href="#topic+single.bdsvd">single.bdsvd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Replicate the illustrative example from Bauer (2024).


p &lt;- 300 #Number of variables. In Bauer (2024), p = 3000
n &lt;- 500 #Number of observations
b &lt;- 3   #Number of blocks
design &lt;- "c"

#Simulate data matrix X
set.seed(1)
Sigma &lt;- bdsvd.cov.sim(p = p, b = b, design = design)
X &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = Sigma)
colnames(X) &lt;- seq_len(p)

ht &lt;- bdsvd.ht(X)
plot(0:(p-1), ht$BIC[,1], xlab = "|S|", ylab = "HBIC", main = "", type = "l")
single.bdsvd(X, dof = ht$dof, standardize = FALSE)

</code></pre>

<hr>
<h2 id='bdsvd.structure'>Data Matrix Structure According to the Detected Block Structure.</h2><span id='topic+bdsvd.structure'></span>

<h3>Description</h3>

<p>Either sorts the data matrix <code class="reqn">X</code> according to the detected block structure <code class="reqn">X_1 , ... , X_b</code>, ordered by the number
of variables that the blocks contain. Or returns the detected submatrices each individually in a list object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bdsvd.structure(X, block.structure, output = "matrix", block.order)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bdsvd.structure_+3A_x">X</code></td>
<td>
<p>Data matrix of dimension <code class="reqn">n x p</code> with possibly <code class="reqn">p &gt;&gt; n</code>.</p>
</td></tr>
<tr><td><code id="bdsvd.structure_+3A_block.structure">block.structure</code></td>
<td>
<p>Output of <code>bdsvd()</code> or <code>single.bdsvd()</code> which identified the block structure.</p>
</td></tr>
<tr><td><code id="bdsvd.structure_+3A_output">output</code></td>
<td>
<p>Should the output be the data matrix ordered according to the blocks (<code>"matrix"</code>), or
a list containing the submatrices (<code>"submatrices"</code>). Default is <code>"matrix"</code>.</p>
</td></tr>
<tr><td><code id="bdsvd.structure_+3A_block.order">block.order</code></td>
<td>
<p>A vector that contains the order of the blocks detected by <code>bdsvd()</code> or <code>single.bdsvd()</code>.
The vector must contain the index of each blocks exactly once. Default is <code>1:b</code> where <code>b</code> is the total number of blocks.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either the data matrix <code>X</code> with columns sorted according to the detected blocks, or a list containing the detected
submatrices.
</p>


<h3>References</h3>

<p><cite>Bauer, J.O. (2024). High-dimensional block diagonal covariance structure detection using singular vectors, J. Comput. Graph. Stat.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bdsvd">bdsvd</a></code>, <code><a href="#topic+single.bdsvd">single.bdsvd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Toying with the illustrative example from Bauer (2024).


p &lt;- 150 #Number of variables. In Bauer (2024), p = 3000.
n &lt;- 500 #Number of observations
b &lt;- 3   #Number of blocks
design &lt;- "c"

#Simulate data matrix X
set.seed(1)
Sigma &lt;- bdsvd.cov.sim(p = p, b = b, design = design)
X &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = Sigma)
colnames(X) &lt;- seq_len(p)

#Compute iterative BD-SVD
bdsvd.obj &lt;- bdsvd(X, standardize = FALSE)

#Obtain the data matrix X, sorted by the detected blocks
colnames(bdsvd.structure(X, bdsvd.obj, output = "matrix") )
colnames(bdsvd.structure(X, bdsvd.obj, output = "matrix", block.order = c(2,1,3)) )

#Obtain the detected submatrices X_1, X_2, and X_3
colnames(bdsvd.structure(X, bdsvd.obj, output = "submatrices")[[1]] )
colnames(bdsvd.structure(X, bdsvd.obj, output = "submatrices")[[2]] )
colnames(bdsvd.structure(X, bdsvd.obj, output = "submatrices")[[3]] )

</code></pre>

<hr>
<h2 id='block-class'>Block</h2><span id='topic+block-class'></span>

<h3>Description</h3>

<p>Class used within the package to store the structure and
information about the detected blocks.
</p>


<h3>Slots</h3>


<dl>
<dt><code>features</code></dt><dd><p>numeric vector that contains the the variables
corresponding to this block.</p>
</dd>
<dt><code>block.columns</code></dt><dd><p>numeric vector that contains the indices of the
singular vectors corresponding to this block.</p>
</dd>
</dl>

<hr>
<h2 id='detect.blocks'>Block Detection</h2><span id='topic+detect.blocks'></span>

<h3>Description</h3>

<p>This function returns the block structure of a matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect.blocks(V, threshold = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="detect.blocks_+3A_v">V</code></td>
<td>
<p>Numeric matrix which either contains the loadings or is a covariance matrix.</p>
</td></tr>
<tr><td><code id="detect.blocks_+3A_threshold">threshold</code></td>
<td>
<p>All absolute values of <code>V</code> below the threshold are set to zero.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>Block</code> containing the features and columns indices corresponding to each detected block.
</p>


<h3>References</h3>

<p><cite>Bauer, J.O. (2024). High-dimensional block diagonal covariance structure detection using singular vectors, J. Comput. Graph. Stat.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bdsvd">bdsvd</a></code>, <code><a href="#topic+single.bdsvd">single.bdsvd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#In the first example, we replicate the simulation study for the ad hoc procedure
#Est_0.1 from Bauer (2024). In the second example, we manually compute the first step
#of BD-SVD, which can be done using the bdsvd() and/or single.bdsvd(), for constructed
#sparse loadings

#Example 1: Replicate the simulation study (a) from Bauer (2024) for the ad hoc
#procedure Est_0.1.

## Not run: 
p &lt;- 500 #Number of variables
n &lt;- 125 #Number of observations
b &lt;- 500 #Number of blocks
design &lt;- "a"

#Simulate data matrix X
set.seed(1)
Sigma &lt;- bdsvd.cov.sim(p = p, b = b, design = design)
X &lt;- mvtnorm::rmvnorm(n, mean=rep(0, p), sigma=Sigma)
colnames(X) &lt;- 1:p

#Perform the ad hoc procedure
detect.blocks(cvCovEst::scadEst(dat = X, lambda = 0.2), threshold = 0)

## End(Not run)

#Example 2: Manually compute the first step of BD-SVD
#for some loadings V that mirror the two blocks
#("A", "B") and c("C", "D").

V &lt;- matrix(c(1,0,
              1,0,
              0,1,
              0,1), 4, 2, byrow = TRUE)

rownames(V) &lt;- c("A", "B", "C", "D")
detected.blocks &lt;- detect.blocks(V)

#Variables in block one with corresponding column index:
detected.blocks[[1]]@features
detected.blocks[[1]]@block.columns

#Variables in block two with corresponding column index:
detected.blocks[[2]]@features
detected.blocks[[2]]@block.columns

</code></pre>

<hr>
<h2 id='hcsvd'>Hierarchical Variable Clustering Using Singular Vectors (HC-SVD).</h2><span id='topic+hcsvd'></span>

<h3>Description</h3>

<p>Performs HC-SVD to reveal the hierarchical variable structure as descried in Bauer (202X). For this divise approach, each cluster is split into two clusters iteratively. Potential splits
are identified by the first sparse loadings (which are sparse approximations of the first right eigenvectors, i.e., vectors with many zero values, of the correlation matrix) that
mirror the masked shape of the correlation matrix. This procedure is continued until each variable lies in a single cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hcsvd(
  R,
  q = "Kaiser",
  linkage = "average",
  is.corr = TRUE,
  max.iter,
  trace = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hcsvd_+3A_r">R</code></td>
<td>
<p>A correlation matrix of dimension <code class="reqn">p</code>x<code class="reqn">p</code> or a data matrix of dimension <code class="reqn">n</code>x<code class="reqn">p</code> an be provided. If a data matrix is supplied, it must be indicated by setting
<code>is.corr = FALSE</code>, and the correlation matrix will then be calculated as <code>cor(X)</code>.</p>
</td></tr>
<tr><td><code id="hcsvd_+3A_q">q</code></td>
<td>
<p>Number of sparse loadings to be used. This should be either a numeric value between zero and one to indicate percentages, or <code>"Kaiser"</code> for as many sparse loadings as
there are eigenvalues larger or equal to one. For a numerical value between zero and one, the number of sparse loadings is determined as the corresponding share of the total number of loadings.
E.g., <code>q = 1</code> (100%) uses all sparse loadings and <code>q = 0.5</code> (50%) will use half of all sparse loadings.</p>
</td></tr>
<tr><td><code id="hcsvd_+3A_linkage">linkage</code></td>
<td>
<p>The linkage function to be used. This should be one of <code>"average"</code>, <code>"single"</code>, or
<code>"RV"</code> (for RV-coefficient).</p>
</td></tr>
<tr><td><code id="hcsvd_+3A_is.corr">is.corr</code></td>
<td>
<p>Is the supplied object a correlation matrix. Default is <code>TRUE</code> and this parameter must be set to <code>FALSE</code> is
a data matrix instead of a correlation matrix is supplied.</p>
</td></tr>
<tr><td><code id="hcsvd_+3A_max.iter">max.iter</code></td>
<td>
<p>How many iterations should be performed for computing the sparse loadings.
Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="hcsvd_+3A_trace">trace</code></td>
<td>
<p>Print out progress as <code class="reqn">p-1</code> iterations for divisive hierarchical clustering are performed.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sparse loadings are computed using the method of Shen and Huang (2008), which is implemented based on the code
of Baglama, Reichel, and Lewis in <code><a href="irlba.html#topic+ssvd">ssvd</a></code> {<a href="irlba.html#topic+irlba">irlba</a>}, with slight modifications to suit our method.
</p>


<h3>Value</h3>

<p>A list with four components:
</p>
<table role = "presentation">
<tr><td><code>hclust</code></td>
<td>

<p>The clustering structure identified by HC-SVD as an object of type <code>hclust</code>.
</p>
</td></tr>
<tr><td><code>dist.matrix</code></td>
<td>

<p>The ultrametric distance matrix (cophenetic matrix) of the HC-SVD structure as an object of class <code>dist</code>.
</p>
</td></tr>
<tr><td><code>u.cor</code></td>
<td>

<p>The ultrametric correlation matrix of <code class="reqn">X</code> obtained by HC-SVD as an object of class <code>matrix</code>.
</p>
</td></tr>
<tr><td><code>q.p</code></td>
<td>

<p>A vector of length <code class="reqn">p-1</code> containing the ratio <code class="reqn">q_i/p_i</code> of the <code class="reqn">q_i</code> sparse loadings used relative to all sparse
loadings <code class="reqn">q_i</code> for the split of each cluster. The ratio is set to <code>NA</code> if the cluster contains only two variables as the search
for sparse loadings that reflect the split is not required in this case.
</p>
</td></tr>
</table>


<h3>References</h3>

<p><cite>Bauer, J.O. (202X). Divisive hierarchical clustering identified by singular vectors.</cite>
</p>
<p><cite>Shen, H. and Huang, J.Z. (2008). Sparse principal component analysis via regularized low rank matrix approximation, J. Multivar. Anal. 99, 1015–1034.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#We replicate the simulation study (a) in Bauer (202X)

## Not run: 
p &lt;- 40
n &lt;- 500
b &lt;- 5
design &lt;- "a"

set.seed(1)
Rho &lt;- hcsvd.cor.sim(p = p, b = b, design = "a")
X &lt;- mvtnorm::rmvnorm(n, mean=rep(0, p), sigma = Rho, checkSymmetry = FALSE)
R &lt;- cor(X)
hcsvd.obj &lt;- hcsvd(R)

#The object of hclust with corresponding dendrogram can be obtained
#directly from hcsvd.obj$hclust:
hc &lt;- hcsvd.obj$hclust
plot(hc)

#The dendrogram can also be obtained from the ultrametric distance matrix:
plot(hclust(hcsvd.obj$dist.matrix))

## End(Not run)


</code></pre>

<hr>
<h2 id='hcsvd.cor.sim'>Correlation Matrix Simulation for HC-SVD</h2><span id='topic+hcsvd.cor.sim'></span>

<h3>Description</h3>

<p>This function generates correlation matrices based on the simulation studies described in Bauer (202X).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hcsvd.cor.sim(p = p, b = b, design = design)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hcsvd.cor.sim_+3A_p">p</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code id="hcsvd.cor.sim_+3A_b">b</code></td>
<td>
<p>Number of blocks.</p>
</td></tr>
<tr><td><code id="hcsvd.cor.sim_+3A_design">design</code></td>
<td>
<p>Simulation design &quot;a&quot; or &quot;b&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correlation matrix according to the chosen simulation design.
</p>


<h3>References</h3>

<p><cite>Bauer, J.O. (202X). Divisive hierarchical clustering identified by singular vectors.</cite>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#The correlation matrix for simulation design (a) is given by
#R &lt;- hcsvd.cov.sim(p = 40, b = 5, design = "a")

</code></pre>

<hr>
<h2 id='single.bdsvd'>Single Iteration of Block Detection Using Singular Vectors (BD-SVD).</h2><span id='topic+single.bdsvd'></span>

<h3>Description</h3>

<p>Performs a single iteration of BD-SVD: splits the data matrix into one (i.e., no split)
or two submatrices, depending on the structure of the first sparse loading <code class="reqn">v</code> (which is a sparse
approximation of the first right singular vector, i.e., a vector with many zero values) that mirrors the
shape of the covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>single.bdsvd(X, dof, standardize = TRUE, max.iter)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="single.bdsvd_+3A_x">X</code></td>
<td>
<p>Data matrix of dimension <code class="reqn">n x p</code> with possibly <code class="reqn">p &gt;&gt; n</code>.</p>
</td></tr>
<tr><td><code id="single.bdsvd_+3A_dof">dof</code></td>
<td>
<p>Number of non-zero components in the sparse loading (degrees of freedom). If
<code class="reqn">S</code> denotes the support of <code class="reqn">v</code>, then the cardinality of the support, <code class="reqn">|S|</code>,
corresponds to the degrees of freedom.</p>
</td></tr>
<tr><td><code id="single.bdsvd_+3A_standardize">standardize</code></td>
<td>
<p>Standardize the data to have unit variance. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="single.bdsvd_+3A_max.iter">max.iter</code></td>
<td>
<p>How many iterations should be performed for computing the sparse loading.
Default is <code>200</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sparse loadings are computed using the method by Shen &amp; Huang (2008), implemented in
the <code>irlba</code> package.
</p>


<h3>Value</h3>

<p>A list containing the feature names of the submatrices of <code>X</code>. It is either of length one (no
split) or length two (split into two submatrices).
</p>


<h3>References</h3>

<p><cite>Bauer, J.O. (2024). High-dimensional block diagonal covariance structure detection using singular vectors, J. Comput. Graph. Stat.</cite>
</p>
<p><cite>Shen, H. and Huang, J.Z. (2008). Sparse principal component analysis via regularized low rank matrix approximation, J. Multivar. Anal. 99, 1015–1034.</cite>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bdsvd">bdsvd</a></code>, <code><a href="#topic+bdsvd.ht">bdsvd.ht</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Replicate the illustrative example from Bauer (2024).

## Not run: 

p &lt;- 300 #Number of variables. In Bauer (2024), p = 3000.
n &lt;- 500 #Number of observations
b &lt;- 3   #Number of blocks
design &lt;- "c"

#Simulate data matrix X
set.seed(1)
Sigma &lt;- bdsvd.cov.sim(p = p, b = b, design = design)
X &lt;- mvtnorm::rmvnorm(n, mean = rep(0, p), sigma = Sigma)
colnames(X) &lt;- 1:p

ht &lt;- bdsvd.ht(X)
plot(0:(p-1), ht$BIC[,1], xlab = "|S|", ylab = "HBIC", main = "", type = "l")
single.bdsvd(X, dof = ht$dof, standardize = FALSE)


## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
