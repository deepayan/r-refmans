<!DOCTYPE html><html><head><title>Help for package frbs</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {frbs}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ANFIS'><p>ANFIS model building</p></a></li>
<li><a href='#ANFIS.update'><p>ANFIS updating function</p></a></li>
<li><a href='#data.gen3d'><p>A data generator</p></a></li>
<li><a href='#defuzzifier'><p>Defuzzifier to transform from linguistic terms to crisp values</p></a></li>
<li><a href='#DENFIS'><p>DENFIS model building</p></a></li>
<li><a href='#DENFIS.eng'><p>DENFIS prediction function</p></a></li>
<li><a href='#denorm.data'><p>The data de-normalization</p></a></li>
<li><a href='#DM.update'><p>FIR.DM updating function</p></a></li>
<li><a href='#ECM'><p>Evolving Clustering Method</p></a></li>
<li><a href='#FH.GBML'><p>FH.GBML model building</p></a></li>
<li><a href='#FIR.DM'><p>FIR.DM model building</p></a></li>
<li><a href='#FRBCS.CHI'><p>FRBCS.CHI model building</p></a></li>
<li><a href='#FRBCS.eng'><p>FRBCS: prediction phase</p></a></li>
<li><a href='#FRBCS.W'><p>FRBCS.W model building</p></a></li>
<li><a href='#frbs-package'><p>Getting started with the frbs package</p></a></li>
<li><a href='#frbs.eng'><p>The prediction phase</p></a></li>
<li><a href='#frbs.gen'><p>The frbs model generator</p></a></li>
<li><a href='#frbs.learn'><p>The frbs model building function</p></a></li>
<li><a href='#frbsData'><p>Data set of the package</p></a></li>
<li><a href='#frbsObjectFactory'><p>The object factory for frbs objects</p></a></li>
<li><a href='#frbsPMML'><p>The frbsPMML generator</p></a></li>
<li><a href='#FS.HGD'><p>FS.HGD model building</p></a></li>
<li><a href='#fuzzifier'><p>Transforming from crisp set into linguistic terms</p></a></li>
<li><a href='#GFS.FR.MOGUL'><p>GFS.FR.MOGUL model building</p></a></li>
<li><a href='#GFS.FR.MOGUL.test'><p>GFS.FR.MOGUL: The prediction phase</p></a></li>
<li><a href='#GFS.GCCL'><p>GFS.GCCL model building</p></a></li>
<li><a href='#GFS.GCCL.eng'><p>GFS.GCCL.test: The prediction phase</p></a></li>
<li><a href='#GFS.LT.RS'><p>GFS.LT.RS model building</p></a></li>
<li><a href='#GFS.LT.RS.test'><p>GFS.LT.RS: The prediction phase</p></a></li>
<li><a href='#GFS.Thrift'><p>GFS.Thrift model building</p></a></li>
<li><a href='#GFS.Thrift.test'><p>GFS.Thrift: The prediction phase</p></a></li>
<li><a href='#HGD.update'><p>FS.HGD updating function</p></a></li>
<li><a href='#HyFIS'><p>HyFIS model building</p></a></li>
<li><a href='#HyFIS.update'><p>HyFIS updating function</p></a></li>
<li><a href='#inference'><p>The process of fuzzy reasoning</p></a></li>
<li><a href='#norm.data'><p>The data normalization</p></a></li>
<li><a href='#plotMF'><p>The plotting function</p></a></li>
<li><a href='#predict.frbs'><p>The frbs prediction stage</p></a></li>
<li><a href='#read.frbsPMML'><p>The frbsPMML reader</p></a></li>
<li><a href='#rulebase'><p>The rule checking function</p></a></li>
<li><a href='#SBC'><p>The subtractive clustering and fuzzy c-means (SBC) model building</p></a></li>
<li><a href='#SBC.test'><p>SBC prediction phase</p></a></li>
<li><a href='#SLAVE'><p>SLAVE model building</p></a></li>
<li><a href='#SLAVE.test'><p>SLAVE.test: The prediction phase</p></a></li>
<li><a href='#summary.frbs'><p>The summary function for frbs objects</p></a></li>
<li><a href='#WM'><p>WM model building</p></a></li>
<li><a href='#write.frbsPMML'><p>The frbsPMML writer</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Maintainer:</td>
<td>Christoph Bergmeir &lt;c.bergmeir@decsai.ugr.es&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE [expanded from: GPL (&ge; 2) | file LICENSE]</td>
</tr>
<tr>
<td>Title:</td>
<td>Fuzzy Rule-Based Systems for Classification and Regression Tasks</td>
</tr>
<tr>
<td>Author:</td>
<td>Lala Septem Riza, Christoph Bergmeir, Francisco Herrera, and
    Jose Manuel Benitez</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of various learning algorithms based on fuzzy rule-based systems (FRBSs) for dealing with classification and regression tasks. Moreover, it allows to construct an FRBS model defined by human experts. 
    FRBSs are based on the concept of fuzzy sets, proposed by Zadeh in 1965, which aims at
    representing the reasoning of human experts in a set of IF-THEN rules, to
    handle real-life problems in, e.g., control, prediction and inference, data
    mining, bioinformatics data processing, and robotics. FRBSs are also known
    as fuzzy inference systems and fuzzy models. During the modeling of an
    FRBS, there are two important steps that need to be conducted: structure
    identification and parameter estimation. Nowadays, there exists a wide
    variety of algorithms to generate fuzzy IF-THEN rules automatically from
    numerical data, covering both steps. Approaches that have been used in the
    past are, e.g., heuristic procedures, neuro-fuzzy techniques, clustering
    methods, genetic algorithms, squares methods, etc. Furthermore, in this
    version we provide a universal framework named 'frbsPMML', which is adopted
    from the Predictive Model Markup Language (PMML), for representing FRBS
    models. PMML is an XML-based language to provide a standard for describing
    models produced by data mining and machine learning algorithms. Therefore,
    we are allowed to export and import an FRBS model to/from 'frbsPMML'.
    Finally, this package aims to implement the most widely used standard
    procedures, thus offering a standard package for FRBS modeling to the R
    community.</td>
</tr>
<tr>
<td>Version:</td>
<td>3.2-0</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://sci2s.ugr.es/dicits/software/FRBS">http://sci2s.ugr.es/dicits/software/FRBS</a></td>
</tr>
<tr>
<td>Date:</td>
<td>2019-12-15</td>
</tr>
<tr>
<td>Suggests:</td>
<td>class, e1071, XML, R.rsp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-12-15 01:48:46 UTC; bergmeir</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-12-15 06:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ANFIS'>ANFIS model building</h2><span id='topic+ANFIS'></span>

<h3>Description</h3>

<p>This is the internal function that implements the adaptive-network-based 
fuzzy inference system (ANFIS). It is used to solve regression tasks. 
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ANFIS(data.train, num.labels, max.iter = 10, step.size = 0.01,
  type.tnorm = "MIN", type.snorm = "MAX",
  type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ANFIS_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="ANFIS_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>), whose elements represent the number of labels (linguistic terms); 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="ANFIS_+3A_max.iter">max.iter</code></td>
<td>
<p>the maximal number of iterations.</p>
</td></tr>
<tr><td><code id="ANFIS_+3A_step.size">step.size</code></td>
<td>
<p>a real number between 0 and 1 representing the step size of 
the gradient descent.</p>
</td></tr>
<tr><td><code id="ANFIS_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="ANFIS_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="ANFIS_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a value representing the type of implication functions. 
For more detail, please have a look at <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by J. S. R. Jang. It uses the Takagi Sugeno Kang model
on the consequent part of the fuzzy IF-THEN rules.  
The ANFIS architecture consists of two processes, the forward and the backward stage.
The forward stage has five layers as follows:
</p>

<ul>
<li><p> Layer 1: The fuzzification process which transforms crisp values into 
linguistic terms using the Gaussian function as the shape of the membership function.
</p>
</li>
<li><p> Layer 2: The inference stage using the t-norm operator (the AND operator).
</p>
</li>
<li><p> Layer 3: Calculating the ratio of the strengths of the rules.
</p>
</li>
<li><p> Layer 4: Calculating the consequent parameters.
</p>
</li>
<li><p> Layer 5: Calculating the overall output as the sum of all incoming signals.
</p>
</li></ul>

<p>The backward stage is a process of parameter learning. In this step, the least squares method 
is used in order to obtain 
the parameters, which are coefficients of linear equations on the consequent part, and 
mean and variance on the antecedent part.
</p>


<h3>References</h3>

<p>J.S.R. Jang, &quot;ANFIS: Adaptive-network-based fuzzy inference system&quot;,
IEEE Transactions on Systems, Man, and Cybernetics, vol. 23, no. 3, pp. 665 - 685 (1993).
</p>
<p>J.S.R. Jang, C.T. Sun, and E. Mizutani., &quot;Neuro-fuzzy and soft computing: 
a computational approach to learning and machine intelligence&quot;, Prentice-Hall, Inc (1997).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ANFIS.update">ANFIS.update</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='ANFIS.update'>ANFIS updating function</h2><span id='topic+ANFIS.update'></span>

<h3>Description</h3>

<p>The role of this function is to update parameters in the ANFIS method. 
This function is called by the main function of the ANFIS method, <code><a href="#topic+ANFIS">ANFIS</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ANFIS.update(data.train, def, rule.data.num, miu.rule, func.tsk, varinp.mf,
  step.size = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ANFIS.update_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.</p>
</td></tr>
<tr><td><code id="ANFIS.update_+3A_def">def</code></td>
<td>
<p>a predicted value</p>
</td></tr>
<tr><td><code id="ANFIS.update_+3A_rule.data.num">rule.data.num</code></td>
<td>
<p>a matrix containing the rule base in integer form.</p>
</td></tr>
<tr><td><code id="ANFIS.update_+3A_miu.rule">miu.rule</code></td>
<td>
<p>a matrix with the degrees of rules. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="ANFIS.update_+3A_func.tsk">func.tsk</code></td>
<td>
<p>a matrix of parameters of the function on the consequent part using the Takagi Sugeno Kang model.</p>
</td></tr>
<tr><td><code id="ANFIS.update_+3A_varinp.mf">varinp.mf</code></td>
<td>
<p>a matrix of parameters of membership functions of the input variables.</p>
</td></tr>
<tr><td><code id="ANFIS.update_+3A_step.size">step.size</code></td>
<td>
<p>a real number between 0 and 1 representing the step size of 
the gradient descent.</p>
</td></tr>
</table>

<hr>
<h2 id='data.gen3d'>A data generator</h2><span id='topic+data.gen3d'></span>

<h3>Description</h3>

<p>The purpose of this function is to generate data, which contains 
two input variables and one output variable, automatically for all values on a plane.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.gen3d(range.input, num.grid = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.gen3d_+3A_range.input">range.input</code></td>
<td>
<p>the range of the input variables, as a matrix (<code class="reqn">2 \times n</code>).</p>
</td></tr>
<tr><td><code id="data.gen3d_+3A_num.grid">num.grid</code></td>
<td>
<p>a number representing the size of the grid on the plane.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the data
</p>


<h3>Examples</h3>

<pre><code class='language-R'>range.input &lt;- matrix(c(0, 100, 0, 100), nrow=2)
num.grid &lt;- 10
data.test &lt;- data.gen3d(range.input, num.grid)
</code></pre>

<hr>
<h2 id='defuzzifier'>Defuzzifier to transform from linguistic terms to crisp values</h2><span id='topic+defuzzifier'></span>

<h3>Description</h3>

<p>Defuzzification is a transformation that extracts the crisp values from the linguistic terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>defuzzifier(data, rule = NULL, range.output = NULL,
  names.varoutput = NULL, varout.mf = NULL, miu.rule,
  type.defuz = NULL, type.model = "TSK", func.tsk = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="defuzzifier_+3A_data">data</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_rule">rule</code></td>
<td>
<p>a list or matrix of fuzzy IF-THEN rules, as discussed in <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_range.output">range.output</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the output data.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_names.varoutput">names.varoutput</code></td>
<td>
<p>a list for giving names to the linguistic terms. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_varout.mf">varout.mf</code></td>
<td>
<p>a matrix constructing the membership function of the output variable. 
See <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_miu.rule">miu.rule</code></td>
<td>
<p>the results of the inference module. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_type.defuz">type.defuz</code></td>
<td>
<p>the type of defuzzification to be used as follows. 
</p>

<ul>
<li> <p><code>1</code> or <code>WAM</code> means weighted average method, 
</p>
</li>
<li> <p><code>2</code> or <code>FIRST.MAX</code> means first maxima,
</p>
</li>
<li> <p><code>3</code> or <code>LAST.MAX</code> means last maxima,
</p>
</li>
<li> <p><code>4</code> or <code>MEAN.MAX</code> means mean maxima,
</p>
</li>
<li> <p><code>5</code> or <code>COG</code> means modified center of gravity (COG).
</p>
</li></ul>
</td></tr>
<tr><td><code id="defuzzifier_+3A_type.model">type.model</code></td>
<td>
<p>the type of the model that will be used in the simulation. 
Here, <code>1</code> or <code>MAMDANI</code> and <code>2</code> or <code>TSK</code> 
means we use Mamdani or Takagi Sugeno Kang model, respectively.</p>
</td></tr>
<tr><td><code id="defuzzifier_+3A_func.tsk">func.tsk</code></td>
<td>
<p>a matrix used to build the linear equation for the consequent part 
if we are using Takagi Sugeno Kang. See also <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this function, there exist two kinds of models which are based on the Mamdani and 
Takagi Sugeno Kang model. 
For the Mamdani model there are five methods for defuzzifying a linguistic term <code class="reqn">A</code> of a universe 
of discourse <code class="reqn">Z</code>. 
They are as follows:
</p>

<ol>
<li><p> weighted average method (<code>WAM</code>).
</p>
</li>
<li><p> first of maxima (<code>FIRST.MAX</code>).
</p>
</li>
<li><p> last of maxima (<code>LAST.MAX</code>)
</p>
</li>
<li><p> mean of maxima (<code>MEAN.MAX</code>).
</p>
</li>
<li><p> modified center of gravity (<code>COG</code>).
</p>
</li></ol>



<h3>Value</h3>

<p>A matrix of crisp values
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fuzzifier">fuzzifier</a></code>, <code><a href="#topic+rulebase">rulebase</a></code>, and <code><a href="#topic+inference">inference</a></code>
</p>

<hr>
<h2 id='DENFIS'>DENFIS model building</h2><span id='topic+DENFIS'></span>

<h3>Description</h3>

<p>This is the internal function that implements the dynamic evolving neural-fuzzy inference system (DENFIS). 
It is used to handle regression tasks. Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DENFIS(data.train, range.data.ori, Dthr = 0.1, max.iter = 100,
  step.size = 0.01, d = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DENFIS_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables (input and output variables).</p>
</td></tr>
<tr><td><code id="DENFIS_+3A_range.data.ori">range.data.ori</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum values, respectively.</p>
</td></tr>
<tr><td><code id="DENFIS_+3A_dthr">Dthr</code></td>
<td>
<p>the threshold value for the evolving clustering method (ECM), between 0 and 1.</p>
</td></tr>
<tr><td><code id="DENFIS_+3A_max.iter">max.iter</code></td>
<td>
<p>the maximal number of iterations.</p>
</td></tr>
<tr><td><code id="DENFIS_+3A_step.size">step.size</code></td>
<td>
<p>the step size of the least squares method, between 0 and 1.</p>
</td></tr>
<tr><td><code id="DENFIS_+3A_d">d</code></td>
<td>
<p>a parameter for the width of the triangular membership function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by Nikola K. Kasabov and Q. Song. There are several steps in this method that 
are to determine the cluster centers using the evolving clustering method (ECM), to partition the input space 
and to find optimal parameters on the consequent part (Takagi Sugeno Kang model) for the IF-THEN rule using a least 
squares estimator.
</p>
<p>ECM is a distance-based clustering method which is determined by a threshold value, <code>Dthr</code>. This parameter 
influences how many clusters are created. In the beginning of the clustering process, the first instance from the 
training data is chosen to be a cluster center, and the determining radius is set to zero. Afterwards, using the 
next instance, cluster centers and radius are changed based on certain mechanisms of ECM (please see <code><a href="#topic+ECM">ECM</a></code>). 
All of the cluster centers are then obtained after evaluating all the training data. 
The next step is to update the parameters on the consequent part with the assumption that the antecedent part which we got from ECM is fixed. 
Actually, ECM can perform well as an online clustering method, but in this package it is used in an offline mode.
</p>


<h3>References</h3>

<p>N.K. Kasabov and Q. Song, &quot;DENFIS: Dynamic evolving neural-fuzzy inference system and its Application for time-series prediction&quot;, 
IEEE Transactions on Fuzzy Systems, vol. 10, no. 2, pp. 144 - 154 (2002).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DENFIS.eng">DENFIS.eng</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='DENFIS.eng'>DENFIS prediction function</h2><span id='topic+DENFIS.eng'></span>

<h3>Description</h3>

<p>This function is an internal function for the prediction phase using the DENFIS method. 
The user should use this function not directly, but with calling <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DENFIS.eng(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DENFIS.eng_+3A_object">object</code></td>
<td>
<p>the frbs model. See <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="DENFIS.eng_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and <code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of predicted values
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DENFIS">DENFIS</a></code>
</p>

<hr>
<h2 id='denorm.data'>The data de-normalization</h2><span id='topic+denorm.data'></span>

<h3>Description</h3>

<p>This function is to transform from normalized data into real-valued data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>denorm.data(dt.norm, range.data, min.scale = 0, max.scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="denorm.data_+3A_dt.norm">dt.norm</code></td>
<td>
<p>a matrix (<code class="reqn">n \times m</code>) of the normalized data.</p>
</td></tr>
<tr><td><code id="denorm.data_+3A_range.data">range.data</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum value, respectively.</p>
</td></tr>
<tr><td><code id="denorm.data_+3A_min.scale">min.scale</code></td>
<td>
<p>the minimum value within normalization.</p>
</td></tr>
<tr><td><code id="denorm.data_+3A_max.scale">max.scale</code></td>
<td>
<p>the maximum value within normalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the real-valued data
</p>


<h3>See Also</h3>

<p><code><a href="#topic+norm.data">norm.data</a></code>
</p>

<hr>
<h2 id='DM.update'>FIR.DM updating function</h2><span id='topic+DM.update'></span>

<h3>Description</h3>

<p>The role of this function is to update the parameters of the fuzzy inference rules by descent method (FIR.DM). 
This function is called by the main function of the FIR.DM method, <code><a href="#topic+FIR.DM">FIR.DM</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DM.update(data.train, rule.data.num, miu.rule, func.tsk, varinp.mf,
  step.size = 0.01, def)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DM.update_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.</p>
</td></tr>
<tr><td><code id="DM.update_+3A_rule.data.num">rule.data.num</code></td>
<td>
<p>a matrix containing the rulebase. Its elements are integers, see <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="DM.update_+3A_miu.rule">miu.rule</code></td>
<td>
<p>a matrix with the degrees of rules which is a result of the <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="DM.update_+3A_func.tsk">func.tsk</code></td>
<td>
<p>a matrix of parameters of the functions on the consequent part of the Takagi Sugeno Kang model.</p>
</td></tr>
<tr><td><code id="DM.update_+3A_varinp.mf">varinp.mf</code></td>
<td>
<p>a matrix of parameters of the membership functions of the input variables.</p>
</td></tr>
<tr><td><code id="DM.update_+3A_step.size">step.size</code></td>
<td>
<p>the step size of the descent method, between 0 and 1.</p>
</td></tr>
<tr><td><code id="DM.update_+3A_def">def</code></td>
<td>
<p>a matrix which is obtained from the defuzzification. Please have a look at <code><a href="#topic+defuzzifier">defuzzifier</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+frbs.learn">frbs.learn</a></code>, <code><a href="#topic+predict">predict</a></code>, and <code><a href="#topic+FIR.DM">FIR.DM</a></code>.
</p>

<hr>
<h2 id='ECM'>Evolving Clustering Method</h2><span id='topic+ECM'></span>

<h3>Description</h3>

<p>This function is a part of the DENFIS method to generate cluster centers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ECM(data.train, Dthr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ECM_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for training, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables where the last column is the output variable.</p>
</td></tr>
<tr><td><code id="ECM_+3A_dthr">Dthr</code></td>
<td>
<p>the threshold value for the evolving clustering method (ECM), between 0 and 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of cluster centers
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DENFIS">DENFIS</a></code> and <code><a href="#topic+DENFIS.eng">DENFIS.eng</a></code>
</p>

<hr>
<h2 id='FH.GBML'>FH.GBML model building</h2><span id='topic+FH.GBML'></span>

<h3>Description</h3>

<p>This is the internal function that implements the Ishibuchi's method based on 
hybridization of genetic cooperative-competitive learning (GCCL) and Pittsburgh (FH.GBML). It is used to solve classification tasks.
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FH.GBML(data.train, popu.size = 10, max.num.rule = 5,
  persen_cross = 0.6, persen_mutant = 0.3, max.gen = 10, num.class,
  range.data.input, p.dcare = 0.5, p.gccl = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FH.GBML_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_popu.size">popu.size</code></td>
<td>
<p>the size of the population which is generated in each generation.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_max.num.rule">max.num.rule</code></td>
<td>
<p>the maximum number of rules.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_persen_cross">persen_cross</code></td>
<td>
<p>a real number between 0 and 1 determining the probability of crossover.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_persen_mutant">persen_mutant</code></td>
<td>
<p>a real number between 0 and 1 determining the probability of mutation.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_max.gen">max.gen</code></td>
<td>
<p>the maximal number of generations for the genetic algorithms.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_num.class">num.class</code></td>
<td>
<p>a number of the classes.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_range.data.input">range.data.input</code></td>
<td>
<p>a matrix containing the ranges of the normalized input data.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_p.dcare">p.dcare</code></td>
<td>
<p>a probability of &quot;don't care&quot; attributes occurred.</p>
</td></tr>
<tr><td><code id="FH.GBML_+3A_p.gccl">p.gccl</code></td>
<td>
<p>a probability of GCCL process occurred.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is based on Ishibuchi's method using the hybridization 
of GCCL and the Pittsburgh approach for genetic fuzzy systems. 
The algorithm of this method is as follows:
</p>

<ul>
<li><p> Step 1: Generate population where each individual in the population is a fuzzy rule set. 
</p>
</li>
<li><p> Step 2: Calculate the fitness value of each rule set in the current population.
</p>
</li>
<li><p> Step 3: Generate new rule sets by the selection, crossover, and mutation in 
the same manner as the Pittsburgh-style algorithm. Then, apply iterations of 
the GCCL to each of the generated rule sets with a probability. 
</p>
</li>
<li><p> Step 4: Add the best rule set in the current population to newly generated rule sets 
to form the next population.
</p>
</li>
<li><p> Step 5: Return to Step 2 if the prespecified stopping condition is not satisfied. 
</p>
</li></ul>



<h3>References</h3>

<p>H. Ishibuchi, T. Yamamoto, and T. Nakashima, &quot;Hybridization of fuzzy GBML approaches for pattern classification 
problems,&quot; IEEE Trans. on Systems, Man, and Cybernetics-Part B: Cybernetics, 
vol. 35, no. 2, pp. 359 - 365 (2005).
</p>

<hr>
<h2 id='FIR.DM'>FIR.DM model building</h2><span id='topic+FIR.DM'></span>

<h3>Description</h3>

<p>This is the internal function that implements the fuzzy inference rules by descent method (FIR.DM).
It is used to solve regression tasks. Users do not need to call it directly, 
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FIR.DM(data.train, num.labels, max.iter, step.size, type.tnorm = "MIN",
  type.snorm = "MAX", type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FIR.DM_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for training, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables. The last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="FIR.DM_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>) whose elements represent the number of labels (fuzzy terms),
where <code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="FIR.DM_+3A_max.iter">max.iter</code></td>
<td>
<p>the maximal number of iterations.</p>
</td></tr>
<tr><td><code id="FIR.DM_+3A_step.size">step.size</code></td>
<td>
<p>the step size of the descent method, between 0 and 1.</p>
</td></tr>
<tr><td><code id="FIR.DM_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FIR.DM_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FIR.DM_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a value representing type of implication function. For more detail, please have a look at <code><a href="#topic+WM">WM</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by H. Nomura, I. Hayashi, and N. Wakami. FIR.DM uses simplified fuzzy 
reasoning where the consequent part is a real number (a particular case within the Takagi Sugeno Kang model),
while the membership function on the 
antecedent part is expressed by an isosceles triangle. So, in the learning phase, FIR.DM updates three parameters 
which are center and width of the triangular and a real number on the consequent part using a descent method.
</p>


<h3>References</h3>

<p>H. Nomura, I. Hayashi and N. Wakami, &quot;A learning method of fuzzy inference rules by descent method&quot;, 
IEEE International Conference on Fuzzy Systems, pp. 203 - 210 (1992).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DM.update">DM.update</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>.
</p>

<hr>
<h2 id='FRBCS.CHI'>FRBCS.CHI model building</h2><span id='topic+FRBCS.CHI'></span>

<h3>Description</h3>

<p>This is the internal function that implements the fuzzy rule-based classification 
system using Chi's technique (FRBCS.CHI). It is used to solve classification tasks. 
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>. This method is
suitable only for classification problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FRBCS.CHI(range.data, data.train, num.labels, num.class,
  type.mf = "TRIANGLE", type.tnorm = "MIN", type.snorm = "MAX",
  type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FRBCS.CHI_+3A_range.data">range.data</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the normalized data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum values, respectively.</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable. Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>), whose elements represent the number of labels (linguistic terms); 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_num.class">num.class</code></td>
<td>
<p>an integer number representing the number of labels (linguistic terms).</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_type.mf">type.mf</code></td>
<td>
<p>the type of the shape of the membership functions. See <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FRBCS.CHI_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>the type of implication function. See <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by Z. Chi, H. Yan, and T. Pham that extends
Wang and Mendel's method for tackling classification problems. 
Basically, the algorithm is quite similar as Wang and Mendel's technique. 
However, since it is based on the FRBCS model, Chi's method only takes class labels on each data
to be consequent parts of fuzzy IF-THEN rules. In other words, we generate rules as in 
Wang and Mendel's technique (<code><a href="#topic+WM">WM</a></code>) and then we replace consequent parts with their classes. 
Regarding calculating degress of each rule, they are determined by antecedent parts of the rules. 
Redudant rules can be deleted by considering their degrees. Lastly, we obtain fuzzy IF-THEN rules 
based on the FRBCS model.
</p>


<h3>References</h3>

<p>Z. Chi, H. Yan, T. Pham, &quot;Fuzzy algorithms with applications to image processing 
and pattern recognition&quot;, World Scientific, Singapore (1996).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FRBCS.eng">FRBCS.eng</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='FRBCS.eng'>FRBCS: prediction phase</h2><span id='topic+FRBCS.eng'></span>

<h3>Description</h3>

<p>This function is the internal function of the fuzzy rule-based classification systems (FRBCS) to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FRBCS.eng(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FRBCS.eng_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="FRBCS.eng_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, 
where <code class="reqn">m</code> is the number of instances and <code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>

<hr>
<h2 id='FRBCS.W'>FRBCS.W model building</h2><span id='topic+FRBCS.W'></span>

<h3>Description</h3>

<p>This is the internal function that implements the fuzzy rule-based classification 
system with weight factor (FRBCS.W). It is used to solve classification tasks. 
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>. This method is
suitable only for classification problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FRBCS.W(range.data, data.train, num.labels, num.class, type.mf,
  type.tnorm = "MIN", type.snorm = "MAX",
  type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FRBCS.W_+3A_range.data">range.data</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the normalized data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum values, respectively.</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable. Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>), whose elements represent the number of labels (linguistic terms); 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_num.class">num.class</code></td>
<td>
<p>an integer number representing the number of labels (linguistic terms).</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_type.mf">type.mf</code></td>
<td>
<p>the type of the shape of the membership functions.</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FRBCS.W_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>the type of implication function. See <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is adopted from Ishibuchi and Nakashima's paper. 
Each fuzzy IF-THEN rule consists of antecedent linguistic values and a single consequent class with certainty grades 
(weights). The antecedent part is determined by a grid-type fuzzy partition from 
the training data. The consequent class is defined as the dominant class in 
the fuzzy subspace corresponding to the antecedent part of each fuzzy IF-THEN rule and 
the certainty grade is calculated from the ratio among the consequent class. 
A class of the new instance is determined by the consequent class of the rule with 
the maximal product of the compatibility grade and the certainty grade.
</p>


<h3>References</h3>

<p>H. Ishibuchi and T. Nakashima, &quot;Effect of rule weights in fuzzy rule-based classification systems&quot;, 
IEEE Transactions on Fuzzy Systems, vol. 1, pp. 59 - 64 (2001).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FRBCS.eng">FRBCS.eng</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='frbs-package'>Getting started with the frbs package</h2><span id='topic+frbs-package'></span><span id='topic+frbs'></span>

<h3>Description</h3>

<p>Fuzzy rule-based systems (FRBSs) are based on the fuzzy concept 
proposed by Zadeh in 1965, which represents the reasoning of human experts in production 
rules (a set of IF-THEN rules) to handle real-life problems from domains 
such as control, prediction and inference, data mining, bioinformatics data processing, 
robotics, and speech recognition. FRBSs are also known as fuzzy inference systems and 
fuzzy models. When applied to specific tasks, they may also be known under specific names 
such as fuzzy associative memories or fuzzy controllers.
In this package, we consider systems with multi-inputs and single-output (MISO), 
with real-valued data.
</p>


<h3>Details</h3>

<p>FRBSs are a competitive alternative to other classic models and algorithms in order to 
solve classification and regression problems. Generally, 
an FRBS consists of four functional parts: 
</p>

<ul>
<li><p> a fuzzification interface which transforms the crisp inputs into degrees 
of membership functions of the linguistic term of each variable. 
See <code><a href="#topic+fuzzifier">fuzzifier</a></code>.
</p>
</li>
<li><p> a knowledge base consisting of a database (DB) and a rulebase (RB). While the database includes 
the fuzzy set definitions, the rulebase contains fuzzy IF-THEN rules. 
We will represent the knowledge as a set of rules. Each one has the following structure.
</p>
<p><code>IF premise (antecedent) THEN conclusion (consequent)</code>
</p>
<p>See <code><a href="#topic+rulebase">rulebase</a></code>.
</p>
</li>
<li><p> an inference engine which performs the inference operations on the fuzzy IF-THEN rules. 
There are two kinds of inference for fuzzy systems based on linguistic rules: 
The Mamdani and the Takagi Sugeno Kang model. See <code><a href="#topic+inference">inference</a></code>.
</p>
</li>
<li><p> a defuzzification process to obtain the crisp values from linguistic values. There are several methods for 
defuzzification such as the weighted average, centroid, etc. 
See <code><a href="#topic+defuzzifier">defuzzifier</a></code>.
</p>
</li></ul>

<p>Since it may be difficult to obtain information from human experts in the form required,
an alternative and effective way to acquire the knowledge is to generate 
the fuzzy IF-THEN rules automatically from the numerical training data. 
In general, when modeling an FRBS, there are two important processes which should be conducted, 
namely structure identification and parameter estimation. 
Structure identification is a process to find appropriate fuzzy IF-THEN rules
and to determine the overall number of rules. 
Parameter estimation is applied to tune parameters of membership functions.
Many approaches have been proposed 
in order to perform this modeling such as a table-lookup scheme, heuristic procedures,
neuro-fuzzy techniques, clustering methods, genetic algorithms, least squares methods,
gradient descent, etc. In this package, the following approaches to generate 
fuzzy IF-THEN rules have been implemented: 
</p>

<ol>
<li><p> FRBS based on space partition
</p>

<ul>
<li><p> Wang and Mendel's technique (<code>WM</code>): It is used to solve regression tasks. See <code><a href="#topic+WM">WM</a></code>.
</p>
</li>
<li><p> Chi's technique (<code>FRBCS.CHI</code>): It is used to solve classification tasks. See <code><a href="#topic+FRBCS.CHI">FRBCS.CHI</a></code>.
</p>
</li>
<li><p> Ishibuchi's technique using weight factor (<code>FRBCS.W</code>): It is used to solve classification tasks. See <code><a href="#topic+FRBCS.W">FRBCS.W</a></code>.
</p>
</li></ul>

</li>
<li><p> FRBS based on neural networks
</p>

<ul>
<li><p> The adaptive-network-based fuzzy inference system (<code>ANFIS</code>): 
It is used to solve regression tasks. See <code><a href="#topic+ANFIS">ANFIS</a></code>.
</p>
</li>
<li><p> The hybrid neural fuzzy inference system (<code>HYFIS</code>): It is used to solve regression tasks. See <code><a href="#topic+HyFIS">HyFIS</a></code>.
</p>
</li></ul>

</li>
<li><p> FRBS based on clustering approach
</p>

<ul>
<li><p> The subtractive clustering and fuzzy c-means (<code>SBC</code>): It is used to solve regression tasks. See <code><a href="#topic+SBC">SBC</a></code>.
</p>
</li>
<li><p> The dynamic evolving neural-fuzzy inference system (<code>DENFIS</code>): 
It is used to solve regression tasks. See <code><a href="#topic+DENFIS">DENFIS</a></code>.
</p>
</li></ul>

</li>
<li><p> FRBS based on genetic algorithms
</p>

<ul>
<li><p> The Thrift's method (<code>GFS.THRIFT</code>): It is used to solve regression tasks. See <code><a href="#topic+GFS.Thrift">GFS.Thrift</a></code>.
</p>
</li>
<li><p> The Genetic fuzzy systems for fuzzy rule learning based on the MOGUL methodology (<code>GFS.FR.MOGUL</code>):
It is used to solve regression tasks. See <code><a href="#topic+GFS.FR.MOGUL">GFS.FR.MOGUL</a></code>.
</p>
</li>
<li><p> The Ishibuchi's method based on genetic cooperative-competitive learning (<code>GFS.GCCL</code>):
It is used to solve classification tasks. See <code><a href="#topic+GFS.GCCL">GFS.GCCL</a></code>.
</p>
</li>
<li><p> The Ishibuchi's method based on hybridization of genetic cooperative-competitive learning (GCCL) and Pittsburgh (<code>FH.GBML</code>):
It is used to solve classification tasks. See <code><a href="#topic+FH.GBML">FH.GBML</a></code>.
</p>
</li>
<li><p> The structural learning algorithm on vague environtment (<code>SLAVE</code>):
It is used to solve classification tasks. See <code><a href="#topic+SLAVE">SLAVE</a></code>.
</p>
</li>
<li><p> The genetic for lateral tuning and rule selection of linguistic fuzzy system (<code>GFS.LT.RS</code>): 
It is used to solve regression tasks. See <code><a href="#topic+GFS.LT.RS">GFS.LT.RS</a></code>.
</p>
</li></ul>

</li>
<li><p> FRBS based on the gradient descent method
</p>

<ul>
<li><p> The FRBS using heuristics and gradient descent method (<code>FS.HGD</code>): 
It is used to solve regression tasks. See <code><a href="#topic+FS.HGD">FS.HGD</a></code>
</p>
</li>
<li><p> The fuzzy inference rules by descent method (<code>FIR.DM</code>): 
It is used to solve regression tasks. See <code><a href="#topic+FIR.DM">FIR.DM</a></code>
</p>
</li></ul>

</li></ol>

<p>The functions documented in the manual for the single methods are all called internally 
by <code><a href="#topic+frbs.learn">frbs.learn</a></code>, which is the central function of the package. 
However, in the documentation of each of the internal learning functions, 
we give some theoretical background and references to the original literature.
</p>
<p><b>Usage of the package:</b>
</p>
<p>First of all, if you have problems using the package, find a bug, or have suggestions, 
please contact the package maintainer by email, instead of writing to the general R lists 
or to other internet forums and mailing lists.
</p>
<p>The main functions of the package are the following:
</p>

<ul>
<li><p> The function <code><a href="#topic+frbs.learn">frbs.learn</a></code> allows to generate the model by 
creating fuzzy IF-THEN rules or cluster centers from training data. 
In other words, users just need to call this function to generate an FRBS model from 
training data. The different algorithms mentioned above are all accessible through this function. 
The outcome of the function is an <code><a href="#topic+frbs-object">frbs-object</a></code>. 
</p>
</li>
<li><p> Even though the main purpose of this package is to generate 
the FRBS models from training data automatically, we provide the function <code><a href="#topic+frbs.gen">frbs.gen</a></code>, 
which can be used to build a model manually without using a learning method.
Moreover, we provide the following features: linguistic hedges, the &quot;and&quot; and &quot;or&quot; operators, 
and the &quot;dont_care&quot; value for representing the degree of 1. The higher degree of interpretability 
can also be achieved by using the &quot;dont_care&quot; value. If we want to define various length of rules
in the rulebase, we can also define the &quot;dont_care&quot; value. See <code><a href="#topic+rulebase">rulebase</a></code>.    
</p>
</li>
<li><p> The purpose of the function <code><a href="#topic+predict">predict</a></code> is to obtain predicted values 
according to the testing data and the model (analogous to the <code>predict</code> function 
that is implemented in many other R packages). 
</p>
</li>
<li><p> There exist functions <code><a href="#topic+summary.frbs">summary.frbs</a></code> and <code><a href="#topic+plotMF">plotMF</a></code> to 
show a summary about an <code><a href="#topic+frbs-object">frbs-object</a></code>, and to plot the shapes of 
the membership functions.
</p>
</li>
<li><p> Exporting an FRBS model to the frbsPMML format can be done by executing <code><a href="#topic+frbsPMML">frbsPMML</a></code> and <code><a href="#topic+write.frbsPMML">write.frbsPMML</a></code>. 
The frbsPMML format is a universal framework adopted from the Predictive Model Markup Language (PMML) format. Then, 
in order to consume/import the frbsPMML format to an FRBS model, we call <code><a href="#topic+read.frbsPMML">read.frbsPMML</a></code>.  
</p>
</li></ul>

<p>To get started with the package, the user can have a look at some examples included in
the documentation of the functions <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+frbs.gen">frbs.gen</a></code> for generating models and
<code><a href="#topic+predict">predict</a></code> for the prediction phase.
</p>
<p>Also, there are many demos that ship with the package. To get a list of them, type:
</p>
<p><code>demo()</code>
</p>
<p>Then, to start a demo, type <code>demo(&lt;demo_name_here&gt;)</code>. All the demos are present as 
R scripts in the package sources in the <code>"demo"</code> subdirectory. Note that
some of them may take quite a long time which depends on specification hardwares.
</p>
<p>Currently, there are the following demos available:
</p>
<p>Regression using the Gas Furnance dataset:
</p>
<p><code>demo(WM.GasFur)</code>,
<code>demo(SBC.GasFur)</code>,
<code>demo(ANFIS.GasFur)</code>,
</p>
<p><code>demo(FS.HGD.GasFur)</code>, 
<code>demo(DENFIS.GasFur)</code>,
<code>demo(HyFIS.GasFur)</code>,
</p>
<p><code>demo(FIR.DM.GasFur)</code>,
<code>demo(GFS.FR.MOGUL.GasFur)</code>,
</p>
<p><code>demo(GFS.THRIFT.GasFur)</code>,
<code>demo(GFS.LT.RS.GasFur)</code>.
</p>
<p>Regression using the Mackey-Glass dataset:
</p>
<p><code>demo(WM.MG1000)</code>,
<code>demo(SBC.MG1000)</code>,
<code>demo(ANFIS.MG1000)</code>,
</p>
<p><code>demo(FS.HGD.MG1000)</code>, 
<code>demo(DENFIS.MG1000)</code>,
<code>demo(HyFIS.MG1000)</code>,
</p>
<p><code>demo(GFS.THRIFT.MG1000)</code>, 
<code>demo(FIR.DM.MG1000)</code>,
</p>
<p><code>demo(GFS.FR.MOGUL.MG1000)</code>,
<code>demo(GFS.LT.RS.MG1000)</code>.
</p>
<p>Classification using the Iris dataset:
</p>
<p><code>demo(FRBCS.W.Iris)</code>,
<code>demo(FRBCS.CHI.Iris)</code>,
<code>demo(GFS.GCCL.Iris)</code>,
</p>
<p><code>demo(FH.GBML.Iris)</code>,
<code>demo(SLAVE.Iris)</code>.
</p>
<p>Generating FRBS model without learning process:
</p>
<p><code>demo(FRBS.Mamdani.Manual)</code>,
<code>demo(FRBS.TSK.Manual)</code>,
<code>demo(FRBS.Manual)</code>.
</p>
<p>Exporting/importing to/from frbsPMML:
</p>
<p><code>demo(WM.GasFur.PMML)</code>,
<code>demo(ANFIS.GasFur.PMML)</code>,
<code>demo(GFS.GCCL.Iris.PMML)</code>.
</p>
<p>The Gas Furnance data and Mackey-Glass data are included in the package, 
please see <code><a href="#topic+frbsData">frbsData</a></code>. The Iris data is the standard Iris dataset that
ships with R.
</p>
<p>Also have a look at the package webpage <a href="http://sci2s.ugr.es/dicits/software/FRBS">http://sci2s.ugr.es/dicits/software/FRBS</a>, 
where we provide a more extensive introduction as well as additional explanations of 
the procedures.
</p>


<h3>Author(s)</h3>

<p>Lala Septem Riza <a href="mailto:lala.s.riza@decsai.ugr.es">lala.s.riza@decsai.ugr.es</a>,
</p>
<p>Christoph Bergmeir <a href="mailto:c.bergmeir@decsai.ugr.es">c.bergmeir@decsai.ugr.es</a>, 
</p>
<p>Francisco Herrera <a href="mailto:herrera@decsai.ugr.es">herrera@decsai.ugr.es</a>, 
</p>
<p>and Jose Manuel Benitez <a href="mailto:j.m.benitez@decsai.ugr.es">j.m.benitez@decsai.ugr.es</a>
</p>
<p>DiCITS Lab, SCI2S group, DECSAI, University of Granada.
</p>
<p><a href="http://sci2s.ugr.es/dicits/">http://sci2s.ugr.es/dicits/</a>, <a href="http://sci2s.ugr.es">http://sci2s.ugr.es</a>
</p>


<h3>References</h3>

<p>A. Guazzelli, M. Zeller, W.C. Lin, and G. Williams., 
&quot;pmml: An open standard for sharing models&quot;, The R Journal, Vol. 1, No. 1, pp. 60-65 (2009).
</p>
<p>C.C. Lee, &quot;Fuzzy Logic in control systems: Fuzzy logic controller part I&quot;, 
IEEE Trans. Syst., Man, Cybern., 
vol. 20, no. 2, pp. 404 - 418 (1990).
</p>
<p>C.C. Lee, &quot;Fuzzy Logic in control systems: Fuzzy logic controller part II&quot;,
IEEE Trans. Syst., Man, Cybern.,
vol. 20, no. 2, pp. 419 - 435 (1990).
</p>
<p>E.H. Mamdani and S. Assilian, &quot;An experiment in linguistic synthesis with 
a fuzzy logic controller,&quot; International Journal of Man Machine Studies, vol. 7, no. 1, 
pp. 1 - 13 (1975).
</p>
<p>W. Pedrycz, &quot;Fuzzy Control and Fuzzy Systems,&quot; New York: Wiley (1989).
</p>
<p>L.S. Riza, C. Bergmeir, F. Herrera, and J.M. Benitez, 
&quot;frbs: Fuzzy Rule-Based Systems for Classification and Regression in R,&quot;
Journal of Statistical Software, vol. 65, no. 6, pp. 1 - 30 (2015).
</p>
<p>M. Sugeno and G.T. Kang, &quot;Structure identification of fuzzy model,&quot; 
Fuzzy Sets Syst., vol. 28, pp. 15 - 33 (1988).
</p>
<p>T. Takagi and M. Sugeno, &quot;Fuzzy identification of systems and its application to 
modelling and control&quot;, IEEE Transactions on Systems, Man and Cybernetics, vol. 15, no. 1, 
pp. 116 - 132 (1985).
</p>
<p>L.A. Zadeh, &quot;Fuzzy sets&quot;, Information and Control, vol. 8, pp. 338 - 353 (1965).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbs.learn">frbs.learn</a></code>, <code><a href="#topic+frbs.gen">frbs.gen</a></code>, <code><a href="#topic+frbsPMML">frbsPMML</a></code>, and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##################################
## I. Regression Problem
## In this example, we are using the gas furnace dataset that 
## contains two input and one output variables.
##################################

## Input data: Using the Gas Furnace dataset
## then split the data to be training and testing datasets
data(frbsData)
data.train &lt;- frbsData$GasFurnance.dt[1 : 204, ]
data.tst &lt;- frbsData$GasFurnance.dt[205 : 292, 1 : 2]
real.val &lt;- matrix(frbsData$GasFurnance.dt[205 : 292, 3], ncol = 1)

## Define interval of data
range.data &lt;-apply(data.train, 2, range)

## Set the method and its parameters,
## for example, we use Wang and Mendel's algorithm
method.type &lt;- "WM"
control &lt;- list(num.labels = 15, type.mf = "GAUSSIAN", type.defuz = "WAM", 
           type.tnorm = "MIN", type.snorm = "MAX", type.implication.func = "ZADEH",
               name = "sim-0") 

## Learning step: Generate an FRBS model
object.reg &lt;- frbs.learn(data.train, range.data, method.type, control)

## Predicting step: Predict for newdata
res.test &lt;- predict(object.reg, data.tst)

## Display the FRBS model
summary(object.reg)

## Plot the membership functions
plotMF(object.reg)

##################################
## II. Classification Problem
## In this example, we are using the iris dataset that 
## contains four input and one output variables.
##################################

## Input data: Using the Iris dataset
data(iris)
set.seed(2)

## Shuffle the data
## then split the data to be training and testing datasets
irisShuffled &lt;- iris[sample(nrow(iris)), ]
irisShuffled[, 5] &lt;- unclass(irisShuffled[, 5])
tra.iris &lt;- irisShuffled[1 : 105, ]
tst.iris &lt;- irisShuffled[106 : nrow(irisShuffled), 1 : 4]
real.iris &lt;- matrix(irisShuffled[106 : nrow(irisShuffled), 5], ncol = 1)

## Define range of input data. Note that it is only for the input variables.
range.data.input &lt;- apply(iris[, -ncol(iris)], 2, range)

## Set the method and its parameters. In this case we use FRBCS.W algorithm
method.type &lt;- "FRBCS.W"
control &lt;- list(num.labels = 7, type.mf = "GAUSSIAN", type.tnorm = "MIN", 
               type.snorm = "MAX", type.implication.func = "ZADEH")  

## Learning step: Generate fuzzy model
object.cls &lt;- frbs.learn(tra.iris, range.data.input, method.type, control)

## Predicting step: Predict newdata
res.test &lt;- predict(object.cls, tst.iris)

## Display the FRBS model
summary(object.cls)

## Plot the membership functions
plotMF(object.cls)

#################################################
## III. Constructing an FRBS model from human expert. 
## In this example, we only consider the Mamdani model for regression. However, 
## other models can be done in the same way.
## Note:
## In the examples, let us consider four input and one output variables.
#################################################

## Define a matrix representing shape and parameters of membership functions of input variables.
## The matrix has 5 rows where the first row represent the type of the membership function whereas
## others are values of its parameters.
## Detailed explanation can be seen in the fuzzifier function to construct the matrix.
varinp.mf &lt;- matrix(c(2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA,
                      2, 0, 35, 75, NA, 3, 35, 75, 100, NA,
                      2, 0, 20, 40, NA, 1, 20, 50, 80, NA, 3, 60, 80, 100, NA,
                      2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA),
                      nrow = 5, byrow = FALSE)

## Define number of linguistic terms of input variables.
## Suppose, we have 3, 2, 3, and 3 numbers of linguistic terms 
## for the first, second, third and fourth variables, respectively.
num.fvalinput &lt;- matrix(c(3, 2, 3, 3), nrow=1)

## Give the names of the linguistic terms of each input variables.
varinput.1 &lt;- c("low", "medium", "high")
varinput.2 &lt;- c("yes", "no")
varinput.3 &lt;- c("bad", "neutral", "good")
varinput.4 &lt;- c("low", "medium", "high")
names.varinput &lt;- c(varinput.1, varinput.2, varinput.3, varinput.4)

## Set interval of data.
range.data &lt;- matrix(c(0, 100, 0, 100, 0, 100, 0, 100, 0, 100), nrow = 2)

## Define inference parameters.
## Detailed information about values can be seen in the inference function.
type.defuz &lt;- "WAM"
type.tnorm &lt;- "MIN"
type.snorm &lt;- "MAX"
type.implication.func &lt;- "ZADEH"

## Give the name of simulation.
name &lt;- "Sim-0"

## Provide new data for testing. 
newdata&lt;- matrix(c(25, 40, 35, 15, 45, 75, 78, 70), nrow = 2, byrow = TRUE)
## the names of variables
colnames.var &lt;- c("input1", "input2", "input3", "input4", "output1")

## Define number of linguistic terms of output variable.
## In this case, we set the number of linguistic terms to 3.
num.fvaloutput &lt;- matrix(c(3), nrow = 1)

## Give the names of the linguistic terms of the output variable.
varoutput.1 &lt;- c("bad", "neutral", "good")
names.varoutput &lt;- c(varoutput.1)

## Define the shapes and parameters of the membership functions of the output variables.
varout.mf &lt;- matrix(c(2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA),
                      nrow = 5, byrow = FALSE)

## Set type of model which is "MAMDANI".
type.model &lt;- "MAMDANI"

## Define the fuzzy IF-THEN rules; 
## In this example we are using the Mamdani model 
## Note: e.g.,
## "a1", "and", "b1, "-&gt;", "e1" means that 
## "IF inputvar.1 is a1 and inputvar.2 is b1 THEN outputvar.1 is e1" 
## Make sure that each rule has a "-&gt;" sign. 
rule &lt;- matrix(
  c("low", "and", "yes", "and", "bad", "and", "low", "-&gt;", "bad",
    "medium", "and", "no", "and", "neutral", "and", "medium", "-&gt;", "neutral", 
    "high", "and", "no", "and", "neutral", "and", "low", "-&gt;", "good"), 
    nrow = 3, byrow = TRUE) 

## Generate a fuzzy model with frbs.gen.
object &lt;- frbs.gen(range.data, num.fvalinput, names.varinput, 
                 num.fvaloutput, varout.mf, names.varoutput, rule, 
                 varinp.mf, type.model, type.defuz, type.tnorm, 
                 type.snorm, func.tsk = NULL, colnames.var, type.implication.func, name)

## Plot the membership function.
plotMF(object)

## Predicting using new data.
res &lt;- predict(object, newdata)$predicted.val

#################################################
## IV. Specifying an FRBS model in the frbsPMML format.
## other examples can be seen in the frbsPMML function.
#################################################
## Input data
data(frbsData)
data.train &lt;- frbsData$GasFurnance.dt[1 : 204, ]
data.fit &lt;- data.train[, 1 : 2]
data.tst &lt;- frbsData$GasFurnance.dt[205 : 292, 1 : 2]
real.val &lt;- matrix(frbsData$GasFurnance.dt[205 : 292, 3], ncol = 1)
range.data&lt;-matrix(c(-2.716, 2.834, 45.6, 60.5, 45.6, 60.5), nrow = 2)

## Set the method and its parameters
method.type &lt;- "WM"
control &lt;- list(num.labels = 3, type.mf = "GAUSSIAN", type.defuz = "WAM", 
                type.tnorm = "MIN", type.snorm = "MAX", 
                type.implication.func = "ZADEH", name="sim-0") 

## Generate fuzzy model
object &lt;- frbs.learn(data.train, range.data, method.type, control)

## 2. Constructing the frbsPMML format
frbsPMML(object)
</code></pre>

<hr>
<h2 id='frbs.eng'>The prediction phase</h2><span id='topic+frbs.eng'></span>

<h3>Description</h3>

<p>This function is one of the main internal functions of the package. 
It determines the values within the prediction phase.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frbs.eng(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frbs.eng_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.eng_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, 
where <code class="reqn">m</code> is the number of instances and <code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function involves four different processing steps on fuzzy rule-based systems. 
Firstly, the rulebase (see <code><a href="#topic+rulebase">rulebase</a></code>) validates 
the consistency of the fuzzy IF-THEN rules form. Then, the fuzzification 
(see <code><a href="#topic+fuzzifier">fuzzifier</a></code>) transforms crisp values 
into linguistic terms. Next, the inference calculates the degree of rule strengths using 
the t-norm and the s-norm. 
Finally, the defuzzification process calculates the results of the model using the Mamdani 
or the Takagi Sugeno Kang model.
</p>


<h3>Value</h3>

<p>A list with the following items:
</p>
<table>
<tr><td><code>rule</code></td>
<td>
<p>the fuzzy IF-THEN rules</p>
</td></tr>
<tr><td><code>varinp.mf</code></td>
<td>
<p>a matrix to generate the shapes of the membership functions for 
the input variables</p>
</td></tr>
<tr><td><code>MF</code></td>
<td>
<p>a matrix of the degrees of the membership functions</p>
</td></tr>
<tr><td><code>miu.rule</code></td>
<td>
<p>a matrix of the degrees of the rules</p>
</td></tr>
<tr><td><code>func.tsk</code></td>
<td>
<p>a matrix of the Takagi Sugeno Kang model for the consequent part of 
the fuzzy IF-THEN rules</p>
</td></tr>
<tr><td><code>predicted.val</code></td>
<td>
<p>a matrix of the predicted values</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+fuzzifier">fuzzifier</a></code>, <code><a href="#topic+rulebase">rulebase</a></code>, <code><a href="#topic+inference">inference</a></code> 
and <code><a href="#topic+defuzzifier">defuzzifier</a></code>.
</p>

<hr>
<h2 id='frbs.gen'>The frbs model generator</h2><span id='topic+frbs.gen'></span>

<h3>Description</h3>

<p>The purpose of this function is to generate a FRBS model from user-given 
input without a learning process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frbs.gen(range.data, num.fvalinput, names.varinput,
  num.fvaloutput = NULL, varout.mf = NULL, names.varoutput = NULL,
  rule, varinp.mf, type.model = "MAMDANI", type.defuz = "WAM",
  type.tnorm = "MIN", type.snorm = "MAX", func.tsk = NULL,
  colnames.var = NULL, type.implication.func = "ZADEH",
  name = "Sim-0")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frbs.gen_+3A_range.data">range.data</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum values, respectively.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_num.fvalinput">num.fvalinput</code></td>
<td>
<p>a matrix representing the number of linguistic terms of each input variables.
</p>
<p>For example: <code>num.fvalinput &lt;- matrix(c(3,2), nrow = 1)</code>
</p>
<p>means that there are two variables where the first variable has three linguistic terms and the second one has two linguistic terms.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_names.varinput">names.varinput</code></td>
<td>
<p>a list containing names to the linguistic terms for input variables. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_num.fvaloutput">num.fvaloutput</code></td>
<td>
<p>the number of linguistic terms of the output variable. This parameter is required for the Mamdani model only. 
</p>
<p>For example: <code>num.fvaloutput &lt;- matrix(3, nrow = 1)</code>
</p>
<p>means there are 3 linguistic terms for the output variable.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_varout.mf">varout.mf</code></td>
<td>
<p>a matrix for constructing the membership functions of the output variable. 
The form is the same as for the <code>varinp.mf</code> parameter. This parameter is required for the Mamdani model only. 
See <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_names.varoutput">names.varoutput</code></td>
<td>
<p>a list giving names of the linguistic terms for the output variable. The form is the same as 
for the <code>names.varinput</code> parameter. This parameter is required for the Mamdani model only. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_rule">rule</code></td>
<td>
<p>a list of fuzzy IF-THEN rules. There are some types of rule structures, for example: Mamdani, Takagi Sugeno Kang,
and fuzzy rule-based classification systems (FRBCS). If we use the Mamdani model then the consequent part is a linguistic term,
but if we use Takagi Sugeno Kang then we build a matrix representing linear equations in the consequent part.
e.g., &quot;a1&quot;, &quot;and&quot;, &quot;b1, &quot;-&gt;&quot;, &quot;e1&quot; means that 
&quot;IF inputvar.1 is a1 and inputvar.2 is b1 THEN outputvar.1 is e1&quot;. 
Make sure that each rule has a &quot;-&gt;&quot; sign.
Furthermore, we are allowed to use linguistic hedges (e.g., &quot;extremely&quot;, &quot;slightly&quot;, etc), negation (i.e., &quot;not&quot;),
and the &quot;dont_care&quot; value representing degree of membership is always 1. 
For more detail, see <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_varinp.mf">varinp.mf</code></td>
<td>
<p>a matrix for constructing the shapes of the membership functions. See how to construct it in <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_type.model">type.model</code></td>
<td>
<p>the type of the model. There are three types available as follows. 
</p>

<ul>
<li> <p><code>MAMDANI</code> means we are using the Mamdani model. 
</p>
</li>
<li> <p><code>TSK</code> means we are using the Takagi Sugeno Kang model.
</p>
</li>
<li> <p><code>FRBCS</code> means we are using fuzzy rule-based classification systems (FRBCS).
</p>
</li></ul>
</td></tr>
<tr><td><code id="frbs.gen_+3A_type.defuz">type.defuz</code></td>
<td>
<p>the type of the defuzzification method. It is used in the Mamdani model only. 
See <code><a href="#topic+defuzzifier">defuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of the t-norm method. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of the s-norm method. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_func.tsk">func.tsk</code></td>
<td>
<p>a matrix of parameters of the function on the consequent part using the Takagi Sugeno Kang model. 
This parameter must be defined when we are using Takagi Sugeno Kang. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_colnames.var">colnames.var</code></td>
<td>
<p>a list of names of input and output variables.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a type of implication function. See <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
<tr><td><code id="frbs.gen_+3A_name">name</code></td>
<td>
<p>a name of the simulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It can be used if rules have already been obtained manually, without employing the 
learning process. 
In the examples shown, we generate a fuzzy model using <code>frbs.gen</code> and generate the
fuzzy rule-based systems step by step manually. Additionally, the examples show several scenarios as follows.
</p>

<ul>
<li><p> Using <code>frbs.gen</code> for constructing the Mamdani model on a regression task. 
</p>
</li>
<li><p> Using <code>frbs.gen</code> for constructing the Takagi Sugeno Kang model on a regression task.
</p>
</li>
<li><p> Constructing the Mamdani model by executing internal functions such as <code>rulebase</code>, <code>fuzzifier</code>,
<code>inference</code>, and <code>defuzzifier</code> for the Mamdani model.
</p>
</li>
<li><p> Using <code>frbs.gen</code> for constructing fuzzy rule-based classification systems (FRBCS) model.
</p>
</li></ul>



<h3>Value</h3>

<p>The <code><a href="#topic+frbs-object">frbs-object</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#################################################
## 1. The following codes show how to generate a fuzzy model 
## using the frbs.gen function for regression tasks. 
## The following are three scenarios:
## 1a. Using the Mamdani model
## 1b. Using the Takagi Sugeno Kang model
## 1c. Using the Mamdani model and internal functions: fuzzifier, etc.
## Note:
## In the examples, let us consider four input variabels and one output variable.
## Some variables could be shared together for other examples.  
#################################################

## Define shape and parameters of membership functions of input variables.
## Please see the fuzzifier function to construct the matrix.
## It can be seen that in this case we employ TRAPEZOID as the membership functions.
varinp.mf &lt;- matrix(c(2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA,
                      2, 0, 35, 75, NA, 3, 35, 75, 100, NA,
                      2, 0, 20, 40, NA, 1, 20, 50, 80, NA, 3, 60, 80, 100, NA,
                      2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA),
                      nrow = 5, byrow = FALSE)

## Define number of linguistic terms of the input variables.
## Suppose, we have 3, 2, 3, and 3 numbers of linguistic terms 
## for the first, second, third and fourth variables, respectively.
num.fvalinput &lt;- matrix(c(3, 2, 3, 3), nrow=1)

## Give the names of the linguistic terms of each input variables.
varinput.1 &lt;- c("a1", "a2", "a3")
varinput.2 &lt;- c("b1", "b2")
varinput.3 &lt;- c("c1", "c2", "c3")
varinput.4 &lt;- c("d1", "d2", "d3")
names.varinput &lt;- c(varinput.1, varinput.2, varinput.3, varinput.4)

## Set interval of data.
range.data &lt;- matrix(c(0,100, 0, 100, 0, 100, 0, 100, 0, 100), nrow=2)

## Define inference parameters.
type.defuz &lt;- "WAM"
type.tnorm &lt;- "MIN"
type.snorm &lt;- "MAX"
type.implication.func &lt;- "ZADEH"

## Give the name of simulation.
name &lt;- "Sim-0"

## Provide new data for testing. 
newdata &lt;- matrix(c(15, 80, 85, 85, 45, 75, 78, 70), nrow = 2, byrow = TRUE)
## the names of variables
colnames.var &lt;- c("input1", "input2", "input3", "input4", "output1")

###################################################################
## 1a. Using the Mamdani Model 
####################################################################
## Define number of linguistic terms of output variable.
## In this case, we set the number of linguistic terms to 3.
num.fvaloutput &lt;- matrix(c(3), nrow = 1)

## Give the names of the linguistic terms of the output variable.
varoutput.1 &lt;- c("e1", "e2", "e3")
names.varoutput &lt;- c(varoutput.1)

## Define the shapes and parameters of the membership functions of the output variables.
varout.mf &lt;- matrix(c(2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA),
                      nrow = 5, byrow = FALSE)

## Set type of model which is "MAMDANI" or "TSK" for Mamdani or 
## Takagi Sugeno Kang models, respectively.
## In this case, we choose the Mamdani model.
type.model &lt;- "MAMDANI"

## Define the fuzzy IF-THEN rules; In this case, we provide two scenarios using different operators:
rule.or &lt;- matrix(c("a1", "or", "b1", "or", "c1", "or", "d1", "-&gt;", "e1",
                 "a2", "and", "b2", "and", "c2", "and", "d2", "-&gt;", "e2", 
                 "a3", "and", "b2", "and", "c2", "and", "d1", "-&gt;", "e3"), 
                 nrow = 3, byrow = TRUE) 
			  
## Define the fuzzy IF-THEN rules; 
rule.and &lt;- matrix(c("a1", "and", "b1", "and", "c1", "and", "d1", "-&gt;", "e1",
                 "a2", "and", "b2", "and", "c2", "and", "d2", "-&gt;", "e2", 
                 "a3", "and", "b2", "and", "c2", "and", "d1", "-&gt;", "e3"), 
                 nrow = 3, byrow = TRUE)  

## Generate a fuzzy model with frbs.gen.
object.or &lt;- frbs.gen(range.data, num.fvalinput, names.varinput, 
                 num.fvaloutput, varout.mf, names.varoutput, rule.or, 
                 varinp.mf, type.model, type.defuz, type.tnorm, 
                 type.snorm, func.tsk = NULL, colnames.var, type.implication.func, name)

object.and &lt;- frbs.gen(range.data, num.fvalinput, names.varinput, 
                 num.fvaloutput, varout.mf, names.varoutput, rule.and, 
                 varinp.mf, type.model, type.defuz, type.tnorm, 
                 type.snorm, func.tsk = NULL, colnames.var, type.implication.func, name)

## Plot the membership function.
plotMF(object.and)

## Predicting using new data.
res.or &lt;- predict(object.or, newdata)$predicted.val
res.and &lt;- predict(object.and, newdata)$predicted.val

#####################################################################
## 1b. Using the Takagi Sugeno Kang (TSK) Model 
#####################################################################
## Define "TSK" for the Takagi Sugeno Kang model
type.model &lt;- "TSK"

## Define linear equations for consequent parts. 
## The following command means that we have three equation related to the rules we have.
## e.g., the first equation is 1*inputvar.1 + 1*inputvar.2 + 5*inputvar.3 + 2*inputvar.4 + 1, 
## where inputvar.i is a value of the i-th input variable.
func.tsk &lt;- matrix(c(1, 1, 5, 2, 1, 3, 1, 0.5, 0.1, 2, 1, 3, 2, 2, 2), 
            nrow = 3, byrow = TRUE)

## Define the fuzzy IF-THEN rules; 
## For TSK model, it isn't necessary to put linguistic term in consequent parts.
## Make sure that each rule has a "-&gt;" sign. 
rule &lt;- matrix(c("a1", "and", "b1", "and", "c1", "and", "d1", "-&gt;",
                 "a2", "and", "b2", "and", "c2", "and", "d2", "-&gt;",  
                 "a3", "and", "b2", "and", "c2", "and", "d1", "-&gt;"), 
                 nrow = 3, byrow = TRUE) 
			  
## Generate a fuzzy model with frbs.gen.
## It should be noted that for TSK model, we do not need to input: 
## num.fvaloutput, varout.mf, names.varoutput, type.defuz.
object &lt;- frbs.gen(range.data, num.fvalinput, names.varinput, 
             num.fvaloutput = NULL, varout.mf = NULL, names.varoutput = NULL, rule, 
			varinp.mf, type.model, type.defuz = NULL, type.tnorm, type.snorm, 
             func.tsk, colnames.var, type.implication.func, name)
			
## Plot the membership function.
plotMF(object)

## Predicting using new data.
res &lt;- predict(object, newdata)$predicted.val

######################
## 1c. Using the same data as in the previous example, this example performs 
## step by step of the generation of a fuzzy rule-based system
######################
## Using the Mamdani model.
type.model &lt;- "MAMDANI"

## Construct rules.
rule &lt;- matrix(c("a1", "and", "b1", "and", "c1", "and", "d1", "-&gt;", "e1",
                 "a2", "and", "b2", "and", "c2", "and", "d2", "-&gt;", "e2", 
                 "a3", "and", "b2", "and", "c2", "and", "d1", "-&gt;", "e3"), 
                 nrow = 3, byrow = TRUE) 

## Check input data given by user.
rule &lt;- rulebase(type.model, rule, func.tsk = NULL)

## Fuzzification Module:
## In this function, we convert crisp into linguistic values/terms
## based on the data and the parameters of the membership function.
## The output: a matrix representing the degree of the membership of the data
num.varinput &lt;- ncol(num.fvalinput)
MF &lt;- fuzzifier(newdata, num.varinput, num.fvalinput, varinp.mf)

## Inference Module:
## In this function, we will calculate the confidence factor on the antecedent for each rule
## considering t-norm and s-norm.
miu.rule &lt;- inference(MF, rule, names.varinput, type.tnorm, type.snorm)

## Defuzzification Module.
## In this function, we calculate and convert the linguistic values back into crisp values. 
range.output &lt;- range.data[, ncol(range.data), drop = FALSE]
result &lt;- defuzzifier(newdata, rule, range.output, names.varoutput,
                  varout.mf, miu.rule, type.defuz, type.model, func.tsk = NULL)


#################################################
## 2. The following codes show how to generate a fuzzy model 
## using the frbs.gen function for classification tasks using the Mamdani model. 
#################################################
## define range of data.
## Note. we only define range of input data. 
range.data.input &lt;- matrix(c(0, 1, 0, 1, 0, 1, 0, 1), nrow=2)

## Define shape and parameters of membership functions of input variables.
## Please see fuzzifier function to construct the matrix.
## In this case, we are using TRIANGLE for membership functions.
varinp.mf &lt;- matrix(c(1, 0, 0, 0.5, NA, 1, 0, 0.5, 1, NA, 1, 0.5, 1, 1, NA,
                      1, 0, 0, 0.5, NA, 1, 0, 0.5, 1, NA, 1, 0.5, 1, 1, NA,
                      1, 0, 0, 0.5, NA, 1, 0, 0.5, 1, NA, 1, 0.5, 1, 1, NA,
                      1, 0, 0, 0.5, NA, 1, 0, 0.5, 1, NA, 1, 0.5, 1, 1, NA),
                      nrow = 5, byrow = FALSE)

## Define number of linguistic terms of input variables.
## Suppose, we have 3, 3, 3, and 3 numbers of linguistic terms 
## for first up to fourth variables, respectively.
num.fvalinput &lt;- matrix(c(3, 3, 3, 3), nrow=1)

## Give the names of the linguistic terms of each input variable.
varinput.1 &lt;- c("v.1_a.1", "v.1_a.2", "v.1_a.3")
varinput.2 &lt;- c("v.2_a.1", "v.2_a.2", "v.2_a.3")
varinput.3 &lt;- c("v.3_a.1", "v.3_a.2", "v.3_a.3")
varinput.4 &lt;- c("v.4_a.1", "v.4_a.2", "v.4_a.3")
names.varinput &lt;- c(varinput.1, varinput.2, varinput.3, varinput.4)

## Provide inference parameters.
type.tnorm &lt;- "MIN"
type.snorm &lt;- "MAX"
type.implication.func &lt;- "ZADEH"
type.model &lt;- "FRBCS"

## Give the name of simulation.
name &lt;- "Sim-0"

## Provide new data for testing. 
newdata&lt;- matrix(c(0.45, 0.5, 0.89, 0.44, 0.51, 0.99, 0.1, 0.98, 0.51,
                   0.56, 0.55, 0.5), nrow = 3, byrow = TRUE)

## the names of variables
colnames.var &lt;- c("input1", "input2", "input3", "input4", "output1")

## Construct rules.
## It should be noted that on consequent parts we define categorical values instead of 
## linguistic terms. 
rule &lt;- matrix(
       c("v.1_a.2", "and", "v.2_a.2", "and", "v.3_a.3", "and", "v.4_a.2", "-&gt;", "3",
         "v.1_a.2", "and", "v.2_a.3", "and", "v.3_a.1", "and", "v.4_a.3", "-&gt;", "1",
         "v.1_a.2", "and", "v.2_a.2", "and", "v.3_a.2", "and", "v.4_a.2", "-&gt;", "2"), 
         nrow = 3, byrow = TRUE) 

## Generate frbs object.
object &lt;- frbs.gen(range.data = range.data.input, num.fvalinput, 
             names.varinput, num.fvaloutput = NULL, varout.mf = NULL, 
             names.varoutput = NULL, rule, varinp.mf, type.model, 
             type.defuz = NULL, type.tnorm, type.snorm, func.tsk = NULL, 
             colnames.var, type.implication.func, name)
			
## Plot the shape of membership functions.
plotMF(object)

## Predicting using new data.
res &lt;- predict(object, newdata)

####################################################
## 3. The following example shows how to convert 
##    the frbs model into frbsPMML 
####################################################
## In this example, we are using the last object of FRBS.
## Display frbsPMML in R
objPMML &lt;- frbsPMML(object)

## Write into a file with .frbsPMML extention
## Not run: write.frbsPMML(objPMML, fileName="obj_frbsPMML")

## Read the frbsPMML file into an R object of FRBS
obj &lt;- read.frbsPMML("obj_frbsPMML.frbsPMML")
## End(Not run)
</code></pre>

<hr>
<h2 id='frbs.learn'>The frbs model building function</h2><span id='topic+frbs.learn'></span>

<h3>Description</h3>

<p>This is one of the central functions of the package. This function is used to 
generate/learn the model from numerical data using fuzzy rule-based systems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frbs.learn(data.train, range.data = NULL, method.type = c("WM"),
  control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frbs.learn_+3A_data.train">data.train</code></td>
<td>
<p>a data frame or matrix (<code class="reqn">m \times n</code>) of data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable. It should be noted that
the training data must be expressed in numbers (numerical data). And,
especially for classification tasks, the last column representing class names/symbols isn't allowed 
to have values 0 (zero). In the other words, the categorical values 0 should be replaced with other values.</p>
</td></tr>
<tr><td><code id="frbs.learn_+3A_range.data">range.data</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum values, respectively. It should be noted that
for <code>"FRBCS.W"</code>, <code>"FRBCS.CHI"</code>, <code>"GFS.GCCL"</code>, <code>"FH.GBML"</code>, and <code>"SLAVE"</code>, <code class="reqn">n</code> represents the number of input variables only
(without the output variable). It will be assigned as min/max of training data if it is omitted.</p>
</td></tr>
<tr><td><code id="frbs.learn_+3A_method.type">method.type</code></td>
<td>
<p>this parameter determines the learning algorithm to be used. 
The following methods are implemented: 
</p>

<ul>
<li> <p><code>"WM"</code>: Wang and Mendel's technique to handle regression tasks. See <code><a href="#topic+WM">WM</a></code>;
</p>
</li>
<li> <p><code>"SBC"</code>: subtractive clustering method to handle regression tasks. See <code><a href="#topic+SBC">SBC</a></code>;
</p>
</li>
<li> <p><code>"HYFIS"</code>: hybrid neural fuzzy inference systems to handle regression tasks. See <code><a href="#topic+HyFIS">HyFIS</a></code>;
</p>
</li>
<li> <p><code>"ANFIS"</code>: adaptive neuro-fuzzy inference systems to handle regression tasks. See <code><a href="#topic+ANFIS">ANFIS</a></code>;
</p>
</li>
<li> <p><code>"FRBCS.W"</code>: fuzzy rule-based classification systems with weight factor based on Ishibuchi's method 
to handle classification tasks. See <code><a href="#topic+FRBCS.W">FRBCS.W</a></code>; 
</p>
</li>
<li> <p><code>"FRBCS.CHI"</code>: fuzzy rule-based classification systems based on Chi's method to handle
classification tasks. See <code><a href="#topic+FRBCS.CHI">FRBCS.CHI</a></code>; 
</p>
</li>
<li> <p><code>"DENFIS"</code>: dynamic evolving neuro-fuzzy inference systems to handle regression tasks. See <code><a href="#topic+DENFIS">DENFIS</a></code>;
</p>
</li>
<li> <p><code>"FS.HGD"</code>: fuzzy system using heuristic and gradient descent method to handle regression tasks. See <code><a href="#topic+FS.HGD">FS.HGD</a></code>; 
</p>
</li>
<li> <p><code>"FIR.DM"</code>: fuzzy inference rules by descent method to handle regression tasks. See <code><a href="#topic+FIR.DM">FIR.DM</a></code>; 
</p>
</li>
<li> <p><code>"GFS.FR.MOGUL"</code>: genetic fuzzy systems for fuzzy rule learning based on the MOGUL methodology 
to handle regression tasks. See <code><a href="#topic+GFS.FR.MOGUL">GFS.FR.MOGUL</a></code>;
</p>
</li>
<li> <p><code>"GFS.THRIFT"</code>: Thrift's technique based on genetic algorithms to handle regression tasks. See <code><a href="#topic+GFS.Thrift">GFS.Thrift</a></code>;
</p>
</li>
<li> <p><code>"GFS.GCCL"</code>: Ishibuchi's method based on genetic cooperative-competitive learning
to handle classification tasks. See <code><a href="#topic+GFS.GCCL">GFS.GCCL</a></code>;
</p>
</li>
<li> <p><code>"FH.GBML"</code>: Ishibuchi's method based on hybridization of genetic cooperative-competitive learning and Pittsburgh to handle
classification tasks. See <code><a href="#topic+FH.GBML">FH.GBML</a></code>;
</p>
</li>
<li> <p><code>"SLAVE"</code>: structural learning algorithm on vague environment to handle classification tasks. See <code><a href="#topic+SLAVE">SLAVE</a></code>;
</p>
</li>
<li> <p><code>"GFS.LT.RS"</code>: genetic algorithm for lateral tuning and rule selection. See <code><a href="#topic+GFS.LT.RS">GFS.LT.RS</a></code> 
</p>
</li></ul>
</td></tr>
<tr><td><code id="frbs.learn_+3A_control">control</code></td>
<td>
<p>a list containing all arguments, depending on the learning algorithm to use. The following list are 
parameters required for each methods, whereas their descriptions will be explained later on.
</p>

<ul>
<li> <p><code>WM</code>: 
</p>
<p><code>list(num.labels, type.mf, type.tnorm, type.defuz,</code>
</p>
<p><code>type.implication.func, name)</code>
</p>
</li>
<li> <p><code>HYFIS</code>: 
</p>
<p><code>list(num.labels, max.iter, step.size, type.tnorm,</code>
</p>
<p><code>type.defuz, type.implication.func, name)</code>
</p>
</li>
<li> <p><code>ANFIS</code> and <code>FIR.DM</code>: 
</p>
<p><code>list(num.labels, max.iter, step.size,</code>
</p>
<p><code>type.tnorm, type.implication.func , name)</code>
</p>
</li>
<li> <p><code>SBC</code>: 
</p>
<p><code>list(r.a, eps.high, eps.low, name)</code>
</p>
</li>
<li> <p><code>FS.HGD</code>: 
</p>
<p><code>list(num.labels, max.iter, step.size, alpha.heuristic,</code>
</p>
<p><code>type.tnorm, type.implication.func, name)</code>
</p>
</li>
<li> <p><code>FRBCS.W</code> and <code>FRBCS.CHI</code>: 
</p>
<p><code>list(num.labels, type.mf, type.tnorm,</code>
</p>
<p><code>type.implication.func, name)</code>
</p>
</li>
<li> <p><code>DENFIS</code> method: 
</p>
<p><code>list(Dthr, max.iter, step.size, d, name)</code>
</p>
</li>
<li> <p><code>GFS.FR.MOGUL</code>: 
</p>
<p><code>list(persen_cross, max.iter, max.gen, max.tune,</code>
</p>
<p><code>persen_mutant, epsilon, name)</code>
</p>
</li>
<li> <p><code>GFS.THRIFT</code> method: 
</p>
<p><code>list(popu.size, num.labels, persen_cross,</code>
</p>
<p><code>max.gen, persen_mutant, type.tnorm, type.defuz,</code>
</p>
<p><code>type.implication.func, name)</code>
</p>
</li>
<li> <p><code>GFS.GCCL</code>: 
</p>
<p><code>list(popu.size, num.class, num.labels, persen_cross,</code>
</p>
<p><code>max.gen, persen_mutant, name)</code>
</p>
</li>
<li> <p><code>FH.GBML</code>: 
</p>
<p><code>list(popu.size, max.num.rule, num.class, persen_cross,</code>
</p>
<p><code>max.gen, persen_mutant, p.dcare, p.gccl, name)</code>
</p>
</li>
<li> <p><code>SLAVE</code>: 
</p>
<p><code>list(num.class, num.labels, persen_cross, max.iter,</code>
</p>
<p><code>max.gen, persen_mutant, k.lower, k.upper, epsilon, name)</code>
</p>
</li>
<li> <p><code>GFS.LT.RS</code>: 
</p>
<p><code>list(popu.size, num.labels, persen_mutant, max.gen,</code>
</p>
<p><code>mode.tuning, type.tnorm, type.implication.func,</code> 
</p>
<p><code>type.defuz, rule.selection, name)</code>
</p>
</li></ul>

<p><b>Description of the <code>control</code> Parameters</b>
</p>

<ul>
<li> <p><code>num.labels</code>: a positive integer to determine the number of labels (linguistic terms). 
The default value is 7.
</p>
</li>
<li> <p><code>type.mf</code>: the following type of the membership function. The default value is <code>GAUSSIAN</code>. For more detail, see <code><a href="#topic+fuzzifier">fuzzifier</a></code>.
</p>

<ul>
<li> <p><code>TRIANGLE</code>: it refers triangular shape.
</p>
</li>
<li> <p><code>TRAPEZOID</code>: it refers trapezoid shape.
</p>
</li>
<li> <p><code>GAUSSIAN</code>: it refers gaussian shape.
</p>
</li>
<li> <p><code>SIGMOID</code>: it refers sigmoid.
</p>
</li>
<li> <p><code>BELL</code>: it refers generalized bell.
</p>
</li></ul>

</li>
<li> <p><code>type.defuz</code>: the type of the defuzzification method as follows. The default value is <code>WAM</code>. For more detail, see <code><a href="#topic+defuzzifier">defuzzifier</a></code>.
</p>

<ul>
<li> <p><code>WAM</code>: the weighted average method.
</p>
</li>
<li> <p><code>FIRST.MAX</code>: the first maxima.
</p>
</li>
<li> <p><code>LAST.MAX</code>: the last maxima.
</p>
</li>
<li> <p><code>MEAN.MAX</code>: the mean maxima.
</p>
</li>
<li> <p><code>COG</code>: the modified center of gravity (COG).
</p>
</li></ul>

</li>
<li> <p><code>type.tnorm</code>: the type of conjunction operator (t-norm). The following are options of t-norm available. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.
The default value is <code>MIN</code>. 
</p>

<ul>
<li> <p><code>MIN</code> means standard type (minimum).
</p>
</li>
<li> <p><code>HAMACHER</code> means Hamacher product.
</p>
</li>
<li> <p><code>YAGER</code> means Yager class (with tao = 1).
</p>
</li>
<li> <p><code>PRODUCT</code> means product.
</p>
</li>
<li> <p><code>BOUNDED</code> mean bounded product.
</p>
</li></ul>

</li>
<li> <p><code>type.snorm</code>: the type of disjunction operator (s-norm). The following are options of s-norm available. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.
The default value is <code>MAX</code>. 
</p>
 
<ul>
<li> <p><code>MAX</code> means standard type (maximum). 
</p>
</li>
<li> <p><code>HAMACHER</code> means Hamacher sum.
</p>
</li>
<li> <p><code>YAGER</code> means Yager class (with tao = 1).
</p>
</li>
<li> <p><code>SUM</code> means sum.
</p>
</li>
<li> <p><code>BOUNDED</code> mean bounded sum. 
</p>
</li></ul>

</li>
<li> <p><code>type.implication.func</code>: the type of implication function. The following are options of implication function available:
<code>DIENES_RESHER</code>, <code>LUKASIEWICZ</code>, <code>ZADEH</code>,
<code>GOGUEN</code>, <code>GODEL</code>, <code>SHARP</code>, <code>MIZUMOTO</code>,
<code>DUBOIS_PRADE</code>, and <code>MIN</code>.
For more detail, please have a look at <code><a href="#topic+WM">WM</a></code>. The default value is <code>ZADEH</code>. 
</p>
</li>
<li> <p><code>name</code>: a name for the model. The default value is <code>"sim-0"</code>.
</p>
</li>
<li> <p><code>max.iter</code>: a positive integer to determine the maximal number of iterations. 
The default value is 10.
</p>
</li>
<li> <p><code>step.size</code>: the step size of the gradient descent, a real number between 0 and 1. 
The default value is 0.01.
</p>
</li>
<li> <p><code>r.a</code>: a positive constant which is effectively the radius defining a neighborhood. 
The default value is 0.5.
</p>
</li>
<li> <p><code>eps.high</code>: an upper threshold value. The default value is 0.5.
</p>
</li>
<li> <p><code>eps.low</code>: a lower threshold value. The default value is 0.15.
</p>
</li>
<li> <p><code>alpha.heuristic</code>: a positive real number representing a heuristic value. 
The default value is 1.
</p>
</li>
<li> <p><code>Dthr</code>: the threshold value for the envolving clustering method (ECM), between 0 and 1. 
The default value is 0.1.
</p>
</li>
<li> <p><code>d</code>: a parameter for the width of the triangular membership function. 
The default value is 2.
</p>
</li>
<li> <p><code>persen_cross</code>: a probability of crossover. The default value is 0.6.
</p>
</li>
<li> <p><code>max.gen</code>: a positive integer to determine the maximal number of generations of the genetic algorithm. 
The default value is 10.
</p>
</li>
<li> <p><code>max.tune</code>: a positive integer to determine the maximal number of tuning iterations.
The default value is 10.
</p>
</li>
<li> <p><code>persen_mutant</code>: a probability of mutation. The default value is 0.3.
</p>
</li>
<li> <p><code>epsilon</code>: a real number between 0 and 1 representing the level of generalization.
A high epsilon can lead to overfitting. The default value is 0.9. 
</p>
</li>
<li> <p><code>popu.size</code>: the size of the population which is generated in each generation. The default value is 10.
</p>
</li>
<li> <p><code>max.num.rule</code>: the maximum size of the rules. The default value is 5.
</p>
</li>
<li> <p><code>num.class</code>: the number of classes.
</p>
</li>
<li> <p><code>p.dcare</code>: a probability of &quot;don't care&quot; attributes. The default value is 0.5.
</p>
</li>
<li> <p><code>p.gccl</code>: a probability of the GCCL process. The default value is 0.5.
</p>
</li>
<li> <p><code>k.lower</code>: a lower bound of the noise threshold with interval between 0 and 1. The default value is 0.
</p>
</li>
<li> <p><code>k.upper</code>: an upper bound of the noise threshold with interval between 0 and 1. The default value is 1.
</p>
</li>
<li> <p><code>mode.tuning</code>: a type of lateral tuning which are <code>"LOCAL"</code> or <code>"GLOBAL"</code>. The default value is <code>"GLOBAL"</code>.
</p>
</li>
<li> <p><code>rule.selection</code>:a boolean value representing whether performs rule selection or not. 
The default value is <code>"TRUE"</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes accessible all learning methods that are implemented 
in this package. All of the methods use this function as interface for the learning 
stage, so users do not need to call other functions in the learning phase. 
In order to obtain good results, users need to adjust some parameters such as the 
number of labels, the type of the shape of the membership function, the maximal number of iterations, 
the step size of the gradient descent, or other method-dependent parameters which are collected in the <code>control</code>
parameter. After creating the model using this function, it can be used to predict new data with <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Value</h3>

<p>The <code><a href="#topic+frbs-object">frbs-object</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict">predict</a></code> for the prediction phase, and 
the following main functions of each of the methods for theoretical background and references:  <code><a href="#topic+WM">WM</a></code>, <code><a href="#topic+SBC">SBC</a></code>,
<code><a href="#topic+HyFIS">HyFIS</a></code>, <code><a href="#topic+ANFIS">ANFIS</a></code>, <code><a href="#topic+FIR.DM">FIR.DM</a></code>, <code><a href="#topic+DENFIS">DENFIS</a></code>, 
<code><a href="#topic+FS.HGD">FS.HGD</a></code>, <code><a href="#topic+FRBCS.W">FRBCS.W</a></code>, <code><a href="#topic+FRBCS.CHI">FRBCS.CHI</a></code>, <code><a href="#topic+GFS.FR.MOGUL">GFS.FR.MOGUL</a></code>,
<code><a href="#topic+GFS.Thrift">GFS.Thrift</a></code>, <code><a href="#topic+GFS.GCCL">GFS.GCCL</a></code>, <code><a href="#topic+FH.GBML">FH.GBML</a></code>, <code><a href="#topic+GFS.LT.RS">GFS.LT.RS</a></code>, and <code><a href="#topic+SLAVE">SLAVE</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##################################
## I. Regression Problem
## Suppose data have two input variables and one output variable.  
## We separate them into training, fitting, and testing data.
## data.train, data.fit, data.test, and range.data are inputs 
## for all regression methods.
###################################
## Take into account that the simulation might take a long time 
## depending on the hardware you are using. The chosen parameters 
## may not be optimal.
## Data must be in data.frame or matrix form and the last column 
## is the output variable/attribute.
## The training data must be expressed in numbers (numerical data).
data.train &lt;- matrix(c(5.2, -8.1, 4.8, 8.8, -16.1, 4.1, 10.6, -7.8, 5.5, 10.4, -29.0, 
                      5.0, 1.8, -19.2, 3.4, 12.7, -18.9, 3.4, 15.6, -10.6, 4.9, 1.9, 
                      -25.0, 3.7, 2.2, -3.1, 3.9, 4.8, -7.8, 4.5, 7.9, -13.9, 4.8, 
                      5.2, -4.5, 4.9, 0.9, -11.6, 3.0, 11.8, -2.1, 4.6, 7.9, -2.0, 
                      4.8, 11.5, -9.0, 5.5, 10.6, -11.2, 4.5, 11.1, -6.1, 4.7, 12.8, 
                      -1.0, 6.6, 11.3, -3.6, 5.1, 1.0, -8.2, 3.9, 14.5, -0.5, 5.7, 
                      11.9, -2.0, 5.1, 8.1, -1.6, 5.2, 15.5, -0.7, 4.9, 12.4, -0.8, 
                      5.2, 11.1, -16.8, 5.1, 5.1, -5.1, 4.6, 4.8, -9.5, 3.9, 13.2, 
                      -0.7, 6.0, 9.9, -3.3, 4.9, 12.5, -13.6, 4.1, 8.9, -10.0, 
                      4.9, 10.8, -13.5, 5.1), ncol = 3, byrow = TRUE)
colnames(data.train) &lt;- c("inp.1", "inp.2", "out.1") 

data.fit &lt;- data.train[, -ncol(data.train)]

data.test &lt;- matrix(c(10.5, -0.9, 5.8, -2.8, 8.5, -0.6, 13.8, -11.9, 9.8, -1.2, 11.0,
                     -14.3, 4.2, -17.0, 6.9, -3.3, 13.2, -1.9), ncol = 2, byrow = TRUE)

range.data &lt;- matrix(apply(data.train, 2, range), nrow = 2)

#############################################################
## I.1 Example: Constructing an FRBS model using Wang &amp; Mendel
#############################################################
method.type &lt;- "WM" 

## collect control parameters into a list
## num.labels = 3 means we define 3 as the number of linguistic terms
control.WM &lt;- list(num.labels = 3, type.mf = "GAUSSIAN", type.tnorm = "MIN",  
type.defuz = "WAM", type.implication.func = "ZADEH", name = "Sim-0") 

## generate the model and save it as object.WM
object.WM &lt;- frbs.learn(data.train, range.data, method.type, control.WM)

#############################################################
## I.2 Example: Constructing an FRBS model using SBC
#############################################################
## Not run: method.type &lt;- "SBC" 
control.SBC &lt;- list(r.a = 0.5, eps.high = 0.5, eps.low = 0.15, name = "Sim-0")

object.SBC &lt;- frbs.learn(data.train, range.data, method.type, control.SBC)
## End(Not run)

#############################################################
## I.3 Example: Constructing an FRBS model using HYFIS
#############################################################
## Not run: method.type &lt;- "HYFIS"

control.HYFIS &lt;- list(num.labels = 5, max.iter = 50, step.size = 0.01, type.tnorm = "MIN", 
                      type.defuz = "COG", type.implication.func = "ZADEH", name = "Sim-0")

object.HYFIS &lt;- frbs.learn(data.train, range.data, method.type, control.HYFIS)
## End(Not run)

#############################################################
## I.4 Example: Constructing an FRBS model using ANFIS
#############################################################
## Not run: method.type &lt;- "ANFIS" 

control.ANFIS &lt;- list(num.labels = 5, max.iter = 10, step.size = 0.01, type.tnorm = "MIN", 
                      type.implication.func = "ZADEH", name = "Sim-0") 

object.ANFIS &lt;- frbs.learn(data.train, range.data, method.type, control.ANFIS)
## End(Not run)

#############################################################
## I.5 Example: Constructing an FRBS model using DENFIS
#############################################################

## Not run: control.DENFIS &lt;- list(Dthr = 0.1, max.iter = 10, step.size = 0.001, d = 2, 
                       name = "Sim-0")
method.type &lt;- "DENFIS"

object.DENFIS &lt;- frbs.learn(data.train, range.data, method.type, control.DENFIS)
## End(Not run)

#############################################################
## I.6 Example: Constructing an FRBS model using FIR.DM
#############################################################
## Not run: method.type &lt;- "FIR.DM"
 
control.DM &lt;- list(num.labels = 5, max.iter = 10, step.size = 0.01, type.tnorm = "MIN", 
                     type.implication.func = "ZADEH", name = "Sim-0") 
object.DM &lt;- frbs.learn(data.train, range.data, method.type, control.DM)
## End(Not run)

#############################################################
## I.7 Example: Constructing an FRBS model using FS.HGD
#############################################################
## Not run: method.type &lt;- "FS.HGD" 
 
control.HGD &lt;- list(num.labels = 5, max.iter = 10, step.size = 0.01, 
               alpha.heuristic = 1, type.tnorm = "MIN",  
               type.implication.func = "ZADEH", name = "Sim-0") 
object.HGD &lt;- frbs.learn(data.train, range.data, method.type, control.HGD)
## End(Not run)

#############################################################
## I.8 Example: Constructing an FRBS model using GFS.FR.MOGUL
#############################################################
## Not run: method.type &lt;- "GFS.FR.MOGUL" 
 
control.GFS.FR.MOGUL &lt;- list(persen_cross = 0.6, 
                    max.iter = 5, max.gen = 2, max.tune = 2, persen_mutant = 0.3, 
                    epsilon = 0.8, name="sim-0") 
object.GFS.FR.MOGUL &lt;- frbs.learn(data.train, range.data, 
                       method.type, control.GFS.FR.MOGUL)
## End(Not run)

#############################################################
## I.9 Example: Constructing an FRBS model using Thrift's method (GFS.THRIFT)
#############################################################
## Not run: method.type &lt;- "GFS.THRIFT" 
 
control.Thrift &lt;- list(popu.size = 6, num.labels = 3, persen_cross = 1, 
                      max.gen = 5, persen_mutant = 1, type.tnorm = "MIN", 
                      type.defuz = "COG", type.implication.func = "ZADEH", 
                      name="sim-0") 
object.Thrift &lt;- frbs.learn(data.train, range.data, method.type, control.Thrift)
## End(Not run)

##############################################################
## I.10 Example: Constructing an FRBS model using
##      genetic for lateral tuning and rule selection (GFS.LT.RS)
#############################################################
## Set the method and its parameters
## Not run: method.type &lt;- "GFS.LT.RS" 
  
control.lt.rs &lt;- list(popu.size = 5, num.labels = 5, persen_mutant = 0.3,
               max.gen = 10, mode.tuning = "LOCAL", type.tnorm = "MIN",  
                type.implication.func = "ZADEH", type.defuz = "WAM", 
                rule.selection = TRUE, name="sim-0")

## Generate fuzzy model
object.lt.rs &lt;- frbs.learn(data.train, range.data, method.type, control.lt.rs)
## End(Not run)

#############################################################
## II. Classification Problems 
#############################################################
## The iris dataset is shuffled and divided into training and 
## testing data. Bad results in the predicted values may result
## from casual imbalanced classes in the training data.
## Take into account that the simulation may take a long time 
## depending on the hardware you use. 
## One may get better results with other parameters. 
## Data are in data.frame or matrix form and the last column is 
## the output variable/attribute
## The data must be expressed in numbers (numerical data).

data(iris)
irisShuffled &lt;- iris[sample(nrow(iris)),]
irisShuffled[,5] &lt;- unclass(irisShuffled[,5])
tra.iris &lt;- irisShuffled[1:105,]
tst.iris &lt;- irisShuffled[106:nrow(irisShuffled),1:4]
real.iris &lt;- matrix(irisShuffled[106:nrow(irisShuffled),5], ncol = 1)

## Please take into account that the interval needed is the range of input data only.
range.data.input &lt;- matrix(apply(iris[, -ncol(iris)], 2, range), nrow = 2)

######################################################### 
## II.1 Example: Constructing an FRBS model using 
##      FRBCS with weighted factor based on Ishibuchi's method
###############################################################
## generate the model
## Not run: method.type &lt;- "FRBCS.W"
control &lt;- list(num.labels = 3, type.mf = "TRIANGLE", type.tnorm = "MIN", 
               type.implication.func = "ZADEH", name = "sim-0") 

object &lt;- frbs.learn(tra.iris, range.data.input, method.type, control)

## conduct the prediction process
res.test &lt;- predict(object, tst.iris)
## End(Not run)

######################################################### 
## II.2 Example: Constructing an FRBS model using 
##      FRBCS based on Chi's method
###############################################################
## generate the model
## Not run: method.type &lt;- "FRBCS.CHI"
control &lt;- list(num.labels = 7, type.mf = "TRIANGLE", type.tnorm = "MIN", 
               type.implication.func = "ZADEH", name = "sim-0") 

object &lt;- frbs.learn(tra.iris, range.data.input, method.type, control)

## conduct the prediction process
res.test &lt;- predict(object, tst.iris)
## End(Not run)

######################################################### 
## II.3 The example: Constructing an FRBS model using GFS.GCCL
###############################################################
## Not run: method.type &lt;- "GFS.GCCL" 

control &lt;- list(popu.size = 5, num.class = 3, num.labels = 5, persen_cross = 0.9, 
                    max.gen = 2, persen_mutant = 0.3,
                    name="sim-0") 
## Training process
## The main result of the training is a rule database which is used later for prediction.
object &lt;- frbs.learn(tra.iris, range.data.input, method.type, control)

## Prediction process
res.test &lt;- predict(object, tst.iris)
## End(Not run)

######################################################### 
## II.4 Example: Constructing an FRBS model using FH.GBML
###############################################################
## Not run: method.type &lt;- "FH.GBML" 
 
control &lt;- list(popu.size = 5, max.num.rule = 5, num.class = 3, 
			persen_cross = 0.9, max.gen = 2, persen_mutant = 0.3, p.dcare = 0.5, 
             p.gccl = 1, name="sim-0") 
 
## Training process
## The main result of the training is a rule database which is used later for prediction.
object &lt;- frbs.learn(tra.iris, range.data.input, method.type, control)

## Prediction process
res.test &lt;- predict(object, tst.iris)
## End(Not run)

######################################################### 
## II.5 The example: Constructing an FRBS model using SLAVE
###############################################################
## Not run: method.type &lt;- "SLAVE" 
 
control &lt;- list(num.class = 3, num.labels = 5,
			persen_cross = 0.9, max.iter = 5, max.gen = 3, persen_mutant = 0.3, 
             k.lower = 0.25, k.upper = 0.75, epsilon = 0.1, name="sim-0") 
 
## Training process
## The main result of the training is a rule database which is used later for prediction.
object &lt;- frbs.learn(tra.iris, range.data.input, method.type, control)

## Prediction process
res.test &lt;- predict(object, tst.iris)
## End(Not run)

</code></pre>

<hr>
<h2 id='frbsData'>Data set of the package</h2><span id='topic+frbsData'></span>

<h3>Description</h3>

<p>The package includes embedded versions of the Mackey-Glass chaotic time series and the Gas Furnance dataset.
</p>


<h3>Details</h3>

<p><b>Mackey-Glass chaotic time series</b>
</p>
<p>The Mackey-Glass chaotic time series is defined by the following delayed differential equation:
</p>
<p><code class="reqn">d_x(t) / d_t = (a * x(t - \tau) / (1 + x(t - \tau) ^ 10)) - b * x(t)</code>
</p>
<p>For this dataset, we generated 1000 samples, with input parameters as follows:
</p>

<ul>
<li> <p><code class="reqn">a = 0.2</code>
</p>
</li>
<li> <p><code class="reqn">b = 0.1</code>
</p>
</li>
<li> <p><code class="reqn">\tau = 17</code>
</p>
</li>
<li> <p><code class="reqn">x_0 = 1.2</code>
</p>
</li>
<li> <p><code class="reqn">d_t = 1</code>
</p>
</li></ul>

<p>The dataset is embedded in the following way:
</p>
<p>input variables: <code class="reqn">x(t - 18)</code>, <code class="reqn">x(t - 12)</code>, <code class="reqn">x(t - 6)</code>, <code class="reqn">x(t)</code>
</p>
<p>output variable: <code class="reqn">x(t + 6)</code>
</p>
<p><b>Gas Furnance dataset</b>
</p>
<p>The Gas Furnance dataset is taken from Box and Jenkins. It consists of 292 consecutive 
values of methane at time <code class="reqn">(t - 4)</code>, and the CO2 produced in a furnance at time <code class="reqn">(t - 1)</code> as input 
variables, with the produced CO2 at time <code class="reqn">(t)</code> as an output variable. So, each training data 
point consists of <code class="reqn">[u(t - 4), y(t - 1), y(t)]</code>, where <code class="reqn">u</code> is methane and <code class="reqn">y</code> is CO2.
</p>


<h3>References</h3>

<p>G. E. P. Box and G. M. Jenkins, &quot;Time series analysis, forecasting and control&quot;, San Fransisco, CA: Holden Day (1970).
</p>
<p>M. Mackey and L. Glass, &quot;Oscillation and chaos in physiological control systems&quot;, Science, vol. 197, pp. 287 - 289 (1977).
</p>

<hr>
<h2 id='frbsObjectFactory'>The object factory for frbs objects</h2><span id='topic+frbsObjectFactory'></span><span id='topic+frbs-object'></span>

<h3>Description</h3>

<p>This function creates objects of type <code>frbs</code>. Currently, its 
implementation is very basic and does no argument checking, as 
it is only used internally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frbsObjectFactory(mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frbsObjectFactory_+3A_mod">mod</code></td>
<td>
<p>a list containing all the attributes for the object</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The members of the <code>frbs</code> object depend on the used learning method. The following list describes all of the members that can be present. 
</p>

<dl>
<dt><code>num.labels</code></dt><dd><p>the number of linguistic terms for the variables</p>
</dd>
<dt><code>varout.mf</code></dt><dd><p>a matrix to generate the shapes of the membership functions for the output variable. 
The first row represents the shape of the membership functions, the other rows contain the parameters that have been generated. 
Whether the values of parameters within the matrix are normalized to lie between 0 and 1 or not depends on the selected method.</p>
</dd>
<dt><code>rule</code></dt><dd><p>the fuzzy IF-THEN rules; In the <code>GFS.FR.MOGUL</code> case, a rule refers to the parameter values of the membership function 
which represents the rule.</p>
</dd>
<dt><code>rule.data.num</code></dt><dd><p>the fuzzy IF-THEN rules in integer format.</p>
</dd>
<dt><code>varinp.mf</code></dt><dd><p>a matrix to generate the shapes of the membership functions for the input variables. 
The first row represents the shape of the membership functions, 
the other rows contain the non <code>NA</code> values representing the parameters related with their type of membership function. 
For example, <code>TRAPEZOID</code>, <code>TRIANGLE</code>, and <code>GAUSSIAN</code> have four, three, and two values as their parameters, respectively. 
Whether the values of parameters within the matrix are normalized to lie between 0 and 1 or not depends on the selected method.</p>
</dd>
<dt><code>type.model</code></dt><dd><p>the type of model. Here, <code>MAMDANI</code> refers to the Mamdani model, and <code>TSK</code> refers to the Takagi Sugeno Kang model on the consequence part.</p>
</dd>
<dt><code>func.tsk</code></dt><dd><p>a matrix of the Takagi Sugeno Kang model consequent part of the fuzzy IF-THEN rules.</p>
</dd>
<dt><code>class</code></dt><dd><p>a matrix representing classes of <code>FRBCS</code> model</p>
</dd>
<dt><code>num.labels</code></dt><dd><p>a number of linguistic terms on each variables/attributes.</p>
</dd>
<dt><code>type.defuz</code></dt><dd><p>the type of the defuzzification method.</p>
</dd>
<dt><code>type.tnorm</code></dt><dd><p>the type of the t-norm method.</p>
</dd>
<dt><code>type.snorm</code></dt><dd><p>the type of the s-norm method.</p>
</dd>
<dt><code>type.mf</code></dt><dd><p>the type of shapes of membership functions.</p>
</dd>
<dt><code>type.implication.func</code></dt><dd><p>the type of the implication function.</p>
</dd>
<dt><code>method.type</code></dt><dd><p>the type of the selected method.</p>
</dd>
<dt><code>name</code></dt><dd><p>the name given to the model.</p>
</dd>
<dt><code>range.data.ori</code></dt><dd><p>range of the original data (before normalization).</p>
</dd>
<dt><code>cls</code></dt><dd><p>cluster centers.</p>
</dd>
<dt><code>Dthr</code></dt><dd><p>the boundary parameter of the <code>DENFIS</code> method.</p>
</dd>
<dt><code>d</code></dt><dd><p>the multiplier parameters of the <code>DENFIS</code> method.</p>
</dd>
<dt><code>r.a</code></dt><dd><p>the neighborhood factor of <code>SBC</code>.</p>
</dd>
<dt><code>degree.rule</code></dt><dd><p>certainty degree of rules.</p>
</dd>
<dt><code>rule.data.num</code></dt><dd><p>a matrix representing the rules in integer form.</p>
</dd>
<dt><code>grade.cert</code></dt><dd><p>grade of certainty for classification problems.</p>
</dd>
<dt><code>alpha.heuristic</code></dt><dd><p>a parameter for the heuristic of the <code>FS.HGD</code> method.</p>
</dd>
<dt><code>var.mf.tune</code></dt><dd><p>a matrix of parameters of membership function for lateral tuning.</p>
</dd>
<dt><code>mode.tuning</code></dt><dd><p>a type of lateral tuning.</p>
</dd>
<dt><code>rule.selection</code></dt><dd><p>a boolean of rule selection.</p>
</dd>
<dt><code>colnames.var</code></dt><dd><p>the names of variables.</p>
</dd>
</dl>



<h3>Value</h3>

<p>an object of type <code>frbs</code>
</p>

<hr>
<h2 id='frbsPMML'>The frbsPMML generator</h2><span id='topic+frbsPMML'></span>

<h3>Description</h3>

<p>It is the main function used for generating the frbsPMML format. In this package, we provide interfaces for writing and reading frbsPMML to/from a text file. 
See <code><a href="#topic+write.frbsPMML">write.frbsPMML</a></code> and <code><a href="#topic+read.frbsPMML">read.frbsPMML</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frbsPMML(model, model.name = "frbs_model", app.name = "frbs",
  description = NULL, copyright = NULL,
  algorithm.name = model$method.type, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frbsPMML_+3A_model">model</code></td>
<td>
<p>an frbs model.</p>
</td></tr>
<tr><td><code id="frbsPMML_+3A_model.name">model.name</code></td>
<td>
<p>a string representing the model name.</p>
</td></tr>
<tr><td><code id="frbsPMML_+3A_app.name">app.name</code></td>
<td>
<p>a string representing an application name.</p>
</td></tr>
<tr><td><code id="frbsPMML_+3A_description">description</code></td>
<td>
<p>a string representing the simulation description.</p>
</td></tr>
<tr><td><code id="frbsPMML_+3A_copyright">copyright</code></td>
<td>
<p>a copyright of simulation.</p>
</td></tr>
<tr><td><code id="frbsPMML_+3A_algorithm.name">algorithm.name</code></td>
<td>
<p>a string representing the algorithm name.</p>
</td></tr>
<tr><td><code id="frbsPMML_+3A_...">...</code></td>
<td>
<p>other parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>frbsPMML is a universal framework for representing FRBS models, which is a format adopted from the Predictive Model Markup Language (PMML). 
PMML is a format constructed by an XML-based language to provide a standard for describing models produced 
by data mining and machine learning algorithms. A main contribution of PMML is 
to provide interoperable schemata of predictive models. 
Using PMML, we can easily perform these tasks as our models are documented
in an XML-based language. Human experts can also update and modify the model on the files directly.
</p>
<p>Since PMML is an XML-based language, the specification is defined by an XML Schema as 
recommended by the World Wide Web Consortium (W3C). The PMML format is specified by the main 
tag <em>PMML</em> that contains some components. In the following, we describe the main components:
</p>

<ul>
<li> <p><em>Header</em>: It contains general information about the PMML document, 
such as copyright information for the model, its description, application, 
and timestamp of generation. 
</p>
</li>
<li> <p><em>DataDictionary</em>: It contains information related to fields or variables, 
such as number, names, types, and value ranges of variables.
</p>
</li>
<li> <p><em>MODEL-ELEMENT</em>: It is a main part of the PMML document that consists of models 
supported by PMML. In each model, there are several components embedded in the element, 
such as <em>MiningSchema</em> and <em>Output</em>. 
<em>MiningSchema</em> specifies outlier treatment, a missing value replacement policy, 
and missing value treatment, whereas <em>Output</em> shows a description of the output variable. 
For example, in a clustering model, we define a schema representing the cluster centers 
that are included in the <em>ClusteringModel</em> element.       
</p>
</li></ul>

<p>Besides these components, there are some optional elements, such as <em>MiningBuildTask</em>, 
<em>TransformationDictionary</em>, and <em>Extension</em>. 
More detailed information about PMML can be found in (Guazzelli et al., 2009).
</p>
<p>Three models, which can be used for handling regression and classification tasks, 
are specified by the proposed representations: Mamdani, Takagi Sugeno Kang, and fuzzy rule-based classification systems. 
There are the following benefits offered by frbsPMML, as follows:
</p>

<ul>
<li><p> Interoperability: It is a standard format for representing many models without 
depending on any programming languages (e.g., Java, Python, and C++) and platforms (e.g., Windows, Linux, and Mac). 
</p>
</li>
<li><p> Tranparency: Since it is formed based on XML Schema containing formal definitions of the available elements, we can 
understand FRBS models as written in frbsPMML.
</p>
</li>
<li><p> Interpretability: frbsPMML expresses rulebase, database, and inference schema in simple ways. For example, 
rulebase is constructed recursively, so that besides it meets to the mathematical logic (predicate), we can
define different operators (i.e., <code>and</code> and <code>or</code>) in one rule.  
</p>
</li>
<li><p> Flexibility: Since frbsPMML is based XML, human experts can easily modify and improve a model in the text file directly. 
</p>
</li>
<li><p> Reproducibility: Sicen frbsPMML is a universal representation, it allows us to store, share, execute, and reproduce an FRBS model.	
</p>
</li></ul>



<h3>Value</h3>

<p>FRBS model in frbsPMML format
</p>


<h3>References</h3>

<p>A. Guazzelli, M. Zeller, W.C. Lin, and G. Williams., 
&quot;pmml: An open standard for sharing models&quot;, The R Journal, Vol. 1, No. 1, pp. 60-65 (2009).
</p>
<p>Data Mining Group, http://www.dmg.org/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This example shows how to construct a frbsPMML file of the frbs model
## Even though we are using MAMDANI model, other models have the same way
## 
## 1. Produce frbs model, for example: we perform Wang &amp; Mendel's technique (WM)
## Input data
## Not run: data(frbsData)
data.train &lt;- frbsData$GasFurnance.dt[1 : 204, ]
data.fit &lt;- data.train[, 1 : 2]
data.tst &lt;- frbsData$GasFurnance.dt[205 : 292, 1 : 2]
real.val &lt;- matrix(frbsData$GasFurnance.dt[205 : 292, 3], ncol = 1)
range.data &lt;- matrix(c(-2.716, 2.834, 45.6, 60.5, 45.6, 60.5), nrow = 2)

## Set the method and its parameters
method.type &lt;- "WM"
control &lt;- list(num.labels = 3, type.mf = "GAUSSIAN", type.defuz = "WAM", 
                type.tnorm = "MIN", type.implication.func = "ZADEH", 
                name = "sim-0") 

## Generate fuzzy model
object &lt;- frbs.learn(data.train, range.data, method.type, control)

## 2. Write frbsPMML file
## by calling frbsPMML(), the frbsPMML format will be displayed in R console
frbsPMML(object)
## End(Not run)

</code></pre>

<hr>
<h2 id='FS.HGD'>FS.HGD model building</h2><span id='topic+FS.HGD'></span>

<h3>Description</h3>

<p>This is the internal function that implements the simplified TSK fuzzy rule generation method 
using heuristics and gradient descent method (FS.HGD). It is used to solve regression tasks. 
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FS.HGD(data.train, num.labels, max.iter = 100, step.size = 0.01,
  alpha.heuristic = 1, type.tnorm = "MIN", type.snorm = "MAX",
  type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FS.HGD_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>), whose elements represent the number of labels (fuzzy terms); 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_max.iter">max.iter</code></td>
<td>
<p>maximal number of iterations.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_step.size">step.size</code></td>
<td>
<p>step size of the descent method.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_alpha.heuristic">alpha.heuristic</code></td>
<td>
<p>a positive real number which is the heuristic parameter.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="FS.HGD_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a value representing type of implication function. 
For more detail, please have a look at <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by K. Nozaki, H. Ishibuchi, and H. Tanaka. It 
uses fuzzy IF-THEN rules with nonfuzzy singletons (i.e. real numbers) in
the consequent parts. The techniques of space partition are implemented to 
generate the antecedent part, while the initial consequent part of each 
rule is determined by the weighted mean value of the given training data. 
Then, the gradient descent method updates the value of the consequent part. 
Futhermore, the heuristic value given by the user affects the value of weight 
of each data.
</p>


<h3>References</h3>

<p>H. Ishibuchi, K. Nozaki, H. Tanaka, Y. Hosaka, and M. Matsuda, &quot;Empirical study on learning in fuzzy systems by rice taste analysis&quot;,
Fuzzy Set and Systems, vol. 64, no. 2, pp. 129 - 144 (1994).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbs.learn">frbs.learn</a></code>, <code><a href="#topic+predict">predict</a></code>, and <code><a href="#topic+HGD.update">HGD.update</a></code>
</p>

<hr>
<h2 id='fuzzifier'>Transforming from crisp set into linguistic terms</h2><span id='topic+fuzzifier'></span>

<h3>Description</h3>

<p>Fuzzification refers to the process of transforming a crisp set into linguistic terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fuzzifier(data, num.varinput, num.labels.input, varinp.mf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fuzzifier_+3A_data">data</code></td>
<td>
<p>a matrix of data containing numerical elements.</p>
</td></tr>
<tr><td><code id="fuzzifier_+3A_num.varinput">num.varinput</code></td>
<td>
<p>number of input variables.</p>
</td></tr>
<tr><td><code id="fuzzifier_+3A_num.labels.input">num.labels.input</code></td>
<td>
<p>the number of labels of the input variables.</p>
</td></tr>
<tr><td><code id="fuzzifier_+3A_varinp.mf">varinp.mf</code></td>
<td>
<p>a matrix containing the parameters to form the membership functions. See the Detail section.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this function, there are five shapes of membership functions implemented, 
namely <code>TRIANGLE</code>, <code>TRAPEZOID</code>, <code>GAUSSIAN</code>, <code>SIGMOID</code>, and <code>BELL</code>. 
They are represented by a matrix that the dimension is (<code class="reqn">5, n</code>) where <code class="reqn">n</code> is 
a multiplication the number of linguistic terms/labels and the number of input variables.
The rows of the matrix represent:
The first row is the type of membership function, where 1 means <code>TRIANGLE</code>, 
2 means <code>TRAPEZOID</code> in left side, 
3 means <code>TRAPEZOID</code> in right side, 4 means <code>TRAPEZOID</code> in the middle, 
5 means <code>GAUSSIAN</code>, 
6 means <code>SIGMOID</code>, and 7 means <code>BELL</code>. And, the second up to fifth row indicate 
the corner points to construct the functions. 
</p>

<ul>
<li> <p><code>TRIANGLE</code> has three parameters (<code class="reqn">a, b, c</code>), where <code class="reqn">b</code> is the center point of the <code>TRIANGLE</code>,
and <code class="reqn">a</code> and <code class="reqn">c</code> are the left and right points, respectively.
</p>
</li>
<li> <p><code>TRAPEZOID</code> has four parameters (<code class="reqn">a, b, c, d</code>).
</p>
</li>
<li> <p><code>GAUSSIAN</code> has two parameters (<code class="reqn">mean</code> and <code class="reqn">variance</code>).
</p>
</li>
<li> <p><code>SIGMOID</code> has two parameters (<code class="reqn">\gamma</code> and <code class="reqn">c</code>) for representing steepness of the function and distance from the origin, respectively. 
</p>
</li>
<li> <p><code>BELL</code> has three parameters (<code class="reqn">a, b, c</code>).
</p>
</li></ul>

<p>For example:
</p>
<p><code>varinp.mf &lt;- matrix(c(2,1,3,2,3,0,30,60,0,40,20,50,80,</code>
</p>
<p><code>30,80,40,70,100,60,100,0,0,100,0,100), nrow=5, byrow=TRUE)</code>
</p>


<h3>Value</h3>

<p>A matrix of the degree of each linguistic terms based on the shape of 
the membership functions
</p>


<h3>See Also</h3>

<p><code><a href="#topic+defuzzifier">defuzzifier</a></code>, <code><a href="#topic+rulebase">rulebase</a></code>, and <code><a href="#topic+inference">inference</a></code>
</p>

<hr>
<h2 id='GFS.FR.MOGUL'>GFS.FR.MOGUL model building</h2><span id='topic+GFS.FR.MOGUL'></span>

<h3>Description</h3>

<p>This is the internal function that implements genetic fuzzy systems for fuzzy rule learning 
based on the MOGUL methodology (GFS.FR.MOGUL). It is used to solve regression tasks. 
Users do not need to call it directly, but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.FR.MOGUL(data.train, persen_cross = 0.6, persen_mutant = 0.3,
  max.iter = 10, max.gen = 10, max.tune = 10, range.data.ori,
  epsilon = 0.4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.FR.MOGUL_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable. Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_persen_cross">persen_cross</code></td>
<td>
<p>a real number between 0 and 1 determining the probability of crossover.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_persen_mutant">persen_mutant</code></td>
<td>
<p>a real number between 0 and 1 determining the probability of mutation.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_max.iter">max.iter</code></td>
<td>
<p>the maximal number of iterations.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_max.gen">max.gen</code></td>
<td>
<p>the maximal number of generations of the genetic algorithm.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_max.tune">max.tune</code></td>
<td>
<p>the maximal number of tuning iterations.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_range.data.ori">range.data.ori</code></td>
<td>
<p>a matrix containing the ranges of the original data.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL_+3A_epsilon">epsilon</code></td>
<td>
<p>a real number between 0 and 1 determining the boundary of covering factor.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by Herrera et al.   
GFS.FR.MOGUL implements a genetic algorithm determining the structure 
of the fuzzy IF-THEN rules and the membership function parameters. 
There are two general types of fuzzy IF-THEN rules, namely the descriptive 
and the approximative/free semantic approaches. A descriptive approach means that
the linguistic labels represent a real-world semantic; the linguistic labels are 
uniformly defined for all rules. In contrast, in the approximative approach 
there isn't any associated linguistic label. This method is based on the latter one. 
We model a fuzzy IF-THEN rule on a chromosome which consists of the parameter values of 
the membership function. So, every rule has its own membership function values. 
A population contains many such generated chromosomes, based on the iterative rule learning 
approach (IRL). IRL means that the chromosomes will be generated one by one, taking into
account the fitness value and covering factor, until there are sufficient chromosomes 
in the population. After having obtained the population, the genetic algorithm is started,
using the genetic operators selection, mutation, and crossover.
</p>


<h3>References</h3>

<p>F. Herrera, M. Lozano, and J.L. Verdegay, 
&quot;A learning process for fuzzy control rules using genetic algorithms&quot;, 
Fuzzy Sets and Systems, vol. 100, pp. 143 - 158 (1998).
</p>
<p>O. Cordon, M.J. del Jesus, F. Herrera, and M. Lozano, 
&quot;MOGUL: A methodology to obtain genetic fuzzy rule-based systems 
under the iterative rule learning approach&quot;, International Journal of Intelligent Systems, 
vol. 14, pp. 1123 - 1153 (1999).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GFS.FR.MOGUL.test">GFS.FR.MOGUL.test</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='GFS.FR.MOGUL.test'>GFS.FR.MOGUL: The prediction phase</h2><span id='topic+GFS.FR.MOGUL.test'></span>

<h3>Description</h3>

<p>This function is the internal function of the GFS.FR.MOGUL method to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.FR.MOGUL.test(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.FR.MOGUL.test_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.FR.MOGUL.test_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>

<hr>
<h2 id='GFS.GCCL'>GFS.GCCL model building</h2><span id='topic+GFS.GCCL'></span>

<h3>Description</h3>

<p>This is the internal function that implements the Ishibuchi's method based on 
genetic cooperative-competitive learning (GFS.GCCL). It is used to handle classification tasks. 
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.GCCL(data.train, popu.size = 10, range.data.input, num.labels,
  persen_cross = 0.6, persen_mutant = 0.3, max.gen = 10,
  range.data.ori)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.GCCL_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_popu.size">popu.size</code></td>
<td>
<p>the size of the population which is generated in each generation.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_range.data.input">range.data.input</code></td>
<td>
<p>a matrix containing the ranges of the normalized input data.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix describing the number of linguistic terms.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_persen_cross">persen_cross</code></td>
<td>
<p>a real number between 0 and 1 representing the probability of crossover.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_persen_mutant">persen_mutant</code></td>
<td>
<p>a real number between 0 and 1 representing the probability of mutation.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_max.gen">max.gen</code></td>
<td>
<p>the maximal number of generations for the genetic algorithm.</p>
</td></tr>
<tr><td><code id="GFS.GCCL_+3A_range.data.ori">range.data.ori</code></td>
<td>
<p>a matrix containing the ranges of the input data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is based on Ishibuchi's method. In this method, a chromosome describes 
each linguistic IF-THEN rule using integer as its representation of the antecedent part. 
In the consequent part of the fuzzy rules, the heuristic method is applied to 
automatically generate the class. The evaluation is calculated for each rule 
which means that the performance is not based on the entire rule set. 
The outline of the method is as follows. 
</p>

<ul>
<li><p> Step 1: Generate an initial population of fuzzy IF-THEN rules.
</p>
</li>
<li><p> Step 2: Evaluate each fuzzy IF-THEN rule in the current population.
</p>
</li>
<li><p> Step 3: Generate new fuzzy IF-THEN rules by genetic operators.
</p>
</li>
<li><p> Step 4: Replace a part of the current population with the newly generated rules.
</p>
</li>
<li><p> Step 5: Terminate the algorithm if a stopping condition is satisfied, 
otherwise return to Step 2. 
</p>
</li></ul>
 
<p>Additionally, to handle high dimensional data, this method uses &quot;don't care&quot;
attributes on the antecedent fuzzy set.
</p>


<h3>References</h3>

<p>H. Ishibuchi, T. Nakashima, and T. Murata, &quot;Performance evaluation of fuzzy classifier systems for 
multidimensional pattern classification problems&quot;,
IEEE trans. on Systems, Man, and Cybernetics - Part B: Sybernetics, vol. 29. no. 5, pp. 601 - 618 (1999).
</p>

<hr>
<h2 id='GFS.GCCL.eng'>GFS.GCCL.test: The prediction phase</h2><span id='topic+GFS.GCCL.eng'></span>

<h3>Description</h3>

<p>This function is the internal function of the GFS.GCCL and FH.GBML method to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.GCCL.eng(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.GCCL.eng_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.GCCL.eng_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>

<hr>
<h2 id='GFS.LT.RS'>GFS.LT.RS model building</h2><span id='topic+GFS.LT.RS'></span>

<h3>Description</h3>

<p>This is the internal function that implements genetic lateral tuning and rule selection of linguistic fuzzy systems (GFS.LT.RS). 
It is used to solve regression tasks. 
Users do not need to call it directly, but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.LT.RS(data.train, popu.size = 10, range.data, num.labels,
  persen_mutant, max.gen = 10, mode.tuning = "GLOBAL",
  type.tnorm = "MIN", type.snorm = "MAX",
  type.implication.func = "ZADEH", type.defuz = "WAM",
  rule.selection = FALSE, range.data.ori)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.LT.RS_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable. Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_popu.size">popu.size</code></td>
<td>
<p>the size of the population which is generated in each generation.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_range.data">range.data</code></td>
<td>
<p>a matrix representing interval of data.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix representing the number of linguistic terms in each variables.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_persen_mutant">persen_mutant</code></td>
<td>
<p>a real number between 0 and 1 determining the probability of mutation.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_max.gen">max.gen</code></td>
<td>
<p>the maximal number of generations of the genetic algorithm.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_mode.tuning">mode.tuning</code></td>
<td>
<p>a type of tuning which are <code>"LOCAL"</code> or <code>"GLOBAL"</code>.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>a type of t-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_type.snorm">type.snorm</code></td>
<td>
<p>a type of s-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a type of implication function. See <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_type.defuz">type.defuz</code></td>
<td>
<p>a type of defuzzification methods. See <code><a href="#topic+defuzzifier">defuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_rule.selection">rule.selection</code></td>
<td>
<p>a boolean value representing whether performs rule selection or not.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS_+3A_range.data.ori">range.data.ori</code></td>
<td>
<p>a matrix containing the ranges of the original data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by R. Alcala et al.   
GFS.LT.RS implements a evolutionary algorithm for postprocessing in constructing FRBS model. 
It uses a new rule representation model based on the linguistic 2-tupples representation that allows
the lateral displacement of the labels. This function allows two different tuning which are global and local tuning.
</p>
<p>Regarding with evolutionary algorithms, the following are main components:
</p>

<ul>
<li><p> coding scheme and initial gene pool;
</p>
</li>
<li><p> chromosome evalution;
</p>
</li>
<li><p> crossover operator;
</p>
</li>
<li><p> restarting approach;
</p>
</li>
<li><p> evolutionary model;
</p>
</li></ul>

<p>In first time, population is constructed by Wang &amp; Mendel's technique. Mean square error (MSE) is used to 
calculate chromosome evaluation. This method performs BLX-a in crossover process. 
Additionally, rule selection method is performed in order to minimize the number of rules.
</p>


<h3>References</h3>

<p>R. Alcala, J. Alcala-Fdez, and F. Herrera, &quot;A proposal for the genetic lateral tuning of linguistic fuzzy systems and its interaction with
rule selection&quot;, IEEE Trans. on Fuzzy Systems, Vol. 15, No. 4, pp. 616 - 635 (2007).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GFS.LT.RS.test">GFS.LT.RS.test</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='GFS.LT.RS.test'>GFS.LT.RS: The prediction phase</h2><span id='topic+GFS.LT.RS.test'></span>

<h3>Description</h3>

<p>This function is the internal function of the GFS.LT.RS method to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.LT.RS.test(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.LT.RS.test_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.LT.RS.test_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>

<hr>
<h2 id='GFS.Thrift'>GFS.Thrift model building</h2><span id='topic+GFS.Thrift'></span>

<h3>Description</h3>

<p>This is the internal function that implements the Thrift's technique based 
on a genetic algorithm. It is used to tackle regression tasks. Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.Thrift(data.train, popu.size = 10, num.labels, persen_cross = 0.6,
  persen_mutant = 0.3, max.gen = 10, range.data.ori,
  type.defuz = "WAM", type.tnorm = "MIN", type.snorm = "MAX",
  type.mf = "TRIANGLE", type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.Thrift_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_popu.size">popu.size</code></td>
<td>
<p>the size of the population which is generated in each generation.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix describing the number of linguistic terms.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_persen_cross">persen_cross</code></td>
<td>
<p>a real number between 0 and 1 representing the probability of crossover.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_persen_mutant">persen_mutant</code></td>
<td>
<p>a real number between 0 and 1 representing the probability of mutation.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_max.gen">max.gen</code></td>
<td>
<p>the maximal number of generations for the genetic algorithm.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_range.data.ori">range.data.ori</code></td>
<td>
<p>a matrix containing the ranges of the original data.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_type.defuz">type.defuz</code></td>
<td>
<p>the type of the defuzzification method. For more detail, see <code><a href="#topic+defuzzifier">defuzzifier</a></code>.
The default value is <code>WAM</code>.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_type.mf">type.mf</code></td>
<td>
<p>the type of shape of membership function. See <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.Thrift_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>the type of implication function. See <code><a href="#topic+WM">WM</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was developed by Thrift using Mamdani's model as fuzzy IF-THEN rules. 
In this method, we consider a table as a genotype with alleles that are fuzzy set indicators 
over the output domain. The phenotype is produced by the behavior produced 
by the fuzzification, max-* composition, and defuzzification operations. 
A chromosome (genotype) is formed from the decision table by going rowwise 
and producing a string of numbers from the code set. Standard crossover 
and mutation operators can act on these string.
</p>


<h3>References</h3>

<p>P. Thrift, &quot;Fuzzy logic synthesis with genetic algorithms&quot;, In Proceedings of the Fourth
International Conference on Genetic Algorithms (ICGA91), San Diego (United States of
America), pp. 509 - 513 (1991).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GFS.Thrift.test">GFS.Thrift.test</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='GFS.Thrift.test'>GFS.Thrift: The prediction phase</h2><span id='topic+GFS.Thrift.test'></span>

<h3>Description</h3>

<p>This function is the internal function of the GFS.Thrift method to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GFS.Thrift.test(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GFS.Thrift.test_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="GFS.Thrift.test_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>

<hr>
<h2 id='HGD.update'>FS.HGD updating function</h2><span id='topic+HGD.update'></span>

<h3>Description</h3>

<p>The role of this function is to update parameters within the simplified TSK fuzzy rule 
generation method using heuristics and the gradient descent method (FS.HGD).
This function is called by the main function 
of the FS.HGD method, see <code><a href="#topic+FS.HGD">FS.HGD</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HGD.update(data.train, miu.rule, func.tsk, varinp.mf, step.size = 0.01,
  def)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HGD.update_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.</p>
</td></tr>
<tr><td><code id="HGD.update_+3A_miu.rule">miu.rule</code></td>
<td>
<p>a matrix with the degrees of rules which is the result of the <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="HGD.update_+3A_func.tsk">func.tsk</code></td>
<td>
<p>a matrix of parameters of the function on the consequent part using the Takagi Sugeno Kang model. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="HGD.update_+3A_varinp.mf">varinp.mf</code></td>
<td>
<p>a matrix of parameters of membership functions of the input variables.</p>
</td></tr>
<tr><td><code id="HGD.update_+3A_step.size">step.size</code></td>
<td>
<p>a real number between 0 and 1 representing the step size of the gradient descent.</p>
</td></tr>
<tr><td><code id="HGD.update_+3A_def">def</code></td>
<td>
<p>a matrix which is obtained by the <code><a href="#topic+defuzzifier">defuzzifier</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+FS.HGD">FS.HGD</a></code>
</p>

<hr>
<h2 id='HyFIS'>HyFIS model building</h2><span id='topic+HyFIS'></span>

<h3>Description</h3>

<p>This is the internal function that implements the hybrid neural fuzzy inference 
system (HyFIS). It is used to solve regression tasks. 
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HyFIS(data.train, num.labels, max.iter = 10, step.size = 0.01,
  type.tnorm = "MIN", type.snorm = "MAX", type.defuz = "COG",
  type.implication.func = "ZADEH")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HyFIS_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="HyFIS_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>), whose elements represent the number of labels (linguistic terms); 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="HyFIS_+3A_max.iter">max.iter</code></td>
<td>
<p>the maximal number of iterations.</p>
</td></tr>
<tr><td><code id="HyFIS_+3A_step.size">step.size</code></td>
<td>
<p>step size of the gradient descent method.</p>
</td></tr>
<tr><td><code id="HyFIS_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>the type of t-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS_+3A_type.snorm">type.snorm</code></td>
<td>
<p>the type of s-norm. For more detail, please have a look at <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS_+3A_type.defuz">type.defuz</code></td>
<td>
<p>the type of aggregation function. For more detail, please have a look at <code><a href="#topic+defuzzifier">defuzzifier</a></code></p>
</td></tr>
<tr><td><code id="HyFIS_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a value representing type of implication function. For more detail, please have a look at <code><a href="#topic+WM">WM</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by J. Kim and N. Kasabov. There are two phases in 
this method for learning, namely the knowledge acquisition module and the 
structure and parameter learning.
The knowledge acquition module uses the techniques of Wang and Mendel. 
The learning of structure and parameters is a supervised learning method using 
gradient descent-based learning algorithms. 
This function generates a model which consists of a rule database and parameters 
of the membership functions. The rules of HyFIS use the Mamdani model on the antecedent and 
consequent parts. Futhermore, 
HyFIS uses a Gaussian membership function. So, there are two kinds of 
parameters that are optimized, mean and variance of the Gaussian function.
</p>


<h3>References</h3>

<p>J. Kim and N. Kasabov, &quot;HyFIS: Adaptive neuro-fuzzy inference systems and 
their application to nonlinear dynamical systems&quot;, 
Neural Networks, vol. 12, no. 9, pp. 1301 - 1319 (1999).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+HyFIS.update">HyFIS.update</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>.
</p>

<hr>
<h2 id='HyFIS.update'>HyFIS updating function</h2><span id='topic+HyFIS.update'></span>

<h3>Description</h3>

<p>This function is called by <code><a href="#topic+HyFIS">HyFIS</a></code> to update the parameters within 
the HyFIS method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HyFIS.update(data.train, def, rule, names.varoutput, var.mf, miu.rule,
  num.labels, MF, step.size = 0.001, degree.rule)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HyFIS.update_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_def">def</code></td>
<td>
<p>matrix of defuzzification results. See <code><a href="#topic+defuzzifier">defuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_rule">rule</code></td>
<td>
<p>fuzzy IF-THEN rules. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_names.varoutput">names.varoutput</code></td>
<td>
<p>a list of names of the output variable.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_var.mf">var.mf</code></td>
<td>
<p>a matrix of parameters of the membership functions. 
Please see <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_miu.rule">miu.rule</code></td>
<td>
<p>a matrix of degree of rules which is a result of the <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>) whose elements represent 
the number of labels (or linguistic terms), where n is the number of variables.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_mf">MF</code></td>
<td>
<p>a matrix of parameters of the membership functions 
which is a result of the <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_step.size">step.size</code></td>
<td>
<p>a real number, the step size of the gradient descent.</p>
</td></tr>
<tr><td><code id="HyFIS.update_+3A_degree.rule">degree.rule</code></td>
<td>
<p>a matrix of degrees of rules. See <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+HyFIS">HyFIS</a></code>
</p>

<hr>
<h2 id='inference'>The process of fuzzy reasoning</h2><span id='topic+inference'></span>

<h3>Description</h3>

<p>Inference refers to the process of fuzzy reasoning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inference(MF, rule, names.varinput, type.tnorm, type.snorm)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inference_+3A_mf">MF</code></td>
<td>
<p>a matrix of the degrees of membership functions which is a result of the <code><a href="#topic+fuzzifier">fuzzifier</a></code>.</p>
</td></tr>
<tr><td><code id="inference_+3A_rule">rule</code></td>
<td>
<p>a matrix or list of fuzzy IF-THEN rules. See <code><a href="#topic+rulebase">rulebase</a></code>.</p>
</td></tr>
<tr><td><code id="inference_+3A_names.varinput">names.varinput</code></td>
<td>
<p>a list of names of the input variables.</p>
</td></tr>
<tr><td><code id="inference_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>a value which represents the type of t-norm to be used: 
</p>

<ul>
<li> <p><code>1</code> or <code>MIN</code> means standard t-norm: <code class="reqn">min(x1, x2)</code>.
</p>
</li>
<li> <p><code>2</code> or <code>HAMACHER</code> means Hamacher product: <code class="reqn">(x1 * x2)/(x1 + x2 - x1 * x2)</code>.
</p>
</li>
<li> <p><code>3</code> or <code>YAGER</code> means Yager class: <code class="reqn">1- min(1, ((1 - x1) + (1 - x2)))</code>.
</p>
</li>
<li> <p><code>4</code> or <code>PRODUCT</code> means product: <code class="reqn">(x1 * x2)</code>.
</p>
</li>
<li> <p><code>5</code> or <code>BOUNDED</code> means bounded product: <code class="reqn">max(0, x1 + x2 - 1)</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="inference_+3A_type.snorm">type.snorm</code></td>
<td>
<p>a value which represents the type of s-norm to be used: 
</p>

<ul>
<li> <p><code>1</code> or <code>MAX</code> means standard s-norm: <code class="reqn">max(x1, x2)</code>.
</p>
</li>
<li> <p><code>2</code> or <code>HAMACHER</code> means Hamacher sum: <code class="reqn">(x1 + x2 - 2x1 * x2) / 1 - x1 * x2</code>.
</p>
</li>
<li> <p><code>3</code> or <code>YAGER</code> means Yager class: <code class="reqn">min(1, (x1 + x2))</code>.
</p>
</li>
<li> <p><code>4</code> or <code>SUM</code> means sum: <code class="reqn">(x1 + x2 - x1 * x2)</code>.
</p>
</li>
<li> <p><code>5</code> or <code>BOUNDED</code> means bounded sum: <code class="reqn">min(1, x1 + x2)</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p>In this function, fuzzy reasoning is conducted based on Mamdani and Takagi Sugeno Kang model. 
Furthermore, there are some formula for conjunction and disjunction operators.
</p>
<p><b>The Mamdani model:</b>
A fuzzy system with, e.g., two inputs <code class="reqn">x1</code> and <code class="reqn">x2</code> (antecedents) and a single output <code class="reqn">y</code> (consequent)
is described by the following fuzzy IF-THEN rule:
</p>
<p><code>IF x1 is A1 and x2 is A2 THEN y is B</code>
</p>
<p>where <code class="reqn">A1</code> and <code class="reqn">A2</code> are the fuzzy sets representing the antecent pairs and
<code class="reqn">B</code> is the fuzzy set representing the consequent.
</p>
<p><b>The Takagi Sugeno Kang model:</b>
Suppose we have two inputs <code class="reqn">x1</code> and <code class="reqn">x2</code> and output <code class="reqn">y</code>, then the fuzzy IF-THEN rule is as follows:
</p>
<p><code>IF x1 is A1 and x2 is A2 THEN y is y = f(x1, x2)</code>
</p>
<p>where <code class="reqn">y = f(x1, x2)</code> is a crisp function in the consequent part which is usually a polynomial function,
and <code class="reqn">A1</code> and <code class="reqn">A2</code> are the fuzzy sets representing the antecent pairs.
</p>
<p>Futhermore, this function has the following capabilities: 
</p>
 
<ul>
<li><p> It supports unary operators (not) and binary operators (<code>AND</code> and <code>OR</code>).
</p>
</li>
<li><p> It provides linguistic hedge (<code>extremely</code>, <code>very</code>, <code>somewhat</code>, and <code>slightly</code>).
</p>
</li>
<li><p> there are several methods for the t-norm and s-norm.
</p>
</li></ul>



<h3>Value</h3>

<p>a matrix of the degrees of the rules.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+defuzzifier">defuzzifier</a></code>, <code><a href="#topic+rulebase">rulebase</a></code>, and <code><a href="#topic+fuzzifier">fuzzifier</a></code>.
</p>

<hr>
<h2 id='norm.data'>The data normalization</h2><span id='topic+norm.data'></span>

<h3>Description</h3>

<p>This function is to transform from real-valued data into normalized data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.data(dt.ori, range.data, min.scale = 0, max.scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm.data_+3A_dt.ori">dt.ori</code></td>
<td>
<p>a matrix (<code class="reqn">n \times m</code>) of the original data.</p>
</td></tr>
<tr><td><code id="norm.data_+3A_range.data">range.data</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where n is the number of variables, and
first and second rows are the minimum and maximum value, respectively.</p>
</td></tr>
<tr><td><code id="norm.data_+3A_min.scale">min.scale</code></td>
<td>
<p>the minimum value within normalization.</p>
</td></tr>
<tr><td><code id="norm.data_+3A_max.scale">max.scale</code></td>
<td>
<p>the maximum value within normalization.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the normalized data
</p>


<h3>See Also</h3>

<p><code><a href="#topic+denorm.data">denorm.data</a></code>
</p>

<hr>
<h2 id='plotMF'>The plotting function</h2><span id='topic+plotMF'></span>

<h3>Description</h3>

<p>This function can be used to plot the shapes of the membership functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMF(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotMF_+3A_object">object</code></td>
<td>
<p>an <code><a href="#topic+frbs-object">frbs-object</a></code> or a list of parameters to plot membership functions when we build the frbs model without learning. 
For plotting using the list, there are several parameters that must be inserted in params as follows.
</p>

<ul>
<li> <p><code>var.mf</code>: a matrix of membership function of input and output variables. Please see <code><a href="#topic+fuzzifier">fuzzifier</a></code>.
</p>
</li>
<li> <p><code>range.data.ori</code>: a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum values, respectively. 
</p>
</li>
<li> <p><code>num.labels</code>: the number of linguistic terms of the input and output variables. 
</p>
<p>For example: <code>num.labels &lt;- matrix(c(3, 3, 3), nrow = 1)</code>
</p>
<p>It means we have 3 linguistic values/labels for two input variables and one output variable.
</p>
</li>
<li> <p><code>names.variables</code>: a list of names of variables. 
</p>
<p>For example: <code>names.variables &lt;- c("input1", "input2", "output1")</code>
</p>
</li></ul>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## The following examples contain two different cases which are
## using an frbs-object and the manual way. 
## 
## 1. Plotting using frbs object.
data(iris)
irisShuffled &lt;- iris[sample(nrow(iris)),]
irisShuffled[,5] &lt;- unclass(irisShuffled[,5])
tra.iris &lt;- irisShuffled[1:105,]
tst.iris &lt;- irisShuffled[106:nrow(irisShuffled),1:4]
real.iris &lt;- matrix(irisShuffled[106:nrow(irisShuffled),5], ncol = 1)

## Please take into account that the interval needed is the range of input data only.
range.data.input &lt;- matrix(c(4.3, 7.9, 2.0, 4.4, 1.0, 6.9, 0.1, 2.5), nrow=2)

## generate the model
method.type &lt;- "FRBCS.W"
control &lt;- list(num.labels = 7, type.mf = 1) 
## Not run: object &lt;- frbs.learn(tra.iris, range.data.input, method.type, control) 

## plot the frbs object
## Not run: plotMF(object)

## 2. Plotting using params.
## Define shape and parameters of membership functions of input variables.
## Please see the fuzzifier function of how to contruct the matrix.
varinp.mf &lt;- matrix(c(2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA,
                      2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA,
                      2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA,
                      2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA),
                      nrow = 5, byrow = FALSE)

## Define the shapes and parameters of the membership functions of the output variables.
varout.mf &lt;- matrix(c(2, 0, 20, 40, NA, 4, 20, 40, 60, 80, 3, 60, 80, 100, NA),
                      nrow = 5, byrow = FALSE)
var.mf &lt;- cbind(varinp.mf, varout.mf)
range.data &lt;- matrix(c(0,100, 0, 100, 0, 100, 0, 100, 0, 100), nrow=2)
num.labels &lt;- matrix(c(3,3,3,3,3), nrow = 1)
names.variables &lt;- c("input1", "input2", "input3", "input4", "output1")

## plot the membership function.
## Not run: plotMF(object = list(var.mf = var.mf, range.data.ori = range.data, 
          num.labels = num.labels, names.variables = names.variables))
## End(Not run)
</code></pre>

<hr>
<h2 id='predict.frbs'>The frbs prediction stage</h2><span id='topic+predict.frbs'></span><span id='topic+predict'></span>

<h3>Description</h3>

<p>This is the main function to obtain a final result as predicted values for all methods in this package. 
In order to get predicted values, this function is run using an <code><a href="#topic+frbs-object">frbs-object</a></code>, which is typically generated using <code><a href="#topic+frbs.learn">frbs.learn</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'frbs'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.frbs_+3A_object">object</code></td>
<td>
<p>an <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="predict.frbs_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables. It should be noted that the testing data must be expressed in numbers (numerical data).</p>
</td></tr>
<tr><td><code id="predict.frbs_+3A_...">...</code></td>
<td>
<p>the other parameters (not used)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+frbs.gen">frbs.gen</a></code> for learning and model generation, 
and the internal main functions of each method for the theory:  
<code><a href="#topic+WM">WM</a></code>, <code><a href="#topic+SBC">SBC</a></code>, <code><a href="#topic+HyFIS">HyFIS</a></code>, <code><a href="#topic+ANFIS">ANFIS</a></code>, 
<code><a href="#topic+FIR.DM">FIR.DM</a></code>, <code><a href="#topic+DENFIS">DENFIS</a></code>, <code><a href="#topic+FS.HGD">FS.HGD</a></code>, <code><a href="#topic+FRBCS.W">FRBCS.W</a></code>, 
<code><a href="#topic+GFS.FR.MOGUL">GFS.FR.MOGUL</a></code>, <code><a href="#topic+GFS.Thrift">GFS.Thrift</a></code>, <code><a href="#topic+GFS.GCCL">GFS.GCCL</a></code>, <code><a href="#topic+FRBCS.CHI">FRBCS.CHI</a></code>, 
<code><a href="#topic+FH.GBML">FH.GBML</a></code>, <code><a href="#topic+GFS.LT.RS">GFS.LT.RS</a></code>, and <code><a href="#topic+SLAVE">SLAVE</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##################################
## I. Regression Problem
###################################
## In this example, we just show how to predict using Wang and Mendel's technique but
## users can do it in the same way for other methods.
data.train &lt;- matrix(c(5.2, -8.1, 4.8, 8.8, -16.1, 4.1, 10.6, -7.8, 5.5, 10.4, -29.0, 
                       5.0, 1.8, -19.2, 3.4, 12.7, -18.9, 3.4, 15.6, -10.6, 4.9, 1.9, 
                       -25.0, 3.7, 2.2, -3.1, 3.9, 4.8, -7.8, 4.5, 7.9, -13.9, 4.8, 
                       5.2, -4.5, 4.9, 0.9, -11.6, 3.0, 11.8, -2.1, 4.6, 7.9, -2.0, 
                       4.8, 11.5, -9.0, 5.5, 10.6, -11.2, 4.5, 11.1, -6.1, 4.7, 12.8, 
                       -1.0, 6.6, 11.3, -3.6, 5.1, 1.0, -8.2, 3.9, 14.5, -0.5, 5.7, 
                       11.9, -2.0, 5.1, 8.1, -1.6, 5.2, 15.5, -0.7, 4.9, 12.4, -0.8, 
                       5.2, 11.1, -16.8, 5.1, 5.1, -5.1, 4.6, 4.8, -9.5, 3.9, 13.2, 
                       -0.7, 6.0, 9.9, -3.3, 4.9, 12.5, -13.6, 4.1, 8.9, -10.0, 
                       4.9, 10.8, -13.5, 5.1), ncol = 3, byrow = TRUE)

data.fit &lt;- matrix(c(10.5, -0.9, 5.2, 5.8, -2.8, 5.6, 8.5, -0.2, 5.3, 13.8, -11.9,
                     3.7, 9.8, -1.2, 4.8, 11.0, -14.3, 4.4, 4.2, -17.0, 5.1, 6.9, 
                     -3.3, 5.1, 13.2, -1.9, 4.6), ncol = 3, byrow = TRUE)

newdata &lt;- matrix(c(10.5, -0.9, 5.8, -2.8, 8.5, -0.2, 13.8, -11.9, 9.8, -1.2, 11.0,
                      -14.3, 4.2, -17.0, 6.9, -3.3, 13.2, -1.9), ncol = 2, byrow = TRUE)

range.data&lt;-matrix(c(0.9, 15.6, -29, -0.2, 3, 6.6), ncol=3, byrow = FALSE)
#############################################################
## I.1 Example: Implementation of Wang &amp; Mendel
#############################################################
method.type &lt;- "WM" 

## collect control parameters into a list
## num.labels = 3 means we define 3 as the number of linguistic terms
control.WM &lt;- list(num.labels = 3, type.mf = "GAUSSIAN", type.tnorm = "MIN", 
               type.snorm = "MAX", type.defuz = "WAM", 
               type.implication.func = "ZADEH", name = "Sim-0") 

## generate the model and save it as object.WM
object.WM &lt;- frbs.learn(data.train, range.data, method.type, control.WM)

## the prediction process
## The following code can be used for all methods
res &lt;- predict(object.WM, newdata)

</code></pre>

<hr>
<h2 id='read.frbsPMML'>The frbsPMML reader</h2><span id='topic+read.frbsPMML'></span>

<h3>Description</h3>

<p>It is used to read the frbsPMML format into an frbs model in R. Detailed information about frbsPMML can be seen in <code><a href="#topic+frbsPMML">frbsPMML</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.frbsPMML(fileName)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.frbsPMML_+3A_filename">fileName</code></td>
<td>
<p>a file name with extension <code>.frbsPMML</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object representing the frbs model.
</p>
<p>an frbs object
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write.frbsPMML">write.frbsPMML</a></code> and <code><a href="#topic+frbsPMML">frbsPMML</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This example shows how to construct and read frbsPMML file of frbs model
## Even though we are using MAMDANI model, other models have the same way
## 
## 1. Produce frbs model, for example: we perform Wang &amp; Mendel's technique (WM)
##
## Input data
data(frbsData)
data.train &lt;- frbsData$GasFurnance.dt[1 : 204, ]
data.fit &lt;- data.train[, 1 : 2]
data.tst &lt;- frbsData$GasFurnance.dt[205 : 292, 1 : 2]
real.val &lt;- matrix(frbsData$GasFurnance.dt[205 : 292, 3], ncol = 1)
range.data&lt;-matrix(c(-2.716, 2.834, 45.6, 60.5, 45.6, 60.5), nrow = 2)

## Set the method and its parameters
method.type &lt;- "WM"
control &lt;- list(num.labels = 15, type.mf = "GAUSSIAN", type.defuz = "WAM", 
                type.tnorm = "MIN", type.implication.func = "ZADEH", 
                name="sim-0") 

## Generate fuzzy model
## Not run: object &lt;- frbs.learn(data.train, range.data, method.type, control)

## 2. Write frbsPMML file
## In this step, we provide two ways as follows.
## a. by calling frbsPMML() function directly. 
## b. by calling write.frbsPMML() function. 

## 2a. by calling frbsPMML(), the format will be displayed in R console
## Not run: frbsPMML(object)

## 2b. by calling write.frbsPMML(), the result will be saved as a file
##     in the working directory.
## Not run: write.frbsPMML(object, file = "MAMDANI.GasFur")

## 3. Read frbsPMML file
## Not run: object &lt;- read.frbsPMML("MAMDANI.GasFur.frbsPMML")

## 4. Perform predicting step
## Not run: res.test &lt;- predict(object, data.tst)

</code></pre>

<hr>
<h2 id='rulebase'>The rule checking function</h2><span id='topic+rulebase'></span>

<h3>Description</h3>

<p>This function checks the consistency of a rule definition (given by the user).
The rulebase consists of several fuzzy IF-THEN rules. The rules could be in 
a list or matrix type. Generally, there are three types of rule structures which are
rules based on Mamdani, Takagi Sugeno Kang and fuzzy rule-based classification systems (FRBCS).
</p>
<p>For rules of the Mamdani model, there are 2 parts in each rule, the antecedent and 
the consequent part, which are separated by &quot;-&gt;&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rulebase(type.model, rule, func.tsk = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rulebase_+3A_type.model">type.model</code></td>
<td>
<p>a value determining the type of model to use. 
Here, <code>MAMDANI</code> and <code>TSK</code> mean Mamdani and Takagi Sugeno Kang model, respectively.</p>
</td></tr>
<tr><td><code id="rulebase_+3A_rule">rule</code></td>
<td>
<p>a matrix or list of rules.</p>
</td></tr>
<tr><td><code id="rulebase_+3A_func.tsk">func.tsk</code></td>
<td>
<p>a matrix representing the consequent parts of rules in Takagi Sugeno Kang formulation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example:  <code>r1 &lt;- c("a1","and","b1","-&gt;", "c1")</code>
</p>
<p>It means that &quot;IF input.variable1 is a1 and input.variable2 is b1 THEN output.variable is c1&quot;
</p>
<p>Here, (&quot;a1&quot;, &quot;and&quot;, &quot;b1&quot;) is the antecedent, with &quot;a1&quot; and &quot;b1&quot; being linguistic terms, 
and (&quot;c1&quot;) is the consequent part.
</p>
<p>A fuzzy IF-THEN rule base with several rules is defined in the following way:
</p>
<p><code>r1 &lt;- c("not a1","and","b1", "-&gt;", "c1")</code>
</p>
<p><code>r2 &lt;- c("a2","or","b2", "-&gt;", "c2")</code>
</p>
<p><code>r3 &lt;- c("a3","or","b2", "-&gt;", "c3")</code>
</p>
<p><code>rule &lt;- list(r1,r2,r3)</code>
</p>
<p>For rules of the Takagi Sugeno Kang model, the rules are at first defined without the consequent part, e.g.:
</p>
<p><code>r1 &lt;- c("a1",1,"b1","-&gt;")</code>
</p>
<p><code>r2 &lt;- c("a2",2,"b2", "-&gt;")</code>
</p>
<p><code>r3 &lt;- c("a3","2","b2", "-&gt;")</code>
</p>
<p><code>rule &lt;- list(r1,r2,r3)</code>
</p>
<p>The consequences are defined then as a matrix <code>fun_tsk</code>, which contains the linear equations of the consequences of the rules.
The dimension of this matrix is [&lt;number_of_rules&gt;, &lt;number_of_variables&gt; + 1]. The matrix has one extra column for the constants. 
If there is no constant, a zero is put.
</p>
<p>So, for example, if we have 3 rules and 2 linguistic variables (A, B), the matrix <code>fun_tsk</code> has dim(3,3), as in:
</p>
<p><code>func.tsk &lt;- matrix(c(1, 1, 5, 2, 1, 3, 1, 2, 2), nrow=3, ncol=3, byrow = TRUE)</code>
</p>
<p>Furthermore, we can represent linguistic hedges within the rules. The kinds of hedges used are
</p>

<ul>
<li> <p><code>"extremely"</code> reduces the truth value. For example, <code>"extremely a1"</code> means membership function <code class="reqn">a1 = \mu(a1)^3</code>.
</p>
</li>
<li> <p><code>"very"</code> reduces the truth value. For example, <code>"very a1"</code> means membership function <code class="reqn">a1 = \mu(a1)^2</code>.
</p>
</li>
<li> <p><code>"somewhat"</code> increases the truth value. For example, <code>"somewhat a1"</code> means membership function 
<code class="reqn">a1 = \mu(a1)^0.5</code>.
</p>
</li>
<li> <p><code>"slightly"</code> increases the truth value. For example, <code>"slightly a1"</code> means membership function 
<code class="reqn">a1 = \mu(a1)^0.33</code>
</p>
</li></ul>

<p>An example of fuzzy IF-THEN rules using linguistic hedge is:
</p>
<p><code>r1 &lt;- c("very a1","and","b1","-&gt;","c1")</code>
</p>
<p><code>r2 &lt;- c("a2",2,"b2", "-&gt;", "c2")</code>
</p>
<p><code>r3 &lt;- c("a3","2","slightly b2", "-&gt;", "c3")</code>
</p>
<p><code>rule &lt;- list(r1,r2,r3)</code>
</p>
<p>Furthermore, the following is an example in order to give names to the linguistic terms in the input and output variables.
</p>
<p><code>varinput.1 &lt;- c("a1", "a2", "a3")</code>
</p>
<p><code>varinput.2 &lt;- c("b1", "b2")</code>
</p>
<p><code>names.varinput &lt;- c(varinput.1, varinput.2)</code>
</p>
<p><code>names.varoutput &lt;- c("c1", "c2", "c3")</code>
</p>
<p>In case of FRBCS model, the structure of rules are quite similar with Takagi Sugeno Kang model. But, instead of using 
linear equation in consequent part, consequent parts in FRBCS are represented by class. For example,
Take into account that consequent parts expresses classes.
</p>
<p><code>rule&lt;-matrix(c("v.1_a.2","and","v.2_a.2","and","v.3_a.3","and","v.4_a.2","-&gt;","3",</code>
</p>
<p><code>"v.1_a.2","and","v.2_a.3","and","v.3_a.1","and","v.4_a.3","-&gt;","1",</code>
</p>
<p><code>"v.1_a.2","and","v.2_a.2","and","v.3_a.2","and","v.4_a.2","-&gt;","2"),</code>
</p>
<p><code>nrow=3, byrow=TRUE)</code>
</p>
<p>Where, <code>"1"</code>, <code>"2"</code>, <code>"3"</code> represent class <code>1</code>, <code>2</code>, and <code>3</code>.
</p>
<p>Noted that all rules included in rule base must have the same length as many as the number of variables. 
However, we can ignore some input variables by defining the &quot;dont_care&quot; value. 
For example, the rule (&quot;not a1&quot;,&quot;and&quot;,&quot;dont_care&quot;, &quot;-&gt;&quot;, &quot;c1&quot;) refers to the rule (&quot;not a1&quot; &quot;-&gt;&quot;, &quot;c1&quot;). 
Furthermore, if we are using the learning methods, the fuzzy IF-THEN rules will be generated automatically 
as the outputs of <code><a href="#topic+frbs.learn">frbs.learn</a></code>.
</p>


<h3>Value</h3>

<p>fuzzy IF-THEN rule base
</p>


<h3>See Also</h3>

<p><code><a href="#topic+defuzzifier">defuzzifier</a></code>, <code><a href="#topic+inference">inference</a></code>, and <code><a href="#topic+fuzzifier">fuzzifier</a></code>
</p>

<hr>
<h2 id='SBC'>The subtractive clustering and fuzzy c-means (SBC) model building</h2><span id='topic+SBC'></span>

<h3>Description</h3>

<p>This is the internal function that implements a combination of the subtractive 
clustering method and fuzzy c-means. It is used to solve regression tasks. Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBC(data.train, range.data.ori, r.a = 0.5, eps.high = 0.5,
  eps.low = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SBC_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable.</p>
</td></tr>
<tr><td><code id="SBC_+3A_range.data.ori">range.data.ori</code></td>
<td>
<p>a matrix (<code class="reqn">2 \times n</code>) containing the range of the data, where <code class="reqn">n</code> is the number of variables, and
first and second rows are the minimum and maximum value, respectively.</p>
</td></tr>
<tr><td><code id="SBC_+3A_r.a">r.a</code></td>
<td>
<p>the radius defining a neighborhood.</p>
</td></tr>
<tr><td><code id="SBC_+3A_eps.high">eps.high</code></td>
<td>
<p>an upper threshold value.</p>
</td></tr>
<tr><td><code id="SBC_+3A_eps.low">eps.low</code></td>
<td>
<p>a lower threshold value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method was proposed by S. Chiu. For generating the rules 
in the learning phase, the subtractive clustering method is used to obtain the cluster 
centers. Subtractive clustering (SBC) is an extension of Yager and Filev's 
mountain method.
SBC considers each data point as a potential cluster center by determining 
the potential of a data point as a function of its distances to all the other 
data points. A data point has a high potential value if that data 
point has many nearby neighbors.
The highest potential is chosen as the cluster center and then the potential of 
each data point will be updated. The process of determining new clusters and updating 
potentials repeats until the remaining potential of all data points falls below 
some fraction  
of the potential of the first cluster center. After getting all the cluster 
centers from subtractive clustering,
the cluster centers are optimized by fuzzy c-means.
</p>


<h3>References</h3>

<p>R. Yager and D. Filev, &quot;Generation of fuzzy rules by mountain clustering,&quot; 
J. of Intelligent and Fuzzy Systems, vol. 2, no. 3, pp. 209 - 219 (1994).
</p>
<p>S. Chiu, &quot;Method and software for extracting fuzzy classification rules by subtractive clustering&quot;, 
Fuzzy Information Processing Society, NAFIPS, pp. 461 - 465 (1996).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SBC.test">SBC.test</a></code>, <code><a href="#topic+frbs.learn">frbs.learn</a></code>, and <code><a href="#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='SBC.test'>SBC prediction phase</h2><span id='topic+SBC.test'></span>

<h3>Description</h3>

<p>This function is the internal function of the SBC method to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SBC.test(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SBC.test_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="SBC.test_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+SBC">SBC</a></code>
</p>

<hr>
<h2 id='SLAVE'>SLAVE model building</h2><span id='topic+SLAVE'></span>

<h3>Description</h3>

<p>This is the internal function that implements 
the structural learning algorithm on vague environment (SLAVE). It is used to handle classification tasks.
Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLAVE(data.train, persen_cross = 0.6, persen_mutant = 0.3,
  max.iter = 10, max.gen = 10, num.labels, range.data.input,
  k.lower = 0.25, k.upper = 0.75, epsilon = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLAVE_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, 
where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; The last column is the output variable.
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_persen_cross">persen_cross</code></td>
<td>
<p>a real number between 0 and 1 representing the probability of crossover.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_persen_mutant">persen_mutant</code></td>
<td>
<p>a real number between 0 and 1 representing the probability of mutation.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_max.iter">max.iter</code></td>
<td>
<p>the maximal number of iterations.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_max.gen">max.gen</code></td>
<td>
<p>the maximal number of generations for the genetic algorithm.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_num.labels">num.labels</code></td>
<td>
<p>a number of the linguistic terms.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_range.data.input">range.data.input</code></td>
<td>
<p>a matrix containing the ranges of the normalized input data.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_k.lower">k.lower</code></td>
<td>
<p>a lower bound of the noise threshold.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_k.upper">k.upper</code></td>
<td>
<p>an upper bound of the noise threshold.</p>
</td></tr>
<tr><td><code id="SLAVE_+3A_epsilon">epsilon</code></td>
<td>
<p>a value between 0 and 1 representing the covering factor.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is adopted from A. Gonzalez and R. Perez's paper which is applied for 
classification problems. SLAVE is based on the iterative rule learning approach 
which means that we get only one fuzzy rule in each execution of the genetic algorithm. 
In order to eliminate the irrelevant variables in a rule, 
SLAVE has a structure composed of two parts: the first part is to represent 
the relevance of variables and the second one is to define values of the parameters. 
The following steps are conducted in order to obtain fuzzy rules:
</p>

<ul>
<li><p> Step 1: Use the genetic algorithm process to obtain ONE RULE for the system.
</p>
</li>
<li><p> Step 2: Collect the rule into the final set of rules.
</p>
</li>
<li><p> Step 3: Check and penalize this rule.
</p>
</li>
<li><p> Step 4: If the stopping criteria is satisfied, 
the system returns the set of rules as solution. Otherwise, back to Step 1.
</p>
</li></ul>

<p>This method uses binary codes as representation of the population and 
applies the basic genetic operators, i.e., selection, crossover, and mutation on it.
And, the best rule is obtained by calculating the degree of consistency and completeness.
</p>


<h3>References</h3>

<p>A. Gonzalez and R. Perez, &quot;Selection of relevant features in a fuzzy genetic learning algorithm&quot;,  
IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, vol. 31, no. 3, 
pp.  417 - 425 (2001).
</p>

<hr>
<h2 id='SLAVE.test'>SLAVE.test: The prediction phase</h2><span id='topic+SLAVE.test'></span>

<h3>Description</h3>

<p>This function is the internal function of the SLAVE method to compute the predicted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SLAVE.test(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SLAVE.test_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code>.</p>
</td></tr>
<tr><td><code id="SLAVE.test_+3A_newdata">newdata</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of data for the prediction process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of input variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predicted values.
</p>

<hr>
<h2 id='summary.frbs'>The summary function for frbs objects</h2><span id='topic+summary.frbs'></span>

<h3>Description</h3>

<p>This function enables the output of a summary of the <code><a href="#topic+frbs-object">frbs-object</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'frbs'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.frbs_+3A_object">object</code></td>
<td>
<p>the <code><a href="#topic+frbs-object">frbs-object</a></code></p>
</td></tr>
<tr><td><code id="summary.frbs_+3A_...">...</code></td>
<td>
<p>the other parameters (not used)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function displays several components of the object. The components of 
one particular method can be different from components of other methods.
The following is a description of all components which might be printed.
</p>

<ul>
<li><p> The name of the model: A name given by the user representing the name of the simulation
or data or model.
</p>
</li>
<li><p> Model was trained using: It shows which method we have been used.
</p>
</li>
<li><p> The names of attributes: a list of names of training data.
</p>
</li>
<li><p> The interval of training data: It is a matrix representing the original 
interval of data where the first and second rows are minimum and maximum of data, 
respectively. The number of columns represents the number of variables.
</p>
</li>
<li><p> Type of FRBS model: a description expresses one of the following FRBS model available such as <code>"MAMDANI"</code>, <code>"TSK"</code>,
<code>"FRBCS"</code>, <code>"CLUSTERING"</code>, <code>"APPROXIMATE"</code>, and <code>"2TUPPLE"</code>.
</p>
</li>
<li><p> Type of membership function: a description expresses one of the following shapes of membership functions: 
<code>"GAUSSIAN"</code>, code&quot;TRIANGLE&quot;, <code>"TRAPEZOID"</code>, <code>"SIGMOID"</code>, and <code>"BELL"</code>.
</p>
</li>
<li><p> Type of t-norm method: a description expresses one of the following type of t-norm: <code>"MIN"</code>, <code>"PRODUCT"</code>, <code>"HAMACHER"</code>,
<code>"YAGER"</code>, and <code>"BOUNDED"</code>.
</p>
</li>
<li><p> Type of s-norm method: a description expresses one of the following type of s-norm: <code>"MAX"</code>, <code>"SUM"</code>, <code>"HAMACHER"</code>,
<code>"YAGER"</code>, and <code>"BOUNDED"</code>.
</p>
</li>
<li><p> Type of defuzzification technique: a description expresses one of the following types: <code>"WAM"</code>, <code>"FIRST_MAX"</code>, 
<code>"LAST_MAX"</code>, <code>"MEAN_MAX"</code>, and <code>"COG"</code>. 
</p>
</li>
<li><p> Type of implication function: a description expresses one of the following types: 
<code>"DIENES_RESHER"</code>, <code>"LUKASIEWICZ"</code>,
<code>"ZADEH"</code>, <code>"GOGUEN"</code>, <code>"GODEL"</code>, <code>"SHARP"</code>, <code>"MIZUMOTO"</code>, 
<code>"DUBOIS_PRADE"</code>, and <code>"MIN"</code>.
</p>
</li>
<li><p> The names of linguistic terms of the input variables: These names are generated
automatically by frbs expressing all linguistic terms considered. Generally,
these names are built by two parts which are the name of variables expressed 
by <code>"v"</code> and the name of linguistic terms of each variables represented by <code>"a"</code>. 
For example, <code>"v.1_a.1"</code> means the linguistic value <code>"a.1"</code> of the first variable (v.1).
However, we provide different format if we set the number of linguistic terms (<code>num.labels</code>) to 3, 5, 7. 
For example, for the number of label 3, it will be <code>"small"</code>, <code>"medium"</code>, and <code>"large"</code>.
</p>
</li>
<li><p> The names of linguistic terms of the output variable: For the Mamdani model, since the frbs package only considers
single output, the names of the linguistic terms for the output variable 
are simple and clear and start with <code>"c"</code>. However, for the Takagi Sugeno Kang model and
fuzzy rule-based classification systems, this component is always <code>NULL</code>.
</p>
</li>
<li><p> The parameter values of membership functions of the input variables (normalized):
It is represented by a matrix (<code class="reqn">5 \times n</code>) where n depends on the number of 
linguistic terms on the input variables and the first row of the matrix describes 
a type of membership function, and the rest of rows are 
their parameter values. 
For example, label <code>"v.1_a.2"</code> has value 
4.0, 0.23, 0.43, 0.53, 0.73 on its column. It means that the label a.2 of variable v.1 
has a parameter as follows. 
4.0 on the first row shows <code>TRAPEZOID</code> shape in the middle position, 
while 0.23, 0.43, 0.53, and 0.73 are corner points of a <code>TRAPEZOID</code>. 
Furthermore, the following is the complete list of shapes of membership functions:
</p>

<ul>
<li> <p><code>TRIANGLE</code>: 1 on the first row and rows 2, 3, and 4 represent corner points. 
</p>
</li>
<li> <p><code>TRAPEZOID</code>: 2, 3, or 4 on the first row means they are <code>TRAPEZOID</code> in left, right and middle side, respectively,
and rows 2, 3, 4, and 5 represent corner points. But for <code>TRAPEZOID</code> at left or right side the fifth row is <code>NA</code>. 
</p>
</li>
<li> <p><code>GAUSSIAN</code>: 5 on the first row means it uses <code>GAUSSIAN</code> and second and third row represent mean and variance.
</p>
</li>
<li> <p><code>SIGMOID</code>: 6 on the first row and two parameters (gamma and c) on second and third rows.
</p>
</li>
<li> <p><code>BELL</code>: 7 on the first row and three parameters (a, b, c) on second, third, and fourth rows.
</p>
</li></ul>

</li>
<li><p> The fuzzy IF-THEN rules: In this package, there are several models for representing
fuzzy IF-THEN rules based on the method used. 
</p>

<ul>
<li><p> the Mamdani model: they are represented as a knowledge base containing two parts: 
antecedent and consequent parts which are separated by a sign &quot;THEN&quot;, as for example in the
following rule:
</p>
<p><code>IF var.1 is v.1_a.1 and var.2 is v.2_a.2 THEN var.3 is c.2</code>
</p>
</li>
<li><p> the Takagi Sugeno Kang model: In this model, this component only represents the antecedent
of rules while the consequent part will be represented by linear equations. 
</p>
</li>
<li><p> fuzzy rule-based classification systems (FRBCS): This model is quite similar to the Takagi Sugeno Kang model,
but the consequent part expresses pre-defined classes instead of a simplify of linear equations.
</p>
</li>
<li><p> approximate approach: Especially for <code>GFS.FR.MOGUL</code>, a matrix of parameters
of membership functions is used to represent the fuzzy IF-THEN rules as well.  
The representation of rules and membership functions is a matrix (<code class="reqn">n \times (p \times m)</code>) where
n is the number of rules and m is the number of variables while p is the number of corner points 
of the membership function, if we are using <code>TRIANGLE</code> or <code>TRAPEZOID</code> then p = 3 or 4, respectively. 
For example, let us consider the triangular membership function and a number of variables of 3. 
The representation of rules and membership functions is as follows:
</p>
<p><code>&lt;&lt;a11 a12 a13&gt;&gt; &lt;&lt;b11 b12 b13&gt;&gt; &lt;&lt;c11 c12 c13&gt;&gt;</code>.
</p>
</li></ul>

</li>
<li><p> The linear equations on consequent parts of fuzzy IF-THEN rules: It is used in
the Takagi Sugeno Kang model.
</p>
</li>
<li><p> The weight of the rules or the certainty factor: For the <code>FRBCS.W</code> method, this shows the weight related to the rules 
representing the ratio of dominance among the rules.
</p>
</li>
<li><p> The cluster centers: This component is used in clustering methods representing cluster centers.
</p>
</li></ul>


<hr>
<h2 id='WM'>WM model building</h2><span id='topic+WM'></span>

<h3>Description</h3>

<p>This is the internal function that implements the model proposed by L. X. Wang and J. M. 
Mendel. It is used to solve regression task. Users do not need to call it directly,
but just use <code><a href="#topic+frbs.learn">frbs.learn</a></code> and <code><a href="#topic+predict">predict</a></code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WM(data.train, num.labels, type.mf = "GAUSSIAN",
  type.tnorm = "PRODUCT", type.implication.func = "ZADEH",
  classification = FALSE, range.data = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WM_+3A_data.train">data.train</code></td>
<td>
<p>a matrix (<code class="reqn">m \times n</code>) of normalized data for the training process, where <code class="reqn">m</code> is the number of instances and 
<code class="reqn">n</code> is the number of variables; the last column is the output variable. 
Note the data must be normalized between 0 and 1.</p>
</td></tr>
<tr><td><code id="WM_+3A_num.labels">num.labels</code></td>
<td>
<p>a matrix (<code class="reqn">1 \times n</code>), whose elements represent the number of labels (linguistic terms); 
<code class="reqn">n</code> is the number of variables.</p>
</td></tr>
<tr><td><code id="WM_+3A_type.mf">type.mf</code></td>
<td>
<p>the type of the membership function. See <code><a href="#topic+frbs.learn">frbs.learn</a></code>.</p>
</td></tr>
<tr><td><code id="WM_+3A_type.tnorm">type.tnorm</code></td>
<td>
<p>a value which represents the type of t-norm. See <code><a href="#topic+inference">inference</a></code>.</p>
</td></tr>
<tr><td><code id="WM_+3A_type.implication.func">type.implication.func</code></td>
<td>
<p>a value representing type of implication function. Let us consider a rule, <code class="reqn">a \to b</code>,
</p>

<ul>
<li> <p><code>DIENES_RESHER</code> means <code class="reqn">(b &gt; 1 - a? b : 1 - a)</code>.
</p>
</li>
<li> <p><code>LUKASIEWICZ</code> means <code class="reqn">(b &lt; a ? 1 - a + b : 1)</code>.
</p>
</li>
<li> <p><code>ZADEH</code> means <code class="reqn">(a &lt; 0.5 || 1 - a &gt; b ? 1 - a : (a &lt; b ? a : b))</code>.
</p>
</li>
<li> <p><code>GOGUEN</code> means <code class="reqn">(a &lt; b ? 1 : b / a)</code>.
</p>
</li>
<li> <p><code>GODEL</code> means <code class="reqn">(a &lt;= b ? 1 : b)</code>.
</p>
</li>
<li> <p><code>SHARP</code> means <code class="reqn">(a &lt;= b ? 1 : 0)</code>.
</p>
</li>
<li> <p><code>MIZUMOTO</code> means <code class="reqn">(1 - a + a * b)</code>.
</p>
</li>
<li> <p><code>DUBOIS_PRADE</code> means <code class="reqn">(b == 0 ? 1 - a : (a == 1 ? b : 1))</code>.
</p>
</li>
<li> <p><code>MIN</code> means <code class="reqn">(a &lt; b ? a : b)</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="WM_+3A_classification">classification</code></td>
<td>
<p>a boolean representing whether it is a classification problem or not.</p>
</td></tr>
<tr><td><code id="WM_+3A_range.data">range.data</code></td>
<td>
<p>a matrix representing interval of data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fuzzy rule-based system for learning from L. X. Wang and J. M. 
Mendel's paper is implemented in this function. For the learning process, there are four stages as follows: 
</p>

<ul>
<li> <p><code>Step 1:</code> Divide equally the input and output spaces of the given numerical data into 
fuzzy regions as the database. In this case, fuzzy regions refers to intervals for each 
linguistic term. Therefore, the length of fuzzy regions represents the number of 
linguistic terms. For example, the linguistic term &quot;hot&quot; has the fuzzy region <code class="reqn">[1, 3]</code>. 
We can construct a triangular membership function having the corner points 
<code class="reqn">a = 1</code>, <code class="reqn">b = 2</code>, and <code class="reqn">c = 3</code> where <code class="reqn">b</code> is a middle point 
that its degree of the membership function equals one. 
</p>
</li>
<li> <p><code>Step 2:</code> Generate fuzzy IF-THEN rules covering the training data, 
using the database from Step 1. First, we calculate degrees of the membership function
for all values in the training data. For each instance in the training data, 
we determine a linguistic term having a maximum degree in each variable. 
Then, we repeat the process for each instance in the training data to construct 
fuzzy rules covering the training data.
</p>
</li>
<li> <p><code>Step 3:</code> Determine a degree for each rule. 
Degrees of each rule are determined by aggregating the degree of membership functions in 
the antecedent and consequent parts. In this case, we are using the product aggregation operators. 
</p>
</li>
<li> <p><code>Step 4:</code> Obtain a final rule base after deleting redundant rules. 
Considering degrees of rules, we can delete the redundant rules having lower degrees. 
</p>
</li></ul>

<p>The outcome is a Mamdani model. In the prediction phase, 
there are four steps: fuzzification, checking the rules, inference, and defuzzification.
</p>


<h3>References</h3>

<p>L.X. Wang and J.M. Mendel, &quot;Generating fuzzy rule by learning from examples&quot;, IEEE Trans. Syst., Man, and Cybern.,
vol. 22, no. 6, pp. 1414 - 1427 (1992).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+frbs.learn">frbs.learn</a></code>, <code><a href="#topic+predict">predict</a></code> and <code><a href="#topic+frbs.eng">frbs.eng</a></code>.
</p>

<hr>
<h2 id='write.frbsPMML'>The frbsPMML writer</h2><span id='topic+write.frbsPMML'></span>

<h3>Description</h3>

<p>It is a function used to save an FRBS model to the .frbsPMML file. Detailed information about frbsPMML can be seen in <code><a href="#topic+frbsPMML">frbsPMML</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.frbsPMML(object, fileName = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.frbsPMML_+3A_object">object</code></td>
<td>
<p>a frbsPMML object which is an object produced by <code><a href="#topic+frbsPMML">frbsPMML</a></code>.</p>
</td></tr>
<tr><td><code id="write.frbsPMML_+3A_filename">fileName</code></td>
<td>
<p>a file name with extension <code>.frbsPMML</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a file containing an FRBS model in frbsPMML format
</p>


<h3>References</h3>

<p>A. Guazzelli, M. Zeller, W.C. Lin, and G. Williams., 
&quot;pmml: An open standard for sharing models&quot;, The R Journal, Vol. 1, No. 1, pp. 60-65 (2009).
</p>
<p>Data Mining Group, http://www.dmg.org/.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read.frbsPMML">read.frbsPMML</a></code> and <code><a href="#topic+frbsPMML">frbsPMML</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## This example shows how to construct frbsPMML file of frbs model
## Even though we are using MAMDANI model, other models have the same way
## 
## 1. Produce frbs model, for example: we perform Wang &amp; Mendel's technique (WM)
##
## Input data
data(frbsData)
data.train &lt;- frbsData$GasFurnance.dt[1 : 204, ]
data.fit &lt;- data.train[, 1 : 2]
data.tst &lt;- frbsData$GasFurnance.dt[205 : 292, 1 : 2]
real.val &lt;- matrix(frbsData$GasFurnance.dt[205 : 292, 3], ncol = 1)
range.data&lt;-matrix(c(-2.716, 2.834, 45.6, 60.5, 45.6, 60.5), nrow = 2)

## Set the method and its parameters
method.type &lt;- "WM"
control &lt;- list(num.labels = 15, type.mf = "GAUSSIAN", type.defuz = "WAM", 
                type.tnorm = "MIN", type.implication.func = "ZADEH", 
                name = "sim-0") 

## Generate fuzzy model
## Not run: object &lt;- frbs.learn(data.train, range.data, method.type, control)

## 2. Write frbsPMML file
## In this step, we provide two steps as follows:
## a. by calling frbsPMML() function directly. 
## b. by calling write.frbsPMML() function. 

## 2a. by calling frbsPMML(), the frbsPMML format will be displayed in R console
## Not run: pmml.obj &lt;- frbsPMML(object)

## 2b. by calling write.frbsPMML(), the result will be saved as a file
##     in the working directory.
## Not run: write.frbsPMML(pmml.obj, file = "MAMDANI.GasFur")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
