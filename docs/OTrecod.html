<!DOCTYPE html><html><head><title>Help for package OTrecod</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OTrecod}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#api29'><p>Student performance in California schools: the results of the county 29</p></a></li>
<li><a href='#api35'><p>Student performance in California schools: the results of the county 35</p></a></li>
<li><a href='#avg_dist_closest'><p>avg_dist_closest()</p></a></li>
<li><a href='#compare_lists'><p>compare_lists()</p></a></li>
<li><a href='#error_group'><p>error_group()</p></a></li>
<li><a href='#ham'><p>ham()</p></a></li>
<li><a href='#imput_cov'><p>imput_cov()</p></a></li>
<li><a href='#indiv_grp_closest'><p>indiv_grp_closest()</p></a></li>
<li><a href='#indiv_grp_optimal'><p>indiv_grp_optimal()</p></a></li>
<li><a href='#merge_dbs'><p>merge_dbs()</p></a></li>
<li><a href='#ncds_14'><p>National Child Development Study: a sample of the first four waves of data collection</p></a></li>
<li><a href='#ncds_5'><p>National Child Development Study: a sample of the fifth wave of data collection</p></a></li>
<li><a href='#OT_joint'><p>OT_joint()</p></a></li>
<li><a href='#OT_outcome'><p>OT_outcome()</p></a></li>
<li><a href='#power_set'><p>power_set()</p></a></li>
<li><a href='#proxim_dist'><p>proxim_dist()</p></a></li>
<li><a href='#select_pred'><p>select_pred()</p></a></li>
<li><a href='#simu_data'><p>A simulated dataset to test the functions of the OTrecod package</p></a></li>
<li><a href='#tab_test'><p>A simulated dataset to test the library</p></a></li>
<li><a href='#transfo_dist'><p>transfo_dist()</p></a></li>
<li><a href='#transfo_quali'><p>transfo_quali()</p></a></li>
<li><a href='#transfo_target'><p>transfo_target()</p></a></li>
<li><a href='#verif_OT'><p>verif_OT()</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Data Fusion using Optimal Transportation Theory</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gregory Guernec &lt;otrecod.pkg@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>In the context of data fusion, the package provides a set of functions dedicated to the solving of 'recoding problems' using optimal transportation theory (Gares, Guernec, Savy (2019) &lt;<a href="https://doi.org/10.1515%2Fijb-2018-0106">doi:10.1515/ijb-2018-0106</a>&gt; and Gares, Omer (2020) &lt;<a href="https://doi.org/10.1080%2F01621459.2020.1775615">doi:10.1080/01621459.2020.1775615</a>&gt;). From two databases with no overlapping part except a subset of shared variables, the functions of the package assist users until obtaining a unique synthetic database, where the missing information is fully completed.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, dplyr, mice, missMDA, plyr, FactoMineR, StatMatch,
proxy, rdist, ROI, ROI.plugin.glpk, ompr, ompr.roi, party, vcd</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown, covr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-05 08:35:44 UTC; secr</td>
</tr>
<tr>
<td>Author:</td>
<td>Gregory Guernec [aut, cre],
  Valerie Gares [aut],
  Pierre Navaro [ctb],
  Jeremy Omer [ctb],
  Philippe Saint-Pierre [ctb],
  Nicolas Savy [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-05 10:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='api29'>Student performance in California schools: the results of the county 29</h2><span id='topic+api29'></span>

<h3>Description</h3>

<p>This database is a sample of the API program <a href="https://www.cde.ca.gov/re/pr/api.asp">https://www.cde.ca.gov/re/pr/api.asp</a> that ended in 2018.
The sample is extracted from the data <code><a href="survey.html#topic+api">api</a></code> of the package <span class="pkg">survey</span>, related to the results of the
county 29 (Nevada).
The database contains information for the 418 schools of this county having at least 100 students.
Missing information has been randomly (and voluntary) added to the <code>awards</code> and <code>ell</code> variables (4% and 7% respectively).
Several variables have been voluntary categorized from their initial types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>api29
</code></pre>


<h3>Format</h3>

<p>A data.frame with 418 schools (rows) and 12 variables
</p>

<dl>
<dt>cds</dt><dd><p>the school identifier</p>
</dd>
<dt>apicl_2000</dt><dd><p>the API score in 2000 classed in 3 ordered levels: <code>[200-600]</code>,<code>(600-800]</code>,<code>(800-1000]</code></p>
</dd>
<dt>stype</dt><dd><p>the school type in a 3 ordered levels factor: <code>Elementary</code>, <code>Middle</code> or <code>High School</code></p>
</dd>
<dt>awards</dt><dd><p>the school eligible for awards program ? Two possible answers: <code>No</code> or <code>Yes</code>. This variable counts 4% of missing information.</p>
</dd>
<dt>acs.core</dt><dd><p>the number of core academic courses in the school</p>
</dd>
<dt>api.stu</dt><dd><p>the number of students tested in the school</p>
</dd>
<dt>acs.k3.20</dt><dd><p>the average class size years K-3 in the school. This variable is stored in a 3-levels factor: <code>Unknown</code>, <code>&lt;=20</code>, <code>&gt;20</code>.</p>
</dd>
<dt>grad.sch</dt><dd><p>the percentage of parents with postgraduate education stored in a 3 ordered levels factor of percents: <code>0</code>, <code>1-10</code>, <code>&gt;10</code></p>
</dd>
<dt>ell</dt><dd><p>the percentage of English language learners stored in a 4 ordered levels factor: <code>[0-10]</code>,<code>(10-30]</code>,<code>(30-50]</code>,<code>(50-100]</code>. This variable counts 7% of missing information.</p>
</dd>
<dt>mobility</dt><dd><p>the percentage of students for whom this is the first year at the school, stored in 2 levels: <code>[0-20]</code> and <code>(20-100]</code></p>
</dd>
<dt>meals</dt><dd><p>the percentage of students eligible for subsidized meals stored in a 4 balanced levels factor (By quartiles): <code>[0-25]</code>, <code>(25-50]</code>, <code>(50-75]</code>, <code>(75-100]</code></p>
</dd>
<dt>full</dt><dd><p>the percentage of fully qualified teachers stored in a 2-levels factor: <code>1</code>: For strictly less than 90%, <code>2</code> otherwise</p>
</dd>
</dl>



<h3>Source</h3>

<p>This database is a sample of the data <code><a href="survey.html#topic+api">api</a></code> from the package <span class="pkg">survey</span>.
</p>

<hr>
<h2 id='api35'>Student performance in California schools: the results of the county 35</h2><span id='topic+api35'></span>

<h3>Description</h3>

<p>This database is a sample of the API program <a href="https://www.cde.ca.gov/re/pr/api.asp">https://www.cde.ca.gov/re/pr/api.asp</a> that ended in 2018.
The sample is extracted from the data <code><a href="survey.html#topic+api">api</a></code> of the package <span class="pkg">survey</span>, related to the results of the
county 35 (San Benito).
The database contains information for the 362 schools of this county having at least 100 students.
Missing information has been randomly (and voluntary) added to the <code>awards</code> and <code>ell</code> variables (4% and 7% respectively).
Several variables have been voluntary categorized from their initial types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>api35
</code></pre>


<h3>Format</h3>

<p>A data.frame with 362 schools (rows) and 12 variables
</p>

<dl>
<dt>cds</dt><dd><p>the school identifier</p>
</dd>
<dt>apicl_1999</dt><dd><p>the API score in 1999 classed in 4 ordered levels: <code>G1</code>,<code>G2</code>,<code>G3</code>, <code>G4</code></p>
</dd>
<dt>stype</dt><dd><p>the school type in a 3 ordered levels factor: <code>Elementary</code>, <code>Middle</code> or <code>High School</code></p>
</dd>
<dt>awards</dt><dd><p>the school eligible for awards program ? Two possible answers: <code>No</code> or <code>Yes</code>. This variable counts 4% of missing information.</p>
</dd>
<dt>acs.core</dt><dd><p>the number of core academic courses in the school</p>
</dd>
<dt>api.stu</dt><dd><p>the number of students tested in the school</p>
</dd>
<dt>acs.k3.20</dt><dd><p>the average class size years K-3 in the school. This variable is stored in a 3-levels factor: <code>Unknown</code>, <code>&lt;=20</code>, <code>&gt;20</code>.</p>
</dd>
<dt>grad.sch</dt><dd><p>the percentage of parents with postgraduate education stored in a 3 ordered levels factor of percents: <code>0</code>, <code>1-10</code>, <code>&gt;10</code></p>
</dd>
<dt>ell</dt><dd><p>the percentage of English language learners stored in a 4 ordered levels factor: <code>[0-10]</code>,<code>(10-30]</code>,<code>(30-50]</code>,<code>(50-100]</code>. This variable counts 7% of missing information.</p>
</dd>
<dt>mobility</dt><dd><p>the percentage of students for whom this is the first year at the school, stored in 2 levels: <code>1</code> and <code>2</code></p>
</dd>
<dt>meals</dt><dd><p>the percentage of students eligible for subsidized meals stored in a 4 balanced levels factor (By quartiles): <code>[0-25]</code>, <code>(25-50]</code>, <code>(50-75]</code>, <code>(75-100]</code></p>
</dd>
<dt>full</dt><dd><p>the percentage of fully qualified teachers stored in a 2-levels factor: <code>1</code>: For strictly less than 90%, <code>2</code> otherwise</p>
</dd>
</dl>



<h3>Source</h3>

<p>This database is a sample of the data <code><a href="survey.html#topic+api">api</a></code> from the package <span class="pkg">survey</span>.
</p>

<hr>
<h2 id='avg_dist_closest'>avg_dist_closest()</h2><span id='topic+avg_dist_closest'></span>

<h3>Description</h3>

<p>This function computes average distances between levels of two categorical variables located in two distinct databases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avg_dist_closest(proxim, percent_closest = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="avg_dist_closest_+3A_proxim">proxim</code></td>
<td>
<p>a <code>proxim_dist</code> object</p>
</td></tr>
<tr><td><code id="avg_dist_closest_+3A_percent_closest">percent_closest</code></td>
<td>
<p>a ratio between 0 and 1 corresponding to the desired part of rows (or statistical units, or individuals) that will participate to the computation of the average distances between levels of factors or
between an individual (a row) and levels of only one factor. Indeed, target variables are factors and each level of factor is characterized by a subset of rows, themselves characterized by their covariate profiles.
These rows can be ordered according to their distances at their factor level. When this ratio is set to 1 (default setting), all rows participate to the computation, nevertheless when this ratio is less than 1, only rows with
the smallest factor level distances will be kept for the computation (see 'Details').</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>avg_dist_closest</code> is an intermediate function for the implementation of original algorithms dedicated to the solving of recoding problems in data fusion using Optimal Transportation theory (for more details, consult the corresponding algorithms called
<code>OUTCOME</code>, <code>R_OUTCOME</code>, <code>JOINT</code> and <code>R_JOINT</code>, in the reference (2)). The function <code>avg_dist_closest</code> is so directly implemented in the <code>OT_outcome</code> and <code>OT_joint</code> functions but can also be used separately.
The function <code>avg_dist_closest</code> uses, in particular, the distance matrix D (that stores distances between rows of A and B) from the function <code><a href="#topic+proxim_dist">proxim_dist</a></code> to produce three distinct matrices saved in a list object.
Therefore, the function requires in input, the specific output of the function <code><a href="#topic+proxim_dist">proxim_dist</a></code> which is available in the package and so must be used beforehand.
In consequence, do not use this function directly on your database, and do not hesitate to consult the provided examples provided for a better understanding.
</p>
<p>DEFINITION OF THE COST MATRIX
</p>
<p>Assuming that A and B are two databases with a set of shared variables and that a same information (referred to a same target population) is stored as a variable <code class="reqn">Y</code> in A and <code class="reqn">Z</code> in B, such that <code class="reqn">Y</code> is unknown in B and <code class="reqn">Z</code> is unknown in A, whose encoding depends on the database (<code class="reqn">n_Y</code> levels in A and <code class="reqn">n_Z</code> levels in B).
A distance between one given level y of <code class="reqn">Y</code> and one given level z of <code class="reqn">Z</code> is estimated by averaging the distances between the two subsets of individuals (units or rows) assigned to y in A and z in B, characterized by their vectors of covariates.
The distance between two individuals depends on the variations between the shared covariates, and so depends on the chosen distance function using the function <code>proxim_dist</code>.
For these computations, all the individuals concerned by these two levels can be taken into account, or only a part of them, depending on the argument <code>percent_closest</code>.
When <code>percent_closest</code> &lt; 1, the average distance between an individual <code class="reqn">i</code> and a given level of factor z only uses the corresponding part of individuals related to z that are the closest to <code class="reqn">i</code>.
Therefore, this choice influences the estimations of average distances between levels of factors but also permits to reduce time computation when necessary.
</p>
<p>The average distance between each individual of <code class="reqn">Y</code> (resp. <code class="reqn">Z</code>) and each levels of <code class="reqn">Z</code> (resp. <code class="reqn">Y</code>) are returned in output, in the object <code>DindivA</code> (<code>DindivB</code> respectively).
The average distance between each levels of <code class="reqn">Y</code> and each levels of <code class="reqn">Z</code> are returned in a matrix saved in output (the object <code>Davg</code>).
<code>Davg</code> returns the computation of the cost matrix D, whose dimensions (<code class="reqn">n_Y \times n_Z</code>) correspond to the number of levels of <code class="reqn">Y</code> (rows) and <code class="reqn">Z</code> (columns).
This matrix can be seen as the ability for an individual (row) to move from a given level of the target variable (<code class="reqn">Y</code>) in A to a given level of <code class="reqn">Z</code> in the database B (or vice versa).
</p>


<h3>Value</h3>

<p>A list of 3 matrices is returned:
</p>
<table>
<tr><td><code>Davg</code></td>
<td>
<p>the cost matrix whose number of rows corresponds to <code class="reqn">n_Y</code>, the number of levels of the target variable <code class="reqn">Y</code> in the database A, and whose number of columns corresponds to <code class="reqn">n_Z</code>: the number of levels of the target variable in B.
In this case, the related cost matrix can be interpreted as the ability to move from one level of <code class="reqn">Y</code> in A to one level of <code class="reqn">Z</code> in B.
Davg[P,Q] refers to the average distance between the modality P of <code class="reqn">Y</code> (only known in A) and modality <code class="reqn">Q</code> of <code class="reqn">Z</code> (only known in B).</p>
</td></tr>
<tr><td><code>DindivA</code></td>
<td>
<p>a matrix whose number of rows corresponds to the number of rows of the first database A and number of columns corresponds to <code class="reqn">n_Z</code>, the number of levels of the target variable <code class="reqn">Z</code> in the second database B.
DindivA[i,Q] refers to the average distance between the <code class="reqn">i^{th}</code> individual (or row) of the first database and a chosen proportion of individuals (<code>percent_closest</code> set by the user) of the second database having the modality <code class="reqn">Q</code> of <code class="reqn">Z</code>.</p>
</td></tr>
<tr><td><code>DindivB</code></td>
<td>
<p>a matrix whose number of rows corresponds to the number of rows of the second database B and number of columns corresponds to nA, the number of levels of the target variable in the first database A.
DindivB[k,P] refers to the average distance between the <code class="reqn">k^{th}</code> individual (or row) of the second database and a chosen proportion of individuals (depending on <code>percent_closest</code>) of the first database having the modality P of <code class="reqn">Y</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec, Valerie Gares, Jeremy Omer
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+proxim_dist">proxim_dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(simu_data)
### The covariates of the data are prepared according to the distance chosen
### using the transfo_dist function

### Example with The Manhattan distance

man1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "M"
)
mat_man1 &lt;- proxim_dist(man1, norm = "M")

# proxim_dist() fixes the chosen distance function,
# and defines neighborhoods between profiles and individuals

# The following row uses only 80 percents of individuals of each level
# of factors for the computation of the average distances:

neig_man1 &lt;- avg_dist_closest(mat_man1, percent_closest = 0.80)

</code></pre>

<hr>
<h2 id='compare_lists'>compare_lists()</h2><span id='topic+compare_lists'></span>

<h3>Description</h3>

<p>This function compares the elements of two lists of same length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_lists(listA, listB)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_lists_+3A_lista">listA</code></td>
<td>
<p>a first list</p>
</td></tr>
<tr><td><code id="compare_lists_+3A_listb">listB</code></td>
<td>
<p>a second list</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boolean vector of same length as the two lists,
which ith element is <code>TRUE</code> if the ith element is different
between the 2 lists, or <code>FALSE</code> otherwise
</p>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data1 &lt;- data.frame(Gender = rep(c("m", "f"), 5), Age = rnorm(5, 20, 4))
data2 &lt;- data.frame(Gender = rep(c("m", "f"), 5), Age = rnorm(5, 21, 5))

list1 &lt;- list(A = 1:4, B = as.factor(c("A", "B", "C")), C = matrix(1:6, ncol = 3))
list2 &lt;- list(A = 1:4, B = as.factor(c("A", "B")), C = matrix(1:6, ncol = 3))
list3 &lt;- list(A = 1:4, B = as.factor(c("A", "B", "C")), C = matrix(c(1:5, 7), ncol = 3))
list4 &lt;- list(A = 1:4, B = as.factor(c("A", "B", "C")), C = matrix(1:6, ncol = 2))
list5 &lt;- list(A = 1:4, B = as.factor(c("A", "B")), C = matrix(1:6, ncol = 2))
list6 &lt;- list(A = 1:4, B = as.factor(c("A", "B")), C = data1)
list7 &lt;- list(A = 1:4, B = as.factor(c("A", "B")), C = data2)

OTrecod::compare_lists(list1, list2)
OTrecod::compare_lists(list1, list3)
OTrecod::compare_lists(list1, list4)
OTrecod::compare_lists(list1, list5)
OTrecod::compare_lists(list6, list7)

</code></pre>

<hr>
<h2 id='error_group'>error_group()</h2><span id='topic+error_group'></span>

<h3>Description</h3>

<p>This function studies the association between two categorical distributions with different numbers of modalities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>error_group(REF, Z, ord = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="error_group_+3A_ref">REF</code></td>
<td>
<p>a factor with a reference number of levels.</p>
</td></tr>
<tr><td><code id="error_group_+3A_z">Z</code></td>
<td>
<p>a factor with a number of levels greater than the number of levels of the reference.</p>
</td></tr>
<tr><td><code id="error_group_+3A_ord">ord</code></td>
<td>
<p>a boolean. If TRUE, only neighboring levels of <code class="reqn">Z</code> will be grouped and tested together.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assuming that <code class="reqn">Y</code> and <code class="reqn">Z</code> are categorical variables summarizing a same information, and that one of the two related encodings is unknown by user
because this latter is, for example, the result of predictions provided by a given model or algorithm, the function <code>error_group</code> searches for potential links between the modalities of <code class="reqn">Y</code> to approach at best the distribution of <code class="reqn">Z</code>.
</p>
<p>Assuming that <code class="reqn">Y</code> and <code class="reqn">Z</code> have <code class="reqn">n_Y</code> and <code class="reqn">n_Z</code> modalities respectively so that <code class="reqn">n_Y &gt; n_Z</code>, in a first step, the
function <code>error_group</code> combines modalities of <code class="reqn">Y</code> to build all possible variables <code class="reqn">Y'</code> verifying  <code class="reqn">n_{Y'} = n_Z</code>.
In a second step, the association between <code class="reqn">Z</code> and each new variable <code class="reqn">Y'</code> generated is measured by studying the ratio of concordant pairs related to the confusion matrix but also using standard criterions:
the Cramer's V (1), the Cohen's kappa coefficient (2) and the Spearman's rank correlation coefficient.
</p>
<p>According to the type of <code class="reqn">Y</code>, different combinations of modalities are tested:
</p>

<ul>
<li><p> If <code class="reqn">Y</code> and <code class="reqn">Z</code> are ordinal (<code>ord = TRUE</code>), only consecutive modalities of <code class="reqn">Y</code> will be grouped to build the variables <code class="reqn">Y'</code>.
</p>
</li>
<li><p> If <code class="reqn">Y</code> and <code class="reqn">Z</code> are nominal (<code>ord = FALSE</code>), all combinations of modalities of <code class="reqn">Y</code> (consecutive or not) will be grouped to build the variables <code class="reqn">Y'</code>.
</p>
</li></ul>

<p>All the associations tested are listed in output as a data.frame object.
The function <code>error_group</code> is directly integrated in the function <code><a href="#topic+verif_OT">verif_OT</a></code> to evaluate the proximity of two multinomial distributions, when one of them is estimated from the predictions of an OT algorithm.
</p>
<p>Example:
Assuming that <code class="reqn">Y = (1,1,2,2,3,3,4,4)</code> and <code class="reqn">Z = (1,1,1,1,2,2,2,2)</code>, so <code class="reqn">n_Y = 4</code> and <code class="reqn">n_Z = 2</code> and the related coefficient of correlation <code class="reqn">cor(Y,Z)</code> is 0.89.
Are there groupings of modalities of <code class="reqn">Y</code> which contribute to improving the proximity between <code class="reqn">Y</code> and <code class="reqn">Z</code> ?
From <code class="reqn">Y</code>, the function <code>error_group</code> gives an answer to this question by successively constructing the variables: <code class="reqn">Y_1 = (1,1,1,1,2,2,2,2)</code>, <code class="reqn">Y_2 = (1,1,2,2,1,1,2,2)</code>, <code class="reqn">Y_3 = (1,1,2,2,2,2,1,1)</code>
and tests <code class="reqn">\mbox{cor}(Z,Y_1) = 1</code>, <code class="reqn">\mbox{cor}(Z,Y_2) = 0</code>, <code class="reqn">\mbox{cor}(Z,Y_3) = 0</code>.
Here, the tests permit to conclude that the difference of encodings between <code class="reqn">Y</code> and <code class="reqn">Z</code> resulted in fact in a simple grouping of modalities.
</p>


<h3>Value</h3>

<p>A data.frame with five columns:
</p>
<table>
<tr><td><code>combi</code></td>
<td>
<p>the first column enumerates all possible groups of modalities of <code class="reqn">Y</code> to obtain the same number of levels as the reference.</p>
</td></tr>
<tr><td><code>error_rate</code></td>
<td>
<p>the second column gives the corresponding rate error from the confusion matrix (ratio of non-diagonal elements)</p>
</td></tr>
<tr><td><code>Kappa</code></td>
<td>
<p>this column indicates the result of the Cohen's kappa coefficient related to each combination of <code class="reqn">Y</code></p>
</td></tr>
<tr><td><code>Vcramer</code></td>
<td>
<p>this column indicates the result of the Cramer's V criterion related to each combination of <code class="reqn">Y</code></p>
</td></tr>
<tr><td><code>RankCor</code></td>
<td>
<p>this column indicates the result of the Spearman's coefficient of correlation related to each combination of <code class="reqn">Y</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Cramér, Harald. (1946). Mathematical Methods of Statistics. Princeton: Princeton University Press.
</p>
</li>
<li><p> McHugh, Mary L. (2012). Interrater reliability: The kappa statistic. Biochemia Medica. 22 (3): 276–282
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'>
# Basic examples:
sample1 &lt;- as.factor(sample(1:3, 50, replace = TRUE))
length(sample1)
sample2 &lt;- as.factor(sample(1:2, 50, replace = TRUE))
length(sample2)
sample3 &lt;- as.factor(sample(c("A", "B", "C", "D"), 50, replace = TRUE))
length(sample3)
sample4 &lt;- as.factor(sample(c("A", "B", "C", "D", "E"), 50, replace = TRUE))
length(sample4)

# By only grouping consecutive levels of sample1:
error_group(sample1, sample4)
# By only all possible levels of sample1, consecutive or not:
error_group(sample2, sample1, ord = FALSE)



### using a sample of the tab_test object (3 complete covariates)
### Y1 and Y2 are a same variable encoded in 2 different forms in DB 1 and 2:
### (4 levels for Y1 and 3 levels for Y2)

data(tab_test)
# Example with n1 = n2 = 70 and only X1 and X2 as covariates
tab_test2 &lt;- tab_test[c(1:70, 5001:5070), 1:5]

### An example of JOINT model (Manhattan distance)
# Suppose we want to impute the missing parts of Y1 in DB2 only ...
try1J &lt;- OT_joint(tab_test2,
  nominal = c(1, 4:5), ordinal = c(2, 3),
  dist.choice = "M", which.DB = "B"
)

# Error rates between Y2 and the predictions of Y1 in the DB 2
# by grouping the levels of Y1:
error_group(try1J$DATA2_OT$Z, try1J$DATA2_OT$OTpred)
table(try1J$DATA2_OT$Z, try1J$DATA2_OT$OTpred)


</code></pre>

<hr>
<h2 id='ham'>ham()</h2><span id='topic+ham'></span>

<h3>Description</h3>

<p>This function computes a matrix distance using the Hamming distance as proximity measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ham(mat_1, mat_2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ham_+3A_mat_1">mat_1</code></td>
<td>
<p>a vector, a matrix or a data.frame of binary values that may contain missing data</p>
</td></tr>
<tr><td><code id="ham_+3A_mat_2">mat_2</code></td>
<td>
<p>a vector, a matrix or a data.frame of binary values with the same number of columns as <code>mat_1</code> that may contain missing data</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ham</code> returns the pairwise distances between rows (observations) of a single matrix if <code>mat_1</code> equals <code>mat_2</code>.
Otherwise <code>ham</code> returns the matrix distance between rows of the two matrices <code>mat_1</code> and <code>mat_2</code> if this 2 matrices are different in input.
Computing the Hamming distance stays possible despite the presence of missing data by applying the following formula. Assuming that A and B are 2 matrices such as <code>ncol(A) = ncol(B)</code>.
The Hamming distance between the <code class="reqn">i^{th}</code> row of A and the <code class="reqn">k^{th}</code> row of B equals:
</p>
<p style="text-align: center;"><code class="reqn">\mbox{ham}(A_i,B_k) = \frac{\sum_j 1_{\left\{A_{ij} \neq B_{kj}\right\}}}{\sum_j 1}\times\left(\frac{\sum_j 1}{\sum_j 1_{\left\{!\mbox{is.na}(A_{ij}) \&amp; !\mbox{is.na}( B_{kj})\right\}}}\right)</code>
</p>

<p>where: <code class="reqn">i = 1,\dots,\mbox{nrow}(A)</code> and  <code class="reqn">k = 1,\dots,\mbox{nrow}(B)</code>; And the expression located to the right term of the multiplication corresponds to a specific weigh applied in presence of NAs in <code class="reqn">A_i</code> and/or <code class="reqn">B_k</code>.
</p>
<p>This specificity is not implemented in the <code>cdist</code> function and the Hamming distance can not be computed using the <code><a href="proxy.html#topic+dist">dist</a></code> function either.
</p>
<p>The Hamming distance can not be calculated in only two situations:
</p>

<ol>
<li><p> If a row of A or B has only missing values (ie for each of the columns of A or B respectively).
</p>
</li>
<li><p> The union of the indexes of the missing values in row i of A with the indexes of the missing values in row j of B concerns the indexes of all considered columns.
</p>
</li></ol>

<p>Example: Assuming that <code class="reqn">\mbox{ncol}(A) = \mbox{ncol}(B) = 3</code>, if <code class="reqn">A_i = (1,\mbox{NA},0)</code> and <code class="reqn">B_j = (\mbox{NA},1,\mbox{NA})</code>, for each column, either the information in row i is missing in A,
or the information is missing in B, which induces: <code class="reqn">\mbox{ham}(A_i,B_k) = \mbox{NA}</code>.
</p>
<p>If <code>mat_1</code> is a vector and <code>mat_2</code> is a matrix (or data.frame) or vice versa, the length of <code>mat_1</code> must be equal to the number of columns of <code>mat_2</code>.
</p>


<h3>Value</h3>

<p>A distance matrix
</p>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>

<p>Roth R (2006). Introduction to Coding Theory. Cambridge University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(3010)
sample_A &lt;- sample(c(0, 1), 12, replace = TRUE)
set.seed(3007)
sample_B &lt;- sample(c(0, 1), 15, replace = TRUE)
A &lt;- matrix(sample_A, ncol = 3)
B &lt;- matrix(sample_B, ncol = 3)

# These 2 matrices have no missing values

# Matrix of pairwise distances with A:
ham(A, A)

# Matrix of distances between the rows of A and the rows of B:
ham(A, B)

# If mat_1 is a vector of binary values:
ham(c(0, 1, 0), B)

# Now by considering A_NA and B_NA two matrices built from A and B respectively,
# where missing values have been manually added:
A_NA &lt;- A
A_NA[3, 1] &lt;- NA
A_NA[2, 2:3] &lt;- rep(NA, 2)

B_NA &lt;- B
B_NA[2, 2] &lt;- NA

ham(A_NA, B_NA)

</code></pre>

<hr>
<h2 id='imput_cov'>imput_cov()</h2><span id='topic+imput_cov'></span>

<h3>Description</h3>

<p>This function performs imputations on incomplete covariates, whatever their types, using functions from the package <span class="pkg">MICE</span> (Van Buuren's Multiple Imputation) or functions from the package <span class="pkg">missMDA</span> (Simple Imputation with Multivariate data analysis).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imput_cov(
  dat1,
  indcol = 1:ncol(dat1),
  R_mice = 5,
  meth = rep("pmm", ncol(dat1)),
  missMDA = FALSE,
  NB_COMP = 3,
  seed_choice = sample(1:1e+06, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imput_cov_+3A_dat1">dat1</code></td>
<td>
<p>a data.frame containing the variables to be imputed and those involved in the imputations</p>
</td></tr>
<tr><td><code id="imput_cov_+3A_indcol">indcol</code></td>
<td>
<p>a vector of integers. The corresponding column indexes (or numbers) corresponding to the variables to be imputed and those involved in the imputations.</p>
</td></tr>
<tr><td><code id="imput_cov_+3A_r_mice">R_mice</code></td>
<td>
<p>an integer. The number of imputed database generated with MICE method (5 by default).</p>
</td></tr>
<tr><td><code id="imput_cov_+3A_meth">meth</code></td>
<td>
<p>a vector of characters which specifies the imputation method to be used for each column in <code>dat1</code>.
&quot;pmm&quot; for continuous covariates or by default option, &quot;logreg&quot; for binary covariates, &quot;polr&quot; for ordinal covariates, &quot;polyreg&quot; for categorical covariates (no order), (cf <code><a href="mice.html#topic+mice">mice</a></code> for more details).</p>
</td></tr>
<tr><td><code id="imput_cov_+3A_missmda">missMDA</code></td>
<td>
<p>a boolean. If <code>TRUE</code>, missing values are imputed using the factoral analysis for mixed data (<code><a href="missMDA.html#topic+imputeFAMD">imputeFAMD</a></code>) from the <span class="pkg">missMDA</span> package (2).</p>
</td></tr>
<tr><td><code id="imput_cov_+3A_nb_comp">NB_COMP</code></td>
<td>
<p>an integer corresponding to the number of components used in FAMD to predict the missing entries (3 by default) when the <code>missMDA</code> option is TRUE.</p>
</td></tr>
<tr><td><code id="imput_cov_+3A_seed_choice">seed_choice</code></td>
<td>
<p>an integer used as argument by the set.seed() for offsetting the random number generator (Random integer by default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, the function <code>impute_cov</code> handles missing information using multivariate imputation by chained equations (MICE, see (1) for more details about the method) by integrating in its syntax the function <code><a href="mice.html#topic+mice">mice</a></code>.
All values of this last function are taken by default, excepted the required number of multiple imputations, which can be fixed by using the argument <code>R_mice</code>, and the chosen imputation method for each variable (<code>meth</code> argument),
that corresponds to the argument <code>defaultMethod</code> of the function <code><a href="mice.html#topic+mice">mice</a></code>.
When multiple imputations are required (for MICE only), each missing information is imputed by a consensus value:
the average of the candidate values will be retained for numerical variables, while the most frequent class will be remained for categorical variables (ordinal or not).
The output <code>MICE_IMPS</code> stores the imputed databases to allow users to build their own consensus values by themselves and(or) to eventually assess the variabilities related to the proposed imputed values if necessary.
For this method, a random number generator must be fixed or sampled using the argument <code>seed_choice</code>.
</p>
<p>When the argument <code>missMDA</code> is equalled to <code>TRUE</code>, incomplete values are replaced (single imputation) using a method based on dimensionality reduction called factor analysis for mixed data (FAMD) using the the <code><a href="missMDA.html#topic+imputeFAMD">imputeFAMD</a></code> function of the <span class="pkg">missMDA</span> package (2).
Using this approach, the function <code>imput_cov</code> keeps all the default values integrated in the function <code>imputeFAMD</code> excepted the number of dimensions used for FAMD which can be fixed by users (3 by default).
</p>


<h3>Value</h3>

<p>A list of 3 or 4 objects (depending on the missMDA argument). The first three following objects if <code>missMDA</code> = TRUE, otherwise 4 objects are returned:
</p>
<table>
<tr><td><code>RAW</code></td>
<td>
<p>a data.frame corresponding to the raw database</p>
</td></tr>
<tr><td><code>IMPUTE</code></td>
<td>
<p>a character indicating the type of selected imputation</p>
</td></tr>
<tr><td><code>DATA_IMPUTE</code></td>
<td>
<p>a data.frame corresponding to the completed (consensus if multiple imputations) database</p>
</td></tr>
<tr><td><code>MICE_IMPS</code></td>
<td>
<p>only if missMDA = FALSE. A list object containing the R imputed databases generated by MICE</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> van Buuren, S., Groothuis-Oudshoorn, K. (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1–67. urlhttps://www.jstatsoft.org/v45/i03/
</p>
</li>
<li><p> Josse J, Husson F (2016). missMDA: A Package for Handling Missing Values in Multivariate Data Analysis. Journal of Statistical Software, 70(1), 1–31. doi: <a href="https://doi.org/10.18637/jss.v070.i01">10.18637/jss.v070.i01</a>
</p>
</li></ol>



<h3>Examples</h3>

<pre><code class='language-R'># Imputation of all incomplete covariates in the table simu_data:
data(simu_data)

# Here we keep the complete variable "Gender" in the imputation model.
# Using MICE (REP = 3):
imput_mice &lt;- imput_cov(simu_data,
  indcol = 4:8, R_mice = 3,
  meth = c("logreg", "polyreg", "polr", "logreg", "pmm")
)
summary(imput_mice)


# Using FAMD (NB_COMP = 3):
imput_famd &lt;- imput_cov(simu_data,
  indcol = 4:8,
  meth = c("logreg", "polyreg", "polr", "logreg", "pmm"),
  missMDA = TRUE
)
summary(imput_famd)

</code></pre>

<hr>
<h2 id='indiv_grp_closest'>indiv_grp_closest()</h2><span id='topic+indiv_grp_closest'></span>

<h3>Description</h3>

<p>This function sequentially assigns individual predictions using a nearest neighbors procedure to solve recoding problems of data fusion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indiv_grp_closest(
  proxim,
  jointprobaA = NULL,
  jointprobaB = NULL,
  percent_closest = 1,
  which.DB = "BOTH"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indiv_grp_closest_+3A_proxim">proxim</code></td>
<td>
<p>a <code><a href="#topic+proxim_dist">proxim_dist</a></code> object or an object of similar structure</p>
</td></tr>
<tr><td><code id="indiv_grp_closest_+3A_jointprobaa">jointprobaA</code></td>
<td>
<p>a matrix whose number of columns corresponds to the number of modalities of the target variable <code class="reqn">Y</code> in database A, and which number of rows corresponds to the number of modalities of Z in database B. It gives an estimation of the joint probability of <code class="reqn">(Y,Z)</code> in A.
The sum of cells of this matrix must be equal to 1</p>
</td></tr>
<tr><td><code id="indiv_grp_closest_+3A_jointprobab">jointprobaB</code></td>
<td>
<p>a matrix whose number of columns equals to the number of modalities of the target variable <code class="reqn">Y</code> in database A, and which number of rows corresponds to the number of modalities of <code class="reqn">Z</code> in database B. It gives an estimation of the joint probability of <code class="reqn">(Y,Z)</code> in B.
The sum of cells of this matrix must be equal to 1</p>
</td></tr>
<tr><td><code id="indiv_grp_closest_+3A_percent_closest">percent_closest</code></td>
<td>
<p>a value between 0 and 1 (by default) corresponding to the fixed <code>percent closest</code> of individuals remained in the computation of the average distances</p>
</td></tr>
<tr><td><code id="indiv_grp_closest_+3A_which.db">which.DB</code></td>
<td>
<p>a character string (with quotes) that indicates which individual predictions need to be computed: only the individual predictions of <code class="reqn">Y</code> in B (&quot;B&quot;), only those of <code class="reqn">Z</code> in A (&quot;A&quot;) or the both (&quot;BOTH&quot; by default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A. THE RECODING PROBLEM IN DATA FUSION
</p>
<p>Assuming that <code class="reqn">Y</code> and <code class="reqn">Z</code> are two variables which refered to the same target population in two separate databases A and B respectively (no overlapping rows),
so that <code class="reqn">Y</code> and <code class="reqn">Z</code> are never jointly observed. Assuming also that A and B share a subset of common covariates <code class="reqn">X</code> of any types (same encodings in A and B)
completed or not. Integrating these two databases often requires to solve the recoding problem by creating an unique database where
the missing information of <code class="reqn">Y</code> and <code class="reqn">Z</code> is fully completed.
</p>
<p>B. DESCRIPTION OF THE FUNCTION
</p>
<p>The function <code>indiv_grp_closest</code> is an intermediate function used in the implementation of an algorithm called OUTCOME (and its enrichment R-OUTCOME, see the reference (2) for more details) dedicated to the solving of recoding problems in data fusion using Optimal Transportation theory.
The model is implemented in the function <code><a href="#topic+OT_outcome">OT_outcome</a></code> which integrates the function <code>indiv_grp_closest</code> in its syntax as a possible second step of the algorithm.
The function <code>indiv_grp_closest</code> can also be used separately provided that the argument <code>proxim</code> receives an output object of the function <code><a href="#topic+proxim_dist">proxim_dist</a></code>.
This latter is available in the package and is so directly usable beforehand.
</p>
<p>The algorithms <code>OUTCOME</code> (and <code>R-OUTCOME</code>) are made of two independent parts. Assuming that the objective consists in the prediction of <code class="reqn">Z</code> in the database A:
</p>

<ul>
<li><p> The first part of the algorithm solves the optimization problem by providing a solution called <code class="reqn">\gamma</code> that corresponds here to an estimation of the joint distribution <code class="reqn">(Y,Z)</code> in A.
</p>
</li>
<li><p> From the first part, a nearest neighbor procedure is carried out as a second part to provide the individual predictions of <code class="reqn">Z</code> in A: this procedure is implemented in the function <code>indiv_group_closest</code>.
In other words, this function sequentially assigns to each individual of A the modality of <code class="reqn">Z</code> that is closest.
</p>
</li></ul>

<p>Obviously, this algorithm  runs in the same way for the prediction of <code class="reqn">Y</code> in the database B.
The function <code>indiv_grp_closest</code> integrates in its syntax the function <code><a href="#topic+avg_dist_closest">avg_dist_closest</a></code>. Therefore, the related argument <code>percent_closest</code> is identical in the two functions.
Thus, when computing average distances between an individual <code class="reqn">i</code> and a subset of individuals assigned to a same level of <code class="reqn">Y</code> or <code class="reqn">Z</code> is required, user can decide if all individuals from the subset of interest can participate to the computation (<code>percent_closest</code>=1) or only a fixed part p (&lt;1) corresponding to the closest neighbors of <code class="reqn">i</code> (in this case <code>percent_closest</code> = p).
</p>
<p>The arguments <code>jointprobaA</code> and <code>jointprobaB</code> correspond to the estimations of <code class="reqn">\gamma</code> (sum of cells must be equal to 1) in A and/or B respectively, according to the <code>which.DB</code> argument.
For example, assuming that <code class="reqn">n_{Y_1}</code> individuals are assigned to the first modality of <code class="reqn">Y</code> in A, the objective consists in the individual predictions of <code class="reqn">Z</code> in A. Then, if <code>jointprobaA</code>[1,2] = 0.10,
the maximum number of individuals that can be assigned to the second modality of <code class="reqn">Z</code> in A, can not exceed <code class="reqn">0.10 \times n_A</code>.
If <code class="reqn">n_{Y_1} \leq 0.10 \times n_A</code> then all individuals assigned to the first modality of <code class="reqn">Y</code> will be assigned to the second modality of <code class="reqn">Z</code>.
At the end of the process, each individual with still no affectation  will receive the same modality of <code class="reqn">Z</code> as those of his nearest neighbor in B.
</p>


<h3>Value</h3>

<p>A list of two vectors of numeric values:
</p>
<table>
<tr><td><code>YAtrans</code></td>
<td>
<p>a vector corresponding to the individual predictions of <code class="reqn">Y</code> (numeric form) in the database B using the Optimal Transportation algorithm</p>
</td></tr>
<tr><td><code>ZBtrans</code></td>
<td>
<p>a vector corresponding to the individual predictions of <code class="reqn">Z</code> (numeric form) in  the database A using the Optimal Transportation algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec, Valerie Gares, Jeremy Omer
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+proxim_dist">proxim_dist</a></code>,<code><a href="#topic+avg_dist_closest">avg_dist_closest</a></code>, ,<code><a href="#topic+OT_outcome">OT_outcome</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(simu_data)

### Example with the Manhattan distance

man1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "M"
)
mat_man1 &lt;- proxim_dist(man1, norm = "M")

### Y(Yb1) and Z(Yb2) are a same information encoded in 2 different forms:
### (3 levels for Y and 5 levels for Z)
### ... Stored in two distinct databases, A and B, respectively
### The marginal distribution of Y in B is unknown,
### as the marginal distribution of Z in A ...

# Empirical distribution of Y in database A:
freqY &lt;- prop.table(table(man1$Y))
freqY

# Empirical distribution of Z in database B
freqZ &lt;- prop.table(table(man1$Z))
freqZ

# By supposing that the following matrix called transport symbolizes
# an estimation of the joint distribution L(Y,Z) ...
# Note that, in reality this distribution is UNKNOWN and is
# estimated in the OT function by resolving an optimisation problem.


transport1 &lt;- matrix(c(0.3625, 0, 0, 0.07083333, 0.05666667,
                      0, 0, 0.0875, 0, 0, 0.1075, 0,
                      0, 0.17166667, 0.1433333),
                     ncol = 5, byrow = FALSE)

# ... So that the marginal distributions of this object corresponds to freqY and freqZ:
apply(transport1, 1, sum) # = freqY
apply(transport1, 2, sum) # = freqZ

# The affectation of the predicted values of Y in database B and Z in database A
# are stored in the following object:

pred_man1 &lt;- indiv_grp_closest(mat_man1,
  jointprobaA = transport1, jointprobaB = transport1,
  percent_closest = 0.90
)
summary(pred_man1)

# For the prediction of Z in A only, add the corresponding argument:
pred_man1_A &lt;- indiv_grp_closest(mat_man1,
  jointprobaA = transport1, jointprobaB = transport1,
  percent_closest = 0.90, which.DB = "A"
)

</code></pre>

<hr>
<h2 id='indiv_grp_optimal'>indiv_grp_optimal()</h2><span id='topic+indiv_grp_optimal'></span>

<h3>Description</h3>

<p>This function assigns individual predictions to the incomplete information of two integrated datasources by solving a linear optimization problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indiv_grp_optimal(
  proxim,
  jointprobaA,
  jointprobaB,
  percent_closest = 1,
  solvr = "glpk",
  which.DB = "BOTH"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="indiv_grp_optimal_+3A_proxim">proxim</code></td>
<td>
<p>a <code><a href="#topic+proxim_dist">proxim_dist</a></code> object or an object of similar structure</p>
</td></tr>
<tr><td><code id="indiv_grp_optimal_+3A_jointprobaa">jointprobaA</code></td>
<td>
<p>a matrix whose number of columns is equal to the number of modalities of the target variable <code class="reqn">Y</code> in database A, and whose number of rows is equal to the number of modalities of <code class="reqn">Z</code> in database B. It gives an estimation of the joint probability <code class="reqn">(Y,Z)</code> in the database A.
The sum of cells of this matrix must be equal to 1.</p>
</td></tr>
<tr><td><code id="indiv_grp_optimal_+3A_jointprobab">jointprobaB</code></td>
<td>
<p>a matrix whose number of columns is equal to the number of modalities of the target variable Y in database A, and whose number of rows is equal to the number of modalities of <code class="reqn">Z</code> in database B. It gives an estimation of the joint probability <code class="reqn">(Y,Z)</code> in the database B.
The sum of cells of this matrix must be equal to 1.</p>
</td></tr>
<tr><td><code id="indiv_grp_optimal_+3A_percent_closest">percent_closest</code></td>
<td>
<p>a value between 0 and 1 (by default) corresponding to the fixed <code>percent closest</code> of individuals used in the computation of the average distances</p>
</td></tr>
<tr><td><code id="indiv_grp_optimal_+3A_solvr">solvr</code></td>
<td>
<p>a character string that specifies the type of method selected to solve the optimization algorithms. The default solver is &quot;glpk&quot;.</p>
</td></tr>
<tr><td><code id="indiv_grp_optimal_+3A_which.db">which.DB</code></td>
<td>
<p>a character string that indicates which individual predictions are computed: only the individual predictions of <code class="reqn">Y</code> in B (&quot;B&quot;), only those of <code class="reqn">Z</code> in A (&quot;A&quot;) or the both (&quot;BOTH&quot; by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A. THE RECODING PROBLEM IN DATA FUSION
</p>
<p>Assuming that <code class="reqn">Y</code> and <code class="reqn">Z</code> are two target variables which refered to the same target population in two separate databases A and B respectively (no overlapping rows),
so that <code class="reqn">Y</code> and <code class="reqn">Z</code> are never jointly observed. Assuming also that A and B share a subset of common covariates <code class="reqn">X</code> of any types (same encodings in A and B)
completed or not. Merging these two databases often requires to solve a recoding problem by creating an unique database where
the missing information of <code class="reqn">Y</code> and <code class="reqn">Z</code> is fully completed.
</p>
<p>B. DESCRIPTION OF THE FUNCTION
</p>
<p>The function <code>indiv_grp_optimal</code> is an intermediate function used in the implementation of an algorithm called <code>OUTCOME</code> (and its enrichment <code>R-OUTCOME</code> (2)) dedicated to the solving of recoding problems in data fusion using Optimal Transportation theory.
The model is implemented in the function <code><a href="#topic+OT_outcome">OT_outcome</a></code> which integrates the function <code>indiv_grp_optimal</code> in its syntax as a possible second step of the algorithm.
The function <code>indiv_grp_optimal</code> can nevertheless be used separately providing that the argument <code>proxim</code> receives an output object of the function <code><a href="#topic+proxim_dist">proxim_dist</a></code>.
This latter is available in the package and is so directly usable beforehand.
</p>
<p>The function <code>indiv_grp_optimal</code> constitutes an alternative method to the nearest neighbor procedure implemented in the function <code><a href="#topic+indiv_grp_closest">indiv_grp_closest</a></code>.
As for the function <code><a href="#topic+indiv_grp_closest">indiv_grp_closest</a></code>, assuming that the objective consists in the prediction of <code class="reqn">Z</code> in the database A, the first step of the algorithm related to <code>OUTCOME</code> provides an estimate of <code class="reqn">\gamma</code>, the solution of the optimization problem, which can be seen, in this case as an estimation of the joint distribution <code class="reqn">(Y,Z)</code> in A.
Rather than using a nearest neighbor approach to provide individual predictions, the function <code>indiv_grp_optimal</code> solves an optimization problem using the simplex algorithm which searches for the individual predictions of <code class="reqn">Z</code> that minimize the computed total distance satisfying the joint probability distribution estimated in the first part.
More details about the theory related to the solving of this optimization problem is described in the section 5.3 of (2).
</p>
<p>Obviously, this algorithm  runs in the same way for the prediction of <code class="reqn">Y</code> in the database B.
The function <code>indiv_grp_optimal</code> integrates in its syntax the function <code><a href="#topic+avg_dist_closest">avg_dist_closest</a></code> and the related argument <code>percent_closest</code> is identical in the two functions.
Thus, when computing average distances between an individual i and a subset of individuals assigned to a same level of <code class="reqn">Y</code> or <code class="reqn">Z</code> is required, user can decide if all individuals from the subset of interest can participate to the computation (<code>percent_closest = 1</code>) or only a fixed part p (&lt;1) corresponding to the closest neighbors of i (in this case <code>percent_closest</code> = p).
</p>
<p>The arguments <code>jointprobaA</code> and <code>jointprobaB</code> can be seen as estimations of <code class="reqn">\gamma</code> (sum of cells must be equal to 1) that correspond to estimations of the joint distributions of <code class="reqn">(Y,Z)</code> in A and B respectively.
</p>
<p>The argument <code>solvr</code> permits user to choose the solver of the optimization algorithm. The default solver is &quot;glpk&quot; that corresponds to the GNU Linear Programming Kit (see (3) for more details). The solver &quot;clp&quot; (see (4)) for Coin-or Linear Programming, convenient in linear and quadratic situations, is also directly integrated in the function.
Moreover, the function actually uses the <code>R</code> optimization infrastructure of the package <span class="pkg">ROI</span> which offers a wide choice of solver to users by easily loading the associated plugins of <span class="pkg">ROI</span> (see (5)).
</p>


<h3>Value</h3>

<p>A list of two vectors of numeric values:
</p>
<table>
<tr><td><code>YAtrans</code></td>
<td>
<p>a vector corresponding to the predicted values of <code class="reqn">Y</code> in database B (numeric form) according to the <code>which.DB</code> argument</p>
</td></tr>
<tr><td><code>ZBtrans</code></td>
<td>
<p>a vector corresponding to the predicted values of <code class="reqn">Z</code> in database A (numeric form) according to the <code>which.DB</code> argument</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec, Valerie Gares, Jeremy Omer
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li>
<li><p> Makhorin A (2011). GNU Linear Programming Kit Reference Manual Version 4.47.<a href="http://www.gnu.org/software/glpk/">http://www.gnu.org/software/glpk/</a>
</p>
</li>
<li><p> Forrest J, de la Nuez D, Lougee-Heimer R (2004). Clp User Guide. <a href="https://www.coin-or.org/Clp/userguide/index.html">https://www.coin-or.org/Clp/userguide/index.html</a>
</p>
</li>
<li><p> Theussl S, Schwendinger F, Hornik K (2020). ROI: An Extensible R Optimization Infrastructure.Journal of Statistical Software,94(15), 1-64. doi: <a href="https://doi.org/10.18637/jss.v094.i15">10.18637/jss.v094.i15</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+proxim_dist">proxim_dist</a></code>, <code><a href="#topic+avg_dist_closest">avg_dist_closest</a></code>, <code><a href="#topic+indiv_grp_closest">indiv_grp_closest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example using The Euclidean distance on a complete database
# For this example we keep only 200 rows:

data(tab_test)
tab_test2 &lt;- tab_test[c(1:80, 5001:5080), ]
dim(tab_test2)

# Adding NAs in Y1 and Y2
tab_test2[tab_test2$ident == 2, 2] &lt;- NA
tab_test2[tab_test2$ident == 1, 3] &lt;- NA

# Because all covariates are ordered in numeric form,
# the transfo_dist function is not required here

mat_testm &lt;- proxim_dist(tab_test2, norm = "M")

### Y(Y1) and Z(Y2) are a same variable encoded in 2 different forms:
### 4 levels for Y1 and 3 levels for Y2
### ... Stored in two distinct databases, A and B, respectively
### The marginal distribution of Y in B is unknown,
### as the marginal distribution of Z in A ...

# Assuming that the following matrix called transport symbolizes
# an estimation of the joint distribution L(Y,Z) ...
# Note that, in reality this distribution is UNKNOWN and is
# estimated in the OT function by resolving the optimization problem.

# By supposing:

val_trans &lt;- c(0.275, 0.115, 0, 0, 0, 0.085, 0.165, 0, 0, 0, 0.095, 0.265)
mat_trans &lt;- matrix(val_trans, ncol = 3, byrow = FALSE)

# Getting the individual predictions of Z in A (only)
# by computing average distances on 90% of the nearest neighbors of
# each modality of Z in B
predopt_A &lt;- indiv_grp_optimal(mat_testm,
  jointprobaA = mat_trans,
  jointprobaB = mat_trans, percent_closest = 0.90,
  which.DB = "A"
)


### Example 2 using The Manhattan distance with incomplete covariates
data(simu_data)

man1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "M"
)
mat_man1 &lt;- proxim_dist(man1, norm = "M")


### Y and Z are a same variable encoded in 2 different forms:
### (3 levels for Y and 5 levels for Z)
### ... Stored in two distinct databases, A and B, respectively
### The marginal distribution of Y in B is unknown,
### as the marginal distribution of Z in A ...


# By supposing that the following matrix called transport symbolizes
# an estimation of the joint distribution L(Y,Z) ...
# Note that, in reality this distribution is UNKNOWN and is
# estimated in the OT function by resolving an optimisation problem.

mat_trans2 &lt;- matrix(c(0.3625, 0, 0, 0.07083333, 0.05666667,
                       0, 0, 0.0875, 0, 0, 0.1075, 0,
                       0, 0.17166667, 0.1433333),
                     ncol = 5, byrow = FALSE)


# The predicted values of Y in database B and Z in
# database A are stored in the following object:

predopt2 &lt;- indiv_grp_optimal(mat_man1,
  jointprobaA = mat_trans2,
  jointprobaB = mat_trans2,
  percent_closest = 0.90
)
summary(predopt2)


</code></pre>

<hr>
<h2 id='merge_dbs'>merge_dbs()</h2><span id='topic+merge_dbs'></span>

<h3>Description</h3>

<p>Harmonization and merging before data fusion of two databases with specific outcome variables and shared covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_dbs(
  DB1,
  DB2,
  row_ID1 = NULL,
  row_ID2 = NULL,
  NAME_Y,
  NAME_Z,
  order_levels_Y = levels(DB1[, NAME_Y]),
  order_levels_Z = levels(DB2[, NAME_Z]),
  ordinal_DB1 = NULL,
  ordinal_DB2 = NULL,
  impute = "NO",
  R_MICE = 5,
  NCP_FAMD = 3,
  seed_choice = sample(1:1e+06, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_dbs_+3A_db1">DB1</code></td>
<td>
<p>a data.frame corresponding to the 1st database to merge (top database)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_db2">DB2</code></td>
<td>
<p>a data.frame corresponding to the 2nd database to merge (bottom database)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_row_id1">row_ID1</code></td>
<td>
<p>the column index of the row identifier of DB1 if it exists (no identifier by default)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_row_id2">row_ID2</code></td>
<td>
<p>the column index of the row identifier of DB2 if it exists (no identifier by default)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_name_y">NAME_Y</code></td>
<td>
<p>the name of the outcome (with quotes) in its specific scale/encoding from the 1st database (DB1)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_name_z">NAME_Z</code></td>
<td>
<p>the name of the outcome (with quotes) in its specific scale/encoding from the 2nd database (DB2)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_order_levels_y">order_levels_Y</code></td>
<td>
<p>the levels of <code class="reqn">Y</code> stored in a vector and sorted in ascending order in the case of ordered factors. This option permits to reorder the levels in the 1st database (DB1) if necessary.</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_order_levels_z">order_levels_Z</code></td>
<td>
<p>the levels of <code class="reqn">Z</code> stored in a vector and sorted in ascending order in the case of ordered factors. This option permits to reorder the levels in the 2nd database (DB2) if necessary.</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_ordinal_db1">ordinal_DB1</code></td>
<td>
<p>a vector of column indexes corresponding to ordinal variables in the 1st database (no ordinal variable by default)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_ordinal_db2">ordinal_DB2</code></td>
<td>
<p>a vector of column indexes corresponding to ordinal variables in the 2nd database (no ordinal variable by default)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_impute">impute</code></td>
<td>
<p>a character equals to &quot;NO&quot; when missing data on covariates are kept (Default option), &quot;CC&quot; for Complete Case by keeping only covariates with no missing information , &quot;MICE&quot; for MICE multiple imputation approach, &quot;FAMD&quot; for single imputation approach using Factorial Analysis for Mixed Data</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_r_mice">R_MICE</code></td>
<td>
<p>the chosen number of multiple imputations required for the  MICE approach (5 by default)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_ncp_famd">NCP_FAMD</code></td>
<td>
<p>an integer corresponding to the number of components used to predict missing values in FAMD imputation (3 by default)</p>
</td></tr>
<tr><td><code id="merge_dbs_+3A_seed_choice">seed_choice</code></td>
<td>
<p>an integer used as argument by the set.seed() for offsetting the random number generator (Random integer by default, only useful with MICE)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Assuming that DB1 and DB2 are two databases (two separate data.frames with no overlapping rows) to be merged vertically before data fusion, the function <code>merge_dbs</code> performs this merging and checks the harmonization of the shared variables.
Firslty, the two databases declared as input to the function (via the argument <code>DB1</code> and <code>DB2</code>) must have the same specific structure.
Each database must contain a target variable (whose label must be filled in the argument <code>Y</code> for DB1 and in <code>Z</code> for DB2 respectively, so that the final synthetic database in output will contain an incomplete variable <code>Y</code> whose corresponding values will be missing in DB2 and another incomplete target <code>Z</code> whose values will be missing in DB1), a subset of shared covariates (by example, the best predictors of <code class="reqn">Y</code> in DB1, and <code class="reqn">Z</code> in DB2).
Each database can have a row identifier whose label must be assigned in the argument <code>row_ID1</code> for DB1 and <code>row_ID2</code> for DB2. Nevertheless, by default DB1 and DB2 are supposed with no row identifiers. The merging keeps unchanged the order of rows in the two databases provided that <code class="reqn">Y</code> and <code class="reqn">Z</code> have no missing values.
By building, the first declared database (in the argument <code>DB1</code>) will be placed automatically above the second one (declared in the argument <code>DB2</code>) in the final database.
</p>
<p>Firstly, by default, a variable with the same name in the two databases is abusively considered as shared. This condition is obviously insufficient to be kept in the final subset of shared variables,
and the function <code>merge_dbs</code> so performs checks before merging described below.
</p>
<p>A. Discrepancies between shared variables
</p>

<ul>
<li><p> Shared variables with discrepancies of types between the two databases (for example, a variable with a common name in the two databases but stored as numeric in DB1, and stored as character in DB2) will be removed from the merging and the variable name will be saved in output (<code>REMOVE1</code>).
</p>
</li>
<li><p> Shared factors with discrepancies of levels (or number of levels) will be also removed from the merging and the variable name will be saved in output (<code>REMOVE2</code>).
</p>
</li>
<li><p> covariates whose names are specific to each database will be also deleted from the merging.
</p>
</li>
<li><p> If some important predictors have been improperly excluded from the merging due to the above-mentioned checks, it is possible for user to transform these variables a posteriori, and re-run the function.
</p>
</li></ul>

<p>B. Rules for the two outcomes (target variables)
</p>
<p>The types of <code>Y</code> and <code>Z</code> must be suitable:
</p>

<ul>
<li><p> Categorical (ordered or not) factors are allowed.
</p>
</li>
<li><p> Numeric and discrete outcomes with a finite number of values are allowed but will be automatically converted as ordered factors using the function <code>transfo_target</code> integrated in the function <code>merge_dbs</code>.
</p>
</li></ul>

<p>C. The function <code>merge_dbs</code> handles incomplete information of shared variables, by respecting the following rules:
</p>

<ul>
<li><p> If <code>Y</code> or <code>Z</code> have missing values in DB1 or DB2, corresponding rows are excluded from the database before merging. Moreover, in the case of incomplete outcomes,
if A and B have row identifiers, the corresponding identifiers are removed and these latters are stored in the objects <code>DB1_ID</code> and <code>DB2_ID</code> of the output.
</p>
</li>
<li><p> Before overlay, the function deals with incomplete covariates according to the argument <code>impute</code>.
Users can decide to work with complete case only (&quot;CC&quot;), to keep (&quot;NO&quot;) or impute incomplete information (&quot;MICE&quot;,&quot;FAMD&quot;).
</p>
</li>
<li><p> The function <code>imput_cov</code>, integrated in the syntax of <code>merge_dbs</code> deals with imputations. Two approaches are actually available:
the multivariate imputation by chained equation approach (MICE, see (3) for more details about the approach or the corresponding package <span class="pkg">mice</span>),
and an imputation approach from the package <span class="pkg">missMDA</span> that uses a dimensionality reduction method (here a factor analysis for mixed data called FAMD (4)), to provide single imputations.
If multiple imputation is required (<code>impute</code> = &quot;MICE&quot;), the default imputation methods are applied according to the type of the variables. The average of the plausible values will be kept for a continuous variable, while the most frequent candidate will be kept as a consensus value for a categorical variable or factor (ordinal or not).
</p>
</li></ul>

<p>As a finally step, the function checks that all values related to <code class="reqn">Y</code> in B are missing and inversely for <code class="reqn">Z</code> in A.
</p>


<h3>Value</h3>

<p>A list containing 12 elements (13 when <code>impute</code> equals &quot;MICE&quot;):
</p>
<table>
<tr><td><code>DB_READY</code></td>
<td>
<p>the database matched from the two initial databases with common covariates and imputed or not according to the impute option</p>
</td></tr>
<tr><td><code>ID1_drop</code></td>
<td>
<p>the row numbers or row identifiers excluded of the data merging because of the presence of missing values in the target variable of DB1. NULL otherwise</p>
</td></tr>
<tr><td><code>ID2_drop</code></td>
<td>
<p>the row numbers or row identifiers excluded of the data merging because of the presence of missing values in the target variable of DB2. NULL otherwise</p>
</td></tr>
<tr><td><code>Y_LEVELS</code></td>
<td>
<p>the remaining levels of the target variable <code class="reqn">Y</code> in the DB1</p>
</td></tr>
<tr><td><code>Z_LEVELS</code></td>
<td>
<p>the remaining Levels of the target variable <code class="reqn">Z</code> in the DB2</p>
</td></tr>
<tr><td><code>REMOVE1</code></td>
<td>
<p>the labels of the deleted covariates because of type incompatibilies of type from DB1 to DB2</p>
</td></tr>
<tr><td><code>REMOVE2</code></td>
<td>
<p>the removed factor(s) because of levels incompatibilities from DB1 to DB2</p>
</td></tr>
<tr><td><code>REMAINING_VAR</code></td>
<td>
<p>labels of the remained covariates for data fusion</p>
</td></tr>
<tr><td><code>IMPUTE_TYPE</code></td>
<td>
<p>a character with quotes that specify the method eventually chosen to handle missing data in covariates</p>
</td></tr>
<tr><td><code>MICE_DETAILS</code></td>
<td>
<p>a list containing the details of the imputed datasets using <code>MICE</code> when this option is chosen. Raw and imputed databases imputed for DB1 and DB2 according to the number of multiple imputation selected (Only if impute = &quot;MICE&quot;)</p>
</td></tr>
<tr><td><code>DB1_raw</code></td>
<td>
<p>a data.frame corresponding to DB1 after merging</p>
</td></tr>
<tr><td><code>DB2_raw</code></td>
<td>
<p>a data.frame corresponding to DB2 after merging</p>
</td></tr>
<tr><td><code>SEED</code></td>
<td>
<p>an integer used as argument by the <code>set.seed</code> function for offsetting the random number generator (random selection by default)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li>
<li><p> van Buuren, S., Groothuis-Oudshoorn, K. (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1–67. urlhttps://www.jstatsoft.org/v45/i03/
</p>
</li>
<li><p> Josse J, Husson F (2016). missMDA: A Package for Handling Missing Values in Multivariate Data Analysis. Journal of Statistical Software, 70(1), 1–31. doi: <a href="https://doi.org/10.18637/jss.v070.i01">10.18637/jss.v070.i01</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+imput_cov">imput_cov</a></code>, <code><a href="#topic+transfo_target">transfo_target</a></code>, <code><a href="#topic+select_pred">select_pred</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Assuming two distinct databases from simu_data: data_A and data_B
### Some transformations will be made beforehand on variables to generate
### heterogeneities between the two bases.
data(simu_data)
data_A &lt;- simu_data[simu_data$DB == "A", c(2, 4:8)]
data_B &lt;- simu_data[simu_data$DB == "B", c(3, 4:8)]

# For the example, a covariate is added (Weight) only in data_A
data_A$Weight &lt;- rnorm(300, 70, 5)

# Be careful: the target variables must be in factor (or ordered) in the 2 databases
# Because it is not the case for Yb2 in data_B, the function will convert it.
data_B$Yb2 &lt;- as.factor(data_B$Yb2)

# Moreover, the Dosage covariate is stored in 3 classes in data_B (instead of 4 classes in data_B)
# to make the encoding of this covariate specific to each database.
data_B$Dosage &lt;- as.character(data_B$Dosage)
data_B$Dosage &lt;- as.factor(ifelse(data_B$Dosage %in% c("Dos 1", "Dos 2"), "D1",
  ifelse(data_B$Dosage == "Dos 3", "D3", "D4")
))

# For more diversity, this covariate iis placed at the last column of the data_B
data_B &lt;- data_B[, c(1:3, 5, 6, 4)]

# Ex 1: The two databases are merged and incomplete covariates are imputed using MICE
merged_ex1 &lt;- merge_dbs(data_A, data_B,
  NAME_Y = "Yb1", NAME_Z = "Yb2",
  ordinal_DB1 = c(1, 4), ordinal_DB2 = c(1, 6),
  impute = "MICE", R_MICE = 2, seed_choice = 3011)

summary(merged_ex1$DB_READY)


# Ex 2: The two databases are merged and missing values are kept
merged_ex2 &lt;- merge_dbs(data_A, data_B,
  NAME_Y = "Yb1", NAME_Z = "Yb2",
  ordinal_DB1 = c(1, 4), ordinal_DB2 = c(1, 6),
  impute = "NO", seed_choice = 3011
)

# Ex 3: The two databases are merged by only keeping the complete cases
merged_ex3 &lt;- merge_dbs(data_A, data_B,
  NAME_Y = "Yb1", NAME_Z = "Yb2",
  ordinal_DB1 = c(1, 4), ordinal_DB2 = c(1, 6),
  impute = "CC", seed_choice = 3011
)

# Ex 4: The two databases are merged and incomplete covariates are imputed using FAMD
merged_ex4 &lt;- merge_dbs(data_A, data_B,
  NAME_Y = "Yb1", NAME_Z = "Yb2",
  ordinal_DB1 = c(1, 4), ordinal_DB2 = c(1, 6),
  impute = "FAMD", NCP_FAMD = 4, seed_choice = 2096
)

# Conclusion:
# The data fusion is successful in each situation.
# The Dosage and Weight covariates have been normally excluded from the fusion.
# The covariates have been imputed when required.

</code></pre>

<hr>
<h2 id='ncds_14'>National Child Development Study: a sample of the first four waves of data collection</h2><span id='topic+ncds_14'></span>

<h3>Description</h3>

<p>This database is a sample of the first four waves of data collection of the National Child Development Study (NCDS)
started in 1958 (<a href="https://cls.ucl.ac.uk/cls-studies/1958-national-child-development-study/">https://cls.ucl.ac.uk/cls-studies/1958-national-child-development-study/</a>).
The NCDS project is a continuing survey which follows the lives of over 17,000 people born in England,
Scotland and Wales in a same week of the year 1958.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncds_14
</code></pre>


<h3>Format</h3>

<p>A data.frame with 5,476 participants (rows) and 6 variables
</p>

<dl>
<dt>ncdsid</dt><dd><p>the anonymised ncds identifier</p>
</dd>
<dt>GO90</dt><dd><p>the Goldthorp social class 90 scale coded as a 12-levels factor: higher-grade professionals <code>10</code>,
lower-grade professionals <code>20</code>, routine non-manual employees with higher grade (administration, commerce) <code>31</code>,
routine non-manual employees with lower grade (sales and services) <code>32</code>, small proprietors with employees <code>41</code>,
small proprietors without employees <code>42</code>, farmers, small holders and workers in primary production <code>43</code>,
lower-grade technicians <code>50</code>, skilled manual workers <code>60</code>, semi-skilled and unskilled manual workers <code>71</code>,
other workers in primary production <code>72</code>, and <code>0</code> when the scale was not applicable to the participant. This variable has 806 NAs.</p>
</dd>
<dt>health</dt><dd><p>the health status of the participant stored in a 4 ordered levels factor: <code>1</code> for excellent,
<code>2</code> for good, <code>3</code> for fair, <code>4</code> for poor. This variable has 2 NAs.</p>
</dd>
<dt>employ</dt><dd><p>the employment status at inclusion stored in a 7-levels factor: <code>1</code> for unemployed status, <code>2</code> for govt sheme,
<code>3</code> for full-time education, <code>4</code> for housework or childcare, <code>5</code> for sick or handicapped, <code>6</code> for other, <code>7</code>
if employed between 16 and 33. This variable has 58 NAs.</p>
</dd>
<dt>gender</dt><dd><p>the gender of the participant stored in a 2-levels factor: <code>1</code> for male, <code>2</code> for female</p>
</dd>
<dt>study</dt><dd><p>a 2-level factor equals to <code>1</code> for participant with completed graduate studies or <code>2</code> otherwise</p>
</dd>
</dl>



<h3>Details</h3>

<p>The ncds identifier have been voluntarily anonymized to allow their availability for the package.
</p>
<p>This sample has 5,476 participants included in the study between the first and fourth wave of data collection.
</p>


<h3>Source</h3>

<p>INSERM - This database is a sample of the National Child Development Study
</p>

<hr>
<h2 id='ncds_5'>National Child Development Study: a sample of the fifth wave of data collection</h2><span id='topic+ncds_5'></span>

<h3>Description</h3>

<p>This database is a sample of the fifth wave of data collection of the National Child Development Study (NCDS)
started in 1958 (<a href="https://cls.ucl.ac.uk/cls-studies/1958-national-child-development-study/">https://cls.ucl.ac.uk/cls-studies/1958-national-child-development-study/</a>).
The NCDS project is a continuing survey which follows the lives of over 17,000 people born in England,
Scotland and Wales in a same week of the year 1958.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ncds_5
</code></pre>


<h3>Format</h3>

<p>A data.frame with 365 participants (rows) and 6 variables
</p>

<dl>
<dt>ncdsid</dt><dd><p>the anonymised ncds identifier</p>
</dd>
<dt>gender</dt><dd><p>the gender of the participant stored in a 2-levels factor: <code>1</code> for male, <code>2</code> for female</p>
</dd>
<dt>RG91</dt><dd><p>the RG social class 91 scale coded as a 7-levels factor: <code>10</code> for professional educations,
<code>20</code> for managerial and technical occupations, <code>31</code> for skilled non-manual occupations,
<code>32</code> for skilled manual occupations, <code>40</code> for party-skilled occupations, <code>50</code> for unskilled occupations <code>50</code>,
and <code>0</code> when the scale was not applicable to the participant. This variable is complete.</p>
</dd>
<dt>health</dt><dd><p>the health status of the participant stored in a 4 ordered levels factor: <code>1</code> for excellent,
<code>2</code> for good, <code>3</code> for fair, <code>4</code> for poor. This variable has 2 NAs.</p>
</dd>
<dt>employ</dt><dd><p>the employment status at inclusion stored in a 7-levels factor: <code>1</code> for unemployed status, <code>2</code> for govt sheme,
<code>3</code> for full-time education, <code>4</code> for housework or childcare, <code>5</code> for sick or handicapped, <code>6</code> for other, <code>7</code>
if employed between 16 and 33. This variable has 58 NAs.</p>
</dd>
<dt>study</dt><dd><p>a 2-level factor equals to <code>1</code> for participant with completed graduate studies or <code>2</code> otherwise</p>
</dd>
</dl>



<h3>Details</h3>

<p>The ncds identifier have been voluntarily anonymized to allow their availability for the package.
</p>
<p>This sample has 365 participants included in the study during the 5th waves of data collection.
</p>


<h3>Source</h3>

<p>INSERM - This database is a sample of the National Child Development Study
</p>

<hr>
<h2 id='OT_joint'>OT_joint()</h2><span id='topic+OT_joint'></span>

<h3>Description</h3>

<p>The function <code>OT_joint</code> integrates two algorithms called (<code>JOINT</code>) and (<code>R-JOINT</code>) dedicated to the solving of recoding problems in data fusion
using optimal transportation of the joint distribution of outcomes and covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OT_joint(
  datab,
  index_DB_Y_Z = 1:3,
  nominal = NULL,
  ordinal = NULL,
  logic = NULL,
  convert.num = NULL,
  convert.class = NULL,
  dist.choice = "E",
  percent.knn = 1,
  maxrelax = 0,
  lambda.reg = 0,
  prox.X = 0.3,
  solvR = "glpk",
  which.DB = "BOTH"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OT_joint_+3A_datab">datab</code></td>
<td>
<p>a data.frame made up of two overlayed databases with at least four columns sorted in a random order. One column must be a column dedicated to the identification of the two databases ranked in ascending order
(For example: 1 for the top database and 2 for the database from below, or more logically here A and B  ...But not B and A!). One column (<code class="reqn">Y</code> here but other names are allowed)
must correspond to the target variable related to the information of interest to merge with its specific encoding in the database A (corresponding encoding should be missing in the database B). In the same way,
one column (<code class="reqn">Z</code> here) corresponds to the second target variable with its specific encoding in the database B (corresponding encoding should be missing in the database A).
Finally, the input database must have at least one shared covariate with same encoding in A and B. Please notice that, if your data.frame has only one shared covariate (four columns) with missing values (because no imputation is desired)
then a warning will appear and the algorithm will only run with complete cases.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_index_db_y_z">index_DB_Y_Z</code></td>
<td>
<p>a vector of three indexes of variables. The first index must correspond to the index of the databases identifier column. The second index corresponds
to the index of the target variable in the first database (A) while the third index corresponds to the column index related to the target variable in the second database (B).</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_nominal">nominal</code></td>
<td>
<p>a vector of column indexes of all the nominal (not ordered) variables (database identifier and target variables included if it is the case for them).</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_ordinal">ordinal</code></td>
<td>
<p>a vector of column indexes of all the ordinal variables (database identifier and target variables included if it is the case for them).</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_logic">logic</code></td>
<td>
<p>a vector of column indexes of all the boolean variables of the data.frame.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_convert.num">convert.num</code></td>
<td>
<p>indexes of the continuous (quantitative) variables. They will be automatically converted in ordered factors. By default, no continuous variables is assumed in the database.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_convert.class">convert.class</code></td>
<td>
<p>a vector indicating for each continuous variable to convert, the corresponding desired number of levels. If the length of the argument <code>convert_num</code> exceeds 1 while the length of <code>convert_class</code> equals 1 (only one integer),
each discretization will count the same number of levels (quantiles).</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_dist.choice">dist.choice</code></td>
<td>
<p>a character string (with quotes) corresponding to the distance function chosen between: the euclidean distance (&quot;E&quot;, by default), the Manhattan distance (&quot;M&quot;),
the Gower distance (&quot;G&quot;), and the Hamming distance (&quot;H&quot;) for binary covariates only.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_percent.knn">percent.knn</code></td>
<td>
<p>the ratio of closest neighbors involved in the computations of the cost matrices. 1 is the default value that includes all rows in the computation.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_maxrelax">maxrelax</code></td>
<td>
<p>the maximum percentage of deviation from expected probability masses. It must be equal to 0 (default value) for the <code>JOINT</code> algorithm, and equal to a strictly positive value for the R-JOINT algorithm.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_lambda.reg">lambda.reg</code></td>
<td>
<p>a coefficient measuring the importance of the regularization term. It corresponds to the <code>R-JOINT</code> algorithm for a value other than 0 (default value).</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_prox.x">prox.X</code></td>
<td>
<p>a probability (betwen 0 and 1) used to calculate the distance threshold below which two covariates' profiles are supposed as neighbors.
If <code>prox.X = 1</code>, all profiles are considered as neighbors.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_solvr">solvR</code></td>
<td>
<p>a character string that specifies the type of method selected to solve the optimization algorithms. The default solver is &quot;glpk&quot;.</p>
</td></tr>
<tr><td><code id="OT_joint_+3A_which.db">which.DB</code></td>
<td>
<p>a character string indicating the database to complete (&quot;BOTH&quot; by default, for the prediction of <code class="reqn">Y</code> and <code class="reqn">Z</code> in the two databases), &quot;A&quot; only for the imputation of <code class="reqn">Z</code> in A, &quot;B&quot; only for the imputation of <code class="reqn">Y</code> in B.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A. THE RECODING PROBLEM IN DATA FUSION
</p>
<p>Assuming that <code class="reqn">Y</code> and <code class="reqn">Z</code> are two target variables which refered to the same target population in two separate databases A and B respectively (no overlapping rows),
so that <code class="reqn">Y</code> and <code class="reqn">Z</code> are never jointly observed. Assuming also that A and B share a subset of common covariates <code class="reqn">X</code> of any types (same encodings in A and B)
completed or not. Merging these two databases often requires to solve a recoding problem by creating an unique database where
the missing information of <code class="reqn">Y</code> and <code class="reqn">Z</code> is fully completed.
</p>
<p>B. INFORMATIONS ABOUT THE ALGORITHM
</p>
<p>As with the function <code><a href="#topic+OT_outcome">OT_outcome</a></code>, the function <code>OT_joint</code> provides a solution to the recoding problem by proposing an
application of optimal transportation which aims is to search for a bijective mapping between the joint distributions of <code class="reqn">(Y,X)</code> and <code class="reqn">(Z,X)</code> in A and B (see (2) for more details).
The principle of the algorithm is also based on the resolution of an optimization problem, which provides a solution <code class="reqn">\gamma</code> (as called in (1) and (2)), estimate
of the joint distribution of <code class="reqn">(X,Y,Z)</code> according to the database to complete (see the argument <code>which.DB</code> for the choice of the database). While the algorithms <code>OUTCOME</code> and <code>R_OUTCOME</code> integrated in
the function <code><a href="#topic+OT_outcome">OT_outcome</a></code> require post-treatment steps to provide individual predictions, the algorithm <code>JOINT</code> directly uses estimations of the conditional distributions <code class="reqn">(Y|Z,X)</code> in B and
<code class="reqn">(Z|Y,X)</code> in A to predict the corresponding incomplete individuals informations of <code class="reqn">Y</code> and/or <code class="reqn">Z</code> respectively.
This algorithm supposes that the conditional distribution <code class="reqn">(Y|X)</code> must be identical in A and B. Respectively, <code class="reqn">(Z|X)</code> is supposed identical in A and B.
Estimations a posteriori of conditional probabilities <code class="reqn">P[Y|X,Z]</code> and <code class="reqn">P[Z|X,Y]</code> are available for each profiles of covariates in output (See the objects <code>estimatorYB</code> and <code>estimatorZA</code>).
Estimations of <code class="reqn">\gamma</code> are also available according to the chosen transport distributions (See the arguments <code>gamma_A</code> and <code>gamma_B</code>).
</p>
<p>The algorithm <code>R-JOINT</code> gathers enrichments of the algorithm <code>JOINT</code> and is also available via the function <code>OT_joint</code>. It allows users to add a relaxation term in the algorithm to relax distributional assumptions (<code>maxrelax</code>&gt;0),
and (or) add also a positive regularization term (<code>lamdba.reg</code>&gt;0) expressing that the transportation map does not vary to quickly with respect of covariates <code class="reqn">X</code>.
Is is suggested to users to calibrate these two parameters a posteriori by studying the stability of the individual predictions in output.
</p>
<p>C. EXPECTED STRUCTURE FOR THE INPUT DATABASE
</p>
<p>The input database is a data.frame that must satisfy a specific form:
</p>

<ul>
<li><p> Two overlayed databases containing a common column of databases identifiers (A and B, 1 or 2, by examples, encoded in numeric or factor form)
</p>
</li>
<li><p> A column corresponding to the target variable with its specific encoding in A (For example a factor <code class="reqn">Y</code> encoded in <code class="reqn">n_Y</code> levels, ordered or not, with NAs in the corresponding rows of B)
</p>
</li>
<li><p> A column corresponding to another target outcome summarizing the same latent information with its specific encoding in B (By example a factor <code class="reqn">Z</code> with <code class="reqn">n_Z</code> levels, with NAs in rows of A)
</p>
</li>
<li><p> The order of the variables in the database have no importance but the column indexes related to the three columns previously described (ie ID, <code class="reqn">Y</code> and <code class="reqn">Z</code>) must be rigorously specified
in the argument <code>index_DB_Y_Z</code>.
</p>
</li>
<li><p> A set of shared common categorical covariates (at least one but more is recommended) with or without missing values (provided that the number of covariates exceeds 1) is required. On the contrary to the
function <code>OT_outcome</code>, please notice, that the function <code>OT_joint</code> does not accept continuous covariates therefore these latters will have to be categorized beforehand or using the provided input process (see <code>convert.num</code>).
</p>
</li></ul>

<p>The function <code><a href="#topic+merge_dbs">merge_dbs</a></code> is available in this package to assist user in the preparation of their databases.
</p>
<p>Remarks about the target variables:
</p>

<ul>
<li><p> A target variable can be of categorical type, but also discrete, stored in factor, ordered or not. Nevertheless, notice that, if the variable is stored in numeric it will be automatically converted in ordered factors.
</p>
</li>
<li><p> If a target variable is incomplete, the corresponding rows will be automatically dropped during the execution of the function.
</p>
</li></ul>

<p>The type of each variables (including <code class="reqn">ID</code>, <code class="reqn">Y</code> and <code class="reqn">Z</code>) of the database must be rigorously specified, in one of the four arguments <code>quanti</code>, <code>nominal</code>, <code>ordinal</code> and <code>logic</code>.
</p>
<p>D. TRANSFORMATIONS OF CONTINUOUS COVARIATES
</p>
<p>Continuous shared variables (predictors) with infinite numbers of values have to be categorized before being introduced in the function.
To assist users in this task, the function <code>OT_joint</code> integrates in its syntax a process dedicated to the categorization of continuous covariates. For this, it is necessary to rigorously fill in
the arguments <code>quanti</code> and <code>convert.class</code>.
The first one informs about the column indexes of the continuous variables to be transformed in ordered factor while the second one specifies the corresponding number of desired balanced levels (for unbalanced levels, users must do transformations by themselves).
Therefore <code>convert.num</code> and <code>convert.class</code> must be vectors of same length, but if the length of <code>quanti</code> exceeds 1, while the length of <code>convert.class</code> is 1, then, by default, all the covariates to convert will have the same number of classes (transformation by quantiles),
that corresponds to the value specified in the argument <code>convert.class</code>.
Notice that only covariates can be transformed (not target variables) and that any incomplete information must have been taken into account beforehand (via the dedicated functions <code><a href="#topic+merge_dbs">merge_dbs</a></code> or <code><a href="#topic+imput_cov">imput_cov</a></code> for examples).
Moreover, all the indexes informed in the argument <code>convert.num</code> must also be informed in the argument <code>quanti</code>.
Finally, it is recommended to declare all discrete covariates as ordinal factors using the argument <code>ordinal</code>.
</p>
<p>E. INFORMATIONS ABOUT DISTANCE FUNCTIONS AND RELATED PARAMETERS
</p>
<p>Each individual (or row) of a given database is here characterized by a vector of covariates, so the distance between two individuals or groups of individuals depends on similarities between covariates
according to the distance function chosen by user (via the argument <code>dist.choice</code>). Actually four distance functions are implemented in <code>OT_joint</code> to take into account the most frequently encountered situation (see (3)):
</p>

<ul>
<li><p> the Manhattan distance (&quot;M&quot;)
</p>
</li>
<li><p> the Euclidean distance (&quot;E&quot;)
</p>
</li>
<li><p> the Gower distance for mixed data (see (4): &quot;G&quot;)
</p>
</li>
<li><p> the Hamming distance for binary data (&quot;H&quot;)
</p>
</li></ul>

<p>Finally, two profiles of covariates <code class="reqn">P_1</code> (<code class="reqn">n_1</code> individuals) and <code class="reqn">P_2</code> (<code class="reqn">n_2</code> individuals) will be considered as neighbors if <code class="reqn">dist(P_1,P_2) &lt; prox.X \times max(dist(P_i,P_j))</code> where <code class="reqn">prox.X</code> must be fixed by user (<code class="reqn">i = 1,\dots,n_1</code> and <code class="reqn">j = 1,\dots,n_2</code>). This choice is used in the computation of the <code>JOINT</code> and <code>R_JOINT</code> algorithms.
The <code>prox.X</code> argument influences a lot the running time of the algorithm. The greater, the more the value will be close to 1, the more the convergence of the algorithm will be difficult or even impossible.
</p>
<p>Each individual <code class="reqn">i</code> from A or B is here considered as a neighbor of only one profile of covariates <code class="reqn">P_j</code>.
</p>
<p>F. INFORMATIONS ABOUT THE SOLVER
</p>
<p>The argument <code>solvR</code> permits user to choose the solver of the optimization algorithm. The default solver is &quot;glpk&quot; that corresponds to the GNU Linear Programming Kit (see (5) for more details).
Moreover, the function actually uses the <code>R</code> optimization infrastructure of the package <span class="pkg">ROI</span> which offers a wide choice of solver to users by easily loading the associated plugins of <span class="pkg">ROI</span> (see (6)).
</p>
<p>For more details about the algorithms integrated in <code>OT_joint</code>, please consult (2).
</p>


<h3>Value</h3>

<p>A &quot;otres&quot; class object of 9 elements:
</p>
<table>
<tr><td><code>time_exe</code></td>
<td>
<p>running time of the function</p>
</td></tr>
<tr><td><code>gamma_A</code></td>
<td>
<p>estimate of <code class="reqn">\gamma</code> for the completion of A. A matrix that corresponds to the joint distribution of <code class="reqn">(Y,Z,X)</code> in A</p>
</td></tr>
<tr><td><code>gamma_B</code></td>
<td>
<p>estimate of <code class="reqn">\gamma</code> for the completion of B. A matrix that corresponds to the joint distribution of <code class="reqn">(Y,Z,X)</code> in B</p>
</td></tr>
<tr><td><code>profile</code></td>
<td>
<p>a data.frame that gives all details about the remaining P profiles of covariates. These informations can be linked to the <code>estimatorZA</code> and the <code>estimatorYB</code> objects for a better interpretation of the results.</p>
</td></tr>
<tr><td><code>res_prox</code></td>
<td>
<p>a <code>proxim_dist</code> object</p>
</td></tr>
<tr><td><code>estimatorZA</code></td>
<td>
<p>an array that corresponds to estimates of the probability distribution of <code class="reqn">Z</code> conditional to <code class="reqn">X</code> and <code class="reqn">Y</code> in database A. The number of rows of each table corresponds to the total number of profiles of covariates.
The first dimension of each table (rownames) correspond to the profiles of covariates sorted by order of appearance in the merged database. The second dimension of the array (columns of the tables) corresponds to the levels of <code class="reqn">Y</code> while the third element corresponds to the levels of <code class="reqn">Z</code>.</p>
</td></tr>
<tr><td><code>estimatorYB</code></td>
<td>
<p>an array that corresponds to estimates of the probability distribution of <code class="reqn">Y</code> conditional to <code class="reqn">X</code> and <code class="reqn">Z</code> in database B. The number of rows of each table corresponds to the total number of profiles of covariates.
The first dimension of each table (rownames) correspond to the profiles of covariates sorted by order of appearance in the merged database. The second dimension of the array (columns of the tables) corresponds to the levels of <code class="reqn">Z</code> while the third element corresponds to the levels of <code class="reqn">Y</code>.</p>
</td></tr>
<tr><td><code>DATA1_OT</code></td>
<td>
<p>the database A with the individual predictions of <code class="reqn">Z</code> using an optimal transportation algorithm (<code>JOINT</code>) or <code>R-JOINT</code></p>
</td></tr>
<tr><td><code>DATA2_OT</code></td>
<td>
<p>the database B with the individual predictions of <code class="reqn">Y</code> using an optimal transportation algorithm (<code>JOINT</code>) or <code>R-JOINT</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec, Valerie Gares, Jeremy Omer
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li>
<li><p> Anderberg, M.R. (1973), Cluster analysis for applications, 359 pp., Academic Press, New York, NY, USA.
</p>
</li>
<li><p> Gower J.C. (1971). A general coefficient of similarity and some of its properties. Biometrics, 27, 623–637
</p>
</li>
<li><p> Makhorin A (2011). GNU Linear Programming Kit Reference Manual Version 4.47.<a href="http://www.gnu.org/software/glpk/">http://www.gnu.org/software/glpk/</a>
</p>
</li>
<li><p> Theussl S, Schwendinger F, Hornik K (2020). ROI: An Extensible R Optimization Infrastructure.Journal of Statistical Software,94(15), 1-64. doi: <a href="https://doi.org/10.18637/jss.v094.i15">10.18637/jss.v094.i15</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+merge_dbs">merge_dbs</a></code>, <code><a href="#topic+OT_outcome">OT_outcome</a></code>, <code><a href="#topic+proxim_dist">proxim_dist</a></code>, <code><a href="#topic+avg_dist_closest">avg_dist_closest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### An example of JOINT algorithm with:
#-----
# - A sample of the database tab_test
# - Y1 and Y2 are a 2 outcomes encoded in 2 different forms in DB 1 and 2:
#   4 levels for Y1 and 3 levels for Y2
# - n1 = n2 = 40
# - 2 discrete covariates X1 and X2 defined as ordinal
# - Distances estimated using the Gower function
# Predictions are assessed for Y1 in B only
#-----

data(tab_test)
tab_test2 &lt;- tab_test[c(1:40, 5001:5040), 1:5]


OUTJ1_B &lt;- OT_joint(tab_test2,
                    nominal = c(1, 4:5), ordinal = c(2, 3),
                    dist.choice = "G", which.DB = "B"
)



### An example of R-JOINT algorithm using the previous database,
### and keeping the same options excepted for:
#-----
# - The distances are estimated using the Gower function
# - Inclusion of an error term in the constraints on
#   the marginals (relaxation term)
# Predictions are assessed for Y1 AND Y2 in A and B respectively
#-----

R_OUTJ1 &lt;- OT_joint(tab_test2,
                    nominal = c(1, 4:5), ordinal = c(2, 3),
                    dist.choice = "G", maxrelax = 0.4,
                    which.DB = "BOTH"
)

### The previous example of R-JOINT algorithm with:
# - Adding a regularization term
# Predictions are assessed for Y1 and Y2 in A and B respectively
#-----

R_OUTJ2 &lt;- OT_joint(tab_test2,
                    nominal = c(1, 4:5), ordinal = c(2, 3),
                    dist.choice = "G", maxrelax = 0.4, lambda.reg = 0.9,
                    which.DB = "BOTH"
)



### Another example of JOINT algorithm with:
#-----
# - A sample of the database simu_data
# - Y1 and Y2 are a 2 outcomes encoded in 2 different forms in DB A and B:
#   (3 levels for Y and 5 levels for Z)
# - n1 = n2 = 100
# - 3 covariates: Gender, Smoking and Age in a qualitative form
# - Complete Case study
# - The Hamming distance
# Predictions are assessed for Y1 and Y2 in A and B respectively
#-----

data(simu_data)
simu_data2 &lt;- simu_data[c(1:100, 401:500), c(1:4, 7:8)]
simu_data3 &lt;- simu_data2[!is.na(simu_data2$Age), ]

OUTJ2 &lt;- OT_joint(simu_data3, prox.X = 0.10,
                  convert.num = 6, convert.class = 3,
                  nominal = c(1, 4:5), ordinal = 2:3,
                  dist.choice = "H", which.DB = "B"
)


</code></pre>

<hr>
<h2 id='OT_outcome'>OT_outcome()</h2><span id='topic+OT_outcome'></span><span id='topic+ot_outcome'></span><span id='topic+OT'></span>

<h3>Description</h3>

<p>The function <code>OT_outcome</code> integrates two algorithms called (<code>OUTCOME</code>) and (<code>R-OUTCOME</code>) dedicated to the solving of recoding problems in data fusion
using optimal transportation (OT) of the joint distribution of outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OT_outcome(
  datab,
  index_DB_Y_Z = 1:3,
  quanti = NULL,
  nominal = NULL,
  ordinal = NULL,
  logic = NULL,
  convert.num = NULL,
  convert.class = NULL,
  FAMD.coord = "NO",
  FAMD.perc = 0.8,
  dist.choice = "E",
  percent.knn = 1,
  maxrelax = 0,
  indiv.method = "sequential",
  prox.dist = 0,
  solvR = "glpk",
  which.DB = "BOTH"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OT_outcome_+3A_datab">datab</code></td>
<td>
<p>a data.frame made up of two overlayed databases with at least four columns sorted in a random order. One column must be a column dedicated to the identification of the two databases ranked in ascending order
(For example: 1 for the top database and 2 for the database from below, or more logically here A and B  ...But not B and A!). One column (<code class="reqn">Y</code> here but other names are allowed)
must correspond to the target variable related to the information of interest to merge with its specific encoding in the database A (corresponding encoding should be missing in the database B). In the same way,
one column (<code class="reqn">Z</code> here) corresponds to the second target variable with its specific encoding in the database B (corresponding encoding should be missing in the database A).
Finally, the input database must have at least one shared covariate with same encoding in A and B. Please notice that, if your data.frame has only one shared covariate (four columns) with missing values (because no imputation is desired)
then a warning will appear and the algorithm will only run with complete cases.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_index_db_y_z">index_DB_Y_Z</code></td>
<td>
<p>a vector of three indexes of variables. The first index must correspond to the index of the databases identifier column. The second index corresponds
to the index of the target variable in the first database (A) while the third index corresponds to the column index related to the target variable in the second database (B).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_quanti">quanti</code></td>
<td>
<p>a vector of column indexes of all the quantitative variables (database identifier and target variables included if it is the case for them).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_nominal">nominal</code></td>
<td>
<p>a vector of column indexes of all the nominal (not ordered) variables (database identifier and target variables included if it is the case for them).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_ordinal">ordinal</code></td>
<td>
<p>a vector of column indexes of all the ordinal variables (database identifier and target variables included if it is the case for them).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_logic">logic</code></td>
<td>
<p>a vector of column indexes of all the boolean variables of the data.frame.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_convert.num">convert.num</code></td>
<td>
<p>indexes of the continuous (quantitative) variables to convert in ordered factors if necessary. All declared indexes in this argument must have been declared in the argument <code>quanti</code> (no conversion by default).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_convert.class">convert.class</code></td>
<td>
<p>a vector indicating for each continuous variable to convert, the corresponding desired number of levels. If the length of the argument <code>convert_num</code> exceeds 1 while the length of <code>convert_class</code> equals 1 (only one integer),
each discretization will count the same number of levels (quantiles).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_famd.coord">FAMD.coord</code></td>
<td>
<p>a logical that must be set to TRUE when user decides to work with principal components of a factor analysis for mixed data (FAMD) instead of the set of raw covariates (FALSE is the default value).</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_famd.perc">FAMD.perc</code></td>
<td>
<p>a percent (between 0 and 1) linked to the <code>FAMD.coord</code> argument (0.8 is the default value). When this latter equals TRUE, this argument corresponds to the minimum part of variability that must be taken into account by the principal components of the FAMD method.
This option fixes the remaining number of principal components for the rest of the study.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_dist.choice">dist.choice</code></td>
<td>
<p>a character string (with quotes) corresponding to the distance function chosen between: the euclidean distance (&quot;E&quot;, by default), The Manhattan distance (&quot;M&quot;),
the Gower distance (&quot;G&quot;), the Hamming distance (&quot;H&quot;) for binary covariates only, and the Euclidean or Manhattan distance computed from principal components of a factor analysis of mixed data (&quot;FAMD&quot;). See (1) for details.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_percent.knn">percent.knn</code></td>
<td>
<p>the ratio of closest neighbors involved in the computations of the cost matrices. 1 is the default value that includes all rows in the computation.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_maxrelax">maxrelax</code></td>
<td>
<p>the maximum percentage of deviation from expected probability masses. It must be equal to 0 (default value) for the <code>OUTCOME</code> algorithm, and equal to a strictly positive value for the R-OUTCOME algorithm. See (2) for details.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_indiv.method">indiv.method</code></td>
<td>
<p>a character string indicating the chosen method to get individual predictions from the joint probabilities assessed, &quot;sequential&quot; by default, or &quot;optimal&quot;. See the <code>details</code> section and (2) for details.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_prox.dist">prox.dist</code></td>
<td>
<p>a probability (between 0 and 1) used to calculate the distance threshold below which an individual (a row) is considered as a neighbor of a given profile of covariates. When shared variables are all factors or categorical, it is suggested to keep this option to 0.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_solvr">solvR</code></td>
<td>
<p>a character string that specifies the type of method selected to solve the optimization algorithms. The default solver is &quot;glpk&quot;.</p>
</td></tr>
<tr><td><code id="OT_outcome_+3A_which.db">which.DB</code></td>
<td>
<p>a character string indicating the database to complete (&quot;BOTH&quot; by default, for the prediction of <code class="reqn">Y</code> and <code class="reqn">Z</code> in the two databases), &quot;A&quot; only for the imputation of <code class="reqn">Z</code> in A, &quot;B&quot; only for the imputation of <code class="reqn">Y</code> in B.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A. THE RECODING PROBLEM IN DATA FUSION
</p>
<p>Assuming that <code class="reqn">Y</code> and <code class="reqn">Z</code> are two target variables which refered to the same target population in two separate databases A and B respectively (no overlapping rows),
so that <code class="reqn">Y</code> and <code class="reqn">Z</code> are never jointly observed. Assuming also that A and B share a subset of common covariates <code class="reqn">X</code> of any types (same encodings in A and B)
completed or not. Merging these two databases often requires to solve a recoding problem by creating an unique database where
the missing information of <code class="reqn">Y</code> and <code class="reqn">Z</code> is fully completed.
</p>
<p>B. INFORMATIONS ABOUT THE ALGORITHM
</p>
<p>The algorithm integrated in the function <code>OT_outcome</code> provides a solution to the recoding problem previously described by proposing an
application of optimal transportation which aims is to search for a bijective mapping between the distributions of of <code class="reqn">Y</code> in A and <code class="reqn">Z</code> in B.
Mathematically, the principle of the algorithm is based on the resolution of an optimization problem which provides an optimal solution <code class="reqn">\gamma</code> (as called in the related articles)
that transfers the distribution of <code class="reqn">Y</code> in A to the distribution of <code class="reqn">Z</code> in B (or conversely, according to the sense of the transport)and can be so interpreted as an estimator of the joint distribution
<code class="reqn">(Y,Z)</code> in A (or B respetively). According to this result, a second step of the algorithm provides individual predictions of <code class="reqn">Y</code> in B (resp. of <code class="reqn">Z</code> in A, or both, depending on the choice
specified by user in the argument <code>which.DB</code>). Two possible approaches are available depending on the argument <code>indiv.method</code>:
</p>

<ul>
<li><p> When <code>indiv.method = "sequential"</code>, a nearest neighbor procedure is applied. This corresponds to the use of the function <code><a href="#topic+indiv_grp_closest">indiv_grp_closest</a></code>
implemented in the function <code>OT_outcome</code>.
</p>
</li>
<li><p> When <code>indiv.method = "optimal"</code>, a linear optimization problem is solved to determine the individual predictions that minimize the sum of the individual distances
in A (resp. in B) with the modalities of <code class="reqn">Z</code> in B (resp. <code class="reqn">Y</code> in A). This approach is applied via the function <code><a href="#topic+indiv_grp_optimal">indiv_grp_optimal</a></code> implemented in the function <code>OT_outcome</code>.
</p>
</li></ul>

<p>This algorithm supposes the respect of the two following assumptions:
</p>

<ol>
<li> <p><code class="reqn">Y</code> must follow the same distribution in A and B. In the same way, <code class="reqn">Z</code> follows the same distribution in the two databases.
</p>
</li>
<li><p> The conditional distribution <code class="reqn">(Y|X)</code> must be identical in A and B. Respectively, <code class="reqn">(Z|X)</code> is supposed identical in A and B.
</p>
</li></ol>

<p>Because the first assumption can be too strong in some situations, a relaxation of the constraints of marginal distribution is possible using the argument <code>maxrelax</code>.
When <code>indiv.method = "sequential"</code> and <code>maxrelax = 0</code>, the algorithm called <code>OUTCOME</code> (see (1) and (2))
is applied. In all other situations, the algorithm applied corresponds to an algorithm called <code>R_OUTCOME</code> (see (2)).
A posteriori estimates of conditional probabilities <code class="reqn">P[Y|X,Z]</code> and <code class="reqn">P[Z|X,Y]</code> are available for each profile of covariates (see the output objects <code>estimatorYB</code> and <code>estimatorZA</code>).
Estimates of <code class="reqn">\gamma</code> are also available according to the desired direction of the transport (from A to B and/or conversely. See <code class="reqn">\gamma_A</code> and <code class="reqn">\gamma_B</code>).
</p>
<p>C. EXPECTED STRUCTURE FOR THE INPUT DATABASE
</p>
<p>The input database is a data.frame that must be saved in a specific form by users:
</p>

<ul>
<li><p> Two overlayed databases containing a common column of database identifiers (A and B, 1 or 2, by examples, encoded in numeric or factor form)
</p>
</li>
<li><p> A column corresponding to the target variable with its specific encoding in A (For example a factor <code class="reqn">Y</code> encoded in <code class="reqn">n_Y</code> levels, ordered or not, with NAs in the corresponding rows of B)
</p>
</li>
<li><p> A column corresponding to the second target outcome with its specific endoded in B (For example a factor <code class="reqn">Z</code> in <code class="reqn">n_Z</code> levels, with NAs in rows of A)
</p>
</li>
<li><p> The order of the variables in the database have no importance but the column indexes related to the three columns previously described (ie ID, <code class="reqn">Y</code> and <code class="reqn">Z</code>) must be rigorously specified
in the argument <code>index_DB_Y_Z</code>.
</p>
</li>
<li><p> A set of shared common covariates (at least one but more is recommended) of any type, complete or not (provided that the number of covariates exceeds 1) is required.
</p>
</li></ul>

<p>The function <code><a href="#topic+merge_dbs">merge_dbs</a></code> is available in this package to assist user in the preparation of their databases, so please, do not hesitate to use it beforehand if necessary.
</p>
<p>Remarks about the target variables:
</p>

<ul>
<li><p> A target variable can be of categorical type, but also discrete, stored in factor, ordered or not. Nevertheless, notice that, if the variable is stored in numeric it will be automatically converted in ordered factors.
</p>
</li>
<li><p> If a target outcome is incomplete, the corresponding rows will be automatically dropped during the execution of the function.
</p>
</li></ul>

<p>The type of each variables (including <code class="reqn">ID</code>, <code class="reqn">Y</code> and <code class="reqn">Z</code>) of the database must be rigorously specified once, in one of the four arguments <code>quanti</code>,<code>nominal</code>, <code>ordinal</code> and <code>logic</code>.
</p>
<p>D. TRANSFORMATIONS OF CONTINUOUS COVARIATES
</p>
<p>The function <code>OT_outcome</code> integrates in its syntax a process dedicated to the categorization of continuous covariates. For this, it is necessary to rigorously fill in the arguments <code>convert.num</code> and <code>convert.class</code>.
The first one informs about the indexes in database of the continuous variables to transform in ordered factor while the second one specifies the corresponding number of desired balanced levels (for unbalanced levels, users must do transformations by themselves).
Therefore <code>convert.num</code> and <code>convert.class</code> must be vectors of same length, but if the length of <code>convert.num</code> exceeds 1, while the length of <code>convert.class</code> is 1, then, by default, all the covariates to convert will have the same number of classes,
that corresponds to the value specified in the argument <code>convert.class</code>.
Please notice that only covariates can be transformed (not outcomes) and missing informations are not taken into account for the transformations.
Moreover, all the indexes informed in the argument <code>convert.num</code> must also be informed in the argument <code>quanti</code>.
</p>
<p>E. INFORMATIONS ABOUT DISTANCE FUNCTIONS
</p>
<p>Each individual (or row) of a given database is here characterized by their covariates, so the distance between two individuals or groups of individuals depends on similarities between covariates
according to the distance function chosen by user (via the argument <code>dist.choice</code>). Actually four distance functions are implemented in <code>OT_outcome</code> to take into account the most frequently encountered situation (see (3)):
</p>

<ul>
<li><p> the Manhattan distance (&quot;M&quot;)
</p>
</li>
<li><p> the Euclidean distance (&quot;E&quot;)
</p>
</li>
<li><p> the Gower distance for mixed data (see (4): &quot;G&quot;)
</p>
</li>
<li><p> the Hamming distance for binary data (&quot;H&quot;)
</p>
</li></ul>

<p>Moreover, it is also possible to directly apply the first three distances mentioned on coordinates extracted from a multivariate analysis (Factor Analysis for Mixed Data, see (5)) applied on raw covariates using the arguments <code>FAMD.coord</code> and <code>FAMD.perc</code>.
This method is used (1).
</p>
<p>As a decision rule, for a given profile of covariates <code class="reqn">P_j</code>, an individual <code class="reqn">i</code> will be considered as a neighbor of <code class="reqn">P_j</code> if <code class="reqn">dist(i,P_j) &lt; \mbox{prox.dist} \times max(dist(i,P_j))</code> where <code class="reqn">prox.dist</code> must be fixed by user.
</p>
<p>F. INFORMATIONS ABOUT THE SOLVER
</p>
<p>The argument <code>solvR</code> permits user to choose the solver of the optimization algorithm. The default solver is &quot;glpk&quot; that corresponds to the GNU Linear Programming Kit (see (6) for more details).
Moreover, the function actually uses the <code>R</code> optimization infrastructure of the package <span class="pkg">ROI</span> which offers a wide choice of solver to users by easily loading the associated plugins of <span class="pkg">ROI</span> (see (7)).
</p>
<p>For more details about the algorithms integrated in <code>OT_outcome</code>, please consult (1) and (2).
</p>


<h3>Value</h3>

<p>A &quot;otres&quot; class object of 9 elements:
</p>
<table>
<tr><td><code>time_exe</code></td>
<td>
<p>the running time of the function</p>
</td></tr>
<tr><td><code>gamma_A</code></td>
<td>
<p>a matrix corresponding to an estimation of the joint distribution of <code class="reqn">(Y,Z)</code> in A</p>
</td></tr>
<tr><td><code>gamma_B</code></td>
<td>
<p>a matrix corresponding to an estimation of the joint distribution of <code class="reqn">(Y,Z)</code> in B</p>
</td></tr>
<tr><td><code>profile</code></td>
<td>
<p>a data.frame that gives all details about the remaining <code class="reqn">P</code> profiles of covariates. These informations can be linked to the <code>estimatorZA</code> and the <code>estimatorYB</code> objects for a better interpretation of the results.</p>
</td></tr>
<tr><td><code>res_prox</code></td>
<td>
<p>the outputs of the function <code>proxim_dist</code></p>
</td></tr>
<tr><td><code>estimatorZA</code></td>
<td>
<p>an array that corresponds to estimates of the probability distribution of <code class="reqn">Z</code> conditional to <code class="reqn">X</code> and <code class="reqn">Y</code> in database A. The number of rows of each table corresponds to the total number of profiles of covariates.
The first dimension of each table (rownames) correspond to the profiles of covariates sorted by order of appearance in the merged database. The second dimension of the array (columns of the tables) corresponds to the levels of <code class="reqn">Y</code> while the third element corresponds to the levels of <code class="reqn">Z</code>.</p>
</td></tr>
<tr><td><code>estimatorYB</code></td>
<td>
<p>an array that corresponds to estimates of the probability distribution of <code class="reqn">Y</code> conditional to <code class="reqn">X</code> and <code class="reqn">Z</code> in database B. The number of rows of each table corresponds to the total number of profiles of covariates.
The first dimension of each table (rownames) correspond to the profiles of covariates sorted by order of appearance in the merged database. The second dimension of the array (columns of the tables) corresponds to the levels of <code class="reqn">Z</code> while the third element corresponds to the levels of <code class="reqn">Y</code>.</p>
</td></tr>
<tr><td><code>DATA1_OT</code></td>
<td>
<p>the database A with the individual predictions of <code class="reqn">Z</code> using an optimal transportation algorithm (<code>OUTCOME</code>) or <code>R-OUTCOME</code></p>
</td></tr>
<tr><td><code>DATA2_OT</code></td>
<td>
<p>the database B with the individual predictions of <code class="reqn">Y</code> using an optimal transportation algorithm (<code>OUTCOME</code>) or <code>R-OUTCOME</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec, Valerie Gares, Jeremy Omer
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li>
<li><p> Anderberg, M.R. (1973), Cluster analysis for applications, 359 pp., Academic Press, New York, NY, USA.
</p>
</li>
<li><p> Gower J.C. (1971). A general coefficient of similarity and some of its properties. Biometrics, 27, 623–637.
</p>
</li>
<li><p> Pages J. (2004). Analyse factorielle de donnees mixtes. Revue Statistique Appliquee. LII (4). pp. 93-111.
</p>
</li>
<li><p> Makhorin A (2011). GNU Linear Programming Kit Reference Manual Version 4.47.<a href="http://www.gnu.org/software/glpk/">http://www.gnu.org/software/glpk/</a>
</p>
</li>
<li><p> Theussl S, Schwendinger F, Hornik K (2020). ROI: An Extensible R Optimization Infrastructure.Journal of Statistical Software,94(15), 1-64. doi: <a href="https://doi.org/10.18637/jss.v094.i15">10.18637/jss.v094.i15</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+transfo_dist">transfo_dist</a></code>,<code><a href="#topic+proxim_dist">proxim_dist</a></code>, <code><a href="#topic+avg_dist_closest">avg_dist_closest</a></code>, <code><a href="#topic+indiv_grp_closest">indiv_grp_closest</a></code>, <code><a href="#topic+indiv_grp_optimal">indiv_grp_optimal</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Using a sample of simu_data dataset
### Y and Z are a same variable encoded in 2 different forms:
### (3 levels for Y and 5 levels for Z)
#--------
data(simu_data)
simu_dat &lt;- simu_data[c(1:200, 301:500), ]

### An example of OUTCOME algorithm that uses:
#-----
# - A nearest neighbor procedure for the estimation of individual predictions
# - The Manhattan distance function
# - 90% of individuals from each modalities to calculate average distances
#   between individuals and modalities
# Predictions are assessed for Y in B and Z in A
#-----

OUTC1 &lt;- OT_outcome(simu_dat,
                    quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
                    dist.choice = "M", maxrelax = 0,
                    indiv.method = "sequential"
)
head(OUTC1$DATA1_OT) # Part of the completed database A
head(OUTC1$DATA2_OT) # Part of the completed database B

head(OUTC1$estimatorZA[, , 1])
# ... Corresponds to P[Z = 1|Y,P1] when P1 corresponds to the 1st profile of covariates (P_1)
# detailed in the 1st row of the profile object:
OUTC1$profile[1, ] # Details of P_1

# So estimatorZA[1,1,1]= 0.2 corresponds to an estimation of:
# P[Z = 1|Y=[20-40],Gender_2=0,Treatment_2=1,Treatment_3=0,Smoking_2=1,Dosage=3,Age=65.44]
# Thus, we can conclude that all individuals with the P_1 profile of covariates have
# 20% of chance to be affected to the 1st level of Z in database A.
# ... And so on, the reasoning is the same for the estimatorYB object.



### An example of OUTCOME algorithm with same conditions as the previous example, excepted that;
# - Only the individual predictions of Y in B are required
# - The continuous covariates "age" (related index = 8) will be converted in an ordinal factors
#   of 3 balanced classes (tertiles)
# - The Gower distance is now used
### -----

OUTC2_B &lt;- OT_outcome(simu_dat,
                      quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
                      dist.choice = "G", maxrelax = 0,
                      convert.num = 8, convert.class = 3,
                      indiv.method = "sequential", which.DB = "B"
)


### An example of OUTCOME algorithm with same conditions as the first example, excepted that;
# - Only the individual predictions of Z in A are required
# - The continuous covariates "age" (related index = 8) will be converted in an ordinal factors
#   of 3 balanced classes (tertiles)
# - Here, the Hamming distance can be applied because, after conversion, all covariates are factors.
#   Disjunctive tables of each covariates will be automatically used to work with a set of binary
#   variables.
### -----

OUTC3_B &lt;- OT_outcome(simu_data,
                      quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
                      dist.choice = "H", maxrelax = 0,
                      convert.num = 8, convert.class = 3,
                      indiv.method = "sequential", which.DB = "B"
)


### An example of R-OUTCOME algorithm using:
# - An optimization procedure for individual predictions on the 2 databases
# - The Manhattan distance
# - Raw covariates
### -----

R_OUTC1 &lt;- OT_outcome(simu_data,
                      quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
                      dist.choice = "M", maxrelax = 0,
                      indiv.method = "optimal"
)


### An example of R-OUTCOME algorithm with:
# - An optimization procedure for individual predictions on the 2 databases
# - The use of Euclidean distance on coordinates from FAMD
# - Raw covariates
### -----

R_OUTC2 &lt;- OT_outcome(simu_data,
                      quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
                      dist.choice = "E",
                      FAMD.coord = "YES", FAMD.perc = 0.8,
                      indiv.method = "optimal"
)


### An example of R-OUTCOME algorithm with relaxation on marginal distributions and:
# - An optimization procedure for individual predictions on the 2 databases
# - The use of the euclidean distance
# - An arbitrary coefficient of relaxation
# - Raw covariates
#-----

R_OUTC3 &lt;- OT_outcome(simu_data,
                      quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
                      dist.choice = "E", maxrelax = 0.4,
                      indiv.method = "optimal"
)


</code></pre>

<hr>
<h2 id='power_set'>power_set()</h2><span id='topic+power_set'></span>

<h3>Description</h3>

<p>A function that gives the power set <code class="reqn">P(S)</code> of any non empty set S.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_set(n, ordinal = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="power_set_+3A_n">n</code></td>
<td>
<p>an integer. The cardinal of the set</p>
</td></tr>
<tr><td><code id="power_set_+3A_ordinal">ordinal</code></td>
<td>
<p>a boolean. If TRUE the power set is only composed of subsets of consecutive elements, FALSE (by default) otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of <code class="reqn">2^n -1</code> subsets (The empty set is excluded)
</p>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>

<p>Devlin, Keith J (1979). Fundamentals of contemporary set theory. Universitext. Springer-Verlag
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Powerset of set of 4 elements
set1 &lt;- power_set(4)

# Powerset of set of 4 elements by only keeping
# subsets of consecutive elements
set2 &lt;- power_set(4, ordinal = TRUE)

</code></pre>

<hr>
<h2 id='proxim_dist'>proxim_dist()</h2><span id='topic+proxim_dist'></span>

<h3>Description</h3>

<p><code>proxim_dist</code> computes the pairwise distance matrix of a database and cross-distance matrix between two databases according to various distances used in the context of data fusion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proxim_dist(data_file, indx_DB_Y_Z = 1:3, norm = "E", prox = 0.3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="proxim_dist_+3A_data_file">data_file</code></td>
<td>
<p>a data.frame corresponding ideally to an output object of the function <code><a href="#topic+transfo_dist">transfo_dist</a></code>. Otherwise this data.frame is the result of two overlayed databases with a column of database identifier (&quot;A&quot; and &quot;B&quot;, 1 and 2, for example), a target variable (called <code class="reqn">Y</code> by example) only known in the first database, a target variable (<code class="reqn">Z</code>) only stored in the second database, such that <code class="reqn">Y</code> and <code class="reqn">Z</code> summarize a same information differently encoded in the two databases and set of common covariates (at least one) of any type.
The order of the variables in the data.frame have no importance. The type of the covariates must be in accordance with the chosen distance function in the <code>norm</code> option.</p>
</td></tr>
<tr><td><code id="proxim_dist_+3A_indx_db_y_z">indx_DB_Y_Z</code></td>
<td>
<p>a vector of three column indexes corresponding to the database identifier, the target variable of the above database and the target variable of the below database. The indexes must be declared in this specific order.</p>
</td></tr>
<tr><td><code id="proxim_dist_+3A_norm">norm</code></td>
<td>
<p>a character string indicating the choice of the distance function. This latest depends on the type of the common covariates: the Hamming distance
for binary covariates only (<code>norm</code> = &quot;H&quot;), the Manhattan distance (&quot;M&quot;, by default) and the euclidean distance (&quot;E&quot;) for continuous covariates only, or the Gower distance for mixed covariates (&quot;G&quot;).</p>
</td></tr>
<tr><td><code id="proxim_dist_+3A_prox">prox</code></td>
<td>
<p>a ratio (betwen 0 and 1) used to calculate the distance threshold below which an individual (a row or a given statistical unit) is considered as a neighbor of a given profile of covariates. 0.3 is the default value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is the first step of a family of algorithms that solve recoding problems of data fusion using optimal transportation theory (see the details of these corresponding models <code>OUTCOME</code>, <code>R_OUTCOME</code>, <code>JOINT</code> and <code>R_JOINT</code> in (1) and (2)).
The function <code>proxim_dist</code> is directly implemented in the functions <code><a href="#topic+OT_outcome">OT_outcome</a></code> and <code><a href="#topic+OT_joint">OT_joint</a></code> but can also be used separately as long as the input database has as suitable structure. Nevertheless, its preparation will have to be rigorously made in two steps detailled in the following sections.
</p>
<p>A. EXPECTED STRUCTURE FOR THE INPUT DATABASE
</p>
<p>Firsly, the initial database required is a data.frame that must be prepared in a specific form by users. From two separate databases, the function <code><a href="#topic+merge_dbs">merge_dbs</a></code> available in this package can assist users in this initial merging, nevertheless notice that this preliminary transformation can also be made directly by following the imposed structure described below:
two overlayed databases containing a common column of database identifiers (A and B for examples, encoded in numeric or factor form),
a column corresponding to the target variable with its specific encoding in A (for example a factor <code class="reqn">Y</code> encoded in <code class="reqn">n_Y</code> levels, ordered or not, with NAs in the corresponding rows of B), a column corresponding to the same variable with its specific endoded in B (for example a factor <code class="reqn">Z</code> in <code class="reqn">n_Z</code> levels,
with NAs in database A), and a set of shared covariates (at least one) between the two databases.
</p>
<p>The order of these variables in the database have no importance but the column indexes related to database identifier, <code class="reqn">Y</code> and <code class="reqn">Z</code>, must be specified in the <code>indx_DB_Y_Z</code> option.
Users can refer to the structure of the table <code><a href="#topic+simu_data">simu_data</a></code> available in the package to adapt their databases to the inital format required.
</p>
<p>Missing values are allowed on covariates only, and are excluded from all computations involving the rows within which they occur.
In the particular case where only one covariate with NAs is used, we recommend working with imputed or complete case only to avoid the presence of NA in the distance matrix that will be computed a posteriori.
If the database counts many covariates and some of them have missing data, user can keep them or apply beforehand the <code><a href="#topic+imput_cov">imput_cov</a></code> function on data.frame to deal with this problem.
</p>
<p>B. DISTANCE FUNCTIONS AND TYPES OF COVARIATES
</p>
<p>In a second step, the shared variables of the merged database will have to be encoded according to the choice of the distance function fixed by user, knowing that it is also frequent that it is the type of the variables which fixes the distance function to choose.
The function <code><a href="#topic+transfo_dist">transfo_dist</a></code> is available in the package to assist users in this task but a user can also decide to make this preparation by themselves.
Thus, with the Euclidean or Manhattan distance ((3), <code>norm</code> = &quot;E&quot; or &quot;M&quot;), if all types of variables are allowed, logical variables are transformed in binary variables, and categorical variables (factors ordered or not) are replaced by their related disjunctive tables (the function <code><a href="#topic+transfo_quali">transfo_quali</a></code> can make these specific transformations).
The Hamming distance (<code>norm</code> = &quot;H&quot;) only requires binary variables (all other forms are not allowed). In this context, continuous variables could have been converted in factor of k levels (<code class="reqn">k&gt;2</code>) beforehand. The categorical covariates are then transformed in disjunctive tables (containing the (<code class="reqn">k-1</code>) corresponding binary variables) before use. With this distance, categorical variables are also transformed in disjunctive tables.
Notice that, using the Hamming distance could be quite long in presence of NAs on covariates.
Finally, the Gower distance ((4), <code>norm</code> = &quot;G&quot;) uses the (<code><a href="StatMatch.html#topic+gower.dist">gower.dist</a></code>) function (5) and so allows logical, categorical and numeric variables without preliminary transformations.
</p>
<p>In conclusion, the structure of the data.frame required in input of the function <code>proxim_dist</code> corresponds to two overlayed databases with two target outcomes and a set of shared covariates whose encodings depend on the distance function choosen by user.
</p>
<p>If some columns are excluded when computing an Euclidean, Manhattan, or Hamming distance between two rows, the sum is scaled up proportionally to the number of columns used in the computation as proposed by the standard (<code><a href="stats.html#topic+dist">dist</a></code>) function.
If all pairs are excluded when computing a particular distance, instead of putting NA in the corresponding cell of the distance matrix, the process stops and an object listing the problematic rows is proposed in output.
It suggests users to remove these rows before running the process again or impute NAs related to these rows (see (6) for more details).
</p>
<p>C. PROFILES OF COVARIATES AND OUTPUT DETAILS
</p>
<p>Whatever the type (mixed or not) and the number of covariates in the data.frame of interest, the function <code>proxim_dist</code> firstly detects all the possible profiles (or combinations) of covariates from the two databases, and saves them in the output <code>profile</code>.
For example, assuming that a data.frame in input (composed of two overlayed data.frames A and B) have three shared binary covariates (identically encoded in A and B) so the sequences <code>011</code> and <code>101</code> will be considered as two distinct profiles of covariates.
If each covariate is a factor of <code class="reqn">n_1</code>, <code class="reqn">n_2</code> and <code class="reqn">n_3</code> levels respectively, so it exists at most <code class="reqn">n_1 \times n_2 \times n_3</code> possible profiles of covariates.
This number is considered as a maximum here because only the profiles of covariates met in at least one of the two databases will be kept for the study.
</p>
<p><code>proxim_dist</code> classifies individuals from the two databases according to their proximities to each profile of covariates and saves the corresponding indexes of rows from A and B in two lists <code>indXA</code> and <code>indXB</code> respectively.
<code>indXA</code> and <code>indXB</code> thus contain as many objects as covariates profiles and the proximity between a given profile and a given individual is defined as follows.
The function also provides in output the list of all the encountered profiles of covariates.
As a decision rule, for a given profile of covariates <code class="reqn">P_j</code>, an individual <code class="reqn">i</code> will be considered as a neighbor of <code class="reqn">P_j</code> if <code class="reqn">dist(i,P_j) &lt; prox \times max(dist(i,P_j))</code> where <code>prox</code> will be fixed by user.
Set the value 0 to the <code>prox</code> parameter assures that each individual of A (and B respectively) is exactly the profile of one profile of covariates. Therefore, it is not recommended in presence of continuous coavariates.
Conversely, assign the value 1 to <code>prox</code> is not recommended because it assumes that each individual is neighbor with all the encountered profiles of covariates.
</p>


<h3>Value</h3>

<p>A list of 16 elements (the first 16 detailed below) is returned containing various distance matrices and lists useful for the algorithms that used Optimal Transportation theory. Two more objects (the last two of the following list) will be returned if distance matrices contain NAs.
</p>
<table>
<tr><td><code>FILE_NAME</code></td>
<td>
<p>a simple reminder of the name of the raw database</p>
</td></tr>
<tr><td><code>nA</code></td>
<td>
<p>the number of rows of the first database (A)</p>
</td></tr>
<tr><td><code>nB</code></td>
<td>
<p>the number of rows of the second database (B)</p>
</td></tr>
<tr><td><code>Xobserv</code></td>
<td>
<p>the subset of the two overlayed databases composed of the shared variables only</p>
</td></tr>
<tr><td><code>profile</code></td>
<td>
<p>the different encountered profiles of covariates according to the data.frame</p>
</td></tr>
<tr><td><code>Yobserv</code></td>
<td>
<p>the numeric values of the target variable in the first database</p>
</td></tr>
<tr><td><code>Zobserv</code></td>
<td>
<p>the numeric values of the target variable in the second database</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>a distance matrix corresponding to the computed distances between individuals of the two databases</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the <code class="reqn">n_Y</code> levels of the target variable in numeric form, in the first database</p>
</td></tr>
<tr><td><code>Z</code></td>
<td>
<p>the <code class="reqn">n_Z</code> levels of the target variable in numeric form, in the second database</p>
</td></tr>
<tr><td><code>indY</code></td>
<td>
<p>a list of <code class="reqn">n_Y</code> groups of individual (or row) numbers where each group corresponds to the individuals indexes related to a given level of <code class="reqn">Y</code> in the first database</p>
</td></tr>
<tr><td><code>indZ</code></td>
<td>
<p>a list of <code class="reqn">n_Z</code> groups of individual (or row) numbers where each group corresponds to the individuals indexes related to a given level of <code class="reqn">Z</code> in the second database</p>
</td></tr>
<tr><td><code>indXA</code></td>
<td>
<p>a list of individual (row) indexes from the first database, sorted by profiles of covariates according to their proximities. See the <code>Details</code> part for more information</p>
</td></tr>
<tr><td><code>indXB</code></td>
<td>
<p>a list of individual (row) indexes from the second database, sorted by profiles of covariates according to their proximities. See the <code>Details</code> part for more information</p>
</td></tr>
<tr><td><code>DA</code></td>
<td>
<p>a distance matrix corresponding to the pairwise distances between individuals of the first database</p>
</td></tr>
<tr><td><code>DB</code></td>
<td>
<p>a distance matrix corresponding to the pairwise distances between individuals of the second database</p>
</td></tr>
<tr><td><code>ROWS_TABLE</code></td>
<td>
<p>combinations of row numbers of the two databases that generate NAs in D</p>
</td></tr>
<tr><td><code>ROWS_TO_RM</code></td>
<td>
<p>number of times a row of the first or second database is involved in the NA process of D</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec, Valerie Gares, Jeremy Omer
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li>
<li><p> Anderberg, M.R. (1973), Cluster analysis for applications, 359 pp., Academic Press, New York, NY, USA.
</p>
</li>
<li><p> Gower, J. C. (1971). A general coefficient of similarity and some of its properties. Biometrics, 27, 623&ndash;637.
</p>
</li>
<li><p> D'Orazio M. (2015). Integration and imputation of survey data in R: the StatMatch package. Romanian Statistical Review, vol. 63(2)
</p>
</li>
<li><p> Borg, I. and Groenen, P. (1997) Modern Multidimensional Scaling. Theory and Applications. Springer.
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+transfo_dist">transfo_dist</a></code>, <code><a href="#topic+imput_cov">imput_cov</a></code>, <code><a href="#topic+merge_dbs">merge_dbs</a></code>, <code><a href="#topic+simu_data">simu_data</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(simu_data)
### The covariates of the data are prepared according to the chosen distance
### using the transfo_dist function

### Ex 1: The Manhattan distance

man1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "M"
)
mat_man1 &lt;- proxim_dist(man1, norm = "M") # man1 compatible with norm = "E" for Euclidean


### Ex 2: The Euclidean and Manhattan distance applied on coordinates from FAMD

eucl_famd &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "FAMD", info = 0.80
)
mat_e_famd &lt;- proxim_dist(eucl_famd, norm = "E")


mat_m_famd &lt;- proxim_dist(eucl_famd, norm = "M")


### Ex 3: The Gower distance with mixed covariates

gow1 &lt;- transfo_dist(simu_data[c(1:100, 301:400), ],
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "G"
)
mat_gow1 &lt;- proxim_dist(gow1, norm = "G")


### Ex 4a: The Hamming distance with binary (but incomplete) covariates only

# categorization of the continuous covariates age by tertiles
ham1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  convert_num = 8, convert_class = 3, prep_choice = "H"
)
mat_ham1 &lt;- proxim_dist(ham1, norm = "H")
# Be patient ... It could take few minutes

### Ex 4b: The Hamming distance with complete cases on nominal and ordinal covariates only
simu_data_CC &lt;- simu_data[(!is.na(simu_data[, 5])) &amp; (!is.na(simu_data[, 6])) &amp;
  (!is.na(simu_data[, 7])), 1:7]
ham2 &lt;- transfo_dist(simu_data_CC,
  quanti = 3, nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  prep_choice = "H"
)
mat_ham2 &lt;- proxim_dist(ham2, norm = "H")


### Ex 5: PARTICULAR CASE, If only one covariate with no NAs

man2 &lt;- man1[, c(1:3, 7)] # Only Smoking variable
man2_nona &lt;- man2[!is.na(man2[, 4]), ] # Keep complete case
mat_man2_nona &lt;- proxim_dist(man2_nona, norm = "M", prox = 0.10)

mat_man2_nona_H &lt;- proxim_dist(man2_nona, norm = "H") # Hamming


### Ex 6: PARTICULAR CASE, many covariates but NAs in distance matrix

# We generated NAs in the man1 object so that:
# dist(A4,B102) and dist(A122,B102) returns NA whatever the norm chosen:
man1b &lt;- man1
man1b[4, 7:9] &lt;- NA
man1b[122, 6:9] &lt;- NA
man1b[300 + 102, 4:6] &lt;- NA
mat_man3 &lt;- proxim_dist(man1b, norm = "M")
# The process stopped indicates 2 NAs and the corresponding row numbers
# The 2nd output of mat_man3 indicates that removing first the 102th row of the database
# B is enough to solve the pb:
man1c &lt;- man1b[-402, ]
mat_man4 &lt;- proxim_dist(man1c, norm = "M")


</code></pre>

<hr>
<h2 id='select_pred'>select_pred()</h2><span id='topic+select_pred'></span>

<h3>Description</h3>

<p>Selection of a subset of non collinear predictors having relevant relationships with a given target outcome using a random forest procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>select_pred(
  databa,
  Y = NULL,
  Z = NULL,
  ID = 1,
  OUT = "Y",
  quanti = NULL,
  nominal = NULL,
  ordinal = NULL,
  logic = NULL,
  convert_num = NULL,
  convert_class = NULL,
  thresh_cat = 0.3,
  thresh_num = 0.7,
  thresh_Y = 0.2,
  RF = TRUE,
  RF_ntree = 500,
  RF_condi = FALSE,
  RF_condi_thr = 0.2,
  RF_SEED = sample(1:1e+06, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="select_pred_+3A_databa">databa</code></td>
<td>
<p>a data.frame with a column of identifiers (of row or of database in the case of two concatened databases), an outcome, and a set of predictors. The number of columns can exceed the number of rows.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_y">Y</code></td>
<td>
<p>the label of a first target variable with quotes</p>
</td></tr>
<tr><td><code id="select_pred_+3A_z">Z</code></td>
<td>
<p>the label of a second target variable with quotes when <code>databa</code> is the result of two overlayed databases.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_id">ID</code></td>
<td>
<p>the column index of the database identifier (The first column by default) in the case of two concatened databases, a row identifier otherwise</p>
</td></tr>
<tr><td><code id="select_pred_+3A_out">OUT</code></td>
<td>
<p>a character that indicates the outcome to predict in the context of overlayed databases. By default, the outcome declared in the argument <code>Y</code> is predicted. Another possible outcome to predict can be set with the related argument <code>Z</code>.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_quanti">quanti</code></td>
<td>
<p>a vector of integers corresponding to the column indexes of all the numeric predictors.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_nominal">nominal</code></td>
<td>
<p>a vector of integers which corresponds to the column indexes of all the categorical nominal predictors.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_ordinal">ordinal</code></td>
<td>
<p>a vector of integers which corresponds to the column indexes of all the categorical ordinal predictors.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_logic">logic</code></td>
<td>
<p>a vector of integers indicating the indexes of logical predictors. No index remained by default</p>
</td></tr>
<tr><td><code id="select_pred_+3A_convert_num">convert_num</code></td>
<td>
<p>a vector of integers indicating the indexes of quantitative variables to convert in ordered factors. No index remained by default. Each index selected has to be defined as quantitative in the argument <code>quanti</code>.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_convert_class">convert_class</code></td>
<td>
<p>a vector of integers indicating the number of classes related to each transformation of quantitative variable in ordered factor. The length of this vector can not exceed the length of the argument <code>convert_num</code>. Nevertheless, if length(<code>convert_num</code>) &gt; 1 and length(<code>convert_class</code>) = 1,
all quantitative predictors selected for discretization will have by default the same number of classes.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_thresh_cat">thresh_cat</code></td>
<td>
<p>a threshold associated to the Cramer's V coefficient (= 0.30 by default)</p>
</td></tr>
<tr><td><code id="select_pred_+3A_thresh_num">thresh_num</code></td>
<td>
<p>a threshold associated to the Spearman's coefficient of correlation (= 0.70 by default)</p>
</td></tr>
<tr><td><code id="select_pred_+3A_thresh_y">thresh_Y</code></td>
<td>
<p>a threshold linked to the RF approach, that corresponds to the minimal cumulative percent of importance measure required to be kept in the final list of predictors.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_rf">RF</code></td>
<td>
<p>a boolean sets to TRUE (default) if a random forest procedure must be applied to select the best subset of predictors according to the outcome.Otherwise, only pairwise associations between predictors are used for the selection.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_rf_ntree">RF_ntree</code></td>
<td>
<p>the number of bootsrap samples required from the row datasource during the random forest procedure</p>
</td></tr>
<tr><td><code id="select_pred_+3A_rf_condi">RF_condi</code></td>
<td>
<p>a boolean specifying if the conditional importance measures must be assessed from the random forest procedure (<code>TRUE</code>) rather than the standard variable importance  measures (<code>FALSE</code> by default)</p>
</td></tr>
<tr><td><code id="select_pred_+3A_rf_condi_thr">RF_condi_thr</code></td>
<td>
<p>a threshold linked to (1 - pvalue) of an association test between each predictor <code class="reqn">X</code> and the other variables, given that a threshold value of zero will include all variables in the computation of the conditional importance measure of <code class="reqn">X</code> (0.20 is the default value).
Conversely, a larger threshold will only keeps the subset of variables that is strongly correlated to <code class="reqn">X</code> for the computation of the variable importance measure of <code class="reqn">X</code>.</p>
</td></tr>
<tr><td><code id="select_pred_+3A_rf_seed">RF_SEED</code></td>
<td>
<p>an integer used as argument by the set.seed() for offsetting the random number generator (random integer by default). This value is only used for RF method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>select_pred</code> function provides several tools to identify, on the one hand, the relationships between predictors, by detecting especially potential problems of collinearity, and, on the other hand, proposes a parcimonious subset of relevant predictors (of the outcome) using appropriate random forest procedures.
The function which can be used as a preliminary step of prediction in regression areas is particularly adapted to the context of data fusion by providing relevant subsets of predictors (the matching variables) to algorithms dedicated to the solving of recoding problems.
</p>
<p>A. REQUIRED STRUCTURE FOR THE DATABASE
</p>
<p>The expected input database is a data.frame that especially requires a specific column of row identifier and a target variable (or outcome) having a finite number of values or classes (ordinal, nominal or discrete type). Notice that if the chosen outcome is in numeric form, it will be automatically converted in ordinal type.
The number of predictors is not a constraint for <code>select_pred</code> (even if, with less than three variables a process of variables selection has no real sense...), and can exceed the number of rows (no problem of high dimensionality here).
The predictors can be continuous (quantitative), boolean, nominal or ordinal with or without missing values.
In presence of numeric variables, users can decide to discretize them or a part of them by themselves beforehand. They can also choose to use the internal process directly integrated in the function. Indeed, to assist users in this task, two arguments called <code>convert_num</code> and <code>convert_class</code> dedicated to these transformations are available in input of the function.
These options make the function <code>select_pred</code> particularly adapted to the function <code><a href="#topic+OT_joint">OT_joint</a></code> which only allows data.frame with categorical covariates.
With the argument <code>convert_num</code>, users choose the continuous variables to convert and the related argument <code>convert_class</code> specifies the corresponding number of classes chosen for each discretization.
It is the reason why these two arguments must be two vectors of indexes of same length. Nevertheless, an unique exception exists when <code>convert_class</code> is equalled to a scalar <code class="reqn">S</code>. In this case, all the continuous predictors selected for conversion will be discretized with a same number of classes S.
By example, if <code>convert_class = 4</code>, all the continuous variables specified in the <code>convert_num</code> argument will be discretized by quartiles. Moreover, notice that missing values from incomplete predictors to convert are not taken into account during the conversion, and that each predictor specified in the argument <code>convert_num</code>
must be also specified in the argument <code>quanti</code>.
In this situation, the label of the outcome must be entered in the argument <code>Y</code>, and the arguments <code>Z</code> and <code>OUT</code> must keep their default values.
Finally, the order of the column indexes related to the identifier and the outcome have no importance.
</p>
<p>For a better flexibility, the input database can also be the result of two overlayed databases.
In this case, the structure of the database must be similar to those observed in the datasets <code><a href="#topic+simu_data">simu_data</a></code> and <code><a href="#topic+tab_test">tab_test</a></code> available in the package with a column of database identifier, one target outcome by database (2 columns), and a subset of shared predictors.
Notice that, overlaying two separate databases can also be done easily using the function <code><a href="#topic+merge_dbs">merge_dbs</a></code> beforehand.
The labels of the two outcomes will have to be specified in the arguments <code>Y</code> for the top database, and in <code>Z</code> for the bottom one.
Notice also that the function <code>select_pred</code> deals with only one outcome at a time that will have to be specified in the argument <code>OUT</code> which must be equalled to &quot;Y&quot; for the study of the top database or &quot;Z&quot; for the study of the bottom one.
</p>
<p>Finally, whatever the structure of the database declared in input, each column index related to the database variable must be entered once (and only once) in one of the following four arguments: <code>quanti</code>, <code>nominal</code>, <code>ordinal</code>, <code>logic</code>.
</p>
<p>B. PAIRWISE ASSOCIATIONS BETWEEN PREDICTORS
</p>
<p>In a first step of process, <code>select_pred</code> calculates standard pairwise associations between predictors according to their types.
</p>

<ol>
<li><p>Between categorical predictors (ordinal, nominal and logical):
Cramer's V (and Bias-corrected Cramer's V, see (1) for more details) are calculated between categorical predictors and the argument <code>thres_cat</code> fixed the associated threshold beyond which two predictors can be considered as redundant.
A similar process is done between the target variable and the subset of categorical variables which provides in output a first table ranking the top scoring predictors. This table summarizes the ability of each variable to predict the target outcome.
</p>
</li>
<li><p>Between continuous predictors:
If the <code>ordinal</code> and <code>logic</code> arguments differ from NULL, all the corresponding predictors are beforehand converted in rank values.
For numeric (quantitative), logical and ordinal predictors, pairwise correlations between ranks (Spearman) are calculated and the argument <code>thresh_num</code> fixed the related threshold beyond which two predictors can be considered as redundant.
A similar process is done between the outcome and the subset of discrete variables which provides in output, a table ranking the top scoring predictor variates which summarizes their abilities to predict the target.
In addition, the result of a Farrar and Glauber test is provided. This test is based on the determinant of the correlation matrix of covariates and the related null hypothesis of the test corresponds to an absence of collinearity between them (see (2) for more details about the method).
In presence of a large number of numeric covariates and/or ordered factors, the approximate Farrar-Glauber test, based on the normal approximation of the null distribution is more adapted and its result is also provided in output.
These two tests are highly sensitive and, by consequence, it suggested to consider these results as simple indicators of collinearity between predictors rather than an essential condition of acceptability.
</p>
</li></ol>

<p>If the initial number of predictors is not too important, these informations can be sufficient to the user for the visualization of potential problems of collinearity and for the selection of a subset of predictors (<code>RF = FALSE</code>).
It is nevertheless often necessary to complete this visualization by an automatical process of selection like the Random Forest approach (see Breiman 2001, for a better understanding of the method) linked to the function <code>select_pred</code> (<code>RF = TRUE</code>).
</p>
<p>C. RANDOM FOREST PROCEDURE
</p>
<p>As a final step of the process, a random forest approach (RF(3)) is here prefered (to regression models) for two main reasons: RF methods allow notably the number of variables to exceed the number of rows and remain applicable whatever the types of covariates considered.
The function <code>select_pred</code> integrates in its algorithm the functions <code><a href="party.html#topic+cforest">cforest</a></code> and <code><a href="party.html#topic+varimp">varimp</a></code> of the package <span class="pkg">party</span> (Hothorn, 2006) and so gives access to their main arguments.
</p>
<p>A RF approach generally provides two types of measures for estimating the mean variable importance of each covariate in the prediction of an outcome: the Gini importance and the permutation importance. These measurements must be used with caution, by taking into account the following constraints:
</p>

<ol>
<li><p>The Gini importance criterion can produce bias in favor of continuous variables and variables with many categories. To avoid this problem, only the permutation criterion is available in the function.
</p>
</li>
<li><p>The permutation importance criterion can overestimate the importance of highly correlated predictors.
</p>
</li></ol>

<p>The function <code>select_pred</code> proposes three different scenarios according to the types of predictors:
</p>

<ol>
<li><p>The first one consists in boiling down to a set of categorical variables (ordered or not) by discretizing all the continuous predictors beforehand, using the internal <code>convert_num</code> argument or another one, and then works with the conditional importance measures (<code>RF_condi = TRUE</code>) which give unbiased estimations.
In the spirit of a partial correlation, the conditional importance measure related to a variable <code class="reqn">X</code> for the prediction of an outcome <code class="reqn">Y</code>, only uses the subset of variables the most correlated to <code class="reqn">X</code> for its computation. The argument <code>RF_condi_thr</code> that corresponds exactly to the argument <code>threshold</code> of the function <code><a href="party.html#topic+varimp">varimp</a></code>,
fixes a ratio below which a variable Z is considered sufficiently correlated to <code class="reqn">X</code> to be used as an adjustment variable in the computation of the importance measure of <code class="reqn">X</code> (In other words, Z is included in the conditioning for the computation, see (4) and (5) for more details). A threshold value of zero will include all variables in the computation of
conditional importance measure of each predictor <code class="reqn">X</code>, while a threshold <code class="reqn">&lt; 1</code>, will only include a subset of variables.
Two remarks related to this method: firstly, notice that taking into account only subsets of predictors in the computation of the variable importance measures could lead to a relevant saving of execution time.
Secondly, because this approach does not take into account incomplete information, the method will only be applied to complete data (incomplete rows will be temporarily removed for the study).
</p>
</li>
<li><p>The second possibility, always in presence of mixed types predictors, consists in the execution of two successive RF procedures. The first one will be used to select an unique candidate in each susbset of correlated predictors (detecting in the 1st section), while the second one will extract the permutation measures from the remaining subset
of uncorrelated predictors (<code>RF_condi = FALSE</code>, by default). This second possibility has the advantage to work in presence of incomplete predictors.
</p>
</li>
<li><p>The third scenario consists in running a first time the function without RF process (<code>RF = FALSE</code>), and according to the presence of highly correlated predictors or not, users can choose to extract redundant predictors manually and re-runs the function with the subset of remaining non-collinear predictors to avoid potential biases introduced by the standard permutations measures.
</p>
</li></ol>

<p>The three scenarios finally lead to a list of uncorrelated predictors of the outcome sorted in importance order. The argument <code>thresh_Y</code> corresponds to the minimal percent of importance required (and fixed by user) for a variable to be considered as a reliable predictor of the outcome.
Finally, because all random forest results are subjects to random variation, users can check whether the same importance ranking is achieved by varying the random seed parameter (<code>RF_SEED</code>) or by increasing the number of trees (<code>RF_ntree</code>).
</p>


<h3>Value</h3>

<p>A list of 14 (if <code>RF = TRUE</code>) or 11 objects (Only the first ten objects if <code>RF = FALSE</code>) is returned:
</p>
<table>
<tr><td><code>seed</code></td>
<td>
<p>the random number generator related to the study</p>
</td></tr>
<tr><td><code>outc</code></td>
<td>
<p>the identifier of the outcome to predict</p>
</td></tr>
<tr><td><code>thresh</code></td>
<td>
<p>a summarize of the different thresholds fixed for the study</p>
</td></tr>
<tr><td><code>convert_num</code></td>
<td>
<p>the labels of the continuous predictors transformed in categorical form</p>
</td></tr>
<tr><td><code>DB_USED</code></td>
<td>
<p>the final database used after potential transformations of predictors</p>
</td></tr>
<tr><td><code>vcrm_OUTC_cat</code></td>
<td>
<p>a table of pairwise associations between the outcome and the categorical predictors (Cramer's V)</p>
</td></tr>
<tr><td><code>cor_OUTC_num</code></td>
<td>
<p>a table of pairwise associations between the outcome and the continuous predictors (Rank correlation)</p>
</td></tr>
<tr><td><code>vcrm_X_cat</code></td>
<td>
<p>a table of pairwise associations between the categorical predictors (Cramer's V)</p>
</td></tr>
<tr><td><code>cor_X_num</code></td>
<td>
<p>a table of pairwise associations between the continuous predictors (Cramer's V)</p>
</td></tr>
<tr><td><code>FG_test</code></td>
<td>
<p>the results of the Farrar and Glauber tests, with and without approximation form</p>
</td></tr>
<tr><td><code>collinear_PB</code></td>
<td>
<p>a table of predictors with problem of collinearity according to the fixed thresholds</p>
</td></tr>
<tr><td><code>drop_var</code></td>
<td>
<p>the labels of predictors to drop after RF process (optional output: only if <code>RF</code>=TRUE)</p>
</td></tr>
<tr><td><code>RF_PRED</code></td>
<td>
<p>the table of variable importance measurements, conditional or not, according to the argument <code>condi_RF</code> (optional output: Only if <code>RF</code>=TRUE)</p>
</td></tr>
<tr><td><code>RF_best</code></td>
<td>
<p>the labels of the best predictors selected (optional output: Only if <code>RF</code>=TRUE) according to the value of the argument <code>thresh_Y</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:gregory.guernec@inserm.fr">gregory.guernec@inserm.fr</a>
</p>


<h3>References</h3>


<ol>
<li><p> Bergsma W. (2013). A bias-correction for Cramer's V and Tschuprow's T. Journal of the Korean Statistical Society, 42, 323–328.
</p>
</li>
<li><p> Farrar D, and Glauber R. (1968). Multicolinearity in regression analysis. Review of Economics and Statistics, 49, 92–107.
</p>
</li>
<li><p> Breiman L. (2001). Random Forests. Machine Learning, 45(1), 5–32.
</p>
</li>
<li><p> Hothorn T, Buehlmann P, Dudoit S, Molinaro A, Van Der Laan M (2006). “Survival Ensembles.” Biostatistics, 7(3), 355–373.
</p>
</li>
<li><p> Strobl C, Boulesteix A-L, Kneib T, Augustin T, Zeileis A (2008). Conditional Variable Importance for Random Forests. BMC Bioinformatics, 9, 307. <a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-307">https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-307</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+simu_data">simu_data</a></code>, <code><a href="#topic+tab_test">tab_test</a></code>, <code><a href="#topic+OT_joint">OT_joint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example 1
#-----
# - From two overlayed databases: using the table simu_data
# - Searching for the best predictors of "Yb1"
# - Using the row database
# - The RF approaches are not required
#-----

data(simu_data)
sel_ex1 &lt;- select_pred(simu_data,
  Y = "Yb1", Z = "Yb2", ID = 1, OUT = "Y",
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  thresh_cat = 0.30, thresh_num = 0.70, thresh_Y = 0.20,
  RF = FALSE
)

### Example 2
#-----
# - With same conditions as example 1
# - Searching for the best predictors of "Yb2"
#-----

sel_ex2 &lt;- select_pred(simu_data,
  Y = "Yb1", Z = "Yb2", ID = 1, OUT = "Z",
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  thresh_cat = 0.30, thresh_num = 0.70, thresh_Y = 0.20,
  RF = FALSE
)


### Example 3
#-----
# - With same conditions as example 1
# - Using a RF approach to estimate the standard variable importance measures
#   and determine the best subset of predictors
# - Here a seed is required
#-----

sel_ex3 &lt;- select_pred(simu_data,
  Y = "Yb1", Z = "Yb2", ID = 1, OUT = "Y",
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  thresh_cat = 0.30, thresh_num = 0.70, thresh_Y = 0.20,
  RF = TRUE, RF_condi = FALSE, RF_SEED = 3023
)

### Example 4
#-----
# - With same conditions as example 1
# - Using a RF approach to estimate the conditional variable importance measures
#   and determine the best subset of predictors
# - This approach requires to convert the numeric variables: Only "Age" here
#   discretized in 3 levels
#-----

sel_ex4 &lt;- select_pred(simu_data,
  Y = "Yb1", Z = "Yb2", ID = 1, OUT = "Z",
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  convert_num = 8, convert_class = 3,
  thresh_cat = 0.30, thresh_num = 0.70, thresh_Y = 0.20,
  RF = TRUE, RF_condi = TRUE, RF_condi_thr = 0.60, RF_SEED = 3023
)

### Example 5
#-----
# - Starting with a unique database
# - Same conditions as example 1
#-----
simu_A &lt;- simu_data[simu_data$DB == "A", -3] # Base A

sel_ex5 &lt;- select_pred(simu_A,
  Y = "Yb1",
  quanti = 7, nominal = c(1, 3:4, 6), ordinal = c(2, 5),
  thresh_cat = 0.30, thresh_num = 0.70, thresh_Y = 0.20,
  RF = FALSE
)

### Example 6
#-----
# - Starting with an unique database
# - Using a RF approach to estimate the conditional variable importance measures
#   and determine the best subset of predictors
# - This approach requires to convert the numeric variables: Only "Age" here
#   discretized in 3 levels
#-----

simu_B &lt;- simu_data[simu_data$DB == "B", -2] # Base B

sel_ex6 &lt;- select_pred(simu_B,
  Y = "Yb2",
  quanti = 7, nominal = c(1, 3:4, 6), ordinal = c(2, 5),
  convert_num = 7, convert_class = 3,
  thresh_cat = 0.30, thresh_num = 0.70, thresh_Y = 0.20,
  RF = TRUE, RF_condi = TRUE, RF_condi_thr = 0.60, RF_SEED = 3023
)


</code></pre>

<hr>
<h2 id='simu_data'>A simulated dataset to test the functions of the OTrecod package</h2><span id='topic+simu_data'></span>

<h3>Description</h3>

<p>The first 300 rows belong to the database A, while the next 400 rows belong to the database B.
Five covariates: <code>Gender</code>, <code>Treatment</code>, <code>Dosage</code>, <code>Smoking</code> and <code>Age</code> are
common to both databases (same encodings). <code>Gender</code> is the only complete covariate.
The variables <code>Yb1</code> and <code>Yb2</code> are the target variables of A and B respectively, summarizing a same information encoded in two different scales.
that summarize a same information saved in two distinct encodings, that is why, <code>Yb1</code> is
missing in the database B and <code>Yb2</code> is missing in the database A.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simu_data
</code></pre>


<h3>Format</h3>

<p>A data.frame made of 2 overlayed databases (A and B) with 700 observations on the following 8 variables.
</p>

<dl>
<dt>DB</dt><dd><p>the database identifier, a character with 2 possible classes: <code>A</code> or <code>B</code></p>
</dd>
<dt>Yb1</dt><dd><p>the target variable of the database A, stored as factor and encoded in 3 ordered levels: <code>[20-40]</code>, <code>[40-60[</code>,<code>[60-80]</code> (the values related to the database B are missing)</p>
</dd>
<dt>Yb2</dt><dd><p>the target variable of the database B, stored as integer (an unknown scale from 1 to 5) in the database B (the values related to A are missing)</p>
</dd>
<dt>Gender</dt><dd><p>a factor with 2 levels (<code>Female</code> or <code>Male</code>) and no missing values</p>
</dd>
<dt>Treatment</dt><dd><p>a covariate of 3 classes stored as a character with 2% of missing values: <code>Placebo</code>, <code>Trt A</code>, <code>Trt B</code></p>
</dd>
<dt>Dosage</dt><dd><p>a factor with 4 levels and 5% of missing values: from <code>Dos 1</code> to <code>dos 4</code></p>
</dd>
<dt>Smoking</dt><dd><p>a covariate of 2 classes stored as a character and 10% of missing values: <code>NO</code> for non smoker, <code>YES</code> otherwise</p>
</dd>
<dt>Age</dt><dd><p>a numeric corresponding to the age of participants in years. This variable counts 5% of missing values</p>
</dd>
</dl>



<h3>Details</h3>

<p>The purpose of the functions contained in this package is to predict the missing information on <code>Yb1</code> and <code>Yb2</code>
in database A and database B using the Optimal Transportation Theory.
</p>
<p>Missing information has been simulated to some covariates following a simple MCAR process.
</p>


<h3>Source</h3>

<p>randomly generated
</p>

<hr>
<h2 id='tab_test'>A simulated dataset to test the library</h2><span id='topic+tab_test'></span>

<h3>Description</h3>

<p>A dataset of 10000 rows containing 3 covariables and 2 outcomes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tab_test
</code></pre>


<h3>Format</h3>

<p>A data frame with 5000 rows and 6 variables:
</p>

<dl>
<dt>ident</dt><dd><p>identifier, 1 or 2</p>
</dd>
<dt>Y1</dt><dd><p>outcome 1 with 2 levels, observed for ident=1 and unobserved for ident=2</p>
</dd>
<dt>Y2</dt><dd><p>outcome 2 with 4 levels, observed for ident=2 and unobserved for ident=1</p>
</dd>
<dt>X1</dt><dd><p>covariate 1, integer</p>
</dd>
<dt>X2</dt><dd><p>covariate 2, integer</p>
</dd>
<dt>X3</dt><dd><p>covariate 3, integer</p>
</dd>
</dl>



<h3>Source</h3>

<p>randomly generated
</p>

<hr>
<h2 id='transfo_dist'>transfo_dist()</h2><span id='topic+transfo_dist'></span>

<h3>Description</h3>

<p>This function prepares an overlayed database for data fusion according to the distance function chosen to evaluate the proximities between units.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfo_dist(
  DB,
  index_DB_Y_Z = 1:3,
  quanti = NULL,
  nominal = NULL,
  ordinal = NULL,
  logic = NULL,
  convert_num = NULL,
  convert_class = NULL,
  prep_choice = "E",
  info = 0.8
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transfo_dist_+3A_db">DB</code></td>
<td>
<p>a data.frame composed of exactly two overlayed databases with a column of database identifier, two columns corresponding to a same information
differently encoded in the two databases and covariates. The order of the variables have no importance.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_index_db_y_z">index_DB_Y_Z</code></td>
<td>
<p>a vector of exactly three integers. The first integer must correspond to the column index of the database identifier. The second integer corresponds
to the index of the target variable in the first database while the third integer corresponds to the index of column related to the target variable in the second database.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_quanti">quanti</code></td>
<td>
<p>the column indexes of all the quantitative variables (database identificatier and target variables included) stored in a vector.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_nominal">nominal</code></td>
<td>
<p>the column indexes of all the nominal (not ordered) variables (DB identification and target variables included) stored in a vector.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_ordinal">ordinal</code></td>
<td>
<p>the column indexes of all the ordinal variables (DB identification and target variables included) stored in a vector.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_logic">logic</code></td>
<td>
<p>the column indexes of all the boolean variables stored in a vector.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_convert_num">convert_num</code></td>
<td>
<p>the column indexes of the continuous (quantitative) variables to convert in ordered factors. All indexes declared in this argument must have been declared in the argument <code>quanti</code> (no conversion by default).</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_convert_class">convert_class</code></td>
<td>
<p>according to the argument <code>convert_num</code>, a vector indicating for each continuous variable to convert the corresponding desired number of levels. If the length of the argument <code>convert_num</code> exceeds 1 while the length of <code>convert_class</code> is equal to 1 (only one integer),
each discretization will count the same number of levels.</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_prep_choice">prep_choice</code></td>
<td>
<p>a character string corresponding to the distance function chosen between: the euclidean distance (&quot;E&quot;, by default), the Manhattan distance (&quot;M&quot;),
the Gower distance (&quot;G&quot;), the Hamming (also called binary) distance (&quot;H&quot;), and a distance computed from principal components of a factor analysis of mixed data (&quot;FAMD&quot;).</p>
</td></tr>
<tr><td><code id="transfo_dist_+3A_info">info</code></td>
<td>
<p>a ratio (between 0 and 1, 0.8 is the default value) that corresponds to the minimal part of variability that must be taken into account by the remaining principal components of the FAMD when this approach is required.
This ratio will fix the number of components that will be kept with this approach. When the argument is set to 1, all the variability is considered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A. EXPECTED STRUCTURE FOR THE INPUT DATABASE
</p>
<p>In input of this function, the expected database is the result of an overlay between two databases A and B.
This structure can be guaranteed using the specific outputs of the functions <code><a href="#topic+merge_dbs">merge_dbs</a></code> or <code><a href="#topic+select_pred">select_pred</a></code>.
Nevertheless, it is also possible to apply directly the function <code>transfo_dist</code> on a raw database provided that a specific structure is respected in input.
The overlayed database (A placed on top of B) must count at least four columns (in an a unspecified order of appearance in the database):
</p>

<ul>
<li><p> A column indicating the database identifier (two classes or levels if factor: A and B, 1 and 2, ...)
</p>
</li>
<li><p> A column dedicated to the outcome (or target variable) of the first database and denoted <code class="reqn">Y</code> for example. This variable can be of categorical (nominal or ordinal factor) or continuous type. Nevertheless, in this last case, a warning will appear and the variable will be automatically converted in ordered factors as a prerequisite format of the database before using data fusion algorithms.
</p>
</li>
<li><p> A column dedicated to the outcome (or target variable) of the second database and denoted <code class="reqn">Z</code> for example. As before, this variable can be of categorical (nominal or ordinal factor) or continuous type, and the variable will be automatically converted in ordered factors as a prerequisite format of the database before using data fusion algorithms.
</p>
</li>
<li><p> At least one shared variable (same encoding in the two databases). Incomplete information is possible on shared covariates only with more than one shared covariate in the final database.
</p>
</li></ul>

<p>In this context, the two databases are overlayed and the information related to <code class="reqn">Y</code> in the second database must be missing as well as the information related to <code class="reqn">Z</code> in the first one.
The column indexes related to the database identifier, <code class="reqn">Y</code> and <code class="reqn">Z</code> must be specified in this order in the argument <code>index_DB_Y_Z</code>.
Moreover, all column indexes (including those related to identifier and target variables <code class="reqn">Y</code> and <code class="reqn">Z</code>) of the overlayed database (DB) must be declared once (and only once), among the arguments <code>quanti</code>, <code>nominal</code>, <code>ordinal</code>, and <code>logic</code>.
</p>
<p>B. TRANSFORMATIONS OF CONTINUOUS COVARIATES
</p>
<p>Because some algorithms dedicated to solving recoding problems like <code>JOINT</code> and <code>R-JOINT</code> (see (1) and/or the documentation of <code><a href="#topic+OT_joint">OT_joint</a></code>) requires the use of no continuous covariates, the function <code>transfo_dist</code> integrates in is syntax
a process dedicated to the categorization of continuous variables. For this, it is necessary to rigorously fill in the arguments <code>convert_num</code> and <code>convert_class</code>. The first one specifies the indexes of continuous variables to transform
in ordered factors while the second one assigns the corresponding desired number of levels.
Only covariates should be transformed (not outcomes) and missing informations are not taken into account for the transformations.
Notice that all the indexes informed in the argument <code>convert_num</code> must also be informed in the argument <code>quanti</code>.
</p>
<p>C. TRANSFORMATIONS ON THE DATABASE ACCORDING TO THE CHOSEN DISTANCE FUNCTION
</p>
<p>These necessary transformations are related to the type of each covariate.
It depends on the distance function chosen by user in the <code>prep_choice</code> argument.
</p>
<p>1. For the Euclidean (&quot;E&quot;) and Manhattan (&quot;M&quot;) distances (see (2) and (3)):
all the remaining continuous variables are standardized.
The related recoding to a boolean variable is 1 for <code>TRUE</code> and 0 for <code>FALSE</code>.
The recoding of a nominal variable of k classes corresponds to its related disjunctive table (of (k-1) binary variables)).
The ordinal variables are all converted to numeric variables (please take care that the order of the classes of each of these variables is well specified at the beginning).
</p>
<p>2. For the Hamming (&quot;H&quot;) distance (see (2) and (3)):
all the continuous variables must be transformed beforehand in categorical forms using the internal process described in section B or via another external approach.
The boolean variables are all converted in ordinal forms and then turned into binaries.
The recoding for nominal or ordinal variable of k classes corresponds to its related disjunctive table (i.e (k-1) binary variables)).
</p>
<p>3. For the Gower (&quot;G&quot;) distance (see (4)):
all covariates remain unchanged
</p>
<p>4. Using the principal components from a factor analysis for mixed data (FAMD (5)):
a factor analysis for mixed data is applied on the covariates of the database and a specific number of the related principal components is remained (depending on the minimal part of variability explained by the covariates that the user wishes to keep by varying the <code>info</code> option).
The function integrates in its syntax the function <code><a href="FactoMineR.html#topic+FAMD">FAMD</a></code> of the package <span class="pkg">FactoMiner</span> (6) using default parameters.
After this step, the covariates are replaced by the remaining principal components of the FAMD, and each value corresponds to coordinates linked to each component.
Please notice that this method supposed complete covariates in input, nevertheless in presence of incomplete covariates, each corresponding rows will be dropped from the study, a warning will appear and the number of remaining rows will be indicated.
</p>


<h3>Value</h3>

<p>A data.frame whose covariates have been transformed according to the distance function or approach (for FAMD) chosen. The columns of the data.frame could have been reordered so that the database identifier, <code class="reqn">Y</code> and <code class="reqn">Z</code> correspond to the first three columns respectively.
Moreover the order of rows remains unchanged during the process.
</p>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li>
<li><p> Anderberg, M.R. (1973). Cluster analysis for applications, 359 pp., Academic Press, New York, NY, USA.
</p>
</li>
<li><p> Borg, I. and Groenen, P. (1997). Modern Multidimensional Scaling. Theory and Applications. Springer.
</p>
</li>
<li><p> Gower, J. C. (1971). A general coefficient of similarity and some of its properties. Biometrics, 27, 623&ndash;637.
</p>
</li>
<li><p> Pages J. (2004). Analyse factorielle de donnees mixtes. Revue Statistique Appliquee. LII (4). pp. 93-111.
</p>
</li>
<li><p> Lê S, Josse J, Husson, F. (2008). FactoMineR: An R Package for Multivariate Analysis. Journal of Statistical Software. 25(1). pp. 1-18.
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+transfo_quali">transfo_quali</a></code>,<code><a href="#topic+merge_dbs">merge_dbs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Using the table simu_data:

data(simu_data)

# 1. the Euclidean distance (same output with Manhattan distance),
eucl1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "E"
)
# Here Yb2 was stored in numeric: It has been automatically converted in factor

# You can also convert beforehand Yb2 in ordered factor by example:
sim_data &lt;- simu_data
sim_data$Yb2 &lt;- as.ordered(sim_data$Yb2)
eucl2 &lt;- transfo_dist(sim_data,
  quanti = 8, nominal = c(1, 4:5, 7),
  ordinal = c(2, 3, 6), logic = NULL, prep_choice = "E"
)

# 2. The Euclidean distance generated on principal components
#    by a factor analysis for mixed data (FAMD):
eucl_famd &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "FAMD"
)

# Please notice that this method works only with rows that have complete
# information on covariates.

# 3. The Gower distance for mixed data:
gow1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7),
  ordinal = c(2, 6), logic = NULL, prep_choice = "G"
)

# 4. The Hamming distance:
# Here the quanti option could only contain indexes related to targets.
# Column indexes related to potential binary covariates or covariates with
# finite number of values must be include in the ordinal option.
# So in simu_data, the discretization of the variable age is required (index=8),
# using the convert_num and convert_class arguments (for tertiles = 3):

ham1 &lt;- transfo_dist(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  convert_num = 8, convert_class = 3, prep_choice = "H"
)


### This function works whatever the order of your columns in your database:
# Suppose that we re-order columns in simu_data:
simu_data2 &lt;- simu_data[, c(2, 4:7, 3, 8, 1)]

# By changing the corresponding indexes in the index_DB_Y_Z argument,
# we observe the desired output:
eucl3 &lt;- transfo_dist(simu_data2,
  index_DB_Y_Z = c(8, 1, 6), quanti = 6:7, nominal = c(2:3, 5, 8),
  ordinal = c(1, 4), logic = NULL, prep_choice = "E"
)

</code></pre>

<hr>
<h2 id='transfo_quali'>transfo_quali()</h2><span id='topic+transfo_quali'></span>

<h3>Description</h3>

<p>A function that transforms a factor of n(&gt;1) levels in (n-1) binary variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfo_quali(x, labx = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transfo_quali_+3A_x">x</code></td>
<td>
<p>a factor</p>
</td></tr>
<tr><td><code id="transfo_quali_+3A_labx">labx</code></td>
<td>
<p>a new label for the generated binary variables (By default the name of the factor is conserved)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of (n-1) binary variables
</p>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
treat &lt;- as.factor(c(rep("A", 10), rep("B", 15), rep("C", 12)))
treat_bin &lt;- transfo_quali(treat, "trt")

</code></pre>

<hr>
<h2 id='transfo_target'>transfo_target()</h2><span id='topic+transfo_target'></span>

<h3>Description</h3>

<p>This function prepares the encoding of the target variable before running an algorithm using optimal transportation theory.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transfo_target(z, levels_order = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transfo_target_+3A_z">z</code></td>
<td>
<p>a factor variable (ordered or not). A variable of another type will be, by default, convert to a factor.</p>
</td></tr>
<tr><td><code id="transfo_target_+3A_levels_order">levels_order</code></td>
<td>
<p>a vector corresponding to the values of the levels of z. When the target is ordinal, the levels can be sorted by ascending order.
By default, the initial order is remained.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>transfo_target</code> is an intermediate function direcly implemented in the functions <code><a href="#topic+OT_outcome">OT_outcome</a></code> and <code><a href="#topic+OT_joint">OT_joint</a></code>,
two functions dedicated to data fusion (see (1) and (2) for details). Nevertheless, this function can also be used separately to assist user in the conversion
of a target variable (outcome) according to the following rules:
</p>

<ul>
<li><p> A character variable is converted in factor if the argument <code>levels_order</code> is set to NULL. In this case, the levels of the factor are assigned by order of appearance in the database.
</p>
</li>
<li><p> A character variable is converted in ordered factor if the argument <code>levels_order</code> differs from NULL. In this case, the levels of the factor correspond to those assigned in the argument.
</p>
</li>
<li><p> A factor stays unchanged if the argument <code>levels_order</code> is set to NULL. Otherwise the factor is converted in ordered factor and the levels are ordered according to the argument <code>levels_order</code>.
</p>
</li>
<li><p> A numeric variable, discrete or continuous is converted in factor if the argument <code>levels_order</code> is set to NULL, and the related levels are the values assigned in ascending order.
</p>
</li>
<li><p> A numeric variable, discrete or continuous is converted in ordered factor if the argument <code>levels_order</code> differed from NULL, and the related levels correspond to those assigned in the argument.
</p>
</li></ul>



<h3>Value</h3>

<p>The list returned is:
</p>
<table>
<tr><td><code>NEW</code></td>
<td>
<p>an object of class factor of the same length as z</p>
</td></tr>
<tr><td><code>LEVELS_NEW</code></td>
<td>
<p>the levels (ordered or not) retained for z</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+compare_lists">compare_lists</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100, 30, 10)
ynew1 &lt;- transfo_target(y)

newlev &lt;- unique(as.integer(y))
ynew2 &lt;- transfo_target(y, levels_order = newlev)
newlev2 &lt;- newlev[-1]
ynew3 &lt;- transfo_target(y, levels_order = newlev2)

outco &lt;- c(rep("A", 25), rep("B", 50), rep("C", 25))
outco_new1 &lt;- transfo_target(outco, levels_order = c("B", "C", "A"))
outco_new2 &lt;- transfo_target(outco, levels_order = c("E", "C", "A", "F"))
outco_new3 &lt;- transfo_target(outco)

outco2 &lt;- c(rep("A", 25), NA, rep("B", 50), rep("C", 25), NA, NA)
gg &lt;- transfo_target(outco2)
hh &lt;- transfo_target(outco2, levels_order = c("B", "C", "A"))

</code></pre>

<hr>
<h2 id='verif_OT'>verif_OT()</h2><span id='topic+verif_OT'></span>

<h3>Description</h3>

<p>This function proposes post-process verifications after data fusion by optimal transportation algorithms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>verif_OT(
  ot_out,
  group.class = FALSE,
  ordinal = TRUE,
  stab.prob = FALSE,
  min.neigb = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="verif_OT_+3A_ot_out">ot_out</code></td>
<td>
<p>an otres object from <code><a href="#topic+OT_outcome">OT_outcome</a></code> or <code><a href="#topic+OT_joint">OT_joint</a></code></p>
</td></tr>
<tr><td><code id="verif_OT_+3A_group.class">group.class</code></td>
<td>
<p>a boolean indicating if the results related to the proximity between outcomes by grouping levels are requested in output (<code>FALSE</code> by default).</p>
</td></tr>
<tr><td><code id="verif_OT_+3A_ordinal">ordinal</code></td>
<td>
<p>a boolean that indicates if <code class="reqn">Y</code> and <code class="reqn">Z</code> are ordinal (<code>TRUE</code> by default) or not. This argument is only useful in the context of groups of levels (<code>group.class</code>=TRUE).</p>
</td></tr>
<tr><td><code id="verif_OT_+3A_stab.prob">stab.prob</code></td>
<td>
<p>a boolean indicating if the results related to the stability of the algorithm are requested in output (<code>FALSE</code> by default).</p>
</td></tr>
<tr><td><code id="verif_OT_+3A_min.neigb">min.neigb</code></td>
<td>
<p>a value indicating the minimal required number of neighbors to consider in the estimation of stability (1 by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In a context of data fusion, where information from a same target population is summarized via two specific variables <code class="reqn">Y</code> and <code class="reqn">Z</code> (two ordinal or nominal factors with different number of levels <code class="reqn">n_Y</code> and <code class="reqn">n_Z</code>), never jointly observed and respectively stored in two distinct databases A and B,
Optimal Transportation (OT) algorithms (see the models <code>OUTCOME</code>, <code>R_OUTCOME</code>, <code>JOINT</code>, and <code>R_JOINT</code> of the reference (2) for more details)
propose methods for the recoding of <code class="reqn">Y</code> in B and/or <code class="reqn">Z</code> in A. Outputs from the functions <code>OT_outcome</code> and <code>OT_joint</code> so provides the related predictions to <code class="reqn">Y</code> in B and/or <code class="reqn">Z</code> in A,
and from these results, the function <code>verif_OT</code> provides a set of tools (optional or not, depending on the choices done by user in input) to estimate:
</p>

<ol>
<li><p> the association between <code class="reqn">Y</code> and <code class="reqn">Z</code> after recoding
</p>
</li>
<li><p> the similarities between observed and predicted distributions
</p>
</li>
<li><p> the stability of the predictions proposed by the algorithm
</p>
</li></ol>

<p>A. PAIRWISE ASSOCIATION BETWEEN <code class="reqn">Y</code> AND <code class="reqn">Z</code>
</p>
<p>The first step uses standard criterions (Cramer's V, and Spearman's rank correlation coefficient) to evaluate associations between two ordinal variables in both databases or in only one database.
When the argument <code>group.class = TRUE</code>, these informations can be completed by those provided by the function <code><a href="#topic+error_group">error_group</a></code>, which is directly integrate in the function <code>verif_OT</code>.
Assuming that <code class="reqn">n_Y &gt; n_Z</code>, and that one of the two scales of <code class="reqn">Y</code> or <code class="reqn">Z</code> is unknown, this function gives additional informations about the potential link between the levels of the unknown scale.
The function proceeds to this result in two steps. Firsty, <code><a href="#topic+error_group">error_group</a></code> groups combinations of modalities of <code class="reqn">Y</code> to build all possible variables <code class="reqn">Y'</code> verifying <code class="reqn">n_{Y'} = n_Z</code>.
Secondly, the function studies the fluctuations in the association of <code class="reqn">Z</code> with each new variable <code class="reqn">Y'</code> by using adapted comparisons criterions (see the documentation of <code><a href="#topic+error_group">error_group</a></code> for more details).
If grouping successive classes of <code class="reqn">Y</code> leads to an improvement in the initial association between <code class="reqn">Y</code> and <code class="reqn">Z</code> then it is possible to conclude in favor of an ordinal coding for <code class="reqn">Y</code> (rather than nominal)
but also to emphasize the consistency in the predictions proposed by the algorithm of fusion.
</p>
<p>B. SIMILARITIES BETWEEN OBSERVED AND PREDICTED DISTRIBUTIONS
</p>
<p>When the predictions of <code class="reqn">Y</code> in B and/or <code class="reqn">Z</code> in A are available in the <code>datab</code> argument, the similarities between the observed and predicted probabilistic distributions of <code class="reqn">Y</code> and/or <code class="reqn">Z</code> are quantified from the Hellinger distance (see (1)).
This measure varies between 0 and 1: a value of 0 corresponds to a perfect similarity while a value close to 1 (the maximum) indicates a great dissimilarity.
Using this distance, two distributions will be considered as close as soon as the observed measure will be less than 0.05.
</p>
<p>C. STABILITY OF THE PREDICTIONS
</p>
<p>These results are based on the decision rule which defines the stability of an algorithm in A (or B) as its average ability to assign a same prediction
of <code class="reqn">Z</code> (or <code class="reqn">Y</code>) to individuals that have a same given profile of covariates <code class="reqn">X</code> and a same given level of <code class="reqn">Y</code> (or <code class="reqn">Z</code> respectively).
</p>
<p>Assuming that the missing information of <code class="reqn">Z</code> in base A was predicted from an OT algorithm (the reasoning will be identical with the prediction of <code class="reqn">Y</code> in B, see (2) and (3) for more details), the function <code>verif_OT</code> uses the conditional probabilities stored in the
object <code>estimatorZA</code> (see outputs of the functions <code><a href="#topic+OT_outcome">OT_outcome</a></code> and <code><a href="#topic+OT_joint">OT_joint</a></code>) which contains the estimates of all the conditional probabilities of <code class="reqn">Z</code> in A, given a profile of covariates <code class="reqn">x</code> and given a level of <code class="reqn">Y = y</code>.
Indeed, each individual (or row) from A, is associated with a conditional probability <code class="reqn">P(Z= z|Y= y, X= x)</code> and averaging all the corresponding estimates can provide an indicator of the predictions stability.
</p>
<p>The function <code><a href="#topic+OT_joint">OT_joint</a></code> provides the individual predictions for subject <code class="reqn">i</code>: <code class="reqn">\widehat{z}_i</code>, <code class="reqn">i=1,\ldots,n_A</code> according to the the maximum a posteriori rule:
</p>
<p style="text-align: center;"><code class="reqn">\widehat{z}_i= \mbox{argmax}_{z\in \mathcal{Z}} P(Z= z| Y= y_i, X= x_i)</code>
</p>

<p>The function <code><a href="#topic+OT_outcome">OT_outcome</a></code> directly deduces the individual predictions from the probablities <code class="reqn">P(Z= z|Y= y, X= x)</code> computed in the second part of the algorithm (see (3)).
</p>
<p>It is nevertheless common that conditional probabilities are estimated from too rare covariates profiles to be considered as a reliable estimate of the reality.
In this context, the use of trimmed means and standard deviances is suggested by removing the corresponding probabilities from the final computation.
In this way, the function provides in output a table (<code>eff.neig</code> object) that provides the frequency of these critical probabilities that must help the user to choose.
According to this table, a minimal number of profiles can be imposed for a conditional probability to be part of the final computation by filling in the <code>min.neigb</code> argument.
</p>
<p>Notice that these results are optional and available only if the argument <code>stab.prob = TRUE</code>.
When the predictions of <code class="reqn">Z</code> in A and <code class="reqn">Y</code> in B are available, the function <code>verif_OT</code> provides in output, global results and results by database.
The <code>res.stab</code> table can produce NA with <code>OT_outcome</code> output in presence of incomplete shared variables: this problem appears when the <code>prox.dist</code> argument is set to 0 and can
be simply solved by increasing this value.
</p>


<h3>Value</h3>

<p>A list of 7 objects is returned:
</p>
<table>
<tr><td><code>nb.profil</code></td>
<td>
<p>the number of profiles of covariates</p>
</td></tr>
<tr><td><code>conf.mat</code></td>
<td>
<p>the global confusion matrix between <code class="reqn">Y</code> and <code class="reqn">Z</code></p>
</td></tr>
<tr><td><code>res.prox</code></td>
<td>
<p>a summary table related to the association measures between <code class="reqn">Y</code> and <code class="reqn">Z</code></p>
</td></tr>
<tr><td><code>res.grp</code></td>
<td>
<p>a summary table related to the study of the proximity of <code class="reqn">Y</code> and <code class="reqn">Z</code> using group of levels. Only if the <code>group.class</code> argument is set to TRUE.</p>
</td></tr>
<tr><td><code>hell</code></td>
<td>
<p>Hellinger distances between observed and predicted distributions</p>
</td></tr>
<tr><td><code>eff.neig</code></td>
<td>
<p>a table which corresponds to a count of conditional probabilities according to the number of neighbors used in their computation (only the first ten values)</p>
</td></tr>
<tr><td><code>res.stab</code></td>
<td>
<p>a summary table related to the stability of the algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gregory Guernec
</p>
<p><a href="mailto:otrecod.pkg@gmail.com">otrecod.pkg@gmail.com</a>
</p>


<h3>References</h3>


<ol>
<li><p> Liese F, Miescke K-J. (2008). Statistical Decision Theory: Estimation, Testing, and Selection. Springer
</p>
</li>
<li><p> Gares V, Dimeglio C, Guernec G, Fantin F, Lepage B, Korosok MR, savy N (2019). On the use of optimal transportation theory to recode variables and application to database merging. The International Journal of Biostatistics.
Volume 16, Issue 1, 20180106, eISSN 1557-4679. doi:10.1515/ijb-2018-0106
</p>
</li>
<li><p> Gares V, Omer J (2020) Regularized optimal transport of covariates and outcomes in data recoding. Journal of the American Statistical Association. doi: <a href="https://doi.org/10.1080/01621459.2020.1775615">10.1080/01621459.2020.1775615</a>
</p>
</li></ol>



<h3>See Also</h3>

<p><code><a href="#topic+OT_outcome">OT_outcome</a></code>, <code><a href="#topic+OT_joint">OT_joint</a></code>, <code><a href="#topic+proxim_dist">proxim_dist</a></code>, <code><a href="#topic+error_group">error_group</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example 1
#-----
# - Using the data simu_data
# - Studying the proximity between Y and Z using standard criterions
# - When Y and Z are predicted in B and A respectively
# - Using an outcome model (individual assignment with knn)
#-----
data(simu_data)
outc1 &lt;- OT_outcome(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  dist.choice = "G", percent.knn = 0.90, maxrelax = 0,
  convert.num = 8, convert.class = 3,
  indiv.method = "sequential", which.DB = "BOTH", prox.dist = 0.30
)

verif_outc1 &lt;- verif_OT(outc1)
verif_outc1



### Example 2
#-----
# - Using the data simu_data
# - Studying the proximity between Y and Z using standard criterions and studying
#   associations by grouping levels of Z
# - When only Y is predicted in B
# - Tolerated distance between a subject and a profile: 0.30 * distance max
# - Using an outcome model (individual assignment with knn)
#-----

data(simu_data)
outc2 &lt;- OT_outcome(simu_data,
  quanti = c(3, 8), nominal = c(1, 4:5, 7), ordinal = c(2, 6),
  dist.choice = "G", percent.knn = 0.90, maxrelax = 0, prox.dist = 0.3,
  convert.num = 8, convert.class = 3,
  indiv.method = "sequential", which.DB = "B"
)

verif_outc2 &lt;- verif_OT(outc2, group.class = TRUE, ordinal = TRUE)
verif_outc2


### Example 3
#-----
# - Using the data simu_data
# - Studying the proximity between Y and Z using standard criterions and studying
#   associations by grouping levels of Z
# - Studying the stability of the conditional probabilities
# - When Y and Z are predicted in B and A respectively
# - Using an outcome model (individual assignment with knn)
#-----

verif_outc2b &lt;- verif_OT(outc2, group.class = TRUE, ordinal = TRUE, stab.prob = TRUE, min.neigb = 5)
verif_outc2b


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
