<!DOCTYPE html><html><head><title>Help for package languageR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {languageR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acf.fnc'><p>Autocorrelation trellis graph</p></a></li>
<li><a href='#affixProductivity'><p>Affix productivity</p></a></li>
<li><a href='#alice'><p>Alice's Adventures in Wonderland</p></a></li>
<li><a href='#aovlmer.fnc'><p>Compute p-values for factors in mixed models</p></a></li>
<li><a href='#auxiliaries'><p>Auxiliaries for regular and irregular verbs in Dutch</p></a></li>
<li><a href='#beginningReaders'><p>Visual lexical decision with beginning readers</p></a></li>
<li><a href='#collin.fnc'><p>Calculate condition number with intercept included</p></a></li>
<li><a href='#compare.richness.fnc'><p>Compare Lexical Richness of Two Texts</p></a></li>
<li><a href='#corres-class'><p>Class &quot;corres&quot;</p></a></li>
<li><a href='#corres.fnc'><p>Correspondence Analysis</p></a></li>
<li><a href='#corresInit'><p>Initialize correspondence object</p></a></li>
<li><a href='#corsup.fnc'><p>Supplementary rows or columns in correspondence analysis</p></a></li>
<li><a href='#danish'><p>Danish auditory lexical decision</p></a></li>
<li><a href='#dative'><p>Dative Alternation</p></a></li>
<li><a href='#dativeSimplified'><p>Dative Alternation - simplified data set</p></a></li>
<li><a href='#degreesOrKnots.fnc'><p>Extract degree of polynomial or knots for restricted cubic spline</p></a></li>
<li><a href='#durationsGe'><p>Durational measurements on the Dutch prefix ge-</p></a></li>
<li><a href='#durationsOnt'><p>Durational measurements on the Dutch prefix ont-</p></a></li>
<li><a href='#dutchSpeakersDist'><p>Cross-entropy based distances between speakers</p></a></li>
<li><a href='#dutchSpeakersDistMeta'><p>Metadata for dutchSpeakersDist</p></a></li>
<li><a href='#english'><p>English visual lexical decision and naming latencies</p></a></li>
<li><a href='#etymology'><p>Etymological age and regularity in Dutch</p></a></li>
<li><a href='#faz'><p>Frankfurter frequencies</p></a></li>
<li><a href='#finalDevoicing'><p>Final Devoicing in Dutch</p></a></li>
<li><a href='#getKnots.fnc'><p>Extracts knots from variable name</p></a></li>
<li><a href='#getMCMCintervals.fnc'><p>calculate HPD prediction intervals</p></a></li>
<li><a href='#getPos.fnc'><p> determine position for labels for interaction plots</p></a></li>
<li><a href='#getRange.fnc'><p>Extracts range of predicted values from list of data frames</p></a></li>
<li><a href='#getRoot.fnc'><p>extract simple name of predictor from expression with poly</p></a></li>
<li><a href='#growth-class'><p>Class &quot;growth&quot;</p></a></li>
<li><a href='#growth.fnc'><p>Calculate vocabulary growth curve and vocabulary richness measures</p></a></li>
<li><a href='#growth2vgc.fnc'><p>Conversion of growth object into a vgc object</p></a></li>
<li><a href='#growthInit'><p>Initialize a vocabulary growth object.</p></a></li>
<li><a href='#havelaar'><p>The determiner 'het' in the Dutch novel Max Havelaar</p></a></li>
<li><a href='#head.growth'><p>Returns first rows of a growth object.</p></a></li>
<li><a href='#heid'><p>Lexical decision latencies for words ending in -heid</p></a></li>
<li><a href='#herdan.fnc'><p>Herdan's C</p></a></li>
<li><a href='#imaging'><p>fMRI Filtered Signal and Priming Scores for Brain-Damaged Patients</p></a></li>
<li><a href='#implementInteractions.fnc'><p>implement interactions in the model matrix</p></a></li>
<li><a href='#item.fnc'><p>Function for by-item regression used by simulateRegression.fnc</p></a></li>
<li><a href='#items.quasif.fnc'><p>By-item anova for simulated data for quasi-F analysis</p></a></li>
<li><a href='#lags.fnc'><p>Calculate vector at specified lag</p></a></li>
<li><a href='#languageR-package'>
<p>Data sets and functions for 'Analyzing Linguistic Data'</p></a></li>
<li><a href='#latinsquare'><p>Simulated Latin Square data set with subjects and items</p></a></li>
<li><a href='#lexdec'><p>Lexical decision latencies for 79 English nouns</p></a></li>
<li><a href='#lexicalMeasures'><p>Lexical measures for 2233 English monomorphemic words</p></a></li>
<li><a href='#lexicalMeasuresClasses'><p>Classification of lexical measures</p></a></li>
<li><a href='#lmerPlotInt.fnc'><p>Plot the interaction of two linear numeric predictors in a model</p>
fitted with lmer</a></li>
<li><a href='#make.reg.fnc'><p>Make a simulated data set with regression design</p></a></li>
<li><a href='#makeDefaultMatrix.fnc'><p> Create model matrix with main effects only</p></a></li>
<li><a href='#makeSplineData.fnc'><p>generate simulated data set with nonlinear function</p></a></li>
<li><a href='#moby'><p>Moby Dick</p></a></li>
<li><a href='#mvrnormplot.fnc'><p>Scatterplot of bivariate standard normal distribution</p></a></li>
<li><a href='#nesscg'><p>Frequency spectrum for -ness in the demographic BNC</p></a></li>
<li><a href='#nessdemog'><p>Frequency spectrum for -ness in the context-governed BNC</p></a></li>
<li><a href='#nessw'><p>Frequency spectrum for -ness in the written BNC</p></a></li>
<li><a href='#oldFrench'><p>Frequencies of tag trigrams in Old French texts</p></a></li>
<li><a href='#oldFrenchMeta'><p>Meta data for the oldFrench data</p></a></li>
<li><a href='#oz'><p>The Wonderful Wizard of Oz</p></a></li>
<li><a href='#pairscor.fnc'><p>Scatterplot matrix with correlations</p></a></li>
<li><a href='#parsePredName.fnc'><p> parse character string specifying restricted cubic spline</p></a></li>
<li><a href='#periphrasticDo'><p>The development of periphrastic do in English</p></a></li>
<li><a href='#phylogeny'><p>Phylogenetic relations between Papuan and Oceanic languages</p></a></li>
<li><a href='#plot.corres'><p>Plot method for correspondence objects</p></a></li>
<li><a href='#plot.growth'><p>Plot method for growth objects</p></a></li>
<li><a href='#plotAll.fnc'><p>create plot or plots for list with data frames for plot or subplots</p></a></li>
<li><a href='#plotLMER.fnc'><p>plot a mer object</p></a></li>
<li><a href='#plotlogistic.fit.fnc'><p>Plot for goodness of fit of logistic regression</p></a></li>
<li><a href='#preparePredictor.fnc'><p> determine X and Y values for a given (sub)plot</p></a></li>
<li><a href='#primingHeid'><p>Primed lexical decision latencies for neologisms ending in -heid</p></a></li>
<li><a href='#primingHeidPrevRT'><p>Primed lexical decision latencies for neologisms ending in -heid</p></a></li>
<li><a href='#print.corres'><p>Print method for correspondence object</p></a></li>
<li><a href='#print.growth'><p>Print method for growth objects.</p></a></li>
<li><a href='#pvals.fnc'><p>Compute p-values and MCMC confidence intervals for mixed models</p></a></li>
<li><a href='#quasif'><p>Simulated data set with subjects and items requiring quasi-F ratios</p></a></li>
<li><a href='#quasiF.fnc'><p>Quasi-F test</p></a></li>
<li><a href='#quasiFsim.fnc'><p>Quasi-F test for specific simple design</p></a></li>
<li><a href='#ratings'><p>Ratings for 81 English nouns</p></a></li>
<li><a href='#regularity'><p>Regular and irregular Dutch verbs</p></a></li>
<li><a href='#selfPacedReadingHeid'><p>Self-paced reading latencies for Dutch neologisms</p></a></li>
<li><a href='#shadenormal.fnc'><p>Shade rejection region for normal probability density function</p></a></li>
<li><a href='#show.growth'><p>Plot method for growth objects.</p></a></li>
<li><a href='#shrinkage'><p>Data set illustrating shrinkage</p></a></li>
<li><a href='#simulateLatinsquare.fnc'><p>Simulate simple Latin Square data and compare models</p></a></li>
<li><a href='#simulateQuasif.fnc'><p>Simulate data for quasi-F analysis and compare models</p></a></li>
<li><a href='#simulateRegression.fnc'><p>Simulate regression data and compare models</p></a></li>
<li><a href='#sizeRatings'><p>Size ratings for 81 English concrete nouns</p></a></li>
<li><a href='#spanish'><p>Relative frequencies of tag trigrams is selected Spanish texts</p></a></li>
<li><a href='#spanishFunctionWords'><p>Relative frequencies of function words in selected Spanish texts</p></a></li>
<li><a href='#spanishMeta'><p>Metadata for the spanish and spanishFunctionWords data sets</p></a></li>
<li><a href='#spectrum.fnc'><p>Frequency spectrum from text vector</p></a></li>
<li><a href='#splitplot'><p>Simulated data set with split plot design</p></a></li>
<li><a href='#subjects.latinsquare.fnc'><p>By-subject analysis of simple Latin Square data sets</p></a></li>
<li><a href='#subjects.quasif.fnc'><p>By-subject analysis of data sets requiring quasi-F ratios</p></a></li>
<li><a href='#summary.corres'><p>Summarize a correspondence object</p></a></li>
<li><a href='#summary.growth'><p>Summary method for growth objects</p></a></li>
<li><a href='#tail.growth'><p>Show last rows of growth object.</p></a></li>
<li><a href='#text2spc.fnc'><p>Create a frequency spectrum from a text vector</p></a></li>
<li><a href='#through'><p>Through the Looking Glass</p></a></li>
<li><a href='#transforming.fnc'><p>transform vector according to specified function</p></a></li>
<li><a href='#twente'><p>Frequency spectrum for the Twente News Corpus</p></a></li>
<li><a href='#variationLijk'><p>Variation in spoken Dutch in the use of the suffix -lijk</p></a></li>
<li><a href='#ver'><p>The Dutch prefix ver-: semantic transparency and frequency</p></a></li>
<li><a href='#verbs'><p>Dative Alternation - simplified data set</p></a></li>
<li><a href='#warlpiri'><p>Ergative case marking in Warlpiri</p></a></li>
<li><a href='#weightRatings'><p>Subjective estimates of the weight of the referents of 81 English nouns</p></a></li>
<li><a href='#writtenVariationLijk'><p>Variation in written Dutch in the use of the suffix -lijk</p></a></li>
<li><a href='#xylowess.fnc'><p>Trellis scatterplot with smoothers</p></a></li>
<li><a href='#yule.fnc'><p>Yule's characteristic constant K</p></a></li>
<li><a href='#zipf.fnc'><p>Zipf's rank frequency distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyzing Linguistic Data: A Practical Introduction to
Statistics</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-01-28</td>
</tr>
<tr>
<td>Author:</td>
<td>R. H. Baayen &lt;harald.baayen@uni-tuebingen.de&gt;, 
	Elnaz Shafaei-Bajestan &lt;elnaz.shafaei-bajestan@uni-tuebingen.de&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>R. H. Baayen &lt;harald.baayen@uni-tuebingen.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Data sets exemplifying statistical methods, and some
        facilitatory utility functions used in &ldquo;Analyzing Linguistic
        Data: A practical introduction to statistics using R&rdquo;,
        Cambridge University Press, 2008.</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 3.0.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cluster, e1071, rms, Hmisc, MASS, rpart, lattice, zipfR,
lme4, multcomp, lmerTest, optimx</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-01-29 15:32:15 UTC; elnaz</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-01-30 08:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='acf.fnc'>Autocorrelation trellis graph</h2><span id='topic+acf.fnc'></span>

<h3>Description</h3>

<p>This function creates a trellis plot with autocorrelation functions
for by-subject sequential dependencies in response latencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acf.fnc(dat, group="Subject", time="Trial", x = "RT", plot=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="acf.fnc_+3A_dat">dat</code></td>
<td>
<p>A data frame with (minimally) a grouping factor, an index for
successive trails/events, and a behavioral measure</p>
</td></tr>
<tr><td><code id="acf.fnc_+3A_group">group</code></td>
<td>
<p>A grouping factor such as <code>Subject</code></p>
</td></tr>
<tr><td><code id="acf.fnc_+3A_time">time</code></td>
<td>
<p>A sequential time measure such as <code>Trial</code> number in the
experimental list</p>
</td></tr>
<tr><td><code id="acf.fnc_+3A_x">x</code></td>
<td>
<p>The dependent variable, usually a chronometric measure such as RT</p>
</td></tr>
<tr><td><code id="acf.fnc_+3A_plot">plot</code></td>
<td>
<p>If true, a trellis graph is produced, otherwise a data frame
with the data on which the trellis graph is based is returned</p>
</td></tr>
<tr><td><code id="acf.fnc_+3A_...">...</code></td>
<td>
<p>other optional arguments, such as <code>layout</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>plot=TRUE</code>, a trellis graph, otherwise a data frame with as column 
names
</p>
<table>
<tr><td><code>Lag</code></td>
<td>
<p>Autocorrelation lag</p>
</td></tr>
<tr><td><code>Acf</code></td>
<td>
<p>Autocorrelation</p>
</td></tr>
<tr><td><code>Subject</code></td>
<td>
<p>The grouping factor, typically Subject</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>The (approximate) 95% confidence interval.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>R. H. Baayen (2001) <em>Word Frequency Distributions</em>, Dordrecht: Kluwer.  
</p>


<h3>See Also</h3>

<p><a href="#topic+lags.fnc">lags.fnc</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(beginningReaders)
acf.fnc(beginningReaders, x="LogRT")   # autocorrelations even though nonword responses not included

## End(Not run)</code></pre>

<hr>
<h2 id='affixProductivity'>Affix productivity</h2><span id='topic+affixProductivity'></span>

<h3>Description</h3>

<p>Affix productivity, gauged by the P* productivity measure, 
for 27 English affixes in 44 texts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(affixProductivity)</code></pre>


<h3>Format</h3>

<p>A data frame with 44 observations on the following 30 variables.
</p>

<dl>
<dt><code>semi</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>anti</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ee</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ism</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ian</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ful</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>y</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ness</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>able</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ly</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>unV</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>unA</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ize</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>less</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>erA</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>erC</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ity</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>super</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>est</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ment</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ify</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>re</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ation</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>in.</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>ex</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>en</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>be</code></dt><dd><p>a numeric vector of P*-values</p>
</dd>
<dt><code>AuthorCodes</code></dt><dd><p>a factor with levels 
</p>

<dl>
<dt><code>BLu</code></dt><dd><p>(King James Version: Luke-Acts)</p>
</dd>
<dt><code>BMo</code></dt><dd><p>(Book of Mormon) </p>
</dd>
<dt><code>CAs</code></dt><dd><p>(Aesop's fables, translation by Townsend)</p>
</dd>
<dt><code>CBo</code></dt><dd><p>(Baum, The Marvelous Land of Oz)</p>
</dd>
<dt><code>CBp</code></dt><dd><p>(Barrie, Peter Pan and Wendy)</p>
</dd>
<dt><code>CBw</code></dt><dd><p>(Baum, The Wonderful Wizard of Oz)</p>
</dd>
<dt><code>CCa</code></dt><dd><p>(Carroll, Alice's Adventures in Wonderland)</p>
</dd>
<dt><code>CCt</code></dt><dd><p>(Carroll, Through the Looking Glass and what Alice Found There)</p>
</dd>
<dt><code>CGr</code></dt><dd><p>(Grimm Fairy Tales, translations)</p>
</dd>
<dt><code>CKj</code></dt><dd><p>(Kipling, The Jungle Book)</p>
</dd>
<dt><code>LAp</code></dt><dd><p>(Austen, Pride and Prejudice)</p>
</dd>
<dt><code>LBp</code></dt><dd><p>(Burroughs, A Princess of Mars)  </p>
</dd>
<dt><code>LBw</code></dt><dd><p>(Bronte, Wuthering Heights) </p>
</dd>
<dt><code>LCl</code></dt><dd><p>(Conrad, Lord Jim)</p>
</dd>
<dt><code>LCn</code></dt><dd><p>(Conrad, Nigger of the Narcissus) </p>
</dd>
<dt><code>LDb</code></dt><dd><p>(Doyle, The Casebook of Sherlock Holmes)</p>
</dd>
<dt><code>LDc</code></dt><dd><p>(Dickens, The Chimes: a Goblin Story) </p>
</dd>
<dt><code>LDC</code></dt><dd><p>(Dickens, A Christmas Carol)     </p>
</dd>
<dt><code>LDh</code></dt><dd><p>(Doyle, The Hound of the Baskervilles)</p>
</dd>
<dt><code>LDv</code></dt><dd><p>(Doyle, The Valley of Fear)  </p>
</dd>
<dt><code>LJc</code></dt><dd><p>(James, Confidence)</p>
</dd>
<dt><code>LJe</code></dt><dd><p>(James, The Europeans)</p>
</dd>
<dt><code>LLc</code></dt><dd><p>(London, The Call of the Wild)</p>
</dd>
<dt><code>LLs</code></dt><dd><p>(London, The Sea Wolf)</p>
</dd>
<dt><code>LMa</code></dt><dd><p>(Montgomery, Anne of Avonlea)</p>
</dd>
<dt><code>LMm</code></dt><dd><p>(Melville, Moby Dick)</p>
</dd>
<dt><code>LMn</code></dt><dd><p>(Morris, News from Nowhere)</p>
</dd>
<dt><code>LMp</code></dt><dd><p>(Milton, Paradise Lost)</p>
</dd>
<dt><code>LOs</code></dt><dd><p>(Orczy, The Scarlet Pimpernel)</p>
</dd>
<dt><code>LSd</code></dt><dd><p>(Stoker, Dracula)</p>
</dd>
<dt><code>LSs</code></dt><dd><p>(Chu, More than a Chance Meeting (Startrek))</p>
</dd>
<dt><code>LTa</code></dt><dd><p>(Trollope, Ayala's Angel)</p>
</dd>
<dt><code>LTe</code></dt><dd><p>(Trollope, The Eustace Diamonds)</p>
</dd>
<dt><code>LTf</code></dt><dd><p>(Trollope, Can you Forgive her?)</p>
</dd>
<dt><code>LTy</code></dt><dd><p>(Twain, A Connecticut Yankee in King Arthur's Court)</p>
</dd>
<dt><code>LWi</code></dt><dd><p>(Wells, The Invisible Man)</p>
</dd>
<dt><code>LWt</code></dt><dd><p>(Wells, The Time Machine)</p>
</dd>
<dt><code>LWw</code></dt><dd><p>(Wells, The War of the Worlds)</p>
</dd>
<dt><code>OAf</code></dt><dd><p>(The Federalist Papers)</p>
</dd>
<dt><code>OCh</code></dt><dd><p>(Texts sampled from Congress Hearings) </p>
</dd>
<dt><code>OCl</code></dt><dd><p>(Texts sampled from Clinton's Election Speeches)</p>
</dd>
<dt><code>ODo</code></dt><dd><p>(Darwin, On the Origin of the Species)</p>
</dd>
<dt><code>OGa</code></dt><dd><p>(Selected Texts from the Government Accounting Office)</p>
</dd>
<dt><code>OJe</code></dt><dd><p>(James, Essays in Radical Empiricism)</p>
</dd>
</dl>

</dd>
<dt><code>Registers</code></dt><dd><p>a factor with levels <code>B</code> (Biblical texts) 
<code>C</code> (Children's books) <code>L</code> (Literary texts) <code>O</code> (other)</p>
</dd>
<dt><code>Birth</code></dt><dd><p>a numeric vector for the author's year of birth 
(where available)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Most texts were obtained from the Gutenberg Project 
(<a href="http://www.gutenberg.org/wiki/Main_Page">http://www.gutenberg.org/wiki/Main_Page</a>) and the Oxford Text
Archive (http://ota.ahds.ac.uk/).
</p>


<h3>References</h3>

<p>Baayen, R. H. (1994) Derivational Productivity and Text Typology,
<em>Journal of Quantitative Linguistics</em>, 1, 16-34.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(affixProductivity)
affixes.pr = prcomp(affixProductivity[,1:(ncol(affixProductivity)-3)], 
center = TRUE, scale. = TRUE)
library(lattice)
trellis.device()
super.sym = trellis.par.get("superpose.symbol")
splom(data.frame(affixes.pr$x[,1:3]), 
groups = affixProductivity$Registers, 
panel = panel.superpose,
key = list(title  = "texts in productivity space",
text   = list(c("Religious", "Children", "Literary", "Other")),
points = list(pch = super.sym$pch[1:4], col = super.sym$col[1:4])))

## End(Not run)
</code></pre>

<hr>
<h2 id='alice'>Alice's Adventures in Wonderland</h2><span id='topic+alice'></span>

<h3>Description</h3>

<p>The text of Lewis Carroll's 'Alice's Adventures in Wonderland', with 
punctuation marks removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alice)</code></pre>


<h3>Format</h3>

<p>A character vector with 27269 words.
</p>


<h3>Source</h3>

<p>The project Gutenberg at <a href="http://www.gutenberg.org/wiki/Main_Page">http://www.gutenberg.org/wiki/Main_Page</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(alice)
  alice[1:5]
</code></pre>

<hr>
<h2 id='aovlmer.fnc'>Compute p-values for factors in mixed models</h2><span id='topic+aovlmer.fnc'></span>

<h3>Description</h3>

<p>This function no longer works with recent versions of lme4.  
For p-values, see the anova() function in the lmerTest package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aovlmer.fnc(object,  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aovlmer.fnc_+3A_object">object</code></td>
<td>
<p>An lmer or glmer model for a response variable 
fitted with <code>lmer</code>.</p>
</td></tr>
<tr><td><code id="aovlmer.fnc_+3A_...">...</code></td>
<td>
<p>Other optional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A warning message.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen, D. Bates</p>


<h3>See Also</h3>

<p>See anova in lmerTest.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
  library(optimx)
  library(lme4)
  data(latinsquare)
  l.lmer = lmer(RT~SOA+(1|Word)+(1|Subject), data=latinsquare,
    control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
  library(lmerTest)
  summary(l.lmer)
  anova(l.lmer)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='auxiliaries'>Auxiliaries for regular and irregular verbs in Dutch</h2><span id='topic+auxiliaries'></span>

<h3>Description</h3>

<p>For 285 regular and irregular Dutch verbs, the auxiliary for the present 
and past perfect is listed together with the count
of verbal synsets in WordNet.  Regular and irregular verbs are matched
in the mean for lemma frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(auxiliaries)</code></pre>


<h3>Format</h3>

<p>A data frame with 285 observations on the following 4 variables.
</p>

<dl>
<dt><code>Verb</code></dt><dd><p>a factor with 285 monomorphemic Dutch verbs.</p>
</dd>
<dt><code>Aux</code></dt><dd><p>a factor with as levels the auxiliaries <code>hebben</code>, 
<code>zijn</code> and <code>zijnheb</code> (for verbs allowing both auxiliaries).</p>
</dd>
<dt><code>VerbalSynsets</code></dt><dd><p>a numeric vector witth the number of 
verbal synonym sets in WordNet in which the verb is listed.</p>
</dd>
<dt><code>Regularity</code></dt><dd><p>a factor with levels <code>irregular</code> and
<code>regular</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baayen, R. H. and Moscoso del Prado Martin, F. (2005)
Semantic density and past-tense formation in three Germanic 
languages, <em>Language</em>, 81, 666-698.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(auxiliaries)
kruskal.test(auxiliaries$VerbalSynsets, auxiliaries$Aux)
</code></pre>

<hr>
<h2 id='beginningReaders'>Visual lexical decision with beginning readers</h2><span id='topic+beginningReaders'></span>

<h3>Description</h3>

<p>Visual lexical decision latencies for beginning readers (8 year-old
Dutch children).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(beginningReaders)</code></pre>


<h3>Format</h3>

<p>A data frame with 7923 observations on the following 13 variables.
</p>

<dl>
<dt><code>Word</code></dt><dd><p>a factor for the words.</p>
</dd>
<dt><code>Subject</code></dt><dd><p>a factor for the subjects.</p>
</dd>
<dt><code>LogRT</code></dt><dd><p>a numeric vector with the log-transformed reaction time
(in ms).</p>
</dd>
<dt><code>Trial</code></dt><dd><p>a numeric vector coding the rank of the trial in the 
experimental list.</p>
</dd>
<dt><code>OrthLength</code></dt><dd><p>a numeric vector coding the word's length in letters.</p>
</dd>
<dt><code>LogFrequency</code></dt><dd><p>a numeric vector with log-transformed frequency in
Vermeer's frequency dictionary of Dutch children's texts.</p>
</dd>
<dt><code>LogFamilySize</code></dt><dd><p>a numeric vector with the log-transformed morphological
family size count (with family members judged to be unknown to young children
removed).</p>
</dd>
<dt><code>ReadingScore</code></dt><dd><p>a numeric vector with a score for reading proficiency.</p>
</dd>
<dt><code>ProportionOfErrors</code></dt><dd><p>a numeric vector for the proportion of error responses for the word.</p>
</dd>
<dt><code>PC1</code></dt><dd><p>a numeric vector for the first principal component of a PCA
orthogonalization of the preceding 4 reaction times</p>
</dd>
<dt><code>PC2</code></dt><dd><p>a numeric vector for the second principal component of a PCA
orthogonalization of the preceding 4 reaction times</p>
</dd>
<dt><code>PC3</code></dt><dd><p>a numeric vector for the third principal component of a PCA
orthogonalization of the preceding 4 reaction times</p>
</dd>
<dt><code>PC4</code></dt><dd><p>a numeric vector for the fourth principal component of a PCA
orthogonalization of the preceding 4 reaction times</p>
</dd>
</dl>



<h3>References</h3>

<p>Perdijk, K., Schreuder, R., Verhoeven, L. and Baayen, R. H. (2006)
<em>Tracing individual differences in reading skills of young children with 
linear mixed-effects models</em>.  Manuscript, Radboud University Nijmegen.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(beginningReaders)
require(lme4)
require(optimx)
require(lmerTest)

beginningReaders.lmer = lmer(LogRT ~  PC1 + PC2 + PC3  + ReadingScore +
  OrthLength + I(OrthLength^2) + LogFrequency + LogFamilySize +
  (1|Word) + (1|Subject) + (0+LogFrequency|Subject) + 
  (0+OrthLength|Subject) + (0+PC1|Subject), 
  data = beginningReaders,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
summary(beginningReaders.lmer)

## End(Not run)
</code></pre>

<hr>
<h2 id='collin.fnc'>Calculate condition number with intercept included</h2><span id='topic+collin.fnc'></span>

<h3>Description</h3>

<p>Calculates the condition number with the intercept included, following
Belsley, Kuh and Welsch (1980).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collin.fnc(data, colvector)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collin.fnc_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="collin.fnc_+3A_colvector">colvector</code></td>
<td>
<p>A vector with the column numbers in the data frame for which
the collinearity is to be assessed. Only numeric predictors allowed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>svd</code></td>
<td>
<p>Singular value decomposition</p>
</td></tr>
<tr><td><code>cindex</code></td>
<td>
<p>Condition indices</p>
</td></tr>
<tr><td><code>cnumber</code></td>
<td>
<p>The condition number</p>
</td></tr>
<tr><td><code>pi</code></td>
<td>
<p>The phi matrix</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>F. J. Tweedie</p>


<h3>References</h3>

<p>Belsley, D. A.  and  Kuh, E. and  Welsch, R. E. (1980) <em>Regression
Diagnostics. Identifying Influential Data and Sources of Collinearity</em>, Wiley
Series in Probability and Mathematical Statistics, New York.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+kappa">kappa</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
     data(english)
     collin.fnc(english[english$AgeSubj=="young",], 7:29)$cnumber
  
## End(Not run)
</code></pre>

<hr>
<h2 id='compare.richness.fnc'>Compare Lexical Richness of Two Texts</h2><span id='topic+compare.richness.fnc'></span>

<h3>Description</h3>

<p>Comparisons of lexical richness between two texts are carried out on the basis
of the vocabulary size (number of types) and on the basis of the vocabulary
growth rate.  Variances of the number of types and of the number of hapax
legomena required for the tests are estimated with the help of LNRE models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.richness.fnc(text1, text2, digits = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare.richness.fnc_+3A_text1">text1</code></td>
<td>
<p>First text in the comparison.</p>
</td></tr>
<tr><td><code id="compare.richness.fnc_+3A_text2">text2</code></td>
<td>
<p>Second text in the comparison.</p>
</td></tr>
<tr><td><code id="compare.richness.fnc_+3A_digits">digits</code></td>
<td>
<p>Number of decimal digits required for the growth rate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The comparison for the vocabulary size is carried out with the test statistic
</p>
<p style="text-align: center;"><code class="reqn">Z = \frac{E[V_1] - E[V_2]}{\sqrt{\sigma(V_1)^2 + \sigma(V_2)^2}}</code>
</p>

<p>and the comparison of the growth rates with the test statistic
</p>
<p style="text-align: center;"><code class="reqn">Z = \frac{\frac{1}{N_1}E[V_1(1)] - \frac{1}{N_2}E[V_2]}{\sqrt{\frac{1}{N_1^2}\sigma(V_1(1))^2 + \frac{1}{N_2^2}\sigma(V_2(1))^2}}</code>
</p>

<p>where <code class="reqn">N</code> denotes the sample size in tokens, <code class="reqn">V</code> the vocabulary size,
and <code class="reqn">V(1)</code> the number of hapax legomena.
</p>


<h3>Value</h3>

<p>A summary listing the Chi-Squared measure of goodness of fit for the
LNRE models (available in the zipfR package) used to estimate variances, 
a table listing tokens, types, hapax legomena and the vocabulary growth rate, 
and two-tailed tests for differences in the vocabulary sizes and growth rates with
Z-score and p-value.
</p>


<h3>Note</h3>

<p>It is probably unwise to attempt to apply this function to texts comprising
more than 500,000 words.
</p>


<h3>Author(s)</h3>

<p>R. Harald Baayen 
Radboud University Nijmegen and 
Max Planck Institute for Psycholinguistics, Nijmegen, The Netherlands. 
baayen@mpi.nl
</p>


<h3>References</h3>

<p>Baayen, R. H. (2001) <em>Word Frequency Distributions</em>,
Kluwer Academic Publishers, Dordrecht.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
     data(alice, through, oz)
     compare.richness.fnc(tolower(alice), tolower(through[1:length(alice)]))
     compare.richness.fnc(tolower(alice), tolower(oz[1:25942]))
  
## End(Not run)
</code></pre>

<hr>
<h2 id='corres-class'>Class &quot;corres&quot; </h2><span id='topic+corres-class'></span>

<h3>Description</h3>

<p>A class for correspondence analysis</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("corres", ...)</code>.
Correspondence objects can be plotted, summarized, and printed. 
</p>


<h3>Slots</h3>


<dl>
<dt><code>data</code>:</dt><dd><p>Object of class <code>"list"</code></p>
</dd>
</dl>



<h3>Methods</h3>

<p>No methods defined with class &quot;corres&quot; in the signature.
</p>


<h3>Note</h3>

<p>to be expanded</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p> Murtagh </p>


<h3>See Also</h3>

<p>See Also <code>corres.fnc</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("corres")
</code></pre>

<hr>
<h2 id='corres.fnc'>Correspondence Analysis</h2><span id='topic+corres.fnc'></span>

<h3>Description</h3>

<p>Correspondence analysis for a contingency table. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corres.fnc(xtab)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corres.fnc_+3A_xtab">xtab</code></td>
<td>
<p>A data frame cross-tabulating frequencies.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correspondence object with summary and plot methods.
The summary method lists eigenvalue rates and coordinates, correlations
and contributions for Factor 1 and Factor 2.  By default, only the
first six rows of the factor tables are shown.  Full tables are
obtained by specifying <code>header = FALSE</code> when calling <code>summary</code>.
For information on higher dimensions, set the option <code>n</code> to the
desired number (e.g., <code>n = 3</code>) within <code>summary</code>.
See <code>plot.corres</code> for documentation of plot options.
</p>


<h3>Author(s)</h3>

<p>Extension of the code in Murtagh (2005) by R. Harald Baayen
</p>
<p>Radboud University Nijmegen &amp; Max Planck Institute for Psycholinguistics
</p>
<p>Nijmegen, The Netherlands
</p>
<p>email: baayen@mpi.nl
</p>


<h3>References</h3>

<p>F. Murtagh (2005) <em>Correspondence Analysis and Data Coding with 
JAVA and R</em>, Chapman &amp; Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+corsup.fnc">corsup.fnc</a></code> for adding supplementary data to a 
correspondence plot, and <code><a href="#topic+plot.corres">plot.corres</a></code> for plot options.</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(oldFrench)
  oldFrench.ca = corres.fnc(oldFrench)
  oldFrench.ca
  summary(oldFrench.ca, head = TRUE)
  plot(oldFrench.ca)

  # more readable plot
  data(oldFrenchMeta)
  plot(oldFrench.ca, rlabels = oldFrenchMeta$Genre, 
  rcol = as.numeric(oldFrenchMeta$Genre), rcex = 0.5, 
  extreme = 0.1, ccol = "blue")

  # create subset of proze texts

  prose = oldFrench[oldFrenchMeta$Genre=="prose" &amp; 
          !is.na(oldFrenchMeta$Year),]
  proseinfo = oldFrenchMeta[oldFrenchMeta$Genre=="prose" &amp; 
          !is.na(oldFrenchMeta$Year),]
  proseinfo$Period = as.factor(proseinfo$Year &lt;= 1250)

  prose.ca = corres.fnc(prose)
  plot(prose.ca, addcol = FALSE, 
  rcol = as.numeric(proseinfo$Period) + 1, 
  rlabels = proseinfo$Year, rcex = 0.7)

  # and add supplementary data for texts with unknown date of composition
  proseSup = oldFrench[oldFrenchMeta$Genre == "prose" &amp; 
          is.na(oldFrenchMeta$Year),]
  corsup.fnc(prose.ca, bycol = FALSE, supp = proseSup, font = 2, 
  cex = 0.8, labels = substr(rownames(proseSup), 1, 4)) 
 
## End(Not run)
</code></pre>

<hr>
<h2 id='corresInit'>Initialize correspondence object</h2><span id='topic+corresInit'></span>

<h3>Description</h3>

<p>Function initializing correspondence object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corresInit(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corresInit_+3A_data">data</code></td>
<td>
<p>A list, see the code of <code>corres</code> for further details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correspondence object.
</p>


<h3>Author(s)</h3>

<p>R. Harald Baayen</p>

<hr>
<h2 id='corsup.fnc'>Supplementary rows or columns in correspondence analysis</h2><span id='topic+corsup.fnc'></span>

<h3>Description</h3>

<p>Corsup calculates supplementary rows or columns for correspondence analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>corsup.fnc(corres, bycol = TRUE, supp, plot = TRUE, font = 3, labels = "", 
cex = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="corsup.fnc_+3A_corres">corres</code></td>
<td>
<p>A correspondence object.</p>
</td></tr>
<tr><td><code id="corsup.fnc_+3A_bycol">bycol</code></td>
<td>
<p>A logical value indicating whether supplementary columns
(the default) or supplementary rows are required.</p>
</td></tr>
<tr><td><code id="corsup.fnc_+3A_supp">supp</code></td>
<td>
<p>Supplementary rows or columns from a data frame with the
same structure as the data frame used for the <code>corres</code> object.</p>
</td></tr>
<tr><td><code id="corsup.fnc_+3A_plot">plot</code></td>
<td>
<p>A logical value indicating whether supplementary rows or columns
should be added to an already existing plot.</p>
</td></tr>
<tr><td><code id="corsup.fnc_+3A_font">font</code></td>
<td>
<p>An integer specifying the font to be used for plotting.</p>
</td></tr>
<tr><td><code id="corsup.fnc_+3A_labels">labels</code></td>
<td>
<p>A character vector with row or column names to be used for plotting.</p>
</td></tr>
<tr><td><code id="corsup.fnc_+3A_cex">cex</code></td>
<td>
<p>A real specifying the font size required for plotting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>plot = FALSE</code>, a matrix with the supplementary coordinates.
Otherwise, supplementary rows or columns are added to an already
existing plot of a correspondence object.
</p>


<h3>Author(s)</h3>

<p>Extension of the code in Murtagh (2005) by R. Harald Baayen
</p>
<p>Radboud University Nijmegen &amp; Max Planck Institute for Psycholinguistics
</p>
<p>Nijmegen, The Netherlands
</p>
<p>email: baayen@mpi.nl
</p>


<h3>References</h3>

<p>F. Murtagh (2005) <em>Correspondence Analysis and Data Coding with 
JAVA and R</em>, Chapman &amp; Hall/CRC, Boca Raton, FL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+corres.fnc">corres.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
  data(oldFrench)
  data(oldFrenchMeta)
  prose = oldFrench[oldFrenchMeta$Genre=="prose" &amp; 
          !is.na(oldFrenchMeta$Year),]
  proseinfo = oldFrenchMeta[oldFrenchMeta$Genre=="prose" &amp; 
          !is.na(oldFrenchMeta$Year),]
  proseinfo$Period = as.factor(proseinfo$Year &lt;= 1250)

  prose.ca = corres.fnc(prose)
  plot(prose.ca, addcol = FALSE, 
  rcol = as.numeric(proseinfo$Period) + 1, 
  rlabels = proseinfo$Year, rcex = 0.7)

  proseSup = oldFrench[oldFrenchMeta$Genre == "prose" &amp; 
          is.na(oldFrenchMeta$Year),]
  corsup.fnc(prose.ca, bycol = FALSE, supp = proseSup, font = 2, 
  cex = 0.8, labels = substr(rownames(proseSup), 1, 4)) 
 
## End(Not run)
</code></pre>

<hr>
<h2 id='danish'>Danish auditory lexical decision</h2><span id='topic+danish'></span>

<h3>Description</h3>

<p>Auditory lexical decision latencies for Danish complex words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(danish)</code></pre>


<h3>Format</h3>

<p>A data frame with 3326 observations on the following 16 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a random-effect factor coding participants in the
experiment.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a random-effect factor coding the words for which 
auditory lexical decision responses were elicited.</p>
</dd>
<dt><code>Affix</code></dt><dd><p>a random-effect factor coding the affixes 
in the words.</p>
</dd>
<dt><code>LogRT</code></dt><dd><p>the dependent variable, log response latency.</p>
</dd> 
<dt><code>PC1</code></dt><dd><p>first principal component orthogonalizing the four 
response latencies preceding the current trial in the experiment.</p>
</dd>
<dt><code>PC2</code></dt><dd><p>second principal component orthogonalizing the four 
response latencies preceding the current trial in the experiment.</p>
</dd>
<dt><code>PrevError</code></dt><dd><p>factor with levels <code>CORRECT</code> and <code>ERROR</code> 
coding whether the preceding trial elicited a correct lexical decision.</p>
</dd> 
<dt><code>Rank</code></dt><dd><p>the trial number in the experiment.</p>
</dd> 
<dt><code>Sex</code></dt><dd><p>factor coding the sex of the participant, 
with levels <code>F</code> (female) and <code>M</code> (male).</p>
</dd> 
<dt><code>LogWordFreq</code></dt><dd><p>log-transformed word frequency.</p>
</dd> 
<dt><code>LogAffixFreq</code></dt><dd><p>log-transformed affix frequency.</p>
</dd> 
<dt><code>ResidFamSize</code></dt><dd><p>residualized morphological family size (taking out <code>LogWordFreq</code> and <code>LogAffixFreq</code>).</p>
</dd> 
<dt><code>ResidSemRating</code></dt><dd><p>residualized semantic rating (taking out
morphological family size).</p>
</dd> 
<dt><code>LogCUP</code></dt><dd><p>log-transformed complex uniqueness point (CUP).</p>
</dd> 
<dt><code>LogUP</code></dt><dd><p>log-transformed uniqueness point (UP).</p>
</dd>
<dt><code>LogCUPtoEnd</code></dt><dd><p>log of the distance (in msec) from the CUP to
the end of the word.</p>
</dd> 
</dl>



<h3>References</h3>

<p>L. Balling and R. H. Baayen (2008). Morphological effects in auditory word 
recognition: Evidence from Danish. Submitted to Language and Cognitive Processes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(danish)
require(lme4)
require(lmerTest)
require(optimx)

# ---- mixed-effects regression with three random intercepts

danish.lmer = lmer(LogRT ~ PC1 + PC2 + PrevError + Rank +
  ResidSemRating + ResidFamSize + LogWordFreq*LogAffixFreq*Sex +  
  poly(LogCUP, 2, raw=TRUE) + LogUP + LogCUPtoEnd + 
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
 
danish.lmerA = lmer(LogRT ~ PC1 + PC2 + PrevError + Rank +
  ResidSemRating + ResidFamSize + LogWordFreq*LogAffixFreq*Sex +  
  poly(LogCUP, 2, raw=TRUE) + LogUP + LogCUPtoEnd + 
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  subset=abs(scale(resid(danish.lmer)))&lt;2.5)

summary(danish.lmerA)

## End(Not run)
</code></pre>

<hr>
<h2 id='dative'>Dative Alternation</h2><span id='topic+dative'></span>

<h3>Description</h3>

<p>Data describing the realization of the dative as NP or PP in the Switchboard
corpus and the Treebank Wall Street Journal collection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dative)</code></pre>


<h3>Format</h3>

<p>A data frame with 3263 observations on the following 15 variables.
</p>

<dl>
<dt><code>Speaker</code></dt><dd><p>a factor coding speaker; available only for the 
subset of spoken English.</p>
</dd>
<dt><code>Modality</code></dt><dd><p>a factor with levels <code>spoken</code>, <code>written</code>.</p>
</dd>
<dt><code>Verb</code></dt><dd><p>a factor with the verbs as levels.</p>
</dd> 
<dt><code>SemanticClass</code></dt><dd><p>a factor with levels 
<code>a</code> (abstract: 'give it some thought'), 
<code>c</code> (communication: 'tell, give me your name'), 
<code>f</code> (future transfer of possession: 'owe, promise'), 
<code>p</code> (prevention of possession: 'cost, deny'), and
<code>t</code> (transfer of possession: 'give an armband, send').</p>
</dd>
<dt><code>LengthOfRecipient</code></dt><dd><p>a numeric vector coding the 
number of words comprising the recipient.</p>
</dd>
<dt><code>AnimacyOfRec</code></dt><dd><p>a factor with levels <code>animate</code> and
<code>inanimate</code> for the animacy of the recipient.</p>
</dd>
<dt><code>DefinOfRec</code></dt><dd><p>a factor with levels <code>definite</code> and
<code>indefinite</code> coding the definiteness of the recipient.</p>
</dd>
<dt><code>PronomOfRec</code></dt><dd><p>a factor with levels <code>nonpronominal</code> and
<code>pronominal</code> coding the pronominality of the recipient.</p>
</dd>
<dt><code>LengthOfTheme</code></dt><dd><p>a numeric vector coding the number of words
comprising the theme.</p>
</dd>
<dt><code>AnimacyOfTheme</code></dt><dd><p>a factor with levels <code>animate</code> and
<code>inanimate</code> coding the animacy of the theme.</p>
</dd>
<dt><code>DefinOfTheme</code></dt><dd><p>a factor with levels <code>definite</code> and
<code>indefinite</code> coding the definiteness of the theme.</p>
</dd>
<dt><code>PronomOfTheme</code></dt><dd><p>a factor with levels <code>nonpronominal</code> and
<code>pronominal</code> coding the pronominality of the theme.</p>
</dd>
<dt><code>RealizationOfRecipient</code></dt><dd><p>a factor with levels <code>NP</code> and
<code>PP</code> coding the realization of the dative.</p>
</dd>
<dt><code>AccessOfRec</code></dt><dd><p>a factor with levels <code>accessible</code>, 
<code>given</code>, and <code>new</code> coding the accessibility of the recipient.</p>
</dd>
<dt><code>AccessOfTheme</code></dt><dd><p>a factor with levels <code>accessible</code>, 
<code>given</code>, and <code>new</code> coding the accessibility of the theme.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bresnan, J., Cueni, A., Nikitina, T. and Baayen, R. H. (2007) Predicting the
dative alternation, in Bouma, G. and Kraemer, I. and Zwarts, J.  (eds.),
<em>Cognitive Foundations of Interpretation</em>, Royal Netherlands Academy
of Sciences, 33 pages, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(dative)

# analysis with CART tree

library(rpart)

# ---- initial tree

dative.rp = rpart(RealizationOfRecipient ~ ., 
 data = dative[ ,-c(1, 3)]) # exclude the columns with subjects, verbs
plot(dative.rp, compress = TRUE, branch = 1, margin = 0.1)
text(dative.rp, use.n = TRUE, pretty = 0)

# ---- pruning the initial tree

plotcp(dative.rp)
dative.rp1 = prune(dative.rp, cp = 0.041)
plot(dative.rp1, compress = TRUE, branch = 1, margin = 0.1)
text(dative.rp1, use.n = TRUE, pretty = 0)


# analysis with logistic regression

# ---- logistic regression with the rms package

library(rms)
dative.dd = datadist(dative)
options(datadist = 'dative.dd')
dative.lrm = lrm(RealizationOfRecipient ~ 
  AccessOfTheme + AccessOfRec + LengthOfRecipient + AnimacyOfRec +
  AnimacyOfTheme + PronomOfTheme + DefinOfTheme + LengthOfTheme+
  SemanticClass + Modality, data = dative)
anova(dative.lrm)
plot(Predict(dative.lrm))

# ---- mixed-effects logistic regression with the lme4 package

require(lme4) 
require(lmerTest)
require(optimx)

dative.lmer = glmer(RealizationOfRecipient ~ AccessOfTheme +
  AccessOfRec + LengthOfRecipient + AnimacyOfRec + 
  AnimacyOfTheme + PronomOfTheme + DefinOfTheme + LengthOfTheme + 
  SemanticClass + Modality + (1|Verb), 
  control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = dative, family = "binomial") 

summary(dative.lmer)

# multiple comparisons for Accessibility of Theme
require(multcomp)
par(mar=c(5,8,3,1))
AcOfTheme.glht &lt;- glht(dative.lmer, linfct = mcp(AccessOfTheme = "Tukey"))
plot(AcOfTheme.glht)
abline(v=0)
summary(AcOfTheme.glht)



## End(Not run) </code></pre>

<hr>
<h2 id='dativeSimplified'>Dative Alternation - simplified data set</h2><span id='topic+dativeSimplified'></span>

<h3>Description</h3>

<p>Data describing the realization of the dative as NP or PP in the Switchboard
corpus and the Treebank Wall Street Journal collection. Simplified version
of the dative data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dativeSimplified)</code></pre>


<h3>Format</h3>

<p>A data frame with 903 observations on the following 5 variables.
</p>

<dl>
<dt><code>Verb</code></dt><dd><p>a factor with the verbs as levels.</p>
</dd> 
<dt><code>AnimacyOfRec</code></dt><dd><p>a factor with levels <code>animate</code> and
<code>inanimate</code> for the animacy of the recipient.</p>
</dd>
<dt><code>LengthOfTheme</code></dt><dd><p>a numeric vector coding the number of words
comprising the theme.</p>
</dd>
<dt><code>AnimacyOfTheme</code></dt><dd><p>a factor with levels <code>animate</code> and
<code>inanimate</code> coding the animacy of the theme.</p>
</dd>
<dt><code>RealizationOfRec</code></dt><dd><p>a factor with levels <code>NP</code> and
<code>PP</code> coding the realization of the dative.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bresnan, J., Cueni, A., Nikitina, T. and Baayen, R. H. (2007) Predicting the
dative alternation, in Bouma, G. and Kraemer, I. and Zwarts, J.  (eds.),
<em>Cognitive Foundations of Interpretation</em>, Royal Netherlands Academy
of Sciences, 33 pages, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
    data(dative)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='degreesOrKnots.fnc'>Extract degree of polynomial or knots for restricted cubic spline</h2><span id='topic+degreesOrKnots.fnc'></span>

<h3>Description</h3>

<p>Extract degree of polynomial or knots for restricted cubic spline
from the predictor name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>degreesOrKnots.fnc(name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="degreesOrKnots.fnc_+3A_name">name</code></td>
<td>
<p>name of predictor, e.g. <code>poly(X, 2, raw = TRUE)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>attempts to find degrees or knots if present in input name
</p>


<h3>Value</h3>

<p>Returns an integer for degrees or knots
</p>


<h3>Note</h3>

 
<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='durationsGe'>Durational measurements on the Dutch prefix ge-</h2><span id='topic+durationsGe'></span>

<h3>Description</h3>

<p>Durational measurements on the Dutch prefix <em>ge-</em> in the 
Spoken Dutch Corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(durationsGe)</code></pre>


<h3>Format</h3>

<p>A data frame with 428 observations on the following 8 variables.
</p>

<dl>
<dt><code>Word</code></dt><dd><p>a factor with the words as levels.</p>
</dd> 
<dt><code>Frequency</code></dt><dd><p>a numeric vector with the word's 
absolute frequency in the Spoken Dutch Corpus.</p>
</dd>
<dt><code>Speaker</code></dt><dd><p>a factor with the speakers as levels.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a factor with levels <code>female</code> and <code>male</code>, 
this information is missing for one speaker.</p>
</dd>
<dt><code>YearOfBirth</code></dt><dd><p>a numeric vector with years of birth.</p>
</dd>
<dt><code>DurationOfPrefix</code></dt><dd><p>a numeric vector with the duration of the
prefix -ont in seconds.</p>
</dd>
<dt><code>SpeechRate</code></dt><dd><p>a numeric vector coding speech rate in number
of syllables per second.</p>
</dd>
<dt><code>NumberSegmentsOnset</code></dt><dd><p>a numeric vector for the number of 
segments in the onset of the stem.</p>
</dd>
</dl>



<h3>References</h3>

<p>Pluymaekers, M., Ernestus, M. and Baayen, R. H. (2005) Frequency and acoustic
length: the case of derivational affixes in Dutch, <em>Journal of the
Acoustical Society of America</em>, 118, 2561-2569.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
    data(durationsGe)
    durationsGe$Frequency = log(durationsGe$Frequency + 1)
    durationsGe$YearOfBirth = durationsGe$YearOfBirth - 1900

    durationsGe.lm = lm(DurationOfPrefix ~ Frequency+SpeechRate, data = durationsGe)
    summary(durationsGe.lm)

    # ---- model criticism
    
    plot(durationsGe.lm)
    outliers = c(271, 392, 256, 413, 118, 256)
    durationsGe.lm = lm(DurationOfPrefix ~ Frequency + SpeechRate, 
      data = durationsGe[-outliers, ])
    summary(durationsGe.lm)
  
## End(Not run)

</code></pre>

<hr>
<h2 id='durationsOnt'>Durational measurements on the Dutch prefix ont-</h2><span id='topic+durationsOnt'></span>

<h3>Description</h3>

<p>Durational measurements on the Dutch prefix <em>ont-</em> 
in the Spoken Dutch Corpus. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(durationsOnt)</code></pre>


<h3>Format</h3>

<p>A data frame with 102 observations on the following 11 variables.
</p>

<dl>
<dt><code>Word</code></dt><dd><p>a factor with the words as levels.</p>
</dd>
<dt><code>Frequency</code></dt><dd><p>a numeric vector with the word's logarithmically
transformed frequency in the Spoken Dutch Corpus.</p>
</dd>
<dt><code>Speaker</code></dt><dd><p>a factor with speakers as levels.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a factor with levels <code>female</code> and <code>male</code>.</p>
</dd>
<dt><code>YearOfBirth</code></dt><dd><p>a numeric vector coding year of birth of the
speaker - 1900.</p>
</dd>
<dt><code>DurationOfPrefix</code></dt><dd><p>a numeric vector for the duration of ont-
in seconds</p>
</dd>
<dt><code>DurationPrefixVowel</code></dt><dd><p>a numeric vector for the duration of the
vowel in the prefix in seconds.</p>
</dd>
<dt><code>DurationPrefixNasal</code></dt><dd><p>a numeric vector for the duration of the
nasal in the prefix in seconds.</p>
</dd>
<dt><code>DurationPrefixPlosive</code></dt><dd><p>a numeric vector for the duration of the   plosive in the prefix in seconds.</p>
</dd>
<dt><code>NumberOfSegmentsOnset</code></dt><dd><p>a numeric vector for the number of segments in the onset of the stem.</p>
</dd>
<dt><code>PlosivePresent</code></dt><dd><p>a factor with levels <code>no</code> and <code>yes</code> 
for whether the plosive is realized in the signal.</p>
</dd>
<dt><code>SpeechRate</code></dt><dd><p>a numeric vector coding speech rate in number
of syllables per second.</p>
</dd>
</dl>



<h3>References</h3>

<p>Pluymaekers, M., Ernestus, M. and Baayen, R. H. (2005) Frequency and acoustic
length: the case of derivational affixes in Dutch, <em>Journal of the
Acoustical Society of America</em>, 118, 2561-2569.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(durationsOnt)

###### modeling the duration of the prefix

prefix.lm = lm(DurationOfPrefix ~ (YearOfBirth + SpeechRate) * Frequency, 
   data = durationsOnt)
summary(prefix.lm)

# ---- model criticism

plot(prefix.lm)
outliers = c(36, 35, 17, 72)
prefix.lm = lm(DurationOfPrefix ~ (YearOfBirth + SpeechRate) * Frequency, 
   data = durationsOnt[-outliers,])
summary(prefix.lm)

###### modeling the presence of the /t/ 

library(rms)
durationsOnt.dd = datadist(durationsOnt)
options(datadist = 'durationsOnt.dd')

plosive.lrm = lrm(PlosivePresent ~ SpeechRate + YearOfBirth, 
   data = durationsOnt, x = TRUE, y = TRUE)
plosive.lrm
validate(plosive.lrm, bw = TRUE, B = 200)

###### modeling the duration of the /n/

nasal.lm = lm(DurationPrefixNasal ~ PlosivePresent + Frequency + 
   YearOfBirth, data = durationsOnt)
summary(nasal.lm)

# ---- model criticism

plot(nasal.lm)
outliers = c(71, 28, 62, 33)
nasal.lm = lm(DurationPrefixNasal ~ PlosivePresent + Frequency + 
   YearOfBirth, data = durationsOnt[-outliers,])
summary(nasal.lm)

</code></pre>

<hr>
<h2 id='dutchSpeakersDist'>Cross-entropy based distances between speakers</h2><span id='topic+dutchSpeakersDist'></span>

<h3>Description</h3>

<p>A distance matrix for the conversations of 165 speakers in the 
Spoken Dutch Corpus.  Metadata on the speakers are available in
a separate dataset, <code>dutchSpeakersDistMeta</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dutchSpeakersDist)</code></pre>


<h3>Format</h3>

<p>A data frame for a 165 by 165 matrix of between-speaker differences.
</p>


<h3>Source</h3>

<p>http://lands.let.kun.nl/cgn/
data collected and analyzed in collaboration with Patrick Juola
</p>


<h3>References</h3>

<p>Juola, P. (2003) The time course of language change,
<em>Computers and the Humanities</em>, 37, 77-96.
</p>
<p>Juola, P. and Baayen, R. H. (2005) A Controlled-corpus Experiment in Authorship
Identification by Cross-entropy, <em>Literary and Linguistic Computing</em>, 20,
59-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
    data(dutchSpeakersDist)
    dutchSpeakersDist.d = as.dist(dutchSpeakersDist)
    dutchSpeakersDist.mds = cmdscale(dutchSpeakersDist.d, k = 3)

    data(dutchSpeakersDistMeta)
    dat = data.frame(dutchSpeakersDist.mds, 
       Sex = dutchSpeakersDistMeta$Sex, 
       Year = dutchSpeakersDistMeta$AgeYear, 
       EduLevel = dutchSpeakersDistMeta$EduLevel)
    dat = dat[!is.na(dat$Year),]

    par(mfrow=c(1,2))
    plot(dat$Year, dat$X1, xlab="year of birth", 
       ylab = "dimension 1", type = "p")
    lines(lowess(dat$Year, dat$X1))
    boxplot(dat$X3 ~ dat$Sex, ylab = "dimension 3")
    par(mfrow=c(1,1))

    cor.test(dat$X1, dat$Year, method="sp")
    t.test(dat$X3~dat$Sex)
	
## End(Not run)
</code></pre>

<hr>
<h2 id='dutchSpeakersDistMeta'>Metadata for dutchSpeakersDist</h2><span id='topic+dutchSpeakersDistMeta'></span>

<h3>Description</h3>

<p>Meta-data for the cross-entropy based between-speaker 
distance matrix <code>dutchSpeakersDist</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dutchSpeakersDistMeta)</code></pre>


<h3>Format</h3>

<p>A data frame with 165 observations on the following 6 variables.
</p>

<dl>
<dt><code>Speaker</code></dt><dd><p>a factor with speakers as levels.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a factor with levels <code>female</code> and <code>male</code>.</p>
</dd>
<dt><code>AgeYear</code></dt><dd><p>a numeric vector with the speakers' year of birth.</p>
</dd>
<dt><code>AgeGroup</code></dt><dd><p>a factor with levels <code>age18to24</code>,
<code>age25to34</code>, <code>age35to44</code>, <code>age45to55</code>, and
<code>age56up</code></p>
</dd></dl>
<p>. 
</p>
<dl>
<dt><code>ConversationType</code></dt><dd><p>a factor with levels <code>femaleOnly</code> <code>maleFemale</code>, <code>maleOnly</code>, and <code>unknown</code>.</p>
</dd>
<dt><code>EduLevel</code></dt><dd><p>a factor with levels <code>EduUnknown</code>, <code>high</code>,
<code>low</code> <code>mid</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>http://lands.let.kun.nl/cgn/
</p>


<h3>References</h3>

<p>Juola, P. (2003) The time course of language change,
<em>Computers and the Humanities</em>, 37, 77-96.
</p>
<p>Juola, P. and Baayen, R. H. (2005) A Controlled-corpus Experiment in Authorship
Identification by Cross-entropy, <em>Literary and Linguistic Computing</em>, 20,
59-67.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
     data(dutchSpeakersDistMeta)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='english'>English visual lexical decision and naming latencies</h2><span id='topic+english'></span><span id='topic+english'></span>

<h3>Description</h3>

<p>This data set gives mean visual lexical decision latencies and word
naming latencies to 2284 monomorphemic English nouns and verbs,
averaged for old and young subjects, with various predictor variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(english)</code></pre>


<h3>Format</h3>

<p>A data frame with 4568 observations on the following variables.
</p>

<dl>
<dt><code>RTlexdec</code></dt><dd><p>numeric vector of log RT in visual lexical decision.</p>
</dd>
<dt><code>RTnaming</code></dt><dd><p>numeric vector of log RT in word naming.</p>
</dd>
<dt><code>Familiarity</code></dt><dd><p>numeric vector of subjective familiarity ratings.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with 2284 words.</p>
</dd>
<dt><code>AgeSubject</code></dt><dd><p>a factor with as levels the age group of the subject: 
<code>young</code> versus <code>old</code>.</p>
</dd> 
<dt><code>WordCategory</code></dt><dd><p>a factor with as levels the word categories 
<code>N</code> (noun) and <code>V</code> (verb).</p>
</dd> 
<dt><code>WrittenFrequency</code></dt><dd><p>numeric vector with log frequency in the CELEX lexical
database.</p>
</dd> 
<dt><code>WrittenSpokenFrequencyRatio</code></dt><dd><p>numeric vector with the logged ratio 
of written frequency (CELEX) to spoken frequency (British National Corpus).</p>
</dd> 
<dt><code>FamilySize</code></dt><dd><p>numeric vector with log morphological family size.</p>
</dd> 
<dt><code>DerivationalEntropy</code></dt><dd><p>numeric vector with derivational entropy.</p>
</dd> 
<dt><code>InflectionalEntropy</code></dt><dd><p>numeric vector with inflectional entropy.</p>
</dd> 
<dt><code>NumberSimplexSynsets</code></dt><dd><p>numeric vector with the log-transformed count of 
synonym sets in WordNet in which the word is listed.</p>
</dd> 
<dt><code>NumberComplexSynsets</code></dt><dd><p>numeric vector with the log-transformed count of
synonym sets in WordNet in which the word is listed as part of a compound.</p>
</dd> 
<dt><code>LengthInLetters</code></dt><dd><p>numeric vector with length of the word in letters.</p>
</dd> 
<dt><code>Ncount</code></dt><dd><p>numeric vector with orthographic neighborhood density, defined as the number of lemmas in CELEX with the same length (in letters) 
at Hamming distance 1.</p>
</dd> 
<dt><code>MeanBigramFrequency</code></dt><dd><p>numeric vector with mean log bigram frequency.</p>
</dd> 
<dt><code>FrequencyInitialDiphone</code></dt><dd><p>numeric vector with log frequency of initial diphone.</p>
</dd> 
<dt><code>ConspelV</code></dt><dd><p>numeric vector with type count of orthographic neighbors.</p>
</dd> 
<dt><code>ConspelN</code></dt><dd><p>numeric vector with token count of orthographic neighbors.</p>
</dd> 
<dt><code>ConphonV</code></dt><dd><p>numeric vector with type count of phonological neighbors.</p>
</dd> 
<dt><code>ConphonN</code></dt><dd><p>numeric vector with token count of phonological neighbors.</p>
</dd> 
<dt><code>ConfriendsV</code></dt><dd><p>numeric vector with type counts of consistent words.</p>
</dd> 
<dt><code>ConfriendsN</code></dt><dd><p>numeric vector with token counts of consistent words.</p>
</dd> 
<dt><code>ConffV</code></dt><dd><p>numeric vector with type count of forward inconsistent words </p>
</dd>   
<dt><code>ConffN</code></dt><dd><p>numeric vector with token count of forward inconsistent words  </p>
</dd> 
<dt><code>ConfbV</code></dt><dd><p>numeric vector with type count of backward inconsistent words  </p>
</dd> 
<dt><code>ConfbN</code></dt><dd><p>numeric vector with token count of backward inconsistent words </p>
</dd> 
<dt><code>NounFrequency</code></dt><dd><p>numeric vector with the frequency of the word used as noun.</p>
</dd> 
<dt><code>VerbFrequency</code></dt><dd><p>numeric vector with the frequency of the word used as verb.</p>
</dd> 
<dt><code>CV</code></dt><dd><p>factor specifying whether the initial phoneme of 
the word is a consonant (<code>C</code>) or a vowel (<code>V</code>).</p>
</dd> 
<dt><code>Obstruent</code></dt><dd><p>factor specifying whether the initial phoneme 
of the word is a continuant (<code>cont</code>) or an obstruent (<code>obst</code>).</p>
</dd> 
<dt><code>Frication</code></dt><dd><p>factor specifying whether the initial phoneme 
has a burst (<code>burst</code>) or frication (<code>frication</code>) for 
consonant-initial words, and for vowel-initial words whether the vowel is 
<code>long</code> or <code>short</code>.</p>
</dd> 
<dt><code>Voice</code></dt><dd><p>factor indicating whether the initial phoneme is <code>voiced</code>
or <code>voiceless</code>.</p>
</dd> 
<dt><code>FrequencyInitialDiphoneWord</code></dt><dd><p>numeric vector with the log-transformed 
frequency of the initial diphone given that it is syllable-initial.</p>
</dd> 
<dt><code>FrequencyInitialDiphoneSyllable</code></dt><dd><p>numeric vector with the log-transformed 
frequency of the initial diphone given that it is word initial.</p>
</dd> 
<dt><code>CorrectLexdec</code></dt><dd><p>numeric vector with the proportion of 
subjects that accepted the item as a word in lexical decision.</p>
</dd>
</dl>



<h3>Source</h3>

 
<p>Balota, D.A., Cortese, M.J. and Pilotti, M. (1999) <em>
Visual lexical decision latencies for 2906 words</em>. Available at http://www.artsci.wustl.edu/~dbalota/lexical_decision.html.
</p>
<p>Spieler, D. H. and Balota, D. A. (1998) <em>
Naming latencies for 2820 words</em>, available at
http://www.artsci.wustl.edu/~dbalota/naming.html.
</p>


<h3>References</h3>

 
<p>Balota, D., Cortese, M., Sergent-Marshall, S., Spieler, D. and Yap, M.
(2004) Visual word recognition for single-syllable words, <em>Journal of
Experimental Psychology:General</em>, 133, 283-316.
</p>
<p>Baayen, R.H., Feldman, L. and Schreuder, R. (2006)
Morphological influences on the recognition of monosyllabic 
monomorphemic words, <em>Journal of Memory and Language</em>,
53, 496-512.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(english)

# ---- orthogonalize orthographic consistency measures

items = english[english$AgeSubject == "young",]
items.pca = prcomp(items[ , c(18:27)], center = TRUE, scale = TRUE)
x = as.data.frame(items.pca$rotation[,1:4])
items$PC1 =  items.pca$x[,1]
items$PC2 =  items.pca$x[,2]
items$PC3 =  items.pca$x[,3]
items$PC4 =  items.pca$x[,4]
items2 = english[english$AgeSubject != "young", ]
items2$PC1 =  items.pca$x[,1]
items2$PC2 =  items.pca$x[,2]
items2$PC3 =  items.pca$x[,3]
items2$PC4 =  items.pca$x[,4]
english = rbind(items, items2) 

# ---- add Noun-Verb frequency ratio

english$NVratio = log(english$NounFrequency+1)-log(english$VerbFrequency+1)

# ---- build model with ols() from rms

library(rms)
english.dd = datadist(english)
options(datadist = 'english.dd')

english.ols = ols(RTlexdec ~ Voice + PC1 + MeanBigramFrequency + 
   rcs(WrittenFrequency, 5) + rcs(WrittenSpokenFrequencyRatio, 3) + 
   NVratio + WordCategory + AgeSubject +
   rcs(FamilySize, 3) + InflectionalEntropy + 
   NumberComplexSynsets + rcs(WrittenFrequency, 5) : AgeSubject,
   data = english, x = TRUE, y = TRUE)

# ---- plot partial effects

plot(Predict(english.ols))

# ---- validate the model

validate(english.ols, bw = TRUE, B = 200)


## End(Not run)</code></pre>

<hr>
<h2 id='etymology'>Etymological age and regularity in Dutch</h2><span id='topic+etymology'></span>

<h3>Description</h3>

<p>Estimated etymological age for regular and irregular monomorphemic Dutch
verbs, together with other distributional predictors of regularity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(etymology)</code></pre>


<h3>Format</h3>

<p>A data frame with 285 observations on the following 14 variables.
</p>

<dl>
<dt><code>Verb</code></dt><dd><p>a factor with the verbs as levels.</p>
</dd>
<dt><code>WrittenFrequency</code></dt><dd><p>a numeric vector of logarithmically transformed
frequencies in written Dutch (as available in the CELEX lexical database).</p>
</dd>
<dt><code>NcountStem</code></dt><dd><p>a numeric vector for the number of orthographic neighbors.</p>
</dd>
<dt><code>MeanBigramFrequency</code></dt><dd><p>a numeric vector for mean log bigram frequency.</p>
</dd>
<dt><code>InflectionalEntropy</code></dt><dd><p>a numeric vector for Shannon's entropy calculated for the word's inflectional variants.</p>
</dd>
<dt><code>Auxiliary</code></dt><dd><p>a factor with levels <code>hebben</code>, <code>zijn</code> and <code>zijnheb</code> for the verb's auxiliary in the perfect tenses.</p>
</dd>
<dt><code>Regularity</code></dt><dd><p>a factor with levels <code>irregular</code> and <code>regular</code>.</p>
</dd>
<dt><code>LengthInLetters</code></dt><dd><p>a numeric vector of the word's orthographic length.</p>
</dd>
<dt><code>Denominative</code></dt><dd><p>a factor with levels <code>Den</code> and <code>N</code> specifying
whether a verb is derived from a noun according to the CELEX lexical database.</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector for the number of types in the word's 
morphological family.</p>
</dd>
<dt><code>EtymAge</code></dt><dd><p>an ordered factor with levels <code>Dutch</code>, <code>DutchGerman</code>, <code>WestGermanic</code>, <code>Germanic</code> and <code>IndoEuropean</code>.</p>
</dd>
<dt><code>Valency</code></dt><dd><p>a numeric vector for the verb's valency, estimated by its 
number of argument structures.</p>
</dd>
<dt><code>NVratio</code></dt><dd><p>a numeric vector for the log-transformed ratio of the nominal
and verbal frequencies of use.</p>
</dd>
<dt><code>WrittenSpokenRatio</code></dt><dd><p>a numeric vector for the log-transformed ratio of the frequencies in written and spoken Dutch.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baayen, R. H. and Moscoso del Prado Martin, F. (2005) Semantic density and 
past-tense formation in three Germanic languages, Language, 81, 666-698.
</p>
<p>Tabak, W., Schreuder, R. and Baayen, R. H. (2005) Lexical statistics and
lexical processing: semantic density, information complexity, sex, and
irregularity in Dutch, in Kepser, S. and Reis, M., <em>Linguistic Evidence -
Empirical, Theoretical, and Computational Perspectives</em>, Berlin: Mouton de
Gruyter, pp. 529-555.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(etymology)

# ---- EtymAge should be an ordered factor, set contrasts accordingly

etymology$EtymAge = ordered(etymology$EtymAge, levels = c("Dutch",
"DutchGerman", "WestGermanic", "Germanic", "IndoEuropean")) 
options(contrasts=c("contr.treatment","contr.treatment"))

library(rms)
etymology.dd = datadist(etymology)
options(datadist = 'etymology.dd')

# ---- EtymAge as additional predictor for regularity

etymology.lrm = lrm(Regularity ~ WrittenFrequency + 
rcs(FamilySize, 3) + NcountStem + InflectionalEntropy + 
Auxiliary + Valency + NVratio + WrittenSpokenRatio + EtymAge, 
data = etymology, x = TRUE, y = TRUE)
anova(etymology.lrm)

# ---- EtymAge as dependent variable

etymology.lrm = lrm(EtymAge ~ WrittenFrequency + NcountStem +
MeanBigramFrequency + InflectionalEntropy + Auxiliary +
Regularity + LengthInLetters + Denominative + FamilySize + Valency + 
NVratio + WrittenSpokenRatio, data = etymology, x = TRUE, y = TRUE)

# ---- model simplification 

etymology.lrm = lrm(EtymAge ~ NcountStem + Regularity + Denominative, 
data = etymology, x = TRUE, y = TRUE)
validate(etymology.lrm, bw=TRUE, B=200)

# ---- plot partial effects and check assumptions ordinal regression

plot(Predict(etymology.lrm))
plot(etymology.lrm)
resid(etymology.lrm, 'score.binary', pl = TRUE)
plot.xmean.ordinaly(EtymAge ~ NcountStem, data = etymology)

## End(Not run)
</code></pre>

<hr>
<h2 id='faz'>Frankfurter frequencies</h2><span id='topic+faz'></span>

<h3>Description</h3>

<p>Frequencies of references to previous years in issues of the Frankfurter 
Allgemeine Zeiting published in 1994.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(faz)</code></pre>


<h3>Format</h3>

<p>A data frame with 800 observations on the following 2 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd><p>a numeric vector coding years referenced in articles
published in 1994.</p>
</dd>
<dt><code>Frequency</code></dt><dd><p>a numeric vector for the frequencies with which
years are referenced.</p>
</dd>
</dl>



<h3>References</h3>

<p>Pollman, T. and Baayen, R. H. (2001)
Computing historical consciousness.  A quantitative inquiry
into the presence of the past in newspaper texts, 
<em>Computers and the Humanities</em>, 35, 237-253.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(faz)
faz$Distance = 1:nrow(faz)

# ---- visualization

plot(log(faz$Distance), log(faz$Frequency + 1), 
xlab = "log Distance", ylab = "log Frequency")
abline(v = log(49), lty=1, col="red")   # 1945
abline(v = log(54), lty=1, col="red")   # 1940
abline(v = log(76), lty=2, col="blue")  # 1918
abline(v = log(80), lty=2, col="blue")  # 1914

# ---- breakpoint analysis

deviances = rep(0, nrow(faz)-1)
faz$LogFrequency = log(faz$Frequency + 1)
faz$LogDistance = log(faz$Distance)
for (pos in 1 : (nrow(faz)-1)) {                             # be patient
  breakpoint = log(pos)
  faz$ShiftedLogDistance = faz$LogDistance - breakpoint
  faz$PastBreakPoint = as.factor(faz$ShiftedLogDistance &gt; 0)
  faz.both = lm(LogFrequency~ShiftedLogDistance:PastBreakPoint, data = faz)
  deviances[pos] = deviance(faz.both)
}
breakpoint = log(which(deviances == min(deviances)))

# ---- refit and plot

faz$ShiftedLogDistance = faz$LogDistance - breakpoint
faz$PastBreakPoint = as.factor(faz$ShiftedLogDistance &gt; 0)
faz.both = lm(LogFrequency ~ ShiftedLogDistance:PastBreakPoint, data = faz)

plot(faz$LogDistance, faz$LogFrequency, 
xlab = "log Distance", ylab = "log Frequency", col = "darkgrey")
lines(faz$LogDistance, fitted(faz.both))

## End(Not run)

</code></pre>

<hr>
<h2 id='finalDevoicing'>Final Devoicing in Dutch</h2><span id='topic+finalDevoicing'></span>

<h3>Description</h3>

<p>Phonological specifications for onset, nucleus and offset for 1697 Dutch
monomorphemic words with a final obstruent.  These final obstruents may exhibit
a voicing alternation that is traditionally described as syllable-final
devoicing: underlying /d/ in /hond/ becomes a /t/ when syllable-final ([hOnt])
and remains a /d/ otherwise ([hOn-den]). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(finalDevoicing)</code></pre>


<h3>Format</h3>

<p>A data frame with 1697 observations on the following 9 variables.
</p>

<dl>
<dt><code>Word</code></dt><dd><p>a factor with the words as levels.</p>
</dd> 
<dt><code>Onset1Type</code></dt><dd><p>a factor for the first consonant in the onset, with levels <code>None</code>, 
<code>Obstruent</code> and <code>Sonorant</code>.</p>
</dd>
<dt><code>Onset2Type</code></dt><dd><p>a factor for the second consonant in the onset, with levels <code>None</code>, 
<code>Obstruent</code> and <code>Sonorant</code>.</p>
</dd>
<dt><code>VowelType</code></dt><dd><p>a factor describing the vowel with levels <code>iuy</code>, <code>long</code> and 
<code>short</code>.</p>
</dd>
<dt><code>ConsonantType</code></dt><dd><p>a factor for the first consonant in the offset, with levels <code>None</code>,
<code>Obstruent</code> and <code>Sonorant</code>.</p>
</dd>
<dt><code>Obstruent</code></dt><dd><p>a factor describing place and manner of articulation of the final obstruent, 
with levels <code>F</code> (/f,v/), <code>P</code> (/p,b/), <code>S</code> (/s,z/), <code>T</code> (/t,d/) and
<code>X</code> (/x,g/).</p>
</dd>
<dt><code>Nsyll</code></dt><dd><p>a numeric vector for the number of syllables in the word.</p>
</dd>
<dt><code>Stress</code></dt><dd><p>a factor with levels <code>A</code> (antepenult), <code>F</code> (final) and
<code>P</code> (penult).</p>
</dd>
<dt><code>Voice</code></dt><dd><p>a factor with levels <code>voiced</code> and <code>voiceless</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Ernestus, M. and Baayen, R. H. (2003) Predicting the unpredictable:
Interpreting neutralized segments in Dutch, <em>Language</em>, 79, 5-38.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(finalDevoicing)
library(rpart)

# ---- CART tree 

finalDevoicing.rp = rpart(Voice ~ ., data = finalDevoicing[ , -1])
plotcp(finalDevoicing.rp)
finalDevoicing.pruned = prune(finalDevoicing.rp, cp = 0.021)
plot(finalDevoicing.pruned, margin = 0.1, compress = TRUE)
text(finalDevoicing.pruned, use.n = TRUE, pretty = 0, cex=0.8)

# ---- logistic regression 

library(rms)

finalDevoicing.dd = datadist(finalDevoicing)
options(datadist='finalDevoicing.dd')

finalDevoicing.lrm = lrm(Voice ~ VowelType + ConsonantType + Obstruent + 
Nsyll + Stress + Onset1Type + Onset2Type, data = finalDevoicing)
anova(finalDevoicing.lrm)

# ---- model simplification

fastbw(finalDevoicing.lrm)

finalDevoicing.lrm = lrm(Voice ~ VowelType + ConsonantType + 
Obstruent + Nsyll, data = finalDevoicing, x = TRUE, y = TRUE)

plot(Predict(finalDevoicing.lrm))

# ---- model validation

validate(finalDevoicing.lrm, B = 200)

## End(Not run)
</code></pre>

<hr>
<h2 id='getKnots.fnc'>Extracts knots from variable name</h2><span id='topic+getKnots.fnc'></span>

<h3>Description</h3>

<p>Extracts knots for predictor specified simply as, e.g., <code>X</code>
from column names of model@X or model@frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getKnots.fnc(colnms, xlb)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getKnots.fnc_+3A_colnms">colnms</code></td>
<td>
<p> columns of <code>model@X</code> </p>
</td></tr>
<tr><td><code id="getKnots.fnc_+3A_xlb">xlb</code></td>
<td>
<p> simple predictor name </p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>an integer (number of knots)
</p>


<h3>Note</h3>

 
<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='getMCMCintervals.fnc'>calculate HPD prediction intervals</h2><span id='topic+getMCMCintervals.fnc'></span>

<h3>Description</h3>

<p>calculate HPD 95% prediction intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getMCMCintervals.fnc(fixf, mcmcMatrix, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getMCMCintervals.fnc_+3A_fixf">fixf</code></td>
<td>
<p> vector of fixed effects coefficients (<code>fixef(model.lmer)</code>) </p>
</td></tr>
<tr><td><code id="getMCMCintervals.fnc_+3A_mcmcmatrix">mcmcMatrix</code></td>
<td>
<p> MCMC matrix obtained with <code>mcmcsamp</code> or 
<code>pvals.fnc</code></p>
</td></tr>
<tr><td><code id="getMCMCintervals.fnc_+3A_m">m</code></td>
<td>
<p> model matrix </p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>A matrix with columns '&quot;lower&quot;' and
'&quot;upper&quot;' and rows corresponding to the values of the predictor to
be plotted on the X-axis.
</p>


<h3>Note</h3>

<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>languageR</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='getPos.fnc'> determine position for labels for interaction plots </h2><span id='topic+getPos.fnc'></span>

<h3>Description</h3>

<p>determines the position (in the X and Y vectors) for the 
adding of text to an interaction plot 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getPos.fnc(vec, pos)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getPos.fnc_+3A_vec">vec</code></td>
<td>
<p>vector of Y values</p>
</td></tr>
<tr><td><code id="getPos.fnc_+3A_pos">pos</code></td>
<td>
<p>can be '&quot;beg&quot;', '&quot;mid&quot;', '&quot;end&quot;'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>an integer specifying position in vector for X and Y values in plot
</p>


<h3>Note</h3>

<p>not indended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='getRange.fnc'>Extracts range of predicted values from list of data frames</h2><span id='topic+getRange.fnc'></span>

<h3>Description</h3>

<p>Extracts range of predicted values from list of data frames
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRange.fnc(lst)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRange.fnc_+3A_lst">lst</code></td>
<td>
<p>a list with one or more data frames with column names
<code>Y</code> and optionally <code>lower</code> and <code>upper</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use.
</p>


<h3>Value</h3>

<table>
<tr><td><code>value</code></td>
<td>
<p>a two-element vector specifying the range of values in <code>Y</code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>not intended for separate use.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p> See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  not intended for independent use

## End(Not run)
</code></pre>

<hr>
<h2 id='getRoot.fnc'>extract simple name of predictor from expression with poly</h2><span id='topic+getRoot.fnc'></span>

<h3>Description</h3>

<p>extract <code>X</code> from expressions such as <code>poly(X, 3, raw = TRUE</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getRoot.fnc(xlabel)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getRoot.fnc_+3A_xlabel">xlabel</code></td>
<td>
<p>character string for predictor name</p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>a character string (simple name of predictor)
</p>


<h3>Note</h3>

 
<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='growth-class'>Class &quot;growth&quot; </h2><span id='topic+growth-class'></span>

<h3>Description</h3>

<p>A class for the analysis of word frequency distributions</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("growth", ...)</code>.
Growth objects can be plotted, summarized, and printed. 
</p>


<h3>Slots</h3>


<dl>
<dt><code>data</code>:</dt><dd><p>Object of class <code>"list"</code>  </p>
</dd>
</dl>



<h3>Methods</h3>

<p>No methods defined with class &quot;growth&quot; in the signature.
</p>


<h3>Note</h3>

<p>to be expanded</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p> R. H. Baayen, 2007 </p>


<h3>See Also</h3>

<p>See Also <code>growth.fnc</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>showClass("growth")
</code></pre>

<hr>
<h2 id='growth.fnc'>Calculate vocabulary growth curve and vocabulary richness measures</h2><span id='topic+growth.fnc'></span>

<h3>Description</h3>

<p>This function calculates, for an increasing sequence of text sizes,
the observed number of types, hapax legomena, dis legomena, tris legomena,
and selected measures of lexical richness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growth.fnc(text = languageR::alice, size = 646, nchunks = 40, chunks = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="growth.fnc_+3A_text">text</code></td>
<td>
<p>A vector of strings representing a text.</p>
</td></tr>
<tr><td><code id="growth.fnc_+3A_size">size</code></td>
<td>
<p>An integer giving the size of a text chunk 
when the text is to be split into a series of equally-sized text chunks.</p>
</td></tr>
<tr><td><code id="growth.fnc_+3A_nchunks">nchunks</code></td>
<td>
<p>An integer denoting the number of desired equally-sized
text chunks.</p>
</td></tr>
<tr><td><code id="growth.fnc_+3A_chunks">chunks</code></td>
<td>
<p>An integer vector denoting the token sizes for which growth
measures are required. When chunks is specified, <code>size</code> and 
<code>nchunks</code> are ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A growth object with methods for plotting, printing.
As running this function on large texts may take some time,
a period is printed on the output device for each completed chunk
to indicate progress.
</p>
<p>The data frame with the actual measures, which can be extracted with 
<code>object.name@data$data</code>, has the following columns.
</p>
<table>
<tr><td><code>Chunk</code></td>
<td>
<p>a numeric vector with chunk numbers.</p>
</td></tr> 
<tr><td><code>Tokens</code></td>
<td>
<p>a numeric vector with the number of tokens up to
and including the current chunk.</p>
</td></tr> 
<tr><td><code>Types</code></td>
<td>
<p>a numeric vector with the number of types up to and
including the current chunk.</p>
</td></tr> 
<tr><td><code>HapaxLegomena</code></td>
<td>
<p>a numeric vector with the corresponding count
of hapax legomena.</p>
</td></tr> 
<tr><td><code>DisLegomena</code></td>
<td>
<p>a numeric vector with the corresponding count
of dis legomena.</p>
</td></tr> 
<tr><td><code>TrisLegomena</code></td>
<td>
<p>a numeric vector with the corresponding count
of tris legomena.</p>
</td></tr> 
<tr><td><code>Yule</code></td>
<td>
<p>a numeric vector with Yule's <code>K</code>.</p>
</td></tr>
<tr><td><code>Zipf</code></td>
<td>
<p>a numeric vector with the slope of Zipf's rank-frequency
curve in the double-logarithmic plane.</p>
</td></tr>
<tr><td><code>TypeTokenRatio</code></td>
<td>
<p>a numeric vector with the ratio of types to
tokens.</p>
</td></tr>
<tr><td><code>Herdan</code></td>
<td>
<p>a numeric vector with Herdan's <code>C</code>.</p>
</td></tr>
<tr><td><code>Guiraud</code></td>
<td>
<p>a numeric vector with Guiraud's <code>R</code>.</p>
</td></tr>
<tr><td><code>Sichel</code></td>
<td>
<p>a numeric vector with Sichel's <code>S</code>.</p>
</td></tr>
<tr><td><code>Lognormal</code></td>
<td>
<p>a numeric vector with mean log frequency.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>R. H. Baayen (2001) <em>Word Frequency Distributions</em>,
Dordrecht: Kluwer Academic Publishers.
</p>
<p>Tweedie, F. J. &amp; Baayen, R. H. (1998) How variable may a constant be?
Measures of lexical richness in perspective, <em>Computers and the
Humanities</em>, 32, 323-352.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+plot.growth">plot.growth</a></code>, and the zipfR package.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  alice.growth = growth.fnc(alice)
  plot(alice.growth)

## End(Not run)</code></pre>

<hr>
<h2 id='growth2vgc.fnc'>Conversion of growth object into a vgc object</h2><span id='topic+growth2vgc.fnc'></span>

<h3>Description</h3>

<p>This function converts a growth object (as defined in the languageR package)
to a vgc object (as defined in the zipfR package).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growth2vgc.fnc(growth)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="growth2vgc.fnc_+3A_growth">growth</code></td>
<td>
<p>A growth object obtained with growth.fnc().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vcg object as defined in the zipfR library.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>R. H. Baayen (2001) <em>Word Frequency Distributions</em>,
Dordrecht: Kluwer Academic Publishers.
</p>
<p>zipfR Website: &lt;URL: http://purl.org/stefan.evert/zipfR/&gt;
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+growth.fnc">growth.fnc</a></code>and the zipfR package.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(zipfR)

data(alice)
alice.growth = growth.fnc(text = alice, size = 648, nchunks = 40)
alice.vgc = growth2vgc.fnc(alice.growth)
plot(alice.vgc)

## End(Not run)</code></pre>

<hr>
<h2 id='growthInit'>Initialize a vocabulary growth object.</h2><span id='topic+growthInit'></span>

<h3>Description</h3>

<p>This function initializes a growth object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>growthInit(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="growthInit_+3A_data">data</code></td>
<td>
<p>A list with as single element a data frame with columns as
described in the documentation of growth.fnc.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A growth object, see growth.fnc for details.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>

<hr>
<h2 id='havelaar'>The determiner 'het' in the Dutch novel Max Havelaar</h2><span id='topic+havelaar'></span>

<h3>Description</h3>

<p>The frequency of the determiner 'het' in the Dutch novel
'Max Havelaar' by Multatuli (Eduard Douwes Dekker), in 99
consecutive text fragments of 1000 tokens each.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(havelaar)</code></pre>


<h3>Format</h3>

<p>A data frame with 99 observations on the following 2 variables.
</p>

<dl>
<dt><code>Chunk</code></dt><dd><p>a numeric vector with the indices of the text 
fragments.</p>
</dd>
<dt><code>Frequency</code></dt><dd><p>a numeric vector with the frequencies of the 
determiner 'het' in the text fragments.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The text of Max Havelaar was obtained from the Project Gutenberg at
at <a href="http://www.gutenberg.org/wiki/Main_Page">http://www.gutenberg.org/wiki/Main_Page</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(havelaar)

n = 1000                          # token size of text fragments
p = mean(havelaar$Frequency / n)  # relative frequencies

plot(qbinom(ppoints(99), n, p), sort(havelaar$Frequency),
   xlab = paste("quantiles of (", n, ",", round(p, 4), 
   ")-binomial", sep=""), ylab = "frequencies")


lambda = mean(havelaar$Frequency)
ks.test(havelaar$Frequency, "ppois", lambda)
ks.test(jitter(havelaar$Frequency), "ppois", lambda)



## End(Not run)</code></pre>

<hr>
<h2 id='head.growth'>Returns first rows of a growth object.</h2><span id='topic+head.growth'></span>

<h3>Description</h3>

<p>Returns the first rows of a growth object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'growth'
head(x, n = 6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="head.growth_+3A_x">x</code></td>
<td>
<p>A growth object.</p>
</td></tr>
<tr><td><code id="head.growth_+3A_n">n</code></td>
<td>
<p>An integer specifying the number of lines to be shown.</p>
</td></tr>
<tr><td><code id="head.growth_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The first n rows of the growth object are printed.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  alice.growth = growth.fnc(alice)
  head(alice.growth)

## End(Not run)</code></pre>

<hr>
<h2 id='heid'>Lexical decision latencies for words ending in -heid</h2><span id='topic+heid'></span>

<h3>Description</h3>

<p>A simplified version of the <code>primingHeid</code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(heid)</code></pre>


<h3>Format</h3>

<p>A data frame with 832 observations on the following 4 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor with subjects as levels.</p>
</dd> 
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd> 
<dt><code>RT</code></dt><dd><p>a numeric vector with logarithmically transformed
reaction times in visual lexical decision.</p>
</dd>
<dt><code>BaseFrequency</code></dt><dd><p>a numeric vector with the logarithmically
transformed frequency of the base adjective of the word with the
suffix <em>-heid</em>.</p>
</dd>
</dl>



<h3>References</h3>

<p>De Vaan, L., Schreuder, R. and Baayen, R. H. (2007) Regular morphologically
complex neologisms leave detectable traces in the mental lexicon, <em>The
Mental Lexicon</em>, 2, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(heid)
heid = aggregate(heid$RT, list(heid$Word, heid$BaseFrequency), mean)
colnames(heid) = c("Word", "BaseFrequency", "MeanRT")

## End(Not run)</code></pre>

<hr>
<h2 id='herdan.fnc'>Herdan's C</h2><span id='topic+herdan.fnc'></span>

<h3>Description</h3>

<p>This function calculates Herdan's constant <code>C</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>herdan.fnc(text, chunks)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="herdan.fnc_+3A_text">text</code></td>
<td>
<p>A vector of strings representing a text.</p>
</td></tr>
<tr><td><code id="herdan.fnc_+3A_chunks">chunks</code></td>
<td>
<p>A vector of chunk sizes for which Herdan's C is required.
Duplicate chunk sizes are not allowed, and the number of chunks should
be at least 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>growth</code></td>
<td>
<p>A data frame with token and type counts for the requested
chunk sizes.</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>Herdan's C.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>Herdan, G. (1960) <em>Type-Token Mathematics</em>, The Hague: Mouton.
</p>
<p>Herdan, G. (1964) <em>Quantitative Linguistics</em>, London: Buttersworths.
</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  herdan.fnc(alice, cumsum(rep(floor(length(alice)/40), 40)))

## End(Not run)</code></pre>

<hr>
<h2 id='imaging'>fMRI Filtered Signal and Priming Scores for Brain-Damaged Patients</h2><span id='topic+imaging'></span>

<h3>Description</h3>

<p>Filtered fMRI signal at the most significant voxel and average priming
scores for brain-damaged patients, in a study addressing the extent 
to which phonological and semantic processes recruit the same brain areas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(imaging)</code></pre>


<h3>Format</h3>

<p>A data frame with 35 observations on the following 3 variables.
</p>

<dl>
<dt><code>Condition</code></dt><dd><p>a factor with levels 
<code>irregulars</code> (the morphological condition involving priming using
inflected forms of irregular English verbs, e.g., 'began'-'begin')
and <code>semantics</code> (priming with semantically related words such 
as 'card' and 'paper').</p>
</dd>
<dt><code>BehavioralScore</code></dt><dd><p>a numeric vector for the average priming
scores.</p>
</dd>
<dt><code>FilteredSignal</code></dt><dd><p>a numeric vector for the intensity of the
filtered fMRI signal at the most significant voxel.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Location of data points reconstructed from the pixel map of Figure 2b
of Tyler et al. 2005.
</p>


<h3>Source</h3>

<p>Tyler, L.K.,  Marslen-Wilson, W.D. and Stamatakis, E.A. (2005)
Differentiating lexical form, meaning, and structure
in the neural language system, <em>PNAS</em>, 102, 8375-8380.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(imaging)

imaging.lm = lm(FilteredSignal~BehavioralScore*Condition, data=imaging)
summary(imaging.lm)

plot(imaging$BehavioralScore, imaging$FilteredSignal, type = "n", 
  xlim = c(-30, 40), ylim = c(0, 80))
semantics = imaging[imaging$Condition == "semantics",]
irregulars = imaging[imaging$Condition == "irregulars",]
points(semantics$BehavioralScore, semantics$FilteredSignal, col = "black")
points(irregulars$BehavioralScore, irregulars$FilteredSignal, col = "darkgrey")
abline(lm(FilteredSignal ~ BehavioralScore, data = semantics), col = 'black')
abline(lm(FilteredSignal ~ BehavioralScore, data = irregulars), 
  col = 'darkgrey')

# model criticism

plot(imaging.lm)
outliers = c(1, 19) # given Cook's distance, or perhaps only
outliers = 1        # the outlier in the semantics subset
imaging.lm = lm(FilteredSignal ~ BehavioralScore * Condition, 
  data = imaging[-outliers, ])
summary(imaging.lm)



## End(Not run)</code></pre>

<hr>
<h2 id='implementInteractions.fnc'>implement interactions in the model matrix</h2><span id='topic+implementInteractions.fnc'></span>

<h3>Description</h3>

<p>given a model matrix with main effects only, add interactions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>implementInteractions.fnc(m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="implementInteractions.fnc_+3A_m">m</code></td>
<td>
<p>a (model) matrix (rows observations, columns predictors)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>an updated (model) matrix
</p>


<h3>Note</h3>

<p>not intended for independent use</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='item.fnc'>Function for by-item regression used by simulateRegression.fnc</h2><span id='topic+item.fnc'></span>

<h3>Description</h3>

<p>This function carries out a by-item regression for the simulated
data sets generated in simulate.regression.fnc.  It is not designed
to be used independently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>item.fnc(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="item.fnc_+3A_data">data</code></td>
<td>
<p>A data frame as produced by make.reg.fnc().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A model fitted with lm().
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+simulateRegression.fnc">simulateRegression.fnc</a></code> and
<code><a href="#topic+make.reg.fnc">make.reg.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  dat = make.reg.fnc()
  dat.lm = item.fnc(dat)
  summary(dat.lm)

## End(Not run)</code></pre>

<hr>
<h2 id='items.quasif.fnc'>By-item anova for simulated data for quasi-F analysis</h2><span id='topic+items.quasif.fnc'></span>

<h3>Description</h3>

<p>By-item anova for simulated data set as created within 
simulateQuasif.fnc.   Not intended for independent use.
Depends on the packages MASS, coda and lme4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>items.quasif.fnc(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="items.quasif.fnc_+3A_dat">dat</code></td>
<td>
<p>Simulated data set with Subjects, Item, and SOA treatment,
as created within simulateQuasif.fnc, or the quasif dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>p-value of F-test for SOA.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the input data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the fitted model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+simulateQuasif.fnc">simulateQuasif.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(quasif)
items.quasif.fnc(quasif)

## End(Not run)</code></pre>

<hr>
<h2 id='lags.fnc'>Calculate vector at specified lag</h2><span id='topic+lags.fnc'></span>

<h3>Description</h3>

<p>This function calculates for a given dependent variable the value of
that variable at lag timesteps earlier in the time series of an
experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lags.fnc(dat, time="Trial", group = "Subject", depvar = "RT", lag=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lags.fnc_+3A_dat">dat</code></td>
<td>
<p>A data frame with (minimally) a grouping factor, an time index for
successive trails/events, and a behavioral measure</p>
</td></tr>
<tr><td><code id="lags.fnc_+3A_group">group</code></td>
<td>
<p>A grouping factor such as <code>Subject</code></p>
</td></tr>
<tr><td><code id="lags.fnc_+3A_time">time</code></td>
<td>
<p>A sequential time index measure such as <code>Trial</code> number in an
experimental list</p>
</td></tr>
<tr><td><code id="lags.fnc_+3A_depvar">depvar</code></td>
<td>
<p>The dependent variable, usually a chronometric measure such as RT</p>
</td></tr>
<tr><td><code id="lags.fnc_+3A_lag">lag</code></td>
<td>
<p>The lag for which previous values are to be extracted</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the values of the dependent variable at the specified lag.
The by-group mean is substituted for the first lag timestep(s), 
for which there is/are no preceding value(s) for the dependent variable.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p><a href="#topic+acf.fnc">acf.fnc</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  dfr = data.frame(Subject=c(rep("a", 5), rep("b", 5)),
                   Trial = c(rep(1:5,2)),
                   RT = rnorm(10, 500, 40))
  dfr$prevRT = lag.fnc(dfr, time="Trial", group="Subject", depvar="RT")
  dfr


## End(Not run)</code></pre>

<hr>
<h2 id='languageR-package'>
Data sets and functions for 'Analyzing Linguistic Data'
</h2><span id='topic+languageR-package'></span><span id='topic+languageR'></span>

<h3>Description</h3>

<p>Data sets and functions accompanying 'Analyzing Linguistic Data:
A practical introduction to statistics', Cambridge University Press, 2007.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> languageR</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2007-01-15</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GNU public license </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>The main function of this package is to make available the data sets
discussed and analyzed in 'Analyzing Linguistic Data:
A practical introduction to statistics using R', to appear with 
Cambridge University Press.  The following packages should be
installed, as ancillary functions in this package depend on them.
</p>

<dl>
<dt><code>zipfR</code></dt><dd><p>for word frequency distributions</p>
</dd>
<dt><code>lme4</code></dt><dd><p>for mixed-effects models</p>
</dd>
<dt><code>coda</code></dt><dd><p>for Markov-Chain Monte Carlo estimation</p>
</dd>
<dt><code>lattice</code></dt><dd><p>for trellis graphics</p>
</dd>
<dt><code>Matrix</code></dt><dd><p>for mixed-effects modeling</p>
</dd>
</dl>

<p>The following packages need to be installed for working through specific 
examples.
</p>

<dl>
<dt><code>rms</code></dt><dd><p>for regression modeling</p>
</dd>
<dt><code>rpart</code></dt><dd><p>for CART trees</p>
</dd>
<dt><code>e1071</code></dt><dd><p>for support vector machines</p>
</dd>
<dt><code>MASS</code></dt><dd><p>for many useful functions</p>
</dd>
<dt><code>ape</code></dt><dd><p>for phylogenetic clustering</p>
</dd>
</dl>

<p>The main convenience functions in this library are, by category:
</p>

<dl>
<dt>correspondence analysis</dt><dd><p>(extending code by Murtagh, 2005)</p>
</dd>
</dl>

<dl>
<dt><code>corres.fnc</code></dt><dd><p>correspondence analysis</p>
</dd>
<dt><code>corsup.fnc</code></dt><dd><p>supplementary data</p>
</dd>
</dl>

<dl>
<dt>vocabulary richness</dt><dd><p>(supplementing current zipfR functionality)</p>
</dd>
</dl>

<dl>
<dt><code>compare.richness.fnc</code></dt><dd><p>for two texts, compare richness</p>
</dd>
<dt><code>growth.fnc</code></dt><dd><p>empirical vocabulary growth data for text</p>
</dd>
<dt><code>growth2vgc</code></dt><dd><p>conversion to vgc object of zipfR</p>
</dd>
<dt><code>spectrum.fnc</code></dt><dd><p>creates frequency spectrum</p>
</dd>
<dt><code>text2spc.fnc</code></dt><dd><p>conversion to spc object of zipfR</p>
</dd>
</dl>

<dl>
<dt>lmer functions</dt><dd><p>(p-values for mixed-effects models with lme4)</p>
</dd>
</dl>

<dl>
<dt><code>pvals.fnc</code></dt><dd><p>p-values for table of coefficients including
MCMC</p>
</dd>
<dt><code>aovlmer.fnc</code></dt><dd><p>p-values for anova tables and/or MCMC
p-value for specified factor</p>
</dd>
</dl>

<dl>
<dt>simulation functions</dt><dd><p>(for comparing mixed models with traditional techniques including F1, F2, and F1+F2)</p>
</dd>
</dl>

<dl>
<dt><code>simulateRegression.fnc</code></dt><dd><p>simulate simple regression design</p>
</dd>
<dt><code>simulateQuasif.fnc</code></dt><dd><p>simulate data for Quasi-F ratios</p>
</dd>
<dt><code>simulateLatinsquare.fnc</code></dt><dd><p>simulating simple Latin-square design</p>
</dd> 
</dl>

<dl>
<dt>miscellaneous</dt><dd><p>(convenience functions)</p>
</dd>
</dl>

<dl>
<dt><code>pairscor.fnc</code></dt><dd><p>scatterplot matrix with correlation tests</p>
</dd>
<dt><code>collin.fnc</code></dt><dd><p>collinearity diagnostics</p>
</dd>
<dt><code>pvals.fnc</code></dt><dd><p>p-values and MCMC confidence intervals for mixed models</p>
</dd>
<dt><code>plot.logistic.fit.fnc</code></dt><dd><p>diagnostic visualization for logistic models</p>
</dd>
<dt><code>xylowess.fnc</code></dt><dd><p>trellis scatterplots with smoother</p>
</dd>
<dt><code>mvrnormplot.fnc</code></dt><dd><p>scatterplot for bivariate standard normal random numbers with regression line</p>
</dd>
<dt><code>lmerPlotInt.fnc</code></dt><dd><p>offers choice of four ways to visualize an interaction between two numeric predictors in an lmer model</p>
</dd>
</dl>




<h3>Author(s)</h3>

<p>R. H. Baayen
</p>
<p>University of Alberta, Edmonton, Canada
</p>
<p><a href="mailto:harald.baayen@gmail.com">harald.baayen@gmail.com</a>
</p>
<p>Maintainer:  harald.baayen@gmail.com 
</p>


<h3>References</h3>

<p>R. H. Baayen (2007) <em>Analyzing Linguistic Data: A practical introduction
to statistics using R</em>, Cambridge: Cambridge University Press. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(languageR)
  data(package="languageR")

## End(Not run)</code></pre>

<hr>
<h2 id='latinsquare'>Simulated Latin Square data set with subjects and items</h2><span id='topic+latinsquare'></span>

<h3>Description</h3>

<p>Simulated lexical decision latencies with SOA as treatment, using
a Latin Square design with subjects and items, as available in
Raaijmakers et al. (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(latinsquare)</code></pre>


<h3>Format</h3>

<p>A data frame with 144 observations on the following 6 variables.
</p>

<dl>
<dt><code>Group</code></dt><dd><p>a factor with levels <code>G1</code>, <code>G2</code> and 
<code>G3</code>, for groups of subjects</p>
</dd>
<dt><code>Subject</code></dt><dd><p>a factor with subjects labelled
<code>S1</code>, ... <code>S12</code>.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with words labelled <code>W1</code> ... <code>W12</code>.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector for reaction times.</p>
</dd>
<dt><code>SOA</code></dt><dd><p>a factor with levels <code>long</code>, <code>medium</code>, 
and <code>short</code>.</p>
</dd>
<dt><code>List</code></dt><dd><p>a factor with levels <code>L1</code>, <code>L2</code>, and <code>L3</code>
for lists of words.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Raaijmakers, J.G.W., Schrijnemakers, J.M.C. &amp; Gremmen, F. (1999)
How to deal with &quot;The language as fixed effect fallacy&quot;: 
common misconceptions and alternative solutions, 
<em>Journal of Memory and Language</em>, 41, 416-426.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(latinsquare)
library(lme4)
latinsquare.with = 
   simulateLatinsquare.fnc(latinsquare, nruns = 1000, with = TRUE) 
latinsquare.without = 
   simulateLatinsquare.fnc(latinsquare, nruns = 1000, with = FALSE)
latinsquare.with$alpha05
latinsquare.without$alpha05

## End(Not run)</code></pre>

<hr>
<h2 id='lexdec'>Lexical decision latencies for 79 English nouns</h2><span id='topic+lexdec'></span>

<h3>Description</h3>

<p>Lexical decision latencies elicited from 21 subjects for 79 English concrete nouns, with
variables linked to subject or word.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lexdec)</code></pre>


<h3>Format</h3>

<p>A data frame with 1659 observations on the following 28 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor for the subjects.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector for logarithmically transformed reaction times.</p>
</dd>
<dt><code>Trial</code></dt><dd><p>a numeric vector for the rank of the trial in the experimental list.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a factor with levels <code>F</code> (female) and <code>M</code> (male).</p>
</dd>
<dt><code>NativeLanguage</code></dt><dd><p>a factor with levels <code>English</code> and <code>Other</code>, distinguishing
between native and nonnative speakers of English.</p>
</dd>
<dt><code>Correct</code></dt><dd><p>a factor with levels <code>correct</code> and <code>incorrect</code> coding whether
the word was correctly responded to as a word rather than a nonword.</p>
</dd>
<dt><code>PrevType</code></dt><dd><p>a factor with levels <code>nonword</code> and <code>word</code> coding whether the
item presented at the preceding trial was a word or a nonword.</p>
</dd>
<dt><code>PrevCorrect</code></dt><dd><p>a factor with levels <code>correct</code> and <code>incorrect</code> coding whether
the preceding item elicited a correct response.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with 79 words as levels.</p>
</dd> 
<dt><code>Frequency</code></dt><dd><p>a numeric vector with logarithmically transformed lemma frequencies
as available in the CELEX lexical database.</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector with the log-transformed count of a word's 
morphological family members.</p>
</dd>
<dt><code>SynsetCount</code></dt><dd><p>a numeric vector with the log-transformed count of synonym sets 
in WordNet in which the word is listed.</p>
</dd>
<dt><code>Length</code></dt><dd><p>a numeric vector for the word's length in letters.</p>
</dd>
<dt><code>Class</code></dt><dd><p>a factor for the semantic category of the word's referent, with levels 
<code>animal</code> and <code>plant</code>.</p>
</dd>
<dt><code>FreqSingular</code></dt><dd><p>a numeric vector with the frequency in CELEX of the singular form.</p>
</dd>
<dt><code>FreqPlural</code></dt><dd><p>a numeric vector with the frequency in CELEX of the plural form.</p>
</dd>
<dt><code>DerivEntropy</code></dt><dd><p>Shannon's entropy calculated over the frequency 
distribution of a word's family members.</p>
</dd>
<dt><code>Complex</code></dt><dd><p>a factor coding morphological complexity with levels <code>complex</code> and
<code>simplex</code>.</p>
</dd>
<dt><code>rInfl</code></dt><dd><p>a numeric vector for the log of the ratio of the singular to the 
plural frequency.</p>
</dd>
<dt><code>meanRT</code></dt><dd><p>a numeric vector for the by-item mean reaction time averaged over subjects.</p>
</dd>
<dt><code>SubjFreq</code></dt><dd><p>a numeric vector for the by-item mean subjective frequency estimate
averaged over subjects.</p>
</dd>
<dt><code>meanSize</code></dt><dd><p>a numeric vector for the by-item mean size rating averaged over subjects.</p>
</dd>
<dt><code>meanWeight</code></dt><dd><p>a numeric vector for the by-item mean weight rating averaged over subjects.</p>
</dd>
<dt><code>BNCw</code></dt><dd><p>a numeric vector with the logarithmically transformed frequency in the
written part of the British National Corpus.</p>
</dd>
<dt><code>BNCc</code></dt><dd><p>a numeric vector with the logarithmically transformed frequency in the
context-governed part of the British National Corpus.</p>
</dd>
<dt><code>BNCd</code></dt><dd><p>a numeric vector  with the logarithmically transformed frequency in the
demographic part of the British National Corpus.</p>
</dd>
<dt><code>BNCcRatio</code></dt><dd><p>a numeric vector with the log of the ratio of the (absolute) frequencies
in the context-governed and written parts of the British National Corpus, normalized
for the differences in corpus size.</p>
</dd>
<dt><code>BNCdRatio</code></dt><dd><p>a numeric vector with the log of the ratio of the (absolute) frequencies
in the demographic and written parts of the British National Corpus, normalized
for the differences in corpus size.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data collected with Jen Hay, University of Canterbury, Christchurch, New Zealand, 2004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(lexdec)
require(lme4)
require(lmerTest)
require(optimx)

lexdec.lmer = lmer(RT ~ 1 + Correct + Trial + PrevType * meanWeight + 
  Frequency + NativeLanguage * Length + (1|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = lexdec)
summary(lexdec.lmer)

# random slopes

lexdec.lmerA = lmer(RT ~ 1 + Correct + Trial + PrevType * meanWeight + 
  Frequency + NativeLanguage * Length + (Trial|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = lexdec)
anova(lexdec.lmer, lexdec.lmerA)

lexdec.lmerB = lmer(RT ~ 1 + Correct + Trial + PrevType * meanWeight + 
  Frequency + NativeLanguage * Length + (Trial|Subject) + 
  (Length|Subject) + (1|Word), data = lexdec,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
anova(lexdec.lmerA, lexdec.lmerB)

# model criticism

qqnorm(resid(lexdec.lmerB))

lexdec.lmerC = lmer(RT ~ 1 + Correct + Trial + PrevType * meanWeight + 
  Frequency + NativeLanguage * Length + 
  (Trial|Subject) + (Length|Subject) + (1|Word), 
  data = lexdec[abs(scale(resid(lexdec.lmerB)))&lt;2,],
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

qqnorm(resid(lexdec.lmerC))

# p values
summary(lexdec.lmerC)


## End(Not run)</code></pre>

<hr>
<h2 id='lexicalMeasures'>Lexical measures for 2233 English monomorphemic words</h2><span id='topic+lexicalMeasures'></span>

<h3>Description</h3>

<p>Lexical distributional measures for 2233 English monomorphemic words.  This dataset provides
a subset of the data available in the dataset <code>english</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lexicalMeasures)</code></pre>


<h3>Format</h3>

<p>A data frame with 2233 observations on the following 24 variables.
</p>

<dl>
<dt><code>Word</code></dt><dd><p>a factor with 2284 words.</p>
</dd>
<dt><code>CelS</code></dt><dd><p>numeric vector with log-transformed lemma frequency in the CELEX lexical
database.</p>
</dd> 
<dt><code>Fdif</code></dt><dd><p>numeric vector with the logged ratio 
of written frequency (CELEX) to spoken frequency (British National Corpus).</p>
</dd> 
<dt><code>Vf</code></dt><dd><p>numeric vector with log morphological family size.</p>
</dd> 
<dt><code>Dent</code></dt><dd><p>numeric vector with derivational entropy.</p>
</dd> 
<dt><code>Ient</code></dt><dd><p>numeric vector with inflectional entropy.</p>
</dd> 
<dt><code>NsyS</code></dt><dd><p>numeric vector with the log-transformed count of 
synonym sets in WordNet in which the word is listed.</p>
</dd> 
<dt><code>NsyC</code></dt><dd><p>numeric vector with the log-transformed count of
synonym sets in WordNet in which the word is listed as part of a compound.</p>
</dd> 
<dt><code>Len</code></dt><dd><p>numeric vector with length of the word in letters.</p>
</dd> 
<dt><code>Ncou</code></dt><dd><p>numeric vector with orthographic neighborhood density.</p>
</dd> 
<dt><code>Bigr</code></dt><dd><p>numeric vector with mean log bigram frequency.</p>
</dd> 
<dt><code>InBi</code></dt><dd><p>numeric vector with log frequency of initial diphone.</p>
</dd> 
<dt><code>spelV</code></dt><dd><p>numeric vector with type count of orthographic neighbors.</p>
</dd> 
<dt><code>spelN</code></dt><dd><p>numeric vector with token count of orthographic neighbors.</p>
</dd> 
<dt><code>phonV</code></dt><dd><p>numeric vector with type count of phonological neighbors.</p>
</dd> 
<dt><code>phonN</code></dt><dd><p>numeric vector with token count of phonological neighbors.</p>
</dd> 
<dt><code>friendsV</code></dt><dd><p>numeric vector with type counts of consistent words.</p>
</dd> 
<dt><code>friendsN</code></dt><dd><p>numeric vector with token counts of consistent words.</p>
</dd> 
<dt><code>ffV</code></dt><dd><p>numeric vector with type count of forward inconsistent words.</p>
</dd>   
<dt><code>ffN</code></dt><dd><p>numeric vector with token count of forward inconsistent words.</p>
</dd> 
<dt><code>fbV</code></dt><dd><p>numeric vector with type count of backward inconsistent words.</p>
</dd> 
<dt><code>fbN</code></dt><dd><p>numeric vector with token count of backward inconsistent words</p>
</dd> 
<dt><code>ffNonzero</code></dt><dd><p>a numeric vector with the count of forward inconsistent words 
with nonzero frequency.</p>
</dd>
<dt><code>NVratio</code></dt><dd><p>a numeric vector with the logarithmically transformed ratio
of the noun and verb frequencies.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baayen, R.H., Feldman, L. and Schreuder, R. (2006)
Morphological influences on the recognition of monosyllabic 
monomorphemic words, <em>Journal of Memory and Language</em>,
53, 496-512.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(lexicalMeasures)
data(lexicalMeasuresDist)

library(rms)
library(cluster)
plot(varclus(as.matrix(lexicalMeasures[,-1])))

lexicalMeasures.cor = cor(lexicalMeasures[,-1], method = "spearman")^2
lexicalMeasures.dist = dist(lexicalMeasures.cor)
pltree(diana(lexicalMeasures.dist))

data(lexicalMeasuresClasses)
x = data.frame(measure = rownames(lexicalMeasures.cor), 
cluster = cutree(diana(lexicalMeasures.dist), 5),
class = lexicalMeasuresClasses$Class)
x = x[order(x$cluster), ]
x

## End(Not run)</code></pre>

<hr>
<h2 id='lexicalMeasuresClasses'>Classification of lexical measures</h2><span id='topic+lexicalMeasuresClasses'></span>

<h3>Description</h3>

<p>A data frame labelling the lexical measures in the 
dataset <code>lexicalMeasures</code> as measures of form or meaning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lexicalMeasuresClasses)</code></pre>


<h3>Format</h3>

<p>A data frame with 23 observations on the following 3 variables.
</p>

<dl>
<dt><code>Variable</code></dt><dd><p>a factor with as levels the measures:
</p>

<dl>
<dt><code>Bigr</code></dt><dd><p>Mean Bigram Frequency.</p>
</dd>
<dt><code>CelS</code></dt><dd><p>CELEX Frequency.</p>
</dd> 
<dt><code>Dent</code></dt><dd><p>Derivational Entropy.</p>
</dd> 
<dt><code>fbN</code></dt><dd><p>Token Count of Backward Inconsistent Words.</p>
</dd> 
<dt><code>fbV</code></dt><dd><p>Type Count of Backward Inconsistent Words.</p>
</dd> 
<dt><code>Fdif</code></dt><dd><p>Ratio of Frequencies in Written and Spoken English.</p>
</dd>
<dt><code>ffN</code></dt><dd><p>Token Count of Forward Inconsistent Words.</p>
</dd> 
<dt><code>ffNonzero</code></dt><dd><p>Type Count of Forward Inconsistent Words 
with Nonzero Frequency.</p>
</dd>
<dt><code>ffV</code></dt><dd><p>Type Count of Forward Inconsistent Words</p>
</dd>
<dt><code>friendsN</code></dt><dd><p>Token Count of Consistent Words.</p>
</dd>
<dt><code>friendsV</code></dt><dd><p>Type Count of Consistent Words.</p>
</dd>
<dt><code>Ient</code></dt><dd><p>Inflectional Entropy</p>
</dd>
<dt><code>InBi</code></dt><dd><p>Initial Bigram Frequency</p>
</dd>
<dt><code>Len</code></dt><dd><p>Length in Letters</p>
</dd>
<dt><code>Ncou</code></dt><dd><p>Orthographic Neighborhood Density</p>
</dd>
<dt><code>NsyC</code></dt><dd><p>Number of Complex Synsets</p>
</dd>
<dt><code>NsyS</code></dt><dd><p>Number of Simplex Synsets</p>
</dd>
<dt><code>NVratio</code></dt><dd><p>Ratio of Noun and Verb Frequencies</p>
</dd>
<dt><code>phonN</code></dt><dd><p>Token Count of Phonological Neighbors.</p>
</dd>
<dt><code>phonV</code></dt><dd><p>Type Count of Phonological Neighbors.</p>
</dd>
<dt><code>spelN</code></dt><dd><p>Token Count of Orthographic Neighbors.</p>
</dd>
<dt><code>spelV</code></dt><dd><p>Type Count of Orthographic Neighbors.</p>
</dd>
<dt><code>Vf</code></dt><dd><p>Morphological Family Size.</p>
</dd>
</dl>

</dd>
<dt><code>Class</code></dt><dd><p>a factor with levels <code>Form</code> and <code>Meaning</code>.</p>
</dd>
<dt><code>Explanation</code></dt><dd><p>a factor with glosses for the variables.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baayen, R.H., Feldman, L. and Schreuder, R. (2006)
Morphological influences on the recognition of monosyllabic 
monomorphemic words, <em>Journal of Memory and Language</em>,
53, 496-512.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(cluster)
data(lexicalMeasures)
data(lexicalMeasuresClasses)

lexicalMeasures.cor = cor(lexicalMeasures[,-1], method = "spearman")^2
x = data.frame(measure = rownames(lexicalMeasures.cor), 
cluster = cutree(diana(dist(lexicalMeasures.cor)), 5),
class = lexicalMeasuresClasses$Class)
x = x[order(x$cluster), ]
x

## End(Not run)</code></pre>

<hr>
<h2 id='lmerPlotInt.fnc'>Plot the interaction of two linear numeric predictors in a model 
fitted with lmer</h2><span id='topic+lmerPlotInt.fnc'></span>

<h3>Description</h3>

<p>Visualization of an interaction in a model fitted with lmer of two 
numeric predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmerPlotInt.fnc(lmermodel, xname, yname, intxyname, 
                qntls = seq(0, 1, by = 0.1), view = 30, 
                addStdError = FALSE, ndigits = 2, nlev = 30, 
                which = "matplot", shadow = 0.5, colour = "lightblue", 
                fun  = NA, ylabel = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmerPlotInt.fnc_+3A_lmermodel">lmermodel</code></td>
<td>
<p>an lmer model object</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_xname">xname</code></td>
<td>
<p>name (character string) of first numeric predictor</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_yname">yname</code></td>
<td>
<p>name (character string) of second numeric predictor</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_intxyname">intxyname</code></td>
<td>
<p>name (character string) of the interaction in the lmer summary</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_qntls">qntls</code></td>
<td>
<p>vector of values to be shown for the second numeric predictor, defaults to deciles</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_view">view</code></td>
<td>
<p>specifies the viewing parameter <code>theta</code> for the perspective plot</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_addstderror">addStdError</code></td>
<td>
<p>add noise with the standard deviation of the residual error in the lmer model to the plot</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_ndigits">ndigits</code></td>
<td>
<p>number of digits to show for the second numeric predictor </p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_nlev">nlev</code></td>
<td>
<p>number of levels for the contour plot</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_which">which</code></td>
<td>
<p>choices are &quot;matplot&quot; (default), &quot;contour&quot;, &quot;persp&quot;, &quot;image&quot;, 
and &quot;all&quot;, in which case a 2 by 2 panel is shown with all four plots</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_shadow">shadow</code></td>
<td>
<p>the amount of <code>shade</code> for the perspective plot</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_colour">colour</code></td>
<td>
<p>the color used for the perspective plot, defaults to &quot;lightblue&quot;</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_fun">fun</code></td>
<td>
<p>for matplot displays, a function for transforming the predicted
response</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_ylabel">ylabel</code></td>
<td>
<p>string, to be added to the Y-axis as y label</p>
</td></tr>
<tr><td><code id="lmerPlotInt.fnc_+3A_...">...</code></td>
<td>
<p>other arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot is shown on the graphics device.
</p>


<h3>Warning</h3>

<p>This function should not be used to plot interactions when one of the predictors also has quadratic or higher terms in the model.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
  require(lme4)
  require(optimx)
	lexdec.lmer = lmer(RT~BNCw*Frequency+(1|Subject)+(1|Word), data=lexdec,
    control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
	lmerPlotInt.fnc(lexdec.lmer, "BNCw", "Frequency", "BNCw:Frequency", 
    which="matplot")

## End(Not run)
  </code></pre>

<hr>
<h2 id='make.reg.fnc'>Make a simulated data set with regression design</h2><span id='topic+make.reg.fnc'></span>

<h3>Description</h3>

<p>This convenience function creates a regression data set with subjects, items,
and three numerical predictors, and optionally an effect of learning or
fatigue.  This function is called by simulateRegression.fnc, and is not
intended for independent use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.reg.fnc(nsubj = 10, nitem = 20, beta = c(400, 2, 6, 4), 
learn = FALSE, learnRate = 10, stdevItem = 40, stdevSubj = 80, 
  stdevError = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.reg.fnc_+3A_nsubj">nsubj</code></td>
<td>
<p>Number of subjects (random effect) required.</p>
</td></tr>
<tr><td><code id="make.reg.fnc_+3A_nitem">nitem</code></td>
<td>
<p>Number of items (random effect) required.</p>
</td></tr>
<tr><td><code id="make.reg.fnc_+3A_beta">beta</code></td>
<td>
<p>A numeric vector with four beta weights: one for the 
intercept and one for each of three predictors.</p>
</td></tr>
<tr><td><code id="make.reg.fnc_+3A_learn">learn</code></td>
<td>
<p>A logical variable, if TRUE, a learning or fatigue effect
will be implemented, as specified by <code>learnRate</code>.</p>
</td></tr>
<tr><td><code id="make.reg.fnc_+3A_learnrate">learnRate</code></td>
<td>
<p>A number indicating learning (if negative) or fatigue
(if positive).</p>
</td></tr>
<tr><td><code id="make.reg.fnc_+3A_stdevitem">stdevItem</code></td>
<td>
<p>A number specifying the standard deviation of the Item random effect.</p>
</td></tr>
<tr><td><code id="make.reg.fnc_+3A_stdevsubj">stdevSubj</code></td>
<td>
<p>A number specifying the standard deviation of the Subject random effect.</p>
</td></tr> 
<tr><td><code id="make.reg.fnc_+3A_stdeverror">stdevError</code></td>
<td>
<p>A number specifying the standard deviation of the Residual Error.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with intercept, predictors labelled X, Y and Z, Item, Subject, the simulated
random effects for Item and Subject, the residual errors, and the simulated RTs.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p><code><a href="#topic+simulateRegression.fnc">simulateRegression.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  simdat = make.reg.fnc()
  require(lme4)
  require(lmerTest)
  require(optimx)
  simdat.lmer = lmer(RT ~ X + Y + Z + (1|Subject) + (1|Item), 
    control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
    data = simdat)
  summary(simdat.lmer)

  simdat = make.reg.fnc(learn = TRUE)
  simdat.lmer = lmer(RT ~ X + Y + Z + Trial + (1|Subject) + (1|Item), 
    control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
    data = simdat)
  summary(simdat.lmer)

## End(Not run)</code></pre>

<hr>
<h2 id='makeDefaultMatrix.fnc'> Create model matrix with main effects only </h2><span id='topic+makeDefaultMatrix.fnc'></span>

<h3>Description</h3>

<p>Creates a model matrix with main effects only
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeDefaultMatrix.fnc(model, n = 100, conditioningPred = "", 
                      conditioningValue = NULL, control = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeDefaultMatrix.fnc_+3A_model">model</code></td>
<td>
<p>A model fit with <code>lmer</code></p>
</td></tr>
<tr><td><code id="makeDefaultMatrix.fnc_+3A_n">n</code></td>
<td>
<p>integer specifying number of points to be plotted on X-axis</p>
</td></tr>
<tr><td><code id="makeDefaultMatrix.fnc_+3A_conditioningpred">conditioningPred</code></td>
<td>
<p>name of predictor entering into interaction</p>
</td></tr>
<tr><td><code id="makeDefaultMatrix.fnc_+3A_conditioningvalue">conditioningValue</code></td>
<td>
<p>vector of values (numeric or factor level names) to be shown for interaction </p>
</td></tr>
<tr><td><code id="makeDefaultMatrix.fnc_+3A_control">control</code></td>
<td>
<p>a two-element list (predictor, value) specifying an additional
predictor to be fixed to the given value in a partial effect plot. May be 
useful for hand-made plots for three-way interactions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>a (model) matrix
</p>


<h3>Note</h3>

 
<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='makeSplineData.fnc'>generate simulated data set with nonlinear function</h2><span id='topic+makeSplineData.fnc'></span>

<h3>Description</h3>

<p>creates a data set with <code>Y ~ 30+cos(X)</code> for 10 subjects,
to compare restricted cubic spline in <code>lmer</code> with the
spline of <code>ols</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeSplineData.fnc(intr=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeSplineData.fnc_+3A_intr">intr</code></td>
<td>
<p>integer denoting type of data set: with 0 a data set with
simple spline is made, with 1 a data set with a parallel interaction,
and with 2 a data set with a crossed interaction.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Requires <code>rms</code> package to be attached.
</p>


<h3>Value</h3>

<p>A data frame with as values:
</p>
<table>
<tr><td><code>y</code></td>
<td>
<p><code>y = 30 + cos(X)</code></p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>ranges from 2 to 8.28</p>
</td></tr>
<tr><td><code>Subject</code></td>
<td>
<p>random-effects factor with 10 levels</p>
</td></tr>
<tr><td><code>Ranef</code></td>
<td>
<p>subjects-specific changes to intercept</p>
</td></tr>
<tr><td><code>Error</code></td>
<td>
<p>by-observation noise</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the dependent variable, <code>y+Ranef+Error</code></p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>intended for illustration only
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require("rms")
require("optimx")
require("lmerTest")
dfr = makeSplineData.fnc()
table(dfr$Subject)
xylowess.fnc(Y ~ X | Subject, data = dfr)

dfr.lmer = lmer(Y ~ rcs(X, 5) + (1|Subject), data = dfr,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
dfr$fittedLMER = as.vector(dfr.lmer@X %*% fixef(dfr.lmer))

dfr.dd = datadist(dfr)
options(datadist='dfr.dd')
dfr.ols = ols(Y~Subject+rcs(X), data=dfr, x=T, y=T)
dfr$fittedOLS = fitted(dfr.ols)

# we plot the lmer() fit in blue, the ols() fit in red (both adjusted for
# subject S1), and plot the underlying model in green
plot(dfr[dfr$Subject=="S1",]$X, dfr[dfr$Subject=="S1",]$fittedLMER +
  ranef(dfr.lmer)[[1]]["S1",], type="l", col="blue",
  ylim = range(dfr$y + ranef(dfr.lmer)[[1]]["S1",],
  dfr[dfr$Subject == "S1",]$fittedLMER,
  dfr[dfr$Subject == "S1",]$fittedOLS), xlab="X", ylab="Y")   
lines(dfr[dfr$Subject=="S1",]$X, dfr[dfr$Subject=="S1",]$fittedOLS, col="red")
lines(dfr[dfr$Subject=="S1",]$X, dfr[dfr$Subject=="S1",]$y+ranef(dfr.lmer)[[1]]["S1",], 
  col="green")
legend(2,29,c("30+cos(x)", "lmer (S1)", "ols (S1)"), lty=rep(1,3), 
col=c("green", "blue", "red"))

## End(Not run)
</code></pre>

<hr>
<h2 id='moby'>Moby Dick</h2><span id='topic+moby'></span>

<h3>Description</h3>

<p>The text of H. Melville's 'Moby Dick', with 
punctuation marks removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alice)</code></pre>


<h3>Format</h3>

<p>A character vector with 215994 words.
</p>


<h3>Source</h3>

<p>The project Gutenberg at <a href="http://www.gutenberg.org/wiki/Main_Page">http://www.gutenberg.org/wiki/Main_Page</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(moby)
  moby[1:2]

## End(Not run)</code></pre>

<hr>
<h2 id='mvrnormplot.fnc'>Scatterplot of bivariate standard normal distribution</h2><span id='topic+mvrnormplot.fnc'></span>

<h3>Description</h3>

<p>This function produces a scatterplot for a bivariate standard normal	
distribution with least squares regression line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrnormplot.fnc(r, n, limits)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvrnormplot.fnc_+3A_r">r</code></td>
<td>
<p>The correlation, defaults to 0.9.</p>
</td></tr>
<tr><td><code id="mvrnormplot.fnc_+3A_n">n</code></td>
<td>
<p>Number of simulated data points, defaults to 100.</p>
</td></tr>
<tr><td><code id="mvrnormplot.fnc_+3A_limits">limits</code></td>
<td>
<p>Optional range for the axes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A scatterplot with ordinary least squares regression line is shown on the
graphics device, with sample estimate of r added at the top of the plot.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>mvrnorm (MASS package)</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
	mvrnormplot.fnc(r=0.9, n=100)

## End(Not run)</code></pre>

<hr>
<h2 id='nesscg'>Frequency spectrum for -ness in the demographic BNC</h2><span id='topic+nesscg'></span>

<h3>Description</h3>

<p>Frequency (m) and frequency of frequency (Vm) for string types
with the suffix <em>-ness</em> in the context-governed subcorpus of the 
British National Corpus sampling spoken British English.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nesscg)</code></pre>


<h3>Format</h3>

<p>A data frame with 37 observations on the following 2 variables.
</p>

<dl>
<dt><code>m</code></dt><dd><p>a numeric vector with word frequencies.</p>
</dd>
<dt><code>Vm</code></dt><dd><p>a numeric vector with the frequencies of word frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The British National Corpus, see <a href="http://www.natcorp.ox.ac.uk/">http://www.natcorp.ox.ac.uk/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(nesscg)
library(zipfR)
nesscg.spc = spc(m=nesscg$m, Vm = nesscg$Vm)
plot(nesscg.spc)

## End(Not run)</code></pre>

<hr>
<h2 id='nessdemog'>Frequency spectrum for -ness in the context-governed BNC</h2><span id='topic+nessdemog'></span>

<h3>Description</h3>

<p>Frequency (m) and frequency of frequency (Vm) for string types
with the suffix <em>-ness</em> in the demographic subcorpus of the 
British National Corpus sampling spoken British English.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nessdemog)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 2 variables.
</p>

<dl>
<dt><code>m</code></dt><dd><p>a numeric vector with word frequencies.</p>
</dd>
<dt><code>Vm</code></dt><dd><p>a numeric vector with the frequencies of word frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The British National Corpus, see <a href="http://www.natcorp.ox.ac.uk/">http://www.natcorp.ox.ac.uk/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(nessdemog)
library(zipfR)
nessdemog.spc = spc(m=nessdemog$m, Vm = nessdemog$Vm)
plot(nessdemog.spc)
</code></pre>

<hr>
<h2 id='nessw'>Frequency spectrum for -ness in the written BNC</h2><span id='topic+nessw'></span>

<h3>Description</h3>

<p>Frequency (m) and frequency of frequency (Vm) for string types
with the suffix <em>-ness</em> in the subcorpus of the British
National Corpus sampling written British English.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nessw)</code></pre>


<h3>Format</h3>

<p>A data frame with 189 observations on the following 2 variables.
</p>

<dl>
<dt><code>m</code></dt><dd><p>a numeric vector with word frequencies.</p>
</dd>
<dt><code>Vm</code></dt><dd><p>a numeric vector with the frequencies of word frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The British National Corpus, see <a href="http://www.natcorp.ox.ac.uk/">http://www.natcorp.ox.ac.uk/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(nessw)
library(zipfR)
nessw.spc = spc(m=nessw$m, Vm = nessw$Vm)
plot(nessw.spc)

## End(Not run)</code></pre>

<hr>
<h2 id='oldFrench'>Frequencies of tag trigrams in Old French texts</h2><span id='topic+oldFrench'></span>

<h3>Description</h3>

<p>Frequencies of 35 morphosyntactic tag trigrams in 343 Old French texts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(oldFrench)</code></pre>


<h3>Format</h3>

<p>A data frame with the frequencies of 35 tag trigrams (columns) for 343 Old French texts (rows)
in the Nouveau Corpus d'Amsterdam.  See oldFrenchMeta for details on the texts (and manuscript
versions).
</p>


<h3>Source</h3>

<p>Data from Nouveau Corpus d'Amsterdam, <a href="http://www.uni-stuttgart.de/lingrom/stein/corpus/">http://www.uni-stuttgart.de/lingrom/stein/corpus/</a>.
</p>


<h3>References</h3>

<p>Ernestus, M., van Mulken, M. and Baayen, R. H. (2007)
De syntax van Oud-Franse ridders en heiligen in ruimte en tijd
To appear in <em>Onze Taal</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(oldFrench)
data(oldFrenchMeta)

oldFrench.ca = corres.fnc(oldFrench)

plot(oldFrench.ca, rlabels = oldFrenchMeta$Genre, 
rcol = as.numeric(oldFrenchMeta$Genre), rcex = 0.5, 
extreme = 0.1, ccol = "blue")
</code></pre>

<hr>
<h2 id='oldFrenchMeta'>Meta data for the oldFrench data</h2><span id='topic+oldFrenchMeta'></span>

<h3>Description</h3>

<p>Meta data for the oldFrench data, a matrix of frequencies for texts (rows) by tag trigrams (columns).
The meta data provide information on the texts, manuscript variants, their authors, 
their region and approximate date of origin, their general topic, and their genre.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(oldFrenchMeta)</code></pre>


<h3>Format</h3>

<p>A data frame with 342 observations on the following 7 variables.
</p>

<dl>
<dt><code>Textlabels</code></dt><dd><p>a factor with texts coded as follows:
</p>

<dl>
<dt><code>Abe</code></dt><dd><p> J. de Meun, Traduction de la premiere epitre de P. Abelard, 1&ndash;821</p>
</dd> 
<dt><code>Hyl1</code></dt><dd><p> Anon, La vie de saint Hylaire</p>
</dd> 
<dt><code>Art</code></dt><dd><p> J. de Meun, L'art de chevalerie</p>
</dd> 
<dt><code>Bar</code></dt><dd><p> Anon, L'histoire de Barlaam et Josaphat</p>
</dd> 
<dt><code>Cathy</code></dt><dd><p> Anon, La vie de sainte Catherine d'Alexandrie</p>
</dd> 
<dt><code>Hyl2</code></dt><dd><p> Anon, La vie de saint Hylaire</p>
</dd> 
<dt><code>Ch1</code></dt><dd><p> Chretien de Troyes, Le Chevalier au lion</p>
</dd> 
<dt><code>Ch2</code></dt><dd><p> Chretien de Troyes, Le chevalier au lion</p>
</dd> 
<dt><code>Clari</code></dt><dd><p> Robert de Clari, La conquete de Constantinople</p>
</dd> 
<dt><code>Marie</code></dt><dd><p> Rutebeuf, Sainte Marie l'Egyptienne</p>
</dd> 
<dt><code>Fab4c</code></dt><dd><p> Anon, Fabliau nr 4 ms C</p>
</dd> 
<dt><code>Fab4e</code></dt><dd><p> Anon, Fabliau nr 4 ms E</p>
</dd> 
<dt><code>Fab4f</code></dt><dd><p> Anon, Fabliau 4f</p>
</dd> 
<dt><code>Faba</code></dt><dd><p> Anon, Fabliaux nrs 1,2,4,23 et 29 du ms A</p>
</dd> 
<dt><code>Fabb</code></dt><dd><p> Anon, Fabliaux nrs 2 et 4 du ms B</p>
</dd> 
<dt><code>Fabd.COD</code></dt><dd><p> Anon, Fabliaux nrs 2 et 4 du ms D</p>
</dd> 
<dt><code>Hyl3</code></dt><dd><p> Anon,  La vie de saint Hylaire</p>
</dd> 
<dt><code>Jacobi</code></dt><dd><p> Pierre de Beauvais, The Liber Sancti Jacobi</p>
</dd> 
<dt><code>Louis</code></dt><dd><p> J. de Joinville, La vie de saint Louis</p>
</dd> 
<dt><code>Cathy1</code></dt><dd><p> Anon, La passion saynte Katherine</p>
</dd> 
<dt><code>Lancelot</code></dt><dd><p> Anon, Lancelot do Lac, p. 1.1&ndash;20.13</p>
</dd> 
<dt><code>Merlin1</code></dt><dd><p> Merlin, Robert  de Boron</p>
</dd> 
<dt><code>Marga</code></dt><dd><p> Anon, La vie de Sainte Marguerite de Wace</p>
</dd> 
<dt><code>Martin</code></dt><dd><p> Anon, Leben und Wunderthaten des heiligen Martin</p>
</dd> 
<dt><code>Merlin2</code></dt><dd><p> Anon, Merlin, p.1&ndash;29 (ms.  Huth)</p>
</dd> 
<dt><code>RoseA</code></dt><dd><p> J. de Meun, Le Roman de la Rose</p>
</dd> 
<dt><code>Arthur</code></dt><dd><p> Anon, La mort le roi Artu, par.1&ndash;35</p>
</dd>
<dt><code>NimAf</code></dt><dd><p> Anon, charroi de Nimes, ms. A, fragment</p>
</dd> 
<dt><code>NimB1</code></dt><dd><p> Anon, Le charroi de Nimes, ms B1</p>
</dd> 
<dt><code>NimB2</code></dt><dd><p> Anon, Le charroi de Nimes, ms B2</p>
</dd> 
<dt><code>Nouvel</code></dt><dd><p> Jacquemart Gielee, Renart le Nouvel</p>
</dd> 
<dt><code>Jehan</code></dt><dd><p> Anon, La vie de saint Jehan Bouche d'Or</p>
</dd>
<dt><code>Per0</code></dt><dd><p> Chretien de Troyes, Perceval</p>
</dd> 
<dt><code>perL</code></dt><dd><p> Chretien de Troyes, Perceval</p>
</dd>
<dt><code>PerQ</code></dt><dd><p> Chretien de Troyes, Perceval</p>
</dd> 
<dt><code>PerS</code></dt><dd><p> Chretien de Troyes, Perceval</p>
</dd>
<dt><code>PerU</code></dt><dd><p> Chretien de Troyes, Perceval</p>
</dd> 
<dt><code>Queste</code></dt><dd><p> Anon, La queste del saint Graal, p.1.1&ndash;41.17</p>
</dd> 
<dt><code>Rob</code></dt><dd><p> Anon, Robert le Diable, v.1&ndash;808</p>
</dd> 
<dt><code>RomB</code></dt><dd><p> Anon, Le Roman de Renart, br.VI, ms B</p>
</dd> 
<dt><code>RomD</code></dt><dd><p> Anon, Roman de Renard, br.VI, ms D</p>
</dd>
<dt><code>RomL</code></dt><dd><p> Anon, Roman de Renard, br. VI, ms L</p>
</dd> 
<dt><code>RomO</code></dt><dd><p> Anon, Le Roman de Renart, br. VI, ms 0</p>
</dd> 
<dt><code>RoseB</code></dt><dd><p> Guillaume de Lorris, Le roman de la rose</p>
</dd> 
<dt><code>Sapi</code></dt><dd><p> Anon, Sermo de sapientia, dans: Li dialoge Gregoire lo pape</p>
</dd> 
<dt><code>Troi</code></dt><dd><p> Anon, Le roman de Troie en prose, par.1&ndash;19</p>
</dd> 
<dt><code>Conqueste</code></dt><dd><p> Josfroi de Vileharduyn, La conqueste de Costentinoble</p>
</dd> 
<dt><code>YvA</code></dt><dd><p> Chretien de Troyes, Le chevalier au lion, v.1&ndash;1000</p>
</dd> 
<dt><code>YvP</code></dt><dd><p> Chretien de Troyes, Le chevalier au lion, v.1&ndash;1000</p>
</dd> 
<dt><code>YvS</code></dt><dd><p> Chretien de Troyes, Le chevalier au lion, v.1&ndash;1000</p>
</dd> 
<dt><code>YvV</code></dt><dd><p> Chretien de Troyes, Le chevalier au lion, v 1&ndash;1000</p>
</dd>
</dl>

</dd>
<dt><code>Codes</code></dt><dd><p>a factor with manuscript variants, indicated by extensions to the text codes.</p>
</dd>
<dt><code>Author</code></dt><dd><p>a factor with levels <code>Anon</code>, <code>ChretienDeTroyes</code>, <code>GuillaumeDeLorris</code>, 
<code>Joinville</code>, <code>Meun</code>, <code>NouvelRenart</code>, <code>PierreDeBeauvais</code>, <code>RobertDeBoron</code>,
<code>RobertDeClari</code>, <code>RobertLeDiable</code>, <code>Rutebeuf</code>, and <code>Villeharduyn</code>.</p>
</dd>
<dt><code>Topic</code></dt><dd><p>a factor with levels <code>Knight</code>, <code>Other</code>, and <code>Saint</code>.</p>
</dd>
<dt><code>Genre</code></dt><dd><p>a factor with levels <code>poetry</code> and <code>prose</code>.</p>
</dd>
<dt><code>Region</code></dt><dd><p>a factor with levels <code>R1</code> (Picardie), <code>R2</code> (Champenois), and
<code>R3</code> (Nievre-Allier).</p>
</dd>
<dt><code>Year</code></dt><dd><p>a numeric vector indicating approximate year of origin.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data from Nouveau Corpus d'Amsterdam, <a href="http://www.uni-stuttgart.de/lingrom/stein/corpus/">http://www.uni-stuttgart.de/lingrom/stein/corpus/</a>.
</p>


<h3>References</h3>

<p>Ernestus, M., van Mulken, M. and Baayen, R. H. (2007)
De syntax van Oud-Franse ridders en heiligen in ruimte en tijd
To appear in <em>Onze Taal</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(oldFrench)
data(oldFrenchMeta)

oldFrench.ca = corres.fnc(oldFrench)

plot(oldFrench.ca, rlabels = oldFrenchMeta$Genre, 
rcol = as.numeric(oldFrenchMeta$Genre), rcex = 0.5, 
extreme = 0.1, ccol = "blue")

## End(Not run)</code></pre>

<hr>
<h2 id='oz'>The Wonderful Wizard of Oz</h2><span id='topic+oz'></span>

<h3>Description</h3>

<p>The text of L. F. Baum's 'The Wonderful Wizard of Oz', with 
punctuation marks removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alice)</code></pre>


<h3>Format</h3>

<p>A character vector with 39513 words.
</p>


<h3>Source</h3>

<p>The project Gutenberg at <a href="http://www.gutenberg.org/wiki/Main_Page">http://www.gutenberg.org/wiki/Main_Page</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(oz)
  oz[1:5]

## End(Not run)</code></pre>

<hr>
<h2 id='pairscor.fnc'>Scatterplot matrix with correlations</h2><span id='topic+pairscor.fnc'></span>

<h3>Description</h3>

<p>A matrix of scatterplots is produced with Pearson and Spearman correlations
in the lower triangle.  By default, smoothers are added to panels in the 
upper triangle, and histograms are added to the panels on the diagonal.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairscor.fnc(data, hist = TRUE, smooth = TRUE,
  cex.points = 1,  col.points = "darkgrey")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairscor.fnc_+3A_data">data</code></td>
<td>
<p>a data frame or matrix with numeric vectors.</p>
</td></tr>
<tr><td><code id="pairscor.fnc_+3A_hist">hist</code></td>
<td>
<p>a logical indicating whether panels on the diagonal
should contain a histogram.</p>
</td></tr>
<tr><td><code id="pairscor.fnc_+3A_smooth">smooth</code></td>
<td>
<p>a logical indicating whether panels in the upper
triangle should have a smoother added.</p>
</td></tr>
<tr><td><code id="pairscor.fnc_+3A_cex.points">cex.points</code></td>
<td>
<p>a number indicating the size of the points in the
panels in the upper triangle, available only when smoothers are added.</p>
</td></tr>
<tr><td><code id="pairscor.fnc_+3A_col.points">col.points</code></td>
<td>
<p>a number or string indicating the color of the points 
in the panels in the upper triangle, available only when smoothers
are added.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. Harald Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="graphics.html#topic+pairs">pairs</a></code> and <code><a href="graphics.html#topic+panel.smooth">panel.smooth</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(lexicalMeasures)
  pairscor.fnc(lexicalMeasures[,c("CelS", "Vf", "Ient", "NsyS", "Ncou")])

## End(Not run)</code></pre>

<hr>
<h2 id='parsePredName.fnc'> parse character string specifying restricted cubic spline </h2><span id='topic+parsePredName.fnc'></span>

<h3>Description</h3>

<p>parse character string specifying restricted cubic spline into simple
predictor name and number of knots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parsePredName.fnc(name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parsePredName.fnc_+3A_name">name</code></td>
<td>
<p> character string for predictor, e.g. <code>rcs(X, 3)</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>not intended for independent use
</p>


<h3>Value</h3>

<p>a list with components
</p>
<table>
<tr><td><code>baseName</code></td>
<td>
<p>character string denoting simple predictor name (<code>X</code>)</p>
</td></tr>
<tr><td><code>knots</code></td>
<td>
<p>integer specifying number of knots</p>
</td></tr>
</table>


<h3>Note</h3>

 
<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='periphrasticDo'>The development of periphrastic do in English</h2><span id='topic+periphrasticDo'></span>

<h3>Description</h3>

<p>The development of periphrastic <em>do</em> in English: Ellegard's counts
for the use of <em>do</em> across four sentence types in 11 consecutive
time periods between 1390 and 1710.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(periphrasticDo)</code></pre>


<h3>Format</h3>

<p>A data frame with 44 observations on the following 5 variables.
</p>

<dl>
<dt><code>begin</code></dt><dd><p>a numeric vector with beginnings of the time periods
used by Ellegard.</p>
</dd>
<dt><code>end</code></dt><dd><p>a numeric vector with ends of these time periods.</p>
</dd>
<dt><code>type</code></dt><dd><p>a factor for sentence type, with levels 
<code>affdecl</code> (affirmative declarative),
<code>affquest</code> (affirmative question), 
<code>negdecl</code> (negative declarative) and 
<code>negquest</code> (negative question).</p>
</dd>
<dt><code>do</code></dt><dd><p>a numeric vector with the count of sentences with
<em>do</em>.</p>
</dd>
<dt><code>other</code></dt><dd><p>a numeric vector with the count of sentences without
<em>do</em>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Ellegard, A. (1953) <em> The auxiliary do: The establishment and regulation
of its use in English</em>, Stockholm: Almquist &amp; Wiksell.
</p>


<h3>References</h3>

<p>Vulanovic, R. and Baayen, R. H. (2006) Fitting the development of periphrastic
do in all sentence types, in Grzybek, P. and Koehler, R. (eds.), Festschrift
fuer Gabriel Altmann, Berlin: Walter de Gruyter, p. 679-688.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(periphrasticDo)

# add midpoints of time periods

periphrasticDo$year = periphrasticDo$begin +
  (periphrasticDo$end-periphrasticDo$begin)/2

# and ad an indicator variable distinguishing the first three time periods
# from the others

periphrasticDo$Indicator = rep(c(rep(0, 3), rep(1, 8)), 4)

# fit a logistic regression model

periphrasticDo.glm = glm(cbind(do, other) ~
(year + I(year^2) + I(year^3)) * type + Indicator * type + 
Indicator * year, data = periphrasticDo, family = "binomial")

anova(periphrasticDo.glm, test = "F")

# visualization of data and model predictions

periphrasticDo$predict = predict(periphrasticDo.glm, type = "response")
par(mfrow=c(2, 2))
for (i in 1:nlevels(periphrasticDo$type)) {
  subset = periphrasticDo[periphrasticDo$type == 
    levels(periphrasticDo$type)[i], ]
  plot(subset$year,
    subset$do/(subset$do + subset$other), 
    type = "p", ylab = "proportion", xlab = "year", 
    ylim = c(0, 1), xlim = c(1400, 1700))
  mtext(levels(periphrasticDo$type)[i], line = 2)
  lines(subset$year, subset$predict, lty = 1)
}
par(mfrow=c(1, 1))


## End(Not run)</code></pre>

<hr>
<h2 id='phylogeny'>Phylogenetic relations between Papuan and Oceanic languages</h2><span id='topic+phylogeny'></span>

<h3>Description</h3>

<p>Phylogenetic relations between Papuan and Oceanic languages: 127 
grammatical traits (absent/present) for 31 languages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(phylogeny)</code></pre>


<h3>Format</h3>

<p>A data frame with 31 observations on the following 127 variables.
</p>

<dl>
<dt><code>Language</code></dt><dd><p>a factor for 31 languages: <code>Anem</code>, <code>Ata</code>,
<code>Bali</code>, <code>Banoni</code>, <code>Bilua</code>, <code>Buin</code>, <code>Gapapaiwa</code>,
<code>Kairiru</code>, <code>Kaulong</code>, <code>Kilivila</code>, <code>Kokota</code>, 
<code>Kol</code>, <code>Kuot</code>, <code>Lavukaleve</code>, <code>Mali</code>, <code>Motuna</code>, 
<code>Nalik</code>, <code>Nasioi</code>, <code>Rotokas</code>, <code>Roviana</code>, 
<code>Savosavo</code>, <code>Siar</code>, <code>Sisiqa</code>, <code>Sudest</code>, 
<code>Sulka</code>, <code>Taiof</code>, <code>Takia</code>, <code>Touo</code>, <code>Tungag</code>,
<code>Yabem</code> and <code>Yeli_Dnye</code>.</p>
</dd>
<dt><code>Family</code></dt><dd><p>a factor with levels <code>Oceanic</code> and <code>Papuan</code>.</p>
</dd>
<dt><code>Frics</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PrenasalizedStops</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PhonDistBetweenLAndR</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PhonVelarFricOrGlide</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PhonVoicingContrAmongStops</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PhonConsLength</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PhonVowelLength</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ContrPhonTypesForVowels</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PhonStress</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>WordFinalConss</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ConsClusters</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>DefOrSpecArt</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>IndefOrNonSpecArt</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ArticleNounOrder</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NounInitNps</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>InclExclDist</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PronNum</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PronRelationship</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PronConflation</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>MoreThan2DegreesDistDem</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NonSpkrAnchoredDem</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerticalityDem</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ClassifiedDem</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NumDeterminedDecl</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>GenderDeterminedDecl</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SuppletiveNouns</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SingMarkedNoun</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>DualMarkedNoun</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PlMarkedNoun</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>OtherNumMarkedNoun</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>LimitedDistNumMarking</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NounClassesGenders</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ConcordBeyondNp</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NumeralClassifiers</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PossClassifiers</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PossClasses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>Inalienability</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>MultiplePossConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PrefixMarkedPoss</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SuffixMarkedPoss</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>MarkedPossr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>MarkedPossessee</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PossrPossdOrder</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>DecimalNumerals</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>QuinaryNumerals</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>CollectiveNouns</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>AdjVerbLexOverlap</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>AdjAttributionPred</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>CoreCaseMarking</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ObliqueCaseMarking</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>Prepositions</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>Postpositions</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>TamPerson</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbPrefixesProclitics</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbSuffixesEnclitics</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PunctualContinuous</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>RealisIrrealis</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SSuffix</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SPrefix</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ASuffix</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>APrefix</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>OSuffix</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>OPrefix</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbVarTam</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbVarVClass</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbVarClauseType</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbVarPerson</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NumStemAlt</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PersonStemAlt</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SepVerbNumPerson</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>Portmanteau3Plus</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>DistributedCategory</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NonCore</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>RecipientObj</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>X3PlacePreds</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbNeg</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbDirection</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbSuppletion</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ConjugationClasses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>TransIntransAlt</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>TransitivizingMorph</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>IntranstivizingMorph</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ReflexiveMorph</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ReciprocalMorph</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbClassifiers</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>Copula</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NonVbPreds</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SerialVerbConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>Auxiliaries</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbCompounds</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbAdjunctConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VbIncorporation</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ExistentialVerb</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>IrregularGive</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ClosedClassOfVb</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SvIntransClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VsIntransClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VInitTransClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VMedialTransClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VFinalTransClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>FixedConstituentOrder</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ClauseFinalNeg</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ClauseInitNeg</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ImpVs.DeclNeg</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VbAndNonVbPredIdentity</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SOMorphInBasicConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SAMorphInBasicConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SOMorphInComplexConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SAMorphInComplexConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SynConflationOfSO</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ControlledUncontrolled</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ClauseChaining</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SimultaneousSequential</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>SayInDesidConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>RelativeClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>PurpSubClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>TemporalSubClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>ComplementClauses</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>CausBySerialVerbConstr</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>CausByBoundAffClit</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>CausByConstrInvolvingSay</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>MorphTopicOrFocus</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>TailHeadLinkage</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>VerbRedup</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
<dt><code>NounRedup</code></dt><dd><p>a numeric vector, 1: presence, 0: absence</p>
</dd>
</dl>



<h3>Source</h3>

<p>Dunn, M., Terrill, A., Reesink, G., Foley, R. A. and Levinson, S. C. (2005)
Structural phylogenetics and the reconstruction of ancient language history,
<em>Science</em>, 309, 2072-2075.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phylogeny)
library(ape)

# joint analysis of both language families

phylogeny.dist = dist(phylogeny[ ,3:ncol(phylogeny)], method = "binary")
phylogeny.dist.tr = nj(phylogeny.dist)
families =
  as.character(phylogeny$Family[as.numeric(phylogeny.dist.tr$tip.label)])
languages =
  as.character(phylogeny$Language[as.numeric(phylogeny.dist.tr$tip.label)])
phylogeny.dist.tr$tip.label = languages
plot(phylogeny.dist.tr, type="u", font = as.numeric(as.factor(families)))

# analysis of subset of Papuan languages

papuan = phylogeny[phylogeny$Family == "Papuan",]
papuan$Language = as.factor(as.character(papuan$Language))
papuan.meta = papuan[ ,1:2]
papuan.mat = papuan[, 3:ncol(papuan)]
papuan.meta$Geography = c(
  "Bougainville", "Bismarck Archipelago", "Bougainville", 
  "Bismarck Archipelago", "Bismarck Archipelago", "Central Solomons",
  "Bougainville", "Louisiade Archipelago", "Bougainville", 
  "Bismarck Archipelago", "Bismarck Archipelago", 
  "Bismarck Archipelago", "Central Solomons", "Central Solomons", 
  "Central Solomons")
papuan.dist = dist(papuan.mat, method = "binary")
papuan.dist.tr = nj(papuan.dist)
fonts = 
  as.character(papuan.meta$Geography[as.numeric(
    papuan.dist.tr$tip.label)])
papuan.dist.tr$tip.label = 
  as.character(papuan.meta$Language[as.numeric(
    papuan.dist.tr$tip.label)])
plot(papuan.dist.tr, type = "u", font = as.numeric(as.factor(fonts)))

## End(Not run)</code></pre>

<hr>
<h2 id='plot.corres'>Plot method for correspondence objects</h2><span id='topic+plot.corres'></span>

<h3>Description</h3>

<p>This function defines a plot method for correspondence objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'corres'
plot(x, main = "", addcol = TRUE, extreme = 0, rcex = 1, rcol = 1, 
rlabels = "", stretch = 1.4, ccex = 1, ccol = 2, clabels = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.corres_+3A_x">x</code></td>
<td>
<p>A correspondence object as produced by <code>corres</code>.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_main">main</code></td>
<td>
<p>A string used for the main title of the plot.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_addcol">addcol</code></td>
<td>
<p>A logical, if true, columns are added to the plot.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_extreme">extreme</code></td>
<td>
<p>If nonzero, defines quantiles that define the extremes
such that only data points exceeding these extremes are plotted.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_rcex">rcex</code></td>
<td>
<p>sets cex graphical parameter for rows.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_rcol">rcol</code></td>
<td>
<p>sets color for rows.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_rlabels">rlabels</code></td>
<td>
<p>vector of row labels.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_stretch">stretch</code></td>
<td>
<p>a number defining the degree to which the columns (or rows)
should be stretched out for visual presentation.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_ccex">ccex</code></td>
<td>
<p>sets cex graphical parameter for columns.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_ccol">ccol</code></td>
<td>
<p>sets color for columns.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_clabels">clabels</code></td>
<td>
<p>vector of column labels.</p>
</td></tr>
<tr><td><code id="plot.corres_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot on the graphics device.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+corres.fnc">corres.fnc</a></code>, <code>link{corsup.fnc}</code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(oldFrench)
  data(oldFrenchMeta)

  oldFrench.ca = corres.fnc(oldFrench)

  plot(oldFrench.ca)

  plot(oldFrench.ca, rlabels = oldFrenchMeta$Genre, 
  rcol = as.numeric(oldFrenchMeta$Genre), rcex = 0.5, 
  extreme = 0.1, ccol = "blue")

## End(Not run)</code></pre>

<hr>
<h2 id='plot.growth'>Plot method for growth objects</h2><span id='topic+plot.growth'></span>

<h3>Description</h3>

<p>This function defines the plot method for growth objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'growth'
plot(x, w = "all", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.growth_+3A_x">x</code></td>
<td>
<p>A growth object.</p>
</td></tr>
<tr><td><code id="plot.growth_+3A_w">w</code></td>
<td>
<p>A character string denoting the name of a specific variable
to be plotted.</p>
</td></tr>
<tr><td><code id="plot.growth_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot shown on the graphics device.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  alice.growth = growth.fnc(alice)
  plot(alice.growth)
  plot(alice.growth, w = "Yule")

## End(Not run)</code></pre>

<hr>
<h2 id='plotAll.fnc'>create plot or plots for list with data frames for plot or subplots </h2><span id='topic+plotAll.fnc'></span>

<h3>Description</h3>

<p>given a list with one or more data frames with values for a plot (or subplot),
create the actual plots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotAll.fnc(reslist, sameYrange = TRUE, ylabel, xlabel = NA, intrName = NA, 
  pos = "end", ylimit = NA, addlines=FALSE, cexsize = 0.6, conditioningVals=NA,
  conditioningColors=1, conditioningLines=1, lineColor=1, addToExistingPlot = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotAll.fnc_+3A_reslist">reslist</code></td>
<td>
<p>list with as components either a data frame or a list with data frames, the data frames specify X and Y coordinates and HPD intervals</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_sameyrange">sameYrange</code></td>
<td>
<p> logical, if <code>TRUE</code>, the <code>ylim</code> for each panel will be chosen to accomodate the range of values across all panels in the plot </p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_ylabel">ylabel</code></td>
<td>
<p> label to be used for the vertical axis</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_xlabel">xlabel</code></td>
<td>
<p> label to be used for the horizontal axis; this option is active
only when a single predictor is plotted</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_intrname">intrName</code></td>
<td>
<p> label for the interaction predictor, if present </p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_pos">pos</code></td>
<td>
<p> location of legend values for interaction </p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_ylimit">ylimit</code></td>
<td>
<p> if specified, overrides <code>sameYrange</code> for <code>ylim</code></p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_addlines">addlines</code></td>
<td>
<p> if TRUE, adds line between levels of same factor(s)</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_cexsize">cexsize</code></td>
<td>
<p>character expansion size for information in the plot for
interactions, default is 0.6</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_conditioningvals">conditioningVals</code></td>
<td>
<p> vector of names of the levels of the conditioning
factor in the interaction (the factor with different lines in the plot) </p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_conditioningcolors">conditioningColors</code></td>
<td>
<p> vector of names of the colors to be used
for the levels of the conditioning factor in the interaction (the 
factor with different lines in the plot) </p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_conditioninglines">conditioningLines</code></td>
<td>
<p> vector of names of the line types to be used
for the levels of the conditioning factor in the interaction (the 
factor with different lines in the plot), by default solid lines </p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_linecolor">lineColor</code></td>
<td>
<p> name of color to be used for the lines in the plot</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_addtoexistingplot">addToExistingPlot</code></td>
<td>
<p> if TRUE, the current plot is added to an already existing plot</p>
</td></tr>
<tr><td><code id="plotAll.fnc_+3A_...">...</code></td>
<td>
<p> further graphical parameters to be passed down, none are currently implemented</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>reslist</code> may contain as elements lists of data frames, these then specify the separate points or lines to be plotted for a given interaction
</p>


<h3>Value</h3>

<p>A plot is produced on the graphics device.
</p>


<h3>Note</h3>

<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='plotLMER.fnc'>plot a mer object</h2><span id='topic+plotLMER.fnc'></span>

<h3>Description</h3>

<p>Plot partial effects of a (generalized) linear mixed-effects model fit with
<code>lmer</code>.  For gaussian models, 95% highest posterior density credible 
intervals can be added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotLMER.fnc(model, xlabel = NA, xlabs = NA, ylabel = NA, ylimit = NA, 
   ilabel = NA, fun = NA, pred = NA, control = NA, ranefs = NA, n = 100, 
   intr = NA,  lockYlim = TRUE, addlines = FALSE, 
   withList = FALSE, cexsize = 0.5, linecolor = 1, addToExistingPlot = FALSE, 
   verbose = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotLMER.fnc_+3A_model">model</code></td>
<td>
<p> a <code>LMM</code> or <code>GLMM</code> model object of class <code>lmerMod</code> </p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_xlabel">xlabel</code></td>
<td>
<p> label for X-axis (if other than the variable name in the
original model formula)</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_xlabs">xlabs</code></td>
<td>
<p> character vector with labels for X-axes in multipanel plot (if 
other than the variable names in the original model formula); if used, 
<code>xlabel</code> should not be specified</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_ylabel">ylabel</code></td>
<td>
<p> label for Y-axis (if other than the variable name of 
the dependent variable in the original model formula) </p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_ylimit">ylimit</code></td>
<td>
<p> range for vertical axis; if not specified, this range will 
be chosen such that all data points across all subplots, including HPD intervals, will be accommodated </p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_ilabel">ilabel</code></td>
<td>
<p> label for the interaction shown in the lower right-hand margin of the plot, overriding the original variable name in the model formula</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_fun">fun</code></td>
<td>
<p> a function to be applied for transforming the dependent variable, 
if <code>NA</code>, no transformation is applied; for models with <code>family = "binomial"</code>, 
fun is set to <code>plogis</code> by default; this can be disabled by setting
<code>fun=function(x)return(x)</code>.</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_pred">pred</code></td>
<td>
<p> character string with name of predictor; 
if specified, a single plot will produced for the partial effect of this
specific predictor</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_control">control</code></td>
<td>
<p> a two-element list <code>list(predictor, val)</code> specifying a <code>predictor</code> the value of which has to be set to <code>val</code> in the partial effect plot(s); the predictor name should be exactly as specified in <code>names(model@fixef)</code>.  It is up to the user to make sure that name and value make sense, the code here hands full 'control' to the user.</p>
</td></tr> 
<tr><td><code id="plotLMER.fnc_+3A_ranefs">ranefs</code></td>
<td>
<p>a four-element list <code>Group, Level, Predictor</code>, specifying a random-effect Group (e.g. <code>Subject</code>), a level (e.g., <code>S10</code>) and a value (e.g., <code>LogFrequency</code>) for which partial effects have to be calibrated.</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_n">n</code></td>
<td>
<p> integer denoting number of points for the plot, chosen at equally
spaced intervals across the empirical range of the predictor variable </p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_intr">intr</code></td>
<td>
<p> a list specifying an interaction to be graphed; obligatory
arguments are (1) the name of the interaction variable, followed by (2) 
a vector of values for that variable, followed by (3) the position for 
interaction labels ('&quot;beg&quot;', '&quot;mid&quot;', or '&quot;end&quot;', or 'NA' if no labels are 
desired), optionally followed by (4) a list with as first element
a vector of colors and as second element a vector of line types. The number
of elements in both vectors should match the number of values specified 
under (2) for the interaction predictor.</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_lockylim">lockYlim</code></td>
<td>
<p> logical specifying whether all subplots should have the same
range of values for the vertical axis; if <code>TRUE</code>, this range will be
chosen to accomodate all fitted values including HDP intervals for all
predictors across all plots</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_addlines">addlines</code></td>
<td>
<p> if TRUE, adds line(s) between levels of same factor(s)</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_withlist">withList</code></td>
<td>
<p> logical, if <code>TRUE</code>, a list will be output with all data 
frames for the subplots</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_cexsize">cexsize</code></td>
<td>
<p> character expansion size (cex) for additional information in
the plot for interactions</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_linecolor">linecolor</code></td>
<td>
<p> color of lines in the plot, by default set to 1 (black) </p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_addtoexistingplot">addToExistingPlot</code></td>
<td>
<p> default FALSE, if set to TRUE, plot will be added to previous plot, but only if pred is specified</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_verbose">verbose</code></td>
<td>
<p> if TRUE (default), effect sizes and default transformations are reported</p>
</td></tr>
<tr><td><code id="plotLMER.fnc_+3A_...">...</code></td>
<td>
<p> further graphical parameters to be passed down; warning: <code>col</code>, 
<code>pch</code>, <code>lty</code> and <code>cex</code> will often generate an error as they are 
internally already fully specified for specialized subplots</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When no predictor is specified, a series of plots is produced for the partial
effects of each predictor.  The graphs are shown for the reference level for
factors and are adjusted for the median value for the other numerical
predicors in the model.  Interactions are not shown.  The user should set up
the appropriate number of subplots on the graphics device before running
plotLMER.fnc().
</p>
<p>Instead of showing all predictors jointly, plotLMER.fnc() can also be used to
plot the partial effect of a specific predictor.  When a specific predictor
is specified (with <code>pred = ...</code>), a single plot is produced for that
predictor.  In this case, the <code>intr</code> argument can be used to specify a
single second predictor that enters into an interaction with the selected
main predictor.  
</p>
<p>Polynomials have to be fitted with <code>poly(..., degree, raw=TRUE)</code> and
restricted cubic splines with <code>rcs()</code> from the <code>rms</code> package.
</p>


<h3>Value</h3>

<p>A plot is produced on the graphical device.
</p>


<h3>Note</h3>

 
<p>This code needs much more work, including (i) extension to <code>poly</code> with <code>raw=FALSE</code>,
and (ii) general clean-up of the code.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>The 'danish' dataset in the example section is contributed by Laura Winther-Balling, 
see Winther-Balling, L. and Baayen, R. H., Morphological effects in auditory word recognition: 
Evidence from Danish, Language and Cognitive Processes, in press.</p>


<h3>See Also</h3>

<p>See also other utilities in languageR for facilitating work with <code>lmer</code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 

###########################################################################
# we will stay as close to the older optimizer of lme4 as possible -
# this requires the optimx package and using the control option of lmer()
###########################################################################
require(optimx)

###########################################################################
# fitting a cosine with a spline (simulated data)
###########################################################################

require("rms", quietly=TRUE, character=TRUE)
require("lme4", quietly=TRUE, character=TRUE)
dfr = makeSplineData.fnc()
table(dfr$Subject)
xylowess.fnc(Y ~ X | Subject, data = dfr)
# the smoother doesn't recognize the cosine function implemented in makeSplineData.fnc()
dev.off()   

dfr.lmer = lmer(Y ~ rcs(X, 5) + (1|Subject), data = dfr,
  control = lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
plotLMER.fnc(dfr.lmer)

# comparison with ols from Design package
dfr.lm = lm(Y~Subject+rcs(X), data=dfr, x=T, y=T)
dfr$fittedOLS = fitted(dfr.lm)
dfr$fittedLMER = as.vector(dfr.lmer@pp$X %*% fixef(dfr.lmer))

# we plot the lmer() fit in blue, the ols() fit in red (both adjusted for
# subject S1), and plot the underlying model in green

plot(dfr[dfr$Subject=="S1",]$X, 
  dfr[dfr$Subject=="S1",]$fittedLMER + ranef(dfr.lmer)[[1]]["S1",], 
  col="blue", ylim = c(24,30), xlab="X", ylab="Y", type="n")   

lines(dfr[dfr$Subject=="S1",]$X, dfr[dfr$Subject=="S1",]$fittedOLS, col="red")
lines(dfr[dfr$Subject=="S1",]$X, dfr[dfr$Subject=="S1",]$fittedLMER, col="blue")
lines(dfr[dfr$Subject=="S1",]$X, dfr[dfr$Subject=="S1",]$y+
  ranef(dfr.lmer)[[1]]["S1",], col="green")
legend(2,30,c("30+cos(x)", "lmer (S1)", "ols (S1)"), lty=rep(1,3), 
  col=c("green", "blue", "red"))


#############################################################
# a model with a raw polynomial
#############################################################

bg.lmer = lmer(LogRT ~ PC1+PC2+PC3 + ReadingScore +
  poly(OrthLength, 2, raw=TRUE) + LogFrequency + LogFamilySize +
  (1|Word) + (1|Subject)+(0+OrthLength|Subject) +
  (0+LogFrequency|Subject), data = beginningReaders,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

pars = par()
par(mfrow=c(3,3), mar=c(5,5,1,1))
plotLMER.fnc(bg.lmer, fun=exp, ylabel = "RT (ms)")

#############################################################
# a model with an interaction involving numeric predictors
#############################################################

danish.lmer = lmer(LogRT ~ PC1 + PC2 + PrevError + Rank +
  ResidSemRating + ResidFamSize + LogWordFreq*LogAffixFreq*Sex +  
  poly(LogCUP, 2, raw=TRUE) + LogUP + LogCUPtoEnd + 
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
danish.lmerA = lmer(LogRT ~ PC1 + PC2 + PrevError + Rank +
  ResidSemRating + ResidFamSize + LogWordFreq*LogAffixFreq*Sex +  
  poly(LogCUP, 2, raw=TRUE) + LogUP + LogCUPtoEnd + 
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  subset=abs(scale(resid(danish.lmer)))&lt;2.5,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

# plot for reference level of Sex
plotLMER.fnc(danish.lmerA, pred = "LogAffixFreq", 
  intr=list("LogWordFreq", round(quantile(danish$LogWordFreq),3), "beg",
  list(c("red", "green", "blue", "yellow", "purple"), rep(1,5))), 
  ylimit=c(6.5,7.0))

# this model has a significant three-way interaction
# for visualization, we can either relevel Sex and refit,
# or make use of the control option. First releveling:

danish$Sex=relevel(danish$Sex, "F")
danish.lmerF = lmer(LogRT ~ PC1 + PC2 + PrevError + Rank +
  ResidSemRating + ResidFamSize + LogWordFreq*LogAffixFreq*Sex +  
  poly(LogCUP, 2, raw=TRUE) + LogUP + LogCUPtoEnd + 
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
danish$Sex=relevel(danish$Sex, "M")
danish.lmerM = lmer(LogRT ~ PC1 + PC2 + PrevError + Rank +
  ResidSemRating + ResidFamSize + LogWordFreq*LogAffixFreq*Sex +  
  poly(LogCUP, 2, raw=TRUE) + LogUP + LogCUPtoEnd + 
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

# Next preparing for using the control option:
#
# names(fixef(danish.lmer))[10]     # SexM
# unique(danish.lmer@pp$X[,10])     # 1 0

par(mfrow=c(2,2))

plotLMER.fnc(danish.lmer, pred="LogWordFreq", ylimit=c(6.5,7.0),
intr=list("LogAffixFreq", round(quantile(danish$LogAffixFreq),2), "end"),
control=list("SexM", 0))
mtext("females", line=1.5, cex=0.9)

plotLMER.fnc(danish.lmer, pred="LogWordFreq", ylimit=c(6.5,7.0),
intr=list("LogAffixFreq", round(quantile(danish$LogAffixFreq),2), "end"),
control=list("SexM", 1))
mtext("males", line=1.5, cex=0.9)

plotLMER.fnc(danish.lmerF, pred="LogWordFreq", ylimit=c(6.5,7.0), 
intr=list("LogAffixFreq", round(quantile(danish$LogAffixFreq),2), "end"))
mtext("females", line=1.5, cex=0.9)

plotLMER.fnc(danish.lmerM, pred="LogWordFreq", ylimit=c(6.5, 7.0),
intr=list("LogAffixFreq", round(quantile(danish$LogAffixFreq),2), "end"))
mtext("males", line=1.5, cex=0.9)

par(mfrow=c(1,1))

#############################################################
# calculating effect sizes, defined as max - min
#############################################################

# effect size for a covariate

dfr = plotLMER.fnc(danish.lmerA, pred = "LogCUP", withList=TRUE)
max(dfr$LogCUP$Y)-min(dfr$LogCUP$Y)

# effect size for a factor

dfr = plotLMER.fnc(danish.lmerA, pred = "PrevError", withList=TRUE)
max(dfr$PrevError$Y)-min(dfr$PrevError$Y)


# effect sizes for the quantiles in an interaction plot

dfr = plotLMER.fnc(danish.lmerA, pred = "LogAffixFreq", 
  withList=TRUE,
  intr=list("LogWordFreq", round(quantile(danish$LogWordFreq),3), "beg"))

unlist(lapply(dfr$LogAffixFreq, FUN=function(X)return(max(X$Y)-min(X$Y))))


#############################################################
# plotting an interaction between two factors
#############################################################

danish$WordFreqFac = danish$LogWordFreq &gt; median(danish$LogWordFreq)
danish.lmer2 = lmer(LogRT ~ WordFreqFac*Sex +  
  (1|Subject) + (1|Word) + (1|Affix), data = danish,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

plotLMER.fnc(danish.lmer2, pred = "Sex", 
  intr=list("WordFreqFac", c("TRUE", "FALSE"), "end", 
  list(c("red",  "blue"), rep(1,2))),
  ylimit=c(6.7,6.9), cexsize=1.0, addlines=TRUE)

#############################################################
# a generalized linear mixed-effects model
#############################################################

dative.lmer = glmer(RealizationOfRecipient ~ 
  AccessOfTheme + AccessOfRec + LengthOfRecipient + AnimacyOfRec +
  AnimacyOfTheme + PronomOfTheme + DefinOfTheme + LengthOfTheme +
  SemanticClass + Modality + (1|Verb), 
  data = dative, family = "binomial",
  control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))

par(mfrow=c(3,4),mar=c(5,5,1,1))
plotLMER.fnc(dative.lmer, fun=plogis, addlines=TRUE)

# with user-specified labels for the x-axis
par(mfrow=c(3,4),mar=c(5,5,1,1))
plotLMER.fnc(dative.lmer, fun=plogis, addlines=TRUE,
  xlabs=unlist(strsplit("abcdefghij","")))

par(pars)


  
## End(Not run)
</code></pre>

<hr>
<h2 id='plotlogistic.fit.fnc'>Plot for goodness of fit of logistic regression</h2><span id='topic+plotlogistic.fit.fnc'></span>

<h3>Description</h3>

<p>This function plots observed proportions against mean predicted
probabilities. For a good fit, points should be approximately on
a straight line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotlogistic.fit.fnc(x, data, method, where, scalesize, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotlogistic.fit.fnc_+3A_x">x</code></td>
<td>
<p>A logistic regression model fitted with <code>lmer</code> or
<code>lrm</code>.</p>
</td></tr>
<tr><td><code id="plotlogistic.fit.fnc_+3A_data">data</code></td>
<td>
<p>The data set to which the model was fitted.</p>
</td></tr>
<tr><td><code id="plotlogistic.fit.fnc_+3A_method">method</code></td>
<td>
<p>Either &quot;cut&quot;, in which case the vector of cut-off points
supplied by the &quot;where&quot; argument will be used to partition the fitted 
probabilities, or &quot;shingle&quot;, in which a shingle (using <code>equal.count</code> 
and its defaults) will be used.</p>
</td></tr>
<tr><td><code id="plotlogistic.fit.fnc_+3A_where">where</code></td>
<td>
<p>A vector of cut-off points for partitioning the vector of
fitted probabilities, by default <code>seq(0, 1, by=0.1)</code></p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="plotlogistic.fit.fnc_+3A_scalesize">scalesize</code></td>
<td>
<p>A positive real &lt;= 1.  If not NA (the default), the circles
representing data points in the graph are scaled to reflect the number of
data points in the underlying data set.  The scalesize parameter specifies
how large the largest circle will be compared to 1 inch.  For counts with
large outliers, small values of scalesize are better.  See example below.
</p>
</td></tr>
<tr><td><code id="plotlogistic.fit.fnc_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot is produced on the graphics device.  The R-squared value shown
above the plot represents the correlation between the X and Y values in the
plot.  It does NOT represent the R-squared of the lrm or lmer model.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(dative)
require(lme4)
require(rms)
require(lmerTest)
require(optimx)

dative.lrm = lrm(RealizationOfRecipient ~ AccessOfTheme + 
   AccessOfRec + LengthOfRecipient + AnimacyOfRec +
   AnimacyOfTheme + PronomOfTheme + DefinOfTheme + LengthOfTheme +
   SemanticClass + Modality, 
   data = dative)

dative.glmm = glmer(RealizationOfRecipient ~ AccessOfTheme + 
   AccessOfRec + LengthOfRecipient + AnimacyOfRec +
   AnimacyOfTheme + PronomOfTheme + DefinOfTheme + LengthOfTheme +
   SemanticClass + Modality + (1|Verb), 
   control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
   data = dative, family = "binomial")

par(mfrow=c(2,2))
plotlogistic.fit.fnc (dative.lrm, dative)
mtext("lrm", 3, 3)
plotlogistic.fit.fnc (dative.glmm, dative)
mtext("lmer", 3, 3)
plotlogistic.fit.fnc (dative.lrm, dative, scalesize=0.2)
mtext("lrm", 3, 3)
plotlogistic.fit.fnc (dative.glmm, dative, method="shingle")
mtext("lmer", 3, 3)
par(mfrow=c(1,1))



## End(Not run)</code></pre>

<hr>
<h2 id='preparePredictor.fnc'> determine X and Y values for a given (sub)plot</h2><span id='topic+preparePredictor.fnc'></span>

<h3>Description</h3>

<p>this function figures out the X and Y values for a given (sub)plot,
including upper and lower 95% HPD intervals
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preparePredictor.fnc(pred, model, m, ylabel, fun, val, xlabel, ranefs, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preparePredictor.fnc_+3A_pred">pred</code></td>
<td>
<p> character string denoting predictor to be plotted on horizontal axis </p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_model">model</code></td>
<td>
<p> model fit by <code>lmer</code></p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_m">m</code></td>
<td>
<p> matrix as produced by <code>makeDefaultMatrix.fnc</code> </p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_ylabel">ylabel</code></td>
<td>
<p>label for vertical axis (if other than name of dependent variable</p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_fun">fun</code></td>
<td>
<p> character string denoting transformation function for dependent variable, currently only '&quot;plogis&quot;' or '&quot;exp&quot;' </p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_val">val</code></td>
<td>
<p> value of interacting variable </p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_xlabel">xlabel</code></td>
<td>
<p> label for horizontal axis </p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_ranefs">ranefs</code></td>
<td>
<p> a three-element list <code>Group, Level, Predictor</code>, specifying a random-effect Group (e.g. <code>Subject</code>), a level (e.g., <code>S10</code>) and a value (e.g., <code>LogFrequency</code>) for which partial effects have to be calibrated; implemented only for <code>mcmcMat=NA</code>.</p>
</td></tr>
<tr><td><code id="preparePredictor.fnc_+3A_...">...</code></td>
<td>
<p> further graphical parameters, currently not implemented </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with values to be plotted, with columns
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>values of predictor</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>fitted values</p>
</td></tr>
<tr><td><code>Type</code></td>
<td>
<p>logical for whether predictor is factor</p>
</td></tr>
<tr><td><code>Interaction</code></td>
<td>
<p>logical for whether predictor is interacting predictor</p>
</td></tr>
<tr><td><code>Levels</code></td>
<td>
<p>for factors, the factor level names (only present for factors)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: Not intended for independent use.
</code></pre>

<hr>
<h2 id='primingHeid'>Primed lexical decision latencies for neologisms ending in -heid</h2><span id='topic+primingHeid'></span>

<h3>Description</h3>

<p>Primed lexical decision latencies for Dutch neologisms ending in the
suffix <em>-heid</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(primingHeid)</code></pre>


<h3>Format</h3>

<p>A data frame with 832 observations on the following 13 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor with subjects as levels.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd>
<dt><code>Trial</code></dt><dd><p>a numeric vector for the rank of the trial in its
experimental list.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector with log-transformed lexical decision
latencies.</p>
</dd>
<dt><code>Condition</code></dt><dd><p>a factor coding the priming treatmen,
with levels <code>baseheid</code> (prime is the base word) and
<code>heid</code> (the prime is the neologism)</p>
</dd>
<dt><code>Rating</code></dt><dd><p>a numeric vector for subjective frequency estimates.</p>
</dd>
<dt><code>Frequency</code></dt><dd><p>a numeric vector for 
log-transformed frequencies of the whole word.</p>
</dd>
<dt><code>BaseFrequency</code></dt><dd><p>a numeric vector for the log-transformed 
frequencies of the base word.</p>
</dd>
<dt><code>LengthInLetters</code></dt><dd><p>a numeric vector coding orthographic length
in letters.</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector for the log-transformed
count of the word's morphological family.</p>
</dd>
<dt><code>NumberOfSynsets</code></dt><dd><p>a numeric vector for the number of synonym
sets in WordNet in which the base is listed.</p>
</dd>
<dt><code>ResponseToPrime</code></dt><dd><p>a factor with levels <code>correct</code> and
<code>incorrect</code> for the response to the prime.</p>
</dd>
<dt><code>RTtoPrime</code></dt><dd><p>a numeric vector for the log-transformed 
reaction time to the prime.</p>
</dd>
</dl>



<h3>References</h3>

<p>De Vaan, L., Schreuder, R. and Baayen, R. H. (2007) Regular morphologically
complex neologisms leave detectable traces in the mental lexicon, <em>The
Mental Lexicon</em>, 2, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(primingHeid)

require(lme4)
require(lmerTest)
require(optimx)

primingHeid.lmer = lmer(RT ~ RTtoPrime * ResponseToPrime + Condition +
  (1|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = primingHeid)
summary(primingHeid.lmer)

# model criticism

primingHeid.lmer = lmer(RT ~ RTtoPrime * ResponseToPrime + Condition +
  (1|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = primingHeid[abs(scale(resid(primingHeid.lmer)))&lt;2.5,])
summary(primingHeid.lmer)

## End(Not run)</code></pre>

<hr>
<h2 id='primingHeidPrevRT'>Primed lexical decision latencies for neologisms ending in -heid</h2><span id='topic+primingHeidPrevRT'></span>

<h3>Description</h3>

<p>Primed lexical decision latencies for Dutch neologisms ending in the
suffix <em>-heid</em>, with information on RTs to preceding trials added
to the data already in primingHeid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(primingHeidPrevRT)</code></pre>


<h3>Format</h3>

<p>A data frame with 832 observations on the following 17 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor with subjects as levels.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd>
<dt><code>Trial</code></dt><dd><p>a numeric vector for the rank of the trial in its
experimental list.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector with log-transformed lexical decision
latencies.</p>
</dd>
<dt><code>Condition</code></dt><dd><p>a factor coding the priming treatmen,
with levels <code>baseheid</code> (prime is the base word) and
<code>heid</code> (the prime is the neologism)</p>
</dd>
<dt><code>Rating</code></dt><dd><p>a numeric vector for subjective frequency estimates.</p>
</dd>
<dt><code>Frequency</code></dt><dd><p>a numeric vector for 
log-transformed frequencies of the whole word.</p>
</dd>
<dt><code>BaseFrequency</code></dt><dd><p>a numeric vector for the log-transformed 
frequencies of the base word.</p>
</dd>
<dt><code>LengthInLetters</code></dt><dd><p>a numeric vector coding orthographic length
in letters.</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector for the log-transformed
count of the word's morphological family.</p>
</dd>
<dt><code>NumberOfSynsets</code></dt><dd><p>a numeric vector for the number of synonym
sets in WordNet in which the base is listed.</p>
</dd>
<dt><code>ResponseToPrime</code></dt><dd><p>a factor with levels <code>correct</code> and
<code>incorrect</code> for the response to the prime.</p>
</dd>
<dt><code>RTtoPrime</code></dt><dd><p>a numeric vector for the log-transformed 
reaction time to the prime.</p>
</dd>
<dt><code>RTmin1</code></dt><dd><p>a numeric vector for  
reaction time in ms to the item preceding the target.</p>
</dd>
<dt><code>RTmin2</code></dt><dd><p>a numeric vector for  
reaction time in ms to the item preceding the target by two trials.</p>
</dd>
<dt><code>RTmin3</code></dt><dd><p>a numeric vector for  
reaction time in ms to the item preceding the target by three trials.</p>
</dd>
<dt><code>RTmin4</code></dt><dd><p>a numeric vector for  
reaction time in ms to the item preceding the target by four trials.</p>
</dd>
</dl>



<h3>References</h3>

<p>De Vaan, L., Schreuder, R. and Baayen, R. H. (2007) Regular morphologically
complex neologisms leave detectable traces in the mental lexicon, <em>The
Mental Lexicon</em>, 2, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(primingHeidPrevRT)

require(lme4)
require(optimx)
require(lmerTest)

primingHeid.lmer = lmer(RT ~ RTtoPrime * ResponseToPrime + Condition + 
  log(RTmin1) + (1|Subject) + (1|Word), data = primingHeidPrevRT,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
summary(primingHeid.lmer)

## End(Not run)</code></pre>

<hr>
<h2 id='print.corres'>Print method for correspondence object</h2><span id='topic+print.corres'></span>

<h3>Description</h3>

<p>Prints eigenvalues and eigenvalue rates for a correspondence object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'corres'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.corres_+3A_x">x</code></td>
<td>
<p>A correspondence object.</p>
</td></tr>
<tr><td><code id="print.corres_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Report of eigenvalues and eigenvalue rates.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+corres.fnc">corres.fnc</a></code>. </p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(oldFrench)
  oldFrench.ca = corres.fnc(oldFrench)
  oldFrench.ca

## End(Not run)</code></pre>

<hr>
<h2 id='print.growth'>Print method for growth objects.</h2><span id='topic+print.growth'></span>

<h3>Description</h3>

<p>Print method for growth objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'growth'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.growth_+3A_x">x</code></td>
<td>
<p>A growth object, as produced by <code>growth.fnc</code>.</p>
</td></tr>
<tr><td><code id="print.growth_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The data frame with chunk sizes and associated vocabulary statistics
is printed.   To access the data frame that is being shown, use
<code>&lt;my.growth.object&gt;@data$data</code>.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  alice.growth = growth.fnc(alice)
  alice.growth
  # for accessing the printed data frame:
  alice.growth@data$data[1:4,]

## End(Not run)</code></pre>

<hr>
<h2 id='pvals.fnc'>Compute p-values and MCMC confidence intervals for mixed models</h2><span id='topic+pvals.fnc'></span>

<h3>Description</h3>

<p>This function used to calculate p-values and HPD intervals for the 
parameters of models fitted with <code>lmer</code>.  
</p>
<p>As MCMC is no longer supported by lme4, this function is now obsolete
and does no longer produce any output, other than a warning.
</p>
<p>See the lme4 function pvalues() for alternatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvals.fnc(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvals.fnc_+3A_object">object</code></td>
<td>
<p>a <code>LMM</code> or <code>GLMM</code> model object of class <code>lmerMod</code></p>
</td></tr>
<tr><td><code id="pvals.fnc_+3A_...">...</code></td>
<td>
<p>Optional arguments that can be passed down.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A warning.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>pvalues</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: 
  data(primingHeid) 
  library(lme4)

  # remove extreme outliers
  primingHeid = primingHeid[primingHeid$RT &lt; 7.1,]

  # fit mixed-effects model

  # we will stay as close to the older optimizer of lme4 as possible -
  # this requires the optimx package and using the control option of lmer()

  require(optimx)
  require(lmerTest)

  primingHeid.lmer = lmer(RT ~ RTtoPrime * ResponseToPrime + 
    Condition + (1|Subject) + (1|Word), data = primingHeid,
    control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
  summary(primingHeid.lmer)
  anova(primingHeid.lmer)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='quasif'>Simulated data set with subjects and items requiring quasi-F ratios</h2><span id='topic+quasif'></span>

<h3>Description</h3>

<p>Simulated lexical decision latencies with SOA as treatment, traditionally
requiring an analysis using quasi-F ratios, as available in
Raaijmakers et al. (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(quasif)</code></pre>


<h3>Format</h3>

<p>A data frame with 64 observations on the following 4 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor coding subjects.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector for simulated reaction times 
in lexical decision.</p>
</dd>
<dt><code>Item</code></dt><dd><p>a factor coding items.</p>
</dd>
<dt><code>SOA</code></dt><dd><p>a factor coding SOA treatment with levels <code>long</code>
and <code>short</code>.</p>
</dd> 
</dl>



<h3>Source</h3>

<p>Raaijmakers, J.G.W., Schrijnemakers, J.M.C. &amp; Gremmen, F. (1999)
How to deal with &quot;The language as fixed effect fallacy&quot;: 
common misconceptions and alternative solutions, 
<em>Journal of Memory and Language</em>, 41, 416-426.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(quasif)
items.quasif.fnc(quasif)

## End(Not run)</code></pre>

<hr>
<h2 id='quasiF.fnc'>Quasi-F test</h2><span id='topic+quasiF.fnc'></span>

<h3>Description</h3>

<p>The textbook Quasi-F test for a design with subjects, items,
and a single factorial predictor.  Included for educational purposes
for this specific design only. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quasiF.fnc(ms1, ms2, ms3, ms4, df1, df2, df3, df4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quasiF.fnc_+3A_ms1">ms1</code></td>
<td>
<p>Mean squares Factor</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_ms2">ms2</code></td>
<td>
<p>Mean squares Item:Subject</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_ms3">ms3</code></td>
<td>
<p>Mean squares Factor:Subject</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_ms4">ms4</code></td>
<td>
<p>Mean squares Item</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_df1">df1</code></td>
<td>
<p>Degrees of freedom Factor</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_df2">df2</code></td>
<td>
<p>Degrees of freedom Item:Subject</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_df3">df3</code></td>
<td>
<p>Degrees of freedom Factor:Subject</p>
</td></tr>
<tr><td><code id="quasiF.fnc_+3A_df4">df4</code></td>
<td>
<p>Degrees of freedom Item</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>F</code></td>
<td>
<p>Quasi-F value.</p>
</td></tr>
<tr><td><code>df1</code></td>
<td>
<p>degrees of freedom numerator.</p>
</td></tr>
<tr><td><code>df2</code></td>
<td>
<p>degrees of freedom denominator.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>p-value.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+quasiFsim.fnc">quasiFsim.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(quasif)

  quasif.lm = lm(RT ~ SOA + Item + Subject + 
     SOA:Subject + Item:Subject, data = quasif)
  quasif.aov = anova(quasif.lm)

  quasiF.fnc(quasif.aov["SOA","Mean Sq"], 
     quasif.aov["Item:Subject", "Mean Sq"],
     quasif.aov["SOA:Subject", "Mean Sq"], 
     quasif.aov["Item", "Mean Sq"],
     quasif.aov["SOA","Df"], 
     quasif.aov["Item:Subject", "Df"],
     quasif.aov["SOA:Subject", "Df"], 
     quasif.aov["Item", "Df"])

  # much simpler is
  quasiFsim.fnc(quasif)$quasiF

</code></pre>

<hr>
<h2 id='quasiFsim.fnc'>Quasi-F test for specific simple design</h2><span id='topic+quasiFsim.fnc'></span>

<h3>Description</h3>

<p>This function carries out a Quasi-F test for data with columns 
labelled SOA, Subject, Item.  
This function is called by simulate.quasif.fnc, and is
not intended for general use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quasiFsim.fnc(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quasiFsim.fnc_+3A_dat">dat</code></td>
<td>
<p>A data frame with RT (or RTsim), SOA, Subject and Item as
predictors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>The p-value of the quasi-F test.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The input data.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The linear model fitted to the data.</p>
</td></tr>
<tr><td><code>qF</code></td>
<td>
<p>a list with F, df1, df2 and p-value of quasi-F test.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+quasiF.fnc">quasiF.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>    data(quasif)
    quasiFsim.fnc(quasif)$quasiF
</code></pre>

<hr>
<h2 id='ratings'>Ratings for 81 English nouns</h2><span id='topic+ratings'></span>

<h3>Description</h3>

<p>Subjective frequency ratings, ratings of estimated weight, and ratings of estimated
size, averaged over subjects, for 81 concrete English nouns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ratings)</code></pre>


<h3>Format</h3>

<p>A data frame with 81 observations on the following 14 variables.
</p>

<dl>
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd> 
<dt><code>Frequency</code></dt><dd><p>a numeric vector of logarithmically transformed frequencies</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector of logarithmically transformed 
morphological family sizes.</p>
</dd>
<dt><code>SynsetCount</code></dt><dd><p>a numeric vector with logarithmically transformed counts
of the number of synonym sets in WordNet in which the word is listed.</p>
</dd>
<dt><code>Length</code></dt><dd><p>a numeric vector for the length of the word in letters.</p>
</dd>
<dt><code>Class</code></dt><dd><p>a factor with levels <code>animal</code> and <code>plant</code>.</p>
</dd>
<dt><code>FreqSingular</code></dt><dd><p>a numeric vector for the frequency of the word in the
singular.</p>
</dd>
<dt><code>FreqPlural</code></dt><dd><p>a numeric vector with the frequency of the word in the
plural.</p>
</dd>
<dt><code>DerivEntropy</code></dt><dd><p>a numeric vector with the derivational entropies of the
words.</p>
</dd>
<dt><code>Complex</code></dt><dd><p>a factor coding morphological complexity with levels 
<code>complex</code> and <code>simplex</code>.</p>
</dd>
<dt><code>rInfl</code></dt><dd><p>a numeric vector coding the log of ratio of singular to plural
frequencies.</p>
</dd>
<dt><code>meanWeightRating</code></dt><dd><p>a numeric vector for the estimated weight of the
word's referent, averaged over subjects.</p>
</dd>
<dt><code>meanSizeRating</code></dt><dd><p>a numeric vector for the estimated size of the word's
referent, averaged over subjects.</p>
</dd>
<dt><code>meanFamiliarity</code></dt><dd><p>a numeric vector with subjective frequency estimates,
averaged over subjects.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data collected together with Jen Hay at the University of Canterbury, Christchurch,
New Zealand, 2004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(ratings)

ratings.lm = lm(meanSizeRating ~ meanFamiliarity * Class + 
I(meanFamiliarity^2), data = ratings)

ratings$fitted = fitted(ratings.lm)

plot(ratings$meanFamiliarity, ratings$meanSizeRating,       
xlab = "mean familiarity", ylab = "mean size rating", type = "n")
text(ratings$meanFamiliarity, ratings$meanSizeRating, 
substr(as.character(ratings$Class), 1, 1), col = 'darkgrey')

plants = ratings[ratings$Class == "plant", ]    
animals = ratings[ratings$Class == "animal", ]  
plants = plants[order(plants$meanFamiliarity),]
animals = animals[order(animals$meanFamiliarity),]

lines(plants$meanFamiliarity, plants$fitted)
lines(animals$meanFamiliarity, animals$fitted)

## End(Not run)</code></pre>

<hr>
<h2 id='regularity'>Regular and irregular Dutch verbs</h2><span id='topic+regularity'></span>

<h3>Description</h3>

<p>Regular and irregular Dutch verbs and selected lexical and distributional
properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(regularity)</code></pre>


<h3>Format</h3>

<p>A data frame with 700 observations on the following 13 variables.
</p>

<dl>
<dt><code>Verb</code></dt><dd><p>a factor with the verbs as levels.</p>
</dd>
<dt><code>WrittenFrequency</code></dt><dd><p>a numeric vector of logarithmically transformed
frequencies in written Dutch (as available in the CELEX lexical database).</p>
</dd>
<dt><code>NcountStem</code></dt><dd><p>a numeric vector for the number of orthographic neighbors.</p>
</dd>
<dt><code>VerbalSynsets</code></dt><dd><p>a numeric vector for the number of verbal synsets in WordNet.</p>
</dd>
<dt><code>MeanBigramFrequency</code></dt><dd><p>a numeric vector for mean log bigram frequency.</p>
</dd>
<dt><code>InflectionalEntropy</code></dt><dd><p>a numeric vector for Shannon's entropy calculated for the word's inflectional variants.</p>
</dd>
<dt><code>Auxiliary</code></dt><dd><p>a factor with levels <code>hebben</code>, <code>zijn</code> and <code>zijnheb</code> for the verb's auxiliary in the perfect tenses.</p>
</dd>
<dt><code>Regularity</code></dt><dd><p>a factor with levels <code>irregular</code> and <code>regular</code>.</p>
</dd>
<dt><code>LengthInLetters</code></dt><dd><p>a numeric vector of the word's orthographic length.</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector for the number of types in the word's 
morphological family.</p>
</dd>
<dt><code>Valency</code></dt><dd><p>a numeric vector for the verb's valency, estimated by its 
number of argument structures.</p>
</dd>
<dt><code>NVratio</code></dt><dd><p>a numeric vector for the log-transformed ratio of the nominal
and verbal frequencies of use.</p>
</dd>
<dt><code>WrittenSpokenRatio</code></dt><dd><p>a numeric vector for the log-transformed ratio of the frequencies in written and spoken Dutch.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baayen, R. H. and Moscoso del Prado Martin, F. (2005) Semantic density and
past-tense formation in three Germanic languages, Language, 81, 666-698.
</p>
<p>Tabak, W., Schreuder, R. and Baayen, R. H. (2005) Lexical statistics and
lexical processing: semantic density, information complexity, sex, and
irregularity in Dutch, in Kepser, S. and Reis, M., <em>Linguistic Evidence -
Empirical, Theoretical, and Computational Perspectives</em>, Berlin: Mouton de
Gruyter, pp. 529-555.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(regularity)

# ---- predicting regularity with a logistic regression model

library(rms)
regularity.dd = datadist(regularity)
options(datadist = 'regularity.dd')

regularity.lrm = lrm(Regularity ~ WrittenFrequency + 
rcs(FamilySize, 3) + NcountStem + InflectionalEntropy + 
Auxiliary + Valency + NVratio + WrittenSpokenRatio, 
data = regularity, x = TRUE, y = TRUE)

anova(regularity.lrm)

# ---- model validation

validate(regularity.lrm, bw = TRUE, B = 200)
pentrace(regularity.lrm, seq(0, 0.8, by = 0.05))
regularity.lrm.pen = update(regularity.lrm, penalty = 0.6)
regularity.lrm.pen

# ---- a plot of the partial effects

plot(Predict(regularity.lrm.pen))

# predicting regularity with a support vector machine

library(e1071)
regularity$AuxNum = as.numeric(regularity$Auxiliary)
regularity.svm = svm(regularity[, -c(1,8,10)], regularity$Regularity, cross=10)
summary(regularity.svm)

## End(Not run)</code></pre>

<hr>
<h2 id='selfPacedReadingHeid'>Self-paced reading latencies for Dutch neologisms</h2><span id='topic+selfPacedReadingHeid'></span>

<h3>Description</h3>

<p>Self-paced reading latencies for Dutch neologisms ending in the
suffix <em>-heid</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(selfPacedReadingHeid)</code></pre>


<h3>Format</h3>

<p>A data frame with 1280 observations on the following 18 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor with subjects as levels.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector with logarithmically transformed
reading latencies.</p>
</dd>
<dt><code>RootFrequency</code></dt><dd><p>a numeric vector for the logarithmically
transformed frequency of the lowest-level base of the neologism
(e.g., <em>lob</em> in <em>[[[lob]+ig]+heid]</em>.</p>
</dd>
<dt><code>Condition</code></dt><dd><p>a factor for the priming conditions 
with levels <code>baseheid</code> (neologism is preceded 40 trials back
by its base word) and <code>heidheid</code> (the neologism is preceded
40 trials back by itself).</p>
</dd>
<dt><code>Rating</code></dt><dd><p>a numeric vector for the word's subjective frequency
estimate.</p>
</dd>
<dt><code>Frequency</code></dt><dd><p>a numeric vector for the neologism's frequency
(all zero).</p>
</dd>
<dt><code>BaseFrequency</code></dt><dd><p>a numeric vector for the base adjective
underlying the neologism (e.g., <em>lobbig</em> in 
<em>[[[lob]+ig]+heid]</em>).</p>
</dd>
<dt><code>LengthInLetters</code></dt><dd><p>a numeric vector coding word length in
letters.</p>
</dd>
<dt><code>FamilySize</code></dt><dd><p>a numeric vector for the logaritmically
transformed count of a word's morphological family members.</p>
</dd>
<dt><code>NumberOfSynsets</code></dt><dd><p>a numeric vector for the count of synonym
sets in WordNet in which the word is listed.</p>
</dd>
<dt><code>RT4WordsBack</code></dt><dd><p>a numeric vector for the log-transformed 
reading latencies four trials back.</p>
</dd>
<dt><code>RT3WordsBack</code></dt><dd><p>a numeric vector for the log-transformed 
reading latencies three trials back.</p>
</dd>
<dt><code>RT2WordsBack</code></dt><dd><p>a numeric vector for the log-transformed 
reading latencies two trials back.</p>
</dd>
<dt><code>RT1WordBack</code></dt><dd><p>a numeric vector for the log-transformed 
reading latencies one trial back.</p>
</dd>
<dt><code>RT1WordLater</code></dt><dd><p>a numeric vector for the log-transformed 
reading latencies one trial later.</p>
</dd>
<dt><code>RT2WordsLater</code></dt><dd><p>a numeric vector for the log-transformed 
reading latencies two trials later.</p>
</dd>
<dt><code>RTtoPrime</code></dt><dd><p>a numeric vector for the log-transformed reading
latency for the prime.</p>
</dd>
</dl>



<h3>References</h3>

<p>De Vaan, L., Schreuder, R. and Baayen, R. H. (2007) Regular morphologically
complex neologisms leave detectable traces in the mental lexicon, <em>The
Mental Lexicon</em>, 2, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(selfPacedReadingHeid)

# data validation
plot(sort(selfPacedReadingHeid$RT))   
selfPacedReadingHeid = selfPacedReadingHeid[selfPacedReadingHeid$RT &gt; 5 &amp; 
  selfPacedReadingHeid$RT &lt; 7.2,]

# fitting a mixed-effects model

require(lme4)
require(lmerTest)
require(optimx)
x = selfPacedReadingHeid[,12:15]
x.pr = prcomp(x, center = TRUE, scale = TRUE)
selfPacedReadingHeid$PC1 = x.pr$x[,1]

selfPacedReadingHeid.lmer = lmer(RT ~ RTtoPrime + LengthInLetters + 
  PC1 * Condition + (1|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = selfPacedReadingHeid)  
summary(selfPacedReadingHeid.lmer)

# model criticism

selfPacedReadingHeid.lmerA = lmer(RT ~ RTtoPrime + LengthInLetters + 
  PC1 * Condition + (1|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = selfPacedReadingHeid[abs(scale(resid(selfPacedReadingHeid.lmer))) &lt; 2.5, ])

qqnorm(resid(selfPacedReadingHeid.lmerA))
summary(selfPacedReadingHeid.lmerA)

## End(Not run)</code></pre>

<hr>
<h2 id='shadenormal.fnc'>Shade rejection region for normal probability density function</h2><span id='topic+shadenormal.fnc'></span>

<h3>Description</h3>

<p>This function plots the standord normal probability density function
and shades the rejection region.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shadenormal.fnc(qnts = c(0.025, 0.975))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shadenormal.fnc_+3A_qnts">qnts</code></td>
<td>
<p>A numeric vector with the Z-scores of the boundaries
of the lower and upper rejection regions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot on the graphics device.
</p>
<p>Type <code>shadenormal.fnc</code> to see the code.  The polygon() function used for
the shaded areas takes a sequence of X and Y coordinates, connects the
corresponding points, and fills the area(s) enclosed with a specified color.
To understand the use of polygon(), one can best think of making a
polygon with a set of pins, a thread, and a board.  Outline the polygon by
placing the pins on the board at the corners of the polygon. First fasten the
thread to one of the pins, then connect the thread to the second pin, from
there to the third pin, and so on, until the first pin has been reached.
What polygon() requires as input is a vector of the X-coordinates of
the pins, and a vector of their Y-coordinates.  These coordinates should be
in exactly the order in which the thread is to be connected from pin to pin.  
</p>
<p>For shading the left rejection area, we specify the vectors of X and Y
coordinates, beginning at the leftmost point of the tail, proceding to the
right edge of the shaded area, then up, and finally to the left and down to
the starting point, thereby closing the polygon.  The X-coordinates are
therefore specified from left to right, and then from right to left.  The
corresponding Y-coordinates are all the zeros necessary to get from $-3$ to
$1.96$ (the default, qnorm(0.025)), and then the Y-coordinates of the 
density in reverse order to return to where we began.  
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
shadenormal.fnc()

## End(Not run)</code></pre>

<hr>
<h2 id='show.growth'>Plot method for growth objects.</h2><span id='topic+show.growth'></span>

<h3>Description</h3>

<p>A print method for growth objects created with <code>growth.fnc</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'growth'
show(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show.growth_+3A_x">x</code></td>
<td>
<p>A growth object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Prints growth object.  To access the data frame embedded in the
growth object, use <code>&lt;my.growth.object&gt;@data$data</code>.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  alice.growth = growth.fnc(alice, chunks= c(5000, 10000, 15000))
  alice.growth

## End(Not run)</code></pre>

<hr>
<h2 id='shrinkage'>Data set illustrating shrinkage</h2><span id='topic+shrinkage'></span>

<h3>Description</h3>

<p>Simulated data set for illustrating shrinkage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(shrinkage)</code></pre>


<h3>Format</h3>

<p>A data frame with 200 observations on the following 6 variables.
</p>

<dl>
<dt><code>intercept</code></dt><dd><p>a numeric vector for the intercept.</p>
</dd>
<dt><code>frequency</code></dt><dd><p>a numeric vector for word frequency.</p>
</dd>
<dt><code>subject</code></dt><dd><p>a factor for subjects with levels <code>S1</code>,
<code>S2</code>, ... , <code>S10</code>.</p>
</dd>
<dt><code>error</code></dt><dd><p>a numeric vector for residuals.</p>
</dd>
<dt><code>ranef</code></dt><dd><p>a numeric vector for random effect.</p>
</dd>
<dt><code>RT</code></dt><dd><p>a numeric vector for simulated RTs.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(shrinkage)

require(lme4)
require(lmerTest)
require(optimx)

shrinkage.lmer = lmer(RT ~ frequency + (1|subject), 
  data = shrinkage,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb"))
shrinkage.lmList = lmList(RT ~ frequency | subject, data = shrinkage)

# and visualize the difference between random regression 
# and mixed-effects regression

mixed = coef(shrinkage.lmer)[[1]]
random = coef(shrinkage.lmList)
subj = unique(shrinkage[,c("subject", "ranef")])
subj = subj[order(subj$subject),]
subj$random = random[,1]
subj$mixed = mixed[,1]
subj = subj[order(subj$random),]
subj$rank = 1:nrow(subj)

par(mfrow=c(1,2))
plot(subj$rank, subj$random, xlab="rank", ylab="RT", ylim=c(200,550), type="n")
text(subj$rank, subj$random, as.character(subj$subject), cex=0.8, col="red")
mtext("random regression", 3, 1)
points(subj$rank, 400+subj$ranef, col="blue")
abline(h=400)
plot(subj$rank, subj$mixed, xlab="rank", ylab="RT", ylim=c(200,550), type="n")
text(subj$rank, subj$mixed, as.character(subj$subject), cex=0.8, col = "red")
mtext("mixed-effects regression", 3, 1)
points(subj$rank, 400+subj$ranef, col="blue")
abline(h=400)
par(mfrow=c(1,1))

## End(Not run)</code></pre>

<hr>
<h2 id='simulateLatinsquare.fnc'>Simulate simple Latin Square data and compare models</h2><span id='topic+simulateLatinsquare.fnc'></span>

<h3>Description</h3>

<p>This function creates a user-specified number of simulated  
datasets with a Latin Square design, and compares mixed-effects 
models with the by-subject anova.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateLatinsquare.fnc(dat, with = TRUE, trial = 0, nruns = 100, 
   nsub = NA, nitem = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateLatinsquare.fnc_+3A_dat">dat</code></td>
<td>
<p>A data frame with the structure of the data set <code>latinsquare</code>.</p>
</td></tr>
<tr><td><code id="simulateLatinsquare.fnc_+3A_with">with</code></td>
<td>
<p>Logical, if TRUE, effect of SOA built into the data.</p>
</td></tr>
<tr><td><code id="simulateLatinsquare.fnc_+3A_trial">trial</code></td>
<td>
<p>A number which, if nonzero, gives the magnitude of a
learning or a fatigue effect.</p>
</td></tr>
<tr><td><code id="simulateLatinsquare.fnc_+3A_nruns">nruns</code></td>
<td>
<p>A number indicating the required number of simulation runs.</p>
</td></tr>
<tr><td><code id="simulateLatinsquare.fnc_+3A_nsub">nsub</code></td>
<td>
<p>A number for the number of subjects.</p>
</td></tr>
<tr><td><code id="simulateLatinsquare.fnc_+3A_nitem">nitem</code></td>
<td>
<p>A number for the number of items.</p>
</td></tr>
<tr><td><code id="simulateLatinsquare.fnc_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>alpha05</code></td>
<td>
<p>Description of 'comp1'</p>
</td></tr>
<tr><td><code>alpha01</code></td>
<td>
<p>proportion of runs in which predictors are significant at the
05 significance level.</p>
</td></tr>
<tr><td><code>res</code></td>
<td>
<p>Data frame with simulation results.</p>
</td></tr>
<tr><td><code>with</code></td>
<td>
<p>Logical, TRUE if SOA effect is built into the simulations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(latinsquare)
	\dontrun{
	library(lme4)
  simulateLatinsquare.fnc(latinsquare, nruns=100)
	}

## End(Not run)</code></pre>

<hr>
<h2 id='simulateQuasif.fnc'>Simulate data for quasi-F analysis and compare models</h2><span id='topic+simulateQuasif.fnc'></span>

<h3>Description</h3>

<p>This function creates a user-specified number of simulated  
datasets, and compares mixed-effects models with quasi-F and 
F1 and F2 analyses.  It should be run with the version of R
and the version of languageR used by Baayen, Davidson &amp; Bates
(2008, JML), as mcmcsamp no longer supports models with
random correlation parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateQuasif.fnc(dat, with = TRUE, nruns = 100, nsub = NA, nitem = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateQuasif.fnc_+3A_dat">dat</code></td>
<td>
<p>Data frame with a data set with as variables Subject, Item and
SOA, as in the <code>quasif</code> data set.</p>
</td></tr>
<tr><td><code id="simulateQuasif.fnc_+3A_with">with</code></td>
<td>
<p>Logical, if TRUE, an effect of SOA is built into the simulation.</p>
</td></tr>
<tr><td><code id="simulateQuasif.fnc_+3A_nruns">nruns</code></td>
<td>
<p>Integer for the number of simulation runs.</p>
</td></tr>
<tr><td><code id="simulateQuasif.fnc_+3A_nsub">nsub</code></td>
<td>
<p>Integer denoting the number of subjects.</p>
</td></tr>
<tr><td><code id="simulateQuasif.fnc_+3A_nitem">nitem</code></td>
<td>
<p>Integer denoting the number of items.</p>
</td></tr>
<tr><td><code id="simulateQuasif.fnc_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Model parameters are estimated from the input data set.
</p>
<p>For each completed simulation run, a dot is added to the R console.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>alpha05</code></td>
<td>
<p>Description of 'comp1'</p>
</td></tr>
<tr><td><code>alpha01</code></td>
<td>
<p>proportion of runs in which predictors are significant at the
05 significance level.</p>
</td></tr>
<tr><td><code>res</code></td>
<td>
<p>Data frame with simulation results.</p>
</td></tr>
<tr><td><code>with</code></td>
<td>
<p>Logical, TRUE if SOA effect is built into the simulations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+subjects.quasif.fnc">subjects.quasif.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(quasif)
library(lme4)

quasif.sim = simulateQuasif.fnc(quasif, nruns = 1000, with = TRUE) 
quasif.sim$alpha05

## End(Not run)</code></pre>

<hr>
<h2 id='simulateRegression.fnc'>Simulate regression data and compare models</h2><span id='topic+simulateRegression.fnc'></span>

<h3>Description</h3>

<p>This function creates a user-specified number of simulated regression 
datasets, and compares mixed-effects regression with random regression,
by-subject regression, by-item regression, and by-subject plus by-item
regression.  Optionally, an effect of learning or fatigue can be
incorporated.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulateRegression.fnc(beta = c(400, 2, 6, 4), nitem = 20, nsubj = 10, 
stdevItem = 40, stdevSubj = 80, stdevError = 50, nruns = 100, learn = FALSE, 
learnRate = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulateRegression.fnc_+3A_beta">beta</code></td>
<td>
<p>A numeric vector with beta weights for the intercept and three
numeric predictors.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_nitem">nitem</code></td>
<td>
<p>A number specifying the number of items.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_nsubj">nsubj</code></td>
<td>
<p>A number specifying the number of subjects.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_stdevitem">stdevItem</code></td>
<td>
<p>A number specifying the standard deviation of the
Item random effect.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_stdevsubj">stdevSubj</code></td>
<td>
<p> A number specifying the standard deviation of the
Subject random effect.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_stdeverror">stdevError</code></td>
<td>
<p>A number specifying the standard deviation of the
Residual Error.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_nruns">nruns</code></td>
<td>
<p>A number specifying the required number of simulated datasets.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_learn">learn</code></td>
<td>
<p>A logical that if TRUE, allows an effect of learning or
fatigue into the model.</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_learnrate">learnRate</code></td>
<td>
<p>A number specifying the learning rate (if negative) or
the effect of fatigue (if positive).</p>
</td></tr>
<tr><td><code id="simulateRegression.fnc_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>alpha05</code></td>
<td>
<p>proportion of runs in which predictors are significant at the
05 significance level.</p>
</td></tr>
<tr><td><code>alpha01</code></td>
<td>
<p>proportion of runs in which predictors are significant at the
01 significance level.</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>mean estimated random effects.</p>
</td></tr>
</table>
<p>As this may take some time, the index of each completed run is shown
on the output device.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+make.reg.fnc">make.reg.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
	library(lme4)
  simulateRegression.fnc(beta = c(400, 2, 6, 4), nruns = 5)

  \dontrun{simulateRegression.fnc(beta = c(400, 2, 6, 0), nruns = 1000, learn = TRUE)}

## End(Not run)</code></pre>

<hr>
<h2 id='sizeRatings'>Size ratings for 81 English concrete nouns</h2><span id='topic+sizeRatings'></span>

<h3>Description</h3>

<p>Subjective estimates of the size of the referents of 81 English 
concrete nouns, collected from 38 subjects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sizeRatings)</code></pre>


<h3>Format</h3>

<p>A data frame with 3078 observations on the following 7 variables.
</p>

<dl>
<dt><code>Rating</code></dt><dd><p>a numeric vector with subjective estimates of the
size of the word's referent.</p>
</dd>
<dt><code>Subject</code></dt><dd><p>a factor with subjects as levels.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd> 
<dt><code>Class</code></dt><dd><p>a factor with levels <code>animal</code> and <code>plant</code>.</p>
</dd>
<dt><code>Naive</code></dt><dd><p>a factor with levels <code>naive</code> and <code>notNaive</code>,
coding whether the subject new about the purpose of the experiment.</p>
</dd>
<dt><code>Language</code></dt><dd><p>a factor with levels <code>English</code> and <code>notEnglish</code> coding whether the subject was a native speaker of English.</p>
</dd>
<dt><code>MeanFamiliarity</code></dt><dd><p>a numeric vector for the by-item mean
familiarity ratings.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data collected with Jen Hay, University of Canterbury, Christchurch,
New Zealand, 2004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(sizeRatings)
require(lme4)
require(lmerTest)
require(optimx)
sizeRatings.lmer = lmer(Rating ~ Class * Naive + 
  MeanFamiliarity * Language + (1|Subject) + (1|Word), 
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = sizeRatings)
summary(sizeRatings.lmer)

## End(Not run)</code></pre>

<hr>
<h2 id='spanish'>Relative frequencies of tag trigrams is selected Spanish texts</h2><span id='topic+spanish'></span>

<h3>Description</h3>

<p>Relative frequencies of the 120 most frequent tag trigrams in 15 texts
contributed by 3 authors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spanish)</code></pre>


<h3>Format</h3>

<p>A data frame with 120 observations on 15 variables documented in
<code>spanishMeta</code>.
</p>


<h3>References</h3>

<p>Spassova, M. S. (2006) <em>Las marcas sintacticas de atribucion forense de
autoria de textos escritos en espanol</em>, Masters thesis, Institut Universitari
de Linguistica Aplicada, Universitat Pompeu Fabra, Barcelona. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(spanish)
data(spanishMeta)

# principal components analysis

spanish.t = t(spanish)
spanish.pca = prcomp(spanish.t, center = TRUE, scale = TRUE)
spanish.x = data.frame(spanish.pca$x)
spanish.x = spanish.x[order(rownames(spanish.x)), ]

library(lattice)
splom(~spanish.x[ , 1:3], groups = spanishMeta$Author)

# linear discriminant analysis

library(MASS)
spanish.pca.lda = lda(spanish.x[ , 1:8], spanishMeta$Author)
plot(spanish.pca.lda)

# cross-validation

n = 8
spanish.t = spanish.t[order(rownames(spanish.t)), ]
predictedClasses = rep("", 15)
for (i in 1:15) {
  training = spanish.t[-i,]                     
  trainingAuthor = spanishMeta[-i,]$Author
  training.pca = prcomp(training, center=TRUE, scale=TRUE)
  training.x = data.frame(training.pca$x)
  training.x = training.x[order(rownames(training.x)), ]
  training.pca.lda = lda(training[ , 1:n], trainingAuthor)
  predictedClasses[i] = 
  as.character(predict(training.pca.lda, spanish.t[ , 1:n])$class[i])  
}

ncorrect = sum(predictedClasses==as.character(spanishMeta$Author))
ncorrect
sum(dbinom(ncorrect:15, 15, 1/3))

## End(Not run)</code></pre>

<hr>
<h2 id='spanishFunctionWords'>Relative frequencies of function words in selected Spanish texts</h2><span id='topic+spanishFunctionWords'></span>

<h3>Description</h3>

<p>Relative frequencies of the 120 most frequent function words in 15 texts
contributed by 3 authors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spanishFunctionWords)</code></pre>


<h3>Format</h3>

<p>A data frame with 120 observations on 15 variables documented in
<code>spanishMeta</code>.
</p>


<h3>References</h3>

<p>Spassova, M. S. (2006) <em>Las marcas sintacticas de atribucion forense de
autoria de textos escritos en espanol</em>, Masters thesis, Institut Universitari
de Linguistica Aplicada, Universitat Pompeu Fabra, Barcelona. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(spanishFunctionWords)
data(spanishMeta)

# principal components analysis

spanishFunctionWords.t = t(spanishFunctionWords)
spanishFunctionWords.t = 
  spanishFunctionWords.t[order(rownames(spanishFunctionWords.t)), ]
spanishFunctionWords.pca = 
  prcomp(spanishFunctionWords.t, center = TRUE, scale = TRUE)

sdevs = spanishFunctionWords.pca$sdev^2
n = sum(sdevs/sum(sdevs)&gt; 0.05) 

# linear discriminant analysis with cross-validation

library(MASS)

predictedClasses = rep("", 15)
for (i in 1:15) {
  training = spanishFunctionWords.t[-i,]                   
  trainingAuthor = spanishMeta[-i,]$Author
  training.pca = prcomp(training, center = TRUE, scale = TRUE)
  training.x = data.frame(training.pca$x)
  training.x = training.x[order(rownames(training.x)), ]
  training.pca.lda = lda(training[ , 1:n], trainingAuthor)
  cl = predict(training.pca.lda, spanishFunctionWords.t[,1:n])$class[i]
  predictedClasses[i] = as.character(cl)
}

ncorrect = sum(predictedClasses==spanishMeta$Author)
sum(dbinom(ncorrect:15, 15, 1/3))

## End(Not run)</code></pre>

<hr>
<h2 id='spanishMeta'>Metadata for the spanish and spanishFunctionWords data sets</h2><span id='topic+spanishMeta'></span>

<h3>Description</h3>

<p>By-text metadata for the spanish and spanishFunctionWords data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(spanishMeta)</code></pre>


<h3>Format</h3>

<p>A data frame with 15 observations on the following 6 variables.
</p>

<dl>
<dt><code>Author</code></dt><dd><p>a factor with levels <code>C</code>, <code>M</code>, and <code>V</code>.</p>
</dd>
<dt><code>YearOfBirth</code></dt><dd><p>a numeric vector with year of birth of the author.</p>
</dd>
<dt><code>TextName</code></dt><dd><p>a factor with codes for the texts as levels (
<code>X14458gll</code> ... <code>X14476gll</code>).</p>
</dd>
<dt><code>PubDate</code></dt><dd><p>a numeric vector with data of publication of the text.</p>
</dd>
<dt><code>Nwords</code></dt><dd><p>a numeric vector with text sizes in tokens.</p>
</dd>
<dt><code>FullName</code></dt><dd><p>a factor with author names: <code>Cela</code>, 
<code>Mendoza</code> and <code>VargasLLosa</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Spassova, M. S. (2006) <em>Las marcas sintacticas de atribucion forense de
autoria de textos escritos en espanol</em>, Masters thesis, Institut Universitari
de Linguistica Aplicada, Universitat Pompeu Fabra, Barcelona. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(spanishMeta)

## End(Not run)</code></pre>

<hr>
<h2 id='spectrum.fnc'>Frequency spectrum from text vector</h2><span id='topic+spectrum.fnc'></span>

<h3>Description</h3>

<p>This function creates a frequency spectrum for a 
text in character vector form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectrum.fnc(text)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spectrum.fnc_+3A_text">text</code></td>
<td>
<p>A character vector containing the words of a text.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with as column variables
</p>
<table>
<tr><td><code>frequency</code></td>
<td>
<p>Word frequencies.</p>
</td></tr>
<tr><td><code>freqOfFreq</code></td>
<td>
<p>The frequencies of the word frequencies.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>R. H. Baayen (2001) <em>Word Frequency Distributions</em>, Dordrecht: Kluwer.  
</p>


<h3>See Also</h3>

<p>See Also the <code>zipfR</code> package.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(alice)
alice.spectrum = spectrum.fnc(alice)
head(alice.spectrum)
tail(alice.spectrum)

## End(Not run)</code></pre>

<hr>
<h2 id='splitplot'>Simulated data set with split plot design</h2><span id='topic+splitplot'></span>

<h3>Description</h3>

<p>Simulated lexical decision latencies with priming as treatment and reaction
time in lexical decision as dependent variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(splitplot)</code></pre>


<h3>Format</h3>

<p>A data frame with 800 observations on the following 11 variables.
</p>

<dl>
<dt><code>items</code></dt><dd><p>A factor with levels <code>w1</code>, <code>w2</code>,
...,  <code>w40</code>, coding 40 word items.</p>
</dd>
<dt><code>ritems</code></dt><dd><p>The by-word random adjustments to the intercept.</p>
</dd>
<dt><code>list</code></dt><dd><p>A factor with levels <code>listA</code> and <code>listB</code>. 
The priming effect is counterbalanced for subjects across these 
two lists, compare <code>table(splitplot$list, splitplot$subjects)</code>.</p>
</dd>
<dt><code>rlist</code></dt><dd><p>The by-list random adjustments to the intercept.</p>
</dd>
<dt><code>priming</code></dt><dd><p>A treatment factor with levels <code>primed</code> and
<code>unprimed</code>.</p>
</dd>
<dt><code>fpriming</code></dt><dd><p>The priming effect, -30 for the primed and 0 for
the unprimed condition.</p>
</dd>
<dt><code>subjects</code></dt><dd><p>A factor with levels <code>s1</code>, <code>s2</code>, 
... <code>s20</code> coding 20 subjects.</p>
</dd>
<dt><code>rsubject</code></dt><dd><p>The by-subject random adjustments to the intercept.</p>
</dd>
<dt><code>error</code></dt><dd><p>The by-observation noise.</p>
</dd>
<dt><code>int</code></dt><dd><p>The intercept.</p>
</dd>
<dt><code>RT</code></dt><dd><p>The reaction time.</p>
</dd>
</dl>



<h3>Source</h3>

<p>R. H. Baayen, D. J. Davidson and D. M. Bates.  Mixed-effects modeling
with crossed random effects for subjects and items.  Manuscript under revision for <em>Journal of Memory and Language</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(splitplot)
table(splitplot$list, splitplot$subjects)
dat=splitplot
require(lme4)
require(optimx)
require(lmerTest)
dat.lmer1 = lmer(RT ~ list*priming+(1+priming|subjects)+(1+list|items),data=dat,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
dat.lmer2 = lmer(RT ~ list*priming+(1+priming|subjects)+(1|items),data=dat,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
dat.lmer3 = lmer(RT ~ list*priming+(1|subjects)+(1|items),data=dat,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
dat.lmer4 = lmer(RT ~ list*priming+(1|subjects),data=dat,
  control=lmerControl(optimizer="optimx",optCtrl=list(method="nlminb")))
anova(dat.lmer1, dat.lmer2, dat.lmer3, dat.lmer4)
summary(dat.lmer3)

## End(Not run)</code></pre>

<hr>
<h2 id='subjects.latinsquare.fnc'>By-subject analysis of simple Latin Square data sets</h2><span id='topic+subjects.latinsquare.fnc'></span>

<h3>Description</h3>

<p>This function is called by <code>simulateLatinsquare.fnc</code> for by-subject
analysis of simulated Latin Square datasets.  It is not intended for
independent use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subjects.latinsquare.fnc(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subjects.latinsquare.fnc_+3A_dat">dat</code></td>
<td>
<p>A data frame with variables RT or RTsim , SOA, Subject, Item,
Group and List, as in the <code>latinsquare</code> data set.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>The p-value of the by-subject anova.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The input dataset.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>The fitted model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+simulateLatinsquare.fnc">simulateLatinsquare.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(latinsquare)
subjects.latinsquare.fnc(latinsquare)$p

## End(Not run)</code></pre>

<hr>
<h2 id='subjects.quasif.fnc'>By-subject analysis of data sets requiring quasi-F ratios</h2><span id='topic+subjects.quasif.fnc'></span>

<h3>Description</h3>

<p>This function is called by <code>simulateQuasif.fnc</code> for by-subject
analysis of simulated datasets traditionally requiring quasi-F ratios.  
It is not intended for independent use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subjects.quasif.fnc(dat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subjects.quasif.fnc_+3A_dat">dat</code></td>
<td>
<p>A data frame with variables RT or RTsim , SOA, Subject and Item.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>p-value for by-subject F-test.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>Data set with aggregated subject means.</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>Anova table of fitted model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+simulateQuasif.fnc">simulateQuasif.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(quasif)
  subjects.quasif.fnc(quasif)

## End(Not run)</code></pre>

<hr>
<h2 id='summary.corres'>Summarize a correspondence object</h2><span id='topic+summary.corres'></span>

<h3>Description</h3>

<p>This function provides a concise summary of a correspondence object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'corres'
summary(object, n = 2, returnList = FALSE, head = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.corres_+3A_object">object</code></td>
<td>
<p>A correspondence object as produced by <code>corres</code>.</p>
</td></tr>
<tr><td><code id="summary.corres_+3A_n">n</code></td>
<td>
<p>A number indicating number of dimensions to be summarized. </p>
</td></tr>
<tr><td><code id="summary.corres_+3A_returnlist">returnList</code></td>
<td>
<p>Logical, if TRUE, a list is returned with as components
the full information on each factor, instead of only the first 6 lines.</p>
</td></tr>
<tr><td><code id="summary.corres_+3A_head">head</code></td>
<td>
<p>Logical, if TRUE, first 6 rows of factor summaries are shown.</p>
</td></tr>
<tr><td><code id="summary.corres_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to summaries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A summary with eigenvalue rates, and coordinates, correlations,
and contributions for the factors (by default, 2, unless n is set to 
a higher number).  
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+corres.fnc">corres.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(oldFrench)
  oldFrench.ca = corres.fnc(oldFrench)
  oldFrench.ca
  summary(oldFrench.ca)

## End(Not run)</code></pre>

<hr>
<h2 id='summary.growth'>Summary method for growth objects</h2><span id='topic+summary.growth'></span>

<h3>Description</h3>

<p>Summary method for vocabulary growth objects created with <code>growth.fnc</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'growth'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.growth_+3A_object">object</code></td>
<td>
<p>A vocabulary growth object.</p>
</td></tr>
<tr><td><code id="summary.growth_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The growth object is printed. For access to the data frame inside
the object, use <code>&lt;my.growth.object&gt;@data$data</code>.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>

<hr>
<h2 id='tail.growth'>Show last rows of growth object.</h2><span id='topic+tail.growth'></span>

<h3>Description</h3>

<p>Prints last rows of growth object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'growth'
tail(x, n = 6, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tail.growth_+3A_x">x</code></td>
<td>
<p>A growth object.</p>
</td></tr>
<tr><td><code id="tail.growth_+3A_n">n</code></td>
<td>
<p>An integer specifying the number of lines to be shown.</p>
</td></tr>
<tr><td><code id="tail.growth_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The last n rows of the growth object are printed.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  alice.growth = growth.fnc(alice)
  tail(alice.growth)

## End(Not run)</code></pre>

<hr>
<h2 id='text2spc.fnc'>Create a frequency spectrum from a text vector</h2><span id='topic+text2spc.fnc'></span>

<h3>Description</h3>

<p>This functions takes a text in the form of a character vector as input,
and outputs a frequency spectrum object as defined in the <code>zipfR</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>text2spc.fnc(text)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="text2spc.fnc_+3A_text">text</code></td>
<td>
<p>A text in the form of a character vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>spc</code> spectrum object as defined in the <code>zipfR</code> package.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See the documentation for <code>zipfR</code> for <code>spc</code> objects.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  library(zipfR)
  data(alice)
  alice.spc = text2spc.fnc(alice)
  plot(alice.spc)

## End(Not run)</code></pre>

<hr>
<h2 id='through'>Through the Looking Glass</h2><span id='topic+through'></span>

<h3>Description</h3>

<p>The text of Lewis Carroll's 'Through the Looking Glass', with 
punctuation marks removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(through)</code></pre>


<h3>Format</h3>

<p>A character vector with 29560 words.
</p>


<h3>Source</h3>

<p>The project Gutenberg at <a href="http://www.gutenberg.org/wiki/Main_Page">http://www.gutenberg.org/wiki/Main_Page</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(through)
  through[1:3]

## End(Not run)</code></pre>

<hr>
<h2 id='transforming.fnc'>transform vector according to specified function</h2><span id='topic+transforming.fnc'></span>

<h3>Description</h3>

<p>Apply function fun to input vector y
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transforming.fnc(y, fun)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transforming.fnc_+3A_y">y</code></td>
<td>
<p> numerical vector (for dependent variable)</p>
</td></tr>
<tr><td><code id="transforming.fnc_+3A_fun">fun</code></td>
<td>
<p>a function, or NA (in which case no transformation is applied</p>
</td></tr>
</table>


<h3>Details</h3>

<p>exists only to make code more readable
</p>


<h3>Value</h3>

<p>a numerical vector
</p>


<h3>Note</h3>

 
<p>not intended for independent use
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plotLMER.fnc">plotLMER.fnc</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run: not intended for independent use
</code></pre>

<hr>
<h2 id='twente'>Frequency spectrum for the Twente News Corpus</h2><span id='topic+twente'></span>

<h3>Description</h3>

<p>Frequency (m) and frequency of frequency (Vm) for string types
in the Twente News Corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(twente)</code></pre>


<h3>Format</h3>

<p>A data frame with 4639 observations on the following 2 variables.
</p>

<dl>
<dt><code>m</code></dt><dd><p>a numeric vector with word frequencies.</p>
</dd>
<dt><code>Vm</code></dt><dd><p>a numeric vector with the frequencies of word frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Twente News Corpus.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(twente)
library(zipfR)
twente.spc = spc(m=twente$m, Vm = twente$Vm)
plot(twente.spc)

## End(Not run)</code></pre>

<hr>
<h2 id='variationLijk'>Variation in spoken Dutch in the use of the suffix -lijk</h2><span id='topic+variationLijk'></span>

<h3>Description</h3>

<p>This dataset documents variation in the use of the suffix <em>-lijk</em>, as
realized in 32 words, in spoken Dutch across region (Flanders versus The
Netherlands), sex (females versus males) and education (high versus mid).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(variationLijk)</code></pre>


<h3>Format</h3>

<p>A data frame with 32 observations on the following 8 variables.
</p>

<dl>
<dt><code>nlfemaleHigh</code></dt><dd><p>a numeric vector with counts for Dutch 
females with a mid education level.</p>
</dd>
<dt><code>nlfemaleMid</code></dt><dd><p>a numeric vector counts for Dutch 
females with a high education level.</p>
</dd>
<dt><code>nlmaleHigh</code></dt><dd><p>a numeric vector counts for Dutch 
males with a high education level.</p>
</dd>
<dt><code>nlmaleMid</code></dt><dd><p>a numeric vector counts for Dutch 
males with a mid education level.</p>
</dd>
<dt><code>vlfemaleHigh</code></dt><dd><p>a numeric vector counts for Flemish 
females with a high education level.</p>
</dd>
<dt><code>vlfemaleMid</code></dt><dd><p>a numeric vector counts for Flemish 
females with a mid education level.</p>
</dd>
<dt><code>vlmaleHigh</code></dt><dd><p>a numeric vector counts for Flemish 
males with a high education level.</p>
</dd>
<dt><code>vlmaleMid</code></dt><dd><p>a numeric vector counts for Flemish 
males with a mid education level.</p>
</dd>
</dl>



<h3>References</h3>

<p>Keune, K., Ernestus, M., Van Hout, R. and Baayen, R.H. (2005) Social,
geographical, and register variation in Dutch: From written 'mogelijk' to
spoken 'mok', <em>Corpus Linguistics and Linguistic Theory</em>, 1, 183-223.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(variationLijk)
variationLijk.ca = corres.fnc(variationLijk)
plot(variationLijk.ca, rcex=0.7, ccol="black",
  rcol = rep("blue", nrow(variationLijk))) 

## End(Not run)</code></pre>

<hr>
<h2 id='ver'>The Dutch prefix ver-: semantic transparency and frequency</h2><span id='topic+ver'></span>

<h3>Description</h3>

<p>Semantic transparency (dichotomous) and frequency for 985 words
with the Dutch prefix <em>ver-</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ver)</code></pre>


<h3>Format</h3>

<p>A data frame with 985 observations on the following 2 variables.
</p>

<dl>
<dt><code>Frequency</code></dt><dd><p>a numeric vector for the words' frequency.</p>
</dd>
<dt><code>SemanticClass</code></dt><dd><p>a factor with levels <code>opaque</code> and
<code>transparent</code> coding semantic transparency.</p>
</dd>
</dl>



<h3>References</h3>

<p>Baayen, R. H. and Lieber, R. (1997) Word Frequency Distributions and Lexical
Semantics, <em>Computers and the Humanities</em>, 30, 281-291.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(ver)
ver$Frequency = log(ver$Frequency)

plot(density(ver$Frequency))

# plot separate densities for opaque and transparent words

ver.transp = ver[ver$SemanticClass == "transparent",]$Frequency
ver.opaque = ver[ver$SemanticClass == "opaque", ]$Frequency

ver.transp.d = density(ver.transp)
ver.opaque.d = density(ver.opaque)
xlimit = range(ver.transp.d$x, ver.opaque.d$x)
ylimit = range(ver.transp.d$y, ver.opaque.d$y)
plot(ver.transp.d, lty = 1, col = "black", 
  xlab = "frequency", ylab = "density", 
  xlim = xlimit, ylim = ylimit, main = "")
lines(ver.opaque.d, col = "darkgrey")
legend(6,0.25, lty=rep(1,2), col=c("black", "darkgrey"), 
legend=c("transparent", "opaque"))

# test whether the difference is significant

ks.test(jitter(ver.transp), jitter(ver.opaque))

## End(Not run)</code></pre>

<hr>
<h2 id='verbs'>Dative Alternation - simplified data set</h2><span id='topic+verbs'></span>

<h3>Description</h3>

<p>A simplified version of the <code>dative</code> data set, used
for expository purposes only.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(verbs)</code></pre>


<h3>Format</h3>

<p>A data frame with 903 observations on the following 5 variables.
</p>

<dl>
<dt><code>RealizationOfRec</code></dt><dd><p>a factor with levels <code>NP</code> 
and <code>PP</code>.</p>
</dd>
<dt><code>Verb</code></dt><dd><p>a factor with the verbs as levels.</p>
</dd> 
<dt><code>AnimacyOfRec</code></dt><dd><p>a factor with levels <code>animate</code> and
<code>inanimate</code>.</p>
</dd>
<dt><code>AnimacyOfTheme</code></dt><dd><p>a factor with levels <code>animate</code> and
<code>inanimate</code>.</p>
</dd>
<dt><code>LengthOfTheme</code></dt><dd><p>a numeric vector coding the length in words
of the theme.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bresnan, J., Cueni, A., Nikitina, T. and Baayen, R. H. (2007) Predicting the
dative alternation, in Bouma, G. and Kraemer, I. and Zwarts, J.  (eds.),
<em>Cognitive Foundations of Interpretation</em>, Royal Netherlands Academy
of Sciences, 33 pages, in press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(verbs)
head(verbs)
xtabs( ~ RealizationOfRec + AnimacyOfRec, data = verbs)
barplot(xtabs( ~ RealizationOfRec + AnimacyOfRec, data = verbs),beside=TRUE)
</code></pre>

<hr>
<h2 id='warlpiri'>Ergative case marking in Warlpiri</h2><span id='topic+warlpiri'></span>

<h3>Description</h3>

<p>This data set documents the use of ergative case marking in the narratives
of native speakers of Lajamanu Warlpiri (8 children, 13 adults) 
describing events in picture books.  
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(warlpiri)</code></pre>


<h3>Format</h3>

<p>A data frame with 347 observations on the following 9 variables.
</p>

<dl>
<dt><code>Speaker</code></dt><dd><p>a factor with speakers as levels.</p>
</dd> 
<dt><code>Sentence</code></dt><dd><p>a factor with sentence as levels.</p>
</dd> 
<dt><code>AgeGroup</code></dt><dd><p>a factor with levels <code>adult</code> and <code>child</code>.</p>
</dd>
<dt><code>CaseMarking</code></dt><dd><p>a factor with levels <code>ergative</code> and
<code>other</code>.</p>
</dd>
<dt><code>WordOrder</code></dt><dd><p>a factor with levels <code>subInitial</code> (subject
initial) and <code>subNotInitial</code> (subject not initial).</p>
</dd>
<dt><code>AnimacyOfSubject</code></dt><dd><p>a factor with levels <code>animate</code> 
and <code>inanimate</code>.</p>
</dd>
<dt><code>OvertnessOfObject</code></dt><dd><p>a factor with levels <code>notOvert</code> 
and <code>overt</code>.</p>
</dd>
<dt><code>AnimacyOfObject</code></dt><dd><p>a factor with levels <code>animate</code> 
and <code>inanimate</code>.</p>
</dd>
<dt><code>Text</code></dt><dd><p>a factor with levels <code>texta</code>, 
<code>textb</code> and <code>textc</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>O'Shannessy, C. (2006) <em>Language contact and child bilingual acquisition:
Learning a mixed language and Warlpiri in northern Australia</em>, PhD Thesis,
University of Sydney, Australia.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(warlpiri)
require(lme4)
require(lmerTest)
require(optimx)
warlpiri.lmer = glmer(CaseMarking ~ WordOrder * AgeGroup + 
  AnimacyOfSubject + (1|Text) + (1|Speaker), 
  control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  family = "binomial", data = warlpiri)
summary(warlpiri.lmer)

## End(Not run)</code></pre>

<hr>
<h2 id='weightRatings'>Subjective estimates of the weight of the referents of 81 English nouns</h2><span id='topic+weightRatings'></span>

<h3>Description</h3>

<p>Subjective estimates on a seven-point scale of the weight of the
referents of 81 English nouns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(weightRatings)</code></pre>


<h3>Format</h3>

<p>A data frame with 1620 observations on the following 7 variables.
</p>

<dl>
<dt><code>Subject</code></dt><dd><p>a factor with subjects as levels.</p>
</dd> 
<dt><code>Rating</code></dt><dd><p>a numeric vector.</p>
</dd>
<dt><code>Trial</code></dt><dd><p>a numeric vector with the weight ratings.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>a factor with levels <code>F</code> and <code>M</code>.</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with words as levels.</p>
</dd> 
<dt><code>Frequency</code></dt><dd><p>a numeric vector with log-transformed
lemma frequencies as available in the CELEX lexical database.</p>
</dd>
<dt><code>Class</code></dt><dd><p>a factor with levels <code>animal</code> and <code>plant</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Data collected with Jen Hay, University of Canterbury, Christchurch,
New Zealand, 2004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(weightRatings)
xylowess.fnc(Rating ~ Frequency | Subject, data = weightRatings, 
  xlab = "log Frequency", ylab = "Weight Rating")

## End(Not run)</code></pre>

<hr>
<h2 id='writtenVariationLijk'>Variation in written Dutch in the use of the suffix -lijk</h2><span id='topic+writtenVariationLijk'></span>

<h3>Description</h3>

<p>This dataset documents variation in the use of the 80 most frequent
words ending in the suffix <em>-lijk</em> in written Dutch.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(writtenVariationLijk)</code></pre>


<h3>Format</h3>

<p>A data frame with 560 observations on the following 5 variables.
</p>

<dl>
<dt><code>Corpus</code></dt><dd><p>a factor with as levels the sampled newspapers: 
<code>belang</code> (Het Belang van Limburg), 
<code>gazet</code> (De Gazet van Antwerpen),
<code>laatnieu</code> (Het Laatste Nieuws),
<code>limburg</code> (De Limburger),
<code>nrc</code> (NRC Handelsblad),
<code>stand</code> (De Standaard), and
<code>tele</code> (De Telegraaf).</p>
</dd>
<dt><code>Word</code></dt><dd><p>a factor with the 80 most frequent words ending in
<em>-lijk</em>.</p>
</dd>
<dt><code>Count</code></dt><dd><p>a numeric vector with token counts in the CONDIV
corpus.</p>
</dd>
<dt><code>Country</code></dt><dd><p>a factor with levels <code>Flanders</code> and 
<code>Netherlands</code>.</p>
</dd>
<dt><code>Register</code></dt><dd><p>a factor with levels <code>National</code>, 
<code>Quality</code> and <code>Regional</code> coding the type of newspaper.</p>
</dd>
</dl>



<h3>References</h3>

<p>Keune, K., Ernestus, M., Van Hout, R. and Baayen, R.H. (2005) Social,
geographical, and register variation in Dutch: From written 'mogelijk' to
spoken 'mok', <em>Corpus Linguistics and Linguistic Theory</em>, 1, 183-223.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(writtenVariationLijk)

require(lme4)
require(lmerTest)
require(lme4)

writtenVariationLijk.lmer = glmer(Count ~ Country * Register + (1|Word), 
  control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = writtenVariationLijk, family = "poisson")

writtenVariationLijk.lmerA = glmer(Count ~ Country * Register + (Country|Word), 
  control=glmerControl(optimizer="optimx",optCtrl=list(method="nlminb")),
  data = writtenVariationLijk, family = "poisson")

anova(writtenVariationLijk.lmer, writtenVariationLijk.lmerA)

summary(writtenVariationLijk.lmerA)

## End(Not run)</code></pre>

<hr>
<h2 id='xylowess.fnc'>Trellis scatterplot with smoothers</h2><span id='topic+xylowess.fnc'></span>

<h3>Description</h3>

<p>Convenience function for trellis scatterplots with smoothers added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>xylowess.fnc(fmla, data, 
  span = 2/3, symbolcolor = "darkgrey", 
  linecolor = "blue", xlabel = "", ylabel = "", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xylowess.fnc_+3A_fmla">fmla</code></td>
<td>
<p>A formula.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_data">data</code></td>
<td>
<p>A dataframe.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_span">span</code></td>
<td>
<p>Span for the smoother.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_symbolcolor">symbolcolor</code></td>
<td>
<p>Color for plot symbols.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_linecolor">linecolor</code></td>
<td>
<p>Color for smoother.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_xlabel">xlabel</code></td>
<td>
<p>Label for horizontal axis.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_ylabel">ylabel</code></td>
<td>
<p>Label for vertical axis.</p>
</td></tr>
<tr><td><code id="xylowess.fnc_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A trellis scatterplot matrix with smoothers is shown on the graphics device.
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>See Also</h3>

<p>See also <code><a href="lattice.html#topic+xyplot">xyplot</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(weightRatings)
  xylowess.fnc(Rating ~ Frequency | Subject, data = weightRatings,
    xlab = "log Frequency", ylab = "Weight Rating")

## End(Not run)</code></pre>

<hr>
<h2 id='yule.fnc'>Yule's characteristic constant K</h2><span id='topic+yule.fnc'></span>

<h3>Description</h3>

<p>This function calculates Yule's characteristic constant K given a
frequency spectrum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>yule.fnc(spect)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="yule.fnc_+3A_spect">spect</code></td>
<td>
<p>A frequency spectrum as generated by <code>spectrum.fnc</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Yule's characteristic constant K
</p>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>Yule, G. U. (1944) <em>The Statistical Study of Literary Vocabulary</em>,
Cambridge: Cambridge University Press.
</p>
<p>Baayen, R. H. (2001) <em>Word Frequency Distributions</em>, Dordrecht: Kluwer.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+spectrum.fnc">spectrum.fnc</a></code> and <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(alice)
  yule.fnc(spectrum.fnc(alice))

## End(Not run)</code></pre>

<hr>
<h2 id='zipf.fnc'>Zipf's rank frequency distribution</h2><span id='topic+zipf.fnc'></span>

<h3>Description</h3>

<p>This function calculates Zipf's rank-frequency distribution for a text
vector, and optionally produces the rank-frequency plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zipf.fnc(text, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zipf.fnc_+3A_text">text</code></td>
<td>
<p>A character vector containing a text.</p>
</td></tr>
<tr><td><code id="zipf.fnc_+3A_plot">plot</code></td>
<td>
<p>Logical, if TRUE, a rank-frequency plot is shown on the
graphics device.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with variables
</p>
<table>
<tr><td><code>frequency</code></td>
<td>
<p>Word Frequencies, ordered from large to small.</p>
</td></tr>
<tr><td><code>freqOfFreq</code></td>
<td>
<p>Frequencies of word frequencies.</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
<p>Zipf rank.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>R. H. Baayen</p>


<h3>References</h3>

<p>Zipf, G. K. (1935) <em>The Psycho-Biology of Language</em>,
Boston: Houghton Mifflin.
</p>
<p>Zipf, G. K. (1949) <em>Human Behavior and the Principle of the Least Effort.
An Introduction to Human Ecology</em>, New York: Hafner.
</p>
<p>Baayen, R. H. (2001) <em>Word Frequency Distributions</em>, Dordrecht: Kluwer.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+growth.fnc">growth.fnc</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(alice)
alice.zipf = zipf.fnc(alice, plot = TRUE) 
head(alice.zipf)

## End(Not run)</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
