<!DOCTYPE html><html lang="en"><head><title>Help for package ShinyItemAnalysis</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ShinyItemAnalysis}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ShinyItemAnalysis-package'><p>ShinyItemAnalysis: Test and Item Analysis via Shiny</p></a></li>
<li><a href='#AIBS'><p>AIBS grant peer review scoring dataset</p></a></li>
<li><a href='#Anxiety'><p>PROMIS Anxiety Scale Dataset</p></a></li>
<li><a href='#AttitudesExpulsion'><p>Attitudes towards the Expulsion of the Sudeten Germans (dataset)</p></a></li>
<li><a href='#BFI2'><p>BFI2 Dataset</p></a></li>
<li><a href='#blis2blirt'><p>Reparametrize fitted BLIS model to IRT</p></a></li>
<li><a href='#BlisClass-class'><p>BLIS S4 class</p></a></li>
<li><a href='#CLoSEread6'><p>Czech Longitudinal Study in Education (CLoSE) - reading in 6th grade</p></a></li>
<li><a href='#coef+2CBlisClass-method'><p>Get Coefficients from a fitted BLIS model</p></a></li>
<li><a href='#cronbach_alpha'><p>Compute Cronbach alpha with confidence interval</p></a></li>
<li><a href='#CZmatura'><p>CZmatura dataset</p></a></li>
<li><a href='#CZmaturaS'><p>CZmatura dataset - sample</p></a></li>
<li><a href='#dataMedical'><p>Dichotomous dataset of admission test to medical school</p></a></li>
<li><a href='#dataMedicalgraded'><p>Graded dataset of admission test to medical school</p></a></li>
<li><a href='#dataMedicalkey'><p>Key of correct answers for dataset of admission test to medical school</p></a></li>
<li><a href='#dataMedicaltest'><p>Dataset of admission test to medical school</p></a></li>
<li><a href='#DDplot'><p>Plot difficulties and discriminations/item validity</p></a></li>
<li><a href='#delta_ses'><p>Get standard errors using delta method approximation</p></a></li>
<li><a href='#DistractorAnalysis'><p>Distractor analysis</p></a></li>
<li><a href='#EPIA'><p>The Eysenck Personality Inventory Impulsivity Subscale</p></a></li>
<li><a href='#fa_parallel'><p>Conduct Parallel Analysis</p></a></li>
<li><a href='#fit_blis'><p>Fit Baseline-category Logit Intercept-Slope (BLIS) model on nominal data</p></a></li>
<li><a href='#gDiscrim'><p>Compute generalized item discrimination</p></a></li>
<li><a href='#get_orig_levels'><p>Get Original Levels from a Fitted BLIS model</p></a></li>
<li><a href='#ggWrightMap'><p>Plot person-item map (Wright map) using <code>ggplot2</code></p></a></li>
<li><a href='#GMAT'><p>Dichotomous dataset based on GMAT with the same total score distribution for groups.</p></a></li>
<li><a href='#HCI'><p>Homeostasis Concept Inventory dichotomous dataset</p></a></li>
<li><a href='#HCIdata'><p>Homeostasis concept inventory full dataset</p></a></li>
<li><a href='#HCIgrads'><p>Homeostasis concept inventory dataset of graduate students</p></a></li>
<li><a href='#HCIkey'><p>Key of correct answers for homeostasis concept inventory dataset</p></a></li>
<li><a href='#HCIlong'><p>Homeostasis Concept Inventory in a long format</p></a></li>
<li><a href='#HCIprepost'><p>Homeostasis concept inventory pretest and posttest scores</p></a></li>
<li><a href='#HCItest'><p>Homeostasis concept inventory multiple-choice dataset</p></a></li>
<li><a href='#HCItestretest'><p>Homeostasis concept inventory test-retest dataset</p></a></li>
<li><a href='#HeightInventory'><p>Height inventory dataset</p></a></li>
<li><a href='#ICCrestricted'><p>Range-restricted reliability with intra-class correlation</p></a></li>
<li><a href='#ItemAnalysis'><p>Compute traditional item analysis indices</p></a></li>
<li><a href='#LearningToLearn'><p>Dichotomous dataset of learning to learn test</p></a></li>
<li><a href='#MSATB'><p>Dichotomous dataset of Medical School Admission Test in Biology.</p></a></li>
<li><a href='#MSclinical'><p>Clinical outcomes in multiple sclerosis patients dataset</p></a></li>
<li><a href='#NIH'><p>NIH grant peer review scoring dataset</p></a></li>
<li><a href='#nominal_to_int'><p>Turn nominal (factor) data to integers, keep original levels with a key of</p>
correct responses alongside</a></li>
<li><a href='#obtain_nrm_def'><p>Obtain model definition for <code>mirt</code>'s nominal model taking in account the key</p>
of correct answers</a></li>
<li><a href='#plot_corr'><p>Compute and plot an item correlation matrix</p></a></li>
<li><a href='#plot.sia_parallel'><p>Plot Method for Parallel Analysis Output</p></a></li>
<li><a href='#plotAdjacent'><p>Plot category probabilities of adjacent category logit model</p></a></li>
<li><a href='#plotCumulative'><p>Plot cumulative and category probabilities of cumulative logit model</p></a></li>
<li><a href='#plotDIFirt'><p>Plot item characteristic curve of DIF IRT model</p></a></li>
<li><a href='#plotDIFLogistic'><p>Function for characteristic curve of 2PL logistic DIF model</p></a></li>
<li><a href='#plotDistractorAnalysis'><p>Plot item distractor analysis</p></a></li>
<li><a href='#plotMultinomial'><p>Plot category probabilities of multinomial model</p></a></li>
<li><a href='#print.blis_coefs'><p>Print method for BLIS coefficients</p></a></li>
<li><a href='#recode_nr'><p>Recognize and recode not-reached responses</p></a></li>
<li><a href='#remove_empty_cols'><p>Remove columns that are empty</p></a></li>
<li><a href='#ShinyItemAnalysis_options'><p>Options consulted by ShinyItemAnalysis</p></a></li>
<li><a href='#startShinyItemAnalysis'><p>Start ShinyItemAnalysis application</p></a></li>
<li><a href='#TestAnxietyCor'><p>Correlation matrix for the test anxiety dataset</p></a></li>
<li><a href='#theme_app'><p>Complete theme for <code>ShinyItemAnalysis</code> graphics</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Test and Item Analysis via Shiny</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-07</td>
</tr>
<tr>
<td>Description:</td>
<td>Package including functions and interactive shiny application
    for the psychometric analysis of educational tests, psychological
    assessments, health-related and other types of multi-item
    measurements, or ratings from multiple raters.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://www.ShinyItemAnalysis.org">https://www.ShinyItemAnalysis.org</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/patriciamar/ShinyItemAnalysis/issues">https://github.com/patriciamar/ShinyItemAnalysis/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>difR (&ge; 5.0), dplyr, ggplot2 (&ge; 3.5.0), lme4, methods, mirt
(&ge; 1.43), nnet, psych (&ge; 2.1.9), purrr, rlang, rstudioapi,
tibble, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>data.table, deltaPlotR, difNLR (&ge; 1.5.0), DT, ggdendro,
gridExtra, knitr, latticeExtra, ltm, plotly, rmarkdown, shiny
(&ge; 1.6.0), shinyBS, shinyjs, stringr, testthat (&ge; 3.0.0),
VGAM, xtable, yaml</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-08 09:30:50 UTC; martinkova</td>
</tr>
<tr>
<td>Author:</td>
<td>Patricia Martinkova [aut, cre],
  Adela Hladka [aut],
  Jan Netik [aut],
  Ondrej Leder [ctb],
  Jakub Houdek [ctb],
  Lubomir Stepanek [ctb],
  Tomas Jurica [ctb],
  Jana Vorlickova [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Patricia Martinkova &lt;martinkova@cs.cas.cz&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-08 10:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ShinyItemAnalysis-package'>ShinyItemAnalysis: Test and Item Analysis via Shiny</h2><span id='topic+ShinyItemAnalysis'></span><span id='topic+ShinyItemAnalysis-package'></span>

<h3>Description</h3>

<p>The <code>ShinyItemAnalysis</code> package contains an interactive Shiny
application for the psychometric analysis of educational tests, psychological
assessments, health-related and other types of multi-item measurements, or
ratings from multiple raters, which can be accessed using function
<code>startShinyItemAnalysis()</code>. The shiny application covers a broad range of
psychometric methods and offers data examples, model equations, parameter
estimates, interpretation of results, together with a selected R code, and is
therefore suitable for teaching psychometric concepts with R. It also allows
the users to upload and analyze their own data and to automatically generate
analysis reports in PDF or HTML.
</p>
<p>Besides, the package provides its own functions for test and item analysis
within classical test theory framework (e.g., functions <code>gDiscrim()</code>,
<code>ItemAnalysis()</code>, <code>DistractorAnalysis()</code>, or <code>DDplot()</code>), using various
regression models (e.g., <code>plotCumulative()</code>, <code>plotAdjacent()</code>,
<code>plotMultinomial()</code>, or <code>plotDIFLogistic()</code>), and under IRT framework (e.g.,
<code>ggWrightMap()</code>, or <code>plotDIFirt()</code>).
</p>
<p>Package also contains several demonstration datasets including the <code>HCI</code>
dataset from the book by Martinkova and Hladka (2023), and from paper
by Martinkova and Drabinova (2018).
</p>


<h3>Functions</h3>


<ul>
<li> <p><code><a href="#topic+startShinyItemAnalysis">startShinyItemAnalysis()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+DDplot">DDplot()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+DistractorAnalysis">DistractorAnalysis()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+plotDistractorAnalysis">plotDistractorAnalysis()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+fa_parallel">fa_parallel()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+gDiscrim">gDiscrim()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+ggWrightMap">ggWrightMap()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+ICCrestricted">ICCrestricted()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+ItemAnalysis">ItemAnalysis()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+blis">blis()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+plotAdjacent">plotAdjacent()</a></code>, <code><a href="#topic+plotCumulative">plotCumulative()</a></code>, <code><a href="#topic+plotMultinomial">plotMultinomial()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+plotDIFirt">plotDIFirt()</a></code>, <code><a href="#topic+plotDIFLogistic">plotDIFLogistic()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+plot_corr">plot_corr()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+recode_nr">recode_nr()</a></code>
</p>
</li></ul>



<h3>Datasets</h3>


<ul>
<li> <p><code><a href="#topic+AIBS">AIBS()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+Anxiety">Anxiety()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+AttitudesExpulsion">AttitudesExpulsion()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+BFI2">BFI2()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+CLoSEread6">CLoSEread6()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+CZmatura">CZmatura()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+CZmaturaS">CZmaturaS()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dataMedical">dataMedical()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dataMedicalgraded">dataMedicalgraded()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dataMedicalkey">dataMedicalkey()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+dataMedicaltest">dataMedicaltest()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCI">HCI()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCIdata">HCIdata()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCIgrads">HCIgrads()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCIkey">HCIkey()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCIlong">HCIlong()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCIprepost">HCIprepost()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCItest">HCItest()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HCItestretest">HCItestretest()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+HeightInventory">HeightInventory()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+LearningToLearn">LearningToLearn()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+MSATB">MSATB()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+MSclinical">MSclinical()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+NIH">NIH()</a></code>
</p>
</li>
<li> <p><code><a href="#topic+TestAnxietyCor">TestAnxietyCor()</a></code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Patricia Martinkova  <br /> Institute of Computer Science of the Czech
Academy of Sciences  <br /> Faculty of Education, Charles University <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>
<p>Adela Hladka (nee Drabinova) <br /> Institute of Computer Science of the Czech
Academy of Sciences
</p>
<p>Jan Netik <br /> Institute of Computer Science of the Czech Academy of
Sciences <br />
</p>


<h3>References</h3>

<p>Martinkova, P., &amp; Hladka, A. (2023). Computational Aspects of
Psychometric Methods: With R. Chapman and Hall/CRC. <a href="https://doi.org/10.1201/9781003054313">doi:10.1201/9781003054313</a>
</p>
<p>Martinkova, P., &amp; Drabinova, A. (2018). ShinyItemAnalysis for
teaching psychometrics and to enforce routine analysis of educational
tests. The R Journal, 10(2), 503&ndash;515, <a href="https://doi.org/10.32614/RJ-2018-074">doi:10.32614/RJ-2018-074</a>
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://www.ShinyItemAnalysis.org">https://www.ShinyItemAnalysis.org</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/patriciamar/ShinyItemAnalysis/issues">https://github.com/patriciamar/ShinyItemAnalysis/issues</a>
</p>
</li></ul>


<hr>
<h2 id='AIBS'>AIBS grant peer review scoring dataset</h2><span id='topic+AIBS'></span>

<h3>Description</h3>

<p>The <code>AIBS</code> dataset (Gallo, 2020) comes from the scientific peer review
facilitated by the American Institute of Biological Sciences (AIBS) of
biomedical applications from and intramural collaborative biomedical research
program for 2014&ndash;2017. For each proposal, three assigned individual
reviewers were asked to provide scores and commentary for the following
application criteria: Innovation, Approach/Feasibility, Investigator, and
Significance (Impact added as scored criterion in 2014). Each of these
criteria is scored on a scale from 1.0 (best) to 5.0 (worst) with a 0.1
gradation, as well as an overall score (1.0&ndash;5.0 with a 0.1 gradation).
Asynchronous discussion was allowed, although few scores changed
post-discussion. The data includes reviewers' self-reported expertise scores
(1/2/3, 1 is high expertise) relative to each proposal reviewed, and reviewer
/ principal investigator demographics. A total of 72 applications (&quot;Standard&quot;
or &quot;Pilot&quot;) were reviewed in 3 review cycles. The success rate was 34&ndash;38 %.
Application scores indicate where each application falls among all
practically possible applications in comparison with the ideal standard of
quality from a perfect application. The dataset was used by Erosheva et al.
(2021a) to demonstrate issues of inter-rater reliability in case of
restricted samples. For details, see Erosheva et al. (2021b).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AIBS
</code></pre>


<h3>Format</h3>

<p><code>AIBS</code> is a <code>data.frame</code> consisting of 216 observations on
25 variables. Data describes 72 proposals with 3 ratings each.
</p>

<dl>
<dt>ID</dt><dd><p>Proposal ID. </p>
</dd>
<dt>Year</dt><dd><p>Year of the review. </p>
</dd>
<dt>PropType</dt><dd><p>Proposal type; <code>"Standard"</code> or <code>"Pilot"</code>. </p>
</dd>
<dt>PIID</dt><dd><p>Anonymized ID of principal investigator (PI). </p>
</dd>
<dt>PIOrgType</dt><dd><p>PI's organization type. </p>
</dd>
<dt>PIGender</dt><dd><p>PI's gender membership; <code>"1"</code> females, <code>"2"</code> males. </p>
</dd>
<dt>PIRank</dt><dd><p>PI's rank; <code>"3"</code> full professor, <code>"1"</code> assistant professor. </p>
</dd>
<dt>PIDegree</dt><dd><p>PI's degree; <code>"1"</code> PhD, <code>"2"</code> MD, <code>"3"</code> PhD/MD. </p>
</dd>
<dt>Innovation</dt><dd><p>Innovation score. </p>
</dd>
<dt>Approach</dt><dd><p>Approach score. </p>
</dd>
<dt>Investig</dt><dd><p>Investigator score. </p>
</dd>
<dt>Signif</dt><dd><p>Significance score. </p>
</dd>
<dt>Impact</dt><dd><p>Impact score. </p>
</dd>
<dt>Score</dt><dd><p>Scientific merit (overall) score. </p>
</dd>
<dt>ScoreAvg</dt><dd><p>Average of the three overall scores from three different reviewers. </p>
</dd>
<dt>ScoreAvgAdj</dt><dd><p>Average of the three overall scores from three different reviewers, increased by multiple of 0.001 of the worst score. </p>
</dd>
<dt>ScoreRank</dt><dd><p>Project rank calculated based on <code>ScoreAvg</code>. </p>
</dd>
<dt>ScoreRankAdj</dt><dd><p>Project rank calculated based on <code>ScoreAvgAdj</code>. </p>
</dd>
<dt>RevID</dt><dd><p>Reviewer's ID. </p>
</dd>
<dt>RevExp</dt><dd><p>Reviewer's experience. </p>
</dd>
<dt>RevInst</dt><dd><p>Reviewer's institution; <code>"1"</code> academia, <code>"2"</code> government. </p>
</dd>
<dt>RevGender</dt><dd><p>Reviewer's gender; <code>"1"</code> females, <code>"2"</code> males. </p>
</dd>
<dt>RevRank</dt><dd><p>Reviewer's rank; <code>"3"</code> full professor, <code>"1"</code> assistant professor. </p>
</dd>
<dt>RevDegree</dt><dd><p>Reviewer's degree; <code>"1"</code> PhD, <code>"2"</code> MD, <code>"3"</code> PhD/MD. </p>
</dd>
<dt>RevCode</dt><dd><p>Reviewer code (<code>"A"</code>, <code>"B"</code>, <code>"C"</code>) in the original wide dataset. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Stephen Gallo <br /> American Institute of Biological Sciences
</p>


<h3>References</h3>

<p>Gallo, S. (2021). Grant  peer  review  scoring  data  with  criteria  scores.
<a href="https://doi.org/10.6084/m9.figshare.12728087">doi:10.6084/m9.figshare.12728087</a>
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. (2021a). When zero may not be zero: A
cautionary note on the use of inter-rater reliability in evaluating grant
peer review. Journal of the Royal Statistical Society - Series A.
<a href="https://doi.org/10.1111/rssa.12681">doi:10.1111/rssa.12681</a>
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. (2021b). Supplementary material: When
zero may not be zero: A cautionary note on the use of inter-rater reliability
in evaluating grant peer review. <a href="https://doi.org/10.17605/OSF.IO/KNPH8">doi:10.17605/OSF.IO/KNPH8</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ICCrestricted">ICCrestricted()</a></code>
</p>

<hr>
<h2 id='Anxiety'>PROMIS Anxiety Scale Dataset</h2><span id='topic+Anxiety'></span>

<h3>Description</h3>

<p>The data contains responses from 766 people sampled from a general population
to the PROMIS Anxiety scale (http://www.nihpromis.org) composed of 29
Likert-type questions with a common rating scale (1 = Never, 2 = Rarely,
3 = Sometimes, 4 = Often, and 5 = Always).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Anxiety
</code></pre>


<h3>Format</h3>

<p>A data frame with 766 observations on the following 32 variables.
</p>

<dl>
<dt><code>age</code></dt><dd><p>0 = younger than 65 and 1 = 65 and older</p>
</dd>
<dt><code>gender</code></dt><dd><p>0 = Male and 1 = Female</p>
</dd>
<dt><code>education</code></dt><dd><p>0 = some college or higher and 1 = high school or lower</p>
</dd>
<dt><code>R1</code></dt><dd><p>I felt fearful</p>
</dd>
<dt><code>R2</code></dt><dd><p>I felt frightened</p>
</dd>
<dt><code>R3</code></dt><dd><p>It scared me when I felt nervous</p>
</dd>
<dt><code>R4</code></dt><dd><p>I felt anxious</p>
</dd>
<dt><code>R5</code></dt><dd><p>I felt like I needed help for my anxiety</p>
</dd>
<dt><code>R6</code></dt><dd><p>I was concerned about my mental health</p>
</dd>
<dt><code>R7</code></dt><dd><p>I felt upset</p>
</dd>
<dt><code>R8</code></dt><dd><p>I had a racing or pounding heart</p>
</dd>
<dt><code>R9</code></dt><dd><p>I was anxious if my normal routine was disturbed</p>
</dd>
<dt><code>R10</code></dt><dd><p>I had sudden feelings of panic</p>
</dd>
<dt><code>R11</code></dt><dd><p>I was easily startled</p>
</dd>
<dt><code>R12</code></dt><dd><p>I had trouble paying attention</p>
</dd>
<dt><code>R13</code></dt><dd><p>I avoided public places or activities</p>
</dd>
<dt><code>R14</code></dt><dd><p>I felt fidgety</p>
</dd>
<dt><code>R15</code></dt><dd><p>I felt something awful would happen</p>
</dd>
<dt><code>R16</code></dt><dd><p>I felt worried</p>
</dd>
<dt><code>R17</code></dt><dd><p>I felt terrified</p>
</dd>
<dt><code>R18</code></dt><dd><p>I worried about other people's reactions to me</p>
</dd>
<dt><code>R19</code></dt><dd><p>I found it hard to focus on anything other than my anxiety</p>
</dd>
<dt><code>R20</code></dt><dd><p>My worries overwhelmed me</p>
</dd>
<dt><code>R21</code></dt><dd><p>I had twitching or trembling muscles</p>
</dd>
<dt><code>R22</code></dt><dd><p>I felt nervous</p>
</dd>
<dt><code>R23</code></dt><dd><p>I felt indecisive</p>
</dd>
<dt><code>R24</code></dt><dd><p>Many situations made me worry</p>
</dd>
<dt><code>R25</code></dt><dd><p>I had difficulty sleeping</p>
</dd>
<dt><code>R26</code></dt><dd><p>I had trouble relaxing</p>
</dd>
<dt><code>R27</code></dt><dd><p>I felt uneasy</p>
</dd>
<dt><code>R28</code></dt><dd><p>I felt tense</p>
</dd>
<dt><code>R29</code></dt><dd><p>I had difficulty calming down</p>
</dd>
<dt><code>score</code></dt><dd><p>Total score.</p>
</dd>
<dt><code>zscore</code></dt><dd><p>Standardized total score.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Reexport from <code>lordif</code> package; http://www.nihpromis.org
</p>


<h3>References</h3>

<p>PROMIS Cooperative Group. Unpublished Manual for the
Patient-Reported Outcomes Measurement Information System (PROMIS) Version
1.1. October, 2008: http://www.nihpromis.org
</p>

<hr>
<h2 id='AttitudesExpulsion'>Attitudes towards the Expulsion of the Sudeten Germans (dataset)</h2><span id='topic+AttitudesExpulsion'></span>

<h3>Description</h3>

<p>Dataset from Kolek et al. (2021) study investigating a video game's effects
on implicit and explicit attitudes towards depicted historical events in the
short- and long-term. As an intervention tool, a serious game
<em>Czechoslovakia 38–89: Borderlands</em> was utilized that deals with the
expulsion of the Sudeten Germans from the former Czechoslovakia after the
WWII. Data consists responses from 145 adults from two groups (experimental
and control group) on number of multi-item measurements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AttitudesExpulsion
</code></pre>


<h3>Format</h3>

<p>A <em>data.frame</em> with 145 rows and
239 variables:
</p>

<dl>
<dt>ID</dt><dd><p>anonymous identifier</p>
</dd>
<dt>Group</dt><dd><p>C = control or E = experimental group</p>
</dd>
<dt>Gender</dt><dd><p><em>factor</em>, <code>male</code> or <code>female</code></p>
</dd>
<dt>GenderF</dt><dd><p><em>integer</em>, 1 = female</p>
</dd>
<dt>Merkel</dt><dd><p>effect of Merkel speech between the posttest and the delayed
posttest, range 0&ndash;5, where 0 stands for no effect, 5 for very significant
effect</p>
</dd>
<dt>Sudety</dt><dd><p><em>factor</em>, N = not originally from Czech Borderlands; Y =
originally from Czech Borderlands</p>
</dd>
<dt>Education</dt><dd><p><em>factor</em>, V = university; S = high school; Z = elementary
school</p>
</dd>
<dt>Education123</dt><dd><p><em>integer</em>, same as above, but coded as 3= university;
2= high school; 1= elementary school, meaning higher the number, higher the
education</p>
</dd>
<dt>*PANASpn</dt><dd><p>total PANAS score of positive and negative affect scales</p>
</dd>
<dt>*PANASp</dt><dd><p>total PANAS score of positive affect scale</p>
</dd>
<dt>*PANASn</dt><dd><p>total PANAS score of negative affect scale</p>
</dd>
<dt>*Macro</dt><dd><p>Macro attitude measurement</p>
</dd>
<dt>*Micro</dt><dd><p>Micro attitude measurement</p>
</dd>
<dt>*IATeffect</dt><dd><p>Single-Category Implicit association test score</p>
</dd>
</dl>

<p>Items beginning with an asterisk have following prefixes in the actual
dataset:
</p>

<dl>
<dt>pre</dt><dd><p>pretest</p>
</dd>
<dt>post</dt><dd><p>immediate posttest</p>
</dd>
<dt>del</dt><dd><p>one month delayed posttest</p>
</dd>
<dt>Post_Pre</dt><dd><p>difference between posttest_pretest</p>
</dd>
<dt>Del_Post</dt><dd><p>difference between delayed posttest and posttest</p>
</dd>
</dl>



<h3>Source</h3>

<p> Kolek, L., Šisler, V., Martinková, P., &amp; Brom, C. (2021). Can video
games change attitudes towards history? Results from a laboratory experiment
measuring short- and long-term effects. <em>Journal of Computer Assisted
Learning</em>, <em>1&ndash;22</em>. <a href="https://doi.org/10.1111/jcal.12575">doi:10.1111/jcal.12575</a>
</p>

<hr>
<h2 id='BFI2'>BFI2 Dataset</h2><span id='topic+BFI2'></span>

<h3>Description</h3>

<p><code>BFI2</code> dataset (Hřebíčková et al., 2020) consists of responses of
1,733
respondents
(1,003
females,
730
males) to Big Five Inventory 2 (BFI-2). It contains 60 ordinal items, vector
of age, education, and vector of gender membership.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BFI2
</code></pre>


<h3>Format</h3>

<p><code>BFI2</code> is a <code>data.frame</code> consisting of
1,733
observations on 64 variables.
</p>

<dl>
<dt>i1&ndash;i60</dt><dd><p>The BFI items, scored on Likert scale where
<code>1</code> = Disagree strongly,
<code>2</code> = Disagree a little,
<code>3</code> = Neutral; no opinion,
<code>4</code> = Agree a little, and
<code>5</code> = Agree strongly.
Some items were recoded so that all items are scored in the same direction, see Details.</p>
</dd>
<dt>Gender</dt><dd><p>Gender membership, <code>0</code> = females, <code>1</code> = males.</p>
</dd>
<dt>Age</dt><dd><p>Age in years.</p>
</dd>
<dt>Educ</dt><dd><p>Education,
<code>1</code> = Basic school,
<code>2</code> = Secondary technical school,
<code>3</code> = Secondary general school,
<code>4</code> = Other secondary school,
<code>5</code> = Tertiary professional school,
<code>6</code> = Bachelor degree,
<code>7</code> = Masters degree,
<code>8</code> = PhD</p>
</dd>
</dl>



<h3>Details</h3>

<p>The items prefixed with <code>i</code> are item scores. Items are indicators of 5 latent
personality factors/dimensions/domains, which are further broken down into
so-called facets. The 5 personality domains are: N = Negative Emotionality, E
= Extraversion, O = Open-Mindedness, C = Consciousness and A = Agreeability.
These are further broken down into so-called facets, as shown in the
following table:</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>Domain</strong> </td><td style="text-align: left;"> <strong>Facet</strong> </td><td style="text-align: left;"> <strong>Item numbers</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
   E </td><td style="text-align: left;"> Sociability (scb) </td><td style="text-align: left;"> 1, 16, 31, 46 </td>
</tr>
<tr>
 <td style="text-align: left;">
   E </td><td style="text-align: left;"> Assertiveness (asr) </td><td style="text-align: left;"> 6, 21, 36, 51 </td>
</tr>
<tr>
 <td style="text-align: left;">
   E </td><td style="text-align: left;"> Energy Level (enl) </td><td style="text-align: left;"> 11, 26, 41, 56 </td>
</tr>
<tr>
 <td style="text-align: left;">
   A </td><td style="text-align: left;"> Compassion (cmp) </td><td style="text-align: left;"> 2, 17, 32, 47 </td>
</tr>
<tr>
 <td style="text-align: left;">
   A </td><td style="text-align: left;"> Respectfulness (rsp) </td><td style="text-align: left;"> 7, 22, 37, 52 </td>
</tr>
<tr>
 <td style="text-align: left;">
   A </td><td style="text-align: left;"> Trust (trs) </td><td style="text-align: left;"> 12, 27, 42, 57 </td>
</tr>
<tr>
 <td style="text-align: left;">
   C </td><td style="text-align: left;"> Organization (org) </td><td style="text-align: left;"> 3, 18, 33, 48 </td>
</tr>
<tr>
 <td style="text-align: left;">
   C </td><td style="text-align: left;"> Productiveness (prd) </td><td style="text-align: left;"> 8, 23, 38, 53 </td>
</tr>
<tr>
 <td style="text-align: left;">
   C </td><td style="text-align: left;"> Responsibility (rsp) </td><td style="text-align: left;"> 13, 28, 43, 58 </td>
</tr>
<tr>
 <td style="text-align: left;">
   N </td><td style="text-align: left;"> Anxiety (anx) </td><td style="text-align: left;"> 4, 19, 34, 49 </td>
</tr>
<tr>
 <td style="text-align: left;">
   N </td><td style="text-align: left;"> Depression (dep) </td><td style="text-align: left;"> 9, 24, 39, 54 </td>
</tr>
<tr>
 <td style="text-align: left;">
   N </td><td style="text-align: left;"> Emotional Volatility (emt) </td><td style="text-align: left;"> 14, 29, 44, 59 </td>
</tr>
<tr>
 <td style="text-align: left;">
   O </td><td style="text-align: left;"> Intellectual Curiosity (int) </td><td style="text-align: left;"> 10, 25, 40, 55 </td>
</tr>
<tr>
 <td style="text-align: left;">
   O </td><td style="text-align: left;"> Aesthetic Sensitivity (aes) </td><td style="text-align: left;"> 5, 20, 35, 50 </td>
</tr>
<tr>
 <td style="text-align: left;">
   O </td><td style="text-align: left;"> Creative Imagination (crt) </td><td style="text-align: left;"> 15, 30, 45, 60 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p>In the original instrument, some items are inversely oriented, i.e., the
higher score means the lower latent trait. This was the case of items number
3, 4, 5, 8, 9, 11, 12, 16, 17, 22, 23, 24, 25, 26, 28, 29, 30, 31, 36, 37,
42, 44, 45, 47, 48, 49, 50, 51, 55, and 58. These <strong>items have been recoded</strong>
for you, i.e., displayed is value of <code style="white-space: pre;">&#8288;6 - original score&#8288;</code>.
</p>
<p>In the sample code, alternative item names are provided. These item names
can be used to decode the item domain, facet, item number, and
whether it was recoded or not. For example, <code>iCorg03r</code> stands for recoded 3rd
item (out of 60) from Consciousness domain and Organization facet.
</p>


<h3>Note</h3>

<p>Thanks to Martina Hřebíčková for sharing this dataset.
</p>


<h3>References</h3>

<p>Hřebíčková, M., Jelínek, M., Květon,P., Benkovič, A., Botek, M.,
Sudzina, F. Soto, Ch., John, O. (2020).  Big Five Inventory 2 (BFI-2):
Hierarchický model s 15 subškálami [Big Five Inventory 2 (BFI-2):
Hierarchical model with 15 subscales, in Czech]. <em>Československá
psychologie, 64,</em> 437&ndash;460.
</p>
<p>Soto, C. J., &amp; John, O. P. (2017). The next Big Five Inventory (BFI-2):
Developing and assessing a hierarchical model with 15 facets to enhance
bandwidth, fidelity, and predictive power. <em>Journal of Personality and
Social Psychology, 113,</em> 117&ndash;143.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>colnames(BFI2)[1:60] &lt;- c(
  "iEscb01", "iAcmp02", "iCorg03r", "iNanx04r", "iOaes05r", "iEasr06",
  "iArsp07", "iCprd08r", "iNdep09r", "iOint10", "iEenl11r", "iAtrs12r", "iCrsp13", "iNemt14",
  "iOcrt15", "iEscb16r", "iAcmp17r", "iCorg18", "iNanx19", "iOaes20", "iEasr21", "iArsp22r",
  "iCprd23r", "iNdep24r", "iOint25r", "iEenl26r", "iAtrs27", "iCrsp28r", "iNemt29r",
  "iOcrt30r", "iEscb31r", "iAcmp32", "iCorg33", "iNanx34", "iOaes35", "iEasr36r", "iArsp37r",
  "iCprd38", "iNdep39", "iOint40", "iEenl41", "iAtrs42r", "iCrsp43", "iNemt44r", "iOcrt45r",
  "iEscb46", "iAcmp47r", "iCorg48r", "iNanx49r", "iOaes50r", "iEasr51r", "iArsp52", "iCprd53",
  "iNdep54", "iOint55r", "iEenl56", "iAtrs57", "iCrsp58r", "iNemt59", "iOcrt60"
)

</code></pre>

<hr>
<h2 id='blis2blirt'>Reparametrize fitted BLIS model to IRT</h2><span id='topic+blis2blirt'></span>

<h3>Description</h3>

<p>Reparametrize fitted BLIS model to IRT
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blis2blirt(fitted_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blis2blirt_+3A_fitted_model">fitted_model</code></td>
<td>
<p>fitted BLIS model (object of class <a href="#topic+BlisClass-class">BlisClass</a>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>IRT parametrization of BLIS model
</p>

<hr>
<h2 id='BlisClass-class'>BLIS S4 class</h2><span id='topic+BlisClass-class'></span>

<h3>Description</h3>

<p>Extends <code>mirt</code>'s <code>SingleGroupClass</code> directly (meaning all <code>mirt</code> methods that
work with that class will work with <a href="#topic+BlisClass-class">BlisClass</a> too; make sure <code>mirt</code> is
loaded).
</p>


<h3>Details</h3>

<p>The purpose of the class is to have a custom <code>coef</code> method  (see
<a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a>) dispatched and the original levels with correct
response (as a <code>key</code> attribute) stored in the resulting fitted model.
</p>


<h3>Slots</h3>


<dl>
<dt><code>orig_levels</code></dt><dd><p><em>list</em> of original levels with logical attribute <code>key</code>,
which stores the information on which response (level) has been considered
as correct. Note that levels not used in the original data are dropped.</p>
</dd>
</dl>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a></code>,
<code><a href="#topic+fit_blis">fit_blis</a>()</code>,
<code><a href="#topic+get_orig_levels">get_orig_levels</a>()</code>,
<code><a href="#topic+nominal_to_int">nominal_to_int</a>()</code>,
<code><a href="#topic+obtain_nrm_def">obtain_nrm_def</a>()</code>,
<code><a href="#topic+print.blis_coefs">print.blis_coefs</a>()</code>
</p>

<hr>
<h2 id='CLoSEread6'>Czech Longitudinal Study in Education (CLoSE) - reading in 6th grade</h2><span id='topic+CLoSEread6'></span>

<h3>Description</h3>

<p><code>CLoSEread6</code> dataset consists of the dichotomously scored responses of 2,634 students
(1,324 boys, 1,310 girls) on 19 multiple-choice items in a test of reading
skills, version B, taken in the 6th grade. Item responses were dichotomized: 1
point was awarded only if the answer was fully correct and 0 if it was not
(Greger, Straková, &amp; Martinková, 2022; Martinková, Hladká, &amp; Potužníková, 2020;
Hladká, Martinková, &amp; Magis, 2023)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CLoSEread6
</code></pre>


<h3>Format</h3>

<p><code>CLoSEread6</code> is a <code>data.frame</code> consisting of 2,634 observations on
the 20 variables.
</p>

<dl>
<dt>Q6B_1-Q6B_19</dt><dd><p>Dichotomously scored items of the test on reading skills. </p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"0"</code> boys, <code>"1"</code> girls. </p>
</dd>
</dl>



<h3>Source</h3>

<p>Hladká, A., Martinková, P., &amp; Magis, D. (2023). Combining item purification and
multiple comparison adjustment methods in detection of differential item
functioning. <em>Multivariate Behavioral Research</em>, In Press.
</p>


<h3>References</h3>

<p>Greger, D., Straková, J., &amp; Martinková, P. (2022). Extending the ILSA study
design to a longitudinal design. TIMSS &amp; PIRLS extension in the Czech Republic:
CLoSE study. In T. Nilsen, A. Stancel-Piatak, &amp; J.-E. Gustafsson (Eds.),
<em>Springer international handbooks of education. International handbook of comparative
large-scale studies in education: Perspectives, methods and findings</em>. Springer.
<a href="https://doi.org/10.1007/978-3-030-38298-8_31-1">doi:10.1007/978-3-030-38298-8_31-1</a>
</p>
<p>Martinková, P., Hladká, A., &amp; Potužníková, E. (2020). Is academic
tracking related to gains in learning competence? Using propensity score
matching and differential item change functioning analysis for better
understanding of tracking implications. <em>Learning and Instruction</em>, <em>66</em>,
101286. <a href="https://doi.org/10.1016/j.learninstruc.2019.101286">doi:10.1016/j.learninstruc.2019.101286</a>
</p>

<hr>
<h2 id='coef+2CBlisClass-method'>Get Coefficients from a fitted BLIS model</h2><span id='topic+coef+2CBlisClass-method'></span>

<h3>Description</h3>

<p>Extracts item parameters from fitted BLIS model. For BLIRT parametrization,
use <code>IRTpars = TRUE</code> in your function call. Contrary to
<a href="mirt.html#topic+coef-method">mirt::coef,SingleGroupClass-method</a>, response category labels can be displayed in
the output using <code>labels = TRUE</code>. On top of that, as BLIS/BLIRT
parametrizations utilize the information of correct response category, you
can denote these in the output with <code>mark_correct = TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'BlisClass'
coef(
  object,
  ...,
  CI = 0.95,
  printSE = FALSE,
  IRTpars = FALSE,
  simplify = FALSE,
  labels = FALSE,
  mark_correct = labels
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef+2B2CBlisClass-method_+3A_object">object</code></td>
<td>
<p><em>object of class <a href="#topic+BlisClass-class">BlisClass</a></em>, model fitted via
<code>fit_blis</code>() or <code>blis()</code>.</p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_...">...</code></td>
<td>
<p>Additional arguments. Not utilized at the moment.</p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_ci">CI</code></td>
<td>
<p><em>numeric</em>, a width of the confidence intervals.</p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_printse">printSE</code></td>
<td>
<p><em>logical</em>, print standard errors instead of CI? Defaults to
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_irtpars">IRTpars</code></td>
<td>
<p><em>logical</em>, convert slope intercept parameters into IRT
parameters (i.e. BLIRT)? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_simplify">simplify</code></td>
<td>
<p><em>logical</em>, return coefficients as a matrix, instead of list?
Defaults to <code>FALSE</code>. <em>Not implemented yet.</em></p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_labels">labels</code></td>
<td>
<p><em>logical</em>, if <code>TRUE</code>, show response labels (e.g. &quot;A&quot;, &quot;B&quot;, &quot;C&quot;)
instead of response numeric indices (e.g. 0, 1, 2). Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="coef+2B2CBlisClass-method_+3A_mark_correct">mark_correct</code></td>
<td>
<p><em>logical</em>, mark the correct response with an asterisk
symbol. Applicable only if <code>labels</code> is <code>TRUE</code> (in which case,
<code>mark_correct</code> defaults to <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of item coefficients of S3 class <code>blis_coefs</code>, so the resulting
output of <code>coef()</code> call is formatted to display only first 3 digits (you
can opt for different rounding via the <a href="#topic+print.blis_coefs">print.blis_coefs</a> method, see the
examples). Note that the list-object returned invisibly has the raw
coefficients stored in it.
</p>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+BlisClass-class">BlisClass-class</a></code>,
<code><a href="#topic+fit_blis">fit_blis</a>()</code>,
<code><a href="#topic+get_orig_levels">get_orig_levels</a>()</code>,
<code><a href="#topic+nominal_to_int">nominal_to_int</a>()</code>,
<code><a href="#topic+obtain_nrm_def">obtain_nrm_def</a>()</code>,
<code><a href="#topic+print.blis_coefs">print.blis_coefs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fitted_blis &lt;- fit_blis(HCItest[, 1:20], HCIkey)

# BLIS coefs
coef(fitted_blis)

# BLIRT coefs
coef(fitted_blis, IRTpars = TRUE)

# store raw coefs
blis_coefs &lt;- coef(fitted_blis)

# print coefs rounded to 2 digits
print(blis_coefs, digits = 2)

</code></pre>

<hr>
<h2 id='cronbach_alpha'>Compute Cronbach alpha with confidence interval</h2><span id='topic+cronbach_alpha'></span>

<h3>Description</h3>

<p>So far internal function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cronbach_alpha(Data, ci = TRUE, ci_lvl = 0.95)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cronbach_alpha_+3A_data">Data</code></td>
<td>
<p><em>data.frame</em> or <em>matrix</em>, item data, <code>NA</code> gets excluded
automatically.</p>
</td></tr>
<tr><td><code id="cronbach_alpha_+3A_ci">ci</code></td>
<td>
<p><em>logical</em>, whether to compute CI or not. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cronbach_alpha_+3A_ci_lvl">ci_lvl</code></td>
<td>
<p><em>numeric</em> ranging from 0 to 1, a confidence level to construct
CI for. Defaults to <code>.95</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with <code class="reqn">\alpha</code> estimate and optionally CI.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ShinyItemAnalysis:::cronbach_alpha(HCI[, 1:20])

</code></pre>

<hr>
<h2 id='CZmatura'>CZmatura dataset</h2><span id='topic+CZmatura'></span>

<h3>Description</h3>

<p>The <code>CZmatura</code> dataset comes from matura exam in
mathematics. The exam was assigned in 2019 to students from Grade 13, at
the end of their secondary education. Original data available from
<a href="https://cermat.gov.cz/">https://cermat.gov.cz/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CZmatura
</code></pre>


<h3>Format</h3>

<p><code>CZmatura</code> is a <code>data.frame</code> consisting of 15,702 observations on
75 variables.
</p>

<dl>
<dt>SchType</dt><dd><p>School type code. </p>
</dd>
<dt>FirstAtt</dt><dd><p>First attempt; <code>"1"</code> yes, <code>"0"</code> no. </p>
</dd>
<dt>SchTypeGY</dt><dd><p>School type gymnasium; <code>"1"</code> yes, <code>"0"</code> no. </p>
</dd>
<dt>o1 &ndash; o26.2</dt><dd><p>Item answers. </p>
</dd>
<dt>b1 &ndash; b26</dt><dd><p>Scored item answers. </p>
</dd>
<dt>Total</dt><dd><p>Total score, calculated as sum of item scores (0 - 50). </p>
</dd>
<dt>IRTscore</dt><dd><p>Score estimated from GPCM/2PL model. </p>
</dd>
<dt>IRTscoreSE</dt><dd><p>SE of score estimated from GPCM/2PL model. </p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+CZmaturaS">CZmaturaS()</a></code>
</p>

<hr>
<h2 id='CZmaturaS'>CZmatura dataset - sample</h2><span id='topic+CZmaturaS'></span>

<h3>Description</h3>

<p>The <code>CZmaturaS</code> dataset comes from a matura exam in
mathematics. The exam was assigned in 2019 to students in Grade 13, at the end of
their secondary education. This is a random sample of 2,000 students from a
total of 15,702. Original data available from
<a href="https://cermat.gov.cz/">https://cermat.gov.cz/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CZmaturaS
</code></pre>


<h3>Format</h3>

<p><code>CZmatura</code> is a <code>data.frame</code> consisting of 2,000
observations on 75 variables.
</p>

<dl>
<dt>SchType</dt><dd><p>School type code. </p>
</dd>
<dt>FirstAtt</dt><dd><p>First attempt; <code>"1"</code> yes, <code>"0"</code> no. </p>
</dd>
<dt>SchTypeGY</dt><dd><p>School type gymnasium; <code>"1"</code> yes, <code>"0"</code> no. </p>
</dd>
<dt>o1 &ndash; o26.2</dt><dd><p>Item answers. </p>
</dd>
<dt>b1 &ndash; b26</dt><dd><p>Scored item answers. </p>
</dd>
<dt>Total</dt><dd><p>Total score, calculated as sum of item scores (0 - 50). </p>
</dd>
<dt>IRTscore</dt><dd><p>Score estimated from GPCM/2PL model. </p>
</dd>
<dt>IRTscoreSE</dt><dd><p>SE of score estimated from GPCM/2PL model. </p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+CZmatura">CZmatura()</a></code>
</p>

<hr>
<h2 id='dataMedical'>Dichotomous dataset of admission test to medical school</h2><span id='topic+dataMedical'></span>

<h3>Description</h3>

<p>The <code>dataMedical</code> dataset consists of the responses of 2,392 subjects (750
males, 1,633 females and 9 subjects without gender specification) to
admission test to a medical school. It contains 100 items. A correct answer
is coded as <code>"1"</code> and incorrect answer as <code>"0"</code>. Missing answers were
evaluated as incorrect, i.e. <code>"0"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataMedical
</code></pre>


<h3>Format</h3>

<p>A <code>dataMedical</code> is a <code>data.frame</code> consisting of 2,392 observations on
the following 102 variables.
</p>

<dl>
<dt>X</dt><dd><p>The first 100 columns represent dichotomously scored items of the
test. </p>
</dd>
<dt>gender</dt><dd><p>Variable describing gender; values <code>"0"</code> and <code>"1"</code> refer to
males and females. </p>
</dd>
<dt>StudySuccess</dt><dd><p>Criterion variable; value <code>"1"</code> means that student
studies standardly, <code>"0"</code> otherwise (e.g., leaving or interrupting studies). </p>
</dd>
</dl>



<h3>Source</h3>

<p>Stuka, C., Vejrazka, M., Martinkova, P., Komenda, M., &amp; Stepanek, L. (2016).
The use of test and item analysis for improvement of tests. Workshop held at
conference MEFANET, 2016, Brno, Czech Republic.
</p>


<h3>References</h3>

<p>Martinkova, P., &amp; Drabinova, A. (2018). ShinyItemAnalysis for
teaching psychometrics and to enforce routine analysis of educational tests.
The R Journal, 10(2), 503&ndash;515, <a href="https://doi.org/10.32614/RJ-2018-074">doi:10.32614/RJ-2018-074</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dataMedicaltest">dataMedicaltest()</a></code>, <code><a href="#topic+dataMedicalkey">dataMedicalkey()</a></code>, <code><a href="#topic+dataMedicalgraded">dataMedicalgraded()</a></code>
</p>

<hr>
<h2 id='dataMedicalgraded'>Graded dataset of admission test to medical school</h2><span id='topic+dataMedicalgraded'></span>

<h3>Description</h3>

<p>The <code>dataMedicalgraded</code> dataset consists of the responses of 2,392 subjects
(750 males, 1,633 females and 9 subjects without gender specification) to
multiple-choice admission test to a medical school. It contains 100 items.
Each item is graded with 0 to 4 points. Maximum of 4 points were set if all
correct answers and none of incorrect answers were selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataMedicalgraded
</code></pre>


<h3>Format</h3>

<p>A <code>dataMedicalgraded</code> is a <code>data.frame</code> consisting of 2,392
observations on the following 102 variables.
</p>

<dl>
<dt>X</dt><dd><p>The first 100 columns represent ordinal item scores of the test. </p>
</dd>
<dt>gender</dt><dd><p>Variable describing gender; values <code>"0"</code> and <code>"1"</code> refer to
males and females.</p>
</dd>
<dt>StudySuccess</dt><dd><p>Criterion variable; value <code>"1"</code> means that student
studies standardly, <code>"0"</code> otherwise (e.g., leaving or interrupting studies).</p>
</dd>
</dl>



<h3>Source</h3>

<p>Stuka, C., Vejrazka, M., Martinkova, P., Komenda, M., &amp; Stepanek, L. (2016).
The use of test and item analysis for improvement of tests. Workshop held at
conference MEFANET, 2016, Brno, Czech Republic.
</p>


<h3>References</h3>

<p>Martinkova, P., &amp; Drabinova, A. (2018). ShinyItemAnalysis for
teaching psychometrics and to enforce routine analysis of educational tests.
The R Journal, 10(2), 503&ndash;515, <a href="https://doi.org/10.32614/RJ-2018-074">doi:10.32614/RJ-2018-074</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dataMedical">dataMedical()</a></code>, <code><a href="#topic+dataMedicaltest">dataMedicaltest()</a></code>, <code><a href="#topic+dataMedicalkey">dataMedicalkey()</a></code>
</p>

<hr>
<h2 id='dataMedicalkey'>Key of correct answers for dataset of admission test to medical school</h2><span id='topic+dataMedicalkey'></span>

<h3>Description</h3>

<p>The <code>dataMedicalkey</code> is a vector of factors representing
correct answers of <code>dataMedicaltest</code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataMedicalkey
</code></pre>


<h3>Format</h3>

<p>A vector with 100 values representing correct answers to items of
<code>dataMedicaltest</code> dataset. For more details see
<code><a href="#topic+dataMedicaltest">dataMedicaltest()</a></code>.
</p>


<h3>Source</h3>

<p>Stuka, C., Vejrazka, M., Martinkova, P., Komenda, M., &amp; Stepanek, L. (2016).
The use of test and item analysis for improvement of tests. Workshop held at
conference MEFANET, 2016, Brno, Czech Republic.
</p>


<h3>References</h3>

<p>Martinkova, P., &amp; Drabinova, A. (2018). ShinyItemAnalysis for
teaching psychometrics and to enforce routine analysis of educational tests.
The R Journal, 10(2), 503&ndash;515, <a href="https://doi.org/10.32614/RJ-2018-074">doi:10.32614/RJ-2018-074</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dataMedical">dataMedical()</a></code>, <code><a href="#topic+dataMedicaltest">dataMedicaltest()</a></code>,
<code><a href="#topic+dataMedicalgraded">dataMedicalgraded()</a></code>
</p>

<hr>
<h2 id='dataMedicaltest'>Dataset of admission test to medical school</h2><span id='topic+dataMedicaltest'></span>

<h3>Description</h3>

<p>The <code>dataMedicaltest</code> dataset consists of the responses of
2,392 subjects (750 males, 1,633 females and 9 subjects without gender
specification) to multiple-choice admission test to a medical school. It
contains 100 items, possible answers were A, B, C, D, while any combination
of these can be correct.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataMedicaltest
</code></pre>


<h3>Format</h3>

<p>A <code>dataMedicaltest</code> is a <code>data.frame</code> consisting of 2,392
observations on the following 102 variables.
</p>

<dl>
<dt>X</dt><dd><p>The first 100 columns represent items answers.</p>
</dd>
<dt>gender</dt><dd><p>Variable describing gender; values <code>"0"</code> and <code>"1"</code> refer to
males and females.</p>
</dd>
<dt>StudySuccess</dt><dd><p>Criterion variable; value <code>"1"</code> means that student
studies standardly, <code>"0"</code> otherwise (e.g., leaving or interrupting studies). </p>
</dd>
</dl>



<h3>Source</h3>

<p>Stuka, C., Vejrazka, M., Martinkova, P., Komenda, M., &amp; Stepanek, L. (2016).
The use of test and item analysis for improvement of tests. Workshop held at
conference MEFANET, 2016, Brno, Czech Republic.
</p>


<h3>References</h3>

<p>Martinkova, P., &amp; Drabinova, A. (2018). ShinyItemAnalysis for
teaching psychometrics and to enforce routine analysis of educational tests.
The R Journal, 10(2), 503&ndash;515, <a href="https://doi.org/10.32614/RJ-2018-074">doi:10.32614/RJ-2018-074</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dataMedical">dataMedical()</a></code>, <code><a href="#topic+dataMedicalkey">dataMedicalkey()</a></code>,
<code><a href="#topic+dataMedicalgraded">dataMedicalgraded()</a></code>
</p>

<hr>
<h2 id='DDplot'>Plot difficulties and discriminations/item validity</h2><span id='topic+DDplot'></span>

<h3>Description</h3>

<p>Plots difficulty and (generalized) discrimination or criterion validity for
items of the multi-item measurement test using the <span class="pkg">ggplot2</span> package.
Difficulty and discrimination/validity indices are plotted for each item,
items are ordered by their difficulty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DDplot(
  Data,
  item.names,
  discrim = "ULI",
  k = 3,
  l = 1,
  u = 3,
  maxscore,
  minscore,
  bin = FALSE,
  cutscore,
  average.score = FALSE,
  thr = 0.2,
  criterion = "none",
  val_type = "simple",
  data
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DDplot_+3A_data">Data</code></td>
<td>
<p>numeric: binary or ordinal data <code>matrix</code> or
<code>data.frame</code> which rows represent examinee answers (<code>1</code> correct,
<code>0</code> incorrect, or ordinal item scores) and columns correspond to the
items.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_item.names">item.names</code></td>
<td>
<p>character: the names of items. If not specified, the names
of <code>Data</code> columns are used.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_discrim">discrim</code></td>
<td>
<p>character: type of discrimination index to be calculated.
Possible values are <code>"ULI"</code> (default), <code>"RIT"</code>, <code>"RIR"</code>, and
<code>"none"</code>. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_k">k</code></td>
<td>
<p>numeric: number of groups to which data may be divided by the total
score to estimate discrimination using <code>discrim = "ULI"</code>. Default
value is 3.  See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_l">l</code></td>
<td>
<p>numeric: lower group. Default value is 1. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_u">u</code></td>
<td>
<p>numeric: upper group. Default value is 3. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_maxscore">maxscore</code></td>
<td>
<p>numeric: maximal scores of items. If single number is
provided, the same maximal score is used for all items. If missing, vector
of achieved maximal scores is calculated and used in calculations.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_minscore">minscore</code></td>
<td>
<p>numeric: minimal scores of items. If single number is
provided, the same maximal score is used for all items. If missing, vector
of achieved maximal scores is calculated and used in calculations.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_bin">bin</code></td>
<td>
<p>logical: should the ordinal data be binarized? Default value is
<code>FALSE</code>. In case that <code>bin = TRUE</code>, all values of <code>Data</code>
equal or greater than <code>cutscore</code> are marked as <code>1</code> and all values
lower than <code>cutscore</code> are marked as <code>0</code>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_cutscore">cutscore</code></td>
<td>
<p>numeric: cut-score used to binarize <code>Data</code>. If numeric,
the same cut-score is used for all items. If missing, vector of maximal
scores is used in calculations.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_average.score">average.score</code></td>
<td>
<p>logical: should average score of the item be displayed
instead of difficulty? Default value is <code>FALSE</code>. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_thr">thr</code></td>
<td>
<p>numeric: value of discrimination threshold. Default value is 0.2.
With <code>thr = NULL</code>, no horizontal line is displayed in the plot.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_criterion">criterion</code></td>
<td>
<p>numeric or logical vector: values of criterion. If supplied,
<code>disrim</code> argument is ignored and item-criterion correlation (validity)
is displayed instead. Default value is <code>"none"</code>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_val_type">val_type</code></td>
<td>
<p>character: criterion validity measure. Possible values are
<code>"simple"</code> (correlation between item score and validity criterion;
default) and <code>"index"</code> (item validity index calculated as
<code>cor(item, criterion) * sqrt(((N - 1) / N) * var(item))</code>, where N is
number of respondents, see Allen &amp; Yen, 1979, Ch. 6.4, for details). The
argument is ignored if user does not supply any <code>criterion</code>.</p>
</td></tr>
<tr><td><code id="DDplot_+3A_data">data</code></td>
<td>
<p>deprecated. Use argument <code>Data</code> instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Discrimination is calculated using method specified in <code>discrim</code>. Default
option <code>"ULI"</code> calculates difference in ratio of correct answers in upper and
lower third of students. <code>"RIT"</code> index calculates correlation between item
score and test total score. <code>"RIR"</code> index calculates correlation between item
score and total score for the rest of the items. With option <code>"none"</code>, only
difficulty is displayed.
</p>
<p><code>"ULI"</code> index can be generalized using arguments <code>k</code>, <code>l</code> and <code>u</code>.
Generalized ULI discrimination is then computed as follows: The function
takes data on individuals, computes their total test score and then divides
individuals into <code>k</code> groups. The lower and upper group are determined by <code>l</code>
and <code>u</code> parameters, i.e.  l-th and u-th group where the ordering is defined
by increasing total score.
</p>
<p>For ordinal data, difficulty is defined as a relative score:
</p>
<div class="sourceCode"><pre>(achieved - minimal)/(maximal - minimal)
</pre></div>
<p>Minimal score can be specified by
<code>minscore</code>, maximal score can be specified by <code>maxscore</code>. Average score of
items can be displayed with argument <code>average.score = TRUE</code>. Note that for
binary data difficulty estimate is the same as average score of the item.
</p>
<p>Note that all correlations are estimated using Pearson correlation
coefficient.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a> <br />
</p>
<p>Lubomir Stepanek <br />
Charles University <br />
</p>
<p>Jana Vorlickova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>References</h3>

<p>Allen, M. J., &amp; Yen, W. M. (1979). Introduction to measurement theory.
Monterey, CA: Brooks/Cole.
</p>
<p>Martinkova, P., Stepanek, L., Drabinova, A., Houdek, J., Vejrazka, M., &amp;
Stuka, C. (2017). Semi-real-time analyses of item characteristics for medical
school admission tests. In: Proceedings of the 2017 Federated Conference on
Computer Science and Information Systems.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gDiscrim">gDiscrim()</a></code> for calculation of generalized ULI <br />
<code><a href="ggplot2.html#topic+ggplot">ggplot2::ggplot()</a></code> for general function to plot a <code>"ggplot"</code> object
</p>


<h3>Examples</h3>

<pre><code class='language-R'># binary dataset
dataBin &lt;- dataMedical[, 1:100]
# ordinal dataset
dataOrd &lt;- dataMedicalgraded[, 1:100]

# DDplot of binary dataset
DDplot(dataBin)
## Not run: 
# DDplot of binary dataset without threshold
DDplot(dataBin, thr = NULL)
# compared to DDplot using ordinal dataset and 'bin = TRUE'
DDplot(dataOrd, bin = TRUE)
# compared to binarized dataset using bin = TRUE and cut-score equal to 3
DDplot(dataOrd, bin = TRUE, cutscore = 3)

# DDplot of binary data using generalized ULI
# discrimination based on 5 groups, comparing 4th and 5th
# threshold lowered to 0.1
DDplot(dataBin, k = 5, l = 4, u = 5, thr = 0.1)

# DDplot of ordinal dataset using ULI
DDplot(dataOrd)
# DDplot of ordinal dataset using generalized ULI
# discrimination based on 5 groups, comparing 4th and 5th
# threshold lowered to 0.1
DDplot(dataOrd, k = 5, l = 4, u = 5, thr = 0.1)
# DDplot of ordinal dataset using RIT
DDplot(dataOrd, discrim = "RIT")
# DDplot of ordinal dataset using RIR
DDplot(dataOrd, discrim = "RIR")
# DDplot of ordinal dataset displaying only difficulty
DDplot(dataBin, discrim = "none")

# DDplot of ordinal dataset displaying difficulty estimates
DDplot(dataOrd)
# DDplot of ordinal dataset displaying average item scores
DDplot(dataOrd, average.score = TRUE)

# item difficulty / criterion validity plot for data with criterion
data(GMAT, package = "difNLR")
DDplot(GMAT[, 1:20], criterion = GMAT$criterion, val_type = "simple")

## End(Not run)
</code></pre>

<hr>
<h2 id='delta_ses'>Get standard errors using delta method approximation</h2><span id='topic+delta_ses'></span>

<h3>Description</h3>

<p>Get standard errors using delta method approximation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delta_ses(formula, mean, cov)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="delta_ses_+3A_formula">formula</code></td>
<td>
<p>a list of RHS-only formula(s)</p>
</td></tr>
<tr><td><code id="delta_ses_+3A_mean">mean</code></td>
<td>
<p>estimated mean of X</p>
</td></tr>
<tr><td><code id="delta_ses_+3A_cov">cov</code></td>
<td>
<p>estimated variance-covariance matrix of X</p>
</td></tr>
</table>


<h3>Value</h3>

<p>SEs vector
</p>

<hr>
<h2 id='DistractorAnalysis'>Distractor analysis</h2><span id='topic+DistractorAnalysis'></span>

<h3>Description</h3>

<p>Performs distractor analysis for each item and
optional number of groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DistractorAnalysis(
  Data,
  key,
  item = "all",
  p.table = FALSE,
  num.groups = 3,
  criterion = NULL,
  crit.discrete = FALSE,
  cut.points,
  data,
  matching,
  match.discrete
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DistractorAnalysis_+3A_data">Data</code></td>
<td>
<p>character: data matrix or data.frame with rows
representing unscored item responses from a multiple-choice test
and columns corresponding to the items.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_key">key</code></td>
<td>
<p>character: answer key for the items. The <code>key</code> must be a
vector of the same length as <code>ncol(Data)</code>. In case it is not
provided, <code>criterion</code> needs to be specified.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_item">item</code></td>
<td>
<p>numeric or character: either character <code>"all"</code> to
apply for all items (default), or a vector of item names (column
names of <code>Data</code>), or item identifiers (integers specifying
the column number).</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_p.table">p.table</code></td>
<td>
<p>logical: should the function return the proportions?
If <code>FALSE</code> (default), the counts are returned.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_num.groups">num.groups</code></td>
<td>
<p>numeric: number of groups to which are the
respondents split.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_criterion">criterion</code></td>
<td>
<p>numeric: numeric vector. If not provided, total
score is calculated and distractor analysis is performed based on
it.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_crit.discrete">crit.discrete</code></td>
<td>
<p>logical: is <code>criterion</code> discrete? Default
value is <code>FALSE</code>. See details.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_cut.points">cut.points</code></td>
<td>
<p>numeric: numeric vector specifying cut points of
<code>criterion</code>. See details.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_data">data</code></td>
<td>
<p>deprecated. Use argument <code>Data</code> instead.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_matching">matching</code></td>
<td>
<p>deprecated. Use argument <code>criterion</code> instead.</p>
</td></tr>
<tr><td><code id="DistractorAnalysis_+3A_match.discrete">match.discrete</code></td>
<td>
<p>deprecated. Use argument <code>crit.discrete</code>
instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an adapted version of the
<code>distractor.analysis()</code> function from <span class="pkg">CTT</span> package. In
case that no <code>criterion</code> is provided, the scores are calculated
using the item <code>Data</code> and <code>key</code>. The respondents are by default
split into the <code>num.groups</code>-quantiles and the number (or
proportion) of respondents in each quantile is reported with
respect to their answers. In case that <code>criterion</code> is discrete
(<code>crit.discrete = TRUE</code>), <code>criterion</code> is split based on its
unique levels. Other cut points can be specified via <code>cut.points</code>
argument.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a> <br />
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Data &lt;- dataMedicaltest[, 1:100]
Databin &lt;- dataMedical[, 1:100]
key &lt;- dataMedicalkey

# distractor analysis for all items
DistractorAnalysis(Data, key)

# distractor analysis for item 1
DistractorAnalysis(Data, key, item = 1)
## Not run: 
# distractor analysis with proportions
DistractorAnalysis(Data, key, p.table = TRUE)

# distractor analysis for 6 groups
DistractorAnalysis(Data, key, num.group = 6)

# distractor analysis using specified criterion
criterion &lt;- round(rowSums(Databin), -1)
DistractorAnalysis(Data, key, criterion = criterion)

# distractor analysis using discrete criterion
DistractorAnalysis(Data, key, criterion = criterion, crit.discrete = TRUE)

# distractor analysis using groups specified by cut.points
DistractorAnalysis(Data, key, cut.points = seq(10, 96, 10))

## End(Not run)

</code></pre>

<hr>
<h2 id='EPIA'>The Eysenck Personality Inventory Impulsivity Subscale</h2><span id='topic+EPIA'></span>

<h3>Description</h3>

<p>The data came from a published study and was kindly provided by Dr. Ferrando.
A group of 1,033 undergraduate students were asked to check on a 112 mm line
segment with two end points (almost never, almost always) using their own
judgement for the five items taken from the Spanish version of the EPI-A
impulsivity subscale. The direct item score was the distance in mm of the
check mark from the left end point (Ferrando, 2002).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EPIA
</code></pre>


<h3>Format</h3>

<p>A data frame with 1033 observations on the following 5 variables.
The sixth variable is a total score (i.e. the sum of the items).
</p>

<dl>
<dt><code>Item 1</code></dt><dd><p>Longs for excitement</p>
</dd>
<dt><code>Item 2</code></dt><dd><p>Does not stop and think things over before doing anything</p>
</dd>
<dt><code>Item 3</code></dt><dd><p>Often shouts back when shouted at</p>
</dd>
<dt><code>Item 4</code></dt><dd><p>Likes doing things in which he/she has to act quickly</p>
</dd>
<dt><code>Item 5</code></dt><dd><p>Tends to do many things at the same time</p>
</dd>
<dt><code>score</code></dt><dd><p>Total score for the aforementioned items</p>
</dd>
</dl>



<h3>Source</h3>

<p>Reexport from <code>EstCRM</code> package with added total scores.
</p>


<h3>References</h3>

<p>Ferrando, P. J. (2002). Theoretical and Empirical Comparison
between Two Models for Continuous Item Responses. <em>Multivariate
Behavioral Research</em>, <em>37</em>(4), 521&ndash;542.
</p>
<p>Zopluoglu C (2022). <em>EstCRM: Calibrating Parameters for the Samejima's Continuous IRT Model</em>.
R package version 1.5, <a href="https://CRAN.R-project.org/package=EstCRM">https://CRAN.R-project.org/package=EstCRM</a>.
</p>

<hr>
<h2 id='fa_parallel'>Conduct Parallel Analysis</h2><span id='topic+fa_parallel'></span>

<h3>Description</h3>

<p>Computes the eigenvalues of the sample correlation matrix and the eigenvalues
obtained from a random correlation matrix for which no factors/components are
assumed. By default, the function utilizes a modified Horn's (1965) method,
which &ndash; instead of mean &ndash; uses 95th percentile of each item eigenvalues
sampling distribution as a threshold to find the optimal number of
factors/components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fa_parallel(
  Data,
  cor = "pearson",
  n_obs = NULL,
  method = "pca",
  threshold = "quantile",
  p = 0.95,
  n_iter = 20,
  plot = TRUE,
  show_kaiser = TRUE,
  fm = "minres",
  use = "pairwise",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fa_parallel_+3A_data">Data</code></td>
<td>
<p><em>data.frame</em> or <em>matrix</em>, dataset (where rows are
observations and columns items) or correlation matrix (recognized
automatically).</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_cor">cor</code></td>
<td>
<p><em>character</em>, how to calculate the correlation matrix of the
real data. Can be either <code>pearson</code> (default), <code>tetrachoric</code> or
<code>polychoric</code>. Unambiguous abbreviations accepted.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_n_obs">n_obs</code></td>
<td>
<p><em>integer</em>, in case you provided the correlation matrix
directly as the input, you have to provide the number of observations in
the original dataset.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_method">method</code></td>
<td>
<p><em>character</em>, either <code>fa</code>, <code>pca</code>, or <code>both</code>
(the default). Which method to use for the eigenvalues simulation and
computation.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_threshold">threshold</code></td>
<td>
<p><em>character</em>, whether to use traditionall Horn's method
or more recent and well-performing quantile one. Either <code>mean</code> or
<code>quantile</code> (default). Can be abbreviated.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_p">p</code></td>
<td>
<p><em>numeric</em> (0&ndash;1), probability for which the sample quantile is
produced. Defaults to <code>.95</code>. Ignored if <code>threshold = "mean"</code>.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_n_iter">n_iter</code></td>
<td>
<p><em>integer</em>, number of iterations, i.e. the number of
zero-factor multivariate normal distributions to sample. Defaults to
<code>20</code>.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_plot">plot</code></td>
<td>
<p><em>logical</em>, if <code>TRUE</code> (the default), show the plot along
with the function results. To create the plot from the resulting object
afterwards, call <code>plot()</code>.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_show_kaiser">show_kaiser</code></td>
<td>
<p><em>logical</em>, whether to show Kaiser boundary in the
plot (the default) or not.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_fm">fm</code></td>
<td>
<p><em>character</em>, factoring method. See <code><a href="psych.html#topic+fa">psych::fa()</a></code>
from the package <code><a href="psych.html#topic+00.psych-package">psych::psych()</a></code>.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_use">use</code></td>
<td>
<p>an optional character string giving a method for computing
covariances in the presence of missing values. This must be (an
abbreviation of) one of the strings &quot;everything&quot;, &quot;all.obs&quot;,
&quot;complete.obs&quot;, &quot;na.or.complete&quot;, or &quot;pairwise.complete.obs&quot;.</p>
</td></tr>
<tr><td><code id="fa_parallel_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="psych.html#topic+tetrachor">psych::polychoric</a></code>
</p>

<dl>
<dt><code>correct</code></dt><dd><p>Correction value to use to correct for continuity in the case of zero entry cell for tetrachoric, polychoric, polybi, and mixed.cor.  See the examples for the effect of correcting versus not correcting for continuity.</p>
</dd>
<dt><code>smooth</code></dt><dd><p>if TRUE and if the tetrachoric/polychoric matrix is not positive definite, then apply a simple smoothing algorithm using cor.smooth</p>
</dd>
<dt><code>global</code></dt><dd><p>When finding pairwise correlations, should we use the global values of the tau parameter (which is somewhat faster), or the local values (global=FALSE)?  The local option is equivalent to the polycor solution, or to doing one correlation at a time. global=TRUE borrows information for one item pair from the other pairs using those item's frequencies.   This will make a difference in the presence of lots of missing data. With very small sample sizes with global=FALSE and correct=TRUE, the function will fail (for as yet underdetermined reasons. </p>
</dd>
<dt><code>weight</code></dt><dd><p>A vector of length of the number of observations that specifies the weights to apply to each case.  The NULL case is equivalent of weights of 1 for all cases.  </p>
</dd>
<dt><code>progress</code></dt><dd><p>Show the progress bar (if  not doing multicores)</p>
</dd>
<dt><code>ML</code></dt><dd><p> ML=FALSE  do a quick two step procedure, ML=TRUE, do longer maximum likelihood &mdash; very slow! Deprecated</p>
</dd>
<dt><code>delete</code></dt><dd><p>Cases with no variance are deleted with a warning before proceeding.</p>
</dd>
<dt><code>max.cat</code></dt><dd><p>The maximum number of categories to bother with for polychoric.  </p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>Horn proposed a solution to the problem of optimal factor number
identification using an approach based on a Monte Carlo simulation.
</p>
<p>First, several (20 by default) zero-factor <code>p</code>-variate normal
distributions (where <code>p</code> is the number of columns) are obtained, and
<code>p</code> × <code>p</code> correlation matrices are computed for them. Eigenvalues
of each matrix is then calculated in order to get an eigenvalues sampling
distribution for each simulated variable.
</p>
<p>Traditionally, Horn obtains an average of each sampling distribution and
these averages are used as a threshold which is compared with eigenvalues of
the original, real data. However, <em>usage of the mean was later disputed</em>
by Buja &amp; Eyuboglu (1992), and 95th percentile of eigenvalues sampling
distribution was suggested as a more accurate threshold. This, more recent
method is used by default in the function.
</p>


<h3>Value</h3>

<p>An object of class <code>data.frame</code> and <code>sia_parallel</code>. Can be
plotted using <code>plot()</code>.
</p>


<h3>Author(s)</h3>

<p>Jan Netik <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>References</h3>

<p>Horn, J. L. (1965). A rationale and test for the number of factors in factor
analysis. Psychometrika, 30, 179&ndash;185. <a href="https://doi.org/10.1007/BF02289447">doi:10.1007/BF02289447</a>
</p>
<p>Buja, A., &amp; Eyuboglu, N. (1992). Remarks on parallel analysis. Multivariate
Behavioral Research, 27, 509&ndash;540. <a href="https://doi.org/10.1207/s15327906mbr2704_2">doi:10.1207/s15327906mbr2704_2</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fa_parallel(TestAnxietyCor, n_obs = 335, method = "pca")

## Not run: 
data("bfi", package = "psych")
items &lt;- bfi[, 1:25]

fa_parallel(items)
fa_parallel(items, threshold = "mean") # traditional Horn's method

## End(Not run)

</code></pre>

<hr>
<h2 id='fit_blis'>Fit Baseline-category Logit Intercept-Slope (BLIS) model on nominal data</h2><span id='topic+fit_blis'></span><span id='topic+blis'></span>

<h3>Description</h3>

<p><code>blis</code> fits the IRT Nominal Response Model to data from multiple-choice tests,
while accounting for the correct answer and treating this option as a baseline
in this baseline-category logit model. The intercept-slope parametrization in
BLIS can be converted to IRT (difficulty-discrimination) parametrization (BLIRT).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_blis(Data, key, ...)

blis(Data, key, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_blis_+3A_data">Data</code></td>
<td>
<p><em>data.frame</em> or <em>tibble</em> with all columns being factors. Support
for <em>matrix</em> is limited and behavior not guaranteed.</p>
</td></tr>
<tr><td><code id="fit_blis_+3A_key">key</code></td>
<td>
<p>A single-column <code>data.frame</code>, (<strong>not</strong> matrix) <code>tibble</code> or -
preferably - a factor vector of levels considered as correct responses.</p>
</td></tr>
<tr><td><code id="fit_blis_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="mirt.html#topic+mirt">mirt::mirt</a></code>
</p>

<dl>
<dt><code>SE</code></dt><dd><p>logical; estimate the standard errors by computing the parameter information matrix?
See <code>SE.type</code> for the type of estimates available</p>
</dd>
<dt><code>covdata</code></dt><dd><p>a data.frame of data used for latent regression models</p>
</dd>
<dt><code>formula</code></dt><dd><p>an R formula (or list of formulas) indicating how the latent traits
can be regressed using external covariates in <code>covdata</code>. If a named list
of formulas is supplied (where the names correspond to the latent trait names in <code>model</code>)
then specific regression effects can be estimated for each factor. Supplying a single formula
will estimate the regression parameters for all latent traits by default</p>
</dd>
<dt><code>itemdesign</code></dt><dd><p>a <code>data.frame</code> with rows equal to the number of items and columns
containing any item-design effects. If items should be included in the design structure
(i.e., should be left in their canonical structure) then fewer rows can be used,
however the <code>rownames</code> must be defined and matched with <code>colnames</code> in the <code>data</code>
input. The item design matrix is constructed with the use of
<code>item.formula</code>. Providing this input will fix the associated <code>'d'</code> intercepts
to 0, where applicable</p>
</dd>
<dt><code>item.formula</code></dt><dd><p>an R formula used to specify any intercept decomposition (e.g.,
the LLTM; Fischer, 1983). Note that only the right-hand side of the formula is required
for compensatory models.
</p>
<p>For non-compensatory <code>itemtype</code>s (e.g., <code>'PC1PL'</code>) the formula must include
the name of the latent trait in the left hand side of the expression to indicate which
of the trait specification should have their intercepts decomposed (see MLTM; Embretson, 1984)</p>
</dd>
<dt><code>SE.type</code></dt><dd><p>type of estimation method to use for calculating the parameter information matrix
for computing standard errors and <code><a href="mirt.html#topic+wald">wald</a></code> tests. Can be:
</p>

<ul>
<li> <p><code>'Richardson'</code>, <code>'forward'</code>, or <code>'central'</code> for the numerical Richardson,
forward difference, and central difference evaluation of observed Hessian matrix
</p>
</li>
<li> <p><code>'crossprod'</code> and <code>'Louis'</code> for standard error computations based on the variance of the
Fisher scores as well as Louis' (1982) exact computation of the observed information matrix.
Note that Louis' estimates can take a long time to obtain for large sample sizes and long tests
</p>
</li>
<li> <p><code>'sandwich'</code> for the sandwich covariance estimate based on the
<code>'crossprod'</code> and <code>'Oakes'</code> estimates (see Chalmers, 2018, for details)
</p>
</li>
<li> <p><code>'sandwich.Louis'</code> for the sandwich covariance estimate based on the
<code>'crossprod'</code> and <code>'Louis'</code> estimates
</p>
</li>
<li> <p><code>'Oakes'</code> for Oakes' (1999) method using a central difference approximation
(see Chalmers, 2018, for details)
</p>
</li>
<li> <p><code>'SEM'</code> for the supplemented EM (disables the <code>accelerate</code> option automatically; EM only)
</p>
</li>
<li> <p><code>'Fisher'</code> for the expected information, <code>'complete'</code> for information based
on the complete-data Hessian used in EM algorithm
</p>
</li>
<li> <p><code>'MHRM'</code> and <code>'FMHRM'</code> for stochastic approximations of observed information matrix
based on the Robbins-Monro filter or a fixed number of MHRM draws without the RM filter.
These are the only options supported when <code>method = 'MHRM'</code>
</p>
</li>
<li> <p><code>'numerical'</code> to obtain the numerical estimate from a call to <code><a href="stats.html#topic+optim">optim</a></code>
when <code>method = 'BL'</code>
</p>
</li></ul>

<p>Note that both the <code>'SEM'</code> method becomes very sensitive if the ML solution has
has not been reached with sufficient precision, and may be further sensitive
if the history of the EM cycles is not stable/sufficient for convergence of the respective estimates.
Increasing the number of iterations (increasing <code>NCYCLES</code> and decreasing
<code>TOL</code>, see below) will help to improve the accuracy, and can be
run in parallel if a <code><a href="mirt.html#topic+mirtCluster">mirtCluster</a></code> object has been defined (this will be
used for Oakes' method as well). Additionally,
inspecting the symmetry of the ACOV matrix for convergence issues by passing
<code>technical = list(symmetric = FALSE)</code> can be helpful to determine if a sufficient
solution has been reached</p>
</dd>
<dt><code>method</code></dt><dd><p>a character object specifying the estimation algorithm to be used. The default is
<code>'EM'</code>, for the standard EM algorithm with fixed quadrature, <code>'QMCEM'</code> for
quasi-Monte Carlo EM estimation, or <code>'MCEM'</code> for Monte Carlo EM estimation.
The option <code>'MHRM'</code> may also be passed to use the MH-RM algorithm,
<code>'SEM'</code> for the Stochastic EM algorithm (first
two stages of the MH-RM stage using an optimizer other than a single Newton-Raphson iteration),
and <code>'BL'</code> for the Bock and Lieberman
approach (generally not recommended for longer tests).
</p>
<p>The <code>'EM'</code> is generally effective with 1-3 factors, but methods such as the <code>'QMCEM'</code>,
<code>'MCEM'</code>, <code>'SEM'</code>, or <code>'MHRM'</code> should be used when the dimensions are 3 or more. Note that
when the optimizer is stochastic the associated <code>SE.type</code> is automatically changed to
<code>SE.type = 'MHRM'</code> by default to avoid the use of quadrature</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>a character indicating which numerical optimizer to use. By default, the EM
algorithm will use the <code>'BFGS'</code> when there are no upper and lower bounds box-constraints and
<code>'nlminb'</code> when there are.
</p>
<p>Other options include the Newton-Raphson (<code>'NR'</code>),
which can be more efficient than the <code>'BFGS'</code> but not as stable for more complex
IRT models (such as the nominal or nested logit models)
and the related <code>'NR1'</code> which is also the Newton-Raphson
but consists of only 1 update that has been coupled with RM Hessian (only
applicable when the MH-RM algorithm is used). The MH-RM algorithm uses the <code>'NR1'</code> by default,
though currently the <code>'BFGS'</code>, <code>'L-BFGS-B'</code>, and <code>'NR'</code>
are also supported with this method (with
fewer iterations by default) to emulate stochastic EM updates.
As well, the <code>'Nelder-Mead'</code> and <code>'SANN'</code>
estimators are available, but their routine use generally is not required or recommended.
</p>
<p>Additionally, estimation subroutines from the <code>Rsolnp</code> and <code>nloptr</code>
packages are available by passing the arguments <code>'solnp'</code> and <code>'nloptr'</code>,
respectively. This should be used in conjunction with the <code>solnp_args</code> and
<code>nloptr_args</code> specified below. If equality constraints were specified in the
model definition only the parameter with the lowest <code>parnum</code>
in the <code>pars = 'values'</code> data.frame is used in the estimation vector passed
to the objective function, and group hyper-parameters are omitted.
Equality an inequality functions should be of the form <code>function(p, optim_args)</code>,
where <code>optim_args</code> is a list of internally parameters that largely can be ignored
when defining constraints (though use of <code>browser()</code> here may be helpful)</p>
</dd>
<dt><code>dentype</code></dt><dd><p>type of density form to use for the latent trait parameters. Current options include
</p>

<ul>
<li> <p><code>'Gaussian'</code> (default) assumes a multivariate Gaussian distribution with an associated
mean vector and variance-covariance matrix
</p>
</li>
<li> <p><code>'empiricalhist'</code> or <code>'EH'</code> estimates latent distribution using an empirical histogram described by
Bock and Aitkin (1981). Only applicable for unidimensional models estimated with the EM algorithm.
For this option, the number of cycles, TOL, and quadpts are adjusted accommodate for
less precision during estimation (namely: <code>TOL = 3e-5</code>, <code>NCYCLES = 2000</code>, <code>quadpts = 121</code>)
</p>
</li>
<li> <p><code>'empiricalhist_Woods'</code> or <code>'EHW'</code> estimates latent distribution using an empirical histogram described by
Bock and Aitkin (1981), with the same specifications as in <code>dentype = 'empiricalhist'</code>,
but with the extrapolation-interpolation method described by Woods (2007). NOTE: to improve stability
in the presence of extreme response styles (i.e., all highest or lowest in each item) the <code>technical</code> option
<code>zeroExtreme = TRUE</code> may be required to down-weight the contribution of these problematic patterns
</p>
</li>
<li> <p><code>'Davidian-#'</code> estimates semi-parametric Davidian curves described by Woods and Lin (2009),
where the <code>#</code> placeholder represents the number of Davidian parameters to estimate
(e.g., <code>'Davidian-6'</code> will estimate 6 smoothing parameters). By default, the number of
<code>quadpts</code> is increased to 121, and this method is only applicable for
unidimensional models estimated with the EM algorithm
</p>
</li></ul>

<p>Note that when <code>itemtype = 'ULL'</code> then a log-normal(0,1) density is used to support the unipolar scaling</p>
</dd>
<dt><code>constrain</code></dt><dd><p>a list of user declared equality constraints. To see how to define the
parameters correctly use <code>pars = 'values'</code> initially to see how the parameters are
labeled. To constrain parameters to be equal create a list with separate concatenated
vectors signifying which parameters to constrain. For example, to set parameters 1 and 5
equal, and also set parameters 2, 6, and 10 equal use
<code>constrain = list(c(1,5), c(2,6,10))</code>. Constraints can also be specified using the
<code><a href="mirt.html#topic+mirt.model">mirt.model</a></code> syntax (recommended)</p>
</dd>
<dt><code>calcNull</code></dt><dd><p>logical; calculate the Null model for additional fit statistics (e.g., TLI)?
Only applicable if the data contains no NA's and the data is not overly sparse</p>
</dd>
<dt><code>draws</code></dt><dd><p>the number of Monte Carlo draws to estimate the log-likelihood for the MH-RM
algorithm. Default is 5000</p>
</dd>
<dt><code>survey.weights</code></dt><dd><p>a optional numeric vector of survey weights to apply for each case in the
data (EM estimation only). If not specified, all cases are weighted equally (the standard IRT
approach). The sum of the <code>survey.weights</code> must equal the total sample size for proper
weighting to be applied</p>
</dd>
<dt><code>quadpts</code></dt><dd><p>number of quadrature points per dimension (must be larger than 2).
By default the number of quadrature uses the following scheme:
<code>switch(as.character(nfact), '1'=61, '2'=31, '3'=15, '4'=9, '5'=7, 3)</code>.
However, if the method input is set to <code>'QMCEM'</code> and this argument is left blank then
the default number of quasi-Monte Carlo integration nodes will be set to 5000 in total</p>
</dd>
<dt><code>TOL</code></dt><dd><p>convergence threshold for EM or MH-RM; defaults are .0001 and .001. If
<code>SE.type = 'SEM'</code> and this value is not specified, the default is set to <code>1e-5</code>.
To evaluate the model using only the starting values pass <code>TOL = NaN</code>, and
to evaluate the starting values without the log-likelihood pass <code>TOL = NA</code></p>
</dd>
<dt><code>gpcm_mats</code></dt><dd><p>a list of matrices specifying how the scoring coefficients in the (generalized)
partial credit model should be constructed. If omitted, the standard gpcm format will be used
(i.e., <code>seq(0, k, by = 1)</code> for each trait). This input should be used if traits
should be scored different for each category (e.g., <code>matrix(c(0:3, 1,0,0,0), 4, 2)</code> for a
two-dimensional model where the first trait is scored like a gpcm, but the second trait is only
positively indicated when the first category is selected). Can be used when <code>itemtype</code>s
are <code>'gpcm'</code> or <code>'Rasch'</code>, but only when the respective element in
<code>gpcm_mats</code> is not <code>NULL</code></p>
</dd>
<dt><code>grsm.block</code></dt><dd><p>an optional numeric vector indicating where the blocking should occur when
using the grsm, NA represents items that do not belong to the grsm block (other items that may
be estimated in the test data). For example, to specify two blocks of 3 with a 2PL item for
the last item: <code>grsm.block = c(rep(1,3), rep(2,3), NA)</code>. If NULL the all items are assumed
to be within the same group and therefore have the same number of item categories</p>
</dd>
<dt><code>rsm.block</code></dt><dd><p>same as <code>grsm.block</code>, but for <code>'rsm'</code> blocks</p>
</dd>
<dt><code>monopoly.k</code></dt><dd><p>a vector of values (or a single value to repeated for each item) which indicate
the degree of the monotone polynomial fitted, where the monotone polynomial
corresponds to <code>monopoly.k * 2 + 1</code> (e.g., <code>monopoly.k = 2</code> fits a
5th degree polynomial). Default is <code>monopoly.k = 1</code>, which fits a 3rd degree polynomial</p>
</dd>
<dt><code>large</code></dt><dd><p>a <code>logical</code> indicating whether unique response patterns should be obtained prior
to performing the estimation so as to avoid repeating computations on identical patterns.
The default <code>TRUE</code> provides the correct degrees of freedom for the model since all unique patterns
are tallied (typically only affects goodness of fit statistics such as G2, but also will influence
nested model comparison methods such as <code>anova(mod1, mod2)</code>), while <code>FALSE</code> will use the
number of rows in <code>data</code> as a placeholder for the total degrees of freedom. As such, model
objects should only be compared if all flags were set to <code>TRUE</code> or all were set to <code>FALSE</code>
</p>
<p>Alternatively, if the collapse table of frequencies is desired for the purpose of saving computations
(i.e., only computing the collapsed frequencies for the data onte-time) then a character vector can
be passed with the arguement <code>large = 'return'</code> to return a list of all the desired
table information used by <code>mirt</code>. This list object can then be reused by passing it back
into the <code>large</code> argument to avoid re-tallying the data again
(again, useful when the dataset are very large and computing the tabulated data is
computationally burdensome). This strategy is shown below:
</p>

<dl>
<dt>Compute organized data</dt><dd><p>e.g., <code>internaldat &lt;- mirt(Science, 1, large = 'return')</code></p>
</dd>
<dt>Pass the organized data to all estimation functions</dt><dd><p>e.g.,
<code>mod &lt;- mirt(Science, 1, large = internaldat)</code></p>
</dd>
</dl>
</dd>
<dt><code>GenRandomPars</code></dt><dd><p>logical; generate random starting values prior to optimization instead of
using the fixed internal starting values?</p>
</dd>
<dt><code>accelerate</code></dt><dd><p>a character vector indicating the type of acceleration to use. Default
is <code>'Ramsay'</code>, but may also be <code>'squarem'</code> for the SQUAREM procedure (specifically,
the gSqS3 approach) described in Varadhan and Roldand (2008).
To disable the acceleration, pass <code>'none'</code></p>
</dd>
<dt><code>verbose</code></dt><dd><p>logical; print observed- (EM) or complete-data (MHRM) log-likelihood
after each iteration cycle? Default is TRUE</p>
</dd>
<dt><code>solnp_args</code></dt><dd><p>a list of arguments to be passed to the <code>solnp::solnp()</code> function for
equality constraints, inequality constraints, etc</p>
</dd>
<dt><code>nloptr_args</code></dt><dd><p>a list of arguments to be passed to the <code>nloptr::nloptr()</code>
function for equality constraints, inequality constraints, etc</p>
</dd>
<dt><code>spline_args</code></dt><dd><p>a named list of lists containing information to be passed to the <code><a href="splines.html#topic+bs">bs</a></code> (default)
and <code><a href="splines.html#topic+ns">ns</a></code> for each spline itemtype. Each element must refer to the name of the itemtype with the
spline, while the internal list names refer to the arguments which are passed. For example, if item 2 were called
'read2', and item 5 were called 'read5', both of which were of itemtype 'spline' but item 5 should use the
<code><a href="splines.html#topic+ns">ns</a></code> form, then a modified list for each input might be of the form:
</p>
<p><code>spline_args = list(read2 = list(degree = 4),
                           read5 = list(fun = 'ns', knots = c(-2, 2)))</code>
</p>
<p>This code input changes the <code>bs()</code> splines function to have a <code>degree = 4</code> input,
while the second element changes to the <code>ns()</code> function with knots set a <code>c(-2, 2)</code></p>
</dd>
<dt><code>control</code></dt><dd><p>a list passed to the respective optimizers (i.e., <code>optim()</code>, <code>nlminb()</code>,
etc). Additional arguments have been included for the <code>'NR'</code> optimizer: <code>'tol'</code>
for the convergence tolerance in the M-step (default is <code>TOL/1000</code>), while the default
number of iterations for the Newton-Raphson optimizer is 50 (modified with the <code>'maxit'</code>
control input)</p>
</dd>
<dt><code>technical</code></dt><dd><p>a list containing lower level technical parameters for estimation. May be:
</p>

<dl>
<dt>NCYCLES</dt><dd><p>maximum number of EM or MH-RM cycles; defaults are 500 and 2000</p>
</dd>
<dt>MAXQUAD</dt><dd><p>maximum number of quadratures, which you can increase if you have more than
4GB or RAM on your PC; default 20000</p>
</dd>
<dt>theta_lim</dt><dd><p>range of integration grid for each dimension; default is <code>c(-6, 6)</code>. Note that
when <code>itemtype = 'ULL'</code> a log-normal distribution is used and the range is change to
<code>c(.01, and 6^2)</code>, where the second term is the square of the <code>theta_lim</code> input instead</p>
</dd>
<dt>set.seed</dt><dd><p>seed number used during estimation. Default is 12345</p>
</dd>
<dt>SEtol</dt><dd><p>standard error tolerance criteria for the S-EM and MHRM computation of the
information matrix. Default is 1e-3</p>
</dd>
<dt>symmetric</dt><dd><p>logical; force S-EM/Oakes information matrix estimates to be symmetric? Default is TRUE
so that computation of standard errors are more stable. Setting this to FALSE can help
to detect solutions that have not reached the ML estimate</p>
</dd>
<dt>SEM_window</dt><dd><p>ratio of values used to define the S-EM window based on the
observed likelihood differences across EM iterations. The default is
<code>c(0, 1 - SEtol)</code>, which provides nearly the very full S-EM window (i.e.,
nearly all EM cycles used). To use the a smaller SEM window change the window to
to something like <code>c(.9, .999)</code> to start at a point farther into the EM history</p>
</dd>
<dt>warn</dt><dd><p>logical; include warning messages during estimation? Default is TRUE</p>
</dd>
<dt>message</dt><dd><p>logical; include general messages during estimation? Default is TRUE</p>
</dd>
<dt>customK</dt><dd><p>a numeric vector used to explicitly declare the number of response
categories for each item. This should only be used when constructing mirt model for
reasons other than parameter estimation (such as to obtain factor scores), and requires
that the input data all have 0 as the lowest category. The format is the same as the
<code>extract.mirt(mod, 'K')</code> slot in all converged models</p>
</dd>
<dt>customPriorFun</dt><dd><p>a custom function used to determine the normalized density for
integration in the EM algorithm. Must be of the form <code>function(Theta, Etable){...}</code>,
and return a numeric vector with the same length as number of rows in <code>Theta</code>. The
<code>Etable</code> input contains the aggregated table generated from the current E-step
computations. For proper integration, the returned vector should sum to
1 (i.e., normalized). Note that if using the <code>Etable</code> it will be NULL
on the first call, therefore the prior will have to deal with this issue accordingly</p>
</dd>
<dt>zeroExtreme</dt><dd><p>logical; assign extreme response patterns a <code>survey.weight</code> of 0
(formally equivalent to removing these data vectors during estimation)?
When <code>dentype = 'EHW'</code>, where Woods' extrapolation is utilized,
this option may be required if the extrapolation causes expected densities to tend towards
positive or negative infinity. The default is <code>FALSE</code></p>
</dd>
<dt>customTheta</dt><dd><p>a custom <code>Theta</code> grid, in matrix form, used for integration.
If not defined, the grid is determined internally based on the number of <code>quadpts</code></p>
</dd>
<dt>nconstrain</dt><dd><p>same specification as the <code>constrain</code> list argument,
however imposes a negative equality constraint instead (e.g., <code class="reqn">a12 = -a21</code>, which
is specified as <code>nconstrain = list(c(12, 21))</code>). Note that each specification
in the list must be of length 2, where the second element is taken to be -1 times the
first element</p>
</dd>
<dt>delta</dt><dd><p>the deviation term used in numerical estimates when computing the ACOV matrix
with the 'forward' or 'central' numerical approaches, as well as Oakes' method with the
Richardson extrapolation. Default is 1e-5</p>
</dd>
<dt>parallel</dt><dd><p>logical; use the parallel cluster defined by <code><a href="mirt.html#topic+mirtCluster">mirtCluster</a></code>?
Default is TRUE</p>
</dd>
<dt>storeEMhistory</dt><dd><p>logical; store the iteration history when using the EM algorithm?
Default is FALSE. When TRUE, use <code><a href="mirt.html#topic+extract.mirt">extract.mirt</a></code> to extract</p>
</dd>
<dt>internal_constraints</dt><dd><p>logical; include the internal constraints when using certain
IRT models (e.g., 'grsm' itemtype). Disable this if you want to use special optimizers
such as the solnp. Default is <code>TRUE</code></p>
</dd>
<dt>gain</dt><dd><p>a vector of two values specifying the numerator and exponent
values for the RM gain function <code class="reqn">(val1 / cycle)^val2</code>.
Default is <code>c(0.10, 0.75)</code></p>
</dd>
<dt>BURNIN</dt><dd><p>number of burn in cycles (stage 1) in MH-RM; default is 150</p>
</dd>
<dt>SEMCYCLES</dt><dd><p>number of SEM cycles (stage 2) in MH-RM; default is 100</p>
</dd>
<dt>MHDRAWS</dt><dd><p>number of Metropolis-Hasting draws to use in the MH-RM at each iteration; default is 5</p>
</dd>
<dt>MHcand</dt><dd><p>a vector of values used to tune the MH sampler. Larger values will
cause the acceptance ratio to decrease. One value is required for each group in
unconditional item factor analysis (<code>mixedmirt()</code> requires additional values
for random effect). If null, these values are determined internally, attempting to
tune the acceptance of the draws to be between .1 and .4</p>
</dd>
<dt>MHRM_SE_draws</dt><dd><p>number of fixed draws to use when <code>SE=TRUE</code> and <code>SE.type = 'FMHRM'</code>
and the maximum number of draws when <code>SE.type = 'MHRM'</code>. Default is 2000</p>
</dd>
<dt>MCEM_draws</dt><dd><p>a function used to determine the number of quadrature points to draw for the
<code>'MCEM'</code> method. Must include one argument which indicates the iteration number of the
EM cycle. Default is <code>function(cycles) 500 + (cycles - 1)*2</code>, which starts the number of
draws at 500 and increases by 2 after each full EM iteration</p>
</dd>
<dt>info_if_converged</dt><dd><p>logical; compute the information matrix when using the MH-RM algorithm
only if the model converged within a suitable number of iterations? Default is <code>TRUE</code></p>
</dd>
<dt>logLik_if_converged</dt><dd><p>logical; compute the observed log-likelihood when using the MH-RM algorithm
only if the model converged within a suitable number of iterations? Default is <code>TRUE</code></p>
</dd>
<dt>keep_vcov_PD</dt><dd><p>logical; attempt to keep the variance-covariance matrix of the latent traits
positive definite during estimation in the EM algorithm? This generally improves the convergence
properties when the traits are highly correlated. Default is <code>TRUE</code></p>
</dd>
</dl>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>For the details on <code>coef</code> method dispatched for fitted BLIS model, see
<a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a>. To get more on the class, see <a href="#topic+BlisClass-class">BlisClass</a>.
</p>


<h3>Value</h3>

<p>Fitted model of class <a href="#topic+BlisClass-class">BlisClass</a> (extending standard <code>mirt</code>'s
<code>SingleGroupClass</code>).
</p>


<h3>Author(s)</h3>

<p>Jan Netik <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br /> Institute of Computer Science of the Czech Academy
of Sciences <br /> <a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+BlisClass-class">BlisClass-class</a></code>,
<code><a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a></code>,
<code><a href="#topic+get_orig_levels">get_orig_levels</a>()</code>,
<code><a href="#topic+nominal_to_int">nominal_to_int</a>()</code>,
<code><a href="#topic+obtain_nrm_def">obtain_nrm_def</a>()</code>,
<code><a href="#topic+print.blis_coefs">print.blis_coefs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fitted_blis &lt;- fit_blis(HCItest[, 1:20], HCIkey, SE = TRUE)
coef(fitted_blis)
coef(fitted_blis)$`Item 12`
coef(fitted_blis, IRTpars = TRUE)
coef(fitted_blis, IRTpars = TRUE, CI = 0.90) # 90% CI instead of 95% CI
coef(fitted_blis, IRTpars = TRUE, printSE = TRUE) # SE instead of CI
</code></pre>

<hr>
<h2 id='gDiscrim'>Compute generalized item discrimination</h2><span id='topic+gDiscrim'></span>

<h3>Description</h3>

<p>Generalized version of discrimination index ULI. The function enumerates the
ability of an item to distinguish between individuals from upper (U) vs.
lower (L) ability groups, i.e. between respondents with high vs. low overall
score on the test. Number of groups, as well as upper and lower groups can be
specified by user. You can also manually supply the maximal and minimal
scores when the theoretical range of item score is known. Note that if the
<em>observed</em> item range is zero <code>NaN</code> is returned.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gDiscrim(Data, k = 3, l = 1, u = 3, maxscore, minscore, x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gDiscrim_+3A_data">Data</code></td>
<td>
<p>matrix or data.frame of items to be examined. Rows represent
respondents, columns represent items.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_k">k</code></td>
<td>
<p>numeric: number of groups to which may be <code>Data</code> divided by the
total score. Default value is 3.  See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_l">l</code></td>
<td>
<p>numeric: lower group. Default value is 1. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_u">u</code></td>
<td>
<p>numeric: upper group. Default value is 3. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_maxscore">maxscore</code></td>
<td>
<p>numeric: maximal score in ordinal items. If missing, vector
of obtained maximal scores is imputed. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_minscore">minscore</code></td>
<td>
<p>numeric: minimal score in ordinal items. If missing, vector
of obtained minimal scores is imputed. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_x">x</code></td>
<td>
<p>deprecated. Use argument <code>Data</code> instead.</p>
</td></tr>
<tr><td><code id="gDiscrim_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="base.html#topic+findInterval">base::findInterval</a></code>
</p>

<dl>
<dt><code>rightmost.closed</code></dt><dd><p>logical; if true, the rightmost interval,
<code>vec[N-1] .. vec[N]</code> is treated as <em>closed</em>, see below.</p>
</dd>
<dt><code>all.inside</code></dt><dd><p>logical; if true, the returned indices are coerced
into <code>1,...,N-1</code>, i.e., <code>0</code> is mapped to <code>1</code>
and <code>N</code> to <code>N-1</code>.</p>
</dd>
<dt><code>left.open</code></dt><dd><p>logical; if true all the intervals are open at left
and closed at right; in the formulas below, <code class="reqn">\le</code> should be
swapped with <code class="reqn">&lt;</code> (and <code class="reqn">&gt;</code> with <code class="reqn">\ge</code>), and
<code>rightmost.closed</code> means &lsquo;leftmost is closed&rsquo;.  This may
be useful, e.g., in survival analysis computations.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes total test scores for all respondents and then
divides the respondents into <code>k</code> groups. The lower and upper groups
are determined by <code>l</code> and <code>u</code> parameters, i.e., l-th and u-th
group where the ordering is defined by increasing total score.
</p>
<p>In ordinal items, difficulty is calculated as difference of average score
divided by range (maximal possible score <code>maxscore</code> minus minimal
possible score <code>minscore</code> for given item).
</p>
<p>Discrimination is calculated as difference in difficulty between upper and
lower group.
</p>


<h3>Note</h3>

<p><code>gDiscrim</code> is used by <code><a href="#topic+DDplot">DDplot()</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br /> Institute of Computer Science of the Czech Academy
of Sciences <br /> <a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Lubomir Stepanek <br /> Institute of Computer Science of the Czech Academy of
Sciences
</p>
<p>Jana Vorlickova <br /> Institute of Computer Science of the Czech Academy of
Sciences
</p>
<p>Patricia Martinkova <br /> Institute of Computer Science of the Czech Academy
of Sciences <br /> <a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>
<p>Jan Netik <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>


<h3>References</h3>

<p>Martinkova, P., Stepanek, L., Drabinova, A., Houdek, J.,
Vejrazka, M., &amp; Stuka, C. (2017). Semi-real-time analyses of item
characteristics for medical school admission tests. In: Proceedings of the
2017 Federated Conference on Computer Science and Information Systems.
https://doi.org/10.15439/2017F380
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDplot">DDplot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># binary dataset
dataBin &lt;- dataMedical[, 1:100]
# ordinal dataset
dataOrd &lt;- dataMedicalgraded[, 1:100]

# ULI for the first 5 items of binary dataset
# compare to psychometric::discrim(dataBin)
gDiscrim(dataBin)[1:5]
# generalized ULI using 5 groups, compare 4th and 5th for binary dataset
gDiscrim(dataBin, k = 5, l = 4, u = 5)[1:5]

# ULI for first 5 items for ordinal dataset
gDiscrim(dataOrd)[1:5]
# generalized ULI using 5 groups, compare 4th and 5th for binary dataset
gDiscrim(dataOrd, k = 5, l = 4, u = 5)[1:5]
# maximum (4) and minimum (0) score are same for all items
gDiscrim(dataOrd, k = 5, l = 4, u = 5, maxscore = 4, minscore = 0)[1:5]
</code></pre>

<hr>
<h2 id='get_orig_levels'>Get Original Levels from a Fitted BLIS model</h2><span id='topic+get_orig_levels'></span>

<h3>Description</h3>

<p>Just a simple accessor to original levels and correct key stored in fitted
BLIS model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_orig_levels(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_orig_levels_+3A_object">object</code></td>
<td>
<p><em>object of class <a href="#topic+BlisClass-class">BlisClass</a></em>, model fitted via <code>fit_blis()</code> or
<code>blis()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><em>list</em> of the original levels and correct key. Key is stored as an
attribute <code>key</code> for every individual item.
</p>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+BlisClass-class">BlisClass-class</a></code>,
<code><a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a></code>,
<code><a href="#topic+fit_blis">fit_blis</a>()</code>,
<code><a href="#topic+nominal_to_int">nominal_to_int</a>()</code>,
<code><a href="#topic+obtain_nrm_def">obtain_nrm_def</a>()</code>,
<code><a href="#topic+print.blis_coefs">print.blis_coefs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fit &lt;- fit_blis(HCItest[, 1:20], HCIkey)
get_orig_levels(fit)
</code></pre>

<hr>
<h2 id='ggWrightMap'>Plot person-item map (Wright map) using <code>ggplot2</code></h2><span id='topic+ggWrightMap'></span>

<h3>Description</h3>

<p>This function allows to generate Wright map (also called
person-item map) using <code>ggplot()</code> function from the <span class="pkg">ggplot2</span>
package. Wright map is used to jointly display histogram of abilities
(or other measured trait) and item difficulty parameters.
Function takes pre-estimated parameter estimates, such as those obtained
from an IRT model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggWrightMap(
  theta,
  b,
  binwidth = 0.5,
  color = "blue",
  size = 15,
  item.names,
  ylab.theta = "Respondent latent trait",
  ylab.b = "Item difficulty",
  rel_widths = c(1, 1)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ggWrightMap_+3A_theta">theta</code></td>
<td>
<p>numeric: vector of ability estimates.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_b">b</code></td>
<td>
<p>numeric: vector of difficulty estimates.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_binwidth">binwidth</code></td>
<td>
<p>numeric: the width of the bins of histogram.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_color">color</code></td>
<td>
<p>character: color of histogram.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_size">size</code></td>
<td>
<p>text size in pts.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_item.names">item.names</code></td>
<td>
<p>names of items to be displayed.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_ylab.theta">ylab.theta</code></td>
<td>
<p>character: description of y-axis for the histogram.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_ylab.b">ylab.b</code></td>
<td>
<p>character: description of y-axis for the plot of difficulty
estimates.</p>
</td></tr>
<tr><td><code id="ggWrightMap_+3A_rel_widths">rel_widths</code></td>
<td>
<p>numeric: vector of length 2 specifying ratio of &quot;facet's&quot;
widths.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Jan Netik <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>References</h3>

<p>Wright, B. &amp; Stone, M. (1979). Best test design. MESA Press: Chicago, IL
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mirt)

# fit Rasch model with the mirt package
fit &lt;- mirt(HCI[, 1:20], model = 1, itemtype = "Rasch")
# factor scores
theta &lt;- as.vector(fscores(fit))
# difficulty estimates using IRT parametrization
b &lt;- coef(fit, simplify = TRUE, IRTpars = TRUE)$items[, "b"]

# Wright map
ggWrightMap(theta, b)

# Wright map with modified item names
item.names &lt;- paste("Item", 1:20)
ggWrightMap(theta, b, item.names = item.names)

# Wright map with modified descriptions of y-axis and relative widths of plots
ggWrightMap(theta, b,
  ylab.theta = "Latent trait", ylab.b = "Difficulty estimates",
  rel_widths = c(2, 1)
)
</code></pre>

<hr>
<h2 id='GMAT'>Dichotomous dataset based on GMAT with the same total score distribution for groups.</h2><span id='topic+GMAT'></span>

<h3>Description</h3>

<p>The <code>GMAT</code> is a generated dataset based on parameters from Graduate
Management Admission Test (GMAT, Kingston et al., 1985). First two items were
considered to function differently in uniform and non-uniform way respectively. The dataset
represents responses of 2,000 subjects to multiple-choice test of 20 items. A correct answer
is coded as 1 and incorrect answer as 0. The column <code>group</code> represents group membership,
where 0 indicates reference group and 1 indicates focal group. Groups are the same
size (i.e. 1,000 per group). The distributions of total scores (sum of correct answers) are the
same for both reference and focal group (Martinkova et al., 2017). The column <code>criterion</code>
represents generated continuous variable which is intended to be predicted by test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GMAT
</code></pre>


<h3>Format</h3>

<p>A <code>GMAT</code> data frame consists of 2,000 observations on the following 22 variables:
</p>

<dl>
<dt>Item1-Item20</dt><dd><p>dichotomously scored items of the test</p>
</dd>
<dt>group</dt><dd><p>group membership vector, <code>"0"</code> reference group, <code>"1"</code> focal group</p>
</dd>
<dt>criterion</dt><dd><p>continuous critetion intended to be predicted by test</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Adela Hladka (nee Drabinova) <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
Faculty of Mathematics and Physics, Charles University <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a> <br />
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>Source</h3>

<p>Reexport from <code>difNLR</code> package.
</p>


<h3>References</h3>

<p>Kingston, N., Leary, L., &amp; Wightman, L. (1985). An exploratory study of the applicability of item response theory
methods to the Graduate Management Admission Test. ETS Research Report Series, 1985(2): 1&ndash;64.
</p>
<p>Martinkova, P., Drabinova, A., Liaw, Y. L., Sanders, E. A., McFarland, J. L., &amp; Price, R. M. (2017).
Checking equity: Why differential item functioning analysis should be a routine part of developing conceptual
assessments. CBE&ndash;Life Sciences Education, 16(2), rm2, <a href="https://doi.org/10.1187/cbe.16-10-0307">doi:10.1187/cbe.16-10-0307</a>.
</p>

<hr>
<h2 id='HCI'>Homeostasis Concept Inventory dichotomous dataset</h2><span id='topic+HCI'></span>

<h3>Description</h3>

<p><code>HCI</code> dataset consists of the dichotomously scored responses of 651
students (405 males, 246 females) to Homeostasis Concept Inventory (HCI)
multiple-choice test. It contains 20 items, vector of gender membership and
identificator whether students plan to major in life sciences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCI
</code></pre>


<h3>Format</h3>

<p><code>HCI</code> is a <code>data.frame</code> consisting of 651 observations on
the 22 variables.
</p>

<dl>
<dt>Item1-Item20</dt><dd><p>Dichotomously scored items of the HCI test. </p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"0"</code> males, <code>"1"</code> females. </p>
</dd>
<dt>major</dt><dd><p>Identificator whether student plans to major in the life
sciences. </p>
</dd>
<dt>total</dt><dd><p>Total score</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCIdata'>Homeostasis concept inventory full dataset</h2><span id='topic+HCIdata'></span>

<h3>Description</h3>

<p><code>HCIdata</code> dataset consists of the responses of 669 students
(405 males, 246 females, 18 without gender specification) to Homeostasis
Concept Inventory (HCI) multiple-choice test. It contains answers to 20
multiple-choice items, scored items, total score, gender membership,
identifier whether students plan to major in science, study year, minority
membership, identifier whether English is the student's first language, and
type of school.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCIdata
</code></pre>


<h3>Format</h3>

<p><code>HCIdata</code> is a <code>data.frame</code> consisting of 669 observations
on the 47 variables.
</p>

<dl>
<dt>A1-A20</dt><dd><p>Multiple-choice items of the HCI test. </p>
</dd>
<dt>QR1-QR20</dt><dd><p>Scored items of the HCI test, <code>"0"</code> incorrect,
<code>"1"</code> correct. </p>
</dd>
<dt>total</dt><dd><p>Total test score. </p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"M"</code> males, <code>"F"</code> females,
<code>"none"</code> undisclosed. </p>
</dd>
<dt>major</dt><dd><p>Identifier whether students plans to major in the life sciences. </p>
</dd>
<dt>yearc5</dt><dd><p>Study year. </p>
</dd>
<dt>minority</dt><dd><p>Minority membership, <code>"maj"</code> majority, <code>"min"</code>
Black/Hispanic minority, <code>"none"</code> undisclosed. </p>
</dd>
<dt>EnglishF</dt><dd><p>Identifier whether English is the student's first language. </p>
</dd>
<dt>typeS</dt><dd><p>Course type, <code>"allied"</code> allied health, <code>"majors"</code>
physiology courses for
science majors, <code>"mixed majors"</code> courses for non-majors. </p>
</dd>
<dt>typeSCH</dt><dd><p>Type of school, <code>"AC"</code> associate's college, <code>"BCAS"</code>
baccalaureate college: arts and sciences focus, <code>"R1"</code> research
university, <code>"MCU"</code> master's college and university. </p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset<br />
<a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCIgrads'>Homeostasis concept inventory dataset of graduate students</h2><span id='topic+HCIgrads'></span>

<h3>Description</h3>

<p><code>HCIgrads</code> dataset consists of the responses of 10 graduate
students to Homeostasis Concept Inventory (HCI) multiple-choice test. It
contains answers to 20 multiple-choice items, scored items, and total test
score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCIgrads
</code></pre>


<h3>Format</h3>

<p><code>HCIgrads</code> is a <code>data.frame</code> consisting of 10 observations
on the 42 variables.
</p>

<dl>
<dt>A1-A20</dt><dd><p>Multiple-choice items of the HCI test. </p>
</dd>
<dt>QR1-QR20</dt><dd><p>Scored items of the HCI test, <code>"0"</code> incorrect,
<code>"1"</code> correct. </p>
</dd>
<dt>total</dt><dd><p>Total test score. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset<br />
<a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCIkey'>Key of correct answers for homeostasis concept inventory dataset</h2><span id='topic+HCIkey'></span>

<h3>Description</h3>

<p>The <code>HCIkey</code> is a vector of factors representing correct
answers of <code>HCItest</code> dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCIkey
</code></pre>


<h3>Format</h3>

<p>A nominal vector with 20 values representing correct answers to items
of <code>HCItest</code> dataset. For more details see <code><a href="#topic+HCItest">HCItest()</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset<br />
<a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCIlong'>Homeostasis Concept Inventory in a long format</h2><span id='topic+HCIlong'></span>

<h3>Description</h3>

<p><code>HCIlong</code> dataset consists of the dichotomously scored responses of 651
students (405 males, 246 females) to Homeostasis Concept Inventory (HCI)
multiple-choice test. It contains 20 items (<strong>in a long format</strong>), vector of
gender membership and identificator whether students plan to major in life
sciences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCIlong
</code></pre>


<h3>Format</h3>

<p><code>HCIlong</code> is a <code>data.frame</code> consisting of 13,020 rows and 5
variables.
</p>

<dl>
<dt>id</dt><dd><p>Row number of the original observation in a wide format.</p>
</dd>
<dt>item</dt><dd><p>Name of the item the rating is for.</p>
</dd>
<dt>rating</dt><dd><p>Response to the item.</p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"0"</code> males, <code>"1"</code> females. </p>
</dd>
<dt>major</dt><dd><p>Identificator whether student plans to major in the life
sciences.</p>
</dd>
<dt>total</dt><dd><p>Total score</p>
</dd>
<dt>zscore</dt><dd><p>Standardized total score (Z-score)</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset (in a wide format)<br />
<a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCIprepost'>Homeostasis concept inventory pretest and posttest scores</h2><span id='topic+HCIprepost'></span>

<h3>Description</h3>

<p><code>HCIprepost</code> dataset consists of the pretest and
posttest score of 16 students to Homeostasis Concept Inventory (HCI).
Between the pre-test and post-test, the students received
instruction on homeostasis within a physiology course.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCIprepost
</code></pre>


<h3>Format</h3>

<p><code>HCIprepost</code> is a <code>data.frame</code> consisting of 16
observations on the 2 variables.
</p>

<dl>
<dt>id</dt><dd><p>Anonymized respondent ID. </p>
</dd>
<dt>score.pre</dt><dd><p>Pretest score. </p>
</dd> <dt>score.post</dt><dd><p>Posttest score. </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset<br />
<a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCItest'>Homeostasis concept inventory multiple-choice dataset</h2><span id='topic+HCItest'></span>

<h3>Description</h3>

<p><code>HCItest</code> dataset consists of the responses of 651
students (405 males, 246 females) to Homeostasis Concept Inventory (HCI)
multiple-choice test. It containts 20 items, vector of gender membership
and identificator whether students plan to major in life sciences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCItest
</code></pre>


<h3>Format</h3>

<p><code>HCItest</code> is a <code>data.frame</code> consisting of 651 observations
on the 22 variables.
</p>

<dl>
<dt>Item1-Item20</dt><dd><p>Multiple-choice items of the HCI test. </p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"0"</code> males, <code>"1"</code> females. </p>
</dd>
<dt>major</dt><dd><p>Identificator whether student plans to major in the life
sciences. </p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
<a href="#topic+HCItestretest">HCItestretest</a> for HCI test-retest dataset<br />
</p>

<hr>
<h2 id='HCItestretest'>Homeostasis concept inventory test-retest dataset</h2><span id='topic+HCItestretest'></span>

<h3>Description</h3>

<p><code>HCItestretest</code> dataset consists of the responses of 45
students to Homeostasis Concept Inventory (HCI). It contains answers to 20
multiple-choice items, scored items, identifier of test/retest, total
score, gender membership and identifier whether students plan to major in
life sciences. The data are organized so that each pair of subsequent rows
belongs to one student. Students took no courses on homeostasis between the
test and retest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCItestretest
</code></pre>


<h3>Format</h3>

<p><code>HCItestretest</code> is a <code>data.frame</code> consisting of 90
observations on the 44 variables.
</p>

<dl>
<dt>A1-A20</dt><dd><p>Multiple-choice items of the HCI test. </p>
</dd>
<dt>QR1-QR20</dt><dd><p>Scored items of the HCI test, <code>"0"</code> incorrect,
<code>"1"</code> correct. </p>
</dd>
<dt>test</dt><dd><p>Identifier of test vs retest, <code>"test"</code> test,
<code>"retest"</code> retest after. </p>
</dd>
<dt>total</dt><dd><p>Total test score. </p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"M"</code> male, <code>"F"</code> female. </p>
</dd>
<dt>major</dt><dd><p>Identifier whether student plans to major in the life sciences. </p>
</dd> </dl>



<h3>Author(s)</h3>

<p>Jenny L. McFarland <br /> Biology Department, Edmonds Community College
</p>


<h3>References</h3>

<p>McFarland, J. L., Price, R. M., Wenderoth, M. P., Martinkova, P.,
Cliff, W., Michael, J., ... &amp; Wright, A. (2017). Development and validation
of the homeostasis concept inventory. CBE-Life Sciences Education, 16(2),
ar35. <a href="https://doi.org/10.1187/cbe.16-10-0305">doi:10.1187/cbe.16-10-0305</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+HCI">HCI</a> for HCI dichotomous dataset<br />
<a href="#topic+HCItest">HCItest</a> for HCI multiple-choice dataset<br />
<a href="#topic+HCIkey">HCIkey</a> for key of correct answers for HCI<br />
<a href="#topic+HCIdata">HCIdata</a> for HCI full dataset<br />
<a href="#topic+HCIlong">HCIlong</a> for HCI in a long format<br />
<a href="#topic+HCIgrads">HCIgrads</a>  for HCI dataset of graduate students<br />
<a href="#topic+HCIprepost">HCIprepost</a> for HCI pretest and posttest scores<br />
</p>

<hr>
<h2 id='HeightInventory'>Height inventory dataset</h2><span id='topic+HeightInventory'></span>

<h3>Description</h3>

<p><code>HeightInventory</code> dataset consists of the responses of 4,885 respondents
(1479 males, 3406 females) to a Height Inventory  (Rečka, 2018). It contains 26
ordinal items of self-perceived height rated on a scale <code>"1"</code> strongly disagree,
<code>"2"</code> disagree, <code>"3"</code> agree, <code>"4"</code> strongly agree, vector of self-reported
heights (in centimeters), and vector of gender membership. Total score is included
as the last variable, total score is NA for respondents who missed any item.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HeightInventory
</code></pre>


<h3>Format</h3>

<p><code>HeightInventory</code> is a <code>data.frame</code> consisting of 4,885 observations
on the 28 variables. First 26 variables are responses on scale <code>"1"</code>
strongly disagree, <code>"2"</code> disagree, <code>"3"</code> agree, <code>"4"</code> strongly agree.
Items 14 - 26 were reverse-coded, so that all items are scored in the same
direction. Names of these items start with <code>"R-"</code>. Original item number
and English wording is provided below.
</p>

<dl>
<dt>ShortTrousers</dt><dd><p>1. A lot of trousers are too short for me.</p>
</dd>
<dt>TallerThanM</dt><dd><p>2.	I am taller than men of my age.</p>
</dd>
<dt>TallerThanF</dt><dd><p>3.	I am taller than women of my age.</p>
</dd>
<dt>HeightForBasketball</dt><dd><p>4.	I have an appropriate height for playing basketball or volleyball.</p>
</dd>
<dt>AskMeToReach</dt><dd><p>5.	Other people sometimes ask me to reach something for them.</p>
</dd>
<dt>CommentsTall</dt><dd><p>6.	I am used to hearing comments about how tall I am.</p>
</dd>
<dt>ConcertObstructs</dt><dd><p>7.	At concerts, my stature usually obstructs other people’s views.</p>
</dd>
<dt>ShortBed</dt><dd><p>8.	Ordinary beds are too short for me.</p>
</dd>
<dt>TopShelfEasy</dt><dd><p>9.	I can easily take wares from top shelves at a store.</p>
</dd>
<dt>CrowdViewComf</dt><dd><p>10.	In a crowd of people, I still have a comfortable view.</p>
</dd>
<dt>ShortBlanket</dt><dd><p>11.	Blankets and bedspreads rarely cover me completely.</p>
</dd>
<dt>BendToHug</dt><dd><p>12.	When I want to hug someone, I usually need to bend over.</p>
</dd>
<dt>CarefulHead</dt><dd><p>13.	I must often be careful to avoid bumping my head against a doorjamb or a low ceiling.</p>
</dd>
<dt>R-SmallerThanM</dt><dd><p>14.	I am smaller than men of my age. (reversed)</p>
</dd>
<dt>R-StoolNeeded</dt><dd><p>15.	I often need a stool to reach something other people could reach without one. (reversed)</p>
</dd>
<dt>R-PlayDwarf</dt><dd><p>16.	I could play a dwarf. (reversed)</p>
</dd>
<dt>R-SmallerThanW</dt><dd><p>17.	I am smaller than women of my age. (reversed)</p>
</dd>
<dt>R-NoticeSmall</dt><dd><p>18.	One of the first things people notice about me is how small I am. (reversed)</p>
</dd>
<dt>R-OnTipToes</dt><dd><p>19.	I often need to stand on the tip of my toes to get a better view. (reversed)</p>
</dd>
<dt>R-ClothChildSize</dt><dd><p>20.	When I buy clothes, children’s sizes often fit me well. (reversed)</p>
</dd>
<dt>R-BusLegsEnoughSpace</dt><dd><p>21.	I have enough room for my legs when traveling by bus. (reversed)</p>
</dd>
<dt>R-FasterWalk</dt><dd><p>22.	I often need to walk faster than I’m used to in order to keep pace with taller people. (reversed)</p>
</dd>
<dt>R-AgeUnderestim</dt><dd><p>23.	Because of my smaller stature, people underestimate my age. (reversed)</p>
</dd>
<dt>R-WishLowerChair</dt><dd><p>24.	It would be more comfortable for me if chairs were made lower. (reversed)</p>
</dd>
<dt>R-UpwardLook</dt><dd><p>25.	When talking to other adults, I have to look upwards if I want to meet their eyes. (reversed)</p>
</dd>
<dt>R-MirrorTooHigh</dt><dd><p>26.	Some mirrors are placed so high up that I have to crane my neck to use them. (reversed)</p>
</dd>
<dt>gender</dt><dd><p>Gender membership, <code>"M"</code> males, <code>"F"</code> females.</p>
</dd>
<dt>HeightCM</dt><dd><p>Self-reported height in centimeters.</p>
</dd>
<dt>total</dt><dd><p>Total score.</p>
</dd>
</dl>



<h3>Note</h3>

<p>Thanks to Karel Rečka and Hynek Cígler for sharing this dataset.
</p>


<h3>References</h3>

<p>Rečka, K. (2018). Height and Weight Inventory. Brno, Masaryk
University: Unpublished Master's thesis
</p>

<hr>
<h2 id='ICCrestricted'>Range-restricted reliability with intra-class correlation</h2><span id='topic+ICCrestricted'></span>

<h3>Description</h3>

<p>Function estimating reliability with intra-class correlation for the complete
or for the range-restricted sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ICCrestricted(
  Data,
  case,
  var,
  rank = NULL,
  dir = "top",
  sel = 1,
  nsim = 100,
  ci = 0.95,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ICCrestricted_+3A_data">Data</code></td>
<td>
<p><code>matrix</code> or <code>data.frame</code> which includes variables
describing ID of ratees (specified in <code>case</code>), ratings (specified in
<code>var</code>), and (optionally) rank of ratees (specified in <code>rank</code>).</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_case">case</code></td>
<td>
<p>character: name of the variable in <code>Data</code> with ID of the
ratee (subject or object being evaluated, such as a respondent, proposal,
patient, applicant etc.)</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_var">var</code></td>
<td>
<p>character: name of the variable in <code>Data</code> with the
ratings/scores.</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_rank">rank</code></td>
<td>
<p>numeric: vector of ranks of ratees. If not provided, rank of
ratee is calculated based on average rating based on <code>var</code> variable.</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_dir">dir</code></td>
<td>
<p>character: direction of range-restriction, available options are
<code>"top"</code> (default) or <code>"bottom"</code>. Can be an unambiguous
abbreviation (i.e., <code>"t"</code> or <code>"b"</code>).</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_sel">sel</code></td>
<td>
<p>numeric: selected number (given &gt; 1) or percentage (given &lt;= 1) of
ratees. Default value is 1 (complete dataset).</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_nsim">nsim</code></td>
<td>
<p>numeric: number of simulations for bootstrap confidence interval.
Default value is 100.</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_ci">ci</code></td>
<td>
<p>numeric: confidence interval. Default value is 0.95.</p>
</td></tr>
<tr><td><code id="ICCrestricted_+3A_seed">seed</code></td>
<td>
<p>seed for simulations. Default value is <code>NULL</code>, random seed.
See <code><a href="lme4.html#topic+bootMer">lme4::bootMer()</a></code> for more detail.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> with the following columns: </p>
<table role = "presentation">
<tr><td><code>n_sel</code></td>
<td>
<p>number
of ratees selected/subsetted.</p>
</td></tr> <tr><td><code>prop_sel</code></td>
<td>
<p>proportion of ratees
selected.</p>
</td></tr> <tr><td><code>dir</code></td>
<td>
<p>direction of range-restriction. <code>NA</code> if range is
effectively not restricted (100% used).</p>
</td></tr> <tr><td><code>VarID</code></td>
<td>
<p>variance due to
ratee, &quot;true variance&quot;, between-group variance.</p>
</td></tr> <tr><td><code>VarResid</code></td>
<td>
<p>residual
variance.</p>
</td></tr> <tr><td><code>VarTotal</code></td>
<td>
<p>total variance.</p>
</td></tr> <tr><td><code>ICC1</code></td>
<td>
<p>single-rater
inter-rater reliability.</p>
</td></tr> <tr><td><code>ICC1_LCI</code></td>
<td>
<p>lower bound of the confidence
interval for <code>ICC1</code>.</p>
</td></tr> <tr><td><code>ICC1_UCI</code></td>
<td>
<p>upper bound of the confidence
interval for <code>ICC1</code>.</p>
</td></tr> <tr><td><code>ICC3</code></td>
<td>
<p>multiple-rater inter-rater
reliability.</p>
</td></tr> <tr><td><code>ICC3_LCI</code></td>
<td>
<p>lower bound of the confidence interval for
<code>ICC3</code>.</p>
</td></tr> <tr><td><code>ICC3_UCI</code></td>
<td>
<p>upper bound of the confidence interval for
<code>ICC3</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>
<p>Jan Netik <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>


<h3>References</h3>

<p>Erosheva, E., Martinkova, P., &amp; Lee, C. (2021a). When zero may not be zero: A
cautionary note on the use of inter-rater reliability in evaluating grant
peer review. Journal of the Royal Statistical Society - Series A. Accepted.
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. (2021b). Supplementary material for
When zero may not be zero: A cautionary note on the use of inter-rater
reliability in evaluating grant peer review.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># ICC for the whole sample
ICCrestricted(Data = AIBS, case = "ID", var = "Score", rank = "ScoreRankAdj")

# ICC for the range-restricted sample considering 80% of top ratees
ICCrestricted(
  Data = AIBS, case = "ID", var = "Score", rank = "ScoreRankAdj",
  sel = 0.8
)

</code></pre>

<hr>
<h2 id='ItemAnalysis'>Compute traditional item analysis indices</h2><span id='topic+ItemAnalysis'></span>

<h3>Description</h3>

<p>Computes various traditional item analysis indices including difficulty,
discrimination and item validity. For ordinal items, the function returns
scaled values for some of the indices. See the details below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ItemAnalysis(
  Data,
  minscore = NULL,
  maxscore = NULL,
  cutscore = NULL,
  criterion = NULL,
  k = NULL,
  l = NULL,
  u = NULL,
  bin = "deprecated"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ItemAnalysis_+3A_data">Data</code></td>
<td>
<p><em>matrix</em> or <em>data.frame</em> of items to be examined. Rows represent
respondents, columns represent items.</p>
</td></tr>
<tr><td><code id="ItemAnalysis_+3A_minscore">minscore</code>, <code id="ItemAnalysis_+3A_maxscore">maxscore</code></td>
<td>
<p><em>integer</em>, theoretical minimal/maximal score. If not
provided, these are computed on observed data. Automatically recycled to
the number of columns of the data.</p>
</td></tr>
<tr><td><code id="ItemAnalysis_+3A_cutscore">cutscore</code></td>
<td>
<p><em>integer</em> If provided, the input data are binarized
accordingly. Automatically recycled to the number of columns of the data.</p>
</td></tr>
<tr><td><code id="ItemAnalysis_+3A_criterion">criterion</code></td>
<td>
<p>vector of criterion values.</p>
</td></tr>
<tr><td><code id="ItemAnalysis_+3A_k">k</code>, <code id="ItemAnalysis_+3A_l">l</code>, <code id="ItemAnalysis_+3A_u">u</code></td>
<td>
<p>Arguments passed on to <code><a href="#topic+gDiscrim">gDiscrim()</a></code>. Provide these if you want to
compute generalized upper-lower index along with a standard ULI (using <code>k</code>
= 3, <code>l</code> = 1, <code>u</code> = 3), which is provided by default.</p>
</td></tr>
<tr><td><code id="ItemAnalysis_+3A_bin">bin</code></td>
<td>
<p><em>deprecated</em>, use <code>cutscore</code> instead. See the <strong>Details</strong>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For calculation of generalized ULI index, it is possible to specify a custom
number of groups <code>k</code>, and which two groups <code>l</code> and <code>u</code> are to be compared.
</p>
<p>In ordinal items, difficulty is calculated as difference of average score
divided by range (maximal possible score <code>maxscore</code> minus minimal possible
score <code>minscore</code>).
</p>
<p>If <code>cutscore</code> is provided, item analysis is conducted on binarized data;
values greater or equal to cut-score are set to <code>1</code>, other values are set to
<code>0</code>. Both the <code>minscore</code> and <code>maxscore</code> arguments are then ingored and set to
0 and 1, respectively.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> with following columns:
</p>
<table role = "presentation">
<tr><td><code>Difficulty</code></td>
<td>
<p>average score of the item divided by its range.</p>
</td></tr>
<tr><td><code>Mean</code></td>
<td>
<p>average item score.</p>
</td></tr>
<tr><td><code>SD</code></td>
<td>
<p>standard deviation of the item score.</p>
</td></tr>
<tr><td><code>Cut.score</code></td>
<td>
<p>cut-score specified in <code>cutscore</code>.</p>
</td></tr>
<tr><td><code>obs.min</code></td>
<td>
<p>observed minimal score.</p>
</td></tr>
<tr><td><code>Min.score</code></td>
<td>
<p>minimal score specified in <code>minscore</code>; if not provided,
observed minimal score.</p>
</td></tr>
<tr><td><code>obs.max</code></td>
<td>
<p>observed maximal score.</p>
</td></tr>
<tr><td><code>Max.score</code></td>
<td>
<p>maximal score specified in <code>maxscore</code>; if not provided,
observed maximal score.</p>
</td></tr>
<tr><td><code>Prop.max.score</code></td>
<td>
<p>proportion of maximal scores.</p>
</td></tr>
<tr><td><code>RIT</code></td>
<td>
<p>item-total correlation (correlation between item score and
overall test score).</p>
</td></tr>
<tr><td><code>RIR</code></td>
<td>
<p>item-rest correlation (correlation between item score and
overall test score without the given item).</p>
</td></tr>
<tr><td><code>ULI</code></td>
<td>
<p>upper-lower index using the standard parameters (3 groups,
comparing 1st and 3rd).</p>
</td></tr>
<tr><td><code>Corr.criterion</code></td>
<td>
<p>correlation between item score and criterion
<code>criterion</code>.</p>
</td></tr>
<tr><td><code>gULI</code></td>
<td>
<p>generalized ULI. <code>NA</code> when the arguments <code>k</code>, <code>l</code>, and <code>u</code>
were not provided.</p>
</td></tr>
<tr><td><code>Alpha.drop</code></td>
<td>
<p>Cronbach's alpha without given item.</p>
</td></tr>
<tr><td><code>Index.rel</code></td>
<td>
<p>Gulliksen's (1950) item reliability index.</p>
</td></tr>
<tr><td><code>Index.val</code></td>
<td>
<p>Gulliksen's (1950) item validity index.</p>
</td></tr>
<tr><td><code>Perc.miss</code></td>
<td>
<p>Percentage of missed responses on the particular item.</p>
</td></tr>
<tr><td><code>Perc.nr</code></td>
<td>
<p>Percentage of respondents that did not reached the item
nor the subsequent ones, see <code><a href="#topic+recode_nr">recode_nr()</a></code> for further details.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Patricia Martinkova <br /> Institute of Computer Science of the Czech
Academy of Sciences <br /> <a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>
<p>Jan Netik <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>
<p>Jana Vorlickova <br /> Institute of Computer Science of the Czech Academy of
Sciences
</p>
<p>Adela Hladka <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>


<h3>References</h3>

<p>Martinkova, P., Stepanek, L., Drabinova, A., Houdek, J.,
Vejrazka, M., &amp; Stuka, C. (2017). Semi-real-time analyses of item
characteristics for medical school admission tests. In: Proceedings of the
2017 Federated Conference on Computer Science and Information Systems.
https://doi.org/10.15439/2017F380
</p>
<p>Gulliksen, H. (1950). <em>Theory of mental tests.</em> John Wiley &amp; Sons Inc.
https://doi.org/10.1037/13240-000
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DDplot">DDplot()</a></code>, <code><a href="#topic+gDiscrim">gDiscrim()</a></code>, <code><a href="#topic+recode_nr">recode_nr()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# binary dataset
dataBin &lt;- dataMedical[, 1:100]
# ordinal dataset
dataOrd &lt;- dataMedicalgraded[, 1:100]
# study success is the same for both data sets
StudySuccess &lt;- dataMedical[, 102]

# item analysis for binary data
head(ItemAnalysis(dataBin))
# item analysis for binary data using also study success
head(ItemAnalysis(dataBin, criterion = StudySuccess))

# item analysis for binary data
head(ItemAnalysis(dataOrd))
# item analysis for binary data using also study success
head(ItemAnalysis(dataOrd, criterion = StudySuccess))
# including also item analysis for binarized data
head(ItemAnalysis(dataOrd,
  criterion = StudySuccess, k = 5, l = 4, u = 5,
  maxscore = 4, minscore = 0, cutscore = 4
))

## End(Not run)

</code></pre>

<hr>
<h2 id='LearningToLearn'>Dichotomous dataset of learning to learn test</h2><span id='topic+LearningToLearn'></span>

<h3>Description</h3>

<p><code>LearningToLearn</code> is a real longitudinal dataset used in Martinkova et al
(2020) study, demonstrating differential item functioning in change (DIF-C)
on Learning to Learn (LtL) test. Among other variables, it primarily contains
binary-coded responses of 782 subjects to (mostly) multiple-choice test
consisting of 41 items within 7 subscales (see <strong>Format</strong> for details). Each
respondent was tested twice in total &ndash; the first time in Grade 6 and the
second time in Grade 9. Most importantly, school track (variable <code>track_01</code>
or <code>track</code>) is available, with 391 students attending basic school (BS) and
391 pursuing selective academic school (AS). This dataset was created using
propensity score matching algorithm to achieve similar characteristics in
both tracks (see <strong>References</strong> for details). To further simplify the work
with <code>LtL</code> dataset, we provide computed total scores as well as 7 subscores,
both for Grade 6 and Grade 9. The dataset also includes <em>change</em> variables
for each item (see <strong>Format</strong> for details) for more detailed DIF-C analysis
using multinomial regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LearningToLearn
</code></pre>


<h3>Format</h3>

<p>A <code>LearningToLearn</code> data frame consists of 782 observations on the following 141 variables:
</p>

<dl>
<dt>track_01</dt><dd><p>Dichotomously scored school track, where <code>"1"</code> denotes the selective academic school one. </p>
</dd>
<dt>track</dt><dd><p>School track, where <code>"AS"</code> represents the selective academic school track, and <code>"BS"</code> stands
for basic school track. </p>
</dd>
<dt>score_6 &amp; score_9</dt><dd><p>Total test score value obtained by summing all 41 items of <code>LtL</code>, the number denotes
the Grade which the respondent was taking at the time of testing. </p>
</dd>
<dt>score_6_subtest1&ndash;score_6_subtest7</dt><dd><p>Scores of respective cognitive subtest (1&ndash;7) of <code>LtL</code> in Grade 6. </p>
</dd>
<dt>score_9_subtest1&ndash;score_9_subtest7</dt><dd><p>Scores of respective cognitive subtest (1&ndash;7) of <code>LtL</code> in Grade 9. </p>
</dd>
<dt>Item1A_6&ndash;Item7F_6</dt><dd><p>Dichotomously coded 41 individual items obtained at Grade 6, <code>"1"</code> represents
the correct answer to the particular item. </p>
</dd>
<dt>Item1A_9&ndash;Item7F_9</dt><dd><p>Dichotomously coded 41 individual items obtained at Grade 9, <code>"1"</code> represents
the correct answer to the particular item. </p>
</dd>
<dt>Item1A_changes&ndash;Item7F_changes</dt><dd><p>Change patterns with those possible values:
</p>

<ul>
<li><p> a student responded correctly in neither Grade 6 nor in Grade 9 (did not improve, <code>"00"</code>)
</p>
</li>
<li><p> a student responded correctly in Grade 6 but not in Grade 9 (deteriorated, <code>"10"</code>)
</p>
</li>
<li><p> a student did not respond correctly in Grade 6 but responded correctly in Grade 9 (improved, <code>"01"</code>), and
</p>
</li>
<li><p> a student responded correctly in both grades (did not deteriorate, <code>"11"</code>)</p>
</li></ul>

</dd>
</dl>



<h3>Source</h3>

<p>Martinkova, P., Hladka, A., &amp; Potuznikova, E. (2020). Is academic
tracking related to gains in learning competence? Using propensity score
matching and differential item change functioning analysis for better
understanding of tracking implications. <em>Learning and Instruction</em>, <em>66</em>,
101286. <a href="https://doi.org/10.1016/j.learninstruc.2019.101286">doi:10.1016/j.learninstruc.2019.101286</a>
</p>

<hr>
<h2 id='MSATB'>Dichotomous dataset of Medical School Admission Test in Biology.</h2><span id='topic+MSATB'></span>

<h3>Description</h3>

<p>The <code>MSATB</code> dataset consists of the responses of 1,407 subjects
(484 males, 923 females) to admission test to medical school in the Czech republic.
It contains 20 selected items from original test while first item was previously detected
as differently functioning (Vlckova, 2014). A correct answer is coded as 1 and incorrect
answer as 0. The column <code>gender</code> represents gender of students, where 0 indicates
males (reference group) and 1 indicates females (focal group).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSATB
</code></pre>


<h3>Format</h3>

<p>A <code>MSATB</code> data frame consists of 1,407 observations on the following 21 variables:
</p>

<dl>
<dt>Item</dt><dd><p>dichotomously scored items of the test</p>
</dd>
<dt>gender</dt><dd><p>gender of respondents, <code>"0"</code> males, <code>"1"</code> females</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Adela Hladka (nee Drabinova) <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
Faculty of Mathematics and Physics, Charles University <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a> <br />
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>Source</h3>

<p>Reexport from <code>difNLR</code> package.
</p>


<h3>References</h3>

<p>Drabinova, A. &amp; Martinkova, P. (2017). Detection of differential item functioning with nonlinear regression:
A non-IRT approach accounting for guessing. Journal of Educational Measurement, 54(4), 498&ndash;517,
<a href="https://doi.org/10.1111/jedm.12158">doi:10.1111/jedm.12158</a>.
</p>
<p>Vlckova, K. (2014). Test and item fairness. Master's thesis. Faculty of Mathematics and Physics, Charles University.
</p>

<hr>
<h2 id='MSclinical'>Clinical outcomes in multiple sclerosis patients dataset</h2><span id='topic+MSclinical'></span>

<h3>Description</h3>

<p>The <code>MSclinical</code> dataset contains clinical measures on multiple sclerosis patients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSclinical
</code></pre>


<h3>Format</h3>

<p><code>MSclinical</code> is a <code>data.frame</code> consisting of 17 observations on
13 variables.
</p>

<dl>
<dt>LCLA</dt><dd><p>Low-Contrast Letter Acuity test.  </p>
</dd>
<dt>MI</dt><dd><p>Motricity Index. </p>
</dd>
<dt>MAS</dt><dd><p>Modified Ashworth Scale. </p>
</dd>
<dt>BBS</dt><dd><p>Berg Balance Scale. </p>
</dd>
<dt>T</dt><dd><p>Tremor. </p>
</dd>
<dt>DD</dt><dd><p>Dysdiadochokinesia. </p>
</dd>
<dt>DM</dt><dd><p>Dysmetria. </p>
</dd>
<dt>PRs</dt><dd><p>Postural reactions. </p>
</dd>
<dt>KH</dt><dd><p>Knee Hyperextension. </p>
</dd>
<dt>NHPT</dt><dd><p>Nine-Hole Peg Test. </p>
</dd>
<dt>T25FW</dt><dd><p>Timed 25-Foot Walk. </p>
</dd>
<dt>PASAT3</dt><dd><p>3-minute version of the Paced Auditory Serial Addition Test. </p>
</dd>
<dt>EDSS</dt><dd><p>Kurtzke Expanded Disability Status Scale. </p>
</dd>
</dl>



<h3>References</h3>

<p>Rasova, K., Martinkova, P., Vyskotova, J., &amp; Sedova, M. (2012).
Assessment set for evaluation of clinical outcomes in multiple sclerosis: Psychometric properties.
Patient related outcome measures, 3, 59. <a href="https://doi.org/10.2147/PROM.S32241">doi:10.2147/PROM.S32241</a>
</p>

<hr>
<h2 id='NIH'>NIH grant peer review scoring dataset</h2><span id='topic+NIH'></span>

<h3>Description</h3>

<p>The <code>NIH</code> dataset (Erosheva et al., 2020a) was sampled from
a full set of 54,740 R01 applications submitted by black and white
principal investigators (PIs) and reviewed by Center for Scientific
Review (CSR) of the National Institutes of Health (NIH) during council
years 2014&ndash;2016.
</p>
<p>It contains the original random sample of white applicants as generated by
Erosheva et al. (2020b) and a sample of 46 black applicants generated to
obtain the same ratio of white and black applicants as in the original
sample (for details, see Erosheva et al., 2021a). The dataset was used by
Erosheva et al. (2021b) to demonstrate issues of inter-rater reliability in
case of restricted samples.
</p>
<p>The available variables include preliminary criterion scores on
Significance, Investigator, Innovation, Approach, Environment and a
preliminary Overall Impact Score. Each of these criteria and the overall
score is scored on an integer scale from 1 (best) to 9 (worst). Besides the
preliminary criteria and Overall Impact Scores, the data include applicant
race, the structural covariates (PI ID, application ID, reviewer ID,
administering institute, IRG, and SRG), the matching variables &ndash; gender,
ethnicity (Hispanic/Latino or not), career stage, type of academic degree,
institution prestige (as reflected by the NIH funding bin), area of science
(as reflected by the IRG handling the application), application type (new
or renewal) and status (amended or not) &ndash; as well as the final overall
score. In addition, the file includes a study group ID variable that refers
to the Matched and Random subsets used in the original study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NIH
</code></pre>


<h3>Format</h3>

<p><code>NIH</code> is a <code>data.frame</code> consisting of 5802 observations on
27 variables.
</p>

<dl>
<dt>ID</dt><dd><p>Proposal ID. </p>
</dd>
<dt>Score</dt><dd><p>Preliminary Overall Impact score (1-9 integer scale, 1 best). </p>
</dd>
<dt>Significance, Investigator, Innovation, Approach, Environment </dt><dd>
<p>Preliminary Criterion Scores (1-9 integer scale, 1 best). </p>
</dd>
<dt>PIRace</dt><dd><p>Principal investigator's self-identified race; <code>"White"</code>
or <code>"Black"</code>. </p>
</dd>
<dt>PIID</dt><dd><p>Anonymized ID of principal investigator (PI). </p>
</dd>
<dt>PIGender</dt><dd><p>PI's gender membership; <code>"Male"</code> or <code>"Female"</code>. </p>
</dd>
<dt>PIEthn</dt><dd><p>PI's ethnicity; <code>"Hispanic/Latino"</code> or <code>"Non-Hispanic"</code>. </p>
</dd>
<dt>PICareerStage</dt><dd><p>PI's career stage; <code>"ESI"</code> Early Stage Investigator,
<code>"Experienced"</code> Experienced Investigator, or <code>"Non-ES NI"</code>
Non-Early Stage New Investigator. </p>
</dd>
<dt>PIDegree</dt><dd><p>PI's degree; <code>"PhD"</code>, <code>"MD"</code>, <code>"MD/PhD"</code>,
or <code>"Others"</code>. </p>
</dd>
<dt>PIInst</dt><dd><p>Lead PI's institution's FY 2014 total institution NIH funding;
5 bins with 1 being most-funded.</p>
</dd>
<dt>GroupID</dt><dd><p>Group ID. </p>
</dd>
<dt>RevID</dt><dd><p>Reviewer's ID. </p>
</dd>
<dt>IRG</dt><dd><p>IRG (Integrated Research Group) id. </p>
</dd>
<dt>AdminOrg</dt><dd><p>Administering Organization id. </p>
</dd>
<dt>SRG</dt><dd><p>SRG (Scientific Research Group) id. </p>
</dd>
<dt>PropType</dt><dd><p>Application type, <code>"New"</code> or <code>"Renewal"</code>. </p>
</dd>
<dt>Ammend</dt><dd><p>Ammend. Logical. </p>
</dd>
<dt>ScoreAvg</dt><dd><p>Average of the three overall scores from different reviewers. </p>
</dd>
<dt>ScoreAvgAdj</dt><dd><p>Average of the three overall scores from different reviewers, increased by multiple of 0.001 of the worst score. </p>
</dd>
<dt>ScoreRank</dt><dd><p>Project rank calculated based on <code>ScoreAvg</code>. </p>
</dd>
<dt>ScoreRankAdj</dt><dd><p>Project rank calculated based on <code>ScoreAvgAdj</code>. </p>
</dd>
<dt>ScoreFinalChar</dt><dd><p>Final Overall Impact score (1-9 integer scale, 1 best; <code>"ND"</code>
refers to &quot;not discussed&quot;)</p>
</dd>
<dt>ScoreFinal</dt><dd><p>Final Overall Impact score (1-9 integer scale, 1 best). </p>
</dd>
</dl>



<h3>References</h3>

<p>Erosheva, E. A., Grant, S., Chen, M.-C., Lindner, M. D., Nakamura, R. K., &amp;
Lee, C. J. (2020a). NIH peer review: Criterion scores completely account for
racial disparities in overall impact scores. Science Advances 6(23), eaaz4868,
<a href="https://doi.org/10.1126/sciadv.aaz4868">doi:10.1126/sciadv.aaz4868</a>
</p>
<p>Erosheva, E. A., Grant, S., Chen, M.-C., Lindner, M. D., Nakamura, R. K., &amp;
Lee, C. J. (2020b). Supplementary material: NIH peer review: Criterion scores
completely account for racial disparities in overall impact scores.
Science Advances 6(23), eaaz4868, <a href="https://doi.org/10.17605/OSF.IO/4D6RX">doi:10.17605/OSF.IO/4D6RX</a>
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. J. (2021a). Supplementary material:
When zero may not be zero: A cautionary note on the use of inter-rater
reliability in evaluating grant peer review.
</p>
<p>Erosheva, E., Martinkova, P., &amp; Lee, C. J. (2021b). When zero may not be zero: A
cautionary note on the use of inter-rater reliability in evaluating grant
peer review. Journal of the Royal Statistical Society &ndash; Series A. Accepted.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ICCrestricted">ICCrestricted()</a></code>
</p>

<hr>
<h2 id='nominal_to_int'>Turn nominal (factor) data to integers, keep original levels with a key of
correct responses alongside</h2><span id='topic+nominal_to_int'></span>

<h3>Description</h3>

<p>Convert a <code>data.frame</code> or <code>tibble</code> with factor variables (items) to integers,
keeping the original factor levels (i.e. response categories) and correct
answers (stored as an <code>key</code> attribute of each item) alongside.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nominal_to_int(Data, key)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nominal_to_int_+3A_data">Data</code></td>
<td>
<p><em>data.frame</em> or <em>tibble</em> with all columns being factors. Support
for <em>matrix</em> is limited and behavior not guaranteed.</p>
</td></tr>
<tr><td><code id="nominal_to_int_+3A_key">key</code></td>
<td>
<p>A single-column <code>data.frame</code>, (<strong>not</strong> matrix) <code>tibble</code> or -
preferably - a factor vector of levels considered as correct responses.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fitting a nominal model using <code><a href="mirt.html#topic+mirt">mirt::mirt()</a></code> package requires the dataset to
consist only of integers, <em>arbitrarily</em> representing the response categories.
You can convert your dataset to integers on your own in that case.
</p>
<p>On the other hand, BLIS model (and thus also the BLIRT parametrization)
further requires the information of correct item response category. On top of
that, the same information is leveraged when fitting a <code>mirt</code> model that
conserves the &quot;directionality&quot; of estimated latent ability (using a model
definition from <code><a href="#topic+obtain_nrm_def">obtain_nrm_def()</a></code>). In these cases, you are recommended to
use <code><a href="#topic+nominal_to_int">nominal_to_int()</a></code> (note that <code><a href="#topic+fit_blis">fit_blis()</a></code> and <code><a href="#topic+blis">blis()</a></code> does this
internally). Note also that fitted BLIS model (of class <a href="#topic+BlisClass-class">BlisClass</a>) stores
the original levels with correct answer key in its <code>orig_levels</code> slot,
accessible by a user via <code><a href="#topic+get_orig_levels">get_orig_levels()</a></code>.
</p>


<h3>Value</h3>

<p><em>List</em> of original levels with logical attribute <code>key</code>, which stores
the information on which response (level) is considered  correct. <em>Note
that levels not used in the original data are dropped.</em>
</p>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+BlisClass-class">BlisClass-class</a></code>,
<code><a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a></code>,
<code><a href="#topic+fit_blis">fit_blis</a>()</code>,
<code><a href="#topic+get_orig_levels">get_orig_levels</a>()</code>,
<code><a href="#topic+obtain_nrm_def">obtain_nrm_def</a>()</code>,
<code><a href="#topic+print.blis_coefs">print.blis_coefs</a>()</code>
</p>

<hr>
<h2 id='obtain_nrm_def'>Obtain model definition for <code>mirt</code>'s nominal model taking in account the key
of correct answers</h2><span id='topic+obtain_nrm_def'></span>

<h3>Description</h3>

<p>Standard <code>mirt</code> model with <code>itemtype = "nominal"</code> puts the
identification constrains on the item response category slopes such as
<code class="reqn">ak_0 = 0</code> and <code class="reqn">ak_{(K-1)} = (K - 1)</code>, freely estimating the rest.
</p>
<p>While nominal item responses are unordered by definition, it is often the
case that one of the item response categories is correct and the
respondents endorsing this category &quot;naturally&quot; possess a higher latent
ability. Use this function to obtain model definition where the correct
response category <code class="reqn">k_c</code> for item <code class="reqn">i</code> with <code class="reqn">K</code> possible response
categories translates to constrains <code class="reqn">ak_{k_c} = (K - 1)</code> and
<code class="reqn">ak_{k_{d1}} = 0</code>, with <code class="reqn">k_{d1}</code> being the first incorrect response
category (i.e. the first distractor).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obtain_nrm_def(data_with_key, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="obtain_nrm_def_+3A_data_with_key">data_with_key</code></td>
<td>
<p>The output of <code>nominal_to_int()</code>.</p>
</td></tr>
<tr><td><code id="obtain_nrm_def_+3A_...">...</code></td>
<td>
<p>arguments passed onto <code>mirt::mirt()</code>. No practical use for now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> with the starting values, parameter numbers,
estimation constrains etc. Pass it as <code>pars</code> argument of <code><a href="mirt.html#topic+mirt">mirt::mirt()</a></code>.
</p>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+BlisClass-class">BlisClass-class</a></code>,
<code><a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a></code>,
<code><a href="#topic+fit_blis">fit_blis</a>()</code>,
<code><a href="#topic+get_orig_levels">get_orig_levels</a>()</code>,
<code><a href="#topic+nominal_to_int">nominal_to_int</a>()</code>,
<code><a href="#topic+print.blis_coefs">print.blis_coefs</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(mirt)

# convert nominal data to integers and the original labels with correct answers
data_with_key &lt;- nominal_to_int(HCItest[, 1:20], HCIkey)

# build model definition for {mirt} using the returned list from above
nrm_def &lt;- obtain_nrm_def(data_with_key)

# fit the nominal model using the obtained model definition in `pars` argument
fit &lt;- mirt(data_with_key$Data, 1, "nominal", pars = nrm_def)
</code></pre>

<hr>
<h2 id='plot_corr'>Compute and plot an item correlation matrix</h2><span id='topic+plot_corr'></span>

<h3>Description</h3>

<p>Computes and visualizes an item correlation matrix (also known as a heatmap),
offering several correlation &quot;types&quot; and optional clustering (with possible
cluster outlining). The function relies on <code><a href="ggplot2.html#topic+ggplot">ggplot2::ggplot()</a></code>, providing a
high customisability using &quot;the grammar of graphics&quot; (see the examples
below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_corr(
  Data,
  cor = c("polychoric", "tetrachoric", "pearson", "spearman", "none"),
  clust_method = "none",
  n_clust = 0L,
  shape = c("circle", "square"),
  labels = FALSE,
  labels_size = 3,
  line_size = 0.5,
  line_col = "black",
  line_alpha = 1,
  fill = NA,
  fill_alpha = NA,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_corr_+3A_data">Data</code></td>
<td>
<p><code>matrix</code>, <code>data.frame</code> or <code>tibble</code>: either a
<code>data.frame</code> with scored items (as columns, one observation per row),
or a correlation matrix.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_cor">cor</code></td>
<td>
<p>character: correlation &quot;type&quot; used to correlation matrix
computation; available options are <code>polychoric</code>, <code>tetrachoric</code>,
<code>pearson</code>, <code>spearman</code>, or <code>none</code> (in case you provide
the correlation matrix as <code>Data</code>).</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_clust_method">clust_method</code></td>
<td>
<p>character: optional clustering method, available options
are: <code>ward.D</code>, <code>ward.D2</code>, <code>single</code>, <code>complete</code>,
<code>average</code> (= UPGMA), <code>mcquitty</code> (= WPGMA), <code>median</code> (=
WPGMC), <code>centroid</code> (= UPGMC) or <code>none</code> (clustering disabled).
See <code><a href="stats.html#topic+hclust">hclust()</a></code> for a detailed description of available options.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_n_clust">n_clust</code></td>
<td>
<p>integer: the number of clusters you want to be outlined. When
set to zero (the default), no cluster are outlined, but items still do get
sorted according to <code>clust_method</code> (if not set to <code>none</code>).</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_shape">shape</code></td>
<td>
<p>character: tile appearance; either <code>circle</code> (default) to
map the correlation coefficient to circle size and color, or <code>square</code>
to draw square-shaped tiles with only shade denoting the coefficient
magnitude. You can use an unambiguous abbreviation of the two.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_labels">labels</code></td>
<td>
<p>logical: when <code>TRUE</code>, the correlation coefficients are
plotted onto tiles.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_labels_size">labels_size</code></td>
<td>
<p>numeric: label size in points (pts).</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_line_size">line_size</code></td>
<td>
<p>numeric: cluster outline width.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_line_col">line_col</code></td>
<td>
<p>character: color of the outline, either a HEX code (e.g.
&quot;#123456&quot;), or one of <code>R</code>'s standard colors (see the
<code><a href="grDevices.html#topic+colors">colors()</a></code>).</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_line_alpha">line_alpha</code></td>
<td>
<p>numeric 0-1: the opacity of the outline.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_fill">fill</code></td>
<td>
<p>character: the color used to fill the outlined clusters.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_fill_alpha">fill_alpha</code></td>
<td>
<p>numeric 0&ndash;1: the opacity of the fill color.</p>
</td></tr>
<tr><td><code id="plot_corr_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="psych.html#topic+tetrachor">psych::polychoric</a></code>
</p>

<dl>
<dt><code>correct</code></dt><dd><p>Correction value to use to correct for continuity in the case of zero entry cell for tetrachoric, polychoric, polybi, and mixed.cor.  See the examples for the effect of correcting versus not correcting for continuity.</p>
</dd>
<dt><code>smooth</code></dt><dd><p>if TRUE and if the tetrachoric/polychoric matrix is not positive definite, then apply a simple smoothing algorithm using cor.smooth</p>
</dd>
<dt><code>global</code></dt><dd><p>When finding pairwise correlations, should we use the global values of the tau parameter (which is somewhat faster), or the local values (global=FALSE)?  The local option is equivalent to the polycor solution, or to doing one correlation at a time. global=TRUE borrows information for one item pair from the other pairs using those item's frequencies.   This will make a difference in the presence of lots of missing data. With very small sample sizes with global=FALSE and correct=TRUE, the function will fail (for as yet underdetermined reasons. </p>
</dd>
<dt><code>weight</code></dt><dd><p>A vector of length of the number of observations that specifies the weights to apply to each case.  The NULL case is equivalent of weights of 1 for all cases.  </p>
</dd>
<dt><code>std.err</code></dt><dd><p>std.err=FALSE does not report the standard errors (faster)  deprecated</p>
</dd>
<dt><code>progress</code></dt><dd><p>Show the progress bar (if  not doing multicores)</p>
</dd>
<dt><code>ML</code></dt><dd><p> ML=FALSE  do a quick two step procedure, ML=TRUE, do longer maximum likelihood &mdash; very slow! Deprecated</p>
</dd>
<dt><code>delete</code></dt><dd><p>Cases with no variance are deleted with a warning before proceeding.</p>
</dd>
<dt><code>max.cat</code></dt><dd><p>The maximum number of categories to bother with for polychoric.  </p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>Correlation heatmap displays selected type of correlations between items. The
color of tiles indicates how much and in which way the items are correlated
&ndash; red color means positive correlation and blue color means negative
correlation. Correlation heatmap can be reordered using hierarchical
clustering method specified with <code>clust_method</code> argument. When the desired
number of clusters (argument <code>n_clust</code>) is not zero and some clustering is
demanded, the rectangles outlining the found clusters are drawn.
</p>


<h3>Value</h3>

<p>An object of class <code>ggplot</code> and/or <code>gg</code>.
</p>


<h3>Author(s)</h3>

<p>Jan Netik <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># use first 20 columns from HCI dataset (the remainder are not items)
HCI &lt;- HCI[, 1:20]

# use Pearson product-moment correlation coefficient for matrix computation
plot_corr(HCI, cor = "pearson")

## Not run: 
# use tetrachoric correlation and reorder the resulting heatmap
# using Ward's method
HCI |&gt; plot_corr(cor = "tetrachoric", clust_method = "ward.D")

# outline 3 Ward's clusters with bold yellow line and add labels
HCI |&gt;
  plot_corr(
    n_clust = 3, clust_method = "ward.D2", line_col = "yellow",
    line_size = 1.5, labels = TRUE
  )

# add title and position the legend below the plot
library(ggplot2)
HCI |&gt;
  plot_corr(n_clust = 3) +
  ggtitle("HCI heatmap") +
  theme(legend.position = "bottom")

# mimic the look of corrplot package
plot_corr(HCI, cor = "polychoric", clust_method = "complete", shape = "square") +
  scale_fill_gradient2(
    limits = c(-.1, 1),
    breaks = seq(-.1, 1, length.out = 12),
    guide = guide_colorbar(
      barheight = .8, barwidth = .0275,
      default.unit = "npc",
      title = NULL, frame.colour = "black", ticks.colour = "black"
    )
  ) +
  theme(axis.text = element_text(colour = "red", size = 12))

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.sia_parallel'>Plot Method for Parallel Analysis Output</h2><span id='topic+plot.sia_parallel'></span>

<h3>Description</h3>

<p>You can call this method to plot an existing object resulting from
<code>fa_paralell()</code> function, which behaves as a standard <code>data.frame</code>,
but can be automatically recognized and processed with a dedicated plot
method. Also, you can <em>post-hoc</em> disable the Kaiser boundaries shown by
default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sia_parallel'
plot(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.sia_parallel_+3A_x">x</code></td>
<td>
<p>object of class <code>sia_parallel</code> to plot.</p>
</td></tr>
<tr><td><code id="plot.sia_parallel_+3A_y">y</code></td>
<td>
<p><em>ignored</em></p>
</td></tr>
<tr><td><code id="plot.sia_parallel_+3A_...">...</code></td>
<td>
<p>additional argument:
</p>
<dl>
<dt><code>show_kaiser</code></dt><dd><p><em>logical</em>, whether to show
horizonal lines denoting Kaiser boundaries (eigenvalue 0 and/or 1 for FA
and/or PCA, respectively). Defaults to <code>TRUE</code>.</p>
</dd></dl>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fa_parallel_result &lt;- BFI2[, 1:60] |&gt; fa_parallel(plot = FALSE) # without plot
fa_parallel_result |&gt; plot() # generate plot from "fitted" object
fa_parallel_result |&gt; plot(show_kaiser = FALSE) # hide Kaiser boundaries

## End(Not run)

</code></pre>

<hr>
<h2 id='plotAdjacent'>Plot category probabilities of adjacent category logit model</h2><span id='topic+plotAdjacent'></span>

<h3>Description</h3>

<p>Function for plotting category probabilities function estimated
by <code>vglm()</code> function from the <code>VGAM</code> package using the
<span class="pkg">ggplot2</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotAdjacent(x, matching.name = "matching")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotAdjacent_+3A_x">x</code></td>
<td>
<p>object of class <code>vglm</code></p>
</td></tr>
<tr><td><code id="plotAdjacent_+3A_matching.name">matching.name</code></td>
<td>
<p>character: name of matching criterion used for
estimation in <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ggplot</code> and/or <code>gg</code>.
</p>


<h3>Author(s)</h3>

<p>Tomas Jurica <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
</p>
<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>See Also</h3>

<p><code><a href="VGAM.html#topic+vglm">VGAM::vglm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># loading packages
library(VGAM)

# loading data
data(Science, package = "mirt")

# total score calculation
score &lt;- rowSums(Science)
Science[, 1] &lt;- factor(Science[, 1], levels = sort(unique(Science[, 1])), ordered = TRUE)

# adjacent category logit model for item 1
fit &lt;- vglm(Science[, 1] ~ score, family = acat(reverse = FALSE, parallel = TRUE))
# coefficients for item 1
coef(fit)

plotAdjacent(fit, matching.name = "Total score")
</code></pre>

<hr>
<h2 id='plotCumulative'>Plot cumulative and category probabilities of cumulative logit model</h2><span id='topic+plotCumulative'></span>

<h3>Description</h3>

<p>Function for plotting cumulative and category probabilities
function estimated by <code>vglm()</code> function from the <code>VGAM</code> package
using the <span class="pkg">ggplot2</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotCumulative(x, type = "cumulative", matching.name = "matching")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotCumulative_+3A_x">x</code></td>
<td>
<p>object of class <code>vglm</code></p>
</td></tr>
<tr><td><code id="plotCumulative_+3A_type">type</code></td>
<td>
<p>character: type of plot to be displayed. Options are
<code>"cumulative"</code> (default) for cumulative probabilities and
<code>"category"</code> for category probabilities.</p>
</td></tr>
<tr><td><code id="plotCumulative_+3A_matching.name">matching.name</code></td>
<td>
<p>character: name of matching criterion used for
estimation in <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ggplot</code> and/or <code>gg</code>.
</p>


<h3>Author(s)</h3>

<p>Tomas Jurica <br /> Institute of Computer Science of the Czech Academy
of Sciences <br />
</p>
<p>Adela Hladka <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a> <br />
</p>
<p>Patricia Martinkova <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="VGAM.html#topic+vglm">VGAM::vglm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># loading packages
library(VGAM)

# loading data
data(Science, package = "mirt")

# total score calculation
score &lt;- rowSums(Science)
Science[, 1] &lt;- factor(Science[, 1], levels = sort(unique(Science[, 1])), ordered = TRUE)

# cumulative logit model for item 1
fit &lt;- vglm(Science[, 1] ~ score, family = cumulative(reverse = TRUE, parallel = TRUE))
# coefficients for item 1
coef(fit)

plotCumulative(fit, type = "cumulative", matching.name = "Total score")
plotCumulative(fit, type = "category", matching.name = "Total score")

</code></pre>

<hr>
<h2 id='plotDIFirt'>Plot item characteristic curve of DIF IRT model</h2><span id='topic+plotDIFirt'></span>

<h3>Description</h3>

<p>Plots characteristic curve of IRT model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDIFirt(
  parameters,
  test = "Lord",
  item = "all",
  item.name,
  same.scale = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDIFirt_+3A_parameters">parameters</code></td>
<td>
<p>numeric: data matrix or data frame. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFirt_+3A_test">test</code></td>
<td>
<p>character: type of statistic to be shown. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFirt_+3A_item">item</code></td>
<td>
<p>either character (&quot;all&quot;), or numeric vector, or single number
corresponding to column indicators. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFirt_+3A_item.name">item.name</code></td>
<td>
<p>character: the name of item.</p>
</td></tr>
<tr><td><code id="plotDIFirt_+3A_same.scale">same.scale</code></td>
<td>
<p>logical: are the item <code>parameters</code> on the same scale?
(default is &quot;FALSE&quot;). See <strong>Details</strong>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots characteristic curve of DIF IRT model.
</p>
<p>The <code>parameters</code> matrix has a number of rows equal to twice the number
of items in the data set. The first J rows refer to the item parameter
estimates in the reference group, while the last J ones correspond to the
same items in the focal group. The number of columns depends on the selected
IRT model: 2 for the 1PL model, 5 for the 2PL model, 6 for the constrained
3PL model and 9 for the unconstrained 3PL model. The columns of
<code>irtParam()</code> have to follow the same structure as the output of
<code>itemParEst()</code>, <code>difLord()</code> or <code>difRaju()</code> command from the
<code>difR</code> package.
</p>
<p>Two possible type of <code>test</code> statistics can be visualized - <code>"Lord"</code>
gives only characteristic curves, <code>"Raju"</code> also highlights area between
these curves.
</p>
<p>For default option <code>"all"</code>, all characteristic curves are plotted.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a> <br />
</p>
<p>Patricia Martinkova <br /> Institute of Computer Science of the Czech Academy of
Sciences <br /> <a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="difR.html#topic+itemParEst">difR::itemParEst()</a></code>, <code><a href="difR.html#topic+difLord">difR::difLord()</a></code>,
<code><a href="difR.html#topic+difRaju">difR::difRaju()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># loading libraries
library(difR)
library(ltm)

# loading data based on GMAT2
data(GMAT2, package = "difNLR")

# Estimation of 2PL IRT model and Lord's statistic
# by difR package
fitLord &lt;- difLord(GMAT2, group = 21, focal.name = 1, model = "2PL")
# plot of item 1 and Lord's statistic
plotDIFirt(fitLord$itemParInit, item = 1)

# Estimation of 2PL IRT model and Raju's statistic
# by difR package
fitRaju &lt;- difRaju(GMAT2, group = 21, focal.name = 1, model = "2PL")
# plot of item 1 and Lord's statistic
plotDIFirt(fitRaju$itemParInit, test = "Raju", item = 1)

</code></pre>

<hr>
<h2 id='plotDIFLogistic'>Function for characteristic curve of 2PL logistic DIF model</h2><span id='topic+plotDIFLogistic'></span>

<h3>Description</h3>

<p>Plots characteristic curve of 2PL logistic DIF model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDIFLogistic(x, item = 1, item.name, group.names = c("Reference",
  "Focal"), Data, group, match, draw.empirical = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDIFLogistic_+3A_x">x</code></td>
<td>
<p>an object of <code>"Logistic"</code> class. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_item">item</code></td>
<td>
<p>numeric: number of item to be plotted</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_item.name">item.name</code></td>
<td>
<p>character: the name of item to be used as title of plot.</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_group.names">group.names</code></td>
<td>
<p>character: names of reference and focal group.</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_data">Data</code></td>
<td>
<p>numeric: the data matrix. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_group">group</code></td>
<td>
<p>numeric: the vector of group membership. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_match">match</code></td>
<td>
<p>character or numeric: specifies observed score used for
matching. Can be either <code>"score"</code>, or numeric vector of the same
length as number of observations in <code>Data</code>. See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDIFLogistic_+3A_draw.empirical">draw.empirical</code></td>
<td>
<p>logical: whether empirical probabilities should be
calculated and plotted. Default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots characteristic curves of 2PL logistic DIF model
fitted by <code>difLogistic()</code> function from difR package using ggplot2.
</p>
<p><code>Data</code> and <code>group</code> are used to calculate empirical probabilities
for reference and focal group. <code>match</code> should be the same as in
<code>x$match</code>. In case that an observed score is used as a matching variable
instead of the total score or the standardized score, <code>match</code> needs to
be a numeric vector of the same the same length as the number of observations
in <code>Data</code>.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="difR.html#topic+difLogistic">difR::difLogistic()</a></code>, <code><a href="ggplot2.html#topic+ggplot">ggplot2::ggplot()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># loading libraries
library(difR)

# loading data based on GMAT
data(GMAT, package = "difNLR")
Data &lt;- GMAT[, 1:20]
group &lt;- GMAT[, 21]

# DIF detection using difLogistic() function
x &lt;- difLogistic(Data, group, focal.name = 1)
# Characteristic curve by logistic regression model
plotDIFLogistic(x, item = 1, Data = Data, group = group)

# Using name of column as item identifier
plotDIFLogistic(x, item = "Item1", Data = Data, group = group)

# Renaming reference and focal group
plotDIFLogistic(x, item = 1, group.names = c("Group 1", "Group 2"), Data = Data, group = group)

# Not plotting empirical probabilities
plotDIFLogistic(x, item = 1, draw.empirical = FALSE)
</code></pre>

<hr>
<h2 id='plotDistractorAnalysis'>Plot item distractor analysis</h2><span id='topic+plotDistractorAnalysis'></span>

<h3>Description</h3>

<p>Plots graphical representation of item distractor
analysis with proportions and optional number of groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotDistractorAnalysis(
  Data,
  key,
  num.groups = 3,
  item = 1,
  item.name,
  multiple.answers = TRUE,
  criterion = NULL,
  crit.discrete = FALSE,
  cut.points,
  data,
  matching,
  match.discrete
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotDistractorAnalysis_+3A_data">Data</code></td>
<td>
<p>character: data matrix or data.frame with rows
representing unscored item response from a multiple-choice test
and columns corresponding to the items.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_key">key</code></td>
<td>
<p>character: answer key for the items. The <code>key</code> must be a
vector of the same length as <code>ncol(Data)</code>. In case it is not
provided, <code>criterion</code> needs to be specified.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_num.groups">num.groups</code></td>
<td>
<p>numeric: number of groups to which are the
respondents splitted.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_item">item</code></td>
<td>
<p>numeric: the number of the item to be plotted.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_item.name">item.name</code></td>
<td>
<p>character: the name of the item.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_multiple.answers">multiple.answers</code></td>
<td>
<p>logical: should be all combinations plotted
(default) or should be answers splitted into distractors. See
<strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_criterion">criterion</code></td>
<td>
<p>numeric: numeric vector. If not provided, total
score is calculated and distractor analysis is performed based on
it.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_crit.discrete">crit.discrete</code></td>
<td>
<p>logical: is <code>criterion</code> discrete? Default
value is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_cut.points">cut.points</code></td>
<td>
<p>numeric: numeric vector specifying cut points of
<code>criterion</code>.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_data">data</code></td>
<td>
<p>deprecated. Use argument <code>Data</code> instead.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_matching">matching</code></td>
<td>
<p>deprecated. Use argument <code>criterion</code> instead.</p>
</td></tr>
<tr><td><code id="plotDistractorAnalysis_+3A_match.discrete">match.discrete</code></td>
<td>
<p>deprecated. Use argument <code>crit.discrete</code>
instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a graphical representation of the
<code><a href="#topic+DistractorAnalysis">DistractorAnalysis()</a></code> function. In case that no <code>criterion</code> is
provided, the scores are calculated using the item <code>Data</code> and
<code>key</code>. The respondents are by default split into the
<code>num.groups</code>-quantiles and the proportions of respondents in each
quantile are displayed with respect to their answers. In case
that <code>criterion</code> is discrete (<code>crit.discrete = TRUE</code>),
<code>criterion</code> is split based on its unique levels. Other cut points
can be specified via <code>cut.points</code> argument.
</p>
<p>If <code>multiple.answers = TRUE</code> (default) all reported combinations
of answers are plotted. If <code>multiple.answers = FALSE</code> all
combinations are split into distractors and only these are then
plotted with correct combination.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DistractorAnalysis">DistractorAnalysis()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Data &lt;- dataMedicaltest[, 1:100]
DataBin &lt;- dataMedical[, 1:100]
key &lt;- dataMedicalkey

# distractor plot for items 48, 57 and 32 displaying distractors only
# correct answer B does not function well:
plotDistractorAnalysis(Data, key, item = 48, multiple.answers = FALSE)

# all options function well, thus the whole item discriminates well:
plotDistractorAnalysis(Data, key, item = 57, multiple.answers = FALSE)

# functions well, thus the whole item discriminates well:
plotDistractorAnalysis(Data, key, item = 32, multiple.answers = FALSE)

## Not run: 
# distractor plot for items 48, 57 and 32 displaying all combinations
plotDistractorAnalysis(Data, key, item = c(48, 57, 32))

# distractor plot for item 57 with all combinations and 6 groups
plotDistractorAnalysis(Data, key, item = 57, num.group = 6)

# distractor plot for item 57 using specified criterion and key option
criterion &lt;- round(rowSums(DataBin), -1)
plotDistractorAnalysis(Data, key, item = 57, criterion = criterion)
# distractor plot for item 57 using specified criterion without key option
plotDistractorAnalysis(Data, item = 57, criterion = criterion)

# distractor plot for item 57 using discrete criterion
plotDistractorAnalysis(Data, key,
  item = 57, criterion = criterion,
  crit.discrete = TRUE
)

# distractor plot for item 57 using groups specified by cut.points
plotDistractorAnalysis(Data, key, item = 57, cut.points = seq(10, 96, 10))

## End(Not run)

</code></pre>

<hr>
<h2 id='plotMultinomial'>Plot category probabilities of multinomial model</h2><span id='topic+plotMultinomial'></span>

<h3>Description</h3>

<p>Plots category probabilities functions estimated by
<code>multinom()</code> from the <code>nnet</code> package using the <span class="pkg">ggplot2</span>
package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotMultinomial(x, matching, matching.name = "matching")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotMultinomial_+3A_x">x</code></td>
<td>
<p>object of class <code>multinom</code></p>
</td></tr>
<tr><td><code id="plotMultinomial_+3A_matching">matching</code></td>
<td>
<p>numeric: vector of matching criterion used for estimation in
<code>x</code>.</p>
</td></tr>
<tr><td><code id="plotMultinomial_+3A_matching.name">matching.name</code></td>
<td>
<p>character: name of matching criterion used for
estimation in <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ggplot</code> and/or <code>gg</code>.
</p>


<h3>Author(s)</h3>

<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Tomas Jurica <br />
Institute of Computer Science of the Czech Academy of Sciences
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+multinom">nnet::multinom()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># loading data
data(GMAT, GMATtest, GMATkey, package = "difNLR")

matching &lt;- scale(rowSums(GMAT[, 1:20])) # Z-score

# multinomial model for item 1
fit &lt;- nnet::multinom(relevel(GMATtest[, 1], ref = paste(GMATkey[1])) ~ matching)

# plotting category probabilities
plotMultinomial(fit, matching, matching.name = "Z-score")

</code></pre>

<hr>
<h2 id='print.blis_coefs'>Print method for BLIS coefficients</h2><span id='topic+print.blis_coefs'></span>

<h3>Description</h3>

<p>Print method for BLIS coefficients
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blis_coefs'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.blis_coefs_+3A_x">x</code></td>
<td>
<p>result of <code>coef()</code>.</p>
</td></tr>
<tr><td><code id="print.blis_coefs_+3A_digits">digits</code></td>
<td>
<p><em>integer</em>, number of digits to show in the output. Note that
printed object are still an original list, which does not round any value
(it is returned invisibly).</p>
</td></tr>
<tr><td><code id="print.blis_coefs_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to <code>print()</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other BLIS/BLIRT related: 
<code><a href="#topic+BlisClass-class">BlisClass-class</a></code>,
<code><a href="#topic+coef+2CBlisClass-method">coef,BlisClass-method</a></code>,
<code><a href="#topic+fit_blis">fit_blis</a>()</code>,
<code><a href="#topic+get_orig_levels">get_orig_levels</a>()</code>,
<code><a href="#topic+nominal_to_int">nominal_to_int</a>()</code>,
<code><a href="#topic+obtain_nrm_def">obtain_nrm_def</a>()</code>
</p>

<hr>
<h2 id='recode_nr'>Recognize and recode not-reached responses</h2><span id='topic+recode_nr'></span>

<h3>Description</h3>

<p><code>recode_nr()</code> function recognizes and recodes not-reached
responses, i.e., missing responses to items such that all subsequent
items are missed as well by the respondent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recode_nr(Data, nr_code = 99, df)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="recode_nr_+3A_data">Data</code></td>
<td>
<p>matrix or data.frame: object to be recoded, must include only
items columns and no additional information</p>
</td></tr>
<tr><td><code id="recode_nr_+3A_nr_code">nr_code</code></td>
<td>
<p>single character, integer or numeric: specifying how should be
recognized not-reached responses coded (default is <code>99</code>)</p>
</td></tr>
<tr><td><code id="recode_nr_+3A_df">df</code></td>
<td>
<p>deprecated. Use argument <code>Data</code> instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> object.
</p>


<h3>Author(s)</h3>

<p>Jan Netik <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>
<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ItemAnalysis">ItemAnalysis()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>HCImissed &lt;- HCI[, 1:20]

# simulate skipped (missed) and not-reached items in HCI dataset
set.seed(4211)
for (i in 1:150) {
  # not-reached (minimum at 10th item, maximum at 20th)
  HCImissed[sample(1:nrow(HCImissed), 1), seq(sample(10:20, 1), 20)] &lt;- NA

  # missed with random location
  HCImissed[sample(1:nrow(HCImissed), 1), sample(1:20, 1)] &lt;- NA
}

summary(HCImissed)

HCImissedNR &lt;- recode_nr(HCImissed, nr_code = 99)
head(HCImissedNR)
summary(HCImissedNR)
</code></pre>

<hr>
<h2 id='remove_empty_cols'>Remove columns that are empty</h2><span id='topic+remove_empty_cols'></span>

<h3>Description</h3>

<p>Remove columns that are empty
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_empty_cols(.data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="remove_empty_cols_+3A_.data">.data</code></td>
<td>
<p>data.frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>cleaned df
</p>

<hr>
<h2 id='ShinyItemAnalysis_options'>Options consulted by ShinyItemAnalysis</h2><span id='topic+ShinyItemAnalysis_options'></span>

<h3>Description</h3>

<p>The package and interactive <code>{shiny}</code> app consult several options that you
can easily set via <code><a href="base.html#topic+options">options()</a></code>. Moreover, there is some behavior that can be
changed through environment variables.
</p>


<h3>Options</h3>

<p>Options are set with <code style="white-space: pre;">&#8288;options(&lt;option&gt; = &lt;value&gt;)&#8288;</code>.
</p>

<ul>
<li> <p><code>sia.disable_modules</code>: You can completely disable SIA modules by setting
this to <code>TRUE</code>.
</p>
</li>
<li> <p><code>sia.modules_repo</code>: This is the URL for a CRAN-like repository that the app
uses to retrieve information about available module packages.
</p>
</li>
<li> <p><code>sia.offer_modules</code>: If set to <code>TRUE</code> (the default), calling <code>run_app()</code>
will check for the available SIA modules on the official repository and offer
to install those module packages that are not installed yet.
</p>
</li></ul>



<h3>Environment variables</h3>

<p>You can set this variable system-wide or use <code>R</code> or project-wise <code>.Renviron</code>
file. For more details, please navigate to <a href="base.html#topic+Startup">the R documentation</a>.
</p>

<ul>
<li> <p><code>SIA_MODULES_DEBUG</code>: Setting this to <code>TRUE</code> provides a verbose description
of SIA modules-related processes. Useful only for debugging purposes.
</p>
</li>
<li> <p><code>SIA_MODULES_FORCE_GUI_INSTALLATION</code>: When the app is running on
shiny-server, interactive module installation within the app is not allowed
by default. Setting this variable to <code>TRUE</code> will override this restriction
and enable module installation in the app.
</p>
</li></ul>


<hr>
<h2 id='startShinyItemAnalysis'>Start ShinyItemAnalysis application</h2><span id='topic+startShinyItemAnalysis'></span><span id='topic+run_app'></span>

<h3>Description</h3>

<p>An interactive shiny application to run test and item analysis. By default,
the function runs the application as a background process (&quot;Jobs&quot; tab in the
&quot;RStudio&quot; IDE). User is then free to use the <code>R</code> Console for other work
and to try the sample R code examples. You can still run the app the usual
way in the console by specifying <code>background = FALSE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>startShinyItemAnalysis(background = TRUE, ...)

run_app(background = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="startShinyItemAnalysis_+3A_background">background</code></td>
<td>
<p><em>logical</em>, should the application be run as a
background process (in the 'RStudio')?</p>
</td></tr>
<tr><td><code id="startShinyItemAnalysis_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="utils.html#topic+install.packages">utils::install.packages</a></code>
</p>

<dl>
<dt><code>lib</code></dt><dd>
<p>character vector giving the library directories where to
install the packages.  Recycled as needed.  If missing, defaults to
the first element of <code><a href="base.html#topic+.libPaths">.libPaths</a>()</code>.
</p>
</dd>
<dt><code>repos</code></dt><dd>
<p>character vector, the base URL(s) of the repositories
to use, e.g., the URL of a CRAN mirror such as
<code>"https://cloud.r-project.org"</code>.  For more details on
supported URL schemes see <code><a href="base.html#topic+url">url</a></code>.
</p>
<p>Can be <code>NULL</code> to install from local files, directories or URLs:
this will be inferred by extension from <code>pkgs</code> if of length one.
</p>
</dd>
<dt><code>contriburl</code></dt><dd>
<p>URL(s) of the contrib sections of the repositories.  Use this
argument if your repository mirror is incomplete, e.g., because
you mirrored only the &lsquo;<span class="file">contrib</span>&rsquo; section, or only have
binary packages.  Overrides argument <code>repos</code>.
Incompatible with <code>type = "both"</code>.
</p>
</dd>
<dt><code>method</code></dt><dd>
<p>download method, see <code><a href="utils.html#topic+download.file">download.file</a></code>.  Unused if
a non-<code>NULL</code> <code>available</code> is supplied.
</p>
</dd>
<dt><code>available</code></dt><dd>
<p>a matrix as returned by <code><a href="utils.html#topic+available.packages">available.packages</a></code>
listing packages available at the repositories, or <code>NULL</code> when
the function makes an internal call to <code>available.packages</code>.
Incompatible with <code>type = "both"</code>.
</p>
</dd>
<dt><code>destdir</code></dt><dd>
<p>directory where downloaded packages are stored.  If it is
<code>NULL</code> (the default) a subdirectory
<code>downloaded_packages</code> of the session temporary
directory will be used (and the files will be deleted
at the end of the session).
</p>
</dd>
<dt><code>dependencies</code></dt><dd><p>logical indicating whether to also install
uninstalled packages which these packages depend on/link
to/import/suggest (and so on recursively).
Not used if <code>repos = NULL</code>.
Can also be a character vector, a subset of
<code>c("Depends", "Imports", "LinkingTo", "Suggests", "Enhances")</code>.
</p>
<p>Only supported if <code>lib</code> is of length one (or missing),
so it is unambiguous where to install the dependent packages.  If
this is not the case it is ignored, with a warning.
</p>
<p>The default, <code>NA</code>, means
<code>c("Depends", "Imports", "LinkingTo")</code>.
</p>
<p><code>TRUE</code> means to use
<code>c("Depends", "Imports", "LinkingTo", "Suggests")</code> for
<code>pkgs</code> and
<code>c("Depends", "Imports", "LinkingTo")</code> for added dependencies:
this installs all the packages needed to run <code>pkgs</code>, their
examples, tests and vignettes (if the package author specified them
correctly).
</p>
<p>In all of these, <code>"LinkingTo"</code> is omitted for binary packages.
</p>
</dd>
<dt><code>type</code></dt><dd><p>character, indicating the type of package to download and
install.  Will be <code>"source"</code> except on Windows and some macOS
builds: see the section on &lsquo;Binary packages&rsquo; for those.
</p>
</dd>
<dt><code>configure.args</code></dt><dd>
<p>(Used only for source installs.) A character vector or a named list.
If a character vector with no names is supplied, the elements are
concatenated into a single string (separated by a space) and used as
the value for the <span class="option">--configure-args</span> flag in the call to
<code>R CMD INSTALL</code>.  If the character vector has names these
are assumed to identify values for <span class="option">--configure-args</span> for
individual packages.  This allows one to specify settings for an
entire collection of packages which will be used if any of those
packages are to be installed.  (These settings can therefore be
re-used and act as default settings.)
</p>
<p>A named list can be used also to the same effect, and that
allows multi-element character strings for each package
which are concatenated to a single string to be used as the
value for <span class="option">--configure-args</span>.
</p>
</dd>
<dt><code>configure.vars</code></dt><dd>
<p>(Used only for source installs.) Analogous to <code>configure.args</code>
for flag <span class="option">--configure-vars</span>, which is used to set environment
variables for the <code>configure</code> run.
</p>
</dd>
<dt><code>clean</code></dt><dd><p>a logical value indicating whether to add the
<span class="option">--clean</span> flag to the call to <code>R CMD INSTALL</code>.
This is sometimes used to perform additional operations at the end
of the package installation in addition to removing intermediate files.
</p>
</dd>
<dt><code>Ncpus</code></dt><dd><p>the number of parallel processes to use for a parallel
install of more than one source package.  Values greater than one
are supported if the <code>make</code> command specified by
<code>Sys.getenv("MAKE", "make")</code> accepts argument
<span class="option">-k -j &lt;Ncpus&gt;</span>.
</p>
</dd>
<dt><code>verbose</code></dt><dd>
<p>a logical indicating if some &ldquo;progress report&rdquo; should be given.
</p>
</dd>
<dt><code>INSTALL_opts</code></dt><dd>
<p>an optional character vector of additional option(s) to be passed to
<code>R CMD INSTALL</code> for a source package install.  E.g.,
<code>c("--html", "--no-multiarch", "--no-test-load")</code>.
</p>
<p>Can also be a named list of character vectors to be used as
additional options, with names the respective package names.
</p>
</dd>
<dt><code>quiet</code></dt><dd>
<p>logical: if true, reduce the amount of output.  This is <em>not</em>
passed to <code><a href="utils.html#topic+available.packages">available.packages</a>()</code> in case that is called, on
purpose.
</p>
</dd>
<dt><code>keep_outputs</code></dt><dd>
<p>a logical: if true, keep the outputs from installing source packages
in the current working directory, with the names of the output files
the package names with &lsquo;<span class="file">.out</span>&rsquo; appended (overwriting existing
files, possibly from previous installation attempts).  Alternatively, a
character string giving the directory in which to save the outputs.
Ignored when installing from local files.
</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value. Called for side effects.
</p>


<h3>Author(s)</h3>

<p>Patricia Martinkova <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:martinkova@cs.cas.cz">martinkova@cs.cas.cz</a>
</p>
<p>Adela Hladka <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:hladka@cs.cas.cz">hladka@cs.cas.cz</a>
</p>
<p>Jan Netik <br />
Institute of Computer Science of the Czech Academy of Sciences <br />
<a href="mailto:netik@cs.cas.cz">netik@cs.cas.cz</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
startShinyItemAnalysis()
startShinyItemAnalysis(background = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='TestAnxietyCor'>Correlation matrix for the test anxiety dataset</h2><span id='topic+TestAnxietyCor'></span>

<h3>Description</h3>

<p>The <code>TestAnxietyCor</code> dataset contains between-item correlations for 20 items
of the Test Anxiety dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestAnxietyCor
</code></pre>


<h3>Format</h3>

<p><code>TestAnxietyCor</code> is a <code>data.frame</code> consisting of between-item
correlations for 20 items.
</p>

<dl>
<dt>i1</dt><dd><p>Lack of confidence during tests. </p>
</dd>
<dt>i2</dt><dd><p>Uneasy, upset feeling. </p>
</dd>
<dt>i3</dt><dd><p>Thinking about grades. </p>
</dd>
<dt>i4</dt><dd><p>Freeze up. </p>
</dd>
<dt>i5</dt><dd><p>Thinking about getting through school. </p>
</dd>
<dt>i6</dt><dd><p>The harder I work, the more confused I get. </p>
</dd>
<dt>i7</dt><dd><p>Thoughts interfere with concentration. </p>
</dd>
<dt>i8</dt><dd><p>Jittery when taking tests. </p>
</dd>
<dt>i9</dt><dd><p>Even when prepared, get nervous. </p>
</dd>
<dt>i10</dt><dd><p>Uneasy before getting the test back. </p>
</dd>
<dt>i11</dt><dd><p>Tense during test. </p>
</dd>
<dt>i12</dt><dd><p>Exams bother me. </p>
</dd>
<dt>i13</dt><dd><p>Tense/ stomach upset. </p>
</dd>
<dt>i14</dt><dd><p>Defeat myself during tests. </p>
</dd>
<dt>i15</dt><dd><p>Panicky during tests. </p>
</dd>
<dt>i16</dt><dd><p>Worry before important tests. </p>
</dd>
<dt>i17</dt><dd><p>Think about failing. </p>
</dd>
<dt>i18</dt><dd><p>Heart beating fast during tests. </p>
</dd>
<dt>i19</dt><dd><p>Can’t stop worrying. </p>
</dd>
<dt>i20</dt><dd><p>Nervous during test, forget facts. </p>
</dd>
</dl>



<h3>References</h3>

<p>Bartholomew, D. J., Steele, F., &amp; Moustaki, I. (2008). Analysis
of multivariate social science data. CRC press.
</p>

<hr>
<h2 id='theme_app'>Complete theme for <code>ShinyItemAnalysis</code> graphics</h2><span id='topic+theme_app'></span>

<h3>Description</h3>

<p>This complete theme is based on <code>theme_bw</code> and it was modified for purposes
of <code>ShinyItemAnalysis</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>theme_app(base_size = 15, base_family = "")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="theme_app_+3A_base_size">base_size</code></td>
<td>
<p>base font size</p>
</td></tr>
<tr><td><code id="theme_app_+3A_base_family">base_family</code></td>
<td>
<p>base font family</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="ggplot2.html#topic+theme">ggplot2::theme()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
data(GMAT, package = "difNLR")
data &lt;- GMAT[, 1:20]
# total score calculation
df &lt;- data.frame(score = apply(data, 1, sum))
# histogram
g &lt;- ggplot(df, aes(score)) +
  geom_histogram(binwidth = 1) +
  xlab("Total score") +
  ylab("Number of respondents")

g
g + theme_app()
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
