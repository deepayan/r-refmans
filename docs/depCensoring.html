<!DOCTYPE html><html lang="en"><head><title>Help for package depCensoring</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {depCensoring}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#A_step'><p>A-step in the EAM algorithm described in KMS19</p></a></li>
<li><a href='#boot.fun'><p>Nonparametric bootstrap approach for the dependent censoring model</p></a></li>
<li><a href='#boot.funI'><p>Nonparametric bootstrap approach for the independent censoring model</p></a></li>
<li><a href='#boot.nonparTrans'><p>Nonparametric bootstrap approach for a Semiparametric transformation model under dependent censpring</p></a></li>
<li><a href='#Bspline.unit.interval'><p>Evaluate the specified B-spline, defined on the unit interval</p></a></li>
<li><a href='#Bvprob'><p>Compute bivariate survival probability</p></a></li>
<li><a href='#cbMV'><p>Combine bounds based on majority vote.</p></a></li>
<li><a href='#check.args.pisurv'><p>Check argument consistency.</p></a></li>
<li><a href='#chol2par'><p>Transform Cholesky decomposition to covariance matrix</p></a></li>
<li><a href='#chol2par.elem'><p>Transform Cholesky decomposition to covariance matrix parameter element.</p></a></li>
<li><a href='#Chronometer'><p>Chronometer object</p></a></li>
<li><a href='#clear.plt.wdw'><p>Clear plotting window</p></a></li>
<li><a href='#CompC'><p>Compute phi function</p></a></li>
<li><a href='#control.arguments'><p>Prepare initial values within the control arguments</p></a></li>
<li><a href='#copdist.Archimedean'><p>The distribution function of the Archimedean copula</p></a></li>
<li><a href='#cophfunc'><p>The h-function of the copula</p></a></li>
<li><a href='#coppar.to.ktau'><p>Convert the copula parameter the Kendall's tau</p></a></li>
<li><a href='#cr.lik'><p>Competing risk likelihood function.</p></a></li>
<li><a href='#D.hat'><p>Obtain the diagonal matrix of sample variances of moment functions</p></a></li>
<li><a href='#dat.sim.reg.comp.risks'><p>Data generation function for competing risks data</p></a></li>
<li><a href='#dchol2par'><p>Derivative of transform Cholesky decomposition to covariance matrix.</p></a></li>
<li><a href='#dchol2par.elem'><p>Derivative of transform Cholesky decomposition to covariance matrix</p>
element.</a></li>
<li><a href='#dD.hat'><p>Obtain the matrix of partial derivatives of the sample variances.</p></a></li>
<li><a href='#Distance'><p>Distance between vectors</p></a></li>
<li><a href='#dLambda_AFT_ll'><p>Derivative of link function (AFT model)</p></a></li>
<li><a href='#dLambda_Cox_wb'><p>Derivative of link function (Cox model)</p></a></li>
<li><a href='#dm.bar'><p>Vector of sample average of each moment function</p>
<code class="reqn">(\bar{m}_n(\theta))</code>.</a></li>
<li><a href='#do.optimization.Mstep'><p>Optimize the expected improvement</p></a></li>
<li><a href='#draw.sv.init'><p>Draw initial set of starting values for optimizing the expected</p>
improvement.</a></li>
<li><a href='#DYJtrans'><p>Derivative of the Yeo-Johnson transformation function</p></a></li>
<li><a href='#E_step'><p>E-step in the EAM algorithm as described in KMS19.</p></a></li>
<li><a href='#EAM'><p>Main function to run the EAM algorithm</p></a></li>
<li><a href='#EAM.converged'><p>Check convergence of the EAM algorithm.</p></a></li>
<li><a href='#EI'><p>Expected improvement</p></a></li>
<li><a href='#estimate.cf'><p>Estimate the control function</p></a></li>
<li><a href='#estimate.cmprsk'><p>Estimate the competing risks model of Rutten, Willems et al. (20XX).</p></a></li>
<li><a href='#feasible_point_search'><p>Method for finding initial points of the EAM algorithm</p></a></li>
<li><a href='#fitDepCens'><p>Fit Dependent Censoring Models</p></a></li>
<li><a href='#fitIndepCens'><p>Fit Independent Censoring Models</p></a></li>
<li><a href='#G.box'><p>Family of box functions</p></a></li>
<li><a href='#G.cd'><p>Family of continuous/discrete instrumental function</p></a></li>
<li><a href='#G.cd.mc'><p>Family of discrete/continuous instrumental functions, in the case of</p>
many covariates.</a></li>
<li><a href='#G.hat'><p>Compute the Gn matrix in step 3b of Bei (2024).</p></a></li>
<li><a href='#G.spline'><p>Family of spline instrumental functions</p></a></li>
<li><a href='#generator.Archimedean'><p>The generator function of the Archimedean copula</p></a></li>
<li><a href='#get.anchor.points'><p>Get anchor points on which to base the instrumental functions</p></a></li>
<li><a href='#get.cond.moment.evals'><p>Compute the conditional moment evaluations</p></a></li>
<li><a href='#get.cvLLn'><p>Compute the critical value of the test statistic.</p></a></li>
<li><a href='#get.deriv.mom.func'><p>Matrix of derivatives of conditional moment functions</p></a></li>
<li><a href='#get.dmi.tens'><p>Faster implementation to obtain the tensor of the evaluations of the</p>
derivatives of the moment functions at each observation.</a></li>
<li><a href='#get.extra.Estep.points'><p>Get extra evaluation points for E-step</p></a></li>
<li><a href='#get.instrumental.function.evals'><p>Evaluate each instrumental function at each of the observations.</p></a></li>
<li><a href='#get.mi.mat'><p>Faster implementation of vector of moment functions.</p></a></li>
<li><a href='#get.next.point'><p>Obtain next point for feasible point search.</p></a></li>
<li><a href='#get.starting.values'><p>Main function for obtaining the starting values of the expected</p>
improvement maximization step.</a></li>
<li><a href='#get.test.statistic'><p>Obtain the test statistic by minimizing the S-function over the</p>
feasible region <code class="reqn">\beta(r)</code>.</a></li>
<li><a href='#gridSearch'><p>Grid search algorithm for finding the identified set</p></a></li>
<li><a href='#gs.algo.bidir'><p>Rudimentary, bidirectional 1D grid search algorithm.</p></a></li>
<li><a href='#gs.binary'><p>Return the next point to evaluate when doing binary search</p></a></li>
<li><a href='#gs.interpolation'><p>Return the next point to evaluate when doing interpolation search</p></a></li>
<li><a href='#gs.regular'><p>Return the next point to evaluate when doing regular grid search</p></a></li>
<li><a href='#insert.row'><p>Insert row into a matrix at a given row index</p></a></li>
<li><a href='#IYJtrans'><p>Inverse Yeo-Johnson transformation function</p></a></li>
<li><a href='#Kernel'><p>Calculate the kernel function</p></a></li>
<li><a href='#ktau.to.coppar'><p>Convert the Kendall's tau into the copula parameter</p></a></li>
<li><a href='#Lambda_AFT_ll'><p>Link function (AFT model)</p></a></li>
<li><a href='#Lambda_Cox_wb'><p>Link function (Cox model)</p></a></li>
<li><a href='#Lambda_inverse_AFT_ll'><p>Inverse of link function (AFT model)</p></a></li>
<li><a href='#Lambda_inverse_Cox_wb'><p>Inverse of link function (Cox model)</p></a></li>
<li><a href='#lf.delta.beta1'><p>Loss function to compute Delta(beta).</p></a></li>
<li><a href='#lf.ts'><p>'Loss function' of the test statistic.</p></a></li>
<li><a href='#LikCopInd'><p>Loglikehood function under independent censoring</p></a></li>
<li><a href='#Likelihood.Parametric'><p>Calculate the likelihood function for the fully parametric joint distribution</p></a></li>
<li><a href='#Likelihood.Profile.Kernel'><p>Calculate the profiled likelihood function with kernel smoothing</p></a></li>
<li><a href='#Likelihood.Profile.Solve'><p>Solve the profiled likelihood function</p></a></li>
<li><a href='#Likelihood.Semiparametric'><p>Calculate the semiparametric version of profiled likelihood function</p></a></li>
<li><a href='#LikF.cmprsk'><p>Second step log-likelihood function.</p></a></li>
<li><a href='#likF.cmprsk.Cholesky'><p>Wrapper implementing likelihood function using Cholesky factorization.</p></a></li>
<li><a href='#LikGamma1'><p>First step log-likelihood function for Z continuous</p></a></li>
<li><a href='#LikGamma2'><p>First step log-likelihood function for Z binary.</p></a></li>
<li><a href='#LikI.bis'><p>Second likelihood function needed to fit the independence model in the</p>
second step of the estimation procedure.</a></li>
<li><a href='#LikI.cmprsk'><p>Second step log-likelihood function under independence assumption.</p></a></li>
<li><a href='#LikI.cmprsk.Cholesky'><p>Wrapper implementing likelihood function assuming independence between</p>
competing risks and censoring using Cholesky factorization.</a></li>
<li><a href='#likIFG.cmprsk.Cholesky'><p>Full likelihood (including estimation of control function).</p></a></li>
<li><a href='#log_transform'><p>Logarithmic transformation function.</p></a></li>
<li><a href='#loglike.clayton.unconstrained'><p>Log-likelihood function for the Clayton copula.</p></a></li>
<li><a href='#loglike.frank.unconstrained'><p>Log-likelihood function for the Frank copula.</p></a></li>
<li><a href='#loglike.gaussian.unconstrained'><p>Log-likelihood function for the Gaussian copula.</p></a></li>
<li><a href='#loglike.gumbel.unconstrained'><p>Log-likelihood function for the Gumbel copula.</p></a></li>
<li><a href='#loglike.indep.unconstrained'><p>Log-likelihood function for the independence copula.</p></a></li>
<li><a href='#Longfun'><p>Long format</p></a></li>
<li><a href='#LongNPT'><p>Change H to long format</p></a></li>
<li><a href='#M_step'><p>M-step in the EAM algorithm described in KMS19.</p></a></li>
<li><a href='#m.bar'><p>Vector of sample average of each moment function</p>
<code class="reqn">(\bar{m}_n(\theta))</code>.</a></li>
<li><a href='#MSpoint'><p>Analogue to KMS_AUX4_MSpoints(...) in MATLAB code of Bei (2024).</p></a></li>
<li><a href='#NonParTrans'><p>Fit a semiparametric transformation model for dependent censoring</p></a></li>
<li><a href='#normalize.covariates'><p>Normalize the covariates of a data set to lie in the unit interval by</p>
scaling based on the ranges of the covariates.</a></li>
<li><a href='#normalize.covariates2'><p>Normalize the covariates of a data set to lie in the unit interval by</p>
transforming based on PCA.</a></li>
<li><a href='#Omega.hat'><p>Obtain the correlation matrix of the moment functions</p></a></li>
<li><a href='#optimlikelihood'><p>Fit the dependent censoring models.</p></a></li>
<li><a href='#parafam.d'><p>Obtain the value of the density function</p></a></li>
<li><a href='#parafam.p'><p>Obtain the value of the distribution function</p></a></li>
<li><a href='#parafam.trunc'><p>Obtain the adjustment value of truncation</p></a></li>
<li><a href='#ParamCop'><p>Estimation of  a parametric dependent censoring model without covariates.</p></a></li>
<li><a href='#Parameters.Constraints'><p>Generate constraints of parameters</p></a></li>
<li><a href='#pi.surv'><p>Estimate the model of Willems et al. (2024+).</p></a></li>
<li><a href='#plot_addpte'><p>Draw points to be evaluated</p></a></li>
<li><a href='#plot_addpte.eval'><p>Draw evaluated points.</p></a></li>
<li><a href='#plot_base'><p>Draw base plot</p></a></li>
<li><a href='#power_transform'><p>Power transformation function.</p></a></li>
<li><a href='#PseudoL'><p>Likelihood function under dependent censoring</p></a></li>
<li><a href='#S.func'><p>S-function</p></a></li>
<li><a href='#ScoreEqn'><p>Score equations of finite parameters</p></a></li>
<li><a href='#SearchIndicate'><p>Search function</p></a></li>
<li><a href='#set.EAM.hyperparameters'><p>Set default hyperparameters for EAM algorithm</p></a></li>
<li><a href='#set.GS.hyperparameters'><p>Set default hyperparameters for grid search algorithm</p></a></li>
<li><a href='#set.hyperparameters'><p>Define the hyperparameters used for finding the identified interval</p></a></li>
<li><a href='#Sigma.hat'><p>Compute the variance-covariance matrix of the moment functions.</p></a></li>
<li><a href='#SolveH'><p>Estimate a nonparametric transformation function</p></a></li>
<li><a href='#SolveHt1'><p>Estimating equation for Ht1</p></a></li>
<li><a href='#SolveL'><p>Cumulative hazard function of survival time under dependent censoring</p></a></li>
<li><a href='#SolveLI'><p>Cumulative hazard function of survival time under independent censoring</p></a></li>
<li><a href='#SolveScore'><p>Estimate finite parameters based on score equations</p></a></li>
<li><a href='#summary.depFit'><p>Summary of <code>depCensoringFit</code> object</p></a></li>
<li><a href='#summary.indepFit'><p>Summary of <code>indepCensoringFit</code> object</p></a></li>
<li><a href='#SurvDC'><p>Semiparametric Estimation of the Survival Function under Dependent Censoring</p></a></li>
<li><a href='#SurvDC.GoF'><p>Calculate the goodness-of-fit test statistic</p></a></li>
<li><a href='#SurvFunc.CG'><p>Estimated survival function based on copula-graphic estimator (Archimedean copula only)</p></a></li>
<li><a href='#SurvFunc.KM'><p>Estimated survival function based on Kaplan-Meier estimator</p></a></li>
<li><a href='#SurvMLE'><p>Maximum likelihood estimator for a given parametric distribution</p></a></li>
<li><a href='#SurvMLE.Likelihood'><p>Likelihood for a given parametric distribution</p></a></li>
<li><a href='#TCsim'><p>Function to simulate (Y,Delta) from the copula based model for (T,C).</p></a></li>
<li><a href='#test.point_Bei'><p>Perform the test of Bei (2024) for a given point</p></a></li>
<li><a href='#test.point_Bei_MT'><p>Perform the test of Bei (2024) simultaneously for multiple time</p>
points.</a></li>
<li><a href='#uniformize.data'><p>Standardize data format</p></a></li>
<li><a href='#variance.cmprsk'><p>Compute the variance of the estimates.</p></a></li>
<li><a href='#YJtrans'><p>Yeo-Johnson transformation function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Statistical Methods for Survival Data with Dependent Censoring</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.7</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Negera Wakgari Deresa &lt;negera.deresa@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Several statistical methods for analyzing survival data under various forms of dependent
    censoring are implemented in the package. In addition to accounting for dependent censoring, it 
    offers tools to adjust for unmeasured confounding factors. The implemented approaches allow 
    users to estimate the dependency between survival time and dependent censoring time, based 
    solely on observed survival data. For more details on the methods, refer to Deresa and Van 
    Keilegom (2021) &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasaa095">doi:10.1093/biomet/asaa095</a>&gt;, Czado and Van Keilegom (2023)
    &lt;<a href="https://doi.org/10.1093%2Fbiomet%2Fasac067">doi:10.1093/biomet/asac067</a>&gt;, Crommen et al. (2024) &lt;<a href="https://doi.org/10.1007%2Fs11749-023-00903-9">doi:10.1007/s11749-023-00903-9</a>&gt;,
    Deresa and Van Keilegom (2024) &lt;<a href="https://doi.org/10.1080%2F01621459.2022.2161387">doi:10.1080/01621459.2022.2161387</a>&gt;, Rutten et al. (2024+) 
    &lt;<a href="https://doi.org/10.48550%2FarXiv.2403.11860">doi:10.48550/arXiv.2403.11860</a>&gt; and  Ding and Van Keilegom (2024).</td>
</tr>
<tr>
<td>Imports:</td>
<td>survival, foreach, parallel, doParallel, pbivnorm, stats,
MASS, nleqslv, OpenMx, methods, Matrix, EnvStats, mvtnorm,
rafalib, rvinecopulib, matrixcalc, nloptr, stringr, numDeriv,
copula, R6, lubridate, splines2</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), rkriging</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-11 22:53:08 UTC; Negera Deresa</td>
</tr>
<tr>
<td>Author:</td>
<td>Ilias Willems <a href="https://orcid.org/0009-0001-9463-9942"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Gilles Crommen <a href="https://orcid.org/0000-0001-8380-1900"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Negera Wakgari Deresa
    <a href="https://orcid.org/0000-0002-1302-3725"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Jie Ding <a href="https://orcid.org/0000-0002-6083-7529"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Claudia Czado <a href="https://orcid.org/0000-0002-6329-5438"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Ingrid Van Keilegom
    <a href="https://orcid.org/0000-0001-8827-7642"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-11 23:10:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='A_step'>A-step in the EAM algorithm described in KMS19</h2><span id='topic+A_step'></span>

<h3>Description</h3>

<p>This function performs the approximation step in the EAM
algorithm. More specifically, it fits a Gaussian-process regression model
(Kriging) to the evaluated data points <code class="reqn">(\theta, c(\theta))</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>A_step(evaluations, verbose = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="A_step_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix containing each point that was already evaluated,
alongside the corresponding test statistic and critical value, as its rows.</p>
</td></tr>
<tr><td><code id="A_step_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Results of the A-step.
</p>


<h3>See Also</h3>

<p>Package <span class="pkg">rkriging</span>.
</p>

<hr>
<h2 id='boot.fun'>Nonparametric bootstrap approach for the dependent censoring model</h2><span id='topic+boot.fun'></span>

<h3>Description</h3>

<p>This function estimates the bootstrap standard errors for the finite-dimensional model parameters and for the non-parametric cumulative
hazard function. Parallel computing using foreach has been used to speed up the estimation of standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.fun(
  init,
  resData,
  X,
  W,
  lhat,
  cumL,
  dist,
  k,
  lb,
  ub,
  Obs.time,
  cop,
  n.boot,
  n.iter,
  ncore,
  eps
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot.fun_+3A_init">init</code></td>
<td>
<p>Initial values for the finite dimensional parameters obtained from the fit of <code><a href="#topic+fitDepCens">fitDepCens</a></code></p>
</td></tr>
<tr><td><code id="boot.fun_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be a vector of ones</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_lhat">lhat</code></td>
<td>
<p>Initial values for the hazard function obtained from the fit of <code><a href="#topic+fitDepCens">fitDepCens</a></code> based on the original data.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_cuml">cumL</code></td>
<td>
<p>Initial values for the cumulative hazard function obtained from the fit of <code><a href="#topic+fitDepCens">fitDepCens</a></code> based on the original data.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_dist">dist</code></td>
<td>
<p>The distribution to be used for the  dependent censoring time C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_k">k</code></td>
<td>
<p>Dimension of X</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_lb">lb</code></td>
<td>
<p>lower boundary for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_ub">ub</code></td>
<td>
<p>Upper boundary for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_obs.time">Obs.time</code></td>
<td>
<p>Observed survival time, which is the minimum of T, C and A, where A is the administrative censoring time.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_cop">cop</code></td>
<td>
<p>Which copula should be computed to account for dependency between T and C. This argument can take
one of the values from <code>c("Gumbel", "Frank", "Normal")</code>.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstraps to use in the estimation of bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations; the default is <code>n.iter = 20</code>. The larger the number of iterations, the longer the computational time.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_ncore">ncore</code></td>
<td>
<p>The number of cores to use for parallel computation is configurable, with the default <code>ncore = 7</code>.</p>
</td></tr>
<tr><td><code id="boot.fun_+3A_eps">eps</code></td>
<td>
<p>Convergence error. This is set by the user in such away that the desired convergence is met; the default is <code>eps = 1e-3</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bootstrap standard errors for parameter estimates and for estimated cumulative hazard function.
</p>

<hr>
<h2 id='boot.funI'>Nonparametric bootstrap approach for the independent censoring model</h2><span id='topic+boot.funI'></span>

<h3>Description</h3>

<p>This function estimates the bootstrap standard errors for the finite-dimensional model parameters and for the non-parametric cumulative
hazard function under the assumption of independent censoring. Parallel computing using foreach has been used to speed up the computation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.funI(
  init,
  resData,
  X,
  W,
  lhat,
  cumL,
  dist,
  k,
  lb,
  ub,
  Obs.time,
  n.boot,
  n.iter,
  ncore,
  eps
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot.funI_+3A_init">init</code></td>
<td>
<p>Initial values for the finite dimensional parameters obtained from the fit of <code><a href="#topic+fitIndepCens">fitIndepCens</a></code></p>
</td></tr>
<tr><td><code id="boot.funI_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be a vector of ones</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_lhat">lhat</code></td>
<td>
<p>Initial values for the hazard function obtained from the fit of <code><a href="#topic+fitIndepCens">fitIndepCens</a></code> based on the original data</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_cuml">cumL</code></td>
<td>
<p>Initial values for the cumulative hazard function obtained from the fit of <code><a href="#topic+fitIndepCens">fitIndepCens</a></code> based on the original data</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_dist">dist</code></td>
<td>
<p>The distribution to be used for the  dependent censoring time C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_k">k</code></td>
<td>
<p>Dimension of X</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_lb">lb</code></td>
<td>
<p>lower boundary for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_ub">ub</code></td>
<td>
<p>Upper boundary for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_obs.time">Obs.time</code></td>
<td>
<p>Observed survival time, which is the minimum of T, C and A, where A is the administrative censoring time.</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstraps to use in the estimation of bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations; the default is <code>n.iter = 20</code>. The larger the number of iterations, the longer the computational time</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_ncore">ncore</code></td>
<td>
<p>The number of cores to use for parallel computation is configurable, with the default <code>ncore = 7</code>.</p>
</td></tr>
<tr><td><code id="boot.funI_+3A_eps">eps</code></td>
<td>
<p>Convergence error. This is set by the user in such away that the desired convergence is met; the default is <code>eps = 1e-3</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bootstrap standard errors for parameter estimates and for estimated cumulative hazard function.
</p>

<hr>
<h2 id='boot.nonparTrans'>Nonparametric bootstrap approach for a Semiparametric transformation model under dependent censpring</h2><span id='topic+boot.nonparTrans'></span>

<h3>Description</h3>

<p>This function estimates the bootstrap standard errors for the finite-dimensional model parameters and for the non-parametric transformation
function. Parallel computing using foreach has been used to speed up the estimation of standard errors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.nonparTrans(init, resData, X, W, n.boot, n.iter, eps)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="boot.nonparTrans_+3A_init">init</code></td>
<td>
<p>Initial values for the finite dimensional parameters obtained from the fit of <code><a href="#topic+NonParTrans">NonParTrans</a></code></p>
</td></tr>
<tr><td><code id="boot.nonparTrans_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="boot.nonparTrans_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="boot.nonparTrans_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C.</p>
</td></tr>
<tr><td><code id="boot.nonparTrans_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstraps to use in the estimation of bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="boot.nonparTrans_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations; the default is <code>n.iter = 15</code>. The larger the number of iterations, the longer the computational time.</p>
</td></tr>
<tr><td><code id="boot.nonparTrans_+3A_eps">eps</code></td>
<td>
<p>Convergence error. This is set by the user in such away that the desired convergence is met; the default is <code>eps = 1e-3</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Bootstrap standard errors for parameter estimates and for estimated cumulative hazard function.
</p>

<hr>
<h2 id='Bspline.unit.interval'>Evaluate the specified B-spline, defined on the unit interval</h2><span id='topic+Bspline.unit.interval'></span>

<h3>Description</h3>

<p>This function evaluates the specified B-spline defined on the
unit interval, when considering <code>n.if.per.cov</code> B-splines. Currently, the
implementation is based on the one in Andrews, Shi 2013 (supplementary
materials).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bspline.unit.interval(x, spline.index, n.if.per.cov, degree = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bspline.unit.interval_+3A_x">x</code></td>
<td>
<p>value inside the unit interval at which to evaluate the spline.</p>
</td></tr>
<tr><td><code id="Bspline.unit.interval_+3A_spline.index">spline.index</code></td>
<td>
<p>Index of the spline to evaluate.</p>
</td></tr>
<tr><td><code id="Bspline.unit.interval_+3A_n.if.per.cov">n.if.per.cov</code></td>
<td>
<p>Number of B-splines to consider over the unit interval.</p>
</td></tr>
<tr><td><code id="Bspline.unit.interval_+3A_degree">degree</code></td>
<td>
<p>Degree of the B-splines. Default is <code>degree = 3</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Andrews, D.W.K. and Shi, X. (2013). Inference based on
confitional moment inequalities. Econometrica. 81(2):609-666.
</p>

<hr>
<h2 id='Bvprob'>Compute bivariate survival probability</h2><span id='topic+Bvprob'></span>

<h3>Description</h3>

<p>This function calculates a bivariate survival probability based on multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Bvprob(lx, ly, rho)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Bvprob_+3A_lx">lx</code></td>
<td>
<p>The first lower bound of integration</p>
</td></tr>
<tr><td><code id="Bvprob_+3A_ly">ly</code></td>
<td>
<p>The second lower bound</p>
</td></tr>
<tr><td><code id="Bvprob_+3A_rho">rho</code></td>
<td>
<p>Association parameter</p>
</td></tr>
</table>

<hr>
<h2 id='cbMV'>Combine bounds based on majority vote.</h2><span id='topic+cbMV'></span>

<h3>Description</h3>

<p>This function combines a list of individual identified intervals
to a single one based on majority vote. Note that the intersection of all
intervals can be viewed as a majority vote as well, so that it is included as
a special case.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cbMV(results.list, threshold)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cbMV_+3A_results.list">results.list</code></td>
<td>
<p>List object containing the individual identified
intervals.</p>
</td></tr>
<tr><td><code id="cbMV_+3A_threshold">threshold</code></td>
<td>
<p>Threshold proportion of identified intervals a given value
should be contained in in order for it to be included in the combined
identified interval. For intersection bounds, set this value to <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The combined identified interval.
</p>

<hr>
<h2 id='check.args.pisurv'>Check argument consistency.</h2><span id='topic+check.args.pisurv'></span>

<h3>Description</h3>

<p>This function checks whether the arguments supplied to the
main estimation function <code>pi.surv</code> are valid. When arguments are
invalid, the an exception is thrown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.args.pisurv(
  data,
  idx.param.of.interest,
  idxs.c,
  t,
  par.space,
  search.method,
  add.options
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.args.pisurv_+3A_data">data</code></td>
<td>
<p>Data frame containing the data on which to fit the model. The
columns should be named as follows: 'Y' = observed timed, 'Delta' = censoring
indicators, 'X0' = intercept column, 'X1' - 'Xp' = covariates.</p>
</td></tr>
<tr><td><code id="check.args.pisurv_+3A_idx.param.of.interest">idx.param.of.interest</code></td>
<td>
<p>Index of element in the covariate vector for
which the identified interval should be estimated. It can also be specified
as <code>idx.param.of.interest = "all"</code>, in which case identified intervals
will be computed for all elements in the parameter vector. Note that
<code>idx.param.of.interest = 1</code> corresponds to the intercept parameter.</p>
</td></tr>
<tr><td><code id="check.args.pisurv_+3A_idxs.c">idxs.c</code></td>
<td>
<p>Vector of indices of the continuous covariates. Suppose the
given data contains 5 covariates, of which 'X2' and 'X5' are continuous, this
argument should be specified as <code>idxs.c = c(2, 5)</code>.</p>
</td></tr>
<tr><td><code id="check.args.pisurv_+3A_t">t</code></td>
<td>
<p>Time point for which to estimate the identified set of
<code class="reqn">\beta(t)</code>.</p>
</td></tr>
<tr><td><code id="check.args.pisurv_+3A_par.space">par.space</code></td>
<td>
<p>Matrix containing bounds on the space of the parameters. The
first column corresponds to lower bounds, the second to upper bounds. The i'th
row corresponds to the bounds on the i'th element in the parameter vector.</p>
</td></tr>
<tr><td><code id="check.args.pisurv_+3A_search.method">search.method</code></td>
<td>
<p>The search method to be used to find the identified
interval. Default is <code>search.method = "GS"</code>.</p>
</td></tr>
<tr><td><code id="check.args.pisurv_+3A_add.options">add.options</code></td>
<td>
<p>List of additional options to be specified to the method.
Notably, it can be used to select the link function <code class="reqn">\Lambda(t))</code> that
should be considered. Currently, the link function leading to an accelerated
failure time model (<code>"AFT_ll"</code>, default) and the link function
leading to a Cox proportional hazards model (<code>"Cox_wb"</code>) are implemented.
Other options can range from 'standard' hyperparameters such as the
confidence level of the test and number of instrumental functions to be used,
to technical hyperparameters regarding the search method and test
implementation. For the latter, we refer to the documentations of
<code>set.hyperparameters</code>, <code>set.EAM.hyperparameters</code> and
<code>set.GS.hyperparameters</code>. We recommend to use the default parameters,
unless you really know what you are doing.</p>
</td></tr>
</table>

<hr>
<h2 id='chol2par'>Transform Cholesky decomposition to covariance matrix</h2><span id='topic+chol2par'></span>

<h3>Description</h3>

<p>This function transforms the parameters of the Cholesky de-
composition to the covariance matrix, represented as a the row-wise con-
catenation of the upper-triangular elements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chol2par(par.chol1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chol2par_+3A_par.chol1">par.chol1</code></td>
<td>
<p>The vector of Cholesky parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Covariance matrix corresponding to the provided Cholesky decomposition.
</p>

<hr>
<h2 id='chol2par.elem'>Transform Cholesky decomposition to covariance matrix parameter element.</h2><span id='topic+chol2par.elem'></span>

<h3>Description</h3>

<p>This function transforms the parameters of the Cholesky de-
composition to a covariance matrix element. This function is used in
chol2par.R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chol2par.elem(a, b, par.chol1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chol2par.elem_+3A_a">a</code></td>
<td>
<p>The row index of the covariance matrix element to be computed.</p>
</td></tr>
<tr><td><code id="chol2par.elem_+3A_b">b</code></td>
<td>
<p>The column index of the covariance matrix element to be computed.</p>
</td></tr>
<tr><td><code id="chol2par.elem_+3A_par.chol1">par.chol1</code></td>
<td>
<p>The vector of Cholesky parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Specified element of the covariance matrix resulting from the
provided Cholesky decomposition.
</p>

<hr>
<h2 id='Chronometer'>Chronometer object</h2><span id='topic+Chronometer'></span>

<h3>Description</h3>

<p>R6 object that mimics a chronometer. It can be started, paused, record legs
and stopped.
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-Chronometer-show"><code>Chronometer$show()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-reset"><code>Chronometer$reset()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-start"><code>Chronometer$start()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-stop"><code>Chronometer$stop()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-record.leg"><code>Chronometer$record.leg()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-get.chronometer.data"><code>Chronometer$get.chronometer.data()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-get.total.time"><code>Chronometer$get.total.time()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-accumulate.legs"><code>Chronometer$accumulate.legs()</code></a>
</p>
</li>
<li> <p><a href="#method-Chronometer-clone"><code>Chronometer$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-Chronometer-show"></a>



<h4>Method <code>show()</code></h4>

<p>Display the values stored in this chronometer object.
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$show()</pre></div>


<hr>
<a id="method-Chronometer-reset"></a>



<h4>Method <code>reset()</code></h4>

<p>Reset the chronometer.
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$reset()</pre></div>


<hr>
<a id="method-Chronometer-start"></a>



<h4>Method <code>start()</code></h4>

<p>Start the chronometer
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$start()</pre></div>


<hr>
<a id="method-Chronometer-stop"></a>



<h4>Method <code>stop()</code></h4>

<p>Stop the chronometer
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$stop(leg.name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>leg.name</code></dt><dd><p>(optional) Name for the stopped leg.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Chronometer-record.leg"></a>



<h4>Method <code>record.leg()</code></h4>

<p>Record a leg time. The chronometer will continue running.
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$record.leg(leg.name = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>leg.name</code></dt><dd><p>Name for the recorded leg.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Chronometer-get.chronometer.data"></a>



<h4>Method <code>get.chronometer.data()</code></h4>

<p>Like <code>show</code> method, but more rudimentary.
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$get.chronometer.data()</pre></div>


<hr>
<a id="method-Chronometer-get.total.time"></a>



<h4>Method <code>get.total.time()</code></h4>

<p>Return the total time span between start and stop.
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$get.total.time(force = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>force</code></dt><dd><p>Boolean variable. If <code>TRUE</code>, avoids error when calling
this function while chronometer has not been stopped yet.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Chronometer-accumulate.legs"></a>



<h4>Method <code>accumulate.legs()</code></h4>

<p>Return total time spent per leg category (using leg names).
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$accumulate.legs(force = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>force</code></dt><dd><p>force Boolean variable. If <code>TRUE</code>, avoids error when calling
this function while chronometer has not been stopped yet.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-Chronometer-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>Chronometer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='clear.plt.wdw'>Clear plotting window</h2><span id='topic+clear.plt.wdw'></span>

<h3>Description</h3>

<p>This function clears the plotting window
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clear.plt.wdw()
</code></pre>

<hr>
<h2 id='CompC'>Compute phi function</h2><span id='topic+CompC'></span>

<h3>Description</h3>

<p>This function estimates phi function at fixed time point t
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompC(theta, t, X, W, ld, cop, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CompC_+3A_theta">theta</code></td>
<td>
<p>Estimated parameter values/initial values for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="CompC_+3A_t">t</code></td>
<td>
<p>A fixed time point</p>
</td></tr>
<tr><td><code id="CompC_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="CompC_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be ones</p>
</td></tr>
<tr><td><code id="CompC_+3A_ld">ld</code></td>
<td>
<p>Output of <code><a href="#topic+SolveL">SolveL</a></code> function at a fixed time t</p>
</td></tr>
<tr><td><code id="CompC_+3A_cop">cop</code></td>
<td>
<p>Which copula should be computed to account for dependency between T and C. This argument can take
one of the values from <code>c("Gumbel", "Frank", "Normal")</code>. The default copula model is &quot;Frank&quot;.</p>
</td></tr>
<tr><td><code id="CompC_+3A_dist">dist</code></td>
<td>
<p>The distribution to  be used for the dependent censoring C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.</p>
</td></tr>
</table>

<hr>
<h2 id='control.arguments'>Prepare initial values within the control arguments</h2><span id='topic+control.arguments'></span>

<h3>Description</h3>

<p>Prepare initial values within the control arguments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>control.arguments(maxit = 300, eps = 1e-06, trace = TRUE, ktau.inits = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="control.arguments_+3A_maxit">maxit</code></td>
<td>
<p>a positive integer that denotes the maximum iteration number in optimization.</p>
</td></tr>
<tr><td><code id="control.arguments_+3A_eps">eps</code></td>
<td>
<p>a positive small numeric value that denotes the tolerance for convergence.</p>
</td></tr>
<tr><td><code id="control.arguments_+3A_trace">trace</code></td>
<td>
<p>a logical value that judges whereh the tracing information on the progress of the model fitting should be produced. The default value if <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="control.arguments_+3A_ktau.inits">ktau.inits</code></td>
<td>
<p>a numeric vector that contains initial values of the Kendall's tau.</p>
</td></tr>
</table>

<hr>
<h2 id='copdist.Archimedean'>The distribution function of the Archimedean copula</h2><span id='topic+copdist.Archimedean'></span>

<h3>Description</h3>

<p>The distribution function of the Archimedean copula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copdist.Archimedean(x, copfam, ktau, coppar = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copdist.Archimedean_+3A_x">x</code></td>
<td>
<p>the value at which the distribution function will be calculated at.</p>
</td></tr>
<tr><td><code id="copdist.Archimedean_+3A_copfam">copfam</code></td>
<td>
<p>a character string that denotes the copula family.</p>
</td></tr>
<tr><td><code id="copdist.Archimedean_+3A_ktau">ktau</code></td>
<td>
<p>a numeric value that denotes the Kendall's tau.</p>
</td></tr>
<tr><td><code id="copdist.Archimedean_+3A_coppar">coppar</code></td>
<td>
<p>a numeric value that denotes the copula parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='cophfunc'>The h-function of the copula</h2><span id='topic+cophfunc'></span>

<h3>Description</h3>

<p>The h-function of the copula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cophfunc(x, coppar, copfam, condvar = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cophfunc_+3A_x">x</code></td>
<td>
<p>the value at which the h-function will be calculated at.</p>
</td></tr>
<tr><td><code id="cophfunc_+3A_coppar">coppar</code></td>
<td>
<p>a numeric value that denotes the copula parameter.</p>
</td></tr>
<tr><td><code id="cophfunc_+3A_copfam">copfam</code></td>
<td>
<p>a character string that denotes the copula family.</p>
</td></tr>
<tr><td><code id="cophfunc_+3A_condvar">condvar</code></td>
<td>
<p>a numeric value that specifies the type of the h-function.</p>
</td></tr>
</table>

<hr>
<h2 id='coppar.to.ktau'>Convert the copula parameter the Kendall's tau</h2><span id='topic+coppar.to.ktau'></span>

<h3>Description</h3>

<p>Convert the copula parameter the Kendall's tau
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coppar.to.ktau(coppar, copfam)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coppar.to.ktau_+3A_coppar">coppar</code></td>
<td>
<p>a numeric value that denotes the copula parameter.</p>
</td></tr>
<tr><td><code id="coppar.to.ktau_+3A_copfam">copfam</code></td>
<td>
<p>a character string that denotes the copula family.</p>
</td></tr>
</table>

<hr>
<h2 id='cr.lik'>Competing risk likelihood function.</h2><span id='topic+cr.lik'></span>

<h3>Description</h3>

<p>This function implements the second step likelihood function of
the competing risk model defined in Willems et al. (2024+).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cr.lik(
  n,
  s,
  Y,
  admin,
  cens.inds,
  M,
  Sigma,
  beta.mat,
  sigma.vct,
  rho.mat,
  theta.vct
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cr.lik_+3A_n">n</code></td>
<td>
<p>The sample size.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_s">s</code></td>
<td>
<p>The number of competing risks.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_y">Y</code></td>
<td>
<p>The observed times.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether or not administrative censoring
should be taken into account.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_cens.inds">cens.inds</code></td>
<td>
<p>matrix of censoring indicators (each row corresponds to a
single observation).</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_m">M</code></td>
<td>
<p>Design matrix, consisting of [intercept, exo.cov, Z, cf]. Note that
<code>cf</code> represents the multiple ways of 'handling' the endogenous covariate
Z, see also the documentation of 'estimate.cmprsk.R'. When there is no
confounding, <code>M</code> will be [intercept, exo.cov].</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_sigma">Sigma</code></td>
<td>
<p>The covariance matrix.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_beta.mat">beta.mat</code></td>
<td>
<p>Matrix containing all of the covariate effects.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_sigma.vct">sigma.vct</code></td>
<td>
<p>Vector of standard deviations. Should be equal to
<code>sqrt(diag(Sigma))</code>.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_rho.mat">rho.mat</code></td>
<td>
<p>The correlation matrix.</p>
</td></tr>
<tr><td><code id="cr.lik_+3A_theta.vct">theta.vct</code></td>
<td>
<p>Vector containing the parameters of the Yeo-Johnsontrans-
formations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Evaluation of the log-likelihood function
</p>


<h3>References</h3>

<p>Willems et al. (2024+). Flexible control function approach under competing risks (in preparation).
</p>

<hr>
<h2 id='D.hat'>Obtain the diagonal matrix of sample variances of moment functions</h2><span id='topic+D.hat'></span>

<h3>Description</h3>

<p>This function computes the diagonal matrix of the sample
variance-covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>D.hat(input, beta = NULL, t = NULL, hp = NULL, m.avg = NULL, mi.mat = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="D.hat_+3A_input">input</code></td>
<td>
<p>Can either be the variance-covariance matrix obtained from the
function Sigma.hat, or the data frame.</p>
</td></tr>
<tr><td><code id="D.hat_+3A_beta">beta</code></td>
<td>
<p>The coefficient vector. Only needs to be supplied when the
argument for <code>input</code> is the data frame.</p>
</td></tr>
<tr><td><code id="D.hat_+3A_t">t</code></td>
<td>
<p>The time point of interest. Only needs to be supplied when the
argument for <code>input</code> is the data frame.</p>
</td></tr>
<tr><td><code id="D.hat_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters. Only needs to be supplied when the
argument for <code>input</code> is the data frame.</p>
</td></tr>
<tr><td><code id="D.hat_+3A_m.avg">m.avg</code></td>
<td>
<p>See documentation of <code>Sigma.hat</code>. Only needs to be supplied
when the argument for <code>input</code> is the data frama.</p>
</td></tr>
<tr><td><code id="D.hat_+3A_mi.mat">mi.mat</code></td>
<td>
<p>See documentation of <code>Sigma.hat</code>. Only needs to be supplied
when the argument for <code>input</code> is the data frama.</p>
</td></tr>
</table>

<hr>
<h2 id='dat.sim.reg.comp.risks'>Data generation function for competing risks data</h2><span id='topic+dat.sim.reg.comp.risks'></span>

<h3>Description</h3>

<p>This function generates competing risk data that can be used in
simulation studies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dat.sim.reg.comp.risks(
  n,
  par,
  iseed,
  s,
  conf,
  Zbin,
  Wbin,
  type.cov,
  A.upper = 15
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dat.sim.reg.comp.risks_+3A_n">n</code></td>
<td>
<p>The sample size of the generated data set.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_par">par</code></td>
<td>
<p>List of parameter vectors for each component of the transformation
model.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_iseed">iseed</code></td>
<td>
<p>Random seed.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_s">s</code></td>
<td>
<p>The number of competing risks. Note that the given parameter vector
could specify the parameters for the model with more than s competing risks,
but in this case only the first s sets of parameters will be considered.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data set should contain
confounding.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_zbin">Zbin</code></td>
<td>
<p>Indicator whether the confounded variable is binary
<code>Zbin = 1</code> or not <code>Zbin = 0</code>. If <code>conf = FALSE</code>, this
variable is ignored.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_wbin">Wbin</code></td>
<td>
<p>Indicator whether the instrument is binary (<code>Zbin = 1</code>) or
not <code>Zbin = 0</code>.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_type.cov">type.cov</code></td>
<td>
<p>Vector of characters &quot;c&quot; and &quot;b&quot;, indicating which exogenous
covariates should be continuous <code>"c"</code> or binary <code>"b"</code>.</p>
</td></tr>
<tr><td><code id="dat.sim.reg.comp.risks_+3A_a.upper">A.upper</code></td>
<td>
<p>The upper bound on the support of the administrative censoring
distribution. This can be used to control for the amount of administrative
censoring in the data. Default is <code>A.upper = 15</code>. <code>A.upper = NULL</code>
will return a data set without administrative censoring.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A generated data set
</p>

<hr>
<h2 id='dchol2par'>Derivative of transform Cholesky decomposition to covariance matrix.</h2><span id='topic+dchol2par'></span>

<h3>Description</h3>

<p>This function defines the derivative of the transformation
function that maps Cholesky parameters to the full covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dchol2par(par.chol1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dchol2par_+3A_par.chol1">par.chol1</code></td>
<td>
<p>The vector of Cholesky parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Derivative of the function that transforms the cholesky parameters
to the full covariance matrix.
</p>

<hr>
<h2 id='dchol2par.elem'>Derivative of transform Cholesky decomposition to covariance matrix
element.</h2><span id='topic+dchol2par.elem'></span>

<h3>Description</h3>

<p>This function defines the derivative of the transformation
function that maps Cholesky parameters to a covariance matrix element. This
function is used in dchol2par.R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dchol2par.elem(k, q, a, b, par.chol1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dchol2par.elem_+3A_k">k</code></td>
<td>
<p>The row index of the parameter with respect to which to take the
derivative.</p>
</td></tr>
<tr><td><code id="dchol2par.elem_+3A_q">q</code></td>
<td>
<p>the column index of the parameter with respect to which to take the
derivative.</p>
</td></tr>
<tr><td><code id="dchol2par.elem_+3A_a">a</code></td>
<td>
<p>The row index of the covariance matrix element to be computed.</p>
</td></tr>
<tr><td><code id="dchol2par.elem_+3A_b">b</code></td>
<td>
<p>The column index of the covariance matrix element to be computed.</p>
</td></tr>
<tr><td><code id="dchol2par.elem_+3A_par.chol1">par.chol1</code></td>
<td>
<p>The vector of Cholesky parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Derivative of the function that transforms the cholesky parameters
to the specified element of the covariance matrix, evaluated at the specified
arguments.
</p>

<hr>
<h2 id='dD.hat'>Obtain the matrix of partial derivatives of the sample variances.</h2><span id='topic+dD.hat'></span>

<h3>Description</h3>

<p>This function computes the matrix of sample derivatives of the
sample variances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dD.hat(
  data,
  beta,
  t,
  hp,
  mi.mat = NULL,
  m.avg = NULL,
  dm.avg = NULL,
  dmi.tens = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dD.hat_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_t">t</code></td>
<td>
<p>Time point at which to evaluate the (derivatives of) the moment
functions. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_hp">hp</code></td>
<td>
<p>List of hyperparamerers.</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_mi.mat">mi.mat</code></td>
<td>
<p>A precomputed matrix of moment function evaluations at each
observation. If supplied, some computations can be skipped. Default is
<code>mi.mat = NULL</code>.</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_m.avg">m.avg</code></td>
<td>
<p>A precomputed vector of the sample average of the moment
functions. If not supplied, this vector is computed. Default is
<code>m.avg = NULL</code>.</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_dm.avg">dm.avg</code></td>
<td>
<p>Matrix of precomputed sample averages of the derivatives of the
moment functions. Default is <code>dm.avg = NULL</code>.</p>
</td></tr>
<tr><td><code id="dD.hat_+3A_dmi.tens">dmi.tens</code></td>
<td>
<p>3D tensor of precomputed evaluations of the derivatives of
the moment functions. Default is <code>dmi.tens = NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the partial derivatives of the variances of the
moment functions. Each row corresponds to a moment function, each column
corresponds to a covariate.
</p>

<hr>
<h2 id='Distance'>Distance between vectors</h2><span id='topic+Distance'></span>

<h3>Description</h3>

<p>This function computes distance between two vectors based on L2-norm
</p>
<p>This function computes distance between two vectors based on L2-norm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Distance(b, a)

Distance(b, a)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Distance_+3A_b">b</code></td>
<td>
<p>Second vector</p>
</td></tr>
<tr><td><code id="Distance_+3A_a">a</code></td>
<td>
<p>First vector</p>
</td></tr>
</table>

<hr>
<h2 id='dLambda_AFT_ll'>Derivative of link function (AFT model)</h2><span id='topic+dLambda_AFT_ll'></span>

<h3>Description</h3>

<p>This function defines the derivative of the AFT link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dLambda_AFT_ll(t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dLambda_AFT_ll_+3A_t">t</code></td>
<td>
<p>time parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='dLambda_Cox_wb'>Derivative of link function (Cox model)</h2><span id='topic+dLambda_Cox_wb'></span>

<h3>Description</h3>

<p>This function defines the derivative of the Cox PH link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dLambda_Cox_wb(t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dLambda_Cox_wb_+3A_t">t</code></td>
<td>
<p>time parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='dm.bar'>Vector of sample average of each moment function
<code class="reqn">(\bar{m}_n(\theta))</code>.</h2><span id='topic+dm.bar'></span>

<h3>Description</h3>

<p>This function computes the matrix containing the sample average
of the partial derivatives of the moment functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dm.bar(data, beta, t, hp, dmi.tens = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dm.bar_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="dm.bar_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="dm.bar_+3A_t">t</code></td>
<td>
<p>Time point at which to compute the derivative of the moment
functions. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="dm.bar_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="dm.bar_+3A_dmi.tens">dmi.tens</code></td>
<td>
<p>Tensor of derivative moment function evaluations. Can be used
to avoid some computation. Default is <code>dmi.tens = NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the sample average of the partial derivatives of
the moment functions. Each row corresponds to a moment function, each column
corresponds to a coefficient.
</p>

<hr>
<h2 id='do.optimization.Mstep'>Optimize the expected improvement</h2><span id='topic+do.optimization.Mstep'></span>

<h3>Description</h3>

<p>This function finds the point for which the expected improvement
is optimal, based on a given set of starting values. (M_step.R)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do.optimization.Mstep(start.vals, EI.Mstep, hyperparams)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="do.optimization.Mstep_+3A_start.vals">start.vals</code></td>
<td>
<p>Starting values for optimization.</p>
</td></tr>
<tr><td><code id="do.optimization.Mstep_+3A_ei.mstep">EI.Mstep</code></td>
<td>
<p>Function to compute expected improvements.</p>
</td></tr>
<tr><td><code id="do.optimization.Mstep_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximum of the expected imrpovement function.
</p>

<hr>
<h2 id='draw.sv.init'>Draw initial set of starting values for optimizing the expected
improvement.</h2><span id='topic+draw.sv.init'></span>

<h3>Description</h3>

<p>Used in the M-step (get.starting.values.R). ToDo: Adapt this
code so as to also perform sample space contractions as in the MatLab
implementation of Bei (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw.sv.init(theta.hash, dir, hyperparams, EI.fun)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="draw.sv.init_+3A_theta.hash">theta.hash</code></td>
<td>
<p>Tentative optimal value for theta, i.e., the largest or
smallest feasible value for theta (if dir = 1 or dir = -1, respectively). A
'feasible value' is one that satisfies all moment restrictions.</p>
</td></tr>
<tr><td><code id="draw.sv.init_+3A_dir">dir</code></td>
<td>
<p>Search direction. <code>dir = 1</code> corresponds to looking for an
upper bound. <code>dir = -1</code> corresponds to looking for a lower bound.</p>
</td></tr>
<tr><td><code id="draw.sv.init_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="draw.sv.init_+3A_ei.fun">EI.fun</code></td>
<td>
<p>Function used to compute the expected improvement. See also
<code>EI</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Initial set of starting values.
</p>


<h3>References</h3>

<p>Bei, X. (2024). Local linearieation based subvector inference in
moment inequality models. Journal of Econometrics. 238:105549-
</p>

<hr>
<h2 id='DYJtrans'>Derivative of the Yeo-Johnson transformation function</h2><span id='topic+DYJtrans'></span>

<h3>Description</h3>

<p>Evaluates the derivative of the Yeo-Johnson transformation at
the provided argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DYJtrans(y, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DYJtrans_+3A_y">y</code></td>
<td>
<p>The argument to be supplied to the derivative of the Yeo-Johnson
transformation.</p>
</td></tr>
<tr><td><code id="DYJtrans_+3A_theta">theta</code></td>
<td>
<p>The parameter of the Yeo-Johnson transformation. This should be
a number in the range [0,2].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformed value of y.
</p>

<hr>
<h2 id='E_step'>E-step in the EAM algorithm as described in KMS19.</h2><span id='topic+E_step'></span>

<h3>Description</h3>

<p>This function performs the estimation step in the EAM algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>E_step(thetas, test.fun, dir, evaluations, verbose)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="E_step_+3A_thetas">thetas</code></td>
<td>
<p>Points at which to perform the E-step. Usually the result of
the M-step.</p>
</td></tr>
<tr><td><code id="E_step_+3A_test.fun">test.fun</code></td>
<td>
<p>Function returning the test statistic, as well as the critical
value.</p>
</td></tr>
<tr><td><code id="E_step_+3A_dir">dir</code></td>
<td>
<p>Direction in which to optimize. For finding upper bounds, set
<code>dir = 1</code>, for finding lower bounds, set <code>dir = -1</code>.</p>
</td></tr>
<tr><td><code id="E_step_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix containing each point that was already evaluated,
alongside the corresponding test statistic and critical value, as its rows.</p>
</td></tr>
<tr><td><code id="E_step_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Results of the E-step.
</p>

<hr>
<h2 id='EAM'>Main function to run the EAM algorithm</h2><span id='topic+EAM'></span>

<h3>Description</h3>

<p>This function implements the EAM search strategy as described in
Kaido, Molinari and Stoye (2019). This is a generic function, requiring the
specification of a test function (<code>test.fun</code>), as well as the
specification of the parameter space (<code>hyperparams</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EAM(
  dir,
  test.fun,
  hyperparams,
  evaluations = NULL,
  time.run.duration = FALSE,
  verbose = 0,
  picturose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EAM_+3A_dir">dir</code></td>
<td>
<p>The direction of the test. <code>dir = 1</code> corresponds to finding
the upper bound of the identified set, <code>dir = -1</code> corresponds to finding
the lower bound.</p>
</td></tr>
<tr><td><code id="EAM_+3A_test.fun">test.fun</code></td>
<td>
<p>The test function to be inverted in order to obtain the
identified set. It should take a scalar parameter as argument (i.e. the
specified value of a component of the full parameter vector) and return a
list with named elements <code>list(theta, t.stat, crit.val)</code>, where
<code>theta</code> is the scalar value that was tested, <code>t.stat</code> is the value
of the test statistic and <code>crit.val</code> is the critical value to be used in
determining whether to reject or not reject.</p>
</td></tr>
<tr><td><code id="EAM_+3A_hyperparams">hyperparams</code></td>
<td>
<p>A list of hyperparameters needed in order for this method
to run (see <code>set.EAM.hyperparameters.R</code>).</p>
</td></tr>
<tr><td><code id="EAM_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of already evaluated points, of which at least one
is feasible. When <code>evaluations = NULL</code> (default), the initial feasible
point search will be executed first.</p>
</td></tr>
<tr><td><code id="EAM_+3A_time.run.duration">time.run.duration</code></td>
<td>
<p>Boolean value indicating whether to time each step
in the EAM algorithm. Requires <code>chronometer.R</code>. Default is
<code>time.run.duration = FALSE</code>.</p>
</td></tr>
<tr><td><code id="EAM_+3A_verbose">verbose</code></td>
<td>
<p>Boolean value indicating whether or not to print run time
updates to the console. Default is <code>verbose = FALSE</code>.</p>
</td></tr>
<tr><td><code id="EAM_+3A_picturose">picturose</code></td>
<td>
<p>Boolean value indicating whether or not to visualize the
identified set search. Default is <code>picturose = FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the evaluations of the test statistic and critical
values, convergence information, and run times.
</p>


<h3>References</h3>

<p>Kaido et al. (2019). Confidence intervals for projections of
partially identified parameters. Econometrica. 87(4):1397-1432.
</p>

<hr>
<h2 id='EAM.converged'>Check convergence of the EAM algorithm.</h2><span id='topic+EAM.converged'></span>

<h3>Description</h3>

<p>This function checks the convergence of the EAM algorithm.
ToDo: Get rid of hard coding stop of algorithm when no more improvement of
theta values (maybe related to parameter space contraction, since the problem
is that the given points to check in the E-step of the following iteration
can always be the same and always be rejected (except of course for the
randomly chosen one), while the most promising theta value continues to be
the same, infeasible value. In this way, it is possible that
theta.hash - mp.theta.next at some point will never decrease).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EAM.converged(
  opt.val.prev,
  evaluations,
  mp.theta.next,
  iter.nbr,
  dir,
  hyperparams,
  verbose
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EAM.converged_+3A_opt.val.prev">opt.val.prev</code></td>
<td>
<p>Previous optimal theta value.</p>
</td></tr>
<tr><td><code id="EAM.converged_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of violation curve evaluations.</p>
</td></tr>
<tr><td><code id="EAM.converged_+3A_mp.theta.next">mp.theta.next</code></td>
<td>
<p>Most promising value of theta for which to run the
E-step in the following iteration</p>
</td></tr>
<tr><td><code id="EAM.converged_+3A_iter.nbr">iter.nbr</code></td>
<td>
<p>Number of iterations of the EAM algorithm run so far.</p>
</td></tr>
<tr><td><code id="EAM.converged_+3A_dir">dir</code></td>
<td>
<p>Search direction.</p>
</td></tr>
<tr><td><code id="EAM.converged_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters used in the EAM algorithm.</p>
</td></tr>
<tr><td><code id="EAM.converged_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity parameter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Boolean value whether or not algorithm has converged.
</p>

<hr>
<h2 id='EI'>Expected improvement</h2><span id='topic+EI'></span>

<h3>Description</h3>

<p>Used in the M-step (M_step.R). Note: predict(fit.krige, ...)
has weird beheviour when making predictions for a single value in terms of
standard error. We work around this issue in this implementation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EI(theta, test.fun, fit.krige, theta.hash, dir)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EI_+3A_theta">theta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="EI_+3A_test.fun">test.fun</code></td>
<td>
<p>Test function (cf. <code>EstimationAlgorithmBei.R</code>).</p>
</td></tr>
<tr><td><code id="EI_+3A_fit.krige">fit.krige</code></td>
<td>
<p>Fitted Kriging model.</p>
</td></tr>
<tr><td><code id="EI_+3A_theta.hash">theta.hash</code></td>
<td>
<p>Tentative optimal value for theta, i.e., the largest or
smallest feasible value for theta (if dir = 1 or dir = -1, respectively). A
'feasible value' is one that satisfies all moment restrictions.</p>
</td></tr>
<tr><td><code id="EI_+3A_dir">dir</code></td>
<td>
<p>Search direction. <code>dir = 1</code> corresponds to looking for an
upper bound. <code>dir = -1</code> corresponds to looking for a lower bound.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The expected improvement.
</p>

<hr>
<h2 id='estimate.cf'>Estimate the control function</h2><span id='topic+estimate.cf'></span>

<h3>Description</h3>

<p>This function estimates the control function for the endogenous
variable based on the provided covariates. This function is called inside
estimate.cmprsk.R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.cf(XandW, Z, Zbin, gammaest = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.cf_+3A_xandw">XandW</code></td>
<td>
<p>Design matrix of exogenous covariates.</p>
</td></tr>
<tr><td><code id="estimate.cf_+3A_z">Z</code></td>
<td>
<p>Endogenous covariate.</p>
</td></tr>
<tr><td><code id="estimate.cf_+3A_zbin">Zbin</code></td>
<td>
<p>Boolean value indicating whether endogenous covariate is binary.</p>
</td></tr>
<tr><td><code id="estimate.cf_+3A_gammaest">gammaest</code></td>
<td>
<p>Vector of pre-estimated parameter vector. If <code>NULL</code>,
this function will first estimate <code>gammaest</code>. Default value is
<code>gammaest = NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the vector of values for the control function and
the regression parameters of the first step.
</p>

<hr>
<h2 id='estimate.cmprsk'>Estimate the competing risks model of Rutten, Willems et al. (20XX).</h2><span id='topic+estimate.cmprsk'></span>

<h3>Description</h3>

<p>This function estimates the parameters in the competing risks
model described in Willems et al. (2024+). Note that this model
extends the model of Crommen, Beyhum and Van Keilegom (2024) and as such, this
function also implements their methodology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estimate.cmprsk(
  data,
  admin,
  conf,
  eoi.indicator.names = NULL,
  Zbin = NULL,
  inst = "cf",
  realV = NULL,
  compute.var = TRUE,
  eps = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="estimate.cmprsk_+3A_data">data</code></td>
<td>
<p>A data frame, adhering to the following formatting rules:
</p>

<ul>
<li><p> The first column, named <code>"y"</code>, contains the observed times.
</p>
</li>
<li><p> The next columns, named <code>"delta1"</code>, <code>delta2</code>, etc. contain
the indicators for each of the competing risks.
</p>
</li>
<li><p> The next column, named <code>da</code>, contains the censoring indicator
(independent censoring).
</p>
</li>
<li><p> The next column should be a column of all ones (representing the
intercept), names <code>x0</code>.
</p>
</li>
<li><p> The subsequent columns should contain the values of the covariates,
named <code>x1</code>, <code>x2</code>, etc.
</p>
</li>
<li><p> When applicable, the next column should contain the values of the
endogenous variable. This column should be named <code>z</code>.
</p>
</li>
<li><p> When <code>z</code> is provided and an instrument for <code>z</code> is
available, the next column, named <code>w</code>, should contain the values for
the instrument.
</p>
</li></ul>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of <code>z</code> and, possibly, <code>w</code>.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_eoi.indicator.names">eoi.indicator.names</code></td>
<td>
<p>Vector of names of the censoring indicator columns
pertaining to events of interest. Events of interest will be modeled allowing
dependence between them, whereas all censoring events (corresponding to
indicator columns not listed in <code>eoi.indicator.names</code>) will be treated
as independent of every other event. If <code>eoi.indicator.names == NULL</code>,
all events will be modeled dependently.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_zbin">Zbin</code></td>
<td>
<p>Indicator value indicating whether (<code>Zbin = TRUE</code>) or not
<code>Zbin = FALSE</code> the endogenous covariate is binary. Default is
<code>Zbin = NULL</code>, corresponding to the case when <code>conf == FALSE</code>.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_inst">inst</code></td>
<td>
<p>Variable encoding which approach should be used for dealing with
the confounding. <code>inst = "cf"</code> indicates that the control function
approach should be used. <code>inst = "W"</code> indicates that the instrumental
variable should be used 'as is'. <code>inst = "None"</code> indicates that Z will
be treated as an exogenous covariate. Finally, when <code>inst = "oracle"</code>,
this function will access the argument <code>realV</code> and use it as the values
for the control function. Default is <code>inst = "cf"</code>.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_realv">realV</code></td>
<td>
<p>Vector of numerics with length equal to the number of rows in
<code>data</code>. Used to provide the true values of the instrumental function
to the estimation procedure.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_compute.var">compute.var</code></td>
<td>
<p>Boolean value indicating whether the variance of the
parameter estimates should be computed as well (this can be very
computationally intensive, so may want to be disabled). Default is
<code>estimate.var = TRUE</code>.</p>
</td></tr>
<tr><td><code id="estimate.cmprsk_+3A_eps">eps</code></td>
<td>
<p>Value that will be added to the diagonal of the covariance matrix
during estimation in order to ensure strictly positive variances.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of parameter estimates in the second stage of the estimation
algorithm (hence omitting the estimates for the control function), as well
as an estimate of their variance and confidence intervals.
</p>


<h3>References</h3>

<p>Willems et al. (2024+). Flexible control function approach under competing risks (in preparation).
</p>
<p>Crommen, G., Beyhum, J., and Van Keilegom, I. (2024). An instrumental variable approach under dependent censoring. Test, 33(2), 473-495.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

n &lt;- 200

# Set parameters
gamma &lt;- c(1, 2, 1.5, -1)
theta &lt;- c(0.5, 1.5)
eta1 &lt;- c(1, -1, 2, -1.5, 0.5)
eta2 &lt;- c(0.5, 1, 1, 3, 0)

# Generate exogenous covariates
x0 &lt;- rep(1, n)
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.5)

# Generate confounder and instrument
w &lt;- rnorm(n)
V &lt;- rnorm(n, 0, 2)
z &lt;- cbind(x0, x1, x2, w) %*% gamma + V
realV &lt;- z - (cbind(x0, x1, x2, w) %*% gamma)

# Generate event times
err &lt;- MASS::mvrnorm(n, mu = c(0, 0), Sigma =
matrix(c(3, 1, 1, 2), nrow = 2, byrow = TRUE))
bn &lt;- cbind(x0, x1, x2, z, realV) %*% cbind(eta1, eta2) + err
Lambda_T1 &lt;- bn[,1]; Lambda_T2 &lt;- bn[,2]
x.ind = (Lambda_T1&gt;0)
y.ind &lt;- (Lambda_T2&gt;0)
T1 &lt;- rep(0,length(Lambda_T1))
T2 &lt;- rep(0,length(Lambda_T2))
T1[x.ind] = ((theta[1]*Lambda_T1[x.ind]+1)^(1/theta[1])-1)
T1[!x.ind] = 1-(1-(2-theta[1])*Lambda_T1[!x.ind])^(1/(2-theta[1]))
T2[y.ind] = ((theta[2]*Lambda_T2[y.ind]+1)^(1/theta[2])-1)
T2[!y.ind] = 1-(1-(2-theta[2])*Lambda_T2[!y.ind])^(1/(2-theta[2]))
# Generate adminstrative censoring time
C &lt;- runif(n, 0, 40)

# Create observed data set
y &lt;- pmin(T1, T2, C)
delta1 &lt;- as.numeric(T1 == y)
delta2 &lt;- as.numeric(T2 == y)
da &lt;- as.numeric(C == y)
data &lt;- data.frame(cbind(y, delta1, delta2, da, x0, x1, x2, z, w))
colnames(data) &lt;- c("y", "delta1", "delta2", "da", "x0", "x1", "x2", "z", "w")

# Estimate the model
admin &lt;- TRUE                # There is administrative censoring in the data.
conf &lt;- TRUE                 # There is confounding in the data (z)
eoi.indicator.names &lt;- NULL  # We will not impose that T1 and T2 are independent
Zbin &lt;- FALSE                # The confounding variable z is not binary
inst &lt;- "cf"                 # Use the control function approach
compute.var &lt;- TRUE          # Variance of estimates should be computed.
# Since we don't use the oracle estimator, this argument is ignored anyway
realV &lt;- NULL
estimate.cmprsk(data, admin, conf, eoi.indicator.names, Zbin, inst, realV,
                compute.var)



</code></pre>

<hr>
<h2 id='feasible_point_search'>Method for finding initial points of the EAM algorithm</h2><span id='topic+feasible_point_search'></span>

<h3>Description</h3>

<p>Also called the 'initialization' step in KMS19, this method
tries to find at least one initial feasible point, which is required to run
the EAM algorithm.
ToDo: Investigate whether the feasible point search of Bei (2024) is better.
If so, implement it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feasible_point_search(
  test.fun,
  hyperparams,
  verbose,
  picturose = FALSE,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="feasible_point_search_+3A_test.fun">test.fun</code></td>
<td>
<p>Function that takes a parameter vector as a first argument
and returns the test statistic, as well as the critical value.</p>
</td></tr>
<tr><td><code id="feasible_point_search_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="feasible_point_search_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity parameter.</p>
</td></tr>
<tr><td><code id="feasible_point_search_+3A_picturose">picturose</code></td>
<td>
<p>Picturosity flag. If <code>TRUE</code>, a plot illustrating the
workings of the algorithm will updated during runtime. Default is
<code>picturose = FALSE</code>.</p>
</td></tr>
<tr><td><code id="feasible_point_search_+3A_parallel">parallel</code></td>
<td>
<p>Flag for whether or not parallel computing should be used.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Results of the initial feasible point search.
</p>


<h3>References</h3>

<p>Kaido et al. (2019). Confidence intervals for projections of
partially identified parameters. Econometrica. 87(4):1397-1432.
</p>

<hr>
<h2 id='fitDepCens'>Fit Dependent Censoring Models</h2><span id='topic+fitDepCens'></span>

<h3>Description</h3>

<p>This function allows to estimate the dependency parameter along all other model parameters. First, estimates the cumulative hazard function, and
then at the second stage it estimates other model parameters assuming that the cumulative hazard function is known. The details for
implementing the dependent censoring methodology can be found in Deresa and Van Keilegom (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitDepCens(
  resData,
  X,
  W,
  cop = c("Frank", "Gumbel", "Normal"),
  dist = c("Weibull", "lognormal"),
  start = NULL,
  n.iter = 50,
  bootstrap = TRUE,
  n.boot = 150,
  ncore = 7,
  eps = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitDepCens_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be a vector of ones.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_cop">cop</code></td>
<td>
<p>Which copula should be computed to account for dependency between T and C. This argument can take
one of the values from <code>c("Gumbel", "Frank", "Normal")</code>.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_dist">dist</code></td>
<td>
<p>The distribution to be used for the censoring time C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_start">start</code></td>
<td>
<p>Initial values for the finite dimensional parameters. If <code>start</code> is NULL, the initial values will be obtained
by fitting a Cox model for survival time T and a Weibull model for dependent censoring C.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations; the default is <code>n.iter = 50</code>. The larger the number of iterations, the longer the computational time.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_bootstrap">bootstrap</code></td>
<td>
<p>A boolean indicating whether to compute bootstrap standard errors for making inferences.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstrap samples to use in the estimation of bootstrap standard errors if <code>bootstrap = TRUE</code>. The default is n.boot = 150. But, higher
values  of <code>n.boot</code> are recommended for obtaining good estimates of bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_ncore">ncore</code></td>
<td>
<p>The number of cores to use for parallel computation in bootstrapping, with the default <code>ncore = 7</code>.</p>
</td></tr>
<tr><td><code id="fitDepCens_+3A_eps">eps</code></td>
<td>
<p>Convergence error. This is set by the user in such away that the desired convergence is met; the default is <code>eps = 1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a fit of dependent censoring model; parameter estimates, estimate of the cumulative hazard function, bootstrap standard
errors for finite-dimensional parameters, the nonparametric cumulative hazard function, etc.
</p>


<h3>References</h3>

<p>Deresa and Van Keilegom (2024). Copula based Cox proportional hazards models for dependent censoring, Journal of the American Statistical Association, 119:1044-1054.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Toy data example to illustrate implementation
n = 300
beta = c(0.5)
lambd = 0.35
eta = c(0.9,0.4)
X = cbind(rbinom(n,1,0.5))
W = cbind(rep(1,n),rbinom(n,1,0.5))
# generate dependency structure from Frank
frank.cop &lt;- copula::frankCopula(param = 5,dim = 2)
U = copula::rCopula(n,frank.cop)
T1 = (-log(1-U[,1]))/(lambd*exp(X*beta))           # Survival time
T2 = (-log(1-U[,2]))^(1.1)*exp(W%*%eta)            # Censoring time
A = runif(n,0,15)                                  # administrative censoring time
Z = pmin(T1,T2,A)
d1 = as.numeric(Z==T1)
d2 = as.numeric(Z==T2)
resData = data.frame("Z" = Z,"d1" = d1, "d2" = d2)   # should be data frame
colnames(W) &lt;- c("ones","cov1")
colnames(X) &lt;- "cov.surv"

# Fit dependent censoring model

fit &lt;- fitDepCens(resData = resData, X = X, W = W, bootstrap = FALSE)

# parameter estimates

fit$parameterEstimates

# summary fit results
summary(fit)

# plot cumulative hazard vs time

plot(fit$observedTime, fit$cumhazardFunction, type = "l",xlab = "Time",
ylab = "Estimated cumulative hazard function")


</code></pre>

<hr>
<h2 id='fitIndepCens'>Fit Independent Censoring Models</h2><span id='topic+fitIndepCens'></span>

<h3>Description</h3>

<p>This function allows to estimate all model parameters under the assumption of independent censoring. First, estimates the cumulative hazard function, and
then at the second stage it estimates other model parameters assuming that the cumulative hazard is known.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitIndepCens(
  resData,
  X,
  W,
  dist = c("Weibull", "lognormal"),
  start = NULL,
  n.iter = 50,
  bootstrap = TRUE,
  n.boot = 150,
  ncore = 7,
  eps = 1e-04
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitIndepCens_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be ones.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_dist">dist</code></td>
<td>
<p>The distribution to be used for the censoring time C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_start">start</code></td>
<td>
<p>Initial values for the finite dimensional parameters. If <code>start</code> is NULL, the initial values will be obtained
by fitting a Cox model for survival time T and a Weibull model for censoring time C.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations; the default is <code>n.iter = 50</code>. The larger the number of iterations, the longer the computational time.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_bootstrap">bootstrap</code></td>
<td>
<p>A boolean indicating whether to compute bootstrap standard errors for making inferences.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstrap samples to use in the estimation of bootstrap standard errors if <code>bootstrap = TRUE</code>. The default is n.boot = 150. But, higher
values  of <code>n.boot</code> are recommended for obtaining good estimates of bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_ncore">ncore</code></td>
<td>
<p>The number of cores to use for parallel computation is configurable, with the default <code>ncore = 7</code>.</p>
</td></tr>
<tr><td><code id="fitIndepCens_+3A_eps">eps</code></td>
<td>
<p>Convergence error. This is set by the user in such away that the desired convergence is met; the default is <code>eps = 1e-4</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a fit of independent censoring model; parameter estimates, estimate of the cumulative hazard function, bootstrap standard
errors for finite-dimensional parameters, the nonparametric cumulative hazard function, etc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Toy data example to illustrate implementation
n = 300
beta = c(0.5)
lambd = 0.35
eta = c(0.9,0.4)
X = cbind(rbinom(n,1,0.5))
W = cbind(rep(1,n),rbinom(n,1,0.5))
# generate dependency structure from Frank
frank.cop &lt;- copula::frankCopula(param = 5,dim = 2)
U = copula::rCopula(n,frank.cop)
T1 = (-log(1-U[,1]))/(lambd*exp(X*beta))                  # Survival time'
T2 = (-log(1-U[,2]))^(1.1)*exp(W%*%eta)                   # Censoring time
A = runif(n,0,15)                                         # administrative censoring time
Z = pmin(T1,T2,A)
d1 = as.numeric(Z==T1)
d2 = as.numeric(Z==T2)
resData = data.frame("Z" = Z,"d1" = d1, "d2" = d2)     # should be data frame

colnames(W) &lt;- c("ones","cov1")
colnames(X) &lt;- "cov.surv"

# Fit independent censoring model

fitI &lt;- fitIndepCens(resData = resData, X = X, W = W, bootstrap = FALSE)

# parameter estimates

fitI$parameterEstimates

# summary fit results
summary(fitI)

# plot cumulative hazard vs time

 plot(fitI$observedTime, fitI$cumhazardFunction, type = "l",xlab = "Time",
 ylab = "Estimated cumulative hazard function")


</code></pre>

<hr>
<h2 id='G.box'>Family of box functions</h2><span id='topic+G.box'></span>

<h3>Description</h3>

<p>This function defined the class of box functions as defined in
Willems et al. (2024+).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>G.box(
  x,
  g.idx,
  data,
  n.box.per.cov,
  norm.func,
  cov.ranges = NULL,
  norm.cov.out = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="G.box_+3A_x">x</code></td>
<td>
<p>Vector of covariates to be normalized alongside the data. Default is
<code>x = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.box_+3A_g.idx">g.idx</code></td>
<td>
<p>Index of the instrumental function, in {1, ..., n.inst.func}.</p>
</td></tr>
<tr><td><code id="G.box_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="G.box_+3A_n.box.per.cov">n.box.per.cov</code></td>
<td>
<p>Number of box functions to consider per continuous
covariate.</p>
</td></tr>
<tr><td><code id="G.box_+3A_norm.func">norm.func</code></td>
<td>
<p>Function to be used to normalize the covariates.</p>
</td></tr>
<tr><td><code id="G.box_+3A_cov.ranges">cov.ranges</code></td>
<td>
<p>Matrix of ranges of the covariates. Used for normalizing
the data to the unit interval before applying the instrumental functions.
Default is <code>cov.ranges = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.box_+3A_norm.cov.out">norm.cov.out</code></td>
<td>
<p>Output of a preliminary call to the supplied covariate
normalization function.</p>
</td></tr>
<tr><td><code id="G.box_+3A_...">...</code></td>
<td>
<p>Additional arguments will be ignored. Useful for allowing
compatibility with the implementations of other instrument function families.
Specifically, it allows to ignore the <code>degree</code> argument used in
'G.spline.R' and 'G.cd.R'.</p>
</td></tr>
</table>

<hr>
<h2 id='G.cd'>Family of continuous/discrete instrumental function</h2><span id='topic+G.cd'></span>

<h3>Description</h3>

<p>The function normalizes the continuous covariates to lie in the
unit interval and then evaluates the subvector of continuous covariates on
the specified family of instrumental function. For the discrete elements,
indicator functions are used for each level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>G.cd(
  x,
  g.idx,
  data,
  n.if.per.cov,
  idxs.c,
  G.c,
  norm.func,
  discrete.covariate.levels = NULL,
  cov.ranges = NULL,
  norm.cov.out = NULL,
  degree = 3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="G.cd_+3A_x">x</code></td>
<td>
<p>The vector of covariates at which to evaluate the B-splines</p>
</td></tr>
<tr><td><code id="G.cd_+3A_g.idx">g.idx</code></td>
<td>
<p>The index of the instrumental function.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_data">data</code></td>
<td>
<p>Data frame containing the data.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_n.if.per.cov">n.if.per.cov</code></td>
<td>
<p>Number of instrumental functions per continuous covariate.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_idxs.c">idxs.c</code></td>
<td>
<p>Vector of indices of the continuous elements in the vector of
covariates.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_g.c">G.c</code></td>
<td>
<p>Family of instrumental functions to use for the subvector of
continuous covariates.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_norm.func">norm.func</code></td>
<td>
<p>Function to be used to normalize the covariates.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_discrete.covariate.levels">discrete.covariate.levels</code></td>
<td>
<p>Matrix containing as rows all possible
'combined' levels of the discrete covariates. Default is
<code>discrete.covariate.levels = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_cov.ranges">cov.ranges</code></td>
<td>
<p>Matrix containing as its rows the lower and upper bounds
for each continuous covariate. Default is <code>cov.ranges = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_norm.cov.out">norm.cov.out</code></td>
<td>
<p>Output of a preliminary call to a covariate normalization
function (defined above). This is used to speed up computations. Note that
this argument should only apply to continuous covariates!! Default is
<code>norm.cov.out = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.cd_+3A_degree">degree</code></td>
<td>
<p>Degree of the spline functions to be used as instrumental
functions for the continuous covariates (if applicable). Default is
<code>degree = 3</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='G.cd.mc'>Family of discrete/continuous instrumental functions, in the case of
many covariates.</h2><span id='topic+G.cd.mc'></span>

<h3>Description</h3>

<p>This function defines the family of discrete/continuous
instrumental functions in the case of many covariates. It does so by
considering a instrumental functions for each pair of entries in the given
covariate vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>G.cd.mc(
  x,
  g.idx,
  data,
  n.if.per.cov,
  idxs.c,
  G.c,
  norm.func,
  info.manycov = NULL,
  cov.ranges = NULL,
  norm.cov.out = NULL,
  degree = 3,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="G.cd.mc_+3A_x">x</code></td>
<td>
<p>The vector of covariates at which to evaluate the B-splines</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_g.idx">g.idx</code></td>
<td>
<p>The index of the instrumental function.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_data">data</code></td>
<td>
<p>Data frame containing the data.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_n.if.per.cov">n.if.per.cov</code></td>
<td>
<p>Number of instrumental functions per continuous covariate.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_idxs.c">idxs.c</code></td>
<td>
<p>Vector of indices of the continuous elements in the vector of
covariates.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_g.c">G.c</code></td>
<td>
<p>Family of instrumental functions to use for the subvector of
continuous covariates.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_norm.func">norm.func</code></td>
<td>
<p>Function to be used to normalize the covariates.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_info.manycov">info.manycov</code></td>
<td>
<p>Data frame containing some information about the global
structure of the instrumental functions of this class. If
<code>info.manycov = NULL</code>, it will be computed during execution. Default is
<code>info.manycov = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_cov.ranges">cov.ranges</code></td>
<td>
<p>Matrix containing as its rows the lower and upper bounds
for each continuous covariate. Default is <code>cov.ranges = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_norm.cov.out">norm.cov.out</code></td>
<td>
<p>Output of function that normalizes the covariates.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_degree">degree</code></td>
<td>
<p>Degree of the spline functions to be used as instrumental
functions for the continuous covariates (if applicable). Default is
<code>degree = 3</code>.</p>
</td></tr>
<tr><td><code id="G.cd.mc_+3A_...">...</code></td>
<td>
<p>Arguments specified here will be ignored. Used for compatibility
with other instrumental function classes.</p>
</td></tr>
</table>

<hr>
<h2 id='G.hat'>Compute the Gn matrix in step 3b of Bei (2024).</h2><span id='topic+G.hat'></span>

<h3>Description</h3>

<p>Compute the Gn matrix in step 3b of Bei (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>G.hat(
  data,
  beta,
  t,
  hp,
  mi.mat = NULL,
  m.avg = NULL,
  dm.avg = NULL,
  dmi.tens = NULL,
  D = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="G.hat_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_t">t</code></td>
<td>
<p>Time point at which to evaluate the (derivatives of) the moment
functions.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_hp">hp</code></td>
<td>
<p>List of hyperparamerers.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_mi.mat">mi.mat</code></td>
<td>
<p>A precomputed matrix of moment function evaluations at each
observation. If supplied, some computations can be skipped. Default is
<code>mi.mat = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_m.avg">m.avg</code></td>
<td>
<p>A precomputed vector of the sample average of the moment
functions. If not supplied, this vector is computed. Default is
<code>m.avg = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_dm.avg">dm.avg</code></td>
<td>
<p>Matrix of precomputed sample averages of the derivatives of the
moment functions. Default is <code>dm.avg = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_dmi.tens">dmi.tens</code></td>
<td>
<p>3D tensor of precomputed evaluations of the derivatives of
the moment functions. Default is <code>dmi.tens = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.hat_+3A_d">D</code></td>
<td>
<p>Diagonal of D-matrix.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix containing the partial derivatives of the variances of the
moment functions. Each row corresponds to a moment function, each column
corresponds to a covariate.
</p>


<h3>References</h3>

<p>Bei, X. (2024). Local linearieation based subvector inference in
moment inequality models. Journal of Econometrics. 238:105549-
</p>

<hr>
<h2 id='G.spline'>Family of spline instrumental functions</h2><span id='topic+G.spline'></span>

<h3>Description</h3>

<p>This function normalizes the covariates to lie in the unit
interval and then evaluates each B-spline at each observation, multiplying
together the results per observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>G.spline(
  x,
  g.idx,
  data,
  n.if.per.cov,
  norm.func,
  cov.ranges = NULL,
  norm.cov.out = NULL,
  degree = 3
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="G.spline_+3A_x">x</code></td>
<td>
<p>The vector of covariates at which to evaluate the B-splines</p>
</td></tr>
<tr><td><code id="G.spline_+3A_g.idx">g.idx</code></td>
<td>
<p>The index of the instrumental function. Note that g.idx ranges
between 1 and n.if.per.cov^n.cov, as an instrumental function is the product
of the appropriate B-spline evaluation for each element in the covariate
vector.</p>
</td></tr>
<tr><td><code id="G.spline_+3A_data">data</code></td>
<td>
<p>Data frame containing the data.</p>
</td></tr>
<tr><td><code id="G.spline_+3A_n.if.per.cov">n.if.per.cov</code></td>
<td>
<p>Number of instrumental variables to be used per covariate.</p>
</td></tr>
<tr><td><code id="G.spline_+3A_norm.func">norm.func</code></td>
<td>
<p>Function to be used to normalize the covariates.</p>
</td></tr>
<tr><td><code id="G.spline_+3A_cov.ranges">cov.ranges</code></td>
<td>
<p>Matrix of ranges of the covariates. Used for normalizing
the covariates. If <code>cov.ranges = NULL</code>, the data will be normalized in a
data-dependent way. Default is <code>cov.ranges = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.spline_+3A_norm.cov.out">norm.cov.out</code></td>
<td>
<p>Output of a preliminary call to the given covariate
normalization function. Default is <code>norm.cov.out = NULL</code>.</p>
</td></tr>
<tr><td><code id="G.spline_+3A_degree">degree</code></td>
<td>
<p>Degree of B-splines to use. Default value is <code>degree = 3</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='generator.Archimedean'>The generator function of the Archimedean copula</h2><span id='topic+generator.Archimedean'></span>

<h3>Description</h3>

<p>The generator function of the Archimedean copula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generator.Archimedean(x, coppar, copfam, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generator.Archimedean_+3A_x">x</code></td>
<td>
<p>the value at which the generator function will be calculated at.</p>
</td></tr>
<tr><td><code id="generator.Archimedean_+3A_coppar">coppar</code></td>
<td>
<p>a numeric value that denotes the copula parameter.</p>
</td></tr>
<tr><td><code id="generator.Archimedean_+3A_copfam">copfam</code></td>
<td>
<p>a character string that denotes the copula family.</p>
</td></tr>
<tr><td><code id="generator.Archimedean_+3A_inverse">inverse</code></td>
<td>
<p>a logical value that specifies whether the inverse function will be used.</p>
</td></tr>
</table>

<hr>
<h2 id='get.anchor.points'>Get anchor points on which to base the instrumental functions</h2><span id='topic+get.anchor.points'></span>

<h3>Description</h3>

<p>The points returned by this function can be used as corner
points in the family of box functions, or as knots in the family of B-spline
functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.anchor.points(data, n.if.per.cov, normalized = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.anchor.points_+3A_data">data</code></td>
<td>
<p>Data set.</p>
</td></tr>
<tr><td><code id="get.anchor.points_+3A_n.if.per.cov">n.if.per.cov</code></td>
<td>
<p>Number of instrumental functions to use per continuous
covariate.</p>
</td></tr>
<tr><td><code id="get.anchor.points_+3A_normalized">normalized</code></td>
<td>
<p>Boolean value indicating whether the covariates in the
given data frame have been normalized. Default is <code>normalized = FALSE</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='get.cond.moment.evals'>Compute the conditional moment evaluations</h2><span id='topic+get.cond.moment.evals'></span>

<h3>Description</h3>

<p>This function computes the 1(Y &lt;= t) - Lambda(X^T beta(t)) and
Lambda(X^T beta(t)) - 1(Y &lt;= t, Delta = 1) parts of the moment functions.
(Used in function get.mi.mat.R)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.cond.moment.evals(data, beta, t, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.cond.moment.evals_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.cond.moment.evals_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="get.cond.moment.evals_+3A_t">t</code></td>
<td>
<p>Time point of interest.</p>
</td></tr>
<tr><td><code id="get.cond.moment.evals_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of 2n elements containing in the first n positions the
evaluations of 1(Y &lt;= t) - Lambda(X^T beta(t)) and in the last n positions
the evaluations of Lambda(X^T beta(t)) - 1(Y &lt;= t, Delta = 1).
</p>

<hr>
<h2 id='get.cvLLn'>Compute the critical value of the test statistic.</h2><span id='topic+get.cvLLn'></span>

<h3>Description</h3>

<p>This function computes the critical value following the
algorithm of Section 4.3 in Bei (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.cvLLn(
  BetaI.r,
  data,
  t,
  hp,
  c,
  r,
  par.space,
  inst.func.evals = NULL,
  alpha = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.cvLLn_+3A_betai.r">BetaI.r</code></td>
<td>
<p>Matrix containing in its columns the minimizers of the
S-function leading to the test statistic.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_t">t</code></td>
<td>
<p>Time point of interest. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_c">c</code></td>
<td>
<p>Projection vector.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_r">r</code></td>
<td>
<p>Result of projection of parameter vector onto <code>c</code>.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_par.space">par.space</code></td>
<td>
<p>Bounds on the parameter space.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Matrix of precomputed instrumental function
evaluations for each observation in the data set. If <code>NULL</code>, the
evaluations will be computed during execution of this function. Default is
<code>inst.func.evals = NULL</code>.</p>
</td></tr>
<tr><td><code id="get.cvLLn_+3A_alpha">alpha</code></td>
<td>
<p>Confidence level.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The critical value for the test statistic.
</p>


<h3>References</h3>

<p>Bei, X. (2024). Local linearieation based subvector inference in
moment inequality models. Journal of Econometrics. 238:105549-
</p>

<hr>
<h2 id='get.deriv.mom.func'>Matrix of derivatives of conditional moment functions</h2><span id='topic+get.deriv.mom.func'></span>

<h3>Description</h3>

<p>This function evaluates the derivatives of the conditional
moment function at each observation. Used in get.dmi.tens.R
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.deriv.mom.func(data, beta, t, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.deriv.mom.func_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.deriv.mom.func_+3A_beta">beta</code></td>
<td>
<p>Parameter vector.</p>
</td></tr>
<tr><td><code id="get.deriv.mom.func_+3A_t">t</code></td>
<td>
<p>Time point of interest.</p>
</td></tr>
<tr><td><code id="get.deriv.mom.func_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>

<hr>
<h2 id='get.dmi.tens'>Faster implementation to obtain the tensor of the evaluations of the
derivatives of the moment functions at each observation.</h2><span id='topic+get.dmi.tens'></span>

<h3>Description</h3>

<p>This function provides a faster implementation of obtaining the
evaluations of the derivative of the moment functions at each observation
(wrt the previous implementation using 'dm.comp' and 'dm.R'). Used in the
function G.hat.R
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.dmi.tens(data, beta, t, hp, inst.func.evals = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.dmi.tens_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.dmi.tens_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="get.dmi.tens_+3A_t">t</code></td>
<td>
<p>Time point of interest. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="get.dmi.tens_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="get.dmi.tens_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Precomputed matrix of instrumental function
evaluations. Defaults is <code>inst.func.evals = NULL</code>, in which case the
evaluations will be done inside this function.</p>
</td></tr>
</table>

<hr>
<h2 id='get.extra.Estep.points'>Get extra evaluation points for E-step</h2><span id='topic+get.extra.Estep.points'></span>

<h3>Description</h3>

<p>Function used to obtain extra theta values to be supplied to the
E-step in the next iteration (M_step.R). Note: this function should be
changed when implementing the sample space contractions (see comment made in
documentation of <code>M_step</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.extra.Estep.points(dir, theta.hash, maxviol.hash, hyperparams)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.extra.Estep.points_+3A_dir">dir</code></td>
<td>
<p>Search direction. <code>dir = 1</code> corresponds to looking for an
upper bound. <code>dir = -1</code> corresponds to looking for a lower bound.</p>
</td></tr>
<tr><td><code id="get.extra.Estep.points_+3A_theta.hash">theta.hash</code></td>
<td>
<p>Tentative optimal value for theta, i.e., the largest or
smallest feasible value for theta (if dir = 1 or dir = -1, respectively). A
'feasible value' is one that satisfies all moment restrictions.</p>
</td></tr>
<tr><td><code id="get.extra.Estep.points_+3A_maxviol.hash">maxviol.hash</code></td>
<td>
<p>Violation curve evaluated at  <code>theta.hash</code>.</p>
</td></tr>
<tr><td><code id="get.extra.Estep.points_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Points to evaluate in E-step.
</p>

<hr>
<h2 id='get.instrumental.function.evals'>Evaluate each instrumental function at each of the observations.</h2><span id='topic+get.instrumental.function.evals'></span>

<h3>Description</h3>

<p>Obtain the evaluations of each observation on each of the
instrumental functions. (Used in function get.mi.mat.R)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.instrumental.function.evals(data, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.instrumental.function.evals_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.instrumental.function.evals_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters. Notably, it contains the instrumental
function to be used in an element named <code>G</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='get.mi.mat'>Faster implementation of vector of moment functions.</h2><span id='topic+get.mi.mat'></span>

<h3>Description</h3>

<p>This function obtains the moment function evaluations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.mi.mat(data, beta, t, hp, inst.func.evals = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.mi.mat_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.mi.mat_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="get.mi.mat_+3A_t">t</code></td>
<td>
<p>Time point at which to compute the moment function. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="get.mi.mat_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters</p>
</td></tr>
<tr><td><code id="get.mi.mat_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Matrix of instrumental function evaluations. If
<code>NULL</code>, it will be computed during execution of this function. Default
value is <code>inst.func.evals = NULL</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='get.next.point'>Obtain next point for feasible point search.</h2><span id='topic+get.next.point'></span>

<h3>Description</h3>

<p>Function to obtain the next point to evaluate in the search for a feasible
point. This function evaluates the entire parameter space of the component of
theta as evenly as possible. Used in the initialization step
(feasible_point_search.R)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.next.point(evaluations, lb.theta, ub.theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.next.point_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of evaluations performed so far.</p>
</td></tr>
<tr><td><code id="get.next.point_+3A_lb.theta">lb.theta</code></td>
<td>
<p>Lower bound on the parameter of interest.</p>
</td></tr>
<tr><td><code id="get.next.point_+3A_ub.theta">ub.theta</code></td>
<td>
<p>Upper bound on the parameter of interest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Next point in the feasible point search.
</p>

<hr>
<h2 id='get.starting.values'>Main function for obtaining the starting values of the expected
improvement maximization step.</h2><span id='topic+get.starting.values'></span>

<h3>Description</h3>

<p>Obtain starting values used in the M-step (M_step.R).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.starting.values(theta.hash, dir, EI.Mstep, hyperparams)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.starting.values_+3A_theta.hash">theta.hash</code></td>
<td>
<p>Tentative optimal value for theta, i.e., the largest or
smallest feasible value for theta (if dir = 1 or dir = -1, respectively). A
'feasible value' is one that satisfies all moment restrictions.</p>
</td></tr>
<tr><td><code id="get.starting.values_+3A_dir">dir</code></td>
<td>
<p>Search direction. <code>dir = 1</code> corresponds to looking for an
upper bound. <code>dir = -1</code> corresponds to looking for a lower bound.</p>
</td></tr>
<tr><td><code id="get.starting.values_+3A_ei.mstep">EI.Mstep</code></td>
<td>
<p>Function to compute expected improvements.</p>
</td></tr>
<tr><td><code id="get.starting.values_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of starting values
</p>

<hr>
<h2 id='get.test.statistic'>Obtain the test statistic by minimizing the S-function over the
feasible region <code class="reqn">\beta(r)</code>.</h2><span id='topic+get.test.statistic'></span>

<h3>Description</h3>

<p>Obtain the test statistic by minimizing the S-function over the
feasible region <code class="reqn">\beta(r)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.test.statistic(
  beta.init,
  data,
  par.space,
  t,
  hp,
  c,
  r,
  inst.func.evals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get.test.statistic_+3A_beta.init">beta.init</code></td>
<td>
<p>Starting value of minimization algorithm.</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_par.space">par.space</code></td>
<td>
<p>Matrix containing the bounds on the parameter space.</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_t">t</code></td>
<td>
<p>Time point at which to evaluate beta. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_c">c</code></td>
<td>
<p>Projection vector</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_r">r</code></td>
<td>
<p>hypothesised value of the projection.</p>
</td></tr>
<tr><td><code id="get.test.statistic_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Matrix of precomputed instrumental function
evaluations for each observation in the data set. If <code>NULL</code>, the
evaluations will be computed during execution of this function. Default is
<code>inst.func.evals = NULL</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the value of the test statistic and the parameter
at which this value was attained.
</p>

<hr>
<h2 id='gridSearch'>Grid search algorithm for finding the identified set</h2><span id='topic+gridSearch'></span>

<h3>Description</h3>

<p>This function implements the gridsearch and binary search
algorithms used to compute the roots of the violation curve and hence in
estimating the identified intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gridSearch(
  dir,
  test.fun,
  hyperparams,
  evaluations = NULL,
  time.run.duration = FALSE,
  verbose = 0,
  picturose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gridSearch_+3A_dir">dir</code></td>
<td>
<p>Search direction.</p>
</td></tr>
<tr><td><code id="gridSearch_+3A_test.fun">test.fun</code></td>
<td>
<p>The test function to be inverted in order to obtain the
identified set. It should take a scalar parameter as argument (i.e. the
specified value of a component of the full parameter vector) and return a
list with named elements <code>list(theta, t.stat, crit.val)</code>, where
<code>theta</code> is the scalar value that was tested, <code>t.stat</code> is the value
of the test statistic and <code>crit.val</code> is the critical value to be used in
determining whether to reject or not reject.</p>
</td></tr>
<tr><td><code id="gridSearch_+3A_hyperparams">hyperparams</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="gridSearch_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of already evaluated points, of which at least one
is feasible. When <code>evaluations = NULL</code> (default), the initial feasible
point search will be executed first.</p>
</td></tr>
<tr><td><code id="gridSearch_+3A_time.run.duration">time.run.duration</code></td>
<td>
<p>Boolean value indicating whether to time each step
in the EAM algorithm. Requires <code>chronometer.R</code>. Default is
<code>time.run.duration = FALSE</code>.</p>
</td></tr>
<tr><td><code id="gridSearch_+3A_verbose">verbose</code></td>
<td>
<p>Boolean value indicating whether or not to print run time
updates to the console. Default is <code>verbose = FALSE</code>.</p>
</td></tr>
<tr><td><code id="gridSearch_+3A_picturose">picturose</code></td>
<td>
<p>Boolean value indicating whether or not to visualize the
identified set search. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the evaluations of the test statistic and critical
values, convergence information, and run times.
</p>

<hr>
<h2 id='gs.algo.bidir'>Rudimentary, bidirectional 1D grid search algorithm.</h2><span id='topic+gs.algo.bidir'></span>

<h3>Description</h3>

<p>This function implements a rudimentary, bidirectional search algorithm. It
works by expanding a grid with given step.size in both directions, starting
from an initial feasible point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs.algo.bidir(test.results, max.iter, step.size)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gs.algo.bidir_+3A_test.results">test.results</code></td>
<td>
<p>Matrix containing the evaluations of the test statistic
and critical value.</p>
</td></tr>
<tr><td><code id="gs.algo.bidir_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="gs.algo.bidir_+3A_step.size">step.size</code></td>
<td>
<p>Step size based on which the grid is constructed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The next point to evaluate in the grid search.
</p>

<hr>
<h2 id='gs.binary'>Return the next point to evaluate when doing binary search</h2><span id='topic+gs.binary'></span>

<h3>Description</h3>

<p>This function implements the binary search algorithm, that
starts from a given feasible point and looks in the given direction for the
root of the violation curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs.binary(evaluations, dir, iter.nbr, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gs.binary_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of evaluated test statistics and critical values.</p>
</td></tr>
<tr><td><code id="gs.binary_+3A_dir">dir</code></td>
<td>
<p>Search direction.</p>
</td></tr>
<tr><td><code id="gs.binary_+3A_iter.nbr">iter.nbr</code></td>
<td>
<p>Iteration number.</p>
</td></tr>
<tr><td><code id="gs.binary_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The next point to evaluate.
</p>

<hr>
<h2 id='gs.interpolation'>Return the next point to evaluate when doing interpolation search</h2><span id='topic+gs.interpolation'></span>

<h3>Description</h3>

<p>This function implements the interpolation search algorithm,
that starts from a given feasible point and looks in the given direction for
the root of the violation curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs.interpolation(evaluations, dir, iter.nbr, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gs.interpolation_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of evaluated test statistics and critical values.</p>
</td></tr>
<tr><td><code id="gs.interpolation_+3A_dir">dir</code></td>
<td>
<p>Search direction.</p>
</td></tr>
<tr><td><code id="gs.interpolation_+3A_iter.nbr">iter.nbr</code></td>
<td>
<p>Iteration number.</p>
</td></tr>
<tr><td><code id="gs.interpolation_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The next point to evaluate.
</p>

<hr>
<h2 id='gs.regular'>Return the next point to evaluate when doing regular grid search</h2><span id='topic+gs.regular'></span>

<h3>Description</h3>

<p>This function implements a unidirectional grid search, that
works by expanding a grid starting from a given feasible point in the
given direction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gs.regular(evaluations, dir, iter.nbr, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gs.regular_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of evaluated test statistics and critical values.</p>
</td></tr>
<tr><td><code id="gs.regular_+3A_dir">dir</code></td>
<td>
<p>Search direction.</p>
</td></tr>
<tr><td><code id="gs.regular_+3A_iter.nbr">iter.nbr</code></td>
<td>
<p>Iteration number.</p>
</td></tr>
<tr><td><code id="gs.regular_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Next point to evaluate in the search algorithm.
</p>

<hr>
<h2 id='insert.row'>Insert row into a matrix at a given row index</h2><span id='topic+insert.row'></span>

<h3>Description</h3>

<p>Used in initalization step (feasible_point_search.R).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>insert.row(evaluations, row, idx.after)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="insert.row_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of violation function evaluations.</p>
</td></tr>
<tr><td><code id="insert.row_+3A_row">row</code></td>
<td>
<p>Row (evaluations) to be added to the evaluation matrix.</p>
</td></tr>
<tr><td><code id="insert.row_+3A_idx.after">idx.after</code></td>
<td>
<p>Index of the row of <code>evaluations</code> after which the given
row should be placed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Evaluation matrix.
</p>

<hr>
<h2 id='IYJtrans'>Inverse Yeo-Johnson transformation function</h2><span id='topic+IYJtrans'></span>

<h3>Description</h3>

<p>Computes the inverse Yeo-Johnson transformation of the provided
argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IYJtrans(y, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="IYJtrans_+3A_y">y</code></td>
<td>
<p>The argument to be supplied to the inverse Yeo-Johnson transformation.</p>
</td></tr>
<tr><td><code id="IYJtrans_+3A_theta">theta</code></td>
<td>
<p>The parameter of the inverted Yeo-Johnson transformation. This
should be a number in the range [0,2].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformed value of y.
</p>

<hr>
<h2 id='Kernel'>Calculate the kernel function</h2><span id='topic+Kernel'></span>

<h3>Description</h3>

<p>Calculate the kernel function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kernel(u, name = "Gaussian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kernel_+3A_u">u</code></td>
<td>
<p>the value in which the kernel function will be calculated at.</p>
</td></tr>
<tr><td><code id="Kernel_+3A_name">name</code></td>
<td>
<p>a character used to specify the type of kernel function.</p>
</td></tr>
</table>

<hr>
<h2 id='ktau.to.coppar'>Convert the Kendall's tau into the copula parameter</h2><span id='topic+ktau.to.coppar'></span>

<h3>Description</h3>

<p>Convert the Kendall's tau into the copula parameter
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ktau.to.coppar(ktau, copfam)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ktau.to.coppar_+3A_ktau">ktau</code></td>
<td>
<p>a numeric value that denotes the Kendall's tau.</p>
</td></tr>
<tr><td><code id="ktau.to.coppar_+3A_copfam">copfam</code></td>
<td>
<p>a character string that denotes the copula family.</p>
</td></tr>
</table>

<hr>
<h2 id='Lambda_AFT_ll'>Link function (AFT model)</h2><span id='topic+Lambda_AFT_ll'></span>

<h3>Description</h3>

<p>This function defines the AFT link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda_AFT_ll(t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lambda_AFT_ll_+3A_t">t</code></td>
<td>
<p>time parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='Lambda_Cox_wb'>Link function (Cox model)</h2><span id='topic+Lambda_Cox_wb'></span>

<h3>Description</h3>

<p>This function defines the Cox PH link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda_Cox_wb(t)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lambda_Cox_wb_+3A_t">t</code></td>
<td>
<p>time parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='Lambda_inverse_AFT_ll'>Inverse of link function (AFT model)</h2><span id='topic+Lambda_inverse_AFT_ll'></span>

<h3>Description</h3>

<p>This function defines the inverse of the AFT link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda_inverse_AFT_ll(p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lambda_inverse_AFT_ll_+3A_p">p</code></td>
<td>
<p>probability.</p>
</td></tr>
</table>

<hr>
<h2 id='Lambda_inverse_Cox_wb'>Inverse of link function (Cox model)</h2><span id='topic+Lambda_inverse_Cox_wb'></span>

<h3>Description</h3>

<p>This function defines the inverse of the Cox PH link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Lambda_inverse_Cox_wb(p)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Lambda_inverse_Cox_wb_+3A_p">p</code></td>
<td>
<p>probability.</p>
</td></tr>
</table>

<hr>
<h2 id='lf.delta.beta1'>Loss function to compute Delta(beta).</h2><span id='topic+lf.delta.beta1'></span>

<h3>Description</h3>

<p>This function defines the loss function used in computing the
penalized local linear approximation of the test statistic in order to
construct the bootstrap distribution of the test statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lf.delta.beta1(
  Delta.sub,
  vnb,
  phi,
  Gn,
  Omegan,
  beta,
  c,
  r,
  data,
  par.space,
  epsilon.n,
  lambda.n
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lf.delta.beta1_+3A_delta.sub">Delta.sub</code></td>
<td>
<p>Subvector of Delta.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_vnb">vnb</code></td>
<td>
<p>Bootstrapped stochastic process.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_phi">phi</code></td>
<td>
<p>Moment selection functions.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_gn">Gn</code></td>
<td>
<p>First-order approximation matrix.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_omegan">Omegan</code></td>
<td>
<p>Correlation matrix of sample moment functions.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_beta">beta</code></td>
<td>
<p>Coefficient vector.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_c">c</code></td>
<td>
<p>Projection vector.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_r">r</code></td>
<td>
<p>Value of projected coefficient vector.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_par.space">par.space</code></td>
<td>
<p>Matrix containing the bounds on the parameter space.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_epsilon.n">epsilon.n</code></td>
<td>
<p>Parameter used in constructing the feasible region as in
Example 4.1 in Bei (2024). Not used in this function.</p>
</td></tr>
<tr><td><code id="lf.delta.beta1_+3A_lambda.n">lambda.n</code></td>
<td>
<p>Weight of penalty term.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Loss function evaluation evaluated at the given Delta.
</p>


<h3>References</h3>

<p>Bei, X. (2024). Local linearieation based subvector inference in
moment inequality models. Journal of Econometrics. 238:105549-
</p>

<hr>
<h2 id='lf.ts'>'Loss function' of the test statistic.</h2><span id='topic+lf.ts'></span>

<h3>Description</h3>

<p>This function implements the loss function used in computing
the test statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lf.ts(beta.sub, data, t, hp, c, r, inst.func.evals = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lf.ts_+3A_beta.sub">beta.sub</code></td>
<td>
<p>Subvector of coefficient vector.</p>
</td></tr>
<tr><td><code id="lf.ts_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="lf.ts_+3A_t">t</code></td>
<td>
<p>Time point of interest. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="lf.ts_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="lf.ts_+3A_c">c</code></td>
<td>
<p>Unit vector containing unity at the location of the parameter of
interest.</p>
</td></tr>
<tr><td><code id="lf.ts_+3A_r">r</code></td>
<td>
<p>Value of the parameter of interest that is tested.</p>
</td></tr>
<tr><td><code id="lf.ts_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Pre-computed matrix of insturmental function
evaluations. If not supplied, it will be computed during execution of this
function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S-functions evaluation for the specified parameter vector.
</p>

<hr>
<h2 id='LikCopInd'>Loglikehood function under independent censoring</h2><span id='topic+LikCopInd'></span>

<h3>Description</h3>

<p>Loglikehood function under independent censoring
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikCopInd(theta, resData, X, W, lhat, cumL, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikCopInd_+3A_theta">theta</code></td>
<td>
<p>Estimated parameter values/initial values for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="LikCopInd_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="LikCopInd_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="LikCopInd_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be ones</p>
</td></tr>
<tr><td><code id="LikCopInd_+3A_lhat">lhat</code></td>
<td>
<p>The estimated hazard function obtained from the output of <code><a href="#topic+SolveLI">SolveLI</a></code>.</p>
</td></tr>
<tr><td><code id="LikCopInd_+3A_cuml">cumL</code></td>
<td>
<p>The estimated cumulative hazard function from the output of <code><a href="#topic+SolveLI">SolveLI</a></code>.</p>
</td></tr>
<tr><td><code id="LikCopInd_+3A_dist">dist</code></td>
<td>
<p>The distribution to  be used for the dependent censoring C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.
@importFrom stats nlminb pnorm  qnorm sd</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximized log-likelihood value
</p>

<hr>
<h2 id='Likelihood.Parametric'>Calculate the likelihood function for the fully parametric joint distribution</h2><span id='topic+Likelihood.Parametric'></span>

<h3>Description</h3>

<p>Calculate the likelihood function for the fully parametric joint distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Likelihood.Parametric(param, yobs, delta, copfam, margins, cure = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Likelihood.Parametric_+3A_param">param</code></td>
<td>
<p>a vector contains all parametric parameters.</p>
</td></tr>
<tr><td><code id="Likelihood.Parametric_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="Likelihood.Parametric_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="Likelihood.Parametric_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.</p>
</td></tr>
<tr><td><code id="Likelihood.Parametric_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.</p>
</td></tr>
<tr><td><code id="Likelihood.Parametric_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
</table>

<hr>
<h2 id='Likelihood.Profile.Kernel'>Calculate the profiled likelihood function with kernel smoothing</h2><span id='topic+Likelihood.Profile.Kernel'></span>

<h3>Description</h3>

<p>Calculate the profiled likelihood function with kernel smoothing
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Likelihood.Profile.Kernel(param, yobs, delta, copfam, margins, cure = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Likelihood.Profile.Kernel_+3A_param">param</code></td>
<td>
<p>a vector contains all parametric parameters.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Kernel_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Kernel_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Kernel_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Kernel_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Kernel_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
</table>

<hr>
<h2 id='Likelihood.Profile.Solve'>Solve the profiled likelihood function</h2><span id='topic+Likelihood.Profile.Solve'></span>

<h3>Description</h3>

<p>Solve the profiled likelihood function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Likelihood.Profile.Solve(
  yobs,
  delta,
  copfam,
  margins,
  ktau.init,
  parapar.init,
  cure,
  curerate.init,
  constraints,
  maxit,
  eps
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Likelihood.Profile.Solve_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_ktau.init">ktau.init</code></td>
<td>
<p>initial value of Kendall's tau.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_parapar.init">parapar.init</code></td>
<td>
<p>initial value of parametric parameters.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_curerate.init">curerate.init</code></td>
<td>
<p>initial value of cure rate.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_constraints">constraints</code></td>
<td>
<p>constraints of parameters.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_maxit">maxit</code></td>
<td>
<p>a positive integer that denotes the maximum iteration number in optimization.</p>
</td></tr>
<tr><td><code id="Likelihood.Profile.Solve_+3A_eps">eps</code></td>
<td>
<p>a positive small numeric value that denotes the tolerance for convergence.</p>
</td></tr>
</table>

<hr>
<h2 id='Likelihood.Semiparametric'>Calculate the semiparametric version of profiled likelihood function</h2><span id='topic+Likelihood.Semiparametric'></span>

<h3>Description</h3>

<p>Calculate the semiparametric version of profiled likelihood function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Likelihood.Semiparametric(
  param,
  Syobs,
  yobs,
  delta,
  copfam,
  margins,
  cure = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Likelihood.Semiparametric_+3A_param">param</code></td>
<td>
<p>a vector contains all parametric parameters.</p>
</td></tr>
<tr><td><code id="Likelihood.Semiparametric_+3A_syobs">Syobs</code></td>
<td>
<p>values of survival function at observed time points.</p>
</td></tr>
<tr><td><code id="Likelihood.Semiparametric_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="Likelihood.Semiparametric_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="Likelihood.Semiparametric_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.</p>
</td></tr>
<tr><td><code id="Likelihood.Semiparametric_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.</p>
</td></tr>
<tr><td><code id="Likelihood.Semiparametric_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
</table>

<hr>
<h2 id='LikF.cmprsk'>Second step log-likelihood function.</h2><span id='topic+LikF.cmprsk'></span>

<h3>Description</h3>

<p>This function defines the log-likelihood used to estimate
the second step in the competing risks extension of the model described in
Willems et al. (2024+).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikF.cmprsk(par, data, admin, conf, cf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikF.cmprsk_+3A_par">par</code></td>
<td>
<p>Vector of all second step model parameters, consisting of the
regression parameters, variance-covariance matrix elements and transformation
parameters.</p>
</td></tr>
<tr><td><code id="LikF.cmprsk_+3A_data">data</code></td>
<td>
<p>Data frame resulting from the 'uniformize.data.R' function.</p>
</td></tr>
<tr><td><code id="LikF.cmprsk_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="LikF.cmprsk_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of Z and W.</p>
</td></tr>
<tr><td><code id="LikF.cmprsk_+3A_cf">cf</code></td>
<td>
<p>&quot;Control function&quot; to be used. This can either be the (i) estimated
control function, (ii) the true control function, (iii) the instrumental
variable, or (iv) nothing (<code>cf = NULL</code>). Option (ii) is used when
comparing the two-step estimator to the oracle estimator, and option (iii) is
used to compare the two-step estimator with the naive estimator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood evaluation of the second step.
</p>


<h3>References</h3>

<p>Willems et al. (2024+). Flexible control function approach under competing risks (in preparation).
</p>

<hr>
<h2 id='likF.cmprsk.Cholesky'>Wrapper implementing likelihood function using Cholesky factorization.</h2><span id='topic+likF.cmprsk.Cholesky'></span>

<h3>Description</h3>

<p>This function parametrizes the covariance matrix using its
Cholesky decomposition, so that optimization of the likelihood can be done
based on this parametrization, and positive-definiteness of the covariance
matrix is guaranteed at each step of the optimization algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likF.cmprsk.Cholesky(par.chol, data, admin, conf, cf, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="likF.cmprsk.Cholesky_+3A_par.chol">par.chol</code></td>
<td>
<p>Vector of all second step model parameters, consisting of the
regression parameters, Cholesky decomposition of the variance-covariance
matrix elements and transformation parameters.</p>
</td></tr>
<tr><td><code id="likF.cmprsk.Cholesky_+3A_data">data</code></td>
<td>
<p>Data frame resulting from the 'uniformize.data.R' function.</p>
</td></tr>
<tr><td><code id="likF.cmprsk.Cholesky_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="likF.cmprsk.Cholesky_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of Z and W.</p>
</td></tr>
<tr><td><code id="likF.cmprsk.Cholesky_+3A_cf">cf</code></td>
<td>
<p>&quot;Control function&quot; to be used. This can either be the (i) estimated
control function, (ii) the true control function, (iii) the instrumental
variable, or (iv) nothing (<code>cf = NULL</code>). Option (ii) is used when
comparing the two-step estimator to the oracle estimator, and option (iii) is
used to compare the two-step estimator with the naive estimator.</p>
</td></tr>
<tr><td><code id="likF.cmprsk.Cholesky_+3A_eps">eps</code></td>
<td>
<p>Minimum value for the diagonal elements in the covariance matrix.
Default is <code>eps = 0.001</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood evaluation of the second step.
</p>

<hr>
<h2 id='LikGamma1'>First step log-likelihood function for Z continuous</h2><span id='topic+LikGamma1'></span>

<h3>Description</h3>

<p>This function defines the maximum likelihood used to estimate
the control function in the case of a continuous endogenous variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikGamma1(gamma, Z, M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikGamma1_+3A_gamma">gamma</code></td>
<td>
<p>Vector of coefficients in the linear model used to estimate the
control function.</p>
</td></tr>
<tr><td><code id="LikGamma1_+3A_z">Z</code></td>
<td>
<p>Endogenous covariate.</p>
</td></tr>
<tr><td><code id="LikGamma1_+3A_m">M</code></td>
<td>
<p>Design matrix, containing an intercept, the exogenous covariates and
the instrumental variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the log-likelihood function corresponding to the data,
evaluated at the point <code>gamma</code>.
</p>

<hr>
<h2 id='LikGamma2'>First step log-likelihood function for Z binary.</h2><span id='topic+LikGamma2'></span>

<h3>Description</h3>

<p>This function defines the maximum likelihood used to estimate
the control function in the case of a binary endogenous variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikGamma2(gamma, Z, M)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikGamma2_+3A_gamma">gamma</code></td>
<td>
<p>Vector of coefficients in the logistic model used to estimate
the control function.</p>
</td></tr>
<tr><td><code id="LikGamma2_+3A_z">Z</code></td>
<td>
<p>Endogenous covariate.</p>
</td></tr>
<tr><td><code id="LikGamma2_+3A_m">M</code></td>
<td>
<p>Design matrix, containing an intercept, the exogenous covariates and
the instrumental variable.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the log-likelihood function corresponding to the data,
evaluated at the point <code>gamma</code>.
</p>

<hr>
<h2 id='LikI.bis'>Second likelihood function needed to fit the independence model in the
second step of the estimation procedure.</h2><span id='topic+LikI.bis'></span>

<h3>Description</h3>

<p>This function defines the log-likelihood used in estimating
the second step in the competing risks extension of the model described in
Willems et al. (2024+). The results of this function will serve as
starting values for subsequent optimizations (LikI.comprsk.R and
LikF.cmprsk.R)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikI.bis(par, data, admin, conf, cf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikI.bis_+3A_par">par</code></td>
<td>
<p>Vector of all second step model parameters, consisting of the
regression parameters, variance-covariance matrix elements and transformation
parameters.</p>
</td></tr>
<tr><td><code id="LikI.bis_+3A_data">data</code></td>
<td>
<p>Data frame resulting from the 'uniformize.data.R' function.</p>
</td></tr>
<tr><td><code id="LikI.bis_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="LikI.bis_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of Z and W</p>
</td></tr>
<tr><td><code id="LikI.bis_+3A_cf">cf</code></td>
<td>
<p>&quot;Control function&quot; to be used. This can either be the (i) estimated
control function, (ii) the true control function, (iii) the instrumental
variable, or (iv) nothing (<code>cf = NULL</code>). Option (ii) is used when
comparing the two-step estimator to the oracle estimator, and option (iii) is
used to compare the two-step estimator with the naive estimator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Starting values for subsequent optimization function used in the
second step of the estimation procedure.
</p>


<h3>References</h3>

<p>Willems et al. (2024+). Flexible control function approach under competing risks (in preparation).
</p>

<hr>
<h2 id='LikI.cmprsk'>Second step log-likelihood function under independence assumption.</h2><span id='topic+LikI.cmprsk'></span>

<h3>Description</h3>

<p>This function defines the log-likelihood used to estimate
the second step in the competing risks extension assuming independence of
some of the competing risks in the model described in Willems et al. (2024+).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikI.cmprsk(par, data, eoi.indicator.names, admin, conf, cf)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikI.cmprsk_+3A_par">par</code></td>
<td>
<p>Vector of all second step model parameters, consisting of the
regression parameters, variance-covariance matrix elements and transformation
parameters.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk_+3A_data">data</code></td>
<td>
<p>Data frame resulting from the 'uniformize.data.R' function.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk_+3A_eoi.indicator.names">eoi.indicator.names</code></td>
<td>
<p>Vector of names of the censoring indicator columns
pertaining to events of interest. Events of interest will be modeled allowing
dependence between them, whereas all censoring events (corresponding to
indicator columns not listed in <code>eoi.indicator.names</code>) will be treated
as independent of every other event.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of Z and W</p>
</td></tr>
<tr><td><code id="LikI.cmprsk_+3A_cf">cf</code></td>
<td>
<p>&quot;Control function&quot; to be used. This can either be the (i) estimated
control function, (ii) the true control function, (iii) the instrumental
variable, or (iv) nothing (<code>cf = NULL</code>). Option (ii) is used when
comparing the two-step estimator to the oracle estimator, and option (iii) is
used to compare the two-step estimator with the naive estimator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood evaluation for the second step in the esimation
procedure.
</p>


<h3>References</h3>

<p>Willems et al. (2024+). Flexible control function approach under competing risks (in preparation).
</p>

<hr>
<h2 id='LikI.cmprsk.Cholesky'>Wrapper implementing likelihood function assuming independence between
competing risks and censoring using Cholesky factorization.</h2><span id='topic+LikI.cmprsk.Cholesky'></span>

<h3>Description</h3>

<p>This function does the same as LikI.cmprsk (in fact, it even
calls said function), but it parametrizes the covariance matrix using its
Cholesky decomposition in order to guarantee positive definiteness. This
function is never used, might not work and could be deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LikI.cmprsk.Cholesky(
  par.chol,
  data,
  eoi.indicator.names,
  admin,
  conf,
  cf,
  eps = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_par.chol">par.chol</code></td>
<td>
<p>Vector of all second step model parameters, consisting of the
regression parameters, Cholesky decomposition of the variance-covariance
matrix elements and transformation parameters.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_data">data</code></td>
<td>
<p>Data frame resulting from the 'uniformize.data.R' function.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_eoi.indicator.names">eoi.indicator.names</code></td>
<td>
<p>Vector of names of the censoring indicator columns
pertaining to events of interest. Events of interest will be modeled allowing
dependence between them, whereas all censoring events (corresponding to
indicator columns not listed in <code>eoi.indicator.names</code>) will be treated
as independent of every other event.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of Z and W.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_cf">cf</code></td>
<td>
<p>&quot;Control function&quot; to be used. This can either be the (i) estimated
control function, (ii) the true control function, (iii) the instrumental
variable, or (iv) nothing (<code>cf = NULL</code>). Option (ii) is used when
comparing the two-step estimator to the oracle estimator, and option (iii) is
used to compare the two-step estimator with the naive estimator.</p>
</td></tr>
<tr><td><code id="LikI.cmprsk.Cholesky_+3A_eps">eps</code></td>
<td>
<p>Minimum value for the diagonal elements in the covariance matrix.
Default is <code>eps = 0.001</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood evaluation for the second step in the estimation
procedure.
</p>

<hr>
<h2 id='likIFG.cmprsk.Cholesky'>Full likelihood (including estimation of control function).</h2><span id='topic+likIFG.cmprsk.Cholesky'></span>

<h3>Description</h3>

<p>This function defines the 'full' likelihood of the model.
Specifically, it includes the estimation of the control function in the
computation of the likelihood. This function is used in the estimation of the
variance of the estimates (variance.cmprsk.R).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likIFG.cmprsk.Cholesky(
  parhatG,
  data,
  eoi.indicator.names,
  admin,
  conf,
  Zbin,
  inst
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_parhatg">parhatG</code></td>
<td>
<p>The full parameter vector.</p>
</td></tr>
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_eoi.indicator.names">eoi.indicator.names</code></td>
<td>
<p>Vector of names of the censoring indicator columns
pertaining to events of interest. Events of interest will be modeled allowing
dependence between them, whereas all censoring events (corresponding to
indicator columns not listed in <code>eoi.indicator.names</code>) will be treated
as independent of every other event. If <code>eoi.indicator.names == NULL</code>,
all events will be modelled dependently.</p>
</td></tr>
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of Z and W.</p>
</td></tr>
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_zbin">Zbin</code></td>
<td>
<p>Boolean value indicating whether the confounding variable is
binary.</p>
</td></tr>
<tr><td><code id="likIFG.cmprsk.Cholesky_+3A_inst">inst</code></td>
<td>
<p>Type of instrumental function to be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Full model log-likelihood evaluation.
</p>

<hr>
<h2 id='log_transform'>Logarithmic transformation function.</h2><span id='topic+log_transform'></span>

<h3>Description</h3>

<p>Computes the logarithm of a number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>log_transform(y)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="log_transform_+3A_y">y</code></td>
<td>
<p>Numerical value of which the logarithm is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the logarithm of the provided argument y
if it is greater than zero. If y is smaller than zero, it will return 0.
</p>

<hr>
<h2 id='loglike.clayton.unconstrained'>Log-likelihood function for the Clayton copula.</h2><span id='topic+loglike.clayton.unconstrained'></span>

<h3>Description</h3>

<p>This likelihood function is maximized to estimate the model parameters under the Clayton copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike.clayton.unconstrained(para, Y, Delta, Dist.T, Dist.C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loglike.clayton.unconstrained_+3A_para">para</code></td>
<td>
<p>Estimated parameter values/initial values.</p>
</td></tr>
<tr><td><code id="loglike.clayton.unconstrained_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="loglike.clayton.unconstrained_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="loglike.clayton.unconstrained_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull")</code> and has to be the same as Dist.C.</p>
</td></tr>
<tr><td><code id="loglike.clayton.unconstrained_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull")</code> and has to be the same as Dist.T.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximized log-likelihood value.
</p>

<hr>
<h2 id='loglike.frank.unconstrained'>Log-likelihood function for the Frank copula.</h2><span id='topic+loglike.frank.unconstrained'></span>

<h3>Description</h3>

<p>This likelihood function is maximized to estimate the model parameters under the Frank copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike.frank.unconstrained(para, Y, Delta, Dist.T, Dist.C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loglike.frank.unconstrained_+3A_para">para</code></td>
<td>
<p>Estimated parameter values/initial values.</p>
</td></tr>
<tr><td><code id="loglike.frank.unconstrained_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="loglike.frank.unconstrained_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="loglike.frank.unconstrained_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
<tr><td><code id="loglike.frank.unconstrained_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximized log-likelihood value.
</p>

<hr>
<h2 id='loglike.gaussian.unconstrained'>Log-likelihood function for the Gaussian copula.</h2><span id='topic+loglike.gaussian.unconstrained'></span>

<h3>Description</h3>

<p>This likelihood function is maximized to estimate the model parameters under the Gaussian copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike.gaussian.unconstrained(para, Y, Delta, Dist.T, Dist.C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loglike.gaussian.unconstrained_+3A_para">para</code></td>
<td>
<p>Estimated parameter values/initial values.</p>
</td></tr>
<tr><td><code id="loglike.gaussian.unconstrained_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="loglike.gaussian.unconstrained_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="loglike.gaussian.unconstrained_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can only the value <code>"lnorm"</code>.</p>
</td></tr>
<tr><td><code id="loglike.gaussian.unconstrained_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can only the value <code>"lnorm"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximized log-likelihood value.
</p>

<hr>
<h2 id='loglike.gumbel.unconstrained'>Log-likelihood function for the Gumbel copula.</h2><span id='topic+loglike.gumbel.unconstrained'></span>

<h3>Description</h3>

<p>This likelihood function is maximized to estimate the model parameters under the Gumbel copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike.gumbel.unconstrained(para, Y, Delta, Dist.T, Dist.C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loglike.gumbel.unconstrained_+3A_para">para</code></td>
<td>
<p>Estimated parameter values/initial values.</p>
</td></tr>
<tr><td><code id="loglike.gumbel.unconstrained_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="loglike.gumbel.unconstrained_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="loglike.gumbel.unconstrained_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull")</code> and has to be the same as Dist.C.</p>
</td></tr>
<tr><td><code id="loglike.gumbel.unconstrained_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull")</code> and has to be the same as Dist.T.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximized log-likelihood value.
</p>

<hr>
<h2 id='loglike.indep.unconstrained'>Log-likelihood function for the independence copula.</h2><span id='topic+loglike.indep.unconstrained'></span>

<h3>Description</h3>

<p>This likelihood function is maximized to estimate the model parameters under the independence copula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loglike.indep.unconstrained(para, Y, Delta, Dist.T, Dist.C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loglike.indep.unconstrained_+3A_para">para</code></td>
<td>
<p>Estimated parameter values/initial values.</p>
</td></tr>
<tr><td><code id="loglike.indep.unconstrained_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="loglike.indep.unconstrained_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="loglike.indep.unconstrained_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
<tr><td><code id="loglike.indep.unconstrained_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Maximized log-likelihood value.
</p>

<hr>
<h2 id='Longfun'>Long format</h2><span id='topic+Longfun'></span>

<h3>Description</h3>

<p>Change hazard and cumulative hazard to long format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Longfun(Z, T1, lhat, Lhat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Longfun_+3A_z">Z</code></td>
<td>
<p>Observed survival time, which is the minimum of T, C and A, where A is the administrative censoring time.</p>
</td></tr>
<tr><td><code id="Longfun_+3A_t1">T1</code></td>
<td>
<p>Distinct observed survival time</p>
</td></tr>
<tr><td><code id="Longfun_+3A_lhat">lhat</code></td>
<td>
<p>Hazard function estimate</p>
</td></tr>
<tr><td><code id="Longfun_+3A_lhat">Lhat</code></td>
<td>
<p>Cumulative hazard function estimate</p>
</td></tr>
</table>

<hr>
<h2 id='LongNPT'>Change H to long format</h2><span id='topic+LongNPT'></span>

<h3>Description</h3>

<p>Change a nonparametric transformation function to long format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LongNPT(Z, T1, H)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LongNPT_+3A_z">Z</code></td>
<td>
<p>Observed survival time, which is the minimum of T, C and A, where A is the administrative censoring time.</p>
</td></tr>
<tr><td><code id="LongNPT_+3A_t1">T1</code></td>
<td>
<p>Distinct observed survival time</p>
</td></tr>
<tr><td><code id="LongNPT_+3A_h">H</code></td>
<td>
<p>Nonparametric transformation function estimate</p>
</td></tr>
</table>

<hr>
<h2 id='M_step'>M-step in the EAM algorithm described in KMS19.</h2><span id='topic+M_step'></span>

<h3>Description</h3>

<p>This function performs the maximization step in the EAM
algorithm. More specifically, it maximizes the expected improvement.
ToDo: implement sample space contractions (see comment made in documentation
of <code>draw.sv.init</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M_step(
  dir,
  evaluations,
  theta.hash,
  fit.krige,
  test.fun,
  c,
  par.space,
  hyperparams,
  verbose
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="M_step_+3A_dir">dir</code></td>
<td>
<p>Direction to search in. <code>dir = 1</code> corresponds to finding the
upper bound of the confidence interval. <code>dir = -1</code> corresponds to
finding the lower bound.</p>
</td></tr>
<tr><td><code id="M_step_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix containing each point that was already evaluated,
alongside the corresponding test statistic and critical value, as its rows.</p>
</td></tr>
<tr><td><code id="M_step_+3A_theta.hash">theta.hash</code></td>
<td>
<p>Tentative best value of theta. Obtained from the E-step.</p>
</td></tr>
<tr><td><code id="M_step_+3A_fit.krige">fit.krige</code></td>
<td>
<p>Kriging model obtained from the A-step.</p>
</td></tr>
<tr><td><code id="M_step_+3A_test.fun">test.fun</code></td>
<td>
<p>The test function to be inverted in order to obtain the
identified set.</p>
</td></tr>
<tr><td><code id="M_step_+3A_c">c</code></td>
<td>
<p>Projection vector.</p>
</td></tr>
<tr><td><code id="M_step_+3A_par.space">par.space</code></td>
<td>
<p>Bounds of the parameter space.</p>
</td></tr>
<tr><td><code id="M_step_+3A_hyperparams">hyperparams</code></td>
<td>
<p>Parameters used in obtaining initial values
for the maximization algorithm. If <code>NULL</code>, default values are used.
Default is <code>hyperparams = NULL</code>.</p>
</td></tr>
<tr><td><code id="M_step_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='m.bar'>Vector of sample average of each moment function
<code class="reqn">(\bar{m}_n(\theta))</code>.</h2><span id='topic+m.bar'></span>

<h3>Description</h3>

<p>This function obtains the vector of sample averages of each
moment function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m.bar(data, beta, t, hp, mi.mat = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="m.bar_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="m.bar_+3A_beta">beta</code></td>
<td>
<p>Vector of coefficients.</p>
</td></tr>
<tr><td><code id="m.bar_+3A_t">t</code></td>
<td>
<p>Time point at which to compute the moment functions. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="m.bar_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="m.bar_+3A_mi.mat">mi.mat</code></td>
<td>
<p>Matrix of moment function evaluations. Can be used to avoid
some computation. Default is <code>mi.mat = NULL</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='MSpoint'>Analogue to KMS_AUX4_MSpoints(...) in MATLAB code of Bei (2024).</h2><span id='topic+MSpoint'></span>

<h3>Description</h3>

<p>Create starting values for EI maximization. Used in the M-step
(get.starting.values.R).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSpoint(draws.init)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="MSpoint_+3A_draws.init">draws.init</code></td>
<td>
<p>Initial draws.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bei, X. (2024). Local linearieation based subvector inference in
moment inequality models. Journal of Econometrics. 238:105549-
</p>

<hr>
<h2 id='NonParTrans'>Fit a semiparametric transformation model for dependent censoring</h2><span id='topic+NonParTrans'></span>

<h3>Description</h3>

<p>This function allows to estimate the dependency parameter along all other model parameters. First, estimates a non-parametric transformation function, and
then at the second stage it estimates other model parameters assuming that the non-parametric function is known. The details for
implementing the dependent censoring methodology can be found in Deresa and Van Keilegom (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NonParTrans(
  resData,
  X,
  W,
  start = NULL,
  n.iter = 15,
  bootstrap = FALSE,
  n.boot = 50,
  eps = 0.001
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="NonParTrans_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_start">start</code></td>
<td>
<p>Initial values for the finite dimensional parameters. If <code>start</code> is NULL, the initial values will be obtained
by fitting an Accelerated failure time models.</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_n.iter">n.iter</code></td>
<td>
<p>Number of iterations; the default is <code>n.iter = 20</code>. The larger the number of iterations, the longer the computational time.</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_bootstrap">bootstrap</code></td>
<td>
<p>A boolean indicating whether to compute bootstrap standard errors for making inferences.</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_n.boot">n.boot</code></td>
<td>
<p>Number of bootstrap samples to use in the estimation of bootstrap standard errors if <code>bootstrap = TRUE</code>. The default is n.boot = 50. But, higher
values  of <code>n.boot</code> are recommended for obtaining good estimates of bootstrap standard errors.</p>
</td></tr>
<tr><td><code id="NonParTrans_+3A_eps">eps</code></td>
<td>
<p>Convergence error. This is set by the user in such away that the desired convergence is met; the default is <code>eps = 1e-3</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns a fit of a semiparametric transformation model; parameter estimates, estimate of the non-parametric transformation function, bootstrap standard
errors for finite-dimensional parameters, the nonparametric cumulative hazard function, etc.
</p>


<h3>References</h3>

<p>Deresa, N. and Van Keilegom, I. (2021). On semiparametric modelling, estimation and inference for survival data subject to dependent censoring, Biometrika, 108, 965979.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Toy data example to illustrate implementation
n = 300
beta = c(0.5, 1); eta = c(1,1.5); rho = 0.70
sigma = matrix(c(1,rho,rho,1),ncol=2)
err = MASS::mvrnorm(n, mu = c(0,0) , Sigma=sigma)
err1 = err[,1]; err2 = err[,2]
x1 = rbinom(n,1,0.5); x2 = runif(n,-1,1)
X = matrix(c(x1,x2),ncol=2,nrow=n); W = X   # data matrix
T1 = X%*%beta+err1
C =  W%*%eta+err2
T1 = exp(T1); C = exp(C)
A = runif(n,0,8); Y = pmin(T1,C,A)
d1 = as.numeric(Y==T1)
d2 = as.numeric(Y==C)
resData = data.frame("Z" = Y,"d1" = d1, "d2" = d2)   # should be data frame
colnames(X) = c("X1", "X2")
colnames(W) = c("W1","W2")

#  Bootstrap is false by default
output = NonParTrans(resData = resData, X = X, W = W, n.iter = 2)
output$parameterEstimates


</code></pre>

<hr>
<h2 id='normalize.covariates'>Normalize the covariates of a data set to lie in the unit interval by
scaling based on the ranges of the covariates.</h2><span id='topic+normalize.covariates'></span>

<h3>Description</h3>

<p>This function normalized the covariates in the data to lie in
the unit interval based on either the empirical or known ranges of the
covariates. It is useful to perform this step when defining the instrumental
functions later on. This function is used in <code>G.box.R</code>, <code>G.spline.R</code>
and by extension in <code>G.cd.R</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize.covariates(
  data = NULL,
  x = NULL,
  cov.ranges = NULL,
  idxs.c = "all",
  norm.cov.out = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize.covariates_+3A_data">data</code></td>
<td>
<p>(optional) Data set to be used to construct the normalizing
transformation. Default is <code>data = NULL</code>.</p>
</td></tr>
<tr><td><code id="normalize.covariates_+3A_x">x</code></td>
<td>
<p>(optional) Vector of covariates to be normalized alongside the data.
Default is <code>x = NULL</code>.</p>
</td></tr>
<tr><td><code id="normalize.covariates_+3A_cov.ranges">cov.ranges</code></td>
<td>
<p>(optional) Matrix that specifies the range of each of the
covariates in the data set. Each column corresponds to a covariate. The first
row contains the lower bound, the second row contains the upper bound.
If not supplied, the data will be normalized based on the minimum and maximum
detected values. If supplied, the non data-dependent transformation function
listed in the appendix of Andrews, Shi 2013 will be used. Default is
<code>cov.ranges = NULL</code>.</p>
</td></tr>
<tr><td><code id="normalize.covariates_+3A_idxs.c">idxs.c</code></td>
<td>
<p>(optional) Vector of indices of covariates that are continuous.
Note that that indices are relative to the covariate vector, not the full
data set. Default value is <code>idxs.c = "all"</code>, which indicates that all
elements should be regarded as continuous. If <code>idxs.c = NULL</code>, all
elements are regarded as discrete.</p>
</td></tr>
<tr><td><code id="normalize.covariates_+3A_norm.cov.out">norm.cov.out</code></td>
<td>
<p>(optional) The output of a previous call to this function.
Can be used to speed up computation. If both <code>data</code> and
<code>norm.cov.out</code> are supplied to the function, this method will throw an
error. Default is <code>norm.cov.out = NULL</code>.</p>
</td></tr>
<tr><td><code id="normalize.covariates_+3A_...">...</code></td>
<td>
<p>Allows easier interchangeability between covariate normalization
functions. All arguments specified under <code>...</code> will be ignored.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Andrews, D.W.K. and Shi, X. (2013). Inference based on
confitional moment inequalities. Econometrica. 81(2):609-666.
</p>

<hr>
<h2 id='normalize.covariates2'>Normalize the covariates of a data set to lie in the unit interval by
transforming based on PCA.</h2><span id='topic+normalize.covariates2'></span>

<h3>Description</h3>

<p>This function normalized the covariates in the data to lie in
the unit interval based on a principal component analysis. It is useful to
perform this step when defining the instrumental functions later on. This
function is used in <code>G.box</code>, <code>G.spline</code> and by extension <code>G.cd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize.covariates2(
  data = NULL,
  x = NULL,
  idxs.c = "all",
  norm.cov.out = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="normalize.covariates2_+3A_data">data</code></td>
<td>
<p>(optional) Data set to be used to construct the normalizing
transformation. Default is <code>data = NULL</code>.</p>
</td></tr>
<tr><td><code id="normalize.covariates2_+3A_x">x</code></td>
<td>
<p>(optional) Vector of covariates to be normalized alongside the data.
Default is <code>x = NULL</code>.</p>
</td></tr>
<tr><td><code id="normalize.covariates2_+3A_idxs.c">idxs.c</code></td>
<td>
<p>(optional) Vector of indices of covariates that are continuous.
Note that that indices are relative to the covariate vector, not the full
data set. Default value is <code>idxs.c = "all"</code>, which indicates that all
elements should be regarded as continuous. If <code>idxs.c = NULL</code>, all
elements are regarded as discrete.</p>
</td></tr>
<tr><td><code id="normalize.covariates2_+3A_norm.cov.out">norm.cov.out</code></td>
<td>
<p>(optional) The output of a previous call to this function.
Can be used to speed up computation. If both <code>data</code> and
<code>norm.cov.out</code> are supplied to the function, the function will throw an
error. Default is <code>norm.cov.out = NULL</code></p>
</td></tr>
<tr><td><code id="normalize.covariates2_+3A_...">...</code></td>
<td>
<p>Allows easier interchangeability between covariate normalization
functions. All arguments specified under <code>...</code> will be ignored.</p>
</td></tr>
</table>

<hr>
<h2 id='Omega.hat'>Obtain the correlation matrix of the moment functions</h2><span id='topic+Omega.hat'></span>

<h3>Description</h3>

<p>This function computes the correlation matrix corresponding to
the variance-covariance matrix as returned by <code>Sigma.hat.R</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Omega.hat(Sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Omega.hat_+3A_sigma">Sigma</code></td>
<td>
<p>The output of the function Sigma.hat</p>
</td></tr>
</table>

<hr>
<h2 id='optimlikelihood'>Fit the dependent censoring models.</h2><span id='topic+optimlikelihood'></span>

<h3>Description</h3>

<p>Estimates the model parameters by maximizing the log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optimlikelihood(Y, Delta, Copula, Dist.T, Dist.C, start)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optimlikelihood_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="optimlikelihood_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="optimlikelihood_+3A_copula">Copula</code></td>
<td>
<p>The copula family. This argument can take values from <code>c("frank","gumbel","clayton","gaussian","indep")</code>.</p>
</td></tr>
<tr><td><code id="optimlikelihood_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
<tr><td><code id="optimlikelihood_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
<tr><td><code id="optimlikelihood_+3A_start">start</code></td>
<td>
<p>Starting values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the minimized negative log-likelihood using the independence copula model, the estimated parameter values for the model with the independence copula, the minimized negative log-likelihood using the specified copula model and the estimated parameter values for the model with the specified copula.
</p>

<hr>
<h2 id='parafam.d'>Obtain the value of the density function</h2><span id='topic+parafam.d'></span>

<h3>Description</h3>

<p>Obtain the value of the density function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parafam.d(x, parameter, distribution, truncation = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parafam.d_+3A_x">x</code></td>
<td>
<p>the value in which the density function will be calculated at.</p>
</td></tr>
<tr><td><code id="parafam.d_+3A_parameter">parameter</code></td>
<td>
<p>the parameter of the specified distribution</p>
</td></tr>
<tr><td><code id="parafam.d_+3A_distribution">distribution</code></td>
<td>
<p>the specified distribution function.</p>
</td></tr>
<tr><td><code id="parafam.d_+3A_truncation">truncation</code></td>
<td>
<p>a positive numeric value thats denotes the value of truncation for the assumed distribution.</p>
</td></tr>
</table>

<hr>
<h2 id='parafam.p'>Obtain the value of the distribution function</h2><span id='topic+parafam.p'></span>

<h3>Description</h3>

<p>Obtain the value of the distribution function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parafam.p(x, parameter, distribution, truncation = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parafam.p_+3A_x">x</code></td>
<td>
<p>the value in which the distribution function will be calculated at.</p>
</td></tr>
<tr><td><code id="parafam.p_+3A_parameter">parameter</code></td>
<td>
<p>the parameter of the specified distribution</p>
</td></tr>
<tr><td><code id="parafam.p_+3A_distribution">distribution</code></td>
<td>
<p>the specified distribution function.</p>
</td></tr>
<tr><td><code id="parafam.p_+3A_truncation">truncation</code></td>
<td>
<p>a positive numeric value thats denotes the value of truncation for the assumed distribution.</p>
</td></tr>
</table>

<hr>
<h2 id='parafam.trunc'>Obtain the adjustment value of truncation</h2><span id='topic+parafam.trunc'></span>

<h3>Description</h3>

<p>Obtain the adjustment value of truncation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parafam.trunc(truncation, parameter, distribution)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parafam.trunc_+3A_truncation">truncation</code></td>
<td>
<p>a positive numeric value thats denotes the value of truncation for the assumed distribution.</p>
</td></tr>
<tr><td><code id="parafam.trunc_+3A_parameter">parameter</code></td>
<td>
<p>the parameter of the specified distribution</p>
</td></tr>
<tr><td><code id="parafam.trunc_+3A_distribution">distribution</code></td>
<td>
<p>the specified distribution function.</p>
</td></tr>
</table>

<hr>
<h2 id='ParamCop'>Estimation of  a parametric dependent censoring model without covariates.</h2><span id='topic+ParamCop'></span>

<h3>Description</h3>

<p>Note that it is not assumed that the association parameter of the copula function is known,
unlike most other papers in the literature. The details for implementing the methodology can be found in Czado and Van Keilegom (2023).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ParamCop(Y, Delta, Copula, Dist.T, Dist.C, start = c(1, 1, 1, 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ParamCop_+3A_y">Y</code></td>
<td>
<p>Follow-up time.</p>
</td></tr>
<tr><td><code id="ParamCop_+3A_delta">Delta</code></td>
<td>
<p>Censoring indicator.</p>
</td></tr>
<tr><td><code id="ParamCop_+3A_copula">Copula</code></td>
<td>
<p>The copula family. This argument can take values from <code>c("frank","gumbel","clayton","gaussian","indep")</code>.</p>
</td></tr>
<tr><td><code id="ParamCop_+3A_dist.t">Dist.T</code></td>
<td>
<p>The distribution to  be used for the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
<tr><td><code id="ParamCop_+3A_dist.c">Dist.C</code></td>
<td>
<p>The distribution to  be used for the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>.</p>
</td></tr>
<tr><td><code id="ParamCop_+3A_start">start</code></td>
<td>
<p>Starting values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A table containing the minimized negative log-likelihood using the independence copula model, the estimated parameter values for the model with the independence copula, the minimized negative log-likelihood using the specified copula model and the estimated parameter values for the model with the specified copula.
</p>


<h3>References</h3>

<p>Czado and Van Keilegom (2023). Dependent censoring based on parametric copulas. Biometrika, 110(3), 721-738.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tau = 0.75
Copula = "frank"
Dist.T = "weibull"
Dist.C = "lnorm"
par.T = c(2,1)
par.C = c(1,2)
n=1000

simdata&lt;-TCsim(tau,Copula,Dist.T,Dist.C,par.T,par.C,n)

Y = simdata[[1]]
Delta = simdata[[2]]

ParamCop(Y,Delta,Copula,Dist.T,Dist.C)

</code></pre>

<hr>
<h2 id='Parameters.Constraints'>Generate constraints of parameters</h2><span id='topic+Parameters.Constraints'></span>

<h3>Description</h3>

<p>Generate constraints of parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Parameters.Constraints(copfam, margins, cure)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Parameters.Constraints_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.</p>
</td></tr>
<tr><td><code id="Parameters.Constraints_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.</p>
</td></tr>
<tr><td><code id="Parameters.Constraints_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
</table>

<hr>
<h2 id='pi.surv'>Estimate the model of Willems et al. (2024+).</h2><span id='topic+pi.surv'></span>

<h3>Description</h3>

<p>This function estimates bounds on the coefficients the single-
index model <code class="reqn">\Lambda(x^\top \beta(t))</code> for the conditional cumulative
distribution function of the event time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pi.surv(
  data,
  idx.param.of.interest,
  idxs.c,
  t,
  par.space,
  search.method = "GS",
  add.options = list(),
  verbose = 0,
  picturose = FALSE,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pi.surv_+3A_data">data</code></td>
<td>
<p>Data frame containing the data on which to fit the model. The
columns should be named as follows: 'Y' = observed timed, 'Delta' = censoring
indicators, 'X0' = intercept column, 'X1' - 'Xp' = covariates.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_idx.param.of.interest">idx.param.of.interest</code></td>
<td>
<p>Index of element in the covariate vector for
which the identified interval should be estimated. It can also be specified
as <code>idx.param.of.interest = "all"</code>, in which case identified intervals
will be computed for all elements in the parameter vector. Note that
<code>idx.param.of.interest = 1</code> corresponds to the intercept parameter.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_idxs.c">idxs.c</code></td>
<td>
<p>Vector of indices of the continuous covariates. Suppose the
given data contains 5 covariates, of which 'X2' and 'X5' are continuous, this
argument should be specified as <code>idxs.c = c(2, 5)</code>.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_t">t</code></td>
<td>
<p>Time point for which to estimate the identified set of
<code class="reqn">\beta(t)</code>.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_par.space">par.space</code></td>
<td>
<p>Matrix containing bounds on the space of the parameters. The
first column corresponds to lower bounds, the second to upper bounds. The i'th
row corresponds to the bounds on the i'th element in the parameter vector.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_search.method">search.method</code></td>
<td>
<p>The search method to be used to find the identified
interval. Default is <code>search.method = "GS"</code>.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_add.options">add.options</code></td>
<td>
<p>List of additional options to be specified to the method.
Notably, it can be used to select the link function <code class="reqn">\Lambda(t))</code> that
should be considered. Currently, the link function leading to an accelerated
failure time model (<code>"AFT_ll"</code>, default) and the link function
leading to a Cox proportional hazards model (<code>"Cox_wb"</code>) are implemented.
Other options can range from 'standard' hyperparameters such as the
confidence level of the test and number of instrumental functions to be used,
to technical hyperparameters regarding the search method and test
implementation. For the latter, we refer to the documentations of
<code>set.hyperparameters</code>, <code>set.EAM.hyperparameters</code> and
<code>set.GS.hyperparameters</code>. We recommend to use the default parameters,
unless you really know what you are doing.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_verbose">verbose</code></td>
<td>
<p>Verbosity level. The higher the value, the more verbose the
method will be. Default is <code>verbose = 0</code>.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_picturose">picturose</code></td>
<td>
<p>Picturosity flag. If <code>TRUE</code>, a plot illustrating the
workings of the algorithm will updated during runtime. Default is
<code>picturose = FALSE</code>.</p>
</td></tr>
<tr><td><code id="pi.surv_+3A_parallel">parallel</code></td>
<td>
<p>Flag for whether or not parallel computing should be used.
Default is <code>parallel = FALSE</code>. When <code>parallel = TRUE</code>, this
implementation will use <code>min(detectCores() - 1, 10)</code> cores to construct
the parallel back-end.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Matrix containing the identified intervals of the specified
coefficients, as well as corresponding convergence information of the
estimation algorithm.
</p>


<h3>References</h3>

<p>Willems, I., Beyhum, J. and Van Keilegom, I. (2024+). Partial
identification for a class of survival models under dependent censoring.
(In preparation).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

  # Clear workspace
  rm(list = ls())
  
  # Load the survival package
  library(survival)
  
  # Set random seed
  set.seed(123)
  
  # Load and preprocess data
  data &lt;- survival::lung
  data[, "intercept"] &lt;- rep(1, nrow(data))
  data[, "status"] &lt;- data[, "status"] - 1
  data &lt;- data[, c("time", "status", "intercept", "age", "sex")]
  colnames(data) &lt;- c("Y", "Delta", "X0", "X1", "X2")
  
  # Standardize age variable
  data[, "X1"] &lt;- scale(data[, "X1"])
  
  ## Example:
  ## - Link function: AFT link function (default setting)
  ## - Number of IF: 5 IF per continuous covariate (default setting)
  ## - Search method: Binary search
  ## - Type of IF: Cubic spline functions for continuous covariate, indicator
  ##   function for discrete covariate (default setting).
  
  # Settings for main estimation function
  idx.param.of.interest &lt;- 2 # Interest in effect of age
  idxs.c &lt;- 1                # X1 (age) is continuous
  t &lt;- 200                   # Model imposed at t = 200
  search.method &lt;- "GS"      # Use binary search
  par.space &lt;- matrix(rep(c(-10, 10), 3), nrow = 3, byrow = TRUE)
  add.options &lt;- list()
  picturose &lt;- TRUE
  parallel &lt;- FALSE
  
  # Estimate the identified intervals
  pi.surv(data, idx.param.of.interest, idxs.c, t, par.space,
          search.method = search.method, add.options = add.options,
          picturose = picturose, parallel = parallel)



</code></pre>

<hr>
<h2 id='plot_addpte'>Draw points to be evaluated</h2><span id='topic+plot_addpte'></span>

<h3>Description</h3>

<p>This function draws the points to be evaluated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_addpte(pte, col = "orange")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_addpte_+3A_pte">pte</code></td>
<td>
<p>Vector of points to be evaluated.</p>
</td></tr>
<tr><td><code id="plot_addpte_+3A_col">col</code></td>
<td>
<p>Color of the points.</p>
</td></tr>
</table>

<hr>
<h2 id='plot_addpte.eval'>Draw evaluated points.</h2><span id='topic+plot_addpte.eval'></span>

<h3>Description</h3>

<p>This function draws evaluated points. Feasible points are
indicated in green, red points correspond to infeasible points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_addpte.eval(evaluations)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_addpte.eval_+3A_evaluations">evaluations</code></td>
<td>
<p>Matrix of evaluations to be drawn.</p>
</td></tr>
</table>

<hr>
<h2 id='plot_base'>Draw base plot</h2><span id='topic+plot_base'></span>

<h3>Description</h3>

<p>This functon draws the base plot, used when
<code>picturose = TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_base(c, hp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_base_+3A_c">c</code></td>
<td>
<p>Projection vector</p>
</td></tr>
<tr><td><code id="plot_base_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters</p>
</td></tr>
</table>

<hr>
<h2 id='power_transform'>Power transformation function.</h2><span id='topic+power_transform'></span>

<h3>Description</h3>

<p>Computes a given power of a number.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>power_transform(y, pw)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="power_transform_+3A_y">y</code></td>
<td>
<p>The number which one wants to raise to a certain power <code>pw</code>.</p>
</td></tr>
<tr><td><code id="power_transform_+3A_pw">pw</code></td>
<td>
<p>The power to which to raise <code>y</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns the result of raising <code>y</code> to the power
<code>pw</code> when <code>y &gt; 0</code>. Otherwise, it will return 1.
</p>

<hr>
<h2 id='PseudoL'>Likelihood function under dependent censoring</h2><span id='topic+PseudoL'></span>

<h3>Description</h3>

<p>The <code>PseudoL</code> function  is maximized in order to
estimate the finite dimensional model parameters, including the dependency parameter.
This function assumes that the cumulative hazard function is known.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PseudoL(theta, resData, X, W, lhat, cumL, cop, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PseudoL_+3A_theta">theta</code></td>
<td>
<p>Estimated parameter values/initial values for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be ones</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_lhat">lhat</code></td>
<td>
<p>The estimated hazard function obtained from the output of <code><a href="#topic+SolveL">SolveL</a></code>.</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_cuml">cumL</code></td>
<td>
<p>The estimated cumulative hazard function from the output of <code><a href="#topic+SolveL">SolveL</a></code>.</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_cop">cop</code></td>
<td>
<p>Which copula should be computed to account for dependency between T and C. This argument can take
one of the values from <code>c("Gumbel", "Frank", "Normal")</code>. The default copula model is &quot;Frank&quot;.</p>
</td></tr>
<tr><td><code id="PseudoL_+3A_dist">dist</code></td>
<td>
<p>The distribution to  be used for the dependent censoring C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>maximized log-likelihood value
</p>

<hr>
<h2 id='S.func'>S-function</h2><span id='topic+S.func'></span>

<h3>Description</h3>

<p>This function computes the loss function at a given point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>S.func(m, Sigma)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="S.func_+3A_m">m</code></td>
<td>
<p>Vector of averages of moment functions.</p>
</td></tr>
<tr><td><code id="S.func_+3A_sigma">Sigma</code></td>
<td>
<p>Sample variance-covariance matrix of moment functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>S(m, Sigma).
</p>

<hr>
<h2 id='ScoreEqn'>Score equations of finite parameters</h2><span id='topic+ScoreEqn'></span>

<h3>Description</h3>

<p>This function computes the score vectors  and the Jacobean matrix for finite model parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScoreEqn(theta, resData, X, W, H)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ScoreEqn_+3A_theta">theta</code></td>
<td>
<p>Vector of parameters in the semiparametric transformation model.</p>
</td></tr>
<tr><td><code id="ScoreEqn_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="ScoreEqn_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T.</p>
</td></tr>
<tr><td><code id="ScoreEqn_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C.</p>
</td></tr>
<tr><td><code id="ScoreEqn_+3A_h">H</code></td>
<td>
<p>The estimated non-parametric transformation function for a given value of theta</p>
</td></tr>
</table>

<hr>
<h2 id='SearchIndicate'>Search function</h2><span id='topic+SearchIndicate'></span>

<h3>Description</h3>

<p>Function to indicate position of t in observed survival time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SearchIndicate(t, T1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SearchIndicate_+3A_t">t</code></td>
<td>
<p>fixed time t</p>
</td></tr>
<tr><td><code id="SearchIndicate_+3A_t1">T1</code></td>
<td>
<p>distinct observed survival time</p>
</td></tr>
</table>

<hr>
<h2 id='set.EAM.hyperparameters'>Set default hyperparameters for EAM algorithm</h2><span id='topic+set.EAM.hyperparameters'></span>

<h3>Description</h3>

<p>This function returns a list with the (default) hyperparameters
used in the EAM algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.EAM.hyperparameters(options)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set.EAM.hyperparameters_+3A_options">options</code></td>
<td>
<p>A list of user-specified values for (some of) the
hyperparameters. These hyperparameters can include:
</p>

<dl>
<dt>min.dist/max.dist:</dt><dd><p>The minimum/maximum distance of sampled points
from the current best value for the coefficient of interest.</p>
</dd>
<dt>min.eval/max.eval:</dt><dd><p>The minimum/maximum number of points evaluated
in the initial feasible point search.</p>
</dd>
<dt>nbr.init.sample.points:</dt><dd><p>The total number of drawn points required in
the initial drawing process.</p>
</dd>
<dt>nbr.init.unif:</dt><dd><p>The total number of uniformly drawn points in the
initial set of starting values.</p>
</dd>
<dt>nbr.points.per.iter.init:</dt><dd><p>Number of points sampled per iteration in
the initial drawing process.</p>
</dd>
<dt>nbr.start.vals:</dt><dd><p>Number of starting values for which to run the
optimization algorithm for the expected improvement.</p>
</dd>
<dt>nbr.opt.EI:</dt><dd><p>Number of optimal theta values found by the optimization
algorithm to return.</p>
</dd>
<dt>nbr.extra:</dt><dd><p>Number of extra randomly drawn points to add to the set
of optimal theta values (to be supplied to the next E-step).</p>
</dd>
<dt>min.improvement:</dt><dd><p>Minimum amount that the current best root of the
violation curve should improve by wrt. the its previous value.</p>
</dd>
<dt>min.possible.improvement:</dt><dd><p>Minimum amount that the next iteration
should be able to improve upon the current best value of the root.</p>
</dd>
<dt>EAM.min.iter:</dt><dd><p>Minimum amount of EAM iterations to run.</p>
</dd>
<dt>max.iter:</dt><dd><p>Maximum amount of EAM iterations to run.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>List of hyperparameters for the EAM algotithm.
</p>

<hr>
<h2 id='set.GS.hyperparameters'>Set default hyperparameters for grid search algorithm</h2><span id='topic+set.GS.hyperparameters'></span>

<h3>Description</h3>

<p>This function returns a list with the (default) hyperparameters
used in the grid search algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.GS.hyperparameters(options)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set.GS.hyperparameters_+3A_options">options</code></td>
<td>
<p>A list of user-specified values for (some of) the
hyperparameters. These hyperparameters could include:
</p>

<dl>
<dt>min.eval/max.eval:</dt><dd><p>Minimum and maximum number of evaluations.</p>
</dd>
<dt>next.gs.point:</dt><dd><p>Function that determines the next point in the grid
search sequence.</p>
</dd>
<dt>step.size:</dt><dd><p>Step size of the grid.</p>
</dd>
<dt>bin.search.tol:</dt><dd><p>Binary search tolerance.</p>
</dd>
<dt>max.iter:</dt><dd><p>Maximum number of iterations that the algorithm can run.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>List of hyperparameters for the gridsearch and binary search
algorithms.
</p>

<hr>
<h2 id='set.hyperparameters'>Define the hyperparameters used for finding the identified interval</h2><span id='topic+set.hyperparameters'></span>

<h3>Description</h3>

<p>This function defines all the necessary hyperparameters used to
run the methodology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set.hyperparameters(data, par.space, c, search.method, options)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set.hyperparameters_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="set.hyperparameters_+3A_par.space">par.space</code></td>
<td>
<p>Bounds on the parameter space.</p>
</td></tr>
<tr><td><code id="set.hyperparameters_+3A_c">c</code></td>
<td>
<p>Projection vector.</p>
</td></tr>
<tr><td><code id="set.hyperparameters_+3A_search.method">search.method</code></td>
<td>
<p>Search method to use (<code>"EAM"</code> or <code>"GS"</code>)</p>
</td></tr>
<tr><td><code id="set.hyperparameters_+3A_options">options</code></td>
<td>
<p>List of user specified hyperparameters that will substitute
the corresponding default values. This list can contain the entries:
</p>

<dl>
<dt>cov.ranges:</dt><dd><p>known bounds on each of the covariates in the data set.</p>
</dd>
<dt>norm.func.name:</dt><dd><p>Name of the normalization function to be used. Can
be either &quot;normalize.covariates1&quot; or &quot;normalize.covariates2&quot; (default).
The former is a simple elementwise rescaling. The latter uses the PCA
approach as discussed in Willems et al. (2024+).</p>
</dd>
<dt>inst.func.family:</dt><dd><p>Family of instrumental functions to be used for
all covariates. Options are &quot;box&quot;, &quot;spline&quot; and &quot;cd&quot;. The former two are
only applicable for continuous covariates. The latter can also handle
discrete covariates. Default is &quot;cd&quot;.</p>
</dd>
<dt>G.c:</dt><dd><p>The class of instrumental functions used for the continuous
covariates in the model, in case &quot;cd&quot; is selected as
<code>inst.func.family:</code>. Options are &quot;box&quot; and &quot;spline&quot;. Default is
&quot;spline&quot;.</p>
</dd>
<dt>degree:</dt><dd><p>The degree of the B-spline functions, should they be used as
instrumental functions for the continuous covariates. Default is 3.</p>
</dd>
<dt>link.function:</dt><dd><p>Name of the link function to be used. Options are
&quot;AFT_ll&quot; for the AFT model with log-logistic baseline, or &quot;Cox_wb&quot; for the
Cox PH model (originally with Weibull baseline, but now for a general)
baseline hazard).</p>
</dd>
<dt>K.bar:</dt><dd><p>Number of refinement steps when obtaining the critical value.
See Bei (2024).</p>
</dd>
<dt>B:</dt><dd><p>Number of bootstrap samples to be used when obtaining the
bootstrap distribution of the test statistic.</p>
</dd>
<dt>ignore.empty.IF:</dt><dd><p>Boolean value indicating whether instrumental
functions with empty support should be ignored (cf. Willems et al., 2024).
Default is FALSE. The feature <code>ignore.empty.IF = TRUE</code> is experimental,
so there might exist edge cases for which the implementation will fail to
run.</p>
</dd>
</dl>

<p>Other (hidden) options can also be overwritten, though we highly discourage
this. If necessary, you can consult the source code of this functions to
find the names of the desired parameters and add their name alongside their
desired value as an entry in <code>options</code> (e.g.
<code>options$min.var &lt;- 1e-4</code>. Again, not recommended!).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The list of hyperparameters.
</p>

<hr>
<h2 id='Sigma.hat'>Compute the variance-covariance matrix of the moment functions.</h2><span id='topic+Sigma.hat'></span>

<h3>Description</h3>

<p>This function comptutes the empricical variance-covariance
matrix of the moment functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sigma.hat(data, beta, t, hp, m.avg = NULL, mi.mat = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Sigma.hat_+3A_data">data</code></td>
<td>
<p>Data frame.</p>
</td></tr>
<tr><td><code id="Sigma.hat_+3A_beta">beta</code></td>
<td>
<p>Coefficient vector.</p>
</td></tr>
<tr><td><code id="Sigma.hat_+3A_t">t</code></td>
<td>
<p>Time point of interest.</p>
</td></tr>
<tr><td><code id="Sigma.hat_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters.</p>
</td></tr>
<tr><td><code id="Sigma.hat_+3A_m.avg">m.avg</code></td>
<td>
<p>A precomputed vector of the sample average of the moment
functions. If not supplied, this vector is computed. Default is
<code>m.avg = NULL</code>.</p>
</td></tr>
<tr><td><code id="Sigma.hat_+3A_mi.mat">mi.mat</code></td>
<td>
<p>A precomputed matrix of moment function evaluations at each
observation. If supplied, some computations can be skipped. Default is
<code>mi.mat = NULL</code>.</p>
</td></tr>
</table>

<hr>
<h2 id='SolveH'>Estimate a nonparametric transformation function</h2><span id='topic+SolveH'></span>

<h3>Description</h3>

<p>This function estimates the nonparametric transformation  function H when the survival time and censoring time
are dependent given covariates.  The estimating equation of H was derived based on the martingale ideas. More details about
the derivation of a nonparmaetric estimator of H and its estimation algorithm can be found in Deresa and Van Keilegom (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SolveH(theta, resData, X, W)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SolveH_+3A_theta">theta</code></td>
<td>
<p>Vector of parameters in the semiparametric transformation model.</p>
</td></tr>
<tr><td><code id="SolveH_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="SolveH_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T.</p>
</td></tr>
<tr><td><code id="SolveH_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the estimated transformation function H for a fixed value of parameters theta.
</p>


<h3>References</h3>

<p>Deresa, N. and Van Keilegom, I. (2021). On semiparametric modelling, estimation and inference for survival data subject to dependent censoring, Biometrika, 108, 965979.
</p>

<hr>
<h2 id='SolveHt1'>Estimating equation for Ht1</h2><span id='topic+SolveHt1'></span>

<h3>Description</h3>

<p>This function obtains an estimating equation of H at the first observed survival time t1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SolveHt1(Ht1, Z, nu, t, X, W, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SolveHt1_+3A_ht1">Ht1</code></td>
<td>
<p>The solver solves for an optimal value of Ht1 by equating the estimating equation to zero.</p>
</td></tr>
<tr><td><code id="SolveHt1_+3A_z">Z</code></td>
<td>
<p>The observed survival time, which is the minimum of T, C and A.</p>
</td></tr>
<tr><td><code id="SolveHt1_+3A_nu">nu</code></td>
<td>
<p>The censoring indicator for T or C</p>
</td></tr>
<tr><td><code id="SolveHt1_+3A_t">t</code></td>
<td>
<p>A fixed time point</p>
</td></tr>
<tr><td><code id="SolveHt1_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T.</p>
</td></tr>
<tr><td><code id="SolveHt1_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C.</p>
</td></tr>
<tr><td><code id="SolveHt1_+3A_theta">theta</code></td>
<td>
<p>Vector of parameters</p>
</td></tr>
</table>

<hr>
<h2 id='SolveL'>Cumulative hazard function of survival time under dependent censoring</h2><span id='topic+SolveL'></span>

<h3>Description</h3>

<p>This function estimates the cumulative hazard function of survival time (T) under dependent censoring (C). The estimation
makes use of the estimating equations derived based on martingale ideas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SolveL(
  theta,
  resData,
  X,
  W,
  cop = c("Frank", "Gumbel", "Normal"),
  dist = c("Weibull", "lognormal")
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SolveL_+3A_theta">theta</code></td>
<td>
<p>Estimated parameter values/initial values for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="SolveL_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="SolveL_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
<tr><td><code id="SolveL_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C. First column of W should be ones</p>
</td></tr>
<tr><td><code id="SolveL_+3A_cop">cop</code></td>
<td>
<p>Which copula should be computed to account for dependency between T and C. This argument can take
one of the values from <code>c("Gumbel", "Frank", "Normal")</code>. The default copula model is &quot;Frank&quot;.</p>
</td></tr>
<tr><td><code id="SolveL_+3A_dist">dist</code></td>
<td>
<p>The distribution to  be used for the dependent censoring C. Only two distributions are allowed, i.e, Weibull
and lognormal distributions. With the value <code>"Weibull"</code> as the
default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns an estimated hazard function, cumulative hazard function and distinct observed survival times;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n = 200
beta = c(0.5)
lambd = 0.35
eta = c(0.9,0.4)
X = cbind(rbinom(n,1,0.5))
W = cbind(rep(1,n),rbinom(n,1,0.5))
frank.cop &lt;- copula::frankCopula(param = 5,dim = 2)
U = copula::rCopula(n,frank.cop)
T1 = (-log(1-U[,1]))/(lambd*exp(X*beta))         # Survival time'
T2 = (-log(1-U[,2]))^(1.1)*exp(W%*%eta)          # Censoring time
A = runif(n,0,15)                                # administrative censoring time
Z = pmin(T1,T2,A)
d1 = as.numeric(Z==T1)
d2 = as.numeric(Z==T2)
resData = data.frame("Z" = Z,"d1" = d1, "d2" = d2)
theta = c(0.3,1,0.3,1,2)

# Estimate cumulative hazard function
cumFit &lt;- SolveL(theta, resData,X,W)
cumhaz = cumFit$cumhaz
time = cumFit$times

# plot hazard vs time

plot(time, cumhaz, type = "l",xlab = "Time",
ylab = "Estimated cumulative hazard function")



</code></pre>

<hr>
<h2 id='SolveLI'>Cumulative hazard function of survival time under independent censoring</h2><span id='topic+SolveLI'></span>

<h3>Description</h3>

<p>This function estimates the cumulative hazard function of survival time (T) under the assumption of independent censoring.
The estimating equation is derived based on martingale ideas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SolveLI(theta, resData, X)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SolveLI_+3A_theta">theta</code></td>
<td>
<p>Estimated parameter values/initial values for finite dimensional parameters</p>
</td></tr>
<tr><td><code id="SolveLI_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="SolveLI_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns an estimated hazard function,  cumulative hazard function and distinct observed survival times;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n = 200
beta = c(0.5)
lambd = 0.35
eta = c(0.9,0.4)
X = cbind(rbinom(n,1,0.5))
W = cbind(rep(1,n),rbinom(n,1,0.5))
frank.cop &lt;- copula::frankCopula(param = 5,dim = 2)
U = copula::rCopula(n,frank.cop)
T1 = (-log(1-U[,1]))/(lambd*exp(X*beta))           # Survival time'
T2 = (-log(1-U[,2]))^(1.1)*exp(W%*%eta)            # Censoring time
A = runif(n,0,15)                                  # administrative censoring time
Z = pmin(T1,T2,A)
d1 = as.numeric(Z==T1)
d2 = as.numeric(Z==T2)
resData = data.frame("Z" = Z,"d1" = d1, "d2" = d2)
theta = c(0.3,1,0.3,1)

# Estimate cumulative hazard function

cumFit_ind &lt;- SolveLI(theta, resData,X)

cumhaz = cumFit_ind$cumhaz
time = cumFit_ind$times

# plot hazard vs time

plot(time, cumhaz, type = "l",xlab = "Time",
ylab = "Estimated cumulative hazard function")




</code></pre>

<hr>
<h2 id='SolveScore'>Estimate finite parameters based on score equations</h2><span id='topic+SolveScore'></span>

<h3>Description</h3>

<p>This function estimates the model parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SolveScore(theta, resData, X, W, H, eps = 0.001)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SolveScore_+3A_theta">theta</code></td>
<td>
<p>Vector of parameters in the semiparametric transformation model.</p>
</td></tr>
<tr><td><code id="SolveScore_+3A_resdata">resData</code></td>
<td>
<p>Data matrix with three columns;  Z = the observed survival time, d1 = the censoring indicator of T
and  d2 =  the censoring indicator of C.</p>
</td></tr>
<tr><td><code id="SolveScore_+3A_x">X</code></td>
<td>
<p>Data matrix with covariates related to T.</p>
</td></tr>
<tr><td><code id="SolveScore_+3A_w">W</code></td>
<td>
<p>Data matrix with covariates related to C.</p>
</td></tr>
<tr><td><code id="SolveScore_+3A_h">H</code></td>
<td>
<p>The estimated non-parametric transformation function for a given value of theta.</p>
</td></tr>
<tr><td><code id="SolveScore_+3A_eps">eps</code></td>
<td>
<p>Convergence error.</p>
</td></tr>
</table>

<hr>
<h2 id='summary.depFit'>Summary of <code>depCensoringFit</code> object</h2><span id='topic+summary.depFit'></span>

<h3>Description</h3>

<p>Summary of <code>depCensoringFit</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'depFit'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.depFit_+3A_object">object</code></td>
<td>
<p>Output of <code><a href="#topic+fitDepCens">fitDepCens</a></code> function</p>
</td></tr>
<tr><td><code id="summary.depFit_+3A_...">...</code></td>
<td>
<p>Further arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Summary of dependent censoring model fit in the form of table
</p>

<hr>
<h2 id='summary.indepFit'>Summary of <code>indepCensoringFit</code> object</h2><span id='topic+summary.indepFit'></span>

<h3>Description</h3>

<p>Summary of <code>indepCensoringFit</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'indepFit'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.indepFit_+3A_object">object</code></td>
<td>
<p>Output of <code><a href="#topic+fitIndepCens">fitIndepCens</a></code> function</p>
</td></tr>
<tr><td><code id="summary.indepFit_+3A_...">...</code></td>
<td>
<p>Further arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Summary of independent censoring model fit in the form of table
</p>

<hr>
<h2 id='SurvDC'>Semiparametric Estimation of the Survival Function under Dependent Censoring</h2><span id='topic+SurvDC'></span>

<h3>Description</h3>

<p>Provide semiparametric approaches that can be used to model right-censored survival data under dependent censoring (without covariates).
The copula-based approach is adopted and there is no need to explicitly specify the association parameter.
One of the margins can be modeled nonparametrically. As a byproduct, both marginal distributions of survival and
censoring times can be considered as fully parametric. The existence of a cured fraction concerning survival time
can also be taken into consideration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvDC(
  yobs,
  delta,
  tm = NULL,
  copfam = "frank",
  margins = list(survfam = NULL, censfam = "lnorm"),
  cure = FALSE,
  Var = list(do = TRUE, nboot = 200, level = 0.05),
  control = list(maxit = 300, eps = 1e-06, trace = TRUE, ktau.inits = NULL)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvDC_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_tm">tm</code></td>
<td>
<p>a numeric vector that contains interested non-negative time points at which the survival probabilities will be evluated.
Note that if we omit the definition of this argument (the default value becomes <code>NULL</code>), our function will automatically output survival probabilities at all oberserved time points, that is, <code>yobs</code>.</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.
Currently, it supports Archimedean copula families, including <code>"frank"</code> (the default value), <code>"clayton"</code>, <code>"gumbel"</code>, and <code>"joe"</code>.
The degenerated independent censoring case can be considered as well by setting <code>"indep"</code>.
(other options will be added in the near future!)</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.
Specifically, it contains the following elements:
</p>

<dl>
<dt><code>survfam</code></dt><dd><p> a character string that defines the assumed distribution for the survival time random variable,
including <code>"lnorm"</code> for log-normal distribution, <code>"weibull"</code> for weibull distribution (other options will be added in the near future).</p>
</dd>
<dt><code>censfam</code></dt><dd><p> a character string that defines the assumed distribution for the censoring time random variable, and the details are the same as those shown in <code>survfam</code>.</p>
</dd>
<dt><code>survtrunc</code></dt><dd><p> a positive numeric value thats denotes the value of truncation for the assumed distribution, that is, <code>survfam</code>.</p>
</dd>
<dt><code>censtrunc</code></dt><dd><p> a positive numeric value thats denotes the value of truncation for the assumed distribution, that is, <code>censfam</code>.</p>
</dd>
</dl>

<p>Note if one of the marginal distributions should be modeled nonparametrically, one can let the corresponding argument to be <code>NULL</code> directly.
For example if a semiparametric framework that defines the survival margin to be nonparametric and the censoring margin to be parametric, say log-normal, is desired,
we can let <code>survfam = NULL</code> and <code>censfam = "lnorm"</code>, which is indeed the default value.
Furthermore, if no truncation is imposed in <code>survfam</code> (or <code>censfam</code>), one can directly omit the specification of <code>survtrunc</code> (or <code>censtrunc</code>), which is the default specification.
We also remark here that when a cured fraction is included (<code>cure = TRUE</code>), if <code>survfam</code> is not <code>NULL</code> and <code>survtrunc = NULL</code>, we will automatically let <code>survtrunc</code> to be <code>max(yobs)</code>.
If we wants to model the data with a non-truncated survival distribution when there is a cured fraction, we can set <code>survtrunc = Inf</code>.</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_var">Var</code></td>
<td>
<p>a list that controls the execution of the bootstrap for variance estimation,
and it contains two elements:
<code>do</code> is a logical value with default <code>FALSE</code> to tell the function whether the boostrap-based variances should be calculated;
<code>nboot</code> is a numeric integer that specifies the number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="SurvDC_+3A_control">control</code></td>
<td>
<p>indicates more detailed control of the underlying model fitting procedures.
It is a list of the following three arguments:
</p>

<dl>
<dt><code>maxit</code></dt><dd><p> a positive integer that denotes the maximum iteration number in optimization. The default value is <code>300</code>.</p>
</dd>
<dt><code>eps</code></dt><dd><p> a positive small numeric value that denotes the tolerance for convergence. The default value is <code>1e-6</code>.</p>
</dd>
<dt><code>trace</code></dt><dd><p> a logical value that judges whereh the tracing information on the progress of the model fitting should be produced. The default value if <code>TRUE</code>.</p>
</dd>
<dt><code>ktau.inits</code></dt><dd><p> a numeric vector that contains initial values of the Kendall's tau.
The default value is <code>NULL</code>, meaning that a grids of initial values will be automatically generated within our function.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>This unified function provide approaches that can be used to model right-censored survival data under dependent censoring (without covariates).
Various specifications of marginal distributions can be considered by choosing different combinations of the provided arguments.
Generally speaking, the following two scenarios are what we mainly focused on:
</p>

<dl>
<dt><code>nonparametric survival margin and parametric censoring margin (without cure)</code></dt><dd>
<p><code>survfam = NULL</code>, <code>censfam</code> is not <code>NULL</code> and <code>cure = FALSE</code>.</p>
</dd>
<dt><code>nonparametric survival margin and parametric censoring margin (with cure)</code></dt><dd>
<p><code>survfam = NULL</code>, <code>censfam</code> is not <code>NULL</code> and <code>cure = TRUE</code>.</p>
</dd>
</dl>

<p>As byproducts, several other scenarios (the distribution of the underlying survival time is not nonparametric
but fully parametric) can also be considered by this R function:
</p>

<dl>
<dt><code>parametric survival and censoring margins (without cure)</code></dt><dd>
<p>both <code>survfam</code> and <code>censfam</code> are not <code>NULL</code> and <code>cure = FALSE</code>.</p>
</dd>
<dt><code>parametric survival and censoring margins (with cure)</code></dt><dd>
<p>both <code>survfam</code> and <code>censfam</code> are not <code>NULL</code> and <code>cure = TRUE</code>.</p>
</dd>
<dt><code>parametric survival margin and nonparametric censoring margin (without cure)</code></dt><dd>
<p><code>survfam</code> is not <code>NULL</code>, <code>censfam = NULL</code> and <code>cure = FALSE</code>.</p>
</dd>
</dl>

<p>Furthermore, one might expect that a scenario with &quot;parametric survival margin and nonparametric censoring margin
(with cure)&quot; can also be included. Indeed, it can be done based on: <code>survfam</code> is not <code>NULL</code>, <code>censfam = NULL</code>
and <code>cure = TRUE</code>. However, from a theoretical perspective of view, whether this type of modeling is reasonable or not
still needs further investigations.
</p>
<p>We emphasize that the first scenario (in byproducts) has also be considered in another function of this package.
Specifically, the scenario of &quot;parametric survival margin and nonparametric censoring margin (without cure)&quot; can be
fitted based on <code>ParamCop()</code>. However, the default joint modeling of survival and censoring times are based on
their joint survival function in line with the semiparametric case (instead of modeling joint distribution function
directly as in  Czado and Van Keilegom (2023) &lt;doi:10.1093/biomet/asac067&gt;), but the idea of estimation methodology
are exactly the same.
</p>
<p>@references Czado and Van Keilegom (2023). Dependent censoring based on parametric copulas. Biometrika, 110(3), 721-738.
@references Delhelle and Van Keilegom (2024). Copula based dependent censoring in cure models. TEST (to appear).
@references Ding and Van Keilegom (2024). Semiparametric estimation of the survival function under dependent censoring (in preparation).
</p>


<h3>Value</h3>

<p>A list of fitted results is returned.
Within this outputted list, the following elements can be found:
</p>

<dl>
<dt><code>probs</code></dt><dd><p>survival probabilities of the survial margin at <code>tm</code>.</p>
</dd>
<dt><code>ktau</code></dt><dd><p>Kendall's tau.</p>
</dd>
<dt><code>parapar</code></dt><dd><p>estimation of all parameters (except Kendall's tau) contained in the parametric part.</p>
</dd>
<dt><code>GoF</code></dt><dd><p>goodness-of-test results.</p>
</dd>
<dt><code>curerate</code></dt><dd><p>cure rate. If <code>cure = FALSE</code>, it is <code>NULL</code>.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>

#----------------------------------------------------------#
# Basic preparations before running subsequent examples ####
#----------------------------------------------------------#

# library necessary packages

#------------------------------------------------------------------------#
# simulated data from Frank copula log-Normal margins (without cure)
#------------------------------------------------------------------------#

# generate the simulated data

# - the sample size of the generated data
n &lt;- 1000

# information on the used copula
copfam.true &lt;- "frank"
ktau.true &lt;- 0.5
coppar.true &lt;- 5.74

# parameters of the underlying log-normal marginal distributions
survpar.true &lt;- c(2.20,1.00)
censpar.true &lt;- c(2.20,0.25)

# - true underlying survival and censoring times
set.seed(1)
u.TC &lt;- copula::rCopula(
  n        = n,
  copula   = copula::archmCopula(
    family = copfam.true,
    param  = coppar.true,
    dim    = 2
  )
)
yobs.T &lt;- qlnorm(1-u.TC[,1],survpar.true[1],survpar.true[2])
yobs.C &lt;- qlnorm(1-u.TC[,2],censpar.true[1],censpar.true[2])

# observations
yobs  &lt;- pmin(yobs.T,yobs.C)
delta &lt;- as.numeric(yobs.T&lt;=yobs.C)
cat("censoring rate is", mean(1-delta))

# model the data under different scenarios

# scenario 1: nonparametric survival margin and parametric censoring margin
set.seed(1)
sol.scenario1 &lt;- SurvDC(
  yobs    = yobs,
  delta   = delta,
  tm      = quantile(yobs, c(0.25,0.50,0.75)),
  copfam  = copfam.true,
  margins = list(survfam = NULL, censfam = "lnorm"),
  Var     = list(do = FALSE, nboot = 50)
)
sol.scenario1$probs
sol.scenario1$ktau
sol.scenario1$parapar

# scenario 2: parametric survival and censoring margins
set.seed(1)
sol.scenario2 &lt;- SurvDC(
  yobs    = yobs,
  delta   = delta,
  tm      = quantile(yobs, c(0.25,0.50,0.75)),
  copfam  = copfam.true,
  margins = list(survfam = "lnorm", censfam = "lnorm"),
  Var     = list(do = FALSE, nboot = 50)
)
sol.scenario2$probs
sol.scenario2$ktau
sol.scenario2$parapar

# scenario 3: parametric survival margin and nonparametric censoring margin
set.seed(1)
sol.scenario3 &lt;- SurvDC(
  yobs    = yobs,
  delta   = delta,
  tm      = quantile(yobs, c(0.25,0.50,0.75)),
  copfam  = copfam.true,
  margins = list(survfam = "lnorm", censfam = NULL),
  Var     = list(do = FALSE, nboot = 50)
)
sol.scenario3$probs
sol.scenario3$ktau
sol.scenario3$parapar

#------------------------------------------------------------------------
# simulated data from Frank copula log-Normal margins (with cure)
#------------------------------------------------------------------------

# generate the simulated data

#  true underlying cure rate
curerate.true &lt;- 0.2

# true underlying survival and censoring times
set.seed(1)
u.TC &lt;- copula::rCopula(
  n        = n,
  copula   = copula::archmCopula(
    family = copfam.true,
    param  = coppar.true,
    dim    = 2
  )
)
yobs.T &lt;- sapply(u.TC[,1],function(uT){
  if(uT&lt;=curerate.true){ val &lt;- Inf }else{
    val &lt;- EnvStats::qlnormTrunc((1-uT)/(1-curerate.true),survpar.true[1],survpar.true[2],0,15)
  }
  return(val)
})
yobs.C &lt;- qlnorm(1-u.TC[,2],censpar.true[1],censpar.true[2])
cat("cure rate is",mean(yobs.T==Inf))

#  observations
yobs  &lt;- pmin(yobs.T,yobs.C)
delta &lt;- as.numeric(yobs.T&lt;=yobs.C)
cat("censoring rate is",mean(1-delta))

# model the data under different scenarios (with cure)

# scenario 4: parametric survival and censoring margins
set.seed(1)
sol.scenario4 &lt;- SurvDC(
  yobs    = yobs,
  delta   = delta,
  tm      = quantile(yobs, c(0.25,0.50,0.75)),
  copfam  = copfam.true,
  margins = list(survfam = "lnorm", censfam = "lnorm"),
  Var     = list(do = FALSE, nboot = 50),
  cure    = TRUE
)
sol.scenario4$probs
sol.scenario4$ktau
sol.scenario4$parapar
sol.scenario4$curerate

# scenario 5: nonparametric survival margin and parametric censoring margin
set.seed(1)
sol.scenario5 &lt;- SurvDC(
  yobs    = yobs,
  delta   = delta,
  tm      = quantile(yobs, c(0.25,0.50,0.75)),
  copfam  = copfam.true,
  margins = list(survfam = NULL, censfam = "lnorm"),
  Var     = list(do = FALSE, nboot = 50),
  cure    = TRUE
)
sol.scenario5$probs
sol.scenario5$ktau
sol.scenario5$parapar
sol.scenario5$curerate


</code></pre>

<hr>
<h2 id='SurvDC.GoF'>Calculate the goodness-of-fit test statistic</h2><span id='topic+SurvDC.GoF'></span>

<h3>Description</h3>

<p>Calculate the goodness-of-fit test statistic
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvDC.GoF(
  yobs,
  delta,
  copfam,
  margins,
  ktau,
  parapar,
  cure = FALSE,
  curerate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvDC.GoF_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_copfam">copfam</code></td>
<td>
<p>a character string that specifies the copula family.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_margins">margins</code></td>
<td>
<p>a list used to define the distribution structures of both the survival and censoring margins.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_ktau">ktau</code></td>
<td>
<p>Kendall's tau.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_parapar">parapar</code></td>
<td>
<p>parametric parameters.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
<tr><td><code id="SurvDC.GoF_+3A_curerate">curerate</code></td>
<td>
<p>value of cure rate.</p>
</td></tr>
</table>

<hr>
<h2 id='SurvFunc.CG'>Estimated survival function based on copula-graphic estimator (Archimedean copula only)</h2><span id='topic+SurvFunc.CG'></span>

<h3>Description</h3>

<p>Estimated survival function based on copula-graphic estimator (Archimedean copula only)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvFunc.CG(tm = NULL, yobs, delta, copfam, ktau, coppar = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvFunc.CG_+3A_tm">tm</code></td>
<td>
<p>a vector contains all time points that the survival function will be calculated at.</p>
</td></tr>
<tr><td><code id="SurvFunc.CG_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="SurvFunc.CG_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="SurvFunc.CG_+3A_copfam">copfam</code></td>
<td>
<p>a character string that denotes the copula family.</p>
</td></tr>
<tr><td><code id="SurvFunc.CG_+3A_ktau">ktau</code></td>
<td>
<p>a numeric value that denotes the Kendall's tau.</p>
</td></tr>
<tr><td><code id="SurvFunc.CG_+3A_coppar">coppar</code></td>
<td>
<p>a numeric value that denotes the copula parameter.</p>
</td></tr>
</table>

<hr>
<h2 id='SurvFunc.KM'>Estimated survival function based on Kaplan-Meier estimator</h2><span id='topic+SurvFunc.KM'></span>

<h3>Description</h3>

<p>Estimated survival function based on Kaplan-Meier estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvFunc.KM(tm = NULL, yobs, delta, type = "right")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvFunc.KM_+3A_tm">tm</code></td>
<td>
<p>a vector contains all time points that the survival function will be calculated at.</p>
</td></tr>
<tr><td><code id="SurvFunc.KM_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="SurvFunc.KM_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="SurvFunc.KM_+3A_type">type</code></td>
<td>
<p>a character string that specifies the type of the step function. If <code>type="right"</code>, it will be a right-continuous function.</p>
</td></tr>
</table>

<hr>
<h2 id='SurvMLE'>Maximum likelihood estimator for a given parametric distribution</h2><span id='topic+SurvMLE'></span>

<h3>Description</h3>

<p>Maximum likelihood estimator for a given parametric distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvMLE(
  yobs,
  delta,
  distribution,
  truncation = NULL,
  cure = FALSE,
  maxit = 300
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvMLE_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="SurvMLE_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="SurvMLE_+3A_distribution">distribution</code></td>
<td>
<p>the specified distribution function.</p>
</td></tr>
<tr><td><code id="SurvMLE_+3A_truncation">truncation</code></td>
<td>
<p>a positive numeric value thats denotes the value of truncation for the assumed distribution.</p>
</td></tr>
<tr><td><code id="SurvMLE_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
<tr><td><code id="SurvMLE_+3A_maxit">maxit</code></td>
<td>
<p>a positive integer that denotes the maximum iteration number in optimization.</p>
</td></tr>
</table>

<hr>
<h2 id='SurvMLE.Likelihood'>Likelihood for a given parametric distribution</h2><span id='topic+SurvMLE.Likelihood'></span>

<h3>Description</h3>

<p>Likelihood for a given parametric distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SurvMLE.Likelihood(
  param,
  yobs,
  delta,
  distribution,
  truncation = NULL,
  cure = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SurvMLE.Likelihood_+3A_param">param</code></td>
<td>
<p>a vector contains all parametric parameters.</p>
</td></tr>
<tr><td><code id="SurvMLE.Likelihood_+3A_yobs">yobs</code></td>
<td>
<p>a numeric vector that indicated the observed survival times.</p>
</td></tr>
<tr><td><code id="SurvMLE.Likelihood_+3A_delta">delta</code></td>
<td>
<p>a numeric vector that stores the right-censoring indicators.</p>
</td></tr>
<tr><td><code id="SurvMLE.Likelihood_+3A_distribution">distribution</code></td>
<td>
<p>the specified distribution function.</p>
</td></tr>
<tr><td><code id="SurvMLE.Likelihood_+3A_truncation">truncation</code></td>
<td>
<p>a positive numeric value thats denotes the value of truncation for the assumed distribution.</p>
</td></tr>
<tr><td><code id="SurvMLE.Likelihood_+3A_cure">cure</code></td>
<td>
<p>a logical value that indicates whether the existence of a cured fraction should be considered.</p>
</td></tr>
</table>

<hr>
<h2 id='TCsim'>Function to simulate (Y,Delta) from the copula based model for (T,C).</h2><span id='topic+TCsim'></span>

<h3>Description</h3>

<p>Generates the follow-up time and censoring indicator according to the specified model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TCsim(
  tau = 0,
  Copula = "frank",
  Dist.T = "lnorm",
  Dist.C = "lnorm",
  par.T = c(0, 1),
  par.C = c(0, 1),
  n = 10000
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TCsim_+3A_tau">tau</code></td>
<td>
<p>Value of Kendall's tau for (T,C). The default value is 0.</p>
</td></tr>
<tr><td><code id="TCsim_+3A_copula">Copula</code></td>
<td>
<p>The copula family. This argument can take values from <code>c("frank","gumbel","clayton","gaussian","indep")</code>. The default copula model is &quot;frank&quot;.</p>
</td></tr>
<tr><td><code id="TCsim_+3A_dist.t">Dist.T</code></td>
<td>
<p>Distribution of the survival time T. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>. The default distribution is &quot;lnorm&quot;.</p>
</td></tr>
<tr><td><code id="TCsim_+3A_dist.c">Dist.C</code></td>
<td>
<p>Distribution of the censoring time C. This argument can take one of the values from <code>c("lnorm", "weibull", "llogis")</code>. The default distribution is &quot;lnorm&quot;.</p>
</td></tr>
<tr><td><code id="TCsim_+3A_par.t">par.T</code></td>
<td>
<p>Parameter values for the distribution of T.</p>
</td></tr>
<tr><td><code id="TCsim_+3A_par.c">par.C</code></td>
<td>
<p>Parameter values for the distribution of C.</p>
</td></tr>
<tr><td><code id="TCsim_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the generated follow-up times and censoring indicators.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>tau = 0.5
Copula = "gaussian"
Dist.T = "lnorm"
Dist.C = "lnorm"
par.T = c(1,1)
par.C = c(2,2)
n=1000

simdata &lt;- TCsim(tau,Copula,Dist.T,Dist.C,par.T,par.C,n)
Y = simdata[[1]]
Delta = simdata[[2]]
hist(Y)
mean(Delta)

</code></pre>

<hr>
<h2 id='test.point_Bei'>Perform the test of Bei (2024) for a given point</h2><span id='topic+test.point_Bei'></span>

<h3>Description</h3>

<p>This function performs the unconditional moment restriction test
as described in Bei (2024).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.point_Bei(
  r,
  c,
  t,
  par.space,
  data,
  hp,
  verbose = FALSE,
  inst.func.evals = NULL,
  alpha = 0.95,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.point_Bei_+3A_r">r</code></td>
<td>
<p>Result of the projection for which the test should be carried out.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_c">c</code></td>
<td>
<p>The projection matrix. For now, c is restricted to being an
elementary vector, i.e. c = (0, ...,0, 1, 0, ..., 0).</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_t">t</code></td>
<td>
<p>The time point at which to evaluate theta.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_par.space">par.space</code></td>
<td>
<p>Matrix containing 2 columns and <code class="reqn">d_\theta</code> rows, where
<code class="reqn">d_\theta</code> is the dimension of the parameter space. The first column
represents the lower left corner of the parameter space, the second column
represents the upper right corner. At least for the time being, only
rectangular parameter spaces are allowed.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_data">data</code></td>
<td>
<p>Data frame on which to base the test.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters needed.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_verbose">verbose</code></td>
<td>
<p>Boolean variable indicating whether to print updates of the
estimation process to the console.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Matrix of precomputed instrumental function
evaluations for each observation in the data set. Used to speed up the
simulations. If <code>NULL</code>, the evaluations will be computed during
execution of this function. Default is <code>inst.func.evals = NULL</code>.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_alpha">alpha</code></td>
<td>
<p>The significance level at which to perform the test. Default is
<code>alpha = 0.95</code>.</p>
</td></tr>
<tr><td><code id="test.point_Bei_+3A_parallel">parallel</code></td>
<td>
<p>Flag for whether or not parallel computing should be used.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bei, X. (2024). Local linearization based subvector inference in
moment inequality models. Journal of Econometrics, 238(1),
105549-. https://doi.org/10.1016/j.jeconom.2023.10554
</p>

<hr>
<h2 id='test.point_Bei_MT'>Perform the test of Bei (2024) simultaneously for multiple time
points.</h2><span id='topic+test.point_Bei_MT'></span>

<h3>Description</h3>

<p>This function performs the unconditional moment restriction test
as described in Bei (2024). This function directly extends
<code>test.point_Bei</code> by allowing for pairs of moment restrictions over a
grid of time points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>test.point_Bei_MT(
  r,
  c,
  t,
  par.space,
  data,
  hp,
  verbose = FALSE,
  inst.func.evals = NULL,
  alpha = 0.95,
  parallel = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="test.point_Bei_MT_+3A_r">r</code></td>
<td>
<p>Result of the projection for which the test should be carried out.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_c">c</code></td>
<td>
<p>The projection matrix. For now, c is restricted to being an
elementary vector, i.e. c = (0, ...,0, 1, 0, ..., 0).</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_t">t</code></td>
<td>
<p>The time point at which to evaluate theta. Also allowed to
be a vector of time points (used in estimating the model under assumed time-
independent coefficients).</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_par.space">par.space</code></td>
<td>
<p>Matrix containing 2 columns and <code class="reqn">d_\theta</code> rows, where
<code class="reqn">d_\theta</code> is the dimension of the parameter space. The first column
represents the lower left corner of the parameter space, the second column
represents the upper right corner. At least for the time being, only
rectangular parameter spaces are allowed.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_data">data</code></td>
<td>
<p>Data frame on which to base the test.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_hp">hp</code></td>
<td>
<p>List of hyperparameters needed.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_verbose">verbose</code></td>
<td>
<p>Boolean variable indicating whether to print updates of the
estimation process to the console.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_inst.func.evals">inst.func.evals</code></td>
<td>
<p>Matrix of precomputed instrumental function
evaluations for each observation in the data set. Used to speed up the
simulations. If <code>NULL</code>, the evaluations will be computed during
execution of this function. Default is <code>inst.func.evals = NULL</code>.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_alpha">alpha</code></td>
<td>
<p>The significance level at which to perform the test. Default is
<code>alpha = 0.95</code>.</p>
</td></tr>
<tr><td><code id="test.point_Bei_MT_+3A_parallel">parallel</code></td>
<td>
<p>Flag for whether or not parallel computing should be used.
Default is <code>parallel = FALSE</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bei, X. (2024). Local linearization based subvector inference in
moment inequality models. Journal of Econometrics, 238(1),
105549-. https://doi.org/10.1016/j.jeconom.2023.10554
</p>

<hr>
<h2 id='uniformize.data'>Standardize data format</h2><span id='topic+uniformize.data'></span>

<h3>Description</h3>

<p>Checks the required preconditions of the data and possibly
restructures the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniformize.data(
  data,
  admin = FALSE,
  conf = FALSE,
  comp.risks = FALSE,
  Zbin = NULL,
  Wbin = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="uniformize.data_+3A_data">data</code></td>
<td>
<p>A data frame that should contain columns named <code>Y</code> and
<code>delta</code> (unless <code>comp.risks = TRUE</code>, see later).</p>
</td></tr>
<tr><td><code id="uniformize.data_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the provided data frame contains
administrative (i.e. independent) censoring on top of the dependent censoring
(in the column named <code>delta</code>). The default is <code>admin = FALSE</code>.</p>
</td></tr>
<tr><td><code id="uniformize.data_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the provided data frame contains
a confounded variable and a corresponding instrument. If <code>cond = TRUE</code>,
the provided data frame should contain columns named <code>Z</code> and <code>W</code>,
corresponding to the confounded variable and instrument, respectively.
Moreover, <code>Zbin</code> and <code>Wbin</code> should be specified. The default value
is <code>conf = FALSE</code>.</p>
</td></tr>
<tr><td><code id="uniformize.data_+3A_comp.risks">comp.risks</code></td>
<td>
<p>Boolean value indicating whether the provided data frame
contains competing risks. If <code>comp.risks = TRUE</code>, the given data frame
should contain the columns <code>delta1</code>, <code>delta2</code>, etc., corresponding
to the indicators I(Y = T1), I(Y = T2), etc. respectively. The default is
<code>comp.risks = FALSE</code>.</p>
</td></tr>
<tr><td><code id="uniformize.data_+3A_zbin">Zbin</code></td>
<td>
<p>Boolean or integer value (0, 1) indicating whether the confounded
variable is binary. <code>Zbin = TRUE</code> or <code>Zbin = 1</code> means that Z is
binary. <code>Zbin = FALSE</code> or <code>Zbin = 0</code> means that Z is continuous.</p>
</td></tr>
<tr><td><code id="uniformize.data_+3A_wbin">Wbin</code></td>
<td>
<p>Boolean or integer value (0, 1) indicating whether the instrument
is binary. <code>Wbin = TRUE</code> or <code>Wbin = 1</code> means that W is binary.
<code>Wbin = FALSE</code> or <code>Wbin = 0</code> means that W is continuous.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the uniformized data set.
</p>

<hr>
<h2 id='variance.cmprsk'>Compute the variance of the estimates.</h2><span id='topic+variance.cmprsk'></span>

<h3>Description</h3>

<p>This function computes the variance of the estimates computed
by the 'estimate.cmprsk.R' function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variance.cmprsk(
  parhatc,
  gammaest,
  data,
  admin,
  conf,
  inst,
  cf,
  eoi.indicator.names,
  Zbin,
  use.chol,
  n.trans,
  totparl
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="variance.cmprsk_+3A_parhatc">parhatc</code></td>
<td>
<p>Vector of estimated parameters, computed in the first part of
<code>estimate.cmprsk.R</code>.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_gammaest">gammaest</code></td>
<td>
<p>Vector of estimated parameters in the regression model for
the control function.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_data">data</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_admin">admin</code></td>
<td>
<p>Boolean value indicating whether the data contains
administrative censoring.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_conf">conf</code></td>
<td>
<p>Boolean value indicating whether the data contains confounding
and hence indicating the presence of <code>z</code> and, possibly, <code>w</code>.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_inst">inst</code></td>
<td>
<p>Variable encoding which approach should be used for dealing with
the confounding. <code>inst = "cf"</code> indicates that the control function
approach should be used. <code>inst = "W"</code> indicates that the instrumental
variable should be used 'as is'. <code>inst = "None"</code> indicates that Z will
be treated as an exogenous covariate. Finally, when <code>inst = "oracle"</code>,
this function will access the argument <code>realV</code> and use it as the values
for the control function. Default is <code>inst = "cf"</code>.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_cf">cf</code></td>
<td>
<p>The control function used to estimate the second step.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_eoi.indicator.names">eoi.indicator.names</code></td>
<td>
<p>Vector of names of the censoring indicator columns
pertaining to events of interest. Events of interest will be modeled allowing
dependence between them, whereas all censoring events (corresponding to
indicator columns not listed in <code>eoi.indicator.names</code>) will be treated
as independent of every other event. If <code>eoi.indicator.names == NULL</code>,
all events will be modeled dependently.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_zbin">Zbin</code></td>
<td>
<p>Indicator value indicating whether (<code>Zbin = TRUE</code>) or not
<code>Zbin = FALSE</code> the endogenous covariate is binary. Default is
<code>Zbin = NULL</code>, corresponding to the case when <code>conf == FALSE</code>.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_use.chol">use.chol</code></td>
<td>
<p>Boolean value indicating whether the cholesky decomposition
was used in estimating the covariance matrix.</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_n.trans">n.trans</code></td>
<td>
<p>Number of competing risks in the model (and hence, number of
transformation models).</p>
</td></tr>
<tr><td><code id="variance.cmprsk_+3A_totparl">totparl</code></td>
<td>
<p>Total number of covariate effects (including intercepts) in
all of the transformation models combined.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Variance estimates of the provided vector of estimated parameters.
</p>

<hr>
<h2 id='YJtrans'>Yeo-Johnson transformation function</h2><span id='topic+YJtrans'></span>

<h3>Description</h3>

<p>Computes the Yeo-Johnson transformation of the provided argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>YJtrans(y, theta)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="YJtrans_+3A_y">y</code></td>
<td>
<p>The argument to be supplied to the Yeo-Johnson transformation.</p>
</td></tr>
<tr><td><code id="YJtrans_+3A_theta">theta</code></td>
<td>
<p>The parameter of the Yeo-Johnson transformation. This should be
a number in the range [0,2].</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The transformed value of y.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
