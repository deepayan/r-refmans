<!DOCTYPE html><html><head><title>Help for package ePCR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ePCR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bootstrapRegCoefs'><p>Bootstrapped testing of regression coefficients in a penalized model</p></a></li>
<li><a href='#conforminput'><p>Conform the dimensions of a new input data matrix to a readily fitted PEP or PSP object</p></a></li>
<li><a href='#cv'><p>Function that creates customized cross-validation folds</p></a></li>
<li><a href='#cv.alpha'><p>Cross-validation runs for risk predition at a single value of alpha</p></a></li>
<li><a href='#cv.grid'><p>Cross-validation runs for risk predition for a grid of predetermined alpha values and their conditional lambda values</p></a></li>
<li><a href='#DREAM'><p>FIMM-UTU DREAM winning implementation of an ensemble of Penalized Cox Regression models for mCPRC research (ePCR)</p></a></li>
<li><a href='#ePCR'><p>Ensemble Penalized Cox Regression Modeling for Overall Survival and Time-to-Event Prediction in Advanced Prostate Cancer</p></a></li>
<li><a href='#heatcv'><p>Plot a heatmap of the prediction performance statistic as a function of lambda and alpha combinations</p></a></li>
<li><a href='#integrateRegCurve'><p>Integrate the area over/under the regularization path of a penalized regression model</p></a></li>
<li><a href='#interact.all'><p>Compute all pairwise interactions between the columns of a data matrix</p></a></li>
<li><a href='#interact.part'><p>Compute a chosen set of pairwise interactions between two sets of columns in a data matrix</p></a></li>
<li><a href='#meanrank'><p>Compute mean of predicted risk ranks for an ePCR ensemble</p></a></li>
<li><a href='#NelsonAalen'><p>Cox-Oakes extension of the Nelson-Aalen estimates for a Cox model</p></a></li>
<li><a href='#normriskrank'><p>Normalize ensemble risk scores to ranks and then to uniform range</p></a></li>
<li><a href='#PEP-class'><p>Penalized Ensemble Predictor (PEP) S4-class ensemble consisting of individual PSP-members</p></a></li>
<li><a href='#PEP-methods'><p>PEP-methods</p></a></li>
<li><a href='#PSP-class'><p>Penalized Single Predictor (PSP) S4-class as a member of PEP-ensembles</p></a></li>
<li><a href='#PSP-methods'><p>PSP-methods</p></a></li>
<li><a href='#score.cindex'><p>Scoring function for evaluating survival prediction through concordance index (c-index)</p></a></li>
<li><a href='#score.iAUC'><p>Scoring function for evaluating survival prediction by time-wise integrated AUC</p></a></li>
<li><a href='#TimeSurvProb'><p>Predict cumulative survival probabilities for new data at given time points</p></a></li>
<li><a href='#TYKS'><p>ePCR model fitted to the Turku University Hospital cohorts (all features)</p></a></li>
<li><a href='#TYKS_reduced'><p>ePCR model fitted to the Turku University Hospital cohorts (features derived from text mining only)</p></a></li>
<li><a href='#TYKSSIMU'><p>TYKSSIMU - simulated data matrices and survival responses from Turku University Hospital</p></a></li>
<li><a href='#zt'><p>Extended function for z-transformation, filling non-finite values and changes column names at will</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Ensemble Penalized Cox Regression for Survival Prediction</td>
</tr>
<tr>
<td>Version:</td>
<td>0.11.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-18</td>
</tr>
<tr>
<td>Author:</td>
<td>Teemu Daniel Laajala &lt;teelaa@utu.fi&gt; [aut, cre], Mika Murtojarvi &lt;mianmu2@hotmail.com&gt; [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Teemu Daniel Laajala &lt;teelaa@utu.fi&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, stats, methods, glmnet, hamlet, survival,
timeROC, pracma, Bolstad2, impute</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, ROCR, c060, utils, Matrix (&ge; 1.5-0), knitr, rmarkdown</td>
</tr>
<tr>
<td>Description:</td>
<td>The top-performing ensemble-based Penalized Cox Regression (ePCR) framework developed during the DREAM 9.5 mCRPC Prostate Cancer Challenge <a href="https://www.synapse.org/ProstateCancerChallenge">https://www.synapse.org/ProstateCancerChallenge</a> presented in Guinney J, Wang T, Laajala TD, et al. (2017) &lt;<a href="https://doi.org/10.1016%2FS1470-2045%2816%2930560-5">doi:10.1016/S1470-2045(16)30560-5</a>&gt; is provided here-in, together with the corresponding follow-up work. While initially aimed at modeling the most advanced stage of prostate cancer, metastatic Castration-Resistant Prostate Cancer (mCRPC), the modeling framework has subsequently been extended to cover also the non-metastatic form of advanced prostate cancer (CRPC). Readily fitted ensemble-based model S4-objects are provided, and a simulated example dataset based on a real-life cohort is provided from the Turku University Hospital, to illustrate the use of the package. Functionality of the ePCR methodology relies on constructing ensembles of strata in patient cohorts and averaging over them, with each ensemble member consisting of a highly optimized penalized/regularized Cox regression model. Various cross-validation and other modeling schema are provided for constructing novel model objects.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-18 21:06:08 UTC; teemu</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-19 12:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bootstrapRegCoefs'>Bootstrapped testing of regression coefficients in a penalized model</h2><span id='topic+bootstrapRegCoefs'></span>

<h3>Description</h3>

<p>The purpose of this function is to evaluate a p-value-like statistic for penalized regression coefficients. A fixed number of bootstrapped datasets are generated, and the model coefficients are fitted to these bootstrapped datasets using the pre-determined lambda.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootstrapRegCoefs(fit, lambda, boot = 1000, epsilon = 10^-6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootstrapRegCoefs_+3A_fit">fit</code></td>
<td>
<p>A regularized regression model fit as provided by the glmnet-package</p>
</td></tr>
<tr><td><code id="bootstrapRegCoefs_+3A_lambda">lambda</code></td>
<td>
<p>The pre-fixed corresponding optimal lambda value, typically determined using cross-validation (e.g. cv.glmnet$lambda.1se or cv.glmnet$lambda.min in glmnet)</p>
</td></tr>
<tr><td><code id="bootstrapRegCoefs_+3A_boot">boot</code></td>
<td>
<p>The number of bootstrapped datasets to generate</p>
</td></tr>
<tr><td><code id="bootstrapRegCoefs_+3A_epsilon">epsilon</code></td>
<td>
<p>The tolerance around beta = 0 to still count estimates as zero</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Significance values for regression coefficients, defined as the proportion of bootstrapped model fits where coefficient did not shrink within epsilon of zero or where it did not flip sign.
</p>


<h3>Note</h3>

<p>Notice that this is a highly experimental function, and that many statisticians argue that computing p-values does not make sense for penalized models. The null hypothesis is not well defined, as the bias (regularization) pushes the regression coefficients towards zero. Therefore the null hypothesis is not known and the interpretation is not the conventional regression coefficient p-value.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Computationally too intensive to run bootstrapped fits &lt;5s
data(TYKSSIMU)
library(survival)
x &lt;- as.matrix(xMEDISIMU)
y &lt;- yMEDISIMU[,"surv"]
nlambda &lt;- 30
psp1 &lt;- new("PSP", alphaseq=c(0, 0.5, 1), nlambda = nlambda, folds = 3, x = x, y = y, seeds = 1)
.Object &lt;- psp1
alphaopt &lt;- psp1@optimum["Alpha"]
bs &lt;- bootstrapRegCoefs(fit = psp1@fit, lambda = psp1@optimum["Lambda"], boot = 100)
# Histogram of bootstrapped ps
hist(bs$ps, breaks=100)

## End(Not run)
</code></pre>

<hr>
<h2 id='conforminput'>Conform the dimensions of a new input data matrix to a readily fitted PEP or PSP object</h2><span id='topic+conforminput'></span>

<h3>Description</h3>

<p>Conform the dimensions of a new input data matrix to a readily fitted PEP or PSP object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conforminput(object, newx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conforminput_+3A_object">object</code></td>
<td>
<p>A readily fitted PSP or PEP object</p>
</td></tr>
<tr><td><code id="conforminput_+3A_newx">newx</code></td>
<td>
<p>A data matrix or a data.frame which to expand</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An expanded data matrix for which the dimensions conform to the regression coefficients in the PSP or PEP
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>

<hr>
<h2 id='cv'>Function that creates customized cross-validation folds</h2><span id='topic+cv'></span>

<h3>Description</h3>

<p>The function creates two matrices and returns them as members of a list. 'train' holds training sample indices, columns are cv-folds and rows are sample indices to hold as training samples in each fold. 'test' holds test/validation sample indices, columns are cv-folds and rows are sample indices to hold as test samples in each fold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(x, fold = 10, strata = rep(1, times = nrow(x)), shuffle = TRUE, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_+3A_x">x</code></td>
<td>
<p>The original data matrix or data.frame</p>
</td></tr>
<tr><td><code id="cv_+3A_fold">fold</code></td>
<td>
<p>Number of desired cross-validation folds; preferably between 3 (3-fold CV) and nrow(x) (LOO-CV)</p>
</td></tr>
<tr><td><code id="cv_+3A_strata">strata</code></td>
<td>
<p>Indicator if some strata should be balanced over the bins; if no balancing is required, the vector should consist of a single value with length equal to rows in x. Otherwise each strata/batch should be indicated as a unique member in the vector.</p>
</td></tr>
<tr><td><code id="cv_+3A_shuffle">shuffle</code></td>
<td>
<p>Whether the indices for the data matrix should be shuffled prior to assigning them to train/test bins</p>
</td></tr>
<tr><td><code id="cv_+3A_seed">seed</code></td>
<td>
<p>A random seed for reproducibility</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(TYKSSIMU)
cvfolds &lt;- cv(x = xMEDISIMU, fold = 3)
cvfolds$train
cvfolds$test
</code></pre>

<hr>
<h2 id='cv.alpha'>Cross-validation runs for risk predition at a single value of alpha</h2><span id='topic+cv.alpha'></span>

<h3>Description</h3>

<p>Run n-fold cross-validation for a chosen prediction metric at a single value of the L1/L2 norm alpha. A suitable lambda sequence is determined by glmnet, and the cross-validation returns a prediction matrix over the folds over various lambda. This function is mostly called by the higher hierarchy functions, such as cv.grid, which allows varying also the alpha-parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.alpha(
  x,
  y,
  folds = 10,
  alpha = 0.5,
  nlamb = 100,
  verb = 0,
  scorefunc,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.alpha_+3A_x">x</code></td>
<td>
<p>The data matrix to use for predictions</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_y">y</code></td>
<td>
<p>The response for coxnet; preferably a preconstructed Surv-object</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_folds">folds</code></td>
<td>
<p>Number of cross-validation folds</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_alpha">alpha</code></td>
<td>
<p>Chosen L1/L2 norm parameter lambda</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_nlamb">nlamb</code></td>
<td>
<p>Number of lambda values</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_verb">verb</code></td>
<td>
<p>Integer indicating level of verbosity, where 0 is silent and 1 provides additional information</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_scorefunc">scorefunc</code></td>
<td>
<p>Chosen scoring function, e.g. score.cindex or score.iAUC</p>
</td></tr>
<tr><td><code id="cv.alpha_+3A_plot">plot</code></td>
<td>
<p>Should a CV-performance curve be plotted as a function of lambda, indicating min/max/mean/median of CV performance over the folds</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of cross-validation scores, where rows correspond to CV folds and columns to various lambda values chosen by glmnet
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TYKSSIMU)
library(survival)
ydat &lt;- Surv(event = yMEDISIMU[,"DEATH"], time = yMEDISIMU[,"LKADT_P"])
set.seed(1)
cvs &lt;- cv.alpha(x = xMEDISIMU, y = ydat, alpha = 0.5, folds = 5, 
	nlamb = 50, verb = 1, scorefunc = score.cindex, plot = TRUE)
cvs
</code></pre>

<hr>
<h2 id='cv.grid'>Cross-validation runs for risk predition for a grid of predetermined alpha values and their conditional lambda values</h2><span id='topic+cv.grid'></span>

<h3>Description</h3>

<p>Expanded Cross-Validation function to run the whole CV in the lambda/alpha grid instead of just lambda-sequence with a pre-specified alpha
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.grid(
  alphaseq = seq(from = 0, to = 1, by = 0.1),
  seed,
  x,
  y,
  folds = 10,
  nlamb = 100,
  verb = 0,
  scorefunc,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.grid_+3A_alphaseq">alphaseq</code></td>
<td>
<p>Sequence of alpha values to test, which should be within [0,1] (with alpha = 0 being ridge regression, 0 &lt; alpha &lt; 1 being elastic net, and alpha = 1 being LASSO)</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_seed">seed</code></td>
<td>
<p>Random number generation seed for reproducibility</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_x">x</code></td>
<td>
<p>Data matrix x</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_y">y</code></td>
<td>
<p>The Surv-object response y</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_folds">folds</code></td>
<td>
<p>Number of folds in the cross-validation</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_nlamb">nlamb</code></td>
<td>
<p>Number of lambda values to test in each alpha; notice that these lambda values vary conditional to alpha</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_verb">verb</code></td>
<td>
<p>Level of verbosity, with 0 as silent and 1 with additional output</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_scorefunc">scorefunc</code></td>
<td>
<p>Chosen scoring function, e.g. score.cindex or score.iAUC</p>
</td></tr>
<tr><td><code id="cv.grid_+3A_plot">plot</code></td>
<td>
<p>Whether a performance should be plotted at each varying alpha-value similar to cv.alpha-plots</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of matrices of cross-validation performance values over the alpha/lambda grid for mean/median/min/max/stdev of the chosen performance metric, with rows indicating various alpha-values and columns indicating lambda-values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TYKSSIMU)
library(survival)
ydat &lt;- Surv(event = yMEDISIMU[,"DEATH"], time = yMEDISIMU[,"LKADT_P"])
cvs &lt;- cv.grid(x = xMEDISIMU, y = ydat, folds = 3, nlamb = 30, alphaseq = seq(0, 1, by=5), 
	scorefunc = score.iAUC, plot = TRUE, seed = 1)
cvs
</code></pre>

<hr>
<h2 id='DREAM'>FIMM-UTU DREAM winning implementation of an ensemble of Penalized Cox Regression models for mCPRC research (ePCR)</h2><span id='topic+DREAM'></span>

<h3>Description</h3>

<p>FIMM-UTU DREAM winning implementation of an ensemble of Penalized Cox Regression models for mCPRC research (ePCR)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ePCRmodels)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>PEP</code> of length 1.
</p>


<h3>Note</h3>

<p>Notice that in order to save space, some slots in the S4 object have been set to null.
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>


<h3>References</h3>

<p>Guinney J, Wang T, Laajala TD, et al. Prediction of overall survival for patients with metastatic castration-resistant prostate cancer: development of a prognostic model through a crowdsourced challenge with open clinical trial data. Lancet Oncol 2017; 18: 132-142.
</p>

<hr>
<h2 id='ePCR'>Ensemble Penalized Cox Regression Modeling for Overall Survival and Time-to-Event Prediction in Advanced Prostate Cancer</h2><span id='topic+ePCR'></span>

<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>


<h3>References</h3>

<p>Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Bioinformatics. 2018 Jun 15. doi: 10.1093/bioinformatics/bty477.
</p>
<p>Guinney J, Wang T, Laajala TD, et al. Prediction of overall survival for patients with metastatic castration-resistant prostate cancer: development of a prognostic model through a crowdsourced challenge with open clinical trial data. Lancet Oncol 2017; 18: 132-142.
</p>
<p>Laajala TD, Guinney J, Costello JC. Community mining of open clinical trial data. Oncotarget 2017; 8: 81721-81722. doi: 10.18632/oncotarget.20853.
</p>

<hr>
<h2 id='heatcv'>Plot a heatmap of the prediction performance statistic as a function of lambda and alpha combinations</h2><span id='topic+heatcv'></span>

<h3>Description</h3>

<p>This function plots a heatmap of cross-validation results by varying the penalization/regularization parameter (lambda, x-axis), together with the corresponding L1/L2 norm parameter alpha (i.e. LASSO, elastic net, ridge regression). The optimal spot in the parameter grid gives insight into the behavior of the regularization in respect to the norms, but note that the lambda-parameter on x-axis is not constant given a conditional alpha-parameter; rather it is a suitable vector chosen by the glmnet-package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>heatcv(
  psp,
  bias = 0.1,
  by.rownames = 1,
  by.colnames = 1,
  paletcol = c("cyan", "blue", "black", "red", "orange"),
  paletncol = 1000,
  xlab = "Alpha-dependent log-Lambda",
  ylab = "Alpha",
  main = "",
  plot.opt = TRUE,
  plot.1sd = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="heatcv_+3A_psp">psp</code></td>
<td>
<p>An S4-class PSP-object to plot, as built using the ePCR-package</p>
</td></tr>
<tr><td><code id="heatcv_+3A_bias">bias</code></td>
<td>
<p>Bias in color palette (skews it to favor distinguishing high values better by default)</p>
</td></tr>
<tr><td><code id="heatcv_+3A_by.rownames">by.rownames</code></td>
<td>
<p>Show every n:th row name (helps for dense axis labels)</p>
</td></tr>
<tr><td><code id="heatcv_+3A_by.colnames">by.colnames</code></td>
<td>
<p>Show every n:th column name (helps for dense axis labels)</p>
</td></tr>
<tr><td><code id="heatcv_+3A_paletcol">paletcol</code></td>
<td>
<p>Names for colours to include in the heatmap palette</p>
</td></tr>
<tr><td><code id="heatcv_+3A_paletncol">paletncol</code></td>
<td>
<p>Number of colours on the color key</p>
</td></tr>
<tr><td><code id="heatcv_+3A_xlab">xlab</code></td>
<td>
<p>Label for the x-axis (typically log-lambda penalization parameter)</p>
</td></tr>
<tr><td><code id="heatcv_+3A_ylab">ylab</code></td>
<td>
<p>Label for the y-axis (typically alpha-value indicating LASSO, elastic net or ridge regression)</p>
</td></tr>
<tr><td><code id="heatcv_+3A_main">main</code></td>
<td>
<p>Main label on top of the heatmap</p>
</td></tr>
<tr><td><code id="heatcv_+3A_plot.opt">plot.opt</code></td>
<td>
<p>Should the best (highest) performance statistic be indicated as a large dot on the heatmap</p>
</td></tr>
<tr><td><code id="heatcv_+3A_plot.1sd">plot.1sd</code></td>
<td>
<p>Should boundaries of the optimal performance statistic area be outlined as within 1 standard deviation of the optimal spot (note: experimental). This attempts to mimic the 1sd-optimum suggested in the glmnet-package for cross-validation for a constant alpha parameter but for 2 dimensions.</p>
</td></tr>
<tr><td><code id="heatcv_+3A_...">...</code></td>
<td>
<p>additional parameters passed on to the hmap-function of hamlet-package</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The heatmap plotting is compatible with the default plot-region in a R graphic canvas. The function hmap from the same author's hmap-package can be highly customized to fit more specific needs.
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ePCRmodels)
par(mfrow=c(1,3))
heatcv(DREAM@PSPs[[1]], main=DREAM@PSPs[[1]]@description, by.rownames=10, by.colnames=10)
heatcv(DREAM@PSPs[[2]], main=DREAM@PSPs[[2]]@description, by.rownames=10, by.colnames=10)
heatcv(DREAM@PSPs[[3]], main=DREAM@PSPs[[3]]@description, by.rownames=10, by.colnames=10)
</code></pre>

<hr>
<h2 id='integrateRegCurve'>Integrate the area over/under the regularization path of a penalized regression model</h2><span id='topic+integrateRegCurve'></span>

<h3>Description</h3>

<p>This function evaluates the overall significance of a regularized regression coefficient in a penalized Cox model. It takes into account the whole range of lambda-penalization parameter, and computes the area over or under the regularization curve. This gives more insight into the importance of a regression coefficient over the whole range of lambda, instead of evaluating it at a single optimal lambda point determined typically using cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integrateRegCurve(fit, weighted = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integrateRegCurve_+3A_fit">fit</code></td>
<td>
<p>A regularized regression model fited using glmnet</p>
</td></tr>
<tr><td><code id="integrateRegCurve_+3A_weighted">weighted</code></td>
<td>
<p>Should the regularization curve be weighted by the corresponding lambda (as higher lambda pushes coefficients to zero)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Integrated area over or under a regularization curve using the trapezoid method from the pracma-package
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Exemplify one PSP of the readily fitted ensembles
data(ePCRmodels)
RegAUC &lt;- cbind(
integrateRegCurve(fit = DREAM@PSPs[[1]]@fit),
integrateRegCurve(fit = DREAM@PSPs[[2]]@fit),
integrateRegCurve(fit = DREAM@PSPs[[3]]@fit)
)
SortRegAUC &lt;- RegAUC[order(apply(RegAUC, MARGIN=1, 
	FUN=function(z) abs(mean(z)) ), decreasing=TRUE),]
colnames(SortRegAUC) &lt;- c(DREAM@PSPs[[1]]@description, 
DREAM@PSPs[[2]]@description,
DREAM@PSPs[[3]]@description)
SortRegAUC[1:10,] # Top 10 coefficients according to (absolute) regularization curve auc
</code></pre>

<hr>
<h2 id='interact.all'>Compute all pairwise interactions between the columns of a data matrix</h2><span id='topic+interact.all'></span>

<h3>Description</h3>

<p>The function multiplies the columns (variables) of a matrix or a data.frame with each other, and produces a new matrix where all pairwise interactions are present. This also includes multiplying a column with its self, thus effectively returning a squared column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interact.all(input)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interact.all_+3A_input">input</code></td>
<td>
<p>A data matrix (of class matrix or data.frame) for which all column-wise multiplications are to be computed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix where columns of the original data matrix have been multiplied, indicating column names coupled with a colon in-between
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
somedata &lt;- data.frame(a = rnorm(10), b = rnorm(10), c = runif(10), d = runif(10))
somedata
allinteract &lt;- interact.all(somedata)
allinteract
</code></pre>

<hr>
<h2 id='interact.part'>Compute a chosen set of pairwise interactions between two sets of columns in a data matrix</h2><span id='topic+interact.part'></span>

<h3>Description</h3>

<p>Similar to interact.all-function, but here user provides two sets of variables, and each pairwise combination between these two sets is multiplied. These pairwise interactions are then returned as a new data matrix, with a colon indicating which variables were multiplied.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>interact.part(input, first, second)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="interact.part_+3A_input">input</code></td>
<td>
<p>The input data matrix, of either class matrix or data.frame</p>
</td></tr>
<tr><td><code id="interact.part_+3A_first">first</code></td>
<td>
<p>The first set of columns to combine with each of the members of the second set, as either integers or column names</p>
</td></tr>
<tr><td><code id="interact.part_+3A_second">second</code></td>
<td>
<p>The second set of columns to combine with each of the members of the first set, as either integers or column names</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data matrix with multiplied columns as indicated using the sets 'first' and 'second'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
somedata &lt;- data.frame(a = rnorm(10), b = rnorm(10), c = runif(10), d = runif(10))
somedata
someinteract &lt;- interact.part(somedata, first = c("a", "b"), second = c("c", "d"))
someinteract
</code></pre>

<hr>
<h2 id='meanrank'>Compute mean of predicted risk ranks for an ePCR ensemble</h2><span id='topic+meanrank'></span>

<h3>Description</h3>

<p>Compute mean of predicted risk ranks for an ePCR ensemble
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meanrank(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meanrank_+3A_x">x</code></td>
<td>
<p>A list or a matrix of risk scores given per each ensemble member (each column or list member is considered an equal member of the ensemble)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An averaged predicted risk rank over all the ensemble members
</p>


<h3>Note</h3>

<p>Extensively called by the 'predict'-function for PEP-objects when risk predictions are performed over the ensemble
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>

<hr>
<h2 id='NelsonAalen'>Cox-Oakes extension of the Nelson-Aalen estimates for a Cox model</h2><span id='topic+NelsonAalen'></span>

<h3>Description</h3>

<p>Implementing the heuristic Cox and Oakes extension of the Nelson-Aalen estimate for Cox model to extract individual-specific survival. Time-to-event predictions are then given at the first time point at which an individual reaches an event probability of 50
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NelsonAalen(
  b,
  Xold,
  Xnew,
  events,
  time,
  tpred = 0:round(max(time, na.rm = T), 0),
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NelsonAalen_+3A_b">b</code></td>
<td>
<p>Beta coefficients at optimal glmnet coxnet model (lambda, alpha)</p>
</td></tr>
<tr><td><code id="NelsonAalen_+3A_xold">Xold</code></td>
<td>
<p>Data matrix with rows as individuals (i.e. training data)</p>
</td></tr>
<tr><td><code id="NelsonAalen_+3A_xnew">Xnew</code></td>
<td>
<p>Possible new prediction data matrix (if omitted the training data is used, or if it is a new dataset the columns should comform to the training data and new individuals be provided as rows)</p>
</td></tr>
<tr><td><code id="NelsonAalen_+3A_events">events</code></td>
<td>
<p>Deaths or right-censoring per each individual (1 death 0 alive censored) for Xold</p>
</td></tr>
<tr><td><code id="NelsonAalen_+3A_time">time</code></td>
<td>
<p>Times to event or censoring for Xold</p>
</td></tr>
<tr><td><code id="NelsonAalen_+3A_tpred">tpred</code></td>
<td>
<p>The predicted time points; more tight grid gives a smoother curve</p>
</td></tr>
<tr><td><code id="NelsonAalen_+3A_plot">plot</code></td>
<td>
<p>Should an individualized plot be plotted to show how the cumulative survival curves behave</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predicted times-to-event predictions either for the training data or an optional provided novel dataset
</p>


<h3>Note</h3>

<p>See section 3.6 at http://data.princeton.edu/pop509/NonParametricSurvival.pdf for the reference
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TYKSSIMU)
library(survival)
xdat &lt;- as.matrix(xMEDISIMU)
ydat &lt;- yMEDISIMU[,"surv"]
</code></pre>

<hr>
<h2 id='normriskrank'>Normalize ensemble risk scores to ranks and then to uniform range</h2><span id='topic+normriskrank'></span>

<h3>Description</h3>

<p>Normalize ensemble risk scores to ranks and then to uniform range
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normriskrank(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normriskrank_+3A_x">x</code></td>
<td>
<p>A list or a matrix of risk scores given per each ensemble member (each column or list member is considered an equal member of the ensemble</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An averaged predicted risk rank over all the ensemble members that has been normalized to the range [0,1] based on: (x - min(x)) / (max(x) - min(x)) -&gt; [0,1]
</p>


<h3>Note</h3>

<p>Normalizes 'predict'-function calls for PEP-objects after calling 'meanrank'-function
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>

<hr>
<h2 id='PEP-class'>Penalized Ensemble Predictor (PEP) S4-class ensemble consisting of individual PSP-members</h2><span id='topic+PEP-class'></span>

<h3>Description</h3>

<p>This class constructs an ensemble of individual Penalized Ensemble Predictor (PSP-class) members. Each member contributes to the model output equally, and ensemble-level functions wrap up individual predictions into an averaged ensemble prediction. The user may define an arbitrary number of PSPs and tailor them to suit the particular needs, and then provide them as a list to the PEP-constructor. As such, constructing well tailored individual ensemble members (of PSP-class) in order to produce a powerful ensemble (of PEP-class) is important on both levels.
</p>


<h3>Slots</h3>


<dl>
<dt><code>PSPs</code></dt><dd><p>List of PSP-objects that will be treated as equal members of the ensemble</p>
</dd>
<dt><code>description</code></dt><dd><p>A character string describing the structure or purpose of the ensemble</p>
</dd>
<dt><code>features</code></dt><dd><p>A character list of variable/feature names</p>
</dd>
<dt><code>dictionary</code></dt><dd><p>A named list of above variables/features and their more precise description</p>
</dd>
<dt><code>predens</code></dt><dd><p>A function for compiling all predictions from the PSPs into consensus prediction</p>
</dd>
<dt><code>prednorm</code></dt><dd><p>A function for normalizing the predictions e.g. to risk scores in [0,1]</p>
</dd>
</dl>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# The PEP-construction is wrapped in NOT RUN, because cross-validating multiple PSPs
# is very time consuming especially if a tight grid of alpha/lambda is to be explored.
# The simulated data from Turku University Hospital (TYKS) is used as an example:
data(TYKSSIMU)

# Two cohorts and corresponding data matrices:
head(xMEDISIMU)
head(xTEXTSIMU)
# Two survival responses:
head(yMEDISIMU)
head(xTEXTSIMU)

# Search L1/L2 norm alpha-grid with 10 values between [0,1]
aseq &lt;- seq(from=0, to=1, by=0.1)
# Lambda sequence penalization is of 100 length conditional for each alpha
nlamb &lt;- 100

library(survival)
# Create three ensemble members; one for MEDI cohort, one for TEXT cohort,
# and finally one member that combines both cohorts simultaneously in a coxnet
psp1 &lt;- new("PSP", x = rbind(xMEDISIMU, xTEXTSIMU), 
y = Surv(rbind(yMEDISIMU, yTEXTSIMU)[,"surv"]),
plot = TRUE, alphaseq = aseq, scorefunc = score.cindex, seed = 1,
folds = 10, nlambda = nlamb)
psp2 &lt;- new("PSP", x = xMEDISIMU, 
y = Surv(yMEDISIMU[,"surv"]),
plot = TRUE, alphaseq = aseq, scorefunc = score.cindex, seed = 1,
folds = 10, nlambda = nlamb)
psp3 &lt;- new("PSP", x = xTEXTSIMU, 
	y = Surv(yTEXTSIMU[,"surv"]),
plot = TRUE, alphaseq = aseq, scorefunc = score.cindex, seed = 1,
folds = 10, nlambda = nlamb)
par(mfrow=c(1,3))
plot(psp1); plot(psp2); plot(psp3); # Inspect the alpha/lambda surfaces

# Create an ensemble of the above 3 members
simuens &lt;- new("PEP", PSPs = list(psp1, psp2, psp3))
simuens
# Ready PEP-object can be used for novel predictions etc


## End(Not run)

# Run example predictions from a previously optimized PEP-model
data(ePCRmodels)
data(TYKSSIMU)

# Perform risk predictions from the joint cohort ensemble member as an example
MEDIpred &lt;- predict(TYKS@PSPs[[1]]@fit, s=TYKS@PSPs[[1]]@optimum["Lambda"], 
newx = conforminput(TYKS@PSPs[[1]], xMEDISIMU))[,1]
TEXTpred &lt;- predict(TYKS@PSPs[[1]]@fit, s=TYKS@PSPs[[1]]@optimum["Lambda"], 
newx = conforminput(TYKS@PSPs[[1]], xTEXTSIMU))[,1]

# Risk scores obtained for the new patients (arbitrary unit as per Cox regression)
head(MEDIpred)
head(TEXTpred)

</code></pre>

<hr>
<h2 id='PEP-methods'>PEP-methods</h2><span id='topic+PEP-methods'></span><span id='topic+print+2CPEP-method'></span><span id='topic+predict+2CPEP-method'></span>

<h3>Description</h3>

<p>PEP-methods
</p>
<p>print.PEP: Print a PEP object to the console
</p>
<p>predict.PEP: Predict for a novel patient from current PEP-ensemble
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'PEP'
print(x, ...)

## S4 method for signature 'PEP'
predict(object, type = "response", newx, x.expand)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PEP-methods_+3A_x">x</code></td>
<td>
<p>Generic x</p>
</td></tr>
<tr><td><code id="PEP-methods_+3A_...">...</code></td>
<td>
<p>Additional custom parameters passed on</p>
</td></tr>
<tr><td><code id="PEP-methods_+3A_object">object</code></td>
<td>
<p>PEP-ensemble model object</p>
</td></tr>
<tr><td><code id="PEP-methods_+3A_type">type</code></td>
<td>
<p>Type of prediction; either &quot;response&quot; or &quot;ensemble&quot;</p>
</td></tr>
<tr><td><code id="PEP-methods_+3A_newx">newx</code></td>
<td>
<p>New data matrix</p>
</td></tr>
<tr><td><code id="PEP-methods_+3A_x.expand">x.expand</code></td>
<td>
<p>A function that may expand (i.e. extract features) from the input data matrix. By default this will be the default x.expand saved in the S4-slot of the first ensemble member. If the user wishes to omit this functionality, setting this parameter to 'x.expand = as.matrix' does not expand the input data matrix. Notice that if the user has manually called the 'conforminput' function for the newx-data, it is no longer necessary to expand the data matrix here.</p>
</td></tr>
</table>

<hr>
<h2 id='PSP-class'>Penalized Single Predictor (PSP) S4-class as a member of PEP-ensembles</h2><span id='topic+PSP-class'></span>

<h3>Description</h3>

<p>PSP is a single penalized Cox regression model, where an alpha/lambda grid has been optimized using cross-validation and a chosen prediction metric. PSPs are single entities that will compile together into PEPs, the ensemble objects that will average over multiple PSPs to generate an ensemble prediction. Typically a single PSP models a part of the data, such as a cohort strata.
</p>


<h3>Slots</h3>


<dl>
<dt><code>description</code></dt><dd><p>A general user-provided string describing the PSP</p>
</dd>
<dt><code>features</code></dt><dd><p>A character vector indicating feature names</p>
</dd>
<dt><code>strata</code></dt><dd><p>Information whether data matrix x included substrata (will be used in plotting functions etc)</p>
</dd>
<dt><code>alphaseq</code></dt><dd><p>The sequence of alpha values to test, ranging between [0,1]; alpha = 0 being ridge regression, 0 &lt; alpha &lt; 1 being elastic net and alpha = 1 being LASSO</p>
</dd>
<dt><code>cvfolds</code></dt><dd><p>The number of cross-validation folds to utilize; by default 10</p>
</dd>
<dt><code>nlambda</code></dt><dd><p>The amount of lambda values utilized in each regularization path; by default 100 as in glmnet-package</p>
</dd>
<dt><code>cvmean</code></dt><dd><p>A matrix indicating the mean CV performance in alpha/lambda grid (preferred over median)</p>
</dd>
<dt><code>cvmedian</code></dt><dd><p>A matrix indicating the median CV performance in alpha/lambda grid</p>
</dd>
<dt><code>cvstdev</code></dt><dd><p>A matrix indicating the standard deviation in CV performance over the folds in the alpha/lambda grid</p>
</dd>
<dt><code>cvmin</code></dt><dd><p>A matrix indicating minimum CV performance in alpha/lambda grid</p>
</dd>
<dt><code>cvmax</code></dt><dd><p>A matrix indicating maximum CV performance in alpha/lambda grid</p>
</dd>
<dt><code>score</code></dt><dd><p>The scoring function, user-defined or one provided by ePCR package such as score.cindex or score.iAUC</p>
</dd>
<dt><code>cvrepeat</code></dt><dd><p>Number of cross-validation procedures to run multiple times and then average over, in order to reduce the effect of binning samples</p>
</dd>
<dt><code>impute</code></dt><dd><p>The imputation function used if provided matrix 'x' includes missing values; by default the impute.knn-function from BioConductor package 'impute'</p>
</dd>
<dt><code>optimum</code></dt><dd><p>The optimum in alpha/lambda grid, with optimal alpha and similarly for lambda</p>
</dd>
<dt><code>seed</code></dt><dd><p>The initial random seed used for cross-validation</p>
</dd>
<dt><code>x</code></dt><dd><p>The input data matrix</p>
</dd>
<dt><code>x.expand</code></dt><dd><p>A function that allows expansion of matrix 'x' to include interactions between variables; if no such are desired, this should be an identity function</p>
</dd>
<dt><code>y</code></dt><dd><p>The Surv-object as in survival-package, which serves as the response y</p>
</dd>
<dt><code>fit</code></dt><dd><p>The glmnet coxnet-object obtained with optimal alpha</p>
</dd>
<dt><code>criterion</code></dt><dd><p>The optimizing criterion; by default &quot;min&quot; for minimizing CV-error</p>
</dd>
<dt><code>dictionary</code></dt><dd><p>A list of discriptions for each variable</p>
</dd>
<dt><code>regAUC</code></dt><dd><p>A numeric vector for the AUC under regularization curve as computed by integrateRegCurve-function</p>
</dd>
</dl>


<h3>Examples</h3>

<pre><code class='language-R'># As an example, illustrate a naive PSP built on the small medication cohort
data(TYKSSIMU)
library(survival)
# Minimal example with much fewer patients and variables
psp_ex &lt;- new("PSP", alphaseq=c(0.2, 0.8), nlambda=20, folds=3,
	x = xMEDISIMU[1:80,c(1:20,40:50)], y = yMEDISIMU[1:80,"surv"],
seeds = 1, score=score.cindex)

plot(psp_ex) # Optimization surface of alpha/lambda

# Illustrate the use of some PSP-methods:
PSP.KM(psp_ex, cutoff = 0.5) # Kaplan-Meier
PSP.PCA(psp_ex) # PCA plot of training data
PSP.BOX(psp_ex) # Boxplots, here for the first training variable
PSP.CSP(psp_ex) # Cumulative survival probabilities for the training data
invisible(PSP.NA(psp_ex)) # Time-to-event Nelson-Aalen heuristic algorithm

## Not run: 
# Computationally intensive novel PSP-fitting is omitted from the test runs
# Functions for readily fitted PSP-objects are illustrated above
data(TYKSSIMU)
library(survival)
psp_meditext &lt;- new("PSP", x = rbind(xMEDISIMU, xTEXTSIMU), 
y = Surv(rbind(yMEDISIMU, yTEXTSIMU)[,"surv"]),
plot = TRUE, alphaseq = seq(0, 1, by=.01), scorefunc = score.cindex, 
seed = 1, folds = 10, nlambda = 100)
plot(psp_meditext)

## End(Not run)
</code></pre>

<hr>
<h2 id='PSP-methods'>PSP-methods</h2><span id='topic+PSP-methods'></span><span id='topic+print+2CPSP-method'></span><span id='topic+plot'></span><span id='topic+plot+2CPSP-method'></span><span id='topic+plot+2CPSP+2CANY-method'></span><span id='topic+coef+2CPSP-method'></span><span id='topic+predict+2CPSP-method'></span><span id='topic+PSP.KM'></span><span id='topic+PSP.KM+2CPSP-method'></span><span id='topic+PSP.KM+2CPSP+2CANY-method'></span><span id='topic+PSP.PCA'></span><span id='topic+PSP.PCA+2CPSP-method'></span><span id='topic+PSP.PCA+2CPSP+2CANY-method'></span><span id='topic+PSP.BOX'></span><span id='topic+PSP.BOX+2CPSP-method'></span><span id='topic+PSP.BOX+2CPSP+2CANY-method'></span><span id='topic+PSP.CSP'></span><span id='topic+PSP.CSP+2CPSP-method'></span><span id='topic+PSP.CSP+2CPSP+2CANY-method'></span><span id='topic+PSP.NA'></span><span id='topic+PSP.NA+2CPSP-method'></span><span id='topic+PSP.NA+2CPSP+2CANY-method'></span>

<h3>Description</h3>

<p>PSP-methods
</p>
<p>print.PSP: Print general information of PSPs contents to the terminal
</p>
<p>plot.PSP: By default the mean CV surface in terms of alpha/lambda is plotted using hamlet-package's hmap-function
</p>
<p>coef.PSP: Default PSP coef-function extracts only the optimum parameters, not whole lambda-range
</p>
<p>predict.PSP: Predict for a novel patient from current PSP
</p>
<p>PSP.KM: Kaplan-Meier with division at a given cutoff point within [0,1]
</p>
<p>PSP.PCA: Principal Component Plot of a single PSP, showing 2 principal axes with a colouring if strata have been indicated; newx can also be plotted in relation to fitting data
</p>
<p>PSP.BOX: Boxplot of a single variable in a PSP in respect to strata, for outlier detection and observing variable distributions
</p>
<p>PSP.CSP: Cumulative survival probabilities
</p>
<p>PSP.NA: Nelson-Aalen with time-to-event prediction at point t = F^-1(0.5)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'PSP'
print(x, ...)

plot(x, y, ...)

## S4 method for signature 'PSP'
plot(x, y, bias = 0.1, ...)

## S4 method for signature 'PSP'
coef(object)

## S4 method for signature 'PSP'
predict(object, type = "response", newx, verb = 0)

PSP.KM(object, ...)

## S4 method for signature 'PSP'
PSP.KM(object, cutoff = 0.5)

PSP.PCA(object, ...)

## S4 method for signature 'PSP'
PSP.PCA(
  object,
  newx,
  expanded = TRUE,
  type = "all",
  shuffle = TRUE,
  z = TRUE,
  cex = 1,
  col = c("aquamarine", "coral", "royalblue", "black"),
  pch = 16
)

PSP.BOX(object, ...)

## S4 method for signature 'PSP'
PSP.BOX(object, newx, var = colnames(object@x)[1], expanded = FALSE)

PSP.CSP(object, ...)

## S4 method for signature 'PSP'
PSP.CSP(object, newx, t = seq(from = 1, to = 36 * 30.5, by = 1), plot = FALSE)

PSP.NA(object, ...)

## S4 method for signature 'PSP'
PSP.NA(object, newx, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PSP-methods_+3A_x">x</code></td>
<td>
<p>Generic x</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_...">...</code></td>
<td>
<p>Additional custom parameters passed on</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_y">y</code></td>
<td>
<p>Generic y</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_bias">bias</code></td>
<td>
<p>Bias for skewing the color in heatmap key plotting</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_object">object</code></td>
<td>
<p>PSP-object</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_type">type</code></td>
<td>
<p>Types of variables to include; recognizes (int)eger, (bin)ary and (num)eric</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_newx">newx</code></td>
<td>
<p>New data matrix</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_verb">verb</code></td>
<td>
<p>Level of verbosity</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_cutoff">cutoff</code></td>
<td>
<p>Cutoff point for division</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_expanded">expanded</code></td>
<td>
<p>Should data matrix expansion through interactions be included</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_shuffle">shuffle</code></td>
<td>
<p>Shuffle plotting order</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_z">z</code></td>
<td>
<p>Should data centering and scaling should be conducted</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_cex">cex</code></td>
<td>
<p>Zooming multiplier</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_col">col</code></td>
<td>
<p>Vector of color numbers or names to use for strata</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_pch">pch</code></td>
<td>
<p>Point type to use (refer to par-function pch-parameter)</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_var">var</code></td>
<td>
<p>Name of variable to plot</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_t">t</code></td>
<td>
<p>Sequence of time points to evaluate cumulative survival probabilities at</p>
</td></tr>
<tr><td><code id="PSP-methods_+3A_plot">plot</code></td>
<td>
<p>Plot the corresponding functionality</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Please refer to the PSP-class examples for applying these PSP-methods
</p>

<hr>
<h2 id='score.cindex'>Scoring function for evaluating survival prediction through concordance index (c-index)</h2><span id='topic+score.cindex'></span>

<h3>Description</h3>

<p>C-index (Concordance index) of the predicted vs. true answer, i.e. proportion of pairs that go in correct direction over all pairwise comparisons
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score.cindex(pred, time, event, real)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.cindex_+3A_pred">pred</code></td>
<td>
<p>Numeric risk score for each event</p>
</td></tr>
<tr><td><code id="score.cindex_+3A_time">time</code></td>
<td>
<p>A vector of event or censoring times</p>
</td></tr>
<tr><td><code id="score.cindex_+3A_event">event</code></td>
<td>
<p>A binary valued vector that indicates either death (1) or right-censoring (0)</p>
</td></tr>
<tr><td><code id="score.cindex_+3A_real">real</code></td>
<td>
<p>A previously constructed Surv-object instead of providing time and event</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Corcordance index (c-index) of the prediction
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A random prediction ought to be near 0.5
# c-index is not sensitive to time scale, as it tests pairwise prediction accuracy
set.seed(1); prediction &lt;- sample(1:20)
time &lt;- seq(from=1000, to=50, by=-50)
event &lt;- c(0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1)
library(survival)
score.cindex(pred = prediction, real = Surv(time=time, event=event))
</code></pre>

<hr>
<h2 id='score.iAUC'>Scoring function for evaluating survival prediction by time-wise integrated AUC</h2><span id='topic+score.iAUC'></span>

<h3>Description</h3>

<p>Time-wise integrated prediction for survival is performed by this scoring function using the timeROC-package. 
It's offered as an alternative to the score.cindex-function with the difference that time-wise integrated AUC is sensitive to the choice of time-window. 
By default (as similar to DREAM 9.5 mCRPC challenge), the AUCs are determined at 6 to 30 months, and the AUC is then normalized to a score within [0,1]. Notice that for studies shorter or longer than this proposed time window, the scoring function should be adjusted accordingly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>score.iAUC(pred, time, event, real, times = seq(6, 30, by = 1) * 30.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="score.iAUC_+3A_pred">pred</code></td>
<td>
<p>Numeric risk score for each event</p>
</td></tr>
<tr><td><code id="score.iAUC_+3A_time">time</code></td>
<td>
<p>A vector of event or censoring times</p>
</td></tr>
<tr><td><code id="score.iAUC_+3A_event">event</code></td>
<td>
<p>A binary valued vector that indicates either death (1) or right-censoring (0)</p>
</td></tr>
<tr><td><code id="score.iAUC_+3A_real">real</code></td>
<td>
<p>A previously constructed Surv-object instead of providing time and event</p>
</td></tr>
<tr><td><code id="score.iAUC_+3A_times">times</code></td>
<td>
<p>Time-points at which to evaluate the iAUC</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The integrated area under the ROC-curve over time
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A random prediction ought to be near 0.5 
# iAUC is sensitive to the choice of time points to test AUC at
set.seed(1); prediction &lt;- sample(1:20)
time &lt;- seq(from=1000, to=50, by=-50)
event &lt;- c(0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1)
library(survival)
score.iAUC(pred = prediction, real = Surv(time=time, event=event))
</code></pre>

<hr>
<h2 id='TimeSurvProb'>Predict cumulative survival probabilities for new data at given time points</h2><span id='topic+TimeSurvProb'></span>

<h3>Description</h3>

<p>Given a readily fitted regularized Cox regression model, this function predicts the cumulative survival probabilities for new data at time points determined by the user. The function uses c060-package's functionality for computing base hazard, and then performs linear predictions for new observations using the fitted regularized Cox regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TimeSurvProb(
  fit,
  time,
  event,
  olddata,
  newdata,
  s,
  times = c(1:36) * 30.5,
  plot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TimeSurvProb_+3A_fit">fit</code></td>
<td>
<p>A single regularized Cox regression model fitted using glmnet</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_time">time</code></td>
<td>
<p>Time to events for the training data</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_event">event</code></td>
<td>
<p>Event indicators for the training data (0 censored, 1 event)</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_olddata">olddata</code></td>
<td>
<p>The old data matrix used to fit the original 'fit' glmnet-object</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_newdata">newdata</code></td>
<td>
<p>The new data matrix for which to predict time-to-event prediction (should comform to the old data matrix)</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_s">s</code></td>
<td>
<p>The optimal lambda parameter as used in the glmnet-package for its fit objects</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_times">times</code></td>
<td>
<p>The time points at which to estimate the cumulative survival probabilities (by default in days)</p>
</td></tr>
<tr><td><code id="TimeSurvProb_+3A_plot">plot</code></td>
<td>
<p>Should the cumulative survival probabilities be plotted as a function of time</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Cumulative survival probabilities at the chosen time points
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>

<hr>
<h2 id='TYKS'>ePCR model fitted to the Turku University Hospital cohorts (all features)</h2><span id='topic+TYKS'></span>

<h3>Description</h3>

<p>ePCR model fitted to the Turku University Hospital cohorts (all features)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ePCRmodels)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>PEP</code> of length 1.
</p>


<h3>Note</h3>

<p>Notice that in order to save space, some slots in the S4 object have been set to null.
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>


<h3>References</h3>

<p>Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Bioinformatics. 2018 Jun 15. doi: 10.1093/bioinformatics/bty477.
</p>

<hr>
<h2 id='TYKS_reduced'>ePCR model fitted to the Turku University Hospital cohorts (features derived from text mining only)</h2><span id='topic+TYKS_reduced'></span>

<h3>Description</h3>

<p>ePCR model fitted to the Turku University Hospital cohorts (features derived from text mining only)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ePCRmodels)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>PEP</code> of length 1.
</p>


<h3>Note</h3>

<p>Notice that in order to save space, some slots in the S4 object have been set to null.
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>
</p>


<h3>References</h3>

<p>Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Bioinformatics. 2018 Jun 15. doi: 10.1093/bioinformatics/bty477.
</p>

<hr>
<h2 id='TYKSSIMU'>TYKSSIMU - simulated data matrices and survival responses from Turku University Hospital</h2><span id='topic+TYKSSIMU'></span><span id='topic+xMEDISIMU'></span><span id='topic+xTEXTSIMU'></span><span id='topic+yMEDISIMU'></span><span id='topic+yTEXTSIMU'></span>

<h3>Description</h3>

<p>TYKSSIMU - simulated data matrices and survival responses from Turku University Hospital
</p>
<p>xMEDISIMU: Simulated prostate cancer data from Turku University Hospital (data matrix x, Medication-cohort)
</p>
<p>xTEXTSIMU: Simulated prostate cancer data from Turku University Hospital (data matrix x, Text-cohort)
</p>
<p>yMEDISIMU: Simulated prostate cancer data from Turku University Hospital (survival response y, Medication-cohort)
</p>
<p>yTEXTSIMU: Simulated prostate cancer data from Turku University Hospital (survival response y, Text-cohort)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(TYKSSIMU)

xMEDISIMU

xTEXTSIMU

yMEDISIMU

yTEXTSIMU
</code></pre>


<h3>Format</h3>

<p>xTEXTSIMU:
</p>
<p>xMEDISIMU:
</p>
<p>yTEXTSIMU:
</p>
<p>yMEDISIMU:
</p>
<p>An object of class <code>data.frame</code> with 150 rows and 101 columns.
</p>
<p>An object of class <code>data.frame</code> with 500 rows and 101 columns.
</p>
<p>An object of class <code>data.frame</code> with 150 rows and 3 columns.
</p>
<p>An object of class <code>data.frame</code> with 500 rows and 3 columns.
</p>


<h3>Author(s)</h3>

<p>Teemu Daniel Laajala <a href="mailto:teelaa@utu.fi">teelaa@utu.fi</a>, Mika Murtojärvi <a href="mailto:mianmu2@hotmail.com">mianmu2@hotmail.com</a>
</p>


<h3>References</h3>

<p>Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Laajala TD, Murtojärvi M, Virkki A, Aittokallio T. ePCR: an R-package for survival and time-to-event prediction in advanced prostate cancer, applied to a real-world patient cohort. Bioinformatics. 2018 Jun 15. doi: 10.1093/bioinformatics/bty477.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(TYKSSIMU)
head(xTEXTSIMU)
head(xMEDISIMU)
head(yTEXTSIMU)
head(yMEDISIMU)
dim(xTEXTSIMU)
dim(xMEDISIMU)
</code></pre>

<hr>
<h2 id='zt'>Extended function for z-transformation, filling non-finite values and changes column names at will</h2><span id='topic+zt'></span>

<h3>Description</h3>

<p>An extended function of the standard z-score standardization of a vector in R (i.e. function 'scale'). Supports filling in non-finite values as well as re-naming variables to distinguish them from non-standardized variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zt(x, fillfinite = 0, addz = T, saveattr = T)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zt_+3A_x">x</code></td>
<td>
<p>A data matrix for which the columns are to be standardized</p>
</td></tr>
<tr><td><code id="zt_+3A_fillfinite">fillfinite</code></td>
<td>
<p>The value to fill non-finite values with, by default zero.</p>
</td></tr>
<tr><td><code id="zt_+3A_addz">addz</code></td>
<td>
<p>Boolean indicating whether letter 'z' should be appended to the variable names to indicate the standardization</p>
</td></tr>
<tr><td><code id="zt_+3A_saveattr">saveattr</code></td>
<td>
<p>Boolean for if an 'attr' should be attached to the standardized vector, similar to how the R default function 'scale' conserves the centering and scaling values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>z-score standardized values (zero mean and unit variation), with non-finite values imputed by zero by default.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>somedata &lt;- cbind(rnorm(100), runif(100))
normdata &lt;- zt(somedata)
head(normdata)
apply(normdata, MARGIN=2, FUN=mean)
apply(normdata, MARGIN=2, FUN=sd)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
