<!DOCTYPE html><html><head><title>Help for package wikiTools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {wikiTools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cc'><p>Converts a text separated by commas into a character vector.</p></a></li>
<li><a href='#checkTitles'><p>checkTitles(titles)</p>
Check if titles are valid. Return TRUE is all titles are valid, else FALSE.
See:See https://en.wikipedia.org/wiki/Wikipedia:Page_name#Technical_restrictions_and_limitations</a></li>
<li><a href='#extractWiki'><p>Extract the first paragraph of a Wikipedia article with a maximum of characters.</p></a></li>
<li><a href='#filext'><p>Extract the extension of a file</p></a></li>
<li><a href='#getFiles'><p>Downloads a list of files in a specified path of the computer, and return a vector of the no-found names (if any).</p></a></li>
<li><a href='#getWikiData'><p>Create a data.frame with Wikidata of a vector of names.</p></a></li>
<li><a href='#getWikiFiles'><p>Downloads a list of Wikipedia pages in a specified path of the computer, and return a vector of the no-found names (if any).</p></a></li>
<li><a href='#getWikiInf'><p>Create a data.frame with Q's and descriptions of a vector of names.</p></a></li>
<li><a href='#httrGetJSON'><p>httrGetJSON</p>
Retrieve responses in JSON format using httr::GET. It is a generic function
to use for request these Wikimedia metrics API:
https://wikimedia.org/api/rest_v1/
https://www.mediawiki.org/wiki/XTools/API/Page (xtools.wmflabs.org)</a></li>
<li><a href='#limitRequester'><p>Limits the rate at which a function will execute</p></a></li>
<li><a href='#m_Opensearch'><p>Open search of a string</p></a></li>
<li><a href='#m_Pageviews'><p>Get number of views of a Wikipedia article</p></a></li>
<li><a href='#m_reqMediaWiki'><p>Retrieve responses using the MediaWiki API.</p></a></li>
<li><a href='#m_XtoolsInfo'><p>Gets various information from a Wikimedia page</p></a></li>
<li><a href='#nametoWikiFrame'><p>Convert names into a Wikipedia's iframe</p></a></li>
<li><a href='#nametoWikiHtml'><p>Create the Wikipedia link of a name or entry.</p></a></li>
<li><a href='#nametoWikiURL'><p>Create the Wikipedia URL of a name or entry.</p></a></li>
<li><a href='#normalizedTitle'><p>normalizedTitle(title, q)</p>
Return de normalized or redirect title (also normalized) from the query part
of the JSON response of a MediaWiki search that uses titles.</a></li>
<li><a href='#preName'><p>Reverse the order of the first and last names of every element of a vector.</p></a></li>
<li><a href='#reqMediaWiki'><p>Uses httr package to retrieve responses using the MediaWiki API.</p></a></li>
<li><a href='#reqWDQS'><p>Get responses from Wikidata Query Service</p></a></li>
<li><a href='#searchWiki'><p>Find if there is a Wikipedia page of a name(s) in the selected language.</p></a></li>
<li><a href='#urltoFrame'><p>Convert an URL link to an HTML iframe.</p></a></li>
<li><a href='#urltoHtml'><p>Convert a Wikipedia URL to an HTML link</p></a></li>
<li><a href='#user_agent'><p>See https://meta.wikimedia.org/wiki/User-Agent_policy.</p></a></li>
<li><a href='#v_AutoSuggest'><p>Suggests VIAF id from a name</p></a></li>
<li><a href='#v_Extract'><p>Gets information from a VIAF record</p></a></li>
<li><a href='#v_GetRecord'><p>Gets record clusters</p></a></li>
<li><a href='#v_Search'><p>Run a CQL Query in VIAF</p></a></li>
<li><a href='#validUrl'><p>Find if an URL link is valid.</p></a></li>
<li><a href='#w_EntityInfo'><p>Get some personal properties of one Wikidata entity</p></a></li>
<li><a href='#w_IdentifiersOfAuthority'><p>Search for Wikidata entities that have a property identifier</p></a></li>
<li><a href='#w_isInstanceOf'><p>Check if a Wikidata entity is an instance of a class</p></a></li>
<li><a href='#w_isValid'><p>Check if a Wikidata entity is valid</p></a></li>
<li><a href='#w_OccupationEntities'><p>Gets Wikidata entities with a certain occupation</p></a></li>
<li><a href='#w_Property'><p>Searching for properties of the entity list</p></a></li>
<li><a href='#w_query'><p>Responses from Wikidata Query Service</p></a></li>
<li><a href='#w_SearchByLabel'><p>Search Wikidata entities</p></a></li>
<li><a href='#w_Wikipedias'><p>Gets Wikipedia pages from a Q list.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-04-12</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Wikidata and Wikipedia</td>
</tr>
<tr>
<td>Description:</td>
<td>A set of wrappers intended to check, read and download information from the Wikimedia sources. It is specifically created to work with names of celebrities, in which case their information and statistics can be downloaded. Additionally, it also builds links and snippets to use in combination with the function gallery() in netCoin package.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>httr, jsonlite, ratelimitr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Modesto Escobar &lt;modesto@usal.es&gt;</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-13 11:11:12 UTC; Modesto</td>
</tr>
<tr>
<td>Author:</td>
<td>Modesto Escobar <a href="https://orcid.org/0000-0003-2072-6071"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cph, cre],
  √Ångel Zazo [aut],
  Carlos Prieto <a href="https://orcid.org/0000-0001-8178-9768"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  David Barrios [aut],
  Cristina Calvo [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-13 11:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cc'>Converts a text separated by commas into a character vector.</h2><span id='topic+cc'></span>

<h3>Description</h3>

<p>Converts a text separated by commas into a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cc(text, sep = ",")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cc_+3A_text">text</code></td>
<td>
<p>Text to be separated.</p>
</td></tr>
<tr><td><code id="cc_+3A_sep">sep</code></td>
<td>
<p>A character of separation. It must be a blank. If it is another character, trailing blanks are suppressed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns inside the text are omitted.
</p>


<h3>Value</h3>

<p>A vector of the split segments of the text.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## A text with three names separated with commas is converted into a vector of length 3.
cc("Pedro Almodovar, Diego Velazquez, Salvador Dali")
</code></pre>

<hr>
<h2 id='checkTitles'>checkTitles(titles)
Check if titles are valid. Return TRUE is all titles are valid, else FALSE.
See:See https://en.wikipedia.org/wiki/Wikipedia:Page_name#Technical_restrictions_and_limitations</h2><span id='topic+checkTitles'></span>

<h3>Description</h3>

<p>checkTitles(titles)
Check if titles are valid. Return TRUE is all titles are valid, else FALSE.
See:See https://en.wikipedia.org/wiki/Wikipedia:Page_name#Technical_restrictions_and_limitations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkTitles(titles)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkTitles_+3A_titles">titles</code></td>
<td>
<p>A vector of titles to check.</p>
</td></tr>
</table>

<hr>
<h2 id='extractWiki'>Extract the first paragraph of a Wikipedia article with a maximum of characters.</h2><span id='topic+extractWiki'></span>

<h3>Description</h3>

<p>Extract the first paragraph of a Wikipedia article with a maximum of characters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractWiki(
  names,
  language = c("en", "es", "fr", "de", "it"),
  plain = FALSE,
  maximum = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractWiki_+3A_names">names</code></td>
<td>
<p>A vector of names, whose entries have to be extracted.</p>
</td></tr>
<tr><td><code id="extractWiki_+3A_language">language</code></td>
<td>
<p>A vector of Wikipedia's languages to look for. If the article is not found in the language of the first element, it search for the followings,.</p>
</td></tr>
<tr><td><code id="extractWiki_+3A_plain">plain</code></td>
<td>
<p>If TRUE, the results are delivered in plain format.</p>
</td></tr>
<tr><td><code id="extractWiki_+3A_maximum">maximum</code></td>
<td>
<p>Number maximum of characters to be included when the paragraph is too large.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a character vector with html formatted (or plain text) Wikipedia paragraphs.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtaining information in English Wikidata
names &lt;- c("William Shakespeare", "Pedro Almodovar")
info &lt;- getWikiInf(names)
info$text &lt;- extractWiki(info$label)
</code></pre>

<hr>
<h2 id='filext'>Extract the extension of a file</h2><span id='topic+filext'></span>

<h3>Description</h3>

<p>Extract the extension of a file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filext(fn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filext_+3A_fn">fn</code></td>
<td>
<p>Character vector with the files whose extensions are to be extracted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extracts the extension of a vector of file names.
</p>


<h3>Value</h3>

<p>A character vector of extension names.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## For a single item:
filext("Albert Einstein.jpg")
## You can do the same for a vector:
filext(c("Hillary Duff.png", "Britney Spears.jpg", "Avril Lavigne.tiff"))
</code></pre>

<hr>
<h2 id='getFiles'>Downloads a list of files in a specified path of the computer, and return a vector of the no-found names (if any).</h2><span id='topic+getFiles'></span>

<h3>Description</h3>

<p>Downloads a list of files in a specified path of the computer, and return a vector of the no-found names (if any).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getFiles(lista, path = "./", ext = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getFiles_+3A_lista">lista</code></td>
<td>
<p>A list or data frame of files' URLs to be download (See details).</p>
</td></tr>
<tr><td><code id="getFiles_+3A_path">path</code></td>
<td>
<p>Directory where to export the files.</p>
</td></tr>
<tr><td><code id="getFiles_+3A_ext">ext</code></td>
<td>
<p>Select desired extension of the files. Default= NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows download a file of files directly into your directory.
This function needs a preexistent data frame of names and pictures' URL. It must be a list (or data.frame) with two values: &quot;name&quot; (specifying the names of the files) and &quot;url&quot; (containing the urls to the files to download)..
All the errors are reported as outcomes (NULL= no errors). The files are donwload into your chosen directory.
</p>


<h3>Value</h3>

<p>It returns a vector of errors, if any. All pictures are download into the selected directory (NULL= no errors).
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## In case you want to download a file directly from an URL:

# dta &lt;- data.frame(name = "Data", url = "https://sociocav.usal.es/me/Stata/example.dta")
# getFiles(dta, path = "./")

##  You can can also combine this function with getWikiData (among others).
## In case you want to download a picture of a person:

# A &lt;- data.frame(name= getWikiData("Rembrandt")$label, url=getWikiData("Rembrandt")$pics)
# getFiles(A, path = "./", ext = "png")

## Or the pics of multiple authors: 

# B &lt;- getWikiData(c("Monet", "Renoir", "Caillebotte"))
# data &lt;- data.frame(name = B$label, url = B$pics)
# getFiles(data, path = "./", ext = NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='getWikiData'>Create a data.frame with Wikidata of a vector of names.</h2><span id='topic+getWikiData'></span>

<h3>Description</h3>

<p>Create a data.frame with Wikidata of a vector of names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWikiData(names, language = "en", csv = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getWikiData_+3A_names">names</code></td>
<td>
<p>A vector consisting of one or more Wikidata's entry (i.e., topic or person).</p>
</td></tr>
<tr><td><code id="getWikiData_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code (default = &quot;en&quot;).</p>
</td></tr>
<tr><td><code id="getWikiData_+3A_csv">csv</code></td>
<td>
<p>A file name to save the results, in which case the only return is a message with the name of the saved file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with personal information of the names or a csv file with the information separated by semicolons.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtaining information in English Wikidata
## Not run: 
names &lt;- c("William Shakespeare", "Pedro Almodovar")
info &lt;- getWikiData(names)
## Obtaining information in Spanish Wikidata
d &lt;- getWikiData(names, language="es")

## End(Not run)
</code></pre>

<hr>
<h2 id='getWikiFiles'>Downloads a list of Wikipedia pages in a specified path of the computer, and return a vector of the no-found names (if any).</h2><span id='topic+getWikiFiles'></span>

<h3>Description</h3>

<p>Downloads a list of Wikipedia pages in a specified path of the computer, and return a vector of the no-found names (if any).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWikiFiles(X, language = c("es", "en", "fr"), directory = "./", maxtime = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getWikiFiles_+3A_x">X</code></td>
<td>
<p>A vector of Wikipedia's entry).</p>
</td></tr>
<tr><td><code id="getWikiFiles_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code (default = &quot;en&quot;).</p>
</td></tr>
<tr><td><code id="getWikiFiles_+3A_directory">directory</code></td>
<td>
<p>Directory where to export the files to.</p>
</td></tr>
<tr><td><code id="getWikiFiles_+3A_maxtime">maxtime</code></td>
<td>
<p>In case you want to apply a random waiting between consecutive searches.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows download a set of Wikipedia pages into a directory of the local computer.
All the errors (not found pages) are reported as outcomes (NULL= no errors). The files are donwload into your chosen directory.
</p>


<h3>Value</h3>

<p>It returns a vector of errors, if any. All pictures are download into the selected directory (NULL= no errors).
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## In case you want to download the Wikipage of a person:

# getWikiFiles("Rembrandt", dir = "./")

## Or the pics of multiple authors: 

# B &lt;- c("Monet", "Renoir", "Caillebotte")
# getWikiFiles(B, dir = "./", language="fr")

## End(Not run)
</code></pre>

<hr>
<h2 id='getWikiInf'>Create a data.frame with Q's and descriptions of a vector of names.</h2><span id='topic+getWikiInf'></span>

<h3>Description</h3>

<p>Create a data.frame with Q's and descriptions of a vector of names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getWikiInf(names, number = 1, language = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getWikiInf_+3A_names">names</code></td>
<td>
<p>A vector consisting of one or more Wikidata's entry (i.e., topic or person).</p>
</td></tr>
<tr><td><code id="getWikiInf_+3A_number">number</code></td>
<td>
<p>Take the number occurrence in case there are several equal names in Wikidata.</p>
</td></tr>
<tr><td><code id="getWikiInf_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code (default = &quot;en&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with name, Q, label and description of the names.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Obtaining information in English Wikidata
names &lt;- c("William Shakespeare", "Pedro Almodovar")
information &lt;- getWikiInf(names)

## Obtaining information in Spanish Wikidata
## Not run: 
informacion &lt;- getWikiInf(names, language="es")

## End(Not run)
</code></pre>

<hr>
<h2 id='httrGetJSON'>httrGetJSON
Retrieve responses in JSON format using httr::GET. It is a generic function
to use for request these Wikimedia metrics API:
https://wikimedia.org/api/rest_v1/
https://www.mediawiki.org/wiki/XTools/API/Page (xtools.wmflabs.org)</h2><span id='topic+httrGetJSON'></span>

<h3>Description</h3>

<p>httrGetJSON
Retrieve responses in JSON format using httr::GET. It is a generic function
to use for request these Wikimedia metrics API:
https://wikimedia.org/api/rest_v1/
https://www.mediawiki.org/wiki/XTools/API/Page (xtools.wmflabs.org)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>httrGetJSON(url)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="httrGetJSON_+3A_url">url</code></td>
<td>
<p>The URL with the query to the API.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A JSON response. Please check httr::stop_for_status(response)
</p>


<h3>Note</h3>

<p>Used in m_Pageviews
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>

<hr>
<h2 id='limitRequester'>Limits the rate at which a function will execute</h2><span id='topic+limitRequester'></span>

<h3>Description</h3>

<p>Limits the rate at which a function will execute
</p>


<h3>Usage</h3>

<pre><code class='language-R'>limitRequester(f, n, period)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="limitRequester_+3A_f">f</code></td>
<td>
<p>The original function</p>
</td></tr>
<tr><td><code id="limitRequester_+3A_n">n</code></td>
<td>
<p>Number of allowed events within a period</p>
</td></tr>
<tr><td><code id="limitRequester_+3A_period">period</code></td>
<td>
<p>Length (in seconds) of measurement period</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If 'f' is a single function, then a new function with the same
signature and (eventual) behavior as the original function, but rate limited.
If 'f' is a named list of functions, then a new list of functions with the
same names and signatures, but collectively bound by a shared rate limit.
Used only for WikiData Query Service (WDQS).
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>See Also</h3>

<p>ratelimitr
</p>

<hr>
<h2 id='m_Opensearch'>Open search of a string</h2><span id='topic+m_Opensearch'></span>

<h3>Description</h3>

<p>Search string in the content of the project page using OpenSearch. Only in
namespace 0. Please, see https://www.mediawiki.org/wiki/API:Opensearch for
further information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m_Opensearch(
  string,
  project = "en.wikipedia.org",
  profile = "engine_autoselect",
  redirects = "resolve"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="m_Opensearch_+3A_string">string</code></td>
<td>
<p>String to search.</p>
</td></tr>
<tr><td><code id="m_Opensearch_+3A_project">project</code></td>
<td>
<p>Wikimedia project, defaults &quot;en.wikipedio.org&quot;.</p>
</td></tr>
<tr><td><code id="m_Opensearch_+3A_profile">profile</code></td>
<td>
<p>This parameter sets the search type: classic,
engine_autoselect (default), fast-fuzzy, fuzzy, fuzzy-subphrases, normal,
normal-subphrases, and strict.</p>
</td></tr>
<tr><td><code id="m_Opensearch_+3A_redirects">redirects</code></td>
<td>
<p>If redirects='return', the page title is the normalized one
(also the URL). If redirects='resolve&quot;, the page title is the normalized and
resolved redirection is in effect (also the URL). Note that in both cases the
API performs a NFC Unicode normalization on search string.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame of page titles and URL returned. If error, return Null.
</p>


<h3>Note</h3>

<p>Only for namespace 0. The function also obtains redirections for
disambiguation pages.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Some search profiles:
df &lt;- m_Opensearch(string='Duque de Alba', project='es.wikipedia.org',
                    profile="engine_autoselect", redirects="resolve")
df &lt;- m_Opensearch(string='Duque de Alba', project='es.wikipedia.org', profile="strict")
df &lt;- m_Opensearch(string='Duque de Alba', project='es.wikipedia.org', profile="fuzzy")
</code></pre>

<hr>
<h2 id='m_Pageviews'>Get number of views of a Wikipedia article</h2><span id='topic+m_Pageviews'></span>

<h3>Description</h3>

<p>Use the Wikimedia REST API (https://wikimedia.org/api/rest_v1/) to get the
number of views one article has in a Wikimedia project in a date interval
(see granularity). If redirect=TRUE, then get the number of views of all
articles that redirects to the article which is the destiny of actual page.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m_Pageviews(
  article,
  start,
  end,
  project = "en.wikipedia.org",
  access = "all-access",
  agent = "user",
  granularity = "monthly",
  redirects = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="m_Pageviews_+3A_article">article</code></td>
<td>
<p>The title of the article to search. Only one article is allowed.</p>
</td></tr>
<tr><td><code id="m_Pageviews_+3A_start">start</code>, <code id="m_Pageviews_+3A_end">end</code></td>
<td>
<p>First and last day to include (format YYYYMMDD or YYYYMMDDHH)</p>
</td></tr>
<tr><td><code id="m_Pageviews_+3A_project">project</code></td>
<td>
<p>The Wikimedia project, defaults en.wikipedia.org</p>
</td></tr>
<tr><td><code id="m_Pageviews_+3A_access">access</code></td>
<td>
<p>Filter by access method: all-access (default), desktop, mobile-app, mobile-web</p>
</td></tr>
<tr><td><code id="m_Pageviews_+3A_agent">agent</code></td>
<td>
<p>Filter by agent type: all-agents, user (default), spider, automated</p>
</td></tr>
<tr><td><code id="m_Pageviews_+3A_granularity">granularity</code></td>
<td>
<p>Time unit for the response data: daily, monthly (default)</p>
</td></tr>
<tr><td><code id="m_Pageviews_+3A_redirects">redirects</code></td>
<td>
<p>Boolean to include the views of all redirections of the page
(defaults: False). If redirects=TRUE then the &quot;normalized&quot; element of the
returned vector contains the destiny of the redirection, and the &quot;original&quot;
element contains the original title of the article.
If a page is just a destiny of other pages, and you want to know the total
number of views that page have (including views of redirections), it is also
necessary set redirects=TRUE,  otherwise only you have the views of that page.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the number of visits by granularity.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v &lt;-  m_Pageviews(article="Cervantes", start="20230101", end="20230501",
                   project="es.wikipedia.org", granularity="monthly")
vv &lt;- m_Pageviews(article="Cervantes", start="20230101", end="20230501",
                   project="es.wikipedia.org", granularity="monthly",
                   redirects=TRUE)
</code></pre>

<hr>
<h2 id='m_reqMediaWiki'>Retrieve responses using the MediaWiki API.</h2><span id='topic+m_reqMediaWiki'></span>

<h3>Description</h3>

<p>Use the MediaWiki API to check Wikipedia pages titles, get redirections of
Wikipedia pages, get image URL of Wikipedia pages or get URL of files in
Wikipedia pages
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m_reqMediaWiki(
  titles,
  mode = c("wikidataEntity", "redirects", "pagePrimaryImage", "pageFiles"),
  project = "en.wikipedia.org",
  redirects = TRUE,
  exclude_ext = "svg|webp|xcf"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="m_reqMediaWiki_+3A_titles">titles</code></td>
<td>
<p>A vector of page titles to search for.</p>
</td></tr>
<tr><td><code id="m_reqMediaWiki_+3A_mode">mode</code></td>
<td>
<p>Select an action to perform:
'wikidataEntity' -&gt;
Use reqMediaWiki to check if page titles are in a Wikimedia project and returns
the Wikidata entity for them. Automatically resolves redirects if parameter
redirects = TRUE (default). If a page title exists in the Wikimedia project,
the status column in the returned data-frame is set to 'OK'. If a page is a
disambiguation page, that column is set to 'disambiguation', and if a title
is not in the Wikimedia project, it is set to 'missing' and no Wikidata
entity is returned;
'redirects' -&gt;
Obtains redirection of pages of the article titles in the Wikimedia project
restricted to namespace 0. Returns a vector for each title, in each vector the
first element is the page destiny, the rest are all pages that redirect to it. If
a title is not in the Wikimedia project its list is NA;
'pagePrimaryImage' -&gt;
Return the URL of the image associated with the Wikipedia pages of the titles,
if pages has one. Automatically resolves redirects, the &quot;normalized&quot; column
of the returned data-frames contains the destiny page of the redirection.
See https://www.mediawiki.org/w/api.php?action=help&amp;modules=query%2Bpageimages;
'pageFiles' -&gt;
Search for URL of files inserted in Wikipedia pages. Exclude extensions
in exclude_ext. Note that the query API named this search as 'images',
but all source files in the page are returned. The function only return URL
that not end with extensions in exclude_ext parameter (case insensitive).
Automatically resolves redirects, the &quot;normalized&quot; column of the returned
data-frame contains the destiny page of the redirection.
See https://en.wikipedia.org/w/api.php?action=help&amp;modules=query%2Bimages</p>
</td></tr>
<tr><td><code id="m_reqMediaWiki_+3A_project">project</code></td>
<td>
<p>Wikimedia project, defaults &quot;en.wikipedia.org&quot;</p>
</td></tr>
<tr><td><code id="m_reqMediaWiki_+3A_redirects">redirects</code></td>
<td>
<p>If page redirects must be resolved. If redirects=TRUE
(default) then the &quot;normalized&quot; column of the returned data-frames contains
the destiny page title of the redirection. Only for mode=wikidataEntity.</p>
</td></tr>
<tr><td><code id="m_reqMediaWiki_+3A_exclude_ext">exclude_ext</code></td>
<td>
<p>File extensions excluded in results.
Only for mode=PageFiles. Default 'svg|webp|xcf'</p>
</td></tr>
</table>


<h3>Value</h3>

<p>depends on the mode selected:
'wikidataEntity' Null if there is any error in response, else a data-frame
with four columns: first, the original page title string, second, the
normalized one, third, logical error=FALSE, if Wikidata entity exists for
the page, or error=TRUE it does not, last, the Wikidata entity itself or a
clarification of the error;
'redirects' A vector for each title, with all pages that are redirects to the
first element;
'pagePrimaryImage' A data-frame with original titles, normalized ones, the
status of the pages and the primary image of the page or NA if it does not
exist;
'pageFiles' A data-frame with original titles, the normalized ones, status
for the page and the URL files of the Wikipedia pages, using use &quot;|&quot; to
separate ones) or NA if files do not exits or are excluded.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Note that URLdecode("a%CC%8C") is
# the letter "a" with the combining caron
df &lt;- m_reqMediaWiki(c('Max Planck', URLdecode("a%CC%8C"), 'Max', 'Cervante', 'humanist'),
                    mode='wikidataEntity', project='en.wikipedia.org')
a &lt;- m_reqMediaWiki(c('Cervantes', 'Planck', 'Noexiste'), mode='redirects',
                    project='es.wikipedia.org')
i &lt;- m_reqMediaWiki(c('Max Planck', URLdecode("a%CC%8C"), 'Max', 'Cervante', 'humanist'),
                    mode='pagePrimaryImage')
f &lt;- m_reqMediaWiki(c('Max Planck', URLdecode("a%CC%8C"), 'Max', 'Cervante', 'humanist'),
                    mode='pageFiles', exclude_ext = "svg|webp|xcf")
</code></pre>

<hr>
<h2 id='m_XtoolsInfo'>Gets various information from a Wikimedia page</h2><span id='topic+m_XtoolsInfo'></span>

<h3>Description</h3>

<p>Obtains information in JSON format about an article in the Wikimedia project
or NULL on errors. Use the wmflabs API. The XTools Page API endpoints offer data
related to a single page. See https://www.mediawiki.org/wiki/XTools/API/Page.
The URL of the API starts with 'https://xtools.wmcloud.org/api/page/'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>m_XtoolsInfo(
  article,
  infotype = c("articleinfo", "prose", "links"),
  project = "en.wikipedia.org",
  redirects = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="m_XtoolsInfo_+3A_article">article</code></td>
<td>
<p>The title of the article to search. Only one article is allowed.</p>
</td></tr>
<tr><td><code id="m_XtoolsInfo_+3A_infotype">infotype</code></td>
<td>
<p>The type of information to request: articleinfo, prose, links.
You also can type 'all' to retrieve all.
Note that the API also offer theses options: top_editors, assessments,
bot_data and automated_edits.</p>
</td></tr>
<tr><td><code id="m_XtoolsInfo_+3A_project">project</code></td>
<td>
<p>The Wikimedia project, defaults en.wikipedia.org.</p>
</td></tr>
<tr><td><code id="m_XtoolsInfo_+3A_redirects">redirects</code></td>
<td>
<p>If redirects==TRUE, then the information is obtained
of the destiny of the page. In that case, then the &quot;original&quot; element of
the returned list contains the original page, and the &quot;page&quot; element the
destiny page. Also, if infotype=='links, the sum of the in-links of all
redirections is assigned to links_in_count.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the information about the article.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;-  m_XtoolsInfo(article="Cervantes", infotype="articleinfo", project="es.wikipedia.org")
xx &lt;- m_XtoolsInfo(article="Cervantes", infotype="articleinfo", project="es.wikipedia.org",
                   redirects=TRUE)

y &lt;-  m_XtoolsInfo(article="Miguel de Cervantes", infotype="links", project="es.wikipedia.org")
yy &lt;- m_XtoolsInfo(article="Cervantes", infotype="links", project="es.wikipedia.org",
                    redirects=TRUE)
z  &lt;- m_XtoolsInfo(article="Miguel de Cervantes", infotype="all", project="es.wikipedia.org")
zz &lt;- m_XtoolsInfo(article="Cervantes", infotype="all", project="es.wikipedia.org",
                       redirects=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='nametoWikiFrame'>Convert names into a Wikipedia's iframe</h2><span id='topic+nametoWikiFrame'></span>

<h3>Description</h3>

<p>Convert names into a Wikipedia's iframe
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nametoWikiFrame(name, language = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nametoWikiFrame_+3A_name">name</code></td>
<td>
<p>A vector consisting of one or more Wikipedia's entry (i.e., topic or person).</p>
</td></tr>
<tr><td><code id="nametoWikiFrame_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code (default = &quot;en&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function adds the Wikipedia's iframe to a entry or name, i.e., &quot;Max Weber&quot; converts into &quot;&lt;iframe src=\&quot;https://es.m.wikipedia.org/wiki/Max_Weber\&quot; width=\&quot;100...&quot;. It also manages different the languages of Wikipedia through the abbreviated two-letter language parameter, i.e., &quot;en&quot; = &quot;english&quot;.
</p>


<h3>Value</h3>

<p>A character vector of Wikipedia's iframes.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## When extracting a single item;
nametoWikiFrame("Computer", language = "en")

## When extracting two objetcs;
A &lt;- c("Computer", "Operating system")
nametoWikiFrame(A)

## Same when three or more items;
B &lt;- c("Socrates", "Plato", "Aristotle")
nametoWikiFrame(B)
</code></pre>

<hr>
<h2 id='nametoWikiHtml'>Create the Wikipedia link of a name or entry.</h2><span id='topic+nametoWikiHtml'></span>

<h3>Description</h3>

<p>Create the Wikipedia link of a name or entry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nametoWikiHtml(name, language = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nametoWikiHtml_+3A_name">name</code></td>
<td>
<p>A vector consisting of one or more Wikipedia's entry (i.e., topic or person).</p>
</td></tr>
<tr><td><code id="nametoWikiHtml_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code (default = &quot;en&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function adds the Wikipedia's html link to a entry or name, i.e., &quot;Max Weber&quot; converts into &quot;<code style="white-space: pre;">&#8288;&lt;a href='https://es.wikipedia.org/wiki/Max_Weber' target='_blank'&gt;Max Weber&lt;/a&gt;&#8288;</code>&quot;. It also manages different the languages of Wikipedia through the abbreviated two-letter language parameter, i.e., &quot;en&quot; = &quot;english&quot;.
</p>


<h3>Value</h3>

<p>A character vector of names' links.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## When extracting a single item;
nametoWikiHtml("Computer", language = "en")

## When extracting two objetcs;
A &lt;- c("Computer", "Operating system")
nametoWikiHtml(A)
B &lt;- c("Socrates", "Plato","Aristotle" )
nametoWikiHtml(B)
</code></pre>

<hr>
<h2 id='nametoWikiURL'>Create the Wikipedia URL of a name or entry.</h2><span id='topic+nametoWikiURL'></span>

<h3>Description</h3>

<p>Create the Wikipedia URL of a name or entry.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nametoWikiURL(name, language = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nametoWikiURL_+3A_name">name</code></td>
<td>
<p>A vector consisting of one or more Wikipedia's entry (i.e., topic or person).</p>
</td></tr>
<tr><td><code id="nametoWikiURL_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code (default = &quot;en&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function adds the Wikipedia URL to a entry or name, i.e., &quot;Max Weber&quot; converts into &quot;https://es.wikipedia.org/wiki/Max_Weber&quot;. It also manages different the languages of Wikipedia thru the abbreviated two-letter language parameter, i.e., &quot;en&quot; = &quot;english&quot;.
</p>


<h3>Value</h3>

<p>A character vector of names' URLs.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## When extracting a single item;
nametoWikiURL("Computer", language = "en")

## When extracting two objetcs;
A &lt;- c("Computer", "Operating system")
nametoWikiURL(A)

## Same when three or more items;
B &lt;- c("Socrates", "Plato" , "Aristotle")
nametoWikiURL(B)
</code></pre>

<hr>
<h2 id='normalizedTitle'>normalizedTitle(title, q)
Return de normalized or redirect title (also normalized) from the query part
of the JSON response of a MediaWiki search that uses titles.</h2><span id='topic+normalizedTitle'></span>

<h3>Description</h3>

<p>normalizedTitle(title, q)
Return de normalized or redirect title (also normalized) from the query part
of the JSON response of a MediaWiki search that uses titles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalizedTitle(title, q)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalizedTitle_+3A_title">title</code></td>
<td>
<p>the title to possibly found in q.</p>
</td></tr>
<tr><td><code id="normalizedTitle_+3A_q">q</code></td>
<td>
<p>(j$query) Query part of the JSON response from a Mediawiki search.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The normalized or redirect title found in q for title, else title
itself.
</p>

<hr>
<h2 id='preName'>Reverse the order of the first and last names of every element of a vector.</h2><span id='topic+preName'></span>

<h3>Description</h3>

<p>Reverse the order of the first and last names of every element of a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>preName(X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="preName_+3A_x">X</code></td>
<td>
<p>A vector of names with format &quot;name, prename&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function reverses the order of the first and last names of the items: i.e., &quot;Weber, Max&quot; turns into &quot;Max Weber&quot;.
</p>


<h3>Value</h3>

<p>Another vector with its elements changed.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## To reconvert a single name:
preName("Weber, Max")
## It is possible to work with several items, as in here:
A &lt;- c("Weber, Max", "Descartes, Rene", "Locke, John")
preName(A)
</code></pre>

<hr>
<h2 id='reqMediaWiki'>Uses httr package to retrieve responses using the MediaWiki API.</h2><span id='topic+reqMediaWiki'></span>

<h3>Description</h3>

<p>For MediaWiki requests only user_agent is necessary in the request headers.
See https://www.mediawiki.org/wiki/API:Etiquette. The standard and default
output format in MediaWiki is JSON. All other formats are discouraged. The
output format should always be specified using the request param &quot;format&quot;
in the &quot;query&quot; request.
See https://www.mediawiki.org/wiki/API:Data_formats#Output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reqMediaWiki(query, project = "en.wikipedia.org", method = "GET", attempts = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reqMediaWiki_+3A_query">query</code></td>
<td>
<p>A list with de (key, values) pairs with the search.
Note that if titles are included in the query, the MediaWiki API has a
limit of 50 titles en each query. In that case a error response is achieved.</p>
</td></tr>
<tr><td><code id="reqMediaWiki_+3A_project">project</code></td>
<td>
<p>The Wikimedia project to search. Default en.wikipedia.org.</p>
</td></tr>
<tr><td><code id="reqMediaWiki_+3A_method">method</code></td>
<td>
<p>The method used in the httr request. Default 'GET'.
Note in &quot;https://www.mediawiki.org/wiki/API:Etiquette#Request_limit&quot;:
&quot;Whenever you're reading data from the web service API, you should try to use
GET requests if possible, not POST, as the latter are not cacheable.&quot;</p>
</td></tr>
<tr><td><code id="reqMediaWiki_+3A_attempts">attempts</code></td>
<td>
<p>On ratelimit errors, the number of times the request is
retried using a 60 seconds interval between retries. Default 2. If 0 no
retries are done.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The response in JSON format or NULL on errors.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>

<hr>
<h2 id='reqWDQS'>Get responses from Wikidata Query Service</h2><span id='topic+reqWDQS'></span>

<h3>Description</h3>

<p>Retrieves responses from Wikidata Query Service (WDQS)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reqWDQS(sparql_query, format = "json", method = "GET")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reqWDQS_+3A_sparql_query">sparql_query</code></td>
<td>
<p>A string with the query in SPARQL language.</p>
</td></tr>
<tr><td><code id="reqWDQS_+3A_format">format</code></td>
<td>
<p>A string with the query response format, mandatory. See
https://www.mediawiki.org/wiki/Wikidata_Query_Service/User_Manual#SPARQL_endpoint.
Only  'json', 'xml' or 'csv' formats are allowed, default 'json'.</p>
</td></tr>
<tr><td><code id="reqWDQS_+3A_method">method</code></td>
<td>
<p>The method used in the httr request, GET or POST, mandatory.
Default 'GET'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The response in the format selected. Please check httr::stop_for_status(response)
</p>


<h3>Note</h3>

<p>For short queries GET method is better, POST for long ones. Only GET queries as cached.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>

<hr>
<h2 id='searchWiki'>Find if there is a Wikipedia page of a name(s) in the selected language.</h2><span id='topic+searchWiki'></span>

<h3>Description</h3>

<p>Find if there is a Wikipedia page of a name(s) in the selected language.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>searchWiki(
  name,
  language = c("en", "es", "fr", "it", "de", "pt", "ca"),
  all = FALSE,
  maxtime = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="searchWiki_+3A_name">name</code></td>
<td>
<p>A vector consisting of one or more Wikipedia's entry (i.e., topic or person).</p>
</td></tr>
<tr><td><code id="searchWiki_+3A_language">language</code></td>
<td>
<p>The language of the Wikipedia page version. This should consist of an ISO language code.</p>
</td></tr>
<tr><td><code id="searchWiki_+3A_all">all</code></td>
<td>
<p>If all, all the languages are checked. If false, once a term is found, there is no search of others, so it's faster.</p>
</td></tr>
<tr><td><code id="searchWiki_+3A_maxtime">maxtime</code></td>
<td>
<p>In case you want to apply a random waiting between consecutive searches.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function checks any page or entry in order to find if it has a Wikipedia page in a given language.
It manages the different the languages of Wikipedia thru the two-letters abbreviated language parameter, i.e, &quot;en&quot; = &quot;english&quot;. It is possible to check multiple languages in order of preference; in this case, only the first available language will appear as TRUE.
</p>


<h3>Value</h3>

<p>A Boolean data frame of TRUE or FALSE.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## When you want to check an entry in a single language:
searchWiki("Manuel Vilas", language = "es")

## When you want to check an entry in several languages:
## Not run: 
searchWiki("Manuel Vilas", language = c( "en", "es", "fr", "it", "de", "pt", "ca"), all=TRUE)

## End(Not run)
## Not run: 
A&lt;-c("Manuel Vilas", "Julia Navarro", "Rosa Montero")
searchWiki(A, language = c("en", "es", "fr", "it", "de", "pt", "ca"), all=FALSE)

## End(Not run)
</code></pre>

<hr>
<h2 id='urltoFrame'>Convert an URL link to an HTML iframe.</h2><span id='topic+urltoFrame'></span>

<h3>Description</h3>

<p>Convert an URL link to an HTML iframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>urltoFrame(url)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="urltoFrame_+3A_url">url</code></td>
<td>
<p>Character vector of URLs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts an available URL direction to the corresponding HTML iframe, i.e., &quot;https://es.wikipedia.org/wiki/Socrates&quot; changes into &quot;<code style="white-space: pre;">&#8288;&lt;a href='https://es.wikipedia.org/wiki/Socrates' target='_blank'&gt;Socrates&lt;/a&gt;&#8288;</code>&quot;.
</p>


<h3>Value</h3>

<p>A character vector of HTML iframe for the given urls.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## When you have a single URL:

urltoFrame("https://es.wikipedia.org/wiki/Socrates")

## It is possible to work with a vector of URL to obtain another vector of html frames:

A &lt;- c("https://es.wikipedia.org/wiki/Socrates", 
       "https://es.wikipedia.org/wiki/Plato", 
       "https://es.wikipedia.org/wiki/Aristotle")
urltoHtml (A)
</code></pre>

<hr>
<h2 id='urltoHtml'>Convert a Wikipedia URL to an HTML link</h2><span id='topic+urltoHtml'></span>

<h3>Description</h3>

<p>Convert a Wikipedia URL to an HTML link
</p>


<h3>Usage</h3>

<pre><code class='language-R'>urltoHtml(url, text = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="urltoHtml_+3A_url">url</code></td>
<td>
<p>Character vector of URLs.</p>
</td></tr>
<tr><td><code id="urltoHtml_+3A_text">text</code></td>
<td>
<p>A vector with name of the correspondent title of the url (See details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function converts an available URL direction to the corresponding HTML link, i.e., &quot;https://es.wikipedia.org/wiki/Socrates&quot; changes into &quot;<code style="white-space: pre;">&#8288;&lt;a href='https://es.wikipedia.org/wiki/Socrates' target='_blank'&gt;Socrates&lt;/a&gt;&#8288;</code>&quot;.
</p>


<h3>Value</h3>

<p>A character vector of HTML links for the given urls.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## When you have a single URL:

urltoHtml("https://es.wikipedia.org/wiki/Socrates", text = "Socrates")

## It is possible to work with several items:

A &lt;- c("https://es.wikipedia.org/wiki/Socrates", 
       "https://es.wikipedia.org/wiki/Plato", 
       "https://es.wikipedia.org/wiki/Aristotle")
urltoHtml (A, text = c("Socrates", "Plato", "Aristotle"))

## And  you can also directly extract the info from nametoWikiURL():

urltoHtml(nametoWikiURL("Plato", "en"), "Plato" )
urltoHtml(nametoWikiURL(c("Plato", "Socrates", "Aristotle"), language="en"), 
          c("Plato", "Socrates", "Aristotle"))
</code></pre>

<hr>
<h2 id='user_agent'>See https://meta.wikimedia.org/wiki/User-Agent_policy.</h2><span id='topic+user_agent'></span>

<h3>Description</h3>

<p>See https://meta.wikimedia.org/wiki/User-Agent_policy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>user_agent
</code></pre>


<h3>Format</h3>

<p>An object of class <code>character</code> of length 1.
</p>

<hr>
<h2 id='v_AutoSuggest'>Suggests VIAF id from a name</h2><span id='topic+v_AutoSuggest'></span>

<h3>Description</h3>

<p>Search the name of the author from the VIAF AutoSuggest API and returns
information in JSON format of the records found. Note that only
returns a maximum of 10 records. Note that those records are not
VIAF cluster records.
A VIAF record is considered a &quot;cluster record,&quot; which is the result of
combining records from many libraries around the world into a single record.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>v_AutoSuggest(author)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="v_AutoSuggest_+3A_author">author</code></td>
<td>
<p>String to search. Please, see the structure of the author
string to obtain better results:
author: last name, first name[,] [([year_of_bird][-year_of_death])]</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with four columns from the elements &quot;term&quot;, &quot;score&quot;,
&quot;nametype&quot; and &quot;viafid&quot; of the Autosuggest API response.
</p>


<h3>See Also</h3>

<p>https://www.oclc.org/developer/api/oclc-apis/viaf/authority-cluster.en.html
</p>


<h3>Examples</h3>

<pre><code class='language-R'>v_AutoSuggest('Iranzo')
v_AutoSuggest('Esparza, Mar√≠a')
# Four rows, only two viafid:
v_AutoSuggest('Escobar, Modesto')
</code></pre>

<hr>
<h2 id='v_Extract'>Gets information from a VIAF record</h2><span id='topic+v_Extract'></span>

<h3>Description</h3>

<p>Returns information from the VIAF record. Note that the VIAF record musts
be in JSON format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>v_Extract(viaf, info, source = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="v_Extract_+3A_viaf">viaf</code></td>
<td>
<p>VIAF cluster record (in JSON format).</p>
</td></tr>
<tr><td><code id="v_Extract_+3A_info">info</code></td>
<td>
<p>is mandatory to select which information you want to retrieve.
The options are 'titles', 'gender', 'dates', 'occupations', 'sources',
'sourceId' or 'wikipedias'.</p>
</td></tr>
<tr><td><code id="v_Extract_+3A_source">source</code></td>
<td>
<p>the identifier of the source (LC, WKP, JPG, BNE...)
Only if info=sourceId.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>depends on the info selected:
'titles' A list with titles;
'gender' The gender of the author o NULL if not exits in the record;
'dates' The bird year and death year in format byear:dyear;
'occupations' A data-frame with sources and occupations from each source or NULL if
occupations do not exist in the record;
'sources' A data-frame with text and sources;
'sourceId' A data-frame with columns text and source, or NULL if the source does
no exist in the viaf record;
'wikipedias' A vector with the URL of the Wikipedias.
</p>

<hr>
<h2 id='v_GetRecord'>Gets record clusters</h2><span id='topic+v_GetRecord'></span>

<h3>Description</h3>

<p>Obtains the record cluster identified by viafid from VIAF, in the format
indicated in record_format. Note that the returned record may be a VIAF
cluster record or a redirect/scavenged record: the function returns the
record as is.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>v_GetRecord(viafid, record_format = "viaf.json")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="v_GetRecord_+3A_viafid">viafid</code></td>
<td>
<p>The VIAF identifier.</p>
</td></tr>
<tr><td><code id="v_GetRecord_+3A_record_format">record_format</code></td>
<td>
<p>'viaf.json' (default) or others in
https://www.oclc.org/developer/api/oclc-apis/viaf/authority-cluster.en.html.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The VIAF record cluster in the format indicated in record_format.
</p>

<hr>
<h2 id='v_Search'>Run a CQL Query in VIAF</h2><span id='topic+v_Search'></span>

<h3>Description</h3>

<p>Run the CQL_Query using the VIAF Search API and return a list of records
found. The search string is formed using the CQL_Query syntax of the API.
Note that returned records use the &quot;info:srw/schema/1/JSON&quot; record schema,
i.e., are complete cluster records packed in JSON format. If the number
of records found is greater than 250 (API restrictions), successive requests
are made.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>v_Search(
  CQL_Query,
  mode = c("default", "anyField", "allmainHeadingEl", "allNames", "allPersonalNames",
    "allTitle")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="v_Search_+3A_cql_query">CQL_Query</code></td>
<td>
<p>String with the search or a name if mode is specified.
See https://www.oclc.org/developer/api/oclc-apis/viaf/authority-cluster.en.html</p>
</td></tr>
<tr><td><code id="v_Search_+3A_mode">mode</code></td>
<td>
<p>apply a predefined query:
'anyField' -&gt; 'cql.any = &quot;string&quot;'
Search preferred Name - names which are the preferred form in an authority
record (1xx fields of the MARC records);
'allmainHeadingEl' -&gt; 'local.mainHeadingEl all &quot;name&quot;'
Search the same as previous, but all terms are searched;
'allNames' -&gt; 'local.names all &quot;name&quot;'
Search Names - any name preferred or alternate (1xx, 4xx, 5xx fields of the
MARC records);
'allPersonalNames' -&gt; 'local.personalNames all &quot;name&quot;'
Search Personal Names within the authority record (100, 400, 500 fields of
MARC records);
'allTitle' -&gt; 'local.title all &quot;title&quot;'
Search for titles.
By 'default', no predefined query will be applied.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the records found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Search in any field (cql.any)
# Operator is "=": so search one or more terms:
CQL_Query &lt;- 'cql.any = "Garc√≠a Iranzo, Juan"'
r &lt;- v_Search(CQL_Query)
# r contains complete VIAF records (sometimes seen as a "cluster record",
# which is unified by combining records from many libraries around the world)
# Search in 1xx, 4xx, 5xx fields of MARC record (local.names)
# Operator is "all": search all terms
CQL_Query &lt;- 'local.names all "Modesto Escobar"'
r &lt;- v_Search(CQL_Query)

# Search in 100, 400, 500 fields of MARC record (local.personalNames)
# Operator is "all": search all terms
CQL_Query &lt;- 'local.personalNames all "Modesto Escobar"'
r &lt;- v_Search(CQL_Query)

# Search in Titles
CQL_Query &lt;- 'local.title all "Los pron√≥sticos electorales con encuestas"'
r &lt;- v_Search(CQL_Query)

## End(Not run)
</code></pre>

<hr>
<h2 id='validUrl'>Find if an URL link is valid.</h2><span id='topic+validUrl'></span>

<h3>Description</h3>

<p>Find if an URL link is valid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validUrl(url, time = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validUrl_+3A_url">url</code></td>
<td>
<p>A vector of URLs.</p>
</td></tr>
<tr><td><code id="validUrl_+3A_time">time</code></td>
<td>
<p>The timeout (in seconds) to be used for each connection. Default = 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function checks if a URL exists on the Internet.
</p>


<h3>Value</h3>

<p>A boolean value of TRUE or FALSE.
</p>


<h3>Author(s)</h3>

<p>Modesto Escobar, Department of Sociology and Communication, University of Salamanca. See <a href="https://sociocav.usal.es/blog/modesto-escobar/">https://sociocav.usal.es/blog/modesto-escobar/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>validUrl(url="https://es.wikipedia.org/wiki/Weber,_Max", time=2)
</code></pre>

<hr>
<h2 id='w_EntityInfo'>Get some personal properties of one Wikidata entity</h2><span id='topic+w_EntityInfo'></span>

<h3>Description</h3>

<p>Gets some properties of the Wikidata &quot;entity&quot; related to birth and death
dates, places, occupations, works, education, awards, identifier in some
libraries, Wikipedia page titles (which can be limited to the languages in
the &quot;wikilangs&quot; parameter), etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_EntityInfo(
  entity,
  langsorder = "en",
  wikilangs = "",
  format = "reduced",
  mode = c("default", "tiny", "film")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_EntityInfo_+3A_entity">entity</code></td>
<td>
<p>The Wikidata entity to search for properties. Only one entity
is allowed.</p>
</td></tr>
<tr><td><code id="w_EntityInfo_+3A_langsorder">langsorder</code></td>
<td>
<p>Order of languages in which the information will be
returned, separated with '|'. If no information exists in the first language,
next is used. This parameter is mandatory, at least one language is required,
default, 'en'.
Note: sometimes not label in any language of langsorder is assigned to an
entity, so an additional search is used to obtain almost one label for it
(?entitylab) with LIMIT 1.</p>
</td></tr>
<tr><td><code id="w_EntityInfo_+3A_wikilangs">wikilangs</code></td>
<td>
<p>List of languages to limit the search of Wikipedia pages,fi
using &quot;|&quot; as separator. Wikipedias pages are returned in same order as
languages in this parameter. If wikilangs=&rdquo; the function returns Wikipedia
pages in any language, not sorted.</p>
</td></tr>
<tr><td><code id="w_EntityInfo_+3A_format">format</code></td>
<td>
<p>Wikipedia address format. By default is reduced, Otherwise, format is regular.</p>
</td></tr>
<tr><td><code id="w_EntityInfo_+3A_mode">mode</code></td>
<td>
<p>The mode to obtain results: 'tiny' less properties are requested
and less checks are done; 'film' gets some properties of the Wikidata
&quot;entity&quot; related to information about film ('default' by default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with the properties of the entity.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df1 &lt;- w_EntityInfo(entity='Q134644', langsorder = 'es|en')
df2 &lt;- w_EntityInfo(entity='Q134644', langsorder = 'es|en', mode = 'tiny')
## Not run: 
films &lt;- w_EntityInfo(entity=c('Q180098','Q151895'), langsorder='es|en',
wikilangs='es|fr|en', mode='film')

## End(Not run)
</code></pre>

<hr>
<h2 id='w_IdentifiersOfAuthority'>Search for Wikidata entities that have a property identifier</h2><span id='topic+w_IdentifiersOfAuthority'></span>

<h3>Description</h3>

<p>Search for Wikidata entities that have an identifier in the Wikidata
authority property &quot;Pauthority&quot;. Return the entities and information (label,
description) in the language order indicated in langsorder. If instanceof
has a value, then response is limited to entities which are instance of it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_IdentifiersOfAuthority(Pauthority, langsorder = "en", instanceof = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_IdentifiersOfAuthority_+3A_pauthority">Pauthority</code></td>
<td>
<p>Wikidata property identifier for the authority, i.e, the
property of Wikidata for the the database of the authority. For example, is
Pauthority = &quot;P4439&quot;, then search Wikidata entities that have an identifier
in the MNCARS (Museo Nacional Centro de Arte Reina Sof√≠a) authority database.</p>
</td></tr>
<tr><td><code id="w_IdentifiersOfAuthority_+3A_langsorder">langsorder</code></td>
<td>
<p>Order of languages in which the information will be
returned, separated with '|'. If no information is given in the first
language, next is used. This parameter is mandatory, at least one language is
required, default, 'en'.</p>
</td></tr>
<tr><td><code id="w_IdentifiersOfAuthority_+3A_instanceof">instanceof</code></td>
<td>
<p>Wikidata entity of which the entities searched for are an
example or member of it (class). Optional. For example, if instanceof=&quot;Q5&quot;
the search are filtered to Wikidata entities of class Q5 (human). Some
entity classes are allowed, separated with '|'.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with 'entity', 'entityLabel', 'entityDescription' and
the identifier in the &quot;Pauthority&quot; database,
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example: Pauthority=P4439 (has identificator in the Museo Nacional Centro de
# Arte Reina Sof√≠a)
mncars   &lt;- w_IdentifiersOfAuthority(Pauthority="P4439",
langsorder = 'es|en')  # 1286  [human, groups, etc.]
mncarsQ5 &lt;- w_IdentifiersOfAuthority(Pauthority="P4439", langsorder = 'es|en',
instanceof = 'Q5')  # 1280
# Wikidata entities are not 'human' (Q5) (see entityDescription column):
mncars[!(mncars$entity %in% mncarsQ5$entity),]  # not instance of Q5.

## End(Not run)
</code></pre>

<hr>
<h2 id='w_isInstanceOf'>Check if a Wikidata entity is an instance of a class</h2><span id='topic+w_isInstanceOf'></span>

<h3>Description</h3>

<p>Check using WDQS if the Wikidata entities in entity_list are instances of
&quot;instanceof&quot; Wikidata entity class. For example, if instanceof=&quot;Q5&quot;, check if
entities are instances of the Wikidata entity class Q5, i.e, are humans.
Duplicated entities are deleted before search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_isInstanceOf(entity_list, instanceof)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_isInstanceOf_+3A_entity_list">entity_list</code></td>
<td>
<p>A vector with de Wikidata entities.</p>
</td></tr>
<tr><td><code id="w_isInstanceOf_+3A_instanceof">instanceof</code></td>
<td>
<p>The Wikidata class to check, mandatory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with two columns, first Wikidata entity, second TRUE
if that entity is instance of the &quot;instanceof&quot; entity, else FALSE. Index of
data-frame are also set to entity_list.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'># aux: get a vector of entities (l).
df &lt;- w_SearchByLabel(string='Iranzo', langsorder='es|en', mode='inlabel')
l &lt;- df$entity

df &lt;- w_isInstanceOf(entity_list=l, instanceof='Q5')
# Not TRUE
df[!df$instanceof_Q5,]
</code></pre>

<hr>
<h2 id='w_isValid'>Check if a Wikidata entity is valid</h2><span id='topic+w_isValid'></span>

<h3>Description</h3>

<p>Check if the Wikidata entities are valid. A entity is valid if it has a label
or has a description. If one entity exists but is not valid, is possible that
it has a redirection to other entity, in that case, the redirection is
obtained. Other entities may have existed in the past, but have been deleted.
Duplicated entities in entity_list are deleted before checking. Index of the
data-frame returned are also set to entity_list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_isValid(entity_list, nlimit = 50000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_isValid_+3A_entity_list">entity_list</code></td>
<td>
<p>A vector with de Wikidata entities.</p>
</td></tr>
<tr><td><code id="w_isValid_+3A_nlimit">nlimit</code></td>
<td>
<p>If the number of entities exceeds this number, chunked queries
are done. This is the number of entities requested in each chunk.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with three columns: firts, the entity itself, second,
if that entity is valid in Wikidata (TRUE or FALSE), last, if the entity
redirects to another Wikidata entity, this entity.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
w_isValid(c("Q9021", "Q115637688", "Q105660123"))

l  &lt;- w_OccupationEntities(Qoc='Q2306091')
l2 &lt;- append(l, c("Q115637688", "Q105660123"))  # Note: adding two new entities
v &lt;- w_isValid(l2)
# Not valid
v[!v$valid,]

## End(Not run)
</code></pre>

<hr>
<h2 id='w_OccupationEntities'>Gets Wikidata entities with a certain occupation</h2><span id='topic+w_OccupationEntities'></span>

<h3>Description</h3>

<p>Returns the Wikidata entities which have the occupation indicated in Qoc, the
Wikidata entity for that occupation. Use chunked requests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_OccupationEntities(
  Qoc,
  nlimit = NULL,
  mode = c("default", "count", "wikipedias")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_OccupationEntities_+3A_qoc">Qoc</code></td>
<td>
<p>The Wikidata entity of the occupation. For example, Q2306091
sociologist, Q2526255 Film director, etc.</p>
</td></tr>
<tr><td><code id="w_OccupationEntities_+3A_nlimit">nlimit</code></td>
<td>
<p>If the number of entities found with that occupation exceeds
this number, chunked queries are done. This is the number of entities requested
in each chunk. No effects in mode='count'. (default=10000, 5000 if mode='wikipedias')</p>
</td></tr>
<tr><td><code id="w_OccupationEntities_+3A_mode">mode</code></td>
<td>
<p>The results you want to obtain: 'default' returns the Wikidata
entities which have the occupation indicated; 'count' search in WDQS to know
the number of Wikidata entities with P106 property (occupation) set to Qoc;
'wikipedias' returns the Wikidata entities which have the occupation
indicated in Qoc, plus the Wikipedia page titles of them.
Note that mode='wikipedias' is similar to first launch w_OccupationEntities
and then launch w_Wikipedias, but is more efficient. (default='default')</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with the Wikidata entities with that occupation by default;
if mode='count' the number of entities with that occupation (integer);
if mode='wikipedias' a data-frame with Wikidata entities, the number of
Wikipedias in which they have page, the Wikipedia languages, the page titles,
and finally, the URL to the pages. Last three columns concatenated with &quot;|&quot;.
Return all Wikipedias pages, not limited by languages.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>w_OccupationEntities(Qoc='Q2306091', mode='count') # Qoc for Sociologist
l &lt;- w_OccupationEntities(Qoc='Q2306091')
## Not run: 
lw &lt;- w_OccupationEntities(Qoc='Q2306091', mode='wikipedias')

## End(Not run)
</code></pre>

<hr>
<h2 id='w_Property'>Searching for properties of the entity list</h2><span id='topic+w_Property'></span>

<h3>Description</h3>

<p>Search the entities of the entity_list for property or properties. Return the
properties in langsorder order. Duplicated entities are deleted before search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_Property(entity_list, Pproperty, langsorder = "en", nlimit = 10000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_Property_+3A_entity_list">entity_list</code></td>
<td>
<p>A vector with de Wikidata entities.</p>
</td></tr>
<tr><td><code id="w_Property_+3A_pproperty">Pproperty</code></td>
<td>
<p>Wikidata properties to search, separated with '|', mandatory.
For example, is Pproperty=&quot;P21&quot;, the results contain information of the sex
of entities. If Pproperty=&quot;P21|P569&quot; also searches for birthdate. If
Pproperty='P21|P569|P214' also searches for VIAF identifier.</p>
</td></tr>
<tr><td><code id="w_Property_+3A_langsorder">langsorder</code></td>
<td>
<p>Order of languages in which the information will be
returned, separated with '|'. If no information is given in the first
language, next is used. This parameter is mandatory, at least one language is
required, default, 'en'</p>
</td></tr>
<tr><td><code id="w_Property_+3A_nlimit">nlimit</code></td>
<td>
<p>If the number of entities exceeds this number, chunked queries
are done. This is the number of entities requested in each chunk.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with 'entity', 'entityLabel', 'entityDescription' and,
additionally, the properties of Pproperty. Index of the data-frame is also
set to entity_list.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
l &lt;- w_OccupationEntities(Qoc='Q2306091')
p &lt;- w_Property(l, Pproperty = 'P21|P569|P214', langsorder = 'es|en')

## End(Not run)
</code></pre>

<hr>
<h2 id='w_query'>Responses from Wikidata Query Service</h2><span id='topic+w_query'></span>

<h3>Description</h3>

<p>Retrieves responses from Wikidata Query Service (WDQS). Uses ratelimitr if
param limitRequester = TRUE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_query(sparql_query, format = "csv", method = "GET", limitRequester = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_query_+3A_sparql_query">sparql_query</code></td>
<td>
<p>A string with the query in SPARQL language.</p>
</td></tr>
<tr><td><code id="w_query_+3A_format">format</code></td>
<td>
<p>A string with the query response format. Mandatory.
See https://www.mediawiki.org/wiki/Wikidata_Query_Service/User_Manual#SPARQL_endpoint.
Only  'json', 'xml' or 'csv' formats are allowed, default 'csv'.</p>
</td></tr>
<tr><td><code id="w_query_+3A_method">method</code></td>
<td>
<p>The method used in the httr request, GET or POST, mandatory.
Default 'GET'.</p>
</td></tr>
<tr><td><code id="w_query_+3A_limitrequester">limitRequester</code></td>
<td>
<p>If True, uses ratelimitr to limit the requests.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The response in selected format or NULL on errors.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>

<hr>
<h2 id='w_SearchByLabel'>Search Wikidata entities</h2><span id='topic+w_SearchByLabel'></span>

<h3>Description</h3>

<p>Search Wikidata entities in label and altLabel (&quot;Also known as&quot;)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_SearchByLabel(
  string,
  langsorder = "en",
  lang = "",
  instanceof = "",
  Pproperty = "",
  mode = c("exact", "startswith", "inlabel")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_SearchByLabel_+3A_string">string</code></td>
<td>
<p>string (label or altLabel) to search.</p>
</td></tr>
<tr><td><code id="w_SearchByLabel_+3A_langsorder">langsorder</code></td>
<td>
<p>Order of languages in which the information will be
returned, separated with '|'. If no information is given in the first
language, next is used. This parameter is mandatory, at least one language is
required, default, 'en'.</p>
</td></tr>
<tr><td><code id="w_SearchByLabel_+3A_lang">lang</code></td>
<td>
<p>The language to search, only one. If lang=&quot;&quot; and mode=&quot;inlabel&quot;,
search is in any language. Mandatory in mode=&quot;startswith&quot;, no effects in
mode=&quot;exact&quot;.</p>
</td></tr>
<tr><td><code id="w_SearchByLabel_+3A_instanceof">instanceof</code></td>
<td>
<p>Wikidata entity of which the entities searched for are an
example or member of it (class). For example, if instanceof=Q5 the
search are filtered to Wikidata entities of class Q5 (human). Some
entity classes are allowed, separated with '|'.</p>
</td></tr>
<tr><td><code id="w_SearchByLabel_+3A_pproperty">Pproperty</code></td>
<td>
<p>Wikidata properties, separated with '|', to optionally
include in the search. For example, is Pproperty=&quot;P21&quot;, the results
include information of the sex of entities found as STRING.</p>
</td></tr>
<tr><td><code id="w_SearchByLabel_+3A_mode">mode</code></td>
<td>
<p>The mode to perform search: 'exact' for search using case
sensitive and differentiate diacritics; 'startswith' for entities which label
or altLabel starts with &quot;string&quot;, similar to a wildcard search &quot;string*&quot;,
searchs &quot;string&quot; in language &quot;lang&quot; in label, but in any language in
altLabel; 'inlabel' for matching whole words in any position. ('exact' by
default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with 'entity', 'entityLabel', 'entityDescription',
(including 'instance', 'instanceLabel', 'altLabel' if mode=&quot;startswith&quot;)
and additionally the properties of Pproperty.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- w_SearchByLabel(string='Iranzo', langsorder='es|en', mode="exact")
df &lt;- w_SearchByLabel(string='Iranzo', langsorder='es|en', instanceof = 'Q5|Q101352', mode="exact")
## Search entities which label or altLabel starts with "string"
df &lt;- w_SearchByLabel(string='Iranzo', lang='en', langsorder='es|en',
mode='startswith')
df &lt;- w_SearchByLabel(string='Iranzo', lang='en', langsorder='en',
instanceof = 'Q5', Pproperty = 'P21|P569|P570', mode='startswith')
## Search in any position in Label or AltLabel (diacritics and case are ignored)
# If lang=='' search in any language, else the search is performed only in the
# language indicated.
df &lt;- w_SearchByLabel(string='Iranzo', langsorder='es|en', mode='inlabel')
# Search in Chinese (Simplified) (language code: zh):
df &lt;- w_SearchByLabel(string='Iranzo', langsorder='zh|es', lang='zh',
mode='inlabel')
</code></pre>

<hr>
<h2 id='w_Wikipedias'>Gets Wikipedia pages from a Q list.</h2><span id='topic+w_Wikipedias'></span>

<h3>Description</h3>

<p>Gets from Wikidata all Wikipedia page titles of the Wikidata entities in
entity_list. If set &quot;instanceof&quot;, then only returns the pages for Wikidata
entities which are instances of that Wikidata class. If wikilangs=&rdquo;, then
returns all Wikipedia page titles, else only the languages in wikilangs.
Duplicated entities are deleted before search.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w_Wikipedias(entity_list, wikilangs = "", instanceof = "", nlimit = 1500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w_Wikipedias_+3A_entity_list">entity_list</code></td>
<td>
<p>A vector of Wikidata entities.</p>
</td></tr>
<tr><td><code id="w_Wikipedias_+3A_wikilangs">wikilangs</code></td>
<td>
<p>List of languages to limit the search, using &quot;|&quot; as
separator. Wikipedias page titles are returned in same order as languages in
this parameter. If wikilangs=&rdquo; the function returns Wikipedia page titles
in any language, not sorted.</p>
</td></tr>
<tr><td><code id="w_Wikipedias_+3A_instanceof">instanceof</code></td>
<td>
<p>Wikidata entity class to limit the result to the instances
of that class. For example, if instanceof='Q5', limit the results to &quot;human&quot;.</p>
</td></tr>
<tr><td><code id="w_Wikipedias_+3A_nlimit">nlimit</code></td>
<td>
<p>If the number of entities exceeds this number, chunked queries
are done. This is the number of entities requested in each chunk.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data-frame with four columns, first the count of Wikipedia pages,
second, the the langs, page title, and URL's of the wikipedia pages. Last
three use &quot;|&quot; as separator. Index of the data-frame is also set to the
entity_list.
</p>


<h3>Author(s)</h3>

<p>Angel Zazo, Department of Computer Science and Automatics, University of Salamanca
</p>


<h3>Examples</h3>

<pre><code class='language-R'># aux: get a vector of entities (l).
df &lt;- w_SearchByLabel(string='Iranzo', langsorder='es|en', mode='inlabel')
l &lt;- df$entity

w &lt;- w_Wikipedias(entity_list=l)
w &lt;- w_Wikipedias(entity_list=l, wikilangs='es|en|fr')
w &lt;- w_Wikipedias(entity_list=l, wikilangs='es|en|fr', instanceof="Q5")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
