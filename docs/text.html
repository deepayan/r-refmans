<!DOCTYPE html><html lang="en"><head><title>Help for package text</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {text}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#centrality_data_harmony'><p>Example data for plotting a Semantic Centrality Plot.</p></a></li>
<li><a href='#DP_projections_HILS_SWLS_100'><p>Data for plotting a Dot Product Projection Plot.</p></a></li>
<li><a href='#find_textrpp_env'><p>Find text required python packages env</p></a></li>
<li><a href='#Language_based_assessment_data_3_100'><p>Example text and numeric data.</p></a></li>
<li><a href='#Language_based_assessment_data_8'><p>Text and numeric data for 10 participants.</p></a></li>
<li><a href='#PC_projections_satisfactionwords_40'><p>Example data for plotting a Principle Component Projection Plot.</p></a></li>
<li><a href='#raw_embeddings_1'><p>Word embeddings from textEmbedRawLayers function</p></a></li>
<li><a href='#textCentrality'><p>Semantic similarity score between single words' and an aggregated word embeddings</p></a></li>
<li><a href='#textCentralityPlot'><p>Plots words from textCentrality()</p></a></li>
<li><a href='#textClean'><p>Cleans text from standard personal information</p></a></li>
<li><a href='#textCleanNonASCII'><p>Clean non-ASCII characters</p></a></li>
<li><a href='#textDescriptives'><p>Compute descriptive statistics of character variables.</p></a></li>
<li><a href='#textDimName'><p>Change dimension names</p></a></li>
<li><a href='#textDistance'><p>Semantic distance</p></a></li>
<li><a href='#textDistanceMatrix'><p>Semantic distance across multiple word embeddings</p></a></li>
<li><a href='#textDistanceNorm'><p>Semantic distance between a text variable and a word norm</p></a></li>
<li><a href='#textDomainCompare'><p>Compare two language domains</p></a></li>
<li><a href='#textEmbed'><p>textEmbed() extracts layers and aggregate them to word embeddings, for all character variables in a given dataframe.</p></a></li>
<li><a href='#textEmbedLayerAggregation'><p>Aggregate layers</p></a></li>
<li><a href='#textEmbedRawLayers'><p>Extract layers of hidden states</p></a></li>
<li><a href='#textEmbedReduce'><p>Pre-trained dimension reduction (experimental)</p></a></li>
<li><a href='#textEmbedStatic'><p>Apply static word embeddings</p></a></li>
<li><a href='#textFindNonASCII'><p>Detect non-ASCII characters</p></a></li>
<li><a href='#textFineTuneDomain'><p>Domain Adapted Pre-Training (EXPERIMENTAL - under development)</p></a></li>
<li><a href='#textFineTuneTask'><p>Task Adapted Pre-Training (EXPERIMENTAL - under development)</p></a></li>
<li><a href='#textGeneration'><p>Text generation</p></a></li>
<li><a href='#textLBAM'><p>The LBAM library</p></a></li>
<li><a href='#textModelLayers'><p>Number of layers</p></a></li>
<li><a href='#textModels'><p>Check downloaded, available models.</p></a></li>
<li><a href='#textModelsRemove'><p>Delete a specified model</p></a></li>
<li><a href='#textNER'><p>Named Entity Recognition. (experimental)</p></a></li>
<li><a href='#textPCA'><p>textPCA()</p></a></li>
<li><a href='#textPCAPlot'><p>textPCAPlot</p></a></li>
<li><a href='#textPlot'><p>Plot words</p></a></li>
<li><a href='#textPredict'><p>textPredict, textAssess and textClassify</p></a></li>
<li><a href='#textPredictAll'><p>Predict from several models, selecting the correct input</p></a></li>
<li><a href='#textPredictTest'><p>Significance testing correlations</p>
If only y1 is provided a t-test is computed, between the absolute error from yhat1-y1 and yhat2-y1.</a></li>
<li><a href='#textProjection'><p>Supervised Dimension Projection</p></a></li>
<li><a href='#textProjectionPlot'><p>Plot Supervised Dimension Projection</p></a></li>
<li><a href='#textQA'><p>Question Answering. (experimental)</p></a></li>
<li><a href='#textrpp_initialize'><p>Initialize text required python packages</p></a></li>
<li><a href='#textrpp_install'><p>Install text required python packages in conda or virtualenv environment</p></a></li>
<li><a href='#textrpp_uninstall'><p>Uninstall textrpp conda environment</p></a></li>
<li><a href='#textSimilarity'><p>Semantic Similarity</p></a></li>
<li><a href='#textSimilarityMatrix'><p>Semantic similarity across multiple word embeddings</p></a></li>
<li><a href='#textSimilarityNorm'><p>Semantic similarity between a text variable and a word norm</p></a></li>
<li><a href='#textSum'><p>Summarize texts. (experimental)</p></a></li>
<li><a href='#textTokenize'><p>Tokenize text-variables</p></a></li>
<li><a href='#textTokenizeAndCount'><p>Tokenize and count</p></a></li>
<li><a href='#textTopics'><p>BERTopics</p></a></li>
<li><a href='#textTopicsReduce'><p>textTopicsReduce (EXPERIMENTAL)</p></a></li>
<li><a href='#textTopicsTest'><p>Wrapper for topicsTest function from the topics package</p></a></li>
<li><a href='#textTopicsTree'><p>textTopicsTest (EXPERIMENTAL) to get the hierarchical topic tree</p></a></li>
<li><a href='#textTopicsWordcloud'><p>Plot word clouds</p></a></li>
<li><a href='#textTrain'><p>Trains word embeddings</p></a></li>
<li><a href='#textTrainExamples'><p>Show language examples (Experimental)</p></a></li>
<li><a href='#textTrainLists'><p>Train lists of word embeddings</p></a></li>
<li><a href='#textTrainN'><p>Cross-validated accuracies across sample-sizes</p></a></li>
<li><a href='#textTrainNPlot'><p>Plot cross-validated accuracies across sample sizes</p></a></li>
<li><a href='#textTrainRandomForest'><p>Trains word embeddings usig random forest</p></a></li>
<li><a href='#textTrainRegression'><p>Train word embeddings to a numeric variable.</p></a></li>
<li><a href='#textTranslate'><p>Translation. (experimental)</p></a></li>
<li><a href='#textZeroShot'><p>Zero Shot Classification (Experimental)</p></a></li>
<li><a href='#word_embeddings_4'><p>Word embeddings for 4 text variables for 40 participants</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analyses of Text using Transformers Models from HuggingFace,
Natural Language Processing and Machine Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Link R with Transformers from Hugging Face to transform text variables to word embeddings; where the word embeddings are used to statistically test the mean difference between set of texts, compute semantic similarity scores between texts, predict numerical variables, and visual statistically significant words according to various dimensions etc. For more information see  <a href="https://www.r-text.org">https://www.r-text.org</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://r-text.org/">https://r-text.org/</a>, <a href="https://github.com/OscarKjell/text/">https://github.com/OscarKjell/text/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/OscarKjell/text/issues/">https://github.com/OscarKjell/text/issues/</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Archs:</td>
<td>x64</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>Python (&gt;= 3.6.0)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>BuildVignettes:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>topics, dplyr, tibble, stringi, tidyr, ggplot2, ggrepel,
cowplot, rlang, purrr, magrittr, parsnip, recipes (&ge; 0.1.16),
rsample, reticulate, tune, workflows, yardstick, future, furrr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, rio, glmnet, randomForest,
overlapping, covr, xml2, ranger, utils, ggwordcloud, reactable,
osfr, vdiffr, svglite</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.00)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-18 11:38:15 UTC; oscarkjell</td>
</tr>
<tr>
<td>Author:</td>
<td>Oscar Kjell <a href="https://orcid.org/0000-0002-2728-6278"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Salvatore Giorgi <a href="https://orcid.org/0000-0001-7381-6295"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Andrew Schwartz <a href="https://orcid.org/0000-0002-6383-3339"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Oscar Kjell &lt;oscar.kjell@psy.lu.se&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-18 13:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='centrality_data_harmony'>Example data for plotting a Semantic Centrality Plot.</h2><span id='topic+centrality_data_harmony'></span>

<h3>Description</h3>

<p>The dataset is a shortened version of the data sets of Study 1
from Kjell, et al., 2016.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>centrality_data_harmony
</code></pre>


<h3>Format</h3>

<p>A data frame with 2,146 and 4 variables:
</p>

<dl>
<dt>words</dt><dd><p>unique words</p>
</dd>
<dt>n</dt><dd><p>overall word frequency</p>
</dd>
<dt>central_semantic_similarity</dt><dd><p>cosine semantic similarity to the aggregated word embedding</p>
</dd>
<dt>n_percent</dt><dd><p>frequency in percent</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://link.springer.com/article/10.1007/s11205-015-0903-z">https://link.springer.com/article/10.1007/s11205-015-0903-z</a>
</p>

<hr>
<h2 id='DP_projections_HILS_SWLS_100'>Data for plotting a Dot Product Projection Plot.</h2><span id='topic+DP_projections_HILS_SWLS_100'></span>

<h3>Description</h3>

<p>Tibble is the output from textProjection.
The dataset is a shortened version of the data sets of Study 3-5
from Kjell, Kjell, Garcia and Sikström 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DP_projections_HILS_SWLS_100
</code></pre>


<h3>Format</h3>

<p>A data frame with 583 rows and 12 variables:
</p>

<dl>
<dt>words</dt><dd><p>unique words</p>
</dd>
<dt>dot.x</dt><dd><p>dot product projection on the x-axes</p>
</dd>
<dt>p_values_dot.x</dt><dd><p>p-value for the word in relation to the x-axes</p>
</dd>
<dt>n_g1.x</dt><dd><p>frequency of the word in group 1 on the x-axes variable</p>
</dd>
<dt>n_g2.x</dt><dd><p>frequency of the word in group 2 on the x-axes variable</p>
</dd>
<dt>dot.y</dt><dd><p>dot product projection on the y-axes</p>
</dd>
<dt>p_values_dot.y</dt><dd><p>p-value for the word in relation to the y-axes</p>
</dd>
<dt>n_g1.y</dt><dd><p>frequency of the word in group 1 on the y-axes variable</p>
</dd>
<dt>n_g2.y</dt><dd><p>frequency of the word in group 2 on the x-axes variable</p>
</dd>
<dt>n</dt><dd><p>overall word frequency</p>
</dd>
<dt>n.percent</dt><dd><p>frequency in percent</p>
</dd>
<dt>N_participant_responses</dt><dd><p>number of participants (as this is needed
in the analyses)</p>
</dd>
</dl>


<hr>
<h2 id='find_textrpp_env'>Find text required python packages env</h2><span id='topic+find_textrpp_env'></span>

<h3>Description</h3>

<p>check whether conda/virtual environment for text required python pacakges exists
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_textrpp_env()
</code></pre>

<hr>
<h2 id='Language_based_assessment_data_3_100'>Example text and numeric data.</h2><span id='topic+Language_based_assessment_data_3_100'></span>

<h3>Description</h3>

<p>The dataset is a shortened version of the data sets of Study 3-5
from Kjell, Kjell, Garcia and Sikström 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Language_based_assessment_data_3_100
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows and 4 variables:
</p>

<dl>
<dt>harmonywords</dt><dd><p>Word responses from the harmony in life word question</p>
</dd>
<dt>hilstotal</dt><dd><p>total score of the Harmony In Life Scale</p>
</dd>
<dt>swlstotal</dt><dd><p>total score of the Satisfaction With Life Scale</p>
</dd>
</dl>


<hr>
<h2 id='Language_based_assessment_data_8'>Text and numeric data for 10 participants.</h2><span id='topic+Language_based_assessment_data_8'></span>

<h3>Description</h3>

<p>The dataset is a shortened version of the data sets of Study 3-5
from Kjell et al., (2018; https://psyarxiv.com/er6t7/).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Language_based_assessment_data_8
</code></pre>


<h3>Format</h3>

<p>A data frame with 40 participants and 8 variables:
</p>

<dl>
<dt>harmonywords</dt><dd><p>descriptive words where respondents describe their harmony in life</p>
</dd>
<dt>satisfactionwords</dt><dd><p>descriptive words where respondents describe their satisfaction with life</p>
</dd>
<dt>harmonytexts</dt><dd><p>text where respondents describe their harmony in life</p>
</dd>
<dt>satisfactiontexts</dt><dd><p>text where respondents describe their satisfaction with life</p>
</dd>
<dt>hilstotal</dt><dd><p>total score of the Harmony In Life Scale</p>
</dd>
<dt>swlstotal</dt><dd><p>total score of the Satisfaction With Life Scale</p>
</dd>
<dt>age</dt><dd><p>respondents age in years</p>
</dd>
<dt>gender</dt><dd><p>respondents gender 1=male, 2=female</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/37126041/">https://pubmed.ncbi.nlm.nih.gov/37126041/</a>
</p>

<hr>
<h2 id='PC_projections_satisfactionwords_40'>Example data for plotting a Principle Component Projection Plot.</h2><span id='topic+PC_projections_satisfactionwords_40'></span>

<h3>Description</h3>

<p>The dataset is a shortened version of the data sets of Study 1
from Kjell, et al., 2016.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PC_projections_satisfactionwords_40
</code></pre>


<h3>Format</h3>

<p>A data frame.
</p>

<dl>
<dt>words</dt><dd><p>unique words</p>
</dd>
<dt>n</dt><dd><p>overall word frequency</p>
</dd>
<dt>Dim_PC1</dt><dd><p>Principle component value for dimension 1</p>
</dd>
<dt>Dim_PC2</dt><dd><p>Principle component value for dimension 2</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://link.springer.com/article/10.1007/s11205-015-0903-z">https://link.springer.com/article/10.1007/s11205-015-0903-z</a>
</p>

<hr>
<h2 id='raw_embeddings_1'>Word embeddings from textEmbedRawLayers function</h2><span id='topic+raw_embeddings_1'></span>

<h3>Description</h3>

<p>The dataset is a shortened version of the data sets of Study 3-5
from Kjell, Kjell, Garcia and Sikström 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>raw_embeddings_1
</code></pre>


<h3>Format</h3>

<p>A list with token-level word embeddings for harmony words.
</p>

<dl>
<dt>tokens</dt><dd><p>words</p>
</dd>
<dt>layer_number </dt><dd><p>layer of the transformer model</p>
</dd>
<dt>Dim1:Dim8</dt><dd><p>Word embeddings dimensions</p>
</dd>
</dl>


<hr>
<h2 id='textCentrality'>Semantic similarity score between single words' and an aggregated word embeddings</h2><span id='topic+textCentrality'></span>

<h3>Description</h3>

<p>textCentrality() computes semantic similarity score between single words' word embeddings
and the aggregated word embedding of all words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textCentrality(
  words,
  word_embeddings,
  word_types_embeddings = word_types_embeddings_df,
  method = "cosine",
  aggregation = "mean",
  min_freq_words_test = 0
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textCentrality_+3A_words">words</code></td>
<td>
<p>(character) Word or text variable to be plotted.</p>
</td></tr>
<tr><td><code id="textCentrality_+3A_word_embeddings">word_embeddings</code></td>
<td>
<p>Word embeddings from textEmbed for the words to be plotted
(i.e., the aggregated word embeddings for the &quot;words&quot; variable).</p>
</td></tr>
<tr><td><code id="textCentrality_+3A_word_types_embeddings">word_types_embeddings</code></td>
<td>
<p>Word embeddings from textEmbed for individual words
(i.e., the decontextualized word embeddings).</p>
</td></tr>
<tr><td><code id="textCentrality_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed. Default is &quot;cosine&quot; (see also
&quot;spearmen&quot;, &quot;pearson&quot; as well as measures from textDistance() (which here is computed as 1 - textDistance)
including &quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; and &quot;minkowski&quot;).</p>
</td></tr>
<tr><td><code id="textCentrality_+3A_aggregation">aggregation</code></td>
<td>
<p>(character) Method to aggregate the word embeddings
(default = &quot;mean&quot;; see also &quot;min&quot;, &quot;max&quot; or &quot;[CLS]&quot;).</p>
</td></tr>
<tr><td><code id="textCentrality_+3A_min_freq_words_test">min_freq_words_test</code></td>
<td>
<p>(numeric) Option to select words that have at least occurred a specified
number of times (default = 0); when creating the semantic similarity
scores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with variables (e.g., including semantic similarity, frequencies)
for the individual words that are used as input for the plotting in the textCentralityPlot function.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textCentralityPlot">textCentralityPlot</a></code> and <code><a href="#topic+textProjection">textProjection</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Computes the semantic similarity between the individual word embeddings (Iwe)
# in the "harmonywords" column of the pre-installed dataset: Language_based_assessment_data_8,
# and the aggregated word embedding (Awe).
# The Awe can be interpreted the latent meaning of the text.

## Not run: 
df_for_plotting &lt;- textCentrality(
  words = Language_based_assessment_data_8["harmonywords"],
  word_embeddings = word_embeddings_4$texts$harmonywords,
  word_types_embeddings = word_embeddings_4$word_types
)

# df_for_plotting contain variables (e.g., semantic similarity, frequencies) for
# the individual words that are used for plotting by the textCentralityPlot function.

## End(Not run)
</code></pre>

<hr>
<h2 id='textCentralityPlot'>Plots words from textCentrality()</h2><span id='topic+textCentralityPlot'></span>

<h3>Description</h3>

<p>textCentralityPlot() plots words according to semantic similarity to the aggregated word embedding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textCentralityPlot(
  word_data,
  min_freq_words_test = 1,
  plot_n_word_extreme = 10,
  plot_n_word_frequency = 10,
  plot_n_words_middle = 10,
  titles_color = "#61605e",
  x_axes = "central_semantic_similarity",
  title_top = "Semantic Centrality Plot",
  x_axes_label = "Semantic Centrality",
  scale_x_axes_lim = NULL,
  scale_y_axes_lim = NULL,
  word_font = NULL,
  centrality_color_codes = c("#EAEAEA", "#85DB8E", "#398CF9", "#9e9d9d"),
  word_size_range = c(3, 8),
  position_jitter_hight = 0,
  position_jitter_width = 0.03,
  point_size = 0.5,
  arrow_transparency = 0.1,
  points_without_words_size = 0.5,
  points_without_words_alpha = 0.5,
  legend_title = "SC",
  legend_x_axes_label = "x",
  legend_x_position = 0.02,
  legend_y_position = 0.02,
  legend_h_size = 0.2,
  legend_w_size = 0.2,
  legend_title_size = 7,
  legend_number_size = 2,
  seed = 1007
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textCentralityPlot_+3A_word_data">word_data</code></td>
<td>
<p>Tibble from the textPlot function.</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_min_freq_words_test">min_freq_words_test</code></td>
<td>
<p>Select words to significance test that have occurred
at least min_freq_words_test (default = 1).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_plot_n_word_extreme">plot_n_word_extreme</code></td>
<td>
<p>Number of words per dimension to plot with extreme
Supervised Dimension Projection value (default = 10).
(i.e., even if not significant;  duplicates are removed).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_plot_n_word_frequency">plot_n_word_frequency</code></td>
<td>
<p>Number of words to plot according to their frequency (default = 10).
(i.e., even if not significant).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_plot_n_words_middle">plot_n_words_middle</code></td>
<td>
<p>Number of words to plot that are in the middle in Supervised Dimension
Projection score (default = 10). (i.e., even if not significant; duplicates are removed).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_titles_color">titles_color</code></td>
<td>
<p>Color for all the titles (default: &quot;#61605e&quot;).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_x_axes">x_axes</code></td>
<td>
<p>Variable to be plotted on the x-axes (default: &quot;central_semantic_similarity&quot;,
could also select &quot;n&quot;, &quot;n_percent&quot;).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_title_top">title_top</code></td>
<td>
<p>Title (default: &quot;  &quot;).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_x_axes_label">x_axes_label</code></td>
<td>
<p>Label on the x-axes (default: &quot;Semantic Centrality&quot;).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_scale_x_axes_lim">scale_x_axes_lim</code></td>
<td>
<p>Length of the x-axes (default: NULL, which uses
c(min(word_data$central_semantic_similarity)-0.05, max(word_data$central_semantic_similarity)+0.05);
change this by e.g., try c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_scale_y_axes_lim">scale_y_axes_lim</code></td>
<td>
<p>Length of the y-axes (default: NULL, which uses c(-1, 1);
change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_word_font">word_font</code></td>
<td>
<p>Type of font (default: NULL).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_centrality_color_codes">centrality_color_codes</code></td>
<td>
<p>(HTML color codes. type = character) Colors of the words selected as
plot_n_word_extreme (minimum values), plot_n_words_middle, plot_n_word_extreme (maximum values) and
plot_n_word_frequency; the default is c(&quot;#EAEAEA&quot;, &quot;#85DB8E&quot;, &quot;#398CF9&quot;, &quot;#9e9d9d&quot;, respectively.</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_word_size_range">word_size_range</code></td>
<td>
<p>Vector with minimum and maximum font size (default: c(3, 8)).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_position_jitter_hight">position_jitter_hight</code></td>
<td>
<p>Jitter height (default: .0).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_position_jitter_width">position_jitter_width</code></td>
<td>
<p>Jitter width (default: .03).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_point_size">point_size</code></td>
<td>
<p>Size of the points indicating the words' position (default: 0.5).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_arrow_transparency">arrow_transparency</code></td>
<td>
<p>Transparency of the lines between each word and point (default: 0.1).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_points_without_words_size">points_without_words_size</code></td>
<td>
<p>Size of the points not linked to a word
(default is to not show the point; , i.e., 0).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_points_without_words_alpha">points_without_words_alpha</code></td>
<td>
<p>Transparency of the points that are not linked to a word
(default is to not show it; i.e., 0).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_title">legend_title</code></td>
<td>
<p>Title of the color legend (default: &quot;SCP&quot;).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_x_axes_label">legend_x_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;x&quot;).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_x_position">legend_x_position</code></td>
<td>
<p>Position on the x coordinates of the color legend (default = 0.02).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_y_position">legend_y_position</code></td>
<td>
<p>Position on the y coordinates of the color legend (default = 0.05).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_h_size">legend_h_size</code></td>
<td>
<p>Height of the color legend (default = 0.15).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_w_size">legend_w_size</code></td>
<td>
<p>Width of the color legend (default = 0.15).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_title_size">legend_title_size</code></td>
<td>
<p>Font size of the title (default = 7).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_legend_number_size">legend_number_size</code></td>
<td>
<p>Font size of the values in the legend (default = 2).</p>
</td></tr>
<tr><td><code id="textCentralityPlot_+3A_seed">seed</code></td>
<td>
<p>Set different seed (default = 1007).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1-dimensional word plot based on similarity to the aggregated word embedding,
as well as tibble with processed data used to plot.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textCentrality">textCentrality</a></code> and <code><a href="#topic+textProjection">textProjection</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot a centrality plot from the dataframe df_for_plotting
# that is returned by the textCentrality function.
## Not run: 
textCentralityPlot(
  df_for_plotting,
  min_freq_words_test = 1,
  plot_n_word_extreme = 10,
  plot_n_word_frequency = 10,
  plot_n_words_middle = 10,
  titles_color = "#61605e",
  x_axes = "central_semantic_similarity",
  title_top = "Semantic Centrality Plot",
  x_axes_label = "Semantic Centrality",
  scale_x_axes_lim = NULL,
  scale_y_axes_lim = NULL,
  word_font = NULL,
  centrality_color_codes = c("#EAEAEA", "#85DB8E", "#398CF9", "#9e9d9d"),
  word_size_range = c(3, 8),
  position_jitter_hight = 0,
  position_jitter_width = 0.03,
  point_size = 0.5,
  arrow_transparency = 0.1,
  points_without_words_size = 0.5,
  points_without_words_alpha = 0.5,
  legend_title = "SC",
  legend_x_axes_label = "x",
  legend_x_position = 0.02,
  legend_y_position = 0.02,
  legend_h_size = 0.2,
  legend_w_size = 0.2,
  legend_title_size = 7,
  legend_number_size = 2,
  seed = 1007
)

## End(Not run)

</code></pre>

<hr>
<h2 id='textClean'>Cleans text from standard personal information</h2><span id='topic+textClean'></span>

<h3>Description</h3>

<p>The text is being cleaned from information that may identify them; however, note that
this is not a guarantee for anonymization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textClean(
  text,
  replace = TRUE,
  date = TRUE,
  time = TRUE,
  phone = TRUE,
  email = TRUE,
  ip = TRUE,
  money = TRUE,
  creditcard = TRUE,
  bitcoin = TRUE,
  location = TRUE,
  ssn = TRUE,
  at_symbol = TRUE,
  url = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textClean_+3A_text">text</code></td>
<td>
<p>(character) The text to be cleaned.</p>
</td></tr>
<tr><td><code id="textClean_+3A_replace">replace</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_date">date</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_time">time</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_phone">phone</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_email">email</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_ip">ip</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_money">money</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_creditcard">creditcard</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_bitcoin">bitcoin</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_location">location</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_ssn">ssn</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_at_symbol">at_symbol</code></td>
<td>
<p>(boolean)</p>
</td></tr>
<tr><td><code id="textClean_+3A_url">url</code></td>
<td>
<p>(boolean)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Text cleaned from typical personal identifiable information
</p>

<hr>
<h2 id='textCleanNonASCII'>Clean non-ASCII characters</h2><span id='topic+textCleanNonASCII'></span>

<h3>Description</h3>

<p>textCleanNonASCII() cleans all text entries with a non-ASCII character in a tibble.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textCleanNonASCII(data_tibble)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textCleanNonASCII_+3A_data_tibble">data_tibble</code></td>
<td>
<p>A tibble with character variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble with removed ascii characters
</p>

<hr>
<h2 id='textDescriptives'>Compute descriptive statistics of character variables.</h2><span id='topic+textDescriptives'></span>

<h3>Description</h3>

<p>Compute descriptive statistics of character variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textDescriptives(
  words,
  compute_total = TRUE,
  entropy_unit = "log2",
  na.rm = TRUE,
  locale = "en_US"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textDescriptives_+3A_words">words</code></td>
<td>
<p>One or several character variables; if its a tibble or dataframe,
all the character variables will be selected.</p>
</td></tr>
<tr><td><code id="textDescriptives_+3A_compute_total">compute_total</code></td>
<td>
<p>Boolean. If the input (words) is a tibble/dataframe with
several character variables, a total variable is computed.</p>
</td></tr>
<tr><td><code id="textDescriptives_+3A_entropy_unit">entropy_unit</code></td>
<td>
<p>The unit entropy is measured in. The default is to used bits
(i.e., log2; see also, &quot;log&quot;, &quot;log10&quot;).
If a total score for several varaibles is computed,the text columns are combined using
the dplyr unite function.
For more information about the entropy see the entropy package and specifically
its entropy.plugin function.</p>
</td></tr>
<tr><td><code id="textDescriptives_+3A_na.rm">na.rm</code></td>
<td>
<p>Option to remove NAs when computing mean, median etc (see under return).</p>
</td></tr>
<tr><td><code id="textDescriptives_+3A_locale">locale</code></td>
<td>
<p>(character string) Locale Identifiers for example in US-English ('en_US')
and Australian-English ('en_AU'); see help(about_locale) in the stringi package</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with descriptive statistics, including
variable = the variable names of input &quot;words&quot;;
w_total = total number of words in the variable;
w_mean = mean number of words in each row of the variable;
w_median = median number of words in each row of the variable;
w_range_min = smallest number of words of all rows;
w_range_max = largest number of words of all rows;
w_sd = the standard deviation of the number of words of all rows;
unique_tokens = the unique number of tokens (using the word_tokenize function from python package nltk)
n_token = number of tokens in the variable (using the word_tokenize function from python package nltk)
entropy = the entropy of the variable. It is computed as the Shannon entropy H of a discrete random variable
from the specified bin frequencies. (see library entropy and specifically
the entropy.plugin function)
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textEmbed">textEmbed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textDescriptives(Language_based_assessment_data_8[1:2])

## End(Not run)
</code></pre>

<hr>
<h2 id='textDimName'>Change dimension names</h2><span id='topic+textDimName'></span>

<h3>Description</h3>

<p>textDimName() changes the names of the dimensions in the word embeddings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textDimName(word_embeddings, dim_names = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textDimName_+3A_word_embeddings">word_embeddings</code></td>
<td>
<p>List of word embeddings</p>
</td></tr>
<tr><td><code id="textDimName_+3A_dim_names">dim_names</code></td>
<td>
<p>(boolean) If TRUE the word embedding name will be attached to the name of each dimension;
is FALSE, the attached part of the name will be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Word embeddings with changed names.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textEmbed">textEmbed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Note that dimensions are called Dim1_harmonytexts etc.
word_embeddings_4$texts$harmonytexts
# Here they are changed to just Dim
w_e_T &lt;- textDimName(word_embeddings_4$texts["harmonytexts"],
  dim_names = FALSE
)
# Here they are changed back
w_e_F &lt;- textDimName(w_e_T, dim_names = TRUE)

</code></pre>

<hr>
<h2 id='textDistance'>Semantic distance</h2><span id='topic+textDistance'></span>

<h3>Description</h3>

<p>textDistance() computes the semantic distance between two text variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textDistance(x, y, method = "euclidean", center = FALSE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textDistance_+3A_x">x</code></td>
<td>
<p>Word embeddings (from textEmbed()).</p>
</td></tr>
<tr><td><code id="textDistance_+3A_y">y</code></td>
<td>
<p>Word embeddings (from textEmbed()).</p>
</td></tr>
<tr><td><code id="textDistance_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed; default is
&quot;euclidean&quot; (see also measures from stats:dist() including &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;,
&quot;binary&quot; and &quot;minkowski&quot;. It is also possible to use &quot;cosine&quot;, which computes the cosine distance
(i.e., 1 - cosine(x, y)).</p>
</td></tr>
<tr><td><code id="textDistance_+3A_center">center</code></td>
<td>
<p>(boolean; from base::scale) If center is TRUE then centering is done by subtracting
the embedding mean
(omitting NAs) of x from each of its dimension, and if center is FALSE, no centering is done.</p>
</td></tr>
<tr><td><code id="textDistance_+3A_scale">scale</code></td>
<td>
<p>(boolean; from base::scale) If scale is TRUE then scaling is done by dividing the
(centered) embedding dimensions by the standard deviation of the embedding if center is TRUE,
and the root mean square otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector comprising semantic distance scores.
</p>


<h3>See Also</h3>

<p>See  <code><a href="#topic+textSimilarity">textSimilarity</a></code> and <code><a href="#topic+textSimilarityNorm">textSimilarityNorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the semantic distance score between the embeddings
# from "harmonytext" and "satisfactiontext".

## Not run: 
distance_scores &lt;- textDistance(
  x = word_embeddings_4$texts$harmonytext,
  y = word_embeddings_4$texts$satisfactiontext
)

# Show information about how distance_scores were constructed.

comment(distance_scores)

## End(Not run)
</code></pre>

<hr>
<h2 id='textDistanceMatrix'>Semantic distance across multiple word embeddings</h2><span id='topic+textDistanceMatrix'></span>

<h3>Description</h3>

<p>textDistanceMatrix() computes semantic distance scores between all combinations in a word embedding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textDistanceMatrix(x, method = "euclidean", center = FALSE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textDistanceMatrix_+3A_x">x</code></td>
<td>
<p>Word embeddings (from textEmbed()).</p>
</td></tr>
<tr><td><code id="textDistanceMatrix_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed; default is
&quot;euclidean&quot; (see also measures from stats:dist() including &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;,
&quot;binary&quot; and &quot;minkowski&quot;. It is also possible to use &quot;cosine&quot;, which computes the cosine distance
(i.e., 1 - cosine(x, y)).</p>
</td></tr>
<tr><td><code id="textDistanceMatrix_+3A_center">center</code></td>
<td>
<p>(boolean; from base::scale) If center is TRUE then centering is done by subtracting
the embedding mean
(omitting NAs) of x from each of its dimension, and if center is FALSE, no centering is done.</p>
</td></tr>
<tr><td><code id="textDistanceMatrix_+3A_scale">scale</code></td>
<td>
<p>(boolean; from base::scale) If scale is TRUE then scaling is done by dividing the
(centered) embedding dimensions by the standard deviation of the embedding if center is TRUE,
and the root mean square otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of semantic distance scores
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textDistanceNorm">textDistanceNorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>distance_scores &lt;- textDistanceMatrix(word_embeddings_4$texts$harmonytext[1:3, ])
round(distance_scores, 3)
</code></pre>

<hr>
<h2 id='textDistanceNorm'>Semantic distance between a text variable and a word norm</h2><span id='topic+textDistanceNorm'></span>

<h3>Description</h3>

<p>textDistanceNorm() computes the semantic distance between a text variable and a word norm
(i.e., a text represented by one word embedding that represent a construct/concept).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textDistanceNorm(x, y, method = "euclidean", center = FALSE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textDistanceNorm_+3A_x">x</code></td>
<td>
<p>Word embeddings (from textEmbed()).</p>
</td></tr>
<tr><td><code id="textDistanceNorm_+3A_y">y</code></td>
<td>
<p>Word embedding from textEmbed (from only one text).</p>
</td></tr>
<tr><td><code id="textDistanceNorm_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed; default is
&quot;euclidean&quot; (see also measures from stats:dist() including &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;,
&quot;binary&quot; and &quot;minkowski&quot;. It is also possible to use &quot;cosine&quot;, which computes the cosine distance
(i.e., 1 - cosine(x, y)).</p>
</td></tr>
<tr><td><code id="textDistanceNorm_+3A_center">center</code></td>
<td>
<p>(boolean; from base::scale) If center is TRUE then centering is done by subtracting
the embedding mean
(omitting NAs) of x from each of its dimension, and if center is FALSE, no centering is done.</p>
</td></tr>
<tr><td><code id="textDistanceNorm_+3A_scale">scale</code></td>
<td>
<p>(boolean; from base::scale) If scale is TRUE then scaling is done by dividing the
(centered) embedding dimensions by the standard deviation of the embedding if center is TRUE,
and the root mean square otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector comprising semantic distance scores.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textDistance">textDistance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
library(tibble)
harmonynorm &lt;- c("harmony peace ")
satisfactionnorm &lt;- c("satisfaction achievement")

norms &lt;- tibble::tibble(harmonynorm, satisfactionnorm)
word_embeddings &lt;- word_embeddings_4$texts
word_embeddings_wordnorm &lt;- textEmbed(norms)
similarity_scores &lt;- textDistanceNorm(
  word_embeddings$harmonytext,
  word_embeddings_wordnorm$harmonynorm
)

## End(Not run)
</code></pre>

<hr>
<h2 id='textDomainCompare'>Compare two language domains</h2><span id='topic+textDomainCompare'></span>

<h3>Description</h3>

<p>Compare two language domains
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textDomainCompare(train_language, assess_language)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textDomainCompare_+3A_train_language">train_language</code></td>
<td>
<p>A word-frequency data frame from textTokenizeAndCount</p>
</td></tr>
<tr><td><code id="textDomainCompare_+3A_assess_language">assess_language</code></td>
<td>
<p>A word-frequency data frame from textTokenizeAndCount</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List with similarity scores: overlapp_percentage, test_recall_percentage and cosine_similarity
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textTokenizeAndCount">textTokenizeAndCount</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
train_language &lt;- textTokenizeAndCount(Language_based_assessment_data_8["harmonytexts"])
assess_language &lt;- textTokenizeAndCount(Language_based_assessment_data_8["satisfactiontexts"])
textDomainCompare(train_language, assess_language)

## End(Not run)
</code></pre>

<hr>
<h2 id='textEmbed'>textEmbed() extracts layers and aggregate them to word embeddings, for all character variables in a given dataframe.</h2><span id='topic+textEmbed'></span>

<h3>Description</h3>

<p>textEmbed() extracts layers and aggregate them to word embeddings, for all character variables in a given dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textEmbed(
  texts,
  model = "bert-base-uncased",
  layers = -2,
  dim_name = TRUE,
  aggregation_from_layers_to_tokens = "concatenate",
  aggregation_from_tokens_to_texts = "mean",
  aggregation_from_tokens_to_word_types = NULL,
  keep_token_embeddings = TRUE,
  batch_size = 100,
  remove_non_ascii = TRUE,
  tokens_select = NULL,
  tokens_deselect = NULL,
  decontextualize = FALSE,
  model_max_length = NULL,
  max_token_to_sentence = 4,
  tokenizer_parallelism = FALSE,
  device = "cpu",
  hg_gated = FALSE,
  hg_token = Sys.getenv("HUGGINGFACE_TOKEN", unset = ""),
  logging_level = "error",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textEmbed_+3A_texts">texts</code></td>
<td>
<p>A character variable or a tibble/dataframe with at least one character variable.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_model">model</code></td>
<td>
<p>Character string specifying pre-trained language model (default 'bert-base-uncased').
For full list of options see pretrained models at
<a href="https://huggingface.co/transformers/pretrained_models.html">HuggingFace</a>.
For example use &quot;bert-base-multilingual-cased&quot;, &quot;openai-gpt&quot;,
&quot;gpt2&quot;, &quot;ctrl&quot;, &quot;transfo-xl-wt103&quot;, &quot;xlnet-base-cased&quot;, &quot;xlm-mlm-enfr-1024&quot;, &quot;distilbert-base-cased&quot;,
&quot;roberta-base&quot;, or &quot;xlm-roberta-base&quot;. Only load models that you trust from HuggingFace; loading a
malicious model can execute arbitrary code on your computer).</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_layers">layers</code></td>
<td>
<p>(string or numeric) Specify the layers that should be extracted
(default -2 which give the second to last layer). It is more efficient to only extract the layers
that you need (e.g., 11). You can also extract several (e.g., 11:12), or all by setting this parameter
to &quot;all&quot;. Layer 0 is the decontextualized input layer (i.e., not comprising hidden states) and
thus should normally not be used. These layers can then be aggregated in the textEmbedLayerAggregation
function.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_dim_name">dim_name</code></td>
<td>
<p>(boolean) If TRUE append the variable name after all variable-names in the output.
(This differentiates between word embedding dimension names; e.g., Dim1_text_variable_name).
see <code><a href="#topic+textDimName">textDimName</a></code> to change names back and forth.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_aggregation_from_layers_to_tokens">aggregation_from_layers_to_tokens</code></td>
<td>
<p>(string) Aggregated layers of each token. Method to aggregate the
contextualized layers (e.g., &quot;mean&quot;, &quot;min&quot; or &quot;max, which takes the minimum, maximum or mean, respectively,
across each column; or &quot;concatenate&quot;, which links  together each word embedding layer to one long row.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_aggregation_from_tokens_to_texts">aggregation_from_tokens_to_texts</code></td>
<td>
<p>(string) Method to carry out the aggregation among the word embeddings
for the words/tokens, including &quot;min&quot;, &quot;max&quot; and &quot;mean&quot; which takes the minimum, maximum or mean across each column;
or &quot;concatenate&quot;, which links together each layer of the word embedding to one long row (default = &quot;mean&quot;). If set to NULL, embeddings are not
aggregated.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_aggregation_from_tokens_to_word_types">aggregation_from_tokens_to_word_types</code></td>
<td>
<p>(string) Aggregates to the word type (i.e., the individual words)
rather than texts. If set to &quot;individually&quot;, then duplicate words are not aggregated, (i.e, the context of individual
is preserved). (default = NULL).</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_keep_token_embeddings">keep_token_embeddings</code></td>
<td>
<p>(boolean) Whether to also keep token embeddings when using texts or word
types aggregation.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_batch_size">batch_size</code></td>
<td>
<p>Number of rows in each batch</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_remove_non_ascii">remove_non_ascii</code></td>
<td>
<p>(bolean) TRUE warns and removes non-ascii (using textFindNonASCII()).</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_tokens_select">tokens_select</code></td>
<td>
<p>Option to select word embeddings linked to specific tokens
such as [CLS] and [SEP] for the context embeddings.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_tokens_deselect">tokens_deselect</code></td>
<td>
<p>Option to deselect embeddings linked to specific tokens
such as [CLS] and [SEP] for the context embeddings.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_decontextualize">decontextualize</code></td>
<td>
<p>(boolean) Provide word embeddings of single words as input to the model
(these embeddings are, e.g., used for plotting; default is to use ). If using this, then set
single_context_embeddings to FALSE.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_model_max_length">model_max_length</code></td>
<td>
<p>The maximum length (in number of tokens) for the inputs to the transformer model
(default the value stored for the associated model).</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_max_token_to_sentence">max_token_to_sentence</code></td>
<td>
<p>(numeric) Maximum number of tokens in a string to handle before
switching to embedding text sentence by sentence.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean) If TRUE this will turn on tokenizer parallelism. Default FALSE.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_device">device</code></td>
<td>
<p>Name of device to use: 'cpu', 'gpu', 'gpu:k' or 'mps'/'mps:k' for MacOS, where k is a
specific device number such as 'mps:1'.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_hg_gated">hg_gated</code></td>
<td>
<p>Set to TRUE if the accessed model is gated.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_hg_token">hg_token</code></td>
<td>
<p>The token needed to access the gated model.
Create a token from the ['Settings' page](https://huggingface.co/settings/tokens) of
the Hugging Face website. An an environment variable HUGGINGFACE_TOKEN can
be set to avoid the need to enter the token each time.</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_logging_level">logging_level</code></td>
<td>
<p>Set the logging level. Default: &quot;warning&quot;.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textEmbed_+3A_...">...</code></td>
<td>
<p>settings from textEmbedRawLayers().</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with tokens, a column for layer identifier and word embeddings.
Note that layer 0 is the input embedding to the transformer.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textEmbedLayerAggregation">textEmbedLayerAggregation</a></code>, <code><a href="#topic+textEmbedRawLayers">textEmbedRawLayers</a></code> and
<code><a href="#topic+textDimName">textDimName</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Automatically transforms the characters in the example dataset:
# Language_based_assessment_data_8 (included in text-package), to embeddings.
## Not run: 
word_embeddings &lt;- textEmbed(Language_based_assessment_data_8[1:2, 1:2],
  layers = 10:11,
  aggregation_from_layers_to_tokens = "concatenate",
  aggregation_from_tokens_to_texts = "mean",
  aggregation_from_tokens_to_word_types = "mean"
)

# Show information about how the embeddings were constructed.
comment(word_embeddings$texts$satisfactiontexts)
comment(word_embeddings$word_types)
comment(word_embeddings$tokens$satisfactiontexts)

# See how the word embeddings are structured.
word_embeddings

# Save the word embeddings to avoid having to embed the text again.
saveRDS(word_embeddings, "word_embeddings.rds")

# Retrieve the saved word embeddings.
word_embeddings &lt;- readRDS("word_embeddings.rds")

## End(Not run)

</code></pre>

<hr>
<h2 id='textEmbedLayerAggregation'>Aggregate layers</h2><span id='topic+textEmbedLayerAggregation'></span>

<h3>Description</h3>

<p>textEmbedLayerAggregation selects and aggregates layers of hidden states to form a word embedding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textEmbedLayerAggregation(
  word_embeddings_layers,
  layers = "all",
  aggregation_from_layers_to_tokens = "concatenate",
  aggregation_from_tokens_to_texts = "mean",
  return_tokens = FALSE,
  tokens_select = NULL,
  tokens_deselect = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textEmbedLayerAggregation_+3A_word_embeddings_layers">word_embeddings_layers</code></td>
<td>
<p>Layers returned by the textEmbedRawLayers function.</p>
</td></tr>
<tr><td><code id="textEmbedLayerAggregation_+3A_layers">layers</code></td>
<td>
<p>(character or numeric) The numbers of the layers to be aggregated
(e.g., c(11:12) to aggregate the eleventh and twelfth).
Note that layer 0 is the input embedding to the transformer, and should normally not be used.
Selecting 'all' thus removes layer 0 (default = &quot;all&quot;)</p>
</td></tr>
<tr><td><code id="textEmbedLayerAggregation_+3A_aggregation_from_layers_to_tokens">aggregation_from_layers_to_tokens</code></td>
<td>
<p>(character) Method to carry out the aggregation among
the layers for each word/token, including &quot;min&quot;, &quot;max&quot; and &quot;mean&quot; which takes the minimum,
maximum or mean across each column; or &quot;concatenate&quot;, which links together each layer of the
word embedding to one long row (default = &quot;concatenate&quot;).</p>
</td></tr>
<tr><td><code id="textEmbedLayerAggregation_+3A_aggregation_from_tokens_to_texts">aggregation_from_tokens_to_texts</code></td>
<td>
<p>(character) Method to carry out the aggregation among the word embeddings
for the words/tokens, including &quot;min&quot;, &quot;max&quot; and &quot;mean&quot; which takes the minimum, maximum or mean across each column;
or &quot;concatenate&quot;, which links together each layer of the word embedding to one long row (default = &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="textEmbedLayerAggregation_+3A_return_tokens">return_tokens</code></td>
<td>
<p>(boolean) If TRUE, provide the tokens used in the specified transformer model (default = FALSE).</p>
</td></tr>
<tr><td><code id="textEmbedLayerAggregation_+3A_tokens_select">tokens_select</code></td>
<td>
<p>(character) Option to only select embeddings linked to specific tokens
in the textEmbedLayerAggregation() phase such as &quot;[CLS]&quot; and &quot;[SEP]&quot; (default NULL).</p>
</td></tr>
<tr><td><code id="textEmbedLayerAggregation_+3A_tokens_deselect">tokens_deselect</code></td>
<td>
<p>(character) Option to deselect embeddings linked to specific tokens in
the textEmbedLayerAggregation() phase such as &quot;[CLS]&quot; and &quot;[SEP]&quot; (default NULL).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with word embeddings. Note that layer 0 is the input embedding to
the transformer, which is normally not used.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textEmbedRawLayers">textEmbedRawLayers</a></code> and <code><a href="#topic+textEmbed">textEmbed</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Aggregate the hidden states from textEmbedRawLayers
# to create a word embedding representing the entire text.
# This is achieved by concatenating layer 11 and 12.
## Not run: 
word_embedding &lt;- textEmbedLayerAggregation(
  imf_embeddings_11_12$context_tokens,
  layers = 11:12,
  aggregation_from_layers_to_tokens = "concatenate",
  aggregation_from_tokens_to_texts = "mean"
)

# Examine word_embedding
word_embedding

## End(Not run)
</code></pre>

<hr>
<h2 id='textEmbedRawLayers'>Extract layers of hidden states</h2><span id='topic+textEmbedRawLayers'></span>

<h3>Description</h3>

<p>textEmbedRawLayers extracts layers of hidden states (word embeddings) for all character variables
in a given dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textEmbedRawLayers(
  texts,
  model = "bert-base-uncased",
  layers = -2,
  return_tokens = TRUE,
  word_type_embeddings = FALSE,
  decontextualize = FALSE,
  keep_token_embeddings = TRUE,
  device = "cpu",
  tokenizer_parallelism = FALSE,
  model_max_length = NULL,
  max_token_to_sentence = 4,
  hg_gated = FALSE,
  hg_token = Sys.getenv("HUGGINGFACE_TOKEN", unset = ""),
  trust_remote_code = FALSE,
  logging_level = "error",
  sort = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textEmbedRawLayers_+3A_texts">texts</code></td>
<td>
<p>A character variable or a tibble with at least one character variable.</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_model">model</code></td>
<td>
<p>(character) Character string specifying pre-trained language model
(default = 'bert-base-uncased'). For full list of options see pretrained models at
<a href="https://huggingface.co/transformers/pretrained_models.html">HuggingFace</a>.
For example use &quot;bert-base-multilingual-cased&quot;, &quot;openai-gpt&quot;,
&quot;gpt2&quot;, &quot;ctrl&quot;, &quot;transfo-xl-wt103&quot;, &quot;xlnet-base-cased&quot;, &quot;xlm-mlm-enfr-1024&quot;,
&quot;distilbert-base-cased&quot;, &quot;roberta-base&quot;, or &quot;xlm-roberta-base&quot;. Only load models that
you trust from HuggingFace; loading a malicious model can execute arbitrary code on
your computer).</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_layers">layers</code></td>
<td>
<p>(character or numeric) Specify the layers that should be extracted
(default -2, which give the second to last layer). It is more efficient to only extract the
layers that you need (e.g., 11). You can also extract several (e.g., 11:12),
or all by setting this parameter to &quot;all&quot;. Layer 0 is the decontextualized input layer
(i.e., not comprising hidden states) and thus should normally not be used. These layers can then
be aggregated in the textEmbedLayerAggregation function.</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_return_tokens">return_tokens</code></td>
<td>
<p>(boolean) If TRUE, provide the tokens used in the specified transformer
model. (default = TRUE)</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_word_type_embeddings">word_type_embeddings</code></td>
<td>
<p>(boolean) Wether to provide embeddings for each word/token type.
(default = FALSE)</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_decontextualize">decontextualize</code></td>
<td>
<p>(boolean) Wether to dectonextualise embeddings (i.e., embedding one word
at a time). (default = TRUE)</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_keep_token_embeddings">keep_token_embeddings</code></td>
<td>
<p>(boolean) Whether to keep token level embeddings in the output
(when using word_types aggregation). (default= TRUE)</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_device">device</code></td>
<td>
<p>(character) Name of device to use: 'cpu', 'gpu', 'gpu:k' or 'mps'/'mps:k'
for MacOS, where k is a specific device number. (default = &quot;cpu&quot;)</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean) If TRUE this will turn on tokenizer parallelism.
(default = FALSE).</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_model_max_length">model_max_length</code></td>
<td>
<p>The maximum length (in number of tokens) for the inputs to the
transformer model (default the value stored for the associated model).</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_max_token_to_sentence">max_token_to_sentence</code></td>
<td>
<p>(numeric) Maximum number of tokens in a string to handle before
switching to embedding text sentence by sentence. (default= 4)</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_hg_gated">hg_gated</code></td>
<td>
<p>Set to TRUE if the accessed model is gated.</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_hg_token">hg_token</code></td>
<td>
<p>The token needed to access the gated model.
Create a token from the ['Settings' page](https://huggingface.co/settings/tokens) of
the Hugging Face website. An an environment variable HUGGINGFACE_TOKEN can
be set to avoid the need to enter the token each time.</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_trust_remote_code">trust_remote_code</code></td>
<td>
<p>use a model with custom code on the Huggingface Hub</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_logging_level">logging_level</code></td>
<td>
<p>(character) Set the logging level. (default =&quot;error&quot;)
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textEmbedRawLayers_+3A_sort">sort</code></td>
<td>
<p>(boolean) If TRUE sort the output to tidy format. (default = TRUE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The textEmbedRawLayers() takes text as input, and returns the hidden states for
each token of the text, including the [CLS] and the [SEP].
Note that layer 0 is the input embedding to the transformer, and should normally not be used.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textEmbedLayerAggregation">textEmbedLayerAggregation</a></code> and <code><a href="#topic+textEmbed">textEmbed</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Get hidden states of layer 11 and 12 for "I am fine".
## Not run: 
imf_embeddings_11_12 &lt;- textEmbedRawLayers(
  "I am fine",
  layers = 11:12
)

# Show hidden states of layer 11 and 12.
imf_embeddings_11_12

## End(Not run)
</code></pre>

<hr>
<h2 id='textEmbedReduce'>Pre-trained dimension reduction (experimental)</h2><span id='topic+textEmbedReduce'></span>

<h3>Description</h3>

<p>Pre-trained dimension reduction (experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textEmbedReduce(
  embeddings,
  n_dim = NULL,
  scalar = "fb20/scalar.csv",
  pca = "fb20/rpca_roberta_768_D_20.csv"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textEmbedReduce_+3A_embeddings">embeddings</code></td>
<td>
<p>(list) Embedding(s) - including, tokens, texts and/or word_types.</p>
</td></tr>
<tr><td><code id="textEmbedReduce_+3A_n_dim">n_dim</code></td>
<td>
<p>(numeric) Number of dimensions to reduce to.</p>
</td></tr>
<tr><td><code id="textEmbedReduce_+3A_scalar">scalar</code></td>
<td>
<p>(string or matrix) Name or URL to scalar for standardizing the embeddings. If a URL, the function
first examines whether it has been downloaded before. The string should be to a csv file containing a matrix with
the pca weights for matrix multiplication. For more information see reference below.</p>
</td></tr>
<tr><td><code id="textEmbedReduce_+3A_pca">pca</code></td>
<td>
<p>(string or matrix) Name or URL to pca weights. If a URL, the function first examines whether it has been
downlaoded before. The string should be to a csv file containing a matrix. For more information see reference below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To use this method please see and cite:<br />
Ganesan, A. V., Matero, M., Ravula, A. R., Vu, H., &amp; Schwartz, H. A. (2021, June).
Empirical evaluation of pre-trained transformers for human-level nlp: The role of sample size and dimensionality.
In Proceedings of the conference. Association for Computational Linguistics. North American Chapter. Meeting
(Vol. 2021, p. 4515).
NIH Public Access.<br /><br />
See <a href="https://adithya8.github.io/blog/paper/2021/04/15/Empirical-Evaluation.html">Git-Hub Empirical-Evaluation</a>
</p>


<h3>Value</h3>

<p>Returns embeddings with reduced number of dimensions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+textEmbed">textEmbed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
embeddings &lt;- textEmbedReduce(word_embeddings_4$texts)

## End(Not run)
</code></pre>

<hr>
<h2 id='textEmbedStatic'>Apply static word embeddings</h2><span id='topic+textEmbedStatic'></span>

<h3>Description</h3>

<p>textEmbedStatic() applies word embeddings from a given decontextualized static space (such as
from Latent Semantic Analyses) to all character variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textEmbedStatic(
  df,
  space,
  tk_df = "null",
  aggregation_from_tokens_to_texts = "mean",
  dim_name = FALSE,
  tolower = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textEmbedStatic_+3A_df">df</code></td>
<td>
<p>dataframe that at least contains one character column.</p>
</td></tr>
<tr><td><code id="textEmbedStatic_+3A_space">space</code></td>
<td>
<p>decontextualized/static space with a column called &quot;words&quot; and the semantic
representations are in columns called Dim1, Dim2 (or V1, V2, ...) and so on (from textSpace,
which is not included in the current text package).</p>
</td></tr>
<tr><td><code id="textEmbedStatic_+3A_tk_df">tk_df</code></td>
<td>
<p>default &quot;null&quot;; option to use either the &quot;tk&quot; of &quot;df&quot; space (if using textSpace, which has
not been implemented yet).</p>
</td></tr>
<tr><td><code id="textEmbedStatic_+3A_aggregation_from_tokens_to_texts">aggregation_from_tokens_to_texts</code></td>
<td>
<p>method to aggregate semantic representation when their
are more than a single word. (default is &quot;mean&quot;; see also &quot;min&quot; and &quot;max&quot;, &quot;concatenate&quot; and &quot;normalize&quot;)</p>
</td></tr>
<tr><td><code id="textEmbedStatic_+3A_dim_name">dim_name</code></td>
<td>
<p>Boolean, if TRUE append the variable name after all variable-names in the output.
(This differentiates between word embedding dimension names; e.g., Dim1_text_variable_name)</p>
</td></tr>
<tr><td><code id="textEmbedStatic_+3A_tolower">tolower</code></td>
<td>
<p>(boolean) Lower case input.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with tibbles for each character variable. Each tibble comprises a column with the text, followed by
columns representing the semantic representations of the text.
The tibbles are called the same as the original variable.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textEmbed">textEmbed</a></code>
</p>

<hr>
<h2 id='textFindNonASCII'>Detect non-ASCII characters</h2><span id='topic+textFindNonASCII'></span>

<h3>Description</h3>

<p>This function to detect non-ASCII characters in a tibble with multiple columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textFindNonASCII(data_tibble)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textFindNonASCII_+3A_data_tibble">data_tibble</code></td>
<td>
<p>A character variable or a tibble including  character variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a tibble containing variable names, row numbers and text including non-acii.
</p>

<hr>
<h2 id='textFineTuneDomain'>Domain Adapted Pre-Training (EXPERIMENTAL - under development)</h2><span id='topic+textFineTuneDomain'></span>

<h3>Description</h3>

<p>Domain Adapted Pre-Training (EXPERIMENTAL - under development)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textFineTuneDomain(
  text_data,
  model_name_or_path = "bert-base-uncased",
  output_dir = "./runs",
  validation_proportion = 0.1,
  evaluation_proportion = 0.1,
  config_name = NULL,
  tokenizer_name = NULL,
  max_seq_length = 128L,
  evaluation_strategy = "epoch",
  eval_accumulation_steps = NULL,
  num_train_epochs = 3,
  past_index = -1,
  set_seed = 2022,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textFineTuneDomain_+3A_text_data">text_data</code></td>
<td>
<p>A dataframe, where the first column contain text data,
and the second column the to-be-predicted variable (numeric or categorical).</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_model_name_or_path">model_name_or_path</code></td>
<td>
<p>(string) Path to foundation/pretrained model or model identifier from huggingface.co/models</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_output_dir">output_dir</code></td>
<td>
<p>(string) Path to the output directory.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_validation_proportion">validation_proportion</code></td>
<td>
<p>(Numeric) Proportion of the text_data to be used for validation.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_evaluation_proportion">evaluation_proportion</code></td>
<td>
<p>(Numeric) Proportion of the text_data to be used for evaluation.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_config_name">config_name</code></td>
<td>
<p>(String) Pretrained config name or path if not the same as model_name.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_tokenizer_name">tokenizer_name</code></td>
<td>
<p>(String) Pretrained tokenizer name or path if not the same as model_name</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_max_seq_length">max_seq_length</code></td>
<td>
<p>(Numeric) The maximum total input sequence length after tokenization. Sequences longer
than this will be truncated, sequences shorter will be padded.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_evaluation_strategy">evaluation_strategy</code></td>
<td>
<p>(String or IntervalStrategy) — The evaluation strategy to adopt during training.
Possible values are:
&quot;no&quot;: No evaluation is done during training.
&quot;steps&quot;: Evaluation is done (and logged) every eval_steps.
&quot;epoch&quot;: Evaluation is done at the end of each epoch.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_eval_accumulation_steps">eval_accumulation_steps</code></td>
<td>
<p>(Integer) Number of predictions steps to accumulate the output tensors for,
before moving the results to the CPU. If left unset, the whole predictions are accumulated on GPU/TPU
before being moved to the CPU (faster but requires more memory).</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_num_train_epochs">num_train_epochs</code></td>
<td>
<p>(Numeric) Total number of training epochs to perform
(if not an integer, will perform the decimal part percents of the last epoch before stopping training).</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_past_index">past_index</code></td>
<td>
<p>(Numeric, defaults to -1) Some models like TransformerXL or XLNet can make use of the
past hidden states for their predictions. If this argument is set to a positive int, the Trainer will use
the corresponding output (usually index 2) as the past state and feed it to the model at the next
training step under the keyword argument mems.</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_set_seed">set_seed</code></td>
<td>
<p>(Numeric) Set the seed</p>
</td></tr>
<tr><td><code id="textFineTuneDomain_+3A_...">...</code></td>
<td>
<p>Parameters related to the fine tuning, which can be seen in the text-package file inst/python/arg2.json.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Information about more parameters see inst/python/args2.json
(https://github.com/OscarKjell/text/tree/master/inst/python/args2.json).
Descriptions of settings can be found in inst/python/task_finetune.py under
&quot;class ModelArguments&quot; and &quot;class DataTrainingArguments&quot; as well as
online at https://huggingface.co/docs/transformers/main_classes/trainer.
</p>


<h3>Value</h3>

<p>A folder containing the pretrained model and output data. The model can then be used, for example, by
textEmbed() by providing the model parameter with a the path to the output folder.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textEmbed">textEmbed</a></code>, <code><a href="#topic+textEmbed">textEmbed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textFineTuneDomain(text_data)

## End(Not run)
</code></pre>

<hr>
<h2 id='textFineTuneTask'>Task Adapted Pre-Training (EXPERIMENTAL - under development)</h2><span id='topic+textFineTuneTask'></span>

<h3>Description</h3>

<p>Task Adapted Pre-Training (EXPERIMENTAL - under development)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textFineTuneTask(
  text_outcome_data,
  model_name_or_path = "bert-base-uncased",
  output_dir = "./runs",
  validation_proportion = 0.1,
  evaluation_proportion = 0.1,
  is_regression = TRUE,
  config_name = NULL,
  tokenizer_name = NULL,
  max_seq_length = 128L,
  evaluation_strategy = "epoch",
  eval_accumulation_steps = NULL,
  num_train_epochs = 3,
  past_index = -1,
  set_seed = 2022,
  label_names = NULL,
  pytorch_mps_high_watermark_ratio = FALSE,
  tokenizer_parallelism = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textFineTuneTask_+3A_text_outcome_data">text_outcome_data</code></td>
<td>
<p>A dataframe, where the first column contain text data,
and the second column the to-be-predicted variable (numeric or categorical).</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_model_name_or_path">model_name_or_path</code></td>
<td>
<p>(string) Path to foundation/pretrained model or model identifier from huggingface.co/models</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_output_dir">output_dir</code></td>
<td>
<p>(string) Path to the output directory.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_validation_proportion">validation_proportion</code></td>
<td>
<p>(Numeric) Proportion of the text_outcome_data to be used for validation.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_evaluation_proportion">evaluation_proportion</code></td>
<td>
<p>(Numeric) Proportion of the text_outcome_data to be used for evaluation.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_is_regression">is_regression</code></td>
<td>
<p>(Boolean) TRUE for regression tasks, FALSE for classification.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_config_name">config_name</code></td>
<td>
<p>(String) Pretrained config name or path if not the same as model_name.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_tokenizer_name">tokenizer_name</code></td>
<td>
<p>(String) Pretrained tokenizer name or path if not the same as model_name</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_max_seq_length">max_seq_length</code></td>
<td>
<p>(Numeric) The maximum total input sequence length after tokenization. Sequences longer
than this will be truncated, sequences shorter will be padded.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_evaluation_strategy">evaluation_strategy</code></td>
<td>
<p>(String or IntervalStrategy) — The evaluation strategy to adopt during training.
Possible values are:
&quot;no&quot;: No evaluation is done during training.
&quot;steps&quot;: Evaluation is done (and logged) every eval_steps.
&quot;epoch&quot;: Evaluation is done at the end of each epoch.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_eval_accumulation_steps">eval_accumulation_steps</code></td>
<td>
<p>(Integer) Number of predictions steps to accumulate the output tensors for,
before moving the results to the CPU. If left unset, the whole predictions are accumulated on GPU/TPU
before being moved to the CPU (faster but requires more memory).</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_num_train_epochs">num_train_epochs</code></td>
<td>
<p>(Numeric) Total number of training epochs to perform
(if not an integer, will perform the decimal part percents of the last epoch before stopping training).</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_past_index">past_index</code></td>
<td>
<p>(Numeric, defaults to -1) Some models like TransformerXL or XLNet can make use of
the past hidden states for their predictions. If this argument is set to a positive int, the Trainer
will use the corresponding output (usually index 2) as the past state and feed it to the model at
the next training step under the keyword argument mems.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_set_seed">set_seed</code></td>
<td>
<p>(Numeric) Set the seed</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_label_names">label_names</code></td>
<td>
<p>label name in case of classification; e.g., label_names = c(&quot;female&quot;, &quot;male&quot;).</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_pytorch_mps_high_watermark_ratio">pytorch_mps_high_watermark_ratio</code></td>
<td>
<p>Set to TRUE to solve error
RuntimeError: MPS backend out of memory.Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for
memory allocations (may cause system failure). Monitor System Resources: If you decide to adjust this setting,
closely monitor your system's resource usage to ensure it does not become unstable.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean) If TRUE this will turn on tokenizer parallelism. Default FALSE.</p>
</td></tr>
<tr><td><code id="textFineTuneTask_+3A_...">...</code></td>
<td>
<p>Parameters related to the fine tuning, which can be seen in the text-package file inst/python/arg2.json.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Information about more parameters see inst/python/args2.json
(https://github.com/OscarKjell/text/tree/master/inst/python/args2.json).
Descriptions of settings can be found in inst/python/task_finetune.py under
&quot;class ModelArguments&quot; and &quot;class DataTrainingArguments&quot; as well as
online at https://huggingface.co/docs/transformers/main_classes/trainer.
</p>


<h3>Value</h3>

<p>A folder containing the pretrained model and output data. The model can then be used, for example, by
textEmbed() by providing the model parameter with a the path to the output folder.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textEmbed">textEmbed</a></code>, <code><a href="#topic+textEmbed">textEmbed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textFineTuneTask(text_outcome_data)

## End(Not run)
</code></pre>

<hr>
<h2 id='textGeneration'>Text generation</h2><span id='topic+textGeneration'></span>

<h3>Description</h3>

<p>textGeneration() predicts the words that will follow a specified text prompt. (experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textGeneration(
  x,
  model = "gpt2",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  max_length = NULL,
  max_new_tokens = 20,
  min_length = 0,
  min_new_tokens = NULL,
  logging_level = "warning",
  force_return_results = FALSE,
  return_tensors = FALSE,
  return_full_text = TRUE,
  clean_up_tokenization_spaces = FALSE,
  prefix = "",
  handle_long_generation = NULL,
  set_seed = 202208L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textGeneration_+3A_x">x</code></td>
<td>
<p>(string)  A variable or a tibble/dataframe with at least one character variable.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_model">model</code></td>
<td>
<p>(string)  Specification of a pre-trained language model that have been trained with an
autoregressive language modeling objective, which includes the uni-directional models (e.g., gpt2).</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_device">device</code></td>
<td>
<p>(string)  Device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_max_length">max_length</code></td>
<td>
<p>(Integer)  The maximum length the generated tokens can have. Corresponds to the length of the input prompt + 'max_new_tokens'. Its effect is overridden by 'max_new_tokens', if also set. Defaults to NULL.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_max_new_tokens">max_new_tokens</code></td>
<td>
<p>(Integer)  The maximum numbers of tokens to generate, ignoring the number of tokens in the prompt. The default value is 20.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_min_length">min_length</code></td>
<td>
<p>(Integer)  The minimum length of the sequence to be generated. Corresponds to the length of the input prompt + 'min_new_tokens'. Its effect is overridden by 'min_new_tokens', if also set. The default value is 0.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_min_new_tokens">min_new_tokens</code></td>
<td>
<p>(Integer)  The minimum numbers of tokens to generate, ignoring the number of tokens in the prompt. Default is NULL.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_logging_level">logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot;
and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_return_tensors">return_tensors</code></td>
<td>
<p>(boolean)  Whether or not the output should include the prediction tensors (as token indices).</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_return_full_text">return_full_text</code></td>
<td>
<p>(boolean) If FALSE only the added text is returned, otherwise the full text is returned.
(This setting is only meaningful if return_text is set to TRUE)</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_clean_up_tokenization_spaces">clean_up_tokenization_spaces</code></td>
<td>
<p>(boolean)  Option to clean up the potential extra spaces in the returned text.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_prefix">prefix</code></td>
<td>
<p>(string) Option to add a prefix to prompt.</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_handle_long_generation">handle_long_generation</code></td>
<td>
<p>By default, this function does not handle long generation
(those that exceed the model maximum length).</p>
</td></tr>
<tr><td><code id="textGeneration_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer) Set seed.
(more info :https://github.com/huggingface/transformers/issues/14033#issuecomment-948385227).
This setting provides some ways to work around the problem:
None: default way, where no particular strategy is applied.
&quot;hole&quot;: Truncates left of input, and leaves a gap that is wide enough to let generation happen.
(this might truncate a lot of the prompt and not suitable when generation exceed the model capacity)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with generated text.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textClassify">textClassify</a></code>, <code><a href="#topic+textNER">textNER</a></code>,
<code><a href="#topic+textSum">textSum</a></code>, <code><a href="#topic+textQA">textQA</a></code>, <code><a href="#topic+textTranslate">textTranslate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# generated_text &lt;- textGeneration("The meaning of life is")
# generated_text

</code></pre>

<hr>
<h2 id='textLBAM'>The LBAM library</h2><span id='topic+textLBAM'></span>

<h3>Description</h3>

<p>Retrieve the Language-Based Assessment Models library (LBAM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textLBAM(columns = NULL, lbam_update = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textLBAM_+3A_columns">columns</code></td>
<td>
<p>(string) Select which columns to retrieve e.g., c(&quot;Name&quot;, &quot;Path&quot;)</p>
</td></tr>
<tr><td><code id="textLBAM_+3A_lbam_update">lbam_update</code></td>
<td>
<p>(boolean) TRUE downloads a new copy of the LBAM file</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Data frame containing information about the Language-based assessment models library (LBAM).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
test_lbam &lt;- textLBAM(
  lbam_update = TRUE
)
subset(
  lbam,
  substr(Construct_Concept_Behaviours, 1, 3) == "Dep",
  select = c(Construct_Concept_Behaviours, Name)
)


## End(Not run)
</code></pre>

<hr>
<h2 id='textModelLayers'>Number of layers</h2><span id='topic+textModelLayers'></span>

<h3>Description</h3>

<p>This functions gets the number of layers in a given model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textModelLayers(
  target_model,
  hg_gated = FALSE,
  hg_token = Sys.getenv("HUGGINGFACE_TOKEN", unset = ""),
  trust_remote_code = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textModelLayers_+3A_target_model">target_model</code></td>
<td>
<p>(string) The name of the model to know the number of layers of.</p>
</td></tr>
<tr><td><code id="textModelLayers_+3A_hg_gated">hg_gated</code></td>
<td>
<p>Set to TRUE if the accessed model is gated.</p>
</td></tr>
<tr><td><code id="textModelLayers_+3A_hg_token">hg_token</code></td>
<td>
<p>The token needed to access the gated model.
Create a token from the ['Settings' page](https://huggingface.co/settings/tokens) of
the Hugging Face website. An an environment variable HUGGINGFACE_TOKEN can
be set to avoid the need to enter the token each time.</p>
</td></tr>
<tr><td><code id="textModelLayers_+3A_trust_remote_code">trust_remote_code</code></td>
<td>
<p>use a model with custom code on the Huggingface Hub</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Number of layers.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textModels">textModels</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textModelLayers(target_model = "bert-base-uncased")

## End(Not run)
</code></pre>

<hr>
<h2 id='textModels'>Check downloaded, available models.</h2><span id='topic+textModels'></span>

<h3>Description</h3>

<p>Check downloaded, available models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textModels()
</code></pre>


<h3>Value</h3>

<p>List of names of models and tokenizers
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textModelsRemove">textModelsRemove</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textModels()

## End(Not run)
</code></pre>

<hr>
<h2 id='textModelsRemove'>Delete a specified model</h2><span id='topic+textModelsRemove'></span>

<h3>Description</h3>

<p>This functions delete specified mode and associated files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textModelsRemove(target_model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textModelsRemove_+3A_target_model">target_model</code></td>
<td>
<p>(string) The name of the model to be deleted.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Confirmation whether the model has been deleted.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textModels">textModels</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textModelsRemove("name-of-model-to-delete")

## End(Not run)
</code></pre>

<hr>
<h2 id='textNER'>Named Entity Recognition. (experimental)</h2><span id='topic+textNER'></span>

<h3>Description</h3>

<p>Named Entity Recognition. (experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textNER(
  x,
  model = "dslim/bert-base-NER",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "error",
  force_return_results = FALSE,
  set_seed = 202208L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textNER_+3A_x">x</code></td>
<td>
<p>(string)  A  variable or a tibble/dataframe with at least one character variable.</p>
</td></tr>
<tr><td><code id="textNER_+3A_model">model</code></td>
<td>
<p>(string)  Specification of a pre-trained language model for token classification
that have been fine-tuned on a NER task (e.g., see &quot;dslim/bert-base-NER&quot;).
Use for predicting the classes of tokens in a sequence: person, organisation, location or miscellaneous).</p>
</td></tr>
<tr><td><code id="textNER_+3A_device">device</code></td>
<td>
<p>(string)  Device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number</p>
</td></tr>
<tr><td><code id="textNER_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textNER_+3A_logging_level">logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textNER_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot;
and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textNER_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer) Set seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with tibble(s) with NER classifications for each column.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textClassify">textClassify</a></code>, <code><a href="#topic+textGeneration">textGeneration</a></code>, <code><a href="#topic+textNER">textNER</a></code>,
<code><a href="#topic+textSum">textSum</a></code>, <code><a href="#topic+textQA">textQA</a></code>, <code><a href="#topic+textTranslate">textTranslate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ner_example &lt;- textNER("Arnes plays football with Daniel")
# ner_example

</code></pre>

<hr>
<h2 id='textPCA'>textPCA()</h2><span id='topic+textPCA'></span>

<h3>Description</h3>

<p>textPCA() computes 2 PCA dimensions of the word embeddings for individual words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textPCA(
  words,
  word_types_embeddings = word_types_embeddings_df,
  to_lower_case = TRUE,
  seed = 1010
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textPCA_+3A_words">words</code></td>
<td>
<p>Word or text variable to be plotted.</p>
</td></tr>
<tr><td><code id="textPCA_+3A_word_types_embeddings">word_types_embeddings</code></td>
<td>
<p>Word embeddings from textEmbed for individual words
(i.e., decontextualized embeddings).</p>
</td></tr>
<tr><td><code id="textPCA_+3A_to_lower_case">to_lower_case</code></td>
<td>
<p>Lower case words</p>
</td></tr>
<tr><td><code id="textPCA_+3A_seed">seed</code></td>
<td>
<p>Set different seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with words, their frquency and two PCA dimensions from the word_embeddings
for the individual words that is used for the plotting in the textPCAPlot function.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textPCAPlot">textPCAPlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Data
df_for_plotting2d &lt;- textPCA(
  words = Language_based_assessment_data_8$harmonywords,
  word_types_embeddings = word_embeddings_4$word_types
)
df_for_plotting2d

## End(Not run)
</code></pre>

<hr>
<h2 id='textPCAPlot'>textPCAPlot</h2><span id='topic+textPCAPlot'></span>

<h3>Description</h3>

<p>textPCAPlot() plots words according to 2-D plot from 2 PCA components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textPCAPlot(
  word_data,
  min_freq_words_test = 1,
  plot_n_word_extreme = 5,
  plot_n_word_frequency = 5,
  plot_n_words_middle = 5,
  titles_color = "#61605e",
  title_top = "Principal Component (PC) Plot",
  x_axes_label = "PC1",
  y_axes_label = "PC2",
  scale_x_axes_lim = NULL,
  scale_y_axes_lim = NULL,
  word_font = NULL,
  bivariate_color_codes = c("#398CF9", "#60A1F7", "#5dc688", "#e07f6a", "#EAEAEA",
    "#40DD52", "#FF0000", "#EA7467", "#85DB8E"),
  word_size_range = c(3, 8),
  position_jitter_hight = 0,
  position_jitter_width = 0.03,
  point_size = 0.5,
  arrow_transparency = 0.1,
  points_without_words_size = 0.2,
  points_without_words_alpha = 0.2,
  legend_title = "PC",
  legend_x_axes_label = "PC1",
  legend_y_axes_label = "PC2",
  legend_x_position = 0.02,
  legend_y_position = 0.02,
  legend_h_size = 0.2,
  legend_w_size = 0.2,
  legend_title_size = 7,
  legend_number_size = 2,
  seed = 1002
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textPCAPlot_+3A_word_data">word_data</code></td>
<td>
<p>Dataframe from textPCA</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_min_freq_words_test">min_freq_words_test</code></td>
<td>
<p>Select words to significance test that have occurred at least min_freq_words_test
(default = 1).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_plot_n_word_extreme">plot_n_word_extreme</code></td>
<td>
<p>Number of words that are extreme on Supervised Dimension Projection per dimension.
(i.e., even if not significant; per dimensions, where duplicates are removed).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_plot_n_word_frequency">plot_n_word_frequency</code></td>
<td>
<p>Number of words based on being most frequent.
(i.e., even if not significant).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_plot_n_words_middle">plot_n_words_middle</code></td>
<td>
<p>Number of words plotted that are in the middle in Supervised Dimension Projection score
(i.e., even if not significant;  per dimensions, where duplicates are removed).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_titles_color">titles_color</code></td>
<td>
<p>Color for all the titles (default: &quot;#61605e&quot;)</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_title_top">title_top</code></td>
<td>
<p>Title (default &quot;  &quot;)</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_x_axes_label">x_axes_label</code></td>
<td>
<p>Label on the x-axes.</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_y_axes_label">y_axes_label</code></td>
<td>
<p>Label on the y-axes.</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_scale_x_axes_lim">scale_x_axes_lim</code></td>
<td>
<p>Manually set the length of the x-axes (default = NULL, which uses
ggplot2::scale_x_continuous(limits = scale_x_axes_lim); change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_scale_y_axes_lim">scale_y_axes_lim</code></td>
<td>
<p>Manually set the length of the y-axes (default = NULL; which uses
ggplot2::scale_y_continuous(limits = scale_y_axes_lim); change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_word_font">word_font</code></td>
<td>
<p>Font type (default: NULL).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_bivariate_color_codes">bivariate_color_codes</code></td>
<td>
<p>The different colors of the words
(default: c(&quot;#398CF9&quot;, &quot;#60A1F7&quot;, &quot;#5dc688&quot;,
&quot;#e07f6a&quot;, &quot;#EAEAEA&quot;, &quot;#40DD52&quot;,
&quot;#FF0000&quot;, &quot;#EA7467&quot;, &quot;#85DB8E&quot;)).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_word_size_range">word_size_range</code></td>
<td>
<p>Vector with minimum and maximum font size (default: c(3, 8)).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_position_jitter_hight">position_jitter_hight</code></td>
<td>
<p>Jitter height (default: .0).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_position_jitter_width">position_jitter_width</code></td>
<td>
<p>Jitter width (default: .03).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_point_size">point_size</code></td>
<td>
<p>Size of the points indicating the words' position (default: 0.5).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_arrow_transparency">arrow_transparency</code></td>
<td>
<p>Transparency of the lines between each word and point (default: 0.1).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_points_without_words_size">points_without_words_size</code></td>
<td>
<p>Size of the points not linked with a words
(default is to not show it, i.e., 0).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_points_without_words_alpha">points_without_words_alpha</code></td>
<td>
<p>Transparency of the points not linked with a words
(default is to not show it, i.e., 0).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_title">legend_title</code></td>
<td>
<p>Title on the color legend (default: &quot;(PCA)&quot;.</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_x_axes_label">legend_x_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;(x)&quot;.</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_y_axes_label">legend_y_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;(y)&quot;.</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_x_position">legend_x_position</code></td>
<td>
<p>Position on the x coordinates of the color legend (default: 0.02).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_y_position">legend_y_position</code></td>
<td>
<p>Position on the y coordinates of the color legend (default: 0.05).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_h_size">legend_h_size</code></td>
<td>
<p>Height of the color legend (default 0.15).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_w_size">legend_w_size</code></td>
<td>
<p>Width of the color legend (default 0.15).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_title_size">legend_title_size</code></td>
<td>
<p>Font size (default: 7).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_legend_number_size">legend_number_size</code></td>
<td>
<p>Font size of the values in the legend (default: 2).</p>
</td></tr>
<tr><td><code id="textPCAPlot_+3A_seed">seed</code></td>
<td>
<p>Set different seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1- or 2-dimensional word plot, as well as tibble with processed data used to plot..
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textPCA">textPCA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The test-data included in the package is called: DP_projections_HILS_SWLS_100

# Supervised Dimension Projection Plot
principle_component_plot_projection &lt;- textPCAPlot(PC_projections_satisfactionwords_40)
principle_component_plot_projection

names(DP_projections_HILS_SWLS_100)
</code></pre>

<hr>
<h2 id='textPlot'>Plot words</h2><span id='topic+textPlot'></span>

<h3>Description</h3>

<p>textPlot() plots words from textProjection() or textWordPrediction().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textPlot(
  word_data,
  k_n_words_to_test = FALSE,
  min_freq_words_test = 1,
  min_freq_words_plot = 1,
  plot_n_words_square = 3,
  plot_n_words_p = 5,
  plot_n_word_extreme = 5,
  plot_n_word_extreme_xy = 0,
  plot_n_word_frequency = 5,
  plot_n_words_middle = 5,
  plot_n_word_random = 0,
  titles_color = "#61605e",
  y_axes = FALSE,
  p_alpha = 0.05,
  overlapping = TRUE,
  p_adjust_method = "none",
  projection_metric = "dot_product",
  title_top = "Supervised Dimension Projection",
  x_axes_label = "Supervised Dimension Projection (SDP)",
  y_axes_label = "Supervised Dimension Projection (SDP)",
  scale_x_axes_lim = NULL,
  scale_y_axes_lim = NULL,
  word_font = NULL,
  bivariate_color_codes = c("#398CF9", "#60A1F7", "#5dc688", "#e07f6a", "#EAEAEA",
    "#40DD52", "#FF0000", "#EA7467", "#85DB8E"),
  word_size_range = c(3, 8),
  position_jitter_hight = 0,
  position_jitter_width = 0.03,
  point_size = 0.5,
  arrow_transparency = 0.1,
  points_without_words_size = 0.2,
  points_without_words_alpha = 0.2,
  legend_title = "SDP",
  legend_x_axes_label = "x",
  legend_y_axes_label = "y",
  legend_x_position = 0.02,
  legend_y_position = 0.02,
  legend_h_size = 0.2,
  legend_w_size = 0.2,
  legend_title_size = 7,
  legend_number_size = 2,
  legend_number_colour = "white",
  group_embeddings1 = FALSE,
  group_embeddings2 = FALSE,
  projection_embedding = FALSE,
  aggregated_point_size = 0.8,
  aggregated_shape = 8,
  aggregated_color_G1 = "black",
  aggregated_color_G2 = "black",
  projection_color = "blue",
  seed = 1005,
  explore_words = NULL,
  explore_words_color = "#ad42f5",
  explore_words_point = "ALL_1",
  explore_words_aggregation = "mean",
  remove_words = NULL,
  n_contrast_group_color = NULL,
  n_contrast_group_remove = FALSE,
  space = NULL,
  scaling = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textPlot_+3A_word_data">word_data</code></td>
<td>
<p>Dataframe from textProjection.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_k_n_words_to_test">k_n_words_to_test</code></td>
<td>
<p>Select the k most frequent words to significance
test (k = sqrt(100*N); N = number of participant responses) (default = TRUE).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_min_freq_words_test">min_freq_words_test</code></td>
<td>
<p>Select words to significance test that have occurred
at least min_freq_words_test (default = 1).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_min_freq_words_plot">min_freq_words_plot</code></td>
<td>
<p>Select words to plot that has occurred at
least min_freq_words_plot times (default = 1).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_words_square">plot_n_words_square</code></td>
<td>
<p>Select number of significant words in each square
of the figure to plot. The significant words, in each square is selected
according to most frequent words (default = 3).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_words_p">plot_n_words_p</code></td>
<td>
<p>Number of significant words to plot on each (positive
and negative) side of the x-axes and y-axes, (where duplicates are removed);
selects first according to lowest p-value and then according to frequency (default = 5). Hence, on a two
dimensional plot it is possible that plot_n_words_p = 1 yield 4 words.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_word_extreme">plot_n_word_extreme</code></td>
<td>
<p>Number of words that are extreme on Supervised Dimension
Projection per dimension. (i.e., even if not significant; per dimension,
where duplicates are removed).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_word_extreme_xy">plot_n_word_extreme_xy</code></td>
<td>
<p>Number of words that are extreme in both x and y dimensions,
considering overall distance from the origin in the Supervised Dimension Projection space.
This selects words based on their combined extremity score, calculated as
the Euclidean distance from (0,0). Ensures balance across all nine squares by selecting
at least one extreme word per square if available.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_word_frequency">plot_n_word_frequency</code></td>
<td>
<p>Number of words based on being most frequent (default = 5).
(i.e., even if not significant).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_words_middle">plot_n_words_middle</code></td>
<td>
<p>Number of words plotted that are in the middle in Supervised
Dimension Projection score (default = 5). (i.e., even if not significant;  per dimensions,
where duplicates are removed).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_plot_n_word_random">plot_n_word_random</code></td>
<td>
<p>(numeric) select random words to plot.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_titles_color">titles_color</code></td>
<td>
<p>Color for all the titles (default: &quot;#61605e&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_y_axes">y_axes</code></td>
<td>
<p>(boolean) If TRUE, also plotting on the y-axes (default = FALSE, i.e, a 1-dimensional
plot is generated). Also plotting on y-axes produces a two dimension 2-dimensional plot, but the
textProjection function has to have had a variable on the y-axes.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_p_alpha">p_alpha</code></td>
<td>
<p>Alpha (default = .05).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_overlapping">overlapping</code></td>
<td>
<p>(boolean) Allow overlapping (TRUE) or disallow (FALSE) (default = TRUE).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_p_adjust_method">p_adjust_method</code></td>
<td>
<p>(character) Method to adjust/correct p-values for multiple comparisons
(default = &quot;none&quot;; see also &quot;holm&quot;, &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;,  &quot;fdr&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_projection_metric">projection_metric</code></td>
<td>
<p>(character) Metric to plot according to; &quot;dot_product&quot; or &quot;cohens_d&quot;.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_title_top">title_top</code></td>
<td>
<p>Title (default &quot;  &quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_x_axes_label">x_axes_label</code></td>
<td>
<p>(character) Label on the x-axes (default = &quot;Supervised Dimension Projection (SDP)&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_y_axes_label">y_axes_label</code></td>
<td>
<p>(character) Label on the y-axes (default = &quot;Supervised Dimension Projection (SDP)&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_scale_x_axes_lim">scale_x_axes_lim</code></td>
<td>
<p>Manually set the length of the x-axes (default = NULL, which uses
ggplot2::scale_x_continuous(limits = scale_x_axes_lim); change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_scale_y_axes_lim">scale_y_axes_lim</code></td>
<td>
<p>Manually set the length of the y-axes (default = NULL; which uses
ggplot2::scale_y_continuous(limits = scale_y_axes_lim); change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_word_font">word_font</code></td>
<td>
<p>Font type (default = NULL).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_bivariate_color_codes">bivariate_color_codes</code></td>
<td>
<p>(HTML color codes. Type = character) The different colors of the words.
Note that, at the moment, two squares should not have the exact same colour-code because the numbers
within the squares of the legend will then be aggregated (and show the same, incorrect  value).
(default: c(&quot;#398CF9&quot;, &quot;#60A1F7&quot;, &quot;#5dc688&quot;,
&quot;#e07f6a&quot;, &quot;#EAEAEA&quot;, &quot;#40DD52&quot;,
&quot;#FF0000&quot;, &quot;#EA7467&quot;, &quot;#85DB8E&quot;)).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_word_size_range">word_size_range</code></td>
<td>
<p>Vector with minimum and maximum font size (default: c(3, 8)).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_position_jitter_hight">position_jitter_hight</code></td>
<td>
<p>Jitter height (default: .0).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_position_jitter_width">position_jitter_width</code></td>
<td>
<p>Jitter width (default: .03).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_point_size">point_size</code></td>
<td>
<p>Size of the points indicating the words' position (default: 0.5).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_arrow_transparency">arrow_transparency</code></td>
<td>
<p>Transparency of the lines between each word and point (default: 0.1).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_points_without_words_size">points_without_words_size</code></td>
<td>
<p>Size of the points not linked with a words
(default is to not show it, i.e., 0).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_points_without_words_alpha">points_without_words_alpha</code></td>
<td>
<p>Transparency of the points not linked with a words
(default is to not show it, i.e., 0).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_title">legend_title</code></td>
<td>
<p>Title on the color legend (default: &quot;SDP&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_x_axes_label">legend_x_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;x&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_y_axes_label">legend_y_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;y&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_x_position">legend_x_position</code></td>
<td>
<p>Position on the x coordinates of the color legend (default: 0.02).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_y_position">legend_y_position</code></td>
<td>
<p>Position on the y coordinates of the color legend (default: 0.05).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_h_size">legend_h_size</code></td>
<td>
<p>Height of the color legend (default 0.15).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_w_size">legend_w_size</code></td>
<td>
<p>Width of the color legend (default 0.15).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_title_size">legend_title_size</code></td>
<td>
<p>Font size (default: 7).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_number_size">legend_number_size</code></td>
<td>
<p>Font size of the values in the legend (default: 2).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_legend_number_colour">legend_number_colour</code></td>
<td>
<p>(string) Colour of the numbers in the box legend.</p>
</td></tr>
<tr><td><code id="textPlot_+3A_group_embeddings1">group_embeddings1</code></td>
<td>
<p>(boolean) Shows a point representing the aggregated word embedding
for group 1 (default = FALSE).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_group_embeddings2">group_embeddings2</code></td>
<td>
<p>(boolean) Shows a point representing the aggregated word embedding
for group 2 (default = FALSE).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_projection_embedding">projection_embedding</code></td>
<td>
<p>(boolean) Shows a point representing the aggregated direction
embedding (default = FALSE).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_aggregated_point_size">aggregated_point_size</code></td>
<td>
<p>Size of the points representing the group_embeddings1,
group_embeddings2 and projection_embedding (default = 0.8).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_aggregated_shape">aggregated_shape</code></td>
<td>
<p>Shape type of the points representing the group_embeddings1,
group_embeddings2 and projection_embedding (default = 8).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_aggregated_color_g1">aggregated_color_G1</code></td>
<td>
<p>Color (default = &quot;black&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_aggregated_color_g2">aggregated_color_G2</code></td>
<td>
<p>Color (default = &quot;black&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_projection_color">projection_color</code></td>
<td>
<p>Color (default = &quot;blue&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_seed">seed</code></td>
<td>
<p>(numeric) Set different seed (default = 1005)..</p>
</td></tr>
<tr><td><code id="textPlot_+3A_explore_words">explore_words</code></td>
<td>
<p>Explore where specific words are positioned in the embedding space.
For example, c(&quot;happy content&quot;, &quot;sad down&quot;) (default = NULL).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_explore_words_color">explore_words_color</code></td>
<td>
<p>Specify the color(s) of the words being explored.
For example c(&quot;#ad42f5&quot;, &quot;green&quot;) (default = &quot;#ad42f5&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_explore_words_point">explore_words_point</code></td>
<td>
<p>Specify the names of the point for the aggregated word embeddings
of all the explored words (default = &quot;ALL_1&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_explore_words_aggregation">explore_words_aggregation</code></td>
<td>
<p>Specify how to aggregate the word embeddings of
the explored words (default = &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_remove_words">remove_words</code></td>
<td>
<p>Manually remove words from the plot (which is done just before the
words are plotted so that the remove_words are part of previous counts/analyses) (default = NULL).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_n_contrast_group_color">n_contrast_group_color</code></td>
<td>
<p>Set color to words that have higher frequency (N)
on the other opposite side of its dot product projection (default = NULL).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_n_contrast_group_remove">n_contrast_group_remove</code></td>
<td>
<p>Remove words that have higher frequency (N) on the other
opposite side of its dot product projection (default = FALSE).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_space">space</code></td>
<td>
<p>Provide a semantic space if using static embeddings and wanting to explore words (default = NULL).</p>
</td></tr>
<tr><td><code id="textPlot_+3A_scaling">scaling</code></td>
<td>
<p>Scaling word embeddings before aggregation (default = FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1- or 2-dimensional word plot, as well as tibble with processed data used
to plot.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textProjection">textProjection</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The test-data included in the package is called: DP_projections_HILS_SWLS_100

# Supervised Dimension Projection Plot
plot_projection &lt;- textPlot(
  word_data = DP_projections_HILS_SWLS_100,
  k_n_words_to_test = FALSE,
  min_freq_words_test = 1,
  plot_n_words_square = 3,
  plot_n_words_p = 3,
  plot_n_word_extreme = 1,
  plot_n_word_frequency = 1,
  plot_n_words_middle = 1,
  y_axes = FALSE,
  p_alpha = 0.05,
  title_top = "Supervised Dimension Projection (SDP)",
  x_axes_label = "Low vs. High HILS score",
  y_axes_label = "Low vs. High SWLS score",
  p_adjust_method = "bonferroni",
  scale_y_axes_lim = NULL
)
plot_projection

names(DP_projections_HILS_SWLS_100)
</code></pre>

<hr>
<h2 id='textPredict'>textPredict, textAssess and textClassify</h2><span id='topic+textPredict'></span><span id='topic+textAssess'></span><span id='topic+textClassify'></span>

<h3>Description</h3>

<p>Trained models created by e.g., textTrain() or stored on e.g., github of huggingface
can be used to predict  scores or classes from embeddings or text using one of these function
aliases.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textPredict(
  model_info = "valence_facebook_mxbai23_eijsbroek2024",
  texts = NULL,
  model_type = "detect",
  lbam_update = TRUE,
  word_embeddings = NULL,
  x_append = NULL,
  append_first = NULL,
  dim_names = TRUE,
  language_distribution = NULL,
  language_distribution_min_words = "trained_distribution_min_words",
  save_model = TRUE,
  threshold = NULL,
  show_texts = FALSE,
  device = "cpu",
  participant_id = NULL,
  save_embeddings = TRUE,
  save_dir = "wd",
  save_name = "textPredict",
  story_id = NULL,
  dataset_to_merge_assessments = NULL,
  previous_sentence = FALSE,
  tokenizer_parallelism = FALSE,
  logging_level = "error",
  force_return_results = TRUE,
  return_all_scores = FALSE,
  function_to_apply = NULL,
  set_seed = 202208,
  ...
)

textAssess(
  model_info = "valence_facebook_mxbai23_eijsbroek2024",
  texts = NULL,
  model_type = "detect",
  lbam_update = TRUE,
  word_embeddings = NULL,
  x_append = NULL,
  append_first = NULL,
  dim_names = TRUE,
  language_distribution = NULL,
  language_distribution_min_words = "trained_distribution_min_words",
  save_model = TRUE,
  threshold = NULL,
  show_texts = FALSE,
  device = "cpu",
  participant_id = NULL,
  save_embeddings = TRUE,
  save_dir = "wd",
  save_name = "textPredict",
  story_id = NULL,
  dataset_to_merge_assessments = NULL,
  previous_sentence = FALSE,
  tokenizer_parallelism = FALSE,
  logging_level = "error",
  force_return_results = TRUE,
  return_all_scores = FALSE,
  function_to_apply = NULL,
  set_seed = 202208,
  ...
)

textClassify(
  model_info = "valence_facebook_mxbai23_eijsbroek2024",
  texts = NULL,
  model_type = "detect",
  lbam_update = TRUE,
  word_embeddings = NULL,
  x_append = NULL,
  append_first = NULL,
  dim_names = TRUE,
  language_distribution = NULL,
  language_distribution_min_words = "trained_distribution_min_words",
  save_model = TRUE,
  threshold = NULL,
  show_texts = FALSE,
  device = "cpu",
  participant_id = NULL,
  save_embeddings = TRUE,
  save_dir = "wd",
  save_name = "textPredict",
  story_id = NULL,
  dataset_to_merge_assessments = NULL,
  previous_sentence = FALSE,
  tokenizer_parallelism = FALSE,
  logging_level = "error",
  force_return_results = TRUE,
  return_all_scores = FALSE,
  function_to_apply = NULL,
  set_seed = 202208,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textPredict_+3A_model_info">model_info</code></td>
<td>
<p>(character or r-object) model_info has four options, including:
1: An R model (e.g, saved output from one of the textTrain() functions).
2: The name specified in the  <a href="https://r-text.org/articles/LBAM.html">L-BAM Documentation</a>.
For the following settings, remember to also set the model_type parameter:
3: Link to a text-trained model online (either in a github repo
(e.g, &quot;https://github.com/CarlViggo/pretrained_swls_model/raw/main/trained_github_model_logistic.RDS&quot;or
OSF https://osf.io/8fp7v)
4: Name or link to a fine-tuned model from Huggingface (e.g., &quot;distilbert-base-uncased-finetuned-sst-2-english&quot;).
5: Path to a model stored locally (e.g, &quot;path/to/your/model/model_name.rds&quot;).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_texts">texts</code></td>
<td>
<p>(character) Text to predict. If this argument is specified, then arguments &quot;word_embeddings&quot;
and &quot;premade embeddings&quot; cannot be defined (default = NULL).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_model_type">model_type</code></td>
<td>
<p>(character) Specify how the function should handle the model argument. The default is &quot;detect&quot; where the fucntion ttried to detect it
automatically. Setting it to &quot;fine-tuned&quot; or &quot;text-trained&quot; will apply their respective default behaviors, while setting it to &quot;implicit motives&quot; will
trigger specific steps tailored to these models.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_lbam_update">lbam_update</code></td>
<td>
<p>(boolean) Updating the L-BAM file by automatically downloading it from Google Sheet.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_word_embeddings">word_embeddings</code></td>
<td>
<p>(tibble; only for &quot;text-trained&quot;-model_type) Embeddings from e.g., textEmbed(). If you're using a pre-trained model,
then texts and embeddings cannot be submitted simultaneously (default = NULL).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_x_append">x_append</code></td>
<td>
<p>(tibble; only for &quot;text-trained&quot;-model_type) Variables to be appended with the word embeddings (x).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_append_first">append_first</code></td>
<td>
<p>(boolean; only for &quot;text-trained&quot; models) If TRUE, x_appened is added before word embeddings.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_dim_names">dim_names</code></td>
<td>
<p>(boolean; only for &quot;text-trained&quot;-models) Account for specific dimension names from textEmbed()
(rather than generic names including Dim1, Dim2 etc.). If FALSE the models need to have been trained on
word embeddings created with dim_names FALSE, so that embeddings were only called Dim1, Dim2 etc.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_language_distribution">language_distribution</code></td>
<td>
<p>(character column; only for &quot;text-trained&quot; models) If you provide the raw language data used for making the embeddings used for assessment,
the language distribution (i.e., a word and frequency table) will be compared with saved one in the model object (if one exists).
This enables calculating similarity scores.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_language_distribution_min_words">language_distribution_min_words</code></td>
<td>
<p>(string or numeric; only for &quot;text-trained&quot; models) Default is to use the removal threshold used when creating the distribution in the
in the training set (&quot;trained_distribution_min_words&quot;). You can set it yourself with a numeric value.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_save_model">save_model</code></td>
<td>
<p>(boolean; only for &quot;text-trained&quot;-models) The model will by default be saved in your work-directory (default = TRUE).
If the model already exists in your work-directory, it will automatically be loaded from there.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_threshold">threshold</code></td>
<td>
<p>(numeric; only for &quot;text-trained&quot;-models) Determine threshold if you are using a logistic model (default = 0.5).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_show_texts">show_texts</code></td>
<td>
<p>(boolean; only for &quot;implicit-motives&quot;-models) Show texts together with predictions (default = FALSE).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_device">device</code></td>
<td>
<p>Name of device to use: 'cpu', 'gpu', 'gpu:k' or 'mps'/'mps:k' for MacOS, where k is a
specific device number such as 'mps:1'.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_participant_id">participant_id</code></td>
<td>
<p>(list; only for &quot;implicit-motives&quot;-models) Vector of participant-ids. Specify this for getting person level scores
(i.e., summed sentence probabilities to the person level corrected for word count). (default = NULL)</p>
</td></tr>
<tr><td><code id="textPredict_+3A_save_embeddings">save_embeddings</code></td>
<td>
<p>(boolean; only for &quot;text-trained&quot;-models) If set to TRUE, embeddings will be saved with a unique identifier, and
will be automatically opened next time textPredict is run with the same text. (default = TRUE)</p>
</td></tr>
<tr><td><code id="textPredict_+3A_save_dir">save_dir</code></td>
<td>
<p>(character; only for &quot;text-trained&quot;-models) Directory to save embeddings. (default = &quot;wd&quot; (i.e, work-directory))</p>
</td></tr>
<tr><td><code id="textPredict_+3A_save_name">save_name</code></td>
<td>
<p>(character; only for &quot;text-trained&quot;-models) Name of the saved embeddings (will be combined with a unique identifier).
(default = &quot;&quot;). Obs: If no save_name is provided, and model_info is a character, then save_name will be set
to model_info.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_story_id">story_id</code></td>
<td>
<p>(vector; only for &quot;implicit-motives&quot;-models) Vector of story-ids. Specify this to get story level scores (i.e., summed sentence
probabilities corrected for word count). When there is both story_id and participant_id indicated, the function
returns a list including both story level and person level prediction corrected for word count. (default = NULL)</p>
</td></tr>
<tr><td><code id="textPredict_+3A_dataset_to_merge_assessments">dataset_to_merge_assessments</code></td>
<td>
<p>(R-object, tibble; only for &quot;implicit-motives&quot;-models) Insert your data here to integrate predictions to your dataset,
(default = NULL).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_previous_sentence">previous_sentence</code></td>
<td>
<p>(boolean; only for &quot;implicit-motives&quot;-models) If set to TRUE, word-embeddings will be averaged over the current and previous
sentence per story-id. For this, both participant-id and story-id must be specified.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean; only for &quot;fine-tuned&quot;-models)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_logging_level">logging_level</code></td>
<td>
<p>(string; only for &quot;fine-tuned&quot;-models)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textPredict_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean; only for &quot;fine-tuned&quot;-models)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot;
and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textPredict_+3A_return_all_scores">return_all_scores</code></td>
<td>
<p>(boolean; only for &quot;fine-tuned&quot;-models)  Whether to return all prediction scores or just the one of the predicted class.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_function_to_apply">function_to_apply</code></td>
<td>
<p>(string; only for &quot;fine-tuned&quot;-models)  The function to apply to the model outputs to retrieve the scores.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer; only for &quot;fine-tuned&quot; models) Set seed.</p>
</td></tr>
<tr><td><code id="textPredict_+3A_...">...</code></td>
<td>
<p>Setting from stats::predict can be called.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions from word-embedding or text input.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textTrain">textTrain</a></code>, <code><a href="#topic+textTrainLists">textTrainLists</a></code> and
<code><a href="#topic+textTrainRandomForest">textTrainRandomForest</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Text data from Language_based_assessment_data_8
text_to_predict &lt;- "I am not in harmony in my life as much as I would like to be."

# Example 1: (predict using pre-made embeddings and an R model-object)
prediction1 &lt;- textPredict(
  model_info = trained_model,
  word_embeddings_4$texts$satisfactiontexts
)

# Example 2: (predict using a pretrained github model)
prediction2 &lt;- textPredict(
  texts = text_to_predict,
  model_info = "https://github.com/CarlViggo/pretrained-models/raw/main/trained_hils_model.RDS"
)

# Example 3: (predict using a pretrained logistic github model and return
# probabilities and classifications)
prediction3 &lt;- textPredict(
  texts = text_to_predict,
  model_info = "https://github.com/CarlViggo/pretrained-models/raw/main/
  trained_github_model_logistic.RDS",
  type = "class_prob",
  threshold = 0.7
)

# Example 4: (predict from texts using a pretrained model stored in an osf project)
prediction4 &lt;- textPredict(
  texts = text_to_predict,
  model_info = "https://osf.io/8fp7v"
)
##### Automatic implicit motive coding section ######

# Create example dataset
implicit_motive_data &lt;- dplyr::mutate(.data = Language_based_assessment_data_8,
participant_id = dplyr::row_number())

# Code implicit motives.
implicit_motives &lt;- textPredict(
  texts = implicit_motive_data$satisfactiontexts,
  model_info = "implicit_power_roberta_large_L23_v1",
  participant_id = implicit_motive_data$participant_id,
  dataset_to_merge_assessments = implicit_motive_data
)

# Examine results
implicit_motives$sentence_predictions
implicit_motives$person_predictions

## End(Not run)

## Not run: 
# Examine the correlation between the predicted values and
# the Satisfaction with life scale score (pre-included in text).

psych::corr.test(
  predictions1$word_embeddings__ypred,
  Language_based_assessment_data_8$swlstotal
)

## End(Not run)
</code></pre>

<hr>
<h2 id='textPredictAll'>Predict from several models, selecting the correct input</h2><span id='topic+textPredictAll'></span>

<h3>Description</h3>

<p>Predict from several models, selecting the correct input
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textPredictAll(models, word_embeddings, x_append = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textPredictAll_+3A_models">models</code></td>
<td>
<p>Object containing several models.</p>
</td></tr>
<tr><td><code id="textPredictAll_+3A_word_embeddings">word_embeddings</code></td>
<td>
<p>List of word embeddings (if using word embeddings from more than one
text-variable use dim_names = TRUE throughout the pipeline).</p>
</td></tr>
<tr><td><code id="textPredictAll_+3A_x_append">x_append</code></td>
<td>
<p>A tibble/dataframe with additional variables used in the training of the models (optional).</p>
</td></tr>
<tr><td><code id="textPredictAll_+3A_...">...</code></td>
<td>
<p>Settings from textPredict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with predictions.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textPredict">textPredict</a></code> and <code><a href="#topic+textTrain">textTrain</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# x &lt;- Language_based_assessment_data_8[1:2, 1:2]
# word_embeddings_with_layers &lt;- textEmbedLayersOutput(x, layers = 11:12)

</code></pre>

<hr>
<h2 id='textPredictTest'>Significance testing correlations
If only y1 is provided a t-test is computed, between the absolute error from yhat1-y1 and yhat2-y1.</h2><span id='topic+textPredictTest'></span>

<h3>Description</h3>

<p>If y2 is provided a bootstrapped procedure is used to compare the correlations between y1 and yhat1 versus
y2 and yhat2. This is achieved by creating two distributions of correlations using bootstrapping; and then
finally compute the distributions overlap.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textPredictTest(
  y1,
  y2,
  yhat1,
  yhat2,
  method = "t-test",
  statistic = "correlation",
  paired = TRUE,
  event_level = "first",
  bootstraps_times = 1000,
  seed = 6134,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textPredictTest_+3A_y1">y1</code></td>
<td>
<p>The observed scores (i.e., what was used to predict when training a model).</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_y2">y2</code></td>
<td>
<p>The second observed scores (default = NULL; i.e., for when comparing models that are predicting different
outcomes. In this case a bootstrap procedure is used to create two distributions of correlations that are
compared (see description above).</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_yhat1">yhat1</code></td>
<td>
<p>The predicted scores from model 1.</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_yhat2">yhat2</code></td>
<td>
<p>The predicted scores from model 2 that will be compared with model 1.</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_method">method</code></td>
<td>
<p>Set &quot;t-test&quot; if comparing predictions from models that predict the SAME outcome.
Set &quot;bootstrap&quot; if comparing predictions from models that predict DIFFERENT outcomes or comparison from logistic
regression computing AUC distributions.</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_statistic">statistic</code></td>
<td>
<p>Character (&quot;correlation&quot;, &quot;auc&quot;) describing statistic to be compared in bootstrapping.</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_paired">paired</code></td>
<td>
<p>Paired test or not in stats::t.test (default TRUE).</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_event_level">event_level</code></td>
<td>
<p>Character &quot;first&quot; or &quot;second&quot; for computing the auc in the bootstrap.</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_bootstraps_times">bootstraps_times</code></td>
<td>
<p>Number of bootstraps (when providing y2).</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_seed">seed</code></td>
<td>
<p>Set seed.</p>
</td></tr>
<tr><td><code id="textPredictTest_+3A_...">...</code></td>
<td>
<p>Settings from stats::t.test or overlapping::overlap (e.g., plot = TRUE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Comparison of correlations either a t-test or the overlap of a bootstrapped procedure (see $OV).
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textTrain">textTrain</a></code> <code><a href="#topic+textPredict">textPredict</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example random data
y1 &lt;- runif(10)
yhat1 &lt;- runif(10)
y2 &lt;- runif(10)
yhat2 &lt;- runif(10)

boot_test &lt;- textPredictTest(y1, y2, yhat1, yhat2)
</code></pre>

<hr>
<h2 id='textProjection'>Supervised Dimension Projection</h2><span id='topic+textProjection'></span>

<h3>Description</h3>

<p>textProjection() computes Supervised Dimension Projection and related variables for plotting words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textProjection(
  words,
  word_embeddings,
  word_types_embeddings,
  x,
  y = NULL,
  pca = NULL,
  aggregation = "mean",
  split = "quartile",
  word_weight_power = 1,
  min_freq_words_test = 0,
  mean_centering = FALSE,
  mean_centering2 = FALSE,
  Npermutations = 10000,
  n_per_split = 50000,
  seed = 1003
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textProjection_+3A_words">words</code></td>
<td>
<p>(character) Word or text variable to be plotted.</p>
</td></tr>
<tr><td><code id="textProjection_+3A_word_embeddings">word_embeddings</code></td>
<td>
<p>Word embeddings from textEmbed for the words to be plotted
(i.e., the aggregated word embeddings for the &quot;words&quot; parameter).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_word_types_embeddings">word_types_embeddings</code></td>
<td>
<p>Word embeddings from textEmbed for individual words
(i.e., decontextualized embeddings).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_x">x</code></td>
<td>
<p>Numeric variable that the words should be plotted according to on the x-axes.</p>
</td></tr>
<tr><td><code id="textProjection_+3A_y">y</code></td>
<td>
<p>Numeric variable that the words should be plotted according to on the y-axes
(default = NULL, i.e., a 1-dimensional plot is created).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_pca">pca</code></td>
<td>
<p>Number of PCA dimensions applied to the word embeddings in the beginning of the
function (default = NULL).
A number below 1 takes out % of variance; An integer specify number of components to extract.
(default is NULL as this setting has not yet been evaluated).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_aggregation">aggregation</code></td>
<td>
<p>(character) Method to aggregate the word embeddings
(default = &quot;mean&quot;; see also &quot;min&quot;, &quot;max&quot;, and &quot;[CLS]&quot;).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_split">split</code></td>
<td>
<p>(character) Method to split the axes
(default = &quot;quartile&quot; involving selecting lower and upper quartile; see also &quot;mean&quot;). However, if the variable is
only containing two different values (i.e., being dichotomous) mean split is used.</p>
</td></tr>
<tr><td><code id="textProjection_+3A_word_weight_power">word_weight_power</code></td>
<td>
<p>Compute the power of the frequency of the words and multiply
the word embeddings with this in the computation of aggregated word embeddings for
group low (1) and group high (2). This increases the weight of more frequent words.</p>
</td></tr>
<tr><td><code id="textProjection_+3A_min_freq_words_test">min_freq_words_test</code></td>
<td>
<p>(numeric) Option to select words that have occurred a specified number of
times (default = 0); when creating the Supervised Dimension Projection line
(i.e., single words receive Supervised Dimension Projection and p-value).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_mean_centering">mean_centering</code></td>
<td>
<p>(boolean) Separately mean centering the Group 1 split aggregation embedding,
and the Group 2 split aggregation embedding</p>
</td></tr>
<tr><td><code id="textProjection_+3A_mean_centering2">mean_centering2</code></td>
<td>
<p>(boolean) Separately mean centering the G1 and G2 split aggregation embeddings</p>
</td></tr>
<tr><td><code id="textProjection_+3A_npermutations">Npermutations</code></td>
<td>
<p>(numeric) Number of permutations in the creation of the null distribution (default = 10000).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_n_per_split">n_per_split</code></td>
<td>
<p>(numeric) Setting to split Npermutations to avoid reaching computer memory limits;
set it lower than Npermutations &lt;- and the higher it is set the faster the computation completes,
but too high may lead to abortion (default = 50000).</p>
</td></tr>
<tr><td><code id="textProjection_+3A_seed">seed</code></td>
<td>
<p>(numeric) Set different seed (default = 1003).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe with variables (e.g., including Supervised Dimension Projection, frequencies, p-values)
for the individual words that is used for the plotting in the textProjectionPlot function.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textProjectionPlot">textProjectionPlot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Pre-processing data for plotting.
## Not run: 
df_for_plotting &lt;- textProjection(
  words = Language_based_assessment_data_8$harmonywords,
  word_embeddings = word_embeddings_4$texts$harmonywords,
  word_types_embeddings = word_embeddings_4$word_types,
  x = Language_based_assessment_data_8$hilstotal,
  split = "mean",
  Npermutations = 10,
  n_per_split = 1
)
# Run df_for_plotting to examine result.
df_for_plotting

## End(Not run)
</code></pre>

<hr>
<h2 id='textProjectionPlot'>Plot Supervised Dimension Projection</h2><span id='topic+textProjectionPlot'></span>

<h3>Description</h3>

<p>textProjectionPlot() plots words according to Supervised Dimension Projection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textProjectionPlot(
  word_data,
  k_n_words_to_test = FALSE,
  min_freq_words_test = 1,
  min_freq_words_plot = 1,
  plot_n_words_square = 3,
  plot_n_words_p = 5,
  plot_n_word_extreme = 5,
  plot_n_word_frequency = 5,
  plot_n_words_middle = 5,
  plot_n_word_random = 0,
  titles_color = "#61605e",
  y_axes = FALSE,
  p_alpha = 0.05,
  overlapping = TRUE,
  p_adjust_method = "none",
  projection_metric = "dot_product",
  title_top = "Supervised Dimension Projection",
  x_axes_label = "Supervised Dimension Projection (SDP)",
  y_axes_label = "Supervised Dimension Projection (SDP)",
  scale_x_axes_lim = NULL,
  scale_y_axes_lim = NULL,
  word_font = NULL,
  bivariate_color_codes = c("#398CF9", "#60A1F7", "#5dc688", "#e07f6a", "#EAEAEA",
    "#40DD52", "#FF0000", "#EA7467", "#85DB8E"),
  word_size_range = c(3, 8),
  position_jitter_hight = 0,
  position_jitter_width = 0.03,
  point_size = 0.5,
  arrow_transparency = 0.1,
  points_without_words_size = 0.2,
  points_without_words_alpha = 0.2,
  legend_title = "SDP",
  legend_x_axes_label = "x",
  legend_y_axes_label = "y",
  legend_x_position = 0.02,
  legend_y_position = 0.02,
  legend_h_size = 0.2,
  legend_w_size = 0.2,
  legend_title_size = 7,
  legend_number_size = 2,
  legend_number_colour = "white",
  group_embeddings1 = FALSE,
  group_embeddings2 = FALSE,
  projection_embedding = FALSE,
  aggregated_point_size = 0.8,
  aggregated_shape = 8,
  aggregated_color_G1 = "black",
  aggregated_color_G2 = "black",
  projection_color = "blue",
  seed = 1005,
  explore_words = NULL,
  explore_words_color = "#ad42f5",
  explore_words_point = "ALL_1",
  explore_words_aggregation = "mean",
  remove_words = NULL,
  n_contrast_group_color = NULL,
  n_contrast_group_remove = FALSE,
  space = NULL,
  scaling = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textProjectionPlot_+3A_word_data">word_data</code></td>
<td>
<p>Dataframe from textProjection</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_k_n_words_to_test">k_n_words_to_test</code></td>
<td>
<p>Select the k most frequent words to significance
test (k = sqrt(100*N); N = number of participant responses). Default = TRUE.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_min_freq_words_test">min_freq_words_test</code></td>
<td>
<p>Select words to significance test that have occurred at least min_freq_words_test
(default = 1).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_min_freq_words_plot">min_freq_words_plot</code></td>
<td>
<p>Select words to plot that has occurred at least min_freq_words_plot times.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_plot_n_words_square">plot_n_words_square</code></td>
<td>
<p>Select number of significant words in each square of the figure to plot. The significant
words, in each square is selected according to most frequent words.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_plot_n_words_p">plot_n_words_p</code></td>
<td>
<p>Number of significant words to plot on each(positive and negative) side of
the x-axes and y-axes, (where duplicates are removed); selects first according to lowest p-value
and then according to frequency. Hence, on a two dimensional plot it is possible that
plot_n_words_p = 1 yield 4 words.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_plot_n_word_extreme">plot_n_word_extreme</code></td>
<td>
<p>Number of words that are extreme on Supervised Dimension Projection per dimension.
(i.e., even if not significant; per dimensions, where duplicates are removed).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_plot_n_word_frequency">plot_n_word_frequency</code></td>
<td>
<p>Number of words based on being most frequent.
(i.e., even if not significant).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_plot_n_words_middle">plot_n_words_middle</code></td>
<td>
<p>Number of words plotted that are in the middle in Supervised
Dimension Projection score (i.e., even if not significant;  per dimensions, where duplicates are removed).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_plot_n_word_random">plot_n_word_random</code></td>
<td>
<p>(numeric) select random words to plot.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_titles_color">titles_color</code></td>
<td>
<p>Color for all the titles (default: &quot;#61605e&quot;)</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_y_axes">y_axes</code></td>
<td>
<p>If TRUE, also plotting on the y-axes (default is FALSE). Also plotting on
y-axes produces a two dimension 2-dimensional plot, but the textProjection function has to
have had a variable on the y-axes.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_p_alpha">p_alpha</code></td>
<td>
<p>Alpha (default = .05).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_overlapping">overlapping</code></td>
<td>
<p>(boolean) Allow overlapping (TRUE) or disallow (FALSE) (default = TRUE).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_p_adjust_method">p_adjust_method</code></td>
<td>
<p>Method to adjust/correct p-values for multiple comparisons
(default = &quot;holm&quot;; see also &quot;none&quot;, &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;,  &quot;fdr&quot;).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_projection_metric">projection_metric</code></td>
<td>
<p>(character) Metric to plot according to; &quot;dot_product&quot; or &quot;cohens_d&quot;.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_title_top">title_top</code></td>
<td>
<p>Title (default &quot;  &quot;)</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_x_axes_label">x_axes_label</code></td>
<td>
<p>Label on the x-axes.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_y_axes_label">y_axes_label</code></td>
<td>
<p>Label on the y-axes.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_scale_x_axes_lim">scale_x_axes_lim</code></td>
<td>
<p>Manually set the length of the x-axes (default = NULL, which uses
ggplot2::scale_x_continuous(limits = scale_x_axes_lim); change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_scale_y_axes_lim">scale_y_axes_lim</code></td>
<td>
<p>Manually set the length of the y-axes (default = NULL; which uses
ggplot2::scale_y_continuous(limits = scale_y_axes_lim); change e.g., by trying c(-5, 5)).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_word_font">word_font</code></td>
<td>
<p>Font type (default: NULL).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_bivariate_color_codes">bivariate_color_codes</code></td>
<td>
<p>The different colors of the words. Note that, at the moment,
two squares should not have the exact same colour-code because the numbers within the
squares of the legend will then be aggregated (and show the same, incorrect  value).
(default: c(&quot;#398CF9&quot;, &quot;#60A1F7&quot;, &quot;#5dc688&quot;,
&quot;#e07f6a&quot;, &quot;#EAEAEA&quot;, &quot;#40DD52&quot;,
&quot;#FF0000&quot;, &quot;#EA7467&quot;, &quot;#85DB8E&quot;)).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_word_size_range">word_size_range</code></td>
<td>
<p>Vector with minimum and maximum font size (default: c(3, 8)).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_position_jitter_hight">position_jitter_hight</code></td>
<td>
<p>Jitter height (default: .0).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_position_jitter_width">position_jitter_width</code></td>
<td>
<p>Jitter width (default: .03).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_point_size">point_size</code></td>
<td>
<p>Size of the points indicating the words' position (default: 0.5).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_arrow_transparency">arrow_transparency</code></td>
<td>
<p>Transparency of the lines between each word and point (default: 0.1).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_points_without_words_size">points_without_words_size</code></td>
<td>
<p>Size of the points not linked with a words
(default is to not show it, i.e., 0).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_points_without_words_alpha">points_without_words_alpha</code></td>
<td>
<p>Transparency of the points not linked with a words
(default is to not show it, i.e., 0).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_title">legend_title</code></td>
<td>
<p>Title on the color legend (default: &quot;(SDP)&quot;.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_x_axes_label">legend_x_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;(x)&quot;.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_y_axes_label">legend_y_axes_label</code></td>
<td>
<p>Label on the color legend (default: &quot;(y)&quot;.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_x_position">legend_x_position</code></td>
<td>
<p>Position on the x coordinates of the color legend (default: 0.02).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_y_position">legend_y_position</code></td>
<td>
<p>Position on the y coordinates of the color legend (default: 0.05).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_h_size">legend_h_size</code></td>
<td>
<p>Height of the color legend (default 0.15).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_w_size">legend_w_size</code></td>
<td>
<p>Width of the color legend (default 0.15).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_title_size">legend_title_size</code></td>
<td>
<p>Font size (default: 7).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_number_size">legend_number_size</code></td>
<td>
<p>Font size of the values in the legend (default: 2).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_legend_number_colour">legend_number_colour</code></td>
<td>
<p>(string) Colour of the numbers in the box legend.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_group_embeddings1">group_embeddings1</code></td>
<td>
<p>Shows a point representing the aggregated word embedding for group 1 (default = FALSE).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_group_embeddings2">group_embeddings2</code></td>
<td>
<p>Shows a point representing the aggregated word embedding for group 2 (default = FALSE).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_projection_embedding">projection_embedding</code></td>
<td>
<p>Shows a point representing the aggregated direction embedding (default = FALSE).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_aggregated_point_size">aggregated_point_size</code></td>
<td>
<p>Size of the points representing the group_embeddings1,
group_embeddings2 and projection_embedding</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_aggregated_shape">aggregated_shape</code></td>
<td>
<p>Shape type of the points representing the group_embeddings1,
group_embeddings2 and projection_embeddingd</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_aggregated_color_g1">aggregated_color_G1</code></td>
<td>
<p>Color</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_aggregated_color_g2">aggregated_color_G2</code></td>
<td>
<p>Color</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_projection_color">projection_color</code></td>
<td>
<p>Color</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_seed">seed</code></td>
<td>
<p>Set different seed.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_explore_words">explore_words</code></td>
<td>
<p>Explore where specific words are positioned in the embedding space.
For example, c(&quot;happy content&quot;, &quot;sad down&quot;).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_explore_words_color">explore_words_color</code></td>
<td>
<p>Specify the color(s) of the words being explored.
For example c(&quot;#ad42f5&quot;, &quot;green&quot;)</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_explore_words_point">explore_words_point</code></td>
<td>
<p>Specify the names of the point for the aggregated word embeddings
of all the explored words.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_explore_words_aggregation">explore_words_aggregation</code></td>
<td>
<p>Specify how to aggregate the word embeddings of the explored words.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_remove_words">remove_words</code></td>
<td>
<p>manually remove words from the plot (which is done just before the words are
plotted so that the remove_words are part of previous counts/analyses).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_n_contrast_group_color">n_contrast_group_color</code></td>
<td>
<p>Set color to words that have higher frequency (N) on the other
opposite side of its dot product projection (default = NULL).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_n_contrast_group_remove">n_contrast_group_remove</code></td>
<td>
<p>Remove words that have higher frequency (N) on the other
opposite side of its dot product projection (default = FALSE).</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_space">space</code></td>
<td>
<p>Provide a semantic space if using static embeddings and wanting to explore words.</p>
</td></tr>
<tr><td><code id="textProjectionPlot_+3A_scaling">scaling</code></td>
<td>
<p>Scaling word embeddings before aggregation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A 1- or 2-dimensional word plot, as well as tibble with processed data used to plot.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textProjection">textProjection</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The test-data included in the package is called: DP_projections_HILS_SWLS_100.
# The dataframe created by textProjection can also be used as input-data.

# Supervised Dimension Projection Plot
plot_projection &lt;- textProjectionPlot(
  word_data = DP_projections_HILS_SWLS_100,
  k_n_words_to_test = FALSE,
  min_freq_words_test = 1,
  plot_n_words_square = 3,
  plot_n_words_p = 3,
  plot_n_word_extreme = 1,
  plot_n_word_frequency = 1,
  plot_n_words_middle = 1,
  y_axes = FALSE,
  p_alpha = 0.05,
  title_top = "Supervised Dimension Projection (SDP)",
  x_axes_label = "Low vs. High HILS score",
  y_axes_label = "Low vs. High SWLS score",
  p_adjust_method = "bonferroni",
  scale_y_axes_lim = NULL
)

plot_projection

# Investigate elements in DP_projections_HILS_SWLS_100.
names(DP_projections_HILS_SWLS_100)
</code></pre>

<hr>
<h2 id='textQA'>Question Answering. (experimental)</h2><span id='topic+textQA'></span>

<h3>Description</h3>

<p>Question Answering. (experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textQA(
  question,
  context,
  model = "",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "warning",
  force_return_results = FALSE,
  top_k = 1L,
  doc_stride = 128L,
  max_answer_len = 15L,
  max_seq_len = 384L,
  max_question_len = 64L,
  handle_impossible_answer = FALSE,
  set_seed = 202208L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textQA_+3A_question">question</code></td>
<td>
<p>(string)  A question</p>
</td></tr>
<tr><td><code id="textQA_+3A_context">context</code></td>
<td>
<p>(string)  The context(s) where the model will look for the answer.</p>
</td></tr>
<tr><td><code id="textQA_+3A_model">model</code></td>
<td>
<p>(string)  HuggingFace name of a pre-trained language model that have been fine-tuned
on a question answering task.</p>
</td></tr>
<tr><td><code id="textQA_+3A_device">device</code></td>
<td>
<p>(string)  Device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number</p>
</td></tr>
<tr><td><code id="textQA_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textQA_+3A_logging_level">logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textQA_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot;
and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textQA_+3A_top_k">top_k</code></td>
<td>
<p>(integer) (int)  Indicates number of possible answer span(s) to get from the model output.</p>
</td></tr>
<tr><td><code id="textQA_+3A_doc_stride">doc_stride</code></td>
<td>
<p>(integer)   If the context is too long to fit with the question for the model, it will be split
into overlapping chunks. This setting controls the overlap size.</p>
</td></tr>
<tr><td><code id="textQA_+3A_max_answer_len">max_answer_len</code></td>
<td>
<p>(integer)  Max answer size to be extracted from the model’s output.</p>
</td></tr>
<tr><td><code id="textQA_+3A_max_seq_len">max_seq_len</code></td>
<td>
<p>(integer)  The max total sentence length (context + question) in tokens of each chunk
passed to the model. If needed, the context is split in chunks (using doc_stride as overlap).</p>
</td></tr>
<tr><td><code id="textQA_+3A_max_question_len">max_question_len</code></td>
<td>
<p>(integer)   The max question length after tokenization. It will be truncated if needed.</p>
</td></tr>
<tr><td><code id="textQA_+3A_handle_impossible_answer">handle_impossible_answer</code></td>
<td>
<p>(boolean)  Whether or not impossible is accepted as an answer.</p>
</td></tr>
<tr><td><code id="textQA_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer) Set seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Answers.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textClassify">textClassify</a></code>, <code><a href="#topic+textGeneration">textGeneration</a></code>, <code><a href="#topic+textNER">textNER</a></code>,
<code><a href="#topic+textSum">textSum</a></code>, <code><a href="#topic+textQA">textQA</a></code>, <code><a href="#topic+textTranslate">textTranslate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#   qa_examples &lt;- textQA(question = "Which colour have trees?",
#     context = "Trees typically have leaves, are mostly green and like water.")

</code></pre>

<hr>
<h2 id='textrpp_initialize'>Initialize text required python packages</h2><span id='topic+textrpp_initialize'></span>

<h3>Description</h3>

<p>Initialize text required python packages to call from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textrpp_initialize(
  python_executable = NULL,
  virtualenv = NULL,
  condaenv = "textrpp_condaenv",
  ask = FALSE,
  refresh_settings = FALSE,
  save_profile = FALSE,
  check_env = TRUE,
  textEmbed_test = FALSE,
  prompt = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textrpp_initialize_+3A_python_executable">python_executable</code></td>
<td>
<p>the full path to the Python executable, for which
text required python packages is installed.</p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_virtualenv">virtualenv</code></td>
<td>
<p>set a path to the Python virtual environment with text required python packages
installed Example: <code>virtualenv = "~/myenv"</code></p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_condaenv">condaenv</code></td>
<td>
<p>set a path to the anaconda virtual environment with text required python packages
installed Example: <code>condalenv = "myenv"</code></p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>FALSE</code>, use the first text required python packages installation found;
if <code>TRUE</code>, list available text required python packages installations and prompt the user for
which to use. If another (e.g. <code>python_executable</code>) is set, then this
value will always be treated as <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_refresh_settings">refresh_settings</code></td>
<td>
<p>logical; if <code>TRUE</code>, text will ignore the saved
settings in the profile and initiate a search of new settings.</p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_save_profile">save_profile</code></td>
<td>
<p>logical; if <code>TRUE</code>, the current text required python packages setting will
be saved for the future use.</p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_check_env">check_env</code></td>
<td>
<p>logical; check whether conda/virtual environment generated
by <code>textrpp_install()</code> exists</p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_textembed_test">textEmbed_test</code></td>
<td>
<p>logical; Test whether function (textEmbed) that requires python packages works.</p>
</td></tr>
<tr><td><code id="textrpp_initialize_+3A_prompt">prompt</code></td>
<td>
<p>logical; asking whether user wants to set the environment as default.</p>
</td></tr>
</table>

<hr>
<h2 id='textrpp_install'>Install text required python packages in conda or virtualenv environment</h2><span id='topic+textrpp_install'></span><span id='topic+textrpp_install_virtualenv'></span>

<h3>Description</h3>

<p>Install text required python packages (rpp) in a self-contained environment.
For macOS and Linux-based systems, this will also install Python itself via a &quot;miniconda&quot; environment, for
<code>textrpp_install</code>.  Alternatively, an existing conda installation may be
used, by specifying its path.  The default setting of <code>"auto"</code> will
locate and use an existing installation automatically, or download and
install one if none exists.
</p>
<p>For Windows, automatic installation of miniconda installation is not currently
available, so the user will need to install
<a href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html">miniconda
(or Anaconda) manually</a>.
</p>
<p>If you wish to install Python in a &quot;virtualenv&quot;, use the
<code>textrpp_install_virtualenv</code> function. It requires that you have a python version
and path to it (such as &quot;/usr/local/bin/python3.9&quot; for Mac and Linux.).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textrpp_install(
  conda = "auto",
  update_conda = FALSE,
  force_conda = FALSE,
  rpp_version = "rpp_version_system_specific_defaults",
  python_version = "python_version_system_specific_defaults",
  envname = "textrpp_condaenv",
  pip = TRUE,
  python_path = NULL,
  prompt = TRUE
)

textrpp_install_virtualenv(
  rpp_version = c("torch==2.0.0", "transformers==4.19.2", "numpy", "pandas", "nltk"),
  python_path = NULL,
  pip_version = NULL,
  bin = "python3",
  envname = "textrpp_virtualenv",
  prompt = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textrpp_install_+3A_conda">conda</code></td>
<td>
<p>character; path to conda executable. Default &quot;auto&quot; which
automatically find the path</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_update_conda">update_conda</code></td>
<td>
<p>Boolean; update to the latest version of Miniconda after install?
(should be combined with force_conda = TRUE)</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_force_conda">force_conda</code></td>
<td>
<p>Boolean; force re-installation if Miniconda is already installed at the requested path?</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_rpp_version">rpp_version</code></td>
<td>
<p>character; default is &quot;rpp_version_system_specific_defaults&quot;, because diffent systems require
different combinations of python version and packages. It is also possible to
specify your own, such as c(&quot;torch==2.0.0&quot;, &quot;transformers==4.19.2&quot;, &quot;numpy&quot;, &quot;pandas&quot;, &quot;nltk&quot;, &quot;scikit-learn&quot;,
&quot;datasets&quot;, &quot;evaluate&quot;).</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_python_version">python_version</code></td>
<td>
<p>character; default is &quot;python_version_system_specific_defaults&quot;. You can specify your
Python version for the condaenv yourself.
installation.</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_envname">envname</code></td>
<td>
<p>character; name of the conda-environment to install text required python packages.
Default is &quot;textrpp_condaenv&quot;.</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_pip">pip</code></td>
<td>
<p><code>TRUE</code> to use pip for installing rpp If <code>FALSE</code>, conda
package manager with conda-forge channel will be used for installing rpp.</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_python_path">python_path</code></td>
<td>
<p>character; path to Python only for virtualenvironment installation</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_prompt">prompt</code></td>
<td>
<p>logical; ask whether to proceed during the installation</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_pip_version">pip_version</code></td>
<td>
<p>character;</p>
</td></tr>
<tr><td><code id="textrpp_install_+3A_bin">bin</code></td>
<td>
<p>character; e.g., &quot;python&quot;, only for virtualenvironment installation</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# install text required python packages in a miniconda environment (macOS and Linux)
textrpp_install(prompt = FALSE)

# install text required python packages to an existing conda environment
textrpp_install(conda = "~/anaconda/bin/")

## End(Not run)
## Not run: 
# install text required python packages in a virtual environment
textrpp_install_virtualenv()

## End(Not run)
</code></pre>

<hr>
<h2 id='textrpp_uninstall'>Uninstall textrpp conda environment</h2><span id='topic+textrpp_uninstall'></span>

<h3>Description</h3>

<p>Removes the conda environment created by textrpp_install()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textrpp_uninstall(conda = "auto", prompt = TRUE, envname = "textrpp_condaenv")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textrpp_uninstall_+3A_conda">conda</code></td>
<td>
<p>path to conda executable, default to &quot;auto&quot; which automatically
finds the path</p>
</td></tr>
<tr><td><code id="textrpp_uninstall_+3A_prompt">prompt</code></td>
<td>
<p>logical; ask whether to proceed during the installation</p>
</td></tr>
<tr><td><code id="textrpp_uninstall_+3A_envname">envname</code></td>
<td>
<p>character; name of conda environment to remove</p>
</td></tr>
</table>

<hr>
<h2 id='textSimilarity'>Semantic Similarity</h2><span id='topic+textSimilarity'></span>

<h3>Description</h3>

<p>textSimilarity() Computes the semantic similarity between two text variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textSimilarity(x, y, method = "cosine", center = TRUE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textSimilarity_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed().</p>
</td></tr>
<tr><td><code id="textSimilarity_+3A_y">y</code></td>
<td>
<p>Word embeddings from textEmbed().</p>
</td></tr>
<tr><td><code id="textSimilarity_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed. Default is &quot;cosine&quot; (see also
&quot;spearmen&quot;, &quot;pearson&quot; as well as measures from textDistance() (which here is computed as 1 - textDistance)
including &quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; and &quot;minkowski&quot;).</p>
</td></tr>
<tr><td><code id="textSimilarity_+3A_center">center</code></td>
<td>
<p>(boolean; from base::scale) If center is TRUE then centering is done by subtracting the column means
(omitting NAs) of x from their corresponding columns, and if center is FALSE, no centering is done.</p>
</td></tr>
<tr><td><code id="textSimilarity_+3A_scale">scale</code></td>
<td>
<p>(boolean; from base::scale) If scale is TRUE then scaling is done by dividing the (centered)
columns of x by their standard deviations if center is TRUE, and the root mean square otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector comprising semantic similarity scores. The closer the value is to 1 when using the default
method, &quot;cosine&quot;, the higher the semantic similarity.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textDistance">textDistance</a></code> and <code><a href="#topic+textSimilarityNorm">textSimilarityNorm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute the semantic similarity between the embeddings from "harmonytext" and "satisfactiontext".
## Not run: 
similarity_scores &lt;- textSimilarity(
  x = word_embeddings_4$texts$harmonytext,
  y = word_embeddings_4$texts$satisfactiontext
)

# Show information about how similarity_scores were constructed.
comment(similarity_scores)

## End(Not run)
</code></pre>

<hr>
<h2 id='textSimilarityMatrix'>Semantic similarity across multiple word embeddings</h2><span id='topic+textSimilarityMatrix'></span>

<h3>Description</h3>

<p>textSimilarityMatrix computes semantic similarity scores between all combinations in a word embedding
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textSimilarityMatrix(x, method = "cosine", center = TRUE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textSimilarityMatrix_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed().</p>
</td></tr>
<tr><td><code id="textSimilarityMatrix_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed. Default is &quot;cosine&quot; (see also
&quot;spearmen&quot;, &quot;pearson&quot; as well as measures from textDistance() (which here is computed as 1 - textDistance)
including &quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; and &quot;minkowski&quot;).</p>
</td></tr>
<tr><td><code id="textSimilarityMatrix_+3A_center">center</code></td>
<td>
<p>(boolean; from base::scale) If center is TRUE then centering is done by subtracting the column means
(omitting NAs) of x from their corresponding columns, and if center is FALSE, no centering is done.</p>
</td></tr>
<tr><td><code id="textSimilarityMatrix_+3A_scale">scale</code></td>
<td>
<p>(boolean; from base::scale) If scale is TRUE then scaling is done by dividing the (centered)
columns of x by their standard deviations if center is TRUE, and the root mean square otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of semantic similarity scores
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textSimilarityNorm">textSimilarityNorm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>similarity_scores &lt;- textSimilarityMatrix(word_embeddings_4$texts$harmonytext[1:3, ])
round(similarity_scores, 3)
</code></pre>

<hr>
<h2 id='textSimilarityNorm'>Semantic similarity between a text variable and a word norm</h2><span id='topic+textSimilarityNorm'></span>

<h3>Description</h3>

<p>textSimilarityNorm() computes the semantic similarity between a text variable and a word norm
(i.e., a text represented by one word embedding that represent a construct).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textSimilarityNorm(x, y, method = "cosine", center = TRUE, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textSimilarityNorm_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed().</p>
</td></tr>
<tr><td><code id="textSimilarityNorm_+3A_y">y</code></td>
<td>
<p>Word embedding from textEmbed (from only one text).</p>
</td></tr>
<tr><td><code id="textSimilarityNorm_+3A_method">method</code></td>
<td>
<p>(character) Character string describing type of measure to be computed. Default is &quot;cosine&quot; (see also
&quot;spearmen&quot;, &quot;pearson&quot; as well as measures from textDistance() (which here is computed as 1 - textDistance)
including &quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; and &quot;minkowski&quot;).</p>
</td></tr>
<tr><td><code id="textSimilarityNorm_+3A_center">center</code></td>
<td>
<p>(boolean; from base::scale) If center is TRUE then centering is done by subtracting the column means
(omitting NAs) of x from their corresponding columns, and if center is FALSE, no centering is done.</p>
</td></tr>
<tr><td><code id="textSimilarityNorm_+3A_scale">scale</code></td>
<td>
<p>(boolean; from base::scale) If scale is TRUE then scaling is done by dividing the (centered)
columns of x by their standard deviations if center is TRUE, and the root mean square otherwise.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector comprising semantic similarity scores.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textSimilarity">textSimilarity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
library(tibble)
harmonynorm &lt;- c("harmony peace ")
satisfactionnorm &lt;- c("satisfaction achievement")

norms &lt;- tibble::tibble(harmonynorm, satisfactionnorm)
word_embeddings &lt;- word_embeddings_4$texts
word_embeddings_wordnorm &lt;- textEmbed(norms)
similarity_scores &lt;- textSimilarityNorm(
  word_embeddings$harmonytext,
  word_embeddings_wordnorm$harmonynorm
)

## End(Not run)
</code></pre>

<hr>
<h2 id='textSum'>Summarize texts. (experimental)</h2><span id='topic+textSum'></span>

<h3>Description</h3>

<p>Summarize texts. (experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textSum(
  x,
  min_length = 10L,
  max_length = 20L,
  model = "t5-small",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "warning",
  force_return_results = FALSE,
  return_text = TRUE,
  return_tensors = FALSE,
  clean_up_tokenization_spaces = FALSE,
  set_seed = 202208L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textSum_+3A_x">x</code></td>
<td>
<p>(string)  A variable or a tibble/dataframe with at least one character variable.</p>
</td></tr>
<tr><td><code id="textSum_+3A_min_length">min_length</code></td>
<td>
<p>(explicit integer; e.g., 10L)  The minimum number of tokens in the summed output.</p>
</td></tr>
<tr><td><code id="textSum_+3A_max_length">max_length</code></td>
<td>
<p>(explicit integer higher than min_length; e.g., 20L)  The maximum number of tokens
in the summed output.</p>
</td></tr>
<tr><td><code id="textSum_+3A_model">model</code></td>
<td>
<p>(string)  Specififcation of a pre-trained language model that have been fine-tuned on a
summarization task, such as ’bart-large-cnn’, ’t5-small’, ’t5-base’, ’t5-large’, ’t5-3b’, ’t5-11b’.</p>
</td></tr>
<tr><td><code id="textSum_+3A_device">device</code></td>
<td>
<p>(string)  Device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number.</p>
</td></tr>
<tr><td><code id="textSum_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textSum_+3A_logging_level">logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textSum_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot;
and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textSum_+3A_return_text">return_text</code></td>
<td>
<p>(boolean)  Whether or not the outputs should include the decoded text.</p>
</td></tr>
<tr><td><code id="textSum_+3A_return_tensors">return_tensors</code></td>
<td>
<p>(boolean)  Whether or not the output should include the prediction tensors (as token indices).</p>
</td></tr>
<tr><td><code id="textSum_+3A_clean_up_tokenization_spaces">clean_up_tokenization_spaces</code></td>
<td>
<p>(boolean)  Option to clean up the potential extra spaces in the returned text.</p>
</td></tr>
<tr><td><code id="textSum_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer) Set seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with summed text(s).
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textClassify">textClassify</a></code>, <code><a href="#topic+textGeneration">textGeneration</a></code>, <code><a href="#topic+textNER">textNER</a></code>,
<code><a href="#topic+textSum">textSum</a></code>, <code><a href="#topic+textQA">textQA</a></code>, <code><a href="#topic+textTranslate">textTranslate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# sum_examples &lt;- textSum(Language_based_assessment_data_8[1:2,1:2],
# min_length = 5L,
# max_length = 10L)

</code></pre>

<hr>
<h2 id='textTokenize'>Tokenize text-variables</h2><span id='topic+textTokenize'></span>

<h3>Description</h3>

<p>textTokenize() tokenizes according to different huggingface transformers
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTokenize(
  texts,
  model = "bert-base-uncased",
  max_token_to_sentence = 4,
  device = "cpu",
  tokenizer_parallelism = FALSE,
  model_max_length = NULL,
  hg_gated = FALSE,
  hg_token = Sys.getenv("HUGGINGFACE_TOKEN", unset = ""),
  trust_remote_code = FALSE,
  logging_level = "error"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTokenize_+3A_texts">texts</code></td>
<td>
<p>A character variable or a tibble/dataframe with at least one character variable.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_model">model</code></td>
<td>
<p>Character string specifying pre-trained language model (default 'bert-base-uncased').
For full list of options see pretrained models at
<a href="https://huggingface.co/transformers/pretrained_models.html">HuggingFace</a>.
For example use &quot;bert-base-multilingual-cased&quot;, &quot;openai-gpt&quot;,
&quot;gpt2&quot;, &quot;ctrl&quot;, &quot;transfo-xl-wt103&quot;, &quot;xlnet-base-cased&quot;, &quot;xlm-mlm-enfr-1024&quot;, &quot;distilbert-base-cased&quot;,
&quot;roberta-base&quot;, or &quot;xlm-roberta-base&quot;.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_max_token_to_sentence">max_token_to_sentence</code></td>
<td>
<p>(numeric) Maximum number of tokens in a string to handle before
switching to embedding text sentence by sentence.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_device">device</code></td>
<td>
<p>Name of device to use: 'cpu', 'gpu', 'gpu:k' or 'mps'/'mps:k' for MacOS, where k is a
specific device number.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>If TRUE this will turn on tokenizer parallelism. Default FALSE.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_model_max_length">model_max_length</code></td>
<td>
<p>The maximum length (in number of tokens) for the inputs to the transformer model
(default the value stored for the associated model).</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_hg_gated">hg_gated</code></td>
<td>
<p>Set to TRUE if the accessed model is gated.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_hg_token">hg_token</code></td>
<td>
<p>The token needed to access the gated model.
Create a token from the ['Settings' page](https://huggingface.co/settings/tokens) of
the Hugging Face website. An an environment variable HUGGINGFACE_TOKEN can
be set to avoid the need to enter the token each time.</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_trust_remote_code">trust_remote_code</code></td>
<td>
<p>use a model with custom code on the Huggingface Hub</p>
</td></tr>
<tr><td><code id="textTokenize_+3A_logging_level">logging_level</code></td>
<td>
<p>Set the logging level. Default: &quot;warning&quot;.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns tokens according to specified huggingface transformer.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textEmbed">textEmbed</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# tokens &lt;- textTokenize("hello are you?")

</code></pre>

<hr>
<h2 id='textTokenizeAndCount'>Tokenize and count</h2><span id='topic+textTokenizeAndCount'></span>

<h3>Description</h3>

<p>Tokenize and count
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTokenizeAndCount(data, n_remove_threshold = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTokenizeAndCount_+3A_data">data</code></td>
<td>
<p>(string) Language to tokenise and count.</p>
</td></tr>
<tr><td><code id="textTokenizeAndCount_+3A_n_remove_threshold">n_remove_threshold</code></td>
<td>
<p>(numeric) Threshold deciding which words to remove</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A word-frequency data frame (can be saved to a model object or compared in textDomainCompare).
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textDomainCompare">textDomainCompare</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
textTokenizeAndCount(Language_based_assessment_data_8["harmonytexts"])

## End(Not run)
</code></pre>

<hr>
<h2 id='textTopics'>BERTopics</h2><span id='topic+textTopics'></span>

<h3>Description</h3>

<p>textTopics creates and trains a BERTopic model (based on bertopic python packaged) on a
text-variable in a tibble/data.frame. (EXPERIMENTAL)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTopics(
  data,
  variable_name,
  embedding_model = "distilroberta",
  umap_model = "default",
  hdbscan_model = "default",
  vectorizer_model = "default",
  representation_model = "mmr",
  num_top_words = 10,
  n_gram_range = c(1, 3),
  stopwords = "english",
  min_df = 5,
  bm25_weighting = FALSE,
  reduce_frequent_words = TRUE,
  set_seed = 8,
  save_dir
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTopics_+3A_data">data</code></td>
<td>
<p>(tibble/data.frame) A tibble with a text-variable to be analysed, and optional
numeric/categorical variables that you might want to use for later analyses testing the
significance of topics in relation to these variables.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_variable_name">variable_name</code></td>
<td>
<p>(string)  Name of the text-variable in the data tibble that you want
to perform topic modeling on.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_embedding_model">embedding_model</code></td>
<td>
<p>(string) Name of the embedding model to use such as &quot;miniLM&quot;, &quot;mpnet&quot;,
&quot;multi-mpnet&quot;, &quot;distilroberta&quot;.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_umap_model">umap_model</code></td>
<td>
<p>(string) The dimension reduction algorithm, currently only &quot;default&quot;
is supported.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_hdbscan_model">hdbscan_model</code></td>
<td>
<p>(string) The clustering algorithm to use, currently only &quot;default&quot;
is supported.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_vectorizer_model">vectorizer_model</code></td>
<td>
<p>(string) Name of the vectorizer model, currently only &quot;default&quot;
is supported.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_representation_model">representation_model</code></td>
<td>
<p>(string) Name of the representation model used for topics,
including &quot;keybert&quot; or &quot;mmr&quot;.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_num_top_words">num_top_words</code></td>
<td>
<p>(integer) Determine the number of top words presented for each topic.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_n_gram_range">n_gram_range</code></td>
<td>
<p>(vector) Two-dimensional vector indicating the ngram range used for
the vectorizer model.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_stopwords">stopwords</code></td>
<td>
<p>(string) Name of the stopword dictionary to use.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_min_df">min_df</code></td>
<td>
<p>(integer) The minimum document frequency of terms.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_bm25_weighting">bm25_weighting</code></td>
<td>
<p>(boolean) Determine whether bm25_weighting is used for ClassTfidfTransformer.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_reduce_frequent_words">reduce_frequent_words</code></td>
<td>
<p>(boolean) Determine whether frequent words are reduced by ClassTfidfTransformer.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_set_seed">set_seed</code></td>
<td>
<p>(integer) The random seed for initialization of the umap model.</p>
</td></tr>
<tr><td><code id="textTopics_+3A_save_dir">save_dir</code></td>
<td>
<p>(string) The directory for saving results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A folder containing the model, data, folder with terms and values for each topic,
and the document-topic matrix. Moreover the model itself is returned formatted as a data.frame
together with metdata.
See <code><a href="#topic+textTopicsReduce">textTopicsReduce</a></code> <code><a href="#topic+textTopicsTest">textTopicsTest</a></code> and <code><a href="#topic+textTopicsWordcloud">textTopicsWordcloud</a></code>.
</p>

<hr>
<h2 id='textTopicsReduce'>textTopicsReduce (EXPERIMENTAL)</h2><span id='topic+textTopicsReduce'></span>

<h3>Description</h3>

<p>textTopicsReduce (EXPERIMENTAL)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTopicsReduce(
  data,
  data_var,
  n_topics = 10,
  load_path = "./results",
  save_dir,
  embedding_model = "default"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTopicsReduce_+3A_data">data</code></td>
<td>
<p>(tibble/data.frame) A tibble with a text-variable to be analysed, and optional
numeric/categorical variables that you might want to use for later analyses testing the
significance of topics in relation to these variables.</p>
</td></tr>
<tr><td><code id="textTopicsReduce_+3A_data_var">data_var</code></td>
<td>
<p>(string)  Name of the text-variable in the data tibble that you want
to perform topic modeling on.</p>
</td></tr>
<tr><td><code id="textTopicsReduce_+3A_n_topics">n_topics</code></td>
<td>
<p>(string) The dimension reduction algorithm, currently only &quot;default&quot;
is supported.</p>
</td></tr>
<tr><td><code id="textTopicsReduce_+3A_load_path">load_path</code></td>
<td>
<p>(string) The clustering algorithm to use, currently only &quot;default&quot;
is supported.</p>
</td></tr>
<tr><td><code id="textTopicsReduce_+3A_save_dir">save_dir</code></td>
<td>
<p>(string) The directory for saving results.</p>
</td></tr>
<tr><td><code id="textTopicsReduce_+3A_embedding_model">embedding_model</code></td>
<td>
<p>(string) Name of the embedding model to use such as &quot;miniLM&quot;, &quot;mpnet&quot;,
&quot;multi-mpnet&quot;, &quot;distilroberta&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A folder containing the model, data, folder with terms and values for each topic,
and the document-topic matrix. Moreover the model itself is returned formatted as a data.frame
together with metdata.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textTopics">textTopics</a></code> <code><a href="#topic+textTopicsTest">textTopicsTest</a></code> and <code><a href="#topic+textTopicsWordcloud">textTopicsWordcloud</a></code>.
</p>

<hr>
<h2 id='textTopicsTest'>Wrapper for topicsTest function from the topics package</h2><span id='topic+textTopicsTest'></span>

<h3>Description</h3>

<p>Wrapper for topicsTest function from the topics package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTopicsTest(
  model,
  x_variable = NULL,
  y_variable = NULL,
  controls = c(),
  test_method = "default",
  p_adjust_method = "fdr",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTopicsTest_+3A_model">model</code></td>
<td>
<p>(list) The trained model</p>
</td></tr>
<tr><td><code id="textTopicsTest_+3A_x_variable">x_variable</code></td>
<td>
<p>(string) The x variable name to be predicted, and to be plotted (only needed for regression or correlation)</p>
</td></tr>
<tr><td><code id="textTopicsTest_+3A_y_variable">y_variable</code></td>
<td>
<p>(string) The y variable name to be predicted, and to be plotted (only needed for regression or correlation)</p>
</td></tr>
<tr><td><code id="textTopicsTest_+3A_controls">controls</code></td>
<td>
<p>(vector) The control variables (not supported yet)</p>
</td></tr>
<tr><td><code id="textTopicsTest_+3A_test_method">test_method</code></td>
<td>
<p>(string) The test method to use, either &quot;correlation&quot;,&quot;t-test&quot;, &quot;linear_regression&quot;,&quot;logistic_regression&quot;, or &quot;ridge_regression&quot;</p>
</td></tr>
<tr><td><code id="textTopicsTest_+3A_p_adjust_method">p_adjust_method</code></td>
<td>
<p>(character) Method to adjust/correct p-values for multiple comparisons
(default = &quot;none&quot;; see also &quot;holm&quot;, &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;,  &quot;fdr&quot;).</p>
</td></tr>
<tr><td><code id="textTopicsTest_+3A_...">...</code></td>
<td>
<p>Parameter settings from topicsTest in the topics-package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the test results, test method, and prediction variable
</p>

<hr>
<h2 id='textTopicsTree'>textTopicsTest (EXPERIMENTAL) to get the hierarchical topic tree</h2><span id='topic+textTopicsTree'></span>

<h3>Description</h3>

<p>textTopicsTest (EXPERIMENTAL) to get the hierarchical topic tree
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTopicsTree(topic_model, data, data_var)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTopicsTree_+3A_topic_model">topic_model</code></td>
<td>
<p>(list) The output from textTopics.</p>
</td></tr>
<tr><td><code id="textTopicsTree_+3A_data">data</code></td>
<td>
<p>(tibble/data.frame) A tibble with the data</p>
</td></tr>
<tr><td><code id="textTopicsTree_+3A_data_var">data_var</code></td>
<td>
<p>(string) The name of the text variable that the topic model was trained on</p>
</td></tr>
</table>


<h3>Value</h3>

<p>prints a hierarchical topic tree on the console
</p>

<hr>
<h2 id='textTopicsWordcloud'>Plot word clouds</h2><span id='topic+textTopicsWordcloud'></span>

<h3>Description</h3>

<p>This function create word clouds and topic fugures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTopicsWordcloud(
  model = NULL,
  ngrams = NULL,
  test = NULL,
  save_dir,
  seed = 2024,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTopicsWordcloud_+3A_model">model</code></td>
<td>
<p>(list) A trained topics model. For examples from topicsModel(). Should be NULL if plotting ngrams.</p>
</td></tr>
<tr><td><code id="textTopicsWordcloud_+3A_ngrams">ngrams</code></td>
<td>
<p>(list) The output from the the topicsGram() function . Should be NULL if plotting topics.</p>
</td></tr>
<tr><td><code id="textTopicsWordcloud_+3A_test">test</code></td>
<td>
<p>(list) The test results; if plotting according to dimension(s) include the object from topicsTest() function.</p>
</td></tr>
<tr><td><code id="textTopicsWordcloud_+3A_save_dir">save_dir</code></td>
<td>
<p>(string) The directory to save the plots.</p>
</td></tr>
<tr><td><code id="textTopicsWordcloud_+3A_seed">seed</code></td>
<td>
<p>(integer) The seed to set for reproducibility; need to be the same seed number as in in</p>
</td></tr>
<tr><td><code id="textTopicsWordcloud_+3A_...">...</code></td>
<td>
<p>Parameters from the topicsPlot() function in the topics pacakge.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function saves figures in the save_dir.
</p>

<hr>
<h2 id='textTrain'>Trains word embeddings</h2><span id='topic+textTrain'></span>

<h3>Description</h3>

<p>textTrain() trains word embeddings to a numeric (ridge regression) or categorical (random forest) variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrain(x, y, force_train_method = "automatic", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrain_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed (or textEmbedLayerAggreation).
Can analyze several variables at the same time; but if training to several
outcomes at the same time use a tibble within the list as input rather than just a
tibble input (i.e., keep the name of the wordembedding).</p>
</td></tr>
<tr><td><code id="textTrain_+3A_y">y</code></td>
<td>
<p>Numeric variable to predict. Can be several; although then make
sure to have them within a tibble (this is required
even if it is only one outcome but several word embeddings variables).</p>
</td></tr>
<tr><td><code id="textTrain_+3A_force_train_method">force_train_method</code></td>
<td>
<p>Default is &quot;automatic&quot;, so if y is a factor
random_forest is used, and if y is numeric ridge regression
is used. This can be overridden using &quot;regression&quot; or &quot;random_forest&quot;.</p>
</td></tr>
<tr><td><code id="textTrain_+3A_...">...</code></td>
<td>
<p>Arguments from textTrainRegression or textTrainRandomForest
the textTrain function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correlation between predicted and observed values; as well as a
tibble of predicted values (t-value, degree of freedom (df), p-value,
alternative-hypothesis, confidence interval, correlation coefficient).
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textTrainRegression">textTrainRegression</a></code>, <code><a href="#topic+textTrainRandomForest">textTrainRandomForest</a></code> and
<code><a href="#topic+textTrainLists">textTrainLists</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examines how well the embeddings from "harmonytext" can
# predict the numeric variable "hilstotal" in the pre-included
# dataset "Language_based_assessment_data_8".

## Not run: 
trained_model &lt;- textTrain(
  x = word_embeddings_4$texts$harmonytext,
  y = Language_based_assessment_data_8$hilstotal
)

# Examine results (t-value, degree of freedom (df), p-value,
# alternative-hypothesis, confidence interval, correlation coefficient).

trained_model$results

## End(Not run)
</code></pre>

<hr>
<h2 id='textTrainExamples'>Show language examples (Experimental)</h2><span id='topic+textTrainExamples'></span><span id='topic+textPredictExamples'></span>

<h3>Description</h3>

<p>This function selects language examples that been used in the textTrain() or textAssess() functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrainExamples(
  text,
  x_variable,
  y_variable = NULL,
  type = "default",
  n_tile = 4,
  n_examples = 5,
  jitter = NULL,
  filter_words = NULL,
  target_color = "darkgreen",
  predictions_color = "darkblue",
  error_color = "darkred",
  distribution_color = c("#00508c", "#805259", "#a71200", "#0a6882", "#a4a4a4",
    "#e04b39", "#19956e", "#22a567", "#5c8a59"),
  figure_format = "svg",
  scatter_legend_dot_size = 3,
  scatter_legend_bg_dot_size = 2,
  scatter_legend_dots_alpha = 0.8,
  scatter_legend_bg_dots_alpha = 0.2,
  scatter_show_axis_values = TRUE,
  scatter_legend_regression_line_colour = NULL,
  x_axis_range = NULL,
  y_axis_range = NULL,
  grid_legend_x_axes_label = NULL,
  grid_legend_y_axes_label = NULL,
  seed = 42
)

textPredictExamples(
  text,
  x_variable,
  y_variable = NULL,
  type = "default",
  n_tile = 4,
  n_examples = 5,
  jitter = NULL,
  filter_words = NULL,
  target_color = "darkgreen",
  predictions_color = "darkblue",
  error_color = "darkred",
  distribution_color = c("#00508c", "#805259", "#a71200", "#0a6882", "#a4a4a4",
    "#e04b39", "#19956e", "#22a567", "#5c8a59"),
  figure_format = "svg",
  scatter_legend_dot_size = 3,
  scatter_legend_bg_dot_size = 2,
  scatter_legend_dots_alpha = 0.8,
  scatter_legend_bg_dots_alpha = 0.2,
  scatter_show_axis_values = TRUE,
  scatter_legend_regression_line_colour = NULL,
  x_axis_range = NULL,
  y_axis_range = NULL,
  grid_legend_x_axes_label = NULL,
  grid_legend_y_axes_label = NULL,
  seed = 42
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrainExamples_+3A_text">text</code></td>
<td>
<p>(string) the language that was used for prediction/assessment/classification.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_x_variable">x_variable</code></td>
<td>
<p>(numeric) the variable used for training (y).</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_y_variable">y_variable</code></td>
<td>
<p>(numeric) the outcome from the model (i.e., y_hat).</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_type">type</code></td>
<td>
<p>(string) If you are plotting errors between predicted and targeted scores, you can set the type to &quot;prediction_errors&quot;,
to produce two extra plots: distribution of scores and absolute error.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_n_tile">n_tile</code></td>
<td>
<p>(integer) the n tile to split the data in (to show the most extreme tiles in different colours).</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_n_examples">n_examples</code></td>
<td>
<p>(integer) the number of language examples to show.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_jitter">jitter</code></td>
<td>
<p>(integer) the percentage of jitter to add to the data for the scatter plot.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_filter_words">filter_words</code></td>
<td>
<p>(character vector) words required to be included in examples.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_target_color">target_color</code></td>
<td>
<p>(string)</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_predictions_color">predictions_color</code></td>
<td>
<p>(string) = &quot;darkblue&quot;,</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_error_color">error_color</code></td>
<td>
<p>=  (string) &quot;darkred&quot;,</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_distribution_color">distribution_color</code></td>
<td>
<p>(string) colors of the distribution plot</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_figure_format">figure_format</code></td>
<td>
<p>(string) file format of the figures.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_scatter_legend_dot_size">scatter_legend_dot_size</code></td>
<td>
<p>(integer) The size of dots in the scatter legend.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_scatter_legend_bg_dot_size">scatter_legend_bg_dot_size</code></td>
<td>
<p>(integer) The size of background dots in the scatter legend.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_scatter_legend_dots_alpha">scatter_legend_dots_alpha</code></td>
<td>
<p>(numeric) The transparency alphe level of the dots.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_scatter_legend_bg_dots_alpha">scatter_legend_bg_dots_alpha</code></td>
<td>
<p>(numeric) The transparency alphe level of the background dots.
For example: c(1,0,1) result in one dot in each quadrant except for the middle quadrant.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_scatter_show_axis_values">scatter_show_axis_values</code></td>
<td>
<p>(boolean) If TRUE, the estimate values are shown on the distribution plot axes.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_scatter_legend_regression_line_colour">scatter_legend_regression_line_colour</code></td>
<td>
<p>(string) If a colour string is added, a regression line will be plotted.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_x_axis_range">x_axis_range</code></td>
<td>
<p>(numeric vector) range of x axis (e.g., c(1, 100)).</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_y_axis_range">y_axis_range</code></td>
<td>
<p>(numeric vector) range of y axis (e.g., c(1, 100)).</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_grid_legend_x_axes_label">grid_legend_x_axes_label</code></td>
<td>
<p>x-axis label of the grid topic plot.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_grid_legend_y_axes_label">grid_legend_y_axes_label</code></td>
<td>
<p>y-axis label of the grid topic plot.</p>
</td></tr>
<tr><td><code id="textTrainExamples_+3A_seed">seed</code></td>
<td>
<p>(integer) The seed to set for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble including examples with descriptive variables.
</p>

<hr>
<h2 id='textTrainLists'>Train lists of word embeddings</h2><span id='topic+textTrainLists'></span>

<h3>Description</h3>

<p>textTrainLists() individually trains word embeddings from several text variables to several numeric or categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrainLists(
  x,
  y,
  force_train_method = "automatic",
  save_output = "all",
  method_cor = "pearson",
  eval_measure = "rmse",
  p_adjust_method = "holm",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrainLists_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed (or textEmbedLayerAggreation). It is possible to have word embeddings
from one text variable and several numeric/categorical variables;
or vice verse, word embeddings from several text variables to one numeric/categorical variable.
It is not possible to mix numeric and categorical variables.</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_y">y</code></td>
<td>
<p>Tibble with several numeric or categorical variables to predict. Please note that you cannot mix numeric and
categorical variables.</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_force_train_method">force_train_method</code></td>
<td>
<p>(character) Default is &quot;automatic&quot;; see also &quot;regression&quot; and &quot;random_forest&quot;.</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_save_output">save_output</code></td>
<td>
<p>(character) Option not to save all output; default &quot;all&quot;. See also &quot;only_results&quot;
and &quot;only_results_predictions&quot;.</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_method_cor">method_cor</code></td>
<td>
<p>(character) A character string describing type of correlation (default &quot;Pearson&quot;).</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_eval_measure">eval_measure</code></td>
<td>
<p>(character) Type of evaluative measure to assess models on (default &quot;rmse&quot;).</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_p_adjust_method">p_adjust_method</code></td>
<td>
<p>Method to adjust/correct p-values for multiple comparisons.
(default = &quot;holm&quot;; see also &quot;none&quot;, &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;,  &quot;fdr&quot;).</p>
</td></tr>
<tr><td><code id="textTrainLists_+3A_...">...</code></td>
<td>
<p>Arguments from textTrainRegression or textTrainRandomForest (the textTrain function).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Correlations between predicted and observed values (t-value, degree of freedom (df), p-value,
confidence interval, alternative hypothesis, correlation coefficient) stored in a dataframe.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textTrain">textTrain</a></code>, <code><a href="#topic+textTrainRegression">textTrainRegression</a></code> and  <code><a href="#topic+textTrainRandomForest">textTrainRandomForest</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examines how well the embeddings from Language_based_assessment_data_8 can
# predict the numerical numerical variables in Language_based_assessment_data_8.
# The training is done combination wise, i.e., correlations are tested pair wise,
# column: 1-5,1-6,2-5,2-6, resulting in a dataframe with four rows.

## Not run: 
word_embeddings &lt;- word_embeddings_4$texts[1:2]
ratings_data &lt;- Language_based_assessment_data_8[5:6]

trained_model &lt;- textTrainLists(
  x = word_embeddings,
  y = ratings_data
)

# Examine results (t-value, degree of freedom (df), p-value,
# alternative-hypothesis, confidence interval, correlation coefficient).

trained_model$results

## End(Not run)

</code></pre>

<hr>
<h2 id='textTrainN'>Cross-validated accuracies across sample-sizes</h2><span id='topic+textTrainN'></span>

<h3>Description</h3>

<p>textTrainN() computes cross-validated correlations for different sample-sizes of a data set.
The cross-validation process can be repeated several times to enhance the reliability of the evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrainN(
  x,
  y,
  sample_percents = c(25, 50, 75, 100),
  handle_word_embeddings = "individually",
  n_cross_val = 1,
  sampling_strategy = "subsets",
  use_same_penalty_mixture = TRUE,
  model = "regression",
  penalty = 10^seq(-16, 16),
  mixture = c(0),
  seed = 2024,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrainN_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed (or textEmbedLayerAggregation).
If several word embedding are provided in a list they will be concatenated.</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_y">y</code></td>
<td>
<p>Numeric variable to predict.</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_sample_percents">sample_percents</code></td>
<td>
<p>(numeric) Numeric vector that specifies the percentages of the total number of
data points to include in each sample (default = c(25,50,75,100), i.e., correlations are evaluated
for 25
each new sample.</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_handle_word_embeddings">handle_word_embeddings</code></td>
<td>
<p>Determine whether to use a list of word embeddings or an individual
word_embedding (default = &quot;individually&quot;, also &quot;concatenate&quot;). If a list of word embeddings are
provided, then they will be concatenated.</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_n_cross_val">n_cross_val</code></td>
<td>
<p>(numeric) Value that determines the number of times to repeat the cross-validation (i.e., number of tests).
(default = 1, i.e., cross-validation is only performed once). Warning: The training process gets
proportionately slower to the number of cross-validations, resulting in a time complexity that increases
with a factor of n (n cross-validations).</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_sampling_strategy">sampling_strategy</code></td>
<td>
<p>Sample a &quot;random&quot; sample for each subset from all data or sample a &quot;subset&quot; from the
larger subsets (i.e., each subset contain the same data).</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_use_same_penalty_mixture">use_same_penalty_mixture</code></td>
<td>
<p>If TRUE it only searches the penalty and mixture search grid once, and then use the same
thereafter; if FALSE, it searches the grid every time.</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_model">model</code></td>
<td>
<p>Type of model. Default is &quot;regression&quot;; see also &quot;logistic&quot; and &quot;multinomial&quot; for classification.</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_penalty">penalty</code></td>
<td>
<p>(numeric) Hyper parameter that is tuned (default = 10^seq(-16,16)).</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_mixture">mixture</code></td>
<td>
<p>A number between 0 and 1 (inclusive) that reflects the proportion of L1 regularization
(i.e. lasso) in the model (for more information see the linear_reg-function in the parsnip-package).
When mixture = 1, it is a pure lasso model while mixture = 0 indicates that ridge regression is being
used (specific engines only).</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_seed">seed</code></td>
<td>
<p>(numeric) Set different seed (default = 2024).</p>
</td></tr>
<tr><td><code id="textTrainN_+3A_...">...</code></td>
<td>
<p>Additional parameters from textTrainRegression.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble containing correlations for each sample. If n_cross_val &gt; 1, correlations for
each new cross-validation, along with standard-deviation, mean and standard error of correlation is included in the
tibble. The information in the tibble is visualised via the textTrainNPlot function.
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textTrainNPlot">textTrainNPlot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Compute correlations for 25%, 50%, 75% and 100% of the data in word_embeddings and perform
# cross-validation thrice.

## Not run: 
tibble_to_plot &lt;- textTrainN(
  x = word_embeddings_4$texts$harmonytext,
  y = Language_based_assessment_data_8$hilstotal,
  sample_percents = c(25, 50, 75, 100),
  n_cross_val = 3
)

# tibble_to_plot contains correlation-coefficients for each cross_validation and
# standard deviation and mean value for each sample. The tibble can be plotted
# using the testTrainNPlot function.

# Examine tibble
tibble_to_plot

## End(Not run)
</code></pre>

<hr>
<h2 id='textTrainNPlot'>Plot cross-validated accuracies across sample sizes</h2><span id='topic+textTrainNPlot'></span>

<h3>Description</h3>

<p>textTrainNPlot() plots cross-validated correlation coefficients across different
sample-sizes from the object returned by the textTrainN function. If the number
of cross-validations exceed one, then error-bars will be included in the plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrainNPlot(
  results_data,
  breaks = NULL,
  x_unit = "percent",
  y_range = NULL,
  title = "Cross-validated correlation coefficients across sample sizes",
  x_axes_label = "Sample Size (percent)",
  y_axes_label = "Correlation Coefficient (r)",
  point_color = "#5dc688",
  error_bar = "std_err",
  bar_color = "#60A1F7",
  line_color = "grey",
  bar_width = 1,
  bar_size = 0.8,
  line_size = 0.6,
  line_type = "straight",
  point_size = 3,
  log_transform_x = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrainNPlot_+3A_results_data">results_data</code></td>
<td>
<p>(list) One or several objects returned by the function textTrainN
as a list (e.g, list(object1, object2)). Also, if several models are provided,
then one can add a vector c() with settings (i.e the parameters below) for each model
(make sure to add the settings in the order as the models are ordered,
if you look to keep the original settings then write &quot;&quot;).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_breaks">breaks</code></td>
<td>
<p>(numeric) Vector containing the percents of the total number of data points that is
included in each sample (default = NULL, which takes the breaks from the percentages).
If several models are provided, then one can add a vector c() with settings for each model
(make sure to add the settings in the order as the models are ordered).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_x_unit">x_unit</code></td>
<td>
<p>(character, &quot;percent&quot; or &quot;quantity&quot;) Determines whether the x-axis-values should represent
the number of elements in each sample, or the number of percent of the total data they represent
(default = &quot;percent&quot;).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_y_range">y_range</code></td>
<td>
<p>(numeric) Optional. Determines the y_range. E.g, y_range = c(1,2) sets the y_range from
1 to 2 (default = NULL).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_title">title</code></td>
<td>
<p>(character) Determine plot title (default = &quot;Cross-validated correlation coefficients
across different sample sizes&quot;).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_x_axes_label">x_axes_label</code></td>
<td>
<p>(character) Determine x-axis-label (default = &quot;Sample Size (percent)&quot;).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_y_axes_label">y_axes_label</code></td>
<td>
<p>(character) Determine y-axis-label (default = &quot;Correlation Coefficient (r)&quot;).</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_point_color">point_color</code></td>
<td>
<p>(character, (Hex color codes)) Determine point color (default = &quot;#5dc688&quot;). Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_error_bar">error_bar</code></td>
<td>
<p>Default &quot;std_err&quot;; see also &quot;std&quot;, NULL. Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_bar_color">bar_color</code></td>
<td>
<p>(character, (Hex color codes)) Determine error-bar color (default = &quot;#60A1F7&quot;). Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_line_color">line_color</code></td>
<td>
<p>(character, (Hex color codes)) Determine line color (default = &quot;grey&quot;). Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_bar_width">bar_width</code></td>
<td>
<p>(numeric) Determine bar-width (default = 1). Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_bar_size">bar_size</code></td>
<td>
<p>(numeric) Determine bar-size (default = 1). Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_line_size">line_size</code></td>
<td>
<p>(numeric) Determine line-size (default = 1). Can set a vector
if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_line_type">line_type</code></td>
<td>
<p>(character, either &quot;straight&quot; or &quot;smooth&quot;) Determine line-type (default = &quot;straight&quot;).
Can set a vector if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_point_size">point_size</code></td>
<td>
<p>(numeric) Determine points size (default = 1). Can set a vector if several results_data are provided.</p>
</td></tr>
<tr><td><code id="textTrainNPlot_+3A_log_transform_x">log_transform_x</code></td>
<td>
<p>(boolean) Determine wether to log-transform x in case of displaying number of samples
(default = FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot with correlation coefficient on y-axis and sample size in quantity or percent on x axis.
If number och cross-validations exceed 1, then error bars measuring standard deviations will be plotted.
</p>


<h3>Plot Example</h3>

<p>Example of a plot created by textTrainNPlot.
<img src="../help/figures/textTrainNPlot.image.png" width=100% alt="textTrainNPlot.image.png" />
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textTrainN">textTrainN</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot cross-validated correlation coefficients across different sample-sizes from the object
# returned by the textTrainN function.

## Not run: 
# Plot the performance of a single model across different sample sizes
plot_object1 &lt;- textTrainNPlot(
  train_data = tibble_to_plot,
  n_cross_val = 3,
  x_unit = "quantity"
)

# Visualize plot
plot_object1

# Plot the performance of several models across different sample sizes.
plot_object2 &lt;- textTrainNPlot(train_data = list(object1, object2, object3),
                               n_cross_val = c(2,1,1),
                               line_color = c("","","#0000FF")) # "" gives the default settings.
# Visualize plot
plot_object2

## End(Not run)
</code></pre>

<hr>
<h2 id='textTrainRandomForest'>Trains word embeddings usig random forest</h2><span id='topic+textTrainRandomForest'></span>

<h3>Description</h3>

<p>textTrainRandomForest() trains word embeddings to a categorical variable using random forest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrainRandomForest(
  x,
  y,
  x_append = NULL,
  append_first = FALSE,
  cv_method = "validation_split",
  outside_folds = 10,
  inside_folds = 3/4,
  strata = "y",
  outside_strata = TRUE,
  outside_breaks = 4,
  inside_strata = TRUE,
  inside_breaks = 4,
  mode_rf = "classification",
  preprocess_step_center = FALSE,
  preprocess_scale_center = FALSE,
  preprocess_PCA = NA,
  extremely_randomised_splitrule = "extratrees",
  mtry = c(1, 10, 20, 40),
  min_n = c(1, 10, 20, 40),
  trees = c(1000),
  parameter_selection_method = "lowest_mtry",
  eval_measure = "bal_accuracy",
  model_description = "Consider writing a description of your model here",
  multi_cores = "multi_cores_sys_default",
  save_output = "all",
  simulate.p.value = FALSE,
  seed = 2020,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrainRandomForest_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_y">y</code></td>
<td>
<p>Categorical variable to predict.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_x_append">x_append</code></td>
<td>
<p>(optional) Variables to be appended after the word embeddings (x);
if wanting to preappend them before the word embeddings use the option
first = TRUE.  If not wanting to train with word embeddings, set x_append = NULL (default = null).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_append_first">append_first</code></td>
<td>
<p>(boolean) Option to add variables before or after all word embeddings (default = FALSE).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_cv_method">cv_method</code></td>
<td>
<p>(character) Cross-validation method to use within a pipeline of nested outer and
inner loops of folds (see nested_cv in rsample). Default is using cv_folds in the
outside folds and &quot;validation_split&quot; using rsample::validation_split in the inner loop to
achieve a development and assessment set (note that for validation_split the inside_folds
should be a proportion, e.g., inside_folds = 3/4); whereas &quot;cv_folds&quot; uses rsample::vfold_cv
to achieve n-folds in both the outer and inner loops.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_outside_folds">outside_folds</code></td>
<td>
<p>(numeric) Number of folds for the outer folds (default = 10).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_inside_folds">inside_folds</code></td>
<td>
<p>(numeric) Number of folds for the inner folds (default = 3/4).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_strata">strata</code></td>
<td>
<p>(string or tibble; default &quot;y&quot;) Variable to stratify according; if a string the
variable needs to be in the training set - if you want to stratify according to another variable
you can include it as a tibble (please note you can only add 1 variable to stratify according).
Can set it to NULL.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_outside_strata">outside_strata</code></td>
<td>
<p>(boolean) Whether to stratify the outside folds.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_outside_breaks">outside_breaks</code></td>
<td>
<p>(numeric) The number of bins wanted to stratify a numeric stratification variable
in the outer cross-validation loop (default = 4).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_inside_strata">inside_strata</code></td>
<td>
<p>(boolean) Whether to stratify the outside folds.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_inside_breaks">inside_breaks</code></td>
<td>
<p>The number of bins wanted to stratify a numeric stratification variable
in the inner cross-validation loop (default = 4).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_mode_rf">mode_rf</code></td>
<td>
<p>Default is &quot;classification&quot; (&quot;regression&quot; is not supported yet).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_preprocess_step_center">preprocess_step_center</code></td>
<td>
<p>(boolean) Normalizes dimensions to have a mean of zero; default is set to FALSE
For more info see (step_center in recipes).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_preprocess_scale_center">preprocess_scale_center</code></td>
<td>
<p>(boolean) Normalizes dimensions to have a standard deviation of one;
default is set to FALSE. For more info see (step_scale in recipes).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_preprocess_pca">preprocess_PCA</code></td>
<td>
<p>Pre-processing threshold for PCA. Can select amount of variance to
retain (e.g., .90 or as a grid c(0.80, 0.90)); or
number of components to select (e.g., 10). (To skip this step, set preprocess_PCA to NA) Default is &quot;min_halving&quot;,
which is a function that selects the number of PCA components based on number of participants and feature
(word embedding dimensions) in the data. The formula is:
preprocess_PCA = round(max(min(number_features/2), number_participants/2), min(50, number_features))).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_extremely_randomised_splitrule">extremely_randomised_splitrule</code></td>
<td>
<p>Default is &quot;extratrees&quot;, which thus implement a random forest;
can also select: NULL, &quot;gini&quot; or &quot;hellinger&quot;; if these are selected your mtry settings will
be overridden (see Geurts et al. (2006) Extremely randomized trees for details; and see the ranger r-package
for details on implementations).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_mtry">mtry</code></td>
<td>
<p>Hyper parameter that may be tuned; default: c(1, 20, 40),</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_min_n">min_n</code></td>
<td>
<p>Hyper parameter that may be tuned; default: c(1, 20, 40)</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_trees">trees</code></td>
<td>
<p>Number of trees to use (default 1000).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_parameter_selection_method">parameter_selection_method</code></td>
<td>
<p>If several results are tied for different parameters (i.e., mtry or min_n),
then select the &quot;lowest_mtry&quot;, &quot;highest_mtry&quot;, &quot;median_mtry&quot;, or &quot;lowest_min_n&quot;, the &quot;highest_min_n&quot; or
the &quot;median_min_n&quot; order of all the tied mtry/min_n</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_eval_measure">eval_measure</code></td>
<td>
<p>(character) Measure to evaluate the models in order to select the best
hyperparameters default &quot;roc_auc&quot;; see also &quot;accuracy&quot;, &quot;bal_accuracy&quot;, &quot;sens&quot;, &quot;spec&quot;, &quot;precision&quot;,
&quot;kappa&quot;, &quot;f_measure&quot;.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_model_description">model_description</code></td>
<td>
<p>(character) Text to describe your model (optional; good when sharing the model with others).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_multi_cores">multi_cores</code></td>
<td>
<p>If TRUE it enables the use of multiple cores if the computer system allows for it (i.e.,
only on unix, not windows). Hence it makes the analyses considerably faster to run. Default is
&quot;multi_cores_sys_default&quot;, where it automatically uses TRUE for Mac and Linux and FALSE for Windows.
Note that having it to TRUE does not enable reproducable results at the moment (i.e., cannot set seed).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_save_output">save_output</code></td>
<td>
<p>(character) Option not to save all output; default &quot;all&quot;. See also &quot;only_results&quot; and
&quot;only_results_predictions&quot;.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_simulate.p.value">simulate.p.value</code></td>
<td>
<p>(Boolean) From fisher.test: a logical indicating whether to compute p-values
by Monte Carlo simulation, in larger than 2 × 2 tables.</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_seed">seed</code></td>
<td>
<p>(numeric) Set different seed (default = 2020).</p>
</td></tr>
<tr><td><code id="textTrainRandomForest_+3A_...">...</code></td>
<td>
<p>For example settings in yardstick::accuracy to set event_level (e.g., event_level = &quot;second&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with roc_curve_data, roc_curve_plot, truth and predictions, preprocessing_recipe,
final_model, model_description chisq and fishers test as well as evaluation measures, e.g., including accuracy,
f_meas and roc_auc (for details on these measures see the yardstick r-package documentation).
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textEmbedLayerAggregation">textEmbedLayerAggregation</a></code>, <code><a href="#topic+textTrainLists">textTrainLists</a></code> and
<code><a href="#topic+textTrainRegression">textTrainRegression</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examines how well the embeddings from column "harmonywords" in
# Language_based_assessment_data_8 can binarily classify gender.

## Not run: 
trained_model &lt;- textTrainRandomForest(
  x = word_embeddings_4$texts$harmonywords,
  y = as.factor(Language_based_assessment_data_8$gender),
  trees = c(1000, 1500),
  mtry = c(1), # this is short because of testing
  min_n = c(1), # this is short because of testing
  multi_cores = FALSE # This is FALSE due to CRAN testing and Windows machines.
)


# Examine results (t-value, degree of freedom (df), p-value,
# alternative-hypothesis, confidence interval, correlation coefficient).

trained_model$results

## End(Not run)
</code></pre>

<hr>
<h2 id='textTrainRegression'>Train word embeddings to a numeric variable.</h2><span id='topic+textTrainRegression'></span>

<h3>Description</h3>

<p>textTrainRegression() trains word embeddings to a numeric or a factor variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTrainRegression(
  x,
  y,
  x_append = NULL,
  append_first = FALSE,
  cv_method = "validation_split",
  id_variable = NULL,
  outside_folds = 10,
  inside_folds = 3/4,
  strata = "y",
  outside_strata = TRUE,
  outside_breaks = 4,
  inside_strata = TRUE,
  inside_breaks = 4,
  model = "regression",
  eval_measure = "default",
  save_aggregated_word_embedding = FALSE,
  language_distribution = NULL,
  language_distribution_min_words = 3,
  preprocess_step_center = TRUE,
  preprocess_step_scale = TRUE,
  preprocess_PCA = NA,
  penalty = 10^seq(-6, 6),
  parameter_selection_method = "lowest_penalty",
  mixture = c(0),
  first_n_predictors = NA,
  impute_missing = FALSE,
  method_cor = "pearson",
  model_description = "Consider writing a description of your model here",
  multi_cores = "multi_cores_sys_default",
  save_output = "all",
  simulate.p.value = FALSE,
  seed = 2020,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTrainRegression_+3A_x">x</code></td>
<td>
<p>Word embeddings from textEmbed (or textEmbedLayerAggregation). If several word embedding are
provided in a list they will be concatenated.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_y">y</code></td>
<td>
<p>Numeric variable to predict.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_x_append">x_append</code></td>
<td>
<p>(optional) Variables to be appended after the word embeddings (x);
if wanting to preappend them before the word embeddings use the option first = TRUE.
If not wanting to train with word embeddings, set x = NULL (default = NULL).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_append_first">append_first</code></td>
<td>
<p>(boolean) Option to add variables before or after all word embeddings (default = False).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_cv_method">cv_method</code></td>
<td>
<p>(character) Cross-validation method to use within a pipeline of nested outer and inner loops
of folds (see nested_cv in rsample). Default is using &quot;cv_folds&quot; in the outside folds and &quot;validation_split&quot;
using rsample::validation_split in the inner loop to achieve a development and assessment set (note that
for &quot;validation_split&quot; the inside_folds should be a proportion, e.g., inside_folds = 3/4); whereas &quot;cv_folds&quot;
uses rsample::vfold_cv to achieve n-folds in both the outer and inner loops. Use &quot;group_cv&quot; to ensure that all cases
with the same ID remain in the same fold. (it uses rsample::group_vfold_cv uses  to ensure that all cases with the same
ID remain in the same fold. group_vfold_cv cannot handle stratification, so if that is requested,
it tries to approximate stratification while preserving group integrity.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_id_variable">id_variable</code></td>
<td>
<p>(variable) If specifying cv_method = &quot;group_cv&quot;, you need to submit an id variable here.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_outside_folds">outside_folds</code></td>
<td>
<p>(numeric) Number of folds for the outer folds (default = 10).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_inside_folds">inside_folds</code></td>
<td>
<p>(numeric) The proportion of data to be used for modeling/analysis; (default proportion = 3/4).
For more information see validation_split in rsample.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_strata">strata</code></td>
<td>
<p>(string or tibble; default &quot;y&quot;) Variable to stratify according;
if a string the variable needs to be in the training set - if you want to stratify
according to another variable you can include it as a tibble (please note you
can only add 1 variable to stratify according). Can set it to NULL.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_outside_strata">outside_strata</code></td>
<td>
<p>(boolean) Whether to stratify the outside folds.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_outside_breaks">outside_breaks</code></td>
<td>
<p>(numeric) The number of bins wanted to stratify a numeric stratification variable in the
outer cross-validation loop (default = 4).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_inside_strata">inside_strata</code></td>
<td>
<p>Whether to stratify the outside folds.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_inside_breaks">inside_breaks</code></td>
<td>
<p>The number of bins wanted to stratify a numeric stratification variable in the inner
cross-validation loop (default = 4).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_model">model</code></td>
<td>
<p>Type of model. Default is &quot;regression&quot;; see also &quot;logistic&quot; and &quot;multinomial&quot; for classification.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_eval_measure">eval_measure</code></td>
<td>
<p>(character) Type of evaluative measure to select models from. Default = &quot;rmse&quot; for regression and
&quot;bal_accuracy&quot; for logistic. For regression use &quot;rsq&quot; or &quot;rmse&quot;; and for classification use &quot;accuracy&quot;,
&quot;bal_accuracy&quot;, &quot;sens&quot;, &quot;spec&quot;, &quot;precision&quot;, &quot;kappa&quot;, &quot;f_measure&quot;, or &quot;roc_auc&quot;,(for more details see
the yardstick package).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_save_aggregated_word_embedding">save_aggregated_word_embedding</code></td>
<td>
<p>(boolean) If TRUE, the aggregated word embeddings (mean, min, and max) are saved
for comparison with other language input when the model is applied to other types of data.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_language_distribution">language_distribution</code></td>
<td>
<p>(Character column) If you provide the raw language data used for making the embeddings,
the language distribution (i.e., a word and frequency table) will be saved to the model object. This enables
calculating similarity scores when the model is being applied to new language domains.
Note that this saves the individual words, which, if you are analyzing sensitive data, can be problematic from a
privacy perspective; to some extent this can be mitigated by increasing the number of words needed to be saved.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_language_distribution_min_words">language_distribution_min_words</code></td>
<td>
<p>(numeric) Minimum number a words need to occur in the data set to be saved to the
language distribution.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_preprocess_step_center">preprocess_step_center</code></td>
<td>
<p>(boolean) Normalizes dimensions to have a mean of zero; default is set to TRUE.
For more info see (step_center in recipes).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_preprocess_step_scale">preprocess_step_scale</code></td>
<td>
<p>(boolean) Normalize dimensions to have a standard deviation of one;
default is set to TRUE. For more info see (step_scale in recipes).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_preprocess_pca">preprocess_PCA</code></td>
<td>
<p>Pre-processing threshold for PCA (to skip this step set it to NA).
Can select amount of variance to retain (e.g., .90 or as a grid c(0.80, 0.90)); or
number of components to select (e.g., 10). Default is &quot;min_halving&quot;, which is a function
that selects the number of PCA components based on number  of participants and feature (word embedding dimensions)
in the data. The formula is:
preprocess_PCA = round(max(min(number_features/2), number_participants/2), min(50, number_features))).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_penalty">penalty</code></td>
<td>
<p>(numeric) Hyper parameter that is tuned (default = 10^seq(-16,16)).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_parameter_selection_method">parameter_selection_method</code></td>
<td>
<p>If several results are tied for different parameters (i.e., penalty or mixture),
then select the &quot;lowest_penalty&quot;, &quot;highest_penalty&quot;, &quot;median_penalty&quot;, or &quot;lowest_mixture&quot;, the &quot;highest_mixture&quot; or
the &quot;median_mixture&quot; order of all the tied penalties/mixtures.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_mixture">mixture</code></td>
<td>
<p>A number between 0 and 1 (inclusive) that reflects the proportion of L1 regularization
(i.e. lasso) in the model (for more information see the linear_reg-function in the parsnip-package).
When mixture = 1, it is a pure lasso model while mixture = 0 indicates that ridge regression is being
used (specific engines only).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_first_n_predictors">first_n_predictors</code></td>
<td>
<p>By default this setting is turned off (i.e., NA). To use this method,
set it to the highest number of predictors you want to test. Then the X first dimensions are used in training,
using a sequence from Kjell et al., 2019 paper in Psychological Methods. Adding 1,
then multiplying by 1.3 and finally rounding to the nearest integer (e.g., 1, 3, 5, 8).
This option is currently only possible for one embedding at the time.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_impute_missing">impute_missing</code></td>
<td>
<p>Default FALSE (can be set to TRUE if something else than word_embeddings are trained).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_method_cor">method_cor</code></td>
<td>
<p>Type of correlation used in evaluation (default &quot;pearson&quot;;
can set to &quot;spearman&quot; or &quot;kendall&quot;).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_model_description">model_description</code></td>
<td>
<p>(character) Text to describe your model (optional; good when sharing the model with others).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_multi_cores">multi_cores</code></td>
<td>
<p>If TRUE it enables the use of multiple cores if the computer system allows for it
(i.e., only on unix, not windows). Hence it makes the analyses considerably faster to run. Default is
&quot;multi_cores_sys_default&quot;, where it automatically uses TRUE for Mac and Linux and FALSE for Windows.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_save_output">save_output</code></td>
<td>
<p>(character) Option not to save all output; default = &quot;all&quot;. see also &quot;only_results&quot;
and &quot;only_results_predictions&quot;.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_simulate.p.value">simulate.p.value</code></td>
<td>
<p>(Boolean) From fisher.test: a logical indicating whether to compute p-values by
Monte Carlo simulation, in larger than 2 * 2 tables.</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_seed">seed</code></td>
<td>
<p>(numeric) Set different seed (default = 2020).</p>
</td></tr>
<tr><td><code id="textTrainRegression_+3A_...">...</code></td>
<td>
<p>For example settings in yardstick::accuracy to set event_level (e.g., event_level = &quot;second&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, NAs are treated as follows:
1. rows with NAs in word embeddings are removed.
2. rows with NAs in y are removed
3. rows with NAs in  x_append are removed; if impute_missing is set to
TRUE, missing values will be imputed using k-nearest neighbours.
When rows are omitted, the user will get a warning.
The CV predictions will include NAs with the same length as the input.
</p>


<h3>Value</h3>

<p>A (one-sided) correlation test between predicted and observed values; tibble
of predicted values (t-value, degree of freedom (df), p-value,
alternative-hypothesis, confidence interval, correlation coefficient), as well as information about
the model (preprossing_recipe, final_model and model_description).
</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+textEmbedLayerAggregation">textEmbedLayerAggregation</a></code>, <code><a href="#topic+textTrainLists">textTrainLists</a></code> and
<code><a href="#topic+textTrainRandomForest">textTrainRandomForest</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Examines how well the embeddings from the column "harmonytext" can
# predict the numerical values in the column "hilstotal".

## Not run: 
trained_model &lt;- textTrainRegression(
  x = word_embeddings_4$texts$harmonytext,
  y = Language_based_assessment_data_8$hilstotal,
  multi_cores = FALSE # This is FALSE due to CRAN testing and Windows machines.
)

# Examine results (t-value, degree of freedom (df), p-value, alternative-hypothesis,
# confidence interval, correlation coefficient).

trained_model$results

## End(Not run)
</code></pre>

<hr>
<h2 id='textTranslate'>Translation. (experimental)</h2><span id='topic+textTranslate'></span>

<h3>Description</h3>

<p>Translation. (experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textTranslate(
  x,
  source_lang = "",
  target_lang = "",
  model = "xlm-roberta-base",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "warning",
  force_return_results = FALSE,
  return_tensors = FALSE,
  return_text = TRUE,
  clean_up_tokenization_spaces = FALSE,
  set_seed = 202208L,
  max_length = 400
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textTranslate_+3A_x">x</code></td>
<td>
<p>(string)  The text to be translated.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_source_lang">source_lang</code></td>
<td>
<p>(string)  The input language. Might be needed for multilingual models
(it will not have any effect for single pair translation models). using ISO 639-1 Code,
such as: &quot;en&quot;, &quot;zh&quot;, &quot;es&quot;, &quot;fr&quot;, &quot;de&quot;, &quot;it&quot;, &quot;sv&quot;, &quot;da&quot;, &quot;nn&quot;.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_target_lang">target_lang</code></td>
<td>
<p>(string)  The desired language output. Might be required for multilingual models
(will not have any effect for single pair translation models).</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_model">model</code></td>
<td>
<p>(string)  Specify a pre-trained language model that have been fine-tuned on a translation task.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_device">device</code></td>
<td>
<p>(string)  Name of device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_logging_level">logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot;
and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_return_tensors">return_tensors</code></td>
<td>
<p>(boolean)  Whether or not to include the predictions' tensors as token indices in the outputs.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_return_text">return_text</code></td>
<td>
<p>(boolean)  Whether or not to also output the decoded texts.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_clean_up_tokenization_spaces">clean_up_tokenization_spaces</code></td>
<td>
<p>(boolean)  Whether or not to clean the output from potential extra spaces.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer) Set seed.</p>
</td></tr>
<tr><td><code id="textTranslate_+3A_max_length">max_length</code></td>
<td>
<p>Set max length of text to be translated</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with transalted text.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textClassify">textClassify</a></code>, <code><a href="#topic+textGeneration">textGeneration</a></code>, <code><a href="#topic+textNER">textNER</a></code>,
<code><a href="#topic+textSum">textSum</a></code>, and <code><a href="#topic+textQA">textQA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# translation_example &lt;- text::textTranslate(
#  Language_based_assessment_data_8[1,1:2],
#  source_lang = "en",
#  target_lang = "fr",
#  model = "t5-base")

</code></pre>

<hr>
<h2 id='textZeroShot'>Zero Shot Classification (Experimental)</h2><span id='topic+textZeroShot'></span>

<h3>Description</h3>

<p>Zero Shot Classification (Experimental)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>textZeroShot(
  sequences,
  candidate_labels,
  hypothesis_template = "This example is {}.",
  multi_label = FALSE,
  model = "",
  device = "cpu",
  tokenizer_parallelism = FALSE,
  logging_level = "error",
  force_return_results = FALSE,
  set_seed = 202208L
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="textZeroShot_+3A_sequences">sequences</code></td>
<td>
<p>(string)  The sequence(s) to classify (not that they will be truncated
if the model input is too large).</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_candidate_labels">candidate_labels</code></td>
<td>
<p>(string) The set of class labels that is possible in the to
classification of each sequence. It may be a single label, a string of comma-separated
labels, or a list of labels.</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_hypothesis_template">hypothesis_template</code></td>
<td>
<p>(string; optional)
The template that is used for turning each of the label into an NLI-style hypothesis.
This template must include a &quot;&quot; or similar syntax so that the candidate label can be
inserted into the template. For example, the default template is
&quot;This example is .&quot; With the candidate label &quot;sports&quot;,
this would be fed into the model like &quot;&lt;cls&gt; sequence to classify &lt;sep&gt; This example is sports . &lt;sep&gt;&quot;.
The default template works well in many cases, but it may be worthwhile to experiment with different templates
depending on the task setting (see https://huggingface.co/docs/transformers/).</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_multi_label">multi_label</code></td>
<td>
<p>(boolean; optional) It indicates whether multiple candidate labels can be true. If FALSE, the scores
are normalized such that the sum of the label likelihoods for each sequence is 1.
If TRUE, the labels are considered independent and probabilities are normalized for each candidate by doing a softmax
of the entailment score vs. the contradiction score.</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_model">model</code></td>
<td>
<p>(string)  Specify a pre-trained language model that have been fine-tuned on a translation task.</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_device">device</code></td>
<td>
<p>(string)  Name of device to use: 'cpu', 'gpu', or 'gpu:k' where k is a specific device number</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_tokenizer_parallelism">tokenizer_parallelism</code></td>
<td>
<p>(boolean)  If TRUE this will turn on tokenizer parallelism.</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_logging_level">logging_level</code></td>
<td>
<p>(string)  Set the logging level.
Options (ordered from less logging to more logging): critical, error, warning, info, debug</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_force_return_results">force_return_results</code></td>
<td>
<p>(boolean)  Stop returning some incorrectly formatted/structured results.
This setting does CANOT evaluate the actual results (whether or not they make sense, exist, etc.).
All it does is to ensure the returned results are formatted correctly (e.g., does the question-answering
dictionary contain the key &quot;answer&quot;, is sentiments from textClassify containing the labels &quot;positive&quot; and &quot;negative&quot;).</p>
</td></tr>
<tr><td><code id="textZeroShot_+3A_set_seed">set_seed</code></td>
<td>
<p>(Integer) Set seed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tibble with the result with the following keys:
sequence (string) The imputed sequence.
labels (string) The labels sorted in the order of likelihood.
scores (numeric) The probabilities for each of the labels.
</p>


<h3>See Also</h3>

<p>see <code><a href="#topic+textClassify">textClassify</a></code>, <code><a href="#topic+textGeneration">textGeneration</a></code>, <code><a href="#topic+textNER">textNER</a></code>,
<code><a href="#topic+textSum">textSum</a></code>, <code><a href="#topic+textQA">textQA</a></code>, <code><a href="#topic+textTranslate">textTranslate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# ZeroShot_example &lt;- text::textZeroShot(sequences = c("I play football",
# "The forest is wonderful"),
# candidate_labels = c("sport", "nature", "research"),
# model = "facebook/bart-large-mnli")

</code></pre>

<hr>
<h2 id='word_embeddings_4'>Word embeddings for 4 text variables for 40 participants</h2><span id='topic+word_embeddings_4'></span>

<h3>Description</h3>

<p>The dataset is a shortened version of the data sets of Study 3-5
from Kjell, Kjell, Garcia and Sikström 2018.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>word_embeddings_4
</code></pre>


<h3>Format</h3>

<p>A list with word embeddings for harmony words, satisfaction words, harmony text,
satisfaction text and decontextualized word embeddings. BERT-base embeddings based on
mean aggregation of layer 11 and 12.
</p>

<dl>
<dt>words</dt><dd><p>words</p>
</dd>
<dt>n</dt><dd><p>word frequency</p>
</dd>
<dt>Dim1:Dim768</dt><dd><p>Word embeddings dimensions</p>
</dd>
</dl>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
