<!DOCTYPE html><html><head><title>Help for package sharp</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sharp}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#sharp-package'><p>sharp: Stability-enHanced Approaches using Resampling Procedures</p></a></li>
<li><a href='#AdjacencyFromObject'><p>Adjacency matrix from object</p></a></li>
<li><a href='#AggregatedEffects'><p>Summarised coefficients conditionally on selection</p></a></li>
<li><a href='#ArgmaxId'><p>Calibrated hyper-parameter(s)</p></a></li>
<li><a href='#BinomialProbabilities'><p>Binomial probabilities for stability score</p></a></li>
<li><a href='#BiSelection'><p>Stability selection of predictors and/or outcomes</p></a></li>
<li><a href='#BlockLambdaGrid'><p>Multi-block grid</p></a></li>
<li><a href='#CalibrationCurve'><p>Calibration curve (internal)</p></a></li>
<li><a href='#CalibrationPlot'><p>Calibration plot</p></a></li>
<li><a href='#CART'><p>Classification And Regression Trees</p></a></li>
<li><a href='#CheckDataRegression'><p>Checking input data (regression model)</p></a></li>
<li><a href='#CheckInputClustering'><p>Checking input parameters (clustering)</p></a></li>
<li><a href='#CheckInputGraphical'><p>Checking input parameters (graphical model)</p></a></li>
<li><a href='#CheckPackageInstalled'><p>Checking that a package is installed</p></a></li>
<li><a href='#CheckParamRegression'><p>Checking input parameters (regression model)</p></a></li>
<li><a href='#Clustering'><p>Consensus clustering</p></a></li>
<li><a href='#ClusteringAlgo'><p>(Weighted) clustering algorithm</p></a></li>
<li><a href='#ClusteringPerformance'><p>Clustering performance</p></a></li>
<li><a href='#Coefficients'><p>Model coefficients</p></a></li>
<li><a href='#Combine'><p>Merging stability selection outputs</p></a></li>
<li><a href='#CoMembership'><p>Pairwise co-membership</p></a></li>
<li><a href='#Concatenate'><p>Concatenate stability objects</p></a></li>
<li><a href='#ConsensusScore'><p>Consensus score</p></a></li>
<li><a href='#DBSCANClustering'><p>(Weighted) density-based clustering</p></a></li>
<li><a href='#DummyToCategories'><p>Categorical from dummy variables</p></a></li>
<li><a href='#Ensemble'><p>Ensemble model</p></a></li>
<li><a href='#EnsemblePredictions'><p>Predictions from ensemble model</p></a></li>
<li><a href='#ExplanatoryPerformance'><p>Prediction performance in regression</p></a></li>
<li><a href='#FDP'><p>False Discovery Proportion</p></a></li>
<li><a href='#Folds'><p>Splitting observations into folds</p></a></li>
<li><a href='#GMMClustering'><p>Model-based clustering</p></a></li>
<li><a href='#Graph'><p>Graph visualisation</p></a></li>
<li><a href='#GraphComparison'><p>Edge-wise comparison of two graphs</p></a></li>
<li><a href='#GraphicalAlgo'><p>Graphical model algorithm</p></a></li>
<li><a href='#GraphicalModel'><p>Stability selection graphical model</p></a></li>
<li><a href='#GroupPLS'><p>Group Partial Least Squares</p></a></li>
<li><a href='#HierarchicalClustering'><p>(Weighted) hierarchical clustering</p></a></li>
<li><a href='#Incremental'><p>Incremental prediction performance in regression</p></a></li>
<li><a href='#KMeansClustering'><p>(Sparse) K-means clustering</p></a></li>
<li><a href='#LambdaGridGraphical'><p>Grid of penalty parameters (graphical model)</p></a></li>
<li><a href='#LambdaGridRegression'><p>Grid of penalty parameters (regression model)</p></a></li>
<li><a href='#LambdaSequence'><p>Sequence of penalty parameters</p></a></li>
<li><a href='#LinearSystemMatrix'><p>Matrix from linear system outputs</p></a></li>
<li><a href='#mystar'><p>Star-shaped nodes</p></a></li>
<li><a href='#mytriangle'><p>Triangular nodes</p></a></li>
<li><a href='#NAToNULL'><p>Transforms NA into NULL</p></a></li>
<li><a href='#OpenMxMatrix'><p>Matrix from OpenMx outputs</p></a></li>
<li><a href='#OpenMxModel'><p>Writing OpenMx model (matrix specification)</p></a></li>
<li><a href='#PAMClustering'><p>(Weighted) Partitioning Around Medoids</p></a></li>
<li><a href='#PenalisedGraphical'><p>Graphical LASSO</p></a></li>
<li><a href='#PenalisedOpenMx'><p>Penalised Structural Equation Model</p></a></li>
<li><a href='#PenalisedRegression'><p>Penalised regression</p></a></li>
<li><a href='#PFER'><p>Per Family Error Rate</p></a></li>
<li><a href='#plot.clustering'><p>Consensus matrix heatmap</p></a></li>
<li><a href='#plot.incremental'><p>Plot of incremental performance</p></a></li>
<li><a href='#plot.roc_band'><p>Receiver Operating Characteristic (ROC) band</p></a></li>
<li><a href='#plot.variable_selection'><p>Plot of selection proportions</p></a></li>
<li><a href='#PLS'><p>Partial Least Squares 'a la carte'</p></a></li>
<li><a href='#predict.variable_selection'><p>Predict method for stability selection</p></a></li>
<li><a href='#PredictPLS'><p>Partial Least Squares predictions</p></a></li>
<li><a href='#Refit'><p>Regression model refitting</p></a></li>
<li><a href='#Resample'><p>Resampling observations</p></a></li>
<li><a href='#SelectionAlgo'><p>Variable selection algorithm</p></a></li>
<li><a href='#SelectionPerformance'><p>Selection performance</p></a></li>
<li><a href='#SelectionPerformanceGraph'><p>Graph representation of selection performance</p></a></li>
<li><a href='#SelectionPerformanceSingle'><p>Selection performance (internal)</p></a></li>
<li><a href='#SelectionProportions'><p>Selection/co-membership proportions</p></a></li>
<li><a href='#SelectionProportionsGraphical'><p>Selection proportions (graphical model)</p></a></li>
<li><a href='#SelectionProportionsRegression'><p>Selection proportions (variable selection)</p></a></li>
<li><a href='#SerialClustering'><p>Consensus clustering (internal)</p></a></li>
<li><a href='#SerialGraphical'><p>Stability selection graphical model (internal)</p></a></li>
<li><a href='#SerialRegression'><p>Stability selection in regression (internal)</p></a></li>
<li><a href='#SparseGroupPLS'><p>Sparse group Partial Least Squares</p></a></li>
<li><a href='#SparseKMeansClustering'><p>Sparse K means clustering</p></a></li>
<li><a href='#SparsePCA'><p>Sparse Principal Component Analysis</p></a></li>
<li><a href='#SparsePLS'><p>Sparse Partial Least Squares</p></a></li>
<li><a href='#Split'><p>Splitting observations into non-overlapping sets</p></a></li>
<li><a href='#Square'><p>Adjacency from bipartite</p></a></li>
<li><a href='#StabilityMetrics'><p>Stability selection metrics</p></a></li>
<li><a href='#StabilityScore'><p>Stability score</p></a></li>
<li><a href='#Stable'><p>Stable results</p></a></li>
<li><a href='#StructuralModel'><p>Stability selection in Structural Equation Modelling</p></a></li>
<li><a href='#UnweightedKMeansClustering'><p>Unweighted K-means clustering</p></a></li>
<li><a href='#VariableSelection'><p>Stability selection in regression</p></a></li>
<li><a href='#WeightBoxplot'><p>Stable attribute weights</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Stability-enHanced Approaches using Resampling Procedures</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-03</td>
</tr>
<tr>
<td>Author:</td>
<td>Barbara Bodinier [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Barbara Bodinier &lt;barbara.bodinier@gmail.com&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/barbarabodinier/sharp">https://github.com/barbarabodinier/sharp</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/barbarabodinier/sharp/issues">https://github.com/barbarabodinier/sharp/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>In stability selection (N Meinshausen, P BÃ¼hlmann (2010) &lt;<a href="https://doi.org/10.1111%2Fj.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>&gt;) and consensus clustering (S Monti et al (2003) &lt;<a href="https://doi.org/10.1023%2FA%3A1023949509487">doi:10.1023/A:1023949509487</a>&gt;), resampling techniques are used to enhance the reliability of the results. In this package, hyper-parameters are calibrated by maximising model stability, which is measured under the null hypothesis that all selection (or co-membership) probabilities are identical (B Bodinier et al (2023a) &lt;<a href="https://doi.org/10.1093%2Fjrsssc%2Fqlad058">doi:10.1093/jrsssc/qlad058</a>&gt; and B Bodinier et al (2023b) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtad635">doi:10.1093/bioinformatics/btad635</a>&gt;). Functions are readily implemented for the use of LASSO regression, sparse PCA, sparse (group) PLS or graphical LASSO in stability selection, and hierarchical clustering, partitioning around medoids, K means or Gaussian mixture models in consensus clustering. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Depends:</td>
<td>fake (&ge; 1.4.0), R (&ge; 3.5)</td>
</tr>
<tr>
<td>Imports:</td>
<td>abind, beepr, future, future.apply, glassoFast (&ge; 1.0.0),
glmnet, grDevices, igraph, mclust, nloptr, plotrix, Rdpack,
withr (&ge; 2.4.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>cluster, corpcor, dbscan, elasticnet, gglasso, mixOmics,
nnet, OpenMx, RCy3, randomcoloR, rCOSA, rmarkdown, rpart,
sgPLS, sparcl, survival (&ge; 3.2.13), testthat (&ge; 3.0.0),
visNetwork</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="https://barbarabodinier.github.io/drat">https://barbarabodinier.github.io/drat</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-03 16:28:15 UTC; barbara</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-03 17:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='sharp-package'>sharp: Stability-enHanced Approaches using Resampling Procedures</h2><span id='topic+sharp-package'></span>

<h3>Description</h3>

<p>In stability selection and consensus clustering, resampling techniques are
used to enhance the reliability of the results. In this package,
hyper-parameters are calibrated by maximising model stability, which is
measured under the null hypothesis that all selection (or co-membership)
probabilities are identical. Functions are readily implemented for the use of
LASSO regression, sparse PCA, sparse (group) PLS or graphical LASSO in
stability selection, and hierarchical clustering, partitioning around
medoids, K means or Gaussian mixture models in consensus clustering.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> sharp</td>
</tr>
<tr>
 <td style="text-align: left;"> Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> Version: </td><td style="text-align: left;">
1.4.6 </td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;"> 2024-02-03 </td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> GPL (&gt;= 3)</td>
</tr>
<tr>
 <td style="text-align: left;"> Maintainer:
</td><td style="text-align: left;"> Barbara Bodinier <a href="mailto:barbara.bodinier@gmail.com">barbara.bodinier@gmail.com</a></td>
</tr>

</table>



<h3>References</h3>

<p>Bodinier B, Vuckovic D, Rodrigues S, Filippi S, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration of consensus weighted distance-based clustering approaches using sharp.&rdquo;
<em>Bioinformatics</em>, btad635.
ISSN 1367-4811, <a href="https://doi.org/10.1093/bioinformatics/btad635">doi:10.1093/bioinformatics/btad635</a>, https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btad635/52191190/btad635.pdf.
</p>
<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Monti S, Tamayo P, Mesirov J, Golub T (2003).
&ldquo;Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data.&rdquo;
<em>Machine Learning</em>, <b>52</b>(1), 91&ndash;118.
<a href="https://doi.org/10.1023/A%3A1023949509487">doi:10.1023/A:1023949509487</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldpar &lt;- par(no.readonly = TRUE)
par(mar = c(5, 5, 5, 5))

## Regression models
# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50)

# Stability selection
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata)
CalibrationPlot(stab)
summary(stab)
SelectedVariables(stab)


## Graphical models
# Data simulation
set.seed(1)
simul &lt;- SimulateGraphical(n = 100, pk = 20, topology = "scale-free")

# Stability selection
stab &lt;- GraphicalModel(xdata = simul$data)
CalibrationPlot(stab)
summary(stab)
plot(stab)


## PCA models
if (requireNamespace("elasticnet", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateComponents(pk = c(5, 3, 4))
  plot(simul)

  # Stability selection
  stab &lt;- BiSelection(
    xdata = simul$data,
    ncomp = 3,
    implementation = SparsePCA
  )
  CalibrationPlot(stab)
  summary(stab)
  SelectedVariables(stab)
}


## PLS models
if (requireNamespace("sgPLS", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 50, pk = c(10, 20, 30), family = "gaussian")

  # Stability selection
  stab &lt;- BiSelection(
    xdata = simul$xdata, ydata = simul$ydata,
    family = "gaussian", ncomp = 3,
    implementation = SparsePLS
  )
  CalibrationPlot(stab)
  summary(stab)
  plot(stab)
}

par(oldpar)

</code></pre>

<hr>
<h2 id='AdjacencyFromObject'>Adjacency matrix from object</h2><span id='topic+AdjacencyFromObject'></span>

<h3>Description</h3>

<p>Returns the adjacency matrix from an
<code><a href="igraph.html#topic+igraph-package">igraph</a></code> object or from the output of
simulation or inference functions from the present package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AdjacencyFromObject(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AdjacencyFromObject_+3A_object">object</code></td>
<td>
<p>input object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector without missing values or NULL.
</p>

<hr>
<h2 id='AggregatedEffects'>Summarised coefficients conditionally on selection</h2><span id='topic+AggregatedEffects'></span>

<h3>Description</h3>

<p>Computes descriptive statistics (defined by <code>FUN</code>) for coefficients of
the (calibrated) models conditionally on selection across resampling
iterations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AggregatedEffects(
  stability,
  lambda_id = NULL,
  side = "X",
  comp = 1,
  FUN = stats::median,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AggregatedEffects_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code> or
<code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="AggregatedEffects_+3A_lambda_id">lambda_id</code></td>
<td>
<p>parameter ID with respect to the grid <code>Lambda</code>. If
<code>NULL</code>, aggregated coefficients across the models run with the
calibrated parameter are returned.</p>
</td></tr>
<tr><td><code id="AggregatedEffects_+3A_side">side</code></td>
<td>
<p>character string indicating if coefficients of predictors
(<code>side="X"</code>) or outcomes (<code>side="Y"</code>) should be returned. Only
applicable to PLS models.</p>
</td></tr>
<tr><td><code id="AggregatedEffects_+3A_comp">comp</code></td>
<td>
<p>component ID. Only applicable to PLS models.</p>
</td></tr>
<tr><td><code id="AggregatedEffects_+3A_fun">FUN</code></td>
<td>
<p>function to use to aggregate coefficients of visited models over
resampling iterations. Recommended functions include
<code><a href="stats.html#topic+median">median</a></code> or <code><a href="base.html#topic+mean">mean</a></code>.</p>
</td></tr>
<tr><td><code id="AggregatedEffects_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of summarised coefficients conditionally on selection across
resampling iterations. Missing values (<code>NA</code>) are returned for
variables that are never selected.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>,
<code><a href="#topic+Refit">Refit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example with univariate outcome
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, family = "gaussian")
median_betas &lt;- AggregatedEffects(stab)

# Comparison with refitted model
refitted &lt;- Refit(xdata = simul$xdata, ydata = simul$ydata, stability = stab)
refitted_betas &lt;- coef(refitted)[-1, 1]
plot(median_betas[names(refitted_betas), ], refitted_betas,
  panel.first = abline(0, 1, lty = 2)
)

# Extracting mean betas conditionally on selection
mean_betas &lt;- AggregatedEffects(stab, FUN = mean)
plot(median_betas, mean_betas)

# Regression with multivariate outcomes
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, q = 2, family = "gaussian")
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, family = "mgaussian")
median_betas &lt;- AggregatedEffects(stab)
dim(median_betas)

# Sparse PLS with multivariate outcome
if (requireNamespace("sgPLS", quietly = TRUE)) {
  set.seed(1)
  simul &lt;- SimulateRegression(n = 50, pk = 15, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata
  stab &lt;- BiSelection(
    xdata = x, ydata = y,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(x) - 1),
    implementation = SparsePLS
  )
  median_betas &lt;- AggregatedEffects(stab)
  dim(median_betas)
  median_betas &lt;- AggregatedEffects(stab, side = "Y")
  dim(median_betas)
}


</code></pre>

<hr>
<h2 id='ArgmaxId'>Calibrated hyper-parameter(s)</h2><span id='topic+ArgmaxId'></span><span id='topic+Argmax'></span>

<h3>Description</h3>

<p>Extracts the calibrated hyper-parameters (or their indices for
<code><a href="#topic+ArgmaxId">ArgmaxId</a></code>) with respect to the grids provided in <code>Lambda</code>
and <code>pi_list</code> in argument <code>stability</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ArgmaxId(stability = NULL, S = NULL)

Argmax(stability)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ArgmaxId_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code> or
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>.</p>
</td></tr>
<tr><td><code id="ArgmaxId_+3A_s">S</code></td>
<td>
<p>matrix of stability scores obtained with different combinations of
parameters where rows correspond to different values of the parameter
controlling the level of sparsity in the underlying feature selection
algorithm and columns correspond to different values of the threshold in
selection proportions. If <code>S=NULL</code>, argument <code>stability</code> must be
provided.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of hyper-parameters (<code><a href="#topic+Argmax">Argmax</a></code>) or indices
(<code><a href="#topic+ArgmaxId">ArgmaxId</a></code>). For multi-block graphical models, rows correspond
to different blocks.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateGraphical(pk = 20)

# Stability selection
stab &lt;- GraphicalModel(xdata = simul$data)

# Extracting calibrated hyper-parameters
Argmax(stab)

# Extracting calibrated hyper-parameters IDs
ids &lt;- ArgmaxId(stab)
ids

# Relationship between the two functions
stab$Lambda[ids[1], 1]
stab$params$pi_list[ids[2]]

</code></pre>

<hr>
<h2 id='BinomialProbabilities'>Binomial probabilities for stability score</h2><span id='topic+BinomialProbabilities'></span>

<h3>Description</h3>

<p>Computes the probabilities of observing each category of selection
proportions under the assumption of a uniform selection procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BinomialProbabilities(q, N, pi, K, n_cat = 3)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BinomialProbabilities_+3A_q">q</code></td>
<td>
<p>average number of features selected by the underlying algorithm.</p>
</td></tr>
<tr><td><code id="BinomialProbabilities_+3A_n">N</code></td>
<td>
<p>total number of features.</p>
</td></tr>
<tr><td><code id="BinomialProbabilities_+3A_pi">pi</code></td>
<td>
<p>threshold in selection proportions. If n_cat=3, these values must
be &gt;0.5 and &lt;1. If n_cat=2, these values must be &gt;0 and &lt;1.</p>
</td></tr>
<tr><td><code id="BinomialProbabilities_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="BinomialProbabilities_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of probabilities for each of the 2 or 3 categories of
selection proportions.
</p>

<hr>
<h2 id='BiSelection'>Stability selection of predictors and/or outcomes</h2><span id='topic+BiSelection'></span>

<h3>Description</h3>

<p>Performs stability selection for dimensionality reduction. The underlying
variable selection algorithm (e.g. sparse PLS) is run with different
combinations of parameters controlling the sparsity (e.g. number of selected
variables per component) and thresholds in selection proportions. These
hyper-parameters are jointly calibrated by maximisation of the stability
score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BiSelection(
  xdata,
  ydata = NULL,
  group_x = NULL,
  group_y = NULL,
  LambdaX = NULL,
  LambdaY = NULL,
  AlphaX = NULL,
  AlphaY = NULL,
  ncomp = 1,
  scale = TRUE,
  pi_list = seq(0.01, 0.99, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = NULL,
  family = "gaussian",
  implementation = SparsePLS,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  beep = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BiSelection_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_group_x">group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used for
models with group penalisation (e.g. <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>).</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_group_y">group_y</code></td>
<td>
<p>optional vector encoding the grouping structure among
outcomes. This argument indicates the number of variables in each group.
Only used if <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_lambdax">LambdaX</code></td>
<td>
<p>matrix of parameters controlling the number of selected
variables (for sparse PCA/PLS) or groups (for group and sparse group PLS)
in X.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_lambday">LambdaY</code></td>
<td>
<p>matrix of parameters controlling the number of selected
variables (for sparse PLS) or groups (for group or sparse group PLS) in Y.
Only used if <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_alphax">AlphaX</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity within
groups in X. Only used if <code>implementation=SparseGroupPLS</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_alphay">AlphaY</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity within
groups in X. Only used if <code>implementation=SparseGroupPLS</code> and
<code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one).</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_family">family</code></td>
<td>
<p>type of PLS model. This parameter must be set to
<code>family="gaussian"</code> for continuous outcomes, or to
<code>family="binomial"</code> for categorical outcomes. Only used if
<code>ydata</code> is provided.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_implementation">implementation</code></td>
<td>
<p>function to use for feature selection. Possible
functions are: <code>SparsePCA</code>, <code>SparsePLS</code>, <code>GroupPLS</code>,
<code>SparseGroupPLS</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_cpss">cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_n_cores">n_cores</code></td>
<td>
<p>number of cores to use for parallel computing (see argument
<code>workers</code> in <code><a href="future.html#topic+multisession">multisession</a></code>). Using
<code>n_cores&gt;1</code> is only supported with <code>optimisation="grid_search"</code>.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_beep">beep</code></td>
<td>
<p>sound indicating the end of the run. Possible values are:
<code>NULL</code> (no sound) or an integer between 1 and 11 (see argument
<code>sound</code> in <code><a href="beepr.html#topic+beep">beep</a></code>).</p>
</td></tr>
<tr><td><code id="BiSelection_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In stability selection, a feature selection algorithm is fitted on
<code>K</code> subsamples (or bootstrap samples) of the data with different
parameters controlling the sparsity (<code>LambdaX</code>, <code>LambdaY</code>,
<code>AlphaX</code>, and/or <code>AlphaY</code>). For a given (set of) sparsity
parameter(s), the proportion out of the <code>K</code> models in which each
feature is selected is calculated. Features with selection proportions
above a threshold pi are considered stably selected. The stability
selection model is controlled by the sparsity parameter(s) (denoted by
<code class="reqn">\lambda</code>) for the underlying algorithm, and the threshold in selection
proportion:
</p>
<p><code class="reqn">V_{\lambda, \pi} = \{ j: p_{\lambda}(j) \ge \pi \} </code>
</p>
<p>For sparse and sparse group dimensionality reduction, &quot;feature&quot; refers to
variable (variable selection model). For group PLS, &quot;feature&quot; refers to
group (group selection model). For (sparse) group PLS, groups need to be
defined <em>a priori</em> and specified in arguments <code>group_x</code> and/or
<code>group_y</code>.
</p>
<p>These parameters can be calibrated by maximisation of a stability score
(see <code><a href="#topic+ConsensusScore">ConsensusScore</a></code> if <code>n_cat=NULL</code> or
<code><a href="#topic+StabilityScore">StabilityScore</a></code> otherwise) calculated under the null
hypothesis of equiprobability of selection.
</p>
<p>It is strongly recommended to examine the calibration plot carefully to
check that the grids of parameters <code>Lambda</code> and <code>pi_list</code> do not
restrict the calibration to a region that would not include the global
maximum (see <code><a href="#topic+CalibrationPlot">CalibrationPlot</a></code>). In particular, the grid
<code>Lambda</code> may need to be extended when the maximum stability is
observed on the left or right edges of the calibration heatmap. In some
instances, multiple peaks of stability score can be observed. Simulation
studies suggest that the peak corresponding to the largest number of
selected features tend to give better selection performances. This is not
necessarily the highest peak (which is automatically retained by the
functions in this package). The user can decide to manually choose another
peak.
</p>
<p>To control the expected number of False Positives (Per Family Error Rate)
in the results, a threshold <code>PFER_thr</code> can be specified. The
optimisation problem is then constrained to sets of parameters that
generate models with an upper-bound in PFER below <code>PFER_thr</code> (see
Meinshausen and BÃ¼hlmann (2010) and Shah and Samworth (2013)).
</p>
<p>Possible resampling procedures include defining (i) <code>K</code> subsamples of
a proportion <code>tau</code> of the observations, (ii) <code>K</code> bootstrap samples
with the full sample size (obtained with replacement), and (iii) <code>K/2</code>
splits of the data in half for complementary pair stability selection (see
arguments <code>resampling</code> and <code>cpss</code>). In complementary pair
stability selection, a feature is considered selected at a given resampling
iteration if it is selected in the two complementary subsamples.
</p>
<p>For categorical outcomes (argument <code>family</code> is <code>"binomial"</code> or
<code>"multinomial"</code>), the proportions of observations from each category
in all subsamples or bootstrap samples are the same as in the full sample.
</p>
<p>To ensure reproducibility of the results, the starting number of the random
number generator is set to <code>seed</code>.
</p>
<p>For parallelisation, stability selection with different sets of parameters
can be run on <code>n_cores</code> cores. Using <code>n_cores &gt; 1</code> creates a
<code><a href="future.html#topic+multisession">multisession</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>bi_selection</code>. A list with: </p>
<table>
<tr><td><code>summary</code></td>
<td>
<p>a
matrix of the best stability scores and corresponding parameters
controlling the level of sparsity in the underlying algorithm for different
numbers of components. Possible columns include: <code>comp</code> (component
index), <code>nx</code> (number of predictors to include, parameter of the
underlying algorithm), <code>alphax</code> (sparsity within the predictor groups,
parameter of the underlying algorithm), <code>pix</code> (threshold in selection
proportion for predictors), <code>ny</code> (number of outcomes to include,
parameter of the underlying algorithm), <code>alphay</code> (sparsity within the
outcome groups, parameter of the underlying algorithm), <code>piy</code>
(threshold in selection proportion for outcomes), <code>S</code> (stability
score). Columns that are not relevant to the model are not reported (e.g.
<code>alpha_x</code> and <code>alpha_y</code> are not returned for sparse PLS models).</p>
</td></tr>
<tr><td><code>summary_full</code></td>
<td>
<p>a matrix of the best stability scores for different
combinations of parameters controlling the sparsity and components.</p>
</td></tr>
<tr><td><code>selectedX</code></td>
<td>
<p>a binary matrix encoding stably selected predictors.</p>
</td></tr>
<tr><td><code>selpropX</code></td>
<td>
<p>a matrix of calibrated selection proportions for
predictors.</p>
</td></tr> <tr><td><code>selectedY</code></td>
<td>
<p>a binary matrix encoding stably selected
outcomes. Only returned for PLS models.</p>
</td></tr> <tr><td><code>selpropY</code></td>
<td>
<p>a matrix of
calibrated selection proportions for outcomes. Only returned for PLS
models.</p>
</td></tr> <tr><td><code>selected</code></td>
<td>
<p>a binary matrix encoding stable relationships
between predictor and outcome variables. Only returned for PLS models.</p>
</td></tr>
<tr><td><code>selectedX_full</code></td>
<td>
<p>a binary matrix encoding stably selected predictors.</p>
</td></tr>
<tr><td><code>selpropX_full</code></td>
<td>
<p>a matrix of selection proportions for predictors.</p>
</td></tr>
<tr><td><code>selectedY_full</code></td>
<td>
<p>a binary matrix encoding stably selected outcomes.
Only returned for PLS models.</p>
</td></tr> <tr><td><code>selpropY_full</code></td>
<td>
<p>a matrix of selection
proportions for outcomes. Only returned for PLS models.</p>
</td></tr> <tr><td><code>coefX</code></td>
<td>
<p>an
array of estimated loadings coefficients for the different components
(rows), for the predictors (columns), as obtained across the <code>K</code>
visited models (along the third dimension).</p>
</td></tr> <tr><td><code>coefY</code></td>
<td>
<p>an array of
estimated loadings coefficients for the different components (rows), for
the outcomes (columns), as obtained across the <code>K</code> visited models
(along the third dimension). Only returned for PLS models.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a
list with <code>type="bi_selection"</code> and values used for arguments
<code>implementation</code>, <code>family</code>, <code>scale</code>, <code>resampling</code>,
<code>cpss</code> and <code>PFER_method</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used
for arguments <code>K</code>, <code>group_x</code>, <code>group_y</code>, <code>LambdaX</code>,
<code>LambdaY</code>, <code>AlphaX</code>, <code>AlphaY</code>, <code>pi_list</code>, <code>tau</code>,
<code>n_cat</code>, <code>pk</code>, <code>n</code> (number of observations),
<code>PFER_thr</code>, <code>FDP_thr</code> and <code>seed</code>. The datasets <code>xdata</code>
and <code>ydata</code> are also included if <code>output_data=TRUE</code>.</p>
</td></tr></table>
<p> The rows of
<code>summary</code> and columns of <code>selectedX</code>, <code>selectedY</code>,
<code>selpropX</code>, <code>selpropY</code>, <code>selected</code>, <code>coefX</code> and
<code>coefY</code> are ordered in the same way and correspond to components and
parameter values stored in <code>summary</code>. The rows of <code>summary_full</code>
and columns of <code>selectedX_full</code>, <code>selectedY_full</code>,
<code>selpropX_full</code> and <code>selpropY_full</code> are ordered in the same way
and correspond to components and parameter values stored in
<code>summary_full</code>.
</p>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Shah RD, Samworth RJ (2013).
&ldquo;Variable selection with error control: another look at stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Liquet B, de Micheaux PL, Hejblum BP, ThiÃ©baut R (2016).
&ldquo;Group and sparse group partial least square approaches applied in genomics context.&rdquo;
<em>Bioinformatics</em>, <b>32</b>(1), 35-42.
ISSN 1367-4803, <a href="https://doi.org/10.1093/bioinformatics/btv535">doi:10.1093/bioinformatics/btv535</a>.
</p>
<p>KA LC, Rossouw D, Robert-GraniÃ© C, Besse P (2008).
&ldquo;A sparse PLS for variable selection when integrating omics data.&rdquo;
<em>Stat Appl Genet Mol Biol</em>, <b>7</b>(1), Article 35.
ISSN 1544-6115, <a href="https://doi.org/10.2202/1544-6115.1390">doi:10.2202/1544-6115.1390</a>.
</p>
<p>Shen H, Huang JZ (2008).
&ldquo;Sparse principal component analysis via regularized low rank matrix approximation.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>99</b>(6), 1015-1034.
ISSN 0047-259X, <a href="https://doi.org/10.1016/j.jmva.2007.06.007">doi:10.1016/j.jmva.2007.06.007</a>.
</p>
<p>Zou H, Hastie T, Tibshirani R (2006).
&ldquo;Sparse Principal Component Analysis.&rdquo;
<em>Journal of Computational and Graphical Statistics</em>, <b>15</b>(2), 265-286.
<a href="https://doi.org/10.1198/106186006X113430">doi:10.1198/106186006X113430</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SparsePCA">SparsePCA</a></code>, <code><a href="#topic+SparsePLS">SparsePLS</a></code>,
<code><a href="#topic+GroupPLS">GroupPLS</a></code>, <code><a href="#topic+SparseGroupPLS">SparseGroupPLS</a></code>,
<code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+Resample">Resample</a></code>,
<code><a href="#topic+StabilityScore">StabilityScore</a></code>
</p>
<p>Other stability functions: 
<code><a href="#topic+Clustering">Clustering</a>()</code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a>()</code>,
<code><a href="#topic+StructuralModel">StructuralModel</a>()</code>,
<code><a href="#topic+VariableSelection">VariableSelection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (requireNamespace("sgPLS", quietly = TRUE)) {
  oldpar &lt;- par(no.readonly = TRUE)
  par(mar = c(12, 5, 1, 1))

  ## Sparse Principal Component Analysis

  # Data simulation
  set.seed(1)
  simul &lt;- SimulateComponents(pk = c(5, 3, 4))

  # sPCA: sparsity on X (unsupervised)
  stab &lt;- BiSelection(
    xdata = simul$data,
    ncomp = 2,
    LambdaX = seq_len(ncol(simul$data) - 1),
    implementation = SparsePCA
  )
  print(stab)

  # Calibration plot
  CalibrationPlot(stab)

  # Visualisation of the results
  summary(stab)
  plot(stab)
  SelectedVariables(stab)


  ## Sparse (Group) Partial Least Squares

  # Data simulation (continuous outcomes)
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 15, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # sPLS: sparsity on X
  stab &lt;- BiSelection(
    xdata = x, ydata = y,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(x) - 1),
    implementation = SparsePLS
  )
  CalibrationPlot(stab)
  summary(stab)
  plot(stab)

  # sPLS: sparsity on both X and Y
  stab &lt;- BiSelection(
    xdata = x, ydata = y,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(x) - 1),
    LambdaY = seq_len(ncol(y) - 1),
    implementation = SparsePLS,
    n_cat = 2
  )
  CalibrationPlot(stab)
  summary(stab)
  plot(stab)

  # sgPLS: sparsity on X
  stab &lt;- BiSelection(
    xdata = x, ydata = y, K = 10,
    group_x = c(2, 8, 5),
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(2), AlphaX = seq(0.1, 0.9, by = 0.1),
    implementation = SparseGroupPLS
  )
  CalibrationPlot(stab)
  summary(stab)

  par(oldpar)
}

</code></pre>

<hr>
<h2 id='BlockLambdaGrid'>Multi-block grid</h2><span id='topic+BlockLambdaGrid'></span>

<h3>Description</h3>

<p>Generates a matrix of parameters controlling the sparsity of the underlying
selection algorithm for multi-block calibration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BlockLambdaGrid(Lambda, lambda_other_blocks = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BlockLambdaGrid_+3A_lambda">Lambda</code></td>
<td>
<p>vector or matrix of penalty parameters.</p>
</td></tr>
<tr><td><code id="BlockLambdaGrid_+3A_lambda_other_blocks">lambda_other_blocks</code></td>
<td>
<p>optional vector of penalty parameters to use for
other blocks in the iterative multi-block procedure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>Lambda</code></td>
<td>
<p>a matrix of (block-specific) penalty
parameters. In multi-block stability selection, rows correspond to sets of
penalty parameters and columns correspond to different blocks.</p>
</td></tr>
<tr><td><code>Sequential_template</code></td>
<td>
<p>logical matrix encoding the type of procedure
for data with multiple blocks in stability selection graphical modelling.
For multi-block estimation, each block is calibrated separately while
others blocks are weakly penalised (<code>TRUE</code> only for the block
currently being calibrated and <code>FALSE</code> for other blocks). Other
approaches with joint calibration of the blocks are allowed (all entries
are set to <code>TRUE</code>).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+GraphicalModel">GraphicalModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Multi-block grid
Lambda &lt;- matrix(
  c(
    0.8, 0.6, 0.3,
    0.5, 0.4, 0.2,
    0.7, 0.5, 0.1
  ),
  ncol = 3, byrow = TRUE
)
mygrid &lt;- BlockLambdaGrid(Lambda, lambda_other_blocks = 0.1)

# Multi-parameter grid (not recommended)
Lambda &lt;- matrix(
  c(
    0.8, 0.6, 0.3,
    0.5, 0.4, 0.2,
    0.7, 0.5, 0.1
  ),
  ncol = 3, byrow = TRUE
)
mygrid &lt;- BlockLambdaGrid(Lambda, lambda_other_blocks = NULL)
</code></pre>

<hr>
<h2 id='CalibrationCurve'>Calibration curve (internal)</h2><span id='topic+CalibrationCurve'></span>

<h3>Description</h3>

<p>Creates a calibration curve for consensus clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalibrationCurve(
  stability,
  bty = "o",
  xlab = NULL,
  ylab = NULL,
  cex.axis = 1,
  cex.lab = 1.5,
  cex.legend = 1.2,
  pch = 19,
  lines = TRUE,
  col = NULL,
  legend = TRUE,
  ncol = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CalibrationCurve_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code> or <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_bty">bty</code></td>
<td>
<p>character string indicating if the box around the plot should be
drawn. Possible values include: <code>"o"</code> (default, the box is drawn), or
<code>"n"</code> (no box).</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_xlab">xlab</code></td>
<td>
<p>label of the x-axis.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_ylab">ylab</code></td>
<td>
<p>label of the y-axis.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_cex.axis">cex.axis</code></td>
<td>
<p>font size for axes.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_cex.lab">cex.lab</code></td>
<td>
<p>font size for labels.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_cex.legend">cex.legend</code></td>
<td>
<p>font size for text legend entries.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_pch">pch</code></td>
<td>
<p>type of point, as in <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_lines">lines</code></td>
<td>
<p>logical indicating if the points should be linked by lines. Only
used if <code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code> or
<code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_col">col</code></td>
<td>
<p>vector of colours.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_legend">legend</code></td>
<td>
<p>logical indicating if the legend should be included.</p>
</td></tr>
<tr><td><code id="CalibrationCurve_+3A_ncol">ncol</code></td>
<td>
<p>integer indicating the number of columns in the legend.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a calibration curve.
</p>

<hr>
<h2 id='CalibrationPlot'>Calibration plot</h2><span id='topic+CalibrationPlot'></span>

<h3>Description</h3>

<p>Creates a plot showing the stability score as a function of the parameter(s)
controlling the level of sparsity in the underlying feature selection
algorithm and/or the threshold in selection proportions. See examples in
<code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>,
<code><a href="#topic+Clustering">Clustering</a></code> and <code><a href="#topic+BiSelection">BiSelection</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CalibrationPlot(
  stability,
  block_id = NULL,
  col = NULL,
  pch = 19,
  cex = 0.7,
  xlim = NULL,
  ylim = NULL,
  bty = "o",
  lines = TRUE,
  lty = 3,
  lwd = 2,
  show_argmax = TRUE,
  show_pix = FALSE,
  show_piy = FALSE,
  offset = 0.3,
  legend = TRUE,
  legend_length = NULL,
  legend_range = NULL,
  ncol = 1,
  xlab = NULL,
  ylab = NULL,
  zlab = expression(italic(q)),
  xlas = 2,
  ylas = NULL,
  zlas = 2,
  cex.lab = 1.5,
  cex.axis = 1,
  cex.legend = 1.2,
  xgrid = FALSE,
  ygrid = FALSE,
  params = c("ny", "alphay", "nx", "alphax")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CalibrationPlot_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code> or <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_block_id">block_id</code></td>
<td>
<p>ID of the block to visualise. Only used for multi-block
stability selection graphical models. If <code>block_id=NULL</code>, all blocks
are represented in separate panels.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_col">col</code></td>
<td>
<p>vector of colours.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_pch">pch</code></td>
<td>
<p>type of point, as in <code><a href="graphics.html#topic+points">points</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_cex">cex</code></td>
<td>
<p>size of point.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_xlim">xlim</code></td>
<td>
<p>displayed range along the x-axis. Only used if <code>stability</code>
is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_ylim">ylim</code></td>
<td>
<p>displayed range along the y-axis. Only used if <code>stability</code>
is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_bty">bty</code></td>
<td>
<p>character string indicating if the box around the plot should be
drawn. Possible values include: <code>"o"</code> (default, the box is drawn), or
<code>"n"</code> (no box).</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_lines">lines</code></td>
<td>
<p>logical indicating if the points should be linked by lines. Only
used if <code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code> or
<code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_lty">lty</code></td>
<td>
<p>line type, as in <code><a href="graphics.html#topic+par">par</a></code>. Only used if
<code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_lwd">lwd</code></td>
<td>
<p>line width, as in <code><a href="graphics.html#topic+par">par</a></code>. Only used if
<code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_show_argmax">show_argmax</code></td>
<td>
<p>logical indicating if the calibrated parameter(s) should
be indicated by lines.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_show_pix">show_pix</code></td>
<td>
<p>logical indicating if the calibrated threshold in selection
proportion in <code>X</code> should be written for each point. Only used if
<code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_show_piy">show_piy</code></td>
<td>
<p>logical indicating if the calibrated threshold in selection
proportion in <code>Y</code> should be written for each point. Only used if
<code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code> with
penalisation of the outcomes.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_offset">offset</code></td>
<td>
<p>distance between the point and the text, as in
<code><a href="graphics.html#topic+text">text</a></code>. Only used if <code>show_pix=TRUE</code> or
<code>show_piy=TRUE</code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_legend">legend</code></td>
<td>
<p>logical indicating if the legend should be included.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_legend_length">legend_length</code></td>
<td>
<p>length of the colour bar. Only used if <code>stability</code>
is the output of <code><a href="#topic+VariableSelection">VariableSelection</a></code> or
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_legend_range">legend_range</code></td>
<td>
<p>range of the colour bar. Only used if <code>stability</code> is
the output of <code><a href="#topic+VariableSelection">VariableSelection</a></code> or
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_ncol">ncol</code></td>
<td>
<p>integer indicating the number of columns in the legend.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_xlab">xlab</code></td>
<td>
<p>label of the x-axis.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_ylab">ylab</code></td>
<td>
<p>label of the y-axis.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_zlab">zlab</code></td>
<td>
<p>label of the z-axis. Only used if <code>stability</code> is the output
of <code><a href="#topic+VariableSelection">VariableSelection</a></code> or <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_xlas">xlas</code></td>
<td>
<p>orientation of labels on the x-axis, as <code>las</code> in
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_ylas">ylas</code></td>
<td>
<p>orientation of labels on the y-axis, as <code>las</code> in
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_zlas">zlas</code></td>
<td>
<p>orientation of labels on the z-axis, as <code>las</code> in
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_cex.lab">cex.lab</code></td>
<td>
<p>font size for labels.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_cex.axis">cex.axis</code></td>
<td>
<p>font size for axes.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_cex.legend">cex.legend</code></td>
<td>
<p>font size for text legend entries.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_xgrid">xgrid</code></td>
<td>
<p>logical indicating if a vertical grid should be drawn. Only used
if <code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_ygrid">ygrid</code></td>
<td>
<p>logical indicating if a horizontal grid should be drawn. Only
used if <code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="CalibrationPlot_+3A_params">params</code></td>
<td>
<p>vector of possible parameters if <code>stability</code> is of class
<code>bi_selection</code>. The order of these parameters defines the order in
which they are represented. Only used if <code>stability</code> is the output of
<code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A calibration plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>,
<code><a href="#topic+Clustering">Clustering</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>
</p>

<hr>
<h2 id='CART'>Classification And Regression Trees</h2><span id='topic+CART'></span>

<h3>Description</h3>

<p>Runs decision trees using implementation from <code><a href="rpart.html#topic+rpart">rpart</a></code>.
This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CART(xdata, ydata, Lambda = NULL, family, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CART_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="CART_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="CART_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the number of splits in the
decision tree.</p>
</td></tr>
<tr><td><code id="CART_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="CART_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="rpart.html#topic+rpart">rpart</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors. Indices
along the third dimension correspond to outcome variable(s).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman L, Friedman JH, Olshen R, Stone CJ (1984).
<em>Classification and Regression Trees</em>.
Wadsworth.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SelectionAlgo">SelectionAlgo</a></code>, <code><a href="#topic+VariableSelection">VariableSelection</a></code>
</p>
<p>Other underlying algorithm functions: 
<code><a href="#topic+ClusteringAlgo">ClusteringAlgo</a>()</code>,
<code><a href="#topic+PenalisedGraphical">PenalisedGraphical</a>()</code>,
<code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a>()</code>,
<code><a href="#topic+PenalisedRegression">PenalisedRegression</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("rpart", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(pk = 50)

  # Running the LASSO
  mycart &lt;- CART(
    xdata = simul$xdata,
    ydata = simul$ydata,
    family = "gaussian"
  )
  head(mycart$selected)
}
</code></pre>

<hr>
<h2 id='CheckDataRegression'>Checking input data (regression model)</h2><span id='topic+CheckDataRegression'></span>

<h3>Description</h3>

<p>Checks if input data formats are appropriate. For inappropriate inputs, this
function (i) fixes the data format, or (ii) stops the run and generates an
error message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckDataRegression(xdata, ydata = NULL, family = "gaussian", verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckDataRegression_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="CheckDataRegression_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="CheckDataRegression_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="CheckDataRegression_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
</table>

<hr>
<h2 id='CheckInputClustering'>Checking input parameters (clustering)</h2><span id='topic+CheckInputClustering'></span>

<h3>Description</h3>

<p>Checks if input parameters are valid. For invalid parameters, this function
(i) stops the run and generates an error message, or (ii) sets the invalid
parameter to its default value and reports it in a warning message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckInputClustering(
  xdata,
  Lambda = NULL,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  implementation = HierarchicalClustering,
  scale = TRUE,
  resampling = "subsampling",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckInputClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters for weighted distance calculation.
Only used for distance-based clustering, including for example
<code>implementation=HierarchicalClustering</code>,
<code>implementation=PAMClustering</code>, or
<code>implementation=DBSCANClustering</code>.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_tau">tau</code></td>
<td>
<p>subsample size.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_implementation">implementation</code></td>
<td>
<p>function to use for clustering. Possible functions
include <code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a></code> (hierarchical clustering),
<code><a href="#topic+PAMClustering">PAMClustering</a></code> (Partitioning Around Medoids),
<code><a href="#topic+KMeansClustering">KMeansClustering</a></code> (k-means) and <code><a href="#topic+GMMClustering">GMMClustering</a></code>
(Gaussian Mixture Models). Alternatively, a user-defined function taking
<code>xdata</code> and <code>Lambda</code> as arguments and returning a binary and
symmetric matrix for which diagonal elements are equal to zero can be used.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled to ensure that
all variables contribute equally to the clustering of the observations.</p>
</td></tr>
<tr><td><code id="CheckInputClustering_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
</table>

<hr>
<h2 id='CheckInputGraphical'>Checking input parameters (graphical model)</h2><span id='topic+CheckInputGraphical'></span>

<h3>Description</h3>

<p>Checks if input parameters are valid. For invalid parameters, this function
(i) stops the run and generates an error message, or (ii) sets the invalid
parameter to its default value and reports it in a warning message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckInputGraphical(
  xdata,
  pk = NULL,
  Lambda = NULL,
  lambda_other_blocks = 0.1,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  implementation = PenalisedGraphical,
  start = "cold",
  scale = TRUE,
  resampling = "subsampling",
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  Lambda_cardinal = 50,
  lambda_max = NULL,
  lambda_path_factor = 1e-04,
  max_density = 0.3,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckInputGraphical_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.
For multi-block stability selection, the variables in data have to be
ordered by group.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>Lambda=NULL</code> and <code>implementation=PenalisedGraphical</code>,
<code><a href="#topic+LambdaGridGraphical">LambdaGridGraphical</a></code> is used to define a relevant grid.
<code>Lambda</code> can be provided as a vector or a matrix with
<code>length(pk)</code> columns.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_lambda_other_blocks">lambda_other_blocks</code></td>
<td>
<p>optional vector of parameters controlling the
level of sparsity in neighbour blocks for the multi-block procedure. To use
jointly a specific set of parameters for each block,
<code>lambda_other_blocks</code> must be set to <code>NULL</code> (not recommended).
Only used for multi-block stability selection, i.e. if <code>length(pk)&gt;1</code>.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_implementation">implementation</code></td>
<td>
<p>function to use for graphical modelling. If
<code>implementation=PenalisedGraphical</code>, the algorithm implemented in
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> is used for regularised estimation of
a conditional independence graph. Alternatively, a user-defined function
can be provided.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_start">start</code></td>
<td>
<p>character string indicating if the algorithm should be
initialised at the estimated (inverse) covariance with previous penalty
parameters (<code>start="warm"</code>) or not (<code>start="cold"</code>). Using
<code>start="warm"</code> can speed-up the computations, but could lead to
convergence issues (in particular with small <code>Lambda_cardinal</code>). Only
used for <code>implementation=PenalisedGraphical</code> (see argument
<code>"start"</code> in <code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code>).</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the correlation (<code>scale=TRUE</code>) or
covariance (<code>scale=FALSE</code>) matrix should be used as input of
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> if
<code>implementation=PenalisedGraphical</code>. Otherwise, this argument must be
used in the function provided in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm. Only used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_lambda_max">lambda_max</code></td>
<td>
<p>optional maximum value for the grid in penalty parameters.
If <code>lambda_max=NULL</code>, the maximum value is set to the maximum
covariance in absolute value. Only used if
<code>implementation=PenalisedGraphical</code> and <code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_lambda_path_factor">lambda_path_factor</code></td>
<td>
<p>multiplicative factor used to define the minimum
value in the grid.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_max_density">max_density</code></td>
<td>
<p>threshold on the density. The grid is defined such that
the density of the estimated graph does not exceed max_density.</p>
</td></tr>
<tr><td><code id="CheckInputGraphical_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
</table>

<hr>
<h2 id='CheckPackageInstalled'>Checking that a package is installed</h2><span id='topic+CheckPackageInstalled'></span>

<h3>Description</h3>

<p>Checks if a package is installed and returns an error message if not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckPackageInstalled(package)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckPackageInstalled_+3A_package">package</code></td>
<td>
<p>character string indicating the name of the package.</p>
</td></tr>
</table>

<hr>
<h2 id='CheckParamRegression'>Checking input parameters (regression model)</h2><span id='topic+CheckParamRegression'></span>

<h3>Description</h3>

<p>Checks if input parameters are valid. For invalid parameters, this function
(i) stops the run and generates an error message, or (ii) sets the invalid
parameter to its default value and reports it in a warning message.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CheckParamRegression(
  Lambda = NULL,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = NULL,
  family = "gaussian",
  implementation = PenalisedRegression,
  resampling = "subsampling",
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  Lambda_cardinal = 100,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CheckParamRegression_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>Lambda=NULL</code> and <code>implementation=PenalisedRegression</code>,
<code><a href="#topic+LambdaGridRegression">LambdaGridRegression</a></code> is used to define a relevant grid.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_implementation">implementation</code></td>
<td>
<p>function to use for variable selection. Possible
functions are: <code>PenalisedRegression</code>, <code>SparsePLS</code>,
<code>GroupPLS</code> and <code>SparseGroupPLS</code>. Alternatively, a user-defined
function can be provided.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm. Only used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="CheckParamRegression_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
</table>

<hr>
<h2 id='Clustering'>Consensus clustering</h2><span id='topic+Clustering'></span>

<h3>Description</h3>

<p>Performs consensus (weighted) clustering. The underlying algorithm (e.g.
hierarchical clustering) is run with different number of clusters <code>nc</code>.
In consensus weighed clustering, weighted distances are calculated using the
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> algorithm with different penalty parameters
<code>Lambda</code>. The hyper-parameters are calibrated by maximisation of the
consensus score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Clustering(
  xdata,
  nc = NULL,
  eps = NULL,
  Lambda = NULL,
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  implementation = HierarchicalClustering,
  scale = TRUE,
  linkage = "complete",
  row = TRUE,
  optimisation = c("grid_search", "nloptr"),
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  beep = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Clustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_eps">eps</code></td>
<td>
<p>radius in density-based clustering, see
<code><a href="dbscan.html#topic+dbscan">dbscan</a></code>. Only used if
<code>implementation=DBSCANClustering</code>.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters for weighted distance calculation.
Only used for distance-based clustering, including for example
<code>implementation=HierarchicalClustering</code>,
<code>implementation=PAMClustering</code>, or
<code>implementation=DBSCANClustering</code>.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_tau">tau</code></td>
<td>
<p>subsample size.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="Clustering_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_implementation">implementation</code></td>
<td>
<p>function to use for clustering. Possible functions
include <code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a></code> (hierarchical clustering),
<code><a href="#topic+PAMClustering">PAMClustering</a></code> (Partitioning Around Medoids),
<code><a href="#topic+KMeansClustering">KMeansClustering</a></code> (k-means) and <code><a href="#topic+GMMClustering">GMMClustering</a></code>
(Gaussian Mixture Models). Alternatively, a user-defined function taking
<code>xdata</code> and <code>Lambda</code> as arguments and returning a binary and
symmetric matrix for which diagonal elements are equal to zero can be used.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled to ensure that
all variables contribute equally to the clustering of the observations.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_linkage">linkage</code></td>
<td>
<p>character string indicating the type of linkage used in
hierarchical clustering to define the stable clusters. Possible values
include <code>"complete"</code>, <code>"single"</code> and <code>"average"</code> (see
argument <code>"method"</code> in <code><a href="stats.html#topic+hclust">hclust</a></code> for a full list).
Only used if <code>implementation=HierarchicalClustering</code>.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_row">row</code></td>
<td>
<p>logical indicating if rows (if <code>row=TRUE</code>) or columns (if
<code>row=FALSE</code>) contain the items to cluster.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_optimisation">optimisation</code></td>
<td>
<p>character string indicating the type of optimisation
method to calibrate the regularisation parameter (only used if
<code>Lambda</code> is not <code>NULL</code>). With <code>optimisation="grid_search"</code>
(the default), all values in <code>Lambda</code> are visited.
Alternatively, optimisation algorithms implemented in
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code> can be used with <code>optimisation="nloptr"</code>.
By default, we use <code>"algorithm"="NLOPT_GN_DIRECT_L"</code>,
<code>"xtol_abs"=0.1</code>, <code>"ftol_abs"=0.1</code> and
<code>"maxeval"</code> defined as <code>length(Lambda)</code>. These values can be
changed by providing the argument <code>opts</code> (see
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code>).</p>
</td></tr>
<tr><td><code id="Clustering_+3A_n_cores">n_cores</code></td>
<td>
<p>number of cores to use for parallel computing (see argument
<code>workers</code> in <code><a href="future.html#topic+multisession">multisession</a></code>). Using
<code>n_cores&gt;1</code> is only supported with <code>optimisation="grid_search"</code>.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="Clustering_+3A_beep">beep</code></td>
<td>
<p>sound indicating the end of the run. Possible values are:
<code>NULL</code> (no sound) or an integer between 1 and 11 (see argument
<code>sound</code> in <code><a href="beepr.html#topic+beep">beep</a></code>).</p>
</td></tr>
<tr><td><code id="Clustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In consensus clustering, a clustering algorithm is applied on
<code>K</code> subsamples of the observations with different numbers of clusters
provided in <code>nc</code>. If <code>row=TRUE</code> (the default), the observations
(rows) are the items to cluster. If <code>row=FALSE</code>, the variables
(columns) are the items to cluster. For a given number of clusters, the
consensus matrix <code>coprop</code> stores the proportion of iterations where
two items were in the same estimated cluster, out of all iterations where
both items were drawn in the subsample.
</p>
<p>Stable cluster membership is obtained by applying a distance-based
clustering method using <code>(1-coprop)</code> as distance (see
<a href="#topic+Clusters">Clusters</a>).
</p>
<p>These parameters can be calibrated by maximisation of a stability score
(see <code><a href="#topic+ConsensusScore">ConsensusScore</a></code>) calculated under the null hypothesis of
equiprobability of co-membership.
</p>
<p>It is strongly recommended to examine the calibration plot (see
<code><a href="#topic+CalibrationPlot">CalibrationPlot</a></code>) to check that there is a clear maximum. The
absence of a clear maximum suggests that the clustering is not stable,
consensus clustering outputs should not be trusted in that case.
</p>
<p>To ensure reproducibility of the results, the starting number of the random
number generator is set to <code>seed</code>.
</p>
<p>For parallelisation, stability selection with different sets of parameters
can be run on <code>n_cores</code> cores. Using <code>n_cores &gt; 1</code> creates a
<code><a href="future.html#topic+multisession">multisession</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>clustering</code>. A list with: </p>
<table>
<tr><td><code>Sc</code></td>
<td>
<p>a matrix
of the best stability scores for different (sets of) parameters controlling
the number of clusters and penalisation of attribute weights.</p>
</td></tr> <tr><td><code>nc</code></td>
<td>
<p>a
matrix of numbers of clusters.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix of regularisation
parameters for attribute weights.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the average number
of selected attributes by the underlying algorithm with different
regularisation parameters.</p>
</td></tr> <tr><td><code>coprop</code></td>
<td>
<p>an array of consensus matrices.
Rows and columns correspond to items. Indices along the third dimension
correspond to different parameters controlling the number of clusters and
penalisation of attribute weights.</p>
</td></tr> <tr><td><code>selprop</code></td>
<td>
<p>an array of selection
proportions. Columns correspond to attributes. Rows correspond to different
parameters controlling the number of clusters and penalisation of attribute
weights.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list with <code>type="clustering"</code> and values
used for arguments <code>implementation</code>, <code>linkage</code>, and
<code>resampling</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used for arguments
<code>K</code>, <code>tau</code>, <code>pk</code>, <code>n</code> (number of observations in
<code>xdata</code>), and <code>seed</code>.</p>
</td></tr></table>
<p> The rows of <code>Sc</code>, <code>nc</code>,
<code>Lambda</code>, <code>Q</code>, <code>selprop</code> and indices along the third
dimension of <code>coprop</code> are ordered in the same way and correspond to
parameter values stored in <code>nc</code> and <code>Lambda</code>.
</p>


<h3>References</h3>

<p>Bodinier B, Vuckovic D, Rodrigues S, Filippi S, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration of consensus weighted distance-based clustering approaches using sharp.&rdquo;
<em>Bioinformatics</em>, btad635.
ISSN 1367-4811, <a href="https://doi.org/10.1093/bioinformatics/btad635">doi:10.1093/bioinformatics/btad635</a>, https://academic.oup.com/bioinformatics/advance-article-pdf/doi/10.1093/bioinformatics/btad635/52191190/btad635.pdf.
</p>
<p>Kampert MM, Meulman JJ, Friedman JH (2017).
&ldquo;rCOSA: A Software Package for Clustering Objects on Subsets of Attributes.&rdquo;
<em>Journal of Classification</em>, <b>34</b>(3), 514&ndash;547.
<a href="https://doi.org/10.1007/s00357-017-9240-z">doi:10.1007/s00357-017-9240-z</a>.
</p>
<p>Friedman JH, Meulman JJ (2004).
&ldquo;Clustering objects on subsets of attributes (with discussion).&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>66</b>(4), 815-849.
<a href="https://doi.org/10.1111/j.1467-9868.2004.02059.x">doi:10.1111/j.1467-9868.2004.02059.x</a>, https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2004.02059.x, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x</a>.
</p>
<p>Monti S, Tamayo P, Mesirov J, Golub T (2003).
&ldquo;Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data.&rdquo;
<em>Machine Learning</em>, <b>52</b>(1), 91&ndash;118.
<a href="https://doi.org/10.1023/A%3A1023949509487">doi:10.1023/A:1023949509487</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Resample">Resample</a></code>, <code><a href="#topic+ConsensusScore">ConsensusScore</a></code>,
<code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a></code>, <code><a href="#topic+PAMClustering">PAMClustering</a></code>,
<code><a href="#topic+KMeansClustering">KMeansClustering</a></code>, <code><a href="#topic+GMMClustering">GMMClustering</a></code>
</p>
<p>Other stability functions: 
<code><a href="#topic+BiSelection">BiSelection</a>()</code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a>()</code>,
<code><a href="#topic+StructuralModel">StructuralModel</a>()</code>,
<code><a href="#topic+VariableSelection">VariableSelection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Consensus clustering
set.seed(1)
simul &lt;- SimulateClustering(
  n = c(30, 30, 30), nu_xc = 1, ev_xc = 0.5
)
stab &lt;- Clustering(xdata = simul$data)
print(stab)
CalibrationPlot(stab)
summary(stab)
Clusters(stab)
plot(stab)

# Consensus weighted clustering
if (requireNamespace("rCOSA", quietly = TRUE)) {
  set.seed(1)
  simul &lt;- SimulateClustering(
    n = c(30, 30, 30), pk = 20,
    theta_xc = c(rep(1, 10), rep(0, 10)),
    ev_xc = 0.9
  )
  stab &lt;- Clustering(
    xdata = simul$data,
    Lambda = LambdaSequence(lmin = 0.1, lmax = 10, cardinal = 10),
    noit = 20, niter = 10
  )
  print(stab)
  CalibrationPlot(stab)
  summary(stab)
  Clusters(stab)
  plot(stab)
  WeightBoxplot(stab)
}

</code></pre>

<hr>
<h2 id='ClusteringAlgo'>(Weighted) clustering algorithm</h2><span id='topic+ClusteringAlgo'></span>

<h3>Description</h3>

<p>Runs the (weighted) clustering algorithm specified in the argument
<code>implementation</code> and returns matrices of variable weights, and the
co-membership structure. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClusteringAlgo(
  xdata,
  nc = NULL,
  eps = NULL,
  Lambda = NULL,
  scale = TRUE,
  row = TRUE,
  implementation = HierarchicalClustering,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ClusteringAlgo_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_eps">eps</code></td>
<td>
<p>radius in density-based clustering, see
<code><a href="dbscan.html#topic+dbscan">dbscan</a></code>. Only used if
<code>implementation=DBSCANClustering</code>.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled to ensure that
all variables contribute equally to the clustering of the observations.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_row">row</code></td>
<td>
<p>logical indicating if rows (if <code>row=TRUE</code>) or columns (if
<code>row=FALSE</code>) contain the items to cluster.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_implementation">implementation</code></td>
<td>
<p>function to use for clustering. Possible functions
include <code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a></code> (hierarchical clustering),
<code><a href="#topic+PAMClustering">PAMClustering</a></code> (Partitioning Around Medoids),
<code><a href="#topic+KMeansClustering">KMeansClustering</a></code> (k-means) and <code><a href="#topic+GMMClustering">GMMClustering</a></code>
(Gaussian Mixture Models). Alternatively, a user-defined function taking
<code>xdata</code> and <code>Lambda</code> as arguments and returning a binary and
symmetric matrix for which diagonal elements are equal to zero can be used.</p>
</td></tr>
<tr><td><code id="ClusteringAlgo_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>implementation</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>weight</code></td>
<td>
<p>array of model coefficients. Rows correspond to
different model parameters. Columns correspond to predictors. Indices along
the third dimension correspond to outcome variable(s).</p>
</td></tr>
<tr><td><code>comembership</code></td>
<td>
<p>array of model coefficients. Rows correspond to
different model parameters. Columns correspond to predictors. Indices along
the third dimension correspond to outcome variable(s).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>
</p>
<p>Other underlying algorithm functions: 
<code><a href="#topic+CART">CART</a>()</code>,
<code><a href="#topic+PenalisedGraphical">PenalisedGraphical</a>()</code>,
<code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a>()</code>,
<code><a href="#topic+PenalisedRegression">PenalisedRegression</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Simulation of 15 observations belonging to 3 groups
set.seed(1)
simul &lt;- SimulateClustering(
  n = c(5, 5, 5), pk = 100
)

# Running hierarchical clustering
myclust &lt;- ClusteringAlgo(
  xdata = simul$data, nc = 2:5,
  implementation = HierarchicalClustering
)

</code></pre>

<hr>
<h2 id='ClusteringPerformance'>Clustering performance</h2><span id='topic+ClusteringPerformance'></span>

<h3>Description</h3>

<p>Computes different metrics of clustering performance by comparing true and
predicted co-membership. This function can only be used in simulation studies
(i.e. when the true cluster membership is known).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ClusteringPerformance(theta, theta_star, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ClusteringPerformance_+3A_theta">theta</code></td>
<td>
<p>output from <code><a href="#topic+Clustering">Clustering</a></code>. Alternatively, it can be
the estimated co-membership matrix (see <code><a href="#topic+CoMembership">CoMembership</a></code>).</p>
</td></tr>
<tr><td><code id="ClusteringPerformance_+3A_theta_star">theta_star</code></td>
<td>
<p>output from <code><a href="fake.html#topic+SimulateClustering">SimulateClustering</a></code>.Alternatively,
it can be the true co-membership matrix (see <code><a href="#topic+CoMembership">CoMembership</a></code>).</p>
</td></tr>
<tr><td><code id="ClusteringPerformance_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+Clusters">Clusters</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of selection metrics including:
</p>
<table>
<tr><td><code>TP</code></td>
<td>
<p>number of True Positives (TP)</p>
</td></tr> <tr><td><code>FN</code></td>
<td>
<p>number of False
Negatives (TN)</p>
</td></tr> <tr><td><code>FP</code></td>
<td>
<p>number of False Positives (FP)</p>
</td></tr> <tr><td><code>TN</code></td>
<td>
<p>number
of True Negatives (TN)</p>
</td></tr> <tr><td><code>sensitivity</code></td>
<td>
<p>sensitivity, i.e. TP/(TP+FN)</p>
</td></tr>
<tr><td><code>specificity</code></td>
<td>
<p>specificity, i.e. TN/(TN+FP)</p>
</td></tr> <tr><td><code>accuracy</code></td>
<td>
<p>accuracy,
i.e. (TP+TN)/(TP+TN+FP+FN)</p>
</td></tr> <tr><td><code>precision</code></td>
<td>
<p>precision (p), i.e.
TP/(TP+FP)</p>
</td></tr> <tr><td><code>recall</code></td>
<td>
<p>recall (r), i.e. TP/(TP+FN)</p>
</td></tr>
<tr><td><code>F1_score</code></td>
<td>
<p>F1-score, i.e. 2*p*r/(p+r)</p>
</td></tr> <tr><td><code>rand</code></td>
<td>
<p>Rand Index, i.e.
(TP+TN)/(TP+FP+TN+FN)</p>
</td></tr> <tr><td><code>ari</code></td>
<td>
<p>Adjusted Rand Index (ARI), i.e.
2*(TP*TN-FP*FN)/((TP+FP)*(TN+FP)+(TP+FN)*(TN+FN))</p>
</td></tr> <tr><td><code>jaccard</code></td>
<td>
<p>Jaccard
index, i.e. TP/(TP+FP+FN)</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other functions for model performance: 
<code><a href="#topic+SelectionPerformance">SelectionPerformance</a>()</code>,
<code><a href="#topic+SelectionPerformanceGraph">SelectionPerformanceGraph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateClustering(
  n = c(30, 30, 30), nu_xc = 1
)
plot(simul)

# Consensus clustering
stab &lt;- Clustering(
  xdata = simul$data, nc = seq_len(5)
)

# Clustering performance
ClusteringPerformance(stab, simul)

# Alternative formulation
ClusteringPerformance(
  theta = CoMembership(Clusters(stab)),
  theta_star = simul$theta
)


</code></pre>

<hr>
<h2 id='Coefficients'>Model coefficients</h2><span id='topic+Coefficients'></span>

<h3>Description</h3>

<p>Extracts the coefficients of visited models at different resampling
iterations of a stability selection run. This function can be applied to the
output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Coefficients(stability, side = "X", comp = 1, iterations = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Coefficients_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.</p>
</td></tr>
<tr><td><code id="Coefficients_+3A_side">side</code></td>
<td>
<p>character string indicating if coefficients of the predictor
(<code>side="X"</code>) or outcome (<code>side="Y"</code>) coefficients should be
returned. Option <code>side="Y"</code> is only applicable to PLS models.</p>
</td></tr>
<tr><td><code id="Coefficients_+3A_comp">comp</code></td>
<td>
<p>component ID. Only applicable to PLS models.</p>
</td></tr>
<tr><td><code id="Coefficients_+3A_iterations">iterations</code></td>
<td>
<p>vector of iteration IDs. If <code>iterations=NULL</code>, the
coefficients of all visited models are returned. This number must be
smaller than the number of iterations <code>K</code> used for the stability
selection run.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>
</p>

<hr>
<h2 id='Combine'>Merging stability selection outputs</h2><span id='topic+Combine'></span>

<h3>Description</h3>

<p>Merges the outputs from two runs of <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code> or <code><a href="#topic+Clustering">Clustering</a></code>. The two runs must
have been done using the same <code>methods</code> and the same <code>params</code> but
with different <code>seed</code>s. The combined output will contain results based
on iterations from both <code>stability1</code> and <code>stability2</code>. This
function can be used for parallelisation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Combine(stability1, stability2, include_beta = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Combine_+3A_stability1">stability1</code></td>
<td>
<p>output from a first run of <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, or <code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="Combine_+3A_stability2">stability2</code></td>
<td>
<p>output from a second run of
<code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, or
<code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="Combine_+3A_include_beta">include_beta</code></td>
<td>
<p>logical indicating if the beta coefficients of visited
models should be concatenated. Only applicable to variable selection or
clustering.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single output of the same format.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Variable selection

# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")

# Two runs
stab1 &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, seed = 1, K = 10)
stab2 &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, seed = 2, K = 10)

# Merging the outputs
stab &lt;- Combine(stability1 = stab1, stability2 = stab2, include_beta = FALSE)
str(stab)


## Graphical modelling

# Data simulation
simul &lt;- SimulateGraphical(pk = 20)

# Two runs
stab1 &lt;- GraphicalModel(xdata = simul$data, seed = 1, K = 10)
stab2 &lt;- GraphicalModel(xdata = simul$data, seed = 2, K = 10)

# Merging the outputs
stab &lt;- Combine(stability1 = stab1, stability2 = stab2)
str(stab)


## Clustering

# Data simulation
simul &lt;- SimulateClustering(n = c(15, 15, 15))

# Two runs
stab1 &lt;- Clustering(xdata = simul$data, seed = 1)
stab2 &lt;- Clustering(xdata = simul$data, seed = 2)

# Merging the outputs
stab &lt;- Combine(stability1 = stab1, stability2 = stab2)
str(stab)

</code></pre>

<hr>
<h2 id='CoMembership'>Pairwise co-membership</h2><span id='topic+CoMembership'></span>

<h3>Description</h3>

<p>Generates a symmetric and binary matrix indicating, if two items are
co-members, i.e. belong to the same cluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CoMembership(groups)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CoMembership_+3A_groups">groups</code></td>
<td>
<p>vector of group membership.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A symmetric and binary matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated grouping structure
mygroups &lt;- c(rep(1, 3), rep(2, 5), rep(3, 2))

# Co-membership matrix
CoMembership(mygroups)
</code></pre>

<hr>
<h2 id='Concatenate'>Concatenate stability objects</h2><span id='topic+Concatenate'></span>

<h3>Description</h3>

<p>Generates a single stability object from two stability objects. This function
is used to concatenate results when using <code><a href="nloptr.html#topic+nloptr">nloptr</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Concatenate(stability1, stability2 = NULL, order_output = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Concatenate_+3A_stability1">stability1</code></td>
<td>
<p>a stability object.</p>
</td></tr>
<tr><td><code id="Concatenate_+3A_stability2">stability2</code></td>
<td>
<p>another stability object (optional).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single stability object.
</p>

<hr>
<h2 id='ConsensusScore'>Consensus score</h2><span id='topic+ConsensusScore'></span>

<h3>Description</h3>

<p>Computes the consensus score from the consensus matrix, matrix of co-sampling
counts and consensus clusters. The score is a z statistic for the comparison
of the co-membership proportions observed within and between the consensus
clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConsensusScore(prop, K, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConsensusScore_+3A_prop">prop</code></td>
<td>
<p>consensus matrix.</p>
</td></tr>
<tr><td><code id="ConsensusScore_+3A_k">K</code></td>
<td>
<p>matrix of co-sampling counts.</p>
</td></tr>
<tr><td><code id="ConsensusScore_+3A_theta">theta</code></td>
<td>
<p>consensus co-membership matrix.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To calculate the consensus score, the features are classified as being stably
selected or not (in selection) or as being in the same consensus cluster or
not (in clustering). In selection, the quantities <code class="reqn">X_w</code> and <code class="reqn">X_b</code> are
defined as the sum of the selection counts for features that are stably
selected or not, respectively. In clustering, the quantities <code class="reqn">X_w</code> and
<code class="reqn">X_b</code> are defined as the sum of the co-membership counts for pairs of
items in the same consensus cluster or in different consensus clusters,
respectively.
</p>
<p>Conditionally on this classification, and under the assumption that the
selection (or co-membership) probabilities are the same for all features (or
item pairs) in each of these two categories, the quantities <code class="reqn">X_w</code> and
<code class="reqn">X_b</code> follow binomial distributions with probabilities <code class="reqn">p_w</code> and
<code class="reqn">p_b</code>, respectively.
</p>
<p>In the most unstable situation, we suppose that all features (or item pairs)
would have the same probability of being selected (or co-members). The
consensus score is the z statistic from a z test where the null hypothesis is
<code class="reqn">p_w \leq p_b</code>.
</p>
<p>The consensus score increases with stability.
</p>


<h3>Value</h3>

<p>A consensus score.
</p>


<h3>See Also</h3>

<p>Other stability metric functions: 
<code><a href="#topic+FDP">FDP</a>()</code>,
<code><a href="#topic+PFER">PFER</a>()</code>,
<code><a href="#topic+StabilityMetrics">StabilityMetrics</a>()</code>,
<code><a href="#topic+StabilityScore">StabilityScore</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(2)
simul &lt;- SimulateClustering(
  n = c(30, 30, 30),
  nu_xc = 1
)
plot(simul)

# Consensus clustering
stab &lt;- Clustering(
  xdata = simul$data
)
stab$Sc[3]

# Calculating the consensus score
theta &lt;- CoMembership(Clusters(stab, argmax_id = 3))
ConsensusScore(
  prop = (stab$coprop[, , 3])[upper.tri(stab$coprop[, , 3])],
  K = stab$sampled_pairs[upper.tri(stab$sampled_pairs)],
  theta = theta[upper.tri(theta)]
)

</code></pre>

<hr>
<h2 id='DBSCANClustering'>(Weighted) density-based clustering</h2><span id='topic+DBSCANClustering'></span>

<h3>Description</h3>

<p>Runs Density-Based Spatial Clustering of Applications with Noise (DBSCAN)
clustering using implementation from <code><a href="dbscan.html#topic+dbscan">dbscan</a></code>. This is
also known as the k-medoids algorithm. If <code>Lambda</code> is provided,
clustering is applied on the weighted distance matrix calculated using the
COSA algorithm as implemented in <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>. Otherwise,
distances are calculated using <code><a href="stats.html#topic+dist">dist</a></code>. This function is
not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DBSCANClustering(
  xdata,
  nc = NULL,
  eps = NULL,
  Lambda = NULL,
  distance = "euclidean",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DBSCANClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="DBSCANClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="DBSCANClustering_+3A_eps">eps</code></td>
<td>
<p>radius in density-based clustering, see
<code><a href="dbscan.html#topic+dbscan">dbscan</a></code>.</p>
</td></tr>
<tr><td><code id="DBSCANClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters (see argument <code>lambda</code> in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>). Unweighted distance matrices are used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="DBSCANClustering_+3A_distance">distance</code></td>
<td>
<p>character string indicating the type of distance to use. If
<code>Lambda=NULL</code>, possible values include <code>"euclidean"</code>,
<code>"maximum"</code>, <code>"canberra"</code>, <code>"binary"</code>, and
<code>"minkowski"</code> (see argument <code>method</code> in
<code><a href="stats.html#topic+dist">dist</a></code>).  Otherwise, possible values include
<code>"euclidean"</code> (<code>pwr=2</code>) or <code>"absolute"</code> (<code>pwr=1</code>) (see
argument <code>pwr</code> in <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>).</p>
</td></tr>
<tr><td><code id="DBSCANClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="dbscan.html#topic+dbscan">dbscan</a></code>
(except for <code>minPts</code> which is fixed to <code>2</code>),
<code><a href="stats.html#topic+dist">dist</a></code>, or <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>. If
<code>weighted=TRUE</code>, parameters <code>niter</code> (default to 1) and
<code>noit</code> (default to 100) correspond to the number of iterations in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> to calculate weights and may need to be
modified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kampert MM, Meulman JJ, Friedman JH (2017).
&ldquo;rCOSA: A Software Package for Clustering Objects on Subsets of Attributes.&rdquo;
<em>Journal of Classification</em>, <b>34</b>(3), 514&ndash;547.
<a href="https://doi.org/10.1007/s00357-017-9240-z">doi:10.1007/s00357-017-9240-z</a>.
</p>
<p>Friedman JH, Meulman JJ (2004).
&ldquo;Clustering objects on subsets of attributes (with discussion).&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>66</b>(4), 815-849.
<a href="https://doi.org/10.1111/j.1467-9868.2004.02059.x">doi:10.1111/j.1467-9868.2004.02059.x</a>, https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2004.02059.x, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x</a>.
</p>


<h3>See Also</h3>

<p>Other clustering algorithms: 
<code><a href="#topic+GMMClustering">GMMClustering</a>()</code>,
<code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a>()</code>,
<code><a href="#topic+KMeansClustering">KMeansClustering</a>()</code>,
<code><a href="#topic+PAMClustering">PAMClustering</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("dbscan", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateClustering(n = c(10, 10), pk = 50)
  plot(simul)

  # DBSCAN clustering
  myclust &lt;- DBSCANClustering(
    xdata = simul$data,
    eps = seq(0, 2 * sqrt(ncol(simul$data) - 1), by = 0.1)
  )

  # Weighted PAM clustering (using COSA)
  if (requireNamespace("rCOSA", quietly = TRUE)) {
    myclust &lt;- DBSCANClustering(
      xdata = simul$data,
      eps = c(0.25, 0.5, 0.75),
      Lambda = c(0.2, 0.5)
    )
  }
}
</code></pre>

<hr>
<h2 id='DummyToCategories'>Categorical from dummy variables</h2><span id='topic+DummyToCategories'></span>

<h3>Description</h3>

<p>Generates a single categorical variable from corresponding dummy variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DummyToCategories(x, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DummyToCategories_+3A_x">x</code></td>
<td>
<p>matrix of dummy variables.</p>
</td></tr>
<tr><td><code id="DummyToCategories_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if messages should be printed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single categorical variable (numeric).
</p>

<hr>
<h2 id='Ensemble'>Ensemble model</h2><span id='topic+Ensemble'></span>

<h3>Description</h3>

<p>Creates an ensemble predictive model from <code><a href="#topic+VariableSelection">VariableSelection</a></code>
outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ensemble(stability, xdata, ydata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Ensemble_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.</p>
</td></tr>
<tr><td><code id="Ensemble_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="Ensemble_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ensemble_model</code>. A list with:
</p>
<table>
<tr><td><code>intercept</code></td>
<td>
<p>a vector of refitted intercepts for the <code>K</code>
calibrated models.</p>
</td></tr> <tr><td><code>beta</code></td>
<td>
<p>a matrix of beta coefficients from the
<code>K</code> calibrated models.</p>
</td></tr> <tr><td><code>models</code></td>
<td>
<p>a list of <code>K</code> models that
can be used for prediction. These models are of class <code>"lm"</code> if
<code>family="gaussian"</code> or <code>"glm"</code> if
<code>family="binomial"</code>.</p>
</td></tr> <tr><td><code>family</code></td>
<td>
<p>type of regression, extracted from
<code>stability</code>. Possible values are <code>"gaussian"</code> or
<code>"binomial"</code>.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other ensemble model functions: 
<code><a href="#topic+EnsemblePredictions">EnsemblePredictions</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Linear regression
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, family = "gaussian")
ensemble &lt;- Ensemble(stability = stab, xdata = simul$xdata, ydata = simul$ydata)

# Logistic regression
set.seed(1)
simul &lt;- SimulateRegression(n = 200, pk = 20, family = "binomial")
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, family = "binomial")
ensemble &lt;- Ensemble(stability = stab, xdata = simul$xdata, ydata = simul$ydata)

</code></pre>

<hr>
<h2 id='EnsemblePredictions'>Predictions from ensemble model</h2><span id='topic+EnsemblePredictions'></span>

<h3>Description</h3>

<p>Makes predictions using an ensemble model created from
<code><a href="#topic+VariableSelection">VariableSelection</a></code> outputs. For each observation in
<code>xdata</code>, the predictions are calculated as the average predicted values
obtained for that observation over the <code>K</code> models fitted in calibrated
stability selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EnsemblePredictions(ensemble, xdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EnsemblePredictions_+3A_ensemble">ensemble</code></td>
<td>
<p>output of <code><a href="#topic+Ensemble">Ensemble</a></code>.</p>
</td></tr>
<tr><td><code id="EnsemblePredictions_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="EnsemblePredictions_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="stats.html#topic+predict">predict</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions computed from the observations in
<code>xdata</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.variable_selection">predict.variable_selection</a></code>
</p>
<p>Other ensemble model functions: 
<code><a href="#topic+Ensemble">Ensemble</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 1000, pk = 50, family = "gaussian")

# Training/test split
ids &lt;- Split(data = simul$ydata, tau = c(0.8, 0.2))
stab &lt;- VariableSelection(
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ]
)

# Constructing the ensemble model
ensemble &lt;- Ensemble(
  stability = stab,
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ]
)

# Making predictions
yhat &lt;- EnsemblePredictions(
  ensemble = ensemble,
  xdata = simul$xdata[ids[[2]], ]
)

# Calculating Q-squared
cor(simul$ydata[ids[[2]], ], yhat)^2

</code></pre>

<hr>
<h2 id='ExplanatoryPerformance'>Prediction performance in regression</h2><span id='topic+ExplanatoryPerformance'></span>

<h3>Description</h3>

<p>Calculates model performance for linear (measured by Q-squared), logistic
(AUC) or Cox (C-statistic) regression. This is done by (i) refitting the
model on a training set including a proportion <code>tau</code> of the
observations, and (ii) evaluating the performance on the remaining
observations (test set). For more reliable results, the procedure can be
repeated <code>K</code> times (default <code>K=1</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExplanatoryPerformance(
  xdata,
  ydata,
  new_xdata = NULL,
  new_ydata = NULL,
  stability = NULL,
  family = NULL,
  implementation = NULL,
  prediction = NULL,
  resampling = "subsampling",
  K = 1,
  tau = 0.8,
  seed = 1,
  n_thr = NULL,
  time = 1000,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExplanatoryPerformance_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_new_xdata">new_xdata</code></td>
<td>
<p>optional test set (predictor data).</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_new_ydata">new_ydata</code></td>
<td>
<p>optional test set (outcome data).</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>. If
<code>stability=NULL</code> (the default), a model including all variables in
<code>xdata</code> as predictors is fitted. Argument <code>family</code> must be
provided in this case.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_family">family</code></td>
<td>
<p>type of regression model. Possible values include
<code>"gaussian"</code> (linear regression), <code>"binomial"</code> (logistic
regression), and <code>"cox"</code> (survival analysis). If provided, this
argument must be consistent with input <code>stability</code>.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_implementation">implementation</code></td>
<td>
<p>optional function to refit the model. If
<code>implementation=NULL</code> and <code>stability</code> is the output of
<code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="stats.html#topic+lm">lm</a></code> (linear
regression), <code><a href="survival.html#topic+coxph">coxph</a></code> (Cox regression),
<code><a href="stats.html#topic+glm">glm</a></code> (logistic regression), or
<code><a href="nnet.html#topic+multinom">multinom</a></code> (multinomial regression) is used.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_prediction">prediction</code></td>
<td>
<p>optional function to compute predicted values from the
model refitted with <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach to create the training set. The default
is <code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations. Alternatively, this argument can be a
function to use for resampling. This function must use arguments named
<code>data</code> and <code>tau</code> and return the IDs of observations to be
included in the resampled dataset.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_k">K</code></td>
<td>
<p>number of training-test splits. Only used if <code>new_xdata</code> and
<code>new_ydata</code> are not provided.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_tau">tau</code></td>
<td>
<p>proportion of observations used in the training set. Only used if
<code>new_xdata</code> and <code>new_ydata</code> are not provided.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_seed">seed</code></td>
<td>
<p>value of the seed to ensure reproducibility of the results. Only
used if <code>new_xdata</code> and <code>new_ydata</code> are not provided.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_n_thr">n_thr</code></td>
<td>
<p>number of thresholds to use to construct the ROC curve. If
<code>n_thr=NULL</code>, all predicted probability values are iteratively used as
thresholds. For faster computations on large data, less thresholds can be
used. Only applicable to logistic regression.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_time">time</code></td>
<td>
<p>numeric indicating the time for which the survival probabilities
are computed. Only applicable to Cox regression.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="ExplanatoryPerformance_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a fair evaluation of the prediction performance, the data is
split into a training set (including a proportion <code>tau</code> of the
observations) and test set (remaining observations). The regression model
is fitted on the training set and applied on the test set. Performance
metrics are computed in the test set by comparing predicted and observed
outcomes.
</p>
<p>For logistic regression, a Receiver Operating Characteristic (ROC) analysis
is performed: the True and False Positive Rates (TPR and FPR), and Area
Under the Curve (AUC) are computed for different thresholds in predicted
probabilities.
</p>
<p>For Cox regression, the Concordance Index (as implemented in
<code><a href="survival.html#topic+concordance">concordance</a></code>) looking at survival probabilities up
to a specific <code>time</code> is computed.
</p>
<p>For linear regression, the squared correlation between predicted and
observed outcome in the test set (Q-squared) is reported.
</p>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>TPR</code></td>
<td>
<p>True Positive Rate (for logistic regression
only).</p>
</td></tr> <tr><td><code>FPR</code></td>
<td>
<p>False Positive Rate (for logistic regression only).</p>
</td></tr>
<tr><td><code>AUC</code></td>
<td>
<p>Area Under the Curve (for logistic regression only).</p>
</td></tr>
<tr><td><code>concordance</code></td>
<td>
<p>Concordance index (for Cox regression only).</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>
<p>matrix of estimated beta coefficients across the <code>K</code>
iterations. Coefficients are extracted using the <code><a href="stats.html#topic+coef">coef</a></code>
function.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+Refit">Refit</a></code>
</p>
<p>Other prediction performance functions: 
<code><a href="#topic+Incremental">Incremental</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(
  n = 1000, pk = 20,
  family = "binomial", ev_xy = 0.8
)

# Data split: selection, training and test set
ids &lt;- Split(
  data = simul$ydata,
  family = "binomial",
  tau = c(0.4, 0.3, 0.3)
)
xselect &lt;- simul$xdata[ids[[1]], ]
yselect &lt;- simul$ydata[ids[[1]], ]
xtrain &lt;- simul$xdata[ids[[2]], ]
ytrain &lt;- simul$ydata[ids[[2]], ]
xtest &lt;- simul$xdata[ids[[3]], ]
ytest &lt;- simul$ydata[ids[[3]], ]

# Stability selection
stab &lt;- VariableSelection(
  xdata = xselect,
  ydata = yselect,
  family = "binomial"
)

# Performances in test set of model refitted in training set
roc &lt;- ExplanatoryPerformance(
  xdata = xtrain, ydata = ytrain,
  new_xdata = xtest, new_ydata = ytest,
  stability = stab
)
plot(roc)
roc$AUC

# Alternative with multiple training/test splits
roc &lt;- ExplanatoryPerformance(
  xdata = rbind(xtrain, xtest),
  ydata = c(ytrain, ytest),
  stability = stab, K = 100
)
plot(roc)
boxplot(roc$AUC)

# Partial Least Squares Discriminant Analysis
if (requireNamespace("sgPLS", quietly = TRUE)) {
  stab &lt;- VariableSelection(
    xdata = xselect,
    ydata = yselect,
    implementation = SparsePLS,
    family = "binomial"
  )

  # Defining wrapping functions for predictions from PLS-DA
  PLSDA &lt;- function(xdata, ydata, family = "binomial") {
    model &lt;- mixOmics::plsda(X = xdata, Y = as.factor(ydata), ncomp = 1)
    return(model)
  }
  PredictPLSDA &lt;- function(xdata, model) {
    xdata &lt;- xdata[, rownames(model$loadings$X), drop = FALSE]
    predicted &lt;- predict(object = model, newdata = xdata)$predict[, 2, 1]
    return(predicted)
  }

  # Performances with custom models
  roc &lt;- ExplanatoryPerformance(
    xdata = rbind(xtrain, xtest),
    ydata = c(ytrain, ytest),
    stability = stab, K = 100,
    implementation = PLSDA, prediction = PredictPLSDA
  )
  plot(roc)
}

</code></pre>

<hr>
<h2 id='FDP'>False Discovery Proportion</h2><span id='topic+FDP'></span>

<h3>Description</h3>

<p>Computes the False Discovery Proportion (upper-bound) as a ratio of the PFER
(upper-bound) over the number of stably selected features. In stability
selection, the FDP corresponds to the expected proportion of stably selected
features that are not relevant to the outcome (i.e. proportion of False
Positives among stably selected features).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FDP(selprop, PFER, pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FDP_+3A_selprop">selprop</code></td>
<td>
<p>matrix or vector of selection proportions.</p>
</td></tr>
<tr><td><code id="FDP_+3A_pfer">PFER</code></td>
<td>
<p>Per Family Error Rate.</p>
</td></tr>
<tr><td><code id="FDP_+3A_pi">pi</code></td>
<td>
<p>threshold in selection proportions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimated upper-bound in FDP.
</p>


<h3>See Also</h3>

<p>Other stability metric functions: 
<code><a href="#topic+ConsensusScore">ConsensusScore</a>()</code>,
<code><a href="#topic+PFER">PFER</a>()</code>,
<code><a href="#topic+StabilityMetrics">StabilityMetrics</a>()</code>,
<code><a href="#topic+StabilityScore">StabilityScore</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulating set of selection proportions
selprop &lt;- round(runif(n = 20), digits = 2)

# Computing the FDP with a threshold of 0.8
fdp &lt;- FDP(PFER = 3, selprop = selprop, pi = 0.8)
</code></pre>

<hr>
<h2 id='Folds'>Splitting observations into folds</h2><span id='topic+Folds'></span>

<h3>Description</h3>

<p>Generates a list of <code>n_folds</code> non-overlapping sets of observation IDs
(folds).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Folds(data, family = NULL, n_folds = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Folds_+3A_data">data</code></td>
<td>
<p>vector or matrix of data. In regression, this should be the
outcome data.</p>
</td></tr>
<tr><td><code id="Folds_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="Folds_+3A_n_folds">n_folds</code></td>
<td>
<p>number of folds.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For categorical outcomes (i.e. <code>family</code> argument is set to
<code>"binomial"</code>, <code>"multinomial"</code> or <code>"cox"</code>), the split is done
such that the proportion of observations from each of the categories in
each of the folds is representative of that of the full sample.
</p>


<h3>Value</h3>

<p>A list of length <code>n_folds</code> with sets of non-overlapping
observation IDs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Splitting into 5 folds
simul &lt;- SimulateRegression()
ids &lt;- Folds(data = simul$ydata)
lapply(ids, length)

# Balanced folds with respect to a binary variable
simul &lt;- SimulateRegression(family = "binomial")
ids &lt;- Folds(data = simul$ydata, family = "binomial")
lapply(ids, FUN = function(x) {
  table(simul$ydata[x, ])
})
</code></pre>

<hr>
<h2 id='GMMClustering'>Model-based clustering</h2><span id='topic+GMMClustering'></span>

<h3>Description</h3>

<p>Runs clustering with Gaussian Mixture Models (GMM) using implementation from
<code><a href="mclust.html#topic+Mclust">Mclust</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GMMClustering(xdata, nc = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GMMClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="GMMClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="GMMClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="mclust.html#topic+Mclust">Mclust</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other clustering algorithms: 
<code><a href="#topic+DBSCANClustering">DBSCANClustering</a>()</code>,
<code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a>()</code>,
<code><a href="#topic+KMeansClustering">KMeansClustering</a>()</code>,
<code><a href="#topic+PAMClustering">PAMClustering</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul &lt;- SimulateClustering(n = c(10, 10), pk = 50)

# Clustering using Gaussian Mixture Models
mygmm &lt;- GMMClustering(xdata = simul$data, nc = seq_len(30))
</code></pre>

<hr>
<h2 id='Graph'>Graph visualisation</h2><span id='topic+Graph'></span>

<h3>Description</h3>

<p>Produces an <code><a href="igraph.html#topic+igraph-package">igraph</a></code> object from an
adjacency matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Graph(
  adjacency,
  node_label = NULL,
  node_colour = NULL,
  node_shape = NULL,
  edge_colour = "grey60",
  label_colour = "grey20",
  mode = "undirected",
  weighted = FALSE,
  satellites = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Graph_+3A_adjacency">adjacency</code></td>
<td>
<p>adjacency matrix or output of <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>.</p>
</td></tr>
<tr><td><code id="Graph_+3A_node_label">node_label</code></td>
<td>
<p>optional vector of node labels. This vector must contain as
many entries as there are rows/columns in the adjacency matrix and must be
in the same order (the order is used to assign labels to nodes).</p>
</td></tr>
<tr><td><code id="Graph_+3A_node_colour">node_colour</code></td>
<td>
<p>optional vector of node colours. This vector must contain
as many entries as there are rows/columns in the adjacency matrix and must
be in the same order (the order is used to assign colours to nodes).
Integers, named colours or RGB values can be used.</p>
</td></tr>
<tr><td><code id="Graph_+3A_node_shape">node_shape</code></td>
<td>
<p>optional vector of node shapes. This vector must contain as
many entries as there are rows/columns in the adjacency matrix and must be
in the same order (the order is used to assign shapes to nodes). Possible
values are <code>"circle"</code>, <code>"square"</code>, <code>"triangle"</code> or
<code>"star"</code>.</p>
</td></tr>
<tr><td><code id="Graph_+3A_edge_colour">edge_colour</code></td>
<td>
<p>optional character string for edge colour. Integers, named
colours or RGB values can be used.</p>
</td></tr>
<tr><td><code id="Graph_+3A_label_colour">label_colour</code></td>
<td>
<p>optional character string for label colour. Integers,
named colours or RGB values can be used.</p>
</td></tr>
<tr><td><code id="Graph_+3A_mode">mode</code></td>
<td>
<p>character string indicating how the adjacency matrix should be
interpreted. Possible values include <code>"undirected"</code> or
<code>"directed"</code> (see <code><a href="igraph.html#topic+graph_from_adjacency_matrix">graph_from_adjacency_matrix</a></code>).</p>
</td></tr>
<tr><td><code id="Graph_+3A_weighted">weighted</code></td>
<td>
<p>indicating if entries of the adjacency matrix should define
edge width. If <code>weighted=FALSE</code>, an unweighted igraph object is
created, all edges have the same width. If <code>weighted=TRUE</code>, edge width
is defined by the corresponding value in the adjacency matrix. If
<code>weighted=NULL</code>, nodes are linked by as many edges as indicated in the
adjacency matrix (integer values are needed).</p>
</td></tr>
<tr><td><code id="Graph_+3A_satellites">satellites</code></td>
<td>
<p>logical indicating if unconnected nodes (satellites) should
be included in the igraph object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functionalities implemented in
<code><a href="igraph.html#topic+igraph-package">igraph</a></code> can be used on the output.
These include cosmetic changes for the visualisation, but also various
tools for network analysis (including topological properties and community
detection).
</p>
<p>The R package <code><a href="visNetwork.html#topic+visDocumentation">visNetwork</a></code> offers
interactive network visualisation tools. An
<code><a href="igraph.html#topic+igraph-package">igraph</a></code> object can easily be converted
to a <code><a href="visNetwork.html#topic+visDocumentation">visNetwork</a></code> object (see
example below).
</p>
<p>For Cytoscape users, the <code><a href="RCy3.html#topic+RCy3">RCy3</a></code> package can be used
to open the network in Cytoscape.
</p>


<h3>Value</h3>

<p>An igraph object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Adjacency">Adjacency</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>,
<a href="https://igraph.org/r/">igraph manual</a>,
<a href="http://datastorm-open.github.io/visNetwork/">visNetwork manual</a>,
<a href="https://cytoscape.org">Cytoscape</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## From adjacency matrix

# Un-weighted
adjacency &lt;- SimulateAdjacency(pk = 20, topology = "scale-free")
plot(Graph(adjacency))

# Weighted
adjacency &lt;- adjacency * runif(prod(dim(adjacency)))
adjacency &lt;- adjacency + t(adjacency)
plot(Graph(adjacency, weighted = TRUE))

# Node colours and shapes
plot(Graph(adjacency, weighted = TRUE, node_shape = "star", node_colour = "red"))


## From stability selection outputs

# Graphical model
set.seed(1)
simul &lt;- SimulateGraphical(pk = 20)
stab &lt;- GraphicalModel(xdata = simul$data)
plot(Graph(stab))

# Sparse PLS
if (requireNamespace("sgPLS", quietly = TRUE)) {
  set.seed(1)
  simul &lt;- SimulateRegression(n = 50, pk = c(5, 5, 5), family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata
  stab &lt;- BiSelection(
    xdata = simul$xdata, ydata = simul$ydata,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(x) - 1),
    implementation = SparsePLS
  )
  plot(Graph(stab))
}


## Tools from other packages

# Applying some igraph functionalities
adjacency &lt;- SimulateAdjacency(pk = 20, topology = "scale-free")
mygraph &lt;- Graph(adjacency)
igraph::degree(mygraph)
igraph::betweenness(mygraph)
igraph::shortest_paths(mygraph, from = 1, to = 2)
igraph::walktrap.community(mygraph)

# Interactive view using visNetwork
if (requireNamespace("visNetwork", quietly = TRUE)) {
  vgraph &lt;- mygraph
  igraph::V(vgraph)$shape &lt;- rep("dot", length(igraph::V(vgraph)))
  v &lt;- visNetwork::visIgraph(vgraph)
  mylayout &lt;- as.matrix(v$x$nodes[, c("x", "y")])
  mylayout[, 2] &lt;- -mylayout[, 2]
  plot(mygraph, layout = mylayout)
}

# Opening in Cytoscape using RCy3
if (requireNamespace("RCy3", quietly = TRUE)) {
  # Make sure that Cytoscape is open before running the following line
  # RCy3::createNetworkFromIgraph(mygraph)
}


</code></pre>

<hr>
<h2 id='GraphComparison'>Edge-wise comparison of two graphs</h2><span id='topic+GraphComparison'></span>

<h3>Description</h3>

<p>Generates an <code><a href="igraph.html#topic+igraph-package">igraph</a></code> object representing
the common and graph-specific edges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GraphComparison(
  graph1,
  graph2,
  col = c("tomato", "forestgreen", "navy"),
  lty = c(2, 3, 1),
  node_colour = NULL,
  show_labels = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GraphComparison_+3A_graph1">graph1</code></td>
<td>
<p>first graph. Possible inputs are: adjacency matrix, or
<code><a href="igraph.html#topic+igraph-package">igraph</a></code> object, or output of
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+BiSelection">BiSelection</a></code>, or output of <code><a href="fake.html#topic+SimulateGraphical">SimulateGraphical</a></code>,
<code><a href="fake.html#topic+SimulateRegression">SimulateRegression</a></code>.</p>
</td></tr>
<tr><td><code id="GraphComparison_+3A_graph2">graph2</code></td>
<td>
<p>second graph.</p>
</td></tr>
<tr><td><code id="GraphComparison_+3A_col">col</code></td>
<td>
<p>vector of edge colours. The first entry of the vector defines
the colour of edges in <code>graph1</code> only, second entry is for edges in
<code>graph2</code> only and third entry is for common edges.</p>
</td></tr>
<tr><td><code id="GraphComparison_+3A_lty">lty</code></td>
<td>
<p>vector of line types for edges. The order is defined as for
argument <code>col</code>.</p>
</td></tr>
<tr><td><code id="GraphComparison_+3A_node_colour">node_colour</code></td>
<td>
<p>optional vector of node colours. This vector must contain
as many entries as there are rows/columns in the adjacency matrix and must
be in the same order (the order is used to assign colours to nodes).
Integers, named colours or RGB values can be used.</p>
</td></tr>
<tr><td><code id="GraphComparison_+3A_show_labels">show_labels</code></td>
<td>
<p>logical indicating if the node labels should be displayed.</p>
</td></tr>
<tr><td><code id="GraphComparison_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+Graph">Graph</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An igraph object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SelectionPerformanceGraph">SelectionPerformanceGraph</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul1 &lt;- SimulateGraphical(pk = 30)
set.seed(2)
simul2 &lt;- SimulateGraphical(pk = 30)

# Edge-wise comparison of the two graphs
mygraph &lt;- GraphComparison(
  graph1 = simul1,
  graph2 = simul2
)
plot(mygraph, layout = igraph::layout_with_kk(mygraph))
</code></pre>

<hr>
<h2 id='GraphicalAlgo'>Graphical model algorithm</h2><span id='topic+GraphicalAlgo'></span>

<h3>Description</h3>

<p>Runs the algorithm specified in the argument <code>implementation</code> and
returns the estimated adjacency matrix. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GraphicalAlgo(
  xdata,
  pk = NULL,
  Lambda,
  Sequential_template = NULL,
  scale = TRUE,
  implementation = PenalisedGraphical,
  start = "cold",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GraphicalAlgo_+3A_xdata">xdata</code></td>
<td>
<p>matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>Lambda=NULL</code> and <code>implementation=PenalisedGraphical</code>,
<code><a href="#topic+LambdaGridGraphical">LambdaGridGraphical</a></code> is used to define a relevant grid.
<code>Lambda</code> can be provided as a vector or a matrix with
<code>length(pk)</code> columns.</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_sequential_template">Sequential_template</code></td>
<td>
<p>logical matrix encoding the type of procedure to
use for data with multiple blocks in stability selection graphical
modelling. For multi-block estimation, the stability selection model is
constructed as the union of block-specific stable edges estimated while the
others are weakly penalised (<code>TRUE</code> only for the block currently being
calibrated and <code>FALSE</code> for other blocks). Other approaches with joint
calibration of the blocks are allowed (all entries are set to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the correlation (<code>scale=TRUE</code>) or
covariance (<code>scale=FALSE</code>) matrix should be used as input of
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> if
<code>implementation=PenalisedGraphical</code>. Otherwise, this argument must be
used in the function provided in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_implementation">implementation</code></td>
<td>
<p>function to use for graphical modelling. If
<code>implementation=PenalisedGraphical</code>, the algorithm implemented in
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> is used for regularised estimation of
a conditional independence graph. Alternatively, a user-defined function
can be provided.</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_start">start</code></td>
<td>
<p>character string indicating if the algorithm should be
initialised at the estimated (inverse) covariance with previous penalty
parameters (<code>start="warm"</code>) or not (<code>start="cold"</code>). Using
<code>start="warm"</code> can speed-up the computations, but could lead to
convergence issues (in particular with small <code>Lambda_cardinal</code>). Only
used for <code>implementation=PenalisedGraphical</code> (see argument
<code>"start"</code> in <code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code>).</p>
</td></tr>
<tr><td><code id="GraphicalAlgo_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>implementation</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The use of the procedure from Equation (4) or (5) is controlled by
the argument &quot;Sequential_template&quot;.
</p>


<h3>Value</h3>

<p>An array with binary and symmetric adjacency matrices along the third
dimension.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, <code><a href="#topic+PenalisedGraphical">PenalisedGraphical</a></code>
</p>
<p>Other wrapping functions: 
<code><a href="#topic+SelectionAlgo">SelectionAlgo</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul &lt;- SimulateGraphical()

# Running graphical LASSO
myglasso &lt;- GraphicalAlgo(
  xdata = simul$data,
  Lambda = cbind(c(0.1, 0.2))
)
</code></pre>

<hr>
<h2 id='GraphicalModel'>Stability selection graphical model</h2><span id='topic+GraphicalModel'></span>

<h3>Description</h3>

<p>Performs stability selection for graphical models. The underlying graphical
model (e.g. graphical LASSO) is run with different combinations of parameters
controlling the sparsity (e.g. penalty parameter) and thresholds in selection
proportions. These two hyper-parameters are jointly calibrated by
maximisation of the stability score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GraphicalModel(
  xdata,
  pk = NULL,
  Lambda = NULL,
  lambda_other_blocks = 0.1,
  pi_list = seq(0.01, 0.99, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = NULL,
  implementation = PenalisedGraphical,
  start = "warm",
  scale = TRUE,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  Lambda_cardinal = 50,
  lambda_max = NULL,
  lambda_path_factor = 0.001,
  max_density = 0.5,
  optimisation = c("grid_search", "nloptr"),
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  beep = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GraphicalModel_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.
For multi-block stability selection, the variables in data have to be
ordered by group.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>Lambda=NULL</code> and <code>implementation=PenalisedGraphical</code>,
<code><a href="#topic+LambdaGridGraphical">LambdaGridGraphical</a></code> is used to define a relevant grid.
<code>Lambda</code> can be provided as a vector or a matrix with
<code>length(pk)</code> columns.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_lambda_other_blocks">lambda_other_blocks</code></td>
<td>
<p>optional vector of parameters controlling the
level of sparsity in neighbour blocks for the multi-block procedure. To use
jointly a specific set of parameters for each block,
<code>lambda_other_blocks</code> must be set to <code>NULL</code> (not recommended).
Only used for multi-block stability selection, i.e. if <code>length(pk)&gt;1</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_implementation">implementation</code></td>
<td>
<p>function to use for graphical modelling. If
<code>implementation=PenalisedGraphical</code>, the algorithm implemented in
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> is used for regularised estimation of
a conditional independence graph. Alternatively, a user-defined function
can be provided.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_start">start</code></td>
<td>
<p>character string indicating if the algorithm should be
initialised at the estimated (inverse) covariance with previous penalty
parameters (<code>start="warm"</code>) or not (<code>start="cold"</code>). Using
<code>start="warm"</code> can speed-up the computations, but could lead to
convergence issues (in particular with small <code>Lambda_cardinal</code>). Only
used for <code>implementation=PenalisedGraphical</code> (see argument
<code>"start"</code> in <code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code>).</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the correlation (<code>scale=TRUE</code>) or
covariance (<code>scale=FALSE</code>) matrix should be used as input of
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> if
<code>implementation=PenalisedGraphical</code>. Otherwise, this argument must be
used in the function provided in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_cpss">cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm. Only used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_lambda_max">lambda_max</code></td>
<td>
<p>optional maximum value for the grid in penalty parameters.
If <code>lambda_max=NULL</code>, the maximum value is set to the maximum
covariance in absolute value. Only used if
<code>implementation=PenalisedGraphical</code> and <code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_lambda_path_factor">lambda_path_factor</code></td>
<td>
<p>multiplicative factor used to define the minimum
value in the grid.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_max_density">max_density</code></td>
<td>
<p>threshold on the density. The grid is defined such that
the density of the estimated graph does not exceed max_density.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_optimisation">optimisation</code></td>
<td>
<p>character string indicating the type of optimisation
method. With <code>optimisation="grid_search"</code> (the default), all values in
<code>Lambda</code> are visited. Alternatively, optimisation algorithms
implemented in <code><a href="nloptr.html#topic+nloptr">nloptr</a></code> can be used with
<code>optimisation="nloptr"</code>. By default, we use
<code>"algorithm"="NLOPT_GN_DIRECT_L"</code>, <code>"xtol_abs"=0.1</code>,
<code>"ftol_abs"=0.1</code> and <code>"maxeval"=Lambda_cardinal</code>. These values
can be changed by providing the argument <code>opts</code> (see
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code>). For stability selection using penalised
regression, <code>optimisation="grid_search"</code> may be faster as it allows
for warm start.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_n_cores">n_cores</code></td>
<td>
<p>number of cores to use for parallel computing (see argument
<code>workers</code> in <code><a href="future.html#topic+multisession">multisession</a></code>). Using
<code>n_cores&gt;1</code> is only supported with <code>optimisation="grid_search"</code>.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_beep">beep</code></td>
<td>
<p>sound indicating the end of the run. Possible values are:
<code>NULL</code> (no sound) or an integer between 1 and 11 (see argument
<code>sound</code> in <code><a href="beepr.html#topic+beep">beep</a></code>).</p>
</td></tr>
<tr><td><code id="GraphicalModel_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In stability selection, a feature selection algorithm is fitted on
<code>K</code> subsamples (or bootstrap samples) of the data with different
parameters controlling the sparsity (<code>Lambda</code>). For a given (set of)
sparsity parameter(s), the proportion out of the <code>K</code> models in which
each feature is selected is calculated. Features with selection proportions
above a threshold pi are considered stably selected. The stability
selection model is controlled by the sparsity parameter(s) for the
underlying algorithm, and the threshold in selection proportion:
</p>
<p><code class="reqn">V_{\lambda, \pi} = \{ j: p_{\lambda}(j) \ge \pi \} </code>
</p>
<p>These parameters can be calibrated by maximisation of a stability score
(see <code><a href="#topic+ConsensusScore">ConsensusScore</a></code> if <code>n_cat=NULL</code> or
<code><a href="#topic+StabilityScore">StabilityScore</a></code> otherwise) calculated under the null
hypothesis of equiprobability of selection.
</p>
<p>It is strongly recommended to examine the calibration plot carefully to
check that the grids of parameters <code>Lambda</code> and <code>pi_list</code> do not
restrict the calibration to a region that would not include the global
maximum (see <code><a href="#topic+CalibrationPlot">CalibrationPlot</a></code>). In particular, the grid
<code>Lambda</code> may need to be extended when the maximum stability is
observed on the left or right edges of the calibration heatmap. In some
instances, multiple peaks of stability score can be observed. Simulation
studies suggest that the peak corresponding to the largest number of
selected features tend to give better selection performances. This is not
necessarily the highest peak (which is automatically retained by the
functions in this package). The user can decide to manually choose another
peak.
</p>
<p>To control the expected number of False Positives (Per Family Error Rate)
in the results, a threshold <code>PFER_thr</code> can be specified. The
optimisation problem is then constrained to sets of parameters that
generate models with an upper-bound in PFER below <code>PFER_thr</code> (see
Meinshausen and BÃ¼hlmann (2010) and Shah and Samworth (2013)).
</p>
<p>Possible resampling procedures include defining (i) <code>K</code> subsamples of
a proportion <code>tau</code> of the observations, (ii) <code>K</code> bootstrap samples
with the full sample size (obtained with replacement), and (iii) <code>K/2</code>
splits of the data in half for complementary pair stability selection (see
arguments <code>resampling</code> and <code>cpss</code>). In complementary pair
stability selection, a feature is considered selected at a given resampling
iteration if it is selected in the two complementary subsamples.
</p>
<p>To ensure reproducibility of the results, the starting number of the random
number generator is set to <code>seed</code>.
</p>
<p>For parallelisation, stability selection with different sets of parameters
can be run on <code>n_cores</code> cores. Using <code>n_cores &gt; 1</code> creates a
<code><a href="future.html#topic+multisession">multisession</a></code>. Alternatively,
the function can be run manually with different <code>seed</code>s and all other
parameters equal. The results can then be combined using
<code><a href="#topic+Combine">Combine</a></code>.
</p>
<p>The generated network can be converted into
<code><a href="igraph.html#topic+igraph-package">igraph</a></code> object using
<code><a href="#topic+Graph">Graph</a></code>. The R package
<code><a href="visNetwork.html#topic+visDocumentation">visNetwork</a></code> can be used for
interactive network visualisation (see examples in <code><a href="#topic+Graph">Graph</a></code>).
</p>


<h3>Value</h3>

<p>An object of class <code>graphical_model</code>. A list with: </p>
<table>
<tr><td><code>S</code></td>
<td>
<p>a
matrix of the best stability scores for different (sets of) parameters
controlling the level of sparsity in the underlying algorithm.</p>
</td></tr>
<tr><td><code>Lambda</code></td>
<td>
<p>a matrix of parameters controlling the level of sparsity in
the underlying algorithm.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the average number of
selected features by the underlying algorithm with different parameters
controlling the level of sparsity.</p>
</td></tr> <tr><td><code>Q_s</code></td>
<td>
<p>a matrix of the calibrated
number of stably selected features with different parameters controlling
the level of sparsity.</p>
</td></tr> <tr><td><code>P</code></td>
<td>
<p>a matrix of calibrated thresholds in
selection proportions for different parameters controlling the level of
sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>PFER</code></td>
<td>
<p>a matrix of upper-bounds
in PFER of calibrated stability selection models with different parameters
controlling the level of sparsity.</p>
</td></tr> <tr><td><code>FDP</code></td>
<td>
<p>a matrix of upper-bounds in
FDP of calibrated stability selection models with different parameters
controlling the level of sparsity.</p>
</td></tr> <tr><td><code>S_2d</code></td>
<td>
<p>a matrix of stability
scores obtained with different combinations of parameters. Columns
correspond to different thresholds in selection proportions.</p>
</td></tr>
<tr><td><code>PFER_2d</code></td>
<td>
<p>a matrix of upper-bounds in FDP obtained with different
combinations of parameters. Columns correspond to different thresholds in
selection proportions. Only returned if <code>length(pk)=1</code>.</p>
</td></tr>
<tr><td><code>FDP_2d</code></td>
<td>
<p>a matrix of upper-bounds in PFER obtained with different
combinations of parameters. Columns correspond to different thresholds in
selection proportions. Only returned if <code>length(pk)=1</code>.</p>
</td></tr>
<tr><td><code>selprop</code></td>
<td>
<p>an array of selection proportions. Rows and columns
correspond to nodes in the graph. Indices along the third dimension
correspond to different parameters controlling the level of sparsity in the
underlying algorithm.</p>
</td></tr> <tr><td><code>sign</code></td>
<td>
<p>a matrix of signs of Pearson's
correlations estimated from <code>xdata</code>.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list with
<code>type="graphical_model"</code> and values used for arguments
<code>implementation</code>, <code>start</code>, <code>resampling</code>, <code>cpss</code> and
<code>PFER_method</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used for arguments
<code>K</code>, <code>pi_list</code>, <code>tau</code>, <code>n_cat</code>, <code>pk</code>, <code>n</code>
(number of observations in <code>xdata</code>), <code>PFER_thr</code>, <code>FDP_thr</code>,
<code>seed</code>, <code>lambda_other_blocks</code>, and <code>Sequential_template</code>.</p>
</td></tr>
</table>
<p>The rows of <code>S</code>, <code>Lambda</code>, <code>Q</code>, <code>Q_s</code>, <code>P</code>,
<code>PFER</code>, <code>FDP</code>, <code>S_2d</code>, <code>PFER_2d</code> and <code>FDP_2d</code>, and
indices along the third dimension of <code>selprop</code> are ordered in the same
way and correspond to parameter values stored in <code>Lambda</code>. For
multi-block inference, the columns of <code>S</code>, <code>Lambda</code>, <code>Q</code>,
<code>Q_s</code>, <code>P</code>, <code>PFER</code> and <code>FDP</code>, and indices along the
third dimension of <code>S_2d</code> correspond to the different blocks.
</p>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Shah RD, Samworth RJ (2013).
&ldquo;Variable selection with error control: another look at stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Friedman J, Hastie T, Tibshirani R (2008).
&ldquo;Sparse inverse covariance estimation with the graphical lasso.&rdquo;
<em>Biostatistics</em>, <b>9</b>(3), 432&ndash;441.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PenalisedGraphical">PenalisedGraphical</a></code>, <code><a href="#topic+GraphicalAlgo">GraphicalAlgo</a></code>,
<code><a href="#topic+LambdaGridGraphical">LambdaGridGraphical</a></code>, <code><a href="#topic+Resample">Resample</a></code>,
<code><a href="#topic+StabilityScore">StabilityScore</a></code> <code><a href="#topic+Graph">Graph</a></code>, <code><a href="#topic+Adjacency">Adjacency</a></code>,
</p>
<p>Other stability functions: 
<code><a href="#topic+BiSelection">BiSelection</a>()</code>,
<code><a href="#topic+Clustering">Clustering</a>()</code>,
<code><a href="#topic+StructuralModel">StructuralModel</a>()</code>,
<code><a href="#topic+VariableSelection">VariableSelection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldpar &lt;- par(no.readonly = TRUE)
par(mar = rep(7, 4))

## Single-block stability selection

# Data simulation
set.seed(1)
simul &lt;- SimulateGraphical(n = 100, pk = 20, nu_within = 0.1)

# Stability selection
stab &lt;- GraphicalModel(xdata = simul$data)
print(stab)

# Calibration heatmap
CalibrationPlot(stab)

# Visualisation of the results
summary(stab)
plot(stab)

# Extraction of adjacency matrix or igraph object
Adjacency(stab)
Graph(stab)


## Multi-block stability selection

# Data simulation
set.seed(1)
simul &lt;- SimulateGraphical(pk = c(10, 10))

# Stability selection
stab &lt;- GraphicalModel(xdata = simul$data, pk = c(10, 10), Lambda_cardinal = 10)
print(stab)

# Calibration heatmap
# par(mfrow = c(1, 3))
CalibrationPlot(stab) # Producing three plots

# Visualisation of the results
summary(stab)
plot(stab)

# Multi-parameter stability selection (not recommended)
Lambda &lt;- matrix(c(0.8, 0.6, 0.3, 0.5, 0.4, 0.3, 0.7, 0.5, 0.1), ncol = 3)
stab &lt;- GraphicalModel(
  xdata = simul$data, pk = c(10, 10),
  Lambda = Lambda, lambda_other_blocks = NULL
)
stab$Lambda


## Example with user-defined function: shrinkage estimation and selection

# Data simulation
set.seed(1)
simul &lt;- SimulateGraphical(n = 100, pk = 20, nu_within = 0.1)

if (requireNamespace("corpcor", quietly = TRUE)) {
  # Writing user-defined algorithm in a portable function
  ShrinkageSelection &lt;- function(xdata, Lambda, ...) {
    mypcor &lt;- corpcor::pcor.shrink(xdata, verbose = FALSE)
    adjacency &lt;- array(NA, dim = c(nrow(mypcor), ncol(mypcor), nrow(Lambda)))
    for (k in seq_len(nrow(Lambda))) {
      A &lt;- ifelse(abs(mypcor) &gt;= Lambda[k, 1], yes = 1, no = 0)
      diag(A) &lt;- 0
      adjacency[, , k] &lt;- A
    }
    return(list(adjacency = adjacency))
  }

  # Running the algorithm without stability
  myglasso &lt;- GraphicalAlgo(
    xdata = simul$data,
    Lambda = matrix(c(0.05, 0.1), ncol = 1), implementation = ShrinkageSelection
  )

  # Stability selection using shrinkage estimation and selection
  stab &lt;- GraphicalModel(
    xdata = simul$data, Lambda = matrix(c(0.01, 0.05, 0.1), ncol = 1),
    implementation = ShrinkageSelection
  )
  CalibrationPlot(stab)
  stable_adjacency &lt;- Adjacency(stab)
}

par(oldpar)

</code></pre>

<hr>
<h2 id='GroupPLS'>Group Partial Least Squares</h2><span id='topic+GroupPLS'></span>

<h3>Description</h3>

<p>Runs a group Partial Least Squares model using implementation from
<code><a href="sgPLS.html#topic+sgPLS-package">sgPLS-package</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GroupPLS(
  xdata,
  ydata,
  family = "gaussian",
  group_x,
  group_y = NULL,
  Lambda,
  keepX_previous = NULL,
  keepY = NULL,
  ncomp = 1,
  scale = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GroupPLS_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_family">family</code></td>
<td>
<p>type of PLS model. If <code>family="gaussian"</code>, a group PLS
model as defined in <code><a href="sgPLS.html#topic+gPLS">gPLS</a></code> is run (for continuous
outcomes). If <code>family="binomial"</code>, a PLS-DA model as defined in
<code><a href="sgPLS.html#topic+gPLSda">gPLSda</a></code> is run (for categorical outcomes).</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_group_x">group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_group_y">group_y</code></td>
<td>
<p>optional vector encoding the grouping structure among
outcomes. This argument indicates the number of variables in each group.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the number of selected groups
at current component, as defined by <code>ncomp</code>.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_keepx_previous">keepX_previous</code></td>
<td>
<p>number of selected groups in previous components. Only
used if <code>ncomp &gt; 1</code>. The argument <code>keepX</code> in
<code><a href="sgPLS.html#topic+sgPLS">sgPLS</a></code> is obtained by concatenating
<code>keepX_previous</code> and <code>Lambda</code>.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_keepy">keepY</code></td>
<td>
<p>number of selected groups of outcome variables. This argument is
defined as in <code><a href="sgPLS.html#topic+sgPLS">sgPLS</a></code>. Only used if
<code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one). Only
used if <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="GroupPLS_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="sgPLS.html#topic+gPLS">gPLS</a></code> or
<code><a href="sgPLS.html#topic+gPLSda">gPLSda</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors (starting
with &quot;X&quot;) or outcomes (starting with &quot;Y&quot;) variables for different
components (denoted by &quot;PC&quot;).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Liquet B, de Micheaux PL, Hejblum BP, ThiÃ©baut R (2016).
&ldquo;Group and sparse group partial least square approaches applied in genomics context.&rdquo;
<em>Bioinformatics</em>, <b>32</b>(1), 35-42.
ISSN 1367-4803, <a href="https://doi.org/10.1093/bioinformatics/btv535">doi:10.1093/bioinformatics/btv535</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>
</p>
<p>Other penalised dimensionality reduction functions: 
<code><a href="#topic+SparseGroupPLS">SparseGroupPLS</a>()</code>,
<code><a href="#topic+SparsePCA">SparsePCA</a>()</code>,
<code><a href="#topic+SparsePLS">SparsePLS</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("sgPLS", quietly = TRUE)) {
  ## Group PLS
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 50, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # Running gPLS with 1 group and sparsity of 0.5
  mypls &lt;- GroupPLS(
    xdata = x, ydata = y, Lambda = 1, family = "gaussian",
    group_x = c(10, 15, 25),
  )

  # Running gPLS with groups on outcomes
  mypls &lt;- GroupPLS(
    xdata = x, ydata = y, Lambda = 1, family = "gaussian",
    group_x = c(10, 15, 25),
    group_y = c(2, 1), keepY = 1
  )
}
</code></pre>

<hr>
<h2 id='HierarchicalClustering'>(Weighted) hierarchical clustering</h2><span id='topic+HierarchicalClustering'></span>

<h3>Description</h3>

<p>Runs hierarchical clustering using implementation from
<code><a href="stats.html#topic+hclust">hclust</a></code>. If <code>Lambda</code> is provided, clustering is
applied on the weighted distance matrix calculated using the
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> algorithm. Otherwise, distances are calculated
using <code><a href="stats.html#topic+dist">dist</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HierarchicalClustering(
  xdata,
  nc = NULL,
  Lambda = NULL,
  distance = "euclidean",
  linkage = "complete",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HierarchicalClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="HierarchicalClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="HierarchicalClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters (see argument <code>lambda</code> in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>). Unweighted distance matrices are used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="HierarchicalClustering_+3A_distance">distance</code></td>
<td>
<p>character string indicating the type of distance to use. If
<code>Lambda=NULL</code>, possible values include <code>"euclidean"</code>,
<code>"maximum"</code>, <code>"canberra"</code>, <code>"binary"</code>, and
<code>"minkowski"</code> (see argument <code>method</code> in
<code><a href="stats.html#topic+dist">dist</a></code>).  Otherwise, possible values include
<code>"euclidean"</code> (<code>pwr=2</code>) or <code>"absolute"</code> (<code>pwr=1</code>) (see
argument <code>pwr</code> in <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>).</p>
</td></tr>
<tr><td><code id="HierarchicalClustering_+3A_linkage">linkage</code></td>
<td>
<p>character string indicating the type of linkage used in
hierarchical clustering to define the stable clusters. Possible values
include <code>"complete"</code>, <code>"single"</code> and <code>"average"</code> (see
argument <code>"method"</code> in <code><a href="stats.html#topic+hclust">hclust</a></code> for a full list).
Only used if <code>implementation=HierarchicalClustering</code>.</p>
</td></tr>
<tr><td><code id="HierarchicalClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="stats.html#topic+hclust">hclust</a></code>,
<code><a href="stats.html#topic+dist">dist</a></code>, or <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>. Parameters
<code>niter</code> (default to 1) and <code>noit</code> (default to 100) correspond to
the number of iterations in <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> to calculate weights
and may need to be modified. Argument <code>pwr</code> in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> is ignored, please provide <code>distance</code>
instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kampert MM, Meulman JJ, Friedman JH (2017).
&ldquo;rCOSA: A Software Package for Clustering Objects on Subsets of Attributes.&rdquo;
<em>Journal of Classification</em>, <b>34</b>(3), 514&ndash;547.
<a href="https://doi.org/10.1007/s00357-017-9240-z">doi:10.1007/s00357-017-9240-z</a>.
</p>
<p>Friedman JH, Meulman JJ (2004).
&ldquo;Clustering objects on subsets of attributes (with discussion).&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>66</b>(4), 815-849.
<a href="https://doi.org/10.1111/j.1467-9868.2004.02059.x">doi:10.1111/j.1467-9868.2004.02059.x</a>, https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2004.02059.x, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x</a>.
</p>


<h3>See Also</h3>

<p>Other clustering algorithms: 
<code><a href="#topic+DBSCANClustering">DBSCANClustering</a>()</code>,
<code><a href="#topic+GMMClustering">GMMClustering</a>()</code>,
<code><a href="#topic+KMeansClustering">KMeansClustering</a>()</code>,
<code><a href="#topic+PAMClustering">PAMClustering</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateClustering(n = c(10, 10), pk = 50)

# Hierarchical clustering
myhclust &lt;- HierarchicalClustering(
  xdata = simul$data,
  nc = seq_len(20)
)

# Weighted Hierarchical clustering (using COSA)
if (requireNamespace("rCOSA", quietly = TRUE)) {
  myhclust &lt;- HierarchicalClustering(
    xdata = simul$data,
    weighted = TRUE,
    nc = seq_len(20),
    Lambda = c(0.2, 0.5)
  )
}
</code></pre>

<hr>
<h2 id='Incremental'>Incremental prediction performance in regression</h2><span id='topic+Incremental'></span>

<h3>Description</h3>

<p>Computes the prediction performance of regression models where predictors are
sequentially added by order of decreasing selection proportion. This function
can be used to evaluate the marginal contribution of each of the selected
predictors over and above more stable predictors. Performances are evaluated
as in <code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Incremental(
  xdata,
  ydata,
  new_xdata = NULL,
  new_ydata = NULL,
  stability = NULL,
  family = NULL,
  implementation = NULL,
  prediction = NULL,
  resampling = "subsampling",
  n_predictors = NULL,
  K = 100,
  tau = 0.8,
  seed = 1,
  n_thr = NULL,
  time = 1000,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Incremental_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_new_xdata">new_xdata</code></td>
<td>
<p>optional test set (predictor data).</p>
</td></tr>
<tr><td><code id="Incremental_+3A_new_ydata">new_ydata</code></td>
<td>
<p>optional test set (outcome data).</p>
</td></tr>
<tr><td><code id="Incremental_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>. If
<code>stability=NULL</code> (the default), a model including all variables in
<code>xdata</code> as predictors is fitted. Argument <code>family</code> must be
provided in this case.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_family">family</code></td>
<td>
<p>type of regression model. Possible values include
<code>"gaussian"</code> (linear regression), <code>"binomial"</code> (logistic
regression), and <code>"cox"</code> (survival analysis). If provided, this
argument must be consistent with input <code>stability</code>.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_implementation">implementation</code></td>
<td>
<p>optional function to refit the model. If
<code>implementation=NULL</code> and <code>stability</code> is the output of
<code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="stats.html#topic+lm">lm</a></code> (linear
regression), <code><a href="survival.html#topic+coxph">coxph</a></code> (Cox regression),
<code><a href="stats.html#topic+glm">glm</a></code> (logistic regression), or
<code><a href="nnet.html#topic+multinom">multinom</a></code> (multinomial regression) is used.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_prediction">prediction</code></td>
<td>
<p>optional function to compute predicted values from the
model refitted with <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach to create the training set. The default
is <code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations. Alternatively, this argument can be a
function to use for resampling. This function must use arguments named
<code>data</code> and <code>tau</code> and return the IDs of observations to be
included in the resampled dataset.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_n_predictors">n_predictors</code></td>
<td>
<p>number of predictors to consider.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_k">K</code></td>
<td>
<p>number of training-test splits. Only used if <code>new_xdata</code> and
<code>new_ydata</code> are not provided.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_tau">tau</code></td>
<td>
<p>proportion of observations used in the training set. Only used if
<code>new_xdata</code> and <code>new_ydata</code> are not provided.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_seed">seed</code></td>
<td>
<p>value of the seed to ensure reproducibility of the results. Only
used if <code>new_xdata</code> and <code>new_ydata</code> are not provided.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_n_thr">n_thr</code></td>
<td>
<p>number of thresholds to use to construct the ROC curve. If
<code>n_thr=NULL</code>, all predicted probability values are iteratively used as
thresholds. For faster computations on large data, less thresholds can be
used. Only applicable to logistic regression.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_time">time</code></td>
<td>
<p>numeric indicating the time for which the survival probabilities
are computed. Only applicable to Cox regression.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="Incremental_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>resampling</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>incremental</code>.
</p>
<p>For logistic regression, a list with: </p>
<table>
<tr><td><code>FPR</code></td>
<td>
<p>A list with, for each of
the models (sequentially added predictors), the False Positive Rates for
different thresholds (columns) and different data splits (rows).</p>
</td></tr>
<tr><td><code>TPR</code></td>
<td>
<p>A list with, for each of the models (sequentially added
predictors), the True Positive Rates for different thresholds (columns) and
different data splits (rows).</p>
</td></tr> <tr><td><code>AUC</code></td>
<td>
<p>A list with, for each of the
models (sequentially added predictors), a vector of Area Under the Curve
(AUC) values obtained with different data splits.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>Estimated
regression coefficients from visited models.</p>
</td></tr> <tr><td><code>names</code></td>
<td>
<p>Names of the
predictors by order of inclusion.</p>
</td></tr> <tr><td><code>stable</code></td>
<td>
<p>Binary vector indicating
which predictors are stably selected. Only returned if <code>stability</code> is
provided.</p>
</td></tr>
</table>
<p>For Cox regression, a list with: </p>
<table>
<tr><td><code>concordance</code></td>
<td>
<p>A list with, for each
of the models (sequentially added predictors), a vector of concordance
indices obtained with different data splits.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>Estimated
regression coefficients from visited models.</p>
</td></tr> <tr><td><code>names</code></td>
<td>
<p>Names of the
predictors by order of inclusion.</p>
</td></tr> <tr><td><code>stable</code></td>
<td>
<p>Binary vector indicating
which predictors are stably selected. Only returned if <code>stability</code> is
provided.</p>
</td></tr>
</table>
<p>For linear regression, a list with: </p>
<table>
<tr><td><code>Q_squared</code></td>
<td>
<p>A list with, for each
of the models (sequentially added predictors), a vector of Q-squared
obtained with different data splits.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>Estimated regression
coefficients from visited models.</p>
</td></tr> <tr><td><code>names</code></td>
<td>
<p>Names of the predictors by
order of inclusion.</p>
</td></tr> <tr><td><code>stable</code></td>
<td>
<p>Binary vector indicating which
predictors are stably selected. Only returned if <code>stability</code> is
provided.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+Refit">Refit</a></code>
</p>
<p>Other prediction performance functions: 
<code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(
  n = 1000, pk = 20,
  family = "binomial", ev_xy = 0.8
)

# Data split: selection, training and test set
ids &lt;- Split(
  data = simul$ydata,
  family = "binomial",
  tau = c(0.4, 0.3, 0.3)
)
xselect &lt;- simul$xdata[ids[[1]], ]
yselect &lt;- simul$ydata[ids[[1]], ]
xtrain &lt;- simul$xdata[ids[[2]], ]
ytrain &lt;- simul$ydata[ids[[2]], ]
xtest &lt;- simul$xdata[ids[[3]], ]
ytest &lt;- simul$ydata[ids[[3]], ]

# Stability selection
stab &lt;- VariableSelection(
  xdata = xselect,
  ydata = yselect,
  family = "binomial"
)

# Performances in test set of model refitted in training set
incr &lt;- Incremental(
  xdata = xtrain, ydata = ytrain,
  new_xdata = xtest, new_ydata = ytest,
  stability = stab, n_predictors = 10
)
plot(incr)

# Alternative with multiple training/test splits
incr &lt;- Incremental(
  xdata = rbind(xtrain, xtest),
  ydata = c(ytrain, ytest),
  stability = stab, K = 10, n_predictors = 10
)
plot(incr)


</code></pre>

<hr>
<h2 id='KMeansClustering'>(Sparse) K-means clustering</h2><span id='topic+KMeansClustering'></span>

<h3>Description</h3>

<p>Runs k-means clustering using implementation from
<code><a href="stats.html#topic+kmeans">kmeans</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KMeansClustering(xdata, nc = NULL, Lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KMeansClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="KMeansClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="KMeansClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters (see argument <code>wbounds</code> in
<code><a href="sparcl.html#topic+KMeansSparseCluster">KMeansSparseCluster</a></code>).</p>
</td></tr>
<tr><td><code id="KMeansClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="stats.html#topic+kmeans">kmeans</a></code> (if
<code>Lambda</code> is <code>NULL</code>) or <code><a href="sparcl.html#topic+KMeansSparseCluster">KMeansSparseCluster</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten DM, Tibshirani R (2010).
&ldquo;A Framework for Feature Selection in Clustering.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>105</b>(490), 713-726.
<a href="https://doi.org/10.1198/jasa.2010.tm09415">doi:10.1198/jasa.2010.tm09415</a>, PMID: 20811510.
</p>


<h3>See Also</h3>

<p>Other clustering algorithms: 
<code><a href="#topic+DBSCANClustering">DBSCANClustering</a>()</code>,
<code><a href="#topic+GMMClustering">GMMClustering</a>()</code>,
<code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a>()</code>,
<code><a href="#topic+PAMClustering">PAMClustering</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateClustering(n = c(10, 10), pk = 50)

# K means clustering
mykmeans &lt;- KMeansClustering(xdata = simul$data, nc = seq_len(20))

# Sparse K means clustering
if (requireNamespace("sparcl", quietly = TRUE)) {
  mykmeans &lt;- KMeansClustering(
    xdata = simul$data, nc = seq_len(20),
    Lambda = c(2, 5)
  )
}

</code></pre>

<hr>
<h2 id='LambdaGridGraphical'>Grid of penalty parameters (graphical model)</h2><span id='topic+LambdaGridGraphical'></span>

<h3>Description</h3>

<p>Generates a relevant grid of penalty parameter values for penalised graphical
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LambdaGridGraphical(
  xdata,
  pk = NULL,
  lambda_other_blocks = 0.1,
  K = 100,
  tau = 0.5,
  n_cat = 3,
  implementation = PenalisedGraphical,
  start = "cold",
  scale = TRUE,
  resampling = "subsampling",
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  Lambda_cardinal = 50,
  lambda_max = NULL,
  lambda_path_factor = 0.001,
  max_density = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LambdaGridGraphical_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.
For multi-block stability selection, the variables in data have to be
ordered by group.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_lambda_other_blocks">lambda_other_blocks</code></td>
<td>
<p>optional vector of parameters controlling the
level of sparsity in neighbour blocks for the multi-block procedure. To use
jointly a specific set of parameters for each block,
<code>lambda_other_blocks</code> must be set to <code>NULL</code> (not recommended).
Only used for multi-block stability selection, i.e. if <code>length(pk)&gt;1</code>.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_implementation">implementation</code></td>
<td>
<p>function to use for graphical modelling. If
<code>implementation=PenalisedGraphical</code>, the algorithm implemented in
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> is used for regularised estimation of
a conditional independence graph. Alternatively, a user-defined function
can be provided.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_start">start</code></td>
<td>
<p>character string indicating if the algorithm should be
initialised at the estimated (inverse) covariance with previous penalty
parameters (<code>start="warm"</code>) or not (<code>start="cold"</code>). Using
<code>start="warm"</code> can speed-up the computations, but could lead to
convergence issues (in particular with small <code>Lambda_cardinal</code>). Only
used for <code>implementation=PenalisedGraphical</code> (see argument
<code>"start"</code> in <code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code>).</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the correlation (<code>scale=TRUE</code>) or
covariance (<code>scale=FALSE</code>) matrix should be used as input of
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> if
<code>implementation=PenalisedGraphical</code>. Otherwise, this argument must be
used in the function provided in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_lambda_max">lambda_max</code></td>
<td>
<p>optional maximum value for the grid in penalty parameters.
If <code>lambda_max=NULL</code>, the maximum value is set to the maximum
covariance in absolute value. Only used if
<code>implementation=PenalisedGraphical</code>.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_lambda_path_factor">lambda_path_factor</code></td>
<td>
<p>multiplicative factor used to define the minimum
value in the grid.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_max_density">max_density</code></td>
<td>
<p>threshold on the density. The grid is defined such that
the density of the estimated graph does not exceed max_density.</p>
</td></tr>
<tr><td><code id="LambdaGridGraphical_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of lambda values with <code>length(pk)</code> columns and
<code>Lambda_cardinal</code> rows.
</p>


<h3>See Also</h3>

<p>Other lambda grid functions: 
<code><a href="#topic+LambdaGridRegression">LambdaGridRegression</a>()</code>,
<code><a href="#topic+LambdaSequence">LambdaSequence</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Single-block simulation
set.seed(1)
simul &lt;- SimulateGraphical()

# Generating grid of 10 values
Lambda &lt;- LambdaGridGraphical(xdata = simul$data, Lambda_cardinal = 10)

# Ensuring PFER &lt; 5
Lambda &lt;- LambdaGridGraphical(xdata = simul$data, Lambda_cardinal = 10, PFER_thr = 5)

# Multi-block simulation
set.seed(1)
simul &lt;- SimulateGraphical(pk = c(10, 10))

# Multi-block grid
Lambda &lt;- LambdaGridGraphical(xdata = simul$data, pk = c(10, 10), Lambda_cardinal = 10)

# Denser neighbouring blocks
Lambda &lt;- LambdaGridGraphical(
  xdata = simul$data, pk = c(10, 10),
  Lambda_cardinal = 10, lambda_other_blocks = 0
)

# Using different neighbour penalties
Lambda &lt;- LambdaGridGraphical(
  xdata = simul$data, pk = c(10, 10),
  Lambda_cardinal = 10, lambda_other_blocks = c(0.1, 0, 0.1)
)
stab &lt;- GraphicalModel(
  xdata = simul$data, pk = c(10, 10),
  Lambda = Lambda, lambda_other_blocks = c(0.1, 0, 0.1)
)
stab$Lambda

# Visiting from empty to full graphs with max_density=1
Lambda &lt;- LambdaGridGraphical(
  xdata = simul$data, pk = c(10, 10),
  Lambda_cardinal = 10, max_density = 1
)
bigblocks &lt;- BlockMatrix(pk = c(10, 10))
bigblocks_vect &lt;- bigblocks[upper.tri(bigblocks)]
N_blocks &lt;- unname(table(bigblocks_vect))
N_blocks # max number of edges per block
stab &lt;- GraphicalModel(xdata = simul$data, pk = c(10, 10), Lambda = Lambda)
apply(stab$Q, 2, max, na.rm = TRUE) # max average number of edges from underlying algo

</code></pre>

<hr>
<h2 id='LambdaGridRegression'>Grid of penalty parameters (regression model)</h2><span id='topic+LambdaGridRegression'></span>

<h3>Description</h3>

<p>Generates a relevant grid of penalty parameter values for penalised
regression using the implementation in <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LambdaGridRegression(
  xdata,
  ydata,
  tau = 0.5,
  seed = 1,
  family = "gaussian",
  resampling = "subsampling",
  Lambda_cardinal = 100,
  check_input = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LambdaGridRegression_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm.</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_check_input">check_input</code></td>
<td>
<p>logical indicating if input values should be checked
(recommended).</p>
</td></tr>
<tr><td><code id="LambdaGridRegression_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of lambda values with one column and as many rows as
indicated in <code>Lambda_cardinal</code>.
</p>


<h3>See Also</h3>

<p>Other lambda grid functions: 
<code><a href="#topic+LambdaGridGraphical">LambdaGridGraphical</a>()</code>,
<code><a href="#topic+LambdaSequence">LambdaSequence</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian") # simulated data

# Lambda grid for linear regression
Lambda &lt;- LambdaGridRegression(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian", Lambda_cardinal = 20
)

# Grid can be used in VariableSelection()
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian", Lambda = Lambda
)
print(SelectedVariables(stab))
</code></pre>

<hr>
<h2 id='LambdaSequence'>Sequence of penalty parameters</h2><span id='topic+LambdaSequence'></span>

<h3>Description</h3>

<p>Generates a sequence of penalty parameters from extreme values and the
required number of elements. The sequence is defined on the log-scale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LambdaSequence(lmax, lmin, cardinal = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LambdaSequence_+3A_lmax">lmax</code></td>
<td>
<p>maximum value in the grid.</p>
</td></tr>
<tr><td><code id="LambdaSequence_+3A_lmin">lmin</code></td>
<td>
<p>minimum value in the grid.</p>
</td></tr>
<tr><td><code id="LambdaSequence_+3A_cardinal">cardinal</code></td>
<td>
<p>number of values in the grid.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with values between &quot;lmin&quot; and &quot;lmax&quot; and as many values as
indicated by &quot;cardinal&quot;.
</p>


<h3>See Also</h3>

<p>Other lambda grid functions: 
<code><a href="#topic+LambdaGridGraphical">LambdaGridGraphical</a>()</code>,
<code><a href="#topic+LambdaGridRegression">LambdaGridRegression</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Grid from extreme values
mygrid &lt;- LambdaSequence(lmax = 0.7, lmin = 0.001, cardinal = 10)
</code></pre>

<hr>
<h2 id='LinearSystemMatrix'>Matrix from linear system outputs</h2><span id='topic+LinearSystemMatrix'></span>

<h3>Description</h3>

<p>Returns a matrix from output of <code><a href="#topic+PenalisedLinearSystem">PenalisedLinearSystem</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LinearSystemMatrix(vect, adjacency)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LinearSystemMatrix_+3A_vect">vect</code></td>
<td>
<p>vector of coefficients to assign to entries of the matrix.</p>
</td></tr>
<tr><td><code id="LinearSystemMatrix_+3A_adjacency">adjacency</code></td>
<td>
<p>binary adjacency matrix of the Directed Acyclic Graph
(transpose of the asymmetric matrix A in Reticular Action Model notation).
The row and column names of this matrix must be defined.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An asymmetric matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PenalisedLinearSystem">PenalisedLinearSystem</a></code>
</p>

<hr>
<h2 id='mystar'>Star-shaped nodes</h2><span id='topic+mystar'></span>

<h3>Description</h3>

<p>Produces star-shaped nodes in an igraph object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mystar(coords, v = NULL, params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mystar_+3A_coords">coords</code></td>
<td>
<p>a matrix of coordinates
(see <code><a href="igraph.html#topic+add_shape">add_shape</a></code>).</p>
</td></tr>
<tr><td><code id="mystar_+3A_v">v</code></td>
<td>
<p>a vector of node IDs
(see <code><a href="igraph.html#topic+add_shape">add_shape</a></code>).</p>
</td></tr>
<tr><td><code id="mystar_+3A_params">params</code></td>
<td>
<p>node graphical parameters
(see <code><a href="igraph.html#topic+add_shape">add_shape</a></code>).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="igraph.html#topic+add_shape">add_shape</a></code>
</p>

<hr>
<h2 id='mytriangle'>Triangular nodes</h2><span id='topic+mytriangle'></span>

<h3>Description</h3>

<p>Produces triangular nodes in an igraph object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mytriangle(coords, v = NULL, params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mytriangle_+3A_coords">coords</code></td>
<td>
<p>a matrix of coordinates
(see <code><a href="igraph.html#topic+add_shape">add_shape</a></code>).</p>
</td></tr>
<tr><td><code id="mytriangle_+3A_v">v</code></td>
<td>
<p>a vector of node IDs
(see <code><a href="igraph.html#topic+add_shape">add_shape</a></code>).</p>
</td></tr>
<tr><td><code id="mytriangle_+3A_params">params</code></td>
<td>
<p>node graphical parameters
(see <code><a href="igraph.html#topic+add_shape">add_shape</a></code>).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="igraph.html#topic+add_shape">add_shape</a></code>
</p>

<hr>
<h2 id='NAToNULL'>Transforms NA into NULL</h2><span id='topic+NAToNULL'></span>

<h3>Description</h3>

<p>Returns a vector with no missing values or NULL if there are no non-missing
values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NAToNULL(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NAToNULL_+3A_x">x</code></td>
<td>
<p>input vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector without missing values or NULL.
</p>

<hr>
<h2 id='OpenMxMatrix'>Matrix from OpenMx outputs</h2><span id='topic+OpenMxMatrix'></span>

<h3>Description</h3>

<p>Returns a matrix from output of <code><a href="OpenMx.html#topic+mxPenaltySearch">mxPenaltySearch</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OpenMxMatrix(vect, adjacency, residual_covariance = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OpenMxMatrix_+3A_vect">vect</code></td>
<td>
<p>vector of coefficients to assign to entries of the matrix.</p>
</td></tr>
<tr><td><code id="OpenMxMatrix_+3A_adjacency">adjacency</code></td>
<td>
<p>binary adjacency matrix of the Directed Acyclic Graph
(transpose of the asymmetric matrix A in Reticular Action Model notation).
The row and column names of this matrix must be defined.</p>
</td></tr>
<tr><td><code id="OpenMxMatrix_+3A_residual_covariance">residual_covariance</code></td>
<td>
<p>binary and symmetric matrix encoding the nonzero
entries in the residual covariance matrix (symmetric matrix S in Reticular
Action Model notation). By default, this is the identity matrix (no
residual covariance).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An asymmetric matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a></code>, <code><a href="#topic+OpenMxModel">OpenMxModel</a></code>
</p>

<hr>
<h2 id='OpenMxModel'>Writing OpenMx model (matrix specification)</h2><span id='topic+OpenMxModel'></span>

<h3>Description</h3>

<p>Returns matrix specification for use in <code><a href="OpenMx.html#topic+mxModel">mxModel</a></code> from
(i) the adjacency matrix of a Directed Acyclic Graph (asymmetric matrix A in
Reticular Action Model notation), and (ii) a binary matrix encoding nonzero
entries in the residual covariance matrix (symmetric matrix S in Reticular
Action Model notation).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OpenMxModel(adjacency, residual_covariance = NULL, manifest = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OpenMxModel_+3A_adjacency">adjacency</code></td>
<td>
<p>binary adjacency matrix of the Directed Acyclic Graph
(transpose of the asymmetric matrix A in Reticular Action Model notation).
The row and column names of this matrix must be defined.</p>
</td></tr>
<tr><td><code id="OpenMxModel_+3A_residual_covariance">residual_covariance</code></td>
<td>
<p>binary and symmetric matrix encoding the nonzero
entries in the residual covariance matrix (symmetric matrix S in Reticular
Action Model notation). By default, this is the identity matrix (no
residual covariance).</p>
</td></tr>
<tr><td><code id="OpenMxModel_+3A_manifest">manifest</code></td>
<td>
<p>optional vector of manifest variable names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of RAM matrices that can be used in <code><a href="OpenMx.html#topic+mxRun">mxRun</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a></code>, <code><a href="#topic+OpenMxMatrix">OpenMxMatrix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("OpenMx", quietly = TRUE)) {
  # Definition of simulated effects
  pk &lt;- c(3, 2, 3)
  dag &lt;- LayeredDAG(layers = pk)
  theta &lt;- dag
  theta[2, 4] &lt;- 0
  theta[3, 7] &lt;- 0
  theta[4, 7] &lt;- 0

  # Data simulation
  set.seed(1)
  simul &lt;- SimulateStructural(n = 500, v_between = 1, theta = theta, pk = pk)

  # Writing RAM matrices for mxModel
  ram_matrices &lt;- OpenMxModel(adjacency = dag)

  # Running unpenalised model
  unpenalised &lt;- OpenMx::mxRun(OpenMx::mxModel(
    "Model",
    OpenMx::mxData(simul$data, type = "raw"),
    ram_matrices$Amat,
    ram_matrices$Smat,
    ram_matrices$Fmat,
    ram_matrices$Mmat,
    OpenMx::mxExpectationRAM("A", "S", "F", "M", dimnames = colnames(dag)),
    OpenMx::mxFitFunctionML()
  ), silent = TRUE, suppressWarnings = TRUE)
  unpenalised$A$values

  # Incorporating latent variables
  ram_matrices &lt;- OpenMxModel(
    adjacency = dag,
    manifest = paste0("x", seq_len(7))
  )
  ram_matrices$Fmat$values

  # Running unpenalised model
  unpenalised &lt;- OpenMx::mxRun(OpenMx::mxModel(
    "Model",
    OpenMx::mxData(simul$data[, seq_len(7)], type = "raw"),
    ram_matrices$Amat,
    ram_matrices$Smat,
    ram_matrices$Fmat,
    ram_matrices$Mmat,
    OpenMx::mxExpectationRAM("A", "S", "F", "M", dimnames = colnames(dag)),
    OpenMx::mxFitFunctionML()
  ), silent = TRUE, suppressWarnings = TRUE)
  unpenalised$A$values
}
</code></pre>

<hr>
<h2 id='PAMClustering'>(Weighted) Partitioning Around Medoids</h2><span id='topic+PAMClustering'></span>

<h3>Description</h3>

<p>Runs Partitioning Around Medoids (PAM) clustering using implementation from
<code><a href="cluster.html#topic+pam">pam</a></code>. This is also known as the k-medoids algorithm. If
<code>Lambda</code> is provided, clustering is applied on the weighted distance
matrix calculated using the COSA algorithm as implemented in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>. Otherwise, distances are calculated using
<code><a href="stats.html#topic+dist">dist</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PAMClustering(xdata, nc = NULL, Lambda = NULL, distance = "euclidean", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PAMClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="PAMClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="PAMClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters (see argument <code>lambda</code> in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>). Unweighted distance matrices are used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="PAMClustering_+3A_distance">distance</code></td>
<td>
<p>character string indicating the type of distance to use. If
<code>Lambda=NULL</code>, possible values include <code>"euclidean"</code>,
<code>"maximum"</code>, <code>"canberra"</code>, <code>"binary"</code>, and
<code>"minkowski"</code> (see argument <code>method</code> in
<code><a href="stats.html#topic+dist">dist</a></code>).  Otherwise, possible values include
<code>"euclidean"</code> (<code>pwr=2</code>) or <code>"absolute"</code> (<code>pwr=1</code>) (see
argument <code>pwr</code> in <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>).</p>
</td></tr>
<tr><td><code id="PAMClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="cluster.html#topic+pam">pam</a></code>,
<code><a href="stats.html#topic+dist">dist</a></code>, or <code><a href="rCOSA.html#topic+cosa2">cosa2</a></code>. If
<code>weighted=TRUE</code>, parameters <code>niter</code> (default to 1) and
<code>noit</code> (default to 100) correspond to the number of iterations in
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> to calculate weights and may need to be
modified.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Kampert MM, Meulman JJ, Friedman JH (2017).
&ldquo;rCOSA: A Software Package for Clustering Objects on Subsets of Attributes.&rdquo;
<em>Journal of Classification</em>, <b>34</b>(3), 514&ndash;547.
<a href="https://doi.org/10.1007/s00357-017-9240-z">doi:10.1007/s00357-017-9240-z</a>.
</p>
<p>Friedman JH, Meulman JJ (2004).
&ldquo;Clustering objects on subsets of attributes (with discussion).&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>66</b>(4), 815-849.
<a href="https://doi.org/10.1111/j.1467-9868.2004.02059.x">doi:10.1111/j.1467-9868.2004.02059.x</a>, https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2004.02059.x, <a href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x">https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2004.02059.x</a>.
</p>


<h3>See Also</h3>

<p>Other clustering algorithms: 
<code><a href="#topic+DBSCANClustering">DBSCANClustering</a>()</code>,
<code><a href="#topic+GMMClustering">GMMClustering</a>()</code>,
<code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a>()</code>,
<code><a href="#topic+KMeansClustering">KMeansClustering</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("cluster", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateClustering(n = c(10, 10), pk = 50)

  # PAM clustering
  myclust &lt;- PAMClustering(
    xdata = simul$data,
    nc = seq_len(20)
  )

  # Weighted PAM clustering (using COSA)
  if (requireNamespace("rCOSA", quietly = TRUE)) {
    myclust &lt;- PAMClustering(
      xdata = simul$data,
      nc = seq_len(20),
      Lambda = c(0.2, 0.5)
    )
  }
}
</code></pre>

<hr>
<h2 id='PenalisedGraphical'>Graphical LASSO</h2><span id='topic+PenalisedGraphical'></span>

<h3>Description</h3>

<p>Runs the graphical LASSO algorithm for estimation of a Gaussian Graphical
Model (GGM). This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PenalisedGraphical(
  xdata,
  pk = NULL,
  Lambda,
  Sequential_template = NULL,
  scale = TRUE,
  start = "cold",
  output_omega = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PenalisedGraphical_+3A_xdata">xdata</code></td>
<td>
<p>matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity.</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_sequential_template">Sequential_template</code></td>
<td>
<p>logical matrix encoding the type of procedure to
use for data with multiple blocks in stability selection graphical
modelling. For multi-block estimation, the stability selection model is
constructed as the union of block-specific stable edges estimated while the
others are weakly penalised (<code>TRUE</code> only for the block currently being
calibrated and <code>FALSE</code> for other blocks). Other approaches with joint
calibration of the blocks are allowed (all entries are set to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the correlation (<code>scale=TRUE</code>) or
covariance (<code>scale=FALSE</code>) matrix should be used as input of
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> if
<code>implementation=PenalisedGraphical</code>. Otherwise, this argument must be
used in the function provided in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_start">start</code></td>
<td>
<p>character string indicating if the algorithm should be
initialised at the estimated (inverse) covariance with previous penalty
parameters (<code>start="warm"</code>) or not (<code>start="cold"</code>). Using
<code>start="warm"</code> can speed-up the computations, but could lead to
convergence issues (in particular with small <code>Lambda_cardinal</code>). Only
used for <code>implementation=PenalisedGraphical</code> (see argument
<code>"start"</code> in <code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code>).</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_output_omega">output_omega</code></td>
<td>
<p>logical indicating if the estimated precision matrices
should be stored and returned.</p>
</td></tr>
<tr><td><code id="PenalisedGraphical_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>implementation</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The use of the procedure from Equation (4) or (5) is controlled by
the argument &quot;Sequential_template&quot;.
</p>


<h3>Value</h3>

<p>An array with binary and symmetric adjacency matrices along the third
dimension.
</p>


<h3>References</h3>

<p>Friedman J, Hastie T, Tibshirani R (2008).
&ldquo;Sparse inverse covariance estimation with the graphical lasso.&rdquo;
<em>Biostatistics</em>, <b>9</b>(3), 432&ndash;441.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GraphicalModel">GraphicalModel</a></code>
</p>
<p>Other underlying algorithm functions: 
<code><a href="#topic+CART">CART</a>()</code>,
<code><a href="#topic+ClusteringAlgo">ClusteringAlgo</a>()</code>,
<code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a>()</code>,
<code><a href="#topic+PenalisedRegression">PenalisedRegression</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul &lt;- SimulateGraphical()

# Running graphical LASSO
myglasso &lt;- PenalisedGraphical(
  xdata = simul$data,
  Lambda = matrix(c(0.1, 0.2), ncol = 1)
)

# Returning estimated precision matrix
myglasso &lt;- PenalisedGraphical(
  xdata = simul$data,
  Lambda = matrix(c(0.1, 0.2), ncol = 1),
  output_omega = TRUE
)
</code></pre>

<hr>
<h2 id='PenalisedOpenMx'>Penalised Structural Equation Model</h2><span id='topic+PenalisedOpenMx'></span><span id='topic+PenalisedLinearSystem'></span>

<h3>Description</h3>

<p>Runs penalised Structural Equation Modelling using implementations from
<code><a href="OpenMx.html#topic+OpenMx">OpenMx</a></code> functions (for <code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a></code>),
or using series of penalised regressions with <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
(for <code><a href="#topic+PenalisedLinearSystem">PenalisedLinearSystem</a></code>). The function
<code><a href="#topic+PenalisedLinearSystem">PenalisedLinearSystem</a></code> does not accommodate latent variables.
These functions are not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PenalisedOpenMx(
  xdata,
  adjacency,
  penalised = NULL,
  residual_covariance = NULL,
  Lambda,
  ...
)

PenalisedLinearSystem(xdata, adjacency, penalised = NULL, Lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PenalisedOpenMx_+3A_xdata">xdata</code></td>
<td>
<p>matrix with observations as rows and variables as columns.
Column names must be defined and in line with the row and column names of
<code>adjacency</code>.</p>
</td></tr>
<tr><td><code id="PenalisedOpenMx_+3A_adjacency">adjacency</code></td>
<td>
<p>binary adjacency matrix of the Directed Acyclic Graph
(transpose of the asymmetric matrix A in Reticular Action Model notation).
The row and column names of this matrix must be defined.</p>
</td></tr>
<tr><td><code id="PenalisedOpenMx_+3A_penalised">penalised</code></td>
<td>
<p>optional binary matrix indicating which coefficients are
regularised.</p>
</td></tr>
<tr><td><code id="PenalisedOpenMx_+3A_residual_covariance">residual_covariance</code></td>
<td>
<p>binary and symmetric matrix encoding the nonzero
entries in the residual covariance matrix (symmetric matrix S in Reticular
Action Model notation). By default, this is the identity matrix (no
residual covariance).</p>
</td></tr>
<tr><td><code id="PenalisedOpenMx_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity. Only
the minimum, maximum and length are used in <code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a></code>.</p>
</td></tr>
<tr><td><code id="PenalisedOpenMx_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="OpenMx.html#topic+OpenMx">OpenMx</a></code> functions (for
<code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a></code>), or <code><a href="glmnet.html#topic+glmnet">glmnet</a></code> (for
<code><a href="#topic+PenalisedLinearSystem">PenalisedLinearSystem</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different regularisation parameters. Columns correspond to
different parameters to estimated.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>matrix of model
coefficients. Rows correspond to different regularisation parameters.
Columns correspond to different parameters to estimated.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Jacobucci R, Grimm KJ, McArdle JJ (2016).
&ldquo;Regularized structural equation modeling.&rdquo;
<em>Structural equation modeling: a multidisciplinary journal</em>, <b>23</b>(4), 555&ndash;566.
<a href="https://doi.org/10.1080/10705511.2016.1154793">doi:10.1080/10705511.2016.1154793</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SelectionAlgo">SelectionAlgo</a></code>, <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+OpenMxMatrix">OpenMxMatrix</a></code>,
<code><a href="#topic+LinearSystemMatrix">LinearSystemMatrix</a></code>
</p>
<p>Other underlying algorithm functions: 
<code><a href="#topic+CART">CART</a>()</code>,
<code><a href="#topic+ClusteringAlgo">ClusteringAlgo</a>()</code>,
<code><a href="#topic+PenalisedGraphical">PenalisedGraphical</a>()</code>,
<code><a href="#topic+PenalisedRegression">PenalisedRegression</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
pk &lt;- c(3, 2, 3)
dag &lt;- LayeredDAG(layers = pk)
theta &lt;- dag
theta[2, 4] &lt;- 0
set.seed(1)
simul &lt;- SimulateStructural(theta = theta, pk = pk, output_matrices = TRUE)

# Running regularised SEM (OpenMx)
if (requireNamespace("OpenMx", quietly = TRUE)) {
  mysem &lt;- PenalisedOpenMx(
    xdata = simul$data, adjacency = dag,
    Lambda = seq(1, 10, 1)
  )
  OpenMxMatrix(vect = mysem$selected[3, ], adjacency = dag)
}

# Running regularised SEM (glmnet)
mysem &lt;- PenalisedLinearSystem(
  xdata = simul$data, adjacency = dag
)
LinearSystemMatrix(vect = mysem$selected[20, ], adjacency = dag)

</code></pre>

<hr>
<h2 id='PenalisedRegression'>Penalised regression</h2><span id='topic+PenalisedRegression'></span>

<h3>Description</h3>

<p>Runs penalised regression using implementation from
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PenalisedRegression(
  xdata,
  ydata,
  Lambda = NULL,
  family,
  penalisation = c("classic", "randomised", "adaptive"),
  gamma = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PenalisedRegression_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="PenalisedRegression_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="PenalisedRegression_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity.</p>
</td></tr>
<tr><td><code id="PenalisedRegression_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="PenalisedRegression_+3A_penalisation">penalisation</code></td>
<td>
<p>type of penalisation to use. If
<code>penalisation="classic"</code> (the default), penalised regression is done
with the same regularisation parameter, or using <code>penalty.factor</code>, if
specified. If <code>penalisation="randomised"</code>, the regularisation for each
of the variables is uniformly chosen between <code>lambda</code> and
<code>lambda/gamma</code>. If <code>penalisation="adaptive"</code>, the regularisation
for each of the variables is weighted by <code>1/abs(beta)^gamma</code> where
<code>beta</code> is the regression coefficient obtained from unpenalised
regression.</p>
</td></tr>
<tr><td><code id="PenalisedRegression_+3A_gamma">gamma</code></td>
<td>
<p>parameter for randomised or adaptive regularisation. Default is
<code>gamma=0.5</code> for randomised regularisation and <code>gamma=2</code> for
adaptive regularisation. The parameter <code>gamma</code> should be between
<code>0</code> and <code>1</code> for randomised regularisation.</p>
</td></tr>
<tr><td><code id="PenalisedRegression_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors. Indices
along the third dimension correspond to outcome variable(s).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zou H (2006).
&ldquo;The adaptive lasso and its oracle properties.&rdquo;
<em>Journal of the American statistical association</em>, <b>101</b>(476), 1418&ndash;1429.
</p>
<p>Tibshirani R (1996).
&ldquo;Regression Shrinkage and Selection via the Lasso.&rdquo;
<em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <b>58</b>(1), 267&ndash;288.
ISSN 00359246, <a href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SelectionAlgo">SelectionAlgo</a></code>, <code><a href="#topic+VariableSelection">VariableSelection</a></code>
</p>
<p>Other underlying algorithm functions: 
<code><a href="#topic+CART">CART</a>()</code>,
<code><a href="#topic+ClusteringAlgo">ClusteringAlgo</a>()</code>,
<code><a href="#topic+PenalisedGraphical">PenalisedGraphical</a>()</code>,
<code><a href="#topic+PenalisedOpenMx">PenalisedOpenMx</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul &lt;- SimulateRegression(pk = 50)

# Running the LASSO
mylasso &lt;- PenalisedRegression(
  xdata = simul$xdata, ydata = simul$ydata,
  Lambda = c(0.1, 0.2), family = "gaussian"
)

# Using glmnet arguments
mylasso &lt;- PenalisedRegression(
  xdata = simul$xdata, ydata = simul$ydata,
  Lambda = c(0.1), family = "gaussian",
  penalty.factor = c(rep(0, 10), rep(1, 40))
)
mylasso$beta_full
</code></pre>

<hr>
<h2 id='PFER'>Per Family Error Rate</h2><span id='topic+PFER'></span>

<h3>Description</h3>

<p>Computes the Per Family Error Rate upper-bound of a stability selection model
using the methods proposed by Meinshausen and BÃ¼hlmann (2010) or Shah and
Samworth (2013). In stability selection, the PFER corresponds to the expected
number of stably selected features that are not relevant to the outcome (i.e.
False Positives).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PFER(q, pi, N, K, PFER_method = "MB")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PFER_+3A_q">q</code></td>
<td>
<p>average number of features selected by the underlying algorithm.</p>
</td></tr>
<tr><td><code id="PFER_+3A_pi">pi</code></td>
<td>
<p>threshold in selection proportions.</p>
</td></tr>
<tr><td><code id="PFER_+3A_n">N</code></td>
<td>
<p>total number of features.</p>
</td></tr>
<tr><td><code id="PFER_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="PFER_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The estimated upper-bound in PFER.
</p>


<h3>References</h3>

<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Shah RD, Samworth RJ (2013).
&ldquo;Variable selection with error control: another look at stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>


<h3>See Also</h3>

<p>Other stability metric functions: 
<code><a href="#topic+ConsensusScore">ConsensusScore</a>()</code>,
<code><a href="#topic+FDP">FDP</a>()</code>,
<code><a href="#topic+StabilityMetrics">StabilityMetrics</a>()</code>,
<code><a href="#topic+StabilityScore">StabilityScore</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Computing PFER for 10/50 selected features and threshold of 0.8
pfer_mb &lt;- PFER(q = 10, pi = 0.8, N = 50, K = 100, PFER_method = "MB")
pfer_ss &lt;- PFER(q = 10, pi = 0.8, N = 50, K = 100, PFER_method = "SS")
</code></pre>

<hr>
<h2 id='plot.clustering'>Consensus matrix heatmap</h2><span id='topic+plot.clustering'></span>

<h3>Description</h3>

<p>Creates a heatmap of the (calibrated) consensus matrix. See examples in
<code><a href="#topic+Clustering">Clustering</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'clustering'
plot(
  x,
  linkage = "complete",
  argmax_id = NULL,
  theta = NULL,
  theta_star = NULL,
  col = c("ivory", "navajowhite", "tomato", "darkred"),
  lines = TRUE,
  col.lines = c("blue"),
  lwd.lines = 2,
  tick = TRUE,
  axes = TRUE,
  col.axis = NULL,
  cex.axis = 1,
  xlas = 2,
  ylas = 2,
  bty = "n",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.clustering_+3A_x">x</code></td>
<td>
<p>output of <code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_linkage">linkage</code></td>
<td>
<p>character string indicating the type of linkage used in
hierarchical clustering to define the stable clusters. Possible values
include <code>"complete"</code>, <code>"single"</code> and <code>"average"</code> (see
argument <code>"method"</code> in <code><a href="stats.html#topic+hclust">hclust</a></code> for a full list).</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_argmax_id">argmax_id</code></td>
<td>
<p>optional indices of hyper-parameters. If
<code>argmax_id=NULL</code>, the calibrated hyper-parameters are used.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_theta">theta</code></td>
<td>
<p>optional vector of cluster membership. If provided, the ordering
of the items should be the same as in <code><a href="#topic+Clusters">Clusters</a></code>. This argument
is used to re-order the consensus matrix.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_theta_star">theta_star</code></td>
<td>
<p>optional vector of true cluster membership. If provided,
the ordering of the items should be the same as in <code><a href="#topic+Clusters">Clusters</a></code>.
This argument is used to define item colours.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_col">col</code></td>
<td>
<p>vector of colours.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_lines">lines</code></td>
<td>
<p>logical indicating if lines separating the clusters provided in
<code>theta</code> should be displayed.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_col.lines">col.lines</code></td>
<td>
<p>colour of the lines separating the clusters.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_lwd.lines">lwd.lines</code></td>
<td>
<p>width of the lines separating the clusters.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_tick">tick</code></td>
<td>
<p>logical indicating if axis tickmarks should be displayed.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_axes">axes</code></td>
<td>
<p>logical indicating if item labels should be displayed.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_col.axis">col.axis</code></td>
<td>
<p>optional vector of cluster colours.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_cex.axis">cex.axis</code></td>
<td>
<p>font size for axes.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_xlas">xlas</code></td>
<td>
<p>orientation of labels on the x-axis, as <code>las</code> in
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_ylas">ylas</code></td>
<td>
<p>orientation of labels on the y-axis, as <code>las</code> in
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_bty">bty</code></td>
<td>
<p>character string indicating if the box around the plot should be
drawn. Possible values include: <code>"o"</code> (default, the box is drawn), or
<code>"n"</code> (no box).</p>
</td></tr>
<tr><td><code id="plot.clustering_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="fake.html#topic+Heatmap">Heatmap</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A heatmap.
</p>

<hr>
<h2 id='plot.incremental'>Plot of incremental performance</h2><span id='topic+plot.incremental'></span><span id='topic+IncrementalPlot'></span><span id='topic+PlotIncremental'></span>

<h3>Description</h3>

<p>Represents prediction performances upon sequential inclusion of the
predictors in a logistic or Cox regression model as produced by
<code><a href="#topic+Incremental">Incremental</a></code>. The median and <code>quantiles</code> of the performance
metric are reported. See examples in <code><a href="#topic+Incremental">Incremental</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'incremental'
plot(
  x,
  quantiles = c(0.05, 0.95),
  col = c("red", "grey"),
  col.axis = NULL,
  xgrid = FALSE,
  ygrid = FALSE,
  output_data = FALSE,
  ...
)

IncrementalPlot(
  x,
  quantiles = c(0.05, 0.95),
  col = c("red", "grey"),
  col.axis = NULL,
  xgrid = FALSE,
  ygrid = FALSE,
  output_data = FALSE,
  ...
)

PlotIncremental(
  x,
  quantiles = c(0.05, 0.95),
  col = c("red", "grey"),
  col.axis = NULL,
  xgrid = FALSE,
  ygrid = FALSE,
  output_data = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.incremental_+3A_x">x</code></td>
<td>
<p>output of <code><a href="#topic+Incremental">Incremental</a></code>.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_quantiles">quantiles</code></td>
<td>
<p>quantiles defining the lower and upper bounds.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_col">col</code></td>
<td>
<p>vector of colours by stable selection status.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_col.axis">col.axis</code></td>
<td>
<p>optional vector of label colours by stable selection status.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_xgrid">xgrid</code></td>
<td>
<p>logical indicating if a vertical grid should be drawn.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_ygrid">ygrid</code></td>
<td>
<p>logical indicating if a horizontal grid should be drawn.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the median and quantiles should be
returned in a matrix.</p>
</td></tr>
<tr><td><code id="plot.incremental_+3A_...">...</code></td>
<td>
<p>additional plotting arguments (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Incremental">Incremental</a></code>
</p>

<hr>
<h2 id='plot.roc_band'>Receiver Operating Characteristic (ROC) band</h2><span id='topic+plot.roc_band'></span>

<h3>Description</h3>

<p>Plots the True Positive Rate (TPR) as a function of the False Positive Rate
(FPR) for different thresholds in predicted probabilities. If the results
from multiple ROC analyses are provided (e.g. output of
<code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a></code> with large <code>K</code>), the point-wise
median is represented and flanked by a transparent band defined by point-wise
<code>quantiles</code>. See examples in <code><a href="fake.html#topic+ROC">ROC</a></code> and
<code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'roc_band'
plot(
  x,
  col_band = NULL,
  alpha = 0.5,
  quantiles = c(0.05, 0.95),
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.roc_band_+3A_x">x</code></td>
<td>
<p>output of <code><a href="fake.html#topic+ROC">ROC</a></code> or <code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a></code>.</p>
</td></tr>
<tr><td><code id="plot.roc_band_+3A_col_band">col_band</code></td>
<td>
<p>colour of the band defined by point-wise <code>quantiles</code>.</p>
</td></tr>
<tr><td><code id="plot.roc_band_+3A_alpha">alpha</code></td>
<td>
<p>level of opacity for the band.</p>
</td></tr>
<tr><td><code id="plot.roc_band_+3A_quantiles">quantiles</code></td>
<td>
<p>point-wise quantiles of the performances defining the band.</p>
</td></tr>
<tr><td><code id="plot.roc_band_+3A_add">add</code></td>
<td>
<p>logical indicating if the curve should be added to the current
plot.</p>
</td></tr>
<tr><td><code id="plot.roc_band_+3A_...">...</code></td>
<td>
<p>additional plotting arguments (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A base plot.
</p>


<h3>See Also</h3>

<p><code><a href="fake.html#topic+ROC">ROC</a></code>, <code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a></code>
</p>

<hr>
<h2 id='plot.variable_selection'>Plot of selection proportions</h2><span id='topic+plot.variable_selection'></span>

<h3>Description</h3>

<p>Makes a barplot of selection proportions in decreasing order. See examples in
<code><a href="#topic+VariableSelection">VariableSelection</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'variable_selection'
plot(
  x,
  col = c("red", "grey"),
  col.axis = NULL,
  col.thr = "darkred",
  lty.thr = 2,
  n_predictors = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.variable_selection_+3A_x">x</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.</p>
</td></tr>
<tr><td><code id="plot.variable_selection_+3A_col">col</code></td>
<td>
<p>vector of colours by stable selection status.</p>
</td></tr>
<tr><td><code id="plot.variable_selection_+3A_col.axis">col.axis</code></td>
<td>
<p>optional vector of label colours by stable selection status.</p>
</td></tr>
<tr><td><code id="plot.variable_selection_+3A_col.thr">col.thr</code></td>
<td>
<p>threshold colour.</p>
</td></tr>
<tr><td><code id="plot.variable_selection_+3A_lty.thr">lty.thr</code></td>
<td>
<p>threshold line type as <code>lty</code> in
<code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="plot.variable_selection_+3A_n_predictors">n_predictors</code></td>
<td>
<p>number of predictors to display.</p>
</td></tr>
<tr><td><code id="plot.variable_selection_+3A_...">...</code></td>
<td>
<p>additional plotting arguments (see <code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>
</p>

<hr>
<h2 id='PLS'>Partial Least Squares 'a la carte'</h2><span id='topic+PLS'></span>

<h3>Description</h3>

<p>Runs a Partial Least Squares (PLS) model in regression mode using algorithm
implemented in <code><a href="mixOmics.html#topic+pls">pls</a></code>. This function allows for the
construction of components based on different sets of predictor and/or
outcome variables. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLS(
  xdata,
  ydata,
  selectedX = NULL,
  selectedY = NULL,
  family = "gaussian",
  ncomp = NULL,
  scale = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLS_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="PLS_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="PLS_+3A_selectedx">selectedX</code></td>
<td>
<p>binary matrix of size <code>(ncol(xdata) * ncomp)</code>. The
binary entries indicate which predictors (in rows) contribute to the
definition of each component (in columns). If <code>selectedX=NULL</code>, all
predictors are selected for all components.</p>
</td></tr>
<tr><td><code id="PLS_+3A_selectedy">selectedY</code></td>
<td>
<p>binary matrix of size <code>(ncol(ydata) * ncomp)</code>. The
binary entries indicate which outcomes (in rows) contribute to the
definition of each component (in columns). If <code>selectedY=NULL</code>, all
outcomes are selected for all components.</p>
</td></tr>
<tr><td><code id="PLS_+3A_family">family</code></td>
<td>
<p>type of PLS model. Only <code>family="gaussian"</code> is supported.
This corresponds to a PLS model as defined in <code><a href="mixOmics.html#topic+pls">pls</a></code>
(for continuous outcomes).</p>
</td></tr>
<tr><td><code id="PLS_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components.</p>
</td></tr>
<tr><td><code id="PLS_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All matrices are defined as in (Wold et al. 2001). The weight matrix
<code>Wmat</code> is the equivalent of <code>loadings$X</code> in
<code><a href="mixOmics.html#topic+pls">pls</a></code>. The loadings matrix <code>Pmat</code> is the
equivalent of <code>mat.c</code> in <code><a href="mixOmics.html#topic+pls">pls</a></code>. The score
matrices <code>Tmat</code> and <code>Qmat</code> are the equivalent of
<code>variates$X</code> and <code>variates$Y</code> in <code><a href="mixOmics.html#topic+pls">pls</a></code>.
</p>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>Wmat</code></td>
<td>
<p>matrix of X-weights.</p>
</td></tr> <tr><td><code>Wstar</code></td>
<td>
<p>matrix of
transformed X-weights.</p>
</td></tr> <tr><td><code>Pmat</code></td>
<td>
<p>matrix of X-loadings.</p>
</td></tr>
<tr><td><code>Cmat</code></td>
<td>
<p>matrix of Y-weights.</p>
</td></tr> <tr><td><code>Tmat</code></td>
<td>
<p>matrix of X-scores.</p>
</td></tr>
<tr><td><code>Umat</code></td>
<td>
<p>matrix of Y-scores.</p>
</td></tr> <tr><td><code>Qmat</code></td>
<td>
<p>matrix needed for
predictions.</p>
</td></tr> <tr><td><code>Rmat</code></td>
<td>
<p>matrix needed for predictions.</p>
</td></tr>
<tr><td><code>meansX</code></td>
<td>
<p>vector used for centering of predictors, needed for
predictions.</p>
</td></tr> <tr><td><code>sigmaX</code></td>
<td>
<p>vector used for scaling of predictors, needed
for predictions.</p>
</td></tr> <tr><td><code>meansY</code></td>
<td>
<p>vector used for centering of outcomes,
needed for predictions.</p>
</td></tr> <tr><td><code>sigmaY</code></td>
<td>
<p>vector used for scaling of outcomes,
needed for predictions.</p>
</td></tr> <tr><td><code>methods</code></td>
<td>
<p>a list with <code>family</code> and
<code>scale</code> values used for the run.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with
<code>selectedX</code> and <code>selectedY</code> values used for the run.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Wold S, SjÃ¶strÃ¶m M, Eriksson L (2001).
&ldquo;PLS-regression: a basic tool of chemometrics.&rdquo;
<em>Chemometrics and Intelligent Laboratory Systems</em>, <b>58</b>(2), 109-130.
ISSN 0169-7439, <a href="https://doi.org/10.1016/S0169-7439%2801%2900155-1">doi:10.1016/S0169-7439(01)00155-1</a>, PLS Methods.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (requireNamespace("mixOmics", quietly = TRUE)) {
  oldpar &lt;- par(no.readonly = TRUE)

  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 200, pk = 15, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # PLS
  mypls &lt;- PLS(xdata = x, ydata = y, ncomp = 3)

  if (requireNamespace("sgPLS", quietly = TRUE)) {
    # Sparse PLS to identify relevant variables
    stab &lt;- BiSelection(
      xdata = x, ydata = y,
      family = "gaussian", ncomp = 3,
      LambdaX = seq_len(ncol(x) - 1),
      LambdaY = seq_len(ncol(y) - 1),
      implementation = SparsePLS,
      n_cat = 2
    )
    plot(stab)

    # Refitting of PLS model
    mypls &lt;- PLS(
      xdata = x, ydata = y,
      selectedX = stab$selectedX,
      selectedY = stab$selectedY
    )

    # Nonzero entries in weights are the same as in selectedX
    par(mfrow = c(2, 2))
    Heatmap(stab$selectedX,
      legend = FALSE
    )
    title("Selected in X")
    Heatmap(ifelse(mypls$Wmat != 0, yes = 1, no = 0),
      legend = FALSE
    )
    title("Nonzero entries in Wmat")
    Heatmap(stab$selectedY,
      legend = FALSE
    )
    title("Selected in Y")
    Heatmap(ifelse(mypls$Cmat != 0, yes = 1, no = 0),
      legend = FALSE
    )
    title("Nonzero entries in Cmat")
  }

  # Multilevel PLS
  # Generating random design
  z &lt;- rep(seq_len(50), each = 4)

  # Extracting the within-variability
  x_within &lt;- mixOmics::withinVariation(X = x, design = cbind(z))

  # Running PLS on within-variability
  mypls &lt;- PLS(xdata = x_within, ydata = y, ncomp = 3)

  par(oldpar)
}

</code></pre>

<hr>
<h2 id='predict.variable_selection'>Predict method for stability selection</h2><span id='topic+predict.variable_selection'></span>

<h3>Description</h3>

<p>Computes predicted values from the output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'variable_selection'
predict(
  object,
  xdata,
  ydata,
  newdata = NULL,
  method = c("ensemble", "refit"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.variable_selection_+3A_object">object</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.</p>
</td></tr>
<tr><td><code id="predict.variable_selection_+3A_xdata">xdata</code></td>
<td>
<p>predictor data (training set).</p>
</td></tr>
<tr><td><code id="predict.variable_selection_+3A_ydata">ydata</code></td>
<td>
<p>outcome data (training set).</p>
</td></tr>
<tr><td><code id="predict.variable_selection_+3A_newdata">newdata</code></td>
<td>
<p>optional predictor data (test set).</p>
</td></tr>
<tr><td><code id="predict.variable_selection_+3A_method">method</code></td>
<td>
<p>character string indicating if predictions should be obtained
from an <code><a href="#topic+Ensemble">Ensemble</a></code> model (if <code>method="ensemble"</code>) or a
<code><a href="#topic+Refit">Refit</a></code>ted model (if <code>method="refit"</code>).</p>
</td></tr>
<tr><td><code id="predict.variable_selection_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="stats.html#topic+predict">predict</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predicted values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Refit">Refit</a></code>, <code><a href="#topic+Ensemble">Ensemble</a></code>,
<code><a href="#topic+EnsemblePredictions">EnsemblePredictions</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Linear regression

# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 500, pk = 50, family = "gaussian")

# Training/test split
ids &lt;- Split(data = simul$ydata, tau = c(0.8, 0.2))

# Stability selection
stab &lt;- VariableSelection(
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ]
)

# Predictions from post stability selection estimation
yhat &lt;- predict(stab,
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ],
  newdata = simul$xdata[ids[[2]], ],
  method = "refit"
)
cor(simul$ydata[ids[[2]], ], yhat)^2 # Q-squared

# Predictions from ensemble model
yhat &lt;- predict(stab,
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ],
  newdata = simul$xdata[ids[[2]], ],
  method = "ensemble"
)
cor(simul$ydata[ids[[2]], ], yhat)^2 # Q-squared


## Logistic regression

# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 500, pk = 20, family = "binomial", ev_xy = 0.9)

# Training/test split
ids &lt;- Split(data = simul$ydata, family = "binomial", tau = c(0.8, 0.2))

# Stability selection
stab &lt;- VariableSelection(
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ],
  family = "binomial"
)

# Predictions from post stability selection estimation
yhat &lt;- predict(stab,
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ],
  newdata = simul$xdata[ids[[2]], ],
  method = "refit", type = "response"
)
plot(ROC(predicted = yhat, observed = simul$ydata[ids[[2]], ]))

# Predictions from ensemble model
yhat &lt;- predict(stab,
  xdata = simul$xdata[ids[[1]], ],
  ydata = simul$ydata[ids[[1]], ],
  newdata = simul$xdata[ids[[2]], ],
  method = "ensemble", type = "response"
)
plot(ROC(predicted = yhat, observed = simul$ydata[ids[[2]], ]),
  add = TRUE,
  col = "blue"
)

</code></pre>

<hr>
<h2 id='PredictPLS'>Partial Least Squares predictions</h2><span id='topic+PredictPLS'></span>

<h3>Description</h3>

<p>Computes predicted values from a Partial Least Squares (PLS) model in
regression mode applied on <code>xdata</code>. This function is using the algorithm
implemented in <code><a href="mixOmics.html#topic+predict.pls">predict.pls</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PredictPLS(xdata, model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PredictPLS_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="PredictPLS_+3A_model">model</code></td>
<td>
<p>output of <code><a href="#topic+PLS">PLS</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An array of predicted values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PLS">PLS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("mixOmics", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = c(5, 5, 5), family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # PLS
  mypls &lt;- PLS(xdata = x, ydata = y, ncomp = 3)

  # Predicted values
  predicted &lt;- PredictPLS(xdata = x, model = mypls)
}
</code></pre>

<hr>
<h2 id='Refit'>Regression model refitting</h2><span id='topic+Refit'></span><span id='topic+Recalibrate'></span>

<h3>Description</h3>

<p>Refits the regression model with stably selected variables as predictors
(without penalisation). Variables in <code>xdata</code> not evaluated in the
stability selection model will automatically be included as predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Refit(
  xdata,
  ydata,
  stability = NULL,
  family = NULL,
  implementation = NULL,
  Lambda = NULL,
  seed = 1,
  verbose = TRUE,
  ...
)

Recalibrate(
  xdata,
  ydata,
  stability = NULL,
  family = NULL,
  implementation = NULL,
  Lambda = NULL,
  seed = 1,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Refit_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="Refit_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="Refit_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code> or
<code><a href="#topic+BiSelection">BiSelection</a></code>. If <code>stability=NULL</code> (the default), a model
including all variables in <code>xdata</code> as predictors is fitted. Argument
<code>family</code> must be provided in this case.</p>
</td></tr>
<tr><td><code id="Refit_+3A_family">family</code></td>
<td>
<p>type of regression model. Possible values include
<code>"gaussian"</code> (linear regression), <code>"binomial"</code> (logistic
regression), <code>"multinomial"</code> (multinomial regression), and
<code>"cox"</code> (survival analysis). If provided, this argument must be
consistent with input <code>stability</code>.</p>
</td></tr>
<tr><td><code id="Refit_+3A_implementation">implementation</code></td>
<td>
<p>optional function to refit the model. If <code>stability</code> is the output of
<code><a href="#topic+VariableSelection">VariableSelection</a></code>, a regression model is refitted.
If <code>implementation=NULL</code> and <code>Lambda=0</code>, this is done using <code><a href="stats.html#topic+lm">lm</a></code> (for linear
regression), <code><a href="survival.html#topic+coxph">coxph</a></code> (Cox regression),
<code><a href="stats.html#topic+glm">glm</a></code> (logistic regression), or
<code><a href="nnet.html#topic+multinom">multinom</a></code> (multinomial regression).
If <code>Lambda=NULL</code>, a Ridge regression is fitted and calibrated by cross validation using <code><a href="glmnet.html#topic+cv.glmnet">cv.glmnet</a></code>.
The function <code><a href="#topic+PLS">PLS</a></code> is used if <code>stability</code> is the output of <code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="Refit_+3A_lambda">Lambda</code></td>
<td>
<p>optional vector of penalty parameters.</p>
</td></tr>
<tr><td><code id="Refit_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="Refit_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="Refit_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the function provided in
<code>implementation</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output as obtained from: </p>
<table>
<tr><td><code>\link[stats]{lm}</code></td>
<td>
<p>for
linear regression (<code>"gaussian"</code> family).</p>
</td></tr>
<tr><td><code>\link[survival]{coxph}</code></td>
<td>
<p>for Cox regression (<code>"cox"</code>
family).</p>
</td></tr> <tr><td><code>\link[stats]{glm}</code></td>
<td>
<p>for logistic regression
(<code>"binomial"</code> family).</p>
</td></tr> <tr><td><code>\link[nnet]{multinom}</code></td>
<td>
<p>for
multinomial regression (<code>"multinomial"</code> family).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Linear regression

# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")

# Data split
ids_train &lt;- Resample(
  data = simul$ydata,
  tau = 0.5, family = "gaussian"
)
xtrain &lt;- simul$xdata[ids_train, , drop = FALSE]
ytrain &lt;- simul$ydata[ids_train, , drop = FALSE]
xrefit &lt;- simul$xdata[-ids_train, , drop = FALSE]
yrefit &lt;- simul$ydata[-ids_train, , drop = FALSE]

# Stability selection
stab &lt;- VariableSelection(xdata = xtrain, ydata = ytrain, family = "gaussian")
print(SelectedVariables(stab))

# Refitting the model
refitted &lt;- Refit(
  xdata = xrefit, ydata = yrefit,
  stability = stab
)
refitted$coefficients # refitted coefficients
head(refitted$fitted.values) # refitted predicted values

# Fitting the full model (including all possible predictors)
refitted &lt;- Refit(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian"
)
refitted$coefficients # refitted coefficients


## Logistic regression

# Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 200, pk = 20, family = "binomial")

# Data split
ids_train &lt;- Resample(
  data = simul$ydata,
  tau = 0.5, family = "binomial"
)
xtrain &lt;- simul$xdata[ids_train, , drop = FALSE]
ytrain &lt;- simul$ydata[ids_train, , drop = FALSE]
xrefit &lt;- simul$xdata[-ids_train, , drop = FALSE]
yrefit &lt;- simul$ydata[-ids_train, , drop = FALSE]

# Stability selection
stab &lt;- VariableSelection(xdata = xtrain, ydata = ytrain, family = "binomial")

# Refitting the model
refitted &lt;- Refit(
  xdata = xrefit, ydata = yrefit,
  stability = stab
)
refitted$coefficients # refitted coefficients
head(refitted$fitted.values) # refitted predicted probabilities

## Partial Least Squares (multiple components)
if (requireNamespace("sgPLS", quietly = TRUE)) {
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 500, pk = 15, q = 3, family = "gaussian")

  # Data split
  ids_train &lt;- Resample(
    data = simul$ydata,
    tau = 0.5, family = "gaussian"
  )
  xtrain &lt;- simul$xdata[ids_train, , drop = FALSE]
  ytrain &lt;- simul$ydata[ids_train, , drop = FALSE]
  xrefit &lt;- simul$xdata[-ids_train, , drop = FALSE]
  yrefit &lt;- simul$ydata[-ids_train, , drop = FALSE]

  # Stability selection
  stab &lt;- BiSelection(
    xdata = xtrain, ydata = ytrain,
    family = "gaussian", ncomp = 3,
    LambdaX = seq_len(ncol(xtrain) - 1),
    LambdaY = seq_len(ncol(ytrain) - 1),
    implementation = SparsePLS
  )
  plot(stab)

  # Refitting the model
  refitted &lt;- Refit(
    xdata = xrefit, ydata = yrefit,
    stability = stab
  )
  refitted$Wmat # refitted X-weights
  refitted$Cmat # refitted Y-weights
}


</code></pre>

<hr>
<h2 id='Resample'>Resampling observations</h2><span id='topic+Resample'></span>

<h3>Description</h3>

<p>Generates a vector of resampled observation IDs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Resample(data, family = NULL, tau = 0.5, resampling = "subsampling", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Resample_+3A_data">data</code></td>
<td>
<p>vector or matrix of data. In regression, this should be the
outcome data.</p>
</td></tr>
<tr><td><code id="Resample_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="Resample_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="Resample_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="Resample_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With categorical outcomes (i.e. &quot;family&quot; argument is set to
&quot;binomial&quot;, &quot;multinomial&quot; or &quot;cox&quot;), the resampling is done such that the
proportion of observations from each of the categories is representative of
that of the full sample.
</p>


<h3>Value</h3>

<p>A vector of resampled IDs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Linear regression framework
# Data simulation
simul &lt;- SimulateRegression()

# Subsampling
ids &lt;- Resample(data = simul$ydata, family = "gaussian")
sum(duplicated(ids))

# Bootstrapping
ids &lt;- Resample(data = simul$ydata, family = "gaussian", resampling = "bootstrap")
sum(duplicated(ids))

## Logistic regression framework
# Data simulation
simul &lt;- SimulateRegression(family = "binomial")

# Subsampling
ids &lt;- Resample(data = simul$ydata, family = "binomial")
sum(duplicated(ids))
prop.table(table(simul$ydata))
prop.table(table(simul$ydata[ids]))

# Data simulation for a binary confounder
conf &lt;- ifelse(runif(n = 100) &gt; 0.5, yes = 1, no = 0)

# User-defined resampling function
BalancedResampling &lt;- function(data, tau, Z, ...) {
  s &lt;- NULL
  for (z in unique(Z)) {
    s &lt;- c(s, sample(which((data == "0") &amp; (Z == z)), size = tau * sum((data == "0") &amp; (Z == z))))
    s &lt;- c(s, sample(which((data == "1") &amp; (Z == z)), size = tau * sum((data == "1") &amp; (Z == z))))
  }
  return(s)
}

# Resampling keeping proportions by Y and Z
ids &lt;- Resample(data = simul$ydata, family = "binomial", resampling = BalancedResampling, Z = conf)
prop.table(table(simul$ydata, conf))
prop.table(table(simul$ydata[ids], conf[ids]))

# User-defined resampling for stability selection
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata, family = "binomial",
  resampling = BalancedResampling, Z = conf
)
</code></pre>

<hr>
<h2 id='SelectionAlgo'>Variable selection algorithm</h2><span id='topic+SelectionAlgo'></span>

<h3>Description</h3>

<p>Runs the variable selection algorithm specified in the argument
<code>implementation</code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionAlgo(
  xdata,
  ydata = NULL,
  Lambda,
  group_x = NULL,
  scale = TRUE,
  family = NULL,
  implementation = PenalisedRegression,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionAlgo_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>Lambda=NULL</code> and <code>implementation=PenalisedRegression</code>,
<code><a href="#topic+LambdaGridRegression">LambdaGridRegression</a></code> is used to define a relevant grid.</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_group_x">group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used for
models with group penalisation (e.g. <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>).</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the predictor data should be scaled.</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_implementation">implementation</code></td>
<td>
<p>function to use for variable selection. Possible
functions are: <code>PenalisedRegression</code>, <code>SparsePLS</code>,
<code>GroupPLS</code> and <code>SparseGroupPLS</code>. Alternatively, a user-defined
function can be provided.</p>
</td></tr>
<tr><td><code id="SelectionAlgo_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the function provided in
<code>implementation</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors. Indices
along the third dimension correspond to outcome variable(s).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+PenalisedRegression">PenalisedRegression</a></code>,
<code><a href="#topic+SparsePCA">SparsePCA</a></code>, <code><a href="#topic+SparsePLS">SparsePLS</a></code>, <code><a href="#topic+GroupPLS">GroupPLS</a></code>,
<code><a href="#topic+SparseGroupPLS">SparseGroupPLS</a></code>
</p>
<p>Other wrapping functions: 
<code><a href="#topic+GraphicalAlgo">GraphicalAlgo</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation (univariate outcome)
set.seed(1)
simul &lt;- SimulateRegression(pk = 50)

# Running the LASSO
mylasso &lt;- SelectionAlgo(
  xdata = simul$xdata, ydata = simul$ydata,
  Lambda = c(0.1, 0.2), family = "gaussian",
)

# Data simulation (multivariate outcome)
set.seed(1)
simul &lt;- SimulateRegression(pk = 50, q = 3)

# Running multivariate Gaussian LASSO
mylasso &lt;- SelectionAlgo(
  xdata = simul$xdata, ydata = simul$ydata,
  Lambda = c(0.1, 0.2), family = "mgaussian"
)
str(mylasso)
</code></pre>

<hr>
<h2 id='SelectionPerformance'>Selection performance</h2><span id='topic+SelectionPerformance'></span>

<h3>Description</h3>

<p>Computes different metrics of selection performance by comparing the set of
selected features to the set of true predictors/edges. This function can only
be used in simulation studies (i.e. when the true model is known).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionPerformance(theta, theta_star, pk = NULL, cor = NULL, thr = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionPerformance_+3A_theta">theta</code></td>
<td>
<p>output from <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+BiSelection">BiSelection</a></code>, or <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>. Alternatively,
it can be a binary matrix of selected variables (in variable selection) or
a binary adjacency matrix (in graphical modelling)</p>
</td></tr>
<tr><td><code id="SelectionPerformance_+3A_theta_star">theta_star</code></td>
<td>
<p>output from <code><a href="fake.html#topic+SimulateRegression">SimulateRegression</a></code>,
<code><a href="fake.html#topic+SimulateComponents">SimulateComponents</a></code>, or <code><a href="fake.html#topic+SimulateGraphical">SimulateGraphical</a></code>.
Alternatively, it can be a binary matrix of true predictors (in variable
selection) or the true binary adjacency matrix (in graphical modelling).</p>
</td></tr>
<tr><td><code id="SelectionPerformance_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="SelectionPerformance_+3A_cor">cor</code></td>
<td>
<p>optional correlation matrix. Only used in graphical modelling.</p>
</td></tr>
<tr><td><code id="SelectionPerformance_+3A_thr">thr</code></td>
<td>
<p>optional threshold in correlation. Only used in graphical
modelling and when argument &quot;cor&quot; is not NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of selection metrics including:
</p>
<table>
<tr><td><code>TP</code></td>
<td>
<p>number of True Positives (TP)</p>
</td></tr> <tr><td><code>FN</code></td>
<td>
<p>number of False
Negatives (TN)</p>
</td></tr> <tr><td><code>FP</code></td>
<td>
<p>number of False Positives (FP)</p>
</td></tr> <tr><td><code>TN</code></td>
<td>
<p>number
of True Negatives (TN)</p>
</td></tr> <tr><td><code>sensitivity</code></td>
<td>
<p>sensitivity, i.e. TP/(TP+FN)</p>
</td></tr>
<tr><td><code>specificity</code></td>
<td>
<p>specificity, i.e. TN/(TN+FP)</p>
</td></tr> <tr><td><code>accuracy</code></td>
<td>
<p>accuracy,
i.e. (TP+TN)/(TP+TN+FP+FN)</p>
</td></tr> <tr><td><code>precision</code></td>
<td>
<p>precision (p), i.e.
TP/(TP+FP)</p>
</td></tr> <tr><td><code>recall</code></td>
<td>
<p>recall (r), i.e. TP/(TP+FN)</p>
</td></tr>
<tr><td><code>F1_score</code></td>
<td>
<p>F1-score, i.e. 2*p*r/(p+r)</p>
</td></tr>
</table>
<p>If argument &quot;cor&quot; is provided, the number of False Positives among
correlated (FP_c) and uncorrelated (FP_i) pairs, defined as having
correlations (provided in &quot;cor&quot;) above or below the threshold &quot;thr&quot;, are
also reported.
</p>
<p>Block-specific performances are reported if &quot;pk&quot; is not NULL. In this case,
the first row of the matrix corresponds to the overall performances, and
subsequent rows correspond to each of the blocks. The order of the blocks
is defined as in <code><a href="fake.html#topic+BlockStructure">BlockStructure</a></code>.
</p>


<h3>See Also</h3>

<p>Other functions for model performance: 
<code><a href="#topic+ClusteringPerformance">ClusteringPerformance</a>()</code>,
<code><a href="#topic+SelectionPerformanceGraph">SelectionPerformanceGraph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Variable selection model
set.seed(1)
simul &lt;- SimulateRegression(pk = 30, nu_xy = 0.5)
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata)

# Selection performance
SelectionPerformance(theta = stab, theta_star = simul)

# Alternative formulation
SelectionPerformance(
  theta = SelectedVariables(stab),
  theta_star = simul$theta
)


</code></pre>

<hr>
<h2 id='SelectionPerformanceGraph'>Graph representation of selection performance</h2><span id='topic+SelectionPerformanceGraph'></span>

<h3>Description</h3>

<p>Generates an igraph object representing the True Positive, False Positive and
False Negative edges by comparing the set of selected edges to the set of
true edges. This function can only be used in simulation studies (i.e. when
the true model is known).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionPerformanceGraph(
  theta,
  theta_star,
  col = c("tomato", "forestgreen", "navy"),
  lty = c(2, 3, 1),
  node_colour = NULL,
  show_labels = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionPerformanceGraph_+3A_theta">theta</code></td>
<td>
<p>binary adjacency matrix or output of
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, <code><a href="#topic+VariableSelection">VariableSelection</a></code>, or
<code><a href="#topic+BiSelection">BiSelection</a></code>.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceGraph_+3A_theta_star">theta_star</code></td>
<td>
<p>true binary adjacency matrix or output of
<code><a href="fake.html#topic+SimulateGraphical">SimulateGraphical</a></code> or <code><a href="fake.html#topic+SimulateRegression">SimulateRegression</a></code>.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceGraph_+3A_col">col</code></td>
<td>
<p>vector of edge colours. The first entry of the vector defines
the colour of False Positive edges, second entry is for True Negatives and
third entry is for True Positives.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceGraph_+3A_lty">lty</code></td>
<td>
<p>vector of line types for edges. The order is defined as for
argument <code>col</code>.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceGraph_+3A_node_colour">node_colour</code></td>
<td>
<p>optional vector of node colours. This vector must contain
as many entries as there are rows/columns in the adjacency matrix and must
be in the same order (the order is used to assign colours to nodes).
Integers, named colours or RGB values can be used.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceGraph_+3A_show_labels">show_labels</code></td>
<td>
<p>logical indicating if the node labels should be displayed.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceGraph_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+Graph">Graph</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An igraph object.
</p>


<h3>See Also</h3>

<p><code><a href="fake.html#topic+SimulateGraphical">SimulateGraphical</a></code>, <code><a href="fake.html#topic+SimulateRegression">SimulateRegression</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+BiSelection">BiSelection</a></code>
</p>
<p>Other functions for model performance: 
<code><a href="#topic+ClusteringPerformance">ClusteringPerformance</a>()</code>,
<code><a href="#topic+SelectionPerformance">SelectionPerformance</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
simul &lt;- SimulateGraphical(pk = 30)

# Stability selection
stab &lt;- GraphicalModel(xdata = simul$data, K = 10)

# Performance graph
perfgraph &lt;- SelectionPerformanceGraph(
  theta = stab,
  theta_star = simul
)
plot(perfgraph)


</code></pre>

<hr>
<h2 id='SelectionPerformanceSingle'>Selection performance (internal)</h2><span id='topic+SelectionPerformanceSingle'></span>

<h3>Description</h3>

<p>Computes different metrics of selection performance from a categorical
vector/matrix with 3 for True Positive, 2 for False Negative, 1 for False
Positive and 0 for True Negative.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionPerformanceSingle(Asum, cor = NULL, thr = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionPerformanceSingle_+3A_asum">Asum</code></td>
<td>
<p>vector (in variable selection) or matrix (in graphical modelling)
containing values of <code>0</code>, <code>1</code>, <code>2</code> or <code>3</code>.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceSingle_+3A_cor">cor</code></td>
<td>
<p>optional correlation matrix. Only used in graphical modelling.</p>
</td></tr>
<tr><td><code id="SelectionPerformanceSingle_+3A_thr">thr</code></td>
<td>
<p>optional threshold in correlation. Only used in graphical
modelling and when argument &quot;cor&quot; is not NULL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of selection metrics including:
</p>
<table>
<tr><td><code>TP</code></td>
<td>
<p>number of True Positives (TP)</p>
</td></tr> <tr><td><code>FN</code></td>
<td>
<p>number of False
Negatives (TN)</p>
</td></tr> <tr><td><code>FP</code></td>
<td>
<p>number of False Positives (FP)</p>
</td></tr> <tr><td><code>TN</code></td>
<td>
<p>number
of True Negatives (TN)</p>
</td></tr> <tr><td><code>sensitivity</code></td>
<td>
<p>sensitivity, i.e. TP/(TP+FN)</p>
</td></tr>
<tr><td><code>specificity</code></td>
<td>
<p>specificity, i.e. TN/(TN+FP)</p>
</td></tr> <tr><td><code>accuracy</code></td>
<td>
<p>accuracy,
i.e. (TP+TN)/(TP+TN+FP+FN)</p>
</td></tr> <tr><td><code>precision</code></td>
<td>
<p>precision (p), i.e.
TP/(TP+FP)</p>
</td></tr> <tr><td><code>recall</code></td>
<td>
<p>recall (r), i.e. TP/(TP+FN)</p>
</td></tr>
<tr><td><code>F1_score</code></td>
<td>
<p>F1-score, i.e. 2*p*r/(p+r)</p>
</td></tr>
</table>
<p>If argument &quot;cor&quot; is provided, the number of False Positives among
correlated (FP_c) and uncorrelated (FP_i) pairs, defined as having
correlations (provided in &quot;cor&quot;) above or below the threshold &quot;thr&quot;, are
also reported.
</p>

<hr>
<h2 id='SelectionProportions'>Selection/co-membership proportions</h2><span id='topic+SelectionProportions'></span><span id='topic+ConsensusMatrix'></span>

<h3>Description</h3>

<p>Extracts selection proportions (for stability selection) or co-membership
proportions (for consensus clustering).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionProportions(stability, argmax_id = NULL)

ConsensusMatrix(stability, argmax_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionProportions_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>, or
<code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="SelectionProportions_+3A_argmax_id">argmax_id</code></td>
<td>
<p>optional indices of hyper-parameters. If
<code>argmax_id=NULL</code>, the calibrated hyper-parameters are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector or matrix of proportions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>,
<code><a href="#topic+BiSelection">BiSelection</a></code>, <code><a href="#topic+Clustering">Clustering</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Stability selection
set.seed(1)
simul &lt;- SimulateRegression(pk = 50)
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata)
SelectionProportions(stab)

# Consensus clustering
set.seed(1)
simul &lt;- SimulateClustering(
  n = c(30, 30, 30), nu_xc = 1, ev_xc = 0.5
)
stab &lt;- Clustering(xdata = simul$data)
ConsensusMatrix(stab)


</code></pre>

<hr>
<h2 id='SelectionProportionsGraphical'>Selection proportions (graphical model)</h2><span id='topic+SelectionProportionsGraphical'></span>

<h3>Description</h3>

<p>Extracts the selection proportions of the (calibrated) stability selection
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionProportionsGraphical(stability, argmax_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionProportionsGraphical_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+GraphicalModel">GraphicalModel</a></code>.</p>
</td></tr>
<tr><td><code id="SelectionProportionsGraphical_+3A_argmax_id">argmax_id</code></td>
<td>
<p>optional indices of hyper-parameters. If
<code>argmax_id=NULL</code>, the calibrated hyper-parameters are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A symmetric matrix.
</p>

<hr>
<h2 id='SelectionProportionsRegression'>Selection proportions (variable selection)</h2><span id='topic+SelectionProportionsRegression'></span>

<h3>Description</h3>

<p>Extracts the selection proportions of the (calibrated) stability selection
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SelectionProportionsRegression(stability, argmax_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SelectionProportionsRegression_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>.</p>
</td></tr>
<tr><td><code id="SelectionProportionsRegression_+3A_argmax_id">argmax_id</code></td>
<td>
<p>optional indices of hyper-parameters. If
<code>argmax_id=NULL</code>, the calibrated hyper-parameters are used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of selection proportions.
</p>

<hr>
<h2 id='SerialClustering'>Consensus clustering (internal)</h2><span id='topic+SerialClustering'></span>

<h3>Description</h3>

<p>Performs consensus (weighted) clustering. The underlying algorithm (e.g.
hierarchical clustering) is run with different number of clusters <code>nc</code>.
In consensus weighed clustering, weighted distances are calculated using the
<code><a href="rCOSA.html#topic+cosa2">cosa2</a></code> algorithm with different penalty parameters
<code>Lambda</code>. The hyper-parameters are calibrated by maximisation of the
consensus score. This function uses a serial implementation and requires the grids of
hyper-parameters as input (for internal use only).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SerialClustering(
  xdata,
  nc,
  eps,
  Lambda,
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  implementation = HierarchicalClustering,
  scale = TRUE,
  linkage = "complete",
  row = TRUE,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SerialClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_eps">eps</code></td>
<td>
<p>radius in density-based clustering, see
<code><a href="dbscan.html#topic+dbscan">dbscan</a></code>. Only used if
<code>implementation=DBSCANClustering</code>.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters for weighted distance calculation.
Only used for distance-based clustering, including for example
<code>implementation=HierarchicalClustering</code>,
<code>implementation=PAMClustering</code>, or
<code>implementation=DBSCANClustering</code>.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_tau">tau</code></td>
<td>
<p>subsample size.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_implementation">implementation</code></td>
<td>
<p>function to use for clustering. Possible functions
include <code><a href="#topic+HierarchicalClustering">HierarchicalClustering</a></code> (hierarchical clustering),
<code><a href="#topic+PAMClustering">PAMClustering</a></code> (Partitioning Around Medoids),
<code><a href="#topic+KMeansClustering">KMeansClustering</a></code> (k-means) and <code><a href="#topic+GMMClustering">GMMClustering</a></code>
(Gaussian Mixture Models). Alternatively, a user-defined function taking
<code>xdata</code> and <code>Lambda</code> as arguments and returning a binary and
symmetric matrix for which diagonal elements are equal to zero can be used.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled to ensure that
all variables contribute equally to the clustering of the observations.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_linkage">linkage</code></td>
<td>
<p>character string indicating the type of linkage used in
hierarchical clustering to define the stable clusters. Possible values
include <code>"complete"</code>, <code>"single"</code> and <code>"average"</code> (see
argument <code>"method"</code> in <code><a href="stats.html#topic+hclust">hclust</a></code> for a full list).
Only used if <code>implementation=HierarchicalClustering</code>.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_row">row</code></td>
<td>
<p>logical indicating if rows (if <code>row=TRUE</code>) or columns (if
<code>row=FALSE</code>) contain the items to cluster.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="SerialClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>Sc</code></td>
<td>
<p>a matrix
of the best stability scores for different (sets of) parameters controlling
the number of clusters and penalisation of attribute weights.</p>
</td></tr> <tr><td><code>nc</code></td>
<td>
<p>a
matrix of numbers of clusters.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix of regularisation
parameters for attribute weights.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the average number
of selected attributes by the underlying algorithm with different
regularisation parameters.</p>
</td></tr> <tr><td><code>coprop</code></td>
<td>
<p>an array of consensus matrices.
Rows and columns correspond to items. Indices along the third dimension
correspond to different parameters controlling the number of clusters and
penalisation of attribute weights.</p>
</td></tr> <tr><td><code>selprop</code></td>
<td>
<p>an array of selection
proportions. Columns correspond to attributes. Rows correspond to different
parameters controlling the number of clusters and penalisation of attribute
weights.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list with <code>type="clustering"</code> and values
used for arguments <code>implementation</code>, <code>linkage</code>, and
<code>resampling</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used for arguments
<code>K</code>, <code>tau</code>, <code>pk</code>, <code>n</code> (number of observations in
<code>xdata</code>), and <code>seed</code>.</p>
</td></tr></table>
<p> The rows of <code>Sc</code>, <code>nc</code>,
<code>Lambda</code>, <code>Q</code>, <code>selprop</code> and indices along the third
dimension of <code>coprop</code> are ordered in the same way and correspond to
parameter values stored in <code>nc</code> and <code>Lambda</code>.
</p>

<hr>
<h2 id='SerialGraphical'>Stability selection graphical model (internal)</h2><span id='topic+SerialGraphical'></span>

<h3>Description</h3>

<p>Runs stability selection graphical models with different combinations of
parameters controlling the sparsity of the underlying selection algorithm
(e.g. penalty parameter for regularised models) and thresholds in selection
proportions. These two parameters are jointly calibrated by maximising the
stability score of the model (possibly under a constraint on the expected
number of falsely stably selected features). This function uses a serial
implementation and requires the grid of parameters controlling the underlying
algorithm as input (for internal use only).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SerialGraphical(
  xdata,
  pk = NULL,
  Lambda,
  lambda_other_blocks = 0.1,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = n_cat,
  implementation = PenalisedGraphical,
  start = "cold",
  scale = TRUE,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SerialGraphical_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.
For multi-block stability selection, the variables in data have to be
ordered by group.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>implementation="glassoFast"</code>, <code>Lambda</code> contains penalty
parameters.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_lambda_other_blocks">lambda_other_blocks</code></td>
<td>
<p>optional vector of parameters controlling the
level of sparsity in neighbour blocks for the multi-block procedure. To use
jointly a specific set of parameters for each block,
<code>lambda_other_blocks</code> must be set to <code>NULL</code> (not recommended).
Only used for multi-block stability selection, i.e. if <code>length(pk)&gt;1</code>.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_implementation">implementation</code></td>
<td>
<p>function to use for graphical modelling. If
<code>implementation=PenalisedGraphical</code>, the algorithm implemented in
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> is used for regularised estimation of
a conditional independence graph. Alternatively, a user-defined function
can be provided.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_start">start</code></td>
<td>
<p>character string indicating if the algorithm should be
initialised at the estimated (inverse) covariance with previous penalty
parameters (<code>start="warm"</code>) or not (<code>start="cold"</code>). Using
<code>start="warm"</code> can speed-up the computations, but could lead to
convergence issues (in particular with small <code>Lambda_cardinal</code>). Only
used for <code>implementation=PenalisedGraphical</code> (see argument
<code>"start"</code> in <code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code>).</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the correlation (<code>scale=TRUE</code>) or
covariance (<code>scale=FALSE</code>) matrix should be used as input of
<code><a href="glassoFast.html#topic+glassoFast">glassoFast</a></code> if
<code>implementation=PenalisedGraphical</code>. Otherwise, this argument must be
used in the function provided in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_cpss">cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="SerialGraphical_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>S</code></td>
<td>
<p>a matrix of the best stability scores for
different (sets of) parameters controlling the level of sparsity in the
underlying algorithm.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix of parameters controlling the
level of sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the
average number of selected features by the underlying algorithm with
different parameters controlling the level of sparsity.</p>
</td></tr> <tr><td><code>Q_s</code></td>
<td>
<p>a
matrix of the calibrated number of stably selected features with different
parameters controlling the level of sparsity.</p>
</td></tr> <tr><td><code>P</code></td>
<td>
<p>a matrix of
calibrated thresholds in selection proportions for different parameters
controlling the level of sparsity in the underlying algorithm.</p>
</td></tr>
<tr><td><code>PFER</code></td>
<td>
<p>a matrix of upper-bounds in PFER of calibrated stability
selection models with different parameters controlling the level of
sparsity.</p>
</td></tr> <tr><td><code>FDP</code></td>
<td>
<p>a matrix of upper-bounds in FDP of calibrated
stability selection models with different parameters controlling the level
of sparsity.</p>
</td></tr> <tr><td><code>S_2d</code></td>
<td>
<p>a matrix of stability scores obtained with
different combinations of parameters. Columns correspond to different
thresholds in selection proportions.</p>
</td></tr> <tr><td><code>PFER_2d</code></td>
<td>
<p>a matrix of
upper-bounds in FDP obtained with different combinations of parameters.
Columns correspond to different thresholds in selection proportions. Only
returned if <code>length(pk)=1</code>.</p>
</td></tr> <tr><td><code>FDP_2d</code></td>
<td>
<p>a matrix of upper-bounds in
PFER obtained with different combinations of parameters. Columns correspond
to different thresholds in selection proportions. Only returned if
<code>length(pk)=1</code>.</p>
</td></tr> <tr><td><code>selprop</code></td>
<td>
<p>an array of selection proportions.
Rows and columns correspond to nodes in the graph. Indices along the third
dimension correspond to different parameters controlling the level of
sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>sign</code></td>
<td>
<p>a matrix of signs of
Pearson's correlations estimated from <code>xdata</code>.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list
with <code>type="graphical_model"</code> and values used for arguments
<code>implementation</code>, <code>start</code>, <code>resampling</code>, <code>cpss</code> and
<code>PFER_method</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used for arguments
<code>K</code>, <code>pi_list</code>, <code>tau</code>, <code>n_cat</code>, <code>pk</code>, <code>n</code>
(number of observations in <code>xdata</code>), <code>PFER_thr</code>, <code>FDP_thr</code>,
<code>seed</code>, <code>lambda_other_blocks</code>, and <code>Sequential_template</code>.</p>
</td></tr>
</table>
<p>The rows of <code>S</code>, <code>Lambda</code>, <code>Q</code>, <code>Q_s</code>, <code>P</code>,
<code>PFER</code>, <code>FDP</code>, <code>S_2d</code>, <code>PFER_2d</code> and <code>FDP_2d</code>, and
indices along the third dimension of <code>selprop</code> are ordered in the same
way and correspond to parameter values stored in <code>Lambda</code>. For
multi-block inference, the columns of <code>S</code>, <code>Lambda</code>, <code>Q</code>,
<code>Q_s</code>, <code>P</code>, <code>PFER</code> and <code>FDP</code>, and indices along the
third dimension of <code>S_2d</code> correspond to the different blocks.
</p>

<hr>
<h2 id='SerialRegression'>Stability selection in regression (internal)</h2><span id='topic+SerialRegression'></span>

<h3>Description</h3>

<p>Runs stability selection regression models with different combinations of
parameters controlling the sparsity of the underlying selection algorithm
(e.g. penalty parameter for regularised models) and thresholds in selection
proportions. These two parameters are jointly calibrated by maximising the
stability score of the model (possibly under a constraint on the expected
number of falsely stably selected features). This function uses a serial
implementation and requires the grid of parameters controlling the underlying
algorithm as input (for internal use only).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SerialRegression(
  xdata,
  ydata = NULL,
  Lambda,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = 3,
  family = "gaussian",
  implementation = PenalisedRegression,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  group_x = NULL,
  group_penalisation = FALSE,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SerialRegression_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
With <code>implementation="glmnet"</code>, <code>Lambda</code> contains penalty
parameters.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_implementation">implementation</code></td>
<td>
<p>function to use for variable selection. Possible
functions are: <code>PenalisedRegression</code>, <code>SparsePLS</code>,
<code>GroupPLS</code> and <code>SparseGroupPLS</code>. Alternatively, a user-defined
function can be provided.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_cpss">cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_group_x">group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used for
models with group penalisation (e.g. <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>).</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_group_penalisation">group_penalisation</code></td>
<td>
<p>logical indicating if a group penalisation should
be considered in the stability score. The use of
<code>group_penalisation=TRUE</code> strictly applies to group (not sparse-group)
penalisation.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="SerialRegression_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>S</code></td>
<td>
<p>a matrix of the best stability scores for
different parameters controlling the level of sparsity in the underlying
algorithm.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix of parameters controlling the level of
sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the average
number of selected features by the underlying algorithm with different
parameters controlling the level of sparsity.</p>
</td></tr> <tr><td><code>Q_s</code></td>
<td>
<p>a matrix of the
calibrated number of stably selected features with different parameters
controlling the level of sparsity.</p>
</td></tr> <tr><td><code>P</code></td>
<td>
<p>a matrix of calibrated
thresholds in selection proportions for different parameters controlling
the level of sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>PFER</code></td>
<td>
<p>a matrix of
upper-bounds in PFER of calibrated stability selection models with
different parameters controlling the level of sparsity.</p>
</td></tr> <tr><td><code>FDP</code></td>
<td>
<p>a
matrix of upper-bounds in FDP of calibrated stability selection models with
different parameters controlling the level of sparsity.</p>
</td></tr> <tr><td><code>S_2d</code></td>
<td>
<p>a
matrix of stability scores obtained with different combinations of
parameters. Columns correspond to different thresholds in selection
proportions.</p>
</td></tr> <tr><td><code>PFER_2d</code></td>
<td>
<p>a matrix of upper-bounds in FDP obtained with
different combinations of parameters. Columns correspond to different
thresholds in selection proportions.</p>
</td></tr> <tr><td><code>FDP_2d</code></td>
<td>
<p>a matrix of
upper-bounds in PFER obtained with different combinations of parameters.
Columns correspond to different thresholds in selection proportions.</p>
</td></tr>
<tr><td><code>selprop</code></td>
<td>
<p>a matrix of selection proportions. Columns correspond to
predictors from <code>xdata</code>.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>an array of model coefficients.
Columns correspond to predictors from <code>xdata</code>. Indices along the third
dimension correspond to different resampling iterations. With multivariate
outcomes, indices along the fourth dimension correspond to outcome-specific
coefficients.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list with <code>type="variable_selection"</code>
and values used for arguments <code>implementation</code>, <code>family</code>,
<code>resampling</code>, <code>cpss</code> and <code>PFER_method</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a
list with values used for arguments <code>K</code>, <code>pi_list</code>, <code>tau</code>,
<code>n_cat</code>, <code>pk</code>, <code>n</code> (number of observations),
<code>PFER_thr</code>, <code>FDP_thr</code> and <code>seed</code>. The datasets <code>xdata</code>
and <code>ydata</code> are also included if <code>output_data=TRUE</code>.</p>
</td></tr></table>
<p> For all
matrices and arrays returned, the rows are ordered in the same way and
correspond to parameter values stored in <code>Lambda</code>.
</p>

<hr>
<h2 id='SparseGroupPLS'>Sparse group Partial Least Squares</h2><span id='topic+SparseGroupPLS'></span>

<h3>Description</h3>

<p>Runs a sparse group Partial Least Squares model using implementation from
<code><a href="sgPLS.html#topic+sgPLS-package">sgPLS-package</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SparseGroupPLS(
  xdata,
  ydata,
  family = "gaussian",
  group_x,
  group_y = NULL,
  Lambda,
  alpha.x,
  alpha.y = NULL,
  keepX_previous = NULL,
  keepY = NULL,
  ncomp = 1,
  scale = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SparseGroupPLS_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_family">family</code></td>
<td>
<p>type of PLS model. If <code>family="gaussian"</code>, a sparse group
PLS model as defined in <code><a href="sgPLS.html#topic+sgPLS">sgPLS</a></code> is run (for continuous
outcomes). If <code>family="binomial"</code>, a PLS-DA model as defined in
<code><a href="sgPLS.html#topic+sgPLSda">sgPLSda</a></code> is run (for categorical outcomes).</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_group_x">group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_group_y">group_y</code></td>
<td>
<p>optional vector encoding the grouping structure among
outcomes. This argument indicates the number of variables in each group.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the number of selected groups
at current component, as defined by <code>ncomp</code>.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_alpha.x">alpha.x</code></td>
<td>
<p>vector of parameters controlling the level of sparsity within
groups of predictors.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_alpha.y">alpha.y</code></td>
<td>
<p>optional vector of parameters controlling the level of
sparsity within groups of outcomes. Only used if <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_keepx_previous">keepX_previous</code></td>
<td>
<p>number of selected groups in previous components. Only
used if <code>ncomp &gt; 1</code>. The argument <code>keepX</code> in
<code><a href="sgPLS.html#topic+sgPLS">sgPLS</a></code> is obtained by concatenating
<code>keepX_previous</code> and <code>Lambda</code>.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_keepy">keepY</code></td>
<td>
<p>number of selected groups of outcome variables. This argument is
defined as in <code><a href="sgPLS.html#topic+sgPLS">sgPLS</a></code>. Only used if
<code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one). Only
used if <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="SparseGroupPLS_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="sgPLS.html#topic+sgPLS">sgPLS</a></code> or
<code><a href="sgPLS.html#topic+sgPLSda">sgPLSda</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors (starting
with &quot;X&quot;) or outcomes (starting with &quot;Y&quot;) variables for different
components (denoted by &quot;PC&quot;).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Liquet B, de Micheaux PL, Hejblum BP, ThiÃ©baut R (2016).
&ldquo;Group and sparse group partial least square approaches applied in genomics context.&rdquo;
<em>Bioinformatics</em>, <b>32</b>(1), 35-42.
ISSN 1367-4803, <a href="https://doi.org/10.1093/bioinformatics/btv535">doi:10.1093/bioinformatics/btv535</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>
</p>
<p>Other penalised dimensionality reduction functions: 
<code><a href="#topic+GroupPLS">GroupPLS</a>()</code>,
<code><a href="#topic+SparsePCA">SparsePCA</a>()</code>,
<code><a href="#topic+SparsePLS">SparsePLS</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("sgPLS", quietly = TRUE)) {
  ## Sparse group PLS
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 30, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # Running sgPLS with 1 group and sparsity of 0.5
  mypls &lt;- SparseGroupPLS(
    xdata = x, ydata = y, Lambda = 1, family = "gaussian",
    group_x = c(10, 15, 5), alpha.x = 0.5
  )

  # Running sgPLS with groups on outcomes
  mypls &lt;- SparseGroupPLS(
    xdata = x, ydata = y, Lambda = 1, family = "gaussian",
    group_x = c(10, 15, 5), alpha.x = 0.5,
    group_y = c(2, 1), keepY = 1, alpha.y = 0.9
  )

  ## Sparse group PLS-DA
  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 50, family = "binomial")

  # Running sgPLS-DA with 1 group and sparsity of 0.9
  mypls &lt;- SparseGroupPLS(
    xdata = simul$xdata, ydata = simul$ydata, Lambda = 1, family = "binomial",
    group_x = c(10, 15, 25), alpha.x = 0.9
  )
}
</code></pre>

<hr>
<h2 id='SparseKMeansClustering'>Sparse K means clustering</h2><span id='topic+SparseKMeansClustering'></span>

<h3>Description</h3>

<p>Runs sparse K means clustering using implementation from
<code><a href="sparcl.html#topic+KMeansSparseCluster">KMeansSparseCluster</a></code>. This function is not using
stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SparseKMeansClustering(xdata, nc = NULL, Lambda, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SparseKMeansClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="SparseKMeansClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="SparseKMeansClustering_+3A_lambda">Lambda</code></td>
<td>
<p>vector of penalty parameters (see argument <code>wbounds</code> in
<code><a href="sparcl.html#topic+KMeansSparseCluster">KMeansSparseCluster</a></code>).</p>
</td></tr>
<tr><td><code id="SparseKMeansClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to
<code><a href="sparcl.html#topic+KMeansSparseCluster">KMeansSparseCluster</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten DM, Tibshirani R (2010).
&ldquo;A Framework for Feature Selection in Clustering.&rdquo;
<em>Journal of the American Statistical Association</em>, <b>105</b>(490), 713-726.
<a href="https://doi.org/10.1198/jasa.2010.tm09415">doi:10.1198/jasa.2010.tm09415</a>, PMID: 20811510.
</p>

<hr>
<h2 id='SparsePCA'>Sparse Principal Component Analysis</h2><span id='topic+SparsePCA'></span>

<h3>Description</h3>

<p>Runs a sparse Principal Component Analysis model using implementation from
<code><a href="elasticnet.html#topic+spca">spca</a></code> (if <code>algo="sPCA"</code>) or
<code><a href="mixOmics.html#topic+spca">spca</a></code> (if <code>algo="rSVD"</code>). This function is not
using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SparsePCA(
  xdata,
  Lambda,
  ncomp = 1,
  scale = TRUE,
  keepX_previous = NULL,
  algorithm = "sPCA",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SparsePCA_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="SparsePCA_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the number of selected
variables at current component, as defined by <code>ncomp</code>.</p>
</td></tr>
<tr><td><code id="SparsePCA_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components.</p>
</td></tr>
<tr><td><code id="SparsePCA_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one).</p>
</td></tr>
<tr><td><code id="SparsePCA_+3A_keepx_previous">keepX_previous</code></td>
<td>
<p>number of selected predictors in previous components.
Only used if <code>ncomp &gt; 1</code>.</p>
</td></tr>
<tr><td><code id="SparsePCA_+3A_algorithm">algorithm</code></td>
<td>
<p>character string indicating the name of the algorithm to use for
sparse PCA. Possible values are: &quot;sPCA&quot; (for the algorithm proposed by Zou,
Hastie and Tibshirani and implemented in <code><a href="elasticnet.html#topic+spca">spca</a></code>) or
&quot;rSVD&quot; (for the regularised SVD approach proposed by Shen and Huang and
implemented in <code><a href="mixOmics.html#topic+spca">spca</a></code>).</p>
</td></tr>
<tr><td><code id="SparsePCA_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to
<code><a href="elasticnet.html#topic+spca">spca</a></code> (if <code>algorithm="sPCA"</code>) or
<code><a href="mixOmics.html#topic+spca">spca</a></code> (if <code>algorithm="rSVD"</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors (starting
with &quot;X&quot;) or outcomes (starting with &quot;Y&quot;) variables for different
components (denoted by &quot;PC&quot;).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Zou H, Hastie T, Tibshirani R (2006).
&ldquo;Sparse Principal Component Analysis.&rdquo;
<em>Journal of Computational and Graphical Statistics</em>, <b>15</b>(2), 265-286.
<a href="https://doi.org/10.1198/106186006X113430">doi:10.1198/106186006X113430</a>.
</p>
<p>Shen H, Huang JZ (2008).
&ldquo;Sparse principal component analysis via regularized low rank matrix approximation.&rdquo;
<em>Journal of Multivariate Analysis</em>, <b>99</b>(6), 1015-1034.
ISSN 0047-259X, <a href="https://doi.org/10.1016/j.jmva.2007.06.007">doi:10.1016/j.jmva.2007.06.007</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>
</p>
<p>Other penalised dimensionality reduction functions: 
<code><a href="#topic+GroupPLS">GroupPLS</a>()</code>,
<code><a href="#topic+SparseGroupPLS">SparseGroupPLS</a>()</code>,
<code><a href="#topic+SparsePLS">SparsePLS</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Data simulation
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")
x &lt;- simul$xdata

# Sparse PCA (by Zou, Hastie, Tibshirani)
if (requireNamespace("elasticnet", quietly = TRUE)) {
  mypca &lt;- SparsePCA(
    xdata = x, ncomp = 2,
    Lambda = c(1, 2), keepX_previous = 10, algorithm = "sPCA"
  )
}

# Sparse PCA (by Shen and Huang)
if (requireNamespace("mixOmics", quietly = TRUE)) {
  mypca &lt;- SparsePCA(
    xdata = x, ncomp = 2,
    Lambda = c(1, 2), keepX_previous = 10, algorithm = "rSVD"
  )
}
</code></pre>

<hr>
<h2 id='SparsePLS'>Sparse Partial Least Squares</h2><span id='topic+SparsePLS'></span>

<h3>Description</h3>

<p>Runs a sparse Partial Least Squares model using implementation from
<code><a href="sgPLS.html#topic+sgPLS-package">sgPLS-package</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SparsePLS(
  xdata,
  ydata,
  Lambda,
  family = "gaussian",
  ncomp = 1,
  scale = TRUE,
  keepX_previous = NULL,
  keepY = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SparsePLS_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the number of selected
predictors at current component, as defined by <code>ncomp</code>.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_family">family</code></td>
<td>
<p>type of PLS model. If <code>family="gaussian"</code>, a sparse PLS
model as defined in <code><a href="sgPLS.html#topic+sPLS">sPLS</a></code> is run (for continuous
outcomes). If <code>family="binomial"</code>, a PLS-DA model as defined in
<code><a href="sgPLS.html#topic+sPLSda">sPLSda</a></code> is run (for categorical outcomes).</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_ncomp">ncomp</code></td>
<td>
<p>number of components.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the data should be scaled (i.e.
transformed so that all variables have a standard deviation of one). Only
used if <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_keepx_previous">keepX_previous</code></td>
<td>
<p>number of selected predictors in previous components.
Only used if <code>ncomp &gt; 1</code>. The argument <code>keepX</code> in
<code><a href="sgPLS.html#topic+sPLS">sPLS</a></code> is obtained by concatenating
<code>keepX_previous</code> and <code>Lambda</code>.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_keepy">keepY</code></td>
<td>
<p>number of selected outcome variables. This argument is defined
as in <code><a href="sgPLS.html#topic+sPLS">sPLS</a></code>. Only used if <code>family="gaussian"</code>.</p>
</td></tr>
<tr><td><code id="SparsePLS_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="sgPLS.html#topic+sPLS">sPLS</a></code> or
<code><a href="sgPLS.html#topic+sPLSda">sPLSda</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>selected</code></td>
<td>
<p>matrix of binary selection status. Rows
correspond to different model parameters. Columns correspond to
predictors.</p>
</td></tr> <tr><td><code>beta_full</code></td>
<td>
<p>array of model coefficients. Rows correspond
to different model parameters. Columns correspond to predictors (starting
with &quot;X&quot;) or outcomes (starting with &quot;Y&quot;) variables for different
components (denoted by &quot;PC&quot;).</p>
</td></tr>
</table>


<h3>References</h3>

<p>KA LC, Rossouw D, Robert-GraniÃ© C, Besse P (2008).
&ldquo;A sparse PLS for variable selection when integrating omics data.&rdquo;
<em>Stat Appl Genet Mol Biol</em>, <b>7</b>(1), Article 35.
ISSN 1544-6115, <a href="https://doi.org/10.2202/1544-6115.1390">doi:10.2202/1544-6115.1390</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>
</p>
<p>Other penalised dimensionality reduction functions: 
<code><a href="#topic+GroupPLS">GroupPLS</a>()</code>,
<code><a href="#topic+SparseGroupPLS">SparseGroupPLS</a>()</code>,
<code><a href="#topic+SparsePCA">SparsePCA</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("sgPLS", quietly = TRUE)) {
  ## Sparse PLS

  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 20, q = 3, family = "gaussian")
  x &lt;- simul$xdata
  y &lt;- simul$ydata

  # Running sPLS with 2 X-variables and 1 Y-variable
  mypls &lt;- SparsePLS(xdata = x, ydata = y, Lambda = 2, family = "gaussian", keepY = 1)


  ## Sparse PLS-DA

  # Data simulation
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 20, family = "binomial")

  # Running sPLS-DA with 2 X-variables and 1 Y-variable
  mypls &lt;- SparsePLS(xdata = simul$xdata, ydata = simul$ydata, Lambda = 2, family = "binomial")
}
</code></pre>

<hr>
<h2 id='Split'>Splitting observations into non-overlapping sets</h2><span id='topic+Split'></span>

<h3>Description</h3>

<p>Generates a list of <code>length(tau)</code> non-overlapping sets of observation
IDs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Split(data, family = NULL, tau = c(0.5, 0.25, 0.25))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Split_+3A_data">data</code></td>
<td>
<p>vector or matrix of data. In regression, this should be the
outcome data.</p>
</td></tr>
<tr><td><code id="Split_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="Split_+3A_tau">tau</code></td>
<td>
<p>vector of the proportion of observations in each of the sets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>With categorical outcomes (i.e. <code>family</code> argument is set to
<code>"binomial"</code>, <code>"multinomial"</code> or <code>"cox"</code>), the split is done
such that the proportion of observations from each of the categories in
each of the sets is representative of that of the full sample.
</p>


<h3>Value</h3>

<p>A list of length <code>length(tau)</code> with sets of non-overlapping
observation IDs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Splitting into 3 sets
simul &lt;- SimulateRegression()
ids &lt;- Split(data = simul$ydata)
lapply(ids, length)

# Balanced splits with respect to a binary variable
simul &lt;- SimulateRegression(family = "binomial")
ids &lt;- Split(data = simul$ydata, family = "binomial")
lapply(ids, FUN = function(x) {
  table(simul$ydata[x, ])
})
</code></pre>

<hr>
<h2 id='Square'>Adjacency from bipartite</h2><span id='topic+Square'></span>

<h3>Description</h3>

<p>Generates a symmetric adjacency matrix encoding a bipartite graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Square(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Square_+3A_x">x</code></td>
<td>
<p>matrix encoding the edges between two types of nodes (rows and
columns).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A symmetric adjacency matrix encoding a bipartite graph.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated links between two sets
set.seed(1)
mat &lt;- matrix(sample(c(0, 1), size = 15, replace = TRUE),
  nrow = 5, ncol = 3
)

# Adjacency matrix of a bipartite graph
Square(mat)
</code></pre>

<hr>
<h2 id='StabilityMetrics'>Stability selection metrics</h2><span id='topic+StabilityMetrics'></span>

<h3>Description</h3>

<p>Computes the stability score (see <code><a href="#topic+StabilityScore">StabilityScore</a></code>) and
upper-bounds of the <code><a href="#topic+PFER">PFER</a></code> and <code><a href="#topic+FDP">FDP</a></code> from selection
proportions of models with a given parameter controlling the sparsity of the
underlying algorithm and for different thresholds in selection proportions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StabilityMetrics(
  selprop,
  pk = NULL,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K = 100,
  n_cat = NULL,
  PFER_method = "MB",
  PFER_thr_blocks = Inf,
  FDP_thr_blocks = Inf,
  Sequential_template = NULL,
  graph = TRUE,
  group = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StabilityMetrics_+3A_selprop">selprop</code></td>
<td>
<p>array of selection proportions.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_pk">pk</code></td>
<td>
<p>optional vector encoding the grouping structure. Only used for
multi-block stability selection where <code>pk</code> indicates the number of
variables in each group. If <code>pk=NULL</code>, single-block stability
selection is performed.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_pfer_thr_blocks">PFER_thr_blocks</code></td>
<td>
<p>vector of block-specific thresholds in PFER for
constrained calibration by error control. If <code>PFER_thr=Inf</code> and
<code>FDP_thr=Inf</code>, unconstrained calibration is used.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_fdp_thr_blocks">FDP_thr_blocks</code></td>
<td>
<p>vector of block-specific thresholds in the expected
proportion of falsely selected features (or False Discovery Proportion,
FDP) for constrained calibration by error control. If <code>PFER_thr=Inf</code>
and <code>FDP_thr=Inf</code>, unconstrained calibration is used.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_sequential_template">Sequential_template</code></td>
<td>
<p>logical matrix encoding the type of procedure to
use for data with multiple blocks in stability selection graphical
modelling. For multi-block estimation, the stability selection model is
constructed as the union of block-specific stable edges estimated while the
others are weakly penalised (<code>TRUE</code> only for the block currently being
calibrated and <code>FALSE</code> for other blocks). Other approaches with joint
calibration of the blocks are allowed (all entries are set to <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_graph">graph</code></td>
<td>
<p>logical indicating if stability selection is performed in a
regression (if <code>FALSE</code>) or graphical (if <code>TRUE</code>)
framework.</p>
</td></tr>
<tr><td><code id="StabilityMetrics_+3A_group">group</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group and only needs to
be provided for group (but not sparse group) penalisation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>S</code></td>
<td>
<p>a matrix of the best (block-specific) stability
scores for different (sets of) penalty parameters. In multi-block stability
selection, rows correspond to different sets of penalty parameters, (values
are stored in the output &quot;Lambda&quot;) and columns correspond to different
blocks.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix of (block-specific) penalty parameters. In
multi-block stability selection, rows correspond to sets of penalty
parameters and columns correspond to different blocks.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix
of average numbers of (block-specific) edges selected by the underlying
algorithm for different (sets of) penalty parameters. In multi-block
stability selection, rows correspond to different sets of penalty
parameters, (values are stored in the output &quot;Lambda&quot;) and columns
correspond to different blocks.</p>
</td></tr> <tr><td><code>Q_s</code></td>
<td>
<p>a matrix of calibrated numbers
of (block-specific) stable edges for different (sets of) penalty
parameters. In multi-block stability selection, rows correspond to
different sets of penalty parameters, (values are stored in the output
&quot;Lambda&quot;) and columns correspond to different blocks.</p>
</td></tr> <tr><td><code>P</code></td>
<td>
<p>a matrix of
calibrated (block-specific) thresholds in selection proportions for
different (sets of) penalty parameters. In multi-block stability selection,
rows correspond to different sets of penalty parameters, (values are stored
in the output &quot;Lambda&quot;) and columns correspond to different blocks.</p>
</td></tr>
<tr><td><code>PFER</code></td>
<td>
<p>a matrix of computed (block-specific) upper-bounds in PFER of
calibrated graphs for different (sets of) penalty parameters. In
multi-block stability selection, rows correspond to different sets of
penalty parameters, (values are stored in the output &quot;Lambda&quot;) and columns
correspond to different blocks.</p>
</td></tr> <tr><td><code>FDP</code></td>
<td>
<p>a matrix of computed
(block-specific) upper-bounds in FDP of calibrated stability selection
models for different (sets of) penalty parameters. In multi-block stability
selection, rows correspond to different sets of penalty parameters, (values
are stored in the output &quot;Lambda&quot;) and columns correspond to different
blocks.</p>
</td></tr> <tr><td><code>S_2d</code></td>
<td>
<p>an array of (block-specific) stability scores obtained
with different combinations of parameters. Rows correspond to different
(sets of) penalty parameters and columns correspond to different thresholds
in selection proportions. In multi-block stability selection, indices along
the third dimension correspond to different blocks.</p>
</td></tr> <tr><td><code>PFER_2d</code></td>
<td>
<p>an
array of computed upper-bounds of PFER obtained with different combinations
of parameters. Rows correspond to different penalty parameters and columns
correspond to different thresholds in selection proportions. Not available
in multi-block stability selection graphical modelling.</p>
</td></tr> <tr><td><code>FDP_2d</code></td>
<td>
<p>an
array of computed upper-bounds of FDP obtained with different combinations
of parameters. Rows correspond to different penalty parameters and columns
correspond to different thresholds in selection proportions. Not available
in multi-block stability selection graphical modelling.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Shah RD, Samworth RJ (2013).
&ldquo;Variable selection with error control: another look at stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>


<h3>See Also</h3>

<p>Other stability metric functions: 
<code><a href="#topic+ConsensusScore">ConsensusScore</a>()</code>,
<code><a href="#topic+FDP">FDP</a>()</code>,
<code><a href="#topic+PFER">PFER</a>()</code>,
<code><a href="#topic+StabilityScore">StabilityScore</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Sparse or sparse group penalisation

# Simulating set of selection proportions
set.seed(1)
selprop &lt;- matrix(round(runif(n = 20), digits = 2), nrow = 2)

# Computing stability scores for different thresholds
metrics &lt;- StabilityMetrics(
  selprop = selprop, pi = c(0.6, 0.7, 0.8),
  K = 100, graph = FALSE
)


## Group penalisation

# Simulating set of selection proportions
set.seed(1)
selprop &lt;- matrix(round(runif(n = 6), digits = 2), nrow = 2)
selprop &lt;- cbind(
  selprop[, 1], selprop[, 1],
  selprop[, 2], selprop[, 2],
  matrix(rep(selprop[, 3], each = 6), nrow = 2, byrow = TRUE)
)

# Computing stability scores for different thresholds
metrics &lt;- StabilityMetrics(
  selprop = selprop, pi = c(0.6, 0.7, 0.8),
  K = 100, graph = FALSE, group = c(2, 2, 6)
)
</code></pre>

<hr>
<h2 id='StabilityScore'>Stability score</h2><span id='topic+StabilityScore'></span>

<h3>Description</h3>

<p>Computes the stability score from selection proportions of models with a
given parameter controlling the sparsity and for different thresholds in
selection proportions. The score measures how unlikely it is that the
selection procedure is uniform (i.e. uninformative) for a given combination
of parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StabilityScore(
  selprop,
  pi_list = seq(0.6, 0.9, by = 0.01),
  K,
  n_cat = 3,
  group = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StabilityScore_+3A_selprop">selprop</code></td>
<td>
<p>array of selection proportions.</p>
</td></tr>
<tr><td><code id="StabilityScore_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="StabilityScore_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="StabilityScore_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="StabilityScore_+3A_group">group</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group and only needs to
be provided for group (but not sparse group) penalisation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The stability score is derived from the likelihood under the
assumption of uniform (uninformative) selection.
</p>
<p>We classify the features into three categories: the stably selected ones
(that have selection proportions <code class="reqn">\ge \pi</code>), the stably excluded ones
(selection proportion <code class="reqn">\le 1-\pi</code>), and the unstable ones (selection
proportions between <code class="reqn">1-\pi</code> and <code class="reqn">\pi</code>).
</p>
<p>Under the hypothesis of equiprobability of selection (instability), the
likelihood of observing stably selected, stably excluded and unstable
features can be expressed as:
</p>
<p><code class="reqn">L_{\lambda, \pi} = \prod_{j=1}^N [ ( 1 - F( K \pi - 1 ) )^{1_{H_{\lambda} (j) \ge K \pi}}
  \times ( F( K \pi - 1 ) - F( K ( 1 - \pi ) )^{1_{ (1-\pi) K &lt; H_{\lambda} (j) &lt; K \pi }}
  \times F( K ( 1 - \pi ) )^{1_{ H_{\lambda} (j) \le K (1-\pi) }} ]</code>
</p>
<p>where <code class="reqn">H_{\lambda} (j)</code> is the selection count of feature <code class="reqn">j</code> and
<code class="reqn">F(x)</code> is the cumulative probability function of the binomial
distribution with parameters <code class="reqn">K</code> and the average proportion of selected
features over resampling iterations.
</p>
<p>The stability score is computed as the minus log-transformed likelihood
under the assumption of equiprobability of selection:
</p>
<p><code class="reqn">S_{\lambda, \pi} = -log(L_{\lambda, \pi})</code>
</p>
<p>The stability score increases with stability.
</p>
<p>Alternatively, the stability score can be computed by considering only two
sets of features: stably selected (selection proportions <code class="reqn">\ge \pi</code>) or
not (selection proportions <code class="reqn">&lt; \pi</code>). This can be done using
<code>n_cat=2</code>.
</p>


<h3>Value</h3>

<p>A vector of stability scores obtained with the different thresholds
in selection proportions.
</p>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>


<h3>See Also</h3>

<p>Other stability metric functions: 
<code><a href="#topic+ConsensusScore">ConsensusScore</a>()</code>,
<code><a href="#topic+FDP">FDP</a>()</code>,
<code><a href="#topic+PFER">PFER</a>()</code>,
<code><a href="#topic+StabilityMetrics">StabilityMetrics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulating set of selection proportions
set.seed(1)
selprop &lt;- round(runif(n = 20), digits = 2)

# Computing stability scores for different thresholds
score &lt;- StabilityScore(selprop, pi_list = c(0.6, 0.7, 0.8), K = 100)
</code></pre>

<hr>
<h2 id='Stable'>Stable results</h2><span id='topic+Stable'></span><span id='topic+SelectedVariables'></span><span id='topic+Adjacency'></span><span id='topic+Clusters'></span>

<h3>Description</h3>

<p>Extracts stable results for stability selection or consensus clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Stable(stability, argmax_id = NULL, linkage = "complete")

SelectedVariables(stability, argmax_id = NULL)

Adjacency(stability, argmax_id = NULL)

Clusters(stability, linkage = "complete", argmax_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Stable_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+VariableSelection">VariableSelection</a></code>,
<code><a href="#topic+BiSelection">BiSelection</a></code>, <code><a href="#topic+GraphicalModel">GraphicalModel</a></code> or
<code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="Stable_+3A_argmax_id">argmax_id</code></td>
<td>
<p>optional indices of hyper-parameters. If
<code>argmax_id=NULL</code>, the calibrated hyper-parameters are used.</p>
</td></tr>
<tr><td><code id="Stable_+3A_linkage">linkage</code></td>
<td>
<p>character string indicating the type of linkage used in
hierarchical clustering to define the stable clusters. Possible values
include <code>"complete"</code>, <code>"single"</code> and <code>"average"</code> (see
argument <code>"method"</code> in <code><a href="stats.html#topic+hclust">hclust</a></code> for a full list).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A binary vector or matrix encoding the selection status (<code>1</code> if
selected, <code>0</code> otherwise) in stability selection or stable cluster
membership in consensus clustering.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+VariableSelection">VariableSelection</a></code>, <code><a href="#topic+BiSelection">BiSelection</a></code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a></code>, <code><a href="#topic+Clustering">Clustering</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Variable selection
set.seed(1)
simul &lt;- SimulateRegression(pk = 20)
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata)
SelectedVariables(stab)
Stable(stab)

# Graphical model
set.seed(1)
simul &lt;- SimulateGraphical(pk = 10)
stab &lt;- GraphicalModel(xdata = simul$data)
Adjacency(stab)
Stable(stab)

# Clustering
set.seed(1)
simul &lt;- SimulateClustering(
  n = c(30, 30, 30),
  nu_xc = 1
)
stab &lt;- Clustering(xdata = simul$data)
Clusters(stab)
Stable(stab)

</code></pre>

<hr>
<h2 id='StructuralModel'>Stability selection in Structural Equation Modelling</h2><span id='topic+StructuralModel'></span>

<h3>Description</h3>

<p>Performs stability selection for Structural Equation Models. The underlying
arrow selection algorithm (e.g. regularised Structural Equation Modelling) is
run with different combinations of parameters controlling the sparsity (e.g.
penalty parameter) and thresholds in selection proportions. These two
hyper-parameters are jointly calibrated by maximisation of the stability
score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>StructuralModel(
  xdata,
  adjacency,
  residual_covariance = NULL,
  Lambda = NULL,
  pi_list = seq(0.01, 0.99, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = NULL,
  implementation = PenalisedLinearSystem,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  Lambda_cardinal = 100,
  optimisation = c("grid_search", "nloptr"),
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="StructuralModel_+3A_xdata">xdata</code></td>
<td>
<p>matrix with observations as rows and variables as columns.
Column names must be defined and in line with the row and column names of
<code>adjacency</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_adjacency">adjacency</code></td>
<td>
<p>binary adjacency matrix of the Directed Acyclic Graph
(transpose of the asymmetric matrix A in Reticular Action Model notation).
The row and column names of this matrix must be defined.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_residual_covariance">residual_covariance</code></td>
<td>
<p>binary and symmetric matrix encoding the nonzero
entries in the residual covariance matrix (symmetric matrix S in Reticular
Action Model notation). By default, this is the identity matrix (no
residual covariance).</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_implementation">implementation</code></td>
<td>
<p>function to use for variable selection.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_cpss">cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm. Only used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_optimisation">optimisation</code></td>
<td>
<p>character string indicating the type of optimisation
method. With <code>optimisation="grid_search"</code> (the default), all values in
<code>Lambda</code> are visited. Alternatively, optimisation algorithms
implemented in <code><a href="nloptr.html#topic+nloptr">nloptr</a></code> can be used with
<code>optimisation="nloptr"</code>. By default, we use
<code>"algorithm"="NLOPT_GN_DIRECT_L"</code>, <code>"xtol_abs"=0.1</code>,
<code>"ftol_abs"=0.1</code> and <code>"maxeval"=Lambda_cardinal</code>. These values
can be changed by providing the argument <code>opts</code> (see
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code>). For stability selection using penalised
regression, <code>optimisation="grid_search"</code> may be faster as it allows
for warm start.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_n_cores">n_cores</code></td>
<td>
<p>number of cores to use for parallel computing (see argument
<code>workers</code> in <code><a href="future.html#topic+multisession">multisession</a></code>). Using
<code>n_cores&gt;1</code> is only supported with <code>optimisation="grid_search"</code>.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="StructuralModel_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In stability selection, a feature selection algorithm is fitted on
<code>K</code> subsamples (or bootstrap samples) of the data with different
parameters controlling the sparsity (<code>Lambda</code>). For a given (set of)
sparsity parameter(s), the proportion out of the <code>K</code> models in which
each feature is selected is calculated. Features with selection proportions
above a threshold pi are considered stably selected. The stability
selection model is controlled by the sparsity parameter(s) for the
underlying algorithm, and the threshold in selection proportion:
</p>
<p><code class="reqn">V_{\lambda, \pi} = \{ j: p_{\lambda}(j) \ge \pi \} </code>
</p>
<p>In Structural Equation Modelling, &quot;feature&quot; refers to an arrow in the
corresponding Directed Acyclic Graph.
</p>
<p>These parameters can be calibrated by maximisation of a stability score
(see <code><a href="#topic+ConsensusScore">ConsensusScore</a></code> if <code>n_cat=NULL</code> or
<code><a href="#topic+StabilityScore">StabilityScore</a></code> otherwise) calculated under the null
hypothesis of equiprobability of selection.
</p>
<p>It is strongly recommended to examine the calibration plot carefully to
check that the grids of parameters <code>Lambda</code> and <code>pi_list</code> do not
restrict the calibration to a region that would not include the global
maximum (see <code><a href="#topic+CalibrationPlot">CalibrationPlot</a></code>). In particular, the grid
<code>Lambda</code> may need to be extended when the maximum stability is
observed on the left or right edges of the calibration heatmap. In some
instances, multiple peaks of stability score can be observed. Simulation
studies suggest that the peak corresponding to the largest number of
selected features tend to give better selection performances. This is not
necessarily the highest peak (which is automatically retained by the
functions in this package). The user can decide to manually choose another
peak.
</p>
<p>To control the expected number of False Positives (Per Family Error Rate)
in the results, a threshold <code>PFER_thr</code> can be specified. The
optimisation problem is then constrained to sets of parameters that
generate models with an upper-bound in PFER below <code>PFER_thr</code> (see
Meinshausen and BÃ¼hlmann (2010) and Shah and Samworth (2013)).
</p>
<p>Possible resampling procedures include defining (i) <code>K</code> subsamples of
a proportion <code>tau</code> of the observations, (ii) <code>K</code> bootstrap
samples with the full sample size (obtained with replacement), and (iii)
<code>K/2</code> splits of the data in half for complementary pair stability
selection (see arguments <code>resampling</code> and <code>cpss</code>). In
complementary pair stability selection, a feature is considered selected at
a given resampling iteration if it is selected in the two complementary
subsamples.
</p>
<p>To ensure reproducibility of the results, the starting number of the random
number generator is set to <code>seed</code>.
</p>
<p>For parallelisation, stability selection with different sets of parameters
can be run on <code>n_cores</code> cores. Using <code>n_cores &gt; 1</code> creates a
<code><a href="future.html#topic+multisession">multisession</a></code>. Alternatively,
the function can be run manually with different <code>seed</code>s and all other
parameters equal. The results can then be combined using
<code><a href="#topic+Combine">Combine</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>variable_selection</code>. A list with: </p>
<table>
<tr><td><code>S</code></td>
<td>
<p>a
matrix of the best stability scores for different parameters controlling
the level of sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix
of parameters controlling the level of sparsity in the underlying
algorithm.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the average number of selected features by
the underlying algorithm with different parameters controlling the level of
sparsity.</p>
</td></tr> <tr><td><code>Q_s</code></td>
<td>
<p>a matrix of the calibrated number of stably selected
features with different parameters controlling the level of sparsity.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>a matrix of calibrated thresholds in selection proportions for
different parameters controlling the level of sparsity in the underlying
algorithm.</p>
</td></tr> <tr><td><code>PFER</code></td>
<td>
<p>a matrix of upper-bounds in PFER of calibrated
stability selection models with different parameters controlling the level
of sparsity.</p>
</td></tr> <tr><td><code>FDP</code></td>
<td>
<p>a matrix of upper-bounds in FDP of calibrated
stability selection models with different parameters controlling the level
of sparsity.</p>
</td></tr> <tr><td><code>S_2d</code></td>
<td>
<p>a matrix of stability scores obtained with
different combinations of parameters. Columns correspond to different
thresholds in selection proportions.</p>
</td></tr> <tr><td><code>PFER_2d</code></td>
<td>
<p>a matrix of
upper-bounds in FDP obtained with different combinations of parameters.
Columns correspond to different thresholds in selection proportions.</p>
</td></tr>
<tr><td><code>FDP_2d</code></td>
<td>
<p>a matrix of upper-bounds in PFER obtained with different
combinations of parameters. Columns correspond to different thresholds in
selection proportions.</p>
</td></tr> <tr><td><code>selprop</code></td>
<td>
<p>a matrix of selection proportions.
Columns correspond to predictors from <code>xdata</code>.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>an array
of model coefficients. Columns correspond to predictors from <code>xdata</code>.
Indices along the third dimension correspond to different resampling
iterations. With multivariate outcomes, indices along the fourth dimension
correspond to outcome-specific coefficients.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list with
<code>type="variable_selection"</code> and values used for arguments
<code>implementation</code>, <code>family</code>, <code>resampling</code>, <code>cpss</code> and
<code>PFER_method</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used for arguments
<code>K</code>, <code>pi_list</code>, <code>tau</code>, <code>n_cat</code>, <code>pk</code>, <code>n</code>
(number of observations), <code>PFER_thr</code>, <code>FDP_thr</code> and <code>seed</code>.
The datasets <code>xdata</code> and <code>ydata</code> are also included if
<code>output_data=TRUE</code>.</p>
</td></tr></table>
<p> For all matrices and arrays returned, the rows
are ordered in the same way and correspond to parameter values stored in
<code>Lambda</code>.
</p>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Shah RD, Samworth RJ (2013).
&ldquo;Variable selection with error control: another look at stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>
<p>Jacobucci R, Grimm KJ, McArdle JJ (2016).
&ldquo;Regularized structural equation modeling.&rdquo;
<em>Structural equation modeling: a multidisciplinary journal</em>, <b>23</b>(4), 555&ndash;566.
<a href="https://doi.org/10.1080/10705511.2016.1154793">doi:10.1080/10705511.2016.1154793</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SelectionAlgo">SelectionAlgo</a></code>,
<code><a href="#topic+Resample">Resample</a></code>, <code><a href="#topic+StabilityScore">StabilityScore</a></code>
</p>
<p>Other stability functions: 
<code><a href="#topic+BiSelection">BiSelection</a>()</code>,
<code><a href="#topic+Clustering">Clustering</a>()</code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a>()</code>,
<code><a href="#topic+VariableSelection">VariableSelection</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>oldpar &lt;- par(no.readonly = TRUE)
par(mar = rep(7, 4))


# Data simulation
set.seed(1)
pk &lt;- c(3, 2, 3)
simul &lt;- SimulateStructural(
  n = 500,
  pk = pk,
  nu_between = 0.5,
  v_between = 1,
  v_sign = 1
)

# Stability selection (using glmnet)
dag &lt;- LayeredDAG(layers = pk)
stab &lt;- StructuralModel(
  xdata = simul$data,
  adjacency = dag
)
CalibrationPlot(stab)
LinearSystemMatrix(vect = Stable(stab), adjacency = dag)

# Stability selection (using OpenMx)
if (requireNamespace("OpenMx", quietly = TRUE)) {
  stab &lt;- StructuralModel(
    xdata = simul$data,
    implementation = PenalisedOpenMx,
    Lambda = seq(50, 500, by = 50),
    adjacency = dag
  )
  CalibrationPlot(stab)
  OpenMxMatrix(SelectedVariables(stab), adjacency = dag)
}

## Not run: 
# Data simulation with latent variables
set.seed(1)
pk &lt;- c(3, 2, 3)
simul &lt;- SimulateStructural(
  n = 500,
  pk = pk,
  nu_between = 0.5,
  v_sign = 1,
  v_between = 1,
  n_manifest = 3,
  ev_manifest = 0.95
)

# Stability selection (using OpenMx)
if (requireNamespace("OpenMx", quietly = TRUE)) {
  dag &lt;- LayeredDAG(layers = pk, n_manifest = 3)
  penalised &lt;- dag
  penalised[, seq_len(ncol(simul$data))] &lt;- 0
  stab &lt;- StructuralModel(
    xdata = simul$data,
    implementation = PenalisedOpenMx,
    adjacency = dag,
    penalised = penalised,
    Lambda = seq(10, 100, by = 20),
    K = 10 # to increase for real use
  )
  CalibrationPlot(stab)
  ids_latent &lt;- grep("f", colnames(dag))
  OpenMxMatrix(SelectedVariables(stab),
    adjacency = dag
  )[ids_latent, ids_latent]
}

## End(Not run)

par(oldpar)
</code></pre>

<hr>
<h2 id='UnweightedKMeansClustering'>Unweighted K-means clustering</h2><span id='topic+UnweightedKMeansClustering'></span>

<h3>Description</h3>

<p>Runs k-means clustering using implementation from
<code><a href="stats.html#topic+kmeans">kmeans</a></code>. This function is not using stability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UnweightedKMeansClustering(xdata, nc = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UnweightedKMeansClustering_+3A_xdata">xdata</code></td>
<td>
<p>data matrix with observations as rows and variables as columns.</p>
</td></tr>
<tr><td><code id="UnweightedKMeansClustering_+3A_nc">nc</code></td>
<td>
<p>matrix of parameters controlling the number of clusters in the
underlying algorithm specified in <code>implementation</code>. If <code>nc</code> is
not provided, it is set to <code>seq(1, tau*nrow(xdata))</code>.</p>
</td></tr>
<tr><td><code id="UnweightedKMeansClustering_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="stats.html#topic+kmeans">kmeans</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with: </p>
<table>
<tr><td><code>comembership</code></td>
<td>
<p>an array of binary and symmetric
co-membership matrices.</p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a matrix of median weights by
feature.</p>
</td></tr>
</table>

<hr>
<h2 id='VariableSelection'>Stability selection in regression</h2><span id='topic+VariableSelection'></span>

<h3>Description</h3>

<p>Performs stability selection for regression models. The underlying variable
selection algorithm (e.g. LASSO regression) is run with different
combinations of parameters controlling the sparsity (e.g. penalty parameter)
and thresholds in selection proportions. These two hyper-parameters are
jointly calibrated by maximisation of the stability score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VariableSelection(
  xdata,
  ydata = NULL,
  Lambda = NULL,
  pi_list = seq(0.01, 0.99, by = 0.01),
  K = 100,
  tau = 0.5,
  seed = 1,
  n_cat = NULL,
  family = "gaussian",
  implementation = PenalisedRegression,
  resampling = "subsampling",
  cpss = FALSE,
  PFER_method = "MB",
  PFER_thr = Inf,
  FDP_thr = Inf,
  Lambda_cardinal = 100,
  group_x = NULL,
  group_penalisation = FALSE,
  optimisation = c("grid_search", "nloptr"),
  n_cores = 1,
  output_data = FALSE,
  verbose = TRUE,
  beep = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VariableSelection_+3A_xdata">xdata</code></td>
<td>
<p>matrix of predictors with observations as rows and variables as
columns.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_ydata">ydata</code></td>
<td>
<p>optional vector or matrix of outcome(s). If <code>family</code> is set
to <code>"binomial"</code> or <code>"multinomial"</code>, <code>ydata</code> can be a vector
with character/numeric values or a factor.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_lambda">Lambda</code></td>
<td>
<p>matrix of parameters controlling the level of sparsity in the
underlying feature selection algorithm specified in <code>implementation</code>.
If <code>Lambda=NULL</code> and <code>implementation=PenalisedRegression</code>,
<code><a href="#topic+LambdaGridRegression">LambdaGridRegression</a></code> is used to define a relevant grid.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_pi_list">pi_list</code></td>
<td>
<p>vector of thresholds in selection proportions. If
<code>n_cat=NULL</code> or <code>n_cat=2</code>, these values must be <code>&gt;0</code> and
<code>&lt;1</code>. If <code>n_cat=3</code>, these values must be <code>&gt;0.5</code> and
<code>&lt;1</code>.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_k">K</code></td>
<td>
<p>number of resampling iterations.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_tau">tau</code></td>
<td>
<p>subsample size. Only used if <code>resampling="subsampling"</code> and
<code>cpss=FALSE</code>.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_seed">seed</code></td>
<td>
<p>value of the seed to initialise the random number generator and
ensure reproducibility of the results (see <code><a href="base.html#topic+set.seed">set.seed</a></code>).</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_n_cat">n_cat</code></td>
<td>
<p>computation options for the stability score. Default is
<code>NULL</code> to use the score based on a z test. Other possible values are 2
or 3 to use the score based on the negative log-likelihood.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_family">family</code></td>
<td>
<p>type of regression model. This argument is defined as in
<code><a href="glmnet.html#topic+glmnet">glmnet</a></code>. Possible values include <code>"gaussian"</code>
(linear regression), <code>"binomial"</code> (logistic regression),
<code>"multinomial"</code> (multinomial regression), and <code>"cox"</code> (survival
analysis).</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_implementation">implementation</code></td>
<td>
<p>function to use for variable selection. Possible
functions are: <code>PenalisedRegression</code>, <code>SparsePLS</code>,
<code>GroupPLS</code> and <code>SparseGroupPLS</code>. Alternatively, a user-defined
function can be provided.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_resampling">resampling</code></td>
<td>
<p>resampling approach. Possible values are:
<code>"subsampling"</code> for sampling without replacement of a proportion
<code>tau</code> of the observations, or <code>"bootstrap"</code> for sampling with
replacement generating a resampled dataset with as many observations as in
the full sample. Alternatively, this argument can be a function to use for
resampling. This function must use arguments named <code>data</code> and
<code>tau</code> and return the IDs of observations to be included in the
resampled dataset.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_cpss">cpss</code></td>
<td>
<p>logical indicating if complementary pair stability selection
should be done. For this, the algorithm is applied on two non-overlapping
subsets of half of the observations. A feature is considered as selected if
it is selected for both subsamples. With this method, the data is split
<code>K/2</code> times (<code>K</code> models are fitted). Only used if
<code>PFER_method="MB"</code>.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_pfer_method">PFER_method</code></td>
<td>
<p>method used to compute the upper-bound of the expected
number of False Positives (or Per Family Error Rate, PFER). If
<code>PFER_method="MB"</code>, the method proposed by Meinshausen and BÃ¼hlmann
(2010) is used. If <code>PFER_method="SS"</code>, the method proposed by Shah and
Samworth (2013) under the assumption of unimodality is used.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_pfer_thr">PFER_thr</code></td>
<td>
<p>threshold in PFER for constrained calibration by error
control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_fdp_thr">FDP_thr</code></td>
<td>
<p>threshold in the expected proportion of falsely selected
features (or False Discovery Proportion) for constrained calibration by
error control. If <code>PFER_thr=Inf</code> and <code>FDP_thr=Inf</code>, unconstrained
calibration is used (the default).</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_lambda_cardinal">Lambda_cardinal</code></td>
<td>
<p>number of values in the grid of parameters controlling
the level of sparsity in the underlying algorithm. Only used if
<code>Lambda=NULL</code>.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_group_x">group_x</code></td>
<td>
<p>vector encoding the grouping structure among predictors. This
argument indicates the number of variables in each group. Only used for
models with group penalisation (e.g. <code>implementation=GroupPLS</code> or
<code>implementation=SparseGroupPLS</code>).</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_group_penalisation">group_penalisation</code></td>
<td>
<p>logical indicating if a group penalisation should
be considered in the stability score. The use of
<code>group_penalisation=TRUE</code> strictly applies to group (not sparse-group)
penalisation.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_optimisation">optimisation</code></td>
<td>
<p>character string indicating the type of optimisation
method. With <code>optimisation="grid_search"</code> (the default), all values in
<code>Lambda</code> are visited. Alternatively, optimisation algorithms
implemented in <code><a href="nloptr.html#topic+nloptr">nloptr</a></code> can be used with
<code>optimisation="nloptr"</code>. By default, we use
<code>"algorithm"="NLOPT_GN_DIRECT_L"</code>, <code>"xtol_abs"=0.1</code>,
<code>"ftol_abs"=0.1</code> and <code>"maxeval"=Lambda_cardinal</code>. These values
can be changed by providing the argument <code>opts</code> (see
<code><a href="nloptr.html#topic+nloptr">nloptr</a></code>). For stability selection using penalised
regression, <code>optimisation="grid_search"</code> may be faster as it allows
for warm start.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_n_cores">n_cores</code></td>
<td>
<p>number of cores to use for parallel computing (see argument
<code>workers</code> in <code><a href="future.html#topic+multisession">multisession</a></code>). Using
<code>n_cores&gt;1</code> is only supported with <code>optimisation="grid_search"</code>.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_output_data">output_data</code></td>
<td>
<p>logical indicating if the input datasets <code>xdata</code> and
<code>ydata</code> should be included in the output.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_verbose">verbose</code></td>
<td>
<p>logical indicating if a loading bar and messages should be
printed.</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_beep">beep</code></td>
<td>
<p>sound indicating the end of the run. Possible values are:
<code>NULL</code> (no sound) or an integer between 1 and 11 (see argument
<code>sound</code> in <code><a href="beepr.html#topic+beep">beep</a></code>).</p>
</td></tr>
<tr><td><code id="VariableSelection_+3A_...">...</code></td>
<td>
<p>additional parameters passed to the functions provided in
<code>implementation</code> or <code>resampling</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In stability selection, a feature selection algorithm is fitted on
<code>K</code> subsamples (or bootstrap samples) of the data with different
parameters controlling the sparsity (<code>Lambda</code>). For a given (set of)
sparsity parameter(s), the proportion out of the <code>K</code> models in which
each feature is selected is calculated. Features with selection proportions
above a threshold pi are considered stably selected. The stability
selection model is controlled by the sparsity parameter(s) for the
underlying algorithm, and the threshold in selection proportion:
</p>
<p><code class="reqn">V_{\lambda, \pi} = \{ j: p_{\lambda}(j) \ge \pi \} </code>
</p>
<p>If argument <code>group_penalisation=FALSE</code>, &quot;feature&quot; refers to variable
(variable selection model). If argument <code>group_penalisation=TRUE</code>,
&quot;feature&quot; refers to group (group selection model). In this case, groups
need to be defined <em>a priori</em> and specified in argument
<code>group_x</code>.
</p>
<p>These parameters can be calibrated by maximisation of a stability score
(see <code><a href="#topic+ConsensusScore">ConsensusScore</a></code> if <code>n_cat=NULL</code> or
<code><a href="#topic+StabilityScore">StabilityScore</a></code> otherwise) calculated under the null
hypothesis of equiprobability of selection.
</p>
<p>It is strongly recommended to examine the calibration plot carefully to
check that the grids of parameters <code>Lambda</code> and <code>pi_list</code> do not
restrict the calibration to a region that would not include the global
maximum (see <code><a href="#topic+CalibrationPlot">CalibrationPlot</a></code>). In particular, the grid
<code>Lambda</code> may need to be extended when the maximum stability is
observed on the left or right edges of the calibration heatmap. In some
instances, multiple peaks of stability score can be observed. Simulation
studies suggest that the peak corresponding to the largest number of
selected features tend to give better selection performances. This is not
necessarily the highest peak (which is automatically retained by the
functions in this package). The user can decide to manually choose another
peak.
</p>
<p>To control the expected number of False Positives (Per Family Error Rate)
in the results, a threshold <code>PFER_thr</code> can be specified. The
optimisation problem is then constrained to sets of parameters that
generate models with an upper-bound in PFER below <code>PFER_thr</code> (see
Meinshausen and BÃ¼hlmann (2010) and Shah and Samworth (2013)).
</p>
<p>Possible resampling procedures include defining (i) <code>K</code> subsamples of
a proportion <code>tau</code> of the observations, (ii) <code>K</code> bootstrap
samples with the full sample size (obtained with replacement), and (iii)
<code>K/2</code> splits of the data in half for complementary pair stability
selection (see arguments <code>resampling</code> and <code>cpss</code>). In
complementary pair stability selection, a feature is considered selected at
a given resampling iteration if it is selected in the two complementary
subsamples.
</p>
<p>For categorical or time to event outcomes (argument <code>family</code> is
<code>"binomial"</code>, <code>"multinomial"</code> or <code>"cox"</code>), the proportions
of observations from each category in all subsamples or bootstrap samples
are the same as in the full sample.
</p>
<p>To ensure reproducibility of the results, the starting number of the random
number generator is set to <code>seed</code>.
</p>
<p>For parallelisation, stability selection with different sets of parameters
can be run on <code>n_cores</code> cores. Using <code>n_cores &gt; 1</code> creates a
<code><a href="future.html#topic+multisession">multisession</a></code>. Alternatively,
the function can be run manually with different <code>seed</code>s and all other
parameters equal. The results can then be combined using
<code><a href="#topic+Combine">Combine</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>variable_selection</code>. A list with: </p>
<table>
<tr><td><code>S</code></td>
<td>
<p>a
matrix of the best stability scores for different parameters controlling
the level of sparsity in the underlying algorithm.</p>
</td></tr> <tr><td><code>Lambda</code></td>
<td>
<p>a matrix
of parameters controlling the level of sparsity in the underlying
algorithm.</p>
</td></tr> <tr><td><code>Q</code></td>
<td>
<p>a matrix of the average number of selected features by
the underlying algorithm with different parameters controlling the level of
sparsity.</p>
</td></tr> <tr><td><code>Q_s</code></td>
<td>
<p>a matrix of the calibrated number of stably selected
features with different parameters controlling the level of sparsity.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>a matrix of calibrated thresholds in selection proportions for
different parameters controlling the level of sparsity in the underlying
algorithm.</p>
</td></tr> <tr><td><code>PFER</code></td>
<td>
<p>a matrix of upper-bounds in PFER of calibrated
stability selection models with different parameters controlling the level
of sparsity.</p>
</td></tr> <tr><td><code>FDP</code></td>
<td>
<p>a matrix of upper-bounds in FDP of calibrated
stability selection models with different parameters controlling the level
of sparsity.</p>
</td></tr> <tr><td><code>S_2d</code></td>
<td>
<p>a matrix of stability scores obtained with
different combinations of parameters. Columns correspond to different
thresholds in selection proportions.</p>
</td></tr> <tr><td><code>PFER_2d</code></td>
<td>
<p>a matrix of
upper-bounds in FDP obtained with different combinations of parameters.
Columns correspond to different thresholds in selection proportions.</p>
</td></tr>
<tr><td><code>FDP_2d</code></td>
<td>
<p>a matrix of upper-bounds in PFER obtained with different
combinations of parameters. Columns correspond to different thresholds in
selection proportions.</p>
</td></tr> <tr><td><code>selprop</code></td>
<td>
<p>a matrix of selection proportions.
Columns correspond to predictors from <code>xdata</code>.</p>
</td></tr> <tr><td><code>Beta</code></td>
<td>
<p>an array
of model coefficients. Columns correspond to predictors from <code>xdata</code>.
Indices along the third dimension correspond to different resampling
iterations. With multivariate outcomes, indices along the fourth dimension
correspond to outcome-specific coefficients.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>a list with
<code>type="variable_selection"</code> and values used for arguments
<code>implementation</code>, <code>family</code>, <code>resampling</code>, <code>cpss</code> and
<code>PFER_method</code>.</p>
</td></tr> <tr><td><code>params</code></td>
<td>
<p>a list with values used for arguments
<code>K</code>, <code>pi_list</code>, <code>tau</code>, <code>n_cat</code>, <code>pk</code>, <code>n</code>
(number of observations), <code>PFER_thr</code>, <code>FDP_thr</code> and <code>seed</code>.
The datasets <code>xdata</code> and <code>ydata</code> are also included if
<code>output_data=TRUE</code>.</p>
</td></tr></table>
<p> For all matrices and arrays returned, the rows
are ordered in the same way and correspond to parameter values stored in
<code>Lambda</code>.
</p>


<h3>References</h3>

<p>Bodinier B, Filippi S, NÃ¸st TH, Chiquet J, Chadeau-Hyam M (2023).
&ldquo;Automated calibration for stability selection in penalised regression and graphical models.&rdquo;
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em>, qlad058.
ISSN 0035-9254, <a href="https://doi.org/10.1093/jrsssc/qlad058">doi:10.1093/jrsssc/qlad058</a>, https://academic.oup.com/jrsssc/advance-article-pdf/doi/10.1093/jrsssc/qlad058/50878777/qlad058.pdf.
</p>
<p>Shah RD, Samworth RJ (2013).
&ldquo;Variable selection with error control: another look at stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>75</b>(1), 55-80.
<a href="https://doi.org/10.1111/j.1467-9868.2011.01034.x">doi:10.1111/j.1467-9868.2011.01034.x</a>.
</p>
<p>Meinshausen N, BÃ¼hlmann P (2010).
&ldquo;Stability selection.&rdquo;
<em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, <b>72</b>(4), 417-473.
<a href="https://doi.org/10.1111/j.1467-9868.2010.00740.x">doi:10.1111/j.1467-9868.2010.00740.x</a>.
</p>
<p>Tibshirani R (1996).
&ldquo;Regression Shrinkage and Selection via the Lasso.&rdquo;
<em>Journal of the Royal Statistical Society. Series B (Methodological)</em>, <b>58</b>(1), 267&ndash;288.
ISSN 00359246, <a href="http://www.jstor.org/stable/2346178">http://www.jstor.org/stable/2346178</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PenalisedRegression">PenalisedRegression</a></code>, <code><a href="#topic+SelectionAlgo">SelectionAlgo</a></code>,
<code><a href="#topic+LambdaGridRegression">LambdaGridRegression</a></code>, <code><a href="#topic+Resample">Resample</a></code>,
<code><a href="#topic+StabilityScore">StabilityScore</a></code> <code><a href="#topic+Refit">Refit</a></code>,
<code><a href="#topic+ExplanatoryPerformance">ExplanatoryPerformance</a></code>, <code><a href="#topic+Incremental">Incremental</a></code>,
</p>
<p>Other stability functions: 
<code><a href="#topic+BiSelection">BiSelection</a>()</code>,
<code><a href="#topic+Clustering">Clustering</a>()</code>,
<code><a href="#topic+GraphicalModel">GraphicalModel</a>()</code>,
<code><a href="#topic+StructuralModel">StructuralModel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
oldpar &lt;- par(no.readonly = TRUE)
par(mar = rep(7, 4))

# Linear regression
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian"
)

# Calibration plot
CalibrationPlot(stab)

# Extracting the results
summary(stab)
Stable(stab)
SelectionProportions(stab)
plot(stab)

# Using randomised LASSO
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian", penalisation = "randomised"
)
plot(stab)

# Using adaptive LASSO
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian", penalisation = "adaptive"
)
plot(stab)

# Using additional arguments from glmnet (e.g. penalty.factor)
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata, family = "gaussian",
  penalty.factor = c(rep(1, 45), rep(0, 5))
)
head(coef(stab))

# Using CART
if (requireNamespace("rpart", quietly = TRUE)) {
  stab &lt;- VariableSelection(
    xdata = simul$xdata, ydata = simul$ydata,
    implementation = CART,
    family = "gaussian",
  )
  plot(stab)
}

# Regression with multivariate outcomes
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 20, q = 3, family = "gaussian")
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "mgaussian"
)
summary(stab)

# Logistic regression
set.seed(1)
simul &lt;- SimulateRegression(n = 200, pk = 10, family = "binomial", ev_xy = 0.8)
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "binomial"
)
summary(stab)

# Sparse PCA (1 component, see BiSelection for more components)
if (requireNamespace("elasticnet", quietly = TRUE)) {
  set.seed(1)
  simul &lt;- SimulateComponents(pk = c(5, 3, 4))
  stab &lt;- VariableSelection(
    xdata = simul$data,
    Lambda = seq_len(ncol(simul$data) - 1),
    implementation = SparsePCA
  )
  CalibrationPlot(stab, xlab = "")
  summary(stab)
}

# Sparse PLS (1 outcome, 1 component, see BiSelection for more options)
if (requireNamespace("sgPLS", quietly = TRUE)) {
  set.seed(1)
  simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")
  stab &lt;- VariableSelection(
    xdata = simul$xdata, ydata = simul$ydata,
    Lambda = seq_len(ncol(simul$xdata) - 1),
    implementation = SparsePLS, family = "gaussian"
  )
  CalibrationPlot(stab, xlab = "")
  SelectedVariables(stab)
}

# Group PLS (1 outcome, 1 component, see BiSelection for more options)
if (requireNamespace("sgPLS", quietly = TRUE)) {
  stab &lt;- VariableSelection(
    xdata = simul$xdata, ydata = simul$ydata,
    Lambda = seq_len(5),
    group_x = c(5, 5, 10, 20, 10),
    group_penalisation = TRUE,
    implementation = GroupPLS, family = "gaussian"
  )
  CalibrationPlot(stab, xlab = "")
  SelectedVariables(stab)
}

# Example with more hyper-parameters: elastic net
set.seed(1)
simul &lt;- SimulateRegression(n = 100, pk = 50, family = "gaussian")
TuneElasticNet &lt;- function(xdata, ydata, family, alpha) {
  stab &lt;- VariableSelection(
    xdata = xdata, ydata = ydata,
    family = family, alpha = alpha, verbose = FALSE
  )
  return(max(stab$S, na.rm = TRUE))
}
myopt &lt;- optimise(TuneElasticNet,
  lower = 0.1, upper = 1, maximum = TRUE,
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian"
)
stab &lt;- VariableSelection(
  xdata = simul$xdata, ydata = simul$ydata,
  family = "gaussian", alpha = myopt$maximum
)
summary(stab)
enet &lt;- SelectedVariables(stab)

# Comparison with LASSO
stab &lt;- VariableSelection(xdata = simul$xdata, ydata = simul$ydata, family = "gaussian")
summary(stab)
lasso &lt;- SelectedVariables(stab)
table(lasso, enet)

# Example using an external function: group-LASSO with gglasso
if (requireNamespace("gglasso", quietly = TRUE)) {
  set.seed(1)
  simul &lt;- SimulateRegression(n = 200, pk = 20, family = "binomial")
  ManualGridGroupLasso &lt;- function(xdata, ydata, family, group_x, ...) {
    # Defining the grouping
    group &lt;- do.call(c, lapply(seq_len(length(group_x)), FUN = function(i) {
      rep(i, group_x[i])
    }))

    if (family == "binomial") {
      ytmp &lt;- ydata
      ytmp[ytmp == min(ytmp)] &lt;- -1
      ytmp[ytmp == max(ytmp)] &lt;- 1
      return(gglasso::gglasso(xdata, ytmp, loss = "logit", group = group, ...))
    } else {
      return(gglasso::gglasso(xdata, ydata, lambda = lambda, loss = "ls", group = group, ...))
    }
  }
  Lambda &lt;- LambdaGridRegression(
    xdata = simul$xdata, ydata = simul$ydata,
    family = "binomial", Lambda_cardinal = 20,
    implementation = ManualGridGroupLasso,
    group_x = rep(5, 4)
  )
  GroupLasso &lt;- function(xdata, ydata, Lambda, family, group_x, ...) {
    # Defining the grouping
    group &lt;- do.call(c, lapply(seq_len(length(group_x)), FUN = function(i) {
      rep(i, group_x[i])
    }))

    # Running the regression
    if (family == "binomial") {
      ytmp &lt;- ydata
      ytmp[ytmp == min(ytmp)] &lt;- -1
      ytmp[ytmp == max(ytmp)] &lt;- 1
      mymodel &lt;- gglasso::gglasso(xdata, ytmp, lambda = Lambda, loss = "logit", group = group, ...)
    }
    if (family == "gaussian") {
      mymodel &lt;- gglasso::gglasso(xdata, ydata, lambda = Lambda, loss = "ls", group = group, ...)
    }
    # Extracting and formatting the beta coefficients
    beta_full &lt;- t(as.matrix(mymodel$beta))
    beta_full &lt;- beta_full[, colnames(xdata)]

    selected &lt;- ifelse(beta_full != 0, yes = 1, no = 0)

    return(list(selected = selected, beta_full = beta_full))
  }
  stab &lt;- VariableSelection(
    xdata = simul$xdata, ydata = simul$ydata,
    implementation = GroupLasso, family = "binomial", Lambda = Lambda,
    group_x = rep(5, 4),
    group_penalisation = TRUE
  )
  summary(stab)
}

par(oldpar)


</code></pre>

<hr>
<h2 id='WeightBoxplot'>Stable attribute weights</h2><span id='topic+WeightBoxplot'></span>

<h3>Description</h3>

<p>Creates a boxplots of the distribution of (calibrated) median attribute
weights obtained from the COSA algorithm across the subsampling iterations.
See examples in <code><a href="#topic+Clustering">Clustering</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WeightBoxplot(
  stability,
  at = NULL,
  argmax_id = NULL,
  col = NULL,
  boxwex = 0.3,
  xlab = "",
  ylab = "Weight",
  cex.lab = 1.5,
  las = 3,
  frame = "F",
  add = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WeightBoxplot_+3A_stability">stability</code></td>
<td>
<p>output of <code><a href="#topic+Clustering">Clustering</a></code>.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_at">at</code></td>
<td>
<p>coordinates along the x-axis (more details in
<code><a href="graphics.html#topic+boxplot">boxplot</a></code>).</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_argmax_id">argmax_id</code></td>
<td>
<p>optional indices of hyper-parameters. If
<code>argmax_id=NULL</code>, the calibrated hyper-parameters are used.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_col">col</code></td>
<td>
<p>optional vector of colours.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_boxwex">boxwex</code></td>
<td>
<p>box width (more details in <code><a href="graphics.html#topic+boxplot">boxplot</a></code>).</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_xlab">xlab</code></td>
<td>
<p>label of the x-axis.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_ylab">ylab</code></td>
<td>
<p>label of the y-axis.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_cex.lab">cex.lab</code></td>
<td>
<p>font size for labels.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_las">las</code></td>
<td>
<p>orientation of labels on the x-axis (see
<code><a href="graphics.html#topic+par">par</a></code>).</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_frame">frame</code></td>
<td>
<p>logical indicating if the box around the plot should be drawn
(more details in <code><a href="graphics.html#topic+boxplot">boxplot</a></code>).</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_add">add</code></td>
<td>
<p>logical indicating if the boxplot should be added to the current
plot.</p>
</td></tr>
<tr><td><code id="WeightBoxplot_+3A_...">...</code></td>
<td>
<p>additional parameters passed to <code><a href="graphics.html#topic+boxplot">boxplot</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A boxplot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Clustering">Clustering</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
