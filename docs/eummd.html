<!DOCTYPE html><html><head><title>Help for package eummd</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {eummd}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#energydist'><p>Naive computation for Energy Distance</p></a></li>
<li><a href='#eummd'><p>euMMD: Efficient Univariate Maximum Mean Discrepancy</p></a></li>
<li><a href='#meammd'><p>MEA-MMD: Multivariate Efficient Approximate Maximum Mean Discrepancy</p></a></li>
<li><a href='#mediandiff'><p>Compute the median difference between pairs of values</p></a></li>
<li><a href='#medianheuristic'><p>Compute the median heuristic</p></a></li>
<li><a href='#mmd'><p>Naive computation for Maximum Mean Discrepancy</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Efficient Univariate Maximum Mean Discrepancy</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.9</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-05-18</td>
</tr>
<tr>
<td>Description:</td>
<td>Computes maximum mean discrepancy two-sample test for univariate data using the Laplacian kernel, as described in Bodenham and Kawahara (2023) &lt;<a href="https://doi.org/10.1007%2Fs11222-023-10271-x">doi:10.1007/s11222-023-10271-x</a>&gt;. The p-value is computed using permutations. Also includes implementation for computing the robust median difference statistic 'Q_n' from Croux and Rousseeuw (1992) &lt;<a href="https://doi.org/10.1007%2F978-3-662-26811-7_58">doi:10.1007/978-3-662-26811-7_58</a>&gt; based on Johnson and Mizoguchi (1978) &lt;<a href="https://doi.org/10.1137%2F0207013">doi:10.1137/0207013</a>&gt;. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0), Rcpp (&ge; 1.0.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), knitr, rmarkdown</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-05-18 17:06:25 UTC; dean</td>
</tr>
<tr>
<td>Author:</td>
<td>Dean Bodenham [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dean Bodenham &lt;deanbodenhampkgs@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-05-21 16:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='energydist'>Naive computation for Energy Distance</h2><span id='topic+energydist'></span>

<h3>Description</h3>

<p>Computes energy distance, and possibly a p-value.
Suitable for multivariate data. Naive approach, quadratic in number
of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>energydist(
  X,
  Y,
  pval = TRUE,
  numperm = 200,
  seednum = 0,
  alternative = c("greater", "two.sided"),
  allowzeropval = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="energydist_+3A_x">X</code></td>
<td>
<p>Matrix (or vector) of observations in first sample.</p>
</td></tr>
<tr><td><code id="energydist_+3A_y">Y</code></td>
<td>
<p>Matrix (or vector) of observations in second sample.</p>
</td></tr>
<tr><td><code id="energydist_+3A_pval">pval</code></td>
<td>
<p>Boolean for whether to compute p-value or not.</p>
</td></tr>
<tr><td><code id="energydist_+3A_numperm">numperm</code></td>
<td>
<p>Number of permutations. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="energydist_+3A_seednum">seednum</code></td>
<td>
<p>Seed number for generating permutations. Default is <code>0</code>,
which means seed is set randomly. For values larger than
<code>0</code>, results will be reproducible.</p>
</td></tr>
<tr><td><code id="energydist_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
which must be either <code>"greater"</code> (default) or
<code>"two.sided"</code>. In Gretton et al., the
MMD test statistic is specified so that if it is
significantly larger than zero, then the null hypothesis
that the two samples come from the same distribution
should be rejected. For this reason, <code>"greater"</code>
is recommended. The test will still work
in many cases with <code>"two.sided"</code> specified, but this
could lead to problems in certain cases.</p>
</td></tr>
<tr><td><code id="energydist_+3A_allowzeropval">allowzeropval</code></td>
<td>
<p>A boolean, specifying whether we will allow zero
p-values or not. Default is <code>FALSE</code>; then
a threshold of <code>0.5 / (numperm+1)</code> is used,
and if the computed p-value is less than this
threshold, it is then set to be this value.
this avoids the possibility of zero p-values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First checks number of columns (dimension) are equal.
Suppose matrix <code class="reqn">X</code> has <code class="reqn">n</code> rows and <code class="reqn">d</code> columns,
and matrix <code class="reqn">Y</code> has <code class="reqn">m</code> rows; checks that <code class="reqn">Y</code>
has <code class="reqn">d</code> columns (if not, then throws error).
Then flattens matrices to vectors (or, if <code class="reqn">d=1</code>, they are
already vectors.
Then calls C++ method. If the first sample has <code class="reqn">n</code>
<code class="reqn">d</code>-dimensional samples and the second sample has
<code class="reqn">m</code> <code class="reqn">d</code>-dimensional samples, then the algorithm
computes the statistic in <code class="reqn">O((n+m)^2)</code> time.
</p>
<p>Random seed is set for <code>std::mt19937</code> and <code>std::shuffle</code> in C++.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>

<dl>
<dt><code>pval</code></dt><dd><p>The p-value of the test, if it is
computed (<code>pval=TRUE</code>). </p>
</dd>
<dt><code>stat</code></dt><dd><p>The statistic of the test, which
is always computed. </p>
</dd>
</dl>



<h3>References</h3>

<p>Baringhaus L. and Franz C. (2004) &quot;On a new multivariate two-sample test.&quot;
Journal of multivariate analysis 88(1):190-206
</p>
<p>Szekely G. J. and Rizzo M. L. (2004) &quot;Testing for equal distributions in
high dimension.&quot; InterStat 5(16.10):1249-1272
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- matrix(c(1:12), ncol=2, byrow=TRUE)
Y &lt;- matrix(c(13:20), ncol=2, byrow=TRUE)
energydistList &lt;- energydist(X=X, Y=Y, pval=FALSE)

#computing p-value
energydistList &lt;- energydist(X=X, Y=Y)

#computing p-value
#using 1000 permutations and seed 1 for reproducibility.
energydistList &lt;- energydist(X=X, Y=Y, numperm=1000, seednum=1)


</code></pre>

<hr>
<h2 id='eummd'>euMMD: Efficient Univariate Maximum Mean Discrepancy</h2><span id='topic+eummd'></span>

<h3>Description</h3>

<p>Computes the maximum mean discrepancy statistic with the Laplacian kernel.
Suitable only for univariate data. Computing the statistic alone
for <code class="reqn">n</code> observations is <code class="reqn">O(n \log n)</code>, and computing the
p-value for <code class="reqn">L</code> permutations is <code class="reqn">O(n \log n + Ln)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eummd(
  x,
  y,
  beta = -0.1,
  pval = TRUE,
  numperm = 200,
  seednum = 0,
  alternative = c("greater", "two.sided"),
  allowzeropval = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eummd_+3A_x">x</code></td>
<td>
<p>Univariate vector of observations in first sample.</p>
</td></tr>
<tr><td><code id="eummd_+3A_y">y</code></td>
<td>
<p>Univariate vector of observations in second sample.</p>
</td></tr>
<tr><td><code id="eummd_+3A_beta">beta</code></td>
<td>
<p>kernel parameter. Must be positive; if not, computes
median heuristic in quadratic time. Default value
is <code>-0.1</code>, which will force median heuristic to be used.</p>
</td></tr>
<tr><td><code id="eummd_+3A_pval">pval</code></td>
<td>
<p>Boolean for whether to compute p-value or not.</p>
</td></tr>
<tr><td><code id="eummd_+3A_numperm">numperm</code></td>
<td>
<p>Number of permutations. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="eummd_+3A_seednum">seednum</code></td>
<td>
<p>Seed number for generating permutations. Default is <code>0</code>,
which means seed is set randomly. For values larger than
<code>0</code>, results will be reproducible.</p>
</td></tr>
<tr><td><code id="eummd_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
which must be either <code>"greater"</code> (default) or
<code>"two.sided"</code>. In Gretton et al., the
MMD test statistic is specified so that if it is
significantly larger than zero, then the null hypothesis
that the two samples come from the same distribution
should be rejected. For this reason, <code>"greater"</code>
is recommended. The test will still work
in many cases with <code>"two.sided"</code> specified, but this
could lead to problems in certain cases.</p>
</td></tr>
<tr><td><code id="eummd_+3A_allowzeropval">allowzeropval</code></td>
<td>
<p>A boolean, specifying whether we will allow zero
p-values or not. Default is <code>FALSE</code>; then
a threshold of <code>0.5 / (numperm+1)</code> is used,
and if the computed p-value is less than this
threshold, it is then set to be this value.
this avoids the possibility of zero p-values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the total number of observations in both samples is <code>n</code>,
first sort combined sample in <code class="reqn">O(n \log n)</code> before remaining
steps are linear in <code>n</code>.
</p>
<p>If <code>beta</code> is not a positive value,
median difference is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn"> m = \textnormal{median} \{ || x_i - x_j ||_1; \,\, i&gt;j, \,\, 
          i=1, 2,\dots, n+m,\,\,\textnormal{ and } j=1, 2,\dots, i-1 \}, </code>
</p>

<p>where <code class="reqn"> || x_i - x_j ||_1</code> is the 1-norm, and
so if the data are univariate then
</p>
<p style="text-align: center;"><code class="reqn"> || x_i - x_j ||_1 = |x_{i} - x_{j}|. </code>
</p>

<p>and finally median heuristic is <code>beta = 1/m</code>.
This can be computed in <code class="reqn">O(n \log n )</code> time
using the algorithms of Johnson and Mizoguchi (1978)
and Croux and Rousseuw (1992); see <code>mediandiff</code>
for references.
</p>
<p>The Laplacian kernel <code class="reqn">k</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn"> k(x,y) = \exp [ -\beta ||x - y||_1  ]. </code>
</p>

<p>The random seed is set for <code>std::mt19937</code> and <code>std::shuffle</code>
in C++.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>

<dl>
<dt><code>pval</code></dt><dd><p>The p-value of the test, if it is
computed (<code>pval=TRUE</code>). Otherwise,
it is set to <code>NA</code>.</p>
</dd>
<dt><code>stat</code></dt><dd><p>The statistic of the test, which
is always computed. </p>
</dd>
<dt><code>beta</code></dt><dd><p>The kernel parameter used in the test.
If <code>beta</code> was not initialised or
negative, this will be the median heuristic
value.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bodenham, D. A., and Kawahara, Y. (2023)
&quot;euMMD: efficiently computing the MMD two-sample test statistic for
univariate data.&quot; Statistics and Computing 33.5 (2023): 110.
</p>
<p>Croux, C. and Rousseeuw, P. J. (1992),
&quot;Time-Efficient Algorithms for Two Highly Robust Estimators of Scale&quot;
In Computational Statistics: Volume 1: Proceedings of the 10th
Symposium on Computational Statistics (pp. 411-428).
</p>
<p>Johnson, D.B., and Mizoguchi, T. (1978),
&quot;Selecting the Kth Element in X + Y and X_1 + X_2 + ... + X_m&quot;,
SIAM Journal of Computing, 7, 147-153.
</p>


<h3>See Also</h3>

<p><code>mediandiff</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(7.1, 1.2, 4.3, 0.4)
y &lt;- c(5.5, 2.6, 8.7)
#setting the kernel parameter to be 0.1; setting seed=1 for reproducibility
mmd_list &lt;- eummd(x, y, beta=0.1, seednum=1)

#now using median heuristic (default)
mmd_list &lt;- eummd(x, y, seednum=1)

#now not computing the p-value, only the statistic
mmd_list &lt;- eummd(x, y, pval=FALSE, seednum=1)

#now using a larger number of permutations 
mmd_list &lt;- eummd(x, y, numperm=1000, seednum=1)



</code></pre>

<hr>
<h2 id='meammd'>MEA-MMD: Multivariate Efficient Approximate Maximum Mean Discrepancy</h2><span id='topic+meammd'></span>

<h3>Description</h3>

<p>Computes maximum mean discrepancy statistics with Laplacian
or Gaussian kernel.
Suitable for multivariate data. Naive approach, quadratic in number
of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>meammd(
  X,
  Y,
  beta = -0.1,
  pval = TRUE,
  type = c("proj", "dist"),
  numproj = 20,
  nmethod = c(2, 1),
  distpval = c("Hommel", "Fisher"),
  numperm = 200,
  seednum = 0,
  alternative = c("greater", "two.sided"),
  allowzeropval = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meammd_+3A_x">X</code></td>
<td>
<p>Matrix (or vector) of observations in first sample.</p>
</td></tr>
<tr><td><code id="meammd_+3A_y">Y</code></td>
<td>
<p>Matrix (or vector) of observations in second sample.</p>
</td></tr>
<tr><td><code id="meammd_+3A_beta">beta</code></td>
<td>
<p>kernel parameter. Must be positive; if not, computes
median heuristic in quadratic time for each projection.
Default value
is <code>-0.1</code>, which will force median heuristic to be used.</p>
</td></tr>
<tr><td><code id="meammd_+3A_pval">pval</code></td>
<td>
<p>Boolean for whether to compute p-value or not.</p>
</td></tr>
<tr><td><code id="meammd_+3A_type">type</code></td>
<td>
<p>The type of projection used. Either <code>"proj"</code> for
random projections (default) or <code>"dist"</code> for interpoint
distances.</p>
</td></tr>
<tr><td><code id="meammd_+3A_numproj">numproj</code></td>
<td>
<p>Number of projections (only used if <code>type="proj"</code>).
Default is <code>20</code>.</p>
</td></tr>
<tr><td><code id="meammd_+3A_nmethod">nmethod</code></td>
<td>
<p>Norm used for interpoint distances, if <code>type="dist"</code>.
Needs to be either <code>2</code> (for two-norm, default) or
<code>1</code> (for one-norm).</p>
</td></tr>
<tr><td><code id="meammd_+3A_distpval">distpval</code></td>
<td>
<p>The p-value combination procedure if <code>type="dist"</code>.
Options are <code>"Hommel"</code> (default) or <code>"Fisher"</code>.
The Hommel method is preferred since the Type I error does
not seem to be controlled if the Fisher method is used.</p>
</td></tr>
<tr><td><code id="meammd_+3A_numperm">numperm</code></td>
<td>
<p>Number of permutations. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="meammd_+3A_seednum">seednum</code></td>
<td>
<p>Seed number for generating permutations. Default is <code>0</code>,
which means seed is set randomly. For values larger than
<code>0</code>, results will be reproducible.</p>
</td></tr>
<tr><td><code id="meammd_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
which must be either <code>"greater"</code> (default) or
<code>"two.sided"</code>. In Gretton et al., the
MMD test statistic is specified so that if it is
significantly larger than zero, then the null hypothesis
that the two samples come from the same distribution
should be rejected. For this reason, <code>"greater"</code>
is recommended. The test will still work
in many cases with <code>"two.sided"</code> specified, but this
could lead to problems in certain cases.</p>
</td></tr>
<tr><td><code id="meammd_+3A_allowzeropval">allowzeropval</code></td>
<td>
<p>A boolean, specifying whether we will allow zero
p-values or not. Default is <code>FALSE</code>; then
a threshold of <code>0.5 / (numperm+1)</code> is used,
and if the computed p-value is less than this
threshold, it is then set to be this value.
this avoids the possibility of zero p-values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following elements:
</p>

<dl>
<dt><code>pval</code></dt><dd><p>The p-value of the test, if it is
computed (<code>pval=TRUE</code>). Otherwise,
it is set to <code>NA</code>.</p>
</dd>
<dt><code>stat</code></dt><dd><p>The statistic of the test, which
is only returned when <code>type="proj"</code>,
otherwise it is set to <code>NA</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bodenham, D. A., and Kawahara, Y. (2023)
&quot;euMMD: efficiently computing the MMD two-sample test statistic for
univariate data.&quot; Statistics and Computing 33.5 (2023): 110.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(c(1:12), ncol=2, byrow=TRUE)
Y &lt;- matrix(c(13:20), ncol=2, byrow=TRUE)
# using the random projections method
mmdList &lt;- meammd(X=X, Y=Y, pval=TRUE, type="proj", numproj=50)

# using the method were distances are computed to the various points 
mmdList &lt;- meammd(X=X, Y=Y, pval=TRUE, type="dist")


</code></pre>

<hr>
<h2 id='mediandiff'>Compute the median difference between pairs of values</h2><span id='topic+mediandiff'></span>

<h3>Description</h3>

<p>Compute the median of all differences between distinct
pairs in vectors or matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mediandiff(X, Y = NULL, kernel = c("Laplacian", "Gaussian"), fast = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mediandiff_+3A_x">X</code></td>
<td>
<p>Numeric vector or matrix of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="mediandiff_+3A_y">Y</code></td>
<td>
<p>Numeric vector or matrix of length <code>m</code>, or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mediandiff_+3A_kernel">kernel</code></td>
<td>
<p>String, either <code>"Laplacian"</code> or <code>"Gaussian"</code>.</p>
</td></tr>
<tr><td><code id="mediandiff_+3A_fast">fast</code></td>
<td>
<p>Boolean; if <code>TRUE</code> will run <code class="reqn">O(N \log N)</code> algorithm,
where <code>N = n + m</code>,
but if <code>FALSE</code> (default)
will run naive <code class="reqn">O(N^2 \log N)</code> algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The median difference is defined as follows:
</p>
<p><code class="reqn">Z</code> is the combined <code class="reqn">X</code> and <code class="reqn">Y</code> values into a single vector
or matrix.
Number of columns is the dimension, and these need to be equal
for <code class="reqn">X</code> and <code class="reqn">Y</code>. Then, if the Laplacian kernel is used,
</p>
<p style="text-align: center;"><code class="reqn"> m = \textnormal{median} \{ || x_i - x_j ||_1; \,\, i&gt;j, \,\, 
        i=1, 2,\dots, n+m,\,\,\textnormal{ and } j=1, 2,\dots, i-1 \}, </code>
</p>

<p>where <code class="reqn"> || z_i - z_j ||_1</code> is the 1-norm, and so if the data
are <code>d</code>-dimensional then
</p>
<p style="text-align: center;"><code class="reqn"> || z_i - z_j ||_1 = \sum_{k=1}^{d} |z_{i,k} - z_{j,k}|. </code>
</p>

<p>If the Gaussian kernel is specified, then the square of the two-norm is
used.
</p>
<p>The median heuristic is defined as <code>beta = 1/m</code>.
</p>
<p>Naive method will compute all distinct pairs, of which there are
<code class="reqn">N(N+1)/2</code> differences. These are then sorted using
a <code class="reqn">O(N \log N)</code> algorithm, so overall <code class="reqn">O(N^2 \log N)</code>.
</p>
<p>The fast method is <code class="reqn">O(N \log N)</code> is from Croux and Rousseeuw (1992),
which is based on Johnson and Mizoguchi (1978).
</p>


<h3>Value</h3>

<p>A scalar, the median of all pairwise differences.
</p>


<h3>References</h3>

<p>Croux, C. and Rousseeuw, P. J. (1992),
&quot;Time-Efficient Algorithms for Two Highly Robust Estimators of Scale&quot;
In Computational Statistics: Volume 1: Proceedings of the 10th
Symposium on Computational Statistics (pp. 411-428).
</p>
<p>Johnson, D.B., and Mizoguchi, T. (1978),
&quot;Selecting the Kth Element in X + Y and X_1 + X_2 + ... + X_m&quot;,
SIAM Journal of Computing, 7, 147-153.
</p>


<h3>See Also</h3>

<p><code>medianheuristic</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- c(7.1, 1.2, 4.3, 0.4)
Y &lt;- c(5.5, 2.6, 8.7)
#using fast method, Laplacian kernel, loglinear in number of observations
md &lt;- mediandiff(X, Y, fast=TRUE)

#using fast method, Gaussian kernel, loglinear in number of observations
md &lt;- mediandiff(X, Y, fast=TRUE, kernel="Gaussian")

#using naive method (default), with Laplacian kernel
md &lt;- mediandiff(X, Y)

</code></pre>

<hr>
<h2 id='medianheuristic'>Compute the median heuristic</h2><span id='topic+medianheuristic'></span>

<h3>Description</h3>

<p>Computes the inverse of the median difference of
all distinct pairs in vectors or matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>medianheuristic(X, Y = NULL, kernel = c("Laplacian", "Gaussian"), fast = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="medianheuristic_+3A_x">X</code></td>
<td>
<p>Numeric vector or matrix of length <code>n</code>.</p>
</td></tr>
<tr><td><code id="medianheuristic_+3A_y">Y</code></td>
<td>
<p>Numeric vector or matrix of length <code>m</code>, or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="medianheuristic_+3A_kernel">kernel</code></td>
<td>
<p>String, either <code>"Laplacian"</code> or <code>"Gaussian"</code>.</p>
</td></tr>
<tr><td><code id="medianheuristic_+3A_fast">fast</code></td>
<td>
<p>Boolean; if <code>TRUE</code> will run <code>O(N log N)</code> algorithm,
where <code>N = n + m</code>,
but if <code>FALSE</code> will run naive <code>O(N^2 log(N))</code> algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Computes median of differences <code>md</code> using <code>mediandiff</code>
and then returns <code>1 / md</code>. See <code>mediandiff</code> for details.
</p>


<h3>Value</h3>

<p>A scalar, the inverse of the median of all pairwise differences.
</p>


<h3>See Also</h3>

<p><code>mediandiff</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- c(7.1, 1.2, 4.3, 0.4)
Y &lt;- c(5.5, 2.6, 8.7)
mh &lt;- medianheuristic(X, Y, kernel="Laplacian", fast=TRUE)

#using fast method, Gaussian kernel, loglinear in number of observations
mh &lt;- medianheuristic(X, Y, fast=TRUE, kernel="Gaussian")

#using naive method (default), with Laplacian kernel
mh &lt;- medianheuristic(X, Y)


</code></pre>

<hr>
<h2 id='mmd'>Naive computation for Maximum Mean Discrepancy</h2><span id='topic+mmd'></span>

<h3>Description</h3>

<p>Computes maximum mean discrepancy statistics with Laplacian
or Gaussian kernel.
Suitable for multivariate data. Naive approach, quadratic in number
of observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmd(
  X,
  Y,
  beta = -0.1,
  pval = TRUE,
  kernel = c("Laplacian", "Gaussian"),
  numperm = 200,
  seednum = 0,
  alternative = c("greater", "two.sided"),
  allowzeropval = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmd_+3A_x">X</code></td>
<td>
<p>Matrix (or vector) of observations in first sample.</p>
</td></tr>
<tr><td><code id="mmd_+3A_y">Y</code></td>
<td>
<p>Matrix (or vector) of observations in second sample.</p>
</td></tr>
<tr><td><code id="mmd_+3A_beta">beta</code></td>
<td>
<p>kernel parameter. Must be positive; if not, computes
median heuristic in quadratic time. Default value
is <code>-0.1</code>, which will force median heuristic to be used.</p>
</td></tr>
<tr><td><code id="mmd_+3A_pval">pval</code></td>
<td>
<p>Boolean for whether to compute p-value or not.</p>
</td></tr>
<tr><td><code id="mmd_+3A_kernel">kernel</code></td>
<td>
<p>String, either <code>"Laplacian"</code> or <code>"Gaussian"</code>.
Default is <code>"Laplacian"</code>.</p>
</td></tr>
<tr><td><code id="mmd_+3A_numperm">numperm</code></td>
<td>
<p>Number of permutations. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="mmd_+3A_seednum">seednum</code></td>
<td>
<p>Seed number for generating permutations. Default is <code>0</code>,
which means seed is set randomly. For values larger than
<code>0</code>, results will be reproducible.</p>
</td></tr>
<tr><td><code id="mmd_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
which must be either <code>"greater"</code> (default) or
<code>"two.sided"</code>. In Gretton et al., the
MMD test statistic is specified so that if it is
significantly larger than zero, then the null hypothesis
that the two samples come from the same distribution
should be rejected. For this reason, <code>"greater"</code>
is recommended. The test will still work
in many cases with <code>"two.sided"</code> specified, but this
could lead to problems in certain cases.</p>
</td></tr>
<tr><td><code id="mmd_+3A_allowzeropval">allowzeropval</code></td>
<td>
<p>A boolean, specifying whether we will allow zero
p-values or not. Default is <code>FALSE</code>; then
a threshold of <code>0.5 / (numperm+1)</code> is used,
and if the computed p-value is less than this
threshold, it is then set to be this value.
this avoids the possibility of zero p-values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First checks number of columns (dimension) are equal.
Suppose matrix <code class="reqn">X</code> has <code class="reqn">n</code> rows and <code class="reqn">d</code> columns,
and matrix <code class="reqn">Y</code> has <code class="reqn">m</code> rows; checks that <code class="reqn">Y</code>
has <code class="reqn">d</code> columns (if not, then throws error).
Then flattens matrices to vectors (or, if <code class="reqn">d=1</code>, they are
already vectors.
Then calls C++ method. If the first sample has <code class="reqn">n</code>
<code class="reqn">d</code>-dimensional samples and the second sample has
<code class="reqn">m</code> <code class="reqn">d</code>-dimensional samples, then the algorithm
computes the statistic in <code class="reqn">O((n+m)^2)</code> time.
</p>
<p>Median difference is as follows:
</p>
<p style="text-align: center;"><code class="reqn"> m = \textnormal{median} \{ || x_i - x_j ||_1; \,\, i&gt;j, \,\, 
        i=1, 2,\dots, n+m,\,\,\textnormal{ and } j=1, 2,\dots, i-1 \}, </code>
</p>

<p>where <code class="reqn"> || x_i - x_j ||_1</code> is the 1-norm, and so if the data
are <code class="reqn">d</code>-dimensional then
</p>
<p style="text-align: center;"><code class="reqn"> || x_i - x_j ||_1 = \sum_{k=1}^{d} |x_{i,k} - x_{j,k}|, </code>
</p>

<p>and finally median heuristic is <code>beta = 1/m</code>.
This can be computed in <code class="reqn">O( (n+m)^2 )</code> time.
</p>
<p>The Laplacian kernel <code class="reqn">k</code> is defined as
</p>
<p style="text-align: center;"><code class="reqn"> k(x,y) = \exp( -\beta || x_i - x_j ||_1 ). </code>
</p>

<p>Random seed is set for <code>std::mt19937</code> and <code>std::shuffle</code> in C++.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>

<dl>
<dt><code>pval</code></dt><dd><p>The p-value of the test, if it is
computed (<code>pval=TRUE</code>). </p>
</dd>
<dt><code>stat</code></dt><dd><p>The statistic of the test, which
is always computed. </p>
</dd>
<dt><code>beta</code></dt><dd><p>The kernel parameter used in the test.
If <code>beta</code> was not initialised or
negative, this will be the median heuristic
value.</p>
</dd>
</dl>



<h3>References</h3>

<p>Gretton, A., Borgwardt, K. M., Rasch M. J., Schölkopf, B. and Smola, A.
(2012) &quot;A kernel two-sample test.&quot; The Journal of Machine Learning Research
13, no. 1, 723-773.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
X &lt;- matrix(c(1:12), ncol=2, byrow=TRUE)
Y &lt;- matrix(c(13:20), ncol=2, byrow=TRUE)
mmdList &lt;- mmd(X=X, Y=Y, beta=0.1, pval=FALSE)

#using median heuristic
mmdList &lt;- mmd(X=X, Y=Y, pval=FALSE)

#using median heuristic and computing p-value
mmdList &lt;- mmd(X=X, Y=Y)

#using median heuristic and computing p-value
#using 1000 permutations and seed 1 for reproducibility.
mmdList &lt;- mmd(X=X, Y=Y, numperm=1000, seednum=1)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
