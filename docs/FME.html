<!DOCTYPE html><html lang="en"><head><title>Help for package FME</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {FME}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#FME-package'>
<p>A Flexible Modelling Environment for Inverse Modelling, Sensitivity,</p>
Identifiability, Monte Carlo Analysis.</a></li>
<li><a href='#collin'>
<p>Estimates the Collinearity of Parameter Sets</p></a></li>
<li><a href='#cross2long'>
<p>Convert a dataset in wide (crosstab) format to long (database) format</p></a></li>
<li><a href='#gaussianWeights'>
<p>A kernel average smoother function to weigh residuals according to a Gaussian</p>
density function
</p>
<p>This function is still experimental...  use with care</p></a></li>
<li><a href='#Grid'>
<p>Grid Distribution</p></a></li>
<li><a href='#Latinhyper'>
<p>Latin Hypercube Sampling</p></a></li>
<li><a href='#modCost'>
<p>Calculates the Discrepancy of a Model Solution with Observations</p></a></li>
<li><a href='#modCRL'>
<p>Monte Carlo Analysis</p></a></li>
<li><a href='#modFit'>
<p>Constrained Fitting of a Model to Data</p></a></li>
<li><a href='#modMCMC'>
<p>Constrained Markov Chain Monte Carlo</p></a></li>
<li><a href='#Norm'>
<p>Normal Random Distribution</p></a></li>
<li><a href='#obsplot'>
<p>Plot Method for observed data</p></a></li>
<li><a href='#pseudoOptim'><p>Pseudo-random Search Optimisation Algorithm of Price (1977)</p></a></li>
<li><a href='#sensFun'>
<p>Local Sensitivity Analysis</p></a></li>
<li><a href='#sensRange'>
<p>Sensitivity Ranges of a Timeseries or 1-D Variables</p></a></li>
<li><a href='#Unif'>
<p>Uniform Random Distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.3.6.3</td>
</tr>
<tr>
<td>Title:</td>
<td>A Flexible Modelling Environment for Inverse Modelling,
Sensitivity, Identifiability and Monte Carlo Analysis</td>
</tr>
<tr>
<td>Author:</td>
<td>Karline Soetaert <a href="https://orcid.org/0000-0003-4603-7100"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Thomas Petzoldt <a href="https://orcid.org/0000-0002-4951-6468"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.6), deSolve, rootSolve, coda</td>
</tr>
<tr>
<td>Imports:</td>
<td>minpack.lm, MASS, graphics, grDevices, stats, utils, minqa</td>
</tr>
<tr>
<td>Suggests:</td>
<td>diagram</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides functions to help in fitting models to data, to
  perform Monte Carlo, sensitivity and identifiability analysis. It is
  intended to work with models be written as a set of differential
  equations that are solved either by an integration routine from
  package 'deSolve', or a steady-state solver from package
  'rootSolve'. However, the methods can also be used with other types of
  functions.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://fme.r-forge.r-project.org/">http://fme.r-forge.r-project.org/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-01 16:00:46 UTC; thpe</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-05 15:03:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='FME-package'>
A Flexible Modelling Environment for Inverse Modelling, Sensitivity,
Identifiability, Monte Carlo Analysis.
</h2><span id='topic+FME-package'></span><span id='topic+FME'></span>

<h3>Description</h3>

<p>R-package FME contains functions to run complex applications of models
that produce output as a function of input parameters.
</p>
<p>Although it was created to be used with models consisting of ordinary
differential equations (ODE), partial differential equations (PDE) or
differential algebraic equations (DAE), it can work with other models.
</p>
<p>It contains:
</p>

<ul>
<li><p> Functions to allow fitting of the model to data.
</p>
<p>Function <code>modCost</code> estimates the (weighted) residuals between
model output and data, variable and model costs.
</p>
<p>Function <code>modFit</code> uses the output of <code>modCost</code> to find
the best-fit parameters. It provides a wrapper around <span class="rlang"><b>R</b></span>'s
built-in minimisation routines (<code>optim</code>, <code>nlm</code>,
<code>nlminb</code>) and <code>nls.lm</code> from package <code>minpack.lm</code>.
</p>
<p>Package FME also includes an implementation of the pseudo-random
search algorithm (function <code><a href="#topic+pseudoOptim">pseudoOptim</a></code>).
</p>
</li>
<li><p> Function <code>sensFun</code> estimates the sensitivity functions of
selected output variables as a function of model parameters. This
is the basis of uni-variate, bi-variate and multi-variate
sensitivity analysis.
</p>
</li>
<li><p> Function <code>collin</code> uses as input the sensitivity functions
and estimates the &quot;collinearity&quot; index for all possible parameter
sets.  This multivariate sensitivity estimate measures approximate
linear dependence and is useful to derive which parameter sets are
identifiable given the data set.
</p>
</li>
<li><p> Function <code>sensRange</code> produces 'envelopes' around the
sensitivity variables, consisting of a time series or a
1-dimensional set, as a function of the sensitivity parameters.
It produces &quot;envelopes&quot; around the variables.
</p>
</li>
<li><p> Function <code>modCRL</code> calculates the values of single
variables as a function of the sensitivity parameters. This
function can be used to run simple &quot;what-if&quot; scenarios
</p>
</li>
<li><p> Function <code>modMCMC</code> runs a Markov chain Monte Carlo
(Bayesian analysis). It implements the delayed rejection -
adaptive Metropolis (DRAM) algorithm.
</p>
</li>
<li><p> FME also contains functions to generate multiple parameter
values arranged according to a grid (<code>Grid</code>) multinormal
(<code>Norm</code>) or uniform (<code>Unif</code>) design, and a latin
hypercube sampling (<code>Latinhyper</code>) function </p>
</li></ul>



<h3>Details</h3>

<p>bug corrections:
</p>

<ul>
<li><p> version 1.3.6, sensFun:  corrected calculation of L2 norm 
(now consistent with help page),
</p>
</li>
<li><p> version 1.3,  modCost: minlogp was not correctly estimated 
if more than one observed variable (used the wrong sd).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Karline Soetaert
</p>
<p>Thomas Petzoldt
</p>


<h3>References</h3>

<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## show examples (see respective help pages for details)
example(modCost)
example(sensFun)
example(modMCMC)
example(modCRL)


## open the directory with documents
browseURL(paste(system.file(package = "FME"), "/doc", sep = ""))

## open the directory with examples
browseURL(paste(system.file(package = "FME"), "/doc/examples", sep = ""))

## the vignettes
vignette("FME")
vignette("FMEdyna")
vignette("FMEsteady")
vignette("FMEother")
vignette("FMEmcmc")

edit(vignette("FME"))
edit(vignette("FMEdyna"))
edit(vignette("FMEsteady"))
edit(vignette("FMEother"))
edit(vignette("FMEmcmc"))


## End(Not run)
</code></pre>

<hr>
<h2 id='collin'>
Estimates the Collinearity of Parameter Sets
</h2><span id='topic+collin'></span><span id='topic+plot.collin'></span><span id='topic+print.collin'></span>

<h3>Description</h3>

<p>Based on the sensitivity functions of model variables to a selection
of parameters, calculates the &quot;identifiability&quot; of sets of parameter.
</p>
<p>The sensitivity functions are a matrix whose (i,j)-th element contains
</p>
<p style="text-align: center;"><code class="reqn">\frac{\partial y_i}{\partial \Theta _j}\cdot \frac{\Delta
  \Theta _j} {\Delta y_i}</code>
</p>
<p> and where
<code class="reqn">y_i</code> is an output variable, at a certain (time) instance, i,
<code class="reqn">\Delta y_i</code> is the scaling of variable
<code class="reqn">y_i</code>, <code class="reqn">\Delta \Theta_j</code> is the scaling of
parameter <code class="reqn">\Theta_j</code>.
</p>
<p>Function <code>collin</code> estimates the collinearity, or identifiability of all
parameter sets or of one parameter set.
</p>
<p>As a rule of thumb, a collinearity value less than about 20 is
&quot;identifiable&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collin(sensfun, parset = NULL, N = NULL, which = NULL, maxcomb = 5000)

## S3 method for class 'collin'
print(x, ...)

## S3 method for class 'collin'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="collin_+3A_sensfun">sensfun</code></td>
<td>
<p>model sensitivity functions as estimated by <code>SensFun</code>.
</p>
</td></tr>
<tr><td><code id="collin_+3A_parset">parset</code></td>
<td>
<p>one selected parameter combination, a vector with their names
or with the indices to the parameters.
</p>
</td></tr>
<tr><td><code id="collin_+3A_n">N</code></td>
<td>
<p>the number of parameters in the set; if <code>NULL</code> then all
combinations will be tried. Ignored if <code>parset</code> is not <code>NULL</code>.
</p>
</td></tr>
<tr><td><code id="collin_+3A_which">which</code></td>
<td>
<p>the name or the index to the observed variables that should be
used. Default = all observed variables.
</p>
</td></tr>
<tr><td><code id="collin_+3A_maxcomb">maxcomb</code></td>
<td>
<p>the maximal number of combinations that can be tested.
If too large, this may produce a huge output. The number of combinations of 
n parameters out of a total of p parameters is <code>choose(p, n)</code>.
</p>
</td></tr>
<tr><td><code id="collin_+3A_x">x</code></td>
<td>
<p>an object of class <code>collin</code>.
</p>
</td></tr>
<tr><td><code id="collin_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The collinearity is a measure of approximate linear dependence between
sets of parameters. The higher its value, the more the parameters are
related.  With &quot;related&quot; is meant that several paraemter combinations
may produce similar values of the output variables.
</p>


<h3>Value</h3>

<p>a data.frame of class <code>collin</code> with one row for each parameter
combination (parameters as in <code>sensfun</code>).
</p>
<p>Each row contains:
</p>
<table role = "presentation">
<tr><td><code>...</code></td>
<td>
<p>for each parameter whether it is present (1) or absent (0)
in the set,</p>
</td></tr>
<tr><td><code>N</code></td>
<td>
<p>the number of parameters in the set,</p>
</td></tr>
<tr><td><code>collinearity</code></td>
<td>
<p>the collinearity value.</p>
</td></tr>
</table>
<p>The data.frame returned by <code>collin</code> has methods for the generic
functions <code><a href="base.html#topic+print">print</a></code> and <code><a href="base.html#topic+plot">plot</a></code>.
</p>


<h3>Note</h3>

<p>It is possible to use <code>collin</code> for selecting parameter sets that
can be fine-tuned based on a data set.  Thus it is a powerful
technique to make model calibration routines more robust, because
calibration routines often fail when parameters are strongly related.
</p>
<p>In general, when the collinearity index exceeds 20, the linear
dependence is assumed to be critical (i.e. it will not be possible or
easy to estimate all the parameters in the combination together).
</p>
<p>The procedure is explained in Omlin et al. (2001).
</p>
<p>1. First the function <code>collin</code> is used to test how far a dataset
can be used for estimating certain (combinations of) parameters.
After selection of an 'identifiable parameter set' (which has a low
&quot;collinearity&quot;) they are fine-tuned by calibration.
</p>
<p>2. As the sensitivity analysis is a <em>local</em> analysis (i.e. its
outcome depends on the current values of the model parameters) and
the fitting routine is used to estimate the best values of the
parameters, this is an iterative procedure.  This means that
identifiable parameters are determined, fitted to the data, then a
newly identifiable parameter set is determined, fitted, etcetera
until convergenc is reached.
</p>
<p>See the paper by Omlin et al. (2001) for more information.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>References</h3>

<p>Brun, R., Reichert, P. and Kunsch, H. R., 2001.
Practical Identifiability Analysis of Large Environmental Simulation Models.
Water Resour. Res. 37(4): 1015&ndash;1030.
</p>
<p>Omlin, M., Brun, R. and Reichert, P., 2001.
Biogeochemical Model of Lake Zurich: Sensitivity, Identifiability and
Uncertainty Analysis. Ecol. Modell. 141: 105&ndash;123.
</p>
<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## =======================================================================
## Test collinearity values
## =======================================================================

## linearly related set...  =&gt; Infinity
collin(cbind(1:5, 2*(1:5)))

## unrelated set            =&gt; 1
MM &lt;- matrix(nr = 4, nc = 2, byrow = TRUE,
  data = c(-0.400, -0.374, 0.255, 0.797, 0.690, -0.472, -0.546,  0.049))

collin(MM)

## =======================================================================
## Bacterial model as in Soetaert and Herman, 2009
## =======================================================================

pars &lt;- list(gmax = 0.5,eff = 0.5,
             ks = 0.5, rB = 0.01, dB = 0.01)

solveBact &lt;- function(pars) {
  derivs &lt;- function(t, state, pars) {   # returns rate of change
    with (as.list(c(state, pars)), {
      dBact &lt;-  gmax*eff*Sub/(Sub + ks)*Bact - dB*Bact - rB*Bact
      dSub  &lt;- -gmax    *Sub/(Sub + ks)*Bact + dB*Bact
      return(list(c(dBact, dSub)))
    })
  }
  state   &lt;- c(Bact = 0.1, Sub = 100)
  tout    &lt;- seq(0, 50, by = 0.5)
  ## ode solves the model by integration...
  return(as.data.frame(ode(y = state, times = tout, func = derivs,
    parms = pars)))
}

out &lt;- solveBact(pars)

## We wish to estimate parameters gmax and eff by fitting the model to
## these data:
Data &lt;- matrix(nc = 2, byrow = TRUE, data =
  c(  2,  0.14,  4,  0.2,    6,  0.38,  8,  0.42,
     10,  0.6,  12,  0.107, 14,  1.3,  16,  2.0,
     18,  3.0,  20,  4.5,   22,  6.15, 24,  11,
     26, 13.8,  28, 20.0,   30,  31 ,  35, 65, 40, 61)
)
colnames(Data) &lt;- c("time","Bact")
head(Data)

Data2 &lt;- matrix(c(2, 100, 20, 93, 30, 55, 50, 0), ncol = 2, byrow = TRUE)
colnames(Data2) &lt;- c("time", "Sub")


## Objective function to minimise
Objective &lt;- function (x) {                  # Model cost
 pars[] &lt;- x
 out   &lt;- solveBact(x)
 Cost  &lt;- modCost(obs = Data2, model = out)  # observed data in 2 data.frames
 return(modCost(obs = Data, model = out, cost = Cost))
}

## 1. Estimate sensitivity functions - all parameters
sF &lt;- sensFun(func = Objective, parms = pars, varscale = 1)

## 2. Estimate the collinearity
Coll &lt;- collin(sF)

## The larger the collinearity, the less identifiable the data set
Coll

plot(Coll, log = "y")

## 20 = magical number above which there are identifiability problems
abline(h = 20, col = "red")

## select "identifiable" sets with 4 parameters
Coll [Coll[,"collinearity"] &lt; 20 &amp; Coll[,"N"]==4,]

## collinearity of one selected parameter set
collin(sF, c(1, 3, 5))
collin(sF, 1:5)

collin(sF, c("gmax", "eff"))
## collinearity of all combinations of 3 parameters
collin(sF, N = 3)

## The collinearity depends on the value of the parameters:
P      &lt;- pars
P[1:2] &lt;- 1  # was: 0.5
collin(sensFun(Objective, P, varscale = 1))

</code></pre>

<hr>
<h2 id='cross2long'>
Convert a dataset in wide (crosstab) format to long (database) format
</h2><span id='topic+cross2long'></span>

<h3>Description</h3>

<p>Rearranges a data frame in cross tab format by putting all relevant columns below
each other, replicating the independent variable and, if necessary, other specified
columns. Optionally, an err column is added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cross2long( data, x, select = NULL, replicate = NULL, 
            error = FALSE,  na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cross2long_+3A_data">data</code></td>
<td>
<p>a data frame (or matrix) with crosstab layout
</p>
</td></tr>
<tr><td><code id="cross2long_+3A_x">x</code></td>
<td>
<p>name of the independent variable to be replicated
</p>
</td></tr>
<tr><td><code id="cross2long_+3A_select">select</code></td>
<td>
<p>a vector of column names to be included (see details).
All columns are included if not specified.
</p>
</td></tr>
<tr><td><code id="cross2long_+3A_replicate">replicate</code></td>
<td>
<p>a vector of names of variables (apart from the
independent variable that have to be replicated for every included
column (e.g. experimental treatment specification).
</p>
</td></tr>
<tr><td><code id="cross2long_+3A_error">error</code></td>
<td>
<p>boolean indicating whether the final dataset in long format
should contain an extra column for error values (cf. <a href="#topic+modCost">modCost</a>);
here filled with 1's.
</p>
</td></tr>
<tr><td><code id="cross2long_+3A_na.rm">na.rm</code></td>
<td>
<p>whether or not to remove the <code>NA</code>s.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The original data frame is converted from a wide (crosstab) layout (one
variable per column) to a long (database) layout (all variable value in
one column).
</p>
<p>As an example of both formats consider the data, called <code>Dat</code> consisting
of two observed variables, called &quot;Obs1&quot; and &quot;Obs2&quot;, both containing two
observations, at time 1 and 2:
</p>

<table>
<tr>
 <td style="text-align: left;">
  name    </td><td style="text-align: left;"> time   </td><td style="text-align: left;">   val </td><td style="text-align: left;"> err </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs1    </td><td style="text-align: left;"> 1      </td><td style="text-align: left;">   50  </td><td style="text-align: left;"> 5  </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs1    </td><td style="text-align: left;"> 2      </td><td style="text-align: left;">  150  </td><td style="text-align: left;"> 15  </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs2    </td><td style="text-align: left;"> 1      </td><td style="text-align: left;">  1    </td><td style="text-align: left;"> 0.1  </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs2    </td><td style="text-align: left;"> 2      </td><td style="text-align: left;">  2    </td><td style="text-align: left;"> 0.2  </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>for the long format and
</p>

<table>
<tr>
 <td style="text-align: left;">
   time   </td><td style="text-align: left;">   Obs1 </td><td style="text-align: left;"> Obs2 </td>
</tr>
<tr>
 <td style="text-align: left;">
   1      </td><td style="text-align: left;">  50    </td><td style="text-align: left;"> 1 </td>
</tr>
<tr>
 <td style="text-align: left;">
   2      </td><td style="text-align: left;">  150   </td><td style="text-align: left;"> 2 </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>for the crosstab format.
</p>
<p>The parameters <code>x</code>, <code>select</code>, and  <code>replicate</code> should
be disjoint. Although the independent variable always has to be replicated
it should not be given by the <code>replicate</code> parameter.
</p>


<h3>Value</h3>

<p>A data frame with the following columns:
</p>
<table role = "presentation">
<tr><td><code>name</code></td>
<td>
<p>Column containing the column names of the original crosstab data frame, <code>data</code>
</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>A replication of the independent variable
</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>The actual data stacked upon each other in one column
</p>
</td></tr>
<tr><td><code>err</code></td>
<td>
<p>Optional column, filled with NA values (necessary for some other functions)
</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>all other columns from the original dataset that had to be replicated
(indicated by the parameter <code>replicate</code>)
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Tom Van Engeland &lt;tom.vanengeland@nioz.nl&gt;
</p>


<h3>References</h3>

<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## =======================================================================
## Suppose we have measured sediment oxygen concentration profiles
## =======================================================================

depth  &lt;- 0:7
O2mud  &lt;- c( 6,   1,   0.5, 0.1, 0.05,0,   0,   0)
O2silt &lt;- c( 6,   5,   3,   2,   1.5, 1,   0.5, 0)
O2sand &lt;- c( 6,   6,   5,   4,   3,   2,   1,   0)
zones  &lt;- c("a", "b", "b", "c", "c", "d", "d", "e")
oxygen &lt;- data.frame(depth = depth,
                     zone  = zones,
                     mud   = O2mud,
                     silt  = O2silt,
                     sand  = O2sand
          )

 cross2long(data = oxygen, x = depth, 
            select = c(silt, mud), replicate = zone)

 cross2long(data = oxygen, x = depth, 
            select = c(mud, -silt), replicate = zone)

# twice the same column name: replicates
 colnames(oxygen)[4] &lt;- "mud"    

 cross2long(data=oxygen, x = depth, select = mud)
</code></pre>

<hr>
<h2 id='gaussianWeights'>
A kernel average smoother function to weigh residuals according to a Gaussian
density function
This function is still experimental...  use with care
</h2><span id='topic+gaussianWeights'></span>

<h3>Description</h3>

<p>A calibration dataset in database format (cf. modCost for the database
format) is extended in order to fit model output using a weighted least
squares approach. To this end, the observations are replicated for a
certain number of times, and weights are assigned to the replicates
according to a Gaussian density function. This density has the relevant
observation as mean value. The standard deviation, provided as a parameter,
determines the number of inserted replicate observations (see Detail).
</p>
<p>This weighted regression approach may be interesting when discontinuities
exist in the observational data. Under these circumstances small changes 
in the timing (or more general the position along the axis of the independent
variable) of the model output may have a disproportional impact on the
overall goodness-of-fit (e.g. timing of nutrient depletion). Additionally,
this approach may be used to model uncertainty in the independent variable
(e.g. slices of sediment profiles, or the timing of a sampling).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gaussianWeights (obs, x = x, y = y, xmodel, spread, weight = "none",
                 aggregation = x ,ordering)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gaussianWeights_+3A_obs">obs</code></td>
<td>
<p>dataset in long (database) format as is typically used by
modCost
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_x">x</code></td>
<td>
<p>name of the independent variable (typically x, cf. modCost) in
<code>obs</code>. Defaults to x (not given as character string; cf. subset)
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_y">y</code></td>
<td>
<p>name of the dependent variable in <code>obs</code>. Defaults to y.
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_xmodel">xmodel</code></td>
<td>
<p>an ordered vector of unique times at which model output
is produced. If not given, the independent variable of the observational
dataset is used.
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_spread">spread</code></td>
<td>
<p>standard deviation used to calculate the weights from a
normal density function. This value also determines the number of
points from the model output that are compared to a specific observa-
tion in <code>obs</code> (2 * 3 * spread + 1; containing 99.7% of the
Gaussian distribution, centered around the observation of interest).
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_weight">weight</code></td>
<td>
<p>scaling factor of the modCost function (&quot;sd&quot;, &quot;mean&quot;, or
&quot;none&quot;). The Gaussian weights are multiplied by this factor to account
for differences in units.
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_aggregation">aggregation</code></td>
<td>
<p>vector of column names from the dataset that are used
to aggregate observations while calculating the scaling factor. Defaults
to the variable name, &quot;name&quot;.
</p>
</td></tr>
<tr><td><code id="gaussianWeights_+3A_ordering">ordering</code></td>
<td>
<p>Optional extra grouping and ordering of observations. Given
as a vector of variable names. If none given, ordering will be done by
variable name and independent variable. If both aggregation and ordering
variables are given, ordering will be done as follows:
x within ordering (in reverse order) within aggregation (in reverse order).
Aggregation and ordering should be disjoint sets of variable names.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Suppose: spread = 1/24 (days; = 1 hour)
x      = time in days, 1 per hour
</p>
<p>Then:
obs_i is replicated 7 times (spread = observational periodicity = 1 hour):
</p>
<p>=&gt;  obs_i-3 = ... = obs_i-1 = obs_i = obs_i+1 = ... = obs_i+3
</p>
<p>The weights (W_i+j, for j = -3 ...3) are calculated as follows:
W'_i+j = 1/(spread * sqrt(2pi)) * exp(-1/2 * ((obs_i+j - obs_i)/spread)^2
</p>
<p>W_i+j  = W'_i+j/sum(W_i-3,...,W_i+3)
(such that their sum equals 1)
</p>


<h3>Value</h3>

<p>A modified version of <code>obs</code> is returned with the following extensions:
</p>
<p>1. Each observation obs[i] is replicated n times were n represents the number
of <code>modelx</code> values within the interval [obs_i - (3 * spread), obs_i +
3 * spread)].
</p>
<p>2. These replicate observations get the same <code>x</code> values as their
modeled counterparts (<code>xmodel</code>).
</p>
<p>3. Weights are given in column, called &quot;err&quot;
</p>
<p>The returned data frame has the following columns:
</p>

<ul>
<li><p>&quot;name&quot; or another name specified by the first element of 
<code>aggregation</code>. Usually this column contains the names of the
observed variables.

</p>
</li>
<li><p>&quot;x&quot; or another name specified by <code>x</code>

</p>
</li>
<li><p>&quot;y&quot; or another name specified by <code>y</code>

</p>
</li>
<li><p>&quot;err&quot; containing the calculated weights

</p>
</li>
<li><p>The rest of the columns of the data frame given by <code>obs</code> in
that order.

</p>
</li></ul>



<h3>Author(s)</h3>

<p>Tom Van Engeland &lt;tom.vanengeland@nioz.nl&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## =======================================================================
## A Sediment example
## =======================================================================

## Sediment oxygen concentration is measured every
## centimeter in 3 sediment types
depth &lt;- 0:7
observations &lt;- data.frame(
                    profile = rep(c("mud","silt","sand"), each=8),
                    depth   = depth,
                    O2      = c(c(6,1,0.5,0.1,0.05,0,0,0),
                                c(6,5,3,2,1.5,1,0.5,0),
                                c(6,6,5,4,3,2,1,0)
                              )
                )

## A model generates profiles with a depth resolution of 1 millimeter
modeldepths &lt;- seq(0, 9, by = 0.05)

## All these model outputs are compared with  weighed observations.
gaussianWeights(obs = observations, x = depth, y = O2,
                xmodel = modeldepths,
                spread = 0.1, weight = "none", 
                aggregation = profile)



# Weights of one observation in silt at depth 2:
Sub &lt;- subset(observations, subset = (profile == "silt" &amp; depth == 2))
plot(Sub[,-1])
SubWW &lt;- gaussianWeights(obs = Sub, x = depth, y = O2, 
                xmodel = modeldepths, spread = 0.5, 
                weight="none", aggregation = profile)
SubWW[,-1]
</code></pre>

<hr>
<h2 id='Grid'>
Grid Distribution
</h2><span id='topic+Grid'></span>

<h3>Description</h3>

<p>Generates parameter sets arranged on a regular grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Grid(parRange, num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Grid_+3A_parrange">parRange</code></td>
<td>
<p>the range (min, max) of the parameters, a matrix or a
data.frame with one row for each parameter, and two columns with the
minimum (1st) and maximum (2nd) column.  </p>
</td></tr>
<tr><td><code id="Grid_+3A_num">num</code></td>
<td>
<p>the number of random parameter sets to generate.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The grid design produces the most regular parameter distribution;
there is no randomness involved.
The number of parameter sets generated with <code>Grid</code> will be &lt;=
<code>num</code>.
</p>


<h3>Value</h3>

<p>a matrix with one row for each generated parameter set, and one column per
parameter.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Norm">Norm</a></code> for (multi)normally distributed random parameter sets.
</p>
<p><code><a href="#topic+Latinhyper">Latinhyper</a></code> to generates parameter sets using
latin hypercube sampling.
</p>
<p><code><a href="#topic+Unif">Unif</a></code> for uniformly distributed random parameter sets.
</p>
<p><code><a href="base.html#topic+seq">seq</a></code> the R-default for generating regular sequences of numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 4 parameters
parRange &lt;- data.frame(min = c(0, 1, 2, 3), max = c(10, 9, 8, 7))
rownames(parRange) &lt;- c("par1", "par2", "par3", "par4")

## grid
pairs(Grid(parRange, 500), main = "Grid")

</code></pre>

<hr>
<h2 id='Latinhyper'>
Latin Hypercube Sampling
</h2><span id='topic+Latinhyper'></span>

<h3>Description</h3>

<p>Generates random parameter sets using a latin hypercube sampling
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Latinhyper(parRange, num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Latinhyper_+3A_parrange">parRange</code></td>
<td>
<p>the range (min, max) of the parameters, a matrix or a
data.frame with one row for each parameter, and two columns with the
minimum (1st) and maximum (2nd) column.
</p>
</td></tr>
<tr><td><code id="Latinhyper_+3A_num">num</code></td>
<td>
<p>the number of random parameter sets to generate.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the latin hypercube sampling, the space for each parameter is
subdivided into <code>num</code> equally-sized segments and one parameter
value in each of the segments drawn randomly.
</p>


<h3>Value</h3>

<p>a matrix with one row for each generated parameter set, and one column
per parameter.
</p>


<h3>Note</h3>

<p>The latin hypercube distributed parameter sets give better coverage in
parameter space than the uniform random design (<code><a href="#topic+Unif">Unif</a></code>).
It is a reasonable choice in case the number of parameter sets is
limited.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>References</h3>

<p>Press, W. H.,  Teukolsky, S. A., Vetterling, W. T. and
Flannery, B. P. (2007) Numerical Recipes in C. Cambridge
University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Norm">Norm</a></code> for (multi)normally distributed random parameter
sets.
</p>
<p><code><a href="#topic+Unif">Unif</a></code> for uniformly distributed random parameter sets.
</p>
<p><code><a href="#topic+Grid">Grid</a></code> to generate random parameter sets arranged on a
regular grid.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 4 parameters
parRange &lt;- data.frame(min = c(0, 1, 2, 3), max = c(10, 9, 8, 7))
rownames(parRange) &lt;- c("par1", "par2", "par3", "par4")

## Latin hypercube
pairs(Latinhyper(parRange, 100), main = "Latin hypercube")
</code></pre>

<hr>
<h2 id='modCost'>
Calculates the Discrepancy of a Model Solution with Observations
</h2><span id='topic+modCost'></span>

<h3>Description</h3>

<p>Given a solution of a model and observed data, estimates the
residuals, and the variable and model costs (sum of squared residuals).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modCost(model, obs, x = "time", y = NULL, err = NULL,
        weight = "none", scaleVar = FALSE, cost = NULL,  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modCost_+3A_model">model</code></td>
<td>
<p>model output, as generated by the integration routine or
the steady-state solver, a matrix or a data.frame, with one column
per dependent and independent variable.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_obs">obs</code></td>
<td>
<p>the observed data, either in long (database) format (name,
x, y), a data.frame, or in wide (crosstable, or matrix) format - see
details.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_x">x</code></td>
<td>
<p>the name of the <em>independent</em> variable; it should be a
name occurring both in the <code>obs</code> and <code>model</code> data
structures.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_y">y</code></td>
<td>
<p>either <code>NULL</code>, the name of the column with the
<em>dependent</em> variable values,or an index to the dependent
variable values; if <code>NULL</code> then the observations are assumed to
be in crosstable (matrix) format, and the names of the independent
variables are given by the column names of this matrix.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_err">err</code></td>
<td>
<p>either <code>NULL</code>, or the name of the column with the
<em>error</em> estimates, used to weigh the residuals (see details);
if <code>NULL</code>, then the residuals are not weighed.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_cost">cost</code></td>
<td>
<p>if not <code>NULL</code>, the output of a previous call to
<code>modCost</code>; in this case, the new output will combine both.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_weight">weight</code></td>
<td>
<p>only if <code>err</code>=<code>NULL</code>: how to weigh the
residuals, one of &quot;none&quot;, &quot;std&quot;, &quot;mean&quot;, see details.
</p>
</td></tr>
<tr><td><code id="modCost_+3A_scalevar">scaleVar</code></td>
<td>
<p>if <code>TRUE</code>, then the residuals of one observed
variable are scaled respectively to the number of observations (see
details).
</p>
</td></tr>
<tr><td><code id="modCost_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <span class="rlang"><b>R</b></span>-function <code>approx</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function compares model output with observed data.
</p>
<p>It computes
</p>

<ol>
<li><p> the weighted <em>residuals</em>, one for each data point.
</p>
</li>
<li><p> the <em>variable costs</em>, i.e. the sum of squared weight
residuals per variable.
</p>
</li>
<li><p> the <em>model cost</em>, the scaled sum of variable costs .
</p>
</li></ol>

<p>There are three steps:
</p>
<p><em>1.</em> For any observed data point, i, the <em>weighted
residuals</em> are estimated as:
</p>
<p style="text-align: center;"><code class="reqn">res_i=\frac{Mod_i-Obs_i}{error_i}</code>
</p>

<p>with <code class="reqn">weight_i = 1/err_i</code> and where <code class="reqn">Mod_i</code> and
<code class="reqn">Obs_i</code> are the modeled, respectively observed value of
data point i.
</p>
<p>The weights are equal to 1/error, where the latter can be inputted,
one for each data point by specifying <code>err</code> as an extra column in
the observed data.
</p>
<p>This can only be done when the data input is in long (database) format.
</p>
<p>When <code>err</code> is not inputted, then the weights are specified via argument
<code>weight</code> which is either:
</p>

<ul>
<li> <p><code>"none"</code>, which sets the weight equal to 1 (the default)
</p>
</li>
<li> <p><code>"std"</code>, which sets the weights equal to the reciprocal of the standard deviation
of the observed data (can only be used if there is more than 1 data point)
</p>
</li>
<li> <p><code>"mean"</code>, which uses 1/mean of the absolute value of the
observed data (can only be used if not 0).
</p>
</li></ul>

<p><em>2.</em> Then for each observed variable, j, a <em>variable cost</em> is
estimated as the sum of squared weighted residuals for this variable:
</p>
<p style="text-align: center;"><code class="reqn">Cost_{var_j}= \sum \limits_{i = 1}^{n_j} {res_i}^2</code>
</p>

<p>where <code class="reqn">n_j</code> is the number of observations for observed
variable j.
</p>
<p><em>3.</em> Finally, the <em>model Cost</em> is estimated as the scaled sum of
variable costs:
</p>
<p style="text-align: center;"><code class="reqn">ModCost=\sum \limits_{j = 1}^{n_v} {\frac{Cost_{var_j}}{scale_{var_j}}}</code>
</p>

<p>and where <code class="reqn">scale_{var_j}</code> allows to scale the variable
costs relative to the number of observations.  This is set by
specifying argument <code>scaleVar</code>. If <code>TRUE</code>, then the variable
costs are rescaled. The default is NOT to rescale
(i.e. <code class="reqn">scale_{var_j}</code>=1).
</p>
<p>The models typically consist of (a system of) differential equations, which
are either solved by:
</p>

<ul>
<li><p> integration routines, e.g. the routines from package <code>deSolve</code>,
</p>
</li>
<li><p> steady-state estimators, as from package <code>rootSolve</code>.
</p>
</li></ul>

<p>The data can be presented in two formats:
</p>

<ul>
<li> <p><em>data table (long) format</em>; this is a two to four column
data.frame that contains the <code>name</code> of the observed variable (always
the FIRST column), the (optional) <code>value of the independent variable</code>
(default column name = &quot;time&quot;), the <code>value of the observation</code> and
the (optional) <code>value of the error</code>.
For data presented in this format, the names of the column(s) with the
independent variable (<code>x</code>) and the name of the column that has the
value of the dependent variable <code>y</code> must be passed to function
<code>modCost</code>.
</p>
</li>
<li> <p><em>crosstable (wide) format</em>; this is a matrix, where each
column denotes one dependent (or independent) variable; the column name
is the name of the observed variable.
When using this format, only the name of the column that contains the
dependent variable must be specified (<code>x</code>).
</p>
</li></ul>

<p>As an example of both formats consider the data, called <code>Dat</code> consisting
of two observed variables, called &quot;Obs1&quot; and &quot;Obs2&quot;, both containing two
observations, at time 1 and 2:
</p>

<table>
<tr>
 <td style="text-align: left;">
  name    </td><td style="text-align: left;"> time   </td><td style="text-align: left;">   val </td><td style="text-align: left;"> err </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs1    </td><td style="text-align: left;"> 1      </td><td style="text-align: left;">   50  </td><td style="text-align: left;"> 5  </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs1    </td><td style="text-align: left;"> 2      </td><td style="text-align: left;">  150  </td><td style="text-align: left;"> 15  </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs2    </td><td style="text-align: left;"> 1      </td><td style="text-align: left;">  1    </td><td style="text-align: left;"> 0.1  </td>
</tr>
<tr>
 <td style="text-align: left;">
  Obs2    </td><td style="text-align: left;"> 2      </td><td style="text-align: left;">  2    </td><td style="text-align: left;"> 0.2  </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>for the long format and
</p>

<table>
<tr>
 <td style="text-align: left;">
   time   </td><td style="text-align: left;">   Obs1 </td><td style="text-align: left;"> Obs2 </td>
</tr>
<tr>
 <td style="text-align: left;">
   1      </td><td style="text-align: left;">  50    </td><td style="text-align: left;"> 1 </td>
</tr>
<tr>
 <td style="text-align: left;">
   2      </td><td style="text-align: left;">  150   </td><td style="text-align: left;"> 2 </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>for the crosstab format. Note, that in the latter case it is not possible to
provide separate errors per data point.
</p>
<p>By calling modCost several consecutive times (using the <code>cost</code> argument),
it is possible to combine both types of data files.
</p>


<h3>Value</h3>

<p>a list of type <code>modCost</code> containing:
</p>
<table role = "presentation">
<tr><td><code>model</code></td>
<td>
<p>one value, the model cost, which equals the sum of scaled
variable costs (see details).
</p>
</td></tr>
<tr><td><code>minlogp</code></td>
<td>
<p>one value, -log(model probablity), where it is assumed
that the data are normally distributed, with standard deviation =
<code>error</code>.
</p>
</td></tr>
<tr><td><code>var</code></td>
<td>
<p> the variable costs, a data.frame with, for each observed
variable the following (see details):
</p>

<ul>
<li><p> name, the name of the observed variable.
</p>
</li>
<li><p> scale, the scale-factor used to weigh the variable cost,
either 1 or 1/(number observations), defaults to 1.
</p>
</li>
<li><p> N, the number of data points per observed variable.
</p>
</li>
<li><p> SSR.unweighted, the sum of squared residuals per observed
variable, unweighted.
</p>
</li>
<li><p> SSR, the sum of weighted squared residuals per observed
variable(see details).
</p>
</li></ul>

</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the data residual, a data.frame with several columns:
</p>

<ul>
<li><p> name, the name of the observed variable.
</p>
</li>
<li><p> x, the value of the independent variable (if present).
</p>
</li>
<li><p> obs, the observed variable value.
</p>
</li>
<li><p> mod, the corresponding modeled value.
</p>
</li>
<li><p> weight, the factor used to weigh the residuals, 1/error,
defaults to 1.
</p>
</li>
<li><p> res, the weighted residuals between model and observations
(mod-obs)*weight.
</p>
</li>
<li><p> res.unweighted, the residuals between model and observations
(mod-obs).
</p>
</li></ul>

</td></tr>
</table>


<h3>Note</h3>

<p>In the future, it should be possible to have more than one independent
variable present. This is not yet implemented, but it should allow e.g.
to fit time series of spatially dependent variables.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;</p>


<h3>References</h3>

<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## =======================================================================
## Type 1 input:  name, time, value
## =======================================================================

## Create new data: two observed variables, "a", "b"
Data &lt;- data.frame(name = c(rep("a", 4), rep("b", 4)),
                   time = c(1:4, 2:5), val = c(runif(4), 1:4))

## "a nonsense model"
Mod &lt;- function (t, y, par) {
  da &lt;- 0
  db &lt;- 1
  return(list(c(da, db)))
}

out &lt;- ode(y = c(a = 0.5, b = 0.5), times = 0:6, func = Mod, parms = NULL)

Data   # Show
out

## The cost function
modCost(model = out, obs = Data, y = "val")

## The cost function with a data error added
Dat2 &lt;- cbind(Data, Err = Data$val*0.1)  # error = 10% of value
modCost(model = out, obs = Dat2, y = "val", err = "Err")


## =======================================================================
## Type 2 input:  Matrix format; column names = variable names
## =======================================================================

## logistic growth model
TT    &lt;- seq(1, 100, 2.5)
N0    &lt;- 0.1
r     &lt;- 0.5
K     &lt;- 100

## analytical solution
Ana &lt;- cbind(time = TT, N = K/(1 + (K/N0 - 1) * exp(-r*TT)))

## numeric solution
logist &lt;- function(t, x, parms) {
  with(as.list(parms), {
    dx &lt;- r * x[1] * (1 - x[1]/K)
    list(dx)
  })
}

time  &lt;- 0:100
parms &lt;- c(r = r, K = K)
x     &lt;- c(N = N0)

## Compare several numerical solutions
Euler &lt;- ode(x, time, logist, parms, hini = 2, method = "euler")
Rk4   &lt;- ode(x, time, logist, parms, hini = 2, method = "rk4")
Lsoda &lt;- ode(x, time, logist, parms) # lsoda is default method
Ana2  &lt;- cbind(time = time, N = K/(1 + (K/N0 - 1) * exp(-r * time)))

## the SSR and residuals with respect to the "data"
cEuler &lt;- modCost(Euler, Ana)$model
cRk4   &lt;- modCost(Rk4  , Ana)$model
cLsoda &lt;- modCost(Lsoda, Ana)$model
cAna   &lt;- modCost(Ana2 , Ana)$model
compare &lt;- data.frame(method = c("euler", "rk4", "lsoda", "Ana"),
                      cost   = c(cEuler, cRk4, cLsoda, cAna))
## Plot Euler, RK and analytic solution
plot(Euler, Rk4, col = c("red", "blue"), obs = Ana,  
     main = "logistic growth", xlab = "time", ylab = "N")

legend("bottomright", c("exact", "euler", "rk4"), pch = c(1, NA, NA),
       col = c("black", "red", "blue"), lty = c(NA, 1, 2))
legend("right", ncol = 2, title = "SSR",
       legend = c(as.character(compare[,1]), 
                  format(compare[,2], digits = 2)))

compare

## =======================================================================
## Now suppose we do not know K and r and they are to be fitted...
## The "observations" are the analytical solution
## =======================================================================

## Run the model with initial guess: K = 10, r = 2
parms["K"] &lt;- 10
parms["r"] &lt;-  2

init &lt;-  ode(x, time, logist, parms)

## FITTING algorithm uses modFit
## First define the objective function (model cost) to be minimised

## more general: using modFit
Cost &lt;- function(P) {
  parms["K"] &lt;- P[1]
  parms["r"] &lt;- P[2]
  out &lt;- ode(x, time, logist, parms)
  return(modCost(out, Ana))
}
(Fit&lt;-modFit(p = c(K = 10, r = 2), f = Cost))

summary(Fit)

## run model with the optimized value:
parms[c("K", "r")] &lt;- Fit$par
fitted &lt;-  ode(x, time, logist, parms)

## show results, compared with "observations"
plot(init, fitted, col = c("green", "blue"), lwd = 2, lty = 1, 
     obs = Ana, obspar = list(col = "red", pch = 16, cex = 2), 
     main = "logistic growth", xlab = "time", ylab = "N")

legend("right", c("initial", "fitted"), col = c("green", "blue"), lwd = 2)

Cost(Fit$par)

</code></pre>

<hr>
<h2 id='modCRL'>
Monte Carlo Analysis
</h2><span id='topic+modCRL'></span><span id='topic+summary.modCRL'></span><span id='topic+plot.modCRL'></span><span id='topic+pairs.modCRL'></span><span id='topic+hist.modCRL'></span>

<h3>Description</h3>

<p>Given a model consisting of differential equations, estimates
the global effect of certain (sensitivity) parameters on selected
sensitivity variables.
</p>
<p>This is done by drawing parameter values according to some predefined
distribution, running the model with each of these parameter
combinations, and calculating the values of the selected output
variables at each output interval.
</p>
<p>This function is useful for &ldquo;what-if&rdquo; scenarios.
</p>
<p>If the output variables consist of a time-series or spatially
dependent, use sensRange instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modCRL(func, parms = NULL, sensvar = NULL, dist = "unif",
       parInput = NULL, parRange = NULL, parMean = NULL, parCovar = NULL,
       num = 100, ...)

## S3 method for class 'modCRL'
summary(object,  ...)

## S3 method for class 'modCRL'
plot(x, which = NULL, trace = FALSE, ask = NULL, ...)

## S3 method for class 'modCRL'
pairs(x, which = 1:ncol(x), nsample = NULL, ...)

## S3 method for class 'modCRL'
hist(x, which = 1:ncol(x), ask = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modCRL_+3A_func">func</code></td>
<td>
<p>an R-function that has as first argument <code>parms</code> and that
returns a vector with variables whose sensitivity should be estimated.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_parms">parms</code></td>
<td>
<p>parameters passed to <code>func</code>; should be either a vector,
or a list with named elements.
If <code>NULL</code>, then the first element of <code>parInput</code> is taken.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_sensvar">sensvar</code></td>
<td>
<p>the output variables for which the sensitivity needs to be
estimated. Either <code>NULL</code>, the default=all output variables,
or a vector with output variable <code>names</code> (which should be present in
the vector returned by <code>func</code>),
or a vector with <code>indices</code> to output variables as present in the
output vector returned by <code>func</code>.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_dist">dist</code></td>
<td>
<p>the distribution according to which the parameters should be
generated, one of <code>"unif"</code> (uniformly random samples),
<code>"norm"</code>, (normally distributed random samples),
<code>"latin"</code> (latin hypercube distribution),
<code>"grid"</code> (parameters arranged on a grid).
</p>
<p>The input parameters for the distribution are specified by
<code>parRange</code> (min,max), except for the normally distributed
parameters, in which case the distribution is specified by the
parameter means <code>parMean</code> and the variance-covariance matrix,
<code>parCovar</code>. Note that, if the distribution is <code>"norm"</code> and
<code>parRange</code> is given, then a truncated distribution will be
generated.  (This is useful to prevent for instance that certain
parameters become negative). Ignored if <code>parInput</code> is
specified.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_parrange">parRange</code></td>
<td>
<p>the range (min, max) of the sensitivity parameters, a
matrix or (preferred) a data.frame with one row for each parameter,
and two columns with the minimum (1st) and maximum (2nd) value.  The
rownames of <code>parRange</code> should be parameter names that are known
in argument <code>parms</code>. Ignored if <code>parInput</code> is specified.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_parinput">parInput</code></td>
<td>
<p>a matrix with dimension (*, npar) with the values of the
sensitivity parameters.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_parmean">parMean</code></td>
<td>
<p>only when <code>dist</code> is <code>"norm"</code>: the mean value of
each parameter. Ignored if <code>parInput</code> is specified.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_parcovar">parCovar</code></td>
<td>
<p>only when <code>dist</code> is <code>"norm"</code>: the parameter's
variance-covariance matrix.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_num">num</code></td>
<td>
<p>the number of times the model has to be run. Set large enough.
If <code>parInput</code> is specified, then <code>num</code> parameters are selected
randomly (from the rows of <code>parInput</code>.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_object">object</code></td>
<td>
<p>an object of class <code>modCRL</code>.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_x">x</code></td>
<td>
<p>an object of class <code>modCRL</code>.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_which">which</code></td>
<td>
<p>the name or the index to the variables and parameters that
should be plotted. Default = all variables and parameters.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_nsample">nsample</code></td>
<td>
<p>the number of xy pairs to be plotted on the upper
panel in the pairs plot. When <code>NULL</code> all xy pairs plotted. Set
to a lower number in case the graph becomes too dense (and the
exported picture too large).  This does not affect the histograms on
the diagonal plot (which are estimated using all values).
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_trace">trace</code></td>
<td>
<p>if <code>TRUE</code>, adds smoothed line to the plot.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>TRUE</code>, the user is <em>ask</em>ed before
each plot, if <code>NULL</code> the user is only asked if more than one
page of plots is necessary and the current graphics device is set
interactive, see <code><a href="graphics.html#topic+par">par</a>(ask=.)</code> and
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>.
</p>
</td></tr>
<tr><td><code id="modCRL_+3A_...">...</code></td>
<td>
<p>additional arguments passed to function <code>func</code> or to
the methods.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data.frame of type <code>modCRL</code> containing the parameter(s) and
the corresponding values of the sensitivity output variables.
</p>
<p>The list returned by <code>modCRL</code> has a method for the generic functions
<code><a href="base.html#topic+summary">summary</a></code> and <code><a href="base.html#topic+plot">plot</a></code> &ndash; see note.
</p>


<h3>Note</h3>

<p>The following <em>methods</em> are included:
</p>

<ul>
<li> <p><a href="base.html#topic+summary">summary</a>, estimates summary statistics for the
sensitivity variables, a table with as many rows as there are
variables (or elements in the vector returned by <code>func</code>) and
the following columns: <code>x</code>, the mapping value, <code>Mean</code>,
the mean, <code>sd</code>, the standard deviation, <code>Min</code>, the
minimal value, <code>Max</code>, the maximal value, <code>q25</code>,
<code>q50</code>, <code>q75</code>, the 25th, 50 and 75% quantile.
</p>
</li>
<li> <p><a href="base.html#topic+plot">plot</a>, produces a plot of the <code>modCRL</code> output,
either one plot for each sensitivity variable and with the
parameter value on the x-axis. This only works when there is only
one parameter!
</p>
<p>OR
</p>
<p>one plot for each parameter value on the x-axis. This only works
when there is only one variable!
</p>
</li>
<li> <p><a href="graphics.html#topic+hist">hist</a>, produces a histogram of the <code>modCRL</code> output
parameters and variables.
</p>
</li>
<li> <p><a href="graphics.html#topic+pairs">pairs</a>, produces a pairs plot of the <code>modCRL</code> output.
</p>
</li></ul>

<p>The data.frame of type <code>modCRL</code> has several attributes, which
remain hidden, and which are generally not of practical use
(they are needed for the S3 methods). There is one exception - see
notes in help of <code><a href="#topic+sensRange">sensRange</a></code>.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;.
</p>


<h3>References</h3>

<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## =======================================================================
## Bacterial growth model as in Soetaert and Herman, 2009
## =======================================================================

pars &lt;- list(gmax = 0.5,eff = 0.5,
              ks = 0.5, rB = 0.01, dB = 0.01)

solveBact &lt;- function(pars) {
  derivs &lt;- function(t,state,pars) {    # returns rate of change
    with (as.list(c(state,pars)), {
      dBact &lt;-  gmax*eff * Sub/(Sub + ks)*Bact - dB*Bact - rB*Bact
      dSub  &lt;- -gmax     * Sub/(Sub + ks)*Bact + dB*Bact
      return(list(c(dBact, dSub)))
    })
  }

 state &lt;- c(Bact = 0.1, Sub = 100)
 tout  &lt;- seq(0, 50, by = 0.5)
 ## ode solves the model by integration...
 return(as.data.frame(ode(y = state, times = tout, func = derivs,
                          parms = pars)))
}

out &lt;- solveBact(pars)

plot(out$time, out$Bact, main = "Bacteria",
  xlab = "time, hour", ylab = "molC/m3", type = "l", lwd = 2)

## Function that returns the last value of the simulation
SF &lt;- function (p) {
  pars["eff"] &lt;- p
  out &lt;- solveBact(pars)
  return(out[nrow(out), 2:3])
}

parRange &lt;- matrix(nr = 1, nc = 2, c(0.2, 0.8),
  dimnames = list("eff", c("min", "max")))
parRange

CRL &lt;- modCRL(func = SF, parRange = parRange)

plot(CRL)  # plots both variables
plot(CRL, which = c("eff", "Bact"), trace = FALSE) #selects one

</code></pre>

<hr>
<h2 id='modFit'>
Constrained Fitting of a Model to Data
</h2><span id='topic+modFit'></span><span id='topic+summary.modFit'></span><span id='topic+deviance.modFit'></span><span id='topic+coef.modFit'></span><span id='topic+residuals.modFit'></span><span id='topic+df.residual.modFit'></span><span id='topic+plot.modFit'></span><span id='topic+print.summary.modFit'></span>

<h3>Description</h3>

<p>Fitting a model to data, with lower and/or upper bounds
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modFit(f, p, ..., lower = -Inf, upper = Inf,
  method = c("Marq", "Port", "Newton",
           "Nelder-Mead", "BFGS", "CG", "L-BFGS-B", "SANN",
           "Pseudo", "bobyqa"), jac = NULL,
  control = list(), hessian = TRUE)

## S3 method for class 'modFit'
summary(object, cov=TRUE,...)

## S3 method for class 'modFit'
deviance(object,  ...)

## S3 method for class 'modFit'
coef(object, ...)

## S3 method for class 'modFit'
residuals(object, ...)

## S3 method for class 'modFit'
df.residual(object, ...)

## S3 method for class 'modFit'
plot(x, ask = NULL, ...)

## S3 method for class 'summary.modFit'
print(x, digits = max(3, getOption("digits") - 3),
               ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modFit_+3A_f">f</code></td>
<td>
<p>a function to be minimized, with first argument the vector
of parameters over which minimization is to take place. It should
return either a vector of <em>residuals</em> (of model versus data) or
an element of class <em>modCost</em> (as returned by a call to
<code><a href="#topic+modCost">modCost</a></code>.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_p">p</code></td>
<td>
<p>initial values for the parameters to be optimized over.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_...">...</code></td>
<td>
<p>additional arguments passed to function <code>f</code> (modFit)
or passed to the methods.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_lower">lower</code></td>
<td>
<p>lower bounds on the parameters; if unbounded set equal to
<code>-Inf</code>.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_upper">upper</code></td>
<td>
<p>upper bounds on the parameters; if unbounded set equal to
<code>Inf</code>.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_method">method</code></td>
<td>
<p>The method to be used, one of &quot;Marq&quot;, &quot;Port&quot;, &quot;Newton&quot;,
&quot;Nelder-Mead&quot;, &quot;BFGS&quot;, &quot;CG&quot;, &quot;L-BFGS-B&quot;, &quot;SANN&quot;, &quot;Pseudo&quot;, &quot;bobyqa&quot; - see details.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_jac">jac</code></td>
<td>
<p>A function that calculates the Jacobian; it should be
called as <code>jac(x, ...)</code> and return the matrix with derivatives
of the model residuals as a function of the parameters. Supplying
the Jacobian can substantially improve performance; see last
example.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_hessian">hessian</code></td>
<td>
<p><code>TRUE</code> if Hessian is to be estimated. Note that,
if set to <code>FALSE</code>, then a summary cannot be estimated.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_control">control</code></td>
<td>
<p>additional control arguments passed to the optimisation
routine - see details of <code><a href="minpack.lm.html#topic+nls.lm">nls.lm</a></code> (&quot;Marq&quot;),
<code><a href="stats.html#topic+nlminb">nlminb</a></code> (&quot;Port&quot;),
<code><a href="stats.html#topic+optim">optim</a></code> (&quot;Nelder-Mead&quot;, &quot;BFGS&quot;, &quot;CG&quot;, &quot;L-BFGS-B&quot;, &quot;SANN&quot;),
<code><a href="stats.html#topic+nlm">nlm</a></code> (&quot;Newton&quot;) or <code><a href="#topic+pseudoOptim">pseudoOptim</a></code>(&quot;Pseudo&quot;).
</p>
</td></tr>
<tr><td><code id="modFit_+3A_object">object</code></td>
<td>
<p>an object of class <code>modFit</code>.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_x">x</code></td>
<td>
<p>an object of class <code>modFit</code>.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_digits">digits</code></td>
<td>
<p>number of significant digits in printout.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_cov">cov</code></td>
<td>
<p>when <code>TRUE</code> also calculates the parameter covariances.
</p>
</td></tr>
<tr><td><code id="modFit_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>TRUE</code>, the user is <em>ask</em>ed before
each plot, if <code>NULL</code> the user is only asked if more than one
page of plots is necessary and the current graphics device is set
interactive, see <code><a href="graphics.html#topic+par">par</a>(ask=.)</code> and
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that arguments after <code>...</code> must be matched exactly.
</p>
<p>The method to be used is specified by argument <code>method</code> which can
be one of the methods from function <code><a href="stats.html#topic+optim">optim</a></code>:
</p>

<ul>
<li><p> &quot;Nelder-Mead&quot;, the default from <code>optim</code>,
</p>
</li>
<li><p> &quot;BFGS&quot;, a quasi-Newton method,
</p>
</li>
<li><p> &quot;CG&quot;, a conjugate-gradient method,
</p>
</li>
<li><p> &quot;L-BFGS-B&quot;, constrained quasi-Newton method,
</p>
</li>
<li><p> &quot;SANN&quot;, method of simulated annealing.
</p>
</li></ul>

<p>Or one of the following:
</p>

<ul>
<li><p> &quot;Marq&quot;, the Levenberg-Marquardt algorithm
(<code><a href="minpack.lm.html#topic+nls.lm">nls.lm</a></code> from package <code>minpack</code>) -
the default. Note that this method is the only least squares method.
</p>
</li>
<li><p> &quot;Newton&quot;, a Newton-type algorithm (see <code><a href="stats.html#topic+nlm">nlm</a></code>),
</p>
</li>
<li><p> &quot;Port&quot;, the Port algorithm (see <code><a href="stats.html#topic+nlminb">nlminb</a></code>),
</p>
</li>
<li><p> &quot;Pseudo&quot;, a pseudorandom-search algorithm
(see <code><a href="#topic+pseudoOptim">pseudoOptim</a></code>),
</p>
</li>
<li><p> &quot;bobyqa&quot;, derivative-free optimization by quadratic
approximation from package <code>minqa</code>.
</p>
</li></ul>

<p>For difficult problems it may be efficient to perform some iterations
with <code>Pseudo</code>, which will bring the algorithm near the vicinity
of a (the) minimum, after which the default algorithm (<code>Marq</code>) is
used to locate the minimum more precisely.
</p>
<p>The implementation for the routines from <code><a href="stats.html#topic+optim">optim</a></code> differs
from <code><a href="stats.html#topic+constrOptim">constrOptim</a></code> which implements an adaptive barrier
algorithm and which allows a more flexible implementation of linear
constraints.
</p>
<p>For all methods except <code>L-BFGS-B</code>, <code>Port</code>, <code>Pseudo</code>, and
<code>bobyqa</code> that handle box constraints internally, bounds on parameters are
imposed by a transformation of the parameters to be fitted.
</p>
<p>In case <em>both lower and upper bounds</em> are specified, this is
achieved by a tangens and arc tangens transformation.
</p>
<p>This is, parameter values, <code class="reqn">p'</code>, generated by the optimisation
routine, and which are located in the range [-Inf, Inf] are
transformed, before they are passed to <code>f</code> as:
</p>
<p style="text-align: center;"><code class="reqn">p = (upper + lower)/2 + (upper - lower) \cdot \arctan(p')/\pi</code>
</p>
<p>.
</p>
<p>which maps them into the interval [lower, upper].
</p>
<p>Before the optimisation routine is called, the original parameter values, as
given by argument <code>p</code> are mapped from [lower,upper] to [-Inf, Inf] by:
</p>
<p style="text-align: center;"><code class="reqn">p' = \tan(\pi/2 \cdot (2 p - upper - lower) / (upper - lower))</code>
</p>

<p>In case <em>only lower or upper bounds</em> are specified, this is achieved
by a log transformation and a corresponding exponential back transformation.
</p>
<p>In case parameters are transformed (all methods) or in case the
<code>method</code> <code>Port</code>, <code>Pseudo</code>, <code>Marq</code> or <code>bobyqa</code> is selected,
the <em>Hessian</em> is approximated as <code class="reqn">2 \cdot J^T \cdot J</code>,
where J is the Jacobian, estimated by finite differences.
</p>
<p>This ignores the second derivative terms, but this is reasonable if the method
has truly converged to the minimum.
</p>
<p>Note that finite differences are not extremely precise.
</p>
<p>In case the Levenberg-Marquard method (<code>Marq</code>) is used, and parameters
are not transformed, 0.5 times the Hessian of the least squares problem is
returned by <code>nls.lm</code>, the original Marquardt algorithm. To make it
compatible, this value is multiplied with 2 and the TRUE Hessian is thus
returned by <code>modFit</code>.
</p>


<h3>Value</h3>

<p>a list of class <em>modFit</em> containing the results as returned from the
called optimisation routines.
</p>
<p>This includes the following:
</p>
<table role = "presentation">
<tr><td><code>par</code></td>
<td>
<p>the best set of parameters found.
</p>
</td></tr>
<tr><td><code>ssr</code></td>
<td>
<p>the sum of squared residuals, evaluated at the best set of
parameters.
</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>A symmetric matrix giving an estimate of the Hessian
at the solution found - see note.
</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the result of the last <code>f</code> evaluation; that is, the
residuals.
</p>
</td></tr>
<tr><td><code>ms</code></td>
<td>
<p>the mean squared residuals, i.e. <code>ssr/length(residuals)</code>.
</p>
</td></tr>
<tr><td><code>var_ms</code></td>
<td>
<p>the weighted and scaled variable mean squared residuals,
one value per observed variable; only when <code>f</code>
returns an element of class <em>modCost</em>; <code>NA</code> otherwise.
</p>
</td></tr>
<tr><td><code>var_ms_unscaled</code></td>
<td>
<p>the weighted, but not scaled variable mean
squared residuals
</p>
</td></tr>
<tr><td><code>var_ms_unweighted</code></td>
<td>
<p>the raw variable mean squared residuals,
unscaled and unweighted.
</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>any other arguments returned by the called optimisation routine.
</p>
</td></tr>
</table>
<p>Note: this means that some return arguments of the original
optimisation functions are renamed.
</p>
<p>More specifically, &quot;objective&quot; and &quot;counts&quot; from routine
<code><a href="stats.html#topic+nlminb">nlminb</a></code> (method = &quot;Port&quot;) are renamed; &quot;value&quot; and
&quot;counts&quot;; &quot;niter&quot; and &quot;minimum&quot; from routine
<code><a href="minpack.lm.html#topic+nls.lm">nls.lm</a></code> (method=Marq) are renamed; &quot;counts&quot;
and &quot;value&quot;; &quot;minimum&quot; and &quot;estimate&quot; from routine <code><a href="stats.html#topic+nlm">nlm</a></code>
(<code>method = "Newton"</code>) are renamed.
</p>
<p>The list returned by <code>modFit</code> has a method for the
<code><a href="base.html#topic+summary">summary</a></code>, <code><a href="stats.html#topic+deviance">deviance</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>,
<code><a href="stats.html#topic+residuals">residuals</a></code>, <code><a href="stats.html#topic+df.residual">df.residual</a></code> and
<code>print.summary</code> &ndash; see note.
</p>


<h3>Note</h3>

<p>The <code><a href="base.html#topic+summary">summary</a></code> <em>method</em> is based on an estimate of the
parameter covariance matrix.
In computing the covariance matrix of the fitted parameters, the problem is
treated as if it were a linear least squares problem, linearizing around
the parameter values that minimize <code class="reqn">Chi^2</code>.
</p>
<p>The covariance matrix is estimated as <code class="reqn">1/(0.5 \cdot Hessian)</code>.
</p>
<p>This computation relies on several things, i.e.:
</p>

<ol>
<li><p> the parameter values are located at the minimum (i.e. the fitting
algorithm has converged).
</p>
</li>
<li><p> the observations <code class="reqn">y_j</code> are subject to independent errors whose
variances are well estimated by <code class="reqn">1 / (n - p)</code> times the residual sum
of squares (where n = number of data points, p = number of parameters).
</p>
</li>
<li><p> the model is not too nonlinear.
</p>
</li></ol>

<p>This means that the estimated covariance (correlation) matrix and the
confidence intervals derived from it may be worthless if the assumptions
behind the covariance computation are invalid.
</p>
<p>If in doubt about the validity of the summary computations, use Monte Carlo
fitting instead, or run a <code><a href="#topic+modMCMC">modMCMC</a></code>.
</p>
<p>Other methods included are:
</p>

<ul>
<li> <p><code><a href="stats.html#topic+deviance">deviance</a></code>, which returns the model deviance,
</p>
</li>
<li> <p><code><a href="stats.html#topic+coef">coef</a></code>, which extracts the values of the fitted parameters,
</p>
</li>
<li> <p><code><a href="stats.html#topic+residuals">residuals</a></code>,which extracts the model residuals,
</p>
</li>
<li> <p><code><a href="stats.html#topic+df.residual">df.residual</a></code> which returns the residual degrees of freedom
</p>
</li>
<li> <p><code>print.summary</code>, producing a nice printout of the summary.
</p>
</li></ul>

<p>Specifying a function to estimate the Jacobian matrix via argument
<code>jac</code> may increase speed. The Jacobian is used in the methods
&quot;Marq&quot;, &quot;BFGS&quot;, &quot;CG&quot;, &quot;L-BFGS&quot;, &quot;Port&quot;, and is also used at the end,
to estimate the Hessian at the optimum.
</p>
<p>Specification of the <code>gradient</code> in routines &quot;BFGS&quot;, &quot;CG&quot;, &quot;L-BFGS&quot;
from <code>optim</code> and &quot;port&quot; from <code>nlminb</code> is not allowed here.
Within <code>modFit</code>, the gradient is rather estimated from the Jacobian
<code>jac</code> and the function <code>f</code>.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;,
</p>
<p>Thomas Petzoldt &lt;thomas.petzoldt@tu-dresden.de&gt;
</p>


<h3>References</h3>

<p>Bates, D., Mullen, K. D. Nash, J. C. and Varadhan, R. 2014.
minqa: Derivative-free optimization algorithms by quadratic approximation.
R package.
<a href="https://cran.r-project.org/package=minqa">https://cran.r-project.org/package=minqa</a>
</p>
<p>Gay, D. M., 1990. Usage Summary for Selected Optimization Routines.
Computing Science Technical Report No. 153. AT&amp;T Bell Laboratories,
Murray Hill, NJ 07974.
</p>
<p>Powell, M. J. D. (2009). The BOBYQA algorithm for bound constrained
optimization without derivatives. Report No. DAMTP 2009/NA06, Centre
for Mathematical Sciences, University of Cambridge, UK.
<a href="https://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf">https://www.damtp.cam.ac.uk/user/na/NA_papers/NA2009_06.pdf</a>
</p>
<p>Press, W. H.,  Teukolsky, S. A., Vetterling, W. T. and
Flannery, B. P., 2007. Numerical Recipes in C. Cambridge
University Press.
</p>
<p>Price, W.L., 1977. A Controlled Random Search Procedure for Global
Optimisation. The Computer Journal, 20: 367-370.
<a href="https://doi.org/10.1093/comjnl/20.4.367">doi:10.1093/comjnl/20.4.367</a>
</p>
<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>
<p>Please see also additional publications on the help pages of the individual
algorithms.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+constrOptim">constrOptim</a></code> for constrained optimization.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## =======================================================================
## logistic growth model
## =======================================================================
TT    &lt;- seq(1, 60, 5)
N0    &lt;- 0.1
r     &lt;- 0.5
K     &lt;- 100

## perturbed analytical solution
Data &lt;- data.frame(
  time = TT,
     N = K / (1+(K/N0-1) * exp(-r*TT)) * (1 + rnorm(length(TT), sd = 0.01))
)

plot(TT, Data[,"N"], ylim = c(0, 120), pch = 16, col = "red",
     main = "logistic growth", xlab = "time", ylab = "N")


##===================================
## Fitted with analytical solution  #
##===================================

## initial "guess"
parms &lt;- c(r = 2, K = 10, N0 = 5)

## analytical solution
model &lt;- function(parms,time)
  with (as.list(parms), return(K/(1+(K/N0-1)*exp(-r*time))))

## run the model with initial guess and plot results
lines(TT, model(parms, TT), lwd = 2, col = "green")

## FITTING algorithm 1
ModelCost &lt;- function(P) {
 out &lt;- model(P, TT)
 return(Data$N-out)  # residuals
}

(Fita &lt;- modFit(f = ModelCost, p = parms))

times &lt;- 0:60
lines(times, model(Fita$par, times), lwd = 2, col = "blue")
summary(Fita)

##===================================
##  Fitted with numerical solution  #
##===================================

## numeric solution
logist &lt;- function(t, x, parms) {
  with(as.list(parms), {
    dx &lt;- r * x[1] * (1 - x[1]/K)
    list(dx)
  })
}

## model cost,
ModelCost2 &lt;- function(P) {
 out &lt;- ode(y = c(N = P[["N0"]]), func = logist, parms = P, times = c(0, TT))
 return(modCost(out, Data))  # object of class modCost
}

Fit &lt;- modFit(f = ModelCost2, p = parms, lower = rep(0, 3),
              upper = c(5, 150, 10))

out &lt;- ode(y = c(N = Fit$par[["N0"]]), func = logist, parms = Fit$par,
           times = times)

lines(out, col = "red", lty = 2)
legend("right", c("data", "original", "fitted analytical", "fitted numerical"),
       lty = c(NA, 1, 1, 2), lwd = c(NA, 2, 2, 1),
       col = c("red", "green", "blue", "red"), pch = c(16, NA, NA, NA))
summary(Fit)
plot(residuals(Fit))

## =======================================================================
## the use of the Jacobian
## =======================================================================

## We use modFit to solve a set of linear equations
A &lt;- matrix(nr = 30, nc = 30, runif(900))
X &lt;- runif(30)
B &lt;- A %*% X

## try to find vector "X"; the Jacobian is matrix A

## Function that returns the vector of residuals
FUN &lt;- function(x)
  as.vector(A %*% x - B)

## Function that returns the Jacobian
JAC &lt;- function(x) A

## The port algorithm
print(system.time(
  mf &lt;- modFit(f = FUN, p = runif(30), method = "Port")
))
print(system.time(
  mf &lt;- modFit(f = FUN, p = runif(30), method = "Port", jac = JAC)
))
max(abs(mf$par - X))  # should be very small

## BFGS
print(system.time(
  mf &lt;- modFit(f = FUN, p = runif(30), method = "BFGS")
))
print(system.time(
  mf &lt;- modFit(f = FUN, p = runif(30), method = "BFGS", jac = JAC)
))
max(abs(mf$par - X))

## Levenberg-Marquardt
print(system.time(
  mf &lt;- modFit(f = FUN, p = runif(30), jac = JAC)
))
max(abs(mf$par - X))
</code></pre>

<hr>
<h2 id='modMCMC'>
Constrained Markov Chain Monte Carlo</h2><span id='topic+modMCMC'></span><span id='topic+summary.modMCMC'></span><span id='topic+plot.modMCMC'></span><span id='topic+pairs.modMCMC'></span><span id='topic+hist.modMCMC'></span>

<h3>Description</h3>

<p>Performs a Markov Chain Monte Carlo simulation, using an adaptive
Metropolis (AM) algorithm and including a delayed rejection (DR)
procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modMCMC(f, p, ..., jump = NULL,  lower = -Inf, upper = +Inf, 
        prior = NULL, var0 = NULL, wvar0 = NULL, n0 = NULL, 
        niter = 1000, outputlength = niter, burninlength = 0, 
        updatecov = niter, covscale = 2.4^2/length(p),
        ntrydr = 1, drscale = NULL, verbose = TRUE)


## S3 method for class 'modMCMC'
summary(object, remove = NULL, ...)

## S3 method for class 'modMCMC'
pairs(x, Full = FALSE, which = 1:ncol(x$pars),
  remove = NULL, nsample = NULL, ...)

## S3 method for class 'modMCMC'
hist(x, Full = FALSE, which = 1:ncol(x$pars),
  remove = NULL, ask = NULL, ...)

## S3 method for class 'modMCMC'
plot(x, Full = FALSE, which = 1:ncol(x$pars),
  trace = TRUE, remove = NULL, ask = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modMCMC_+3A_f">f</code></td>
<td>
<p>the function to be evaluated, with first argument the vector
of parameters which should be varied. It should return either the
model residuals, an element of class <em>modCost</em> (as returned by
a call to <code><a href="#topic+modCost">modCost</a></code>) or -2*log(likelihood).  The latter
is equivalent to the sum-of-squares functions when using a Gaussian
likelihood and prior.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_p">p</code></td>
<td>
<p>initial values for the parameters to be optimized over.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_...">...</code></td>
<td>
<p>additional arguments passed to function <code>f</code> or to the
methods.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_jump">jump</code></td>
<td>
<p>jump length, either a <em>number</em>, a <em>vector</em> with
length equal to the total number of parameters, a <em>covariance
matrix</em>, or a <em>function</em> that takes as input the current values
of the parameters and produces as output the perturbed
parameters. See details.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_prior">prior</code></td>
<td>
<p>-2*log(parameter prior probability), either a function
that is called as <code>prior(p)</code> or <code>NULL</code>; in the latter case
a non-informative prior is used (i.e. all parameters are equally
likely, depending on <code>lower</code> and <code>upper</code> within min and max bounds).
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_var0">var0</code></td>
<td>
<p>initial model variance; if <code>NULL</code>, it is assumed
that the model variance is <code>1</code>, and the return element from <code>f</code>
is -2*log (likelihood). If it has a value, it is assumed that the return element
from <code>f</code> contain the model residuals or a list of class
<code>modFit</code>.  See details. Good options for <code>var0</code> are to use 
the modelvariance (<code>modVariance</code>) as returned by the 
<code>summary</code> method of <a href="#topic+modFit">modFit</a>. When this option is chosen, and 
the model has several variables, they will all be scaled similarly.
See vignette <code>FMEdyna</code>. In case the model has several variables with 
different magnitudes, then it may be better to scale each variable
independently. In that case, one can use as <code>var0</code>, the mean of the 
unweighted squared residuals from the model fit as returned from 
<a href="#topic+modFit">modFit</a> (<code>var_ms_unweighted</code>). See vignette <code>FME</code>.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_wvar0">wvar0</code></td>
<td>
<p>&quot;weight&quot; for the initial model variance &ndash; see details.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_n0">n0</code></td>
<td>
<p>parameter used for weighing the initial model variance -
if <code>NULL</code>, it is estimated as <code>n0=wvar0*n</code>, where n = number
of observations. See details.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_lower">lower</code></td>
<td>
<p>lower bounds on the parameters; for unbounded parameters
set equal to <code>-Inf</code>.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_upper">upper</code></td>
<td>
<p>upper bounds on the parameters; for unbounded parameters
set equal to <code>Inf</code>.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_niter">niter</code></td>
<td>
<p>number of iterations for the MCMC.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_outputlength">outputlength</code></td>
<td>
<p>number of iterations kept in the output; should
be smaller or equal to <code>niter</code>.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_updatecov">updatecov</code></td>
<td>
<p>number of iterations after which the parameter
covariance matrix is (re)evaluated based on the parameters kept thus
far, and used to update the MCMC jumps.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_covscale">covscale</code></td>
<td>
<p>scale factor for the parameter covariance matrix,
used to perform the MCMC jumps.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_burninlength">burninlength</code></td>
<td>
<p>number of initial iterations to be removed from
output.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_ntrydr">ntrydr</code></td>
<td>
<p>maximal number of tries for the delayed rejection
procedure.  It is generally not a good idea to set this to a too
large value.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_drscale">drscale</code></td>
<td>
<p>for each try during delayed rejection, the cholesky
decomposition of the proposal matrix is scaled with this amount; if
<code>NULL</code>, it is assumed to be <code>c(0.2,0.25, 0.333, 0.333,
    ...)</code>  </p>
</td></tr>
<tr><td><code id="modMCMC_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code> or <code>1</code>: prints extra output, if 
numeric value <code>i &gt; 1</code>, prints status information every 
<code>i</code> iterations.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_object">object</code></td>
<td>
<p>an object of class <code><a href="#topic+modMCMC">modMCMC</a></code>.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_x">x</code></td>
<td>
<p>an object of class <code><a href="#topic+modMCMC">modMCMC</a></code>.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_full">Full</code></td>
<td>
<p>If TRUE then not only the parameters will be plotted, but
also the function value and (if appropriate) the model variance(s).
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_which">which</code></td>
<td>
<p>the name or the index to the parameters that should be
plotted.  Default = all parameters. If <code>Full=TRUE</code>, setting
<code>which = NULL</code> will plot only the function value and the model
variance.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_trace">trace</code></td>
<td>
<p>if <code>TRUE</code>, adds smoothed line to the plot.
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_remove">remove</code></td>
<td>
<p>a list with indices of the runs that should be removed (e.g.
to remove runs during burnin).
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_nsample">nsample</code></td>
<td>
<p>the number of xy pairs to be plotted on the upper
panel in the pairs plot. When <code>NULL</code> all xy pairs plotted. Set
to a lower number in case the graph becomes too dense (and the
exported picture too large).  This does not affect the histograms on
the diagonal plot (which are estimated using all MCMC draws).
</p>
</td></tr>
<tr><td><code id="modMCMC_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>TRUE</code>, the user is <em>ask</em>ed before
each plot, if <code>NULL</code> the user is only asked if more than one
page of plots is necessary and the current graphics device is set
interactive, see <code><a href="graphics.html#topic+par">par</a>(ask=.)</code> and
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that arguments after ... must be matched exactly.
</p>
<p>R-function <code>f</code> is called as <code>f(p, ...)</code>. It should return
either -2 times the log likelihood of the model (one value), the
residuals between model and data or an item of class <code>modFit</code> (as
created by function <code><a href="#topic+modFit">modFit</a></code>.
</p>
<p>In the latter two cases, it is assumed that the prior distribution for
<code class="reqn">\theta</code> is either non-informative or gaussian. If gaussian, it
can be treated as a sum of squares (SS). If the measurement function
is defined as:
</p>
<p style="text-align: center;"><code class="reqn">y=f(\theta) + \xi\\
\xi ~ N(0,\sigma^2)</code>
</p>

<p>where <code class="reqn">\xi</code> is the measurement error, assumed normally
distribution, then the posterior for the parameters will be estimated
as:
</p>
<p style="text-align: center;"><code class="reqn">p(\theta | y,\sigma^2)\propto exp(-0.5 \cdot (\frac{SS(\theta)}{\sigma^2}
  +SS_{pri}(\theta))</code>
</p>

<p>and where <code class="reqn">\sigma^2</code> is the error variance, SS is the sum of squares
function <code class="reqn">SS(\theta)=\sum(y_i-f(\theta))^2</code>.
If non-informative priors are used, then <code class="reqn">SS_{pri}(\theta)=0</code>.
</p>
<p>The error variance <code class="reqn">\sigma^2</code> is considered a nuisance parameter.
A prior distribution of it should be specified and a posterior distribution
is estimated.
</p>
<p>If <code>wvar0</code> or <code>n0</code> is &gt;0, then the variances are sampled as
conjugate priors from the inverse gamma distribution with parameters
<code>var0</code> and <code>n0=wvar0*n</code>.  Larger values of <code>wvar0</code> keep
these samples closer to <code>var0</code>.
</p>
<p>Thus, at each step, 1/ the error variance (<code class="reqn">\sigma^{-2}</code>) is sampled
from a gamma distribution:
</p>
<p style="text-align: center;"><code class="reqn">p(\sigma^{-2}|y,\theta) \sim \Gamma(\frac{(n_0+n)}{2},
  \frac{(n_0 \cdot var0+SS(\theta))}{2})</code>
</p>

<p>where <code>n</code> is the number of data points and where
<code class="reqn">n0=n \cdot wvar0</code>, and where the second argument to the gamma function
is the shape parameter.
</p>
<p>The prior parameters (<code>var0</code> and <code>wvar0</code>) are the prior mean
for <code class="reqn">\sigma^2</code> and the prior accuracy.
</p>
<p>By setting <code>wvar0</code> equal to 1, equal weight is given to the
prior and the current value.
</p>
<p>If <code>wvar0</code> is 0 then the prior is ignored.
</p>
<p>If <code>wvar0</code> is <code>NULL</code> (the default) then the error variances are
assumed to be fixed.
</p>
<p><code>var0</code> estimates the variance of the measured components. In case
independent estimates are not available, these variances can be
obtained from the mean squares of fitted residuals. (e.g. as reported
in <code>modFit</code>). See the examples. (but note that this is not truly
independent information)
</p>
<p><code>var0</code> is either one value, or a value for each observed
variable, or a value for each observed data point.
</p>
<p>When <code>var0</code> is not <code>NULL</code>, then <code>f</code> is assumed to
return the model residuals OR an instance of class <code>modCost</code>.
</p>
<p>When <code>var0=NULL</code>, then <code>f</code> should return either
-2*log(probability of the model), or an instance of class
<code>modCost</code>.
</p>
<p><code>modMCMC</code> implements the Metropolis-Hastings method. The proposal
distribution, which is used to generate new parameter values is the
(multidimensional) Gaussian density distribution, with standard
deviation given by <code>jump</code>.
</p>
<p><code>jump</code> can be either one value, a vector of length = number of
parameters or a parameter covariance matrix (nrow = ncol = number
parameters).
</p>
<p>The jump parameter, <code>jump</code> thus determines how much the new
parameter set will deviate from the old one.
</p>
<p>If <code>jump</code> is one value, or a vector, then the new parameter
values are generated by sampling a normal distribution with standard
deviation equal to <code>jump</code>.  A larger value will lead to larger
jumps in the parameter space, but acceptance of new points can get
very low. Smaller jump lengths increase the acceptance rate, but the
algorithm may move too slowly, and too many runs may be needed to scan
the parameter space.
</p>
<p>If <code>jump</code> is <code>NULL</code>, then the jump length is taken as 10%
of the parameter value as given in <code>p</code>.
</p>
<p><code>jump</code> can also be a proposal covariance matrix. In this case,
the new parameter values are generated by sampling a multidimensional
normal distribution. It can be efficient to initialise <code>jump</code>
using the parameter covariance as resulting from fitting the model
(e.g. using <code>modFit</code>) &ndash; see examples.
</p>
<p>Finally, <code>jump</code> can also be an R-function that takes as input the
current values of the parameters and returns the new parameter values.
</p>
<p>Two methods are implemented to increase the number of accepted runs.
</p>

<ol>
<li><p> In the <em>&quot;adaptive Metropolis&quot;</em> method, new parameters are
generated with a covariance matrix that is estimated from the
parameters generated (and saved) thus far.  The idea behind this
is that the MCMC method is more efficient if the proposal
covariance (to generate new parameter values) is somehow tuned to
the shape and size of the target distribution.
</p>
<p>Setting <code>updatecov</code> smaller than <code>niter</code> will trigger
this functionality. In this case, every <code>updatecov</code>
iterations, the jump covariance matrix will be estimated from the
covariance matrix of the saved parameter values. The covariance
matrix is scaled with <code class="reqn">(2.4^2/npar)</code> where npar is the number
of parameters, unless <code>covscale</code> has been given a different
value.  Thus, <code class="reqn">Jump= ( cov(\theta_1,\theta_2,....\theta_n)
      \cdot diag(np,+1e^{-16})\cdot(2.4^2/npar)</code> where the small number <code class="reqn">1e^{-16}</code>
is added on the diagonal of the covariance matrix to prevent it
from becoming singular.
</p>
<p>Note that a problem of adapting the proposal distribution using
the MCMC results so far is that standard convergence results do
not apply.  One solution is to use adaptation only for the burn-in
period and discard the part of the chain where adaptation has been
used.
</p>
<p>Thus, when using <code>updatecov</code> with a positive value of
<code>burninlength</code>, the proposal distribution is only updated
during burnin. If <code>burninlength</code> = 0 though, the updates
occur throughout the entire simulation.
</p>
<p>When using the adaptive Metropolis method, it is best to start
with a small value of the jump length.
</p>
</li>
<li><p> In the <em>&quot;delayed rejection&quot;</em> method, new parameter
values are tried upon rejection. The process of delaying rejection
can be iterated for at most <code>ntrydr</code> trials. Setting
<code>ntrydr</code> equal to 1 (the default) toggles off delayed
rejection.
</p>
<p>During the delayed rejection procedure, new parameters are
generated from the last accepted value by scaling the jump
covariance matrix with a factor as specified in
<code>drscale</code>. The acceptance probability of this new set depends
on the candidates so far proposed and rejected, in such a way that
reversibility of the Markov chain is preserved. See Haario et
al. (2005, 2006) for more details.
</p>
</li></ol>

<p>Convergence of the MCMC chain can be checked via <code>plot</code>, which
plots for each iteration the values of all parameters, and if
<code>Full</code> is <code>TRUE</code>, of the function value (SS) and (if
appropriate) the modeled variance.  If converged, there should be no
visible drift.
</p>
<p>In addition, the methods from package <code>coda</code> become available by
making the object returned by <code>modMCMC</code> of class <code>mcmc</code>, as
used in the methods of <code>coda</code>.  For instance, if object
<code>MCMCres</code> is returned by <code>modMCMC</code> then
<code>as.mcmc(MCMCres$pars)</code> will make an instance of class
<code>mcmc</code>, usable by <code>coda</code>.
</p>
<p>The <code>burninlength</code> is the number of initial steps that is not
included in the output. It can be useful if the initial value of the
parameters is far from the optimal value. Starting the MCMC with the
best fit parameter set will alleviate the need for using
<code>burninlength</code>.
</p>


<h3>Value</h3>

<p>a list of class <em>modMCMC</em> containing the results as returned from the
Markov chain.
</p>
<p>This includes the following:
</p>
<table role = "presentation">
<tr><td><code>pars</code></td>
<td>
<p>an array with dimension (<code>outputlength</code>,
length(<code>p</code>)), containing the parameters of the MCMC at each
iteration that is kept.
</p>
</td></tr>
<tr><td><code>SS</code></td>
<td>
<p>vector with the sum of squares function, one for each row
in <code>pars</code>.</p>
</td></tr>
<tr><td><code>naccepted</code></td>
<td>
<p>the number of accepted runs.
</p>
</td></tr>
<tr><td><code>sig</code></td>
<td>
<p>the sampled error variance <code class="reqn">\sigma^2</code>, a matrix with
one row for each row in <code>pars</code>.
</p>
</td></tr>
<tr><td><code>bestpar</code></td>
<td>
<p>the parameter set that gave the highest probability.
</p>
</td></tr>
<tr><td><code>bestfunp</code></td>
<td>
<p>the function value corresponding to <code>bestpar</code>.
</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>the parameter prior, one value for each row in
<code>pars</code>.
</p>
</td></tr>
<tr><td><code>count</code></td>
<td>
<p>information about the MCMC chain: number of delayed
rejection steps (<code>dr_steps</code>), the number of alfa steps
<code>Alfasteps</code>, the number of accepted runs (<code>num_accepted</code>)
and the number of times the proposal covariance matrix has been
updated (<code>num_covupdate</code>.)
</p>
</td></tr>
<tr><td><code>settings</code></td>
<td>
<p>the settings for error covariance calculation,
i.e. arguments <code>var0</code>, <code>n0</code> and <code>N</code> the number of
data points.
</p>
</td></tr>
</table>
<p>The list returned by <code>modMCMC</code> has methods for the generic
functions <code><a href="base.html#topic+summary">summary</a></code>, <code><a href="base.html#topic+plot">plot</a></code>,
<code><a href="graphics.html#topic+pairs">pairs</a></code> &ndash; see note.
</p>


<h3>Note</h3>

<p>The following S3 methods are provided:
</p>

<ul>
<li><p> summary, produces summary statistics of the MCMC results
</p>
</li>
<li><p> plot, plots the MCMC results, for all parameters. Use it to
check convergence.
</p>
</li>
<li><p> pairs, produces a pairs plot of the MCMC results; overrides
the default <code>gap = 0</code>, <code>upper.panel = NA</code>, and
<code>diag.panel</code>.
</p>
</li></ul>

<p>It is also possible to use the methods from the <code>coda</code> package,
e.g.  <code><a href="coda.html#topic+densplot">densplot</a></code>.
</p>
<p>To do that, first the <code>modMCMC</code> object has to be converted to an
mcmc object.  See the examples for an application.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>
<p>Marko Laine &lt;Marko.Laine@fmi.fi&gt;
</p>


<h3>References</h3>

<p>Laine, M., 2008. Adaptive MCMC Methods With Applications in
Environmental and Geophysical Models. Finnish Meteorological Institute
contributions 69, ISBN 978-951-697-662-7, Finnish Meteorological
Institute, Helsinki.
</p>
<p>Haario, H., Saksman, E. and Tamminen, J., 2001. An Adaptive Metropolis
Algorithm. Bernoulli 7, pp. 223&ndash;242.
<a href="https://doi.org/10.2307/3318737">doi:10.2307/3318737</a>
</p>
<p>Haario, H., Laine, M., Mira, A. and Saksman, E., 2006. DRAM: Efficient
Adaptive MCMC. Statistics and Computing, 16(4), 339&ndash;354.
<a href="https://doi.org/10.1007/s11222-006-9438-0">doi:10.1007/s11222-006-9438-0</a>
</p>
<p>Haario, H., Saksman, E. and Tamminen, J., 2005. Componentwise
Adaptation for High Dimensional MCMC. Computational Statistics 20(2),
265&ndash;274. <a href="https://doi.org/10.1007/BF02789703">doi:10.1007/BF02789703</a>
</p>
<p>Gelman, A. Varlin, J. B., Stern, H. S. and Rubin, D. B.,
2004. Bayesian Data Analysis.  Second edition. Chapman and Hall, Boca
Raton.
</p>
<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+modFit">modFit</a></code> for constrained model fitting
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## =======================================================================
## Sampling a 3-dimensional normal distribution,
## =======================================================================
# mean = 1:3, sd = 0.1
# f returns -2*log(probability) of the parameter values

NN &lt;- function(p) {
  mu &lt;- c(1,2,3)
  -2*sum(log(dnorm(p, mean = mu, sd = 0.1)))   #-2*log(probability)
}

# simple Metropolis-Hastings
MCMC &lt;- modMCMC(f = NN, p = 0:2, niter = 5000,
                outputlength = 1000, jump = 0.5)

# More accepted values by updating the jump covariance matrix...
MCMC &lt;- modMCMC(f = NN, p = 0:2, niter = 5000, updatecov = 100,
                 outputlength = 1000, jump = 0.5)
summary(MCMC)

plot(MCMC)   # check convergence
pairs(MCMC)

## =======================================================================
## test 2: sampling a 3-D normal distribution, larger standard deviation...
## noninformative priors, lower and upper bounds imposed on parameters
## =======================================================================

NN &lt;- function(p) {
  mu &lt;- c(1,2,2.5)
  -2*sum(log(dnorm(p, mean = mu, sd = 0.5)))   #-2*log(probability)
}

MCMC2 &lt;- modMCMC(f = NN, p = 1:3, niter = 2000, burninlength = 500,
  updatecov = 10, jump = 0.5, lower = c(0, 2, 1), upper = c(1, 3, 3))
plot(MCMC2)
hist(MCMC2, breaks = 20)

## Compare output of p3 with theoretical distribution
hist(MCMC2, which = "p3", breaks = 20)
lines(seq(1, 3, 0.1), dnorm(seq(1, 3, 0.1), mean = 2.5,
  sd = 0.5)/pnorm(3, 2.5, 0.5))
summary(MCMC2)

# functions from package coda...
cumuplot(as.mcmc(MCMC2$pars))
summary(as.mcmc(MCMC2$pars))
raftery.diag(MCMC2$pars)

## =======================================================================
## test 3: sampling a log-normal distribution, log mean=1:4, log sd = 1
## =======================================================================

NL &lt;- function(p) {
  mu &lt;- 1:4
  -2*sum(log(dlnorm(p, mean = mu, sd = 1)))      #-2*log(probability)
}
MCMCl &lt;- modMCMC(f = NL, p = log(1:4), niter = 3000,
                 outputlength = 1000, jump = 5)
plot(MCMCl)   # bad convergence
cumuplot(as.mcmc(MCMCl$pars))

MCMCl &lt;- modMCMC (f = NL, p = log(1:4), niter = 3000,
                  outputlength = 1000, jump = 2^(2:5))
plot(MCMCl)   # better convergence but CHECK it!
pairs(MCMCl)
colMeans(log(MCMCl$pars))
apply(log(MCMCl$pars), 2, sd)

MCMCl &lt;- modMCMC (f = NL, p = rep(1, 4), niter = 3000, 
                  outputlength = 1000, jump = 5, updatecov = 100)
plot(MCMCl)
colMeans(log(MCMCl$pars))
apply(log(MCMCl$pars), 2, sd)

## =======================================================================
## Fitting a Monod (Michaelis-Menten) function to data
## =======================================================================

# the observations
#---------------------
Obs &lt;- data.frame(x=c(   28,  55,   83,  110,  138,  225,  375),   # mg COD/l
                  y=c(0.053,0.06,0.112,0.105,0.099,0.122,0.125))   # 1/hour
plot(Obs, pch = 16, cex = 2, xlim = c(0, 400), ylim = c(0, 0.15),
     xlab = "mg COD/l", ylab = "1/hr", main = "Monod")

# the Monod model
#---------------------
Model &lt;- function(p, x) data.frame(x = x, N = p[1]*x/(x+p[2]))

# Fitting the model to the data
#---------------------
# define the residual function
Residuals  &lt;- function(p) (Obs$y - Model(p, Obs$x)$N)

# use modFit to find parameters
P      &lt;- modFit(f = Residuals, p = c(0.1, 1))

# plot best-fit model
x      &lt;-0:375
lines(Model(P$par, x))

# summary of fit
sP    &lt;- summary(P)
sP[]
print(sP)

# Running an MCMC
#---------------------
# estimate parameter covariances
# (to efficiently generate new parameter values)
Covar   &lt;- sP$cov.scaled * 2.4^2/2

# the model variance
s2prior &lt;- sP$modVariance

# set nprior = 0 to avoid updating model variance
MCMC &lt;- modMCMC(f = Residuals, p = P$par,jump = Covar, niter = 1000,
                var0 = s2prior, wvar0 = NULL, updatecov = 100)

plot(MCMC, Full = TRUE)
pairs(MCMC)
# function from the coda package.
raftery.diag(as.mcmc(MCMC$pars))
cor(MCMC$pars)

cov(MCMC$pars)   # covariances by MCMC
sP$cov.scaled    # covariances by Hessian of fit

x  &lt;- 1:400
SR &lt;- summary(sensRange(parInput = MCMC$pars, func = Model, x = x))
plot(SR, xlab="mg COD/l", ylab = "1/hr", main = "Monod")
points(Obs, pch = 16, cex = 1.5)

</code></pre>

<hr>
<h2 id='Norm'>
Normal Random Distribution
</h2><span id='topic+Norm'></span>

<h3>Description</h3>

<p>Generates random parameter sets that are (multi)normally distributed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Norm(parMean, parCovar, parRange = NULL, num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Norm_+3A_parmean">parMean</code></td>
<td>
<p>a vector, with the mean value of each parameter.
</p>
</td></tr>
<tr><td><code id="Norm_+3A_parcovar">parCovar</code></td>
<td>
<p>the parameter variance-covariance matrix.
</p>
</td></tr>
<tr><td><code id="Norm_+3A_parrange">parRange</code></td>
<td>
<p>the range (min, max) of the parameters, a matrix or a
data.frame with one row for each parameter, and two columns with the
minimum (1st) and maximum (2nd) column.
</p>
</td></tr>
<tr><td><code id="Norm_+3A_num">num</code></td>
<td>
<p>the number of random parameter sets to generate.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>Norm</code>, draws parameter sets from a multivariate normal
distribution, as specified through the mean value and the
variance-covariance matrix of the parameters. In addition, it is
possible to impose a minimum and maximum of each parameter, via
<code>parRange</code>. This will generate a truncated distribution.  Use
this for instance if certain parameters cannot become negative.
</p>


<h3>Value</h3>

<p>a matrix with one row for each generated parameter set, and one column per
parameter.
</p>


<h3>Note</h3>

<p>For function <code>Norm</code> to work, <code>parCovar</code> must be a valid
variance-covariance matrix. (i.e. positive definite). If this is not the
case, then the function will fail.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Unif">Unif</a></code> for uniformly distributed random parameter sets.
</p>
<p><code><a href="#topic+Latinhyper">Latinhyper</a></code> to generates parameter sets using
latin hypercube sampling.
</p>
<p><code><a href="#topic+Grid">Grid</a></code> to generate random parameter sets arranged on a regular
grid
</p>
<p><code><a href="stats.html#topic+rnorm">rnorm</a></code> the R-default for generating normally distributed random
numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## multinormal parameters: variance-covariance matrix and parameter mean
parCovar &lt;- matrix(data = c(0.5, -0.2, 0.3, 0.4, -0.2, 1.0, 0.1, 0.3,
                   0.3, 0.1, 1.5, -0.7, 1.0, 0.3, -0.7, 4.5), nrow = 4)
parCovar

parMean &lt;- 4:1

## Generated sample
Ndist &lt;- Norm(parCovar = parCovar, parMean = parMean, num = 500)
cov(Ndist)   # check
pairs(Ndist, main = "normal")

## truncated multinormal
Ranges &lt;- data.frame(min = rep(0, 4), max = rep(Inf, 4))

pairs(Norm(parCovar = parCovar, parMean = parMean, parRange = Ranges,
      num = 500), main = "truncated normal")

</code></pre>

<hr>
<h2 id='obsplot'>
Plot Method for observed data
</h2><span id='topic+obsplot'></span>

<h3>Description</h3>

<p>Plot all observed variables in matrix formalt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obsplot(x, ..., which = NULL, xyswap = FALSE, ask = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="obsplot_+3A_x">x</code></td>
<td>
<p>a <code>matrix</code> or <code>data.frame</code>, containing the observed
data to be plotted. The 'x'-values (first axis) should be the first
column.      
</p>
<p>Several other matrices or data.frames can be passed in the <code>...</code>,
after <code>x</code> (unnamed) - see second example.
</p>
<p>If the first column of <code>x</code> consists of factors, or characters (strings),
then it is assumed that the data are presented in long (database) format,
where the first three columns contain (name, x, y). See last example.
</p>
</td></tr>
<tr><td><code id="obsplot_+3A_which">which</code></td>
<td>
<p>the name(s) or the index to the variables that should be
plotted.  Default = all variables, except the first column. </p>
</td></tr>
<tr><td><code id="obsplot_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>TRUE</code>, the user is <em>ask</em>ed before
each plot, if <code>NULL</code> the user is only asked if more than one
page of plots is necessary and the current graphics device is set
interactive, see <code><a href="graphics.html#topic+par">par</a>(ask=.)</code> and
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>.</p>
</td></tr>
<tr><td><code id="obsplot_+3A_xyswap">xyswap</code></td>
<td>
<p> if <code>TRUE</code>, then x-and y-values are swapped and the 
y-axis is from top to bottom. Useful for drawing vertical profiles.</p>
</td></tr>
<tr><td><code id="obsplot_+3A_...">...</code></td>
<td>
<p>additional arguments.
</p>
<p>The graphical arguments are passed to <code><a href="graphics.html#topic+plot.default">plot.default</a></code>
and <code>points</code>.
</p>
<p>The dots may contain other matrices and data.frames with observed data
to be plotted on the same graphs as <code>x</code>  - see second example.
</p>
<p>The arguments after ... must be matched exactly.     
</p>
</td></tr> 
</table>


<h3>Details</h3>

<p>The number of panels per page is automatically determined up to 3 x 3
(<code>par(mfrow = c(3, 3))</code>). This default can be overwritten by
specifying user-defined settings for <code>mfrow</code> or <code>mfcol</code>.
Set <code>mfrow</code> equal to <code>NULL</code> to avoid the plotting function to 
change user-defined <code>mfrow</code> or <code>mfcol</code> settings.
</p>
<p>Other graphical parameters can be passed as well. Parameters
are vectorized, either according to the number of plots 
(<code>xlab, ylab</code>, <code>main, sub</code>, <code>xlim, ylim</code>, <code>log</code>,
<code>asp, ann, axes, frame.plot</code>,<code>panel.first,panel.last</code>,
<code>cex.lab,cex.axis,cex.main</code>) or 
according to the number of lines within one plot (other parameters 
e.g. <code>col</code>, <code>lty</code>, <code>lwd</code> etc.) so it is possible to
assign specific axis labels to individual plots, resp. different plotting 
style. Plotting parameter <code>ylim</code>, or <code>xlim</code> can also be a list 
to assign different axis limits to individual plots.
</p>


<h3>See Also</h3>

<p><code><a href="deSolve.html#topic+print.deSolve">print.deSolve</a></code>, <code><a href="deSolve.html#topic+ode">ode</a></code>,  <code><a href="deSolve.html#topic+deSolve">deSolve</a></code>  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 'observed' data
AIRquality &lt;- cbind(DAY = 1:153, airquality[, 1:4])
head(AIRquality)
obsplot(AIRquality, type="l", xlab="Day since May")

## second set of observed data
AIR2 &lt;- cbind( 1:100, Solar.R = 250 * runif(100), Temp = 90-30*cos(2*pi*1:100/365) )

obsplot(AIRquality, AIR2, type = "l", xlab = "Day since May" , lwd = 1:2)

obsplot(AIRquality, AIR2, type = "l", xlab = "Day since May" , 
         lwd = 1 : 2, which =c("Solar.R", "Temp"), 
         xlim = list(c(0, 150), c(0, 100)))

obsplot(AIRquality, AIR2, type = "l", xlab = "Day since May" , 
         lwd = 1 : 2, which =c("Solar.R", "Temp"), log = c("y", ""))

obsplot(AIRquality, AIR2, which = 1:3, xyswap = c(TRUE,FALSE,TRUE))

## ' a data.frame, with 'treatments', presented in long database format
Data &lt;- ToothGrowth[,c(2,3,1)]
head   (Data)
obsplot(Data, ylab = "len", xlab = "dose")

# same, plotted as two observed data sets
obsplot(subset(ToothGrowth, supp == "VC", select = c(dose, len)),
        subset(ToothGrowth, supp == "OJ", select = c(dose, len)))

</code></pre>

<hr>
<h2 id='pseudoOptim'>Pseudo-random Search Optimisation Algorithm of Price (1977)</h2><span id='topic+pseudoOptim'></span>

<h3>Description</h3>

<p>Fits a model to data, using the pseudo-random search
algorithm of Price (1977), a random-based fitting technique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseudoOptim(f, p,..., lower, upper, control = list())</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pseudoOptim_+3A_f">f</code></td>
<td>
<p>function to be minimised, its first argument should be the vector
of parameters over which minimization is to take place. It should return
a scalar result, the model cost, e.g the sum of squared residuals.</p>
</td></tr>
<tr><td><code id="pseudoOptim_+3A_p">p</code></td>
<td>
<p>initial values of the parameters to be optimised.</p>
</td></tr>
<tr><td><code id="pseudoOptim_+3A_...">...</code></td>
<td>
<p>arguments passed to function <code>f</code>.</p>
</td></tr>
<tr><td><code id="pseudoOptim_+3A_lower">lower</code></td>
<td>
<p>minimal values of the parameters to be optimised; these
must be specified; they cannot be -Inf.</p>
</td></tr>
<tr><td><code id="pseudoOptim_+3A_upper">upper</code></td>
<td>
<p>maximal values of the parameters to be optimised; these
must be specified; they cannot be +Inf.</p>
</td></tr>
<tr><td><code id="pseudoOptim_+3A_control">control</code></td>
<td>
<p>a list of control parameters - see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>control</code> argument is a list that can supply any of the
following components:
</p>

<ul>
<li><p> npop, number of elements in the population.
Defaults to max(5*length(p),50).
</p>
</li>
<li><p> numiter, maximal number of iterations to be performed.
Defaults to 10000. The algorithm either stops when <code>numiter</code>
iterations has been performed or when the remaining variation is less
than <code>varleft</code>.
</p>
</li>
<li><p> centroid, number of elements from which to estimate a new parameter
vector, defaults to 3.
</p>
</li>
<li><p> varleft, relative variation remaining; if below this value the
algorithm stops; defaults to 1e-8.
</p>
</li>
<li><p> verbose, if TRUE, more verbose output will contain the parameters
in the final population, their respective population costs and the cost
at each succesful interation. Defaults to <code>FALSE</code>.
</p>
</li></ul>

<p>see the book of Soetaert and Herman (2009) for a description of the algorithm
AND for a line to line explanation of the function code.
</p>


<h3>Value</h3>

<p>a list containing:
</p>
<table role = "presentation">
<tr><td><code>par</code></td>
<td>
<p>the optimised parameter values.</p>
</td></tr>
<tr><td><code>cost</code></td>
<td>
<p>the model cost, or function evaluation associated to the
optimised parameter values, i.e. the minimal cost.</p>
</td></tr>
<tr><td><code>iterations</code></td>
<td>
<p>the number of iterations performed.</p>
</td></tr>
</table>
<p>and if <code>control$verbose</code> is TRUE:
</p>
<table role = "presentation">
<tr><td><code>poppar</code></td>
<td>
<p>all parameter vectors remaining in the population, matrix
of dimension (npop,length(par)).</p>
</td></tr>
<tr><td><code>popcost</code></td>
<td>
<p>model costs associated with all population parameter vectors,
vector of length npop.</p>
</td></tr>
<tr><td><code>rsstrace</code></td>
<td>
<p>a 2-columned matrix with the iteration number and the model
cost at each succesful iteration.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;</p>


<h3>References</h3>

<p>Soetaert, K. and Herman, P. M. J., 2009.  A Practical Guide to Ecological
Modelling. Using R as a Simulation Platform.  Springer, 372 pp.
</p>
<p>Price, W.L., 1977.  A Controlled Random Search Procedure for Global
Optimisation.  The Computer Journal, 20: 367-370.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>amp    &lt;- 6
period &lt;- 5
phase  &lt;- 0.5

x &lt;- runif(20)*13 
y &lt;- amp*sin(2*pi*x/period+phase) + rnorm(20, mean = 0, sd = 0.05)
plot(x, y, pch = 16)


cost &lt;- function(par)
    sum((par[1] * sin(2*pi*x/par[2]+par[3])-y)^2)

p1 &lt;- optim(par = c(amplitude = 1, phase = 1, period = 1), fn = cost)
p2 &lt;- optim(par = c(amplitude = 1, phase = 1, period = 1), fn = cost, 
            method = "SANN")
p3 &lt;- pseudoOptim(p = c(amplitude = 1, phase = 1, period = 1), 
            lower = c(0, 1e-8, 0), upper = c(100, 2*pi, 100), 
            f = cost, control = c(numiter = 3000, verbose = TRUE))

curve(p1$par[1]*sin(2*pi*x/p1$par[2]+p1$par[3]), lty = 2, add = TRUE)
curve(p2$par[1]*sin(2*pi*x/p2$par[2]+p2$par[3]), lty = 3, add = TRUE)
curve(p3$par[1]*sin(2*pi*x/p3$par[2]+p3$par[3]), lty = 1, add = TRUE)
legend ("bottomright", lty = c(1, 2, 3),
         c("Price", "Mathematical", "Simulated annealing"))</code></pre>

<hr>
<h2 id='sensFun'>
Local Sensitivity Analysis
</h2><span id='topic+sensFun'></span><span id='topic+summary.sensFun'></span><span id='topic+plot.sensFun'></span><span id='topic+plot.summary.sensFun'></span><span id='topic+pairs.sensFun'></span>

<h3>Description</h3>

<p>Given a model consisting of differential equations, estimates the
local effect of certain parameters on selected sensitivity variables
by calculating a matrix of so-called sensitivity functions.  In this
matrix the (i,j)-th element contains
</p>
<p style="text-align: center;"><code class="reqn">\frac{\partial y_i}{\partial \Theta _j}\cdot \frac{\Delta \Theta _j}
  {\Delta y_i}</code>
</p>

<p>and where <code class="reqn">y_i</code> is an output variable (at a certain time instance),
<code class="reqn">\Theta_j</code> is a parameter, and
<code class="reqn">\Delta y_i</code> is the scaling of variable <code class="reqn">y_i</code>,
<code class="reqn">\Delta \Theta_j</code> is the scaling of parameter
<code class="reqn">\Theta_j</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensFun(func, parms, sensvar = NULL, senspar = names(parms),
        varscale = NULL, parscale = NULL, tiny = 1e-8, map = 1, ...)

## S3 method for class 'sensFun'
summary(object, vars = FALSE, ...)

## S3 method for class 'sensFun'
pairs(x, which = NULL, ...)

## S3 method for class 'sensFun'
plot(x, which = NULL, legpos="topleft", ask = NULL, ...)

## S3 method for class 'summary.sensFun'
plot(x, which = 1:nrow(x), ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sensFun_+3A_func">func</code></td>
<td>
<p>an R-function that has as first argument <code>parms</code> and
that returns a matrix or data.frame with the values of the output
variables (columns) at certain output intervals (rows), and
&ndash; optionally &ndash; a mapping variable (by default the first column).
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_parms">parms</code></td>
<td>
<p>parameters passed to <code>func</code>; should be either a vector,
or a list with named elements.
If <code>NULL</code>, then the first element of <code>parInput</code> is taken.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_sensvar">sensvar</code></td>
<td>
<p>the output variables for which the sensitivity needs
to be estimated. Either <code>NULL</code>, the default, which selects all
variables, or a vector with variable <code>names</code> (which should be
present in the matrix returned by <code>func</code>), or a vector with
<code>indices</code> to variables as present in the output matrix (note
that the column of this matrix with the mapping variable should not
be selected).
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_senspar">senspar</code></td>
<td>
<p>the parameters whose sensitivity needs to be
estimated, the default=all parameters. Either a vector with
parameter <em>names</em>, or a vector with <em>indices</em> to positions
of parameters in <code>parms</code>.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_varscale">varscale</code></td>
<td>
<p>the scaling (weighing) factor for sensitivity
variables, <code>NULL</code> indicates that the variable value is used.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_parscale">parscale</code></td>
<td>
<p>the scaling (weighing) factor for sensitivity
parameters, <code>NULL</code> indicates that the parameter value is used.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_tiny">tiny</code></td>
<td>
<p>the perturbation, or numerical difference, factor, see
details.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_map">map</code></td>
<td>
<p>the column number with the (independent) mapping variable
in the output matrix returned by <code>func</code>. For dynamic models
solved by integration, this will be the (first) column with
<code>time</code>. For 1-D spatial output, this column will be some
distance variable.  Set to NULL if there is no mapping
variable. Mapping variables should not be selected for estimating
sensitivity functions; they are used for plotting.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>func</code> or to the
methods.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_object">object</code></td>
<td>
<p>an object of class <code>sensFun</code>.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_x">x</code></td>
<td>
<p>an object of class <code>sensFun</code>.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_vars">vars</code></td>
<td>
<p>if FALSE: summaries per parameter are returned; if
<code>TRUE</code>, summaries per parameter and per variable are returned.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_which">which</code></td>
<td>
<p>the name or the index to the variables that should be
plotted.  Default = all variables.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_legpos">legpos</code></td>
<td>
<p>position of the legend; set to <code>NULL</code> to avoid
plotting a legend.
</p>
</td></tr>
<tr><td><code id="sensFun_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>TRUE</code>, the user is <em>ask</em>ed before
each plot, if <code>NULL</code> the user is only asked if more than one
page of plots is necessary and the current graphics device is set
interactive, see <code><a href="graphics.html#topic+par">par</a>(ask = ...)</code> and
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are essentially two ways in which to use function <code>sensFun</code>.
</p>

<ul>
<li><p> When <code>func</code> returns a matrix or data frame with output
values, <code>sensFun</code> can be used for sensitivity analysis,
estimating the <em>impact</em> of parameters on output variables.
</p>
</li>
<li><p> When <code>func</code> returns an instance of class <code>modCost</code>
(as returned by a call to function <code><a href="#topic+modCost">modCost</a></code>), then
<code>sensFun</code> can be used for <em>parameter
identifiability</em>. In this case the results from <code>sensFun</code> are
used as input to function <a href="#topic+collin">collin</a>. See the help file for
<code>collin</code>.
</p>
</li></ul>

<p>For each sensitivity parameter, the number of sensitivity functions
estimated is: length(sensvar) * length(mapping variable), i.e. one for
each element returned by <code>func</code> (except the mapping variable).
</p>
<p>The sensitivity functions are estimated numerically. This means that
each parameter value <code class="reqn">\Theta_j</code> is perturbed as
<code class="reqn">\max{(tiny,\Theta_j \cdot (1+tiny))}</code>
</p>


<h3>Value</h3>

<p>a data.frame of class <code>sensFun</code> containing the sensitivity
functions this is one row for each sensitivity variable at each
independent (time or position) value and the following columns:
</p>
<p><code>x</code>, the value of the independent (mapping) variable, usually
time (solver= &quot;ode..&quot;), or distance (solver= &quot;steady.1D&quot;)
</p>
<p><code>var</code>, the name of the observed variable,
</p>
<p><code>...</code>, a number of columns, one for each sensitivity parameter
</p>
<p>The data.frame returned by <code>sensFun</code> has methods for the generic
functions  <code><a href="base.html#topic+summary">summary</a></code>, <code><a href="base.html#topic+plot">plot</a></code>,
<code><a href="graphics.html#topic+pairs">pairs</a></code> &ndash; see note.
</p>


<h3>Note</h3>

<p>Sensitivity functions are generated by perturbing one by one the parameters
with a very small amount, and quantifying the differences in the output. 
</p>
<p>It is important that the output is generated with high precision, else it 
is possible, that the sensitivity functions are just noise.
For instance, when used with a dynamic model (using solver from <code>deSolve</code>)
set the tolerances <code>atol</code> and <code>rtol</code> to  a lower value, to see if 
the sensitivity results make sense.  
</p>
<p>The following methods are provided:
</p>

<ul>
<li> <p><em>summary</em>. Produces summary statistics of the sensitivity
functions, a <code>data.frame</code> with: one row for each parameter
and the following columns:
</p>

<ul>
<li><p> L1: the L1-norm <code class="reqn">\frac{1}{n} \cdot \sum{|S_{ij}|}</code>,
</p>
</li>
<li><p> L2: the L2-norm <code class="reqn">\cdot \sqrt{\frac{1}{n}\sum{S_{ij}
          \cdot S_{ij}}}</code>,
</p>
</li>
<li><p> Mean: the mean of the sensitivity functions,
</p>
</li>
<li><p> Min: the minimal value of the sensitivity functions,
</p>
</li>
<li><p> Max: the maximal value of the sensitivity functions.
</p>
</li></ul>

</li>
<li> <p><em>var </em>the summary of the variables sensitivity functions, a
data.frame with the same columns as <code>model</code>
and one row for each parameter + variable combination.
This is only outputted if the variable names are effectively known
</p>
</li>
<li> <p><em>plot </em> plots the sensitivity functions for each parameter;
each parameter has its own color.
</p>
<p>By default, the sensitivity functions for all variables are plotted
in one figure, unless <code>which</code> gives a selection of variables;
in that case, each variable will be plotted in a separate figure, and
the figures aligned in a rectangular grid, unless par <code>mfrow</code> is
passed as an argument.
</p>
</li>
<li> <p><em>pairs </em> produces a pairs plot of the sensitivity results;
per parameter.
</p>
<p>By default, the sensitivity functions for all variables are plotted
in one figure, unless <code>which</code> gives a selection of variables.
</p>
<p>Overrides the default <code>gap = 0</code>, <code>upper.panel = NA</code>, and
<code>diag.panel</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>References</h3>

<p>Soetaert, K. and Herman, P. M. J., 2009. A Practical Guide to Ecological
Modelling &ndash; Using R as a Simulation Platform. Springer, 390 pp.
</p>
<p>Brun, R., Reichert, P. and Kunsch, H.R., 2001.  Practical
Identificability Analysis of Large Environmental Simulation Models.
Water Resour. Res. 37(4): 1015&ndash;1030.
<a href="https://doi.org/10.1029/2000WR900350">doi:10.1029/2000WR900350</a>
</p>
<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>## =======================================================================
## Bacterial growth model as in Soetaert and Herman, 2009
## =======================================================================
pars &lt;- list(gmax = 0.5, eff = 0.5,
              ks = 0.5, rB = 0.01, dB = 0.01)

solveBact &lt;- function(pars) {
  derivs &lt;- function(t, state, pars) { # returns rate of change
    with (as.list(c(state, pars)), {
      dBact &lt;-  gmax * eff * Sub/(Sub + ks) * Bact - dB * Bact - rB * Bact
      dSub  &lt;- -gmax       * Sub/(Sub + ks) * Bact + dB * Bact
      return(list(c(dBact, dSub)))
    })
  }
  state   &lt;- c(Bact = 0.1, Sub = 100)
  tout    &lt;- seq(0, 50, by = 0.5)
  ## ode solves the model by integration ...
  return(as.data.frame(ode(y = state, times = tout, func = derivs,
    parms = pars)))
}

out &lt;- solveBact(pars)

plot(out$time, out$Bact, ylim = range(c(out$Bact, out$Sub)),
     xlab = "time, hour", ylab = "molC/m3", type = "l", lwd = 2)
lines(out$time, out$Sub, lty = 2, lwd = 2)
lines(out$time, out$Sub + out$Bact)

legend("topright", c("Bacteria", "Glucose", "TOC"),
       lty = c(1, 2, 1), lwd = c(2, 2, 1))

## sensitivity functions
SnsBact &lt;- sensFun(func = solveBact, parms = pars,
                   sensvar = "Bact", varscale = 1)
head(SnsBact)
plot(SnsBact)
plot(SnsBact, type = "b", pch = 15:19, col = 2:6, 
     main = "Sensitivity all vars")

summary(SnsBact)
plot(summary(SnsBact))

SF &lt;- sensFun(func = solveBact, parms = pars,
             sensvar = c("Bact", "Sub"), varscale = 1)
head(SF)
tail(SF)

summary(SF, var = TRUE)

plot(SF)
plot(SF, which = c("Sub","Bact"))
pm &lt;- par(mfrow = c(1,3))
plot(SF, which = c("Sub", "Bact"), mfrow = NULL)
plot(SF, mfrow = NULL)
par(mfrow = pm)

## Bivariate sensitivity
pairs(SF)  # same color
pairs(SF, which = "Bact", col = "green", pch = 15)
pairs(SF, which = c("Bact", "Sub"), col = c("green", "blue"))
mtext(outer = TRUE, side = 3, line = -2,
      "Sensitivity functions", cex = 1.5)

## pairwise correlation
cor(SnsBact[,-(1:2)])

</code></pre>

<hr>
<h2 id='sensRange'>
Sensitivity Ranges of a Timeseries or 1-D Variables
</h2><span id='topic+sensRange'></span><span id='topic+summary.sensRange'></span><span id='topic+plot.sensRange'></span><span id='topic+plot.summary.sensRange'></span>

<h3>Description</h3>

<p>Given a model consisting of differential equations, estimates the
global effect of certain (sensitivity) parameters on a time series or
on 1-D spatial series of selected sensitivity variables.
</p>
<p>This is done by drawing parameter values according to some predefined
distribution, running the model with each of these parameter
combinations, and calculating the values of the selected output
variables at each output interval.
</p>
<p>This function thus produces 'envelopes' around the sensitivity
variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sensRange(func, parms = NULL, sensvar = NULL, dist = "unif",
          parInput = NULL, parRange = NULL, parMean = NULL, 
          parCovar = NULL, map = 1, num = 100,  ...)
  
## S3 method for class 'sensRange'
summary(object, ...)

## S3 method for class 'summary.sensRange'
plot(x, xyswap = FALSE,
              which = NULL, legpos = "topleft",
              col = c(grey(0.8), grey(0.7)),
              quant = FALSE, ask = NULL, obs = NULL, 
              obspar = list(), ...)

## S3 method for class 'sensRange'
plot(x, xyswap = FALSE,
              which = NULL, ask = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sensRange_+3A_func">func</code></td>
<td>
<p>an R-function that has as first argument <code>parms</code> and
that returns a matrix or data.frame with the values of the output
variables (columns) at certain output intervals (rows), and &ndash;
optionally &ndash; a mapping variable (by default the first column).
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_parms">parms</code></td>
<td>
<p>parameters passed to <code>func</code>; should be either a
vector, or a list with named elements.  If <code>NULL</code>, then the
first element of <code>parInput</code> is taken.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_sensvar">sensvar</code></td>
<td>
<p>the output variables for which the sensitivity needs
to be estimated. Either <code>NULL</code>, the default, which selects all
variables, or a vector with variable <code>names</code> (which should be
present in the matrix returned by <code>func</code>), or a vector with
<code>indices</code> to variables as present in the output matrix (note
that the column of this matrix with the mapping variable should not
be selected).
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_dist">dist</code></td>
<td>
<p>the distribution according to which the parameters should be
generated, one of <code>"unif"</code> (uniformly random samples),
<code>"norm"</code>, (normally distributed random samples),
<code>"latin"</code> (latin hypercube distribution),
<code>"grid"</code> (parameters arranged on a grid).
The input parameters for the distribution are specified by
<code>parRange</code> (min,max), except for the normally distributed
parameters, in which case the distribution is specified by the
parameter means <code>parMean</code> and the variance-covariance matrix,
<code>parCovar</code>. Note that, if the distribution is <code>"norm"</code> and
<code>parRange</code> is given, then a truncated distribution will be
generated.  (This is useful to prevent for instance that certain
parameters become negative). Ignored if <code>parInput</code> is
specified.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_parrange">parRange</code></td>
<td>
<p>the range (min, max) of the sensitivity parameters, a
matrix or (preferred) a data.frame with one row for each parameter,
and two columns with the minimum (1st) and maximum (2nd) value.  The
rownames of <code>parRange</code> should be parameter names that are known
in argument <code>parms</code>. Ignored if <code>parInput</code> is specified.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_parinput">parInput</code></td>
<td>
<p>a matrix with dimension (*, npar) with the values of
the sensitivity parameters.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_parmean">parMean</code></td>
<td>
<p>only when <code>dist</code> is <code>"norm"</code>: the mean value
of each parameter. Ignored if <code>parInput</code> is specified.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_parcovar">parCovar</code></td>
<td>
<p>only when <code>dist</code> is <code>"norm"</code>: the parameter's
variance-covariance matrix.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_num">num</code></td>
<td>
<p>the number of times the model has to be run. Set large
enough.  If <code>parInput</code> is specified, then <code>num</code> parameters
are selected randomly (from the rows of <code>parInput</code>.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_map">map</code></td>
<td>
<p>the column number with the (independent) mapping variable
in the output matrix returned by <code>func</code>. For dynamic models
solved by integration, this will be the (first) column with
<code>time</code>. For 1-D spatial output, this column will be some
distance variable.  Set to <code>NULL</code> if there is no mapping
variable. Mapping variables should not be selected for estimating
sensitivity ranges; they are used for plotting.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_object">object</code></td>
<td>
<p>an object of class <code>sensRange</code>.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_x">x</code></td>
<td>
<p>an object of class <code>sensRange</code>.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_legpos">legpos</code></td>
<td>
<p>position of the legend; set to <code>NULL</code> to avoid
plotting a legend.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_xyswap">xyswap</code></td>
<td>
<p>if <code>TRUE</code>, then x-and y-values are swapped and the
y-axis is from top to bottom. Useful for drawing vertical profiles.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_which">which</code></td>
<td>
<p>the name or the index to the variables that should be
plotted.  Default = all variables.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_col">col</code></td>
<td>
<p>the two colors of the polygons that should be plotted.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_quant">quant</code></td>
<td>
<p>if <code>TRUE</code>, then the median surrounded by the
quantiles q25-q75 and q95-q95 are plotted, else the min-max and
mean +- sd are plotted.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_ask">ask</code></td>
<td>
<p>logical; if <code>TRUE</code>, the user is <em>ask</em>ed before
each plot, if <code>NULL</code> the user is only asked if more than one
page of plots is necessary and the current graphics device is set
interactive, see <code><a href="graphics.html#topic+par">par</a>(ask=...)</code> and
<code><a href="grDevices.html#topic+dev.interactive">dev.interactive</a></code>.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_obs">obs</code></td>
<td>
<p>a <code>data.frame</code> or <code>matrix</code> with &quot;observed data&quot; that 
will be added as <code>points</code> to the plots. <code>obs</code> can also be a 
<code>list</code> with multiple data.frames and/or matrices containing 
observed data.
The first column of <code>obs</code> should contain the <code>time</code> or space-variable. 
If <code>obs</code> is not <code>NULL</code> and <code>which</code> is <code>NULL</code>, 
then the variables, common to both <code>obs</code> and <code>x</code> will be plotted.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_obspar">obspar</code></td>
<td>
<p>additional graphics arguments passed to <code>points</code>, for 
plotting the observed data. If <code>obs</code> is a <code>list</code> containing multiple
observed data sets, then the graphics arguments can be  a vector
or a list (e.g. for <code>xlim</code>, <code>ylim</code>), specifying each data set 
separately.
</p>
</td></tr>
<tr><td><code id="sensRange_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>func</code> or to the
methods.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Models solved by integration (i.e. by using one of <code>'ode', 'ode.1D',
  'ode.band', 'ode.2D'</code>), have the output already in a form usable by
<code>sensRange</code>.
</p>


<h3>Value</h3>

<p>a <code>data.frame</code> of type <code>sensRange</code> containing the parameter
set and the corresponding values of the sensitivity output variables.
</p>
<p>The list returned by <code>sensRange</code> has a method for the generic
functions <code><a href="base.html#topic+summary">summary</a></code>,<code><a href="base.html#topic+plot">plot</a></code> and
<code>plot.summary</code> &ndash; see note.
</p>


<h3>Note</h3>

<p>The following <em>methods</em> are included:
</p>

<ul>
<li> <p><a href="base.html#topic+summary">summary</a>, estimates summary statistics for the
sensitivity variables, a data.frame with as many rows as there are
mapping variables (or rows in the matrix returned by <code>func</code>)
and the following columns: <code>x</code>, the mapping value,
<code>Mean</code>, the mean, <code>sd</code>, the standard deviation,
<code>Min</code>, the minimal value, <code>Max</code>, the maximal value,
<code>q25</code>, <code>q50</code>, <code>q75</code>, the 25th, 50 and 75% quantile
</p>
</li>
<li> <p><a href="base.html#topic+plot">plot</a>, produces a &quot;matplot&quot; of the <code>sensRange</code>
output, one plot for each sensitivity variable and with the
mapping variable on the x-axis.
</p>
<p>Each variable will be plotted in a separate figure, and the
figures aligned in a rectangular grid, unless par <code>mfrow</code> is
passed as an argument.
</p>
</li>
<li><p> summary.plot, produces a plot of the summary of the
<code>sensRange</code> output, one plot for each sensitivity variable
and with the ranges and mean +- standard deviation or the
quantiles as coloured polygons.
</p>
<p>Each variable will be plotted in a separate figure, and the
figures aligned in a rectangular grid, unless par <code>mfrow</code> is
passed as an argument.
</p>
</li></ul>

<p>The output for models solved by a steady-state solver (i.e. one of
<code>'steady', 'steady.1D', 'steady.band', 'steady.2D'</code>, needs to be
rearranged &ndash; see examples.
</p>
<p>For <code>plot.summary.sensRange</code> and <code>plot.sensRange</code>, 
the number of panels per page is automatically determined up to 3 x 3
(<code>par(mfrow = c(3, 3))</code>). This default can be overwritten by
specifying user-defined settings for <code>mfrow</code> or <code>mfcol</code>.
Set <code>mfrow</code> equal to <code>NULL</code> to avoid the plotting function to 
change user-defined <code>mfrow</code> or <code>mfcol</code> settings.
</p>
<p>Other graphical parameters can be passed as well. Parameters
are vectorized, either according to the number of plots 
(<code>xlab, ylab</code>, <code>main, sub</code>, <code>xlim, ylim</code>, <code>log</code>,
<code>asp, ann, axes, frame.plot</code>,<code>panel.first,panel.last</code>,
<code>cex.lab,cex.axis,cex.main</code>) or 
according to the number of lines within one plot (other parameters 
e.g. <code>col</code>, <code>lty</code>, <code>lwd</code> etc.) so it is possible to
assign specific axis labels to individual plots, resp. different plotting 
style. Plotting parameter <code>ylim</code>, or <code>xlim</code> can also be a list 
to assign different axis limits to individual plots.
</p>
<p>Similarly, the graphical parameters for observed data, as passed by 
<code>obspar</code> can be vectorized, according to the number of observed 
data sets (when <code>obs</code> is a <code>list</code>).
</p>
<p>The <code>data.frame</code> of type <code>sensRange</code> has several attributes,
which remain hidden, and which are generally not of practical use
(they are needed for the S3 methods).
</p>
<p>There is one exception, i.e. if parameter values are imposed via
argument <code>parInput</code>, and these parameters are generated by a
Markov chain (<code><a href="#topic+modMCMC">modMCMC</a></code>). If the number of draws,
<code>num</code>, is less than the number of rows in <code>parInput</code>, then
<code>num</code> random draws will be taken. Attribute, &quot;pset&quot; then contains
the index to the parameters that have been selected.
</p>
<p>The <code>sensRange</code> method only represents the distribution of the
model response variables as a function of the parameter values. But an
additional source of noise is due to the <em>model error</em>, as
represented by the sampled values of sigma in the Markov chain.  In
order to represent also this source of error, gaussian noise should be
added to each sensitivity output variables, with a standard deviation
that corresponds to the original parameter draw &ndash; see vignette
&quot;FMEother&quot;.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>References</h3>

<p>Soetaert, K. and Petzoldt, T. 2010.  Inverse Modelling, Sensitivity and
Monte Carlo Analysis in R Using Package FME.  Journal of Statistical
Software 33(3) 1&ndash;28. <a href="https://doi.org/10.18637/jss.v033.i03">doi:10.18637/jss.v033.i03</a></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## =======================================================================
## Bacterial growth model from Soetaert and Herman, 2009
## =======================================================================

pars &lt;- list(gmax = 0.5,eff = 0.5,
              ks = 0.5, rB = 0.01, dB = 0.01)

solveBact &lt;- function(pars) {
  derivs &lt;- function(t,state,pars) {    # returns rate of change
    with (as.list(c(state,pars)), {
      dBact &lt;- gmax*eff * Sub/(Sub + ks)*Bact - dB*Bact - rB*Bact
      dSub  &lt;- -gmax    * Sub/(Sub + ks)*Bact + dB*Bact
      return(list(c(dBact,dSub)))
    })
  }

  state &lt;- c(Bact = 0.1,Sub = 100)
  tout  &lt;- seq(0, 50, by = 0.5)
  ## ode solves the model by integration ...
  return(as.data.frame(ode(y = state, times = tout, func = derivs,
    parms = pars)))
}

out &lt;- solveBact(pars)

mf  &lt;-par(mfrow = c(2,2))

plot(out$time, out$Bact, main = "Bacteria",
     xlab = "time, hour", ylab = "molC/m3", type = "l", lwd = 2)

## the sensitivity parameters
parRanges &lt;- data.frame(min = c(0.4, 0.4, 0.0), max = c(0.6, 0.6, 0.02))
rownames(parRanges)&lt;- c("gmax", "eff", "rB")
parRanges

tout &lt;- 0:50
## sensitivity to rB; equally-spaced parameters ("grid")
SensR &lt;- sensRange(func = solveBact, parms = pars, dist = "grid",
                   sensvar = "Bact", parRange = parRanges[3,], num = 50)

Sens  &lt;-summary(SensR)
plot(Sens, legpos = "topleft", xlab = "time, hour", ylab = "molC/m3",
     main = "Sensitivity to rB", mfrow = NULL)

## sensitivity to all; latin hypercube
Sens2 &lt;- summary(sensRange(func = solveBact, parms = pars, dist = "latin",
           sensvar = c("Bact", "Sub"), parRange = parRanges, num = 50))

## Plot all variables; plot mean +- sd, min max
plot(Sens2, xlab = "time, hour", ylab = "molC/m3",
     main = "Sensitivity to gmax,eff,rB", mfrow = NULL)

par(mfrow = mf)

## Select one variable for plotting; plot the quantiles
plot(Sens2, xlab = "time, hour", ylab = "molC/m3", which = "Bact", quant = TRUE)

## Add data
data &lt;- cbind(time = c(0,10,20,30), Bact = c(0,1,10,45))
plot(Sens2, xlab = "time, hour", ylab = "molC/m3", quant = TRUE, 
  obs = data, obspar = list(col = "darkblue", pch = 16, cex = 2))



</code></pre>

<hr>
<h2 id='Unif'>
Uniform Random Distribution
</h2><span id='topic+Unif'></span>

<h3>Description</h3>

<p>Generates uniformly distributed random parameter sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Unif(parRange, num)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Unif_+3A_parrange">parRange</code></td>
<td>
<p>the range (min, max) of the parameters, a matrix or a
data.frame with one row for each parameter, and two columns with the
minimum (1st) and maximum (2nd) value.
</p>
</td></tr>
<tr><td><code id="Unif_+3A_num">num</code></td>
<td>
<p>the number of random parameter sets to generate.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the uniform sampling, each parameter is uniformly random distributed
over its range.
</p>


<h3>Value</h3>

<p>a matrix with one row for each generated parameter set, and one column
per parameter.
</p>


<h3>Note</h3>

<p>For small sample sizes, the latin hypercube distributed parameter sets
(<code><a href="#topic+Latinhyper">Latinhyper</a></code>) may give better coverage in parameter space
than the uniform random design.
</p>


<h3>Author(s)</h3>

<p>Karline Soetaert &lt;karline.soetaert@nioz.nl&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Norm">Norm</a></code> for (multi)normally distributed random parameter sets.
</p>
<p><code><a href="#topic+Latinhyper">Latinhyper</a></code> to generates parameter sets using
latin hypercube sampling.
</p>
<p><code><a href="#topic+Grid">Grid</a></code> to generate random parameter sets arranged on a
regular grid
</p>
<p><code><a href="stats.html#topic+runif">runif</a></code> the R-default for generating uniformally distributed
random numbers.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 4 parameters
parRange &lt;- data.frame(min = c(0, 1, 2, 3), max = c(10, 9, 8, 7))
rownames(parRange) &lt;- c("par1", "par2", "par3", "par4")

## uniform
pairs(Unif(parRange, 100), main = "Uniformly random")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
