<!DOCTYPE html><html><head><title>Help for package som.nn</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {som.nn}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dist.fun.bubble'><p>Bubble distance functions for topological k-NN classifier</p></a></li>
<li><a href='#dist.fun.inverse'><p>Inverse exponential distance functions for topological k-NN classifier</p></a></li>
<li><a href='#dist.fun.linear'><p>Linear distance functions for topological k-NN classifier</p></a></li>
<li><a href='#dist.fun.tricubic'><p>Tricubic distance functions for topological k-NN classifier</p></a></li>
<li><a href='#dist.torus'><p>Torus distance matrix</p></a></li>
<li><a href='#enrich.dirty'><p>enrich training set with dirty mapped samples</p></a></li>
<li><a href='#get.border.neurons'><p>Get border neurons.</p></a></li>
<li><a href='#hexbinpie'><p>Plots the hexagonals and pi charts.</p>
Adapted code from package somplot.</a></li>
<li><a href='#initialize,SOMnn-method'><p>Constructor of SOMnn Class</p></a></li>
<li><a href='#make.codes.grid'><p>Makes a data.frame with codes coordinates</p></a></li>
<li><a href='#makehexbinplot'><p>makes the actual heagonal plot.</p>
Adapted code from package somplot.</a></li>
<li><a href='#norm.linear'><p>Linear normalisation</p></a></li>
<li><a href='#norm.softmax'><p>Softmax normalisation</p></a></li>
<li><a href='#plot_predictions'><p>Plots predicted samples as points into a plotted som.</p></a></li>
<li><a href='#plot,SOMnn,ANY-method'><p>Plot method for S4 class <code>SOMnn</code></p></a></li>
<li><a href='#predict,SOMnn-method'><p>predict method for S4 class <code>SOMnn</code></p></a></li>
<li><a href='#round.probabilities'><p>Advanced rounding of vectors</p></a></li>
<li><a href='#som.nn-package'><p>Topological k-NN Classifier Based on Self-Organising Maps</p></a></li>
<li><a href='#som.nn.accuracy'><p>Calculate accuracy measures</p></a></li>
<li><a href='#som.nn.all.accuracy'><p>Calculate overall accuracy</p></a></li>
<li><a href='#som.nn.confusion'><p>Calculate confusion matrix</p></a></li>
<li><a href='#som.nn.continue'><p>Continue hexagonal som training</p></a></li>
<li><a href='#som.nn.do.train'><p>Work hourse for hexagonal som training</p></a></li>
<li><a href='#som.nn.export.kohonen'><p>Export a som.nn model as object of type <code>kohonen</code></p></a></li>
<li><a href='#som.nn.export.som'><p>Export a som.nn model as object of type <code>SOM</code></p></a></li>
<li><a href='#som.nn.max.row'><p>Special version of maximum finder for SOMnn</p></a></li>
<li><a href='#som.nn.multitrain'><p>Multi-step hexagonal som training</p></a></li>
<li><a href='#som.nn.round.votes'><p>Rounds a dataframe with vectors of votes for SOMnn</p></a></li>
<li><a href='#som.nn.run.kernel'><p>calls the specified kernel for som training.</p></a></li>
<li><a href='#som.nn.set'><p>Set parameters for k-NN-like classifier in som.nn model</p></a></li>
<li><a href='#som.nn.som.experimental'><p>Work hourse for som training.</p></a></li>
<li><a href='#som.nn.som.gaussian'><p>Gaussian kernel for som training.</p></a></li>
<li><a href='#som.nn.som.internal'><p>Work hourse for som training.</p></a></li>
<li><a href='#som.nn.train'><p>Hexagonal som training</p></a></li>
<li><a href='#som.nn.validate'><p>Predict class labels for a validation dataset</p></a></li>
<li><a href='#som.nn.visual'><p>Mapping function for SOMnn</p></a></li>
<li><a href='#som.nn.visual.one'><p>Maps one vector to the SOM</p></a></li>
<li><a href='#SOMnn-class'><p>An S4 class to hold a model for the topological classifier som.nn</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Topological k-NN Classifier Based on Self-Organising Maps</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.4</td>
</tr>
<tr>
<td>Author:</td>
<td>Andreas Dominik</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andreas Dominik &lt;andreas.dominik@mni.thm.de&gt;</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>hexbin, class, kohonen, som, methods, graphics, grDevices,
stats, utils</td>
</tr>
<tr>
<td>Description:</td>
<td>A topological version of k-NN: An abstract model is build
             as 2-dimensional self-organising map. Samples of unknown
             class are predicted by mapping them on the SOM and analysing
             class membership of neurons in the neighbourhood.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-04-03 16:02:50 UTC; andreas</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-04-03 17:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dist.fun.bubble'>Bubble distance functions for topological k-NN classifier</h2><span id='topic+dist.fun.bubble'></span>

<h3>Description</h3>

<p>The function is used as distance-dependent weight <code class="reqn">w</code> for k-NN voting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.fun.bubble(x, sigma = 1.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.fun.bubble_+3A_x">x</code></td>
<td>
<p>Distance or <code>numeric</code> vector or matrix of distances.</p>
</td></tr>
<tr><td><code id="dist.fun.bubble_+3A_sigma">sigma</code></td>
<td>
<p>Maximum distance to be considered. Default is 1.1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns 1.0 for <code class="reqn">0 &lt; x \le \sigma</code> and 0.0 for <code class="reqn">x &gt; \sigma</code>.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>  Distance-dependent weight.
</pre></div>

<hr>
<h2 id='dist.fun.inverse'>Inverse exponential distance functions for topological k-NN classifier</h2><span id='topic+dist.fun.inverse'></span>

<h3>Description</h3>

<p>The function is used as distance-dependent weight <code class="reqn">w</code> for k-NN voting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.fun.inverse(x, sigma = 1.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.fun.inverse_+3A_x">x</code></td>
<td>
<p>Distance or <code>numeric</code> vector or matrix of distances.</p>
</td></tr>
<tr><td><code id="dist.fun.inverse_+3A_sigma">sigma</code></td>
<td>
<p>Maximum distance to be considered. Default is 1.1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns 1.0 for <code class="reqn">x = 0</code>, 0.0 for <code class="reqn">x \ge \sigma</code> and
</p>
<p style="text-align: center;"><code class="reqn">1 / (x+1)^(1/sigma)</code>
</p>

<p>for <code class="reqn">0 &lt; x &lt; \sigma</code>.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>  Distance-dependent weight.
</pre></div>

<hr>
<h2 id='dist.fun.linear'>Linear distance functions for topological k-NN classifier</h2><span id='topic+dist.fun.linear'></span>

<h3>Description</h3>

<p>The function is used as distance-dependent weight <code class="reqn">w</code> for k-NN voting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.fun.linear(x, sigma = 1.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.fun.linear_+3A_x">x</code></td>
<td>
<p>Distance or <code>numeric</code> vector of distances.</p>
</td></tr>
<tr><td><code id="dist.fun.linear_+3A_sigma">sigma</code></td>
<td>
<p>Maximum distance to be considered. Default is 1.1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns 1.0 for <code class="reqn">x = 0</code>, 0.0 for <code class="reqn">x \ge \sigma</code> and
</p>
<p style="text-align: center;"><code class="reqn">1 - x / \sigma</code>
</p>

<p>for <code class="reqn">0 &lt; x &lt; \sigma</code>.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>  Distance-dependent weight.
</pre></div>

<hr>
<h2 id='dist.fun.tricubic'>Tricubic distance functions for topological k-NN classifier</h2><span id='topic+dist.fun.tricubic'></span>

<h3>Description</h3>

<p>The tricubic function is used as distance-dependent weight <code class="reqn">w</code> for
k-NN voting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.fun.tricubic(x, sigma = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.fun.tricubic_+3A_x">x</code></td>
<td>
<p>Distance or <code>numeric</code> vector or matrix of distances.</p>
</td></tr>
<tr><td><code id="dist.fun.tricubic_+3A_sigma">sigma</code></td>
<td>
<p>Maximum distance to be considered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns 1.0 for <code class="reqn">x = 0</code>, 0.0 for <code class="reqn">x \ge \sigma</code> and
</p>
<p style="text-align: center;"><code class="reqn">w(x) = (1 - x^3 / \sigma^3)^3</code>
</p>

<p>for <code class="reqn">0 &lt; x &lt; \sigma</code>.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>  Distance-dependent weight.
</pre></div>

<hr>
<h2 id='dist.torus'>Torus distance matrix</h2><span id='topic+dist.torus'></span>

<h3>Description</h3>

<p>Calculates the distance matrix of points on the surface of a torus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist.torus(coors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dist.torus_+3A_coors">coors</code></td>
<td>
<p><code>data.frame</code> or <code>matrix</code> with two
columns with x- and y-coordinates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A rectangular plane is considered as torus (i.e. on an endless plane that contimues on the left,
when leaving at the right side, and in the same way connects top and bottom
border). Distances between two points on the plane are calculated as the shortest distance
between the points on the torus surface.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre> Complete distance matrix with diagonal and upper triangle values.
</pre></div>

<hr>
<h2 id='enrich.dirty'>enrich training set with dirty mapped samples</h2><span id='topic+enrich.dirty'></span>

<h3>Description</h3>

<p>Maps x to the SOM defined in model and makes a list of dirty neurons
(i.e. neurons with more then one class label mapped).
All training samples in these neurons are added to the training set
to enhance their training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>enrich.dirty(x, model, multiple)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="enrich.dirty_+3A_x">x</code></td>
<td>
<p>training data</p>
</td></tr>
<tr><td><code id="enrich.dirty_+3A_model">model</code></td>
<td>
<p>SOMnn model</p>
</td></tr>
<tr><td><code id="enrich.dirty_+3A_multiple">multiple</code></td>
<td>
<p>enhancement factor for dirty samples</p>
</td></tr>
</table>

<hr>
<h2 id='get.border.neurons'>Get border neurons.</h2><span id='topic+get.border.neurons'></span>

<h3>Description</h3>

<p>Returns a list of neurons which are on the border between 2 or more classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.border.neurons(p, classes, model, distance = 1.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.border.neurons_+3A_p">p</code></td>
<td>
<p>prediction for training data set</p>
</td></tr>
<tr><td><code id="get.border.neurons_+3A_classes">classes</code></td>
<td>
<p>vector of true class lables for prediction</p>
</td></tr>
<tr><td><code id="get.border.neurons_+3A_model">model</code></td>
<td>
<p>Object of class type <code>SOMnn</code></p>
</td></tr>
<tr><td><code id="get.border.neurons_+3A_distance">distance</code></td>
<td>
<p>maximum distance of 2 neurons to be the border. Default 1.1:
only direct neighbours.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function analyses all pairs of neurons with distance &lt;= <code>distance</code>.
If samples represented by the pair belong to more than one class, both neurons
are added to the list.
</p>


<h3>Value</h3>

<p>numeric vector with the indices of all border neurons.
</p>

<hr>
<h2 id='hexbinpie'>Plots the hexagonals and pi charts.
Adapted code from package somplot.</h2><span id='topic+hexbinpie'></span>

<h3>Description</h3>

<p>Plots the hexagonals and pi charts.
Adapted code from package somplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hexbinpie(
  x,
  y,
  kat,
  xbnds = range(x),
  ybnds = range(y),
  hbc = NA,
  pal = NA,
  hex = "gray",
  circ = "gray50",
  cnt = "black",
  show.counter.border,
  ...
)
</code></pre>

<hr>
<h2 id='initialize+2CSOMnn-method'>Constructor of SOMnn Class</h2><span id='topic+initialize+2CSOMnn-method'></span><span id='topic+initialize+2CANY+2CANY-method'></span>

<h3>Description</h3>

<p>The constructor creates a new object of type SOMnn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SOMnn'
initialize(
  .Object,
  name,
  codes,
  qerror,
  class.idx,
  classes,
  class.counts,
  class.freqs,
  confusion,
  measures,
  accuracy,
  xdim,
  ydim,
  len.total,
  toroidal,
  norm,
  norm.center,
  norm.scale,
  dist.fun,
  max.dist,
  strict
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_.object">.Object</code></td>
<td>
<p>SOMnn object</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_name">name</code></td>
<td>
<p>optional name of the model.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_codes">codes</code></td>
<td>
<p><code>data.frame</code> with codebook vectors of the som.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_qerror">qerror</code></td>
<td>
<p>sum of the mapping errors of the training data.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_class.idx">class.idx</code></td>
<td>
<p><code>numeric</code> index of column with categories.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_classes">classes</code></td>
<td>
<p><code>character</code> vector with names of categories.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_class.counts">class.counts</code></td>
<td>
<p><code>data.frame</code> with class hits for each neuron.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_class.freqs">class.freqs</code></td>
<td>
<p><code>data.frame</code> with class frequencies for each neuron
(freqs sum up to 1).</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_confusion">confusion</code></td>
<td>
<p><code>data.frame</code> with confusion matrix for training data.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_measures">measures</code></td>
<td>
<p><code>data.frame</code> with classes as rows and the
columns sensitivity, specificity and accuracy for each class.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_accuracy">accuracy</code></td>
<td>
<p>Overall accuracy.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_xdim">xdim</code></td>
<td>
<p>number of neurons in x-direction of the som.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_ydim">ydim</code></td>
<td>
<p>number of neurons in y-direction of the som.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_len.total">len.total</code></td>
<td>
<p>total number of training steps, performed to create the model.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_toroidal">toroidal</code></td>
<td>
<p><code>logical</code>; if TRUE, the map is toroidal (i.e. borderless).</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_norm">norm</code></td>
<td>
<p><code>logical</code>; if TRUE, data is normalised before training and mapping.
Parameters for normalisation of training data is stored in the model and
applied before mapping of test data.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_norm.center">norm.center</code></td>
<td>
<p>vector of centers for each column of training
data.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_norm.scale">norm.scale</code></td>
<td>
<p>vector of scale factors for each column of training
data.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_dist.fun">dist.fun</code></td>
<td>
<p><code>function</code>; kernel for the kNN classifier.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_max.dist">max.dist</code></td>
<td>
<p>maximum distance <code class="reqn">\sigma</code> for the kNN classifier.</p>
</td></tr>
<tr><td><code id="initialize+2B2CSOMnn-method_+3A_strict">strict</code></td>
<td>
<p>Minimum vote for the winner (if the winner's vote is smaller than strict,
&quot;unknown&quot; is reported as class label (<code>default = 0.8</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constructor needs not to be called directly, because the normal
way to create a SOMnn object is to use <code><a href="#topic+som.nn.train">som.nn.train</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
new.som &lt;- new("SOMnn", name = name,
              codes = codes,
              qerror = qerror,
              classes = classes, 
              class.idx = class.idx,
              class.counts = class.counts, 
              class.freqs = class.freqs,
              confusion = confusion, 
              measures = measures,
              accuracy = accuracy,
              xdim = xdim, 
              ydim = ydim, 
              len.total = len.total, 
              toroidal = toroidal,
              norm = norm, 
              norm.center = norm.center, 
              norm.scale = norm.scale,
              dist.fun = dist.fun, 
              max.dist = max.dist.
              strict = strict)

## End(Not run)

</code></pre>

<hr>
<h2 id='make.codes.grid'>Makes a data.frame with codes coordinates</h2><span id='topic+make.codes.grid'></span>

<h3>Description</h3>

<p>Coordinates of neurons of a som are calculated by
calling <code><a href="class.html#topic+somgrid">somgrid</a></code> to be consistent with
other som/kohonen packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.codes.grid(xdim, ydim, topo = "hexagonal")
</code></pre>

<hr>
<h2 id='makehexbinplot'>makes the actual heagonal plot.
Adapted code from package somplot.</h2><span id='topic+makehexbinplot'></span>

<h3>Description</h3>

<p>makes the actual heagonal plot.
Adapted code from package somplot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makehexbinplot(
  data,
  col = NA,
  show.legend = TRUE,
  legend.loc = "bottomright",
  legend.width = 4,
  window.width = NA,
  window.height = NA,
  onlyDefCols = FALSE,
  show.box = TRUE,
  edit.cols = FALSE,
  show.counter.border = 0.98,
  ...
)
</code></pre>

<hr>
<h2 id='norm.linear'>Linear normalisation</h2><span id='topic+norm.linear'></span>

<h3>Description</h3>

<p>Calculates a linear normalisation for the class frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.linear(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm.linear_+3A_x">x</code></td>
<td>
<p>vector of votes for classes</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function is applied to a vector to squeeze the values in a way that they sum up
to 1.0:
</p>
<p><code>som.nn.linnorm(x) = x / sum(x)</code>
</p>
<p>Linear normalisation is used to normalise class distrubution during
prediction. Results seems often more reasonable, compared to softmax. The
S4 <code>predict</code> function for Class <code>SOMnn</code> allows to specify
the normalisation function as parameter.
</p>


<h3>Value</h3>

<p>Vector of normalised values.
</p>

<hr>
<h2 id='norm.softmax'>Softmax normalisation</h2><span id='topic+norm.softmax'></span>

<h3>Description</h3>

<p>Calculates a softmax-like normalisation for the class frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.softmax(x, t = 0.2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm.softmax_+3A_x">x</code></td>
<td>
<p>vector of votes for classes</p>
</td></tr>
<tr><td><code id="norm.softmax_+3A_t">t</code></td>
<td>
<p>temperature parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Softmax function is applied to a vector to squeeze the values in a way that they sum up
to 1.0:
</p>
<p><code>som.nn.softmax(x) = exp(x/T) / sum(exp(x/T))</code>
</p>
<p>Low values for <code>T</code> result in a
strong separation of output values. High values for <code>T</code>
make output values more equal.
</p>


<h3>Value</h3>

<p>Vector of softmax normalised values.
</p>

<hr>
<h2 id='plot_predictions'>Plots predicted samples as points into a plotted som.</h2><span id='topic+plot_predictions'></span>

<h3>Description</h3>

<p>Plots predicted samples as points into a plotted som.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_predictions(grid, predict, pch.col, pch, ...)
</code></pre>

<hr>
<h2 id='plot+2CSOMnn+2CANY-method'>Plot method for S4 class <code>SOMnn</code></h2><span id='topic+plot+2CSOMnn+2CANY-method'></span><span id='topic+plot+2CSOMnn-method'></span>

<h3>Description</h3>

<p>Creates a plot of the hexagonal som in the model of type <code>SOMnn</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SOMnn,ANY'
plot(
  x,
  title = TRUE,
  col = NA,
  onlyDefCols = FALSE,
  edit.cols = FALSE,
  show.legend = TRUE,
  legend.loc = "bottomright",
  legend.width = 4,
  window.width = NA,
  window.height = NA,
  show.box = TRUE,
  show.counter.border = 0.98,
  predict = NULL,
  add = FALSE,
  pch.col = "black",
  pch = 19,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_x">x</code></td>
<td>
<p>trained som of type <code>SOMnn</code>.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_title">title</code></td>
<td>
<p><code>logical</code>; if TRUE, slots name and date are used as main title.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_col">col</code></td>
<td>
<p>defines colours for the classes of the dataset. Possible values include:
<code>NA</code>: default value; colours are generated with <code>rainbow</code>,
a <code>vector</code> of colour definitions or a
<code>data.frame</code> with categories in the first and respective colours in the second column.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_onlydefcols">onlyDefCols</code></td>
<td>
<p><code>logical</code>; if TRUE, only categories are plotted, for which colours are defined.
Default: FALSE.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_edit.cols">edit.cols</code></td>
<td>
<p><code>logical</code>; if TRUE, colour definitions can be edited interactively before plotting.
Default: FALSE.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_show.legend">show.legend</code></td>
<td>
<p><code>logical</code>; if TRUE, a legend is displayed,. Default: TRUE.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_legend.loc">legend.loc</code></td>
<td>
<p>Legend position as specified for <code><a href="graphics.html#topic+legend">legend</a></code>. Default is <code>"bottomright"</code>.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_legend.width">legend.width</code></td>
<td>
<p>size of the legend.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_window.width">window.width</code></td>
<td>
<p>Manual setting of window width. Default is NA.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_window.height">window.height</code></td>
<td>
<p>Manual setting of window height. Default is NA.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_show.box">show.box</code></td>
<td>
<p>Show frame around the plot . Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_show.counter.border">show.counter.border</code></td>
<td>
<p>Percentile as limit for the display of labels in the pie charts. Default is 0.98.
Higher counts are displayed as numbers in the neuron.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_predict">predict</code></td>
<td>
<p><code>data.frame</code> as returned by the <code>som.nn::predict</code> function
or a <code>data.frame</code> or matrix that follows the specification:
If columns <code>x</code> and <code>y</code> exist, these are used as coordinates
for the traget neuron; otherwise the first two columns are used.
Default: NULL.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_add">add</code></td>
<td>
<p><code>logical</code>; if TRUE, points are plotted on an existing plot. This can be used to
stepwise plot
points of different classes with different colours or symbols.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_pch.col">pch.col</code></td>
<td>
<p>Colour of the markers for predicted samples.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_pch">pch</code></td>
<td>
<p>Symbol of the markers for predicted samples.</p>
</td></tr>
<tr><td><code id="plot+2B2CSOMnn+2B2CANY-method_+3A_...">...</code></td>
<td>
<p>More parameters as well as general
plot parameters are allowed; see <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In addition to the required parameters, many options can be
specified to plot predicted samples and to modify colours, legend and scaling.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## get example data and add class labels:
data(iris)
species &lt;- iris$Species

## train with default radius = diagonal / 2:
rlen &lt;- 500
som &lt;- som.nn.train(iris, class.col = "Species", kernel = "internal",
                    xdim = 15, ydim = 9, alpha = 0.2, len = rlen, 
                    norm = TRUE, toroidal = FALSE)


## continue training with different alpha and radius;
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 5)
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 2)

## predict some samples:
unk &lt;- iris[,!(names(iris) %in% "Species")]

setosa &lt;- unk[species=="setosa",]
setosa &lt;- setosa[sample(nrow(setosa), 20),]

versicolor &lt;- unk[species=="versicolor",]
versicolor &lt;- versicolor[sample(nrow(versicolor), 20),]

virginica &lt;- unk[species=="virginica",]
virginica &lt;- virginica[sample(nrow(virginica), 20),]

p &lt;- predict(som, unk)
head(p)

## plot:
plot(som)
dev.off()
plot(som, predict = predict(som, setosa))
plot(som, predict = predict(som, versicolor), add = TRUE, pch.col = "magenta", pch = 17)
plot(som, predict = predict(som, virginica), add = TRUE, pch.col = "white", pch = 8)

</code></pre>

<hr>
<h2 id='predict+2CSOMnn-method'>predict method for S4 class <code>SOMnn</code></h2><span id='topic+predict+2CSOMnn-method'></span>

<h3>Description</h3>

<p>Predicts categories for a table of data, based on the hexagonal som in the model.
This S4 method is a wrapper for the predict method stored in the slot <code>predict</code>
of a model of type SOMnn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SOMnn'
predict(object, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict+2B2CSOMnn-method_+3A_object">object</code></td>
<td>
<p>object of type <code>SOMnn</code>.</p>
</td></tr>
<tr><td><code id="predict+2B2CSOMnn-method_+3A_x">x</code></td>
<td>
<p><code>data.frame</code> with rows of data to be predicted.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the winner neuron in <code>codes</code> for
each test vector in <code>x</code>.
<code>x</code> is organised as one vector per row and must have
the same number of columns (i.e. dimensions) and the identical column names
as stored in the SOMnn object.
</p>
<p>If data have been normalised during training, the same normalisation is applied
to the unknown data to be predicted.
</p>
<p>Probablilities are softmax normalised by default.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>       \code{data.frame} with columns: 
               \code{winner}, \code{x}, \code{y}, the predicted probabilities
               for all categories and the prediction 
               as category index (column name \code{prediction}) and
               class label (column name \code{pred.class}).
</pre></div>

<hr>
<h2 id='round.probabilities'>Advanced rounding of vectors</h2><span id='topic+round.probabilities'></span>

<h3>Description</h3>

<p>Rounds a vector of probabilities preserving their sum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'probabilities'
round(x, digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="round.probabilities_+3A_x">x</code></td>
<td>
<p><code>numeric</code> vector of values.</p>
</td></tr>
<tr><td><code id="round.probabilities_+3A_digits">digits</code></td>
<td>
<p>demanded precision</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, if a vector of floating point values is rounded,
the sum is not preserverd.
For a vector of probabilities (which sum up to 1.0), this may lead to
strange results.
This function rounds all values of the vector and takes care, that
the sum ist not changed (with a precision given in <code>digits</code>).
</p>

<hr>
<h2 id='som.nn-package'>Topological k-NN Classifier Based on Self-Organising Maps</h2><span id='topic+som.nn'></span><span id='topic+som.nn-package'></span>

<h3>Description</h3>

<p>The package <code>som.nn</code> provides tools to train self-organising maps
and predict class memberships by means of a k-NN-like classifier.
</p>


<h3>Details</h3>

<p>The functions <code><a href="#topic+som.nn.train">som.nn.train</a></code> and <code><a href="#topic+som.nn.continue">som.nn.continue</a></code> are used
train and re-train self-organising maps. The training can be performed with functions
of the packages
<span class="pkg">kohonen</span>, <span class="pkg">som</span>, <span class="pkg">class</span> or with pure-R-implementations with
distance function <code>bubble</code> (kernel <code>internal</code>) or
<code>gaussian</code> (kernel <code>gaussian</code>).
(Remark: The pure-R-impelementations actually are faster as the external calls to
C implementations in the above-mentioned packages!).
</p>
<p>In contrast to a normal som training, class lables are required for all
training samples. These class lables are used to assign classes to the
codebook vectors (i.e. the neurons of the map) after the training and build
the set of reference
vectors. This reference is used for nearest-neigbour classification.
</p>
<p>The nearest neighbour classifier is implemented as predict method.
It is controlled by the following parameters:
</p>

<ul>
<li> <p><code>dist.fun</code>: the distance function to weight the distance of reference
vectors and the sample to be predicted.
</p>
</li>
<li> <p><code>max.dist</code>: the maximum distance to be considered.
</p>
</li></ul>

<p>Some distance functions are provided in the package (linear, bubble, inverse
and tricubic) but any custom function scan be defined as well.
</p>
<p>The prediction differs significantly from a standard nearest-neighbour classifier, because
the neighbourhood is not defined by the distance between reference vectors and
unknown sample vector. Instead the neighbourhood of the neurons on the
self-oranising map is used.
</p>
<p>Because the som have been generated by an unsupervised training, the classifier is
robust against overtraining.
</p>
<p>In addition the abstract model can be visualised as 2-dimensional map, using
the plot method.
</p>

<hr>
<h2 id='som.nn.accuracy'>Calculate accuracy measures</h2><span id='topic+som.nn.accuracy'></span>

<h3>Description</h3>

<p>Calculates the sensitivity, specificity and overall accuracy for a prediction result
if the corresponding vector of true class labels
is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.accuracy(x, class.labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.accuracy_+3A_x">x</code></td>
<td>
<p><code>data.frame</code> with the predictions as returned by the
SOM.nn predict method.</p>
</td></tr>
<tr><td><code id="som.nn.accuracy_+3A_class.labels">class.labels</code></td>
<td>
<p><code>vector</code> of correct class labels for the predictions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Sensitivity</strong> is the classifier's ability to correctly identify samples of a specific class A.
It is defined as
</p>
<p style="text-align: center;"><code class="reqn">sens_{A} = TP_{A} / (TP_{A} + FN_{A})</code>
</p>

<p>with  TP = true positives and FN = false negatives. This is equivalent to the
ratio of (correctly identified samples of class A) / (total number of samples of class A).
</p>
<p><strong>Specificity</strong> is the classifier's ability to correctly identify samples not
of a specific class A.
It is defined as
</p>
<p style="text-align: center;"><code class="reqn">spec_{A} = TN_{A} / (TN_{A} + FP_{A})</code>
</p>

<p>with  TN = true negatives and FP = false positives. This is equivalent to the
ratio of (correctly identified samples not in class A) / (total number of samples not in class A).
</p>
<p><strong>Accuracy</strong> is the classifier's ability to correctly classify samples of
a specific class A.
It is defined as
</p>
<p style="text-align: center;"><code class="reqn">acc_{A} = (TP_{A} + TN_{A}) / total</code>
</p>

<p>with  TP = true positives, TN = true negatives and total = total number of samples of a class.
This is equivalent to the
ratio of (correctly classified samples) / (total number of samples).
</p>


<h3>Value</h3>

<p><code>data.frame</code> containing sensitivity, specificity and accuracy for all
class labels in the data set.
</p>

<hr>
<h2 id='som.nn.all.accuracy'>Calculate overall accuracy</h2><span id='topic+som.nn.all.accuracy'></span>

<h3>Description</h3>

<p>Calculates the accuracy over all class lables for a prediction result
if the corresponding vector of true class labels
is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.all.accuracy(x, class.labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.all.accuracy_+3A_x">x</code></td>
<td>
<p><code>data.frame</code> with the predictions as returned by the
SOM.nn predict method.</p>
</td></tr>
<tr><td><code id="som.nn.all.accuracy_+3A_class.labels">class.labels</code></td>
<td>
<p><code>vector</code> of correct class labels for the predictions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It is defined as
</p>
<p style="text-align: center;"><code class="reqn">acc = (TP + TN) / total = sum(diag(cmat)) / sum(cmat)</code>
</p>

<p>with  TP = true positives, TN = true negatives and total = total number of samples of a class.
This is equivalent to the
ratio of (correctly classified samples) / (total number of samples).
</p>


<h3>Value</h3>

<p><code>one value</code> overall accuracy.
</p>

<hr>
<h2 id='som.nn.confusion'>Calculate confusion matrix</h2><span id='topic+som.nn.confusion'></span>

<h3>Description</h3>

<p>Calculates the confusion matrix for a prediction result
if the corresponding vector of true class labels
is provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.confusion(x, class.labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.confusion_+3A_x">x</code></td>
<td>
<p><code>data.frame</code> with the predictions as returned by the
SOM.nn predict method.</p>
</td></tr>
<tr><td><code id="som.nn.confusion_+3A_class.labels">class.labels</code></td>
<td>
<p><code>vector</code> of correct class labels for the predictions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confusion matrix (also called table of confusion) displays the number
of predicted class labels for each actual class. Example:
</p>

<table>
<tr>
 <td style="text-align: right;">
</td><td style="text-align: right;"> pred. cat </td><td style="text-align: right;"> pred. dog  </td><td style="text-align: right;"> pred. rabbit </td><td style="text-align: right;"> unknown </td>
</tr>
<tr>
 <td style="text-align: right;">
actual cat     </td><td style="text-align: right;">   5       </td><td style="text-align: right;">   3        </td><td style="text-align: right;">   0          </td><td style="text-align: right;">  0      </td>
</tr>
<tr>
 <td style="text-align: right;">
actual dog     </td><td style="text-align: right;">   2       </td><td style="text-align: right;">   3        </td><td style="text-align: right;">   1          </td><td style="text-align: right;">  0      </td>
</tr>
<tr>
 <td style="text-align: right;">
actual rabbit  </td><td style="text-align: right;">   0       </td><td style="text-align: right;">   2        </td><td style="text-align: right;">   9          </td><td style="text-align: right;">  2
</td>
</tr>

</table>

<p>The confusion matrix includes a column <code>unknown</code> displaying the samples
for which no unambiguous prediction is possible.
</p>


<h3>Value</h3>

<p><code>data.frame</code> containing the confusion matrix.
</p>

<hr>
<h2 id='som.nn.continue'>Continue hexagonal som training</h2><span id='topic+som.nn.continue'></span>

<h3>Description</h3>

<p>An existing self-organising map with hexagonal tolology is further trained and
a model created for prediction of unknown samples.
In contrast to a &quot;normal&quot; som, class-labels for all samples of
the training set are required to build the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.continue(
  model,
  x,
  kernel = "internal",
  len = 0,
  alpha = 0.2,
  radius = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.continue_+3A_model">model</code></td>
<td>
<p>model of type <code>SOMnn</code>.</p>
</td></tr>
<tr><td><code id="som.nn.continue_+3A_x">x</code></td>
<td>
<p>data.fame with training data. Samples are requested as rows and taken randomly for the
training steps. All
columns except of the class lables are considered to be attributes and parts of
the training vector.
<code>x</code> must include the same columns as the data.frame with which the model
have been trained originally.
One column is needed as class labels. The column with class
lables is selected by the slot <code>class.idx</code> of the model.</p>
</td></tr>
<tr><td><code id="som.nn.continue_+3A_kernel">kernel</code></td>
<td>
<p>Kernel for som training. One of the predefined kernels
<code>"bubble"</code> and <code>"gaussian"</code> == train with the R-implementation or
<code>"SOM"</code> == train with <code><a href="class.html#topic+SOM">SOM</a></code> or
<code>"kohonen"</code> == train with <code><a href="kohonen.html#topic+som">som</a></code> (<code>kohonen::som</code>) or
<code>"som"</code> == train with <code><a href="som.html#topic+som">som</a></code> (<code>som::som</code>).
If a function is specified (as closure, not as character)
the specified custom function is used for training.</p>
</td></tr>
<tr><td><code id="som.nn.continue_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.continue_+3A_alpha">alpha</code></td>
<td>
<p>initial training rate; default 0.02.</p>
</td></tr>
<tr><td><code id="som.nn.continue_+3A_radius">radius</code></td>
<td>
<p>inital radius for SOM training.
If Gaussian distance function is used, radius corresponds to sigma.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any specified custom kernel function is used for som training. The function must match the
signature <code>kernel(data, grid, rlen, alpha, radius, init, toroidal)</code>, with
arguments:
</p>

<ul>
<li> <p><code>data</code> <code>numeric</code> matrix of training data; one sample per row
</p>
</li>
<li> <p><code>classes:</code> optional <code>charater</code> vector of classes for training data
</p>
</li>
<li> <p><code>grid</code> somgrid, generated with <code><a href="class.html#topic+somgrid">somgrid</a></code>
</p>
</li>
<li> <p><code>rlen</code> number of training steps
</p>
</li>
<li> <p><code>alpha</code> training rate
</p>
</li>
<li> <p><code>radius</code> training radius
</p>
</li>
<li> <p><code>init</code> <code>numeric</code> matrix of initial codebook vectors; one code per row
</p>
</li>
<li> <p><code>toroidal</code> <code>logical</code>; TRUE, if the topology of grid is toroidal
</p>
</li></ul>

<p>The returned value must be a list with at minimum one element
</p>

<ul>
<li> <p><code>codes:</code> <code>numeric</code> matrix of result codebook vectors; one code per row
</p>
</li></ul>



<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the trained model
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'>## get example data and add class labels:
data(iris)
species &lt;- iris$Species

## train with default radius = diagonal / 2:
rlen &lt;- 500
som &lt;- som.nn.train(iris, class.col = "Species", kernel = "internal",
                    xdim = 15, ydim = 9, alpha = 0.2, len = rlen, 
                    norm = TRUE, toroidal = FALSE)


## continue training with different alpha and radius;
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 5)
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 2)

## predict some samples:
unk &lt;- iris[,!(names(iris) %in% "Species")]

setosa &lt;- unk[species=="setosa",]
setosa &lt;- setosa[sample(nrow(setosa), 20),]

versicolor &lt;- unk[species=="versicolor",]
versicolor &lt;- versicolor[sample(nrow(versicolor), 20),]

virginica &lt;- unk[species=="virginica",]
virginica &lt;- virginica[sample(nrow(virginica), 20),]

p &lt;- predict(som, unk)
head(p)

## plot:
plot(som)
dev.off()
plot(som, predict = predict(som, setosa))
plot(som, predict = predict(som, versicolor), add = TRUE, pch.col = "magenta", pch = 17)
plot(som, predict = predict(som, virginica), add = TRUE, pch.col = "white", pch = 8)

</code></pre>

<hr>
<h2 id='som.nn.do.train'>Work hourse for hexagonal som training</h2><span id='topic+som.nn.do.train'></span>

<h3>Description</h3>

<p>The function is called by <code><a href="#topic+som.nn.train">som.nn.train</a></code> and <code><a href="#topic+som.nn.continue">som.nn.continue</a></code>
to train self-organising map with hexagonal tolology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.do.train(
  x,
  class.idx,
  kernel = "internal",
  xdim,
  ydim,
  toroidal,
  len,
  alpha,
  radius = 0,
  norm,
  norm.center,
  norm.scale,
  dist.fun,
  max.dist,
  strict,
  name,
  continue,
  len.total,
  codes = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.do.train_+3A_x">x</code></td>
<td>
<p>data.fame with training data. Samples are requested as rows and taken randomly for the
training steps. All
columns except of the class lables are considered to be attributes and parts of
the training vector.
One column is needed as class labels. The column with class
lables is selected by the argument <code>class.col</code>.
If class is not given, the first column is used as class labels.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_class.idx">class.idx</code></td>
<td>
<p>index of the column with as class labels
(after beeing coerced to character).</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_kernel">kernel</code></td>
<td>
<p>kernel to be used for training.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_xdim">xdim</code></td>
<td>
<p>dimension in x-direction.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_ydim">ydim</code></td>
<td>
<p>dimension in y-direction.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_toroidal">toroidal</code></td>
<td>
<p><code>logical</code>; if TRUE an endless som is trained as on the
surface of a torus.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_alpha">alpha</code></td>
<td>
<p>initial training rate.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_radius">radius</code></td>
<td>
<p>inital radius for SOM training.
Gaussian distance function is used, radius corresponds to sigma.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_norm">norm</code></td>
<td>
<p>logical; if TRUE, input data is normalised with <code>scale(x, TRUE, TRUE)</code>.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_dist.fun">dist.fun</code></td>
<td>
<p>parameter for k-NN prediction. Function is used to calculate
distance-dependent weights. Any distance function must accept the two parameters
<code>x</code> (distance) and <code>sigma</code> (maximum distance to give a weight &gt; 0.0).</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_max.dist">max.dist</code></td>
<td>
<p>parameter for k-NN prediction. Parameter <code>sigma</code> for dist.fun.
In order to avoid rounding issues, it is recommended not to
use exact integers as limit, but values like 1.1 to make sure, that all
neurons with distance 1 are included.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_strict">strict</code></td>
<td>
<p>difference of maximum votes to assign class label
(if the difference between the to two votes is smaller or equal to
strict, unknown is predicted). <code>default = 0.3.</code></p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_name">name</code></td>
<td>
<p>name for the model. Name will be stored as slot <code>model@name</code> in the
trained model.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_continue">continue</code></td>
<td>
<p>logical; if TRUE, the codebook vectors of the model, given in argument <code>model</code> will be used
as initial codes.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_len.total">len.total</code></td>
<td>
<p>number of previuos training steps.</p>
</td></tr>
<tr><td><code id="som.nn.do.train_+3A_codes">codes</code></td>
<td>
<p>codes of a model to be used for initialisation.</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the trained model
</pre></div>

<hr>
<h2 id='som.nn.export.kohonen'>Export a som.nn model as object of type <code>kohonen</code></h2><span id='topic+som.nn.export.kohonen'></span>

<h3>Description</h3>

<p>An existing model of type <code>SOMnn</code> is exported as
object of type <code>kohonen</code> for use with the tools of the
package <code>kohonen</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.export.kohonen(model, train)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.export.kohonen_+3A_model">model</code></td>
<td>
<p>model of type <code>SOMnn</code>.</p>
</td></tr>
<tr><td><code id="som.nn.export.kohonen_+3A_train">train</code></td>
<td>
<p>training data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Training data is necessary to generate the kohonen object.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>    Vist of type \code{kohonen} with the trained som.
            See \code{\link[kohonen]{som}} for details.
</pre></div>

<hr>
<h2 id='som.nn.export.som'>Export a som.nn model as object of type <code>SOM</code></h2><span id='topic+som.nn.export.som'></span>

<h3>Description</h3>

<p>An existing model of type <code>SOMnn</code> is exported as
object of type <code>SOM</code> for use with the tools of the
package <code>class</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.export.som(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.export.som_+3A_model">model</code></td>
<td>
<p>model of type <code>SOMnn</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>    List of type \code{SOM} with the trained som.
            See \code{\link[class]{SOM}} for details.
</pre></div>

<hr>
<h2 id='som.nn.max.row'>Special version of maximum finder for SOMnn</h2><span id='topic+som.nn.max.row'></span>

<h3>Description</h3>

<p>Returns the index of the column with the maximum value for each row of a
data.frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.max.row(x, strict = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.max.row_+3A_x">x</code></td>
<td>
<p>data.frame or matrix</p>
</td></tr>
<tr><td><code id="som.nn.max.row_+3A_strict">strict</code></td>
<td>
<p>minimum for max vote</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A class is only assigned, if the vote for one class is higher than for
all others.
If more than one element has the same maximum value, 0 is returned.
</p>


<h3>Value</h3>

<p>index of max value for each row or 0, if more
than one element has the same maximum value.
</p>

<hr>
<h2 id='som.nn.multitrain'>Multi-step hexagonal som training</h2><span id='topic+som.nn.multitrain'></span>

<h3>Description</h3>

<p>A self-organising map with hexagonal tolology is trained
in several steps and
a model of Type SOMnn created for prediction of unknown samples.
In contrast to a &quot;normal&quot; som, class-labels for all samples of
the training set are required to build the topological model after SOM training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.multitrain(
  x,
  class.col = 1,
  kernel = "internal",
  xdim = 7,
  ydim = 5,
  toroidal = FALSE,
  len = c(0),
  alpha = c(0.2),
  radius = c(0),
  focus = 1,
  norm = TRUE,
  dist.fun = dist.fun.inverse,
  max.dist = 1.1,
  name = "som.nn job"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.multitrain_+3A_x">x</code></td>
<td>
<p>data.fame with training data. Samples are requested as rows and taken randomly for the
training steps. All
columns except of the class lables are considered to be attributes and parts of
the training vector.
One column is needed as class labels. The column with class
lables is selected by the argument <code>class.col</code>.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_class.col">class.col</code></td>
<td>
<p>single string or number. If class is a string, it is considered to be the
name of the column with class labels.
If class is a number, the respective column will be used as class labels
(after beeing coerced to character).
Default is 1.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_kernel">kernel</code></td>
<td>
<p>kernel for som training. One of the predefined kernels
<code>"bubble"</code>: train with the R-implementation or
<code>"gaussian"</code>: train with the R-implementation of the Gaussian kernel or
<code>"SOM"</code>: train with <code><a href="class.html#topic+SOM">SOM</a></code> (<code>class::SOM</code>) or
<code>"kohonen"</code>: train with <code><a href="kohonen.html#topic+som">som</a></code> (<code>kohonen::som</code>) or
<code>"som"</code>: train with <code><a href="som.html#topic+som">som</a></code> (<code>som::som</code>).
If a function is specified (as closure, not as character)
the specified custom function is used for training.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_xdim">xdim</code></td>
<td>
<p>dimension in x-direction.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_ydim">ydim</code></td>
<td>
<p>dimension in y-direction.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_toroidal">toroidal</code></td>
<td>
<p><code>logical</code>; if TRUE an endless som is trained as on the
surface of a torus. default: FALSE.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_len">len</code></td>
<td>
<p><code>vector</code> of numberis of steps to be trained (steps - not epochs!).
the length of len defines the number of training rounds tobe performed.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_alpha">alpha</code></td>
<td>
<p>initial training rate; the learning rate is decreased linearly to 0.0 for the laset training step.
Default: 0.02.
If length(<code>alpha</code>) &gt; 1, the length must be tha same as for <code>len</code>
and defines different alphas for each training round.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_radius">radius</code></td>
<td>
<p>inital radius for SOM training.
If Gaussian distance function is used, radius corresponds to sigma.
The distance is decreased linearly to 1.0 for the last training step.
If <code>radius = 0</code> (default), the diameter of the SOM is used as initial
radius.
If length(<code>radius</code>) &gt; 1, the length must be tha same as for <code>len</code>
and defines different radii for each training round.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_focus">focus</code></td>
<td>
<p>Enhancement factor for focussing of training of &quot;dirty&quot; samples.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_norm">norm</code></td>
<td>
<p>logical; if TRUE, input data is normalised by <code>scale(x, TRUE, TRUE)</code>.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_dist.fun">dist.fun</code></td>
<td>
<p>parameter for k-NN prediction: Function used to calculate
distance-dependent weights. Any distance function must accept the two parameters
<code>x</code> (distance) and <code>sigma</code> (maximum distance to give a weight &gt; 0.0).
Default is <code>dist.fun.inverse</code>.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_max.dist">max.dist</code></td>
<td>
<p>parameter for k-NN prediction: Parameter <code>sigma</code> for dist.fun.
Default is 2.1. In order to avoid rounding issues, it is recommended not to
use exact integers as limit, but values like 1.1 to make sure, that all
neurons within distance 1 are included.</p>
</td></tr>
<tr><td><code id="som.nn.multitrain_+3A_name">name</code></td>
<td>
<p>optional name for the model. Name will be stored as slot <code>model@name</code> in the
trained model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Besides of the predefined kernels
<code>"bubble", "gaussian", "SOM", "kohonen" or "som"</code>,
any specified custom kernel function can be used for som training. The function must match the
signature <code>kernel(data, grid, rlen, alpha, radius, init, toroidal)</code>, with
arguments:
</p>

<ul>
<li> <p><code>data:</code> <code>numeric</code> matrix of training data; one sample per row
</p>
</li>
<li> <p><code>classes:</code> optional <code>charater</code> vector of classes for training data
</p>
</li>
<li> <p><code>grid:</code> somgrid, generated with <code><a href="class.html#topic+somgrid">somgrid</a></code>
</p>
</li>
<li> <p><code>rlen:</code> number of training steps
</p>
</li>
<li> <p><code>alpha:</code> training rate
</p>
</li>
<li> <p><code>radius:</code> training radius
</p>
</li>
<li> <p><code>init:</code> <code>numeric</code> matrix of initial codebook vectors; one code per row
</p>
</li>
<li> <p><code>toroidal:</code> <code>logical</code>; TRUE, if the topology of grid is toroidal
</p>
</li></ul>

<p>The returned value must be a list with at minimum one element
</p>

<ul>
<li> <p><code>codes:</code> <code>numeric</code> matrix of result codebook vectors; one code per row
</p>
</li></ul>

<p>If <code>focus &gt; 1</code> enhancement of dirty samples is activated:
Training samples, mapped to neuron with &gt;1 classes, are preferred in the next training step.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the trained model
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'>## get example data and add class labels:
data(iris)
species &lt;- iris$Species

## train with default radius = diagonal / 2:
rlen &lt;- 500
som &lt;- som.nn.train(iris, class.col = "Species", kernel = "internal",
                    xdim = 15, ydim = 9, alpha = 0.2, len = rlen, 
                    norm = TRUE, toroidal = FALSE)


## continue training with different alpha and radius;
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 5)
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 2)

## predict some samples:
unk &lt;- iris[,!(names(iris) %in% "Species")]

setosa &lt;- unk[species=="setosa",]
setosa &lt;- setosa[sample(nrow(setosa), 20),]

versicolor &lt;- unk[species=="versicolor",]
versicolor &lt;- versicolor[sample(nrow(versicolor), 20),]

virginica &lt;- unk[species=="virginica",]
virginica &lt;- virginica[sample(nrow(virginica), 20),]

p &lt;- predict(som, unk)
head(p)

## plot:
plot(som)
dev.off()
plot(som, predict = predict(som, setosa))
plot(som, predict = predict(som, versicolor), add = TRUE, pch.col = "magenta", pch = 17)
plot(som, predict = predict(som, virginica), add = TRUE, pch.col = "white", pch = 8)

</code></pre>

<hr>
<h2 id='som.nn.round.votes'>Rounds a dataframe with vectors of votes for SOMnn</h2><span id='topic+som.nn.round.votes'></span>

<h3>Description</h3>

<p>Each row of the <code>data.frame</code> may sum up to 1.0
before and after rounding.
Rounding is performed with <code>round.probabilities</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.round.votes(votes, classes, digits = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.round.votes_+3A_votes">votes</code></td>
<td>
<p><code>data.frame</code> with rows of class probabilities.</p>
</td></tr>
<tr><td><code id="som.nn.round.votes_+3A_classes">classes</code></td>
<td>
<p><code>character</code> vector with name of categories.
Names must match the column names of probabilities to be
rounded.</p>
</td></tr>
<tr><td><code id="som.nn.round.votes_+3A_digits">digits</code></td>
<td>
<p>precision; default = 2.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>data.frame</code> with roundes rows of class probabilities.
other columns are not affected.
</p>

<hr>
<h2 id='som.nn.run.kernel'>calls the specified kernel for som training.</h2><span id='topic+som.nn.run.kernel'></span>

<h3>Description</h3>

<p>calls the specified kernel for som training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.run.kernel(
  data,
  classes = "no classes",
  kernel = c("internal", "SOM"),
  xdim,
  ydim,
  len = 100,
  alpha = 0.05,
  radius = 1,
  init,
  toroidal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.run.kernel_+3A_data">data</code></td>
<td>
<p><code>numeric</code> matrix or data.frame with training data.
Only numeric columns of data.frame are used for training.</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_classes">classes</code></td>
<td>
<p><code>character</code> vector with class labels (only necessary for
supervised training kernels).</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_kernel">kernel</code></td>
<td>
<p>kernel to be used</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_xdim">xdim</code></td>
<td>
<p>number of neurons in x</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_ydim">ydim</code></td>
<td>
<p>number of neurons in y</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_alpha">alpha</code></td>
<td>
<p>initial learning rate (decreased to 0).</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_radius">radius</code></td>
<td>
<p>initial radius (decreased to 1).</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_init">init</code></td>
<td>
<p><code>numeric</code> matrix or data.frame with codes for initialisation.</p>
</td></tr>
<tr><td><code id="som.nn.run.kernel_+3A_toroidal">toroidal</code></td>
<td>
<p>true if doughnut-shaped som.</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>    list with elements \code{codes} and \code{grid}.
</pre></div>

<hr>
<h2 id='som.nn.set'>Set parameters for k-NN-like classifier in som.nn model</h2><span id='topic+som.nn.set'></span>

<h3>Description</h3>

<p>Parameters for the k-NN-like classification can be set for an existing model of type SOMnn
after training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.set(
  model,
  x,
  dist.fun = NULL,
  max.dist = NULL,
  strict = NULL,
  name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.set_+3A_model">model</code></td>
<td>
<p>model of type <code>SOMnn</code>.</p>
</td></tr>
<tr><td><code id="som.nn.set_+3A_x">x</code></td>
<td>
<p>data.fame with training data. Samples are requested as rows and taken randomly for the
training steps. All
columns except of the class lables are considered to be attributes and parts of
the training vector.
<code>x</code> must include the same columns as the data.frame with which the model
have been trained originally.
One column is needed as class labels. The column with class
lables is selected by the slot <code>class.idx</code> of the model.</p>
</td></tr>
<tr><td><code id="som.nn.set_+3A_dist.fun">dist.fun</code></td>
<td>
<p>distance function for weighting distances between codebook
vectors on the som (kernel for k-NN classifier).</p>
</td></tr>
<tr><td><code id="som.nn.set_+3A_max.dist">max.dist</code></td>
<td>
<p>maximum distance to be considered by the nearest-neighbour counting.</p>
</td></tr>
<tr><td><code id="som.nn.set_+3A_strict">strict</code></td>
<td>
<p>strictness for class label assignment. Default = 0.8.</p>
</td></tr>
<tr><td><code id="som.nn.set_+3A_name">name</code></td>
<td>
<p>new name of the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The distance function defines the behaviour of the k-nearest-neighbour algorithm.
Choices for the distance function include <code>dist.fun.inverse</code> or <code>dist.fun.tricubic</code>,
as defined in this package, or any other function that accepts exactly two arguments <code>x</code>
(the distance) and <code>sigma</code> (a parameter defined by max.distance).
</p>
<p>A data set must be presented to calculate the accuracy statistics of the
modified predictor.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the updated model.
</pre></div>


<h3>See Also</h3>

<p><code><a href="#topic+dist.fun.bubble">dist.fun.bubble</a></code>, <code><a href="#topic+dist.fun.linear">dist.fun.linear</a></code>,
<code><a href="#topic+dist.fun.inverse">dist.fun.inverse</a></code>, <code><a href="#topic+dist.fun.tricubic">dist.fun.tricubic</a></code>.
</p>

<hr>
<h2 id='som.nn.som.experimental'>Work hourse for som training.</h2><span id='topic+som.nn.som.experimental'></span>

<h3>Description</h3>

<p>Function is the kernel <code>internal</code> for som training, implemented
in pure R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.som.experimental(
  data,
  grid,
  len = 100,
  alpha = 0.05,
  radius,
  init,
  toroidal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.som.experimental_+3A_data">data</code></td>
<td>
<p>matrix with training data.</p>
</td></tr>
<tr><td><code id="som.nn.som.experimental_+3A_grid">grid</code></td>
<td>
<p>somgrid object</p>
</td></tr>
<tr><td><code id="som.nn.som.experimental_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.som.experimental_+3A_alpha">alpha</code></td>
<td>
<p>learning rate c(first, last).</p>
</td></tr>
<tr><td><code id="som.nn.som.experimental_+3A_radius">radius</code></td>
<td>
<p>radius c(first, last).</p>
</td></tr>
<tr><td><code id="som.nn.som.experimental_+3A_init">init</code></td>
<td>
<p>codes for initialisation.</p>
</td></tr>
<tr><td><code id="som.nn.som.experimental_+3A_toroidal">toroidal</code></td>
<td>
<p>true if doughnut-shaped som.</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>    S3 object of type \code{kohonen} with the trained som.
</pre></div>

<hr>
<h2 id='som.nn.som.gaussian'>Gaussian kernel for som training.</h2><span id='topic+som.nn.som.gaussian'></span>

<h3>Description</h3>

<p>Function is the kernel <code>gaussian</code> for som training, implemented
in pure R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.som.gaussian(
  data,
  grid,
  len = 100,
  alpha = 0.05,
  radius,
  init,
  toroidal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.som.gaussian_+3A_data">data</code></td>
<td>
<p>matrix with training data.</p>
</td></tr>
<tr><td><code id="som.nn.som.gaussian_+3A_grid">grid</code></td>
<td>
<p>somgrid object</p>
</td></tr>
<tr><td><code id="som.nn.som.gaussian_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.som.gaussian_+3A_alpha">alpha</code></td>
<td>
<p>learning rate.</p>
</td></tr>
<tr><td><code id="som.nn.som.gaussian_+3A_radius">radius</code></td>
<td>
<p>radius.</p>
</td></tr>
<tr><td><code id="som.nn.som.gaussian_+3A_init">init</code></td>
<td>
<p>codes for initialisation.</p>
</td></tr>
<tr><td><code id="som.nn.som.gaussian_+3A_toroidal">toroidal</code></td>
<td>
<p>true if doughnut-shaped som.</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>    S3 object of type \code{kohonen} with the trained som.
</pre></div>

<hr>
<h2 id='som.nn.som.internal'>Work hourse for som training.</h2><span id='topic+som.nn.som.internal'></span>

<h3>Description</h3>

<p>Function is the kernel <code>internal</code> for som training, implemented
in pure R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.som.internal(
  data,
  grid,
  len = 100,
  alpha = 0.05,
  radius,
  init,
  toroidal = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.som.internal_+3A_data">data</code></td>
<td>
<p>matrix with training data.</p>
</td></tr>
<tr><td><code id="som.nn.som.internal_+3A_grid">grid</code></td>
<td>
<p>somgrid object</p>
</td></tr>
<tr><td><code id="som.nn.som.internal_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.som.internal_+3A_alpha">alpha</code></td>
<td>
<p>learning rate c(first, last).</p>
</td></tr>
<tr><td><code id="som.nn.som.internal_+3A_radius">radius</code></td>
<td>
<p>radius c(first, last).</p>
</td></tr>
<tr><td><code id="som.nn.som.internal_+3A_init">init</code></td>
<td>
<p>codes for initialisation.</p>
</td></tr>
<tr><td><code id="som.nn.som.internal_+3A_toroidal">toroidal</code></td>
<td>
<p>true if doughnut-shaped som.</p>
</td></tr>
</table>


<h3>Value</h3>

<div class="sourceCode"><pre>    S3 object of type \code{kohonen} with the trained som.
</pre></div>

<hr>
<h2 id='som.nn.train'>Hexagonal som training</h2><span id='topic+som.nn.train'></span>

<h3>Description</h3>

<p>A self-organising map with hexagonal tolology is trained and
a model of Type SOMnn created for prediction of unknown samples.
In contrast to a &quot;normal&quot; som, class-labels for all samples of
the training set are required to build the topological model after SOM training.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.train(
  x,
  class.col = 1,
  kernel = "internal",
  xdim = 7,
  ydim = 5,
  toroidal = FALSE,
  len = 0,
  alpha = 0.2,
  radius = 0,
  norm = TRUE,
  dist.fun = dist.fun.inverse,
  max.dist = 1.1,
  strict = 0.8,
  name = "som.nn job"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.train_+3A_x">x</code></td>
<td>
<p>data.fame with training data. Samples are requested as rows and taken randomly for the
training steps. All
columns except of the class lables are considered to be attributes and parts of
the training vector.
One column is needed as class labels. The column with class
lables is selected by the argument <code>class.col</code>.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_class.col">class.col</code></td>
<td>
<p>single string or number. If class is a string, it is considered to be the
name of the column with class labels.
If class is a number, the respective column will be used as class labels
(after beeing coerced to character).
Default is 1.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_kernel">kernel</code></td>
<td>
<p>kernel for som training. One of the predefined kernels
<code>"bubble"</code>: train with the R-implementation or
<code>"gaussian"</code>: train with the R-implementation of the Gaussian kernel or
<code>"SOM"</code>: train with <code><a href="class.html#topic+SOM">SOM</a></code> (<code>class::SOM</code>) or
<code>"kohonen"</code>: train with <code><a href="kohonen.html#topic+som">som</a></code> (<code>kohonen::som</code>) or
<code>"som"</code>: train with <code><a href="som.html#topic+som">som</a></code> (<code>som::som</code>).
If a function is specified (as closure, not as character)
the specified custom function is used for training.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_xdim">xdim</code></td>
<td>
<p>dimension in x-direction.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_ydim">ydim</code></td>
<td>
<p>dimension in y-direction.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_toroidal">toroidal</code></td>
<td>
<p><code>logical</code>; if TRUE an endless som is trained as on the
surface of a torus. default: FALSE.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_len">len</code></td>
<td>
<p>number of steps to be trained (steps - not epochs!).</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_alpha">alpha</code></td>
<td>
<p>initial training rate; the learning rate is decreased linearly to 0.0 for the laset training step.
Default: 0.02.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_radius">radius</code></td>
<td>
<p>inital radius for SOM training.
If Gaussian distance function is used, radius corresponds to sigma.
The distance is decreased linearly to 1.0 for the last training step.
If <code>radius = 0</code> (default), the diameter of the SOM is used as initial
radius.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_norm">norm</code></td>
<td>
<p>logical; if TRUE, input data is normalised by <code>scale(x, TRUE, TRUE)</code>.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_dist.fun">dist.fun</code></td>
<td>
<p>parameter for k-NN prediction: Function used to calculate
distance-dependent weights. Any distance function must accept the two parameters
<code>x</code> (distance) and <code>sigma</code> (maximum distance to give a weight &gt; 0.0).
Default is <code>dist.fun.inverse</code>.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_max.dist">max.dist</code></td>
<td>
<p>parameter for k-NN prediction: Parameter <code>sigma</code> for dist.fun.
Default is 2.1. In order to avoid rounding issues, it is recommended not to
use exact integers as limit, but values like 1.1 to make sure, that all
neurons within distance 1 are included.</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_strict">strict</code></td>
<td>
<p>Minimum vote for the winner (if the winner's vote is smaller than strict,
&quot;unknown&quot; is reported as class label (<code>default = 0.8</code>).</p>
</td></tr>
<tr><td><code id="som.nn.train_+3A_name">name</code></td>
<td>
<p>optional name for the model. Name will be stored as slot <code>model@name</code> in the
trained model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Besides of the predefined kernels
<code>"internal", "gaussian", "SOM", "kohonen" or "som"</code>,
any specified custom kernel function can be used for som training. The function must match the
signature <code>kernel(data, grid, rlen, alpha, radius, init, toroidal)</code>, with
arguments:
</p>

<ul>
<li> <p><code>data:</code> <code>numeric</code> matrix of training data; one sample per row
</p>
</li>
<li> <p><code>classes:</code> optional <code>charater</code> vector of classes for training data
</p>
</li>
<li> <p><code>grid:</code> somgrid, generated with <code><a href="class.html#topic+somgrid">somgrid</a></code>
</p>
</li>
<li> <p><code>rlen:</code> number of training steps
</p>
</li>
<li> <p><code>alpha:</code> training rate
</p>
</li>
<li> <p><code>radius:</code> training radius
</p>
</li>
<li> <p><code>init:</code> <code>numeric</code> matrix of initial codebook vectors; one code per row
</p>
</li>
<li> <p><code>toroidal:</code> <code>logical</code>; TRUE, if the topology of grid is toroidal
</p>
</li></ul>

<p>The returned value must be a list with at minimum one element
</p>

<ul>
<li> <p><code>codes:</code> <code>numeric</code> matrix of result codebook vectors; one code per row
</p>
</li></ul>



<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the trained model
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'>## get example data and add class labels:
data(iris)
species &lt;- iris$Species

## train with default radius = diagonal / 2:
rlen &lt;- 500
som &lt;- som.nn.train(iris, class.col = "Species", kernel = "internal",
                    xdim = 15, ydim = 9, alpha = 0.2, len = rlen, 
                    norm = TRUE, toroidal = FALSE)


## continue training with different alpha and radius;
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 5)
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 2)

## predict some samples:
unk &lt;- iris[,!(names(iris) %in% "Species")]

setosa &lt;- unk[species=="setosa",]
setosa &lt;- setosa[sample(nrow(setosa), 20),]

versicolor &lt;- unk[species=="versicolor",]
versicolor &lt;- versicolor[sample(nrow(versicolor), 20),]

virginica &lt;- unk[species=="virginica",]
virginica &lt;- virginica[sample(nrow(virginica), 20),]

p &lt;- predict(som, unk)
head(p)

## plot:
plot(som)
dev.off()
plot(som, predict = predict(som, setosa))
plot(som, predict = predict(som, versicolor), add = TRUE, pch.col = "magenta", pch = 17)
plot(som, predict = predict(som, virginica), add = TRUE, pch.col = "white", pch = 8)

</code></pre>

<hr>
<h2 id='som.nn.validate'>Predict class labels for a validation dataset</h2><span id='topic+som.nn.validate'></span>

<h3>Description</h3>

<p>A model of type <code>SOMnn</code> is tested with a validation dataset. The dataset must
include a column with correct class labels.
The model is used to predict class labels. Confusion table,
specificity, sensitivity and accuracy for each class are calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.validate(model, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.validate_+3A_model">model</code></td>
<td>
<p>model of type <code>SOMnn</code>.</p>
</td></tr>
<tr><td><code id="som.nn.validate_+3A_x">x</code></td>
<td>
<p>data.fame with validation data. Samples are requested as rows.
<code>x</code> must include the same columns as the data.frame with which the model
have been trained originally.
A column with correct class labels is needed. The column with class
lables is selected by the slot <code>class.idx</code> of the model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameters stored in the model are applied for k-NN-like prediction. If necessary
the parameters can be changed by <code><a href="#topic+som.nn.set">som.nn.set</a></code> before testing.
</p>
<p>The funcion is only a wrapper and actually calls <code>som.nn.continue</code> with the test data and
without training (i.e. <code>len = 0</code>).
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>    S4 object of type \code{\link{SOMnn}} with the unchanged model and the
            test statistics for the test data.
</pre></div>


<h3>Examples</h3>

<pre><code class='language-R'>## get example data and add class labels:
data(iris)
species &lt;- iris$Species

## train with default radius = diagonal / 2:
rlen &lt;- 500
som &lt;- som.nn.train(iris, class.col = "Species", kernel = "internal",
                    xdim = 15, ydim = 9, alpha = 0.2, len = rlen, 
                    norm = TRUE, toroidal = FALSE)


## continue training with different alpha and radius;
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 5)
som &lt;- som.nn.continue(som, iris, alpha = 0.02, len=500, radius = 2)

## predict some samples:
unk &lt;- iris[,!(names(iris) %in% "Species")]

setosa &lt;- unk[species=="setosa",]
setosa &lt;- setosa[sample(nrow(setosa), 20),]

versicolor &lt;- unk[species=="versicolor",]
versicolor &lt;- versicolor[sample(nrow(versicolor), 20),]

virginica &lt;- unk[species=="virginica",]
virginica &lt;- virginica[sample(nrow(virginica), 20),]

p &lt;- predict(som, unk)
head(p)

## plot:
plot(som)
dev.off()
plot(som, predict = predict(som, setosa))
plot(som, predict = predict(som, versicolor), add = TRUE, pch.col = "magenta", pch = 17)
plot(som, predict = predict(som, virginica), add = TRUE, pch.col = "white", pch = 8)

</code></pre>

<hr>
<h2 id='som.nn.visual'>Mapping function for SOMnn</h2><span id='topic+som.nn.visual'></span>

<h3>Description</h3>

<p>Maps a sample of unknown category to a self-organising map (SOM)
stored in a object of type SOMnn.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.visual(codes, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.visual_+3A_codes">codes</code></td>
<td>
<p><code>data.frame</code> with codebook vectors.</p>
</td></tr>
<tr><td><code id="som.nn.visual_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> with data to be mapped. Columns of <code>x</code>
must have the same names as columns of <code>codes</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the winner neuron in <code>codes</code> for
each test vector in <code>x</code>.
<code>codes</code> and <code>x</code> are one vector per row and must have
the same number of columns (i.e. dimensions) and the identical column names.
</p>
<p><code>som.nn.visual</code> is the work horse for the k-NN-like classifier and normally used
from <code>predict</code>.
</p>


<h3>Value</h3>

<div class="sourceCode"><pre>   \code{data.frame} with 2 columns:
           \itemize{
           \item Index of the winner neuron for each row (index starting at 1).
           \item Distance between winner and row.
           }
</pre></div>

<hr>
<h2 id='som.nn.visual.one'>Maps one vector to the SOM</h2><span id='topic+som.nn.visual.one'></span>

<h3>Description</h3>

<p>Working hourse function for visual.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>som.nn.visual.one(one, codes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="som.nn.visual.one_+3A_one">one</code></td>
<td>
<p><code>numeric</code> vector to be mapped</p>
</td></tr>
<tr><td><code id="som.nn.visual.one_+3A_codes">codes</code></td>
<td>
<p><code>numeric matrix</code> of codebook vectors with
one code per row</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector with 2 elements: index of winner and qerror
</p>

<hr>
<h2 id='SOMnn-class'>An S4 class to hold a model for the topological classifier som.nn</h2><span id='topic+SOMnn-class'></span><span id='topic+SOMnn'></span>

<h3>Description</h3>

<p>Objects of type <code>SOMnn</code> can be created by training a self-organising map
with <a href="#topic+som.nn.train">som.nn.train</a>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>name</code></dt><dd><p>optional name of the model.</p>
</dd>
<dt><code>date</code></dt><dd><p>time and date of creation.</p>
</dd>
<dt><code>codes</code></dt><dd><p><code>data.frame</code> with codebook vectors of the som.</p>
</dd>
<dt><code>qerror</code></dt><dd><p>sum of the mapping errors of the training data.</p>
</dd>
<dt><code>class.idx</code></dt><dd><p>column index of column with class labels in input data.</p>
</dd>
<dt><code>classes</code></dt><dd><p><code>character</code> vector with names of categories.</p>
</dd>
<dt><code>class.counts</code></dt><dd><p><code>data.frame</code> with class hits for each neuron.</p>
</dd>
<dt><code>class.freqs</code></dt><dd><p><code>data.frame</code> with class frequencies for each neuron
(freqs sum up to 1).</p>
</dd>
<dt><code>norm</code></dt><dd><p><code>logical</code>; if TRUE, data is normalised before training and mapping.
Parameters for normalisation of training data is stored in the model and
applied before mapping of test data.</p>
</dd>
<dt><code>norm.center</code></dt><dd><p>vector of centers for each column of training
data.</p>
</dd>
<dt><code>norm.scale</code></dt><dd><p>vector of scale factors for each column of training
data.</p>
</dd>
<dt><code>confusion</code></dt><dd><p><code>data.frame</code> with confusion matrix for training data.</p>
</dd>
<dt><code>measures</code></dt><dd><p><code>data.frame</code> with classes as rows and the
columns sensitivity, specificity and accuracy for each class.</p>
</dd>
<dt><code>accuracy</code></dt><dd><p>The overall accuracy calculated based on the confusion matrix cmat:
<code class="reqn">acc = sum(diag(cmat)) / sum(cmat)</code>.</p>
</dd>
<dt><code>xdim</code></dt><dd><p>number of neurons in x-direction of the som.</p>
</dd>
<dt><code>ydim</code></dt><dd><p>number of neurons in y-direction of the som.</p>
</dd>
<dt><code>len.total</code></dt><dd><p>total number of training steps, performed to create the model.</p>
</dd>
<dt><code>toroidal</code></dt><dd><p><code>logical</code>; if TRUE, the map is toroidal (i.e. borderless).</p>
</dd>
<dt><code>dist.fun</code></dt><dd><p><code>function</code>; kernel for the kNN classifier.</p>
</dd>
<dt><code>max.dist</code></dt><dd><p>maximum distance for the kNN classifier.</p>
</dd>
<dt><code>strict</code></dt><dd><p>Minimum vote for the winner (if the winner's vote is smaller than strict,
&quot;unknown&quot; is reported as class label (<code>default = 0.8</code>).</p>
</dd>
</dl>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
