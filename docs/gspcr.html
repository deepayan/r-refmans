<!DOCTYPE html><html><head><title>Help for package gspcr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {gspcr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CFA_data'><p>CFA example data</p></a></li>
<li><a href='#compute_sc'><p>Compute the GLM systematic component.</p></a></li>
<li><a href='#cp_AIC'><p>Compute Akaike's information criterion</p></a></li>
<li><a href='#cp_BIC'><p>Compute bayesian information criterion</p></a></li>
<li><a href='#cp_F'><p>Compute F statistic</p></a></li>
<li><a href='#cp_gR2'><p>Compute generalized R-squared</p></a></li>
<li><a href='#cp_LRT'><p>Compute likelihood ratio test</p></a></li>
<li><a href='#cp_thrs_LLS'><p>Compute threshold values based on Log-likelihood values</p></a></li>
<li><a href='#cp_thrs_NOR'><p>Compute normalized association measure</p></a></li>
<li><a href='#cp_thrs_PR2'><p>Compute threshold values based on the pseudo R2</p></a></li>
<li><a href='#cp_validation_fit'><p>Compute fit measure(s) on the validation data set</p></a></li>
<li><a href='#cv_average'><p>Average fit measures computed in the K-fold cross-validation procedure</p></a></li>
<li><a href='#cv_choose'><p>Cross-validation choice</p></a></li>
<li><a href='#cv_gspcr'><p>Cross-validation of Generalized Principal Component Regression</p></a></li>
<li><a href='#est_gspcr'><p>Estimate Generalized Principal Component Regression</p></a></li>
<li><a href='#est_univ_mods'><p>Estimate simple GLM models</p></a></li>
<li><a href='#gspcr-package'><p>gspcr: Generalized Supervised Principal Component Regression</p></a></li>
<li><a href='#GSPCRexdata'><p>GSPCR example data</p></a></li>
<li><a href='#LL_baseline'><p>Baseline category logistic regression log-likelihood</p></a></li>
<li><a href='#LL_binomial'><p>Binomial log-likelihood</p></a></li>
<li><a href='#LL_cumulative'><p>Proportional odds model log-likelihood</p></a></li>
<li><a href='#LL_gaussian'><p>Gaussian log-likelihood</p></a></li>
<li><a href='#LL_newdata'><p>Log-Likelihood for new data</p></a></li>
<li><a href='#LL_poisson'><p>Poisson regression log-likelihood</p></a></li>
<li><a href='#pca_mix'><p>PCA of a mixture of numerical and categorical data</p></a></li>
<li><a href='#plot.gspcrcv'><p>Plot the cross-validation solution path for the GSPCR algorithm</p></a></li>
<li><a href='#predict.gspcrout'><p>Predict GSPCR model dependent variable scores</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Generalized Supervised Principal Component Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.4.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Generalization of supervised principal component regression (SPCR; 
    Bair et al., 2006, &lt;<a href="https://doi.org/10.1198%2F016214505000000628">doi:10.1198/016214505000000628</a>&gt;) to support continuous, 
    binary, and discrete variables as outcomes and predictors 
    (inspired by the 'superpc' R package <a href="https://cran.r-project.org/package=superpc">https://cran.r-project.org/package=superpc</a>).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, lmtest, patchwork, rmarkdown, superpc, testthat (&ge;
3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, FactoMineR, ggplot2, MASS, MLmetrics, nnet, PCAmixdata,
reshape2, rlang</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-21 15:42:42 UTC; edoardo</td>
</tr>
<tr>
<td>Author:</td>
<td>Edoardo Costantini
    <a href="https://orcid.org/0000-0001-9581-9913"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Edoardo Costantini &lt;costantini.edoardo@yahoo.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-21 22:30:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='CFA_data'>CFA example data</h2><span id='topic+CFA_data'></span>

<h3>Description</h3>

<p>Contains a data set used to develop and test the main features of the <code>gspcr</code> package. The data contains 50 predictors generated based on true number of principal components.
</p>


<h3>Format</h3>

<p><code>CFA_data</code> is a list containing two objects:
</p>

<ul>
<li> <p><code>X</code>: A data.frame with 5000 rows (observations) and 30 columns (possible predictors.) This data was generated based on a CFA model describing 10 independent latent variables measured by 3 items each, and a factor loading matrix describing simple structure.
</p>
</li>
<li> <p><code>y</code>: A numeric vector of length 1000. This variable was genearted as a linear combination of 5 latent variables used to generate <code>X</code>.
</p>
</li></ul>



<h3>Details</h3>

<p>A supervised PCA approach should identify that only 5 components are useful for the prediction of <code>y</code> and that only the first 15 variables should be used to compute them.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Check out the first 6 rows of the predictors
head(CFA_data$X)

# Check out first 6 elements of the dependent variable
head(CFA_data$y)
</code></pre>

<hr>
<h2 id='compute_sc'>Compute the GLM systematic component.</h2><span id='topic+compute_sc'></span>

<h3>Description</h3>

<p>Compute the systematic component of a GLM of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_sc(mod, predictors)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_sc_+3A_mod">mod</code></td>
<td>
<p>a fit object returned by one of <code>stats::lm</code>, <code>stats::glm</code>, <code>nnet::multinom</code>, or <code>MASS::polr</code>.</p>
</td></tr>
<tr><td><code id="compute_sc_+3A_predictors">predictors</code></td>
<td>
<p>matrix or data.frame of predictor values to compute the systematic component based on.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function takes different model objects and knows how to treat the coefficient vector (or matrix) to obtain the systematic component.
</p>


<h3>Value</h3>

<p>a matrix of <code class="reqn">n \times k</code>, where <code class="reqn">k</code> is equal to 1 for all but multi-categorical models. This matrix contains the systematic component values for the provided predictors.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>

<hr>
<h2 id='cp_AIC'>Compute Akaike's information criterion</h2><span id='topic+cp_AIC'></span>

<h3>Description</h3>

<p>Computes Akaike's information criterion for comparing competing models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_AIC(ll, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_AIC_+3A_ll">ll</code></td>
<td>
<p>numeric vector of length 1 (or an object of class 'logLik') storing the log-likelihood of the model of interest</p>
</td></tr>
<tr><td><code id="cp_AIC_+3A_k">k</code></td>
<td>
<p>numeric vector of length 1 storing the number of parameters estimated by the model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of length 1 storing the computed AIC.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit some model
lm_out &lt;- lm(mpg ~ cyl + disp, data = mtcars)

# Compute AIC with your function
AIC_M &lt;- cp_AIC(
    ll = logLik(lm_out),
    k = length(coef(lm_out)) + 1 # intercept + reg coefs + error variance
)
</code></pre>

<hr>
<h2 id='cp_BIC'>Compute bayesian information criterion</h2><span id='topic+cp_BIC'></span>

<h3>Description</h3>

<p>Computes bayesian information criterion for comparing competing models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_BIC(ll, n, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_BIC_+3A_ll">ll</code></td>
<td>
<p>numeric vector of length 1 (or an object of class 'logLik') storing the log-likelihood of the model of interest</p>
</td></tr>
<tr><td><code id="cp_BIC_+3A_n">n</code></td>
<td>
<p>numeric vector of length 1 storing the sample size of data used to compute the log-likelihood</p>
</td></tr>
<tr><td><code id="cp_BIC_+3A_k">k</code></td>
<td>
<p>numeric vector of length 1 storing the number of estimated parameters by the model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of length 1 storing the computed BIC.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit some model
lm_out &lt;- lm(mpg ~ cyl + disp, data = mtcars)

# Compute BIC with your function
BIC_M &lt;- cp_BIC(
    ll = logLik(lm_out),
    n = nobs(lm_out),
    k = length(coef(lm_out)) + 1 # intercept + reg coefs + error variance
)
</code></pre>

<hr>
<h2 id='cp_F'>Compute F statistic</h2><span id='topic+cp_F'></span>

<h3>Description</h3>

<p>Computes the F statistic comparing two nested models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_F(y, y_hat_restricted, y_hat_full, n = length(y), p_restricted = 0, p_full)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_F_+3A_y">y</code></td>
<td>
<p>numeric vector storing the observed values on the dependent variable</p>
</td></tr>
<tr><td><code id="cp_F_+3A_y_hat_restricted">y_hat_restricted</code></td>
<td>
<p>numeric vector storing the predicted values on <code>y</code> based on the restricted model</p>
</td></tr>
<tr><td><code id="cp_F_+3A_y_hat_full">y_hat_full</code></td>
<td>
<p>numeric vector storing the predicted values on <code>y</code> based on the full model</p>
</td></tr>
<tr><td><code id="cp_F_+3A_n">n</code></td>
<td>
<p>numeric vector of length 1 storing the sample size used to train the models</p>
</td></tr>
<tr><td><code id="cp_F_+3A_p_restricted">p_restricted</code></td>
<td>
<p>numeric vector of length 1 storing the number of predictors involved in training the restricted model</p>
</td></tr>
<tr><td><code id="cp_F_+3A_p_full">p_full</code></td>
<td>
<p>numeric vector of length 1 storing the number of predictors involved in training the full model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that:
</p>

<ul>
<li><p> The full model is always the model with more estimated parameters, the model with more predictor variables.
</p>
</li>
<li><p> The restricted model is the model with fewer estimated parameters.
</p>
</li>
<li><p> The restricted model must be nested within the full model.
</p>
</li></ul>



<h3>Value</h3>

<p>numeric vector of length 1 storing the F-statistic
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Null vs full model
lm_n &lt;- lm(mpg ~ 1, data = mtcars) # Fit a null model
lm_f &lt;- lm(mpg ~ cyl + disp, data = mtcars) # Fit a full model
f_M &lt;- cp_F(
    y = mtcars$mpg,
    y_hat_restricted = predict(lm_n),
    y_hat_full = predict(lm_f),
    p_full = 2
)

# Simpler vs more complex model
lm_f_2 &lt;- lm(mpg ~ cyl + disp + hp + drat + qsec, data = mtcars) # a more complex full model
f_change_M &lt;- cp_F(
    y = mtcars$mpg,
    y_hat_restricted = predict(lm_f),
    y_hat_full = predict(lm_f_2),
    p_restricted = 2,
    p_full = 5
)

</code></pre>

<hr>
<h2 id='cp_gR2'>Compute generalized R-squared</h2><span id='topic+cp_gR2'></span>

<h3>Description</h3>

<p>Computes the Cox and Snell generalized R-squared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_gR2(ll_n, ll_f, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_gR2_+3A_ll_n">ll_n</code></td>
<td>
<p>numeric vector of length 1 (or an object of class 'logLik') storing the log-likelihood of the null (restricted) model</p>
</td></tr>
<tr><td><code id="cp_gR2_+3A_ll_f">ll_f</code></td>
<td>
<p>numeric vector of length 1 (or an object of class 'logLik') storing the log-likelihood of the full model</p>
</td></tr>
<tr><td><code id="cp_gR2_+3A_n">n</code></td>
<td>
<p>numeric vector of length 1 storing the sample size of the data used to estimate the models</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cox and Snell generalized R-squared is equal to the R-squared when applied to multiple linear regression. The highest value for this measure is 1 - exp(ll_n)^(2/n), which is usually &lt; 1.
The null (restricted) model must be nested within the full model.
</p>


<h3>Value</h3>

<p>numeric vector of length 1 storing the computed Cox and Snell generalized R-squared.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Allison, P. D. (2014, March). Measures of fit for logistic regression. In Proceedings of the SAS global forum 2014 conference (pp. 1-13). Cary, NC: SAS Institute Inc.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a null model
lm_n &lt;- lm(mpg ~ 1, data = mtcars)

# Fit a full model
lm_f &lt;- lm(mpg ~ cyl + disp, data = mtcars)

# Compute generalized R2
gr2 &lt;- cp_gR2(
    ll_n = as.numeric(logLik(lm_n)),
    ll_f = as.numeric(logLik(lm_f)),
    n = nobs(lm_f)
)

</code></pre>

<hr>
<h2 id='cp_LRT'>Compute likelihood ratio test</h2><span id='topic+cp_LRT'></span>

<h3>Description</h3>

<p>Computes the likelihood ratio expressed as a difference between the log-likelihoods of observed data under two nested competing models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_LRT(ll_restricted, ll_full)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_LRT_+3A_ll_restricted">ll_restricted</code></td>
<td>
<p>numeric vector of length 1 (or an object of class 'logLik') storing the log-likelihood of the observed data under the restricted model</p>
</td></tr>
<tr><td><code id="cp_LRT_+3A_ll_full">ll_full</code></td>
<td>
<p>numeric vector of length 1 (or an object of class 'logLik') storing the log-likelihood of the observed data under the full model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that:
</p>

<ul>
<li><p> The full model is always the model with more estimated parameters, the model with more predictor variables.
</p>
</li>
<li><p> The restricted model is the model with fewer estimated parameters.
</p>
</li>
<li><p> The restricted model must be nested within the full model.
</p>
</li></ul>



<h3>Value</h3>

<p>numeric vector of length 1 storing the likelihood ratio test statistic
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Fit a nested model
nested &lt;- glm(mpg ~ cyl + disp, data = mtcars)

# Fit a complex model
complex &lt;- glm(mpg ~ cyl + disp + hp + am, data = mtcars)

# Compute log-likelihood statistic with your function
LRT_M &lt;- cp_LRT(
    ll_restricted = logLik(nested),
    ll_full = logLik(complex)
)
</code></pre>

<hr>
<h2 id='cp_thrs_LLS'>Compute threshold values based on Log-likelihood values</h2><span id='topic+cp_thrs_LLS'></span>

<h3>Description</h3>

<p>Produces a vector of threshold values that define active predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_thrs_LLS(dv, ivs, fam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_thrs_LLS_+3A_dv">dv</code></td>
<td>
<p>numeric vector or factor of dependent variable values</p>
</td></tr>
<tr><td><code id="cp_thrs_LLS_+3A_ivs">ivs</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed)</p>
</td></tr>
<tr><td><code id="cp_thrs_LLS_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model (see <code><a href="#topic+cv_gspcr">cv_gspcr()</a></code> for the list of possible options)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of log-likelihood value from all of the univariate GLM models regressing <code>dv</code> on each column of <code>ivs</code>.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example inputs
dv &lt;- mtcars[, 1]
ivs &lt;- mtcars[, -1]
fam &lt;- "gaussian"

# Use function
cp_thrs_LLS(dv, ivs, fam)

</code></pre>

<hr>
<h2 id='cp_thrs_NOR'>Compute normalized association measure</h2><span id='topic+cp_thrs_NOR'></span>

<h3>Description</h3>

<p>A function to compute the normalized bivariate association measures between a <code>dv</code> and a collection of <code>ivs</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_thrs_NOR(dv, ivs, s0_perc = NULL, scale_dv = TRUE, scale_ivs = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_thrs_NOR_+3A_dv">dv</code></td>
<td>
<p>numeric vector of dependent variable values</p>
</td></tr>
<tr><td><code id="cp_thrs_NOR_+3A_ivs">ivs</code></td>
<td>
<p><code class="reqn">n \times p</code> matrix of numeric independent variables</p>
</td></tr>
<tr><td><code id="cp_thrs_NOR_+3A_s0_perc">s0_perc</code></td>
<td>
<p>numeric vector of length 1 storing the factor for the denominator of association statistic (i.e., the percentile of standard deviation values added to the denominator, a value between 0 and 1.) The default is 0.5 (the median)</p>
</td></tr>
<tr><td><code id="cp_thrs_NOR_+3A_scale_dv">scale_dv</code></td>
<td>
<p>logical value defining whether <code>dv</code> should be scaled</p>
</td></tr>
<tr><td><code id="cp_thrs_NOR_+3A_scale_ivs">scale_ivs</code></td>
<td>
<p>logical value defining whether <code>ivs</code> should be scaled</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is based on the function <code>cor.func</code> in the package <code>superpc</code>.
</p>


<h3>Value</h3>

<p>numeric vector of bivariate association measures between <code>dv</code> and <code>ivs</code>. numeric vector of log-likelihood value from all of the univariate GLM models regressing <code>dv</code> on each column of <code>ivs</code>.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Bair E, Hastie T, Paul D, Tibshirani R (2006). “Prediction by supervised principal components.” J. Am. Stat. Assoc., 101(473), 119-137.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example inputs
dv &lt;- mtcars[, 1]
ivs &lt;- mtcars[, -1]
s0_perc &lt;- 0

# Use the function
cp_thrs_NOR(dv, ivs, s0_perc)

</code></pre>

<hr>
<h2 id='cp_thrs_PR2'>Compute threshold values based on the pseudo R2</h2><span id='topic+cp_thrs_PR2'></span>

<h3>Description</h3>

<p>Produces a vector of threshold values that define active predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_thrs_PR2(dv, ivs, fam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_thrs_PR2_+3A_dv">dv</code></td>
<td>
<p>numeric vector or factor of dependent variable values</p>
</td></tr>
<tr><td><code id="cp_thrs_PR2_+3A_ivs">ivs</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed)</p>
</td></tr>
<tr><td><code id="cp_thrs_PR2_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model (see <code><a href="#topic+cv_gspcr">cv_gspcr()</a></code> for the list of possible options)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of bivariate association measures between <code>dv</code> and <code>ivs</code>.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example inputs
dv &lt;- mtcars[, 1]
ivs &lt;- mtcars[, -1]

# Use the function
cp_thrs_PR2(dv, ivs, fam = "gaussian")

</code></pre>

<hr>
<h2 id='cp_validation_fit'>Compute fit measure(s) on the validation data set</h2><span id='topic+cp_validation_fit'></span>

<h3>Description</h3>

<p>Given a training and validation data set, it computes a target fit measure on the validation data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cp_validation_fit(y_train, y_valid, X_train, X_valid, fam, fit_measure)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cp_validation_fit_+3A_y_train">y_train</code></td>
<td>
<p>numeric vector or factor of dependent variable values from the training set</p>
</td></tr>
<tr><td><code id="cp_validation_fit_+3A_y_valid">y_valid</code></td>
<td>
<p>numeric vector or factor of dependent variable values from the validation set</p>
</td></tr>
<tr><td><code id="cp_validation_fit_+3A_x_train">X_train</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed) from the training set. Can also be set to NULL to obtain the log-likelihood of the new data under the null model.</p>
</td></tr>
<tr><td><code id="cp_validation_fit_+3A_x_valid">X_valid</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed) from the validation set. If <code>X_train</code> is set to NULL to obtain the log-likelihood of the new data under the null model, <code>X_valid</code> is ignored.</p>
</td></tr>
<tr><td><code id="cp_validation_fit_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model (see <code><a href="#topic+cv_gspcr">cv_gspcr()</a></code> for the list of possible options)</p>
</td></tr>
<tr><td><code id="cp_validation_fit_+3A_fit_measure">fit_measure</code></td>
<td>
<p>character vector indicating which fit measure should be computed (see <code><a href="#topic+cv_gspcr">cv_gspcr()</a></code> for the list of possible options)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The validation data set can be specified to be the same as the training data set if desired.
</p>


<h3>Value</h3>

<p>numeric vector of length 1 storing the requested fit measure
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example inputs
y_train = mtcars[1:20, 1]
y_valid = mtcars[-c(1:20), 1]
X_train = mtcars[1:20, -1]
X_valid = mtcars[-c(1:20), -1]
fam = "gaussian"
fit_measure = "BIC"

# Use the function
cp_validation_fit(y_train, y_valid, X_train, X_valid, fam, fit_measure)

</code></pre>

<hr>
<h2 id='cv_average'>Average fit measures computed in the K-fold cross-validation procedure</h2><span id='topic+cv_average'></span>

<h3>Description</h3>

<p>Function to average results from an array of K-fold CV fit measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_average(cv_array, fit_measure)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_average_+3A_cv_array">cv_array</code></td>
<td>
<p><code class="reqn">Q \times nthrs \times K</code> array containing fit measures computed for different combinations of the number of components, threshold values, and number of CV-folds.</p>
</td></tr>
<tr><td><code id="cv_average_+3A_fit_measure">fit_measure</code></td>
<td>
<p>character vector of length 1 indicating the type of fit measure to be used in the to cross-validation procedure</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input of this function is an array of <code class="reqn">Q \times nthrs \times K</code>, where <code>Q</code> is the number of principal components, <code>nthrs</code> is the number of thresholds, and <code>K</code> is the number of folds.
</p>


<h3>Value</h3>

<p>list of three <code class="reqn">Q \times nthrs</code> matrices:
</p>

<ul>
<li> <p><code>scor</code>: contains the average CV scores across the K folds
</p>
</li>
<li> <p><code>scor_upr</code>: contains the average CV scores across the K folds + 1 standard deviation
</p>
</li>
<li> <p><code>scor_lwr</code>: contains the average CV scores across the K folds - 1 standard deviation
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example inputs
cv_array = array(abs(rnorm(10 * 3 * 2)), dim = c(10, 3, 2))
fit_measure = "F"

# Use the function
cv_average(cv_array, fit_measure)

</code></pre>

<hr>
<h2 id='cv_choose'>Cross-validation choice</h2><span id='topic+cv_choose'></span>

<h3>Description</h3>

<p>Extracting the CV choices of SPCR parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_choose(scor, scor_lwr, scor_upr, K, fit_measure)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_choose_+3A_scor">scor</code></td>
<td>
<p><code class="reqn">npcs \times nthrs</code> matrix of K-fold CV scores</p>
</td></tr>
<tr><td><code id="cv_choose_+3A_scor_lwr">scor_lwr</code></td>
<td>
<p><code class="reqn">npcs \times nthrs</code> matrix of score lower bounds</p>
</td></tr>
<tr><td><code id="cv_choose_+3A_scor_upr">scor_upr</code></td>
<td>
<p><code class="reqn">npcs \times nthrs</code> matrix of score upper bounds</p>
</td></tr>
<tr><td><code id="cv_choose_+3A_k">K</code></td>
<td>
<p>numeric vector of length 1 storing the number of folds for the K-fold cross-validation procedure</p>
</td></tr>
<tr><td><code id="cv_choose_+3A_fit_measure">fit_measure</code></td>
<td>
<p>character vector of length 1 indicating the type of fit measure to be used in the to cross-validation procedure</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a matrix of <code class="reqn">npcs \times nthrs</code>, returns the best choice based on the type of fit measure (best overall and 1se rule versions.)
This function returns as solutions:
</p>

<ul>
<li> <p><code>default</code>: the best choice based on the given fit measure (e.g. highest likelihood ratio test statistic, lowest BIC)
</p>
</li>
<li> <p><code>oneSE</code>: the solution that defined the most parsimonious model within 1 standard error from the best one.
When both the number of components and the threshold parameter are cross-validated, the 1-standard error rule finds the candidate alternative solutions using the lowest number of PCs and having the best fit-measure.
This decision is guided by the desire to counterbalance the tendency of GSPCR of selecting the highest number of components available when using cross-validation.
</p>
</li></ul>



<h3>Value</h3>

<p>A list of two numeric vectors:
</p>

<ul>
<li> <p><code>default</code>: numeric vector of length 2 that reports the coordinates in <code>scor</code> defining the default solution.
</p>
</li>
<li> <p><code>oneSE</code>: numeric vector of length 2 that reports the coordinates for <code>scor</code> defining the solution based on the one standard error rule
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Score matrices
scor &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 3, ncol = 2)
scor_lwr &lt;- matrix(c(1, 2, 3, 4, 5, 6) - 1.5, nrow = 3, ncol = 2)
scor_upr &lt;- matrix(c(1, 2, 3, 4, 5, 6) + 1.5, nrow = 3, ncol = 2)

# Number of folds
K &lt;- 10

# Type of fit_measure
fit_measure &lt;- "F"

# Use the function
cv_choose(scor, scor_lwr, scor_upr, K, fit_measure)

</code></pre>

<hr>
<h2 id='cv_gspcr'>Cross-validation of Generalized Principal Component Regression</h2><span id='topic+cv_gspcr'></span>

<h3>Description</h3>

<p>Use K-fold cross-validation to decide on the number of principal components and the threshold value for GSPCR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv_gspcr(
  dv,
  ivs,
  fam = c("gaussian", "binomial", "poisson", "baseline", "cumulative")[1],
  thrs = c("LLS", "PR2", "normalized")[1],
  nthrs = 10L,
  npcs_range = 1L:3L,
  K = 5,
  fit_measure = c("F", "LRT", "AIC", "BIC", "PR2", "MSE")[1],
  max_features = ncol(ivs),
  min_features = 1,
  oneSE = TRUE,
  save_call = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_gspcr_+3A_dv">dv</code></td>
<td>
<p>numeric vector or factor of dependent variable values</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_ivs">ivs</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed)</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_thrs">thrs</code></td>
<td>
<p>character vector of length 1 storing the type of threshold to be used (see below for available options)</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_nthrs">nthrs</code></td>
<td>
<p>numeric vector of length 1 storing the number of threshold values to be used</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_npcs_range">npcs_range</code></td>
<td>
<p>numeric vector defining the numbers of principal components to be used</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_k">K</code></td>
<td>
<p>numeric vector of length 1 storing the number of folds for the K-fold cross-validation procedure</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_fit_measure">fit_measure</code></td>
<td>
<p>character vector of length 1 indicating the type of fit measure to be used in the cross-validation procedure</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_max_features">max_features</code></td>
<td>
<p>numeric vector of length 1 indicating the maximum number of features that can be selected</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_min_features">min_features</code></td>
<td>
<p>numeric vector of length 1 indicating the minimum number of features that should be selected</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_onese">oneSE</code></td>
<td>
<p>logical value indicating whether the results with the 1se rule should be saved</p>
</td></tr>
<tr><td><code id="cv_gspcr_+3A_save_call">save_call</code></td>
<td>
<p>logical value indicating whether the call should be saved and returned in the results</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variables in <code>ivs</code> do not need to be standardized beforehand as the function handles scaling appropriately based on the measurement levels of the data.
</p>
<p>The <code>fam</code> argument is used to define which model will be used when regressing the dependent variable on the principal components:
</p>

<ul>
<li> <p><code>gaussian</code>: fits a linear regression model (continuous dv)
</p>
</li>
<li> <p><code>binomial</code>: fits a logistic regression model (binary dv)
</p>
</li>
<li> <p><code>poisson</code>: fits a poisson regression model (count dv)
</p>
</li>
<li> <p><code>baseline</code>: fits a baseline-category logit model (nominal dv, using <code><a href="nnet.html#topic+multinom">nnet::multinom()</a></code>)
</p>
</li>
<li> <p><code>cumulative</code>: fits a proportional odds logistic regression (ordinal dv, using <code><a href="MASS.html#topic+polr">MASS::polr()</a></code>)
</p>
</li></ul>

<p>The <code>thrs</code> argument defines the bivariate association-threshold measures used to determine the active set of predictors for a SPCR analysis.
The following association measures are supported (measurement levels allowed reported between brackets):
</p>

<ul>
<li> <p><code>LLS</code>: simple GLM regression likelihoods (any dv with any iv)
</p>
</li>
<li> <p><code>PR2</code>: Cox and Snell generalized R-squared is computed for the GLMs between <code>dv</code> and every column in <code>ivs</code>. Then, the square root of these values is used to obtain the threshold values. For more information about the computation of the Cox and Snell R2 see the help file for <code><a href="#topic+cp_gR2">cp_gR2()</a></code>. When using this measure for simple linear regressions (with continuous <code>dv</code> and <code>ivs</code>) is equivalent to the regular R-squared. Therefore, it can be thought of as equivalent to the bivariate correlations between <code>dv</code> and <code>ivs</code>. (any dv with any iv)
</p>
</li>
<li> <p><code>normalized</code>: normalized correlation based on <code><a href="superpc.html#topic+superpc.cv">superpc::superpc.cv()</a></code> (continuous dv with continuous ivs)
</p>
</li></ul>

<p>The <code>fit_measure</code> argument defines which fit measure should be used within the cross-validation procedure.
The supported measures are:
</p>

<ul>
<li> <p><code>F</code>: F-statistic computed with <code><a href="#topic+cp_F">cp_F()</a></code> (continuous dv)
</p>
</li>
<li> <p><code>LRT</code>: likelihood-ratio test statistic computed with <code><a href="#topic+cp_LRT">cp_LRT()</a></code> (any dv)
</p>
</li>
<li> <p><code>AIC</code>: Akaike's information criterion computed with <code><a href="#topic+cp_AIC">cp_AIC()</a></code> (any dv)
</p>
</li>
<li> <p><code>BIC</code>: bayesian information criterion computed with <code><a href="#topic+cp_BIC">cp_BIC()</a></code> (any dv)
</p>
</li>
<li> <p><code>PR2</code>: Cox and Snell generalized R-squared computed with <code><a href="#topic+cp_gR2">cp_gR2()</a></code> (any dv)
</p>
</li>
<li> <p><code>MSE</code>: Mean squared error compute with <code><a href="MLmetrics.html#topic+MSE">MLmetrics::MSE()</a></code> (continuous dv)
</p>
</li></ul>

<p>Details regarding the 1 standard error rule implemented here can be found in the documentation for the function <code><a href="#topic+cv_choose">cv_choose()</a></code>.
</p>


<h3>Value</h3>

<p>Object of class <code>gspcr</code>, which is a list containing:
</p>

<ul>
<li> <p><code>solution</code>: a list containing the number of PCs that was selected (Q), the threshold value used, and the resulting active set for both the <code>standard</code> and <code>oneSE</code> solutions
</p>
</li>
<li> <p><code>sol_table</code>: data.frame reporting the threshold number, value, and the number of PCs identified by the procedure
</p>
</li>
<li> <p><code>thr</code>: vector of threshold values of the requested type used for the K-fold cross-validation procedure
</p>
</li>
<li> <p><code>thr_cv</code>: numeric vector of length 1 indicating the threshold number that was selected by the K-fold cross-validation procedure using the default decision rule
</p>
</li>
<li> <p><code>thr_cv_1se</code>: numeric vector of length 1 indicating the threshold number that was selected by the K-fold cross-validation procedure using the 1-standard-error rule
</p>
</li>
<li> <p><code>Q_cv</code>: numeric vector of length 1 indicating the number of PCs that was selected by the K-fold cross-validation procedure using the default decision rule
</p>
</li>
<li> <p><code>Q_cv_1se</code>: numeric vector of length 1 indicating the number of PCs that was selected by the K-fold cross-validation procedure using the 1-standard-error rule
</p>
</li>
<li> <p><code>scor</code>: <code class="reqn">npcs \times nthrs</code> matrix of fit-measure scores averaged across the K folds
</p>
</li>
<li> <p><code>scor_lwr</code>: <code class="reqn">npcs \times nthrs</code> matrix of fit-measure score lower bounds averaged across the K folds
</p>
</li>
<li> <p><code>scor_upr</code>: <code class="reqn">npcs \times nthrs</code> matrix of fit-measure score upper bounds averaged across the K folds
</p>
</li>
<li> <p><code>pred_map</code>: matrix of <code class="reqn">p \times nthrs</code> logical values indicating which predictors were active for every threshold value used
</p>
</li>
<li> <p><code>gspcr_call</code>: the function call
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Bair, E., Hastie, T., Paul, D., &amp; Tibshirani, R. (2006). Prediction by supervised principal components. Journal of the American Statistical Association, 101(473), 119-137.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example input values
dv &lt;- mtcars[, 1]
ivs &lt;- mtcars[, -1]
thrs &lt;- "PR2"
nthrs &lt;- 5
fam &lt;- "gaussian"
npcs_range &lt;- 1:3
K &lt;- 3
fit_measure &lt;- "F"
max_features &lt;- ncol(ivs)
min_features &lt;- 1
oneSE &lt;- TRUE
save_call &lt;- TRUE

# Example usage
out_cont &lt;- cv_gspcr(
  dv = GSPCRexdata$y$cont,
  ivs = GSPCRexdata$X$cont,
  fam = "gaussian",
  nthrs = 5,
  npcs_range = 1:3,
  K = 3,
  fit_measure = "F",
  thrs = "normalized",
  min_features = 1,
  max_features = ncol(GSPCRexdata$X$cont),
  oneSE = TRUE,
  save_call = TRUE
)

</code></pre>

<hr>
<h2 id='est_gspcr'>Estimate Generalized Principal Component Regression</h2><span id='topic+est_gspcr'></span>

<h3>Description</h3>

<p>Estimate SPCA on the data given chosen parameter values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_gspcr(object = NULL, dv, ivs, fam, active_set, ndim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_gspcr_+3A_object">object</code></td>
<td>
<p><code>gspcrcv</code> object resulting from the call of <code>cv_gspcr()</code>. If this is specified, then every other argument can be left blank.</p>
</td></tr>
<tr><td><code id="est_gspcr_+3A_dv">dv</code></td>
<td>
<p>numeric vector or factor of dependent variable values</p>
</td></tr>
<tr><td><code id="est_gspcr_+3A_ivs">ivs</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed)</p>
</td></tr>
<tr><td><code id="est_gspcr_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model</p>
</td></tr>
<tr><td><code id="est_gspcr_+3A_active_set">active_set</code></td>
<td>
<p>names of the columns of ivs to be used as predictors</p>
</td></tr>
<tr><td><code id="est_gspcr_+3A_ndim">ndim</code></td>
<td>
<p>numeric vector defining the number of principal components to be used (2 or more)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After deciding on the number of components and the active set, this estimates the GSPCR model.
This function can be used by specifying the object argument or by filling in custom values for every argument. If both the object and any other argument are specified, then the argument values will be prioritized.
</p>


<h3>Value</h3>

<p>Description of function output
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Bair, E., Hastie, T., Paul, D., &amp; Tibshirani, R. (2006). Prediction by supervised principal components. Journal of the American Statistical Association, 101(473), 119-137.
</p>

<hr>
<h2 id='est_univ_mods'>Estimate simple GLM models</h2><span id='topic+est_univ_mods'></span>

<h3>Description</h3>

<p>Given a dependent variable, a set of possible predictors, and a GLM family, this function estimates a null GLM and all of the simple GLMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_univ_mods(dv, ivs, fam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_univ_mods_+3A_dv">dv</code></td>
<td>
<p>numeric vector or factor of dependent variable values</p>
</td></tr>
<tr><td><code id="est_univ_mods_+3A_ivs">ivs</code></td>
<td>
<p><code class="reqn">n \times p</code> data.frame of independent variables (factors allowed)</p>
</td></tr>
<tr><td><code id="est_univ_mods_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model (see <code><a href="#topic+cv_gspcr">cv_gspcr()</a></code> for the list of possible options)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>We use the expression &quot;simple GLM models&quot; to describe GLM models with a single dependent variable and a single predictor.
</p>


<h3>Value</h3>

<p>List containing:
</p>

<ul>
<li> <p><code>ll0</code>: log-likelihoods for the null model
</p>
</li>
<li> <p><code>lls</code>: log-likelihoods for all the simple models
</p>
</li>
<li> <p><code>coefs</code>: if <code>dv</code> and <code>ivs</code> are continuous, standardized simple regression coefficients
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Run the function on the example data set
dv_con_ivs_con &lt;- est_univ_mods(
    dv = GSPCRexdata$y$cont,
    ivs = GSPCRexdata$X$cont,
    fam = "gaussian"
)

</code></pre>

<hr>
<h2 id='gspcr-package'>gspcr: Generalized Supervised Principal Component Regression</h2><span id='topic+gspcr'></span><span id='topic+gspcr-package'></span>

<h3>Description</h3>

<p>Generalization of supervised principal component regression (SPCR; Bair et al., 2006, <a href="https://doi.org/10.1198/016214505000000628">doi:10.1198/016214505000000628</a>) to support continuous, binary, and discrete variables as outcomes and predictors (inspired by the 'superpc' R package <a href="https://cran.r-project.org/package=superpc">https://cran.r-project.org/package=superpc</a>).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Edoardo Costantini <a href="mailto:costantini.edoardo@yahoo.com">costantini.edoardo@yahoo.com</a> (<a href="https://orcid.org/0000-0001-9581-9913">ORCID</a>)
</p>

<hr>
<h2 id='GSPCRexdata'>GSPCR example data</h2><span id='topic+GSPCRexdata'></span>

<h3>Description</h3>

<p>Contains a data set used to develop and test the main features of the <code>gspcr</code> package. The data contains a dependent variable and 50 predictors generated based on true number of principal components.
</p>


<h3>Format</h3>

<p><code>GSPCRexdata</code> is a list containing two data.frame objects:
</p>

<ul>
<li> <p><code>X</code>: A list of data.frames with 1000 rows (observations) and 50 columns (possible predictors). The list contains matrices storing data coded with different measurement levels:
</p>

<ul>
<li> <p><code>cont</code> with 50 continuous variables
</p>
</li>
<li> <p><code>bin</code> with 50 binary variables (factors)
</p>
</li>
<li> <p><code>ord</code> with 50 ordinal variables (ordered factors)
</p>
</li>
<li> <p><code>cat</code> with 50 categorical variables (unordered factors)
</p>
</li>
<li> <p><code>mix</code> with 20 continuous variables, 10 binary variables (factors), 10 ordinal variables (ordered factors), 10 categorical variables (unordered factors).
</p>
</li></ul>

</li>
<li> <p><code>y</code>: A data.frame with 1000 rows and 5 columns. The first column <code>cont</code> is a continuous variable produced using a linear model with the first two PCs underlying <code>X</code> as a data-generating model.
The other columns are transformed versions of <code>cont</code> to match common discrete target distribution in the social sciences.
These are the variables stored:
</p>

<ul>
<li> <p><code>cont</code> continuous dependent variable (numeric vector)
</p>
</li>
<li> <p><code>bin</code> binary dependent variable (factor)
</p>
</li>
<li> <p><code>ord</code> ordinal dependent variable (ordered factor)
</p>
</li>
<li> <p><code>cat</code> nominal dependent variable (unordered factor)
</p>
</li>
<li> <p><code>pois</code> count dependent variable (numeric vector)
</p>
</li></ul>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># Check out the first 6 rows of the continuous predictors
head(GSPCRexdata$X$cont)

# Check out first 6 rows of the dv data.frame
head(GSPCRexdata$y)
</code></pre>

<hr>
<h2 id='LL_baseline'>Baseline category logistic regression log-likelihood</h2><span id='topic+LL_baseline'></span>

<h3>Description</h3>

<p>Computes the baseline category logistic regression log-likelihood given a nominal categorical variable and the corresponding GLM linear predictor values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL_baseline(y, x, mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL_baseline_+3A_y">y</code></td>
<td>
<p>factor or disjunctive table representation recording a nominal variable with 3 or more categories.</p>
</td></tr>
<tr><td><code id="LL_baseline_+3A_x">x</code></td>
<td>
<p>data.frame (or matrix) containing predictor values.</p>
</td></tr>
<tr><td><code id="LL_baseline_+3A_mod">mod</code></td>
<td>
<p><code>multinom</code> object containing the estimated baseline-category logit model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> and <code>y</code> are equal to the data on which <code>mod</code> has been trained, this function returns the same result as the default <code>logLink</code> function. If <code>x</code> and <code>y</code> are new, the function returns the log-likelihood of the new data under the trained model.
</p>
<p>A disjunctive table is a matrix representation of a multi-categorical variable. The dimensionality of the matrix is i times j, with i = number of observations, and j = number of categories. <code>y_{ij}</code> is equal to 1 if observation i responded with category j, and it is equal to 0 otherwise.
The log-likelihood equation is based on Agresti (2002, p. 192).
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>ll</code> atomic vector of length 1 containing the log-likelihood value.
</p>
</li>
<li> <p><code>sc</code> numeric matrix containing the systematic component for the input <code>x</code> and <code>mod</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Agresti, A. (2012). Categorical data analysis (Vol. 792). John Wiley &amp; Sons.
</p>

<hr>
<h2 id='LL_binomial'>Binomial log-likelihood</h2><span id='topic+LL_binomial'></span>

<h3>Description</h3>

<p>Computes the binomial log-likelihood given a response vector and corresponding GLM linear predictor values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL_binomial(y, x, mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL_binomial_+3A_y">y</code></td>
<td>
<p>numeric vector (or factor) recording a binary dependent variable.</p>
</td></tr>
<tr><td><code id="LL_binomial_+3A_x">x</code></td>
<td>
<p>data.frame (or matrix) containing predictor values.</p>
</td></tr>
<tr><td><code id="LL_binomial_+3A_mod">mod</code></td>
<td>
<p><code>glm</code> object containing and estimated logistic regression model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> and <code>y</code> are equal to the data on which <code>mod</code> has been trained, this function returns the same result as the default <code>logLink</code> function. If <code>x</code> and <code>y</code> are new, the function returns the log-likelihood of the new data under the trained model.
The log-likelihood equation is based on Agresti (2002, p. 192).
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>ll</code> an atomic vector of length 1 containing the log-likelihood value.
</p>
</li>
<li> <p><code>sc</code> an atomic vector containing the systematic component for the input <code>x</code> and <code>mod</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2022
</p>


<h3>References</h3>

<p>Agresti, A. (2012). Categorical data analysis (Vol. 792). John Wiley &amp; Sons.
</p>

<hr>
<h2 id='LL_cumulative'>Proportional odds model log-likelihood</h2><span id='topic+LL_cumulative'></span>

<h3>Description</h3>

<p>Computes the log-likelihood given an ordered category response vector and corresponding GLM linear predictor values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL_cumulative(y, x, mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL_cumulative_+3A_y">y</code></td>
<td>
<p>ordered factor or disjunctive table representation recording an ordinal variable with 3 or more categories.</p>
</td></tr>
<tr><td><code id="LL_cumulative_+3A_x">x</code></td>
<td>
<p>data.frame (or matrix) containing predictor values.</p>
</td></tr>
<tr><td><code id="LL_cumulative_+3A_mod">mod</code></td>
<td>
<p><code>polr</code> object containing the estimated proportional odds model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> and <code>y</code> are equal to the data on which <code>mod</code> has been trained, this function returns the same result as the default <code>logLink</code> function. If <code>x</code> and <code>y</code> are new, the function returns the log-likelihood of the new data under the trained model.
The log-likelihood equation is based on Agresti (2002, p. 192).
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>ll</code> an atomic vector of length 1 containing the log-likelihood value.
</p>
</li>
<li> <p><code>sc</code>, a numeric matrix containing the systematic component for the input <code>x</code> and <code>mod</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2022
</p>


<h3>References</h3>

<p>Agresti, A. (2012). Categorical data analysis (Vol. 792). John Wiley &amp; Sons.
</p>

<hr>
<h2 id='LL_gaussian'>Gaussian log-likelihood</h2><span id='topic+LL_gaussian'></span>

<h3>Description</h3>

<p>Computes the gaussian (normal) log-likelihood of a vector of observed values given a trained linear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL_gaussian(y, x, mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL_gaussian_+3A_y">y</code></td>
<td>
<p>numeric vector recording a continuous dependent variable.</p>
</td></tr>
<tr><td><code id="LL_gaussian_+3A_x">x</code></td>
<td>
<p>data.frame (or matrix) containing predictor values.</p>
</td></tr>
<tr><td><code id="LL_gaussian_+3A_mod">mod</code></td>
<td>
<p><code>glm</code> or <code>lm</code> object containing the estimated linear regression model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> and <code>y</code> are equal to the data on which <code>mod</code> has been trained, this function returns the same result as the default <code>logLink</code> function. If <code>x</code> and <code>y</code> are new, the function returns the log-likelihood of the new data under the trained model.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>ll</code> an atomic vector of length 1 containing the log-likelihood value.
</p>
</li>
<li> <p><code>sc</code> an atomic vector containing the systematic component for the input <code>x</code> and <code>mod</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2022
</p>

<hr>
<h2 id='LL_newdata'>Log-Likelihood for new data</h2><span id='topic+LL_newdata'></span>

<h3>Description</h3>

<p>Given training and validation datasets, this function returns the log-likelihood of unobserved data under the model trained on the training data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL_newdata(y_train, y_valid, X_train = NULL, X_valid = NULL, fam)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL_newdata_+3A_y_train">y_train</code></td>
<td>
<p>Vector of DV values in the training dataset.</p>
</td></tr>
<tr><td><code id="LL_newdata_+3A_y_valid">y_valid</code></td>
<td>
<p>Vector of DV values in the validation dataset.</p>
</td></tr>
<tr><td><code id="LL_newdata_+3A_x_train">X_train</code></td>
<td>
<p>Matrix of IV values in the training dataset. Can also be set to 1 to obtain the log-likelihood of the new data under the null model.</p>
</td></tr>
<tr><td><code id="LL_newdata_+3A_x_valid">X_valid</code></td>
<td>
<p>Matrix of IV values in the validation dataset. If <code>X_train</code> is set to 1 to obtain the log-likelihood of the new data under the null model, <code>X_valid</code> is ignored.</p>
</td></tr>
<tr><td><code id="LL_newdata_+3A_fam">fam</code></td>
<td>
<p>character vector of length 1 storing the description of the error distribution and link function to be used in the model (see <code><a href="#topic+cv_gspcr">cv_gspcr()</a></code> for the list of possible options)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function trains a GLM regressing <code>y_train</code> on <code>X_train</code> using as link function what is specified in <code>fam</code>. Then, it computes the predictions for the validation data based on the trained model on the scale of the linear predictors (e.g., logit). The likelihood of the validation under the model is returned.
</p>


<h3>Value</h3>

<p>A list of objects.
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>

<hr>
<h2 id='LL_poisson'>Poisson regression log-likelihood</h2><span id='topic+LL_poisson'></span>

<h3>Description</h3>

<p>Computes the Poisson regression log-likelihood of a vector of observed values given the GLM systematic component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LL_poisson(y, x, mod)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LL_poisson_+3A_y">y</code></td>
<td>
<p>numeric vector recording a count dependent variable.</p>
</td></tr>
<tr><td><code id="LL_poisson_+3A_x">x</code></td>
<td>
<p>data.frame (or matrix) containing predictor values.</p>
</td></tr>
<tr><td><code id="LL_poisson_+3A_mod">mod</code></td>
<td>
<p><code>glm</code> object containing the estimated poisson regression model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x</code> and <code>y</code> are equal to the data on which <code>mod</code> has been trained, this function returns the same result as the default <code>logLink</code> function. If <code>x</code> and <code>y</code> are new, the function returns the log-likelihood of the new data under the trained model.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<ul>
<li> <p><code>ll</code> an atomic vector of length 1 containing the log-likelihood value.
</p>
</li>
<li> <p><code>sc</code> an atomic vector containing the systematic component for the input <code>x</code> and <code>mod</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Agresti, A. (2012). Categorical data analysis (Vol. 792). John Wiley &amp; Sons.
</p>

<hr>
<h2 id='pca_mix'>PCA of a mixture of numerical and categorical data</h2><span id='topic+pca_mix'></span>

<h3>Description</h3>

<p>Wrapper for the <code>PCAmixdata::PCAmix()</code> function to be used in the main cross-validation procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pca_mix(X_tr, X_va, npcs = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pca_mix_+3A_x_tr">X_tr</code></td>
<td>
<p>data.frame of training data</p>
</td></tr>
<tr><td><code id="pca_mix_+3A_x_va">X_va</code></td>
<td>
<p>data.frame of validation data</p>
</td></tr>
<tr><td><code id="pca_mix_+3A_npcs">npcs</code></td>
<td>
<p>number of principal components to keep</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of training and validation PC scores
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>


<h3>References</h3>

<p>Chavent M, Kuentz V, Labenne A, Liquet B, Saracco J (2017). PCAmixdata: Multivariate Analysis of Mixed Data. R package version 3.1, <a href="https://CRAN.R-project.org/package=PCAmixdata">https://CRAN.R-project.org/package=PCAmixdata</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example inputs
data(wine, package = "FactoMineR")
X &lt;- wine[, c(1, 2, 16, 22)]
X$Label &lt;- factor(X$Label)
X$Soil &lt;- factor(X$Soil)
X_tr &lt;- X[1:15, ]
X_va &lt;- X[16:21, ]
npcs &lt;- 2

# Example use
pca_mix(
    X_tr = X[1:15, ],
    X_va = X[16:21, ],
    npcs = 2
)
</code></pre>

<hr>
<h2 id='plot.gspcrcv'>Plot the cross-validation solution path for the GSPCR algorithm</h2><span id='topic+plot.gspcrcv'></span>

<h3>Description</h3>

<p>Produces a scatter plot showing the CV score obtained by <code>cv_gspcr</code> (Y-axis) with different threshold values (X-axis) for a different number of components (lines).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gspcrcv'
plot(
  x,
  y = NULL,
  labels = TRUE,
  errorBars = FALSE,
  discretize = TRUE,
  y_reverse = FALSE,
  print = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.gspcrcv_+3A_x">x</code></td>
<td>
<p>An object of class <code>gspcr</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_y">y</code></td>
<td>
<p>The CV fit measure to report on the Y axis. Default is the fit measure specified in <code>cv_gspcr()</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_labels">labels</code></td>
<td>
<p>Logical value. <code>FALSE</code> hides the labels of the points indicating the number of components used. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_errorbars">errorBars</code></td>
<td>
<p>Logical value. <code>TRUE</code> shows the error bars for each point. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_discretize">discretize</code></td>
<td>
<p>Logical value. <code>TRUE</code> treats the X-axis as a discrete measure that facilitates comparing solution paths between different fit measures. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_y_reverse">y_reverse</code></td>
<td>
<p>Logical value. <code>TRUE</code> reverses the y axis scale. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_print">print</code></td>
<td>
<p>Logical value. TRUE prints the plot when the function is called. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.gspcrcv_+3A_...">...</code></td>
<td>
<p>Other arguments passed on to methods. Not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bounds defining the error bars are computed by <code>cv_gspcr()</code>. First, the K-fold cross-validation score of the statistic of interest (e.g., the F score, the MSE) is computed. Then, the standard deviation of the statistic across the K folds is computed. Finally, the bounds used for the error bars are computed by summing and subtracting this standard deviation to and from the K-fold cross-validation score of the statistic.
</p>
<p>Reversing the y-axis with <code>y_reverse</code> can be helpful to compare results obtained by different fit measures.
</p>


<h3>Value</h3>

<p>A scatter plot of <code>ggplot</code> class
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>

<hr>
<h2 id='predict.gspcrout'>Predict GSPCR model dependent variable scores</h2><span id='topic+predict.gspcrout'></span>

<h3>Description</h3>

<p>Predicts dependent variable values based on (new) predictor variables values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'gspcrout'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.gspcrout_+3A_object">object</code></td>
<td>
<p>An object of class <code>gspcr</code>.</p>
</td></tr>
<tr><td><code id="predict.gspcrout_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables with which to predict. If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.gspcrout_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of prediction in &quot;response&quot; format for numerical data and probability of class membership for categorical data
</p>


<h3>Author(s)</h3>

<p>Edoardo Costantini, 2023
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
