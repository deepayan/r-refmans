<!DOCTYPE html><html><head><title>Help for package stminsights</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {stminsights}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#get_diag'><p>computes stm model diagnostics</p></a></li>
<li><a href='#get_effects'><p>extract stm effect estimates</p></a></li>
<li><a href='#get_network'><p>extract topic correlation network</p></a></li>
<li><a href='#run_stminsights'><p>launch the stminsights shiny app</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A 'Shiny' Application for Inspecting Structural Topic Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-18</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/cschwem2er/stminsights">https://github.com/cschwem2er/stminsights</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cschwem2er/stminsights/issues">https://github.com/cschwem2er/stminsights/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>This app enables interactive validation, interpretation and visualization of structural topic models from the 'stm' package by Roberts and others (2014) &lt;<a href="https://doi.org/10.1111%2Fajps.12103">doi:10.1111/ajps.12103</a>&gt;. It also includes helper functions for model diagnostics and extracting data from effect estimates.</td>
</tr>
<tr>
<td>Imports:</td>
<td>stm (&ge; 1.3.5), tidygraph (&ge; 1.2.0), ggraph (&ge; 2.1.0),
igraph (&ge; 1.4.0), ggrepel (&ge; 0.9.0), shiny (&ge; 1.7.0),
shinyBS (&ge; 0.6.0), shinydashboard (&ge; 0.7.0), shinyjs (&ge;
2.1.0), ggplot2 (&ge; 3.4.0), purrr (&ge; 1.0.0), stringr (&ge;
1.5.0), dplyr (&ge; 1.1.0), tibble (&ge; 3.2.0), readr (&ge; 2.1.0),
huge (&ge; 1.3.0), stats, scales</td>
</tr>
<tr>
<td>Suggests:</td>
<td>quanteda (&ge; 3.3.0), knitr, rmarkdown</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-18 12:53:34 UTC; cschw</td>
</tr>
<tr>
<td>Author:</td>
<td>Carsten Schwemmer <a href="https://orcid.org/0000-0001-9084-946X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Jonne Guyt [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carsten Schwemmer &lt;c.schwem2er@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-18 19:20:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='get_diag'>computes stm model diagnostics</h2><span id='topic+get_diag'></span>

<h3>Description</h3>

<p><code> get_diag()</code> is a helper function to compute average and median
<code><a href="stm.html#topic+semanticCoherence">semanticCoherence</a></code> and <code><a href="stm.html#topic+exclusivity">exclusivity</a></code> for
a number of  <code><a href="stm.html#topic+stm">stm</a></code> models. The function does not work for
models with content covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_diag(models, outobj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_diag_+3A_models">models</code></td>
<td>
<p>A list of stm models.</p>
</td></tr>
<tr><td><code id="get_diag_+3A_outobj">outobj</code></td>
<td>
<p>The <code>out</code> object containing documents for all stm models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns model diagnostics in a data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(stm)
library(dplyr)
library(ggplot2)
library(quanteda)

# prepare data
data &lt;- corpus(gadarian, text_field = 'open.ended.response')
docvars(data)$text &lt;- as.character(data)

data &lt;- tokens(data, remove_punct = TRUE) |&gt;
  tokens_wordstem() |&gt;
  tokens_remove(stopwords('english')) |&gt; dfm() |&gt;
  dfm_trim(min_termfreq = 2)

out &lt;- convert(data, to = 'stm')

# fit models
gadarian_3 &lt;- stm(documents = out$documents,
                  vocab = out$vocab,
                  data = out$meta,
                  prevalence = ~ treatment + s(pid_rep),
                  K = 3,
                  max.em.its = 1, # reduce computation time for example
                  verbose = FALSE)

gadarian_5 &lt;- stm(documents = out$documents,
                  vocab = out$vocab,
                  data = out$meta,
                  prevalence = ~ treatment + s(pid_rep),
                  K = 5,
                  max.em.its = 1, # reduce computation time for example
                  verbose = FALSE)

# get diagnostics
diag &lt;- get_diag(models = list(
                 model_3 = gadarian_3,
                 model_5 = gadarian_5),
                 outobj = out)
## Not run: 
# plot diagnostics
diag |&gt;
ggplot(aes(x = coherence, y = exclusivity, color = statistic))  +
  geom_text(aes(label = name), nudge_x = 5) + geom_point() +
  labs(x = 'Semantic Coherence', y = 'Exclusivity') + theme_light()

## End(Not run)

</code></pre>

<hr>
<h2 id='get_effects'>extract stm effect estimates</h2><span id='topic+get_effects'></span>

<h3>Description</h3>

<p><code> get_effects()</code> is a helper function to store effect estimates from
stm in a data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_effects(
  estimates,
  variable,
  type,
  ci = 0.95,
  moderator = NULL,
  modval = NULL,
  cov_val1 = NULL,
  cov_val2 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_effects_+3A_estimates">estimates</code></td>
<td>
<p>The object containing estimates calculated with
<code><a href="stm.html#topic+estimateEffect">estimateEffect</a></code>.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_variable">variable</code></td>
<td>
<p>The variable for which estimates should be extracted.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_type">type</code></td>
<td>
<p>The estimate type. Must be either <code>'pointestimate'</code>,
<code>'continuous'</code>, or <code>'difference'</code>.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_ci">ci</code></td>
<td>
<p>The confidence interval for uncertainty estimates.
Defaults to  <code>0.95</code>.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_moderator">moderator</code></td>
<td>
<p>The moderator variable in case you want to include
an interaction effect.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_modval">modval</code></td>
<td>
<p>The value of the moderator variable for an interaction effect.
See examples for combining data for multiple values.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_cov_val1">cov_val1</code></td>
<td>
<p>The first value of a covariate for type <code>'difference'</code>.</p>
</td></tr>
<tr><td><code id="get_effects_+3A_cov_val2">cov_val2</code></td>
<td>
<p>The second value of a covariate for type <code>'difference'</code>.
The topic proportion of <code>'cov_val2'</code> will be subtracted from the
proportion of <code>'cov_val1'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns effect estimates in a tidy data frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(stm)
library(dplyr)
library(ggplot2)

# store effects
prep &lt;- estimateEffect(1:3 ~ treatment + pid_rep, gadarianFit, gadarian)

effects &lt;- get_effects(estimates = prep,
                      variable = 'treatment',
                      type = 'pointestimate')


# plot effects
effects |&gt; filter(topic == 3) |&gt;
ggplot(aes(x = value, y = proportion)) +
 geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1, size = 1) +
 geom_point(size = 3) +
 coord_flip() + theme_light() + labs(x = 'Treatment', y = 'Topic Proportion')


# combine estimates for interaction effects
prep_int &lt;- estimateEffect(1:3 ~ treatment * s(pid_rep),
 gadarianFit, gadarian)

effects_int &lt;- get_effects(estimates = prep_int,
                          variable = 'pid_rep',
                          type = 'continuous',
                          moderator = 'treatment',
                          modval = 1) |&gt;
 bind_rows(
   get_effects(estimates = prep_int,
               variable = 'pid_rep',
               type = 'continuous',
               moderator = 'treatment',
               modval = 0)
 )

# plot interaction effects
effects_int  |&gt;  filter(topic == 2) |&gt;
 mutate(moderator = as.factor(moderator)) |&gt;
 ggplot(aes(x = value, y = proportion, color = moderator,
 group = moderator, fill = moderator)) +
 geom_line() +
 geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2)  +
 theme_light() + labs(x = 'PID Rep.', y = 'Topic Proportion',
 color = 'Treatment', group = 'Treatment', fill = 'Treatment')


</code></pre>

<hr>
<h2 id='get_network'>extract topic correlation network</h2><span id='topic+get_network'></span>

<h3>Description</h3>

<p><code> get_network()</code> is a helper function to extract topic correlation networks
as tidygraph objects and add labels and topic proportions.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_network_+3A_model">model</code></td>
<td>
<p>The stm model for computing the correlation network.</p>
</td></tr>
<tr><td><code id="get_network_+3A_method">method</code></td>
<td>
<p>The method for determining edges. Can be either  <code>'simple'</code> or  <code>'huge'</code>.</p>
</td></tr>
<tr><td><code id="get_network_+3A_cutoff">cutoff</code></td>
<td>
<p>The correlation cutoff criterion for <code>method = 'cutoff'</code>. Defaults to <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="get_network_+3A_labels">labels</code></td>
<td>
<p>An optional vector of topic labels. Must include a label for each topic of the model.</p>
</td></tr>
<tr><td><code id="get_network_+3A_cutiso">cutiso</code></td>
<td>
<p>Remove isolated notes without any edges from the network. Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns tidygraph network of topic correlations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(stm)
library(ggraph)
library(quanteda)

# prepare data
data &lt;- corpus(gadarian, text_field = 'open.ended.response')
docvars(data)$text &lt;- as.character(data)

data &lt;- tokens(data, remove_punct = TRUE) |&gt;
  tokens_wordstem() |&gt;
  tokens_remove(stopwords('english')) |&gt; dfm() |&gt;
  dfm_trim(min_termfreq = 2)

out &lt;- convert(data, to = 'stm')

# fit model
gadarian_10 &lt;- stm(documents = out$documents,
                   vocab = out$vocab,
                   data = out$meta,
                   prevalence = ~ treatment + s(pid_rep),
                   K = 10,
                   max.em.its = 1, # reduce computation time for example
                   verbose = FALSE)

# extract network
stm_corrs &lt;- get_network(model = gadarian_10,
                         method = 'simple',
                         labels = paste('Topic', 1:10),
                         cutoff = 0.001,
                         cutiso = TRUE)

## Not run: 
# plot network
ggraph(stm_corrs, layout = 'fr') +
  geom_edge_link(
    aes(edge_width = weight),
    label_colour = '#fc8d62',
    edge_colour = '#377eb8') +
  geom_node_point(size = 4, colour = 'black')  +
  geom_node_label(
    aes(label = name, size = props),
    colour = 'black',  repel = TRUE, alpha = 0.85) +
  scale_size(range = c(2, 10), labels = scales::percent) +
  labs(size = 'Topic Proportion',  edge_width = 'Topic Correlation') +
  scale_edge_width(range = c(1, 3)) +
  theme_graph()

## End(Not run)

</code></pre>

<hr>
<h2 id='run_stminsights'>launch the stminsights shiny app</h2><span id='topic+run_stminsights'></span>

<h3>Description</h3>

<p><code>run_stminsights</code> launches the app to analyze Structural Topic models.
It requires a .RData file with stm objects as illustrated in the example below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_stminsights(use_browser = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run_stminsights_+3A_use_browser">use_browser</code></td>
<td>
<p>Choose whether you want to launch the shiny app in your browser.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
 ## Not run: 

library(stm)
library(quanteda)

# prepare data
data &lt;- corpus(gadarian, text_field = 'open.ended.response')
docvars(data)$text &lt;- as.character(data)

data &lt;- tokens(data, remove_punct = TRUE) |&gt;
  tokens_wordstem() |&gt;
  tokens_remove(stopwords('english')) |&gt; dfm() |&gt;
  dfm_trim(min_termfreq = 2)

out &lt;- convert(data, to = 'stm')

# fit models and effect estimates
gadarian_3 &lt;- stm(documents = out$documents,
                  vocab = out$vocab,
                  data = out$meta,
                  prevalence = ~ treatment + s(pid_rep),
                  K = 3,
                  max.em.its = 1, # reduce computation time for example
                  verbose = FALSE)

prep_3 &lt;- estimateEffect(1:3 ~ treatment + s(pid_rep), gadarian_3,
                         meta = out$meta)

gadarian_5 &lt;- stm(documents = out$documents,
                  vocab = out$vocab,
                  data = out$meta,
                  prevalence = ~ treatment + s(pid_rep),
                  K = 5,
                  max.em.its = 1, # reduce computation time for example
                  verbose = FALSE)

prep_5 &lt;- estimateEffect(1:5 ~ treatment + s(pid_rep), gadarian_5,
                         meta = out$meta)

# save objects in .RData file
save.image(paste0(tempdir(), '/stm_gadarian.RData'))

# launch the app
if(interactive()){
  run_stminsights()
}


## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
