<!DOCTYPE html><html><head><title>Help for package meteorits</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {meteorits}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#meteorits-package'><p>MEteorits: Mixtures-of-ExperTs modEling for cOmplex and non-noRmal dIsTributions</p></a></li>
<li><a href='#emNMoE'><p>emNMoE implements the EM algorithm to fit a Normal Mixture of Experts (NMoE).</p></a></li>
<li><a href='#emSNMoE'><p>emSNMoE implements the ECM algorithm to fit a Skew-Normal Mixture of Experts</p>
(SNMoE).</a></li>
<li><a href='#emStMoE'><p>emStMoE implements the ECM algorithm to fit a Skew-t Mixture of Experts</p>
(StMoE).</a></li>
<li><a href='#emTMoE'><p>emTMoE implements the ECM algorithm to fit a t Mixture of Experts (TMoE).</p></a></li>
<li><a href='#ModelNMoE-class'><p>A Reference Class which represents a fitted NMoE model.</p></a></li>
<li><a href='#ModelSNMoE-class'><p>A Reference Class which represents a fitted SNMoE model.</p></a></li>
<li><a href='#ModelStMoE-class'><p>A Reference Class which represents a fitted StMoE model.</p></a></li>
<li><a href='#ModelTMoE-class'><p>A Reference Class which represents a fitted TMoE model.</p></a></li>
<li><a href='#ParamNMoE-class'><p>A Reference Class which contains parameters of a NMoE model.</p></a></li>
<li><a href='#ParamSNMoE-class'><p>A Reference Class which contains parameters of a SNMoE model.</p></a></li>
<li><a href='#ParamStMoE-class'><p>A Reference Class which contains parameters of a StMoE model.</p></a></li>
<li><a href='#ParamTMoE-class'><p>A Reference Class which contains parameters of a TMoE model.</p></a></li>
<li><a href='#sampleUnivNMoE'><p>Draw a sample from a normal mixture of linear experts model.</p></a></li>
<li><a href='#sampleUnivSNMoE'><p>Draw a sample from a skew-normal mixture of linear experts model.</p></a></li>
<li><a href='#sampleUnivStMoE'><p>Draw a sample from a univariate skew-t mixture.</p></a></li>
<li><a href='#sampleUnivTMoE'><p>Draw a sample from a univariate t mixture of experts (TMoE).</p></a></li>
<li><a href='#StatNMoE-class'><p>A Reference Class which contains statistics of a NMoE model.</p></a></li>
<li><a href='#StatSNMoE-class'><p>A Reference Class which contains statistics of a SNMoE model.</p></a></li>
<li><a href='#StatStMoE-class'><p>A Reference Class which contains statistics of a StMoE model.</p></a></li>
<li><a href='#StatTMoE-class'><p>A Reference Class which contains statistics of a TMoE model.</p></a></li>
<li><a href='#tempanomalies'><p>Global Annual Temperature Anomalies (Land Meteorological Stations)</p>
(1880-2015)</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Mixture-of-Experts Modeling for Complex Non-Normal Distributions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a unified mixture-of-experts (ME) modeling and 
    estimation framework with several original and flexible ME models to 
    model, cluster and classify heterogeneous data in many complex 
    situations where the data are distributed according to non-normal, 
    possibly skewed distributions, and when they might be corrupted by 
    atypical observations. Mixtures-of-Experts models for complex and 
    non-normal distributions ('meteorits') are originally introduced and 
    written in 'Matlab' by Faicel Chamroukhi. The references are mainly the 
    following ones. The references are mainly the following ones.
    Chamroukhi F., Same A., Govaert, G. and Aknin P. (2009) &lt;<a href="https://doi.org/10.1016%2Fj.neunet.2009.06.040">doi:10.1016/j.neunet.2009.06.040</a>&gt;.
    Chamroukhi F. (2010) <a href="https://chamroukhi.com/FChamroukhi-PhD.pdf">https://chamroukhi.com/FChamroukhi-PhD.pdf</a>.
    Chamroukhi F. (2015) &lt;<a href="https://doi.org/10.48550/arXiv.1506.06707">doi:10.48550/arXiv.1506.06707</a>&gt;.
    Chamroukhi F. (2015) <a href="https://chamroukhi.com/FChamroukhi-HDR.pdf">https://chamroukhi.com/FChamroukhi-HDR.pdf</a>.
    Chamroukhi F. (2016) &lt;<a href="https://doi.org/10.1109%2FIJCNN.2016.7727580">doi:10.1109/IJCNN.2016.7727580</a>&gt;.
    Chamroukhi F. (2016) &lt;<a href="https://doi.org/10.1016%2Fj.neunet.2016.03.002">doi:10.1016/j.neunet.2016.03.002</a>&gt;.
    Chamroukhi F. (2017) &lt;<a href="https://doi.org/10.1016%2Fj.neucom.2017.05.044">doi:10.1016/j.neucom.2017.05.044</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/fchamroukhi/MEteorits">https://github.com/fchamroukhi/MEteorits</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/fchamroukhi/MEteorits/issues">https://github.com/fchamroukhi/MEteorits/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>pracma, methods, stats, MASS, Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Collate:</td>
<td>meteorits-package.R RcppExports.R logsumexp.R utils.R
sampleUnivNMoE.R sampleUnivSNMoE.R sampleUnivStMoE.R
sampleUnivTMoE.R ParamSNMoE.R ParamStMoE.R ParamTMoE.R
ParamNMoE.R StatSNMoE.R StatStMoE.R StatTMoE.R StatNMoE.R
ModelSNMoE.R ModelStMoE.R ModelTMoE.R ModelNMoE.R emSNMoE.R
emStMoE.R emTMoE.R emNMoE.R data-tempanomalies.R</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-01-10 13:06:19 UTC; lecocq191</td>
</tr>
<tr>
<td>Author:</td>
<td>Faicel Chamroukhi <a href="https://orcid.org/0000-0002-5894-3103"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Florian Lecocq [aut, trl, cre] (R port),
  Marius Bartcus [aut, trl] (R port)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Lecocq &lt;florian.lecocq@outlook.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-01-10 16:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='meteorits-package'>MEteorits: Mixtures-of-ExperTs modEling for cOmplex and non-noRmal dIsTributions</h2><span id='topic+meteorits'></span><span id='topic+meteorits-package'></span>

<h3>Description</h3>

<p><code>meteorits</code> is a package containing several original and
flexible mixtures-of-experts models to model, cluster and classify
heteregenous data in many complex situations where the data are distributed
according to non-normal and possibly skewed distributions, and when they
might be corrupted by atypical observations. The toolbox also contains
sparse mixture-of-experts models for high-dimensional data.
</p>
<p><code>meteorits</code> contains the following Mixture-of-Experts models:
</p>

<ul>
<li><p> NMoE (Normal Mixtures-of-Experts) provides a flexible framework for
heterogenous data with Normal expert regressors network;
</p>
</li>
<li><p> SNMoE (Skew-Normal Mixtures-of-Experts) provides a flexible
modeling framework for heterogenous data with possibly skewed
distributions to generalize the standard Normal mixture of expert model;
</p>
</li>
<li><p> tMoE (t Mixtures-of-Experts) provides a flexible and robust
modeling framework for heterogenous data with possibly heavy-tailed
distributions and corrupted by atypical observations;
</p>
</li>
<li><p> StMoE (Skew t Mixtures-of-Experts) provides a flexible and robust
modeling framework for heterogenous data with possibly skewed,
heavy-tailed distributions and corrupted by atypical observations.
</p>
</li></ul>

<p>For the advantages/differences of each of them, the user is referred to our
mentioned paper references.
</p>
<p>To learn more about <code>meteorits</code>, start with the vignettes:
<code>browseVignettes(package = "meteorits")</code>
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Florian Lecocq <a href="mailto:florian.lecocq@outlook.com">florian.lecocq@outlook.com</a> (R port) [translator]
</p>
<p>Authors:
</p>

<ul>
<li><p> Faicel Chamroukhi <a href="mailto:faicel.chamroukhi@unicaen.fr">faicel.chamroukhi@unicaen.fr</a> (0000-0002-5894-3103)
</p>
</li>
<li><p> Marius Bartcus <a href="mailto:marius.bartcus@gmail.com">marius.bartcus@gmail.com</a> (R port) [translator]
</p>
</li></ul>



<h3>References</h3>

<p>Chamroukhi, F. 2017. <em>Skew-T Mixture of Experts.</em> Neurocomputing - Elsevier 266: 390&ndash;408. <a href="https://chamroukhi.com/papers/STMoE.pdf">https://chamroukhi.com/papers/STMoE.pdf</a>.
</p>
<p>Chamroukhi, F. 2016a. <em>Robust Mixture of Experts Modeling Using the T-Distribution.</em> Neural Networks - Elsevier 79: 20&ndash;36. <a href="https://chamroukhi.com/papers/TMoE.pdf">https://chamroukhi.com/papers/TMoE.pdf</a>.
</p>
<p>Chamroukhi, F. 2016b. <em>Skew-Normal Mixture of Experts.</em> In The International Joint Conference on Neural Networks (IJCNN). Vancouver, Canada. <a href="https://chamroukhi.com/papers/Chamroukhi-SNMoE-IJCNN2016.pdf">https://chamroukhi.com/papers/Chamroukhi-SNMoE-IJCNN2016.pdf</a>.
</p>
<p>Chamroukhi, F. 2015a. <em>Non-Normal Mixtures of Experts.</em> <a href="http://arxiv.org/pdf/1506.06707.pdf">http://arxiv.org/pdf/1506.06707.pdf</a>.
</p>
<p>Chamroukhi, F. 2015b. <em>Statistical Learning of Latent Data Models for Complex Data Analysis.</em> Habilitation Thesis (HDR), Universite de Toulon. <a href="https://chamroukhi.com/FChamroukhi-HDR.pdf">https://chamroukhi.com/FChamroukhi-HDR.pdf</a>.
</p>
<p>Chamroukhi, F. 2010. <em>Hidden Process Regression for Curve Modeling, Classification and Tracking.</em> Ph.D. Thesis, Universite de Technologie de Compiegne. <a href="https://chamroukhi.com/FChamroukhi-PhD.pdf">https://chamroukhi.com/FChamroukhi-PhD.pdf</a>.
</p>
<p>Chamroukhi, F., A. Same, G. Govaert, and P. Aknin. 2009. <em>Time Series Modeling by a Regression Approach Based on a Latent Process.</em> Neural Networks 22 (5-6): 593&ndash;602. <a href="https://chamroukhi.com/papers/Chamroukhi_Neural_Networks_2009.pdf">https://chamroukhi.com/papers/Chamroukhi_Neural_Networks_2009.pdf</a>.
</p>


<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/fchamroukhi/MEteorits">https://github.com/fchamroukhi/MEteorits</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/fchamroukhi/MEteorits/issues">https://github.com/fchamroukhi/MEteorits/issues</a>
</p>
</li></ul>


<hr>
<h2 id='emNMoE'>emNMoE implements the EM algorithm to fit a Normal Mixture of Experts (NMoE).</h2><span id='topic+emNMoE'></span>

<h3>Description</h3>

<p>emNMoE implements the maximum-likelihood parameter estimation of a Normal
Mixture of Experts (NMoE) model by the Expectation-Maximization (EM)
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emNMoE(X, Y, K, p = 3, q = 1, n_tries = 1, max_iter = 1500,
  threshold = 1e-06, verbose = FALSE, verbose_IRLS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emNMoE_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_k">K</code></td>
<td>
<p>The number of experts.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression for the experts.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_q">q</code></td>
<td>
<p>Optional. The order of the logistic regression for the gating
network.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the EM algorithm. The solution
providing the highest log-likelihood will be returned.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the EM
algorithm.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the EM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during EM iterations.</p>
</td></tr>
<tr><td><code id="emNMoE_+3A_verbose_irls">verbose_IRLS</code></td>
<td>
<p>Optional. A logical value indicating whether or not
values of the criterion optimized by IRLS should be printed at each step of
the EM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emNMoE function implements the EM algorithm for the NMoE model. This
function starts with an initialization of the parameters done by the method
<code>initParam</code> of the class <a href="#topic+ParamNMoE">ParamNMoE</a>, then it alternates between
the E-Step (method of the class <a href="#topic+StatNMoE">StatNMoE</a>) and the M-Step
(method of the class <a href="#topic+ParamNMoE">ParamNMoE</a>) until convergence (until the
relative variation of log-likelihood between two steps of the EM algorithm
is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>EM returns an object of class <a href="#topic+ModelNMoE">ModelNMoE</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelNMoE">ModelNMoE</a>, <a href="#topic+ParamNMoE">ParamNMoE</a>, <a href="#topic+StatNMoE">StatNMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

nmoe &lt;- emNMoE(X = x, Y = y, K = 2, p = 1, verbose = TRUE)

nmoe$summary()

nmoe$plot()
</code></pre>

<hr>
<h2 id='emSNMoE'>emSNMoE implements the ECM algorithm to fit a Skew-Normal Mixture of Experts
(SNMoE).</h2><span id='topic+emSNMoE'></span>

<h3>Description</h3>

<p>emSNMoE implements the maximum-likelihood parameter estimation of a
Skew-Normal Mixture of Experts (SNMoE) model by the Expectation Conditional
Maximization (ECM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emSNMoE(X, Y, K, p = 3, q = 1, n_tries = 1, max_iter = 1500,
  threshold = 1e-06, verbose = FALSE, verbose_IRLS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emSNMoE_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_k">K</code></td>
<td>
<p>The number of experts.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression for the experts.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_q">q</code></td>
<td>
<p>Optional. The order of the logistic regression for the gating
network.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the ECM algorithm. The solution
providing the highest log-likelihood will be returned.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the ECM
algorithm.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the ECM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during ECM iterations.</p>
</td></tr>
<tr><td><code id="emSNMoE_+3A_verbose_irls">verbose_IRLS</code></td>
<td>
<p>Optional. A logical value indicating whether or not
values of the criterion optimized by IRLS should be printed at each step of
the ECM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emSNMoE function implements the ECM algorithm for the SNMoE model.
This function starts with an initialization of the parameters done by the
method <code>initParam</code> of the class <a href="#topic+ParamSNMoE">ParamSNMoE</a>, then it
alternates between the E-Step (method of the class <a href="#topic+StatSNMoE">StatSNMoE</a>)
and the M-Step (method of the class <a href="#topic+ParamSNMoE">ParamSNMoE</a>) until
convergence (until the relative variation of log-likelihood between two
steps of the ECM algorithm is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>ECM returns an object of class <a href="#topic+ModelSNMoE">ModelSNMoE</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelSNMoE">ModelSNMoE</a>, <a href="#topic+ParamSNMoE">ParamSNMoE</a>, <a href="#topic+StatSNMoE">StatSNMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

snmoe &lt;- emSNMoE(X = x, Y = y, K = 2, p = 1, verbose = TRUE)

snmoe$summary()

snmoe$plot()
</code></pre>

<hr>
<h2 id='emStMoE'>emStMoE implements the ECM algorithm to fit a Skew-t Mixture of Experts
(StMoE).</h2><span id='topic+emStMoE'></span>

<h3>Description</h3>

<p>emStMoE implements the maximum-likelihood parameter estimation of a
Skew-t Mixture of Experts (StMoE) model by the Expectation Conditional
Maximization (ECM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emStMoE(X, Y, K, p = 3, q = 1, n_tries = 1, max_iter = 1500,
  threshold = 1e-06, verbose = FALSE, verbose_IRLS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emStMoE_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_k">K</code></td>
<td>
<p>The number of experts.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression for the experts.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_q">q</code></td>
<td>
<p>Optional. The order of the logistic regression for the gating
network.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the ECM algorithm. The solution
providing the highest log-likelihood will be returned.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the ECM
algorithm.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the ECM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during ECM iterations.</p>
</td></tr>
<tr><td><code id="emStMoE_+3A_verbose_irls">verbose_IRLS</code></td>
<td>
<p>Optional. A logical value indicating whether or not
values of the criterion optimized by IRLS should be printed at each step of
the ECM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emStMoE function implements the ECM algorithm for the StMoE model.
This function starts with an initialization of the parameters done by the
method <code>initParam</code> of the class <a href="#topic+ParamStMoE">ParamStMoE</a>, then it
alternates between the E-Step (method of the class <a href="#topic+StatStMoE">StatStMoE</a>)
and the M-Step (method of the class <a href="#topic+ParamStMoE">ParamStMoE</a>) until
convergence (until the relative variation of log-likelihood between two
steps of the ECM algorithm is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>ECM returns an object of class <a href="#topic+ModelStMoE">ModelStMoE</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelStMoE">ModelStMoE</a>, <a href="#topic+ParamStMoE">ParamStMoE</a>, <a href="#topic+StatStMoE">StatStMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

stmoe &lt;- emStMoE(X = x, Y = y, K = 2, p = 1, threshold = 1e-4, verbose = TRUE)

stmoe$summary()

stmoe$plot()
</code></pre>

<hr>
<h2 id='emTMoE'>emTMoE implements the ECM algorithm to fit a t Mixture of Experts (TMoE).</h2><span id='topic+emTMoE'></span>

<h3>Description</h3>

<p>emTMoE implements the maximum-likelihood parameter estimation of a Student
Mixture of Experts (TMoE) model by the Conditional Expectation Maximization
(ECM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emTMoE(X, Y, K, p = 3, q = 1, n_tries = 1, max_iter = 1500,
  threshold = 1e-06, verbose = FALSE, verbose_IRLS = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emTMoE_+3A_x">X</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_y">Y</code></td>
<td>
<p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_k">K</code></td>
<td>
<p>The number of experts.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_p">p</code></td>
<td>
<p>Optional. The order of the polynomial regression for the experts.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_q">q</code></td>
<td>
<p>Optional. The order of the logistic regression for the gating
network.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_n_tries">n_tries</code></td>
<td>
<p>Optional. Number of runs of the ECM algorithm. The solution
providing the highest log-likelihood will be returned.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_max_iter">max_iter</code></td>
<td>
<p>Optional. The maximum number of iterations for the ECM
algorithm.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_threshold">threshold</code></td>
<td>
<p>Optional. A numeric value specifying the threshold for the
relative difference of log-likelihood between two steps of the ECM as
stopping criteria.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_verbose">verbose</code></td>
<td>
<p>Optional. A logical value indicating whether or not values of
the log-likelihood should be printed during ECM iterations.</p>
</td></tr>
<tr><td><code id="emTMoE_+3A_verbose_irls">verbose_IRLS</code></td>
<td>
<p>Optional. A logical value indicating whether or not
values of the criterion optimized by IRLS should be printed at each step of
the ECM algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>emTMoE function implements the ECM algorithm for the TMoE model. This
function starts with an initialization of the parameters done by the method
<code>initParam</code> of the class <a href="#topic+ParamTMoE">ParamTMoE</a>, then it alternates between
the E-Step (method of the class <a href="#topic+StatTMoE">StatTMoE</a>) and the M-Step
(method of the class <a href="#topic+ParamTMoE">ParamTMoE</a>) until convergence (until the
relative variation of log-likelihood between two steps of the ECM algorithm
is less than the <code>threshold</code> parameter).
</p>


<h3>Value</h3>

<p>ECM returns an object of class <a href="#topic+ModelTMoE">ModelTMoE</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+ModelTMoE">ModelTMoE</a>, <a href="#topic+ParamTMoE">ParamTMoE</a>, <a href="#topic+StatTMoE">StatTMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

tmoe &lt;- emTMoE(X = x, Y = y, K = 2, p = 1, verbose = TRUE)

tmoe$summary()

tmoe$plot()
</code></pre>

<hr>
<h2 id='ModelNMoE-class'>A Reference Class which represents a fitted NMoE model.</h2><span id='topic+ModelNMoE-class'></span><span id='topic+ModelNMoE'></span>

<h3>Description</h3>

<p>ModelNMoE represents an estimated NMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamNMoE">ParamNMoE</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatNMoE">StatNMoE</a> object. It contains all the statistics
associated to the NMoE model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("meancurve", "confregions", "clusters", "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"meancurve" = </code> Estimated mean and estimated
experts means given the input <code>X</code> (fields <code>Ey</code> and
<code>Ey_k</code> of class <a href="#topic+StatNMoE">StatNMoE</a>).
</p>
</li>
<li> <p><code>"confregions" = </code> Estimated mean and confidence
regions. Confidence regions are computed as plus and minus twice
the estimated standard deviation (the squarre root of the field
<code>Vary</code> of class <a href="#topic+StatNMoE">StatNMoE</a>).
</p>
</li>
<li> <p><code>"clusters" = </code> Estimated experts means (field
<code>Ey_k</code>) and hard partition (field <code>klas</code> of class
<a href="#topic+StatNMoE">StatNMoE</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatNMoE">StatNMoE</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamNMoE">ParamNMoE</a>, <a href="#topic+StatNMoE">StatNMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

nmoe &lt;- emNMoE(X = x, Y = y, K = 2, p = 1, verbose = TRUE)

# nmoe is a ModelNMoE object. It contains some methods such as 'summary' and 'plot'
nmoe$summary()
nmoe$plot()

# nmoe has also two fields, stat and param which are reference classes as well

# Log-likelihood:
nmoe$stat$loglik

# Parameters of the polynomial regressions:
nmoe$param$beta
</code></pre>

<hr>
<h2 id='ModelSNMoE-class'>A Reference Class which represents a fitted SNMoE model.</h2><span id='topic+ModelSNMoE-class'></span><span id='topic+ModelSNMoE'></span>

<h3>Description</h3>

<p>ModelSNMoE represents an estimated SNMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamSNMoE">ParamSNMoE</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatSNMoE">StatSNMoE</a> object. It contains all the statistics
associated to the SNMoE model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("meancurve", "confregions", "clusters", "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"meancurve" = </code> Estimated mean and estimated
experts means given the input <code>X</code> (fields <code>Ey</code> and
<code>Ey_k</code> of class <a href="#topic+StatSNMoE">StatSNMoE</a>).
</p>
</li>
<li> <p><code>"confregions" = </code> Estimated mean and confidence
regions. Confidence regions are computed as plus and minus twice
the estimated standard deviation (the squarre root of the field
<code>Vary</code> of class <a href="#topic+StatSNMoE">StatSNMoE</a>).
</p>
</li>
<li> <p><code>"clusters" = </code> Estimated experts means (field
<code>Ey_k</code>) and hard partition (field <code>klas</code> of class
<a href="#topic+StatSNMoE">StatSNMoE</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatSNMoE">StatSNMoE</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamSNMoE">ParamSNMoE</a>, <a href="#topic+StatSNMoE">StatSNMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

snmoe &lt;- emSNMoE(X = x, Y = y, K = 2, p = 1, verbose = TRUE)

# snmoe is a ModelSNMoE object. It contains some methods such as 'summary' and 'plot'
snmoe$summary()
snmoe$plot()

# snmoe has also two fields, stat and param which are reference classes as well

# Log-likelihood:
snmoe$stat$loglik

# Parameters of the polynomial regressions:
snmoe$param$beta
</code></pre>

<hr>
<h2 id='ModelStMoE-class'>A Reference Class which represents a fitted StMoE model.</h2><span id='topic+ModelStMoE-class'></span><span id='topic+ModelStMoE'></span>

<h3>Description</h3>

<p>ModelStMoE represents an estimated StMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamStMoE">ParamStMoE</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatStMoE">StatStMoE</a> object. It contains all the statistics
associated to the StMoE model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("meancurve", "confregions", "clusters", "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"meancurve" = </code> Estimated mean and estimated
experts means given the input <code>X</code> (fields <code>Ey</code> and
<code>Ey_k</code> of class <a href="#topic+StatStMoE">StatStMoE</a>).
</p>
</li>
<li> <p><code>"confregions" = </code> Estimated mean and confidence
regions. Confidence regions are computed as plus and minus twice
the estimated standard deviation (the squarre root of the field
<code>Vary</code> of class <a href="#topic+StatStMoE">StatStMoE</a>).
</p>
</li>
<li> <p><code>"clusters" = </code> Estimated experts means (field
<code>Ey_k</code>) and hard partition (field <code>klas</code> of class
<a href="#topic+StatStMoE">StatStMoE</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatStMoE">StatStMoE</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamStMoE">ParamStMoE</a>, <a href="#topic+StatStMoE">StatStMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

stmoe &lt;- emStMoE(X = x, Y = y, K = 2, p = 1, threshold = 1e-4, verbose = TRUE)

# stmoe is a ModelSTMoE object. It contains some methods such as 'summary' and 'plot'
stmoe$summary()
stmoe$plot()

# stmoe has also two fields, stat and param which are reference classes as well

# Log-likelihood:
stmoe$stat$loglik

# Parameters of the polynomial regressions:
stmoe$param$beta
</code></pre>

<hr>
<h2 id='ModelTMoE-class'>A Reference Class which represents a fitted TMoE model.</h2><span id='topic+ModelTMoE-class'></span><span id='topic+ModelTMoE'></span>

<h3>Description</h3>

<p>ModelTMoE represents an estimated TMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>param</code></dt><dd><p>A <a href="#topic+ParamTMoE">ParamTMoE</a> object. It contains the estimated
values of the parameters.</p>
</dd>
<dt><code>stat</code></dt><dd><p>A <a href="#topic+StatTMoE">StatTMoE</a> object. It contains all the statistics
associated to the TMoE model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>plot(what = c("meancurve", "confregions", "clusters", "loglikelihood"), ...)</code></dt><dd><p>Plot method.
</p>

<dl>
<dt><code>what</code></dt><dd><p>The type of graph requested:
</p>

<ul>
<li> <p><code>"meancurve" = </code> Estimated mean and estimated
experts means given the input <code>X</code> (fields <code>Ey</code> and
<code>Ey_k</code> of class <a href="#topic+StatTMoE">StatTMoE</a>).
</p>
</li>
<li> <p><code>"confregions" = </code> Estimated mean and confidence
regions. Confidence regions are computed as plus and minus twice
the estimated standard deviation (the squarre root of the field
<code>Vary</code> of class <a href="#topic+StatTMoE">StatTMoE</a>).
</p>
</li>
<li> <p><code>"clusters" = </code> Estimated experts means (field
<code>Ey_k</code>) and hard partition (field <code>klas</code> of class
<a href="#topic+StatTMoE">StatTMoE</a>).
</p>
</li>
<li> <p><code>"loglikelihood" = </code> Value of the log-likelihood for
each iteration (field <code>stored_loglik</code> of class
<a href="#topic+StatTMoE">StatTMoE</a>).
</p>
</li></ul>

</dd>
<dt><code>...</code></dt><dd><p>Other graphics parameters.</p>
</dd>
</dl>

<p>By default, all the graphs mentioned above are produced.</p>
</dd>
<dt><code>summary(digits = getOption("digits"))</code></dt><dd><p>Summary method.
</p>

<dl>
<dt><code>digits</code></dt><dd><p>The number of significant digits to use when
printing.</p>
</dd>
</dl>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamTMoE">ParamTMoE</a>, <a href="#topic+StatTMoE">StatTMoE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tempanomalies)
x &lt;- tempanomalies$Year
y &lt;- tempanomalies$AnnualAnomaly

tmoe &lt;- emTMoE(X = x, Y = y, K = 2, p = 1, verbose = TRUE)

# tmoe is a ModelTMoE object. It contains some methods such as 'summary' and 'plot'
tmoe$summary()
tmoe$plot()

# tmoe has also two fields, stat and param which are reference classes as well

# Log-likelihood:
tmoe$stat$loglik

# Parameters of the polynomial regressions:
tmoe$param$beta
</code></pre>

<hr>
<h2 id='ParamNMoE-class'>A Reference Class which contains parameters of a NMoE model.</h2><span id='topic+ParamNMoE-class'></span><span id='topic+ParamNMoE'></span>

<h3>Description</h3>

<p>ParamNMoE contains all the parameters of a NMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</dd>
<dt><code>n</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of experts.</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression for the experts.</p>
</dd>
<dt><code>q</code></dt><dd><p>The order of the logistic regression for the gating network.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>Parameters of the gating network. <code class="reqn">\boldsymbol{\alpha} =
  (\boldsymbol{\alpha}_{1},\dots,\boldsymbol{\alpha}_{K-1})</code> is a matrix of dimension <code class="reqn">(q + 1, K -
  1)</code>, with <code>q</code> the order of the logistic regression for the gating network.
<code>q</code> is fixed to 1 by default.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Polynomial regressions coefficients for each expert.
<code class="reqn">\boldsymbol{\beta} =
  (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is a matrix of dimension <code class="reqn">(p + 1, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> mixture components (matrix of size
<code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>df</code></dt><dd><p>The degree of freedom of the NMoE model representing the complexity
of the model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(segmental = FALSE)</code></dt><dd><p>Method to initialize parameters <code>alpha</code>, <code>beta</code> and
<code>sigma2</code>.
</p>
<p>If <code>segmental = TRUE</code> then <code>alpha</code>, <code>beta</code> and
<code>sigma2</code> are initialized by clustering the response <code>Y</code>
uniformly into <code>K</code> contiguous segments. Otherwise, <code>alpha</code>,
<code>beta</code> and <code>sigma2</code> are initialized by clustering randomly
the response <code>Y</code> into <code>K</code> segments.</p>
</dd>
</dl>

<hr>
<h2 id='ParamSNMoE-class'>A Reference Class which contains parameters of a SNMoE model.</h2><span id='topic+ParamSNMoE-class'></span><span id='topic+ParamSNMoE'></span>

<h3>Description</h3>

<p>ParamSNMoE contains all the parameters of a SNMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</dd>
<dt><code>n</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of experts.</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression for the experts.</p>
</dd>
<dt><code>q</code></dt><dd><p>The order of the logistic regression for the gating network.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>Parameters of the gating network. <code class="reqn">\boldsymbol{\alpha} =
  (\boldsymbol{\alpha}_{1},\dots,\boldsymbol{\alpha}_{K-1})</code> is a matrix of dimension <code class="reqn">(q + 1, K -
  1)</code>, with <code>q</code> the order of the logistic regression for the gating network.
<code>q</code> is fixed to 1 by default.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Polynomial regressions coefficients for each expert.
<code class="reqn">\boldsymbol{\beta} =
  (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is a matrix of dimension <code class="reqn">(p + 1, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> mixture components (matrix of size
<code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>lambda</code></dt><dd><p>The skewness parameters for each experts (matrix of size
<code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>delta</code></dt><dd><p>delta is equal to <code class="reqn">\delta =
\frac{\lambda}{\sqrt{1+\lambda^2}}</code>.</p>
</dd>
<dt><code>df</code></dt><dd><p>The degree of freedom of the SNMoE model representing the
complexity of the model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(segmental = FALSE)</code></dt><dd><p>Method to initialize parameters <code>alpha</code>, <code>beta</code> and
<code>sigma2</code>.
</p>
<p>If <code>segmental = TRUE</code> then <code>alpha</code>, <code>beta</code> and
<code>sigma2</code> are initialized by clustering the response <code>Y</code>
uniformly into <code>K</code> contiguous segments. Otherwise, <code>alpha</code>,
<code>beta</code> and <code>sigma2</code> are initialized by clustering randomly
the response <code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statSNMoE, verbose_IRLS)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the SNMoE model based on statistics provided by the object
<code>statSNMoE</code> of class <a href="#topic+StatSNMoE">StatSNMoE</a> (which contains the E-step).</p>
</dd>
</dl>

<hr>
<h2 id='ParamStMoE-class'>A Reference Class which contains parameters of a StMoE model.</h2><span id='topic+ParamStMoE-class'></span><span id='topic+ParamStMoE'></span>

<h3>Description</h3>

<p>ParamStMoE contains all the parameters of a StMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</dd>
<dt><code>n</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of experts.</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression for the experts.</p>
</dd>
<dt><code>q</code></dt><dd><p>The order of the logistic regression for the gating network.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>Parameters of the gating network. <code class="reqn">\boldsymbol{\alpha} =
  (\boldsymbol{\alpha}_{1},\dots,\boldsymbol{\alpha}_{K-1})</code> is a matrix of dimension <code class="reqn">(q + 1, K -
  1)</code>, with <code>q</code> the order of the logistic regression for the gating network.
<code>q</code> is fixed to 1 by default.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Polynomial regressions coefficients for each expert.
<code class="reqn">\boldsymbol{\beta} =
  (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is a matrix of dimension <code class="reqn">(p + 1, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> mixture components (matrix of size
<code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>lambda</code></dt><dd><p>The skewness parameters for each experts (matrix of size
<code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>delta</code></dt><dd><p>delta is equal to <code class="reqn">\delta =
\frac{\lambda}{\sqrt{1+\lambda^2}}</code>.</p>
</dd>
<dt><code>nu</code></dt><dd><p>The degree of freedom for the Student distribution for each
experts (matrix of size <code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>df</code></dt><dd><p>The degree of freedom of the StMoE model representing the
complexity of the model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(segmental = FALSE)</code></dt><dd><p>Method to initialize parameters <code>alpha</code>, <code>beta</code> and
<code>sigma2</code>.
</p>
<p>If <code>segmental = TRUE</code> then <code>alpha</code>, <code>beta</code> and
<code>sigma2</code> are initialized by clustering the response <code>Y</code>
uniformly into <code>K</code> contiguous segments. Otherwise, <code>alpha</code>,
<code>beta</code> and <code>sigma2</code> are initialized by clustering randomly
the response <code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statStMoE, calcAlpha = FALSE, calcBeta = FALSE, calcSigma2 = FALSE,
  calcLambda = FALSE, calcNu = FALSE, verbose_IRLS = FALSE)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the StMoE model based on statistics provided by the object
<code>statStMoE</code> of class <a href="#topic+StatStMoE">StatStMoE</a> (which contains the E-step).</p>
</dd>
</dl>

<hr>
<h2 id='ParamTMoE-class'>A Reference Class which contains parameters of a TMoE model.</h2><span id='topic+ParamTMoE-class'></span><span id='topic+ParamTMoE'></span>

<h3>Description</h3>

<p>ParamTMoE contains all the parameters of a TMoE model.
</p>


<h3>Fields</h3>


<dl>
<dt><code>X</code></dt><dd><p>Numeric vector of length <em>n</em> representing the covariates/inputs
<code class="reqn">x_{1},\dots,x_{n}</code>.</p>
</dd>
<dt><code>Y</code></dt><dd><p>Numeric vector of length <em>n</em> representing the observed
response/output <code class="reqn">y_{1},\dots,y_{n}</code>.</p>
</dd>
<dt><code>n</code></dt><dd><p>Numeric. Length of the response/output vector <code>Y</code>.</p>
</dd>
<dt><code>K</code></dt><dd><p>The number of experts.</p>
</dd>
<dt><code>p</code></dt><dd><p>The order of the polynomial regression for the experts.</p>
</dd>
<dt><code>q</code></dt><dd><p>The order of the logistic regression for the gating network.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>Parameters of the gating network. <code class="reqn">\boldsymbol{\alpha} =
  (\boldsymbol{\alpha}_{1},\dots,\boldsymbol{\alpha}_{K-1})</code> is a matrix of dimension <code class="reqn">(q + 1, K -
  1)</code>, with <code>q</code> the order of the logistic regression for the gating network.
<code>q</code> is fixed to 1 by default.</p>
</dd>
<dt><code>beta</code></dt><dd><p>Polynomial regressions coefficients for each expert.
<code class="reqn">\boldsymbol{\beta} =
  (\boldsymbol{\beta}_{1},\dots,\boldsymbol{\beta}_{K})</code> is a matrix of dimension <code class="reqn">(p + 1, K)</code>,
with <code>p</code> the order of the polynomial regression. <code>p</code> is fixed to 3 by
default.</p>
</dd>
<dt><code>sigma2</code></dt><dd><p>The variances for the <code>K</code> mixture components (matrix of size
<code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>nu</code></dt><dd><p>The degree of freedom for the Student distribution for each
experts (matrix of size <code class="reqn">(1, K)</code>).</p>
</dd>
<dt><code>df</code></dt><dd><p>The degree of freedom of the TMoE model representing the
complexity of the model.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>initParam(segmental = FALSE)</code></dt><dd><p>Method to initialize parameters <code>alpha</code>, <code>beta</code> and
<code>sigma2</code>.
</p>
<p>If <code>segmental = TRUE</code> then <code>alpha</code>, <code>beta</code> and
<code>sigma2</code> are initialized by clustering the response <code>Y</code>
uniformly into <code>K</code> contiguous segments. Otherwise, <code>alpha</code>,
<code>beta</code> and <code>sigma2</code> are initialized by clustering randomly
the response <code>Y</code> into <code>K</code> segments.</p>
</dd>
<dt><code>MStep(statTMoE, verbose_IRLS)</code></dt><dd><p>Method which implements the M-step of the EM algorithm to learn the
parameters of the TMoE model based on statistics provided by the object
<code>statTMoE</code> of class <a href="#topic+StatTMoE">StatTMoE</a> (which contains the E-step).</p>
</dd>
</dl>

<hr>
<h2 id='sampleUnivNMoE'>Draw a sample from a normal mixture of linear experts model.</h2><span id='topic+sampleUnivNMoE'></span>

<h3>Description</h3>

<p>Draw a sample from a normal mixture of linear experts model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleUnivNMoE(alphak, betak, sigmak, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleUnivNMoE_+3A_alphak">alphak</code></td>
<td>
<p>The parameters of the gating network. <code>alphak</code> is a matrix of
size <em>(q + 1, K - 1)</em>, with <em>K - 1</em>, the number of regressors
(experts) and <em>q</em> the order of the logistic regression</p>
</td></tr>
<tr><td><code id="sampleUnivNMoE_+3A_betak">betak</code></td>
<td>
<p>Matrix of size <em>(p + 1, K)</em> representing the regression
coefficients of the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivNMoE_+3A_sigmak">sigmak</code></td>
<td>
<p>Vector of length <em>K</em> giving the standard deviations of
the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivNMoE_+3A_x">x</code></td>
<td>
<p>A vector og length <em>n</em> representing the inputs (predictors).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the output variable <code>y</code> and statistics.
</p>

<ul>
<li> <p><code>y</code> Vector of length <em>n</em> giving the output variable.
</p>
</li>
<li> <p><code>zi</code> A vector of size <em>n</em> giving the hidden label of the
expert component generating the i-th observation. Its elements are
<code class="reqn">zi[i] = k</code>, if the i-th observation has been generated by the
k-th expert.
</p>
</li>
<li> <p><code>z</code> A matrix of size <em>(n, K)</em> giving the values of the binary
latent component indicators <code class="reqn">Z_{ik}</code> such that
<code class="reqn">Z_{ik} = 1</code> iff <code class="reqn">Z_{i} = k</code>.
</p>
</li>
<li> <p><code>stats</code> A list whose elements are:
</p>

<ul>
<li> <p><code>Ey_k</code> Matrix of size <em>(n, K)</em> giving the conditional
expectation of Yi the output variable given the value of the
hidden label of the expert component generating the ith observation
<em>zi = k</em>, and the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Ey</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary_k</code> Vector of length <em>k</em> representing the conditional
variance of Yi given <em>zi = k</em>, and <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given <em>X = xi</em>.
</p>
</li></ul>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500 # Size of the sample
alphak &lt;- matrix(c(0, 8), ncol = 1) # Parameters of the gating network
betak &lt;- matrix(c(0, -2.5, 0, 2.5), ncol = 2) # Regression coefficients of the experts
sigmak &lt;- c(1, 1) # Standard deviations of the experts
x &lt;- seq.int(from = -1, to = 1, length.out = n) # Inputs (predictors)

# Generate sample of size n
sample &lt;- sampleUnivNMoE(alphak = alphak, betak = betak, sigmak = sigmak, x = x)

# Plot points and estimated means
plot(x, sample$y, pch = 4)
lines(x, sample$stats$Ey_k[, 1], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey_k[, 2], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey, col = "red", lwd = 1.5)
</code></pre>

<hr>
<h2 id='sampleUnivSNMoE'>Draw a sample from a skew-normal mixture of linear experts model.</h2><span id='topic+sampleUnivSNMoE'></span>

<h3>Description</h3>

<p>Draw a sample from a skew-normal mixture of linear experts model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleUnivSNMoE(alphak, betak, sigmak, lambdak, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleUnivSNMoE_+3A_alphak">alphak</code></td>
<td>
<p>The parameters of the gating network. <code>alphak</code> is a matrix of
size <em>(q + 1, K - 1)</em>, with <em>K - 1</em>, the number of regressors
(experts) and <em>q</em> the order of the logistic regression</p>
</td></tr>
<tr><td><code id="sampleUnivSNMoE_+3A_betak">betak</code></td>
<td>
<p>Matrix of size <em>(p + 1, K)</em> representing the regression
coefficients of the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivSNMoE_+3A_sigmak">sigmak</code></td>
<td>
<p>Vector of length <em>K</em> giving the standard deviations of
the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivSNMoE_+3A_lambdak">lambdak</code></td>
<td>
<p>Vector of length <em>K</em> giving the skewness parameter of
each experts.</p>
</td></tr>
<tr><td><code id="sampleUnivSNMoE_+3A_x">x</code></td>
<td>
<p>A vector og length <em>n</em> representing the inputs (predictors).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the output variable <code>y</code> and statistics.
</p>

<ul>
<li> <p><code>y</code> Vector of length <em>n</em> giving the output variable.
</p>
</li>
<li> <p><code>zi</code> A vector of size <em>n</em> giving the hidden label of the
expert component generating the i-th observation. Its elements are
<code class="reqn">zi[i] = k</code>, if the i-th observation has been generated by the
k-th expert.
</p>
</li>
<li> <p><code>z</code> A matrix of size <em>(n, K)</em> giving the values of the binary
latent component indicators <code class="reqn">Z_{ik}</code> such that
<code class="reqn">Z_{ik} = 1</code> iff <code class="reqn">Z_{i} = k</code>.
</p>
</li>
<li> <p><code>stats</code> A list whose elements are:
</p>

<ul>
<li> <p><code>Ey_k</code> Matrix of size <em>(n, K)</em> giving the conditional
expectation of Yi the output variable given the value of the
hidden label of the expert component generating the ith observation
<em>zi = k</em>, and the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Ey</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary_k</code> Vector of length <em>k</em> representing the conditional
variance of Yi given <em>zi = k</em>, and <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given <em>X = xi</em>.
</p>
</li></ul>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500 # Size of the sample
alphak &lt;- matrix(c(0, 8), ncol = 1) # Parameters of the gating network
betak &lt;- matrix(c(0, -2.5, 0, 2.5), ncol = 2) # Regression coefficients of the experts
lambdak &lt;- c(3, 5) # Skewness parameters of the experts
sigmak &lt;- c(1, 1) # Standard deviations of the experts
x &lt;- seq.int(from = -1, to = 1, length.out = n) # Inputs (predictors)

# Generate sample of size n
sample &lt;- sampleUnivSNMoE(alphak = alphak, betak = betak, sigmak = sigmak,
                          lambdak = lambdak, x = x)

# Plot points and estimated means
plot(x, sample$y, pch = 4)
lines(x, sample$stats$Ey_k[, 1], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey_k[, 2], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey, col = "red", lwd = 1.5)
</code></pre>

<hr>
<h2 id='sampleUnivStMoE'>Draw a sample from a univariate skew-t mixture.</h2><span id='topic+sampleUnivStMoE'></span>

<h3>Description</h3>

<p>Draw a sample from a univariate skew-t mixture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleUnivStMoE(alphak, betak, sigmak, lambdak, nuk, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleUnivStMoE_+3A_alphak">alphak</code></td>
<td>
<p>The parameters of the gating network. <code>alphak</code> is a matrix of
size <em>(q + 1, K - 1)</em>, with <em>K - 1</em>, the number of regressors
(experts) and <em>q</em> the order of the logistic regression</p>
</td></tr>
<tr><td><code id="sampleUnivStMoE_+3A_betak">betak</code></td>
<td>
<p>Matrix of size <em>(p + 1, K)</em> representing the regression
coefficients of the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivStMoE_+3A_sigmak">sigmak</code></td>
<td>
<p>Vector of length <em>K</em> giving the standard deviations of
the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivStMoE_+3A_lambdak">lambdak</code></td>
<td>
<p>Vector of length <em>K</em> giving the skewness parameter of
each experts.</p>
</td></tr>
<tr><td><code id="sampleUnivStMoE_+3A_nuk">nuk</code></td>
<td>
<p>Vector of length <em>K</em> giving the degrees of freedom of the
experts network t densities.</p>
</td></tr>
<tr><td><code id="sampleUnivStMoE_+3A_x">x</code></td>
<td>
<p>A vector og length <em>n</em> representing the inputs (predictors).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the output variable <code>y</code> and statistics.
</p>

<ul>
<li> <p><code>y</code> Vector of length <em>n</em> giving the output variable.
</p>
</li>
<li> <p><code>zi</code> A vector of size <em>n</em> giving the hidden label of the
expert component generating the i-th observation. Its elements are
<code class="reqn">zi[i] = k</code>, if the i-th observation has been generated by the
k-th expert.
</p>
</li>
<li> <p><code>z</code> A matrix of size <em>(n, K)</em> giving the values of the binary
latent component indicators <code class="reqn">Z_{ik}</code> such that
<code class="reqn">Z_{ik} = 1</code> iff <code class="reqn">Z_{i} = k</code>.
</p>
</li>
<li> <p><code>stats</code> A list whose elements are:
</p>

<ul>
<li> <p><code>Ey_k</code> Matrix of size <em>(n, K)</em> giving the conditional
expectation of Yi the output variable given the value of the
hidden label of the expert component generating the ith observation
<em>zi = k</em>, and the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Ey</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary_k</code> Vector of length <em>k</em> representing the conditional
variance of Yi given <em>zi = k</em>, and <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given <em>X = xi</em>.
</p>
</li></ul>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500 # Size of the sample
alphak &lt;- matrix(c(0, 8), ncol = 1) # Parameters of the gating network
betak &lt;- matrix(c(0, -2.5, 0, 2.5), ncol = 2) # Regression coefficients of the experts
sigmak &lt;- c(0.5, 0.5) # Standard deviations of the experts
lambdak &lt;- c(3, 5) # Skewness parameters of the experts
nuk &lt;- c(5, 7) # Degrees of freedom of the experts network t densities
x &lt;- seq.int(from = -1, to = 1, length.out = n) # Inputs (predictors)

# Generate sample of size n
sample &lt;- sampleUnivStMoE(alphak = alphak, betak = betak, sigmak = sigmak,
                          lambdak = lambdak, nuk = nuk, x = x)

# Plot points and estimated means
plot(x, sample$y, pch = 4)
lines(x, sample$stats$Ey_k[, 1], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey_k[, 2], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey, col = "red", lwd = 1.5)
</code></pre>

<hr>
<h2 id='sampleUnivTMoE'>Draw a sample from a univariate t mixture of experts (TMoE).</h2><span id='topic+sampleUnivTMoE'></span>

<h3>Description</h3>

<p>Draw a sample from a univariate t mixture of experts (TMoE).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleUnivTMoE(alphak, betak, sigmak, nuk, x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleUnivTMoE_+3A_alphak">alphak</code></td>
<td>
<p>The parameters of the gating network. <code>alphak</code> is a matrix of
size <em>(q + 1, K - 1)</em>, with <em>K - 1</em>, the number of regressors
(experts) and <em>q</em> the order of the logistic regression</p>
</td></tr>
<tr><td><code id="sampleUnivTMoE_+3A_betak">betak</code></td>
<td>
<p>Matrix of size <em>(p + 1, K)</em> representing the regression
coefficients of the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivTMoE_+3A_sigmak">sigmak</code></td>
<td>
<p>Vector of length <em>K</em> giving the standard deviations of
the experts network.</p>
</td></tr>
<tr><td><code id="sampleUnivTMoE_+3A_nuk">nuk</code></td>
<td>
<p>Vector of length <em>K</em> giving the degrees of freedom of the
experts network t densities.</p>
</td></tr>
<tr><td><code id="sampleUnivTMoE_+3A_x">x</code></td>
<td>
<p>A vector of length <em>n</em> representing the inputs (predictors).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the output variable <code>y</code> and statistics.
</p>

<ul>
<li> <p><code>y</code> Vector of length <em>n</em> giving the output variable.
</p>
</li>
<li> <p><code>zi</code> A vector of size <em>n</em> giving the hidden label of the
expert component generating the i-th observation. Its elements are
<code class="reqn">zi[i] = k</code>, if the i-th observation has been generated by the
k-th expert.
</p>
</li>
<li> <p><code>z</code> A matrix of size <em>(n, K)</em> giving the values of the binary
latent component indicators <code class="reqn">Z_{ik}</code> such that
<code class="reqn">Z_{ik} = 1</code> iff <code class="reqn">Z_{i} = k</code>.
</p>
</li>
<li> <p><code>stats</code> A list whose elements are:
</p>

<ul>
<li> <p><code>Ey_k</code> Matrix of size <em>(n, K)</em> giving the conditional
expectation of Yi the output variable given the value of the
hidden label of the expert component generating the ith observation
<em>zi = k</em>, and the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Ey</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given the value of predictor <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary_k</code> Vector of length <em>k</em> representing the conditional
variance of Yi given <em>zi = k</em>, and <em>X = xi</em>.
</p>
</li>
<li> <p><code>Vary</code> Vector of length <em>n</em> giving the conditional expectation
of Yi given <em>X = xi</em>.
</p>
</li></ul>

</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500 # Size of the sample
alphak &lt;- matrix(c(0, 8), ncol = 1) # Parameters of the gating network
betak &lt;- matrix(c(0, -2.5, 0, 2.5), ncol = 2) # Regression coefficients of the experts
sigmak &lt;- c(0.5, 0.5) # Standard deviations of the experts
nuk &lt;- c(5, 7) # Degrees of freedom of the experts network t densities
x &lt;- seq.int(from = -1, to = 1, length.out = n) # Inputs (predictors)

# Generate sample of size n
sample &lt;- sampleUnivTMoE(alphak = alphak, betak = betak, sigmak = sigmak,
                         nuk = nuk, x = x)

# Plot points and estimated means
plot(x, sample$y, pch = 4)
lines(x, sample$stats$Ey_k[, 1], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey_k[, 2], col = "blue", lty = "dotted", lwd = 1.5)
lines(x, sample$stats$Ey, col = "red", lwd = 1.5)
</code></pre>

<hr>
<h2 id='StatNMoE-class'>A Reference Class which contains statistics of a NMoE model.</h2><span id='topic+StatNMoE-class'></span><span id='topic+StatNMoE'></span>

<h3>Description</h3>

<p>StatNMoE contains all the statistics associated to a <a href="#topic+ParamNMoE">NMoE</a> model.
It mainly includes the E-Step of the EM algorithm calculating the posterior
distribution of the hidden variables, as well as the calculation of the
log-likelhood.
</p>


<h3>Fields</h3>


<dl>
<dt><code>piik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> representing the probabilities
<code class="reqn">\pi_{k}(x_{i}; \boldsymbol{\Psi}) = P(z_{i} = k |
  \boldsymbol{x}; \Psi)</code> of
the latent variable <code class="reqn">z_{i}, i = 1,\dots,n</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(n, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ \tau_{is};\ 0 \
  \textrm{otherwise}</code>,
<code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>tik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the posterior probability
<code class="reqn">\tau_{ik}</code> that the observation <code class="reqn">y_{i}</code> originates
from the <code class="reqn">k</code>-th expert.</p>
</dd>
<dt><code>Ey_k</code></dt><dd><p>Matrix of dimension <em>(n, K)</em> giving the estimated means of the experts.</p>
</dd>
<dt><code>Ey</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated mean of the NMoE.</p>
</dd>
<dt><code>Var_yk</code></dt><dd><p>Column matrix of dimension <em>K</em> giving the estimated means of the experts.</p>
</dd>
<dt><code>Vary</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated variance of the response.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Observed-data log-likelihood of the NMoE model.</p>
</dd>
<dt><code>com_loglik</code></dt><dd><p>Numeric. Complete-data log-likelihood of the NMoE model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each EM iteration.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>ICL</code></dt><dd><p>Numeric. Value of ICL (Integrated Completed Likelihood).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>log_piik_fik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the values of the
logarithm of the joint probability <code class="reqn">P(y_{i}, \ z_{i} = k |
  \boldsymbol{x}, \boldsymbol{\Psi})</code>, <code class="reqn">i
  = 1,\dots,n</code>.</p>
</dd>
<dt><code>log_sum_piik_fik</code></dt><dd><p>Column matrix of size <em>m</em> giving the values of
<code class="reqn">\textrm{log} \sum_{k = 1}^{K} P(y_{i}, \ z_{i} = k | \boldsymbol{x},
  \boldsymbol{\Psi})</code>,
<code class="reqn">i = 1,\dots,n</code>.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(reg_irls)</code></dt><dd><p>Method to compute the log-likelihood. <code>reg_irls</code> is the value of
the regularization part in the IRLS algorithm.</p>
</dd>
<dt><code>computeStats(paramNMoE)</code></dt><dd><p>Method used in the EM algorithm to compute statistics based on
parameters provided by the object <code>paramNMoE</code> of class
<a href="#topic+ParamNMoE">ParamNMoE</a>.</p>
</dd>
<dt><code>EStep(paramNMoE)</code></dt><dd><p>Method used in the EM algorithm to update statistics based on parameters
provided by the object <code>paramNMoE</code> of class <a href="#topic+ParamNMoE">ParamNMoE</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z_{ik} = 1 \ \textrm{if} \ k = \textrm{arg} \ \textrm{max}_{s}
      \ \tau_{is};\ 0 \ \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamNMoE">ParamNMoE</a>
</p>

<hr>
<h2 id='StatSNMoE-class'>A Reference Class which contains statistics of a SNMoE model.</h2><span id='topic+StatSNMoE-class'></span><span id='topic+StatSNMoE'></span>

<h3>Description</h3>

<p>StatSNMoE contains all the statistics associated to a <a href="#topic+ParamSNMoE">SNMoE</a> model.
It mainly includes the E-Step of the ECM algorithm calculating the posterior
distribution of the hidden variables, as well as the calculation of the
log-likelhood.
</p>


<h3>Fields</h3>


<dl>
<dt><code>piik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> representing the probabilities
<code class="reqn">\pi_{k}(x_{i}; \boldsymbol{\Psi}) = P(z_{i} = k |
  \boldsymbol{x}; \Psi)</code> of
the latent variable <code class="reqn">z_{i}, i = 1,\dots,n</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(n, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ \tau_{is};\ 0 \
  \textrm{otherwise}</code>,
<code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>tik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the posterior probability
<code class="reqn">\tau_{ik}</code> that the observation <code class="reqn">y_{i}</code> originates
from the <code class="reqn">k</code>-th expert.</p>
</dd>
<dt><code>Ey_k</code></dt><dd><p>Matrix of dimension <em>(n, K)</em> giving the estimated means of the experts.</p>
</dd>
<dt><code>Ey</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated mean of the SNMoE.</p>
</dd>
<dt><code>Var_yk</code></dt><dd><p>Column matrix of dimension <em>K</em> giving the estimated means of the experts.</p>
</dd>
<dt><code>Vary</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated variance of the response.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Observed-data log-likelihood of the SNMoE model.</p>
</dd>
<dt><code>com_loglik</code></dt><dd><p>Numeric. Complete-data log-likelihood of the SNMoE model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each ECM iteration.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>ICL</code></dt><dd><p>Numeric. Value of ICL (Integrated Completed Likelihood).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>log_piik_fik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the values of the
logarithm of the joint probability <code class="reqn">P(y_{i}, \ z_{i} = k |
  \boldsymbol{x}, \boldsymbol{\Psi})</code>, <code class="reqn">i
  = 1,\dots,n</code>.</p>
</dd>
<dt><code>log_sum_piik_fik</code></dt><dd><p>Column matrix of size <em>m</em> giving the values of
<code class="reqn">\textrm{log} \sum_{k = 1}^{K} P(y_{i}, \ z_{i} = k | \boldsymbol{x},
  \boldsymbol{\Psi})</code>,
<code class="reqn">i = 1,\dots,n</code>.</p>
</dd>
<dt><code>E1ik</code></dt><dd><p>Conditional expectations of <code class="reqn">U_{i}</code> (Matrix of size <code class="reqn">(n, K)</code>).</p>
</dd>
<dt><code>E2ik</code></dt><dd><p>Conditional expectations of <code class="reqn">U_{i}^{2}</code> (Matrix of size <code class="reqn">(n, K)</code>).</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(reg_irls)</code></dt><dd><p>Method to compute the log-likelihood. <code>reg_irls</code> is the value of
the regularization part in the IRLS algorithm.</p>
</dd>
<dt><code>computeStats(paramSNMoE)</code></dt><dd><p>Method used in the ECM algorithm to compute statistics based on
parameters provided by the object <code>paramSNMoE</code> of class
<a href="#topic+ParamSNMoE">ParamSNMoE</a>.</p>
</dd>
<dt><code>EStep(paramSNMoE)</code></dt><dd><p>Method used in the ECM algorithm to update statistics based on parameters
provided by the object <code>paramSNMoE</code> of class <a href="#topic+ParamSNMoE">ParamSNMoE</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z_{ik} = 1 \ \textrm{if} \ k = \textrm{arg} \ \textrm{max}_{s}
      \ \tau_{is};\ 0 \ \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamSNMoE">ParamSNMoE</a>
</p>

<hr>
<h2 id='StatStMoE-class'>A Reference Class which contains statistics of a StMoE model.</h2><span id='topic+StatStMoE-class'></span><span id='topic+StatStMoE'></span>

<h3>Description</h3>

<p>StatStMoE contains all the statistics associated to a <a href="#topic+ParamStMoE">StMoE</a>
model. It mainly includes the E-Step of the ECM algorithm calculating the
posterior distribution of the hidden variables, as well as the calculation of
the log-likelhood.
</p>


<h3>Fields</h3>


<dl>
<dt><code>piik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> representing the probabilities
<code class="reqn">\pi_{k}(x_{i}; \boldsymbol{\Psi}) = P(z_{i} = k | \boldsymbol{x};
  \Psi)</code> of the latent
variable <code class="reqn">z_{i}, i = 1,\dots,n</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(n, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ \tau_{is};\ 0 \
  \textrm{otherwise}</code>,
<code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>tik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the posterior probability
<code class="reqn">\tau_{ik}</code> that the observation <code class="reqn">y_{i}</code> originates
from the <code class="reqn">k</code>-th expert.</p>
</dd>
<dt><code>Ey_k</code></dt><dd><p>Matrix of dimension <em>(n, K)</em> giving the estimated means of
the experts.</p>
</dd>
<dt><code>Ey</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated mean of the StMoE.</p>
</dd>
<dt><code>Var_yk</code></dt><dd><p>Column matrix of dimension <em>K</em> giving the estimated means
of the experts.</p>
</dd>
<dt><code>Vary</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated variance
of the response.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Observed-data log-likelihood of the StMoE model.</p>
</dd>
<dt><code>com_loglik</code></dt><dd><p>Numeric. Complete-data log-likelihood of the StMoE model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each ECM iteration.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>ICL</code></dt><dd><p>Numeric. Value of ICL (Integrated Completed Likelihood).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>log_piik_fik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the values of the
logarithm of the joint probability <code class="reqn">P(y_{i}, \ z_{i} = k |
  \boldsymbol{x}, \boldsymbol{\Psi})</code>, <code class="reqn">i
  = 1,\dots,n</code>.</p>
</dd>
<dt><code>log_sum_piik_fik</code></dt><dd><p>Column matrix of size <em>m</em> giving the values of
<code class="reqn">\textrm{log} \sum_{k = 1}^{K} P(y_{i}, \ z_{i} = k | \boldsymbol{x},
  \boldsymbol{\Psi})</code>,
<code class="reqn">i = 1,\dots,n</code>.</p>
</dd>
<dt><code>dik</code></dt><dd><p>It represents the value of <code class="reqn">d_{ik}</code>.</p>
</dd>
<dt><code>wik</code></dt><dd><p>Conditional expectations <code class="reqn">w_{ik}</code>.</p>
</dd>
<dt><code>E1ik</code></dt><dd><p>Conditional expectations <code class="reqn">e_{1,ik}</code>.</p>
</dd>
<dt><code>E2ik</code></dt><dd><p>Conditional expectations <code class="reqn">e_{2,ik}</code>.</p>
</dd>
<dt><code>E3ik</code></dt><dd><p>Conditional expectations <code class="reqn">e_{3,ik}</code>.</p>
</dd>
<dt><code>stme_pdf</code></dt><dd><p>Skew-t mixture of experts density.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(reg_irls)</code></dt><dd><p>Method to compute the log-likelihood. <code>reg_irls</code> is the value of
the regularization part in the IRLS algorithm.</p>
</dd>
<dt><code>computeStats(paramStMoE)</code></dt><dd><p>Method used in the ECM algorithm to compute statistics based on
parameters provided by the object <code>paramStMoE</code> of class
<a href="#topic+ParamStMoE">ParamStMoE</a>.</p>
</dd>
<dt><code>EStep(paramStMoE, calcTau = FALSE, calcE1 = FALSE, calcE2 = FALSE,
  calcE3 = FALSE)</code></dt><dd><p>Method used in the ECM algorithm to update statistics based on parameters
provided by the object <code>paramStMoE</code> of class <a href="#topic+ParamStMoE">ParamStMoE</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z_{ik} = 1 \ \textrm{if} \ k = \textrm{arg} \ \textrm{max}_{s}
      \ \tau_{is};\ 0 \ \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamStMoE">ParamStMoE</a>
</p>

<hr>
<h2 id='StatTMoE-class'>A Reference Class which contains statistics of a TMoE model.</h2><span id='topic+StatTMoE-class'></span><span id='topic+StatTMoE'></span>

<h3>Description</h3>

<p>StatTMoE contains all the statistics associated to a <a href="#topic+ParamTMoE">TMoE</a> model.
It mainly includes the E-Step of the ECM algorithm calculating the posterior
distribution of the hidden variables, as well as the calculation of the
log-likelhood.
</p>


<h3>Fields</h3>


<dl>
<dt><code>piik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> representing the probabilities
<code class="reqn">\pi_{k}(x_{i}; \boldsymbol{\Psi}) = P(z_{i} = k |
  \boldsymbol{x}; \Psi)</code> of
the latent variable <code class="reqn">z_{i}, i = 1,\dots,n</code>.</p>
</dd>
<dt><code>z_ik</code></dt><dd><p>Hard segmentation logical matrix of dimension <code class="reqn">(n, K)</code>
obtained by the Maximum a posteriori (MAP) rule: <code class="reqn">z\_ik = 1 \
  \textrm{if} \ z\_ik = \textrm{arg} \ \textrm{max}_{s} \ \tau_{is};\ 0 \
  \textrm{otherwise}</code>,
<code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>klas</code></dt><dd><p>Column matrix of the labels issued from <code>z_ik</code>. Its elements are
<code class="reqn">klas(i) = k</code>, <code class="reqn">k = 1,\dots,K</code>.</p>
</dd>
<dt><code>tik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the posterior probability
<code class="reqn">\tau_{ik}</code> that the observation <code class="reqn">y_{i}</code> originates
from the <code class="reqn">k</code>-th expert.</p>
</dd>
<dt><code>Ey_k</code></dt><dd><p>Matrix of dimension <em>(n, K)</em> giving the estimated means of the experts.</p>
</dd>
<dt><code>Ey</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated mean of the TMoE.</p>
</dd>
<dt><code>Var_yk</code></dt><dd><p>Column matrix of dimension <em>K</em> giving the estimated means of the experts.</p>
</dd>
<dt><code>Vary</code></dt><dd><p>Column matrix of dimension <em>n</em> giving the estimated variance of the response.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>Numeric. Observed-data log-likelihood of the TMoE model.</p>
</dd>
<dt><code>com_loglik</code></dt><dd><p>Numeric. Complete-data log-likelihood of the TMoE model.</p>
</dd>
<dt><code>stored_loglik</code></dt><dd><p>Numeric vector. Stored values of the log-likelihood at
each ECM iteration.</p>
</dd>
<dt><code>BIC</code></dt><dd><p>Numeric. Value of BIC (Bayesian Information Criterion).</p>
</dd>
<dt><code>ICL</code></dt><dd><p>Numeric. Value of ICL (Integrated Completed Likelihood).</p>
</dd>
<dt><code>AIC</code></dt><dd><p>Numeric. Value of AIC (Akaike Information Criterion).</p>
</dd>
<dt><code>log_piik_fik</code></dt><dd><p>Matrix of size <code class="reqn">(n, K)</code> giving the values of the
logarithm of the joint probability <code class="reqn">P(y_{i}, \ z_{i} = k |
  \boldsymbol{x}, \boldsymbol{\Psi})</code>, <code class="reqn">i
  = 1,\dots,n</code>.</p>
</dd>
<dt><code>log_sum_piik_fik</code></dt><dd><p>Column matrix of size <em>m</em> giving the values of
<code class="reqn">\textrm{log} \sum_{k = 1}^{K} P(y_{i}, \ z_{i} = k | \boldsymbol{x},
  \boldsymbol{\Psi})</code>,
<code class="reqn">i = 1,\dots,n</code>.</p>
</dd>
<dt><code>Wik</code></dt><dd><p>Conditional expectations <code class="reqn">w_{ik}</code>.</p>
</dd>
</dl>


<h3>Methods</h3>


<dl>
<dt><code>computeLikelihood(reg_irls)</code></dt><dd><p>Method to compute the log-likelihood. <code>reg_irls</code> is the value of
the regularization part in the IRLS algorithm.</p>
</dd>
<dt><code>computeStats(paramTMoE)</code></dt><dd><p>Method used in the ECM algorithm to compute statistics based on
parameters provided by the object <code>paramTMoE</code> of class
<a href="#topic+ParamTMoE">ParamTMoE</a>.</p>
</dd>
<dt><code>EStep(paramTMoE)</code></dt><dd><p>Method used in the ECM algorithm to update statistics based on parameters
provided by the object <code>paramTMoE</code> of class <a href="#topic+ParamTMoE">ParamTMoE</a>
(prior and posterior probabilities).</p>
</dd>
<dt><code>MAP()</code></dt><dd><p>MAP calculates values of the fields <code>z_ik</code> and <code>klas</code>
by applying the Maximum A Posteriori Bayes allocation rule.
</p>
<p><code class="reqn">z_{ik} = 1 \ \textrm{if} \ k = \textrm{arg} \ \textrm{max}_{s}
      \ \tau_{is};\ 0 \ \textrm{otherwise}</code></p>
</dd>
</dl>


<h3>See Also</h3>

<p><a href="#topic+ParamTMoE">ParamTMoE</a>
</p>

<hr>
<h2 id='tempanomalies'>Global Annual Temperature Anomalies (Land Meteorological Stations)
(1880-2015)</h2><span id='topic+tempanomalies'></span>

<h3>Description</h3>

<p>This dataset is from <a href="https://cdiac.ess-dive.lbl.gov/ftp/trends/temp/hansen/gl_land.txt">https://cdiac.ess-dive.lbl.gov/ftp/trends/temp/hansen/gl_land.txt</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tempanomalies
</code></pre>


<h3>Format</h3>

<p>A data frame with 136 rows and 3 columns:
</p>

<dl>
<dt>Year</dt><dd><p>Year of observation.</p>
</dd>
<dt>AnnualAnomaly</dt><dd><p>Value in degrees C of the global annual temperature anomaly.</p>
</dd>
<dt>5-YearMean</dt><dd><p>5-Year mean of temperature anomalies.</p>
</dd>
</dl>


<h3>Details</h3>

<p>Global annual temperature anomalies (degrees C) computed using data from
land meteorological stations, 1880-2015.
Anomalies are relative to the 1951-1980 base period means.
</p>
<p>Non-computed values are indicated by &quot;-99.99&quot;.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
