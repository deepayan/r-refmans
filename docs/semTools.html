<!DOCTYPE html><html lang="en"><head><title>Help for package semTools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {semTools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#semTools'><p>semTools: Useful Tools for Structural Equation Modeling</p></a></li>
<li><a href='#auxiliary'><p>Implement Saturated Correlates with FIML</p></a></li>
<li><a href='#AVE'><p>Calculate average variance extracted</p></a></li>
<li><a href='#BootMiss-class'><p>Class For the Results of Bollen-Stine Bootstrap with Incomplete Data</p></a></li>
<li><a href='#bsBootMiss'><p>Bollen-Stine Bootstrap with the Existence of Missing Data</p></a></li>
<li><a href='#calculate.D2-deprecated'><p>Calculate the &quot;D2&quot; statistic</p></a></li>
<li><a href='#chisqSmallN'><p>Small-<em>N</em> correction for <code class="reqn">chi^2</code> test statistic</p></a></li>
<li><a href='#clipboard'><p>Copy or save the result of <code>lavaan</code> or <code>FitDiff</code> objects into a</p>
clipboard or a file</a></li>
<li><a href='#combinequark'><p>Combine the results from the quark function</p></a></li>
<li><a href='#compareFit'><p>Build an object summarizing fit indices across multiple models</p></a></li>
<li><a href='#compRelSEM'><p>Composite Reliability using SEM</p></a></li>
<li><a href='#dat2way'><p>Simulated Dataset to Demonstrate Two-way Latent Interaction</p></a></li>
<li><a href='#dat3way'><p>Simulated Dataset to Demonstrate Three-way Latent Interaction</p></a></li>
<li><a href='#datCat'><p>Simulated Data set to Demonstrate Categorical Measurement Invariance</p></a></li>
<li><a href='#discriminantValidity'><p>Calculate discriminant validity statistics</p></a></li>
<li><a href='#EFA-class'><p>Class For Rotated Results from EFA</p></a></li>
<li><a href='#efa.ekc'><p>Empirical Kaiser criterion</p></a></li>
<li><a href='#efaUnrotate-deprecated'><p>Analyze Unrotated Exploratory Factor Analysis Model</p></a></li>
<li><a href='#exLong'><p>Simulated Data set to Demonstrate Longitudinal Measurement Invariance</p></a></li>
<li><a href='#findRMSEApower'><p>Find the statistical power based on population RMSEA</p></a></li>
<li><a href='#findRMSEApowernested'><p>Find power given a sample size in nested model comparison</p></a></li>
<li><a href='#findRMSEAsamplesize'><p>Find the minimum sample size for a given statistical power based on</p>
population RMSEA</a></li>
<li><a href='#findRMSEAsamplesizenested'><p>Find sample size given a power in nested model comparison</p></a></li>
<li><a href='#FitDiff-class'><p>Class For Representing A Template of Model Fit Comparisons</p></a></li>
<li><a href='#fmi'><p>Fraction of Missing Information.</p></a></li>
<li><a href='#goricaSEM'><p>Wrapper for <code>goric.lavaan()</code> from the <code>restriktor</code> package</p></a></li>
<li><a href='#htmt'><p>Assessing Discriminant Validity using Heterotrait&ndash;Monotrait Ratio</p></a></li>
<li><a href='#imposeStart'><p>Specify starting values from a lavaan output</p></a></li>
<li><a href='#indProd'><p>Make products of indicators using no centering, mean centering, double-mean</p>
centering, or residual centering</a></li>
<li><a href='#kd'><p>Generate data via the Kaiser-Dickman (1962) algorithm.</p></a></li>
<li><a href='#kurtosis'><p>Finding excessive kurtosis</p></a></li>
<li><a href='#lavaan2emmeans'><p><code>emmeans</code> Support Functions for <code>lavaan</code> Models</p></a></li>
<li><a href='#lavTestLRT.mi-deprecated'><p>Likelihood Ratio Test for Multiple Imputations</p></a></li>
<li><a href='#lavTestScore.mi-deprecated'><p>Score Test for Multiple Imputations</p></a></li>
<li><a href='#lavTestWald.mi-deprecated'><p>Wald Test for Multiple Imputations</p></a></li>
<li><a href='#loadingFromAlpha'><p>Find standardized factor loading from coefficient alpha</p></a></li>
<li><a href='#longInvariance-deprecated'><p>Measurement Invariance Tests Within Person</p></a></li>
<li><a href='#lrv2ord'><p>Calculate Population Moments for Ordinal Data Treated as Numeric</p></a></li>
<li><a href='#mardiaKurtosis'><p>Finding Mardia's multivariate kurtosis</p></a></li>
<li><a href='#mardiaSkew'><p>Finding Mardia's multivariate skewness</p></a></li>
<li><a href='#maximalRelia'><p>Calculate maximal reliability</p></a></li>
<li><a href='#measEq.syntax'><p>Syntax for measurement equivalence</p></a></li>
<li><a href='#measEq.syntax-class'><p>Class for Representing a Measurement-Equivalence Model</p></a></li>
<li><a href='#measurementInvariance-deprecated'><p>Measurement Invariance Tests</p></a></li>
<li><a href='#measurementInvarianceCat-deprecated'><p>Measurement Invariance Tests for Categorical Items</p></a></li>
<li><a href='#miPowerFit'><p>Modification indices and their power approach for model fit evaluation</p></a></li>
<li><a href='#modindices.mi-deprecated'><p>Modification Indices for Multiple Imputations</p></a></li>
<li><a href='#monteCarloCI'><p>Monte Carlo Confidence Intervals to Test Functions of Parameter Estimates</p></a></li>
<li><a href='#moreFitIndices'><p>Calculate more fit indices</p></a></li>
<li><a href='#mvrnonnorm'><p>Generate Non-normal Data using Vale and Maurelli (1983) method</p></a></li>
<li><a href='#net'><p>Nesting and Equivalence Testing</p></a></li>
<li><a href='#Net-class'><p>Class For the Result of Nesting and Equivalence Testing</p></a></li>
<li><a href='#nullRMSEA'><p>Calculate the RMSEA of the null model</p></a></li>
<li><a href='#OLDlavaan.mi-class'><p>Class for a lavaan Model Fitted to Multiple Imputations</p></a></li>
<li><a href='#parcelAllocation'><p>Random Allocation of Items to Parcels in a Structural Equation Model</p></a></li>
<li><a href='#partialInvariance'><p>Partial Measurement Invariance Testing Across Groups</p></a></li>
<li><a href='#PAVranking'><p>Parcel-Allocation Variability in Model Ranking</p></a></li>
<li><a href='#permuteMeasEq'><p>Permutation Randomization Tests of Measurement Equivalence and Differential</p>
Item Functioning (DIF)</a></li>
<li><a href='#permuteMeasEq-class'><p>Class for the Results of Permutation Randomization Tests of Measurement</p>
Equivalence and DIF</a></li>
<li><a href='#plausibleValues'><p>Plausible-Values Imputation of Factor Scores Estimated from a lavaan Model</p></a></li>
<li><a href='#plotProbe'><p>Plot a latent interaction</p></a></li>
<li><a href='#plotRMSEAdist'><p>Plot the sampling distributions of RMSEA</p></a></li>
<li><a href='#plotRMSEApower'><p>Plot power curves for RMSEA</p></a></li>
<li><a href='#plotRMSEApowernested'><p>Plot power of nested model RMSEA</p></a></li>
<li><a href='#poolMAlloc'><p>Combine sampling variability with parcel-allocation variability by</p>
pooling results across M parcel-allocations</a></li>
<li><a href='#probe2WayMC'><p>Probing two-way interaction on the no-centered or mean-centered latent</p>
interaction</a></li>
<li><a href='#probe2WayRC'><p>Probing two-way interaction on the residual-centered latent interaction</p></a></li>
<li><a href='#probe3WayMC'><p>Probing three-way interaction on the no-centered or mean-centered latent</p>
interaction</a></li>
<li><a href='#probe3WayRC'><p>Probing three-way interaction on the residual-centered latent interaction</p></a></li>
<li><a href='#quark'><p>Quark</p></a></li>
<li><a href='#reliability-deprecated'><p>Composite Reliability using SEM</p></a></li>
<li><a href='#reliabilityL2-deprecated'><p>Calculate the reliability values of a second-order factor</p></a></li>
<li><a href='#residualCovariate'><p>Residual-center all target indicators by covariates</p></a></li>
<li><a href='#rotate-deprecated'><p>Implement orthogonal or oblique rotation</p></a></li>
<li><a href='#runMI-deprecated'><p>Fit a lavaan Model to Multiple Imputed Data Sets</p></a></li>
<li><a href='#semTools-deprecated'><p>Deprecated functions in package <span class="pkg">semTools</span>.</p></a></li>
<li><a href='#simParcel'><p>Simulated Data set to Demonstrate Random Allocations of Parcels</p></a></li>
<li><a href='#singleParamTest'><p>Single Parameter Test Divided from Nested Model Comparison</p></a></li>
<li><a href='#skew'><p>Finding skewness</p></a></li>
<li><a href='#splitSample'><p>Randomly Split a Data Set into Halves</p></a></li>
<li><a href='#SSpower'><p>Power for model parameters</p></a></li>
<li><a href='#tukeySEM'><p>Tukey's WSD post-hoc test of means for unequal variance and sample size</p></a></li>
<li><a href='#twostage'><p>Fit a lavaan model using 2-Stage Maximum Likelihood (TSML) estimation for</p>
missing data.</a></li>
<li><a href='#twostage-class'><p>Class for the Results of 2-Stage Maximum Likelihood (TSML) Estimation for</p>
Missing Data</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5-7</td>
</tr>
<tr>
<td>Title:</td>
<td>Useful Tools for Structural Equation Modeling</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides miscellaneous tools for structural equation modeling, 
             many of which extend the 'lavaan' package. For example, latent
             interactions can be estimated using product indicators (Lin et al.,
             2010, &lt;<a href="https://doi.org/10.1080%2F10705511.2010.488999">doi:10.1080/10705511.2010.488999</a>&gt;) and simple effects probed;
             analytical power analyses can be conducted (Jak et al., 2021,
             &lt;<a href="https://doi.org/10.3758%2Fs13428-020-01479-0">doi:10.3758/s13428-020-01479-0</a>&gt;); and scale reliability
             can be estimated based on estimated factor-model parameters.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 4.0), lavaan(&ge; 0.6-12), methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, pbivnorm, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Amelia, blavaan, emmeans, lavaan.mi, MASS, mice, mnormt,
parallel, restriktor, testthat, GPArotation</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/simsem/semTools/wiki">https://github.com/simsem/semTools/wiki</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/simsem/semTools/issues">https://github.com/simsem/semTools/issues</a></td>
</tr>
<tr>
<td>Date:</td>
<td>2025-03-12</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-12 21:15:08 UTC; terrence</td>
</tr>
<tr>
<td>Author:</td>
<td>Terrence D. Jorgensen
    <a href="https://orcid.org/0000-0001-5111-6773"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Sunthud Pornprasertmanit [aut],
  Alexander M. Schoemann
    <a href="https://orcid.org/0000-0002-8479-8798"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Yves Rosseel <a href="https://orcid.org/0000-0002-4129-4477"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Patrick Miller [ctb],
  Corbin Quick [ctb],
  Mauricio Garnier-Villarreal
    <a href="https://orcid.org/0000-0002-2951-6647"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  James Selig [ctb],
  Aaron Boulton [ctb],
  Kristopher Preacher [ctb],
  Donna Coffman [ctb],
  Mijke Rhemtulla <a href="https://orcid.org/0000-0003-2572-2424"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Alexander Robitzsch
    <a href="https://orcid.org/0000-0002-8226-3132"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Craig Enders [ctb],
  Ruben Arslan <a href="https://orcid.org/0000-0002-6670-5658"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Bell Clinton [ctb],
  Pavel Panko [ctb],
  Edgar Merkle <a href="https://orcid.org/0000-0001-7158-0653"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Steven Chesnut [ctb],
  Jarrett Byrnes [ctb],
  Jason D. Rights [ctb],
  Ylenio Longo [ctb],
  Maxwell Mansolf <a href="https://orcid.org/0000-0001-6861-8657"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Mattan S. Ben-Shachar
    <a href="https://orcid.org/0000-0002-4287-4801"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Mikko Rönkkö <a href="https://orcid.org/0000-0001-7988-7609"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Andrew R. Johnson <a href="https://orcid.org/0000-0001-7000-8065"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Leonard Vanbrabant [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Terrence D. Jorgensen &lt;TJorgensen314@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-13 08:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='semTools'>semTools: Useful Tools for Structural Equation Modeling</h2><span id='topic+semTools'></span><span id='topic+semTools-package'></span>

<h3>Description</h3>

<p>The <span class="pkg">semTools</span> package provides many miscellaneous functions that are
useful for statistical analysis involving SEM in R.  Many functions extend
the funtionality of the <span class="pkg">lavaan</span> package.  Some sets of functions in
<span class="pkg">semTools</span> correspond to the same theme. We call such a collection of
functions a <em>suite</em>. Our suites include:
</p>

<ul>
<li><p>Model Fit Evaluation:
<code><a href="#topic+moreFitIndices">moreFitIndices()</a></code>,
<code><a href="#topic+nullRMSEA">nullRMSEA()</a></code>,
<code><a href="#topic+singleParamTest">singleParamTest()</a></code>,
<code><a href="#topic+miPowerFit">miPowerFit()</a></code>, and
<code><a href="#topic+chisqSmallN">chisqSmallN()</a></code>
</p>
</li>
<li><p>Measurement Invariance:
<code><a href="#topic+measEq.syntax">measEq.syntax()</a></code>,
<code><a href="#topic+partialInvariance">partialInvariance()</a></code>,
<code><a href="#topic+partialInvarianceCat">partialInvarianceCat()</a></code>, and
<code><a href="#topic+permuteMeasEq">permuteMeasEq()</a></code>
</p>
</li>
<li><p>Power Analysis:
<code><a href="#topic+SSpower">SSpower()</a></code>,
<code><a href="#topic+findRMSEApower">findRMSEApower()</a></code>,
<code><a href="#topic+plotRMSEApower">plotRMSEApower()</a></code>,
<code><a href="#topic+plotRMSEAdist">plotRMSEAdist()</a></code>,
<code><a href="#topic+findRMSEAsamplesize">findRMSEAsamplesize()</a></code>,
<code><a href="#topic+findRMSEApowernested">findRMSEApowernested()</a></code>,
<code><a href="#topic+plotRMSEApowernested">plotRMSEApowernested()</a></code>, and
<code><a href="#topic+findRMSEAsamplesizenested">findRMSEAsamplesizenested()</a></code>
</p>
</li>
<li><p>Missing Data Analysis:
<code><a href="#topic+auxiliary">auxiliary()</a></code>,
<code><a href="#topic+twostage">twostage()</a></code>,
<code><a href="#topic+fmi">fmi()</a></code>,
<code><a href="#topic+bsBootMiss">bsBootMiss()</a></code>,
<code><a href="#topic+quark">quark()</a></code>, and
<code><a href="#topic+combinequark">combinequark()</a></code>
</p>
</li>
<li><p>Latent Interactions:
<code><a href="#topic+indProd">indProd()</a></code>,
<code><a href="#topic+orthogonalize">orthogonalize()</a></code>,
<code><a href="#topic+probe2WayMC">probe2WayMC()</a></code>,
<code><a href="#topic+probe3WayMC">probe3WayMC()</a></code>,
<code><a href="#topic+probe2WayRC">probe2WayRC()</a></code>,
<code><a href="#topic+probe3WayRC">probe3WayRC()</a></code>, and
<code><a href="#topic+plotProbe">plotProbe()</a></code>
</p>
</li>
<li><p>Exploratory Factor Analysis (EFA):
<code><a href="#topic+efa.ekc">efa.ekc()</a></code>
</p>
</li>
<li><p>Reliability Estimation:
<code><a href="#topic+compRelSEM">compRelSEM()</a></code> and
<code><a href="#topic+maximalRelia">maximalRelia()</a></code>
(see also <code><a href="#topic+AVE">AVE()</a></code>)
</p>
</li>
<li><p>Parceling:
<code><a href="#topic+parcelAllocation">parcelAllocation()</a></code>,
<code><a href="#topic+PAVranking">PAVranking()</a></code>, and
<code><a href="#topic+poolMAlloc">poolMAlloc()</a></code>
</p>
</li>
<li><p>Non-Normality:
<code><a href="#topic+skew">skew()</a></code>,
<code><a href="#topic+kurtosis">kurtosis()</a></code>,
<code><a href="#topic+mardiaSkew">mardiaSkew()</a></code>,
<code><a href="#topic+mardiaKurtosis">mardiaKurtosis()</a></code>, and
<code><a href="#topic+mvrnonnorm">mvrnonnorm()</a></code>
</p>
</li></ul>

<p>All users of R (or SEM) are invited to submit functions or ideas for
functions by contacting the maintainer, Terrence Jorgensen
(<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>). Contributors are encouraged to use
<code>Roxygen</code> comments to document their contributed code, which is
consistent with the rest of <span class="pkg">semTools</span>.  Read the vignette from the
<span class="pkg">roxygen2</span> package for details:
<code>vignette("rd", package = "roxygen2")</code>
</p>

<hr>
<h2 id='auxiliary'>Implement Saturated Correlates with FIML</h2><span id='topic+auxiliary'></span><span id='topic+lavaan.auxiliary'></span><span id='topic+cfa.auxiliary'></span><span id='topic+sem.auxiliary'></span><span id='topic+growth.auxiliary'></span>

<h3>Description</h3>

<p>Automatically add auxiliary variables to a lavaan model when using full
information maximum likelihood (FIML) to handle missing data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auxiliary(model, data, aux, fun, ..., envir = getNamespace("lavaan"),
  return.syntax = FALSE)

lavaan.auxiliary(model, data, aux, ..., envir = getNamespace("lavaan"))

cfa.auxiliary(model, data, aux, ..., envir = getNamespace("lavaan"))

sem.auxiliary(model, data, aux, ..., envir = getNamespace("lavaan"))

growth.auxiliary(model, data, aux, ..., envir = getNamespace("lavaan"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="auxiliary_+3A_model">model</code></td>
<td>
<p>The analysis model can be specified with 1 of 2 objects:
</p>

<ol>
<li><p>  lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> specifying a hypothesized
model <em>without</em> mention of auxiliary variables in <code>aux</code>
</p>
</li>
<li><p>  a parameter table, as returned by <code><a href="lavaan.html#topic+parTable">lavaan::parTable()</a></code>,
specifying the target model <em>without</em> auxiliary variables.
This option requires these columns (and silently ignores all others):
<code>c("lhs","op","rhs","user","group","free","label","plabel","start")</code>
</p>
</li></ol>
</td></tr>
<tr><td><code id="auxiliary_+3A_data">data</code></td>
<td>
<p><code>data.frame</code> that includes auxiliary variables as well as
any observed variables in the <code>model</code></p>
</td></tr>
<tr><td><code id="auxiliary_+3A_aux">aux</code></td>
<td>
<p><code>character</code>. Names of auxiliary variables to add to <code>model</code></p>
</td></tr>
<tr><td><code id="auxiliary_+3A_fun">fun</code></td>
<td>
<p><code>character</code>. Name of a specific lavaan function used to fit
<code>model</code> to <code>data</code> (i.e., <code>"lavaan"</code>, <code>"cfa"</code>,
<code>"sem"</code>, or <code>"growth"</code>). Only required for <code>auxiliary</code>.</p>
</td></tr>
<tr><td><code id="auxiliary_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code style="white-space: pre;">&#8288;fun=&#8288;</code>.</p>
</td></tr>
<tr><td><code id="auxiliary_+3A_envir">envir</code></td>
<td>
<p>Passed to <code><a href="base.html#topic+do.call">do.call()</a></code>.</p>
</td></tr>
<tr><td><code id="auxiliary_+3A_return.syntax">return.syntax</code></td>
<td>
<p><code>logical</code> indicating whether to return a
<code>character</code> string of <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> that can be
added to a target <code style="white-space: pre;">&#8288;model=&#8288;</code> that is also a <code>character</code> string.
This can be advantageous, for example, to use add saturated correlates to
a <span class="pkg">blavaan</span> model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are wrappers around the corresponding lavaan functions.
You can use them the same way you use <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>, but you
<em>must</em> pass your full <code>data.frame</code> to the <code>data</code> argument.
Because the saturated-correlates approaches (Enders, 2008) treats exogenous
variables as random, <code>fixed.x</code> must be set to <code>FALSE</code>. Because FIML
requires continuous data (although nonnormality corrections can still be
requested), no variables in the model nor auxiliary variables specified in
<code>aux</code> can be declared as <code>ordered</code>.
</p>


<h3>Value</h3>

<p>a fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> object.  Additional
information is stored as a <code>list</code> in the <code style="white-space: pre;">&#8288;@external&#8288;</code> slot:
</p>

<ul>
<li> <p><code>baseline.model</code>. a fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>
object. Results of fitting an appropriate independence model for
the calculation of incremental fit indices (e.g., CFI, TLI) in
which the auxiliary variables remain saturated, so only the target
variables are constrained to be orthogonal. See Examples for how
to send this baseline model to <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code>.
</p>
</li>
<li> <p><code>aux</code>. The character vector of auxiliary variable names.
</p>
</li>
<li> <p><code>baseline.syntax</code>. A character vector generated within the
<code>auxiliary</code> function, specifying the <code>baseline.model</code>
syntax.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Enders, C. K. (2008). A note on the use of missing auxiliary variables in
full information maximum likelihood-based structural equation models.
<em>Structural Equation Modeling, 15</em>(3), 434&ndash;448.
<a href="https://doi.org/10.1080/10705510802154307">doi:10.1080/10705510802154307</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat1 &lt;- lavaan::HolzingerSwineford1939
set.seed(12345)
dat1$z &lt;- rnorm(nrow(dat1))
dat1$x5 &lt;- ifelse(dat1$z &lt; quantile(dat1$z, .3), NA, dat1$x5)
dat1$x9 &lt;- ifelse(dat1$z &gt; quantile(dat1$z, .8), NA, dat1$x9)

targetModel &lt;- "
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9
"

## works just like cfa(), but with an extra "aux" argument
fitaux1 &lt;- cfa.auxiliary(targetModel, data = dat1, aux = "z",
                         missing = "fiml", estimator = "mlr")

## with multiple auxiliary variables and multiple groups
fitaux2 &lt;- cfa.auxiliary(targetModel, data = dat1, aux = c("z","ageyr","grade"),
                         group = "school", group.equal = "loadings")

## calculate correct incremental fit indices (e.g., CFI, TLI)
fitMeasures(fitaux2, fit.measures = c("cfi","tli"))
## NOTE: lavaan will use the internally stored baseline model, which
##       is the independence model plus saturated auxiliary parameters
lavInspect(fitaux2@external$baseline.model, "free")


</code></pre>

<hr>
<h2 id='AVE'>Calculate average variance extracted</h2><span id='topic+AVE'></span>

<h3>Description</h3>

<p>Calculate average variance extracted (AVE) per factor from <code>lavaan</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AVE(object, obs.var = TRUE, omit.imps = c("no.conv", "no.se"),
  omit.factors = character(0), dropSingle = TRUE, return.df = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AVE_+3A_object">object</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object,
expected to contain only exogenous common factors (i.e., a CFA model).
Cross-loadings are not allowed and will result in <code>NA</code> for any factor with
indicator(s) that cross-load.</p>
</td></tr>
<tr><td><code id="AVE_+3A_obs.var">obs.var</code></td>
<td>
<p><code>logical</code> indicating whether to compute AVE using
observed variances in the denominator. Setting <code>FALSE</code> triggers
using model-implied variances in the denominator.</p>
</td></tr>
<tr><td><code id="AVE_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
<tr><td><code id="AVE_+3A_omit.factors">omit.factors</code></td>
<td>
<p><code>character</code> vector naming any common factors
modeled in <code>object</code> whose indicators' AVE is not of interest.</p>
</td></tr>
<tr><td><code id="AVE_+3A_dropsingle">dropSingle</code></td>
<td>
<p><code>logical</code> indicating whether to exclude factors
defined by a single indicator from the returned results. If <code>TRUE</code>
(default), single indicators will still be included in the <code>total</code>
column when <code>return.total = TRUE</code>.</p>
</td></tr>
<tr><td><code id="AVE_+3A_return.df">return.df</code></td>
<td>
<p><code>logical</code> indicating whether to return reliability
coefficients in a <code>data.frame</code> (one row per group/level), which is
possible when every model block includes the same factors (after excluding
those in <code>omit.factors</code> and applying <code>dropSingle</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The average variance extracted (AVE) can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> AVE = \frac{\bold{1}^\prime
\textrm{diag}\left(\Lambda\Psi\Lambda^\prime\right)\bold{1}}{\bold{1}^\prime
\textrm{diag}\left(\hat{\Sigma}\right) \bold{1}}, </code>
</p>

<p>Note that this formula is modified from Fornell &amp; Larcker (1981) in the case
that factor variances are not 1. The proposed formula from Fornell &amp; Larcker
(1981) assumes that the factor variances are 1. Note that AVE will not be
provided for factors consisting of items with dual loadings. AVE is the
property of items but not the property of factors. AVE is calculated with
polychoric correlations when ordinal indicators are used.
</p>


<h3>Value</h3>

<p><code>numeric</code> vector of average variance extracted from indicators
per factor.  For models with multiple &quot;blocks&quot; (any combination of groups
and levels), vectors may be returned as columns in a <code>data.frame</code>
with additional columns indicating the group/level (see <code style="white-space: pre;">&#8288;return.df=&#8288;</code>
argument description for caveat).
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Fornell, C., &amp; Larcker, D. F. (1981). Evaluating structural equation models
with unobservable variables and measurement errors. <em>Journal of
Marketing Research, 18</em>(1), 39&ndash;50. <a href="https://doi.org/10.2307/3151312">doi:10.2307/3151312</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compRelSEM">compRelSEM()</a></code> for composite reliability estimates
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HolzingerSwineford1939)
HS9 &lt;- HolzingerSwineford1939[ , c("x7","x8","x9")]
HSbinary &lt;- as.data.frame( lapply(HS9, cut, 2, labels=FALSE) )
names(HSbinary) &lt;- c("y7","y8","y9")
HS &lt;- cbind(HolzingerSwineford1939, HSbinary)

HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ y7 + y8 + y9 '

fit &lt;- cfa(HS.model, data = HS, ordered = c("y7","y8","y9"), std.lv = TRUE)

## works for factors with exclusively continuous OR categorical indicators
AVE(fit) # uses observed (or unconstrained polychoric/polyserial) by default
AVE(fit, obs.var = FALSE)


## works for multigroup models and for multilevel models (and both)
data(Demo.twolevel)
## assign clusters to arbitrary groups
Demo.twolevel$g &lt;- ifelse(Demo.twolevel$cluster %% 2L, "type1", "type2")
model2 &lt;- ' group: type1
  level: within
    fac =~ y1 + L2*y2 + L3*y3
  level: between
    fac =~ y1 + L2*y2 + L3*y3

group: type2
  level: within
    fac =~ y1 + L2*y2 + L3*y3
  level: between
    fac =~ y1 + L2*y2 + L3*y3
'
fit2 &lt;- sem(model2, data = Demo.twolevel, cluster = "cluster", group = "g")
AVE(fit2)

</code></pre>

<hr>
<h2 id='BootMiss-class'>Class For the Results of Bollen-Stine Bootstrap with Incomplete Data</h2><span id='topic+BootMiss-class'></span><span id='topic+show+2CBootMiss-method'></span><span id='topic+summary+2CBootMiss-method'></span><span id='topic+hist+2CBootMiss-method'></span>

<h3>Description</h3>

<p>This class contains the results of Bollen-Stine bootstrap with missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'BootMiss'
show(object)

## S4 method for signature 'BootMiss'
summary(object)

## S4 method for signature 'BootMiss'
hist(x, ..., alpha = 0.05, nd = 2,
  printLegend = TRUE, legendArgs = list(x = "topleft"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="BootMiss-class_+3A_object">object</code>, <code id="BootMiss-class_+3A_x">x</code></td>
<td>
<p>object of class <code>BootMiss</code></p>
</td></tr>
<tr><td><code id="BootMiss-class_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="graphics.html#topic+hist">graphics::hist()</a></code></p>
</td></tr>
<tr><td><code id="BootMiss-class_+3A_alpha">alpha</code></td>
<td>
<p>alpha level used to draw confidence limits</p>
</td></tr>
<tr><td><code id="BootMiss-class_+3A_nd">nd</code></td>
<td>
<p>number of digits to display</p>
</td></tr>
<tr><td><code id="BootMiss-class_+3A_printlegend">printLegend</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (default), a legend will
be printed with the histogram</p>
</td></tr>
<tr><td><code id="BootMiss-class_+3A_legendargs">legendArgs</code></td>
<td>
<p><code>list</code> of arguments passed to the
<code><a href="graphics.html#topic+legend">graphics::legend()</a></code> function.  The default argument is a list
placing the legend at the top-left of the figure.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>hist</code> method returns a list of <code>length == 2</code>,
containing the arguments for the call to <code>hist</code> and the arguments
to the call for <code>legend</code>, respectively.
</p>


<h3>Slots</h3>


<dl>
<dt><code>time</code></dt><dd><p>A list containing 2 <code>difftime</code> objects (<code>transform</code>
and <code>fit</code>), indicating the time elapsed for data transformation and
for fitting the model to bootstrap data sets, respectively.</p>
</dd>
<dt><code>transData</code></dt><dd><p>Transformed data</p>
</dd>
<dt><code>bootDist</code></dt><dd><p>The vector of <code class="reqn">chi^2</code> values from bootstrap data sets
fitted by the target model</p>
</dd>
<dt><code>origChi</code></dt><dd><p>The <code class="reqn">chi^2</code> value from the original data set</p>
</dd>
<dt><code>df</code></dt><dd><p>The degree of freedom of the model</p>
</dd>
<dt><code>bootP</code></dt><dd><p>The <em>p</em> value comparing the original <code class="reqn">chi^2</code> with the
bootstrap distribution</p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>Objects can be created via the
<code><a href="#topic+bsBootMiss">bsBootMiss()</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bsBootMiss">bsBootMiss()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See the example from the bsBootMiss function

</code></pre>

<hr>
<h2 id='bsBootMiss'>Bollen-Stine Bootstrap with the Existence of Missing Data</h2><span id='topic+bsBootMiss'></span>

<h3>Description</h3>

<p>Implement the Bollen and Stine's (1992) Bootstrap when missing observations
exist. The implemented method is proposed by Savalei and Yuan (2009). This
can be used in two ways. The first and easiest option is to fit the model to
incomplete data in <code>lavaan</code> using the FIML estimator, then pass that
<code>lavaan</code> object to <code>bsBootMiss</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bsBootMiss(x, transformation = 2, nBoot = 500, model, rawData, Sigma, Mu,
  group, ChiSquared, EMcov, writeTransData = FALSE, transDataOnly = FALSE,
  writeBootData = FALSE, bootSamplesOnly = FALSE, writeArgs, seed = NULL,
  suppressWarn = TRUE, showProgress = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bsBootMiss_+3A_x">x</code></td>
<td>
<p>A target <code>lavaan</code> object used in the Bollen-Stine bootstrap</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_transformation">transformation</code></td>
<td>
<p>The transformation methods in Savalei and Yuan (2009).
There are three methods in the article, but only the first two are currently
implemented here.  Use <code>transformation = 1</code> when there are few missing
data patterns, each of which has a large size, such as in a
planned-missing-data design.  Use <code>transformation = 2</code> when there are
more missing data patterns. The currently unavailable
<code>transformation = 3</code> would be used when several missing data patterns
have n = 1.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_nboot">nBoot</code></td>
<td>
<p>The number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_model">model</code></td>
<td>
<p>Optional. The target model if <code>x</code> is not provided.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_rawdata">rawData</code></td>
<td>
<p>Optional. The target raw data set if <code>x</code> is not
provided.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_sigma">Sigma</code></td>
<td>
<p>Optional. The model-implied covariance matrix if <code>x</code> is
not provided.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_mu">Mu</code></td>
<td>
<p>Optional. The model-implied mean vector if <code>x</code> is not
provided.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_group">group</code></td>
<td>
<p>Optional character string specifying the name of the grouping
variable in <code>rawData</code> if <code>x</code> is not provided.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_chisquared">ChiSquared</code></td>
<td>
<p>Optional. The model's <code class="reqn">\chi^2</code> test statistic if
<code>x</code> is not provided.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_emcov">EMcov</code></td>
<td>
<p>Optional, if <code>x</code> is not provided. The EM (or Two-Stage ML)
estimated covariance matrix used to speed up Transformation 2 algorithm.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_writetransdata">writeTransData</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the transformed data set is
written to a text file, <code>transDataOnly</code> is set to <code>TRUE</code>, and the
transformed data is returned invisibly.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_transdataonly">transDataOnly</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the result will provide the
transformed data only.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_writebootdata">writeBootData</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the stacked bootstrap data
sets are written to a text file, <code>bootSamplesOnly</code> is set to
<code>TRUE</code>, and the list of bootstrap data sets are returned invisibly.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_bootsamplesonly">bootSamplesOnly</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the result will provide
bootstrap data sets only.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_writeargs">writeArgs</code></td>
<td>
<p>Optional <code>list</code>. If <code>writeBootData = TRUE</code> or
<code>writeBootData = TRUE</code>, user can pass arguments to the
<code><a href="utils.html#topic+write.table">utils::write.table()</a></code> function as a list.  Some default values
are provided: <code>file</code> = &quot;bootstrappedSamples.dat&quot;, <code>row.names</code> =
<code>FALSE</code>, and <code>na</code> = &quot;-999&quot;, but the user can override all of these
by providing other values for those arguments in the <code>writeArgs</code> list.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_seed">seed</code></td>
<td>
<p>The seed number used in randomly drawing bootstrap samples.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_suppresswarn">suppressWarn</code></td>
<td>
<p>Logical. If <code>TRUE</code>, warnings from <code>lavaan</code>
function will be suppressed when fitting the model to each bootstrap sample.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_showprogress">showProgress</code></td>
<td>
<p>Logical. Indicating whether to display a progress bar
while fitting models to bootstrap samples.</p>
</td></tr>
<tr><td><code id="bsBootMiss_+3A_...">...</code></td>
<td>
<p>The additional arguments in the <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>
function. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The second is designed for users of other software packages (e.g., LISREL,
EQS, Amos, or Mplus). Users can import their data, <code class="reqn">\chi^2</code> value, and
model-implied moments from another package, and they have the option of
saving (or writing to a file) either the transformed data or bootstrapped
samples of that data, which can be analyzed in other programs. In order to
analyze the bootstrapped samples and return a <em>p</em> value, users of other
programs must still specify their model using lavaan syntax.
</p>


<h3>Value</h3>

<p>As a default, this function returns a <a href="#topic+BootMiss-class">BootMiss</a>
object containing the results of the bootstrap samples. Use <code>show</code>,
<code>summary</code>, or <code>hist</code> to examine the results. Optionally, the
transformed data set is returned if <code>transDataOnly = TRUE</code>. Optionally,
the bootstrap data sets are returned if <code>bootSamplesOnly = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Syntax for transformations borrowed from http://www2.psych.ubc.ca/~vsavalei/
</p>


<h3>References</h3>

<p>Bollen, K. A., &amp; Stine, R. A. (1992). Bootstrapping goodness-of-fit measures
in structural equation models. <em>Sociological Methods &amp;
Research, 21</em>(2), 205&ndash;229. <a href="https://doi.org/10.1177/0049124192021002004">doi:10.1177/0049124192021002004</a>
</p>
<p>Savalei, V., &amp; Yuan, K.-H. (2009). On the model-based bootstrap with missing
data: Obtaining a p-value for a test of exact fit. <em>Multivariate
Behavioral Research, 44</em>(6), 741&ndash;763. <a href="https://doi.org/10.1080/00273170903333590">doi:10.1080/00273170903333590</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+BootMiss-class">BootMiss</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat1 &lt;- HolzingerSwineford1939
dat1$x5 &lt;- ifelse(dat1$x1 &lt;= quantile(dat1$x1, .3), NA, dat1$x5)
dat1$x9 &lt;- ifelse(is.na(dat1$x5), NA, dat1$x9)

targetModel &lt;- "
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9
"
targetFit &lt;- sem(targetModel, dat1, meanstructure = TRUE, std.lv = TRUE,
                 missing = "fiml", group = "school")
summary(targetFit, fit = TRUE, standardized = TRUE)


## The number of bootstrap samples should be much higher than this example
temp &lt;- bsBootMiss(targetFit, transformation = 1, nBoot = 10, seed = 31415)

temp
summary(temp)
hist(temp)
hist(temp, printLegend = FALSE) # suppress the legend
## user can specify alpha level (default: alpha = 0.05), and the number of
## digits to display (default: nd = 2).  Pass other arguments to hist(...),
## or a list of arguments to legend() via "legendArgs"
hist(temp, alpha = .01, nd = 3, xlab = "something else", breaks = 25,
     legendArgs = list("bottomleft", box.lty = 2))


</code></pre>

<hr>
<h2 id='calculate.D2-deprecated'>Calculate the &quot;D2&quot; statistic</h2><span id='topic+calculate.D2-deprecated'></span>

<h3>Description</h3>

<p>This is a utility function used to calculate the &quot;D2&quot; statistic for pooling
test statistics across multiple imputations. This function is called by
several functions used for <a href="#topic+OLDlavaan.mi-class">OLDlavaan.mi</a> objects, such as
<code><a href="#topic+lavTestLRT.mi">lavTestLRT.mi()</a></code>, <code><a href="#topic+lavTestWald.mi">lavTestWald.mi()</a></code>, and
<code><a href="#topic+lavTestScore.mi">lavTestScore.mi()</a></code>. But this function can be used for any general
scenario because it only requires a vector of <code class="reqn">\chi^2</code> statistics (one
from each imputation) and the degrees of freedom for the test statistic.
See Li, Meng, Raghunathan, &amp; Rubin (1991) and Enders (2010, chapter 8) for
details about how it is calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate.D2(w, DF = 0L, asymptotic = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate.D2-deprecated_+3A_w">w</code></td>
<td>
<p><code>numeric</code> vector of Wald <code class="reqn">\chi^2</code> statistics. Can also
be Wald <em>z</em> statistics, which will be internally squared to make
<code class="reqn">\chi^2</code> statistics with one <em>df</em> (must set <code>DF = 0L</code>).</p>
</td></tr>
<tr><td><code id="calculate.D2-deprecated_+3A_df">DF</code></td>
<td>
<p>degrees of freedom (<em>df</em>) of the <code class="reqn">\chi^2</code> statistics.
If <code>DF = 0L</code> (default), <code>w</code> is assumed to contain <em>z</em>
statistics, which will be internally squared.</p>
</td></tr>
<tr><td><code id="calculate.D2-deprecated_+3A_asymptotic">asymptotic</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code> (default), the pooled test
will be returned as an <em>F</em>-distributed statistic with numerator
(<code>df1</code>) and denominator (<code>df2</code>) degrees of freedom.
If <code>TRUE</code>, the pooled <em>F</em> statistic will be multiplied by its
<code>df1</code> on the assumption that its <code>df2</code> is sufficiently large
enough that the statistic will be asymptotically <code class="reqn">\chi^2</code> distributed
with <code>df1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>numeric</code> vector containing the test statistic, <em>df</em>,
its <em>p</em> value, and 2 missing-data diagnostics: the relative invrease
in variance (RIV, or average for multiparameter tests: ARIV) and the
fraction missing information (FMI = ARIV / (1 + ARIV)).
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. New
York, NY: Guilford.
</p>
<p>Li, K.-H., Meng, X.-L., Raghunathan, T. E., &amp; Rubin, D. B. (1991).
Significance levels from repeated <em>p</em>-values with multiply-imputed
data. <em>Statistica Sinica, 1</em>(1), 65&ndash;92. Retrieved from
<a href="https://www.jstor.org/stable/24303994">https://www.jstor.org/stable/24303994</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lavTestLRT.mi">lavTestLRT.mi()</a></code>, <code><a href="#topic+lavTestWald.mi">lavTestWald.mi()</a></code>, <code><a href="#topic+lavTestScore.mi">lavTestScore.mi()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## generate a vector of chi-squared values, just for example
DF &lt;- 3 # degrees of freedom
M &lt;- 20 # number of imputations
CHI &lt;- rchisq(M, DF)

## pool the "results"
calculate.D2(CHI, DF) # by default, an F statistic is returned
calculate.D2(CHI, DF, asymptotic = TRUE) # asymptotically chi-squared

## generate standard-normal values, for an example of Wald z tests
Z &lt;- rnorm(M)
calculate.D2(Z) # default DF = 0 will square Z to make chisq(DF = 1)
## F test is equivalent to a t test with the denominator DF

</code></pre>

<hr>
<h2 id='chisqSmallN'>Small-<em>N</em> correction for <code class="reqn">chi^2</code> test statistic</h2><span id='topic+chisqSmallN'></span>

<h3>Description</h3>

<p>Calculate small-<em>N</em> corrections for <code class="reqn">chi^2</code> model-fit test
statistic to adjust for small sample size (relative to model size).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisqSmallN(fit0, fit1 = NULL, smallN.method = if (is.null(fit1))
  c("swain", "yuan.2015") else "yuan.2005", ..., omit.imps = c("no.conv",
  "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chisqSmallN_+3A_fit0">fit0</code>, <code id="chisqSmallN_+3A_fit1">fit1</code></td>
<td>
<p><a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object(s)</p>
</td></tr>
<tr><td><code id="chisqSmallN_+3A_smalln.method">smallN.method</code></td>
<td>
<p><code>character</code> indicating the small-<em>N</em>
correction method to use. Multiple may be chosen (all of which assume
normality), as described in Shi et al. (2018):
<code>c("swain","yuan.2015","yuan.2005","bartlett")</code>. Users may also
simply select <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="chisqSmallN_+3A_...">...</code></td>
<td>
<p>Additional arguments to the <code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code> or
<code><a href="lavaan.mi.html#topic+lavTestLRT.mi">lavaan.mi::lavTestLRT.mi()</a></code> functions. Ignored when <code>is.null(fit1)</code>.</p>
</td></tr>
<tr><td><code id="chisqSmallN_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results. Ignored unless <code>fit0</code> (and
optionally <code>fit1</code>) is a <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object. See
<code><a href="lavaan.mi.html#topic+lavTestLRT.mi">lavaan.mi::lavTestLRT.mi()</a></code> for a description of options and defaults.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Four finite-sample adjustments to the chi-squared statistic are currently
available, all of which are described in Shi et al. (2018). These all
assume normally distributed data, and may not work well with severely
nonnormal data. Deng et al. (2018, section 4) review proposed small-<em>N</em>
adjustments that do not assume normality, which rarely show promise, so
they are not implemented here. This function currently will apply
small-<em>N</em> adjustments to scaled test statistics with a warning that
they do not perform well (Deng et al., 2018).
</p>


<h3>Value</h3>

<p>A <code>list</code> of <code>numeric</code> vectors: one for the originally
requested statistic(s), along with one per requested <code>smallN.method</code>.
All include the the (un)adjusted test statistic, its <em>df</em>, and the
<em>p</em> value for the test under the null hypothesis that the model fits
perfectly (or that the 2 models have equivalent fit).
The adjusted chi-squared statistic(s) also include(s) the scaling factor
for the small-<em>N</em> adjustment.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Deng, L., Yang, M., &amp; Marcoulides, K. M. (2018). Structural equation
modeling with many variables: A systematic review of issues and
developments. <em>Frontiers in Psychology, 9</em>, 580.
<a href="https://doi.org/10.3389/fpsyg.2018.00580">doi:10.3389/fpsyg.2018.00580</a>
</p>
<p>Shi, D., Lee, T., &amp; Terry, R. A. (2018). Revisiting the model
size effect in structural equation modeling.
<em>Structural Equation Modeling, 25</em>(1), 21&ndash;40.
<a href="https://doi.org/10.1080/10705511.2017.1369088">doi:10.1080/10705511.2017.1369088</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HS.model &lt;- '
    visual  =~ x1 + b1*x2 + x3
    textual =~ x4 + b2*x5 + x6
    speed   =~ x7 + b3*x8 + x9
'
fit1 &lt;- cfa(HS.model, data = HolzingerSwineford1939[1:50,])
## test a single model (implicitly compared to a saturated model)
chisqSmallN(fit1)

## fit a more constrained model
fit0 &lt;- cfa(HS.model, data = HolzingerSwineford1939[1:50,],
            orthogonal = TRUE)
## compare 2 models
chisqSmallN(fit1, fit0)

</code></pre>

<hr>
<h2 id='clipboard'>Copy or save the result of <code>lavaan</code> or <code>FitDiff</code> objects into a
clipboard or a file</h2><span id='topic+clipboard'></span><span id='topic+saveFile'></span>

<h3>Description</h3>

<p>Copy or save the result of <code>lavaan</code> or <a href="#topic+FitDiff-class">FitDiff</a>
object into a clipboard or a file. From the clipboard, users may paste the
result into the Microsoft Excel or spreadsheet application to create a table
of the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clipboard(object, what = "summary", ...)

saveFile(object, file, what = "summary", tableFormat = FALSE,
  fit.measures = "default", writeArgs = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clipboard_+3A_object">object</code></td>
<td>
<p>An object of class <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or
<a href="#topic+FitDiff-class">FitDiff</a>.</p>
</td></tr>
<tr><td><code id="clipboard_+3A_what">what</code></td>
<td>
<p>The attributes of the <code>lavaan</code> object to be copied in the
clipboard. <code>"summary"</code> is to copy the screen provided from the
<code>summary</code> function. <code>"mifit"</code> is to copy the result from the
<code><a href="#topic+miPowerFit">miPowerFit()</a></code> function. Other attributes listed in the
<code>inspect</code> method in the <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> could also be
used, such as <code>"coef"</code>, <code>"se"</code>, <code>"fit"</code>, <code>"samp"</code>, and
so on.  Ignored for <a href="#topic+FitDiff-class">FitDiff</a>-class objects.</p>
</td></tr>
<tr><td><code id="clipboard_+3A_...">...</code></td>
<td>
<p>Additional arguments when passing a <code>lavaan</code> object to the
<code>summary</code> or <code><a href="#topic+miPowerFit">miPowerFit()</a></code> function.</p>
</td></tr>
<tr><td><code id="clipboard_+3A_file">file</code></td>
<td>
<p>A file name used for saving the result.</p>
</td></tr>
<tr><td><code id="clipboard_+3A_tableformat">tableFormat</code></td>
<td>
<p>If <code>TRUE</code>, save the result in the table format using
tabs for separation. Otherwise, save the result as the output screen
printed in the R console.</p>
</td></tr>
<tr><td><code id="clipboard_+3A_fit.measures">fit.measures</code></td>
<td>
<p><code>character</code> vector specifying names of fit measures
returned by <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> to be copied/saved.  Only
relevant if <code>object</code> is class <a href="#topic+FitDiff-class">FitDiff</a>.</p>
</td></tr>
<tr><td><code id="clipboard_+3A_writeargs">writeArgs</code></td>
<td>
<p><code>list</code> of additional arguments to be passed to
<code><a href="utils.html#topic+write.table">utils::write.table()</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The resulting output will be saved into a clipboard or a file. If
using the <code>clipboard</code> function, users may paste it in the other
applications.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)
HW.model &lt;- ' visual  =~ x1 + c1*x2 + x3
              textual =~ x4 + c1*x5 + x6
              speed   =~ x7 +    x8 + x9 '

fit &lt;- cfa(HW.model, data = HolzingerSwineford1939, group = "school")

if(interactive()){
# Copy the summary of the lavaan object
clipboard(fit)

# pass additional arguments to summary() method for class?lavaan
clipboard(fit, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)

# Copy modification indices and fit stats from the miPowerFit() function
clipboard(fit, "mifit")

# Copy the parameter estimates
clipboard(fit, "coef")

# Copy the standard errors
clipboard(fit, "se")

# Copy the sample statistics
clipboard(fit, "samp")

# Copy the fit measures
clipboard(fit, "fit")

# Save the summary of the lavaan object
saveFile(fit, "out.txt")

# Save modification indices and fit stats from the miPowerFit() function
saveFile(fit, "out.txt", "mifit")

# Save the parameter estimates
saveFile(fit, "out.txt", "coef")

# Save the standard errors
saveFile(fit, "out.txt", "se")

# Save the sample statistics
saveFile(fit, "out.txt", "samp")

# Save the fit measures
saveFile(fit, "out.txt", "fit")
}

</code></pre>

<hr>
<h2 id='combinequark'>Combine the results from the quark function</h2><span id='topic+combinequark'></span>

<h3>Description</h3>

<p>This function builds upon the <code><a href="#topic+quark">quark()</a></code> function to provide a
final dataset comprised of the original dataset provided to
<code><a href="#topic+quark">quark()</a></code> and enough principal components to be able to account
for a certain level of variance in the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>combinequark(quark, percent)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="combinequark_+3A_quark">quark</code></td>
<td>
<p>Provide the <code><a href="#topic+quark">quark()</a></code> object that was returned.  It
should be a list of objects.  Make sure to include it in its entirety.</p>
</td></tr>
<tr><td><code id="combinequark_+3A_percent">percent</code></td>
<td>
<p>Provide a percentage of variance that you would like to have
explained.  That many components (columns) will be extracted and kept with
the output dataset.  Enter this variable as a number WITHOUT a percentage
sign.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The output of this function is the original dataset used in quark
combined with enough principal component scores to be able to account for
the amount of variance that was requested.
</p>


<h3>Author(s)</h3>

<p>Steven R. Chesnut (University of Southern Mississippi
<a href="mailto:Steven.Chesnut@usm.edu">Steven.Chesnut@usm.edu</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+quark">quark()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123321)
dat &lt;- HolzingerSwineford1939[,7:15]
misspat &lt;- matrix(runif(nrow(dat) * 9) &lt; 0.3, nrow(dat))
dat[misspat] &lt;- NA
dat &lt;- cbind(HolzingerSwineford1939[,1:3], dat)

quark.list &lt;- quark(data = dat, id = c(1, 2))

final.data &lt;- combinequark(quark = quark.list, percent = 80)

</code></pre>

<hr>
<h2 id='compareFit'>Build an object summarizing fit indices across multiple models</h2><span id='topic+compareFit'></span>

<h3>Description</h3>

<p>This function will create the template to compare fit indices across
multiple fitted lavaan objects. The results can be exported to a clipboard
or a file later.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compareFit(..., nested = TRUE, argsLRT = list(), indices = TRUE,
  moreIndices = FALSE, baseline.model = NULL, nPrior = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compareFit_+3A_...">...</code></td>
<td>
<p>fitted <code>lavaan</code> models or list(s) of <code>lavaan</code> objects.
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> objects are also accepted, but all models
must belong to the same class.</p>
</td></tr>
<tr><td><code id="compareFit_+3A_nested">nested</code></td>
<td>
<p><code>logical</code> indicating whether the models in <code>...</code> are
nested. See <code><a href="#topic+net">net()</a></code> for an empirical test of nesting.</p>
</td></tr>
<tr><td><code id="compareFit_+3A_argslrt">argsLRT</code></td>
<td>
<p><code>list</code> of arguments to pass to
<code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code>, as well as to
<code><a href="lavaan.mi.html#topic+lavTestLRT.mi">lavaan.mi::lavTestLRT.mi()</a></code> and <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> when
comparing <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> models.</p>
</td></tr>
<tr><td><code id="compareFit_+3A_indices">indices</code></td>
<td>
<p><code>logical</code> indicating whether to return fit indices from
the <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> function. Selecting particular
indices is controlled in the <code>summary</code> method; see
<a href="#topic+FitDiff-class">FitDiff</a>.</p>
</td></tr>
<tr><td><code id="compareFit_+3A_moreindices">moreIndices</code></td>
<td>
<p><code>logical</code> indicating whether to return fit indices
from the <code><a href="#topic+moreFitIndices">moreFitIndices()</a></code> function. Selecting particular
indices is controlled in the <code>summary</code> method; see
<a href="#topic+FitDiff-class">FitDiff</a>.</p>
</td></tr>
<tr><td><code id="compareFit_+3A_baseline.model">baseline.model</code></td>
<td>
<p>optional fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> model passed to
<code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> to calculate incremental fit indices.</p>
</td></tr>
<tr><td><code id="compareFit_+3A_nprior">nPrior</code></td>
<td>
<p>passed to <code><a href="#topic+moreFitIndices">moreFitIndices()</a></code>, if relevant</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="#topic+FitDiff-class">FitDiff</a> object that saves model fit
comparisons across multiple models. If the models are not nested, only
fit indices for each model are returned. If the models are nested, the
differences in fit indices are additionally returned, as well as test
statistics comparing each sequential pair of models (ordered by their
degrees of freedom).
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><a href="#topic+FitDiff-class">FitDiff</a>, <code><a href="#topic+clipboard">clipboard()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

## non-nested models
fit1 &lt;- cfa(HS.model, data = HolzingerSwineford1939)

m2 &lt;- ' f1 =~ x1 + x2 + x3 + x4
        f2 =~ x5 + x6 + x7 + x8 + x9 '
fit2 &lt;- cfa(m2, data = HolzingerSwineford1939)

(out1 &lt;- compareFit(fit1, fit2, nested = FALSE))
summary(out1)


## nested model comparisons: measurement equivalence/invariance
fit.config &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school")
fit.metric &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
                  group.equal = "loadings")
fit.scalar &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
                  group.equal = c("loadings","intercepts"))
fit.strict &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
                  group.equal = c("loadings","intercepts","residuals"))

measEqOut &lt;- compareFit(fit.config, fit.metric, fit.scalar, fit.strict,
                        moreIndices = TRUE) # include moreFitIndices()
summary(measEqOut)
summary(measEqOut, fit.measures = "all")
summary(measEqOut, fit.measures = c("aic", "bic", "sic", "ibic"))



</code></pre>

<hr>
<h2 id='compRelSEM'>Composite Reliability using SEM</h2><span id='topic+compRelSEM'></span>

<h3>Description</h3>

<p>Calculate composite reliability from estimated factor-model parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compRelSEM(object, obs.var = TRUE, tau.eq = FALSE, ord.scale = TRUE,
  config = character(0), shared = character(0), higher = character(0),
  return.total = FALSE, dropSingle = TRUE, omit.factors = character(0),
  omit.indicators = character(0), omit.imps = c("no.conv", "no.se"),
  return.df = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compRelSEM_+3A_object">object</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object,
expected to contain only exogenous common factors (i.e., a CFA model).</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_obs.var">obs.var</code></td>
<td>
<p><code>logical</code> indicating whether to compute reliability
using observed variances in the denominator. Setting <code>FALSE</code> triggers
using model-implied variances in the denominator.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_tau.eq">tau.eq</code></td>
<td>
<p><code>logical</code> indicating whether to assume (essential)
tau-equivalence, yielding a coefficient analogous to <code class="reqn">\alpha</code>.
Setting <code>FALSE</code> yields an <code class="reqn">\omega</code>-type coefficient.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_ord.scale">ord.scale</code></td>
<td>
<p><code>logical</code> indicating whether to apply Green and Yang's
(2009, formula 21) correction, so that reliability is calculated for the
actual ordinal response scale (ignored for factors with continuous
indicators).  Setting <code>FALSE</code> yields coefficients that are
only applicable to the continuous latent-response scale.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_config">config</code></td>
<td>
<p><code>character</code> vector naming any configural constructs in
a multilevel CFA. For these constructs (and optional total composite),
Lai's (2021) coefficients <code class="reqn">\omega^\textrm{W}</code> and <code class="reqn">\omega^\textrm{2L}</code>
are returned (or corresponding <code class="reqn">\alpha</code> coefficients when
<code>tau.eq=TRUE</code>), rather than Geldhof et al.'s (2014) coefficients for
hypothetical composites of latent components (although the same formula
is used for <code class="reqn">\omega^\textrm{W}</code> in either case). Note that the same name
must be used for the factor component represented at each level of the
model.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_shared">shared</code></td>
<td>
<p><code>character</code> vector naming any shared constructs in
a multilevel CFA. For these constructs (and optional total composite),
Lai's (2021) coefficient <code class="reqn">\omega^\textrm{B}</code> or <code class="reqn">\alpha^\textrm{B}</code> is
returned, rather than Geldhof et al.'s (2014) between-level coefficient
for hypothetical composites of latent cluster means. Lai's (2021)
coefficient quantifies reliability relative to error associated with both
indicators (measurement error) and subjects (sampling error), like a
generalizability coefficient.  Given that subjects can be considered as
raters of their cluster's shared construct, an interrater reliability
(IRR) coefficient is also returned, quantifying reliability relative to
rater/sampling error alone.  To quantify reliability relative to
indicator/measurement error alone (i.e., <code class="reqn">\omega^\textrm{2L}</code>), the
<code style="white-space: pre;">&#8288;shared=&#8288;</code> construct name(s) can additionally be included in
<code style="white-space: pre;">&#8288;config=&#8288;</code> argument.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_higher">higher</code></td>
<td>
<p><code>character</code> vector naming any higher-order constructs in
<code>object</code> for which composite reliability should be calculated.
Ignored when <code>tau.eq=TRUE</code> because alpha is not based on a CFA model;
instead, users must fit a CFA with tau-equivalence constraints.
To obtain Lai's (2021) multilevel composite-reliability indices for a
higher-order factor, do not use this argument; instead, specify the
higher-order factor(s) using the <code style="white-space: pre;">&#8288;shared=&#8288;</code> or <code style="white-space: pre;">&#8288;config=&#8288;</code> argument
(<code>compRelSEM</code> will automatically check whether it includes latent
indicators and apply the appropriate formula).</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_return.total">return.total</code></td>
<td>
<p><code>logical</code> indicating whether to return a final
column containing the reliability of a composite of all indicators (not
listed in <code>omit.indicators</code>) of first-order factors not listed in
<code>omit.factors</code>.  Ignored in 1-factor models, and should only be set
<code>TRUE</code> if all factors represent scale dimensions that could be
meaningfully collapsed to a single composite (scale sum or scale mean).
Setting a negative value (e.g., <code>-1</code> returns <strong>only</strong> the
total-composite reliability (excluding coefficients per factor), except
when requesting Lai's (2021) coefficients for multilevel <code>config</code>ural
or <code style="white-space: pre;">&#8288;shared=&#8288;</code> constructs.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_dropsingle">dropSingle</code></td>
<td>
<p><code>logical</code> indicating whether to exclude factors
defined by a single indicator from the returned results. If <code>TRUE</code>
(default), single indicators will still be included in the <code>total</code>
column when <code>return.total = TRUE</code>.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_omit.factors">omit.factors</code></td>
<td>
<p><code>character</code> vector naming any common factors
modeled in <code>object</code> whose composite reliability is not of
interest. For example, higher-order or method factors. Note that
<code><a href="#topic+reliabilityL2">reliabilityL2()</a></code> should be used to calculate composite
reliability of a higher-order factor.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_omit.indicators">omit.indicators</code></td>
<td>
<p><code>character</code> vector naming any observed variables
that should be omitted from the composite whose reliability is calculated.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
<tr><td><code id="compRelSEM_+3A_return.df">return.df</code></td>
<td>
<p><code>logical</code> indicating whether to return reliability
coefficients in a <code>data.frame</code> (one row per group/level), which is
possible when every model block includes the same factors (after excluding
those in <code>omit.factors</code> and applying <code>dropSingle</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Several coefficients for factor-analysis reliability have been termed
&quot;omega&quot;, which Cho (2021) argues is a misleading misnomer and argues for
using <code class="reqn">\rho</code> to represent them all, differentiated by descriptive
subscripts.  In our package, we strive to provide unlabeled coefficients,
leaving it to the user to decide on a label in their report.  But we do
use the symbols <code class="reqn">\alpha</code> and <code class="reqn">\omega</code> in the formulas below in order
to distinguish coefficients that do (not) assume essential tau-equivalence.
For higher-order constructs with latent indicators, only <code class="reqn">\omega</code> is
available. Lai's (2021) multilevel coefficients are labeled in accordance
with the symbols used in that article (more details below).
</p>
<p>Bentler (1968) first introduced factor-analysis reliability for a
unidimensional factor model with congeneric indicators, labeling the
coeficients <code class="reqn">\alpha</code>.  McDonald (1999) later referred to this
<em>and other reliability coefficients</em>, first as <code class="reqn">\theta</code> (in 1970),
then as <code class="reqn">\omega</code>, which is a source of confusion when reporting
coefficients (Cho, 2021).  Coefficients based on factor models were later
generalized to account for multidimenisionality (possibly with
cross-loadings) and correlated errors. The general <code class="reqn">\omega</code> formula
implemented in this function is:
</p>
<p style="text-align: center;"><code class="reqn"> \omega = \frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\bold{1}^\prime \hat{\Sigma} \bold{1}}, </code>
</p>

<p>where <code class="reqn">\hat{\Sigma}</code> can be the model-implied covariance matrix from
either the saturated model (i.e., the &quot;observed&quot; covariance matrix, used by
default) or from the hypothesized CFA model, controlled by the
<code>obs.var</code> argument. A <code class="reqn">k</code>-dimensional vector <code class="reqn">\bold{1}</code> is used
to sum elements in the matrix. Note that if the model includes any directed
effects (latent regression slopes), all coefficients are calculated
from <strong>total</strong> factor variances: <code>lavInspect(object, "cov.lv")</code>.
</p>
<p>Assuming (essential) tau-equivalence (<code>tau.eq=TRUE</code>) makes <code class="reqn">\omega</code>
equivalent to coefficient <code class="reqn">\alpha</code> from classical test theory
(Cronbach, 1951):
</p>
<p style="text-align: center;"><code class="reqn"> \alpha = \frac{k}{k - 1}\left[ 1 - \frac{\sum^{k}_{i = 1}
\sigma_{ii}}{\sum^{k}_{i = 1} \sigma_{ii} + 2\sum_{i &lt; j} \sigma_{ij}}
\right],</code>
</p>

<p>where <code class="reqn">k</code> is the number of items in a factor's composite,
<code class="reqn">\sigma_{ii}</code> signifies item <em>i</em>'s variance, and <code class="reqn">\sigma_{ij}</code>
signifies the covariance between items <em>i</em> and <em>j</em>. Again, the
<code>obs.var</code> argument controls whether <code class="reqn">\alpha</code> is calculated using
the observed or model-implied covariance matrix.
</p>
<p>By setting <code>return.total=TRUE</code>, one can estimate reliability for a
single composite calculated using all indicators in a multidimensional
CFA (Bentler, 1972, 2009). Setting <code>return.total = -1</code> will return
<strong>only</strong> the total-composite reliability (not per factor).
</p>
<p><strong>Higher-Order Factors</strong>:
The reliability of a composite that represents a higher-order construct
requires partitioning the model-implied factor covariance matrix <code class="reqn">\Phi</code>
in order to isolate the common-factor variance associated only with the
higher-order factor. Using a second-order factor model, the model-implied
covariance matrix of observed indicators <code class="reqn">\hat{\Sigma}</code> can be
partitioned into 3 sources:
</p>

<ol>
<li><p> the second-order common-factor (co)variance:
<code class="reqn">\Lambda \bold{B} \Phi_2 \bold{B}^{\prime} \Lambda^{\prime}</code>
</p>
</li>
<li><p> the residual variance of the first-order common factors (i.e., not
accounted for by the second-order factor):
<code class="reqn">\Lambda \Psi_{u} \Lambda^{\prime}</code>
</p>
</li>
<li><p> the measurement error of observed indicators: <code class="reqn">\Theta</code>
</p>
</li></ol>

<p>where <code class="reqn">\Lambda</code> contains first-order factor loadings, <code class="reqn">\bold{B}</code>
contains second-order factor loadings, <code class="reqn">\Phi_2</code> is the model-implied
covariance matrix of the second-order factor(s), and <code class="reqn">\Psi_{u}</code> is the
covariance matrix of first-order factor disturbances. In practice, we can
use the full <code class="reqn">\bold{B}</code> matrix and full model-implied <code class="reqn">\Phi</code> matrix
(i.e., including all latent factors) because the zeros in <code class="reqn">\bold{B}</code>
will cancel out unwanted components of <code class="reqn">\Phi</code>. Thus, we can calculate
the proportion of variance of a composite score calculated from the observed
indicators (e.g., a total score or scale mean) that is attributable to the
second-order factor (i.e., coefficient <code class="reqn">\omega</code>):
</p>
<p style="text-align: center;"><code class="reqn">\omega=\frac{\bold{1}^{\prime} \Lambda \bold{B} \Phi \bold{B}^{\prime}
  \Lambda^{\prime} \bold{1} }{ \bold{1}^{\prime} \hat{\Sigma} \bold{1}}, </code>
</p>

<p>where <code class="reqn">\bold{1}</code> is the <em>k</em>-dimensional vector of 1s and <em>k</em>
is the number of observed indicators in the composite. Note that if a
higher-order factor also has observed indicators, it is necessary to model
the observed indicators as single-indicator constructs, so that all of the
higher-order factor indicators are latent (with loadings in the Beta matrix,
not Lambda).
</p>
<p><strong>Categorical Indicators</strong>:
When all indicators (per composite) are ordinal, the <code>ord.scale</code>
argument controls whether the coefficient is calculated on the
latent-response scale (<code>FALSE</code>) or on the observed ordinal scale
(<code>TRUE</code>, the default).  For <code class="reqn">\omega</code>-type coefficients
(<code>tau.eq=FALSE</code>), Green and Yang's (2009, formula 21) approach is used
to transform factor-model results back to the ordinal response scale. When
<code>ord.scale=TRUE</code> and <code>tau.eq=TRUE</code>, coefficient <code class="reqn">\alpha</code> is
calculated using the covariance matrix calculated from the integer-valued
numeric weights for ordinal categories, consistent with its definition
(Chalmers, 2018) and the <code>alpha</code> function in the <code>psych</code> package;
this implies <code>obs.var=TRUE</code>, so <code>obs.var=FALSE</code> will be ignored
When <code>ord.scale=FALSE</code>, the standard <code class="reqn">\alpha</code> formula is applied to
the polychoric correlation matrix (&quot;ordinal <code class="reqn">\alpha</code>&quot;; Zumbo et al., 2007),
estimated from the saturated or hypothesized model (see <code>obs.var</code>),
and <code class="reqn">\omega</code> is calculated from CFA results without applying Green and
Yang's (2009) correction (see Zumbo &amp; Kroc, 2019, for a rationalization).
No method analogous to Green and Yang (2009) has been proposed for
calculating reliability with a mixture of categorical and continuous
indicators, so an error is returned if <code>object</code> includes factors with a
mixture of indicator types (unless omitted using <code>omit.factors</code>). If
categorical indicators load on a different factor(s) than continuous
indicators, then reliability will still be calculated separately for those
factors, but <code>return.total</code> must be <code>FALSE</code> (unless
<code>omit.factors</code> is used to isolate factors with indicators of the same
type).
</p>
<p><strong>Multilevel Measurement Models</strong>:
Under the default settings, <code>compRelSEM()</code> will apply the same formula
in each &quot;block&quot; (group and/or level of analysis). In the case of multilevel
(ML-)SEMs, this yields &quot;reliability&quot; for latent within- and between-level
components, as proposed by Geldhof et al. (2014).  Although this works fine
to calculate reliability per group, this is not recommended for ML-SEMs
because the coefficients do not correspond to actual composites that would
be calculated from the observed data.  Lai (2021) proposed coefficients for
reliability of actual composites, depending on the type of construct, which
requires specifying the names of constructs for which reliability is desired
(or multiple constructs whose indicators would compose a multidimensional
composite). Configural (<code style="white-space: pre;">&#8288;config=&#8288;</code>) and/or <code style="white-space: pre;">&#8288;shared=&#8288;</code> constructs
can be specified; the same construct can be specified in both arguments, so
that overall scale-reliability can be estimated for a shared construct by
including it in <code>config</code>.  Instead of organizing the output by block
(the default), specifying <code style="white-space: pre;">&#8288;config=&#8288;</code> and/or <code style="white-space: pre;">&#8288;shared=&#8288;</code> will prompt
organizing the list of output by <code style="white-space: pre;">&#8288;$config&#8288;</code> and/or <code style="white-space: pre;">&#8288;$shared&#8288;</code>.
</p>

<ul>
<li><p> The overall (<code style="white-space: pre;">&#8288;_2L&#8288;</code>) scale reliability for <code>config</code>ural
constructs is returned, along with the reliability of a purely
individual-level composite (<code style="white-space: pre;">&#8288;_W&#8288;</code>, calculated by cluster-mean
centering).
</p>
</li>
<li><p> The reliability for a <code>shared</code> construct quantifies
generalizability across both indicators and raters (i.e., subjects rating
their cluster's construct).  Lüdtke et al. (2011) refer to these as
measurement error and sampling error, respectively.  An interrater
reliability (IRR) coefficient is also returned, quantifying
generalizability across rater/sampling-error only. To obtain a
scale-reliability coefficient (quantifying a shared construct's
generalizability across indicator/measurement-error only), include the
same factor name in <code style="white-space: pre;">&#8288;config=&#8288;</code>.  Jak et al. (2021) recommended
modeling components of the same construct at both levels, but users may
also saturate the within-level model (Lai, 2021).
</p>
</li></ul>

<p>Be careful about including Level-2 variables in the model, especially
whether it makes sense to include them in a total composite for a Level-2
construct.  <code>dropSingle=TRUE</code> only prevents estimating reliability for
a single-indicator construct, not from including such an indicator in a
total composite.  It is permissible for <code style="white-space: pre;">&#8288;shared=&#8288;</code> constructs to have
additional indicators at Level-2 only.  If it is necessary to model other
Level-2 variables (e.g., to justify the missing-at-random assumption when
using <code style="white-space: pre;">&#8288;missing="FIML" estimation&#8288;</code>), they should be placed in the
<code style="white-space: pre;">&#8288;omit.indicators=&#8288;</code> argument to exclude them from total composites.
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of composite reliability coefficients per
factor, or a <code>list</code> of vectors per &quot;block&quot; (group and/or level of
analysis), optionally returned as a <code>data.frame</code> when possible (see
<code style="white-space: pre;">&#8288;return.df=&#8288;</code> argument description for caveat). If there are multiple
factors, whose multidimensional indicators combine into a single
composite, users can request <code>return.total=TRUE</code> to add a column
including a reliability coefficient for the total composite, or
<code>return.total = -1</code> to return <strong>only</strong> the total-composite
reliability (ignored when <code style="white-space: pre;">&#8288;config=&#8288;</code> or <code style="white-space: pre;">&#8288;shared=&#8288;</code> is specified
because each factor's specification must be checked across levels).
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Uses hidden functions written by Sunthud Pornprasertmanit
(<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>) for the old <code>reliability()</code> function.
</p>


<h3>References</h3>

<p>Bentler, P. M. (1968). Alpha-maximized factor analysis (alphamax): Its
relation to alpha and canonical factor analysis. <em>Psychometrika, 33</em>(3),
335&ndash;345. <a href="https://doi.org/10.1007/BF02289328">doi:10.1007/BF02289328</a>
</p>
<p>Bentler, P. M. (1972). A lower-bound method for the dimension-free
measurement of internal consistency. <em>Social Science Research, 1</em>(4),
343&ndash;357. <a href="https://doi.org/10.1016/0049-089X%2872%2990082-8">doi:10.1016/0049-089X(72)90082-8</a>
</p>
<p>Bentler, P. M. (2009). Alpha, dimension-free, and model-based internal
consistency reliability. <em>Psychometrika, 74</em>(1), 137&ndash;143.
<a href="https://doi.org/10.1007/s11336-008-9100-1">doi:10.1007/s11336-008-9100-1</a>
</p>
<p>Chalmers, R. P. (2018). On misconceptions and the limited usefulness of
ordinal alpha. <em>Educational and Psychological Measurement, 78</em>(6),
1056&ndash;1071. <a href="https://doi.org/10.1177/0013164417727036">doi:10.1177/0013164417727036</a>
</p>
<p>Cho, E. (2021) Neither Cronbach’s alpha nor McDonald’s omega: A commentary
on Sijtsma and Pfadt. <em>Psychometrika, 86</em>(4), 877&ndash;886.
<a href="https://doi.org/10.1007/s11336-021-09801-1">doi:10.1007/s11336-021-09801-1</a>
</p>
<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of
tests. <em>Psychometrika, 16</em>(3), 297&ndash;334. <a href="https://doi.org/10.1007/BF02310555">doi:10.1007/BF02310555</a>
</p>
<p>Geldhof, G. J., Preacher, K. J., &amp; Zyphur, M. J. (2014). Reliability
estimation in a multilevel confirmatory factor analysis framework.
<em>Psychological Methods, 19</em>(1), 72&ndash;91. <a href="https://doi.org/10.1037/a0032138">doi:10.1037/a0032138</a>
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using
structural equation modeling: An alternative to coefficient alpha.
<em>Psychometrika, 74</em>(1), 155&ndash;167. <a href="https://doi.org/10.1007/s11336-008-9099-3">doi:10.1007/s11336-008-9099-3</a>
</p>
<p>Jak, S., Jorgensen, T. D., &amp; Rosseel, Y. (2021). Evaluating cluster-level
factor models with <code>lavaan</code> and M<em>plus</em>. <em>Psych, 3</em>(2),
134&ndash;152. <a href="https://doi.org/10.3390/psych3020012">doi:10.3390/psych3020012</a>
</p>
<p>Lai, M. H. C. (2021). Composite reliability of multilevel data: It’s about
observed scores and construct meanings. <em>Psychological Methods, 26</em>(1),
90&ndash;102. <a href="https://doi.org/10.1037/met0000287">doi:10.1037/met0000287</a>
</p>
<p>Lüdtke, O., Marsh, H. W., Robitzsch, A., &amp; Trautwein, U. (2011).
A 2 <code class="reqn">\times</code> 2 taxonomy of multilevel latent contextual models:
Accuracy&ndash;bias trade-offs in full and partial error correction models.
<em>Psychological Methods, 16</em>(4), 444&ndash;467. <a href="https://doi.org/10.1037/a0024376">doi:10.1037/a0024376</a>
</p>
<p>McDonald, R. P. (1999). <em>Test theory: A unified treatment</em>. Mahwah, NJ:
Erlbaum.
</p>
<p>Zumbo, B. D., Gadermann, A. M., &amp; Zeisser, C. (2007). Ordinal versions of
coefficients alpha and theta for Likert rating scales.
<em>Journal of Modern Applied Statistical Methods, 6</em>(1), 21&ndash;29.
<a href="https://doi.org/10.22237/jmasm/1177992180">doi:10.22237/jmasm/1177992180</a>
</p>
<p>Zumbo, B. D., &amp; Kroc, E. (2019). A measurement is a choice and Stevens’
scales of measurement do not help make it: A response to Chalmers.
<em>Educational and Psychological Measurement, 79</em>(6), 1184&ndash;1197.
<a href="https://doi.org/10.1177/0013164419844305">doi:10.1177/0013164419844305</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+maximalRelia">maximalRelia()</a></code> for the maximal reliability of weighted composite
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(HolzingerSwineford1939)
HS9 &lt;- HolzingerSwineford1939[ , c("x7","x8","x9")]
HSbinary &lt;- as.data.frame( lapply(HS9, cut, 2, labels=FALSE) )
names(HSbinary) &lt;- c("y7","y8","y9")
HS &lt;- cbind(HolzingerSwineford1939, HSbinary)

HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ y7 + y8 + y9 '

fit &lt;- cfa(HS.model, data = HS, ordered = c("y7","y8","y9"), std.lv = TRUE)

## works for factors with exclusively continuous OR categorical indicators
compRelSEM(fit)

## reliability for ALL indicators only available when they are
## all continuous or all categorical
compRelSEM(fit, omit.factors = "speed", return.total = TRUE)


## loop over visual indicators to calculate alpha if one indicator is removed
for (i in paste0("x", 1:3)) {
  cat("Drop ", i, ":\n", sep = "")
  print(compRelSEM(fit, omit.factors = c("textual","speed"),
                   omit.indicators = i, tau.eq = TRUE))
}
## item-total correlations obtainable by adding a composite to the data
HS$Visual &lt;- HS$x1 + HS$x2 + HS$x3
cor(HS$Visual, y = HS[paste0("x", 1:3)])
## comparable to psych::alpha(HS[paste0("x", 1:3)])

## Reliability of a composite that represents a higher-order factor
mod.hi &lt;- ' visual  =~ x1 + x2 + x3
            textual =~ x4 + x5 + x6
            speed   =~ x7 + x8 + x9
            general =~ visual + textual + speed '

fit.hi &lt;- cfa(mod.hi, data = HolzingerSwineford1939)
compRelSEM(fit.hi, higher = "general")
## reliabilities for lower-order composites also returned


## works for multigroup models and for multilevel models (and both)
data(Demo.twolevel)
## assign clusters to arbitrary groups
Demo.twolevel$g &lt;- ifelse(Demo.twolevel$cluster %% 2L, "type1", "type2")
model2 &lt;- ' group: type1
  level: 1
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6
  level: 2
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6

group: type2
  level: 1
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6
  level: 2
    f1 =~ y1 + L2*y2 + L3*y3
    f2 =~ y4 + L5*y5 + L6*y6
'
fit2 &lt;- sem(model2, data = Demo.twolevel, cluster = "cluster", group = "g")
compRelSEM(fit2) # Geldhof's indices (hypothetical, for latent components)

## Lai's (2021) indices for Level-1 and configural constructs
compRelSEM(fit2, config = c("f1","f2"))
## Lai's (2021) indices for shared (Level-2) constructs
## (also an interrater reliability coefficient)
compRelSEM(fit2, shared = c("f1","f2"))


## Shared construct using saturated within-level model
mod.sat1 &lt;- ' level: 1
  y1 ~~ y1 + y2 + y3 + y4 + y5 + y6
  y2 ~~ y2 + y3 + y4 + y5 + y6
  y3 ~~ y3 + y4 + y5 + y6
  y4 ~~ y4 + y5 + y6
  y5 ~~ y5 + y6
  y6 ~~ y6

  level: 2
  f1 =~ y1 + L2*y2 + L3*y3
  f2 =~ y4 + L5*y5 + L6*y6
'
fit.sat1 &lt;- sem(mod.sat1, data = Demo.twolevel, cluster = "cluster")
compRelSEM(fit.sat1, shared = c("f1","f2"))


## Simultaneous shared-and-configural model (Stapleton et al, 2016, 2019),
## not recommended, but possible by omitting shared or configural factor.
mod.both &lt;- ' level: 1
    fc =~ y1 + L2*y2 + L3*y3 + L4*y4 + L5*y5 + L6*y6
  level: 2
  ## configural construct
    fc =~ y1 + L2*y2 + L3*y3 + L4*y4 + L5*y5 + L6*y6
  ## orthogonal shared construct
    fs =~ NA*y1 + y2 + y3 + y4 + y5 + y6
    fs ~~ 1*fs + 0*fc
'
fit.both &lt;- sem(mod.both, data = Demo.twolevel, cluster = "cluster")
compRelSEM(fit.both, shared = "fs", config = "fc")

</code></pre>

<hr>
<h2 id='dat2way'>Simulated Dataset to Demonstrate Two-way Latent Interaction</h2><span id='topic+dat2way'></span>

<h3>Description</h3>

<p>A simulated data set with 2 independent factors and 1 dependent factor where
each factor has three indicators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dat2way
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 500 observations of 9 variables.
</p>

<dl>
<dt>x1</dt><dd><p>The first indicator of the first independent factor</p>
</dd>
<dt>x2</dt><dd><p>The second indicator of the first independent factor</p>
</dd>
<dt>x3</dt><dd><p>The third indicator of the first independent factor</p>
</dd>
<dt>x4</dt><dd><p>The first indicator of the second independent factor</p>
</dd>
<dt>x5</dt><dd><p>The second indicator of the second independent factor</p>
</dd>
<dt>x6</dt><dd><p>The third indicator of the second independent factor</p>
</dd>
<dt>x7</dt><dd><p>The first indicator of the dependent factor</p>
</dd>
<dt>x8</dt><dd><p>The second indicator of the dependent factor</p>
</dd>
<dt>x9</dt><dd><p>The third indicator of the dependent factor</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data were generated by the <code><a href="MASS.html#topic+mvrnorm">MASS::mvrnorm()</a></code> function in
the <code>MASS</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> head(dat2way)
</code></pre>

<hr>
<h2 id='dat3way'>Simulated Dataset to Demonstrate Three-way Latent Interaction</h2><span id='topic+dat3way'></span>

<h3>Description</h3>

<p>A simulated data set with 3 independent factors and 1 dependent factor where
each factor has three indicators
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dat3way
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 500 observations of 12 variables.
</p>

<dl>
<dt>x1</dt><dd><p>The first indicator of the first independent factor</p>
</dd>
<dt>x2</dt><dd><p>The second indicator of the first independent factor</p>
</dd>
<dt>x3</dt><dd><p>The third indicator of the first independent factor</p>
</dd>
<dt>x4</dt><dd><p>The first indicator of the second independent factor</p>
</dd>
<dt>x5</dt><dd><p>The second indicator of the second independent factor</p>
</dd>
<dt>x6</dt><dd><p>The third indicator of the second independent factor</p>
</dd>
<dt>x7</dt><dd><p>The first indicator of the third independent factor</p>
</dd>
<dt>x8</dt><dd><p>The second indicator of the third independent factor</p>
</dd>
<dt>x9</dt><dd><p>The third indicator of the third independent factor</p>
</dd>
<dt>x10</dt><dd><p>The first indicator of the dependent factor</p>
</dd>
<dt>x11</dt><dd><p>The second indicator of the dependent factor</p>
</dd>
<dt>x12</dt><dd><p>The third indicator of the dependent factor</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data were generated by the <code><a href="MASS.html#topic+mvrnorm">MASS::mvrnorm()</a></code> function in
the <code>MASS</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(dat3way)
</code></pre>

<hr>
<h2 id='datCat'>Simulated Data set to Demonstrate Categorical Measurement Invariance</h2><span id='topic+datCat'></span>

<h3>Description</h3>

<p>A simulated data set with 2 factors with 4 indicators each separated into
two groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>datCat
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 200 observations of 9 variables.
</p>

<dl>
<dt>g</dt><dd><p>Sex of respondents</p>
</dd>
<dt>u1</dt><dd><p>Indicator 1</p>
</dd>
<dt>u2</dt><dd><p>Indicator 2</p>
</dd>
<dt>u3</dt><dd><p>Indicator 3</p>
</dd>
<dt>u4</dt><dd><p>Indicator 4</p>
</dd>
<dt>u5</dt><dd><p>Indicator 5</p>
</dd>
<dt>u6</dt><dd><p>Indicator 6</p>
</dd>
<dt>u7</dt><dd><p>Indicator 7</p>
</dd>
<dt>u8</dt><dd><p>Indicator 8</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data were generated using the <code>lavaan</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(datCat)
</code></pre>

<hr>
<h2 id='discriminantValidity'>Calculate discriminant validity statistics</h2><span id='topic+discriminantValidity'></span>

<h3>Description</h3>

<p>Calculate discriminant validity statistics based on a fitted lavaan object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discriminantValidity(object, cutoff = 0.9, merge = FALSE, level = 0.95,
  boot.ci.type = "perc")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discriminantValidity_+3A_object">object</code></td>
<td>
<p>The <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> model object returned by
the <code><a href="lavaan.html#topic+cfa">lavaan::cfa()</a></code> function.</p>
</td></tr>
<tr><td><code id="discriminantValidity_+3A_cutoff">cutoff</code></td>
<td>
<p>A cutoff to be used in the constrained models in likelihood
ratio tests.</p>
</td></tr>
<tr><td><code id="discriminantValidity_+3A_merge">merge</code></td>
<td>
<p>Whether the constrained models should be constructed by merging
two factors as one. Implies <code>cutoff</code> = 1.</p>
</td></tr>
<tr><td><code id="discriminantValidity_+3A_level">level</code></td>
<td>
<p>The confidence level required.</p>
</td></tr>
<tr><td><code id="discriminantValidity_+3A_boot.ci.type">boot.ci.type</code></td>
<td>
<p>If bootstrapping was used, the type of interval required.
The value should be one of <code>"norm"</code>, <code>"basic"</code>, <code>"perc"</code>,
or <code>"bca.simple"</code>. For the first three options, see the help page of
the <code>boot.ci</code> function in the boot package. The
<code>"bca.simple"</code> option produces intervals using the adjusted bootstrap
percentile (BCa) method, but with no correction for acceleration (only for
bias). Note that the p-value is still computed assuming that the z-statistic
follows a standard normal distribution.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Evaluated on the measurement scale level, discriminant validity is commonly
evaluated by checking if each pair of latent correlations is sufficiently
below one (in absolute value) that the latent variables can be thought of
representing two distinct constructs.
</p>
<p><code>discriminantValidity</code> function calculates two sets of statistics that
are commonly used in discriminant validity evaluation. The first set are
factor correlation estimates and their confidence intervals. The second set
is a series of nested model tests, where the baseline model is compared
against a set of constrained models that are constructed by constraining
each factor correlation to the specified cutoff one at a time.
</p>
<p>The function assume that the <code>object</code> is set of confirmatory
factor analysis results where the latent variables are scaled by fixing their
variances to 1s. If the model is not a CFA model, the function will calculate
the statistics for the correlations among exogenous latent variables, but
for the <em>residual</em> variances with endogenous variables. If the
latent variables are scaled in some other way (e.g. fixing the first loadings),
the function issues a warning and re-estimates the model by fixing latent
variances to 1 (and estimating all loadings) so that factor covariances are
already estimated as correlations.
</p>
<p>The likelihood ratio tests are done by comparing the original baseline model
against more constrained alternatives. By default, these alternatives are
constructed by fixing each correlation at a time to a cutoff value. The
typical purpose of this test is to demonstrate that the estimated factor
correlation is well below the cutoff and a significant <code class="reqn">chi^2</code> statistic
thus indicates support for discriminant validity. In some cases, the original
correlation estimate may already be greater than the cutoff, making it
redundant to fit a &quot;restricted&quot; model. When this happens, the likelihood
ratio test will be replaced by comparing the baseline model against itself.
For correlations that are estimated to be negative, a negation of the cutoff
is used in the constrained model.
</p>
<p>Another alternative is to do a nested model comparison against a model where
two factors are merged as one by setting the <code>merge</code> argument to
<code>TRUE</code>. In this comparison, the constrained model is constructed by
removing one of the correlated factors from the model and assigning its
indicators to the factor that remains in the model.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> of latent variable correlation estimates, their
confidence intervals, and a likelihood ratio tests against constrained models.
with the following attributes:
</p>

<dl>
<dt>baseline</dt><dd><p>The baseline model after possible rescaling.</p>
</dd>
<dt>constrained</dt><dd><p>A <code>list</code> of the fitted constrained models
used in the likelihood ratio test.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Mikko Rönkkö (University of Jyväskylä; <a href="mailto:mikko.ronkko@jyu.fi">mikko.ronkko@jyu.fi</a>):
</p>


<h3>References</h3>

<p>Rönkkö, M., &amp; Cho, E. (2022). An updated guideline for assessing
discriminant validity. <em>Organizational Research Methods</em>, 25(1), 6–14.
<a href="https://doi.org/10.1177/1094428120968614">doi:10.1177/1094428120968614</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)

HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit &lt;- cfa(HS.model, data = HolzingerSwineford1939)
discriminantValidity(fit)
discriminantValidity(fit, merge = TRUE)

</code></pre>

<hr>
<h2 id='EFA-class'>Class For Rotated Results from EFA</h2><span id='topic+EFA-class'></span><span id='topic+show+2CEFA-method'></span><span id='topic+summary+2CEFA-method'></span>

<h3>Description</h3>

<p>This class contains the results of rotated exploratory factor analysis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'EFA'
show(object)

## S4 method for signature 'EFA'
summary(object, suppress = 0.1, sort = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EFA-class_+3A_object">object</code></td>
<td>
<p>object of class <code>EFA</code></p>
</td></tr>
<tr><td><code id="EFA-class_+3A_suppress">suppress</code></td>
<td>
<p>any standardized loadings less than the specified value
will not be printed to the screen</p>
</td></tr>
<tr><td><code id="EFA-class_+3A_sort">sort</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (default), factor loadings will
be sorted by their size in the console output</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>loading</code></dt><dd><p>Rotated standardized factor loading matrix</p>
</dd>
<dt><code>rotate</code></dt><dd><p>Rotation matrix</p>
</dd>
<dt><code>gradRotate</code></dt><dd><p>gradient of the objective function at the rotated loadings</p>
</dd>
<dt><code>convergence</code></dt><dd><p>Convergence status</p>
</dd>
<dt><code>phi:</code></dt><dd><p>Factor correlation matrix. Will be an identity matrix if
orthogonal rotation is used.</p>
</dd>
<dt><code>se</code></dt><dd><p>Standard errors of the rotated standardized factor loading matrix</p>
</dd>
<dt><code>method</code></dt><dd><p>Method of rotation</p>
</dd>
<dt><code>call</code></dt><dd><p>The command used to generate this object</p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>Objects can be created via the
<code><a href="#topic+orthRotate">orthRotate</a></code> or <code><a href="#topic+oblqRotate">oblqRotate</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+efaUnrotate">efaUnrotate</a></code>; <code><a href="#topic+orthRotate">orthRotate</a></code>;
<code><a href="#topic+oblqRotate">oblqRotate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


unrotated &lt;- efaUnrotate(HolzingerSwineford1939, nf = 3,
                         varList = paste0("x", 1:9), estimator = "mlr")
summary(unrotated, std = TRUE)
lavInspect(unrotated, "std")

# Rotated by Quartimin
rotated &lt;- oblqRotate(unrotated, method = "quartimin")
summary(rotated)


</code></pre>

<hr>
<h2 id='efa.ekc'>Empirical Kaiser criterion</h2><span id='topic+efa.ekc'></span>

<h3>Description</h3>

<p>Identify the number of factors to extract based on the Empirical Kaiser
Criterion (EKC). The analysis can be run on a <code>data.frame</code> or data
<code>matrix</code> (<code>data</code>), or on a correlation or covariance matrix
(<code>sample.cov</code>) and the sample size (<code>sample.nobs</code>). A
<code>data.frame</code> is returned with two columns: the eigenvalues from your
data or covariance matrix and the reference eigenvalues. The number of
factors suggested by the Empirical Kaiser Criterion (i.e. the sample
eigenvalues greater than the reference eigenvalues), and the number of
factors suggested by the original Kaiser Criterion
(i.e. sample eigenvalues &gt; 1) is printed above the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efa.ekc(data = NULL, sample.cov = NULL, sample.nobs = NULL,
  missing = "default", ordered = NULL, plot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="efa.ekc_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> or data <code>matrix</code> containing columns of
variables to be factor-analyzed.</p>
</td></tr>
<tr><td><code id="efa.ekc_+3A_sample.cov">sample.cov</code></td>
<td>
<p>A covariance or correlation matrix can be used, instead of
<code>data</code>, to estimate the eigenvalues.</p>
</td></tr>
<tr><td><code id="efa.ekc_+3A_sample.nobs">sample.nobs</code></td>
<td>
<p>Number of observations (i.e. sample size) if
<code>is.null(data)</code> and <code style="white-space: pre;">&#8288;sample.cov=&#8288;</code> is used.</p>
</td></tr>
<tr><td><code id="efa.ekc_+3A_missing">missing</code></td>
<td>
<p>If <code>"listwise"</code>, incomplete cases are removed listwise from
the <code>data.frame</code>. If <code>"direct"</code> or <code>"ml"</code> or <code>"fiml"</code> and the <code style="white-space: pre;">&#8288;estimator=&#8288;</code>
is maximum likelihood, an EM algorithm is used to estimate an unrestricted
covariance matrix (and mean vector). If <code>"pairwise"</code>, pairwise deletion is
used. If '&quot;default&quot;&ldquo;, the value is set depending on the estimator and the
mimic option (see <code><a href="lavaan.html#topic+lavCor">lavaan::lavCor()</a></code> for details).</p>
</td></tr>
<tr><td><code id="efa.ekc_+3A_ordered">ordered</code></td>
<td>
<p><code>character</code> vector. Only used if object is a <code>data.frame</code>.
Treat these variables as <code style="white-space: pre;">&#8288;ordered=&#8288;</code> (ordinal) variables. Importantly, all
other variables will be treated as numeric (unless <code>is.ordered == TRUE</code> in
<code>data</code>). (see also <a href="lavaan.html#topic+lavCor">lavCor</a>)</p>
</td></tr>
<tr><td><code id="efa.ekc_+3A_plot">plot</code></td>
<td>
<p>logical. Whether to print a scree plot comparing the sample
eigenvalues with the reference eigenvalues.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> showing the sample and reference eigenvalues.
</p>
<p>The number of factors suggested by the Empirical Kaiser Criterion (i.e. the
sample eigenvalues greater than the reference eigenvalues) is returned as an
attribute (see <strong>Examples</strong>).
</p>
<p>The number of factors suggested by the original Kaiser Criterion (i.e.
sample eigenvalues &gt; 1) is also printed as a header to the <code>data.frame</code>
</p>


<h3>Author(s)</h3>

<p>Ylenio Longo (University of Nottingham;
<a href="mailto:yleniolongo@gmail.com">yleniolongo@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Braeken, J., &amp; van Assen, M. A. L. M. (2017). An empirical
Kaiser criterion. <em>Psychological Methods, 22</em>(3), 450&ndash;466.
<a href="https://doi.org/10.1037/met0000074">doi:10.1037/met0000074</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulate data with 3 factors
model &lt;- '
  f1 =~ .3*x1 + .5*x2 + .4*x3
  f2 =~ .3*x4 + .5*x5 + .4*x6
  f3 =~ .3*x7 + .5*x8 + .4*x9
'
dat &lt;- simulateData(model, seed = 123)
## save summary statistics
myCovMat &lt;- cov(dat)
myCorMat &lt;- cor(dat)
N &lt;- nrow(dat)

## Run the EKC function
(out &lt;- efa.ekc(dat))

## To extract the recommended number of factors using the EKC:
attr(out, "nfactors")

## If you do not have raw data, you can use summary statistics
(x1 &lt;- efa.ekc(sample.cov = myCovMat, sample.nobs = N, plot = FALSE))
(x2 &lt;- efa.ekc(sample.cov = myCorMat, sample.nobs = N, plot = FALSE))

</code></pre>

<hr>
<h2 id='efaUnrotate-deprecated'>Analyze Unrotated Exploratory Factor Analysis Model</h2><span id='topic+efaUnrotate-deprecated'></span>

<h3>Description</h3>

<p>This function will analyze unrotated exploratory factor analysis model. The
unrotated solution can be rotated by the <code><a href="#topic+orthRotate">orthRotate</a></code> and
<code><a href="#topic+oblqRotate">oblqRotate</a></code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efaUnrotate(data = NULL, nf, varList = NULL,
            start = TRUE, aux = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="efaUnrotate-deprecated_+3A_data">data</code></td>
<td>
<p>A target <code>data.frame</code></p>
</td></tr>
<tr><td><code id="efaUnrotate-deprecated_+3A_nf">nf</code></td>
<td>
<p>The desired number of factors</p>
</td></tr>
<tr><td><code id="efaUnrotate-deprecated_+3A_varlist">varList</code></td>
<td>
<p>Target observed variables. If not specified, all variables in
<code>data</code> will be used (or <code>sample.cov</code> if <code>is.null(data)</code>;
see <code><a href="lavaan.html#topic+cfa">cfa</a></code> for argument descriptions).</p>
</td></tr>
<tr><td><code id="efaUnrotate-deprecated_+3A_start">start</code></td>
<td>
<p>Use starting values in the analysis from the
<code><a href="stats.html#topic+factanal">factanal</a></code> <code>function</code>. If <code>FALSE</code>, the starting values
from the <code>lavaan</code> package will be used. <code>TRUE</code> is ignored with a
warning if the <code>aux</code> argument is used.</p>
</td></tr>
<tr><td><code id="efaUnrotate-deprecated_+3A_aux">aux</code></td>
<td>
<p>The list of auxiliary variables. These variables will be included
in the model by the saturated-correlates approach to account for missing
information.</p>
</td></tr>
<tr><td><code id="efaUnrotate-deprecated_+3A_...">...</code></td>
<td>
<p>Other arguments in the <code><a href="lavaan.html#topic+cfa">cfa</a></code> function in
the <code>lavaan</code> package, such as <code>ordered</code>, <code>se</code>,
<code>estimator</code>, or <code>sample.cov</code> and <code>sample.nobs</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will generate a lavaan script for unrotated exploratory factor
analysis model such that (1) all factor loadings are estimated, (2) factor
variances are fixed to 1, (3) factor covariances are fixed to 0, and (4) the
dot products of any pairs of columns in the factor loading matrix are fixed
to zero (Johnson &amp; Wichern, 2002). The reason for creating this function
to supplement the <code><a href="stats.html#topic+factanal">factanal</a></code> function is that users can enjoy
some advanced features from the <code>lavaan</code> package, such as scaled
<code class="reqn">\chi^2</code>, diagonally weighted least squares estimation for ordinal
indicators, or full-information maximum likelihood (FIML) to handle
incomplete data.
</p>


<h3>Value</h3>

<p>A <code>lavaan</code> output of unrotated exploratory factor analysis
solution.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


unrotated &lt;- efaUnrotate(HolzingerSwineford1939, nf = 3,
                         varList = paste0("x", 1:9), estimator = "mlr")
summary(unrotated, std = TRUE)
inspect(unrotated, "std")

dat &lt;- data.frame(HolzingerSwineford1939,
                  z = rnorm(nrow(HolzingerSwineford1939), 0, 1))
unrotated2 &lt;- efaUnrotate(dat, nf = 2, varList = paste0("x", 1:9), aux = "z")


</code></pre>

<hr>
<h2 id='exLong'>Simulated Data set to Demonstrate Longitudinal Measurement Invariance</h2><span id='topic+exLong'></span>

<h3>Description</h3>

<p>A simulated data set with 1 factors with 3 indicators in three timepoints
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exLong
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 200 observations of 10 variables.
</p>

<dl>
<dt>sex</dt><dd><p>Sex of respondents</p>
</dd>
<dt>y1t1</dt><dd><p>Indicator 1 in Time 1</p>
</dd>
<dt>y2t1</dt><dd><p>Indicator 2 in Time 1</p>
</dd>
<dt>y3t1</dt><dd><p>Indicator 3 in Time 1</p>
</dd>
<dt>y1t2</dt><dd><p>Indicator 1 in Time 2</p>
</dd>
<dt>y2t2</dt><dd><p>Indicator 2 in Time 2</p>
</dd>
<dt>y3t2</dt><dd><p>Indicator 3 in Time 2</p>
</dd>
<dt>y1t3</dt><dd><p>Indicator 1 in Time 3</p>
</dd>
<dt>y2t3</dt><dd><p>Indicator 2 in Time 3</p>
</dd>
<dt>y3t3</dt><dd><p>Indicator 3 in Time 3</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data were generated using the <code>simsem</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(exLong)
</code></pre>

<hr>
<h2 id='findRMSEApower'>Find the statistical power based on population RMSEA</h2><span id='topic+findRMSEApower'></span>

<h3>Description</h3>

<p>Find the proportion of the samples from the sampling distribution of RMSEA
in the alternative hypothesis rejected by the cutoff dervied from the
sampling distribution of RMSEA in the null hypothesis. This function can be
applied for both test of close fit and test of not-close fit (MacCallum,
Browne, &amp; Suguwara, 1996)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findRMSEApower(rmsea0, rmseaA, df, n, alpha = 0.05, group = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findRMSEApower_+3A_rmsea0">rmsea0</code></td>
<td>
<p>Null RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEApower_+3A_rmseaa">rmseaA</code></td>
<td>
<p>Alternative RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEApower_+3A_df">df</code></td>
<td>
<p>Model degrees of freedom</p>
</td></tr>
<tr><td><code id="findRMSEApower_+3A_n">n</code></td>
<td>
<p>Sample size of a dataset</p>
</td></tr>
<tr><td><code id="findRMSEApower_+3A_alpha">alpha</code></td>
<td>
<p>Alpha level used in power calculations</p>
</td></tr>
<tr><td><code id="findRMSEApower_+3A_group">group</code></td>
<td>
<p>The number of group that is used to calculate RMSEA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function find the proportion of sampling distribution derived from the
alternative RMSEA that is in the critical region derived from the sampling
distribution of the null RMSEA. If <code>rmseaA</code> is greater than
<code>rmsea0</code>, the test of close fit is used and the critical region is in
the right hand side of the null sampling distribution. On the other hand, if
<code>rmseaA</code> is less than <code>rmsea0</code>, the test of not-close fit is used
and the critical region is in the left hand side of the null sampling
distribution (MacCallum, Browne, &amp; Suguwara, 1996).
</p>
<p>There is also a Shiny app called &quot;power4SEM&quot; that provides a graphical user
interface for this functionality (Jak et al., in press).  It can be accessed
at <a href="https://sjak.shinyapps.io/power4SEM/">https://sjak.shinyapps.io/power4SEM/</a>.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>MacCallum, R. C., Browne, M. W., &amp; Sugawara, H. M. (1996). Power analysis
and determination of sample size for covariance structure modeling.
<em>Psychological Methods, 1</em>(2), 130&ndash;149. <a href="https://doi.org/10.1037/1082-989X.1.2.130">doi:10.1037/1082-989X.1.2.130</a>
</p>
<p>Jak, S., Jorgensen, T. D., Verdam, M. G., Oort, F. J., &amp; Elffers, L.
(2021). Analytical power calculations for structural equation modeling:
A tutorial and Shiny app. <em>Behavior Research Methods, 53</em>, 1385&ndash;1406.
<a href="https://doi.org/10.3758/s13428-020-01479-0">doi:10.3758/s13428-020-01479-0</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+plotRMSEApower">plotRMSEApower()</a></code> to plot the statistical power based on
population RMSEA given the sample size
</p>
</li>
<li> <p><code><a href="#topic+plotRMSEAdist">plotRMSEAdist()</a></code> to visualize the RMSEA distributions
</p>
</li>
<li> <p><code><a href="#topic+findRMSEAsamplesize">findRMSEAsamplesize()</a></code> to find the minium sample size for
a given statistical power based on population RMSEA
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
findRMSEApower(rmsea0 = .05, rmseaA = .08, df = 20, n = 200)

</code></pre>

<hr>
<h2 id='findRMSEApowernested'>Find power given a sample size in nested model comparison</h2><span id='topic+findRMSEApowernested'></span>

<h3>Description</h3>

<p>Find the sample size that the power in rejection the samples from the
alternative pair of RMSEA is just over the specified power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findRMSEApowernested(rmsea0A = NULL, rmsea0B = NULL, rmsea1A,
  rmsea1B = NULL, dfA, dfB, n, alpha = 0.05, group = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findRMSEApowernested_+3A_rmsea0a">rmsea0A</code></td>
<td>
<p>The <code class="reqn">H_0</code> baseline RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_rmsea0b">rmsea0B</code></td>
<td>
<p>The <code class="reqn">H_0</code> alternative RMSEA (trivial misfit)</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_rmsea1a">rmsea1A</code></td>
<td>
<p>The <code class="reqn">H_1</code> baseline RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_rmsea1b">rmsea1B</code></td>
<td>
<p>The <code class="reqn">H_1</code> alternative RMSEA (target misfit to be rejected)</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_dfa">dfA</code></td>
<td>
<p>degree of freedom of the more-restricted model</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_dfb">dfB</code></td>
<td>
<p>degree of freedom of the less-restricted model</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level</p>
</td></tr>
<tr><td><code id="findRMSEApowernested_+3A_group">group</code></td>
<td>
<p>The number of group in calculating RMSEA</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bell Clinton
</p>
<p>Pavel Panko (Texas Tech University; <a href="mailto:pavel.panko@ttu.edu">pavel.panko@ttu.edu</a>)
</p>
<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>MacCallum, R. C., Browne, M. W., &amp; Cai, L. (2006). Testing
differences between nested covariance structure models: Power analysis and
null hypotheses. <em>Psychological Methods, 11</em>(1), 19&ndash;35.
<a href="https://doi.org/10.1037/1082-989X.11.1.19">doi:10.1037/1082-989X.11.1.19</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+plotRMSEApowernested">plotRMSEApowernested()</a></code> to plot the statistical power for
nested model comparison based on population RMSEA given the sample size
</p>
</li>
<li> <p><code><a href="#topic+findRMSEAsamplesizenested">findRMSEAsamplesizenested()</a></code> to find the minium sample
size for a given statistical power in nested model comparison based on
population RMSEA
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
findRMSEApowernested(rmsea0A = 0.06, rmsea0B = 0.05, rmsea1A = 0.08,
                     rmsea1B = 0.05, dfA = 22, dfB = 20, n = 200,
                     alpha = 0.05, group = 1)

</code></pre>

<hr>
<h2 id='findRMSEAsamplesize'>Find the minimum sample size for a given statistical power based on
population RMSEA</h2><span id='topic+findRMSEAsamplesize'></span>

<h3>Description</h3>

<p>Find the minimum sample size for a specified statistical power based on
population RMSEA. This function can be applied for both test of close fit
and test of not-close fit (MacCallum, Browne, &amp; Suguwara, 1996)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findRMSEAsamplesize(rmsea0, rmseaA, df, power = 0.8, alpha = 0.05,
  group = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findRMSEAsamplesize_+3A_rmsea0">rmsea0</code></td>
<td>
<p>Null RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesize_+3A_rmseaa">rmseaA</code></td>
<td>
<p>Alternative RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesize_+3A_df">df</code></td>
<td>
<p>Model degrees of freedom</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesize_+3A_power">power</code></td>
<td>
<p>Desired statistical power to reject misspecified model (test of
close fit) or retain good model (test of not-close fit)</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesize_+3A_alpha">alpha</code></td>
<td>
<p>Alpha level used in power calculations</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesize_+3A_group">group</code></td>
<td>
<p>The number of group that is used to calculate RMSEA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function find the minimum sample size for a specified power based on an
iterative routine. The sample size keep increasing until the calculated
power from <code><a href="#topic+findRMSEApower">findRMSEApower()</a></code> function is just over the specified
power. If <code>group</code> is greater than 1, the resulting sample size is the
sample size per group.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>MacCallum, R. C., Browne, M. W., &amp; Sugawara, H. M. (1996). Power analysis
and determination of sample size for covariance structure modeling.
<em>Psychological Methods, 1</em>(2), 130&ndash;149. <a href="https://doi.org/10.1037/1082-989X.1.2.130">doi:10.1037/1082-989X.1.2.130</a>
</p>
<p>Jak, S., Jorgensen, T. D., Verdam, M. G., Oort, F. J., &amp; Elffers, L.
(2021). Analytical power calculations for structural equation modeling:
A tutorial and Shiny app. <em>Behavior Research Methods, 53</em>, 1385&ndash;1406.
<a href="https://doi.org/10.3758/s13428-020-01479-0">doi:10.3758/s13428-020-01479-0</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+plotRMSEApower">plotRMSEApower()</a></code> to plot the statistical power based on
population RMSEA given the sample size
</p>
</li>
<li> <p><code><a href="#topic+plotRMSEAdist">plotRMSEAdist()</a></code> to visualize the RMSEA distributions
</p>
</li>
<li> <p><code><a href="#topic+findRMSEApower">findRMSEApower()</a></code> to find the statistical power based on
population RMSEA given a sample size
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
findRMSEAsamplesize(rmsea0 = .05, rmseaA = .08, df = 20, power = 0.80)

</code></pre>

<hr>
<h2 id='findRMSEAsamplesizenested'>Find sample size given a power in nested model comparison</h2><span id='topic+findRMSEAsamplesizenested'></span>

<h3>Description</h3>

<p>Find the sample size that the power in rejection the samples from the
alternative pair of RMSEA is just over the specified power.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>findRMSEAsamplesizenested(rmsea0A = NULL, rmsea0B = NULL, rmsea1A,
  rmsea1B = NULL, dfA, dfB, power = 0.8, alpha = 0.05, group = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findRMSEAsamplesizenested_+3A_rmsea0a">rmsea0A</code></td>
<td>
<p>The <code class="reqn">H_0</code> baseline RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_rmsea0b">rmsea0B</code></td>
<td>
<p>The <code class="reqn">H_0</code> alternative RMSEA (trivial misfit)</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_rmsea1a">rmsea1A</code></td>
<td>
<p>The <code class="reqn">H_1</code> baseline RMSEA</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_rmsea1b">rmsea1B</code></td>
<td>
<p>The <code class="reqn">H_1</code> alternative RMSEA (target misfit to be rejected)</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_dfa">dfA</code></td>
<td>
<p>degree of freedom of the more-restricted model.</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_dfb">dfB</code></td>
<td>
<p>degree of freedom of the less-restricted model.</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_power">power</code></td>
<td>
<p>The desired statistical power.</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level.</p>
</td></tr>
<tr><td><code id="findRMSEAsamplesizenested_+3A_group">group</code></td>
<td>
<p>The number of group in calculating RMSEA.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bell Clinton
</p>
<p>Pavel Panko (Texas Tech University; <a href="mailto:pavel.panko@ttu.edu">pavel.panko@ttu.edu</a>)
</p>
<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>MacCallum, R. C., Browne, M. W., &amp; Cai, L. (2006). Testing
differences between nested covariance structure models: Power analysis and
null hypotheses. <em>Psychological Methods, 11</em>(1), 19&ndash;35.
<a href="https://doi.org/10.1037/1082-989X.11.1.19">doi:10.1037/1082-989X.11.1.19</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+plotRMSEApowernested">plotRMSEApowernested()</a></code> to plot the statistical power for
nested model comparison based on population RMSEA given the sample size
</p>
</li>
<li> <p><code><a href="#topic+findRMSEApowernested">findRMSEApowernested()</a></code> to find the power for a given
sample size in nested model comparison based on population RMSEA
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
findRMSEAsamplesizenested(rmsea0A = 0, rmsea0B = 0, rmsea1A = 0.06,
                          rmsea1B = 0.05, dfA = 22, dfB = 20, power = 0.80,
                          alpha = .05, group = 1)

</code></pre>

<hr>
<h2 id='FitDiff-class'>Class For Representing A Template of Model Fit Comparisons</h2><span id='topic+FitDiff-class'></span><span id='topic+show+2CFitDiff-method'></span><span id='topic+summary+2CFitDiff-method'></span>

<h3>Description</h3>

<p>This class contains model fit measures and model fit comparisons among
multiple models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'FitDiff'
show(object)

## S4 method for signature 'FitDiff'
summary(object, fit.measures = "default", nd = 3,
  tag = "†")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FitDiff-class_+3A_object">object</code></td>
<td>
<p>object of class <code>FitDiff</code></p>
</td></tr>
<tr><td><code id="FitDiff-class_+3A_fit.measures">fit.measures</code></td>
<td>
<p><code>character</code> vector naming fit indices the user can
request from <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code>. If <code>"default"</code>, the
fit measures will be <code>c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr", "aic", "bic")</code>. If <code>"all"</code>, all available fit
measures will be returned.</p>
</td></tr>
<tr><td><code id="FitDiff-class_+3A_nd">nd</code></td>
<td>
<p>number of digits printed</p>
</td></tr>
<tr><td><code id="FitDiff-class_+3A_tag">tag</code></td>
<td>
<p>single <code>character</code> used to flag the model preferred by each
fit index. To omit tags, set to <code>NULL</code> or <code>NA</code>.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>name</code></dt><dd><p><code>character</code>. The name of each model</p>
</dd>
<dt><code>model.class</code></dt><dd><p><code>character</code>. One class to which each model belongs</p>
</dd>
<dt><code>nested</code></dt><dd><p><code>data.frame</code>. Model fit comparisons between adjacently
nested models that are ordered by their degrees of freedom (<em>df</em>)</p>
</dd>
<dt><code>fit</code></dt><dd><p><code>data.frame</code>. Fit measures of all models specified in the
<code>name</code> slot, ordered by their <em>df</em></p>
</dd>
<dt><code>fit.diff</code></dt><dd><p><code>data.frame</code>. Sequential differences in fit measures in
the <code>fit</code> slot</p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>Objects can be created via the
<code><a href="#topic+compareFit">compareFit()</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compareFit">compareFit()</a></code>; <code><a href="#topic+clipboard">clipboard()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '
fit.config &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school")
## invariance constraints
fit.metric &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
                  group.equal = "loadings")
fit.scalar &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
                  group.equal = c("loadings","intercepts"))
fit.strict &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
                  group.equal = c("loadings","intercepts","residuals"))
measEqOut &lt;- compareFit(fit.config, fit.metric, fit.scalar, fit.strict)
summary(measEqOut)
summary(measEqOut, fit.measures = "all")
summary(measEqOut, fit.measures = c("aic", "bic"))

if(interactive()){
## Save results to a file
saveFile(measEqOut, file = "measEq.txt")

## Copy to a clipboard
clipboard(measEqOut)
}

</code></pre>

<hr>
<h2 id='fmi'>Fraction of Missing Information.</h2><span id='topic+fmi'></span>

<h3>Description</h3>

<p>This function estimates the Fraction of Missing Information (FMI) for
summary statistics of each variable, using either an incomplete data set or
a list of imputed data sets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmi(data, method = "saturated", group = NULL, ords = NULL,
  varnames = NULL, exclude = NULL, return.fit = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fmi_+3A_data">data</code></td>
<td>
<p>Either a single <code>data.frame</code> with incomplete observations,
or a <code>list</code> of imputed data sets.</p>
</td></tr>
<tr><td><code id="fmi_+3A_method">method</code></td>
<td>
<p>character. If <code>"saturated"</code> or <code>"sat"</code> (default),
the model used to estimate FMI is a freely estimated covariance matrix and
mean vector for numeric variables, and/or polychoric correlations and
thresholds for ordered categorical variables, for each group (if
applicable). If <code>"null"</code>, only means and variances are estimated for
numeric variables, and/or thresholds for ordered categorical variables
(i.e., covariances and/or polychoric/polyserial correlations are
constrained to zero). See <strong>Details</strong> for more information.</p>
</td></tr>
<tr><td><code id="fmi_+3A_group">group</code></td>
<td>
<p><code>character</code>. The optional name of a grouping variable, to
request FMI in each group.</p>
</td></tr>
<tr><td><code id="fmi_+3A_ords">ords</code></td>
<td>
<p>Optional <code>character</code> vector naming ordered-categorical
variables, if they are not already stored as class <code>ordered</code> in <code>data</code>.</p>
</td></tr>
<tr><td><code id="fmi_+3A_varnames">varnames</code></td>
<td>
<p>Optional <code>character</code> vector of variable names, to calculate
FMI for a subset of variables in <code>data</code>. By default, all numeric and
<code style="white-space: pre;">&#8288;ordered=&#8288;</code> variables will be included, unless <code style="white-space: pre;">&#8288;data=&#8288;</code> is a single
incomplete <code>data.frame</code>, in which case only numeric variables can be
used with FIML estimation. Other variable types will be removed.</p>
</td></tr>
<tr><td><code id="fmi_+3A_exclude">exclude</code></td>
<td>
<p>Optional <code>character</code> vector naming variables to exclude from
the analysis.</p>
</td></tr>
<tr><td><code id="fmi_+3A_return.fit">return.fit</code></td>
<td>
<p>logical. If <code>TRUE</code>, the fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> model is returned, so FMI can be found from
<code>summary(..., fmi=TRUE)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function estimates a saturated model with <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> for a
single incomplete data set using FIML, or with <code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code>
for a list of imputed data sets. If method = <code>"saturated"</code>, FMI will be
estiamted for all summary statistics, which could take a lot of time with
big data sets. If method = <code>"null"</code>, FMI will only be estimated for
univariate statistics (e.g., means, variances, thresholds). The saturated
model gives more reliable estimates, so it could also help to request a
subset of variables from a large data set.
</p>


<h3>Value</h3>

<p><code>fmi()</code> returns a list with at least 2 of the following:
</p>
<table role = "presentation">
<tr><td><code>Covariances</code></td>
<td>
<p>A list of symmetric matrices: (1) the estimated/pooled
covariance matrix, or a list of group-specific matrices (if applicable)
and (2) a matrix of FMI, or a list of group-specific matrices (if
applicable). Only available if <code>method = "saturated"</code>.  When
<code>method="cor"</code>, this element is replaced by <code>Correlations</code>.</p>
</td></tr>
<tr><td><code>Variances</code></td>
<td>
<p>The estimated/pooled variance for each numeric variable.
Only available if <code>method = "null"</code> (otherwise, it is on the diagonal
of Covariances).</p>
</td></tr>
<tr><td><code>Means</code></td>
<td>
<p>The estimated/pooled mean for each numeric variable.</p>
</td></tr>
<tr><td><code>Thresholds</code></td>
<td>
<p>The estimated/pooled threshold(s) for each
ordered-categorical variable.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mauricio Garnier Villarreal (Vrije Universiteit Amsterdam; <a href="mailto:m.garniervillarreal@vu.nl">m.garniervillarreal@vu.nl</a>)
</p>
<p>Terrence Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>.
New York, NY: Wiley.
</p>
<p>Savalei, V. &amp; Rhemtulla, M. (2012). On obtaining estimates of the fraction
of missing information from full information maximum likelihood.
<em>Structural Equation Modeling, 19</em>(3), 477&ndash;494.
<a href="https://doi.org/10.1080/10705511.2012.687669">doi:10.1080/10705511.2012.687669</a>
</p>
<p>Wagner, J. (2010). The fraction of missing information as a tool for
monitoring the quality of survey data. <em>Public Opinion Quarterly,
74</em>(2), 223&ndash;243. <a href="https://doi.org/10.1093/poq/nfq007">doi:10.1093/poq/nfq007</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HSMiss &lt;- HolzingerSwineford1939[ , c(paste("x", 1:9, sep = ""),
                                      "ageyr","agemo","school")]
set.seed(12345)
HSMiss$x5 &lt;- ifelse(HSMiss$x5 &lt;= quantile(HSMiss$x5, .3), NA, HSMiss$x5)
age &lt;- HSMiss$ageyr + HSMiss$agemo/12
HSMiss$x9 &lt;- ifelse(age &lt;= quantile(age, .3), NA, HSMiss$x9)

## calculate FMI (using FIML, provide partially observed data set)
(out1 &lt;- fmi(HSMiss, exclude = "school"))
(out2 &lt;- fmi(HSMiss, exclude = "school", method = "null"))
(out3 &lt;- fmi(HSMiss, varnames = c("x5","x6","x7","x8","x9")))
(out4 &lt;- fmi(HSMiss, method = "cor", group = "school")) # correlations by group

## significance tests in lavaan(.mi) object
out5 &lt;- fmi(HSMiss, method = "cor", return.fit = TRUE)
summary(out5) # factor loading == SD, covariance = correlation

if(requireNamespace("lavaan.mi")){
  ## ordered-categorical data
  data(binHS5imps, package = "lavaan.mi")

  ## calculate FMI, using list of imputed data sets
  fmi(binHS5imps, group = "school")
}

</code></pre>

<hr>
<h2 id='goricaSEM'>Wrapper for <code>goric.lavaan()</code> from the <code>restriktor</code> package</h2><span id='topic+goricaSEM'></span>

<h3>Description</h3>

<p>The <code>goricaSEM()</code> function is an interface to <code><a href="restriktor.html#topic+goric">restriktor::goric.lavaan()</a></code>,
allowing users to perform generalized order-restricted information criterion
approximation (GORICA) analysis specifically for structural equation
models fitted using the <span class="pkg">lavaan</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goricaSEM(object, ..., hypotheses = NULL, comparison = NULL,
  type = "gorica", standardized = FALSE, debug = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goricaSEM_+3A_object">object</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> object.</p>
</td></tr>
<tr><td><code id="goricaSEM_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="restriktor.html#topic+goric">restriktor::goric.lavaan()</a></code>.</p>
</td></tr>
<tr><td><code id="goricaSEM_+3A_hypotheses">hypotheses</code></td>
<td>
<p>A named <code>list</code> of hypotheses to test. See <strong>Details</strong> for
information on how to specify hypotheses.</p>
</td></tr>
<tr><td><code id="goricaSEM_+3A_comparison">comparison</code></td>
<td>
<p>A <code>character</code> string specifying the type of comparison.
Options are <code>"unconstrained"</code>, <code>"complement"</code>, or <code>"none"</code>.
Default behavior depends on the number of hypotheses.</p>
</td></tr>
<tr><td><code id="goricaSEM_+3A_type">type</code></td>
<td>
<p>A <code>character</code> string indicating the type of analysis, either
<code>"gorica"</code> (default) or <code>"goricac"</code>.</p>
</td></tr>
<tr><td><code id="goricaSEM_+3A_standardized">standardized</code></td>
<td>
<p><code>logical</code> indicating whether standardized estimates are
used in the analysis. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="goricaSEM_+3A_debug">debug</code></td>
<td>
<p><code>logical</code> indicating whether to print debugging information.
Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is designed as a wrapper for the <code><a href="restriktor.html#topic+goric">restriktor::goric.lavaan()</a></code>
function. It calculates GORICA values and weights, which can be used to
compare models or hypotheses under inequality constraints.
</p>
<p>The <code style="white-space: pre;">&#8288;hypotheses=&#8288;</code> argument allows users to specify constraints in text-based
syntax or matrix notation. For text-based syntax, constraints are specified
as a string (e.g., <code>"a1 &gt; a2"</code>). For matrix notation, a named list with
<code style="white-space: pre;">&#8288;$constraints&#8288;</code>, <code style="white-space: pre;">&#8288;$rhs&#8288;</code>, and <code style="white-space: pre;">&#8288;$neq&#8288;</code> elements can be provided.
</p>
<p>The <code style="white-space: pre;">&#8288;comparison=&#8288;</code> argument determines whether the specified hypothesis is
compared against its <code>"complement"</code>, the <code>"unconstrained"</code> model, or
neither (<code>"none"</code>).
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the results of the <code>goric.lavaan</code> function,
including:
</p>

<ul>
<li><p> The log-likelihood.
</p>
</li>
<li><p> Penalty term.
</p>
</li>
<li><p> GORIC(A) values and weights.
</p>
</li>
<li><p> Relative GORIC(A) weights.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Rebecca Kuiper
</p>


<h3>References</h3>

<p>Kuiper, R. M., Hoijtink, H., &amp; Silvapulle, M. J. (2011). An Akaike-type
information criterion for model selection under inequality constraints.
<em>Biometrika, 98</em>(2), 495&ndash;501. <a href="https://doi.org/10.1093/biomet/asr002">doi:10.1093/biomet/asr002</a>
</p>
<p>Vanbrabant, L., Van Loey, N., &amp; Kuiper, R. M. (2020). Evaluating a
theory-based hypothesis against its complement using an AIC-type
information criterion with an application to facial burn injury.
<em>Psychological Methods, 25</em>(2), 129&ndash;142. <a href="https://doi.org/10.1037/met0000238">doi:10.1037/met0000238</a>
</p>


<h3>See Also</h3>

<p><code><a href="restriktor.html#topic+goric">restriktor::goric.lavaan()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example: Perform GORICA analysis on a lavaan model
library(lavaan)
library(restriktor)

## Define the SEM model
model &lt;- '
  ind60 =~ x1 + x2 + x3
  dem60 =~ y1 + a1*y2 + b1*y3 + c1*y4
  dem65 =~ y5 + a2*y6 + b2*y7 + c2*y8
  dem60 ~ ind60
  dem65 ~ ind60 + dem60
  y1 ~~ y5
  y2 ~~ y4 + y6
  y3 ~~ y7
  y4 ~~ y8
  y6 ~~ y8
'

## Fit the model
data(PoliticalDemocracy)
fit &lt;- sem(model, data = PoliticalDemocracy)

## Define hypotheses
myHypothesis &lt;- 'a1 &gt; a2, b1 &gt; b2, c1 &gt; c2'

## Perform GORICA analysis
result &lt;- goricaSEM(fit, hypotheses = list(H1 = myHypothesis),
                    standardized = FALSE, comparison = "complement",
                    type = "gorica")

## Print result
print(result)

</code></pre>

<hr>
<h2 id='htmt'>Assessing Discriminant Validity using Heterotrait&ndash;Monotrait Ratio</h2><span id='topic+htmt'></span>

<h3>Description</h3>

<p>This function assesses discriminant validity through the
heterotrait-monotrait ratio (HTMT) of the correlations (Henseler, Ringlet &amp;
Sarstedt, 2015). Specifically, it assesses the arithmetic (Henseler et al.,
) or geometric (Roemer et al., 2021) mean correlation
among indicators across constructs (i.e. heterotrait&ndash;heteromethod
correlations) relative to the geometric-mean correlation among indicators
within the same construct (i.e. monotrait&ndash;heteromethod correlations).
The resulting HTMT(2) values are interpreted as estimates of inter-construct
correlations. Absolute values of the correlations are recommended to
calculate the HTMT matrix, and are required to calculate HTMT2. Correlations
are estimated using the <code><a href="lavaan.html#topic+lavCor">lavaan::lavCor()</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htmt(model, data = NULL, sample.cov = NULL, missing = "listwise",
  ordered = NULL, absolute = TRUE, htmt2 = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="htmt_+3A_model">model</code></td>
<td>
<p>lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> of a confirmatory factor
analysis model where at least two factors are required for indicators
measuring the same construct.</p>
</td></tr>
<tr><td><code id="htmt_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> or data <code>matrix</code></p>
</td></tr>
<tr><td><code id="htmt_+3A_sample.cov">sample.cov</code></td>
<td>
<p>A covariance or correlation matrix can be used, instead of
<code style="white-space: pre;">&#8288;data=&#8288;</code>, to estimate the HTMT values.</p>
</td></tr>
<tr><td><code id="htmt_+3A_missing">missing</code></td>
<td>
<p>If <code>"listwise"</code>, cases with missing values are removed listwise
from the data frame. If <code>"direct"</code> or <code>"ml"</code> or <code>"fiml"</code> and the estimator is
maximum likelihood, an EM algorithm is used to estimate the unrestricted
covariance matrix (and mean vector). If <code>"pairwise"</code>, pairwise deletion is
used. If <code>"default"</code>, the value is set depending on the estimator and the
mimic option (see details in <code><a href="lavaan.html#topic+lavCor">lavaan::lavCor()</a></code>).</p>
</td></tr>
<tr><td><code id="htmt_+3A_ordered">ordered</code></td>
<td>
<p>Character vector. Only used if object is a <code>data.frame</code>.
Treat these variables as ordered (ordinal) variables. Importantly, all
other variables will be treated as numeric (unless <code>is.ordered</code> in
<code style="white-space: pre;">&#8288;data=&#8288;</code>). See also <code><a href="lavaan.html#topic+lavCor">lavaan::lavCor()</a></code>.</p>
</td></tr>
<tr><td><code id="htmt_+3A_absolute">absolute</code></td>
<td>
<p><code>logical</code> indicating whether HTMT values should be
estimated based on absolute correlations (default is <code>TRUE</code>). This
is recommended for HTMT but required for HTMT2 (so silently ignored).</p>
</td></tr>
<tr><td><code id="htmt_+3A_htmt2">htmt2</code></td>
<td>
<p><code>logical</code> indicating whether to use the geometric mean
(default, appropriate for congeneric indicators) or arithmetic mean
(which assumes tau-equivalence).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix showing HTMT(2) values (i.e., discriminant validity)
between each pair of factors.
</p>


<h3>Author(s)</h3>

<p>Ylenio Longo (University of Nottingham; <a href="mailto:yleniolongo@gmail.com">yleniolongo@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Henseler, J., Ringle, C. M., &amp; Sarstedt, M. (2015). A new criterion for
assessing discriminant validity in variance-based structural equation
modeling. <em>Journal of the Academy of Marketing Science, 43</em>(1),
115&ndash;135. <a href="https://doi.org/10.1007/s11747-014-0403-8">doi:10.1007/s11747-014-0403-8</a>
</p>
<p>Roemer, E., Schuberth, F., &amp; Henseler, J. (2021). HTMT2&mdash;An improved
criterion for assessing discriminant validity in structural equation
modeling. <em>Industrial Management &amp; Data Systems, 121</em>(21), 2637&ndash;2650.
<a href="https://doi.org/10.1108/IMDS-02-2021-0082">doi:10.1108/IMDS-02-2021-0082</a>
</p>
<p>Voorhees, C. M., Brady, M. K., Calantone, R., &amp; Ramirez, E. (2016).
Discriminant validity testing in marketing: An analysis, causes for
concern, and proposed remedies.
<em>Journal of the Academy of Marketing Science, 44</em>(1), 119&ndash;134.
<a href="https://doi.org/10.1007/s11747-015-0455-4">doi:10.1007/s11747-015-0455-4</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

dat &lt;- HolzingerSwineford1939[, paste0("x", 1:9)]
htmt(HS.model, dat)

## save covariance matrix
HS.cov &lt;- cov(HolzingerSwineford1939[, paste0("x", 1:9)])
## HTMT using arithmetic mean
htmt(HS.model, sample.cov = HS.cov, htmt2 = FALSE)

</code></pre>

<hr>
<h2 id='imposeStart'>Specify starting values from a lavaan output</h2><span id='topic+imposeStart'></span>

<h3>Description</h3>

<p>This function will save the parameter estimates of a lavaan output and
impose those parameter estimates as starting values for another analysis
model. The free parameters with the same names or the same labels across two
models will be imposed the new starting values. This function may help to
increase the chance of convergence in a complex model (e.g.,
multitrait-multimethod model or complex longitudinal invariance model).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imposeStart(out, expr, silent = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="imposeStart_+3A_out">out</code></td>
<td>
<p>The <code>lavaan</code> output that users wish to use the parameter
estimates as staring values for an analysis model</p>
</td></tr>
<tr><td><code id="imposeStart_+3A_expr">expr</code></td>
<td>
<p>The original code that users use to run a lavaan model</p>
</td></tr>
<tr><td><code id="imposeStart_+3A_silent">silent</code></td>
<td>
<p>Logical to print the parameter table with new starting values</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted lavaan model
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## The following example show that the longitudinal weak invariance model
## using effect coding was not convergent with three time points but convergent
## with two time points. Thus, the parameter estimates from the model with
## two time points are used as starting values of the three time points.
## The model with new starting values is convergent properly.

weak2time &lt;- '
	# Loadings
	f1t1 =~ LOAD1*y1t1 + LOAD2*y2t1 + LOAD3*y3t1
    f1t2 =~ LOAD1*y1t2 + LOAD2*y2t2 + LOAD3*y3t2

	# Factor Variances
	f1t1 ~~ f1t1
	f1t2 ~~ f1t2

	# Factor Covariances
	f1t1 ~~ f1t2

	# Error Variances
	y1t1 ~~ y1t1
	y2t1 ~~ y2t1
	y3t1 ~~ y3t1
	y1t2 ~~ y1t2
	y2t2 ~~ y2t2
	y3t2 ~~ y3t2

	# Error Covariances
	y1t1 ~~ y1t2
	y2t1 ~~ y2t2
	y3t1 ~~ y3t2

	# Factor Means
	f1t1 ~ NA*1
	f1t2 ~ NA*1

	# Measurement Intercepts
	y1t1 ~ INT1*1
	y2t1 ~ INT2*1
	y3t1 ~ INT3*1
	y1t2 ~ INT4*1
	y2t2 ~ INT5*1
	y3t2 ~ INT6*1

	# Constraints for Effect-coding Identification
	LOAD1 == 3 - LOAD2 - LOAD3
	INT1 == 0 - INT2 - INT3
	INT4 == 0 - INT5 - INT6
'
model2time &lt;- lavaan(weak2time, data = exLong)

weak3time &lt;- '
	# Loadings
	f1t1 =~ LOAD1*y1t1 + LOAD2*y2t1 + LOAD3*y3t1
    f1t2 =~ LOAD1*y1t2 + LOAD2*y2t2 + LOAD3*y3t2
    f1t3 =~ LOAD1*y1t3 + LOAD2*y2t3 + LOAD3*y3t3

	# Factor Variances
	f1t1 ~~ f1t1
	f1t2 ~~ f1t2
	f1t3 ~~ f1t3

	# Factor Covariances
	f1t1 ~~ f1t2 + f1t3
	f1t2 ~~ f1t3

	# Error Variances
	y1t1 ~~ y1t1
	y2t1 ~~ y2t1
	y3t1 ~~ y3t1
	y1t2 ~~ y1t2
	y2t2 ~~ y2t2
	y3t2 ~~ y3t2
	y1t3 ~~ y1t3
	y2t3 ~~ y2t3
	y3t3 ~~ y3t3

	# Error Covariances
	y1t1 ~~ y1t2
	y2t1 ~~ y2t2
	y3t1 ~~ y3t2
	y1t1 ~~ y1t3
	y2t1 ~~ y2t3
	y3t1 ~~ y3t3
	y1t2 ~~ y1t3
	y2t2 ~~ y2t3
	y3t2 ~~ y3t3

	# Factor Means
	f1t1 ~ NA*1
	f1t2 ~ NA*1
	f1t3 ~ NA*1

	# Measurement Intercepts
	y1t1 ~ INT1*1
	y2t1 ~ INT2*1
	y3t1 ~ INT3*1
	y1t2 ~ INT4*1
	y2t2 ~ INT5*1
	y3t2 ~ INT6*1
	y1t3 ~ INT7*1
	y2t3 ~ INT8*1
	y3t3 ~ INT9*1

	# Constraints for Effect-coding Identification
	LOAD1 == 3 - LOAD2 - LOAD3
	INT1 == 0 - INT2 - INT3
	INT4 == 0 - INT5 - INT6
	INT7 == 0 - INT8 - INT9
'
### The following command does not provide convergent result
# model3time &lt;- lavaan(weak3time, data = exLong)

### Use starting values from the model with two time points
model3time &lt;- imposeStart(model2time, lavaan(weak3time, data = exLong))
summary(model3time)

</code></pre>

<hr>
<h2 id='indProd'>Make products of indicators using no centering, mean centering, double-mean
centering, or residual centering</h2><span id='topic+indProd'></span><span id='topic+orthogonalize'></span>

<h3>Description</h3>

<p>The <code>indProd</code> function will make products of indicators using no
centering, mean centering, double-mean centering, or residual centering. The
<code>orthogonalize</code> function is the shortcut of the <code>indProd</code> function
to make the residual-centered indicators products.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>indProd(data, var1, var2, var3 = NULL, match = TRUE, meanC = TRUE,
  residualC = FALSE, doubleMC = TRUE, namesProd = NULL)

orthogonalize(data, var1, var2, var3 = NULL, match = TRUE,
  namesProd = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="indProd_+3A_data">data</code></td>
<td>
<p>The desired data to be transformed.</p>
</td></tr>
<tr><td><code id="indProd_+3A_var1">var1</code></td>
<td>
<p>Names or indices of the variables loaded on the first factor</p>
</td></tr>
<tr><td><code id="indProd_+3A_var2">var2</code></td>
<td>
<p>Names or indices of the variables loaded on the second factor</p>
</td></tr>
<tr><td><code id="indProd_+3A_var3">var3</code></td>
<td>
<p>Names or indices of the variables loaded on the third factor
(for three-way interaction)</p>
</td></tr>
<tr><td><code id="indProd_+3A_match">match</code></td>
<td>
<p>Specify <code>TRUE</code> to use match-paired approach (Marsh, Wen, &amp;
Hau, 2004). If <code>FALSE</code>, the resulting products are all possible
products.</p>
</td></tr>
<tr><td><code id="indProd_+3A_meanc">meanC</code></td>
<td>
<p>Specify <code>TRUE</code> for mean centering the main effect
indicator before making the products</p>
</td></tr>
<tr><td><code id="indProd_+3A_residualc">residualC</code></td>
<td>
<p>Specify <code>TRUE</code> for residual centering the products by
the main effect indicators (Little, Bovaird, &amp; Widaman, 2006).</p>
</td></tr>
<tr><td><code id="indProd_+3A_doublemc">doubleMC</code></td>
<td>
<p>Specify <code>TRUE</code> for centering the resulting products
(Lin et. al., 2010)</p>
</td></tr>
<tr><td><code id="indProd_+3A_namesprod">namesProd</code></td>
<td>
<p>The names of resulting products</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original data attached with the products.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>) Alexander
Schoemann (East Carolina University; <a href="mailto:schoemanna@ecu.edu">schoemanna@ecu.edu</a>)
</p>


<h3>References</h3>

<p>Marsh, H. W., Wen, Z. &amp; Hau, K. T. (2004). Structural equation
models of latent interactions: Evaluation of alternative estimation
strategies and indicator construction. <em>Psychological Methods, 9</em>(3),
275&ndash;300. <a href="https://doi.org/10.1037/1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>
</p>
<p>Lin, G. C., Wen, Z., Marsh, H. W., &amp; Lin, H. S. (2010). Structural equation
models of latent interactions: Clarification of orthogonalizing and
double-mean-centering strategies. <em>Structural Equation Modeling, 17</em>(3),
374&ndash;391. <a href="https://doi.org/10.1080/10705511.2010.488999">doi:10.1080/10705511.2010.488999</a>
</p>
<p>Little, T. D., Bovaird, J. A., &amp; Widaman, K. F. (2006). On the merits of
orthogonalizing powered and product terms: Implications for modeling
interactions among latent variables. <em>Structural Equation Modeling,
13</em>(4), 497&ndash;519. <a href="https://doi.org/10.1207/s15328007sem1304_1">doi:10.1207/s15328007sem1304_1</a>
</p>


<h3>See Also</h3>

 <ul>
<li> <p><code><a href="#topic+probe2WayMC">probe2WayMC()</a></code> For probing the two-way
latent interaction when the results are obtained from mean-centering, or
double-mean centering.  </p>
</li>
<li> <p><code><a href="#topic+probe3WayMC">probe3WayMC()</a></code> For probing the
three-way latent interaction when the results are obtained from
mean-centering, or double-mean centering.  </p>
</li>
<li> <p><code><a href="#topic+probe2WayRC">probe2WayRC()</a></code>
For probing the two-way latent interaction when the results are obtained
from residual-centering approach.  </p>
</li>
<li> <p><code><a href="#topic+probe3WayRC">probe3WayRC()</a></code> For
probing the two-way latent interaction when the results are obtained from
residual-centering approach.  </p>
</li>
<li> <p><code><a href="#topic+plotProbe">plotProbe()</a></code> Plot the simple
intercepts and slopes of the latent interaction.  </p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
## Mean centering / two-way interaction / match-paired
dat &lt;- indProd(attitude[ , -1], var1 = 1:3, var2 = 4:6)

## Residual centering / two-way interaction / match-paired
dat2 &lt;- indProd(attitude[ , -1], var1 = 1:3, var2 = 4:6, match = FALSE,
                meanC = FALSE, residualC = TRUE, doubleMC = FALSE)

## Double-mean centering / two-way interaction / match-paired
dat3 &lt;- indProd(attitude[ , -1], var1 = 1:3, var2 = 4:6, match = FALSE,
                meanC = TRUE, residualC = FALSE, doubleMC = TRUE)

## Mean centering / three-way interaction / match-paired
dat4 &lt;- indProd(attitude[ , -1], var1 = 1:2, var2 = 3:4, var3 = 5:6)

## Residual centering / three-way interaction / match-paired
dat5 &lt;- orthogonalize(attitude[ , -1], var1 = 1:2, var2 = 3:4, var3 = 5:6,
                      match = FALSE)

## Double-mean centering / three-way interaction / match-paired
dat6 &lt;- indProd(attitude[ , -1], var1 = 1:2, var2 = 3:4, var3 = 5:6,
                match = FALSE, meanC = TRUE, residualC = TRUE,
                doubleMC = TRUE)


## To add product-indicators to multiple-imputed data sets

HSMiss &lt;- HolzingerSwineford1939[ , c(paste0("x", 1:9), "ageyr","agemo")]
set.seed(12345)
HSMiss$x5 &lt;- ifelse(HSMiss$x5 &lt;= quantile(HSMiss$x5, .3), NA, HSMiss$x5)
age &lt;- HSMiss$ageyr + HSMiss$agemo/12
HSMiss$x9 &lt;- ifelse(age &lt;= quantile(age, .3), NA, HSMiss$x9)
library(Amelia)
set.seed(12345)
HS.amelia &lt;- amelia(HSMiss, m = 3, p2s = FALSE)
imps &lt;- HS.amelia$imputations # extract a list of imputations
## apply indProd() to the list of data.frames
imps2 &lt;- lapply(imps, indProd,
                var1 = c("x1","x2","x3"), var2 = c("x4","x5","x6"))
## verify:
lapply(imps2, head)


</code></pre>

<hr>
<h2 id='kd'>Generate data via the Kaiser-Dickman (1962) algorithm.</h2><span id='topic+kd'></span>

<h3>Description</h3>

<p>Given a covariance matrix and sample size, generate raw data that correspond
to the covariance matrix.  Data can be generated to match the covariance
matrix exactly, or to be a sample from the population covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kd(covmat, n, type = c("exact", "sample"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kd_+3A_covmat">covmat</code></td>
<td>
<p>a symmetric, positive definite covariance matrix</p>
</td></tr>
<tr><td><code id="kd_+3A_n">n</code></td>
<td>
<p>the sample size for the data that will be generated</p>
</td></tr>
<tr><td><code id="kd_+3A_type">type</code></td>
<td>
<p>type of data generation. <code>exact</code> generates data that
exactly correspond to <code>covmat</code>.  <code>sample</code> treats <code>covmat</code> as
a poulation covariance matrix, generating a sample of size <code>n</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default, R's <code>cov()</code> function divides by <code>n</code>-1.  The data
generated by this algorithm result in a covariance matrix that matches
<code>covmat</code>, but you must divide by <code>n</code> instead of <code>n</code>-1.
</p>


<h3>Value</h3>

<p><code>kd</code> returns a data matrix of dimension <code>n</code> by
<code>nrow(covmat)</code>.
</p>


<h3>Author(s)</h3>

<p>Ed Merkle (University of Missouri; <a href="mailto:merklee@missouri.edu">merklee@missouri.edu</a>)
</p>


<h3>References</h3>

<p>Kaiser, H. F. and Dickman, K. (1962).  Sample and population
score matrices and sample correlation matrices from an arbitrary population
correlation matrix.  <em>Psychometrika, 27</em>(2), 179&ndash;182.
<a href="https://doi.org/10.1007/BF02289635">doi:10.1007/BF02289635</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### First Example

## Get data
dat &lt;- HolzingerSwineford1939[ , 7:15]
hs.n &lt;- nrow(dat)

## Covariance matrix divided by n
hscov &lt;- ((hs.n-1)/hs.n) * cov(dat)

## Generate new, raw data corresponding to hscov
newdat &lt;- kd(hscov, hs.n)

## Difference between new covariance matrix and hscov is minimal
newcov &lt;- (hs.n-1)/hs.n * cov(newdat)
summary(as.numeric(hscov - newcov))

## Generate sample data, treating hscov as population matrix
newdat2 &lt;- kd(hscov, hs.n, type = "sample")

#### Another example

## Define a covariance matrix
covmat &lt;- matrix(0, 3, 3)
diag(covmat) &lt;- 1.5
covmat[2:3,1] &lt;- c(1.3, 1.7)
covmat[3,2] &lt;- 2.1
covmat &lt;- covmat + t(covmat)

## Generate data of size 300 that have this covariance matrix
rawdat &lt;- kd(covmat, 300)

## Covariances are exact if we compute sample covariance matrix by
## dividing by n (vs by n - 1)
summary(as.numeric((299/300)*cov(rawdat) - covmat))

## Generate data of size 300 where covmat is the population covariance matrix
rawdat2 &lt;- kd(covmat, 300)

</code></pre>

<hr>
<h2 id='kurtosis'>Finding excessive kurtosis</h2><span id='topic+kurtosis'></span>

<h3>Description</h3>

<p>Finding excessive kurtosis (<code class="reqn">g_{2}</code>) of an object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kurtosis(object, population = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kurtosis_+3A_object">object</code></td>
<td>
<p>A vector used to find a excessive kurtosis</p>
</td></tr>
<tr><td><code id="kurtosis_+3A_population">population</code></td>
<td>
<p><code>TRUE</code> to compute the parameter formula. <code>FALSE</code>
to compute the sample statistic formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The excessive kurtosis computed by default is <code class="reqn">g_{2}</code>, the fourth
standardized moment of the empirical distribution of <code>object</code>.
The population parameter excessive kurtosis <code class="reqn">\gamma_{2}</code> formula is
</p>
<p style="text-align: center;"><code class="reqn">\gamma_{2} = \frac{\mu_{4}}{\mu^{2}_{2}} - 3,</code>
</p>

<p>where <code class="reqn">\mu_{i}</code> denotes the <code class="reqn">i</code> order central moment.
</p>
<p>The excessive kurtosis formula for sample statistic <code class="reqn">g_{2}</code> is
</p>
<p style="text-align: center;"><code class="reqn">g_{2} = \frac{k_{4}}{k^{2}_{2}} - 3,</code>
</p>

<p>where <code class="reqn">k_{i}</code> are the <code class="reqn">i</code> order <em>k</em>-statistic.
</p>
<p>The standard error of the excessive kurtosis is
</p>
<p style="text-align: center;"><code class="reqn">Var(\hat{g}_{2}) = \frac{24}{N}</code>
</p>

<p>where <code class="reqn">N</code> is the sample size.
</p>


<h3>Value</h3>

<p>A value of an excessive kurtosis with a test statistic if the
population is specified as <code>FALSE</code>
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Weisstein, Eric W. (n.d.). <em>Kurtosis.</em> Retrieved from
<em>MathWorld</em>&ndash;A Wolfram Web Resource:
<a href="http://mathworld.wolfram.com/Kurtosis.html">http://mathworld.wolfram.com/Kurtosis.html</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+skew">skew()</a></code> Find the univariate skewness of a variable
</p>
</li>
<li> <p><code><a href="#topic+mardiaSkew">mardiaSkew()</a></code> Find the Mardia's multivariate
skewness of a set of variables
</p>
</li>
<li> <p><code><a href="#topic+mardiaKurtosis">mardiaKurtosis()</a></code> Find the Mardia's multivariate kurtosis
of a set of variables
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
kurtosis(1:5)

</code></pre>

<hr>
<h2 id='lavaan2emmeans'><code>emmeans</code> Support Functions for <code>lavaan</code> Models</h2><span id='topic+lavaan2emmeans'></span><span id='topic+recover_data.lavaan'></span><span id='topic+emm_basis.lavaan'></span>

<h3>Description</h3>

<p>Provide emmeans support for lavaan objects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recover_data.lavaan(object, lavaan.DV, data = NULL, ...)

emm_basis.lavaan(object, trms, xlev, grid, lavaan.DV, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lavaan2emmeans_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>.
See <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="lavaan2emmeans_+3A_lavaan.dv">lavaan.DV</code></td>
<td>
<p><code>character</code> string naming the variable(s) for which
expected marginal means / trends should be produced.
A vector of names indicates a multivariate outcome, treated by default
as repeated measures.</p>
</td></tr>
<tr><td><code id="lavaan2emmeans_+3A_data">data</code></td>
<td>
<p>An optional <code>data.frame</code> without missing values, to be passed
when <code>missing="FIML"</code> estimation was useed, thus avoiding a reference-grid
with missing values.</p>
</td></tr>
<tr><td><code id="lavaan2emmeans_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>emmeans::recover_data.lm</code> or
<code>emmeans::emm_basis.lm</code></p>
</td></tr>
<tr><td><code id="lavaan2emmeans_+3A_trms">trms</code>, <code id="lavaan2emmeans_+3A_xlev">xlev</code>, <code id="lavaan2emmeans_+3A_grid">grid</code></td>
<td>
<p>See <code>emmeans::emm_basis</code></p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Supported DVs</h4>

<p><code>lavaan.DV</code> must be an <em>endogenous variable</em>, by appearing on
the left-hand side of either a regression operator (<code>"~"</code>)
or an intercept operator (<code>"~1"</code>), or both.
<br /><br />
<code>lavaan.DV</code> can also be a vector of endogenous variable, in which
case they will be treated by <code>emmeans</code> as a multivariate outcome
(often, this indicates repeated measures) represented by an additional
factor named <code>rep.meas</code> by default.  The <code style="white-space: pre;">&#8288;mult.name=&#8288;</code> argument
can be used to overwrite this default name.
</p>



<h4>Unsupported Models</h4>

<p>This functionality does not support the following models:
</p>

<ul>
<li><p> Multi-level models are not supported.
</p>
</li>
<li><p> Models not fit to a <code>data.frame</code> (i.e., models fit to a
covariance matrix).
</p>
</li></ul>




<h4>Dealing with Fixed Parameters</h4>

<p>Fixed parameters (set with <code>lavaan</code>'s modifiers) are treated as-is:
their values are set by the users, and they have a <em>SE</em> of 0 (as such,
they do not co-vary with any other parameter).
</p>



<h4>Dealing with Multigroup Models</h4>

<p>If a multigroup model is supplied, a factor is added to the reference grid,
the name matching the <code>group</code> argument supplied when fitting the model.
<em>Note that you must set</em> <code>nesting = NULL</code>.
</p>



<h4>Dealing with Missing Data</h4>

<p>Limited testing suggests that these functions do work when the model was fit
to incomplete data.
</p>



<h4>Dealing with Factors</h4>

<p>By default <code>emmeans</code> recognizes binary variables (0,1) as a &quot;factor&quot;
with two levels (and not a continuous variable). With some clever contrast
defenitions it should be possible to get the desired emmeans / contasts.
See example below.
</p>



<h3>Author(s)</h3>

<p>Mattan S. Ben-Shachar (Ben-Gurion University of the Negev;
<a href="mailto:matanshm@post.bgu.ac.il">matanshm@post.bgu.ac.il</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

  library(lavaan)
  library(emmeans)

  #### Moderation Analysis ####

  mean_sd &lt;- function(x) mean(x) + c(-sd(x), 0, sd(x))

  model &lt;- '
  # regressions
  Sepal.Length ~ b1 * Sepal.Width + b2 * Petal.Length + b3 * Sepal.Width:Petal.Length


  # define mean parameter label for centered math for use in simple slopes
  Sepal.Width ~ Sepal.Width.mean * 1

  # define variance parameter label for centered math for use in simple slopes
  Sepal.Width ~~ Sepal.Width.var * Sepal.Width

  # simple slopes for condition effect
  SD.below := b2 + b3 * (Sepal.Width.mean - sqrt(Sepal.Width.var))
  mean     := b2 + b3 * (Sepal.Width.mean)
  SD.above := b2 + b3 * (Sepal.Width.mean + sqrt(Sepal.Width.var))
  '

  semFit &lt;- sem(model = model,
                data = iris)

  ## Compare simple slopes
  # From `emtrends`
  test(
    emtrends(semFit, ~ Sepal.Width, "Petal.Length",
             lavaan.DV = "Sepal.Length",
             cov.red = mean_sd)
  )

  # From lavaan
  parameterEstimates(semFit, output = "pretty")[13:15, ]
  # Identical slopes.
  # SEs differ due to lavaan estimating uncertainty of the mean / SD
  # of Sepal.Width, whereas emmeans uses the mean+-SD as is (fixed).


  #### Latent DV ####

  model &lt;- '
  LAT1 =~ Sepal.Length + Sepal.Width

  LAT1 ~ b1 * Petal.Width + 1 * Petal.Length

  Petal.Length ~ Petal.Length.mean * 1

  V1 := 1 * Petal.Length.mean + 1 * b1
  V2 := 1 * Petal.Length.mean + 2 * b1
  '

  semFit &lt;- sem(model = model,
                data = iris, std.lv = TRUE)

  ## Compare emmeans
  # From emmeans
  test(
    emmeans(semFit, ~ Petal.Width,
            lavaan.DV = "LAT1",
            at = list(Petal.Width = 1:2))
  )

  # From lavaan
  parameterEstimates(semFit, output = "pretty")[15:16, ]
  # Identical means.
  # SEs differ due to lavaan estimating uncertainty of the mean
  # of Petal.Length, whereas emmeans uses the mean as is.

  #### Multi-Variate DV ####

  model &lt;- '
  ind60 =~ x1 + x2 + x3

  # metric invariance
  dem60 =~ y1 + a*y2 + b*y3 + c*y4
  dem65 =~ y5 + a*y6 + b*y7 + c*y8

  # scalar invariance
  y1 + y5 ~ d*1
  y2 + y6 ~ e*1
  y3 + y7 ~ f*1
  y4 + y8 ~ g*1

  # regressions (slopes differ: interaction with time)
  dem60 ~ b1*ind60
  dem65 ~ b2*ind60 + NA*1 + Mean.Diff*1

  # residual correlations
  y1 ~~ y5
  y2 ~~ y4 + y6
  y3 ~~ y7
  y4 ~~ y8
  y6 ~~ y8

  # conditional mean differences (besides mean(ind60) == 0)
   low := (-1*b2 + Mean.Diff) - (-1*b1) # 1 SD below M
  high := (b2 + Mean.Diff) - b1         # 1 SD above M
'

  semFit &lt;- sem(model, data = PoliticalDemocracy)


  ## Compare contrasts
  # From emmeans
  emmeans(semFit, pairwise ~ rep.meas|ind60,
          lavaan.DV = c("dem60","dem65"),
          at = list(ind60 = c(-1,1)))[[2]]

  # From lavaan
  parameterEstimates(semFit, output = "pretty")[49:50, ]


  #### Multi Group ####

  model &lt;- 'x1 ~ c(int1, int2)*1 + c(b1, b2)*ageyr
  diff_11 := (int2 + b2*11) - (int1 + b1*11)
  diff_13 := (int2 + b2*13) - (int1 + b1*13)
  diff_15 := (int2 + b2*15) - (int1 + b1*15)
'
  semFit &lt;- sem(model, group = "school", data = HolzingerSwineford1939)


  ## Compare contrasts
  # From emmeans (note `nesting = NULL`)
  emmeans(semFit, pairwise ~ school | ageyr, lavaan.DV = "x1",
          at = list(ageyr = c(11, 13, 15)), nesting = NULL)[[2]]

  # From lavaan
  parameterEstimates(semFit, output = "pretty")

  #### Dealing with factors ####

  warpbreaks &lt;- cbind(warpbreaks,
                      model.matrix(~ wool + tension, data = warpbreaks))

  model &lt;- "
  # Split for convenience
  breaks ~ 1
  breaks ~ woolB
  breaks ~ tensionM + tensionH
  breaks ~ woolB:tensionM + woolB:tensionH
  "

  semFit &lt;- sem(model, warpbreaks)

  ## Compare contrasts
  # From lm -&gt; emmeans
  lmFit &lt;- lm(breaks ~ wool * tension, data = warpbreaks)
  lmEM &lt;- emmeans(lmFit, ~ tension + wool)
  contrast(lmEM, method = data.frame(L_all = c(-1, .05, 0.5),
                                     M_H   = c(0, 1, -1)), by = "wool")

  # From lavaan -&gt; emmeans
  lavEM &lt;- emmeans(semFit, ~ tensionM + tensionH + woolB,
                   lavaan.DV = "breaks")
  contrast(lavEM,
           method = list(
             "L_all|A" = c(c(-1, .05, 0.5, 0), rep(0, 4)),
             "M_H  |A" = c(c(0, 1, -1, 0),     rep(0, 4)),
             "L_all|A" = c(rep(0, 4),          c(-1, .05, 0.5, 0)),
             "M_H  |A" = c(rep(0, 4),          c(0, 1, -1, 0))
           ))

## End(Not run)
</code></pre>

<hr>
<h2 id='lavTestLRT.mi-deprecated'>Likelihood Ratio Test for Multiple Imputations</h2><span id='topic+lavTestLRT.mi-deprecated'></span>

<h3>Description</h3>

<p>Likelihood ratio test (LRT) for lavaan models fitted to multiple imputed
data sets. Statistics for comparing nested models can be calculated by
pooling the likelihood ratios across imputed data sets, as described by
Meng &amp; Rubin (1992), or by pooling the LRT statistics from each imputation,
as described by Li, Meng, Raghunathan, &amp; Rubin (1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lavTestLRT.mi(object, h1 = NULL, test = c("D3","D2"),
              omit.imps = c("no.conv","no.se"),
              asymptotic = FALSE, pool.robust = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lavTestLRT.mi-deprecated_+3A_object">object</code>, <code id="lavTestLRT.mi-deprecated_+3A_h1">h1</code></td>
<td>
<p>An object of class <a href="#topic+OLDlavaan.mi-class">OLDlavaan.mi</a>.
<code>object</code> should be nested within (more constrained than) <code>h1</code>.</p>
</td></tr>
<tr><td><code id="lavTestLRT.mi-deprecated_+3A_test">test</code></td>
<td>
<p><code>character</code> indicating which pooling method to use.
<code>"D3"</code>, <code>"mr"</code>, or <code>"meng.rubin"</code> (default) requests the
method described by Meng &amp; Rubin (1992). <code>"D2"</code>, <code>"LMRR"</code>,
or <code>"Li.et.al"</code> requests the complete-data LRT statistic should be
calculated using each imputed data set, which will then be pooled across
imputations, as described in Li, Meng, Raghunathan, &amp; Rubin (1991).
Find additional details in Enders (2010, chapter 8).</p>
</td></tr>
<tr><td><code id="lavTestLRT.mi-deprecated_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases. Specific imputation numbers can also be included in this
argument, in case users want to  apply their own custom omission criteria
(or simulations can use different numbers of imputations without
redundantly refitting the model).</p>
</td></tr>
<tr><td><code id="lavTestLRT.mi-deprecated_+3A_asymptotic">asymptotic</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code> (default), the pooled test
will be returned as an <em>F</em>-distributed statistic with numerator
(<code>df1</code>) and denominator (<code>df2</code>) degrees of freedom.
If <code>TRUE</code>, the pooled <em>F</em> statistic will be multiplied by its
<code>df1</code> on the assumption that its <code>df2</code> is sufficiently large
enough that the statistic will be asymptotically <code class="reqn">\chi^2</code> distributed
with <code>df1</code>.</p>
</td></tr>
<tr><td><code id="lavTestLRT.mi-deprecated_+3A_pool.robust">pool.robust</code></td>
<td>
<p><code>logical</code>. Ignored unless <code>test = "D2"</code> and a
robust test was requested. If <code>pool.robust = TRUE</code>, the robust test
statistic is pooled, whereas <code>pool.robust = FALSE</code> will pool
the naive test statistic (or difference statistic) and apply the average
scale/shift parameter to it (unavailable for mean- and variance-adjusted
difference statistics, so <code>pool.robust</code> will be set <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="lavTestLRT.mi-deprecated_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code>,
only if <code>test = "D2"</code> and <code>pool.robust = TRUE</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Meng &amp; Rubin (1992) method, also referred to as the <code>"D3"</code>
statistic, is only applicable when using a likelihood-based estimator.
Otherwise (e.g., DWLS for categorical outcomes), users are notified that
<code>test</code> was set to <code>"D2"</code>.
</p>
<p><code>test = "Mplus"</code> implies <code>"D3"</code> and <code>asymptotic = TRUE</code>
(see Asparouhov &amp; Muthen, 2010).
</p>
<p>Note that unlike <code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code>, <code>lavTestLRT</code> can
only be used to compare a single pair of models, not a longer list of
models.  To compare several nested models fitted to multiple imputations,
see examples on the <code><a href="#topic+compareFit">compareFit()</a></code> help page.
</p>


<h3>Value</h3>

<p>A vector containing the LRT statistic (either an <code>F</code> or <code class="reqn">\chi^2</code>
statistic, depending on the <code>asymptotic</code> argument), its degrees of
freedom (numerator and denominator, if <code>asymptotic = FALSE</code>), its
<em>p</em> value, and 2 missing-data diagnostics: the relative invrease
in variance (RIV, or average for multiparameter tests: ARIV) and the
fraction missing information (FMI = ARIV / (1 + ARIV)). Robust statistics
will also include the average (across imputations) scaling factor and
(if relevant) shift parameter(s), unless <code>pool.robust = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>.
New York, NY: Guilford.
</p>
<p>Li, K.-H., Meng, X.-L., Raghunathan, T. E., &amp; Rubin, D. B. (1991).
Significance levels from repeated <em>p</em>-values with multiply-imputed
data. <em>Statistica Sinica, 1</em>(1), 65&ndash;92. Retrieved from
<a href="https://www.jstor.org/stable/24303994">https://www.jstor.org/stable/24303994</a>
</p>
<p>Meng, X.-L., &amp; Rubin, D. B. (1992). Performing likelihood ratio tests with
multiply-imputed data sets. <em>Biometrika, 79</em>(1), 103&ndash;111.
<a href="https://doi.org/10.2307/2337151">doi:10.2307/2337151</a>
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>.
New York, NY: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code>, <code><a href="#topic+compareFit">compareFit()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See the new lavaan.mi package

</code></pre>

<hr>
<h2 id='lavTestScore.mi-deprecated'>Score Test for Multiple Imputations</h2><span id='topic+lavTestScore.mi-deprecated'></span>

<h3>Description</h3>

<p>Score test (or &quot;Lagrange multiplier&quot; test) for lavaan models fitted to
multiple imputed data sets. Statistics for releasing one or more
fixed or constrained parameters in model can be calculated by pooling
the gradient and information matrices pooled across imputed data sets in a
method proposed by Mansolf, Jorgensen, &amp; Enders (2020)&mdash;analogous to
the &quot;D1&quot; Wald test proposed by Li, Meng, Raghunathan, &amp; Rubin's (1991)&mdash;or
by pooling the complete-data score-test statistics across imputed data sets
(i.e., &quot;D2&quot;; Li et al., 1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lavTestScore.mi(object, add = NULL, release = NULL,
                test = c("D2","D1"), scale.W = !asymptotic,
                omit.imps = c("no.conv","no.se"),
                asymptotic = is.null(add),
                univariate = TRUE, cumulative = FALSE,
                epc = FALSE, standardized = epc, cov.std = epc,
                verbose = FALSE, warn = TRUE, information = "expected")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lavTestScore.mi-deprecated_+3A_object">object</code></td>
<td>
<p>An object of class <a href="#topic+OLDlavaan.mi-class">OLDlavaan.mi</a>.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_add">add</code></td>
<td>
<p>Either a <code>character</code> string (typically between single
quotes) or a parameter table containing additional (currently
fixed-to-zero) parameters for which the score test must be computed.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_release">release</code></td>
<td>
<p>Vector of <code>integer</code>s. The indices of the <em>equality</em>
constraints that should be released. The indices correspond to the order of
the equality constraints as they appear in the parameter table.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_test">test</code></td>
<td>
<p><code>character</code> indicating which pooling method to use.
<code>"D1"</code> requests Mansolf, Jorgensen, &amp; Enders' (2020) proposed
Wald-like test for pooling the gradient and information, which are then
used to calculate score-test statistics in the usual manner. <code>"D2"</code>
(default because it is less computationall intensive) requests to pool the
complete-data score-test statistics from each imputed data set, then pool
them across imputations, described by Li et al. (1991) and Enders (2010).</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_scale.w">scale.W</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code>, the pooled
information matrix is calculated as the weighted sum of the
within-imputation and between-imputation components. Otherwise, the pooled
information is calculated by scaling the within-imputation component by
the average relative increase in variance (ARIV; Enders, 2010, p. 235),
which is <em>only</em> consistent when requesting the <em>F</em> test (i.e.,
<code>asymptotic = FALSE</code>.  Ignored (irrelevant) if <code>test = "D2"</code>.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases. Specific imputation numbers can also be included in this
argument, in case users want to  apply their own custom omission criteria
(or simulations can use different numbers of imputations without
redundantly refitting the model).</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_asymptotic">asymptotic</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code> (default when using
<code>add</code> to test adding fixed parameters to the model), the pooled test
will be returned as an <em>F</em>-distributed variable with numerator
(<code>df1</code>) and denominator (<code>df2</code>) degrees of freedom.
If <code>TRUE</code>, the pooled <em>F</em> statistic will be multiplied by its
<code>df1</code> on the assumption that its <code>df2</code> is sufficiently large
enough that the statistic will be asymptotically <code class="reqn">\chi^2</code> distributed
with <code>df1</code>. When using the <code>release</code> argument, <code>asymptotic</code>
will be set to <code>TRUE</code> because (A)RIV can only be calculated for
<code>add</code>ed parameters.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_univariate">univariate</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, compute the univariate
score statistics, one for each constraint.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_cumulative">cumulative</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, order the univariate score
statistics from large to small, and compute a series of multivariate
score statistics, each time including an additional constraint in the test.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_epc">epc</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, and we are releasing existing
constraints, compute the expected parameter changes for the existing
(free) parameters (and any specified with <code>add</code>), if all constraints
were released. For EPCs associated with a particular (1-<em>df</em>)
constraint, only specify one parameter in <code>add</code> or one constraint in
<code>release</code>.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_standardized">standardized</code></td>
<td>
<p>If <code>TRUE</code>, two extra columns (<code>sepc.lv</code> and
<code>sepc.all</code>) in the <code style="white-space: pre;">&#8288;$epc&#8288;</code> table will contain standardized values
for the EPCs. See <code><a href="lavaan.html#topic+lavTestScore">lavaan::lavTestScore()</a></code>.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_cov.std">cov.std</code></td>
<td>
<p><code>logical</code>. See <code><a href="lavaan.html#topic+standardizedSolution">lavaan::standardizedSolution()</a></code>.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>. Not used for now.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_warn">warn</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, print warnings if they occur.</p>
</td></tr>
<tr><td><code id="lavTestScore.mi-deprecated_+3A_information">information</code></td>
<td>
<p><code>character</code> indicating the type of information
matrix to use (check <code><a href="lavaan.html#topic+lavInspect">lavaan::lavInspect()</a></code> for available options).
<code>"expected"</code> information is the default, which provides better
control of Type I errors.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing at least one <code>data.frame</code>:
</p>

<ul>
<li><p><code style="white-space: pre;">&#8288;$test&#8288;</code>: The total score test, with columns for the score
test statistic (<code>X2</code>), its degrees of freedom (<code>df</code>), its
<em>p</em> value under the <code class="reqn">\chi^2</code> distribution (<code>p.value</code>),
and if <code>asymptotic=FALSE</code>, the average relative invrease in
variance (ARIV) used to calculate the denominator <em>df</em> is also
returned as a missing-data diagnostic, along with the fraction missing
information (FMI = ARIV / (1 + ARIV)).
</p>
</li>
<li><p><code style="white-space: pre;">&#8288;$uni&#8288;</code>: Optional (if <code>univariate=TRUE</code>).
Each 1-<em>df</em> score test, equivalent to modification indices. Also
includes EPCs if <code>epc=TRUE</code>, and RIV and FMI if
<code>asymptotic=FALSE</code>.
</p>
</li>
<li><p><code style="white-space: pre;">&#8288;$cumulative&#8288;</code>: Optional (if <code>cumulative=TRUE</code>).
Cumulative score tests, with ARIV and FMI if <code>asymptotic=FALSE</code>.
</p>
</li>
<li><p><code style="white-space: pre;">&#8288;$epc&#8288;</code>: Optional (if <code>epc=TRUE</code>). Parameter estimates,
expected parameter changes, and expected parameter values if ALL
the tested constraints were freed.
</p>
</li></ul>

<p>See <code><a href="lavaan.html#topic+lavTestScore">lavaan::lavTestScore()</a></code> for details.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Adapted from <span class="pkg">lavaan</span> source code, written by
Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p><code>test = "D1"</code> method proposed by
Maxwell Mansolf (University of California, Los Angeles;
<a href="mailto:mamansolf@gmail.com">mamansolf@gmail.com</a>)
</p>


<h3>References</h3>

<p>Bentler, P. M., &amp; Chou, C.-P. (1992). Some new covariance structure model
improvement statistics. <em>Sociological Methods &amp; Research, 21</em>(2),
259&ndash;282. <a href="https://doi.org/10.1177/0049124192021002006">doi:10.1177/0049124192021002006</a>
</p>
<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>.
New York, NY: Guilford.
</p>
<p>Li, K.-H., Meng, X.-L., Raghunathan, T. E., &amp; Rubin, D. B. (1991).
Significance levels from repeated <em>p</em>-values with multiply-imputed
data. <em>Statistica Sinica, 1</em>(1), 65&ndash;92. Retrieved from
<a href="https://www.jstor.org/stable/24303994">https://www.jstor.org/stable/24303994</a>
</p>
<p>Mansolf, M., Jorgensen, T. D., &amp; Enders, C. K. (2020). A multiple
imputation score test for model modification in structural equation
models. <em>Psychological Methods, 25</em>(4), 393&ndash;411.
<a href="https://doi.org/10.1037/met0000243">doi:10.1037/met0000243</a>
</p>


<h3>See Also</h3>

<p><code><a href="lavaan.html#topic+lavTestScore">lavaan::lavTestScore()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See the new lavaan.mi package

</code></pre>

<hr>
<h2 id='lavTestWald.mi-deprecated'>Wald Test for Multiple Imputations</h2><span id='topic+lavTestWald.mi-deprecated'></span>

<h3>Description</h3>

<p>Wald test for testing a linear hypothesis about the parameters of lavaan
models fitted to multiple imputed data sets. Statistics for constraining
one or more free parameters in a model can be calculated from the pooled
point estimates and asymptotic covariance matrix of model parameters
using Rubin's (1987) rules, or by pooling the Wald  test statistics
across imputed data sets (Li, Meng, Raghunathan, &amp; Rubin, 1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lavTestWald.mi(object, constraints = NULL, test = c("D1","D2"),
               asymptotic = FALSE, scale.W = !asymptotic,
               omit.imps = c("no.conv","no.se"),
               verbose = FALSE, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lavTestWald.mi-deprecated_+3A_object">object</code></td>
<td>
<p>An object of class <a href="#topic+OLDlavaan.mi-class">OLDlavaan.mi</a>.</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_constraints">constraints</code></td>
<td>
<p>A <code>character</code> string (typically between single
quotes) containing one or more equality constraints.
See examples for more details</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_test">test</code></td>
<td>
<p><code>character</code> indicating which pooling method to use.
<code>"D1"</code> or <code>"Rubin"</code> (default) indicates Rubin's (1987) rules
will be applied to the point estimates and the asymptotic covariance
matrix of model parameters, and those pooled values will be used to
calculate the Wald test in the usual manner. <code>"D2"</code>, <code>"LMRR"</code>,
or <code>"Li.et.al"</code> indicate that the complete-data Wald test statistic
should be calculated using each imputed data set, which will then be
pooled across imputations, as described in Li, Meng, Raghunathan, &amp; Rubin
(1991) and Enders (2010, chapter 8).</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_asymptotic">asymptotic</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code> (default), the pooled test
will be returned as an <em>F</em>-distributed statistic with numerator
(<code>df1</code>) and denominator (<code>df2</code>) degrees of freedom.
If <code>TRUE</code>, the pooled <em>F</em> statistic will be multiplied by its
<code>df1</code> on the assumption that its <code>df2</code> is sufficiently large
enough that the statistic will be asymptotically <code class="reqn">\chi^2</code> distributed
with <code>df1</code>.</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_scale.w">scale.W</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code>, the pooled
asymptotic covariance matrix of model parameters is calculated as the
weighted sum of the within-imputation and between-imputation components.
Otherwise, the pooled asymptotic covariance matrix of model parameters is
calculated by scaling the within-imputation component by the
average relative increase in variance (ARIV; see Enders, 2010, p. 235),
which is <em>only</em> consistent when requesting the <em>F</em> test (i.e.,
<code>asymptotic = FALSE</code>.  Ignored (irrelevant) if <code>test = "D2"</code>.</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases. Specific imputation numbers can also be included in this
argument, in case users want to  apply their own custom omission criteria
(or simulations can use different numbers of imputations without
redundantly refitting the model).</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, print the restriction
matrix and the estimated restricted values.</p>
</td></tr>
<tr><td><code id="lavTestWald.mi-deprecated_+3A_warn">warn</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, print warnings if they occur.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constraints are specified using the <code>"=="</code> operator.
Both the left-hand side and the right-hand side of the equality can contain
a linear combination of model parameters, or a constant (like zero).
The model parameters must be specified by their user-specified labels from
the <code>link[lavaan]{model.syntax}</code>. Names of defined parameters
(using the &quot;:=&quot; operator) can be included too.
</p>


<h3>Value</h3>

<p>A vector containing the Wald test statistic (either an <code>F</code> or
<code class="reqn">\chi^2</code> statistic, depending on the <code>asymptotic</code> argument),
the degrees of freedom (numerator and denominator, if
<code>asymptotic = FALSE</code>), and a <em>p</em> value. If
<code>asymptotic = FALSE</code>, the relative invrease in variance (RIV, or
average for multiparameter tests: ARIV) used to calculate the denominator
<em>df</em> is also returned as a missing-data diagnostic, along with the
fraction missing information (FMI = ARIV / (1 + ARIV)).
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Adapted from <span class="pkg">lavaan</span> source code, written by
Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>.
New York, NY: Guilford.
</p>
<p>Li, K.-H., Meng, X.-L., Raghunathan, T. E., &amp; Rubin, D. B. (1991).
Significance levels from repeated <em>p</em>-values with multiply-imputed
data. <em>Statistica Sinica, 1</em>(1), 65&ndash;92. Retrieved from
<a href="https://www.jstor.org/stable/24303994">https://www.jstor.org/stable/24303994</a>
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>.
New York, NY: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="lavaan.html#topic+lavTestWald">lavaan::lavTestWald()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See the new lavaan.mi package

</code></pre>

<hr>
<h2 id='loadingFromAlpha'>Find standardized factor loading from coefficient alpha</h2><span id='topic+loadingFromAlpha'></span>

<h3>Description</h3>

<p>Find standardized factor loading from coefficient alpha assuming that all
items have equal loadings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadingFromAlpha(alpha, ni)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="loadingFromAlpha_+3A_alpha">alpha</code></td>
<td>
<p>A desired coefficient alpha value.</p>
</td></tr>
<tr><td><code id="loadingFromAlpha_+3A_ni">ni</code></td>
<td>
<p>A desired number of items.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>result</code></td>
<td>
<p>The standardized factor loadings that make desired
coefficient alpha with specified number of items.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
loadingFromAlpha(0.8, 4)

</code></pre>

<hr>
<h2 id='longInvariance-deprecated'>Measurement Invariance Tests Within Person</h2><span id='topic+longInvariance-deprecated'></span>

<h3>Description</h3>

<p>Testing measurement invariance across timepoints (longitudinal) or any
context involving the use of the same scale in one case (e.g., a dyad case
with husband and wife answering the same scale). The measurement invariance
uses a typical sequence of model comparison tests. This function currently
works with only one scale, and only with continuous indicators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>longInvariance(model, varList, auto = "all", constrainAuto = FALSE,
               fixed.x = TRUE, std.lv = FALSE, group = NULL,
               group.equal = "", group.partial = "", strict = FALSE,
               warn = TRUE, debug = FALSE, quiet = FALSE,
               fit.measures = "default", baseline.model = NULL,
               method = "satorra.bentler.2001", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="longInvariance-deprecated_+3A_model">model</code></td>
<td>
<p>lavaan syntax or parameter table</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_varlist">varList</code></td>
<td>
<p>A list containing indicator names of factors used in the
invariance testing, such as the list that the first element is the vector
of indicator names in the first timepoint and the second element is the
vector of indicator names in the second timepoint. The order of indicator
names should be the same (but measured in different times or different
units).</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_auto">auto</code></td>
<td>
<p>The order of autocorrelation on the measurement errors on the
similar items across factor (e.g., Item 1 in Time 1 and Time 2). If 0 is
specified, the autocorrelation will be not imposed. If 1 is specified,
the autocorrelation will imposed for the adjacent factor listed in
<code>varList</code>. The maximum number can be specified is the number of
factors specified minus 1. If <code>"all"</code> is specified, the maximum
number of order will be used.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_constrainauto">constrainAuto</code></td>
<td>
<p>If <code>TRUE</code>, the function will equate the
auto-<em>covariance</em> to be equal within the same item across factors.
For example, the covariance of item 1 in time 1 and time 2 is equal to
the covariance of item 1 in time 2 and time 3.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_fixed.x">fixed.x</code></td>
<td>
<p>See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_std.lv">std.lv</code></td>
<td>
<p>See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_group">group</code></td>
<td>
<p>See <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_group.equal">group.equal</code></td>
<td>
<p>See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_group.partial">group.partial</code></td>
<td>
<p>See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_strict">strict</code></td>
<td>
<p>If <code>TRUE</code>, the sequence requires strict invariance. See</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_warn">warn</code></td>
<td>
<p>See See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_debug">debug</code></td>
<td>
<p>See See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>. details for more information.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code> (default), a summary is printed out containing
an overview of the different models that are fitted, together with some
model comparison tests. If <code>TRUE</code>, no summary is printed.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_fit.measures">fit.measures</code></td>
<td>
<p>Fit measures used to calculate the differences between
nested models.</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_baseline.model">baseline.model</code></td>
<td>
<p>custom baseline model passed to
<code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code></p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_method">method</code></td>
<td>
<p>The method used to calculate likelihood ratio test. See
<code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code> for available options</p>
</td></tr>
<tr><td><code id="longInvariance-deprecated_+3A_...">...</code></td>
<td>
<p>Additional arguments in the <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>
function. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>strict = FALSE</code>, the following four models are tested in order:
</p>

<ol>
<li><p> Model 1: configural invariance. The same factor structure is
imposed on all units.
</p>
</li>
<li><p> Model 2: weak invariance. The factor loadings are constrained to be
equal across units.
</p>
</li>
<li><p> Model 3: strong invariance. The factor loadings and intercepts are
constrained to be equal across units.
</p>
</li>
<li><p> Model 4: The factor loadings, intercepts and means are constrained to
be equal across units.
</p>
</li></ol>

<p>Each time a more restricted model is fitted, a <code class="reqn">\Delta\chi^2</code> test is
reported, comparing the current model with the previous one, and comparing
the current model to the baseline model (Model 1). In addition, the
difference in CFA is also reported (<code class="reqn">\Delta</code>CFI).
</p>
<p>If <code>strict = TRUE</code>, the following five models are tested in order:
</p>

<ol>
<li><p> Model 1: configural invariance. The same factor structure is imposed
on all units.
</p>
</li>
<li><p> Model 2: weak invariance. The factor loadings are constrained to be
equal across units.
</p>
</li>
<li><p> Model 3: strong invariance. The factor loadings and intercepts are
constrained to be equal across units.
</p>
</li>
<li><p> Model 4: strict invariance. The factor loadings, intercepts and
residual variances are constrained to be equal across units.
</p>
</li>
<li><p> Model 5: The factor loadings, intercepts, residual variances and
means are constrained to be equal across units.
</p>
</li></ol>

<p>Note that if the <code class="reqn">\chi^2</code> test statistic is scaled (eg. a Satorra-Bentler
or Yuan-Bentler test statistic), a special version of the <code class="reqn">\Delta\chi^2</code>
test is used as described in <a href="http://www.statmodel.com/chidiff.shtml">http://www.statmodel.com/chidiff.shtml</a>
</p>


<h3>Value</h3>

<p>Invisibly, all model fits in the sequence are returned as a list.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Vandenberg, R. J., and Lance, C. E. (2000). A review and
synthesis of the measurement invariance literature: Suggestions,
practices, and recommendations for organizational research.
<em>Organizational Research Methods, 3</em>(1), 4&ndash;70.
<a href="https://doi.org/10.1177/109442810031002">doi:10.1177/109442810031002</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- ' f1t1 =~ y1t1 + y2t1 + y3t1
           f1t2 =~ y1t2 + y2t2 + y3t2
			      f1t3 =~ y1t3 + y2t3 + y3t3 '

## Create list of variables
var1 &lt;- c("y1t1", "y2t1", "y3t1")
var2 &lt;- c("y1t2", "y2t2", "y3t2")
var3 &lt;- c("y1t3", "y2t3", "y3t3")
constrainedVar &lt;- list(var1, var2, var3)

## Invariance of the same factor across timepoints
longInvariance(model, auto = 1, constrainAuto = TRUE,
               varList = constrainedVar, data = exLong)

## Invariance of the same factor across timepoints and groups
longInvariance(model, auto = 1, constrainAuto = TRUE,
               varList = constrainedVar, data = exLong, group = "sex",
	              group.equal = c("loadings", "intercepts"))

</code></pre>

<hr>
<h2 id='lrv2ord'>Calculate Population Moments for Ordinal Data Treated as Numeric</h2><span id='topic+lrv2ord'></span>

<h3>Description</h3>

<p>This function calculates ordinal-scale moments implied by LRV-scale moments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lrv2ord(Sigma, Mu, thresholds, cWts)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lrv2ord_+3A_sigma">Sigma</code></td>
<td>
<p>Population covariance <code><a href="base.html#topic+matrix">matrix()</a></code>, with variable names
saved in the <code><a href="base.html#topic+dimnames">dimnames()</a></code> attribute.</p>
</td></tr>
<tr><td><code id="lrv2ord_+3A_mu">Mu</code></td>
<td>
<p>Optional <code>numeric</code> vector of population means. If missing,
all means will be set to zero.</p>
</td></tr>
<tr><td><code id="lrv2ord_+3A_thresholds">thresholds</code></td>
<td>
<p>Either a single <code>numeric</code> vector of population
thresholds used to discretize each normally distributed variable, or a
named <code>list</code> of each discretized variable's vector of thresholds.
The discretized variables may be a subset of all variables in <code>Sigma</code>
if the remaining variables are intended to be observed rather than latent
normally distributed variables.</p>
</td></tr>
<tr><td><code id="lrv2ord_+3A_cwts">cWts</code></td>
<td>
<p>Optional (default when missing is to use 0 for the lowest
category, followed by successive integers for each higher category).
Either a single <code>numeric</code> vector of category weights (if they are
identical across all variables) or a named <code>list</code> of each
discretized variable's vector of category weights.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Binary and ordinal data are frequently accommodated in SEM by incorporating
a threshold model that links each observed categorical response variable to
a corresponding latent response variable that is typically assumed to be
normally distributed (Kamata &amp; Bauer, 2008; Wirth &amp; Edwards, 2007).
This function can be useful for real-data analysis or for designing
Monte Carlo simulations, as described by Jorgensen and Johnson (2022).
</p>


<h3>Value</h3>

<p>A <code>list</code> including the LRV-scale population moments (means,
covariance matrix, correlation matrix, and thresholds), the category
weights, a <code>data.frame</code> of implied univariate moments (means,
<em>SD</em>s, skewness, and excess kurtosis (i.e., in excess of 3, which is
the kurtosis of the normal distribution) for discretized data treated as
<code>numeric</code>, and the implied covariance and correlation matrix of
discretized data treated as <code>numeric</code>.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Andrew R. Johnson (Curtin University; <a href="mailto:andrew.johnson@curtin.edu.au">andrew.johnson@curtin.edu.au</a>)
</p>


<h3>References</h3>

<p>Jorgensen, T. D., &amp; Johnson, A. R. (2022). How to derive expected values of
structural equation model parameters when treating discrete data as
continuous. <em>Structural Equation Modeling, 29</em>(4), 639&ndash;650.
<a href="https://doi.org/10.1080/10705511.2021.1988609">doi:10.1080/10705511.2021.1988609</a>
</p>
<p>Kamata, A., &amp; Bauer, D. J. (2008). A note on the relation between factor
analytic and item response theory models.
<em>Structural Equation Modeling, 15</em>(1), 136&ndash;153.
<a href="https://doi.org/10.1080/10705510701758406">doi:10.1080/10705510701758406</a>
</p>
<p>Wirth, R. J., &amp; Edwards, M. C. (2007). Item factor analysis: Current
approaches and future directions. <em>Psychological Methods, 12</em>(1),
58&ndash;79. <a href="https://doi.org/10.1037/1082-989X.12.1.58">doi:10.1037/1082-989X.12.1.58</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## SCENARIO 1: DIRECTLY SPECIFY POPULATION PARAMETERS

## specify population model in LISREL matrices
Nu &lt;- rep(0, 4)
Alpha &lt;- c(1, -0.5)
Lambda &lt;- matrix(c(1, 1, 0, 0, 0, 0, 1, 1), nrow = 4, ncol = 2,
                 dimnames = list(paste0("y", 1:4), paste0("eta", 1:2)))
Psi &lt;- diag(c(1, .75))
Theta &lt;- diag(4)
Beta &lt;- matrix(c(0, .5, 0, 0), nrow = 2, ncol = 2)

## calculate model-implied population means and covariance matrix
## of latent response variables (LRVs)
IB &lt;- solve(diag(2) - Beta) # to save time and space
Mu_LRV &lt;- Nu + Lambda %*% IB %*% Alpha
Sigma_LRV &lt;- Lambda %*% IB %*% Psi %*% t(IB) %*% t(Lambda) + Theta

## Specify (unstandardized) thresholds to discretize normally distributed data
## generated from Mu_LRV and Sigma_LRV, based on marginal probabilities
PiList &lt;- list(y1 = c(.25, .5, .25),
               y2 = c(.17, .33, .33, .17),
               y3 = c(.1, .2, .4, .2, .1),
               ## make final variable highly asymmetric
               y4 = c(.33, .25, .17, .12, .08, .05))
sapply(PiList, sum) # all sum to 100%
CumProbs &lt;- sapply(PiList, cumsum)
## unstandardized thresholds
TauList &lt;- mapply(qnorm, p = lapply(CumProbs, function(x) x[-length(x)]),
                  m = Mu_LRV, sd = sqrt(diag(Sigma_LRV)))
for (i in 1:4) names(TauList[[i]]) &lt;- paste0(names(TauList)[i], "|t",
                                             1:length(TauList[[i]]))

## assign numeric weights to each category (optional, see default)
NumCodes &lt;- list(y1 = c(-0.5, 0, 0.5), y2 = 0:3, y3 = 1:5, y4 = 1:6)


## Calculate Population Moments for Numerically Coded Ordinal Variables
lrv2ord(Sigma = Sigma_LRV, Mu = Mu_LRV, thresholds = TauList, cWts = NumCodes)


## SCENARIO 2: USE ESTIMATED PARAMETERS AS POPULATION

data(datCat) # already stored as c("ordered","factor")
fit &lt;- cfa(' f =~ 1*u1 + 1*u2 + 1*u3 + 1*u4 ', data = datCat)
lrv2ord(Sigma = fit, thresholds = fit) # use same fit for both
## or use estimated thresholds with specified parameters, but note that
## lrv2ord() will only extract standardized thresholds
dimnames(Sigma_LRV) &lt;- list(paste0("u", 1:4), paste0("u", 1:4))
lrv2ord(Sigma = cov2cor(Sigma_LRV), thresholds = fit)

</code></pre>

<hr>
<h2 id='mardiaKurtosis'>Finding Mardia's multivariate kurtosis</h2><span id='topic+mardiaKurtosis'></span>

<h3>Description</h3>

<p>Finding Mardia's multivariate kurtosis of multiple variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mardiaKurtosis(dat, use = "everything")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mardiaKurtosis_+3A_dat">dat</code></td>
<td>
<p>The target matrix or data frame with multiple variables</p>
</td></tr>
<tr><td><code id="mardiaKurtosis_+3A_use">use</code></td>
<td>
<p>Missing data handling method from the <code><a href="stats.html#topic+cor">stats::cov()</a></code>
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mardia's multivariate kurtosis formula (Mardia, 1970) is
</p>
<p style="text-align: center;"><code class="reqn"> b_{2, d} = \frac{1}{n}\sum^n_{i=1}\left[ \left(\bold{X}_i -
 \bold{\bar{X}} \right)^{'} \bold{S}^{-1} \left(\bold{X}_i -
 \bold{\bar{X}} \right) \right]^2, </code>
</p>

<p>where <code class="reqn">d</code> is the number of variables, <code class="reqn">X</code> is the target
dataset with multiple variables, <code class="reqn">n</code> is the sample size, <code class="reqn">\bold{S}</code>
is the sample covariance matrix of the target dataset, and
<code class="reqn">\bold{\bar{X}}</code> is the mean vectors of the target dataset binded in
<code class="reqn">n</code> rows. When the population multivariate kurtosis is normal, the
<code class="reqn">b_{2,d}</code> is asymptotically distributed as normal distribution with the
mean of <code class="reqn">d(d + 2)</code> and variance of <code class="reqn">8d(d + 2)/n</code>.
</p>


<h3>Value</h3>

<p>A value of a Mardia's multivariate kurtosis with a test statistic
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Mardia, K. V. (1970). Measures of multivariate skewness and
kurtosis with applications. <em>Biometrika, 57</em>(3), 519&ndash;530.
<a href="https://doi.org/10.2307/2334770">doi:10.2307/2334770</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+skew">skew()</a></code> Find the univariate skewness of a variable
</p>
</li>
<li> <p><code><a href="#topic+kurtosis">kurtosis()</a></code> Find the univariate excessive kurtosis
of a variable
</p>
</li>
<li> <p><code><a href="#topic+mardiaSkew">mardiaSkew()</a></code> Find the Mardia's multivariate skewness
of a set of variables
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)
mardiaKurtosis(HolzingerSwineford1939[ , paste0("x", 1:9)])

</code></pre>

<hr>
<h2 id='mardiaSkew'>Finding Mardia's multivariate skewness</h2><span id='topic+mardiaSkew'></span>

<h3>Description</h3>

<p>Finding Mardia's multivariate skewness of multiple variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mardiaSkew(dat, use = "everything")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mardiaSkew_+3A_dat">dat</code></td>
<td>
<p>The target matrix or data frame with multiple variables</p>
</td></tr>
<tr><td><code id="mardiaSkew_+3A_use">use</code></td>
<td>
<p>Missing data handling method from the <code><a href="stats.html#topic+cor">stats::cov()</a></code>
function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Mardia's multivariate skewness formula (Mardia, 1970) is
</p>
<p style="text-align: center;"><code class="reqn"> b_{1, d} = \frac{1}{n^2}\sum^n_{i=1}\sum^n_{j=1}\left[
 \left(\bold{X}_i - \bold{\bar{X}} \right)^{'} \bold{S}^{-1}
 \left(\bold{X}_j - \bold{\bar{X}} \right) \right]^3, </code>
</p>

<p>where <code class="reqn">d</code> is the number of variables, <code class="reqn">X</code> is the target dataset
with multiple variables, <code class="reqn">n</code> is the sample size, <code class="reqn">\bold{S}</code> is
the sample covariance matrix of the target dataset, and <code class="reqn">\bold{\bar{X}}</code>
is the mean vectors of the target dataset binded in <code class="reqn">n</code> rows.
When the population multivariate skewness is normal, the
<code class="reqn">\frac{n}{6}b_{1,d}</code> is asymptotically distributed as <code class="reqn">\chi^2</code>
distribution with <code class="reqn">d(d + 1)(d + 2)/6</code> degrees of freedom.
</p>


<h3>Value</h3>

<p>A value of a Mardia's multivariate skewness with a test statistic
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Mardia, K. V. (1970). Measures of multivariate skewness and
kurtosis with applications. <em>Biometrika, 57</em>(3), 519&ndash;530.
<a href="https://doi.org/10.2307/2334770">doi:10.2307/2334770</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+skew">skew()</a></code> Find the univariate skewness of a variable
</p>
</li>
<li> <p><code><a href="#topic+kurtosis">kurtosis()</a></code> Find the univariate excessive
kurtosis of a variable
</p>
</li>
<li> <p><code><a href="#topic+mardiaKurtosis">mardiaKurtosis()</a></code> Find the Mardia's multivariate
kurtosis of a set of variables
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)
mardiaSkew(HolzingerSwineford1939[ , paste0("x", 1:9)])

</code></pre>

<hr>
<h2 id='maximalRelia'>Calculate maximal reliability</h2><span id='topic+maximalRelia'></span>

<h3>Description</h3>

<p>Calculate maximal reliability of a scale
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maximalRelia(object, omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="maximalRelia_+3A_object">object</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object,
expected to contain only exogenous common factors (i.e., a CFA model).</p>
</td></tr>
<tr><td><code id="maximalRelia_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given that a composite score (<code class="reqn">W</code>) is a weighted sum of item scores:
</p>
<p style="text-align: center;"><code class="reqn"> W = \bold{w}^\prime \bold{x} ,</code>
</p>

<p>where <code class="reqn">\bold{x}</code> is a <code class="reqn">k \times 1</code> vector of the scores of each
item, <code class="reqn">\bold{w}</code> is a <code class="reqn">k \times 1</code> weight vector of each item, and
<code class="reqn">k</code> represents the number of items. Then, maximal reliability is
obtained by finding <code class="reqn">\bold{w}</code> such that reliability attains its maximum
(Li, 1997; Raykov, 2012). Note that the reliability can be obtained by
</p>
<p style="text-align: center;"><code class="reqn"> \rho = \frac{\bold{w}^\prime \bold{S}_T \bold{w}}{\bold{w}^\prime
\bold{S}_X \bold{w}}</code>
</p>

<p>where <code class="reqn">\bold{S}_T</code> is the covariance matrix explained by true scores and
<code class="reqn">\bold{S}_X</code> is the observed covariance matrix. Numerical method is used
to find <code class="reqn">\bold{w}</code> in this function.
</p>
<p>For continuous items, <code class="reqn">\bold{S}_T</code> can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \bold{S}_T = \Lambda \Psi \Lambda^\prime,</code>
</p>

<p>where <code class="reqn">\Lambda</code> is the factor loading matrix and <code class="reqn">\Psi</code> is the
covariance matrix among factors. <code class="reqn">\bold{S}_X</code> is directly obtained by
covariance among items.
</p>
<p>For categorical items, Green and Yang's (2009) method is used for
calculating <code class="reqn">\bold{S}_T</code> and <code class="reqn">\bold{S}_X</code>. The element <code class="reqn">i</code> and
<code class="reqn">j</code> of <code class="reqn">\bold{S}_T</code> can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \left[\bold{S}_T\right]_{ij} = \sum^{C_i - 1}_{c_i = 1} \sum^{C_j -
1}_{c_j - 1} \Phi_2\left( \tau_{x_{c_i}}, \tau_{x_{c_j}}, \left[ \Lambda
\Psi \Lambda^\prime \right]_{ij} \right) - \sum^{C_i - 1}_{c_i = 1}
\Phi_1(\tau_{x_{c_i}}) \sum^{C_j - 1}_{c_j - 1} \Phi_1(\tau_{x_{c_j}}),</code>
</p>

<p>where <code class="reqn">C_i</code> and <code class="reqn">C_j</code> represents the number of thresholds in Items
<code class="reqn">i</code> and <code class="reqn">j</code>, <code class="reqn">\tau_{x_{c_i}}</code> represents the threshold <code class="reqn">c_i</code>
of Item <code class="reqn">i</code>, <code class="reqn">\tau_{x_{c_j}}</code> represents the threshold <code class="reqn">c_i</code> of
Item <code class="reqn">j</code>, <code class="reqn"> \Phi_1(\tau_{x_{c_i}})</code> is the cumulative probability of
<code class="reqn">\tau_{x_{c_i}}</code> given a univariate standard normal cumulative
distribution and <code class="reqn">\Phi_2\left( \tau_{x_{c_i}}, \tau_{x_{c_j}}, \rho
\right)</code> is the joint cumulative probability of <code class="reqn">\tau_{x_{c_i}}</code> and
<code class="reqn">\tau_{x_{c_j}}</code> given a bivariate standard normal cumulative
distribution with a correlation of <code class="reqn">\rho</code>
</p>
<p>Each element of <code class="reqn">\bold{S}_X</code> can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \left[\bold{S}_T\right]_{ij} = \sum^{C_i - 1}_{c_i = 1} \sum^{C_j -
1}_{c_j - 1} \Phi_2\left( \tau_{V_{c_i}}, \tau_{V_{c_j}}, \rho^*_{ij}
\right) - \sum^{C_i - 1}_{c_i = 1} \Phi_1(\tau_{V_{c_i}}) \sum^{C_j -
1}_{c_j - 1} \Phi_1(\tau_{V_{c_j}}),</code>
</p>

<p>where <code class="reqn">\rho^*_{ij}</code> is a polychoric correlation between Items <code class="reqn">i</code>
and <code class="reqn">j</code>.
</p>


<h3>Value</h3>

<p>Maximal reliability values of each group. The maximal-reliability
weights are also provided. Users may extracted the weighted by the
<code>attr</code> function (see example below).
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Li, H. (1997). A unifying expression for the maximal reliability of a linear
composite. <em>Psychometrika, 62</em>(2), 245&ndash;249. <a href="https://doi.org/10.1007/BF02295278">doi:10.1007/BF02295278</a>
</p>
<p>Raykov, T. (2012). Scale construction and development using structural
equation modeling. In R. H. Hoyle (Ed.), <em>Handbook of structural
equation modeling</em> (pp. 472&ndash;494). New York, NY: Guilford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+reliability">reliability()</a></code> for reliability of an unweighted
composite score
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
total &lt;- 'f =~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 '
fit &lt;- cfa(total, data = HolzingerSwineford1939)
maximalRelia(fit)

# Extract the weight
mr &lt;- maximalRelia(fit)
attr(mr, "weight")

</code></pre>

<hr>
<h2 id='measEq.syntax'>Syntax for measurement equivalence</h2><span id='topic+measEq.syntax'></span>

<h3>Description</h3>

<p>Automatically generates <code>lavaan</code> model syntax to specify a confirmatory
factor analysis (CFA) model with equality constraints imposed on
user-specified measurement (or structural) parameters. Optionally returns
the fitted model (if data are provided) representing some chosen level of
measurement equivalence/invariance across groups and/or repeated measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measEq.syntax(configural.model, ..., ID.fac = "std.lv",
  ID.cat = "Wu.Estabrook.2016", ID.thr = c(1L, 2L), group = NULL,
  group.equal = "", group.partial = "", longFacNames = list(),
  longIndNames = list(), long.equal = "", long.partial = "",
  auto = "all", warn = TRUE, debug = FALSE, return.fit = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="measEq.syntax_+3A_configural.model">configural.model</code></td>
<td>
<p>A model with no measurement-invariance constraints
(i.e., representing only configural invariance), unless required for model
identification. <code>configural.model</code> can be either:
</p>

<ul>
<li> <p><code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> or a <code><a href="lavaan.html#topic+parTable">lavaan::parTable()</a></code> specifying the
configural model. Using this option, the user can also provide
either raw <code>data</code> or summary statistics via <code>sample.cov</code>
and (optionally) <code>sample.mean</code>. See argument descriptions in
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>. In order to include thresholds in
the generated syntax, either users must provide raw <code>data</code>,
or the <code>configural.model</code> syntax must specify all thresholds
(see first example). If raw <code>data</code> are not provided, the
number of blocks (groups, levels, or combination) must be
indicated using an arbitrary <code>sample.nobs</code> argument (e.g.,
3 groups could be specified using <code>sample.nobs=rep(1, 3)</code>).
</p>
</li>
<li><p> a fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> model (e.g., as returned by
<code><a href="lavaan.html#topic+cfa">lavaan::cfa()</a></code>) estimating the configural model
</p>
</li></ul>

<p>Note that the specified or fitted model must not contain any latent
structural parameters (i.e., it must be a CFA model), unless they are
higher-order constructs with latent indicators (i.e., a second-order CFA).</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_...">...</code></td>
<td>
<p>Additional arguments (e.g., <code>data</code>, <code>ordered</code>, or
<code>parameterization</code>) passed to the <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>
function. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_id.fac">ID.fac</code></td>
<td>
<p><code>character</code>. The method for identifying common-factor
variances and (if <code>meanstructure = TRUE</code>) means. Three methods are
available, which go by different names in the literature:
</p>

<ul>
<li><p> Standardize the common factor (mean = 0, <em>SD</em> = 1) by
specifying any of: <code>"std.lv"</code>, <code>"unit.variance"</code>,
<code>"UV"</code>, <code>"fixed.factor"</code>,
<code>"fixed-factor"</code>
</p>
</li>
<li><p> Choose a reference indicator by specifying any of:
<code>"auto.fix.first"</code>, <code>"unit.loading"</code>, <code>"UL"</code>,
<code>"marker"</code>, <code>"ref"</code>,  <code>"ref.indicator"</code>,
<code>"reference.indicator"</code>, <code>"reference-indicator"</code>,
<code>"marker.variable"</code>, <code>"marker-variable"</code>
</p>
</li>
<li><p> Apply effects-code constraints to loadings and intercepts by
specifying any of: <code>"FX"</code>, <code>"EC"</code>, <code>"effects"</code>,
<code>"effects.coding"</code>, <code>"effects-coding"</code>,
<code>"effects.code"</code>, <code>"effects-code"</code>
</p>
</li></ul>

<p>See Kloessner &amp; Klopp (2019) for details about all three methods.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_id.cat">ID.cat</code></td>
<td>
<p><code>character</code>. The method for identifying (residual)
variances and intercepts of latent item-responses underlying any
<code>ordered</code> indicators. Four methods are available:
</p>

<ul>
<li><p> To follow Wu &amp; Estabrook's (2016) guidelines (default), specify
any of: <code>"Wu.Estabrook.2016"</code>, <code>"Wu.2016"</code>,
<code>"Wu.Estabrook"</code>, <code>"Wu"</code>, <code>"Wu2016"</code>. For
consistency, specify <code>ID.fac = "std.lv"</code>.
</p>
</li>
<li><p> To use the default settings of M<em>plus</em> and <code>lavaan</code>,
specify any of: <code>"default"</code>, <code>"Mplus"</code>, <code>"Muthen"</code>.
Details provided in Millsap &amp; Tein (2004).
</p>
</li>
<li><p> To use the constraints recommended by Millsap &amp; Tein (2004; see
also Liu et al., 2017, for the longitudinal case)
specify any of: <code>"millsap"</code>, <code>"millsap.2004"</code>,
<code>"millsap.tein.2004"</code>. For consistency, specify
<code>ID.fac = "marker"</code> and <code>parameterization = "theta"</code>.
</p>
</li>
<li><p> To use the default settings of LISREL, specify <code>"LISREL"</code>
or <code>"Joreskog"</code>. Details provided in Millsap &amp; Tein (2004).
For consistency, specify <code>parameterization = "theta"</code>.
</p>
</li></ul>

<p>See <strong>Details</strong> and <strong>References</strong> for more information.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_id.thr">ID.thr</code></td>
<td>
<p><code>integer</code>. Only relevant when
<code>ID.cat = "Millsap.Tein.2004"</code>. Used to indicate which thresholds
should be constrained for identification. The first integer indicates the
threshold used for all indicators, the second integer indicates the
additional threshold constrained for a reference indicator (ignored if
binary).</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_group">group</code></td>
<td>
<p>optional <code>character</code> indicating the name of a grouping
variable. See <code><a href="lavaan.html#topic+cfa">lavaan::cfa()</a></code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_group.equal">group.equal</code></td>
<td>
<p>optional <code>character</code> vector indicating type(s) of
parameter to equate across groups. Ignored if <code>is.null(group)</code>.
See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_group.partial">group.partial</code></td>
<td>
<p>optional <code>character</code> vector or a parameter table
indicating exceptions to <code>group.equal</code> (see
<code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>). Any variables not appearing in the
<code>configural.model</code> will be ignored, and any parameter constraints
needed for identification (e.g., two thresholds per indicator when
<code>ID.cat = "Millsap"</code>) will be removed.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_longfacnames">longFacNames</code></td>
<td>
<p>optional named <code>list</code> of <code>character</code> vectors,
each indicating multiple factors in the model that are actually the same
construct measured repeatedly. See <strong>Details</strong> and <strong>Examples</strong>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_longindnames">longIndNames</code></td>
<td>
<p>optional named <code>list</code> of <code>character</code> vectors,
each indicating multiple indicators in the model that are actually the
same indicator measured repeatedly. See <strong>Details</strong> and
<strong>Examples</strong>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_long.equal">long.equal</code></td>
<td>
<p>optional <code>character</code> vector indicating type(s) of
parameter to equate across repeated measures. Ignored if no factors are
indicated as repeatedly measured in <code>longFacNames</code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_long.partial">long.partial</code></td>
<td>
<p>optional <code>character</code> vector or a parameter table
indicating exceptions to <code>long.equal</code>. Any longitudinal variable
names not  appearing in <code>names(longFacNames)</code> or
<code>names(longIndNames)</code> will be ignored, and any parameter constraints
needed for identification will be removed.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_auto">auto</code></td>
<td>
<p>Used to automatically included autocorrelated measurement errors
among repeatedly measured indicators in <code>longIndNames</code>. Specify a
single <code>integer</code> to set the maximum order (e.g., <code>auto = 1L</code>
indicates that an indicator's unique factors should only be correlated
between adjacently measured occasions). <code>auto = TRUE</code> or <code>"all"</code>
will specify residual covariances among all possible lags per repeatedly
measured indicator in <code>longIndNames</code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_warn">warn</code>, <code id="measEq.syntax_+3A_debug">debug</code></td>
<td>
<p><code>logical</code>. Passed to <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>
and <code><a href="lavaan.html#topic+model.syntax">lavaan::lavParseModelString()</a></code>.
See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax_+3A_return.fit">return.fit</code></td>
<td>
<p><code>logical</code> indicating whether the generated syntax
should be fitted to the provided <code>data</code> (or summary statistics, if
provided via <code>sample.cov</code>). If <code>configural.model</code> is a fitted
lavaan model, the generated syntax will be fitted using the <code>update</code>
method (see <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>), and ... will be passed to
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>. If neither data nor a fitted lavaan model
were provided, this must be <code>FALSE</code>. If <code>TRUE</code>, the generated
<code>measEq.syntax</code> object will be included in the <code>lavaan</code> object's
<code style="white-space: pre;">&#8288;@external&#8288;</code> slot, accessible by <code>fit@external$measEq.syntax</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is a pedagogical and analytical tool to generate model syntax
representing some level of measurement equivalence/invariance across any
combination of multiple groups and/or repeated measures. Support is provided
for confirmatory factor analysis (CFA) models with simple or complex
structure (i.e., cross-loadings and correlated residuals are allowed).
For any complexities that exceed the limits of automation, this function is
intended to still be useful by providing a means to generate syntax that
users can easily edit to accommodate their unique situations.
</p>
<p>Limited support is provided for bifactor models and higher-order constructs.
Because bifactor models have cross-loadings by definition, the option
<code>ID.fac = "effects.code"</code> is unavailable. <code>ID.fac = "UV"</code> is
recommended for bifactor models, but <code>ID.fac = "UL"</code> is available on
the condition that each factor has a unique first indicator in the
<code>configural.model</code>. In order to maintain generality, higher-order
factors may include a mix of manifest and latent indicators, but they must
therefore require <code>ID.fac = "UL"</code> to avoid complications with
differentiating lower-order vs. higher-order (or mixed-level) factors.
The keyword <code>"loadings"</code> in <code>group.equal</code> or <code>long.equal</code>
constrains factor loadings of all manifest indicators (including loadings on
higher-order factors that also have latent indicators), whereas the keyword
<code>"regressions"</code> constrains factor loadings of latent indicators. Users
can edit the model syntax manually to adjust constraints as necessary, or
clever use of the <code>group.partial</code> or <code>long.partial</code> arguments
could make it possible for users to still automated their model syntax.
The keyword <code>"intercepts"</code> constrains the intercepts of all manifest
indicators, and the keyword <code>"means"</code> constrains intercepts and means
of all latent common factors, regardless of whether they are latent
indicators of higher-order factors.  To test equivalence of lower-order and
higher-order intercepts/means in separate steps, the user can either
manually edit their generated syntax or conscientiously exploit the
<code>group.partial</code> or <code>long.partial</code> arguments as necessary.
</p>
<p><strong><code>ID.fac</code>:</strong> If the <code>configural.model</code> fixes any (e.g.,
the first) factor loadings, the generated syntax object will retain those
fixed values. This allows the user to retain additional constraints that
might be necessary (e.g., if there are only 1 or 2 indicators). Some methods
must be used in conjunction with other settings:
</p>

<ul>
<li> <p><code>ID.cat = "Millsap"</code> requires <code>ID.fac = "UL"</code> and
<code>parameterization = "theta"</code>.
</p>
</li>
<li> <p><code>ID.cat = "LISREL"</code> requires <code>parameterization = "theta"</code>.
</p>
</li>
<li> <p><code>ID.fac = "effects.code"</code> is unavailable when there are any
cross-loadings.
</p>
</li></ul>

<p><strong><code>ID.cat</code>:</strong> Wu &amp; Estabrook (2016) recommended constraining
thresholds to equality first, and doing so should allow releasing any
identification constraints no longer needed. For each <code>ordered</code>
indicator, constraining one threshold to equality will allow the item's
intercepts to be estimated in all but the first group or repeated measure.
Constraining a second threshold (if applicable) will allow the item's
(residual) variance to be estimated in all but the first group or repeated
measure. For binary data, there is no independent test of threshold,
intercept, or residual-variance equality. Equivalence of thresholds must
also be assumed for three-category indicators. These guidelines provide the
least restrictive assumptions and tests, and are therefore the default.
</p>
<p>The default setting in M<em>plus</em> is similar to Wu &amp; Estabrook (2016),
except that intercepts are always constrained to zero (so they are assumed
to be invariant without testing them). Millsap &amp; Tein (2004) recommended
<code>parameterization = "theta"</code> and identified an item's residual variance
in all but the first group (or occasion; Liu et al., 2017) by constraining
its intercept to zero and one of its thresholds to equality. A second
threshold for the reference indicator (so <code>ID.fac = "UL"</code>) is used to
identify the common-factor means in all but the first group/occasion. The
LISREL software fixes the first threshold to zero and (if applicable) the
second threshold to 1, and assumes any remaining thresholds to be equal
across groups / repeated measures; thus, the intercepts are always
identified, and residual variances (<code>parameterization = "theta"</code>) are
identified except for binary data, when they are all fixed to one.
</p>
<p><strong>Repeated Measures:</strong> If each repeatedly measured factor is measured
by the same indicators (specified in the same order in the
<code>configural.model</code>) on each occasion, without any cross-loadings, the
user can let <code>longIndNames</code> be automatically generated. Generic names
for the repeatedly measured indicators are created using the name of the
repeatedly measured factors (i.e., <code>names(longFacNames)</code>) and the
number of indicators. So the repeatedly measured first indicator
(<code>"ind"</code>) of a longitudinal construct called &quot;factor&quot; would be
generated as <code>"._factor_ind.1"</code>.
</p>
<p>The same types of parameter can be specified for <code>long.equal</code> as for
<code>group.equal</code> (see <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code> for a list), except
for <code>"residual.covariances"</code> or <code>"lv.covariances"</code>. Instead, users
can constrain <em>auto</em>covariances using keywords <code>"resid.autocov"</code>
or <code>"lv.autocov"</code>. Note that <code>group.equal = "lv.covariances"</code> or
<code>group.equal = "residual.covariances"</code> will constrain any
autocovariances across groups, along with any other covariances the user
specified in the <code>configural.model</code>. Note also that autocovariances
cannot be specified as exceptions in <code>long.partial</code>, so anything more
complex than the <code>auto</code> argument automatically provides should instead
be manually specified in the <code>configural.model</code>.
</p>
<p>When users set <code>orthogonal=TRUE</code> in the <code>configural.model</code> (e.g.,
in bifactor models of repeatedly measured constructs), autocovariances of
each repeatedly measured factor will still be freely estimated in the
generated syntax.
</p>
<p><strong>Missing Data:</strong> If users wish to utilize the <code><a href="#topic+auxiliary">auxiliary()</a></code>
function to automatically include auxiliary variables in conjunction with
<code>missing = "FIML"</code>, they should first generate the hypothesized-model
syntax, then submit that syntax as the model to <code>auxiliary()</code>.
If users utilized <code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code> to fit their <code>configural.model</code>
to multiply imputed data, that model can also be passed to the
<code>configural.model</code> argument, and if <code>return.fit = TRUE</code>, the
generated model will be fitted to the multiple imputations.
</p>


<h3>Value</h3>

<p>By default, an object of class <a href="#topic+measEq.syntax-class">measEq.syntax</a>.
If <code>return.fit = TRUE</code>, a fitted <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>
model, with the <code>measEq.syntax</code> object stored in the
<code style="white-space: pre;">&#8288;@external&#8288;</code> slot, accessible by <code>fit@external$measEq.syntax</code>.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Kloessner, S., &amp; Klopp, E. (2019). Explaining constraint interaction: How
to interpret estimated model parameters under alternative scaling methods.
<em>Structural Equation Modeling, 26</em>(1), 143&ndash;155.
<a href="https://doi.org/10.1080/10705511.2018.1517356">doi:10.1080/10705511.2018.1517356</a>
</p>
<p>Liu, Y., Millsap, R. E., West, S. G., Tein, J.-Y., Tanaka, R., &amp; Grimm,
K. J. (2017). Testing measurement invariance in longitudinal data with
ordered-categorical measures. <em>Psychological Methods, 22</em>(3),
486&ndash;506. <a href="https://doi.org/10.1037/met0000075">doi:10.1037/met0000075</a>
</p>
<p>Millsap, R. E., &amp; Tein, J.-Y. (2004). Assessing factorial invariance in
ordered-categorical measures. <em>Multivariate Behavioral Research, 39</em>(3),
479&ndash;515. <a href="https://doi.org/10.1207/S15327906MBR3903_4">doi:10.1207/S15327906MBR3903_4</a>
</p>
<p>Wu, H., &amp; Estabrook, R. (2016). Identification of confirmatory factor
analysis models of different levels of invariance for ordered categorical
outcomes. <em>Psychometrika, 81</em>(4), 1014&ndash;1045.
<a href="https://doi.org/10.1007/s11336-016-9506-0">doi:10.1007/s11336-016-9506-0</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compareFit">compareFit()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod.cat &lt;- ' FU1 =~ u1 + u2 + u3 + u4
             FU2 =~ u5 + u6 + u7 + u8 '
## the 2 factors are actually the same factor (FU) measured twice
longFacNames &lt;- list(FU = c("FU1","FU2"))

## CONFIGURAL model: no constraints across groups or repeated measures
syntax.config &lt;- measEq.syntax(configural.model = mod.cat,
                               # NOTE: data provides info about numbers of
                               #       groups and thresholds
                               data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", ID.cat = "Wu.Estabrook.2016",
                               group = "g", longFacNames = longFacNames)
## print lavaan syntax to the Console
cat(as.character(syntax.config))
## print a summary of model features
summary(syntax.config)

## THRESHOLD invariance:
## only necessary to specify thresholds if you have no data
mod.th &lt;- '
  u1 | t1 + t2 + t3 + t4
  u2 | t1 + t2 + t3 + t4
  u3 | t1 + t2 + t3 + t4
  u4 | t1 + t2 + t3 + t4
  u5 | t1 + t2 + t3 + t4
  u6 | t1 + t2 + t3 + t4
  u7 | t1 + t2 + t3 + t4
  u8 | t1 + t2 + t3 + t4
'
syntax.thresh &lt;- measEq.syntax(configural.model = c(mod.cat, mod.th),
                               # NOTE: data not provided, so syntax must
                               #       include thresholds, and number of
                               #       groups == 2 is indicated by:
                               sample.nobs = c(1, 1),
                               parameterization = "theta",
                               ID.fac = "std.lv", ID.cat = "Wu.Estabrook.2016",
                               group = "g", group.equal = "thresholds",
                               longFacNames = longFacNames,
                               long.equal = "thresholds")
## notice that constraining 4 thresholds allows intercepts and residual
## variances to be freely estimated in all but the first group &amp; occasion
cat(as.character(syntax.thresh))
## print a summary of model features
summary(syntax.thresh)


## Fit a model to the data either in a subsequent step (recommended):
mod.config &lt;- as.character(syntax.config)
fit.config &lt;- cfa(mod.config, data = datCat, group = "g",
                  ordered = paste0("u", 1:8), parameterization = "theta")
## or in a single step (not generally recommended):
fit.thresh &lt;- measEq.syntax(configural.model = mod.cat, data = datCat,
                            ordered = paste0("u", 1:8),
                            parameterization = "theta",
                            ID.fac = "std.lv", ID.cat = "Wu.Estabrook.2016",
                            group = "g", group.equal = "thresholds",
                            longFacNames = longFacNames,
                            long.equal = "thresholds", return.fit = TRUE)
## compare their fit to test threshold invariance
anova(fit.config, fit.thresh)


## --------------------------------------------------------
## RECOMMENDED PRACTICE: fit one invariance model at a time
## --------------------------------------------------------

## - A downside of setting return.fit=TRUE is that if the model has trouble
##   converging, you don't have the opportunity to investigate the syntax,
##   or even to know whether an error resulted from the syntax-generator or
##   from lavaan itself.
## - A downside of automatically fitting an entire set of invariance models
##   (like the old measurementInvariance() function did) is that you might
##   end up testing models that shouldn't even be fitted because less
##   restrictive models already fail (e.g., don't test full scalar
##   invariance if metric invariance fails! Establish partial metric
##   invariance first, then test equivalent of intercepts ONLY among the
##   indicators that have invariate loadings.)

## The recommended sequence is to (1) generate and save each syntax object,
## (2) print it to the screen to verify you are fitting the model you expect
## to (and potentially learn which identification constraints should be
## released when equality constraints are imposed), and (3) fit that model
## to the data, as you would if you had written the syntax yourself.

## Continuing from the examples above, after establishing invariance of
## thresholds, we proceed to test equivalence of loadings and intercepts
##   (metric and scalar invariance, respectively)
## simultaneously across groups and repeated measures.



## metric invariance
syntax.metric &lt;- measEq.syntax(configural.model = mod.cat, data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", ID.cat = "Wu.Estabrook.2016",
                               group = "g", longFacNames = longFacNames,
                               group.equal = c("thresholds","loadings"),
                               long.equal  = c("thresholds","loadings"))
summary(syntax.metric)                    # summarize model features
mod.metric &lt;- as.character(syntax.metric) # save as text
cat(mod.metric)                           # print/view lavaan syntax
## fit model to data
fit.metric &lt;- cfa(mod.metric, data = datCat, group = "g",
                  ordered = paste0("u", 1:8), parameterization = "theta")
## test equivalence of loadings, given equivalence of thresholds
anova(fit.thresh, fit.metric)

## scalar invariance
syntax.scalar &lt;- measEq.syntax(configural.model = mod.cat, data = datCat,
                               ordered = paste0("u", 1:8),
                               parameterization = "theta",
                               ID.fac = "std.lv", ID.cat = "Wu.Estabrook.2016",
                               group = "g", longFacNames = longFacNames,
                               group.equal = c("thresholds","loadings",
                                               "intercepts"),
                               long.equal  = c("thresholds","loadings",
                                               "intercepts"))
summary(syntax.scalar)                    # summarize model features
mod.scalar &lt;- as.character(syntax.scalar) # save as text
cat(mod.scalar)                           # print/view lavaan syntax
## fit model to data
fit.scalar &lt;- cfa(mod.scalar, data = datCat, group = "g",
                  ordered = paste0("u", 1:8), parameterization = "theta")
## test equivalence of intercepts, given equal thresholds &amp; loadings
anova(fit.metric, fit.scalar)


## For a single table with all results, you can pass the models to
## summarize to the compareFit() function
Comparisons &lt;- compareFit(fit.config, fit.thresh, fit.metric, fit.scalar)
summary(Comparisons)


## ------------------------------------------------------
## NOT RECOMMENDED: fit several invariance models at once
## ------------------------------------------------------
test.seq &lt;- c("thresholds","loadings","intercepts","means","residuals")
meq.list &lt;- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label &lt;- "configural"
    group.equal &lt;- ""
    long.equal &lt;- ""
  } else {
    meq.label &lt;- test.seq[i]
    group.equal &lt;- test.seq[1:i]
    long.equal &lt;- test.seq[1:i]
  }
  meq.list[[meq.label]] &lt;- measEq.syntax(configural.model = mod.cat,
                                         data = datCat,
                                         ordered = paste0("u", 1:8),
                                         parameterization = "theta",
                                         ID.fac = "std.lv",
                                         ID.cat = "Wu.Estabrook.2016",
                                         group = "g",
                                         group.equal = group.equal,
                                         longFacNames = longFacNames,
                                         long.equal = long.equal,
                                         return.fit = TRUE)
}

evalMeasEq &lt;- compareFit(meq.list)
summary(evalMeasEq)


## -----------------
## Binary indicators
## -----------------

## borrow example data from Mplus user guide
myData &lt;- read.table("http://www.statmodel.com/usersguide/chap5/ex5.16.dat")
names(myData) &lt;- c("u1","u2","u3","u4","u5","u6","x1","x2","x3","g")
bin.mod &lt;- '
  FU1 =~ u1 + u2 + u3
  FU2 =~ u4 + u5 + u6
'
## Must SIMULTANEOUSLY constrain thresholds, loadings, and intercepts
test.seq &lt;- list(strong = c("thresholds","loadings","intercepts"),
                 means = "means",
                 strict = "residuals")
meq.list &lt;- list()
for (i in 0:length(test.seq)) {
  if (i == 0L) {
    meq.label &lt;- "configural"
    group.equal &lt;- ""
    long.equal &lt;- ""
  } else {
    meq.label &lt;- names(test.seq)[i]
    group.equal &lt;- unlist(test.seq[1:i])
    # long.equal &lt;- unlist(test.seq[1:i])
  }
  meq.list[[meq.label]] &lt;- measEq.syntax(configural.model = bin.mod,
                                         data = myData,
                                         ordered = paste0("u", 1:6),
                                         parameterization = "theta",
                                         ID.fac = "std.lv",
                                         ID.cat = "Wu.Estabrook.2016",
                                         group = "g",
                                         group.equal = group.equal,
                                         #longFacNames = longFacNames,
                                         #long.equal = long.equal,
                                         return.fit = TRUE)
}

evalMeasEq &lt;- compareFit(meq.list)
summary(evalMeasEq)



## ---------------------
## Multilevel Invariance
## ---------------------

## To test invariance across levels in a MLSEM, specify syntax as though
## you are fitting to 2 groups instead of 2 levels.

mlsem &lt;- ' f1 =~ y1 + y2 + y3
           f2 =~ y4 + y5 + y6 '
## metric invariance
syntax.metric &lt;- measEq.syntax(configural.model = mlsem, meanstructure = TRUE,
                               ID.fac = "std.lv", sample.nobs = c(1, 1),
                               group = "cluster", group.equal = "loadings")
## by definition, Level-1 means must be zero, so fix them
syntax.metric &lt;- update(syntax.metric,
                        change.syntax = paste0("y", 1:6, " ~ c(0, NA)*1"))
## save as a character string
mod.metric &lt;- as.character(syntax.metric, groups.as.blocks = TRUE)
## convert from multigroup to multilevel
mod.metric &lt;- gsub(pattern = "group:", replacement = "level:",
                   x = mod.metric, fixed = TRUE)
## fit model to data
fit.metric &lt;- lavaan(mod.metric, data = Demo.twolevel, cluster = "cluster")
summary(fit.metric)

</code></pre>

<hr>
<h2 id='measEq.syntax-class'>Class for Representing a Measurement-Equivalence Model</h2><span id='topic+measEq.syntax-class'></span><span id='topic+show+2CmeasEq.syntax-method'></span><span id='topic+summary+2CmeasEq.syntax-method'></span><span id='topic+as.character+2CmeasEq.syntax-method'></span><span id='topic+update+2CmeasEq.syntax-method'></span>

<h3>Description</h3>

<p>This class of object stores information used to automatically generate
lavaan model syntax to represent user-specified levels of measurement
equivalence/invariance across groups and/or repeated measures. See
<code><a href="#topic+measEq.syntax">measEq.syntax()</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'measEq.syntax'
as.character(x, package = "lavaan",
  params = NULL, single = TRUE, groups.as.blocks = FALSE)

## S4 method for signature 'measEq.syntax'
show(object)

## S4 method for signature 'measEq.syntax'
summary(object, verbose = TRUE)

## S4 method for signature 'measEq.syntax'
update(object, ..., evaluate = TRUE,
  change.syntax = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="measEq.syntax-class_+3A_x">x</code>, <code id="measEq.syntax-class_+3A_object">object</code></td>
<td>
<p>an object of class <code>measEq.syntax</code></p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_package">package</code></td>
<td>
<p><code>character</code> indicating the package for which the model
syntax should be generated.  Currently, only <code>"lavaan"</code> and
<code>"mplus"</code> are supported.</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_params">params</code></td>
<td>
<p><code>character</code> vector indicating which type(s) of parameter
to print syntax for. Must match a type that can be passed to
<code>group.equal</code> or <code>long.equal</code>, but <code>"residual.covariances"</code>
and <code>"lv.covariances"</code> will be silently ignored. Instead, requesting
<code>"residuals"</code> or <code>"lv.variances"</code> will return covariances along
with variances. By default (<code>NULL</code>), all types are printed.</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_single">single</code></td>
<td>
<p><code>logical</code> indicating whether to concatenate lavaan
<code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> into a single <code>character</code> string.
Setting <code>FALSE</code> will return a vector of strings, which may be
convenient (or even necessary to prevent an error) in
models with long variable names, many variables, or many groups.</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_groups.as.blocks">groups.as.blocks</code></td>
<td>
<p><code>logical</code> indicating whether to write lavaan
<code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> using vectors of labels and values
for multiple groups (the default: <code>FALSE</code>), or whether to write
a separate &quot;block&quot; of syntax per group. The block structure could allow
users to apply the generated multigroup syntax (after some editing) to
test invariance across levels in a multilevel SEM (see final example on
<code><a href="#topic+measEq.syntax">measEq.syntax()</a></code> help page).</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code> indicating whether to print a summary to the
screen (default). If <code>FALSE</code>, only a pattern matrix is returned.</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_...">...</code></td>
<td>
<p>Additional arguments to the <code>call</code>, or arguments with
changed values.</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_evaluate">evaluate</code></td>
<td>
<p>If <code>TRUE</code>, evaluate the new <code>call</code>; otherwise,
return the new <code>call</code>.</p>
</td></tr>
<tr><td><code id="measEq.syntax-class_+3A_change.syntax">change.syntax</code></td>
<td>
<p><code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> specifying
labels or fixed/free values of parameters in <code>object</code>.
These provide some flexibility to customize
existing parameters without having to copy/paste the output of
<code>as.character(object)</code> into an R script. For example,
<code>group.partial</code> will free a parameter across all groups, but
<code>update</code> allows users to free the parameter in just one group
while maintaining equality constraints among other groups.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>summary</code></td>
<td>
<p><code>signature(object = "measEq.syntax", verbose = TRUE)</code>:
A <code>character</code> matrix indicating the pattern of <code>numeric</code>,
<code>ordered</code>, or latent indicators loading on common factors.
By default (<code>verbose = TRUE</code>), <code>summary</code> also prints descriptive
details about the model, including the numbers of indicators and factors,
and which parameters are constrained to equality.</p>
</td></tr>
<tr><td><code>show</code></td>
<td>
<p><code>signature(object = "measEq.syntax")</code>: Prints a message
about how to use the <code>object</code> for model fitting. Invisibly
returns the <code>object</code>.</p>
</td></tr>
<tr><td><code>update</code></td>
<td>
<p><code>signature(object = "measEq.syntax", ..., evaluate = TRUE, change.syntax = NULL)</code>: Creates a new
<code>object</code> with updated arguments in <code>...</code>, or updated
parameter labels or fixed/free specifications in <code>object</code>.</p>
</td></tr>
<tr><td><code>as.character</code></td>
<td>
<p><code>signature(x = "measEq.syntax", package = "lavaan")</code>:
Converts the <code>measEq.syntax</code> object to model syntax that can be
copy/pasted or written to a syntax file to be edited before analysis,
or simply passed to <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> to fit the model to
data. Generated M<em>plus</em> syntax could also be utilized using the
<span class="pkg">MplusAuthomation</span> package.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>package</code></dt><dd><p><code>character</code> indicating the software package used to
represent the model. Currently, only <code>"lavaan"</code> is available, which
uses the LISREL representation (see <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>).
In the future, <code>"OpenMx"</code> may become available, using RAM
representation.</p>
</dd>
<dt><code>model.type</code></dt><dd><p><code>character</code>. Currently, only &quot;cfa&quot; is available.
Future versions may allow for MIMIC / RFA models, where invariance can be
tested across levels of exogenous variables explicitly included as
predictors of indicators, controlling for their effects on (or correlation
with) the common factors.</p>
</dd>
<dt><code>call</code></dt><dd><p>The function call as returned by <code>match.call()</code>, with
some arguments updated if necessary for logical consistency.</p>
</dd>
<dt><code>meanstructure</code></dt><dd><p><code>logical</code> indicating whether a mean structure is
included in the model.</p>
</dd>
<dt><code>numeric</code></dt><dd><p><code>character</code> vector naming <code>numeric</code> manifest indicators.</p>
</dd>
<dt><code>ordered</code></dt><dd><p><code>character</code> vector naming <code>ordered</code> indicators.</p>
</dd>
<dt><code>parameterization</code></dt><dd><p><code>character</code>. See <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</dd>
<dt><code>specify</code></dt><dd><p><code>list</code> of parameter matrices, similar in form to the
output of <code>lavInspect(fit, "free")</code>. These matrices
are <code>logical</code>, indicating whether each parameter should be specified
in the model syntax.</p>
</dd>
<dt><code>values</code></dt><dd><p><code>list</code> of parameter matrices, similar in form to the
output of <code>lavInspect(fit, "free")</code>. These matrices
are <code>numeric</code>, indicating whether each parameter should be freely
estimated (indicated by <code>NA</code>) or fixed to a particular value.</p>
</dd>
<dt><code>labels</code></dt><dd><p><code>list</code> of parameter matrices, similar in form to the
output of <code>lavInspect(fit, "free")</code>. These matrices
contain <code>character</code> labels used to constrain parameters to equality.</p>
</dd>
<dt><code>constraints</code></dt><dd><p><code>character</code> vector containing additional equality
constraints used to identify the model when <code>ID.fac = "fx"</code>.</p>
</dd>
<dt><code>ngroups</code></dt><dd><p><code>integer</code> indicating the number of groups.</p>
</dd>
</dl>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See ?measEq.syntax help page for examples using lavaan


</code></pre>

<hr>
<h2 id='measurementInvariance-deprecated'>Measurement Invariance Tests</h2><span id='topic+measurementInvariance-deprecated'></span>

<h3>Description</h3>

<p>Testing measurement invariance across groups using a typical sequence of
model comparison tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measurementInvariance(..., std.lv = FALSE, strict = FALSE, quiet = FALSE,
                      fit.measures = "default", baseline.model = NULL,
                      method = "satorra.bentler.2001")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="measurementInvariance-deprecated_+3A_...">...</code></td>
<td>
<p>The same arguments as for any lavaan model.  See
<code><a href="lavaan.html#topic+cfa">lavaan::cfa()</a></code> for more information.</p>
</td></tr>
<tr><td><code id="measurementInvariance-deprecated_+3A_std.lv">std.lv</code></td>
<td>
<p>If <code>TRUE</code>, the fixed-factor method of scale
identification is used. If <code>FALSE</code>, the first variable for each factor
is used as marker variable.</p>
</td></tr>
<tr><td><code id="measurementInvariance-deprecated_+3A_strict">strict</code></td>
<td>
<p>If <code>TRUE</code>, the sequence requires &lsquo;strict&rsquo; invariance.
See details for more information.</p>
</td></tr>
<tr><td><code id="measurementInvariance-deprecated_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code> (default), a summary is printed out containing
an overview of the different models that are fitted, together with some
model comparison tests. If <code>TRUE</code>, no summary is printed.</p>
</td></tr>
<tr><td><code id="measurementInvariance-deprecated_+3A_fit.measures">fit.measures</code></td>
<td>
<p>Fit measures used to calculate the differences between
nested models.</p>
</td></tr>
<tr><td><code id="measurementInvariance-deprecated_+3A_baseline.model">baseline.model</code></td>
<td>
<p>custom baseline model passed to
<code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code></p>
</td></tr>
<tr><td><code id="measurementInvariance-deprecated_+3A_method">method</code></td>
<td>
<p>The method used to calculate likelihood ratio test. See
<code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code> for available options</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>strict = FALSE</code>, the following four models are tested in order:
</p>

<ol>
<li><p> Model 1: configural invariance. The same factor structure
is imposed on all groups.
</p>
</li>
<li><p> Model 2: weak invariance. The factor loadings are constrained to
be equal across groups.
</p>
</li>
<li><p> Model 3: strong invariance. The factor loadings and intercepts
are constrained to be equal across groups.
</p>
</li>
<li><p> Model 4: The factor loadings, intercepts and means are constrained
to be equal across groups.
</p>
</li></ol>

<p>Each time a more restricted model is fitted, a <code class="reqn">\Delta\chi^2</code> test is
reported, comparing the current model with the previous one, and comparing
the current model to the baseline model (Model 1). In addition, the
difference in CFI is also reported (<code class="reqn">\Delta</code>CFI).
</p>
<p>If <code>strict = TRUE</code>, the following five models are tested in order:
</p>

<ol>
<li><p> Model 1: configural invariance. The same factor structure
is imposed on all groups.
</p>
</li>
<li><p> Model 2: weak invariance. The factor loadings are constrained to be
equal across groups.
</p>
</li>
<li><p> Model 3: strong invariance. The factor loadings and intercepts are
constrained to be equal across groups.
</p>
</li>
<li><p> Model 4: strict invariance. The factor loadings, intercepts and
residual variances are constrained to be equal across groups.
</p>
</li>
<li><p> Model 5: The factor loadings, intercepts, residual variances and means
are constrained to be equal across groups.
</p>
</li></ol>

<p>Note that if the <code class="reqn">\chi^2</code> test statistic is scaled (e.g., a Satorra-Bentler
or Yuan-Bentler test statistic), a special version of the <code class="reqn">\Delta\chi^2</code>
test is used as described in <a href="http://www.statmodel.com/chidiff.shtml">http://www.statmodel.com/chidiff.shtml</a>
</p>


<h3>Value</h3>

<p>Invisibly, all model fits in the sequence are returned as a list.
</p>


<h3>Author(s)</h3>

<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Vandenberg, R. J., and Lance, C. E. (2000). A review and synthesis of the
measurement invariance literature: Suggestions, practices, and
recommendations for organizational research. <em>Organizational
Research Methods, 3,</em> 4&ndash;70.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HW.model &lt;- ' visual =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed =~ x7 + x8 + x9 '

measurementInvariance(model = HW.model, data = HolzingerSwineford1939,
                      group = "school", fit.measures = c("cfi","aic"))

</code></pre>

<hr>
<h2 id='measurementInvarianceCat-deprecated'>Measurement Invariance Tests for Categorical Items</h2><span id='topic+measurementInvarianceCat-deprecated'></span>

<h3>Description</h3>

<p>Testing measurement invariance across groups using a typical sequence of
model comparison tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measurementInvarianceCat(..., std.lv = FALSE, strict = FALSE,
                         quiet = FALSE, fit.measures = "default",
                         baseline.model = NULL, method = "default")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_...">...</code></td>
<td>
<p>The same arguments as for any lavaan model.  See
<code><a href="lavaan.html#topic+cfa">lavaan::cfa()</a></code> for more information.</p>
</td></tr>
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_std.lv">std.lv</code></td>
<td>
<p>If <code>TRUE</code>, the fixed-factor method of scale
identification is used. If <code>FALSE</code>, the first variable for each
factor is used as marker variable.</p>
</td></tr>
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_strict">strict</code></td>
<td>
<p>If <code>TRUE</code>, the sequence requires &lsquo;strict&rsquo; invariance.
See details for more information.</p>
</td></tr>
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code> (default), a summary is printed out containing
an overview of the different models that are fitted, together with some
model comparison tests. If <code>TRUE</code>, no summary is printed.</p>
</td></tr>
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_fit.measures">fit.measures</code></td>
<td>
<p>Fit measures used to calculate the differences between
nested models.</p>
</td></tr>
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_baseline.model">baseline.model</code></td>
<td>
<p>custom baseline model passed to
<code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code></p>
</td></tr>
<tr><td><code id="measurementInvarianceCat-deprecated_+3A_method">method</code></td>
<td>
<p>The method used to calculate likelihood ratio test. See
<code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code> for available options</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Theta parameterization is used to represent SEM for categorical items.  That
is, residual variances are modeled instead of the total variance of
underlying normal variate for each item.  Five models can be tested based on
different constraints across groups.
</p>

<ol>
<li><p> Model 1: configural invariance. The same factor structure is imposed
on all groups.
</p>
</li>
<li><p> Model 2: weak invariance. The factor loadings are constrained to be
equal across groups.
</p>
</li>
<li><p> Model 3: strong invariance. The factor loadings and thresholds are
constrained to be equal across groups.
</p>
</li>
<li><p> Model 4: strict invariance. The factor loadings, thresholds and
residual variances are constrained to be equal across groups.
For categorical variables, all residual variances are fixed as 1.
</p>
</li>
<li><p> Model 5: The factor loadings, threshoulds, residual variances and
means are constrained to be equal across groups.
</p>
</li></ol>

<p>However, if all items have two items (dichotomous), scalar invariance and
weak invariance cannot be separated because thresholds need to be equal
across groups for scale identification. Users can specify <code>strict</code>
option to include the strict invariance model for the invariance testing.
See the further details of scale identification and different
parameterization in Millsap and Yun-Tein (2004).
</p>


<h3>Value</h3>

<p>Invisibly, all model fits in the sequence are returned as a list.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Millsap, R. E., &amp; Yun-Tein, J. (2004). Assessing factorial
invariance in ordered-categorical measures. <em>Multivariate Behavioral
Research, 39</em>(3), 479&ndash;515. <a href="https://doi.org/10.1207/S15327906MBR3903_4">doi:10.1207/S15327906MBR3903_4</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

syntax &lt;- ' f1 =~ u1 + u2 + u3 + u4'

measurementInvarianceCat(model = syntax, data = datCat, group = "g",
                         parameterization = "theta", estimator = "wlsmv",
                         ordered = c("u1", "u2", "u3", "u4"))


</code></pre>

<hr>
<h2 id='miPowerFit'>Modification indices and their power approach for model fit evaluation</h2><span id='topic+miPowerFit'></span>

<h3>Description</h3>

<p>The model fit evaluation approach using modification indices and expected
parameter changes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>miPowerFit(lavaanObj, stdLoad = 0.4, cor = 0.1, stdBeta = 0.1,
  intcept = 0.2, stdDelta = NULL, delta = NULL, cilevel = 0.9, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="miPowerFit_+3A_lavaanobj">lavaanObj</code></td>
<td>
<p>The lavaan model object used to evaluate model fit</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_stdload">stdLoad</code></td>
<td>
<p>The amount of standardized factor loading that one would like
to be detected (rejected). The default value is 0.4, which is suggested by
Saris and colleagues (2009, p. 571).</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_cor">cor</code></td>
<td>
<p>The amount of factor or error correlations that one would like to
be detected (rejected). The default value is 0.1, which is suggested by
Saris and colleagues (2009, p. 571).</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_stdbeta">stdBeta</code></td>
<td>
<p>The amount of standardized regression coefficients that one
would like to be detected (rejected). The default value is 0.1, which is
suggested by Saris and colleagues (2009, p. 571).</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_intcept">intcept</code></td>
<td>
<p>The amount of standardized intercept (similar to Cohen's
<em>d</em> that one would like to be detected (rejected). The default value
is 0.2, which is equivalent to a low effect size proposed by Cohen (1988,
1992).</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_stddelta">stdDelta</code></td>
<td>
<p>The vector of the standardized parameters that one would
like to be detected (rejected). If this argument is specified, the value
here will overwrite the other arguments above. The order of the vector
must be the same as the row order from modification indices from the
<code>lavaan</code> object. If a single value is specified, the value will be
applied to all parameters.</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_delta">delta</code></td>
<td>
<p>The vector of the unstandardized parameters that one would like
to be detected (rejected). If this argument is specified, the value here
will overwrite the other arguments above. The order of the vector must be
the same as the row order from modification indices from the <code>lavaan</code>
object. If a single value is specified, the value will be applied to all
parameters.</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_cilevel">cilevel</code></td>
<td>
<p>The confidence level of the confidence interval of expected
parameter changes. The confidence intervals are used in the equivalence
testing.</p>
</td></tr>
<tr><td><code id="miPowerFit_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="lavaan.html#topic+modificationIndices">lavaan::modificationIndices()</a></code>,
except for <code>delta</code>, which is already an argument (which can be
substituted for <code>stdDelta</code> or specific sets of parameters using
<code>stdLoad</code>, <code>cor</code>, <code>stdBeta</code>, and <code>intcept</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To decide whether a parameter should be freed, one can inspect its
modification index (MI) and expected parameter change (EPC).
Those values can be used to evaluate model fit by 2 methods.
</p>
<p>Method  1: Saris, Satorra, and van der Veld (2009, pp. 570&ndash;573) used
power (probability of detecting a significant MI) and EPC to decide whether
to free a parametr.  First, one should evaluate whether a parameter's MI
is significant. Second, one should evaluate whether the power to detect a
target EPC is high enough.  The combination of criteria leads to the
so-called &quot;JRule&quot; first implemented with LISREL (van der Veld et al., 2008):
</p>

<ul>
<li><p> If the MI is not significant and the power is low,
the test is inconclusive.
</p>
</li>
<li><p> If the MI is not significant and the power is high,
there is no misspecification.
</p>
</li>
<li><p> If the MI is significant and the power is low,
the fixed parameter is misspecified.
</p>
</li>
<li><p> If the MI is significant and the power is high,
the EPC is investigated.  If the EPC is large (greater than the
the target EPC), the parameter is misspecified.  If the EPC is low
(lower than the target EPC), the parameter is not misspecificied.
</p>
</li></ul>

<p>Method 2:  The confidence interval (CI) of an EPC is calculated.
These CIs are compared with the range of trivial
misspecification, which could be (-<code>delta</code>, <code>delta</code>) or (0,
<code>delta</code>) for nonnegative parameters.
</p>

<ul>
<li><p> If a CI overlaps with the range of trivial misspecification,
the test is inconclusive.
</p>
</li>
<li><p> If a CI completely exceeds the range of trivial misspecification,
the fixed parameters are severely misspecified.
</p>
</li>
<li><p> If a CI is completely within the range of trivial misspecification,
the fixed parameters are trivially misspecified.
</p>
</li></ul>



<h3>Value</h3>

<p>A data frame with these variables:
</p>

<ol>
<li> <p><code>lhs</code>: The left-hand side variable, with respect to the operator in
in the lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code>
</p>
</li>
<li> <p><code>op</code>: The lavaan syntax operator: &quot;~~&quot; represents covariance,
&quot;=~&quot; represents factor loading, &quot;~&quot; represents regression, and
&quot;~1&quot; represents intercept.
</p>
</li>
<li> <p><code>rhs</code>: The right-hand side variable
</p>
</li>
<li> <p><code>group</code>: The level of the group variable for the parameter in question
</p>
</li>
<li> <p><code>mi</code>: The modification index of the fixed parameter
</p>
</li>
<li> <p><code>epc</code>: The EPC if the parameter is freely estimated
</p>
</li>
<li> <p><code>target.epc</code>: The target EPC that represents the minimum size
of misspecification that one would like to be detected
by the test with a high power
</p>
</li>
<li> <p><code>std.epc</code>: The standardized EPC if the parameter is freely estimated
</p>
</li>
<li> <p><code>std.target.epc</code>: The standardized target expected parameter change
</p>
</li>
<li> <p><code>significant.mi</code>: Represents whether the modification index value is
significant
</p>
</li>
<li> <p><code>high.power</code>: Represents whether the power is enough to detect the
target expected parameter change
</p>
</li>
<li> <p><code>decision.pow</code>: The decision whether the parameter is misspecified
or not based on Saris et al's method: <code>"M"</code> represents the parameter
is misspecified, <code>"NM"</code> represents the parameter is not misspecified,
<code>"EPC:M"</code> represents the parameter is misspecified decided by
checking the expected parameter change value, <code>"EPC:NM"</code> represents
the parameter is not misspecified decided by checking the expected
parameter change value, and <code>"I"</code> represents the decision is
inconclusive.
</p>
</li>
<li> <p><code>se.epc</code>: The standard errors of the expected parameter changes.
</p>
</li>
<li> <p><code>lower.epc</code>: The lower bound of the confidence interval of expected
parameter changes.
</p>
</li>
<li> <p><code>upper.epc</code>: The upper bound of the confidence interval of expected
parameter changes.
</p>
</li>
<li> <p><code>lower.std.epc</code>: Lower confidence limit of standardized EPCs
</p>
</li>
<li> <p><code>upper.std.epc</code>: Upper confidence limit of standardized EPCs
</p>
</li>
<li> <p><code>decision.ci</code>: Decision whether the parameter is misspecified
based on the CI method: <code>"M"</code> represents the
parameter is misspecified, <code>"NM"</code> represents the parameter is not
misspecified, and <code>"I"</code> represents the decision is inconclusive.
</p>
</li></ol>

<p>The row numbers matches with the results obtained from the
<code>inspect(object, "mi")</code> function.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Cohen, J. (1988). <em>Statistical power analysis for the
behavioral sciences</em> (2nd ed.). Hillsdale, NJ: Erlbaum.
</p>
<p>Cohen, J. (1992). A power primer. <em>Psychological Bulletin, 112</em>(1),
155&ndash;159. <a href="https://doi.org/10.1037/0033-2909.112.1.155">doi:10.1037/0033-2909.112.1.155</a>
</p>
<p>Saris, W. E., Satorra, A., &amp; van der Veld, W. M. (2009). Testing structural
equation models or detection of misspecifications? <em>Structural Equation
Modeling, 16</em>(4), 561&ndash;582. <a href="https://doi.org/10.1080/10705510903203433">doi:10.1080/10705510903203433</a>
</p>
<p>van der Veld, W. M., Saris, W. E., &amp; Satorra, A. (2008).
<em>JRule 3.0 Users Guide</em>. <a href="https://doi.org/10.13140/RG.2.2.13609.90729">doi:10.13140/RG.2.2.13609.90729</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+moreFitIndices">moreFitIndices()</a></code> For the additional fit indices
information
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)

HS.model &lt;- ' visual  =~ x1 + x2 + x3 '
fit &lt;- cfa(HS.model, data = HolzingerSwineford1939,
           group = "sex", group.equal = c("loadings","intercepts"))
miPowerFit(fit, free.remove = FALSE, op = "=~") # loadings
miPowerFit(fit, free.remove = FALSE, op = "~1") # intercepts

model &lt;- '
  # latent variable definitions
     ind60 =~ x1 + x2 + x3
     dem60 =~ y1 + a*y2 + b*y3 + c*y4
     dem65 =~ y5 + a*y6 + b*y7 + c*y8

  # regressions
    dem60 ~ ind60
    dem65 ~ ind60 + dem60

  # residual correlations
    y1 ~~ y5
    y2 ~~ y4 + y6
    y3 ~~ y7
    y4 ~~ y8
    y6 ~~ y8
'
fit2 &lt;- sem(model, data = PoliticalDemocracy, meanstructure = TRUE)
miPowerFit(fit2, stdLoad = 0.3, cor = 0.2, stdBeta = 0.2, intcept = 0.5)

</code></pre>

<hr>
<h2 id='modindices.mi-deprecated'>Modification Indices for Multiple Imputations</h2><span id='topic+modindices.mi-deprecated'></span>

<h3>Description</h3>

<p>Modification indices (1-<em>df</em> Lagrange multiplier tests) from a
latent variable model fitted to multiple imputed data sets. Statistics
for releasing one or more fixed or constrained parameters in model can
be calculated by pooling the gradient and information matrices
across imputed data sets in a method proposed by Mansolf, Jorgensen, &amp;
Enders (2020)&mdash;analogous to the &quot;D1&quot; Wald test proposed by Li, Meng,
Raghunathan, &amp; Rubin (1991)&mdash;or by pooling the complete-data score-test
statistics across imputed data sets (i.e., &quot;D2&quot;; Li et al., 1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>modindices.mi(object, test = c("D2","D1"), omit.imps = c("no.conv","no.se"),
              standardized = TRUE, cov.std = TRUE, information = "expected",
              power = FALSE, delta = 0.1, alpha = 0.05, high.power = 0.75,
              sort. = FALSE, minimum.value = 0, maximum.number = nrow(LIST),
              na.remove = TRUE, op = NULL)

modificationIndices.mi(object, test = c("D2","D1"),
                       omit.imps = c("no.conv","no.se"),
                       standardized = TRUE, cov.std = TRUE,
                       information = "expected", power = FALSE, delta = 0.1,
                       alpha = 0.05, high.power = 0.75, sort. = FALSE,
                       minimum.value = 0, maximum.number = nrow(LIST),
                       na.remove = TRUE, op = NULL)

modificationindices.mi(object, test = c("D2","D1"),
                       omit.imps = c("no.conv","no.se"),
                       standardized = TRUE, cov.std = TRUE,
                       information = "expected", power = FALSE, delta = 0.1,
                       alpha = 0.05, high.power = 0.75, sort. = FALSE,
                       minimum.value = 0, maximum.number = nrow(LIST),
                       na.remove = TRUE, op = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="modindices.mi-deprecated_+3A_object">object</code></td>
<td>
<p>An object of class <a href="#topic+OLDlavaan.mi-class">OLDlavaan.mi</a></p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_test">test</code></td>
<td>
<p><code>character</code> indicating which pooling method to use.
<code>"D1"</code> requests Mansolf, Jorgensen, &amp; Enders' (2020) proposed
Wald-like test for pooling the gradient and information, which are then
used to calculate score-test statistics in the usual manner. <code>"D2"</code>
(default because it is less computationall intensive) requests to pool the
complete-data score-test statistics from each imputed data set, then pool
them across imputations, described by Li et al. (1991) and Enders (2010).</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases. Specific imputation numbers can also be included in this
argument, in case users want to  apply their own custom omission criteria
(or simulations can use different numbers of imputations without
redundantly refitting the model).</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_standardized">standardized</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, two extra columns
(<code style="white-space: pre;">&#8288;$sepc.lv&#8288;</code> and <code style="white-space: pre;">&#8288;$sepc.all&#8288;</code>) will contain standardized values
for the EPCs. In the first column (<code style="white-space: pre;">&#8288;$sepc.lv&#8288;</code>), standardizization is
based on the variances of the (continuous) latent variables. In the second
column (<code style="white-space: pre;">&#8288;$sepc.all&#8288;</code>), standardization is based on both the variances
of both (continuous) observed and latent variables. (Residual) covariances
are standardized using (residual) variances.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_cov.std">cov.std</code></td>
<td>
<p><code>logical</code>. <code>TRUE</code> if <code>test == "D2"</code>.
If <code>TRUE</code> (default), the (residual)
observed covariances are scaled by the square-root of the diagonal elements
of the <code class="reqn">\Theta</code> matrix, and the (residual) latent covariances are
scaled by the square-root of the diagonal elements of the <code class="reqn">\Psi</code>
matrix. If <code>FALSE</code>, the (residual) observed covariances are scaled by
the square-root of the diagonal elements of the model-implied covariance
matrix of observed variables (<code class="reqn">\Sigma</code>), and the (residual) latent
covariances are scaled by the square-root of the diagonal elements of the
model-implied covariance matrix of the latent variables.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_information">information</code></td>
<td>
<p><code>character</code> indicating the type of information
matrix to use (check <code><a href="lavaan.html#topic+lavInspect">lavaan::lavInspect()</a></code> for available options).
<code>"expected"</code> information is the default, which provides better
control of Type I errors.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_power">power</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, the (post-hoc) power is
computed for each modification index, using the values of <code>delta</code>
and <code>alpha</code>.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_delta">delta</code></td>
<td>
<p>The value of the effect size, as used in the post-hoc power
computation, currently using the unstandardized metric of the <code style="white-space: pre;">&#8288;$epc&#8288;</code>
column.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_alpha">alpha</code></td>
<td>
<p>The significance level used for deciding if the modification
index is statistically significant or not.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_high.power">high.power</code></td>
<td>
<p>If the computed power is higher than this cutoff value,
the power is considered 'high'. If not, the power is considered 'low'.
This affects the values in the <code style="white-space: pre;">&#8288;$decision&#8288;</code> column in the output.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_sort.">sort.</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, sort the output using the
values of the modification index values. Higher values appear first.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_minimum.value">minimum.value</code></td>
<td>
<p><code>numeric</code>. Filter output and only show rows with a
modification index value equal or higher than this minimum value.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_maximum.number">maximum.number</code></td>
<td>
<p><code>integer</code>. Filter output and only show the first
maximum number rows. Most useful when combined with the <code>sort.</code> option.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_na.remove">na.remove</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (default), filter output by
removing all rows with <code>NA</code> values for the modification indices.</p>
</td></tr>
<tr><td><code id="modindices.mi-deprecated_+3A_op">op</code></td>
<td>
<p><code>character</code> string. Filter the output by selecting only those
rows with operator <code>op</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> containing modification indices and (S)EPCs.
</p>


<h3>Note</h3>

<p>When <code>test = "D2"</code>, each (S)EPC will be pooled by taking its
average across imputations. When <code>test = "D1"</code>, EPCs will be
calculated in the standard way using the pooled gradient and information,
and SEPCs will be calculated by standardizing the EPCs using model-implied
(residual) variances.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Adapted from <span class="pkg">lavaan</span> source code, written by
Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p><code>test = "D1"</code> method proposed by
Maxwell Mansolf (University of California, Los Angeles;
<a href="mailto:mamansolf@gmail.com">mamansolf@gmail.com</a>)
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>.
New York, NY: Guilford.
</p>
<p>Li, K.-H., Meng, X.-L., Raghunathan, T. E., &amp; Rubin, D. B. (1991).
Significance levels from repeated <em>p</em>-values with multiply-imputed
data.<em>Statistica Sinica, 1</em>(1), 65&ndash;92. Retrieved from
<a href="https://www.jstor.org/stable/24303994">https://www.jstor.org/stable/24303994</a>
</p>
<p>Mansolf, M., Jorgensen, T. D., &amp; Enders, C. K. (2020). A multiple
imputation score test for model modification in structural equation
models. <em>Psychological Methods, 25</em>(4), 393&ndash;411.
<a href="https://doi.org/10.1037/met0000243">doi:10.1037/met0000243</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See the new lavaan.mi package

</code></pre>

<hr>
<h2 id='monteCarloCI'>Monte Carlo Confidence Intervals to Test Functions of Parameter Estimates</h2><span id='topic+monteCarloCI'></span><span id='topic+monteCarloMed'></span>

<h3>Description</h3>

<p>Robust confidence intervals for functions of parameter estimates,
based on empirical sampling distributions of estimated model parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>monteCarloCI(object = NULL, expr, coefs, ACM, nRep = 20000,
  standardized = FALSE, fast = TRUE, level = 0.95, na.rm = TRUE,
  append.samples = FALSE, plot = FALSE,
  ask = getOption("device.ask.default"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="monteCarloCI_+3A_object">object</code></td>
<td>
<p>A object of class <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> in which
functions of parameters have already been defined using the <code style="white-space: pre;">&#8288;:=&#8288;</code>
operator in <code>lavaan</code>'s <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code>. When
<code>NULL</code>, users must specify <code>expr</code>, <code>coefs</code>, and <code>ACM</code>.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_expr">expr</code></td>
<td>
<p>Optional <code>character</code> vector specifying functions of model
parameters (e.g., an indirect effect). Ideally, the vector should have
names, which is necessary if any user-defined parameters refer to other
user-defined parameters defined earlier in the vector (order matters!).
All parameters appearing in the vector must be provided in <code>coefs</code>,
or defined (as functions of <code>coefs</code>) earlier in <code>expr</code>. If
<code>length(expr) &gt; 1L</code>, <code>nRep</code> samples will be drawn
simultaneously from a single multivariate distribution; thus,
<code>ACM</code> must include all parameters in <code>coefs</code>.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_coefs">coefs</code></td>
<td>
<p><code>numeric</code> vector of parameter estimates used in
<code>expr</code>. Ignored when <code>object</code> is used.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_acm">ACM</code></td>
<td>
<p>Symmetric <code>matrix</code> representing the asymptotic sampling
covariance matrix (ACOV) of the parameter estimates in <code>coefs</code>.
Ignored when <code>object</code> is used. Information on how to obtain the ACOV
in popular SEM software is described in <strong>Details</strong>.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_nrep">nRep</code></td>
<td>
<p><code>integer</code>. The number of samples to draw, to obtain an
empirical sampling distribution of model parameters. Many thousand are
recommended to minimize Monte Carlo error of the estimated CIs.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_standardized">standardized</code></td>
<td>
<p><code>logical</code> indicating whether to obtain CIs for the
fully standardized (<code>"std.all"</code>) estimates, using their asymptotic
sampling covariance matrix.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_fast">fast</code></td>
<td>
<p><code>logical</code> indicating whether to use a fast algorithm that
assumes all functions of parameters (in <code>object</code> or <code>expr</code>) use
standard operations. Set to <code>FALSE</code> if using (e.g.) <code><a href="base.html#topic+c">c()</a></code>
to concatenate parameters in the definition, which would have unintended
consequences when vectorizing functions in <code>expr</code> across sampled
parameters.</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_level">level</code></td>
<td>
<p><code>numeric</code> confidence level, between 0&ndash;1</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code> passed to <code><a href="stats.html#topic+quantile">stats::quantile()</a></code></p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_append.samples">append.samples</code></td>
<td>
<p><code>logical</code> indicating whether to return the
simulated empirical sampling distribution of parameters (in <code>coefs</code>)
and functions (in <code>expr</code>) in a <code>list</code> with the results. This
could be useful to calculate more precise highest-density intervals (see
examples).</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_plot">plot</code></td>
<td>
<p><code>logical</code> indicating whether to plot the empirical sampling
distribution of each function in <code>expr</code></p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_ask">ask</code></td>
<td>
<p>whether to prompt user before printing each plot</p>
</td></tr>
<tr><td><code id="monteCarloCI_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="graphics.html#topic+hist">graphics::hist()</a></code> when
<code>plot = TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the Monte Carlo method of obtaining an empirical
sampling distribution of estimated model parameters, as described by
MacKinnon et al. (2004) for testing indirect effects in mediation models.
This is essentially a parametric bootstrap method, which (re)samples
parameters (rather than raw data) from a multivariate-normal distribution
with mean vector equal to estimates in <code>coef()</code> and covariance matrix
equal to the asymptotic covariance matrix <code>vcov()</code> of estimated parameters.
</p>
<p>The easiest way to use the function is to fit a SEM to data with
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>, using the <code style="white-space: pre;">&#8288;:=&#8288;</code> operator in the
<code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> to specify user-defined parameters.
All information is then available in the resulting
<a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> object.  Alternatively (especially when using
external SEM software to fit the model), the expression(s) can be explicitly
passed to the function, along with the vector of estimated model parameters
and their associated asymptotic sampling covariance matrix (ACOV).
For further information on the Monte Carlo method, see MacKinnon et al.
(2004) and Preacher &amp; Selig (2012).
</p>
<p>The asymptotic covariance matrix can be obtained easily from many popular
SEM software packages.
</p>

<ul>
<li><p>LISREL: Including the EC option on the OU line will print the ACM
to a seperate file. The file contains the lower triangular elements of
the ACM in free format and scientific notation.
</p>
</li>
<li><p>M<em>plus</em>: Include the command TECH3; in the OUTPUT section.
The ACM will be printed in the output.
</p>
</li>
<li><p><code>lavaan</code>: Use the <code><a href="stats.html#topic+vcov">vcov()</a></code> method on the fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>
object to return the ACM.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>lavaan.data.frame</code> (to use lavaan's <code>print</code> method)
with point estimates and confidence limits of each requested function of
parameters in <code>expr</code> is returned. If <code>append.samples = TRUE</code>,
output will be a <code>list</code> with the same <code style="white-space: pre;">&#8288;$Results&#8288;</code> along with a
second <code>data.frame</code> with the <code style="white-space: pre;">&#8288;$Samples&#8288;</code> (in rows) of each
parameter (in columns), and an additional column for each requested
function of those parameters.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>MacKinnon, D. P., Lockwood, C. M., &amp; Williams, J. (2004). Confidence limits
for the indirect effect: Distribution of the product and resampling methods.
<em>Multivariate Behavioral Research, 39</em>(1) 99&ndash;128.
<a href="https://doi.org/10.1207/s15327906mbr3901_4">doi:10.1207/s15327906mbr3901_4</a>
</p>
<p>Preacher, K. J., &amp; Selig, J. P. (2010, July). Monte Carlo method
for assessing multilevel mediation: An interactive tool for creating
confidence intervals for indirect effects in 1-1-1 multilevel models.
Computer software available from <a href="http://quantpsy.org/">http://quantpsy.org/</a>.
</p>
<p>Preacher, K. J., &amp; Selig, J. P. (2012). Advantages of Monte Carlo confidence
intervals for indirect effects. <em>Communication Methods and Measures, 6</em>(2),
77&ndash;98. <a href="https://doi.org/10.1080/19312458.2012.679848">doi:10.1080/19312458.2012.679848</a>
</p>
<p>Selig, J. P., &amp; Preacher, K. J. (2008, June). Monte Carlo method for
assessing mediation: An interactive tool for creating confidence intervals
for indirect effects. Computer software available from
<a href="http://quantpsy.org/">http://quantpsy.org/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## From the mediation tutorial:
## http://lavaan.ugent.be/tutorial/mediation.html

set.seed(1234)
X &lt;- rnorm(100)
M &lt;- 0.5*X + rnorm(100)
Y &lt;- 0.7*M + rnorm(100)
dat &lt;- data.frame(X = X, Y = Y, M = M)

mod &lt;- ' # direct effect
  Y ~ c*X
  # mediator
  M ~ a*X
  Y ~ b*M
  # indirect effect (a*b)
  ind := a*b
  # total effect
  total := ind + c
'
fit &lt;- sem(mod, data = dat)
summary(fit, ci = TRUE) # print delta-method CIs

## Automatically extract information from lavaan object
set.seed(1234)
monteCarloCI(fit) # CIs more robust than delta method in smaller samples

## delta method for standardized solution
standardizedSolution(fit)
## compare to Monte Carlo CIs:
set.seed(1234)
monteCarloCI(fit, standardized = TRUE)


## save samples to calculate more precise intervals:
set.seed(1234)
foo &lt;- monteCarloCI(fit, append.samples = TRUE)
# library(HDInterval) # not a dependency; must be installed
# hdi(foo$Samples)

## Parameters can also be obtained from an external analysis
myParams &lt;- c("a","b","c")
(coefs &lt;- coef(fit)[myParams]) # names must match those in the "expression"
## Asymptotic covariance matrix from an external analysis
(AsyCovMat &lt;- vcov(fit)[myParams, myParams])
## Compute CI, include a plot
set.seed(1234)
monteCarloCI(expr = c(ind = 'a*b', total = 'ind + c',
                      ## other arbitrary functions are also possible
                      meaningless = 'sqrt(a)^b / log(abs(c))'),
             coefs = coefs, ACM = AsyCovMat,
             plot = TRUE, ask = TRUE) # print a plot for each

</code></pre>

<hr>
<h2 id='moreFitIndices'>Calculate more fit indices</h2><span id='topic+moreFitIndices'></span>

<h3>Description</h3>

<p>Calculate more fit indices that are not already provided in lavaan.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moreFitIndices(object, fit.measures = "all", nPrior = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moreFitIndices_+3A_object">object</code></td>
<td>
<p>The lavaan model object provided after running the <code>cfa</code>,
<code>sem</code>, <code>growth</code>, or <code>lavaan</code> functions.</p>
</td></tr>
<tr><td><code id="moreFitIndices_+3A_fit.measures">fit.measures</code></td>
<td>
<p>Additional fit measures to be calculated. All additional
fit measures are calculated by default</p>
</td></tr>
<tr><td><code id="moreFitIndices_+3A_nprior">nPrior</code></td>
<td>
<p>The sample size on which prior is based. This argument is used
to compute <code>bic.priorN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+nullRMSEA">nullRMSEA()</a></code> for the further details of the computation of
RMSEA of the null model.
</p>
<p>Gamma-Hat (<code>gammaHat</code>; West, Taylor, &amp; Wu, 2012) is a global
goodness-of-fit index which can be computed (assuming equal number of
indicators across groups) by
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\Gamma} =\frac{p}{p + 2 \times \frac{\chi^{2}_{k} - df_{k}}{N}},</code>
</p>

<p>where <code class="reqn">p</code> is the number of variables in the model, <code class="reqn">\chi^{2}_{k}</code> is
the <code class="reqn">\chi^2</code> test statistic value of the target model, <code class="reqn">df_{k}</code> is
the degree of freedom when fitting the target model, and <code class="reqn">N</code> is the
sample size (or sample size minus the number of groups if <code>mimic</code> is
set to <code>"EQS"</code>).
</p>
<p>Adjusted Gamma-Hat (<code>adjGammaHat</code>; West, Taylor, &amp; Wu, 2012) is a
global fit index which can be computed by
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\Gamma}_\textrm{adj} = \left(1 - \frac{K \times p \times
  (p + 1)}{2 \times df_{k}} \right) \times \left( 1 - \hat{\Gamma} \right),</code>
</p>

<p>where <code class="reqn">K</code> is the number of groups (please refer to Dudgeon, 2004, for
the multiple-group adjustment for <code>adjGammaHat</code>).
</p>
<p>Note that if Satorra&ndash;Bentler's or Yuan&ndash;Bentler's method is used, the fit
indices using the scaled <code class="reqn">\chi^2</code> values are also provided.
</p>
<p>The remaining indices are information criteria calculated using the
<code>object</code>'s <code class="reqn">-2 \times</code> log-likelihood, abbreviated <code class="reqn">-2LL</code>.
</p>
<p>Corrected Akaike Information Criterion (<code>aic.smallN</code>; Burnham &amp;
Anderson, 2003) is a corrected version of AIC for small sample size, often
abbreviated AICc:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{AIC}_{\textrm{small}-N} = AIC + \frac{2q(q + 1)}{N - q - 1},</code>
</p>

<p>where <code class="reqn">AIC</code> is the original AIC: <code class="reqn">-2LL + 2q</code> (where <code class="reqn">q</code>
= the number of estimated parameters in the target model). Note that AICc is
a small-sample correction derived for univariate regression models, so it is
probably <em>not</em> appropriate for comparing SEMs.
</p>
<p>Corrected Bayesian Information Criterion (<code>bic.priorN</code>; Kuha, 2004) is
similar to BIC but explicitly specifying the sample size on which the prior
is based (<code class="reqn">N_{prior}</code>) using the <code>nPrior</code> argument.
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{BIC}_{\textrm{prior}-N} = -2LL + q\log{( 1 + \frac{N}{N_{prior}} )}.</code>
</p>

<p>Bollen et al. (2012, 2014) discussed additional BICs that incorporate more
terms from a Taylor series expansion, which the standard BIC drops.  The
&quot;Scaled Unit-Information Prior&quot; BIC is calculated depending on whether the
product of the vector of estimated model parameters (<code class="reqn">\hat{\theta}</code>) and
the observed information matrix (FIM) exceeds the number of estimated model
parameters (Case 1) or not (Case 2), which is checked internally:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{SPBIC}_{\textrm{Case 1}} = -2LL + q(1 - \frac{q}{\hat{\theta}^{'} \textrm{FIM} \hat{\theta}}), \textrm{ or}</code>
</p>

<p style="text-align: center;"><code class="reqn"> \textrm{SPBIC}_{\textrm{Case 2}} = -2LL + \hat{\theta}^{'} \textrm{FIM} \hat{\theta},</code>
</p>

<p>Note that this implementation of SPBIC is calculated on the assumption that
priors for all estimated parameters are centered at zero, which is
inappropriate for most SEMs (e.g., variances should not have priors centered
at the lowest possible value; Bollen, 2014, p. 6).
</p>
<p>Bollen et al. (2014, eq. 14) credit the HBIC to Haughton (1988):
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{HBIC} = -2LL + q\log{\frac{N}{2 \pi}}.</code>
</p>

<p>Bollen et al. (2012, p. 305) proposed the information matrix (<code class="reqn">I</code>)-based BIC by
adding another term:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{IBIC} = -2LL + q\log{\frac{N}{2 \pi}} + \log{\det{\textrm{FIM}}},</code>
</p>

<p>or equivalently, using the inverse information (the asymptotic sampling
covariance matrix of estimated parameters: ACOV):
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{IBIC} = -2LL - q\log{2 \pi} - \log{\det{\textrm{ACOV}}}.</code>
</p>

<p>Stochastic information criterion (SIC; see Preacher, 2006, for details) is
similar to IBIC but does not include the <code class="reqn">q\log{2 \pi}</code> term that is
also in HBIC.  SIC and IBIC both account for model complexity in a model's
functional form, not merely the number of free parameters.  The SIC can be
computed as:
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{SIC} = -2LL + q\log{N} + \log{\det{\textrm{FIM}}} = -2LL - \log{\det{\textrm{ACOV}}}.</code>
</p>

<p>Hannan&ndash;Quinn Information Criterion (HQC; Hannan &amp; Quinn, 1979) is used for
model selection, similar to AIC or BIC.
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{HQC} = -2LL + 2q\log{(\log{N})},</code>
</p>

<p>Bozdogan Information Complexity (ICOMP) Criteria (Howe et al., 2011),
instead of penalizing the number of free parameters directly,
ICOMP penalizes the covariance complexity of the model.
</p>
<p style="text-align: center;"><code class="reqn"> \textrm{ICOMP} = -2LL + s \times log(\frac{\bar{\lambda_a}}{\bar{\lambda_g}}) </code>
</p>



<h3>Value</h3>

<p>A <code>numeric</code> <code>lavaan.vector</code> including any of the
following requested via <code style="white-space: pre;">&#8288;fit.measures=&#8288;</code>
</p>

<ol>
<li> <p><code>gammaHat</code>: Gamma-Hat
</p>
</li>
<li> <p><code>adjGammaHat</code>: Adjusted Gamma-Hat
</p>
</li>
<li> <p><code>baseline.rmsea</code>: RMSEA of the default baseline (i.e., independence) model
</p>
</li>
<li> <p><code>gammaHat.scaled</code>: Gamma-Hat using scaled <code class="reqn">\chi^2</code>
</p>
</li>
<li> <p><code>adjGammaHat.scaled</code>: Adjusted Gamma-Hat using scaled <code class="reqn">\chi^2</code>
</p>
</li>
<li> <p><code>baseline.rmsea.scaled</code>: RMSEA of the default baseline (i.e.,
independence) model using scaled <code class="reqn">\chi^2</code>
</p>
</li>
<li> <p><code>aic.smallN</code>: Corrected (for small sample size) AIC
</p>
</li>
<li> <p><code>bic.priorN</code>: BIC with specified prior sample size
</p>
</li>
<li> <p><code>spbic</code>: Scaled Unit-Information Prior BIC (SPBIC)
</p>
</li>
<li> <p><code>hbic</code>: Haughton's BIC (HBIC)
</p>
</li>
<li> <p><code>ibic</code>: Information-matrix-based BIC (IBIC)
</p>
</li>
<li> <p><code>sic</code>: Stochastic Information Criterion (SIC)
</p>
</li>
<li> <p><code>hqc</code>: Hannan-Quinn Information Criterion (HQC)
</p>
</li>
<li> <p><code>icomp</code>: Bozdogan Information Complexity (ICOMP) Criteria
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>
<p>Aaron Boulton (University of Delaware)
</p>
<p>Ruben Arslan (Humboldt-University of Berlin, <a href="mailto:rubenarslan@gmail.com">rubenarslan@gmail.com</a>)
</p>
<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p>Mauricio Garnier-Villarreal (Vrije Universiteit Amsterdam; <a href="mailto:mgv@pm.me">mgv@pm.me</a>)
</p>
<p>A great deal of feedback was provided by Kris Preacher regarding Bollen et
al.'s (2012, 2014) extensions of BIC.
</p>


<h3>References</h3>

<p>Bollen, K. A., Ray, S., Zavisca, J., &amp; Harden, J. J. (2012). A comparison of
Bayes factor approximation methods including two new methods.
<em>Sociological Methods &amp; Research, 41</em>(2), 294&ndash;324.
<a href="https://doi.org/10.1177/0049124112452393">doi:10.1177/0049124112452393</a>
</p>
<p>Bollen, K. A., Harden, J. J., Ray, S., &amp; Zavisca, J. (2014). BIC and
alternative Bayesian information criteria in the selection of structural
equation models. <em>Structural Equation Modeling, 21</em>(1), 1&ndash;19.
<a href="https://doi.org/10.1080/10705511.2014.856691">doi:10.1080/10705511.2014.856691</a>
</p>
<p>Burnham, K., &amp; Anderson, D. (2003). <em>Model selection and
multimodel inference: A practical&ndash;theoretic approach</em>. New York, NY:
Springer&ndash;Verlag.
</p>
<p>Dudgeon, P. (2004). A note on extending Steiger's (1998) multiple sample
RMSEA adjustment to other noncentrality parameter-based statistic.
<em>Structural Equation Modeling, 11</em>(3), 305&ndash;319.
<a href="https://doi.org/10.1207/s15328007sem1103_1">doi:10.1207/s15328007sem1103_1</a>
</p>
<p>Howe, E. D., Bozdogan, H., &amp; Katragadda, S. (2011). Structural equation
modeling (SEM) of categorical and mixed-data using the novel Gifi
transformations and information complexity (ICOMP) criterion.
<em>Istanbul University Journal of the School of Business Administration, 40</em>(1), 86&ndash;123.
</p>
<p>Kuha, J. (2004). AIC and BIC: Comparisons of assumptions and performance.
<em>Sociological Methods Research, 33</em>(2), 188&ndash;229.
<a href="https://doi.org/10.1177/0049124103262065">doi:10.1177/0049124103262065</a>
</p>
<p>Preacher, K. J. (2006). Quantifying parsimony in structural equation
modeling. <em>Multivariate Behavioral Research, 43</em>(3), 227&ndash;259.
<a href="https://doi.org/10.1207/s15327906mbr4103_1">doi:10.1207/s15327906mbr4103_1</a>
</p>
<p>West, S. G., Taylor, A. B., &amp; Wu, W. (2012). Model fit and model selection
in structural equation modeling. In R. H. Hoyle (Ed.), <em>Handbook of
structural equation modeling</em> (pp. 209&ndash;231). New York, NY: Guilford.
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+miPowerFit">miPowerFit()</a></code> For the modification indices and their
power approach for model fit evaluation
</p>
</li>
<li> <p><code><a href="#topic+nullRMSEA">nullRMSEA()</a></code> For RMSEA of the default independence model
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit &lt;- cfa(HS.model, data = HolzingerSwineford1939)
moreFitIndices(fit)

fit2 &lt;- cfa(HS.model, data = HolzingerSwineford1939, estimator = "mlr")
moreFitIndices(fit2)

</code></pre>

<hr>
<h2 id='mvrnonnorm'>Generate Non-normal Data using Vale and Maurelli (1983) method</h2><span id='topic+mvrnonnorm'></span>

<h3>Description</h3>

<p>Generate Non-normal Data using Vale and Maurelli (1983) method. The function
is designed to be as similar as the popular <code>mvrnorm</code> function in the
<code>MASS</code> package. The codes are copied from <code>mvrnorm</code> function in
the <code>MASS</code> package for argument checking and <code>lavaan</code> package for
data generation using Vale and Maurelli (1983) method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mvrnonnorm(n, mu, Sigma, skewness = NULL, kurtosis = NULL,
  empirical = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mvrnonnorm_+3A_n">n</code></td>
<td>
<p>Sample size</p>
</td></tr>
<tr><td><code id="mvrnonnorm_+3A_mu">mu</code></td>
<td>
<p>A mean vector. If elements are named, those will be used as
variable names in the returned data matrix.</p>
</td></tr>
<tr><td><code id="mvrnonnorm_+3A_sigma">Sigma</code></td>
<td>
<p>A positive-definite symmetric matrix specifying the covariance
matrix of the variables. If rows or columns are named (and <code>mu</code> is
unnamed), those will be used as variable names in the returned data matrix.</p>
</td></tr>
<tr><td><code id="mvrnonnorm_+3A_skewness">skewness</code></td>
<td>
<p>A vector of skewness of the variables</p>
</td></tr>
<tr><td><code id="mvrnonnorm_+3A_kurtosis">kurtosis</code></td>
<td>
<p>A vector of excessive kurtosis of the variables</p>
</td></tr>
<tr><td><code id="mvrnonnorm_+3A_empirical">empirical</code></td>
<td>
<p>deprecated, ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data matrix
</p>


<h3>Author(s)</h3>

<p>The original function is the <code><a href="lavaan.html#topic+simulateData">lavaan::simulateData()</a></code>
function written by Yves Rosseel in the <code>lavaan</code> package. The function
is adjusted for a convenient usage by Sunthud Pornprasertmanit
(<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>). Terrence D. Jorgensen added the feature to
retain variable names from <code>mu</code> or <code>Sigma</code>.
</p>


<h3>References</h3>

<p>Vale, C. D. &amp; Maurelli, V. A. (1983). Simulating multivariate
nonormal distributions. <em>Psychometrika, 48</em>(3), 465&ndash;471.
<a href="https://doi.org/10.1007/BF02293687">doi:10.1007/BF02293687</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123)
mvrnonnorm(20, c(1, 2), matrix(c(10, 2, 2, 5), 2, 2),
	skewness = c(5, 2), kurtosis = c(3, 3))
## again, with variable names specified in mu
set.seed(123)
mvrnonnorm(20, c(a = 1, b = 2), matrix(c(10, 2, 2, 5), 2, 2),
	skewness = c(5, 2), kurtosis = c(3, 3))

</code></pre>

<hr>
<h2 id='net'>Nesting and Equivalence Testing</h2><span id='topic+net'></span>

<h3>Description</h3>

<p>This test examines whether pairs of SEMs are nested or equivalent.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>net(..., crit = 1e-04)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="net_+3A_...">...</code></td>
<td>
<p>The <code>lavaan</code> objects used for test of nesting and
equivalence</p>
</td></tr>
<tr><td><code id="net_+3A_crit">crit</code></td>
<td>
<p>The upper-bound criterion for testing the equivalence of models.
Models are considered nested (or equivalent) if the difference between
their <code class="reqn">\chi^2</code> fit statistics is less than this criterion.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The concept of nesting/equivalence should be the same regardless of
estimation method. However, the particular method of testing
nesting/equivalence (as described in Bentler &amp; Satorra, 2010) employed by
the <code>net</code> function analyzes summary statistics (model-implied means and
covariance matrices, not raw data). In the case of robust methods like MLR,
the raw data is only utilized for the robust adjustment to SE and chi-sq,
and the net function only checks the unadjusted chi-sq for the purposes of
testing nesting/equivalence.  This method also applies to models for
categorical data, following the procedure described by Asparouhov &amp; Muthen
(2019).
</p>


<h3>Value</h3>

<p>The <a href="#topic+Net-class">Net</a> object representing the outputs for nesting
and equivalent testing, including a logical matrix of test results and a
vector of degrees of freedom for each model.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Bentler, P. M., &amp; Satorra, A. (2010). Testing model nesting and equivalence.
<em>Psychological Methods, 15</em>(2), 111&ndash;123. <a href="https://doi.org/10.1037/a0019625">doi:10.1037/a0019625</a>
</p>
<p>Asparouhov, T., &amp; Muthen, B. (2019). Nesting and equivalence testing for
structural equation models. <em>Structural Equation Modeling, 26</em>(2),
302&ndash;309. <a href="https://doi.org/10.1080/10705511.2018.1513795">doi:10.1080/10705511.2018.1513795</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
m1 &lt;- ' visual  =~ x1 + x2 + x3
	       textual =~ x4 + x5 + x6
	       speed   =~ x7 + x8 + x9 '


m2 &lt;- ' f1  =~ x1 + x2 + x3 + x4
	       f2 =~ x5 + x6 + x7 + x8 + x9 '

m3 &lt;- ' visual  =~ x1 + x2 + x3
	       textual =~ eq*x4 + eq*x5 + eq*x6
	       speed   =~ x7 + x8 + x9 '

fit1 &lt;- cfa(m1, data = HolzingerSwineford1939)
fit1a &lt;- cfa(m1, data = HolzingerSwineford1939, std.lv = TRUE) # Equivalent to fit1
fit2 &lt;- cfa(m2, data = HolzingerSwineford1939) # Not equivalent to or nested in fit1
fit3 &lt;- cfa(m3, data = HolzingerSwineford1939) # Nested in fit1 and fit1a


tests &lt;- net(fit1, fit1a, fit2, fit3)
tests
summary(tests)


</code></pre>

<hr>
<h2 id='Net-class'>Class For the Result of Nesting and Equivalence Testing</h2><span id='topic+Net-class'></span><span id='topic+show+2CNet-method'></span><span id='topic+summary+2CNet-method'></span>

<h3>Description</h3>

<p>This class contains the results of nesting and equivalence testing among
multiple models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'Net'
show(object)

## S4 method for signature 'Net'
summary(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Net-class_+3A_object">object</code></td>
<td>
<p>An object of class <code>Net</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>show</code></td>
<td>
<p><code>signature(object = "Net")</code>: prints the logical matrix of
test results. <code>NA</code> indicates a model did not converge.</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p><code>signature(object = "Net")</code>: prints a narrative
description of results. The original <code>object</code> is invisibly returned.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>test</code></dt><dd><p>Logical <code>matrix</code> indicating nesting/equivalence among models</p>
</dd>
<dt><code>df</code></dt><dd><p>The degrees of freedom of tested models</p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>Objects can be created via the
<code><a href="#topic+net">net()</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+net">net()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See the example in the net function.

</code></pre>

<hr>
<h2 id='nullRMSEA'>Calculate the RMSEA of the null model</h2><span id='topic+nullRMSEA'></span>

<h3>Description</h3>

<p>Calculate the RMSEA of the null (baseline) model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nullRMSEA(object, scaled = FALSE, silent = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nullRMSEA_+3A_object">object</code></td>
<td>
<p>The lavaan model object provided after running the <code>cfa</code>,
<code>sem</code>, <code>growth</code>, or <code>lavaan</code> functions.</p>
</td></tr>
<tr><td><code id="nullRMSEA_+3A_scaled">scaled</code></td>
<td>
<p>If <code>TRUE</code>, the scaled (or robust, if available) RMSEA
is returned. Ignored if a robust test statistic was not requested.</p>
</td></tr>
<tr><td><code id="nullRMSEA_+3A_silent">silent</code></td>
<td>
<p>If <code>TRUE</code>, do not print anything on the screen.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RMSEA of the null model is calculated similar to the formula provided in the
<code>lavaan</code> package. The standard formula of RMSEA is
</p>
<p style="text-align: center;"><code class="reqn"> RMSEA =\sqrt{\frac{\chi^2}{N \times df} - \frac{1}{N}} \times
\sqrt{G} </code>
</p>

<p>where <code class="reqn">\chi^2</code> is the chi-square test statistic value of the target
model, <code class="reqn">N</code> is the total sample size, <code class="reqn">df</code> is the degree of freedom
of the hypothesized model, <code class="reqn">G</code> is the number of groups. Kenny proposed
in his website that
</p>
<p>&quot;A reasonable rule of thumb is to examine the RMSEA for the null model and
make sure that is no smaller than 0.158. An RMSEA for the model of 0.05 and
a TLI of .90, implies that the RMSEA of the null model is 0.158.  If the
RMSEA for the null model is less than 0.158, an incremental measure of fit
may not be that informative.&quot;
</p>
<p>See also <a href="http://davidakenny.net/cm/fit.htm">http://davidakenny.net/cm/fit.htm</a>
</p>


<h3>Value</h3>

<p>A value of RMSEA of the null model (a <code>numeric</code> vector)
returned invisibly.
</p>


<h3>Author(s)</h3>

<p>Ruben Arslan (Humboldt-University of Berlin, <a href="mailto:rubenarslan@gmail.com">rubenarslan@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Kenny, D. A., Kaniskan, B., &amp; McCoach, D. B. (2015). The
performance of RMSEA in models with small degrees of freedom.
<em>Sociological Methods Research, 44</em>(3), 486&ndash;507.
<a href="https://doi.org/10.1177/0049124114543236">doi:10.1177/0049124114543236</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+miPowerFit">miPowerFit()</a></code> For the modification indices and their
power approach for model fit evaluation
</p>
</li>
<li> <p><code><a href="#topic+moreFitIndices">moreFitIndices()</a></code> For other fit indices
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit &lt;- cfa(HS.model, data = HolzingerSwineford1939)
nullRMSEA(fit)

</code></pre>

<hr>
<h2 id='OLDlavaan.mi-class'>Class for a lavaan Model Fitted to Multiple Imputations</h2><span id='topic+OLDlavaan.mi-class'></span><span id='topic+show+2COLDlavaan.mi-method'></span><span id='topic+summary+2COLDlavaan.mi-method'></span><span id='topic+fitMeasures+2COLDlavaan.mi-method'></span><span id='topic+fitmeasures+2COLDlavaan.mi-method'></span><span id='topic+anova+2COLDlavaan.mi-method'></span><span id='topic+nobs+2COLDlavaan.mi-method'></span><span id='topic+coef+2COLDlavaan.mi-method'></span><span id='topic+vcov+2COLDlavaan.mi-method'></span><span id='topic+fitted+2COLDlavaan.mi-method'></span><span id='topic+fitted.values+2COLDlavaan.mi-method'></span><span id='topic+residuals+2COLDlavaan.mi-method'></span><span id='topic+resid+2COLDlavaan.mi-method'></span>

<h3>Description</h3>

<p>This class extends the <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a> class, created by
fitting a lavaan model to a list of data sets. In this case, the list of
data sets are multiple imputations of missing data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'OLDlavaan.mi'
show(object)

## S4 method for signature 'OLDlavaan.mi'
summary(object, se = TRUE, ci = FALSE,
  level = 0.95, standardized = FALSE, rsquare = FALSE, fmi = FALSE,
  scale.W = !asymptotic, omit.imps = c("no.conv", "no.se"),
  asymptotic = FALSE, header = TRUE, output = "text",
  fit.measures = FALSE, ...)

## S4 method for signature 'OLDlavaan.mi'
nobs(object, total = TRUE)

## S4 method for signature 'OLDlavaan.mi'
coef(object, type = "free", labels = TRUE,
  omit.imps = c("no.conv", "no.se"))

## S4 method for signature 'OLDlavaan.mi'
vcov(object, type = c("pooled", "between", "within",
  "ariv"), scale.W = TRUE, omit.imps = c("no.conv", "no.se"))

## S4 method for signature 'OLDlavaan.mi'
anova(object, ...)

## S4 method for signature 'OLDlavaan.mi'
fitMeasures(object, fit.measures = "all",
  baseline.model = NULL, output = "vector", omit.imps = c("no.conv",
  "no.se"), ...)

## S4 method for signature 'OLDlavaan.mi'
fitmeasures(object, fit.measures = "all",
  baseline.model = NULL, output = "vector", omit.imps = c("no.conv",
  "no.se"), ...)

## S4 method for signature 'OLDlavaan.mi'
fitted(object, omit.imps = c("no.conv", "no.se"))

## S4 method for signature 'OLDlavaan.mi'
fitted.values(object, omit.imps = c("no.conv",
  "no.se"))

## S4 method for signature 'OLDlavaan.mi'
residuals(object, type = c("raw", "cor"),
  omit.imps = c("no.conv", "no.se"))

## S4 method for signature 'OLDlavaan.mi'
resid(object, type = c("raw", "cor"),
  omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OLDlavaan.mi-class_+3A_object">object</code></td>
<td>
<p>An object of class <code>OLDlavaan.mi</code></p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_se">se</code>, <code id="OLDlavaan.mi-class_+3A_ci">ci</code>, <code id="OLDlavaan.mi-class_+3A_level">level</code>, <code id="OLDlavaan.mi-class_+3A_standardized">standardized</code>, <code id="OLDlavaan.mi-class_+3A_rsquare">rsquare</code>, <code id="OLDlavaan.mi-class_+3A_header">header</code>, <code id="OLDlavaan.mi-class_+3A_output">output</code></td>
<td>
<p>See
<code><a href="lavaan.html#topic+parameterEstimates">lavaan::parameterEstimates()</a></code>. The <code style="white-space: pre;">&#8288;output=&#8288;</code> argument
can also be passed to <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code>.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_fmi">fmi</code></td>
<td>
<p><code>logical</code> indicating whether to include the Fraction Missing
Information (FMI) for parameter estimates in the <code>summary</code>
output (see <strong>Value</strong> section).</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_scale.w">scale.W</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (default), the <code>vcov</code>
method will calculate the pooled covariance matrix by scaling the
within-imputation component by the ARIV (see Enders, 2010, p. 235,
for definition and formula). Otherwise, the pooled matrix is
calculated as the weighted sum of the within-imputation and
between-imputation components (see Enders, 2010, ch. 8, for details).
This in turn affects how the <code>summary()</code> method calculates its
pooled standard errors, as well as <code><a href="#topic+lavTestWald.mi">lavTestWald.mi()</a></code>.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation. Specific imputation
numbers can also be included in this argument, in case users want to
apply their own custom omission criteria (or simulations can use
different numbers of imputations without redundantly refitting the
model).</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_asymptotic">asymptotic</code></td>
<td>
<p><code>logical</code>. If <code>FALSE</code> (typically a default, but
see <strong>Value</strong> section for details using various methods), pooled
tests (of fit or pooled estimates) will be <em>F</em> or <em>t</em>
statistics with associated degrees of freedom (<em>df</em>). If
<code>TRUE</code>, the (denominator) <em>df</em> are assumed to be
sufficiently large for a <em>t</em> statistic to follow a normal
distribution, so it is printed as a <em>z</em> statisic; likewise,
<em>F</em> times its numerator <em>df</em> is printed, assumed to follow
a <code class="reqn">\chi^2</code> distribution.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_fit.measures">fit.measures</code>, <code id="OLDlavaan.mi-class_+3A_baseline.model">baseline.model</code></td>
<td>
<p>See <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code>.
<code>summary(object, fit.measures = TRUE)</code> will print (but not
return) a table of fit measures to the console.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to <code><a href="#topic+lavTestLRT.mi">lavTestLRT.mi()</a></code>, or
subsequently to <code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code>.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_total">total</code></td>
<td>
<p><code>logical</code> (default: <code>TRUE</code>) indicating whether the
<code>nobs</code> method should return the total sample size or (if
<code>FALSE</code>) a vector of group sample sizes.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_type">type</code></td>
<td>
<p>The meaning of this argument varies depending on which method it
it used for. Find detailed descriptions in the <strong>Value</strong> section
under <code>coef</code>, <code>vcov</code>, and <code>residuals</code>.</p>
</td></tr>
<tr><td><code id="OLDlavaan.mi-class_+3A_labels">labels</code></td>
<td>
<p><code>logical</code> indicating whether the <code>coef</code> output
should include parameter labels. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>coef</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", type = "free", labels = TRUE, omit.imps = c("no.conv","no.se"))</code>:
See <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>. Returns the pooled point estimates (i.e.,
averaged across imputed data sets; see Rubin, 1987).</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", scale.W = TRUE, omit.imps = c("no.conv","no.se"), type = c("pooled","between","within","ariv"))</code>:  By default, returns the
pooled covariance matrix of parameter estimates (<code>type = "pooled"</code>),
the within-imputations covariance matrix (<code>type = "within"</code>), the
between-imputations covariance matrix (<code>type = "between"</code>), or the
average relative increase in variance (<code>type = "ariv"</code>) due to
missing data.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", omit.imps = c("no.conv","no.se"))</code>: See <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>.
Returns model-implied moments, evaluated at the pooled point estimates.</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>alias for <code>fitted.values</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", type = c("raw","cor"), omit.imps = c("no.conv","no.se"))</code>:
See <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>. By default (<code>type = "raw"</code>), returns
the difference between the model-implied moments from <code>fitted.values</code>
and the pooled observed moments (i.e., averaged across imputed data sets).
Standardized residuals are also available, using Bollen's
(<code>type = "cor"</code> or <code>"cor.bollen"</code>) or Bentler's
(<code>type = "cor.bentler"</code>) formulas.</p>
</td></tr>
<tr><td><code>resid</code></td>
<td>
<p>alias for <code>residuals</code></p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", total = TRUE)</code>: either
the total (default) sample size or a vector of group sample sizes
(<code>total = FALSE</code>).</p>
</td></tr>
<tr><td><code>anova</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", ...)</code>:
Returns a test of model fit for a single model (<code>object</code>) or test(s)
of the difference(s) in fit between nested models passed via <code>...</code>.
See <code><a href="#topic+lavTestLRT.mi">lavTestLRT.mi()</a></code> and <code><a href="#topic+compareFit">compareFit()</a></code> for details.</p>
</td></tr>
<tr><td><code>fitMeasures</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", fit.measures = "all", baseline.model = NULL, output = "vector", omit.imps = c("no.conv","no.se"), ...)</code>: See lavaan's
<code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> for details. Pass additional arguments
to <code><a href="#topic+lavTestLRT.mi">lavTestLRT.mi()</a></code> via <code>...</code>.</p>
</td></tr>
<tr><td><code>fitmeasures</code></td>
<td>
<p>alias for <code>fitMeasures</code>.</p>
</td></tr>
<tr><td><code>show</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi")</code>: returns a message about
convergence rates and estimation problems (if applicable) across imputed
data sets.</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p><code>signature(object = "OLDlavaan.mi", se = TRUE, ci = FALSE, level = .95, standardized = FALSE, rsquare = FALSE, fmi = FALSE, scale.W = !asymptotic, omit.imps = c("no.conv","no.se"), asymptotic = FALSE, header = TRUE, output = "text", fit.measures = FALSE, ...)</code>:
See <code><a href="lavaan.html#topic+parameterEstimates">lavaan::parameterEstimates()</a></code> for details.
By default, <code>summary()</code> returns pooled point and <em>SE</em>
estimates, along with <em>t</em> test statistics and their associated
<em>df</em> and <em>p</em> values. If <code>ci = TRUE</code>, confidence intervals
are returned with the specified confidence <code>level</code> (default 95\
If <code>asymptotic = TRUE</code>, <em>z</em> instead of <em>t</em> tests are
returned. <code>standardized</code> solution(s) can also be requested by name
(<code>"std.lv"</code> or <code>"std.all"</code>) or both are returned with <code>TRUE</code>.
<em>R</em>-squared for endogenous variables can be requested, as well as the
Fraction Missing Information (FMI) for parameter estimates. By default, the
output will appear like <code>lavaan</code>'s <code>summary()</code> output, but if
<code>output == "data.frame"</code>, the returned <code>data.frame</code> will resemble
the <code>parameterEstimates()</code> output. The <code>scale.W</code> argument is
passed to <code>vcov</code> (see description above).
Setting <code>fit.measures=TRUE</code> will additionally print fit measures to
the console, but they will not be returned; additional arguments may be
passed via <code>...</code> to <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> and
subsequently to <code><a href="#topic+lavTestLRT.mi">lavTestLRT.mi()</a></code>.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>coefList</code></dt><dd><p><code>list</code> of estimated coefficients in matrix format (one
per imputation) as output by <code>lavInspect(fit, "est")</code></p>
</dd>
<dt><code>phiList</code></dt><dd><p><code>list</code> of model-implied latent-variable covariance
matrices (one per imputation) as output by
<code>lavInspect(fit, "cov.lv")</code></p>
</dd>
<dt><code>miList</code></dt><dd><p><code>list</code> of modification indices output by
<code><a href="lavaan.html#topic+modificationIndices">lavaan::modindices()</a></code></p>
</dd>
<dt><code>seed</code></dt><dd><p><code>integer</code> seed set before running imputations</p>
</dd>
<dt><code>lavListCall</code></dt><dd><p>call to <code><a href="lavaan.html#topic+lavaanList">lavaan::lavaanList()</a></code> used to fit the
model to the list of imputed data sets in <code style="white-space: pre;">&#8288;@DataList&#8288;</code>, stored as a
<code>list</code> of arguments</p>
</dd>
<dt><code>imputeCall</code></dt><dd><p>call to imputation function (if used), stored as a
<code>list</code> of arguments</p>
</dd>
<dt><code>convergence</code></dt><dd><p><code>list</code> of <code>logical</code> vectors indicating whether,
for each imputed data set, (1) the model converged on a solution, (2)
<em>SE</em>s could be calculated, (3) the (residual) covariance matrix of
latent variables (<code class="reqn">\Psi</code>) is non-positive-definite, and (4) the
residual covariance matrix of observed variables (<code class="reqn">\Theta</code>) is
non-positive-definite.</p>
</dd>
<dt><code>lavaanList_slots</code></dt><dd><p>All remaining slots are from
<a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a>, but <code><a href="#topic+runMI">runMI()</a></code> only populates a
subset of the <code>list</code> slots, two of them with custom information:</p>
</dd>
<dt><code>DataList</code></dt><dd><p>The <code>list</code> of imputed data sets</p>
</dd>
<dt><code>SampleStatsList</code></dt><dd><p>List of output from
<code>lavInspect(fit, "sampstat")</code> applied to each fitted
model</p>
</dd>
<dt><code>ParTableList</code></dt><dd><p>See <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a></p>
</dd>
<dt><code>vcovList</code></dt><dd><p>See <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a></p>
</dd>
<dt><code>testList</code></dt><dd><p>See <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a></p>
</dd>
<dt><code>h1List</code></dt><dd><p>See <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a>. An additional element is
added to the <code>list</code>: <code style="white-space: pre;">&#8288;$PT&#8288;</code> is the &quot;saturated&quot; model's parameter
table, returned by <code><a href="lavaan.html#topic+lav_partable">lavaan::lav_partable_unrestricted()</a></code>.</p>
</dd>
<dt><code>baselineList</code></dt><dd><p>See <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a></p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>See the <code><a href="#topic+runMI">runMI()</a></code> function for details.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Asparouhov, T., &amp; Muthen, B. (2010). <em>Chi-square statistics
with multiple imputation</em>. Technical Report. Retrieved from
<a href="http://www.statmodel.com/">http://www.statmodel.com/</a>
</p>
<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. New York, NY:
Guilford.
</p>
<p>Li, K.-H., Meng, X.-L., Raghunathan, T. E., &amp; Rubin, D. B. (1991).
Significance levels from repeated <em>p</em>-values with multiply-imputed
data. <em>Statistica Sinica, 1</em>(1), 65&ndash;92. Retrieved from
<a href="https://www.jstor.org/stable/24303994">https://www.jstor.org/stable/24303994</a>
</p>
<p>Meng, X.-L., &amp; Rubin, D. B. (1992). Performing likelihood ratio tests with
multiply-imputed data sets. <em>Biometrika, 79</em>(1), 103&ndash;111.
<a href="https://doi.org/10.2307/2337151">doi:10.2307/2337151</a>
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>.
New York, NY: Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See the new lavaan.mi package

</code></pre>

<hr>
<h2 id='parcelAllocation'>Random Allocation of Items to Parcels in a Structural Equation Model</h2><span id='topic+parcelAllocation'></span>

<h3>Description</h3>

<p>This function generates a given number of randomly generated item-to-parcel
allocations, fits a model to each allocation, and provides averaged results
over all allocations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parcelAllocation(model, data, parcel.names, item.syntax, nAlloc = 100,
  fun = "sem", alpha = 0.05, fit.measures = c("chisq", "df", "cfi",
  "tli", "rmsea", "srmr"), ..., show.progress = FALSE, iseed = 12345,
  do.fit = TRUE, return.fit = FALSE, warn = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parcelAllocation_+3A_model">model</code></td>
<td>
<p><code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> model syntax specifying the model
fit to (at least some) parceled data. Note that there can be a mixture of
items and parcels (even within the same factor), in case certain items
should never be parceled. Can be a character string or parameter table.
Also see <code><a href="lavaan.html#topic+model.syntax">lavaan::lavaanify()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing all observed variables appearing
in the <code>model</code>, as well as those in the <code>item.syntax</code> used to
create parcels. If the data have missing values, multiple imputation
before parceling is recommended: submit a stacked data set (with a variable
for the imputation number, so they can be separateed later) and set
<code>do.fit = FALSE</code> to return the list of <code>data.frame</code>s (one per
allocation), each of which is a stacked, imputed data set with parcels.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_parcel.names">parcel.names</code></td>
<td>
<p><code>character</code> vector containing names of all parcels
appearing as indicators in <code>model</code>.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_item.syntax">item.syntax</code></td>
<td>
<p><code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> specifying the model
that would be fit to all of the unparceled items, including items that
should be randomly allocated to parcels appearing in <code>model</code>.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_nalloc">nAlloc</code></td>
<td>
<p>The number of random items-to-parcels allocations to generate.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_fun">fun</code></td>
<td>
<p><code>character</code> string indicating the name of the
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> function used to fit <code>model</code> to
<code>data</code>. Can only take the values <code>"lavaan"</code>, <code>"sem"</code>,
<code>"cfa"</code>, or <code>"growth"</code>.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_alpha">alpha</code></td>
<td>
<p>Alpha level used as criterion for significance.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_fit.measures">fit.measures</code></td>
<td>
<p><code>character</code> vector containing names of fit measures
to request from each fitted <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> model.  See the
output of <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> for a list of available measures.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to
<code><a href="lavaan.html#topic+lavaanList">lavaan::lavaanList()</a></code>. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code></p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_show.progress">show.progress</code></td>
<td>
<p>If <code>TRUE</code>, show a <code><a href="utils.html#topic+txtProgressBar">utils::txtProgressBar()</a></code>
indicating how fast the model-fitting iterates over allocations.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_iseed">iseed</code></td>
<td>
<p>(Optional) Random seed used for parceling items. When the same
random seed is specified and the program is re-run, the same allocations
will be generated. Using the same <code>iseed</code> argument will ensure the
any model is fit to the same parcel allocations. <em>Note</em>: When using
<span class="pkg">parallel</span> options, you must first type <code>RNGkind("L'Ecuyer-CMRG")</code>
into the R Console, so that the seed will be controlled across cores.</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_do.fit">do.fit</code></td>
<td>
<p>If <code>TRUE</code> (default), the <code>model</code> is fitted to each
parceled data set, and the summary of results is returned (see the Value
section below). If <code>FALSE</code>, the items are randomly parceled, but the
model is not fit; instead, the <code>list</code> of <code>data.frame</code>s is
returned (so assign it to an object).</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_return.fit">return.fit</code></td>
<td>
<p>If <code>TRUE</code>, a <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a> object
is returned with the <code>list</code> of results across allocations</p>
</td></tr>
<tr><td><code id="parcelAllocation_+3A_warn">warn</code></td>
<td>
<p>Whether to print warnings when fitting <code>model</code> to each allocation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements the random item-to-parcel allocation procedure
described in Sterba (2011) and Sterba and MacCallum (2010). The function
takes a single data set with item-level data, randomly assigns items to
parcels, fits a structural equation model to the parceled data using
<code><a href="lavaan.html#topic+lavaanList">lavaan::lavaanList()</a></code>, and repeats this process for a user-specified
number of random allocations. Results from all fitted models are summarized
in the output. For further details on the benefits of randomly allocating
items to parcels, see Sterba (2011) and Sterba and MacCallum (2010).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Estimates</code></td>
<td>
<p>A <code>data.frame</code> containing results related to
parameter estimates with columns corresponding to their names; average
and standard deviation across allocations; minimum, maximum, and range
across allocations; and the proportion of allocations in which each
parameter estimate was significant.</p>
</td></tr>
<tr><td><code>SE</code></td>
<td>
<p>A <code>data.frame</code> containing results similar to
<code>Estimates</code>, but related to the standard errors of parameter
estimates.</p>
</td></tr>
<tr><td><code>Fit</code></td>
<td>
<p>A <code>data.frame</code> containing results related to model fit,
with columns corresponding to fit index names; their average and
standard deviation across allocations; the minimum, maximum, and range
across allocations; and (if the test statistic or RMSEA is included in
<code>fit.measures</code>) the proportion of allocations in which each
test of (exact or close) fit was significant.</p>
</td></tr>
<tr><td><code>Model</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaanList-class">lavaan::lavaanList</a> object containing results
of the <code>model</code> fitted to each parcel allocation. Only returned if
<code>return.fit = TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Sterba, S. K. (2011). Implications of parcel-allocation
variability for comparing fit of item-solutions and parcel-solutions.
<em>Structural Equation Modeling, 18</em>(4), 554&ndash;577.
<a href="https://doi.org/10.1080/10705511.2011.607073">doi:10.1080/10705511.2011.607073</a>
</p>
<p>Sterba, S. K. &amp; MacCallum, R. C. (2010). Variability in parameter estimates
and model fit across random allocations of items to parcels.
<em>Multivariate Behavioral Research, 45</em>(2), 322&ndash;358.
<a href="https://doi.org/10.1080/00273171003680302">doi:10.1080/00273171003680302</a>
</p>
<p>Sterba, S. K., &amp; Rights, J. D. (2016). Accounting for parcel-allocation
variability in practice: Combining sources of uncertainty and choosing the
number of allocations. <em>Multivariate Behavioral Research, 51</em>(2&ndash;3),
296&ndash;313. <a href="https://doi.org/10.1080/00273171.2016.1144502">doi:10.1080/00273171.2016.1144502</a>
</p>
<p>Sterba, S. K., &amp; Rights, J. D. (2017). Effects of parceling on model
selection: Parcel-allocation variability in model ranking.
<em>Psychological Methods, 22</em>(1), 47&ndash;68. <a href="https://doi.org/10.1037/met0000067">doi:10.1037/met0000067</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PAVranking">PAVranking()</a></code> for comparing 2 models,
<code><a href="#topic+poolMAlloc">poolMAlloc()</a></code> for choosing the number of allocations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Fit 2-factor CFA to simulated data. Each factor has 9 indicators.

## Specify the item-level model (if NO parcels were created)
item.syntax &lt;- c(paste0("f1 =~ f1item", 1:9),
                 paste0("f2 =~ f2item", 1:9))
cat(item.syntax, sep = "\n")
## Below, we reduce the size of this same model by
## applying different parceling schemes


## 3-indicator parcels
mod.parcels &lt;- '
f1 =~ par1 + par2 + par3
f2 =~ par4 + par5 + par6
'
## names of parcels
(parcel.names &lt;- paste0("par", 1:6))


## override default random-number generator to use parallel options
RNGkind("L'Ecuyer-CMRG")

parcelAllocation(mod.parcels, data = simParcel, nAlloc = 100,
                 parcel.names = parcel.names, item.syntax = item.syntax,
               # parallel = "multicore",  # parallel available in Mac/Linux
                 std.lv = TRUE)           # any addition lavaan arguments



## POOL RESULTS by treating parcel allocations as multiple imputations
## Details provided in Sterba &amp; Rights (2016); see ?poolMAlloc.

## save list of data sets instead of fitting model yet
dataList &lt;- parcelAllocation(mod.parcels, data = simParcel, nAlloc = 100,
                             parcel.names = parcel.names,
                             item.syntax = item.syntax,
                             do.fit = FALSE)
## now fit the model to each data set
library(lavaan.mi)
fit.parcels &lt;- cfa.mi(mod.parcels, data = dataList, std.lv = TRUE)
summary(fit.parcels)        # pooled using Rubin's rules
anova(fit.parcels)          # pooled test statistic
help(package = "lavaan.mi") # find more methods for pooling results



## multigroup example
simParcel$group &lt;- 0:1 # arbitrary groups for example
mod.mg &lt;- '
f1 =~ par1 + c(L2, L2)*par2 + par3
f2 =~ par4 + par5 + par6
'
## names of parcels
(parcel.names &lt;- paste0("par", 1:6))

parcelAllocation(mod.mg, data = simParcel, parcel.names, item.syntax,
                 std.lv = TRUE, group = "group", group.equal = "loadings",
                 nAlloc = 20, show.progress = TRUE)



## parcels for first factor, items for second factor
mod.items &lt;- '
f1 =~ par1 + par2 + par3
f2 =~ f2item2 + f2item7 + f2item8
'
## names of parcels
(parcel.names &lt;- paste0("par", 1:3))

parcelAllocation(mod.items, data = simParcel, parcel.names, item.syntax,
                 nAlloc = 20, std.lv = TRUE)



## mixture of 1- and 3-indicator parcels for second factor
mod.mix &lt;- '
f1 =~ par1 + par2 + par3
f2 =~ f2item2 + f2item7 + f2item8 + par4 + par5 + par6
'
## names of parcels
(parcel.names &lt;- paste0("par", 1:6))

parcelAllocation(mod.mix, data = simParcel, parcel.names, item.syntax,
                 nAlloc = 20, std.lv = TRUE)

</code></pre>

<hr>
<h2 id='partialInvariance'>Partial Measurement Invariance Testing Across Groups</h2><span id='topic+partialInvariance'></span><span id='topic+partialInvarianceCat'></span>

<h3>Description</h3>

<p>This test will provide partial invariance testing by (a) freeing a parameter
one-by-one from nested model and compare with the original nested model or
(b) fixing (or constraining) a parameter one-by-one from the parent model
and compare with the original parent model. This function only works with
congeneric models. The <code>partialInvariance</code> is used for continuous
variable. The <code>partialInvarianceCat</code> is used for categorical variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partialInvariance(fit, type, free = NULL, fix = NULL, refgroup = 1,
  poolvar = TRUE, p.adjust = "none", fbound = 2, return.fit = FALSE,
  method = "satorra.bentler.2001")

partialInvarianceCat(fit, type, free = NULL, fix = NULL, refgroup = 1,
  poolvar = TRUE, p.adjust = "none", return.fit = FALSE,
  method = "satorra.bentler.2001")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="partialInvariance_+3A_fit">fit</code></td>
<td>
<p>A list of models for invariance testing. Each model should be
assigned by appropriate names (see details). The result from
<code><a href="#topic+measurementInvariance">measurementInvariance()</a></code> or
<code><a href="#topic+measurementInvarianceCat">measurementInvarianceCat()</a></code> could be used in this argument
directly.</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_type">type</code></td>
<td>
<p>The types of invariance testing: &quot;metric&quot;, &quot;scalar&quot;, &quot;strict&quot;,
or &quot;means&quot;</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_free">free</code></td>
<td>
<p>A vector of variable names that are free across groups in
advance. If partial mean invariance is tested, this argument represents a
vector of factor names that are free across groups.</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_fix">fix</code></td>
<td>
<p>A vector of variable names that are constrained to be equal
across groups in advance. If partial mean invariance is tested, this
argument represents a vector of factor names that are fixed across groups.</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_refgroup">refgroup</code></td>
<td>
<p>The reference group used to make the effect size comparison
with the other groups.</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_poolvar">poolvar</code></td>
<td>
<p>If <code>TRUE</code>, the variances are pooled across group for
standardization. Otherwise, the variances of the reference group are used
for standardization.</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_p.adjust">p.adjust</code></td>
<td>
<p>The method used to adjust p values. See
<code><a href="stats.html#topic+p.adjust">stats::p.adjust()</a></code> for the options for adjusting p values. The
default is to not use any corrections.</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_fbound">fbound</code></td>
<td>
<p>The z-scores of factor that is used to calculate the effect
size of the loading difference proposed by Millsap and Olivera-Aguilar
(2012).</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_return.fit">return.fit</code></td>
<td>
<p>Return the submodels fitted by this function</p>
</td></tr>
<tr><td><code id="partialInvariance_+3A_method">method</code></td>
<td>
<p>The method used to calculate likelihood ratio test. See
<code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code> for available options</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are four types of partial invariance testing:
</p>

<ul>
<li><p> Partial weak invariance. The model named 'fit.configural'
from the list of models is compared with the model named 'fit.loadings'.
Each loading will be freed or fixed from the metric and configural
invariance models respectively. The modified models are compared with the
original model. Note that the objects in the list of models must have the
names of &quot;fit.configural&quot; and &quot;fit.loadings&quot;. Users may use &quot;metric&quot;,
&quot;weak&quot;, &quot;loading&quot;, or &quot;loadings&quot; in the <code>type</code> argument. Note that, for
testing invariance on marker variables, other variables will be assigned as
marker variables automatically.
</p>
</li>
<li><p> Partial strong invariance. The model
named 'fit.loadings' from the list of models is compared with the model
named either 'fit.intercepts' or 'fit.thresholds'. Each intercept will be
freed or fixed from the scalar and metric invariance models respectively.
The modified models are compared with the original model. Note that the
objects in the list of models must have the names of &quot;fit.loadings&quot; and
either &quot;fit.intercepts&quot; or &quot;fit.thresholds&quot;. Users may use &quot;scalar&quot;,
&quot;strong&quot;, &quot;intercept&quot;, &quot;intercepts&quot;, &quot;threshold&quot;, or &quot;thresholds&quot; in the
<code>type</code> argument. Note that, for testing invariance on marker variables,
other variables will be assigned as marker variables automatically. Note
that if all variables are dichotomous, scalar invariance testing is not
available.
</p>
</li>
<li><p> Partial strict invariance. The model named either
'fit.intercepts' or 'fit.thresholds' (or 'fit.loadings') from the list of
models is compared with the model named 'fit.residuals'. Each residual
variance will be freed or fixed from the strict and scalar (or metric)
invariance models respectively. The modified models are compared with the
original model. Note that the objects in the list of models must have the
names of &quot;fit.residuals&quot; and either &quot;fit.intercepts&quot;, &quot;fit.thresholds&quot;, or
&quot;fit.loadings&quot;. Users may use &quot;strict&quot;, &quot;residual&quot;, &quot;residuals&quot;, &quot;error&quot;, or
&quot;errors&quot; in the <code>type</code> argument.
</p>
</li>
<li><p> Partial mean invariance. The
model named either 'fit.intercepts' or 'fit.thresholds' (or 'fit.residuals'
or 'fit.loadings') from the list of models is compared with the model named
'fit.means'. Each factor mean will be freed or fixed from the means and
scalar (or strict or metric) invariance models respectively. The modified
models are compared with the original model. Note that the objects in the
list of models must have the names of &quot;fit.means&quot; and either
&quot;fit.residuals&quot;, &quot;fit.intercepts&quot;, &quot;fit.thresholds&quot;, or &quot;fit.loadings&quot;.
Users may use &quot;means&quot; or &quot;mean&quot; in the <code>type</code> argument. </p>
</li></ul>

<p>Two types of comparisons are used in this function:
</p>

<ol>
<li> <p><code>free</code>: The nested model is used as a template. Then, one
parameter indicating the differences between two models is free. The new
model is compared with the nested model. This process is repeated for all
differences between two models. The likelihood-ratio test and the difference
in CFI are provided.
</p>
</li>
<li> <p><code>fix</code>: The parent model is used as a template. Then, one parameter
indicating the differences between two models is fixed or constrained to be
equal to other parameters. The new model is then compared with the parent
model. This process is repeated for all differences between two models. The
likelihood-ratio test and the difference in CFI are provided.
</p>
</li>
<li> <p><code>wald</code>: This method is similar to the <code>fix</code> method. However,
instead of building a new model and compare them with likelihood-ratio test,
multivariate wald test is used to compare equality between parameter
estimates. See <code><a href="lavaan.html#topic+lavTestWald">lavaan::lavTestWald()</a></code> for further details. Note
that if any rows of the contrast cannot be summed to 0, the Wald test is not
provided, such as comparing two means where one of the means is fixed as 0.
This test statistic is not as accurate as likelihood-ratio test provided in
<code>fix</code>. I provide it here in case that likelihood-ratio test fails to
converge.
</p>
</li></ol>

<p>Note that this function does not adjust for the inflated Type I error rate
from multiple tests. The degree of freedom of all tests would be the number
of groups minus 1.
</p>
<p>The details of standardized estimates and the effect size used for each
parameters are provided in the vignettes by running
<code>vignette("partialInvariance")</code>.
</p>


<h3>Value</h3>

<p>A list of results are provided. The list will consists of at least
two elements:
</p>

<ol>
<li> <p><code>estimates</code>: The results of parameter estimates including pooled
estimates (<code>poolest</code>), the estimates for each group, standardized
estimates for each group (<code>std</code>), the difference in standardized
values, and the effect size statistic (<em>q</em> for factor loading
difference and <em>h</em> for error variance difference). See the details of
this effect size statistic by running <code>vignette("partialInvariance")</code>.
In the <code>partialInvariance</code> function, the additional effect statistics
proposed by Millsap and Olivera-Aguilar (2012) are provided. For factor
loading, the additional outputs are the observed mean difference
(<code>diff_mean</code>), the mean difference if factor scores are low
(<code>low_fscore</code>), and the mean difference if factor scores are high
(<code>high_fscore</code>). The low factor score is calculated by (a) finding the
factor scores that its <em>z</em> score equals -<code>bound</code> (the default is
<code class="reqn">-2</code>) from all groups and (b) picking the minimum value among the
factor scores. The high factor score is calculated by (a) finding the
factor scores that its <em>z</em> score equals <code>bound</code> (default = 2)
from all groups and (b) picking the maximum value among the factor scores.
For measurement intercepts, the additional outputs are the observed means
difference (<code>diff_mean</code>) and the proportion of the differences in the
intercepts over the observed means differences (<code>propdiff</code>). For error
variances, the additional outputs are the proportion of the difference in
error variances over the difference in observed variances (<code>propdiff</code>).
</p>
</li>
<li> <p><code>results</code>: Statistical tests as well as the change in CFI are
provided. <code class="reqn">\chi^2</code> and <em>p</em> value are provided for all methods.
</p>
</li>
<li> <p><code>models</code>: The submodels used in the <code>free</code> and <code>fix</code>
methods, as well as the nested and parent models. The nested and parent
models will be changed from the original models if <code>free</code> or
<code>fit</code> arguments are specified.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Millsap, R. E., &amp; Olivera-Aguilar, M. (2012). Investigating
measurement invariance using confirmatory factor analysis. In R. H. Hoyle
(Ed.), <em>Handbook of structural equation modeling</em> (pp. 380&ndash;392). New
York, NY: Guilford.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+measurementInvariance">measurementInvariance()</a></code> for measurement invariance for
continuous variables; <code><a href="#topic+measurementInvarianceCat">measurementInvarianceCat()</a></code> for measurement
invariance for categorical variables; <code><a href="lavaan.html#topic+lavTestWald">lavaan::lavTestWald()</a></code> for
multivariate Wald test
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Conduct weak invariance testing manually by using fixed-factor
## method of scale identification

library(lavaan)

conf &lt;- "
f1 =~ NA*x1 + x2 + x3
f2 =~ NA*x4 + x5 + x6
f1 ~~ c(1, 1)*f1
f2 ~~ c(1, 1)*f2
"

weak &lt;- "
f1 =~ NA*x1 + x2 + x3
f2 =~ NA*x4 + x5 + x6
f1 ~~ c(1, NA)*f1
f2 ~~ c(1, NA)*f2
"

configural &lt;- cfa(conf, data = HolzingerSwineford1939, std.lv = TRUE, group="school")
weak &lt;- cfa(weak, data = HolzingerSwineford1939, group="school", group.equal="loadings")
models &lt;- list(fit.configural = configural, fit.loadings = weak)
partialInvariance(models, "metric")


partialInvariance(models, "metric", free = "x5") # "x5" is free across groups in advance
partialInvariance(models, "metric", fix = "x4") # "x4" is fixed across groups in advance

## Use the result from the measurementInvariance function
HW.model &lt;- ' visual =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed =~ x7 + x8 + x9 '

models2 &lt;- measurementInvariance(model = HW.model, data=HolzingerSwineford1939,
                                 group="school")
partialInvariance(models2, "scalar")

## Conduct weak invariance testing manually by using fixed-factor
## method of scale identification for dichotomous variables

f &lt;- rnorm(1000, 0, 1)
u1 &lt;- 0.9*f + rnorm(1000, 1, sqrt(0.19))
u2 &lt;- 0.8*f + rnorm(1000, 1, sqrt(0.36))
u3 &lt;- 0.6*f + rnorm(1000, 1, sqrt(0.64))
u4 &lt;- 0.7*f + rnorm(1000, 1, sqrt(0.51))
u1 &lt;- as.numeric(cut(u1, breaks = c(-Inf, 0, Inf)))
u2 &lt;- as.numeric(cut(u2, breaks = c(-Inf, 0.5, Inf)))
u3 &lt;- as.numeric(cut(u3, breaks = c(-Inf, 0, Inf)))
u4 &lt;- as.numeric(cut(u4, breaks = c(-Inf, -0.5, Inf)))
g &lt;- rep(c(1, 2), 500)
dat2 &lt;- data.frame(u1, u2, u3, u4, g)

configural2 &lt;- "
f1 =~ NA*u1 + u2 + u3 + u4
u1 | c(t11, t11)*t1
u2 | c(t21, t21)*t1
u3 | c(t31, t31)*t1
u4 | c(t41, t41)*t1
f1 ~~ c(1, 1)*f1
f1 ~ c(0, NA)*1
u1 ~~ c(1, 1)*u1
u2 ~~ c(1, NA)*u2
u3 ~~ c(1, NA)*u3
u4 ~~ c(1, NA)*u4
"

outConfigural2 &lt;- cfa(configural2, data = dat2, group = "g",
                      parameterization = "theta", estimator = "wlsmv",
                      ordered = c("u1", "u2", "u3", "u4"))

weak2 &lt;- "
f1 =~ NA*u1 + c(f11, f11)*u1 + c(f21, f21)*u2 + c(f31, f31)*u3 + c(f41, f41)*u4
u1 | c(t11, t11)*t1
u2 | c(t21, t21)*t1
u3 | c(t31, t31)*t1
u4 | c(t41, t41)*t1
f1 ~~ c(1, NA)*f1
f1 ~ c(0, NA)*1
u1 ~~ c(1, 1)*u1
u2 ~~ c(1, NA)*u2
u3 ~~ c(1, NA)*u3
u4 ~~ c(1, NA)*u4
"

outWeak2 &lt;- cfa(weak2, data = dat2, group = "g", parameterization = "theta",
                estimator = "wlsmv", ordered = c("u1", "u2", "u3", "u4"))
modelsCat &lt;- list(fit.configural = outConfigural2, fit.loadings = outWeak2)

partialInvarianceCat(modelsCat, type = "metric")

partialInvarianceCat(modelsCat, type = "metric", free = "u2")
partialInvarianceCat(modelsCat, type = "metric", fix = "u3")

## Use the result from the measurementInvarianceCat function

model &lt;- ' f1 =~ u1 + u2 + u3 + u4
           f2 =~ u5 + u6 + u7 + u8'

modelsCat2 &lt;- measurementInvarianceCat(model = model, data = datCat, group = "g",
	                                      parameterization = "theta",
	                                      estimator = "wlsmv", strict = TRUE)

partialInvarianceCat(modelsCat2, type = "scalar")


</code></pre>

<hr>
<h2 id='PAVranking'>Parcel-Allocation Variability in Model Ranking</h2><span id='topic+PAVranking'></span>

<h3>Description</h3>

<p>This function quantifies and assesses the consequences of parcel-allocation
variability for model ranking of structural equation models (SEMs) that
differ in their structural specification but share the same parcel-level
measurement specification (see Sterba &amp; Rights, 2016). This function calls
<code><a href="#topic+parcelAllocation">parcelAllocation()</a></code>&mdash;which can be used with only one SEM in
isolation&mdash;to fit two (assumed) nested models to each of a specified number
of random item-to-parcel allocations.  Output includes summary information
about the distribution of model selection results (including plots) and the
distribution of results for each model individually, across allocations
within-sample. Note that this function can be used when selecting among more
than two competing structural models as well (see instructions below
involving the <code style="white-space: pre;">&#8288;seed=&#8288;</code> argument).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PAVranking(model0, model1, data, parcel.names, item.syntax, nAlloc = 100,
  fun = "sem", alpha = 0.05, bic.crit = 10, fit.measures = c("chisq",
  "df", "cfi", "tli", "rmsea", "srmr", "logl", "aic", "bic", "bic2"), ...,
  show.progress = FALSE, iseed = 12345, warn = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PAVranking_+3A_model0">model0</code>, <code id="PAVranking_+3A_model1">model1</code></td>
<td>
<p><code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> model syntax specifying
nested models (<code>model0</code> within <code>model1</code>) to be fitted
to the same parceled data.  Note that there can be a mixture of
items and parcels (even within the same factor), in case certain items
should never be parceled. Can be a character string or parameter table.
Also see <code><a href="lavaan.html#topic+model.syntax">lavaan::lavaanify()</a></code> for more details.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing all observed variables appearing
in <code style="white-space: pre;">&#8288;model0=&#8288;</code> and <code style="white-space: pre;">&#8288;model1=&#8288;</code>, as well as those in the <code style="white-space: pre;">&#8288;item.syntax=&#8288;</code> used to
create parcels. If the data have missing values, multiple imputation
before parceling is recommended: submit a stacked data set (with a variable
for the imputation number, so they can be separated later) and set
<code>do.fit=FALSE</code> to return the list of <code>data.frame</code>s (one per
allocation), each of which is a stacked, multiply imputed data set with
parcels created using the same allocation scheme.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_parcel.names">parcel.names</code></td>
<td>
<p><code>character</code> vector containing names of all parcels
appearing as indicators in <code style="white-space: pre;">&#8288;model0=&#8288;</code> or <code style="white-space: pre;">&#8288;model1=&#8288;</code>.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_item.syntax">item.syntax</code></td>
<td>
<p><code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> model syntax specifying the model
that would be fit to all of the unparceled items, including items that
should be randomly allocated to parcels appearing in <code style="white-space: pre;">&#8288;model0=&#8288;</code> and <code style="white-space: pre;">&#8288;model1=&#8288;</code>.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_nalloc">nAlloc</code></td>
<td>
<p>The number of random items-to-parcels allocations to generate.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_fun">fun</code></td>
<td>
<p><code>character</code> string indicating the name of the
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> function used to fit  <code style="white-space: pre;">&#8288;model0=&#8288;</code> and <code style="white-space: pre;">&#8288;model1=&#8288;</code> to <code style="white-space: pre;">&#8288;data=&#8288;</code>.
Can only take the values <code>"lavaan"</code>, <code>"sem"</code>, <code>"cfa"</code>, or <code>"growth"</code>.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_alpha">alpha</code></td>
<td>
<p>Alpha level used as criterion for significance.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_bic.crit">bic.crit</code></td>
<td>
<p>Criterion for assessing evidence in favor of one model
over another.  See Rafferty (1995) for guidelines (default is &quot;very
strong evidence&quot; in favor of the model with lower BIC).</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_fit.measures">fit.measures</code></td>
<td>
<p><code>character</code> vector containing names of fit measures
to request from each fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> model.  See the
output of <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> for a list of available measures.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to
<code><a href="lavaan.html#topic+lavaanList">lavaan::lavaanList()</a></code>. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code></p>
</td></tr>
<tr><td><code id="PAVranking_+3A_show.progress">show.progress</code></td>
<td>
<p>If <code>TRUE</code>, show a <code><a href="utils.html#topic+txtProgressBar">utils::txtProgressBar()</a></code>
indicating how fast each model-fitting iterates over allocations.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_iseed">iseed</code></td>
<td>
<p>(Optional) Random seed used for parceling items. When the same
random seed is specified and the program is re-run, the same allocations
will be generated. The seed argument can be used to assess parcel-allocation
variability in model ranking when considering more than two models. For each
pair of models under comparison, the program should be rerun using the same
random seed. Doing so ensures that multiple model comparisons will employ
the same set of parcel datasets. <em>Note</em>: When using <span class="pkg">parallel</span>
options, you must first type <code>RNGkind("L'Ecuyer-CMRG")</code> into the R
Console, so that the seed will be controlled across cores.</p>
</td></tr>
<tr><td><code id="PAVranking_+3A_warn">warn</code></td>
<td>
<p>Whether to print warnings when fitting models to each allocation</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is based on a SAS macro <code>ParcelAlloc</code> (Sterba &amp; MacCallum, 2010).
The <code>PAVranking()</code> function produces results discussed in Sterba and
Rights (2016) relevant to the assessment of parcel-allocation variability in
model selection and model ranking. Specifically, the <code>PAVranking()</code>
function first calls <code><a href="#topic+parcelAllocation">parcelAllocation()</a></code> to generate a given
number (<code style="white-space: pre;">&#8288;nAlloc=&#8288;</code>) of item-to-parcel allocations, fitting both specified
models to each allocation, and providing summaryies of PAV for each model.
Additionally, <code>PAVranking()</code> provides the following new summaries:
</p>

<ul>
<li><p>PAV in model selection index values and model ranking between
Models <code style="white-space: pre;">&#8288;model0=&#8288;</code> and <code style="white-space: pre;">&#8288;model1=&#8288;</code>.
</p>
</li>
<li><p>The proportion of allocations that converged and the proportion of
proper solutions (results are summarized for allocations with both
converged and proper  allocations only).
</p>
</li></ul>

<p>For further details on the benefits of the random allocation of items to
parcels, see Sterba (2011) and Sterba and MacCallum (2010).
</p>
<p>To test whether nested models have equivalent fit, results can be pooled
across allocations using the same methods available for pooling results
across multiple imputations of missing data (see <strong>Examples</strong>).
</p>
<p><em>Note</em>: This function requires the <code>lavaan</code> package. Missing data
must be coded as <code>NA</code>. If the function returns <code>"Error in plot.new() : figure margins too large"</code>, the user may need to increase
size of the plot window (e.g., in RStudio) and rerun the function.
</p>


<h3>Value</h3>

<p>A <code>list</code> with 3 elements.  The first two (<code>model0.results</code> and
<code>model1.results</code>) are results returned by <code><a href="#topic+parcelAllocation">parcelAllocation()</a></code>
for <code>model0</code> and <code>model1</code>, respectively.
The third element (<code>model0.v.model1</code>) is a <code>list</code> of
model-comparison results, including the following:
</p>
<table role = "presentation">
<tr><td><code>\verb{LRT_Summary:}</code></td>
<td>
<p> The average likelihood ratio test across
allocations, as well as the <em>SD</em>, minimum, maximum, range, and the
proportion of allocations for which the test was significant.</p>
</td></tr>
<tr><td><code>\verb{Fit_Index_Differences:}</code></td>
<td>
<p> Differences in fit indices, organized
by what proportion favored each model and among those, what the average
difference was.</p>
</td></tr>
<tr><td><code>\verb{Favored_by_BIC:}</code></td>
<td>
<p> The proportion of allocations in which each
model met the criterion (<code>bic.crit</code>) for a substantial difference
in fit.</p>
</td></tr>
<tr><td><code>\verb{Convergence_Summary:}</code></td>
<td>
<p> The proportion of allocations in which
each model (and both models) converged on a solution.</p>
</td></tr>
</table>
<p>Histograms are also printed to the current plot-output device.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Raftery, A. E. (1995). Bayesian model selection in social
research. <em>Sociological Methodology, 25</em>, 111&ndash;163. <a href="https://doi.org/10.2307/271063">doi:10.2307/271063</a>
</p>
<p>Sterba, S. K. (2011). Implications of parcel-allocation variability for
comparing fit of item-solutions and parcel-solutions. <em>Structural
Equation Modeling, 18</em>(4), 554&ndash;577.<a href="https://doi.org/10.1080/10705511.2011.607073">doi:10.1080/10705511.2011.607073</a>
</p>
<p>Sterba, S. K., &amp; MacCallum, R. C. (2010). Variability in parameter estimates
and model fit across repeated allocations of items to parcels.
<em>Multivariate Behavioral Research, 45</em>(2), 322&ndash;358.
<a href="https://doi.org/10.1080/00273171003680302">doi:10.1080/00273171003680302</a>
</p>
<p>Sterba, S. K., &amp; Rights, J. D. (2016). Accounting for parcel-allocation
variability in practice: Combining sources of uncertainty and choosing the
number of allocations. <em>Multivariate Behavioral Research, 51</em>(2&ndash;3),
296&ndash;313. <a href="https://doi.org/10.1080/00273171.2016.1144502">doi:10.1080/00273171.2016.1144502</a>
</p>
<p>Sterba, S. K., &amp; Rights, J. D. (2017). Effects of parceling on model
selection: Parcel-allocation variability in model ranking.
<em>Psychological Methods, 22</em>(1), 47&ndash;68. <a href="https://doi.org/10.1037/met0000067">doi:10.1037/met0000067</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+parcelAllocation">parcelAllocation()</a></code> for fitting a single model,
<code><a href="#topic+poolMAlloc">poolMAlloc()</a></code> for choosing the number of allocations
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Specify the item-level model (if NO parcels were created)
## This must apply to BOTH competing models

item.syntax &lt;- c(paste0("f1 =~ f1item", 1:9),
                 paste0("f2 =~ f2item", 1:9))
cat(item.syntax, sep = "\n")
## Below, we reduce the size of this same model by
## applying different parceling schemes

## Specify a 2-factor CFA with correlated factors, using 3-indicator parcels
mod1 &lt;- '
f1 =~ par1 + par2 + par3
f2 =~ par4 + par5 + par6
'
## Specify a more restricted model with orthogonal factors
mod0 &lt;- '
f1 =~ par1 + par2 + par3
f2 =~ par4 + par5 + par6
f1 ~~ 0*f2
'
## names of parcels (must apply to BOTH models)
(parcel.names &lt;- paste0("par", 1:6))


## override default random-number generator to use parallel options
RNGkind("L'Ecuyer-CMRG")

PAVranking(model0 = mod0, model1 = mod1, data = simParcel, nAlloc = 100,
           parcel.names = parcel.names, item.syntax = item.syntax,
           # parallel = "multicore",   # parallel available on Mac/Linux
           std.lv = TRUE)       # any addition lavaan arguments



## POOL RESULTS by treating parcel allocations as multiple imputations.
## Details provided in Sterba &amp; Rights (2016); see ?poolMAlloc.

## save list of data sets instead of fitting model yet
dataList &lt;- parcelAllocation(mod0, # or mod1 (either uses same allocations)
                             data = simParcel, nAlloc = 100,
                             parcel.names = parcel.names,
                             item.syntax = item.syntax,
                             do.fit = FALSE)
## now fit each model to each data set
if(requireNamespace("lavaan.mi")){
  library(lavaan.mi)
  fit0 &lt;- cfa.mi(mod0, data = dataList, std.lv = TRUE)
  fit1 &lt;- cfa.mi(mod1, data = dataList, std.lv = TRUE)
  anova(fit0, fit1)           # Pooled test statistic comparing models.
  help(package = "lavaan.mi") # Find more methods for pooling results.
}



</code></pre>

<hr>
<h2 id='permuteMeasEq'>Permutation Randomization Tests of Measurement Equivalence and Differential
Item Functioning (DIF)</h2><span id='topic+permuteMeasEq'></span>

<h3>Description</h3>

<p>The function <code>permuteMeasEq</code> provides tests of hypotheses involving
measurement equivalence, in one of two frameworks: multigroup CFA or MIMIC
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>permuteMeasEq(nPermute, modelType = c("mgcfa", "mimic"), con, uncon = NULL,
  null = NULL, param = NULL, freeParam = NULL, covariates = NULL,
  AFIs = NULL, moreAFIs = NULL, maxSparse = 10, maxNonconv = 10,
  showProgress = TRUE, warn = -1, datafun, extra,
  parallelType = c("none", "multicore", "snow"), ncpus = NULL, cl = NULL,
  iseed = 12345)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permuteMeasEq_+3A_npermute">nPermute</code></td>
<td>
<p>An integer indicating the number of random permutations used
to form empirical distributions under the null hypothesis.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_modeltype">modelType</code></td>
<td>
<p>A character string indicating type of model employed:
multiple-group CFA (<code>"mgcfa"</code>) or MIMIC (<code>"mimic"</code>).</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_con">con</code></td>
<td>
<p>The constrained <code>lavaan</code> object, in which the parameters
specified in <code>param</code> are constrained to equality across all groups when
<code>modelType = "mgcfa"</code>, or which regression paths are fixed to zero when
<code>modelType = "mimic"</code>. In the case of testing <em>configural</em>
invariance when <code>modelType = "mgcfa"</code>, <code>con</code> is the configural
model (implicitly, the unconstrained model is the saturated model, so use
the defaults <code>uncon = NULL</code> and <code>param = NULL</code>). When
<code>modelType = "mimic"</code>, <code>con</code> is the MIMIC model in which the
covariate predicts the latent construct(s) but no indicators (unless they
have already been identified as DIF items).</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_uncon">uncon</code></td>
<td>
<p>Optional.  The unconstrained <code>lavaan</code> object, in which the
parameters specified in <code>param</code> are freely estimated in all groups.
When <code>modelType = "mgcfa"</code>, only in the case of testing
<em>configural</em> invariance should <code>uncon = NULL</code>. When
<code>modelType = "mimic"</code>, any non-<code style="white-space: pre;">&#8288;NULL uncon&#8288;</code> is silently set to
<code>NULL</code>.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_null">null</code></td>
<td>
<p>Optional.  A <code>lavaan</code> object, in which an alternative null
model is fit (besides the default independence model specified by
<code>lavaan</code>) for the calculation of incremental fit indices. See Widamin &amp;
Thompson (2003) for details. If <code>NULL</code>, <code>lavaan</code>'s default
independence model is used.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_param">param</code></td>
<td>
<p>An optional character vector or list of character vectors
indicating which parameters the user would test for DIF following a
rejection of the omnibus null hypothesis tested using
(<code>more</code>)<code>AFIs</code>. Note that <code>param</code> does not guarantee certain
parameters <em>are</em> constrained in <code>con</code>; that is for the user to
specify when fitting the model. If users have any &quot;anchor items&quot; that they
would never intend to free across groups (or levels of a covariate), these
should be excluded from <code>param</code>; exceptions to a type of parameter can
be specified in <code>freeParam</code>. When <code>modelType = "mgcfa"</code>,
<code>param</code> indicates which parameters of interest are constrained across
groups in <code>con</code> and are unconstrained in <code>uncon</code>. Parameter names
must match those returned by <code>names(coef(con))</code>, but omitting any
group-specific suffixes (e.g., <code>"f1~1"</code> rather than <code>"f1~1.g2"</code>)
or user-specified labels (that is, the parameter names must follow the rules
of lavaan's <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code>). Alternatively (or
additionally), to test all constraints of a certain type (or multiple types)
of parameter in <code>con</code>, <code>param</code> may take any combination of the
following values: <code>"loadings"</code>, <code>"intercepts"</code>,
<code>"thresholds"</code>, <code>"residuals"</code>, <code>"residual.covariances"</code>,
<code>"means"</code>, <code>"lv.variances"</code>, and/or <code>"lv.covariances"</code>. When
<code>modelType = "mimic"</code>, <code>param</code> must be a vector of individual
parameters or a list of character strings to be passed one-at-a-time to
<code>lavaan::lavTestScore(object = con, add = param[i])</code>,
indicating which (sets of) regression paths fixed to zero in <code>con</code> that
the user would consider freeing (i.e., exclude anchor items). If
<code>modelType = "mimic"</code> and <code>param</code> is a list of character strings,
the multivariate test statistic will be saved for each list element instead
of 1-<em>df</em> modification indices for each individual parameter, and
<code>names(param)</code> will name the rows of the <code>MI.obs</code> slot (see
<a href="#topic+permuteMeasEq-class">permuteMeasEq</a>). Set <code>param = NULL</code> (default) to avoid
collecting modification indices for any follow-up tests.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_freeparam">freeParam</code></td>
<td>
<p>An optional character vector, silently ignored when
<code>modelType = "mimic"</code>. If <code>param</code> includes a type of parameter
(e.g., <code>"loadings"</code>), <code>freeParam</code> indicates exceptions (i.e.,
anchor items) that the user would <em>not</em> intend to free across groups
and should therefore be ignored when calculating <em>p</em> values adjusted
for the number of follow-up tests. Parameter types that are already
unconstrained across groups in the fitted <code>con</code> model (i.e., a
<em>partial</em> invariance model) will automatically be ignored, so they do
not need to be specified in <code>freeParam</code>. Parameter names must match
those returned by <code>names(coef(con))</code>, but omitting any group-specific
suffixes (e.g., <code>"f1~1"</code> rather than <code>"f1~1.g2"</code>) or
user-specified labels (that is, the parameter names must follow the rules of
lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code>).</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_covariates">covariates</code></td>
<td>
<p>An optional character vector, only applicable when
<code>modelType = "mimic"</code>. The observed data are partitioned into columns
indicated by <code>covariates</code>, and the rows are permuted simultaneously for
the entire set before being merged with the remaining data.  Thus, the
covariance structure is preserved among the covariates, which is necessary
when (e.g.) multiple dummy codes are used to represent a discrete covariate
or when covariates interact. If <code>covariates = NULL</code> when
<code>modelType = "mimic"</code>, the value of <code>covariates</code> is inferred by
searching <code>param</code> for predictors (i.e., variables appearing after the
&quot;<code>~</code>&quot; operator).</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_afis">AFIs</code></td>
<td>
<p>A character vector indicating which alternative fit indices (or
chi-squared itself) are to be used to test the multiparameter omnibus null
hypothesis that the constraints specified in <code>con</code> hold in the
population. Any fit measures returned by <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code>
may be specified (including constants like <code>"df"</code>, which would be
nonsensical). If both <code>AFIs</code> and <code>moreAFIs</code> are <code>NULL</code>, only
<code>"chisq"</code> will be returned.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_moreafis">moreAFIs</code></td>
<td>
<p>Optional. A character vector indicating which (if any)
alternative fit indices returned by <code><a href="#topic+moreFitIndices">moreFitIndices()</a></code>
are to be used to test the multiparameter omnibus null hypothesis that the
constraints specified in <code>con</code> hold in the population.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_maxsparse">maxSparse</code></td>
<td>
<p>Only applicable when <code>modelType = "mgcfa"</code> and at
least one indicator is <code>ordered</code>. An integer indicating the maximum
number of consecutive times that randomly permuted group assignment can
yield a sample in which at least one category (of an <code>ordered</code>
indicator) is unobserved in at least one group, such that the same set of
parameters cannot be estimated in each group. If such a sample occurs, group
assignment is randomly permuted again, repeatedly until a sample is obtained
with all categories observed in all groups. If <code>maxSparse</code> is exceeded,
<code>NA</code> will be returned for that iteration of the permutation
distribution.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_maxnonconv">maxNonconv</code></td>
<td>
<p>An integer indicating the maximum number of consecutive
times that a random permutation can yield a sample for which the model does
not converge on a solution. If such a sample occurs, permutation is
attempted repeatedly until a sample is obtained for which the model does
converge. If <code>maxNonconv</code> is exceeded, <code>NA</code> will be returned for
that iteration of the permutation distribution, and a warning will be
printed when using <code>show</code> or <code>summary</code>.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_showprogress">showProgress</code></td>
<td>
<p>Logical. Indicating whether to display a progress bar
while permuting. Silently set to <code>FALSE</code> when using parallel options.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_warn">warn</code></td>
<td>
<p>Sets the handling of warning messages when fitting model(s) to
permuted data sets. See <code><a href="base.html#topic+options">base::options()</a></code>.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_datafun">datafun</code></td>
<td>
<p>An optional function that can be applied to the data
(extracted from <code>con</code>) after each permutation, but before fitting the
model(s) to each permutation. The <code>datafun</code> function must have an
argument named <code>data</code> that accepts a <code>data.frame</code>, and it must
return a <code>data.frame</code> containing the same column names. The column
order may differ, the values of those columns may differ (so be careful!),
and any additional columns will be ignored when fitting the model, but an
error will result if any column names required by the model syntax do not
appear in the transformed data set. Although available for any
<code>modelType</code>, <code>datafun</code> may be useful when using the MIMIC method
to test for nonuniform DIF (metric/weak invariance) by using product
indicators for a latent factor representing the interaction between a factor
and one of the <code>covariates</code>, in which case the product indicators would
need to be recalculated after each permutation of the <code>covariates</code>. To
access other R objects used within <code>permuteMeasEq</code>, the arguments to
<code>datafun</code> may also contain any subset of the following: <code>"con"</code>,
<code>"uncon"</code>, <code>"null"</code>, <code>"param"</code>, <code>"freeParam"</code>,
<code>"covariates"</code>, <code>"AFIs"</code>, <code>"moreAFIs"</code>, <code>"maxSparse"</code>,
<code>"maxNonconv"</code>, and/or <code>"iseed"</code>. The values for those arguments
will be the same as the values supplied to <code>permuteMeasEq</code>.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_extra">extra</code></td>
<td>
<p>An optional function that can be applied to any (or all) of the
fitted lavaan objects (<code>con</code>, <code>uncon</code>, and/or <code>null</code>). This
function will also be applied after fitting the model(s) to each permuted
data set. To access the R objects used within <code>permuteMeasEq</code>, the
arguments to <code>extra</code> must be any subset of the following: <code>"con"</code>,
<code>"uncon"</code>, <code>"null"</code>, <code>"param"</code>, <code>"freeParam"</code>,
<code>"covariates"</code>, <code>"AFIs"</code>, <code>"moreAFIs"</code>, <code>"maxSparse"</code>,
<code>"maxNonconv"</code>, and/or <code>"iseed"</code>. The values for those arguments
will be the same as the values supplied to <code>permuteMeasEq</code>. The
<code>extra</code> function must return a named <code>numeric</code> vector or a named
<code>list</code> of scalars (i.e., a <code>list</code> of <code>numeric</code> vectors of
<code>length == 1</code>). Any unnamed elements (e.g., <code>""</code> or <code>NULL</code>)
of the returned object will result in an error.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_paralleltype">parallelType</code></td>
<td>
<p>The type of parallel operation to be used (if any). The
default is <code>"none"</code>. Forking is not possible on Windows, so if
<code>"multicore"</code> is requested on a Windows machine, the request will be
changed to <code>"snow"</code> with a message.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_ncpus">ncpus</code></td>
<td>
<p>Integer: number of processes to be used in parallel operation.
If <code>NULL</code> (the default) and <code>parallelType %in% c("multicore","snow")</code>, the default is one less than the maximum number of
processors detected by <code><a href="parallel.html#topic+detectCores">parallel::detectCores()</a></code>. This default is
also silently set if the user specifies more than the number of processors
detected.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_cl">cl</code></td>
<td>
<p>An optional <span class="pkg">parallel</span> or <span class="pkg">snow</span> cluster for use when
<code>parallelType = "snow"</code>.  If <code>NULL</code>, a <code>"PSOCK"</code> cluster on
the local machine is created for the duration of the <code>permuteMeasEq</code>
call. If a valid <code><a href="parallel.html#topic+makeCluster">parallel::makeCluster()</a></code> object is supplied,
<code>parallelType</code> is silently set to <code>"snow"</code>, and <code>ncpus</code> is
silently set to <code>length(cl)</code>.</p>
</td></tr>
<tr><td><code id="permuteMeasEq_+3A_iseed">iseed</code></td>
<td>
<p>Integer: Only used to set the states of the RNG when using
parallel options, in which case <code><a href="base.html#topic+Random">base::RNGkind()</a></code> is set to
<code>"L'Ecuyer-CMRG"</code> with a message. See
<code><a href="parallel.html#topic+RngStream">parallel::clusterSetRNGStream()</a></code> and Section 6 of
<code>vignette("parallel", "parallel")</code> for more details. If user supplies
an invalid value, <code>iseed</code> is silently set to the default (12345). To
set the state of the RNG when not using parallel options, call
<code><a href="base.html#topic+Random">base::set.seed()</a></code> before calling <code>permuteMeasEq</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>permuteMeasEq</code> provides tests of hypotheses involving
measurement equivalence, in one of two frameworks:
</p>

<ol>
<li><p>1 For multiple-group CFA models, provide a pair of nested lavaan objects,
the less constrained of which (<code>uncon</code>) freely estimates a set of
measurement parameters (e.g., factor loadings, intercepts, or thresholds;
specified in <code>param</code>) in all groups, and the more constrained of which
(<code>con</code>) constrains those measurement parameters to equality across
groups. Group assignment is repeatedly permuted and the models are fit to
each permutation, in order to produce an empirical distribution under the
null hypothesis of no group differences, both for (a) changes in
user-specified fit measures (see <code>AFIs</code> and <code>moreAFIs</code>) and for
(b) the maximum modification index among the user-specified equality
constraints. Configural invariance can also be tested by providing that
fitted lavaan object to <code>con</code> and leaving <code>uncon = NULL</code>, in which
case <code>param</code> must be <code>NULL</code> as well.
</p>
</li>
<li><p>2 In MIMIC models, one or a set of continuous and/or discrete
<code>covariates</code> can be permuted, and a constrained model is fit to each
permutation in order to provide a distribution of any fit measures (namely,
the maximum modification index among fixed parameters in <code>param</code>) under
the null hypothesis of measurement equivalence across levels of those
covariates.
</p>
</li></ol>

<p>In either framework, modification indices for equality constraints or fixed
parameters specified in <code>param</code> are calculated from the constrained
model (<code>con</code>) using the function <code><a href="lavaan.html#topic+lavTestScore">lavaan::lavTestScore()</a></code>.
</p>
<p>For multiple-group CFA models, the multiparameter omnibus null hypothesis of
measurement equivalence/invariance is that there are no group differences in
any measurement parameters (of a particular type). This can be tested using
the <code>anova</code> method on nested <code>lavaan</code> objects, as seen in the
output of <code><a href="#topic+measurementInvariance">measurementInvariance()</a></code>, or by inspecting
the change in alternative fit indices (AFIs) such as the CFI. The
permutation randomization method employed by <code>permuteMeasEq</code> generates
an empirical distribution of any <code>AFIs</code> under the null hypothesis, so
the user is not restricted to using fixed cutoffs proposed by Cheung &amp;
Rensvold (2002), Chen (2007), or Meade, Johnson, &amp; Braddy (2008).
</p>
<p>If the multiparameter omnibus null hypothesis is rejected, partial
invariance can still be established by freeing invalid equality constraints,
as long as equality constraints are valid for at least two indicators per
factor. Modification indices can be calculated from the constrained model
(<code>con</code>), but multiple testing leads to inflation of Type I error rates.
The permutation randomization method employed by <code>permuteMeasEq</code>
creates a distribution of the maximum modification index if the null
hypothesis is true, which allows the user to control the familywise Type I
error rate in a manner similar to Tukey's <em>q</em> (studentized range)
distribution for the Honestly Significant Difference (HSD) post hoc test.
</p>
<p>For MIMIC models, DIF can be tested by comparing modification indices of
regression paths to the permutation distribution of the maximum modification
index, which controls the familywise Type I error rate. The MIMIC approach
could also be applied with multiple-group models, but the grouping variable
would not be permuted; rather, the covariates would be permuted separately
within each group to preserve between-group differences. So whether
parameters are constrained or unconstrained across groups, the MIMIC
approach is only for testing null hypotheses about the effects of
<code>covariates</code> on indicators, controlling for common factors.
</p>
<p>In either framework, <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>'s <code>group.label</code>
argument is used to preserve the order of groups seen in <code>con</code> when
permuting the data.
</p>


<h3>Value</h3>

<p>The <a href="#topic+permuteMeasEq-class">permuteMeasEq</a> object representing the results of
testing measurement equivalence (the multiparameter omnibus test) and DIF
(modification indices), as well as diagnostics and any <code>extra</code> output.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p><strong>Papers about permutation tests of measurement equivalence:</strong>
</p>
<p>Jorgensen, T. D., Kite, B. A., Chen, P.-Y., &amp; Short, S. D. (2018).
Permutation randomization methods for testing measurement equivalence and
detecting differential item functioning in multiple-group confirmatory
factor analysis. <em>Psychological Methods, 23</em>(4), 708&ndash;728.
<a href="https://doi.org/10.1037/met0000152">doi:10.1037/met0000152</a>
</p>
<p>Kite, B. A., Jorgensen, T. D., &amp; Chen, P.-Y. (2018). Random permutation
testing applied to measurement invariance testing with ordered-categorical
indicators. <em>Structural Equation Modeling 25</em>(4), 573&ndash;587.
<a href="https://doi.org/10.1080/10705511.2017.1421467">doi:10.1080/10705511.2017.1421467</a>
</p>
<p>Jorgensen, T. D. (2017). Applying permutation tests and multivariate
modification indices to configurally invariant models that need
respecification. <em>Frontiers in Psychology, 8</em>(1455).
<a href="https://doi.org/10.3389/fpsyg.2017.01455">doi:10.3389/fpsyg.2017.01455</a>
</p>
<p><strong>Additional reading:</strong>
</p>
<p>Chen, F. F. (2007). Sensitivity of goodness of fit indexes to
lack of measurement invariance.  <em>Structural Equation Modeling, 14</em>(3),
464&ndash;504. <a href="https://doi.org/10.1080/10705510701301834">doi:10.1080/10705510701301834</a>
</p>
<p>Cheung, G. W., &amp; Rensvold, R. B. (2002). Evaluating goodness-of-fit indexes
for testing measurement invariance. <em>Structural Equation Modeling,
9</em>(2), 233&ndash;255. <a href="https://doi.org/10.1207/S15328007SEM0902_5">doi:10.1207/S15328007SEM0902_5</a>
</p>
<p>Meade, A. W., Johnson, E. C., &amp; Braddy, P. W. (2008). Power and sensitivity
of alternative fit indices in tests of measurement invariance. <em>Journal
of Applied Psychology, 93</em>(3), 568&ndash;592. <a href="https://doi.org/10.1037/0021-9010.93.3.568">doi:10.1037/0021-9010.93.3.568</a>
</p>
<p>Widamin, K. F., &amp; Thompson, J. S. (2003). On specifying the null model for
incremental fit indices in structural equation modeling. <em>Psychological
Methods, 8</em>(1), 16&ndash;37. <a href="https://doi.org/10.1037/1082-989X.8.1.16">doi:10.1037/1082-989X.8.1.16</a>
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+TukeyHSD">stats::TukeyHSD()</a></code>, <code><a href="lavaan.html#topic+lavTestScore">lavaan::lavTestScore()</a></code>,
<code><a href="#topic+measurementInvariance">measurementInvariance()</a></code>,
<code><a href="#topic+measurementInvarianceCat">measurementInvarianceCat()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


########################
## Multiple-Group CFA ##
########################

## create 3-group data in lavaan example(cfa) data
HS &lt;- lavaan::HolzingerSwineford1939
HS$ageGroup &lt;- ifelse(HS$ageyr &lt; 13, "preteen",
                      ifelse(HS$ageyr &gt; 13, "teen", "thirteen"))

## specify and fit an appropriate null model for incremental fit indices
mod.null &lt;- c(paste0("x", 1:9, " ~ c(T", 1:9, ", T", 1:9, ", T", 1:9, ")*1"),
              paste0("x", 1:9, " ~~ c(L", 1:9, ", L", 1:9, ", L", 1:9, ")*x", 1:9))
fit.null &lt;- cfa(mod.null, data = HS, group = "ageGroup")

## fit target model with varying levels of measurement equivalence
mod.config &lt;- '
visual  =~ x1 + x2 + x3
textual =~ x4 + x5 + x6
speed   =~ x7 + x8 + x9
'
fit.config &lt;- cfa(mod.config, data = HS, std.lv = TRUE, group = "ageGroup")
fit.metric &lt;- cfa(mod.config, data = HS, std.lv = TRUE, group = "ageGroup",
                  group.equal = "loadings")
fit.scalar &lt;- cfa(mod.config, data = HS, std.lv = TRUE, group = "ageGroup",
                  group.equal = c("loadings","intercepts"))


####################### Permutation Method

## fit indices of interest for multiparameter omnibus test
myAFIs &lt;- c("chisq","cfi","rmsea","mfi","aic")
moreAFIs &lt;- c("gammaHat","adjGammaHat")

## Use only 20 permutations for a demo.  In practice,
## use &gt; 1000 to reduce sampling variability of estimated p values

## test configural invariance
set.seed(12345)
out.config &lt;- permuteMeasEq(nPermute = 20, con = fit.config)
out.config

## test metric equivalence
set.seed(12345) # same permutations
out.metric &lt;- permuteMeasEq(nPermute = 20, uncon = fit.config, con = fit.metric,
                            param = "loadings", AFIs = myAFIs,
                            moreAFIs = moreAFIs, null = fit.null)
summary(out.metric, nd = 4)

## test scalar equivalence
set.seed(12345) # same permutations
out.scalar &lt;- permuteMeasEq(nPermute = 20, uncon = fit.metric, con = fit.scalar,
                            param = "intercepts", AFIs = myAFIs,
                            moreAFIs = moreAFIs, null = fit.null)
summary(out.scalar)

## Not much to see without significant DIF.
## Try using an absurdly high alpha level for illustration.
outsum &lt;- summary(out.scalar, alpha = .50)

## notice that the returned object is the table of DIF tests
outsum

## visualize permutation distribution
hist(out.config, AFI = "chisq")
hist(out.metric, AFI = "chisq", nd = 2, alpha = .01,
     legendArgs = list(x = "topright"))
hist(out.scalar, AFI = "cfi", printLegend = FALSE)


####################### Extra Output

## function to calculate expected change of Group-2 and -3 latent means if
## each intercept constraint were released
extra &lt;- function(con) {
  output &lt;- list()
  output["x1.vis2"] &lt;- lavTestScore(con, release = 19:20, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[70]
  output["x1.vis3"] &lt;- lavTestScore(con, release = 19:20, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[106]
  output["x2.vis2"] &lt;- lavTestScore(con, release = 21:22, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[70]
  output["x2.vis3"] &lt;- lavTestScore(con, release = 21:22, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[106]
  output["x3.vis2"] &lt;- lavTestScore(con, release = 23:24, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[70]
  output["x3.vis3"] &lt;- lavTestScore(con, release = 23:24, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[106]
  output["x4.txt2"] &lt;- lavTestScore(con, release = 25:26, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[71]
  output["x4.txt3"] &lt;- lavTestScore(con, release = 25:26, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[107]
  output["x5.txt2"] &lt;- lavTestScore(con, release = 27:28, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[71]
  output["x5.txt3"] &lt;- lavTestScore(con, release = 27:28, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[107]
  output["x6.txt2"] &lt;- lavTestScore(con, release = 29:30, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[71]
  output["x6.txt3"] &lt;- lavTestScore(con, release = 29:30, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[107]
  output["x7.spd2"] &lt;- lavTestScore(con, release = 31:32, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[72]
  output["x7.spd3"] &lt;- lavTestScore(con, release = 31:32, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[108]
  output["x8.spd2"] &lt;- lavTestScore(con, release = 33:34, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[72]
  output["x8.spd3"] &lt;- lavTestScore(con, release = 33:34, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[108]
  output["x9.spd2"] &lt;- lavTestScore(con, release = 35:36, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[72]
  output["x9.spd3"] &lt;- lavTestScore(con, release = 35:36, univariate = FALSE,
                                    epc = TRUE, warn = FALSE)$epc$epc[108]
  output
}

## observed EPC
extra(fit.scalar)

## permutation results, including extra output
set.seed(12345) # same permutations
out.scalar &lt;- permuteMeasEq(nPermute = 20, uncon = fit.metric, con = fit.scalar,
                            param = "intercepts", AFIs = myAFIs,
                            moreAFIs = moreAFIs, null = fit.null, extra = extra)
## summarize extra output
summary(out.scalar, extra = TRUE)


###########
## MIMIC ##
###########

## Specify Restricted Factor Analysis (RFA) model, equivalent to MIMIC, but
## the factor covaries with the covariate instead of being regressed on it.
## The covariate defines a single-indicator construct, and the
## double-mean-centered products of the indicators define a latent
## interaction between the factor and the covariate.
mod.mimic &lt;- '
visual  =~ x1 + x2 + x3
age =~ ageyr
age.by.vis =~ x1.ageyr + x2.ageyr + x3.ageyr

x1 ~~ x1.ageyr
x2 ~~ x2.ageyr
x3 ~~ x3.ageyr
'

HS.orth &lt;- indProd(var1 = paste0("x", 1:3), var2 = "ageyr", match = FALSE,
                   data = HS[ , c("ageyr", paste0("x", 1:3))] )
fit.mimic &lt;- cfa(mod.mimic, data = HS.orth, meanstructure = TRUE)
summary(fit.mimic, stand = TRUE)

## Whereas MIMIC models specify direct effects of the covariate on an indicator,
## DIF can be tested in RFA models by specifying free loadings of an indicator
## on the covariate's construct (uniform DIF, scalar invariance) and the
## interaction construct (nonuniform DIF, metric invariance).
param &lt;- as.list(paste0("age + age.by.vis =~ x", 1:3))
names(param) &lt;- paste0("x", 1:3)
# param &lt;- as.list(paste0("x", 1:3, " ~ age + age.by.vis")) # equivalent

## test both parameters simultaneously for each indicator
do.call(rbind, lapply(param, function(x) lavTestScore(fit.mimic, add = x)$test))
## or test each parameter individually
lavTestScore(fit.mimic, add = as.character(param))


####################### Permutation Method

## function to recalculate interaction terms after permuting the covariate
datafun &lt;- function(data) {
  d &lt;- data[, c(paste0("x", 1:3), "ageyr")]
  indProd(var1 = paste0("x", 1:3), var2 = "ageyr", match = FALSE, data = d)
}

set.seed(12345)
perm.mimic &lt;- permuteMeasEq(nPermute = 20, modelType = "mimic",
                            con = fit.mimic, param = param,
                            covariates = "ageyr", datafun = datafun)
summary(perm.mimic)



</code></pre>

<hr>
<h2 id='permuteMeasEq-class'>Class for the Results of Permutation Randomization Tests of Measurement
Equivalence and DIF</h2><span id='topic+permuteMeasEq-class'></span><span id='topic+show+2CpermuteMeasEq-method'></span><span id='topic+summary+2CpermuteMeasEq-method'></span><span id='topic+hist+2CpermuteMeasEq-method'></span>

<h3>Description</h3>

<p>This class contains the results of tests of Measurement Equivalence and
Differential Item Functioning (DIF).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'permuteMeasEq'
show(object)

## S4 method for signature 'permuteMeasEq'
summary(object, alpha = 0.05, nd = 3,
  extra = FALSE)

## S4 method for signature 'permuteMeasEq'
hist(x, ..., AFI, alpha = 0.05, nd = 3,
  printLegend = TRUE, legendArgs = list(x = "topleft"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="permuteMeasEq-class_+3A_object">object</code>, <code id="permuteMeasEq-class_+3A_x">x</code></td>
<td>
<p>object of class <code>permuteMeasEq</code></p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_alpha">alpha</code></td>
<td>
<p>alpha level used to draw confidence limits in <code>hist</code> and
flag significant statistics in <code>summary</code> output</p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_nd">nd</code></td>
<td>
<p>number of digits to display</p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_extra">extra</code></td>
<td>
<p><code>logical</code> indicating whether the <code>summary</code> output
should return permutation-based <em>p</em> values for each statistic returned
by the <code>extra</code> function.  If <code>FALSE</code> (default), <code>summary</code>
will return permutation-based <em>p</em> values for each modification index.</p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="graphics.html#topic+hist">graphics::hist()</a></code></p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_afi">AFI</code></td>
<td>
<p><code>character</code> indicating the fit measure whose permutation
distribution should be plotted</p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_printlegend">printLegend</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (default), a legend will
be printed with the histogram</p>
</td></tr>
<tr><td><code id="permuteMeasEq-class_+3A_legendargs">legendArgs</code></td>
<td>
<p><code>list</code> of arguments passed to the
<code><a href="graphics.html#topic+legend">graphics::legend()</a></code> function.  The default argument is a list
placing the legend at the top-left of the figure.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li><p> The <code>show</code> method prints a summary of the multiparameter
omnibus test results, using the user-specified AFIs. The parametric
(<code class="reqn">\Delta</code>)<code class="reqn">\chi^2</code> test is also displayed.
</p>
</li>
<li><p> The <code>summary</code> method prints the same information from the
<code>show</code> method, but when <code>extra = FALSE</code> (the default) it also
provides a table summarizing any requested follow-up tests of DIF using
modification indices in slot <code>MI.obs</code>. The user can also specify an
<code>alpha</code> level for flagging modification indices as significant, as
well as <code>nd</code> (the number of digits displayed). For each modification
index, the <em>p</em> value is displayed using a central <code class="reqn">\chi^2</code>
distribution with the <em>df</em> shown in that column. Additionally, a
<em>p</em> value is displayed using the permutation distribution of the
maximum index, which controls the familywise Type I error rate in a manner
similar to Tukey's studentized range test. If any indices are flagged as
significant using the <code>tukey.p.value</code>, then a message is displayed for
each flagged index. The invisibly returned <code>data.frame</code> is the
displayed table of modification indices, unless
<code><a href="#topic+permuteMeasEq">permuteMeasEq()</a></code> was called with <code>param = NULL</code>,
in which case the invisibly returned object is <code>object</code>. If
<code>extra = TRUE</code>, the permutation-based <em>p</em> values for each
statistic returned by the <code>extra</code> function are displayed and returned
in a <code>data.frame</code> instead of the modification indices requested in the
<code>param</code> argument.
</p>
</li>
<li><p> The <code>hist</code> method returns a list of <code>length == 2</code>,
containing the arguments for the call to <code>hist</code> and the arguments
to the call for <code>legend</code>, respectively. This list may facilitate
creating a customized histogram of <code>AFI.dist</code>, <code>MI.dist</code>, or
<code>extra.dist</code>
</p>
</li></ul>



<h3>Slots</h3>


<dl>
<dt><code>PT</code></dt><dd><p>A <code>data.frame</code> returned by a call to
<code><a href="lavaan.html#topic+parTable">lavaan::parTable()</a></code> on the constrained model</p>
</dd>
<dt><code>modelType</code></dt><dd><p>A character indicating the specified <code>modelType</code> in the
call to <code>permuteMeasEq</code></p>
</dd>
<dt><code>ANOVA</code></dt><dd><p>A <code>numeric</code> vector indicating the results of the observed
(<code class="reqn">\Delta</code>)<code class="reqn">\chi^2</code> test, based on the central <code class="reqn">\chi^2</code>
distribution</p>
</dd>
<dt><code>AFI.obs</code></dt><dd><p>A vector of observed (changes in) user-selected fit measures</p>
</dd>
<dt><code>AFI.dist</code></dt><dd><p>The permutation distribution(s) of user-selected fit measures.
A <code>data.frame</code> with <code>n.Permutations</code> rows and one column for each
<code>AFI.obs</code>.</p>
</dd>
<dt><code>AFI.pval</code></dt><dd><p>A vector of <em>p</em> values (one for each element in slot
<code>AFI.obs</code>) calculated using slot <code>AFI.dist</code>, indicating the
probability of observing a change at least as extreme as <code>AFI.obs</code>
if the null hypothesis were true</p>
</dd>
<dt><code>MI.obs</code></dt><dd><p>A <code>data.frame</code> of observed Lagrange Multipliers
(modification indices) associated with the equality constraints or fixed
parameters specified in the <code>param</code> argument. This is a subset of the
output returned by a call to <code><a href="lavaan.html#topic+lavTestScore">lavaan::lavTestScore()</a></code> on the
constrained model.</p>
</dd>
<dt><code>MI.dist</code></dt><dd><p>The permutation distribution of the maximum modification index
(among those seen in slot <code>MI.obs$X2</code>) at each permutation of group
assignment or of <code>covariates</code></p>
</dd>
<dt><code>extra.obs</code></dt><dd><p>If <code>permuteMeasEq</code> was called with an <code>extra</code>
function, the output when applied to the original data is concatenated
into this vector</p>
</dd>
<dt><code>extra.dist</code></dt><dd><p>A <code>data.frame</code>, each column of which contains the
permutation distribution of the corresponding statistic in slot
<code>extra.obs</code></p>
</dd>
<dt><code>n.Permutations</code></dt><dd><p>An <code>integer</code> indicating the number of permutations
requested by the user</p>
</dd>
<dt><code>n.Converged</code></dt><dd><p>An <code>integer</code> indicating the number of permuation
iterations which yielded a converged solution</p>
</dd>
<dt><code>n.nonConverged</code></dt><dd><p>An <code>integer</code> vector of length
<code>n.Permutations</code> indicating how many times group assignment was
randomly permuted (at each iteration) before converging on a solution</p>
</dd>
<dt><code>n.Sparse</code></dt><dd><p>Only relevant with <code>ordered</code> indicators when
<code>modelType == "mgcfa"</code>. An <code>integer</code> vector of length
<code>n.Permutations</code> indicating how many times group assignment was
randomly permuted (at each iteration) before obtaining a sample with all
categories observed in all groups.</p>
</dd>
<dt><code>oldSeed</code></dt><dd><p>An <code>integer</code> vector storing the value of
<code>.Random.seed</code> before running <code>permuteMeasEq</code>. Only relevant
when using a parallel/multicore option and the original
<code>RNGkind() != "L'Ecuyer-CMRG"</code>. This enables users to restore their
previous <code>.Random.seed</code> state, if desired, by running:
<code>.Random.seed[-1] &lt;- permutedResults@oldSeed[-1]</code></p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>Objects can be created via the
<code><a href="#topic+permuteMeasEq">permuteMeasEq()</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+permuteMeasEq">permuteMeasEq()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See the example from the permuteMeasEq function

</code></pre>

<hr>
<h2 id='plausibleValues'>Plausible-Values Imputation of Factor Scores Estimated from a lavaan Model</h2><span id='topic+plausibleValues'></span>

<h3>Description</h3>

<p>Draw plausible values of factor scores estimated from a fitted
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> model, then treat them as multiple imputations
of missing data using <code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plausibleValues(object, nDraws = 20L, seed = 12345,
  omit.imps = c("no.conv", "no.se"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plausibleValues_+3A_object">object</code></td>
<td>
<p>A fitted model of class <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>,
<a href="blavaan.html#topic+blavaan-class">blavaan::blavaan</a>, or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a></p>
</td></tr>
<tr><td><code id="plausibleValues_+3A_ndraws">nDraws</code></td>
<td>
<p><code>integer</code> specifying the number of draws, analogous to
the number of imputed data sets. If <code>object</code> is of class
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>, this will be the number of draws taken
<em>per imputation</em>.  If <code>object</code> is of class
<a href="blavaan.html#topic+blavaan-class">blavaan::blavaan</a>, <code>nDraws</code> cannot exceed
<code>blavInspect(object, "niter") * blavInspect(bfitc, "n.chains")</code>
(number of MCMC samples from the posterior). The drawn samples will be
evenly spaced (after permutation for <code>target="stan"</code>), using
<code><a href="base.html#topic+ceiling">ceiling()</a></code> to resolve decimals.</p>
</td></tr>
<tr><td><code id="plausibleValues_+3A_seed">seed</code></td>
<td>
<p><code>integer</code> passed to <code><a href="base.html#topic+set.seed">set.seed()</a></code>.</p>
</td></tr>
<tr><td><code id="plausibleValues_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations when <code>object</code> is of class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>.
Can include any of <code>c("no.conv", "no.se", "no.npd")</code>.</p>
</td></tr>
<tr><td><code id="plausibleValues_+3A_...">...</code></td>
<td>
<p>Optional arguments to pass to <code><a href="lavaan.html#topic+lavPredict">lavaan::lavPredict()</a></code>.
<code>assemble</code> will be ignored because multiple groups are always
assembled into a single <code>data.frame</code> per draw. <code>type</code> will be
ignored because it is set internally to <code>type="lv"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because latent variables are unobserved, they can be considered as missing
data, which can be imputed using Monte Carlo methods.  This may be of
interest to researchers with sample sizes too small to fit their complex
structural models.  Fitting a factor model as a first step,
<code><a href="lavaan.html#topic+lavPredict">lavaan::lavPredict()</a></code> provides factor-score estimates, which can
be treated as observed values in a path analysis (Step 2).  However, the
resulting standard errors and test statistics could not be trusted because
the Step-2 analysis would not take into account the uncertainty about the
estimated factor scores.  Using the asymptotic sampling covariance matrix
of the factor scores provided by <code><a href="lavaan.html#topic+lavPredict">lavaan::lavPredict()</a></code>,
<code>plausibleValues</code> draws a set of <code>nDraws</code> imputations from the
sampling distribution of each factor score, returning a list of data sets
that can be treated like multiple imputations of incomplete data.  If the
data were already imputed to handle missing data, <code>plausibleValues</code>
also accepts an object of class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>, and will
draw <code>nDraws</code> plausible values from each imputation.  Step 2 would
then take into account uncertainty about both missing values and factor
scores.  Bayesian methods can also be used to generate factor scores, as
available with the <span class="pkg">blavaan</span> package, in which case plausible
values are simply saved parameters from the posterior distribution. See
Asparouhov and Muthen (2010) for further technical details and references.
</p>
<p>Each returned <code>data.frame</code> includes a <code>case.idx</code> column that
indicates the corresponding rows in the data set to which the model was
originally fitted (unless the user requests only Level-2 variables).  This
can be used to merge the plausible values with the original observed data,
but users should note that including any new variables in a Step-2 model
might not accurately account for their relationship(s) with factor scores
because they were not accounted for in the Step-1 model from which factor
scores were estimated.
</p>
<p>If <code>object</code> is a multilevel <code>lavaan</code> model, users can request
plausible values for latent variables at particular levels of analysis by
setting the <code><a href="lavaan.html#topic+lavPredict">lavaan::lavPredict()</a></code> argument <code>level=1</code> or
<code>level=2</code>.  If the <code>level</code> argument is not passed via ...,
then both levels are returned in a single merged data set per draw.  For
multilevel models, each returned <code>data.frame</code> also includes a column
indicating to which cluster each row belongs (unless the user requests only
Level-2 variables).
</p>


<h3>Value</h3>

<p>A <code>list</code> of length <code>nDraws</code>, each of which is a
<code>data.frame</code> containing plausible values, which can be treated as
a <code>list</code> of imputed data sets to be passed to <code><a href="#topic+runMI">runMI()</a></code>
(see <strong>Examples</strong>). If <code>object</code> is of class
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>, the <code>list</code> will be of length
<code>nDraws*m</code>, where <code>m</code> is the number of imputations.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Asparouhov, T. &amp; Muthen, B. O. (2010). <em>Plausible values for latent
variables using M</em>plus. Technical Report. Retrieved from
www.statmodel.com/download/Plausible.pdf
</p>


<h3>See Also</h3>

<p><code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code>, <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example from ?cfa and ?lavPredict help pages
HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 '

fit1 &lt;- cfa(HS.model, data = HolzingerSwineford1939)
fs1 &lt;- plausibleValues(fit1, nDraws = 3,
                       ## lavPredict() can add only the modeled data
                       append.data = TRUE)
lapply(fs1, head)


## To merge factor scores to original data.frame (not just modeled data)
fs1 &lt;- plausibleValues(fit1, nDraws = 3)
idx &lt;- lavInspect(fit1, "case.idx")      # row index for each case
if (is.list(idx)) idx &lt;- do.call(c, idx) # for multigroup models
data(HolzingerSwineford1939)             # copy data to workspace
HolzingerSwineford1939$case.idx &lt;- idx   # add row index as variable
## loop over draws to merge original data with factor scores
for (i in seq_along(fs1)) {
  fs1[[i]] &lt;- merge(fs1[[i]], HolzingerSwineford1939, by = "case.idx")
}
lapply(fs1, head)


## multiple-group analysis, in 2 steps
step1 &lt;- cfa(HS.model, data = HolzingerSwineford1939, group = "school",
            group.equal = c("loadings","intercepts"))
PV.list &lt;- plausibleValues(step1)

## subsequent path analysis
path.model &lt;- ' visual ~ c(t1, t2)*textual + c(s1, s2)*speed '
if(requireNamespace("lavaan.mi")){
  library(lavaan.mi)
  step2 &lt;- sem.mi(path.model, data = PV.list, group = "school")
  ## test equivalence of both slopes across groups
  lavTestWald.mi(step2, constraints = 't1 == t2 ; s1 == s2')
}


## multilevel example from ?Demo.twolevel help page
model &lt;- '
  level: 1
    fw =~ y1 + y2 + y3
    fw ~ x1 + x2 + x3
  level: 2
    fb =~ y1 + y2 + y3
    fb ~ w1 + w2
'
msem &lt;- sem(model, data = Demo.twolevel, cluster = "cluster")
mlPVs &lt;- plausibleValues(msem, nDraws = 3) # both levels by default
lapply(mlPVs, head, n = 10)
## only Level 1
mlPV1 &lt;- plausibleValues(msem, nDraws = 3, level = 1)
lapply(mlPV1, head)
## only Level 2
mlPV2 &lt;- plausibleValues(msem, nDraws = 3, level = 2)
lapply(mlPV2, head)



## example with 20 multiple imputations of missing data:
nPVs &lt;- 5
nImps &lt;- 20

if(requireNamespace("lavaan.mi")){
  data(HS20imps, package = "lavaan.mi")

  ## specify CFA model from lavaan's ?cfa help page
  HS.model &lt;- '
    visual  =~ x1 + x2 + x3
    textual =~ x4 + x5 + x6
    speed   =~ x7 + x8 + x9
  '
  out2 &lt;- cfa.mi(HS.model, data = HS20imps)
  PVs &lt;- plausibleValues(out2, nDraws = nPVs)

  idx &lt;- out2@Data@case.idx # can't use lavInspect() on lavaan.mi
  ## empty list to hold expanded imputations
  impPVs &lt;- list()
  for (m in 1:nImps) {
    HS20imps[[m]]["case.idx"] &lt;- idx
    for (i in 1:nPVs) {
      impPVs[[ nPVs*(m - 1) + i ]] &lt;- merge(HS20imps[[m]],
                                            PVs[[ nPVs*(m - 1) + i ]],
                                            by = "case.idx")
    }
  }
  lapply(impPVs, head)
}



</code></pre>

<hr>
<h2 id='plotProbe'>Plot a latent interaction</h2><span id='topic+plotProbe'></span>

<h3>Description</h3>

<p>This function will plot the line graphs representing the simple effect of
the independent variable given the values of the moderator. For multigroup
models, it will only generate a plot for 1 group, as specified in the
function used to obtain the first argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotProbe(object, xlim, xlab = "Indepedent Variable",
  ylab = "Dependent Variable", legend = TRUE, legendArgs = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotProbe_+3A_object">object</code></td>
<td>
<p>A <code>list</code>, typically the result of probing a latent 2-way
or 3-way interaction obtained from the <code><a href="#topic+probe2WayMC">probe2WayMC()</a></code>,
<code><a href="#topic+probe2WayRC">probe2WayRC()</a></code>, <code><a href="#topic+probe3WayMC">probe3WayMC()</a></code>, or
<code><a href="#topic+probe3WayRC">probe3WayRC()</a></code> functions.</p>
</td></tr>
<tr><td><code id="plotProbe_+3A_xlim">xlim</code></td>
<td>
<p>The vector of two numbers: the minimum and maximum values of the
independent variable</p>
</td></tr>
<tr><td><code id="plotProbe_+3A_xlab">xlab</code></td>
<td>
<p>The label of the x-axis</p>
</td></tr>
<tr><td><code id="plotProbe_+3A_ylab">ylab</code></td>
<td>
<p>The label of the y-axis</p>
</td></tr>
<tr><td><code id="plotProbe_+3A_legend">legend</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (default), a legend is printed.</p>
</td></tr>
<tr><td><code id="plotProbe_+3A_legendargs">legendArgs</code></td>
<td>
<p><code>list</code> of arguments passed to <code><a href="graphics.html#topic+legend">legend()</a></code>
function if <code>legend=TRUE</code>.</p>
</td></tr>
<tr><td><code id="plotProbe_+3A_...">...</code></td>
<td>
<p>Any additional argument for the <code><a href="base.html#topic+plot">plot()</a></code> function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None. This function will plot the simple main effect only.
</p>


<h3>Note</h3>

<p>If the <code>object</code> does not contain simple intercepts (i.e., if the
<code>object$SimpleIntcept</code> element is <code>NULL</code>), then all simple
intercepts are arbitrarily set to zero in order to plot the simple slopes.
This may not be consistent with the fitted model, but was (up until version
0.5-7) the default behavior when the y-intercept was fixed to 0. In this case,
although the relative steepness of simple slopes can still meaningfully be
compared, the relative vertical positions of lines at any point along the
<em>x</em>-axis should not be interpreted.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Schoemann, A. M., &amp; Jorgensen, T. D. (2021). Testing and interpreting
latent variable interactions using the <code>semTools</code> package.
<em>Psych, 3</em>(3), 322&ndash;335. <a href="https://doi.org/10.3390/psych3030024">doi:10.3390/psych3030024</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+indProd">indProd()</a></code> For creating the indicator products with no
centering, mean centering, double-mean centering, or residual centering.
</p>
</li>
<li> <p><code><a href="#topic+probe2WayMC">probe2WayMC()</a></code> For probing the two-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe3WayMC">probe3WayMC()</a></code> For probing the three-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe2WayRC">probe2WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+probe3WayRC">probe3WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)

dat2wayMC &lt;- indProd(dat2way, 1:3, 4:6)

model1 &lt;- "
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f12 =~ x1.x4 + x2.x5 + x3.x6
f3 =~ x7 + x8 + x9
f3 ~ f1 + f2 + f12
f12 ~~ 0*f1
f12 ~~ 0*f2
x1 ~ 0*1
x4 ~ 0*1
x1.x4 ~ 0*1
x7 ~ 0*1
f1 ~ NA*1
f2 ~ NA*1
f12 ~ NA*1
f3 ~ NA*1
"

fitMC2way &lt;- sem(model1, data = dat2wayMC, meanstructure = TRUE)
result2wayMC &lt;- probe2WayMC(fitMC2way, nameX = c("f1", "f2", "f12"),
                            nameY = "f3", modVar = "f2", valProbe = c(-1, 0, 1))
plotProbe(result2wayMC, xlim = c(-2, 2))


dat3wayMC &lt;- indProd(dat3way, 1:3, 4:6, 7:9)

model3 &lt;- "
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
f12 =~ x1.x4 + x2.x5 + x3.x6
f13 =~ x1.x7 + x2.x8 + x3.x9
f23 =~ x4.x7 + x5.x8 + x6.x9
f123 =~ x1.x4.x7 + x2.x5.x8 + x3.x6.x9
f4 =~ x10 + x11 + x12
f4 ~ f1 + f2 + f3 + f12 + f13 + f23 + f123
f1 ~~ 0*f12
f1 ~~ 0*f13
f1 ~~ 0*f123
f2 ~~ 0*f12
f2 ~~ 0*f23
f2 ~~ 0*f123
f3 ~~ 0*f13
f3 ~~ 0*f23
f3 ~~ 0*f123
f12 ~~ 0*f123
f13 ~~ 0*f123
f23 ~~ 0*f123
x1 ~ 0*1
x4 ~ 0*1
x7 ~ 0*1
x10 ~ 0*1
x1.x4 ~ 0*1
x1.x7 ~ 0*1
x4.x7 ~ 0*1
x1.x4.x7 ~ 0*1
f1 ~ NA*1
f2 ~ NA*1
f3 ~ NA*1
f12 ~ NA*1
f13 ~ NA*1
f23 ~ NA*1
f123 ~ NA*1
f4 ~ NA*1
"

fitMC3way &lt;- sem(model3, data = dat3wayMC, std.lv = FALSE,
                 meanstructure = TRUE)
result3wayMC &lt;- probe3WayMC(fitMC3way, nameX = c("f1", "f2", "f3", "f12",
                                                 "f13", "f23", "f123"),
                            nameY = "f4", modVar = c("f1", "f2"),
                            valProbe1 = c(-1, 0, 1), valProbe2 = c(-1, 0, 1))
plotProbe(result3wayMC, xlim = c(-2, 2))

</code></pre>

<hr>
<h2 id='plotRMSEAdist'>Plot the sampling distributions of RMSEA</h2><span id='topic+plotRMSEAdist'></span>

<h3>Description</h3>

<p>Plots the sampling distributions of RMSEA based on the noncentral chi-square
distributions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRMSEAdist(rmsea, n, df, ptile = NULL, caption = NULL,
  rmseaScale = TRUE, group = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotRMSEAdist_+3A_rmsea">rmsea</code></td>
<td>
<p>The vector of RMSEA values to be plotted</p>
</td></tr>
<tr><td><code id="plotRMSEAdist_+3A_n">n</code></td>
<td>
<p>Sample size of a dataset</p>
</td></tr>
<tr><td><code id="plotRMSEAdist_+3A_df">df</code></td>
<td>
<p>Model degrees of freedom</p>
</td></tr>
<tr><td><code id="plotRMSEAdist_+3A_ptile">ptile</code></td>
<td>
<p>The percentile rank of the distribution of the first RMSEA that
users wish to plot a vertical line in the resulting graph</p>
</td></tr>
<tr><td><code id="plotRMSEAdist_+3A_caption">caption</code></td>
<td>
<p>The name vector of each element of <code>rmsea</code></p>
</td></tr>
<tr><td><code id="plotRMSEAdist_+3A_rmseascale">rmseaScale</code></td>
<td>
<p>If <code>TRUE</code>, the RMSEA scale is used in the x-axis. If
<code>FALSE</code>, the chi-square scale is used in the x-axis.</p>
</td></tr>
<tr><td><code id="plotRMSEAdist_+3A_group">group</code></td>
<td>
<p>The number of group that is used to calculate RMSEA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates overlappling plots of the sampling distribution of
RMSEA based on noncentral <code class="reqn">\chi^2</code> distribution (MacCallum, Browne, &amp;
Suguwara, 1996). First, the noncentrality parameter (<code class="reqn">\lambda</code>) is
calculated from RMSEA (Steiger, 1998; Dudgeon, 2004) by </p>
<p style="text-align: center;"><code class="reqn">\lambda = (N -
1)d\varepsilon^2 / K,</code>
</p>
<p> where <code class="reqn">N</code> is sample size, <code class="reqn">d</code> is the model
degree of freedom, <code class="reqn">K</code> is the number of group, and <code class="reqn">\varepsilon</code> is
the population RMSEA. Next, the noncentral <code class="reqn">\chi^2</code> distribution with a
specified <em>df</em> and noncentrality parameter is plotted. Thus,
the x-axis represents the sample <code class="reqn">\chi^2</code> value. The sample <code class="reqn">\chi^2</code>
value can be transformed to the sample RMSEA scale (<code class="reqn">\hat{\varepsilon}</code>)
by </p>
<p style="text-align: center;"><code class="reqn">\hat{\varepsilon} = \sqrt{K}\sqrt{\frac{\chi^2 - d}{(N - 1)d}},</code>
</p>

<p>where <code class="reqn">\chi^2</code> is the <code class="reqn">\chi^2</code> value obtained from the noncentral
<code class="reqn">\chi^2</code> distribution.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Dudgeon, P. (2004). A note on extending Steiger's (1998)
multiple sample RMSEA adjustment to other noncentrality parameter-based
statistic. <em>Structural Equation Modeling, 11</em>(3), 305&ndash;319.
<a href="https://doi.org/10.1207/s15328007sem1103_1">doi:10.1207/s15328007sem1103_1</a>
</p>
<p>MacCallum, R. C., Browne, M. W., &amp; Sugawara, H. M. (1996). Power analysis
and determination of sample size for covariance structure modeling.
<em>Psychological Methods, 1</em>(2), 130&ndash;149. <a href="https://doi.org/10.1037/1082-989X.1.2.130">doi:10.1037/1082-989X.1.2.130</a>
</p>
<p>Steiger, J. H. (1998). A note on multiple sample extensions of the RMSEA fit
index. <em>Structural Equation Modeling, 5</em>(4), 411&ndash;419.
<a href="https://doi.org/10.1080/10705519809540115">doi:10.1080/10705519809540115</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+plotRMSEApower">plotRMSEApower()</a></code> to plot the statistical power
based on population RMSEA given the sample size
</p>
</li>
<li> <p><code><a href="#topic+findRMSEApower">findRMSEApower()</a></code> to find the statistical power based on
population RMSEA given a sample size
</p>
</li>
<li> <p><code><a href="#topic+findRMSEAsamplesize">findRMSEAsamplesize()</a></code> to find the minium sample size for
a given statistical power based on population RMSEA
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
plotRMSEAdist(c(.05, .08), n = 200, df = 20, ptile = .95, rmseaScale = TRUE)
plotRMSEAdist(c(.05, .01), n = 200, df = 20, ptile = .05, rmseaScale = FALSE)

</code></pre>

<hr>
<h2 id='plotRMSEApower'>Plot power curves for RMSEA</h2><span id='topic+plotRMSEApower'></span>

<h3>Description</h3>

<p>Plots power of RMSEA over a range of sample sizes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRMSEApower(rmsea0, rmseaA, df, nlow, nhigh, steps = 1, alpha = 0.05,
  group = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotRMSEApower_+3A_rmsea0">rmsea0</code></td>
<td>
<p>Null RMSEA</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_rmseaa">rmseaA</code></td>
<td>
<p>Alternative RMSEA</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_df">df</code></td>
<td>
<p>Model degrees of freedom</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_nlow">nlow</code></td>
<td>
<p>Lower sample size</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_nhigh">nhigh</code></td>
<td>
<p>Upper sample size</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_steps">steps</code></td>
<td>
<p>Increase in sample size for each iteration. Smaller values of
steps will lead to more precise plots. However, smaller step sizes means a
longer run time.</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_alpha">alpha</code></td>
<td>
<p>Alpha level used in power calculations</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_group">group</code></td>
<td>
<p>The number of group that is used to calculate RMSEA.</p>
</td></tr>
<tr><td><code id="plotRMSEApower_+3A_...">...</code></td>
<td>
<p>The additional arguments for the plot function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates plot of power for RMSEA against a range of sample
sizes. The plot places sample size on the horizontal axis and power on the
vertical axis. The user should indicate the lower and upper values for
sample size and the sample size between each estimate (&quot;step size&quot;) We
strongly urge the user to read the sources below (see References) before
proceeding.  A web version of this function is available at:
<a href="http://quantpsy.org/rmsea/rmseaplot.htm">http://quantpsy.org/rmsea/rmseaplot.htm</a>. This function is also
implemented in the web application &quot;power4SEM&quot;:
<a href="https://sjak.shinyapps.io/power4SEM/">https://sjak.shinyapps.io/power4SEM/</a>
</p>


<h3>Value</h3>

<p>Plot of power for RMSEA against a range of sample sizes
</p>


<h3>Author(s)</h3>

<p>Alexander M. Schoemann (East Carolina University; <a href="mailto:schoemanna@ecu.edu">schoemanna@ecu.edu</a>)
</p>
<p>Kristopher J. Preacher (Vanderbilt University; <a href="mailto:kris.preacher@vanderbilt.edu">kris.preacher@vanderbilt.edu</a>)
</p>
<p>Donna L. Coffman (Pennsylvania State University; <a href="mailto:dlc30@psu.edu">dlc30@psu.edu</a>)
</p>


<h3>References</h3>

<p>MacCallum, R. C., Browne, M. W., &amp; Cai, L. (2006). Testing
differences between nested covariance structure models: Power analysis and
null hypotheses. <em>Psychological Methods, 11</em>(1), 19&ndash;35.
<a href="https://doi.org/10.1037/1082-989X.11.1.19">doi:10.1037/1082-989X.11.1.19</a>
</p>
<p>MacCallum, R. C., Browne, M. W., &amp; Sugawara, H. M. (1996). Power analysis
and determination of sample size for covariance structure modeling.
<em>Psychological Methods, 1</em>(2), 130&ndash;149. <a href="https://doi.org/10.1037/1082-989X.1.2.130">doi:10.1037/1082-989X.1.2.130</a>
</p>
<p>MacCallum, R. C., Lee, T., &amp; Browne, M. W. (2010). The issue of isopower in
power analysis for tests of structural equation models. <em>Structural
Equation Modeling, 17</em>(1), 23&ndash;41. <a href="https://doi.org/10.1080/10705510903438906">doi:10.1080/10705510903438906</a>
</p>
<p>Preacher, K. J., Cai, L., &amp; MacCallum, R. C. (2007). Alternatives to
traditional model comparison strategies for covariance structure models. In
T. D. Little, J. A. Bovaird, &amp; N. A. Card (Eds.), <em>Modeling contextual
effects in longitudinal studies</em> (pp. 33&ndash;62). Mahwah, NJ: Lawrence Erlbaum
Associates.
</p>
<p>Steiger, J. H. (1998). A note on multiple sample extensions of the RMSEA fit
index. <em>Structural Equation Modeling, 5</em>(4), 411&ndash;419.
<a href="https://doi.org/10.1080/10705519809540115">doi:10.1080/10705519809540115</a>
</p>
<p>Steiger, J. H., &amp; Lind, J. C. (1980, June). <em>Statistically based tests
for the number of factors.</em> Paper presented at the annual meeting of the
Psychometric Society, Iowa City, IA.
</p>
<p>Jak, S., Jorgensen, T. D., Verdam, M. G., Oort, F. J., &amp; Elffers, L.
(2021). Analytical power calculations for structural equation modeling:
A tutorial and Shiny app. <em>Behavior Research Methods, 53</em>, 1385&ndash;1406.
<a href="https://doi.org/10.3758/s13428-020-01479-0">doi:10.3758/s13428-020-01479-0</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+plotRMSEAdist">plotRMSEAdist()</a></code> to visualize the RMSEA distributions
</p>
</li>
<li> <p><code><a href="#topic+findRMSEApower">findRMSEApower()</a></code> to find the statistical power based on
population RMSEA given a sample size
</p>
</li>
<li> <p><code><a href="#topic+findRMSEAsamplesize">findRMSEAsamplesize()</a></code> to find the minium sample size for
a given statistical power based on population RMSEA
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
plotRMSEApower(rmsea0 = .025, rmseaA = .075, df = 23,
               nlow = 100, nhigh = 500, steps = 10)

</code></pre>

<hr>
<h2 id='plotRMSEApowernested'>Plot power of nested model RMSEA</h2><span id='topic+plotRMSEApowernested'></span>

<h3>Description</h3>

<p>Plot power of nested model RMSEA over a range of possible sample sizes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotRMSEApowernested(rmsea0A = NULL, rmsea0B = NULL, rmsea1A,
  rmsea1B = NULL, dfA, dfB, nlow, nhigh, steps = 1, alpha = 0.05,
  group = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plotRMSEApowernested_+3A_rmsea0a">rmsea0A</code></td>
<td>
<p>The <code class="reqn">H_0</code> baseline RMSEA</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_rmsea0b">rmsea0B</code></td>
<td>
<p>The <code class="reqn">H_0</code> alternative RMSEA (trivial misfit)</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_rmsea1a">rmsea1A</code></td>
<td>
<p>The <code class="reqn">H_1</code> baseline RMSEA</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_rmsea1b">rmsea1B</code></td>
<td>
<p>The <code class="reqn">H_1</code> alternative RMSEA (target misfit to be rejected)</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_dfa">dfA</code></td>
<td>
<p>degree of freedom of the more-restricted model</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_dfb">dfB</code></td>
<td>
<p>degree of freedom of the less-restricted model</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_nlow">nlow</code></td>
<td>
<p>Lower bound of sample size</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_nhigh">nhigh</code></td>
<td>
<p>Upper bound of sample size</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_steps">steps</code></td>
<td>
<p>Step size</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_group">group</code></td>
<td>
<p>The number of group in calculating RMSEA</p>
</td></tr>
<tr><td><code id="plotRMSEApowernested_+3A_...">...</code></td>
<td>
<p>The additional arguments for the plot function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Bell Clinton
</p>
<p>Pavel Panko (Texas Tech University; <a href="mailto:pavel.panko@ttu.edu">pavel.panko@ttu.edu</a>)
</p>
<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>MacCallum, R. C., Browne, M. W., &amp; Cai, L. (2006). Testing
differences between nested covariance structure models: Power analysis and
null hypotheses. <em>Psychological Methods, 11</em>(1), 19&ndash;35.
<a href="https://doi.org/10.1037/1082-989X.11.1.19">doi:10.1037/1082-989X.11.1.19</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+findRMSEApowernested">findRMSEApowernested()</a></code> to find the power for a given
sample size in nested model comparison based on population RMSEA
</p>
</li>
<li> <p><code><a href="#topic+findRMSEAsamplesizenested">findRMSEAsamplesizenested()</a></code> to find the minium sample
size for a given statistical power in nested model comparison based on
population RMSEA
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
plotRMSEApowernested(rmsea0A = 0, rmsea0B = 0, rmsea1A = 0.06,
                     rmsea1B = 0.05, dfA = 22, dfB = 20, nlow = 50,
                     nhigh = 500, steps = 1, alpha = .05, group = 1)

</code></pre>

<hr>
<h2 id='poolMAlloc'>Combine sampling variability with parcel-allocation variability by
pooling results across M parcel-allocations</h2><span id='topic+poolMAlloc'></span>

<h3>Description</h3>

<p>This function employs an iterative algorithm to pick the number of random
item-to-parcel allocations needed to meet user-defined stability criteria
for a fitted structural equation model (SEM) (see <strong>Details</strong> below for
more information). Pooled point and standard-error estimates from this SEM
can be outputted at this final selected number of allocations (however, it
is more efficient to save the allocations and treat them as multiple
imputations using <code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code>; see <strong>See Also</strong> for links with
examples). Additionally, new indices (see Sterba &amp; Rights, 2016) are
outputted for assessing the relative contributions of parcel-allocation
variability vs. sampling variability in each estimate. At each iteration,
this function generates a given number of random item-to-parcel allocations,
fits a SEM to each allocation, pools estimates across allocations from that
iteration, and then assesses whether stopping criteria are met. If stopping
criteria are not met, the algorithm increments the number of allocations
used (generating all new allocations).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poolMAlloc(nPerPar, facPlc, nAllocStart, nAllocAdd = 0,
  parceloutput = NULL, syntax, dataset, stopProp, stopValue,
  selectParam = NULL, indices = "default", double = FALSE,
  checkConv = FALSE, names = "default", leaveout = 0,
  useTotalAlloc = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="poolMAlloc_+3A_nperpar">nPerPar</code></td>
<td>
<p>A list in which each element is a vector, corresponding to
each factor, indicating sizes of parcels. If variables are left out of
parceling, they should not be accounted for here (i.e., there should not
be parcels of size &quot;1&quot;).</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_facplc">facPlc</code></td>
<td>
<p>A list of vectors, each corresponding to a factor, specifying
the item indicators of that factor (whether included in parceling or not).
Either variable names or column numbers. Variables not listed will not be
modeled or included in output datasets.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_nallocstart">nAllocStart</code></td>
<td>
<p>The number of random allocations of items to parcels to
generate in the first iteration of the algorithm.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_nallocadd">nAllocAdd</code></td>
<td>
<p>The number of allocations to add with each iteration of the
algorithm. Note that if only one iteration is desired, <code>nAllocAdd</code> can
be set to <code class="reqn">0</code> and results will be output for <code>nAllocStart</code>
allocations only.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_parceloutput">parceloutput</code></td>
<td>
<p>Optional <code>character</code>. Path (folder/directory) where
<em>M</em> (the final selected number of allocations) parceled data sets will
be outputted from the iteration where the algorithm met stopping criteria.
Note for Windows users: file path must be specified using forward slashes
(<code>/</code>), not backslashes (<code style="white-space: pre;">&#8288;\\&#8288;</code>). See <code><a href="base.html#topic+path.expand">base::path.expand()</a></code>
for details.  If <code>NULL</code> (default), nothing is saved to disk.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_syntax">syntax</code></td>
<td>
<p>lavaan syntax that defines the model.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_dataset">dataset</code></td>
<td>
<p>Item-level dataset</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_stopprop">stopProp</code></td>
<td>
<p>Value used in defining stopping criteria of the algorithm
(<code class="reqn">\delta_a</code> in Sterba &amp; Rights, 2016).  This is the minimum proportion
of change (in any pooled parameter or pooled standard error estimate
listed in <code>selectParam</code>) that is allowable from one iteration of the
algorithm to the next.  That is, change in pooled estimates and pooled
standard errors from one iteration to the next must all be less than
(<code>stopProp</code>) <code class="reqn">\times</code> (value from former iteration). Note that
<code>stopValue</code> can override this criterion (see below). Also note that values
less than .01 are unlikely to lead to more substantively meaningful
precision. Also note that if only <code>stopValue</code> is a desired criterion,
<code>stopProp</code> can be set to 0.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_stopvalue">stopValue</code></td>
<td>
<p>Value used in defining stopping criteria of the algorithm
(<code class="reqn">\delta_b</code> in Sterba &amp; Rights, 2016). <code>stopValue</code> is a minimum
allowable amount of absolute change (in any pooled parameter or pooled
standard error estimate listed in <code>selectParam</code>) from one iteration of
the algorithm to the next. For a given pooled estimate or pooled standard
error, <code>stopValue</code> is only invoked as a stopping criteria when the
minimum change required by <code>stopProp</code> is less than <code>stopValue</code>.
Note that values less than .01 are unlikely to lead to more substantively
meaningful precision. Also note that if only <code>stopProp</code> is a desired
criterion, <code>stopValue</code> can be set to 0.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_selectparam">selectParam</code></td>
<td>
<p>(Optional) A list of the pooled parameters to be used in
defining stopping criteria (i.e., <code>stopProp</code> and <code>stopValue</code>).
These parameters should appear in the order they are listed in the lavaan
syntax. By default, all pooled parameters are used. Note that
<code>selectParam</code> should only contain freely-estimated parameters. In one
example from Sterba &amp; Rights (2016) <code>selectParam</code> included all free
parameters except item intercepts and in another example <code>selectParam</code>
included only structural parameters.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_indices">indices</code></td>
<td>
<p>Optional <code>character</code> vector indicating the names of
available <code><a href="lavaan.html#topic+fitMeasures">lavaan::fitMeasures()</a></code> to be included in the output.
The first and second elements should be a chi-squared test statistic and
its associated degrees of freedom, both of which will be added if missing.
If <code>"default"</code>, the indices will be <code>c("chisq", "df", "cfi", "tli", "rmsea","srmr")</code>. If a robust test statistic is requested (see
<code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>), <code>c("chisq","df")</code> will be replaced
by <code>c("chisq.scaled","df.scaled")</code>. For the output to include both the
naive and robust test statistics, <code>indices</code> should include both, but
put the scaled test statistics first, as in <code>indices = c("chisq.scaled", "df.scaled", "chisq", "df")</code></p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_double">double</code></td>
<td>
<p>(Optional) If set to <code>TRUE</code>, requires stopping criteria
(<code>stopProp</code> and <code>stopValue</code>) to be met for all parameters (in
<code>selectParam</code>) for two consecutive iterations of the algorithm. By
default, this is set to <code>FALSE</code>, meaning stopping criteria need only be
met at one iteration of the algorithm.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_checkconv">checkConv</code></td>
<td>
<p>(Optional) If set to TRUE, function will output pooled
estimates and standard errors from 10 iterations post-convergence.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_names">names</code></td>
<td>
<p>(Optional) A character vector containing the names of parceled
variables.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_leaveout">leaveout</code></td>
<td>
<p>(Optional) A vector of variables to be left out of
randomized parceling. Either variable names or column numbers are allowed.</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_usetotalalloc">useTotalAlloc</code></td>
<td>
<p>(Optional) If set to <code>TRUE</code>, function will output
a separate set of results that uses all allocations created by the
algorithm, rather than <em>M</em> allocations (see &quot;Allocations needed for
stability&quot; below). This distinction is further discussed in Sterba and
Rights (2016).</p>
</td></tr>
<tr><td><code id="poolMAlloc_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to
<code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements an algorithm for choosing the number of allocations
(<em>M</em>; described in Sterba &amp; Rights, 2016), pools point and
standard-error estimates across these <em>M</em> allocations, and produces
indices for assessing the relative contributions of parcel-allocation
variability vs. sampling variability in each estimate.
</p>
<p>To obtain pooled test statistics for model fit or model comparison, the
<code>list</code> or parcel allocations can be passed to <code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code>
(find <strong>Examples</strong> on the help pages for <code><a href="#topic+parcelAllocation">parcelAllocation()</a></code>
and <code><a href="#topic+PAVranking">PAVranking()</a></code>).
</p>
<p>This function randomly generates a given number (<code>nAllocStart</code>) of
item-to-parcel allocations, fits a SEM to each allocation, and then
increments the number of allocations used (by <code>nAllocAdd</code>) until the
pooled point and standard-error estimates fulfill stopping criteria
(<code>stopProp</code> and <code>stopValue</code>, defined above). A summary of results
from the model that was fit to the <em>M</em> allocations are returned.
</p>
<p>Additionally, this function outputs the proportion of allocations with
solutions that converged (using a maximum likelihood estimator) as well as
the proportion of allocations with solutions that were converged and proper.
The converged and proper solutions among the final <em>M</em> allocations are
used in computing pooled results.
</p>
<p>Additionally, after each iteration of the algorithm, information useful in
monitoring the algorithm is outputted. The number of allocations used at
that iteration, the proportion of pooled parameter estimates meeting
stopping criteria at the previous iteration, the proportion of pooled
standard errors meeting stopping criteria at the previous iteration, and the
runtime of that iteration are outputted. When stopping criteria are
satisfied, the full set of results are outputted.
</p>
<p>For further details on the benefits of the random allocation of items to
parcels, see Sterba (2011) and Sterba &amp; MacCallum (2010).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Estimates</code></td>
<td>
<p>A table containing pooled results across <em>M</em>
allocations at the iteration where stopping criteria were met. Columns
correspond to individual parameter name, pooled estimate, pooled standard
error, <em>p</em> value for a <em>z</em> test of the parameter, normal-theory <code class="reqn">95\%</code>
CI, <em>p</em> value for a <em>t</em> test of the parameter (using <code class="reqn">df</code> described in
Sterba &amp; Rights, 2016), and <em>t</em>-based <code class="reqn">95\%</code> CI for the parameter.</p>
</td></tr>
<tr><td><code>Fit</code></td>
<td>
<p>A table containing results related to model fit from the <em>M</em>
allocations at the iteration where stopping criteria were met. Columns
correspond to fit index names, the mean of each index across allocations,
the <em>SD</em> of each fit index across allocations, the minimum, maximum and
range of each fit index across allocations, and the percent of the <em>M</em>
allocations where the chi-square test of absolute fit was significant.</p>
</td></tr>
<tr><td><code>Proportions</code></td>
<td>
<p>A table containing the proportion of the final <em>M</em>
allocations that (a) met the optimizer convergence criteria) and
(b) converged to proper solutions. Note that pooled estimates, pooled
standard errors, and other results are computed using only the converged,
proper allocations.</p>
</td></tr>
<tr><td><code>Stability</code></td>
<td>
<p>The number of allocations (<em>M</em>) needed for stability, at
which point the algorithm's stopping criteria (defined above) were met.</p>
</td></tr>
<tr><td><code>Uncertainty</code></td>
<td>
<p>Indices used to quantify uncertainty in estimates due to
sample vs. allocation variability. A table containing individual parameter
names, an estimate of the proportion of total variance of a pooled
parameter estimate that is attributable to parcel-allocation variability
(PPAV), and an estimate of the ratio of the between-allocation variance of
a pooled parameter estimate to the within-allocation variance (RPAV).
See Sterba &amp; Rights (2016) for more detail.</p>
</td></tr>
<tr><td><code>Time</code></td>
<td>
<p>The total runtime of the function, in minutes. Note that the
total runtime will be greater when the specified model encounters
convergence problems for some allocations, as is the case with the
<code><a href="#topic+simParcel">simParcel()</a></code> dataset used below.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jason D. Rights (Vanderbilt University; <a href="mailto:jason.d.rights@vanderbilt.edu">jason.d.rights@vanderbilt.edu</a>)
</p>
<p>The author would also like to credit Corbin Quick and Alexander Schoemann
for providing the original <code><a href="#topic+parcelAllocation">parcelAllocation()</a></code> function (prior to its
revision by Terrence D. Jorgensen) on which this function is based.
</p>


<h3>References</h3>

<p>Sterba, S. K. (2011). Implications of parcel-allocation
variability for comparing fit of item-solutions and parcel-solutions.
<em>Structural Equation Modeling, 18</em>(4), 554&ndash;577.
<a href="https://doi.org/10.1080/10705511.2011.607073">doi:10.1080/10705511.2011.607073</a>
</p>
<p>Sterba, S. K., &amp; MacCallum, R. C. (2010). Variability in parameter estimates
and model fit across random allocations of items to parcels.
<em>Multivariate Behavioral Research, 45</em>(2), 322&ndash;358.
<a href="https://doi.org/10.1080/00273171003680302">doi:10.1080/00273171003680302</a>
</p>
<p>Sterba, S. K., &amp; Rights, J. D. (2016). Accounting for parcel-allocation
variability in practice: Combining sources of uncertainty and choosing the
number of allocations. <em>Multivariate Behavioral Research, 51</em>(2&ndash;3),
296&ndash;313. <a href="https://doi.org/10.1080/00273171.2016.1144502">doi:10.1080/00273171.2016.1144502</a>
</p>
<p>Sterba, S. K., &amp; Rights, J. D. (2017). Effects of parceling on model
selection: Parcel-allocation variability in model ranking.
<em>Psychological Methods, 22</em>(1), 47&ndash;68. <a href="https://doi.org/10.1037/met0000067">doi:10.1037/met0000067</a>
</p>


<h3>See Also</h3>

<p><code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code> for treating allocations as multiple imputations
to pool results across allocations. See <strong>Examples</strong> on help pages for
<code><a href="#topic+parcelAllocation">parcelAllocation()</a></code> (when fitting a single model) and <code><a href="#topic+PAVranking">PAVranking()</a></code>
(when comparing 2 models).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## lavaan syntax: A 2 Correlated
## factor CFA model to be fit to parceled data

parmodel &lt;- '
   f1 =~ NA*p1f1 + p2f1 + p3f1
   f2 =~ NA*p1f2 + p2f2 + p3f2
   p1f1 ~ 1
   p2f1 ~ 1
   p3f1 ~ 1
   p1f2 ~ 1
   p2f2 ~ 1
   p3f2 ~ 1
   p1f1 ~~ p1f1
   p2f1 ~~ p2f1
   p3f1 ~~ p3f1
   p1f2 ~~ p1f2
   p2f2 ~~ p2f2
   p3f2 ~~ p3f2
   f1 ~~ 1*f1
   f2 ~~ 1*f2
   f1 ~~ f2
'

## specify items for each factor
f1name &lt;- colnames(simParcel)[1:9]
f2name &lt;- colnames(simParcel)[10:18]

## run function
poolMAlloc(nPerPar = list(c(3,3,3), c(3,3,3)),
           facPlc = list(f1name, f2name), nAllocStart = 10, nAllocAdd = 10,
           syntax = parmodel, dataset = simParcel, stopProp = .03,
           stopValue = .03, selectParam = c(1:6, 13:18, 21),
           names = list("p1f1","p2f1","p3f1","p1f2","p2f2","p3f2"),
           double = FALSE, useTotalAlloc = FALSE)


## See examples on ?parcelAllocation and ?PAVranking for how to obtain
## pooled test statistics and other pooled lavaan output.
## Details provided in Sterba &amp; Rights (2016).

</code></pre>

<hr>
<h2 id='probe2WayMC'>Probing two-way interaction on the no-centered or mean-centered latent
interaction</h2><span id='topic+probe2WayMC'></span>

<h3>Description</h3>

<p>Probing interaction for simple intercept and simple slope for the
no-centered or mean-centered latent two-way interaction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probe2WayMC(fit, nameX, nameY, modVar, valProbe, group = 1L,
  omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probe2WayMC_+3A_fit">fit</code></td>
<td>
<p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object with a latent 2-way interaction.</p>
</td></tr>
<tr><td><code id="probe2WayMC_+3A_namex">nameX</code></td>
<td>
<p><code>character</code> vector of all 3 factor names used as the
predictors. The lower-order factors must be listed first, and the final
name must be the latent interaction factor.</p>
</td></tr>
<tr><td><code id="probe2WayMC_+3A_namey">nameY</code></td>
<td>
<p>The name of factor that is used as the dependent variable.</p>
</td></tr>
<tr><td><code id="probe2WayMC_+3A_modvar">modVar</code></td>
<td>
<p>The name of factor that is used as a moderator. The effect of
the other independent factor will be probed at each value of the
moderator variable listed in <code>valProbe</code>.</p>
</td></tr>
<tr><td><code id="probe2WayMC_+3A_valprobe">valProbe</code></td>
<td>
<p>The values of the moderator that will be used to probe the
effect of the focal predictor.</p>
</td></tr>
<tr><td><code id="probe2WayMC_+3A_group">group</code></td>
<td>
<p>In multigroup models, the label of the group for which the
results will be returned. Must correspond to one of
<code>lavInspect(fit, "group.label")</code>, or an integer
corresponding to which of those group labels.</p>
</td></tr>
<tr><td><code id="probe2WayMC_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results. Ignored unless <code>fit</code> is of
class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>. Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before using this function, researchers need to make the products of the
indicators between the first-order factors using mean centering (Marsh, Wen,
&amp; Hau, 2004). Note that the double-mean centering may not be appropriate for
probing interaction if researchers are interested in simple intercepts. The
mean or double-mean centering can be done by the <code><a href="#topic+indProd">indProd()</a></code>
function. The indicator products can be made for all possible combination or
matched-pair approach (Marsh et al., 2004). Next, the hypothesized model
with the regression with latent interaction will be used to fit all original
indicators and the product terms. See the example for how to fit the product
term below. Once the lavaan result is obtained, this function will be used
to probe the interaction.
</p>
<p>Let that the latent interaction model regressing the dependent variable
(<code class="reqn">Y</code>) on the independent variable (<code class="reqn">X</code>) and the moderator (<code class="reqn">Z</code>)
be </p>
<p style="text-align: center;"><code class="reqn"> Y = b_0 + b_1X + b_2Z + b_3XZ + r, </code>
</p>
<p> where <code class="reqn">b_0</code> is the
estimated intercept or the expected value of <code class="reqn">Y</code> when both <code class="reqn">X</code> and
<code class="reqn">Z</code> are 0, <code class="reqn">b_1</code> is the effect of <code class="reqn">X</code> when <code class="reqn">Z</code> is 0,
<code class="reqn">b_2</code> is the effect of <code class="reqn">Z</code> when <code class="reqn">X</code> is 0, <code class="reqn">b_3</code> is the
interaction effect between <code class="reqn">X</code> and <code class="reqn">Z</code>, and <code class="reqn">r</code> is the residual
term.
</p>
<p>To probe a two-way interaction, the simple intercept of the independent
variable at each value of the moderator (Aiken &amp; West, 1991; Cohen, Cohen,
West, &amp; Aiken, 2003; Preacher, Curran, &amp; Bauer, 2006) can be obtained by
</p>
<p style="text-align: center;"><code class="reqn"> b_{0|X = 0, Z} = b_0 + b_2 Z. </code>
</p>

<p>The simple slope of the independent varaible at each value of the moderator
can be obtained by
</p>
<p style="text-align: center;"><code class="reqn"> b_{X|Z} = b_1 + b_3 Z. </code>
</p>

<p>The variance of the simple intercept formula is
</p>
<p style="text-align: center;"><code class="reqn"> Var\left(b_{0|X = 0, Z}\right) =
       Var\left(b_0\right) + 2Z \times Cov\left(b_0, b_2\right) +
       Z^2 \times Var\left(b_2\right) </code>
</p>
<p>,
where <code class="reqn">Var</code> denotes the variance of a parameter
estimate and <code class="reqn">Cov</code> denotes the covariance of two parameter estimates.
</p>
<p>The variance of the simple slope formula is
</p>
<p style="text-align: center;"><code class="reqn"> Var\left(b_{X|Z}\right) = Var\left(b_1\right) + 2Z \times
       Cov\left(b_1, b_3\right) + Z^2 \times Var\left(b_3\right) </code>
</p>

<p>Wald <em>z</em> statistic is used for test statistic (even for objects of
class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>).
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>

<ol>
<li> <p><code>SimpleIntercept</code>: The simple intercepts given each value of the
moderator.
</p>
</li>
<li> <p><code>SimpleSlope</code>: The simple slopes given each value of the moderator.
</p>
</li></ol>

<p>In each element, the first column represents the values of the moderator
specified in the <code>valProbe</code> argument. The second column is the simple
intercept or simple slope. The third column is the <em>SE</em> of the simple
intercept or simple slope. The fourth column is the Wald (<em>z</em>)
statistic, and the fifth column is the associated <em>p</em> value testing
the null hypothesis that each simple intercept or slope is 0.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Tutorial:
</p>
<p>Schoemann, A. M., &amp; Jorgensen, T. D. (2021). Testing and interpreting
latent variable interactions using the <code>semTools</code> package.
<em>Psych, 3</em>(3), 322&ndash;335. <a href="https://doi.org/10.3390/psych3030024">doi:10.3390/psych3030024</a>
</p>
<p>Background literature:
</p>
<p>Aiken, L. S., &amp; West, S. G. (1991). <em>Multiple regression: Testing
and interpreting interactions</em>. Newbury Park, CA: Sage.
</p>
<p>Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied
multiple regression/correlation analysis for the behavioral sciences</em>
(3rd ed.). New York, NY: Routledge.
</p>
<p>Marsh, H. W., Wen, Z., &amp; Hau, K. T. (2004). Structural equation models of
latent interactions: Evaluation of alternative estimation strategies and
indicator construction. <em>Psychological Methods, 9</em>(3), 275&ndash;300.
<a href="https://doi.org/10.1037/1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>
</p>
<p>Preacher, K. J., Curran, P. J., &amp; Bauer, D. J. (2006). Computational tools
for probing interactions in multiple linear regression, multilevel modeling,
and latent curve analysis. <em>Journal of Educational and Behavioral
Statistics, 31</em>(4), 437&ndash;448. <a href="https://doi.org/10.3102/10769986031004437">doi:10.3102/10769986031004437</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+indProd">indProd()</a></code> For creating the indicator products with no
centering, mean centering, double-mean centering, or residual centering.
</p>
</li>
<li> <p><code><a href="#topic+probe3WayMC">probe3WayMC()</a></code> For probing the three-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe2WayRC">probe2WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+probe3WayRC">probe3WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+plotProbe">plotProbe()</a></code> Plot the simple intercepts and slopes of the
latent interaction.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
dat2wayMC &lt;- indProd(dat2way, 1:3, 4:6) # double mean centered by default

model1 &lt;- "
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f12 =~ x1.x4 + x2.x5 + x3.x6
f3 =~ x7 + x8 + x9
f3 ~ f1 + f2 + f12
f12 ~~ 0*f1 + 0*f2 # not necessary, but implied by double mean centering
"

fitMC2way &lt;- sem(model1, data = dat2wayMC, meanstructure = TRUE)
summary(fitMC2way)

probe2WayMC(fitMC2way, nameX = c("f1", "f2", "f12"), nameY = "f3",
            modVar = "f2", valProbe = c(-1, 0, 1))


## can probe multigroup models, one group at a time
dat2wayMC$g &lt;- 1:2

model2 &lt;- "
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f12 =~ x1.x4 + x2.x5 + x3.x6
f3 =~ x7 + x8 + x9
f3 ~ c(b1.g1, b1.g2)*f1 + c(b2.g1, b2.g2)*f2 + c(b12.g1, b12.g2)*f12
f12 ~~ 0*f1 + 0*f2
"
fit2 &lt;- sem(model2, data = dat2wayMC, group = "g")
probe2WayMC(fit2, nameX = c("f1", "f2", "f12"), nameY = "f3",
            modVar = "f2", valProbe = c(-1, 0, 1)) # group = 1 by default
probe2WayMC(fit2, nameX = c("f1", "f2", "f12"), nameY = "f3",
            modVar = "f2", valProbe = c(-1, 0, 1), group = 2)

</code></pre>

<hr>
<h2 id='probe2WayRC'>Probing two-way interaction on the residual-centered latent interaction</h2><span id='topic+probe2WayRC'></span>

<h3>Description</h3>

<p>Probing interaction for simple intercept and simple slope for the
residual-centered latent two-way interaction (Geldhof et al., 2013)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probe2WayRC(fit, nameX, nameY, modVar, valProbe, group = 1L,
  omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probe2WayRC_+3A_fit">fit</code></td>
<td>
<p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object with a latent 2-way interaction.</p>
</td></tr>
<tr><td><code id="probe2WayRC_+3A_namex">nameX</code></td>
<td>
<p><code>character</code> vector of all 3 factor names used as the
predictors. The lower-order factors must be listed first, and the final
name must be the latent interaction factor.</p>
</td></tr>
<tr><td><code id="probe2WayRC_+3A_namey">nameY</code></td>
<td>
<p>The name of factor that is used as the dependent variable.</p>
</td></tr>
<tr><td><code id="probe2WayRC_+3A_modvar">modVar</code></td>
<td>
<p>The name of factor that is used as a moderator. The effect of
the other independent factor will be probed at each value of the
moderator variable listed in <code>valProbe</code>.</p>
</td></tr>
<tr><td><code id="probe2WayRC_+3A_valprobe">valProbe</code></td>
<td>
<p>The values of the moderator that will be used to probe the
effect of the focal predictor.</p>
</td></tr>
<tr><td><code id="probe2WayRC_+3A_group">group</code></td>
<td>
<p>In multigroup models, the label of the group for which the
results will be returned. Must correspond to one of
<code>lavInspect(fit, "group.label")</code>, or an integer
corresponding to which of those group labels.</p>
</td></tr>
<tr><td><code id="probe2WayRC_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results. Ignored unless <code>fit</code> is of
class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>. Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before using this function, researchers need to make the products of the
indicators between the first-order factors and residualize the products by
the original indicators (Lance, 1988; Little, Bovaird, &amp; Widaman, 2006). The
process can be automated by the <code><a href="#topic+indProd">indProd()</a></code> function. Note that
the indicator products can be made for all possible combination or
matched-pair approach (Marsh et al., 2004). Next, the hypothesized model
with the regression with latent interaction will be used to fit all original
indicators and the product terms. To use this function the model must be fit
with a mean structure. See the example for how to fit the product term
below. Once the lavaan result is obtained, this function will be used to
probe the interaction.
</p>
<p>The probing process on residual-centered latent interaction is based on
transforming the residual-centered result into the no-centered result. See
Geldhof et al. (2013) for further details. Note that this approach is based
on a strong assumption that the first-order latent variables are normally
distributed. The probing process is applied after the no-centered result
(parameter estimates and their covariance matrix among parameter estimates)
has been computed. See the <code><a href="#topic+probe2WayMC">probe2WayMC()</a></code> for further details.
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>

<ol>
<li> <p><code>SimpleIntercept</code>: The simple intercepts given each value of the
moderator.
</p>
</li>
<li> <p><code>SimpleSlope</code>: The simple slopes given each value of the moderator.
</p>
</li></ol>

<p>In each element, the first column represents the values of the moderators
specified in the <code>valProbe</code> argument. The second column is the simple
intercept or simple slope. The third column is the standard error of the
simple intercept or slope. The fourth column is the Wald (<em>z</em>)
statistic, and the fifth column is the associated <em>p</em> value testing
the null hypothesis that each simple intercept or slope is 0.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Tutorial:
</p>
<p>Schoemann, A. M., &amp; Jorgensen, T. D. (2021). Testing and interpreting
latent variable interactions using the <code>semTools</code> package.
<em>Psych, 3</em>(3), 322&ndash;335. <a href="https://doi.org/10.3390/psych3030024">doi:10.3390/psych3030024</a>
</p>
<p>Background literature:
</p>
<p>Lance, C. E. (1988). Residual centering, exploratory and confirmatory
moderator analysis, and decomposition of effects in path models containing
interactions. <em>Applied Psychological Measurement, 12</em>(2), 163&ndash;175.
<a href="https://doi.org/10.1177/014662168801200205">doi:10.1177/014662168801200205</a>
</p>
<p>Little, T. D., Bovaird, J. A., &amp; Widaman, K. F. (2006). On the merits of
orthogonalizing powered and product terms: Implications for modeling
interactions. <em>Structural Equation Modeling, 13</em>(4), 497&ndash;519.
<a href="https://doi.org/10.1207/s15328007sem1304_1">doi:10.1207/s15328007sem1304_1</a>
</p>
<p>Marsh, H. W., Wen, Z., &amp; Hau, K. T. (2004). Structural equation models of
latent interactions: Evaluation of alternative estimation strategies and
indicator construction. <em>Psychological Methods, 9</em>(3), 275&ndash;300.
<a href="https://doi.org/10.1037/1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>
</p>
<p>Geldhof, G. J., Pornprasertmanit, S., Schoemann, A. M., &amp; Little, T. D.
(2013). Orthogonalizing through residual centering: Extended applications
and caveats. <em>Educational and Psychological Measurement, 73</em>(1), 27&ndash;46.
<a href="https://doi.org/10.1177/0013164412445473">doi:10.1177/0013164412445473</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+indProd">indProd()</a></code> For creating the indicator products with no
centering, mean centering, double-mean centering, or residual centering.
</p>
</li>
<li> <p><code><a href="#topic+probe2WayMC">probe2WayMC()</a></code> For probing the two-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe3WayMC">probe3WayMC()</a></code> For probing the three-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe3WayRC">probe3WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+plotProbe">plotProbe()</a></code> Plot the simple intercepts and slopes of the
latent interaction.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
dat2wayRC &lt;- orthogonalize(dat2way, 1:3, 4:6)

model1 &lt;- "
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f12 =~ x1.x4 + x2.x5 + x3.x6
f3 =~ x7 + x8 + x9
f3 ~ f1 + f2 + f12
f12 ~~ 0*f1 + 0*f2
x1 + x4 + x1.x4 + x7 ~ 0*1 # identify latent means
f1 + f2 + f12 + f3 ~ NA*1
"

fitRC2way &lt;- sem(model1, data = dat2wayRC, meanstructure = TRUE)
summary(fitRC2way)

probe2WayRC(fitRC2way, nameX = c("f1", "f2", "f12"), nameY = "f3",
            modVar = "f2", valProbe = c(-1, 0, 1))


## can probe multigroup models, one group at a time
dat2wayRC$g &lt;- 1:2

model2 &lt;- "
f1  =~ x1 + x2 + x3
f2  =~ x4 + x5 + x6
f12 =~ x1.x4 + x2.x5 + x3.x6
f3  =~ x7 + x8 + x9
f3 ~ c(b1.g1, b1.g2)*f1 + c(b2.g1, b2.g2)*f2 + c(b12.g1, b12.g2)*f12
f12 ~~ 0*f1 + 0*f2
x1 + x4 + x1.x4 + x7 ~ 0*1 # identify latent means
f1 + f2 + f12 ~ NA*1
f3 ~ NA*1 + c(b0.g1, b0.g2)*1
"
fit2 &lt;- sem(model2, data = dat2wayRC, group = "g")
probe2WayRC(fit2, nameX = c("f1", "f2", "f12"), nameY = "f3",
            modVar = "f2", valProbe = c(-1, 0, 1)) # group = 1 by default
probe2WayRC(fit2, nameX = c("f1", "f2", "f12"), nameY = "f3",
            modVar = "f2", valProbe = c(-1, 0, 1), group = 2)

</code></pre>

<hr>
<h2 id='probe3WayMC'>Probing three-way interaction on the no-centered or mean-centered latent
interaction</h2><span id='topic+probe3WayMC'></span>

<h3>Description</h3>

<p>Probing interaction for simple intercept and simple slope for the
no-centered or mean-centered latent two-way interaction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probe3WayMC(fit, nameX, nameY, modVar, valProbe1, valProbe2, group = 1L,
  omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probe3WayMC_+3A_fit">fit</code></td>
<td>
<p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object with a latent 2-way interaction.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_namex">nameX</code></td>
<td>
<p><code>character</code> vector of all 7 factor names used as the
predictors. The 3 lower-order factors must be listed first, followed by
the 3 second-order factors (specifically, the 4th element must be the
interaction between the factors listed first and second, the 5th element
must be the interaction between the factors listed first and third, and
the 6th element must be the interaction between the factors listed second
and third). The final name will be the factor representing the 3-way
interaction.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_namey">nameY</code></td>
<td>
<p>The name of factor that is used as the dependent variable.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_modvar">modVar</code></td>
<td>
<p>The name of two factors that are used as the moderators. The
effect of the independent factor will be probed at each combination of
the moderator variables' chosen values.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_valprobe1">valProbe1</code></td>
<td>
<p>The values of the first moderator that will be used to
probe the effect of the independent factor.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_valprobe2">valProbe2</code></td>
<td>
<p>The values of the second moderator that will be used to
probe the effect of the independent factor.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_group">group</code></td>
<td>
<p>In multigroup models, the label of the group for which the
results will be returned. Must correspond to one of
<code>lavInspect(fit, "group.label")</code>.</p>
</td></tr>
<tr><td><code id="probe3WayMC_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results. Ignored unless <code>fit</code> is of
class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>. Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before using this function, researchers need to make the products of the
indicators between the first-order factors using mean centering (Marsh, Wen,
&amp; Hau, 2004). Note that the double-mean centering may not be appropriate for
probing interaction if researchers are interested in simple intercepts. The
mean or double-mean centering can be done by the <code><a href="#topic+indProd">indProd()</a></code>
function. The indicator products can be made for all possible combination or
matched-pair approach (Marsh et al., 2004). Next, the hypothesized model
with the regression with latent interaction will be used to fit all original
indicators and the product terms. See the example for how to fit the product
term below. Once the lavaan result is obtained, this function will be used
to probe the interaction.
</p>
<p>Let that the latent interaction model regressing the dependent variable
(<code class="reqn">Y</code>) on the independent variable (<code class="reqn">X</code>) and two moderators (<code class="reqn">Z</code>
and <code class="reqn">W</code>) be </p>
<p style="text-align: center;"><code class="reqn"> Y = b_0 + b_1X + b_2Z + b_3W + b_4XZ + b_5XW + b_6ZW
+ b_7XZW + r, </code>
</p>
<p> where <code class="reqn">b_0</code> is the estimated intercept or the expected
value of <code class="reqn">Y</code> when <code class="reqn">X</code>, <code class="reqn">Z</code>, and <code class="reqn">W</code> are 0, <code class="reqn">b_1</code> is the
effect of <code class="reqn">X</code> when <code class="reqn">Z</code> and <code class="reqn">W</code> are 0, <code class="reqn">b_2</code> is the effect of
<code class="reqn">Z</code> when <code class="reqn">X</code> and <code class="reqn">W</code> is 0, <code class="reqn">b_3</code> is the effect of <code class="reqn">W</code>
when <code class="reqn">X</code> and <code class="reqn">Z</code> are 0, <code class="reqn">b_4</code> is the interaction effect between
<code class="reqn">X</code> and <code class="reqn">Z</code> when <code class="reqn">W</code> is 0, <code class="reqn">b_5</code> is the interaction effect
between <code class="reqn">X</code> and <code class="reqn">W</code> when <code class="reqn">Z</code> is 0, <code class="reqn">b_6</code> is the interaction
effect between <code class="reqn">Z</code> and <code class="reqn">W</code> when <code class="reqn">X</code> is 0, <code class="reqn">b_7</code> is the
three-way interaction effect between <code class="reqn">X</code>, <code class="reqn">Z</code>, and <code class="reqn">W</code>, and
<code class="reqn">r</code> is the residual term.
</p>
<p>To probe a three-way interaction, the simple intercept of the independent
variable at the specific values of the moderators (Aiken &amp; West, 1991) can
be obtained by
</p>
<p style="text-align: center;"><code class="reqn"> b_{0|X = 0, Z, W} = b_0 + b_2Z + b_3W + b_6ZW. </code>
</p>

<p>The simple slope of the independent variable at the specific values of the
moderators can be obtained by
</p>
<p style="text-align: center;"><code class="reqn"> b_{X|Z, W} = b_1 + b_3Z + b_4W + b_7ZW.</code>
</p>

<p>The variance of the simple intercept formula is
</p>
<p style="text-align: center;"><code class="reqn"> Var\left(b_{0|X = 0, Z, W}\right) =
    Var\left(b_0\right) + Z^2Var\left(b_2\right) + W^2Var\left(b_3\right) +
    Z^2W^2Var\left(b_6\right)</code>
</p>

<p style="text-align: center;"><code class="reqn">+ 2ZCov\left(b_0, b_2\right)    + 2WCov\left(b_0, b_3\right)  +
        2ZWCov\left(b_0, b_6\right)   + 2ZWCov\left(b_2, b_3\right) +
        2Z^2WCov\left(b_2, b_6\right) + 2ZW^2Cov\left(b_3, b_6\right), </code>
</p>

<p>where <code class="reqn">Var</code> denotes the variance of a parameter estimate and <code class="reqn">Cov</code>
denotes the covariance of two parameter estimates.
</p>
<p>The variance of the simple slope formula is
</p>
<p style="text-align: center;"><code class="reqn"> Var\left(b_{X|Z, W}\right) =
      Var\left(b_1\right) + Z^2Var\left(b_4\right) + W^2Var\left(b_5\right)
      + Z^2W^2Var\left(b_7\right) </code>
</p>

<p style="text-align: center;"><code class="reqn">+ 2ZCov\left(b_1, b_4\right)    + 2WCov\left(b_1, b_5\right)  +
        2ZWCov\left(b_1, b_7\right)   + 2ZWCov\left(b_4, b_5\right) +
        2Z^2WCov\left(b_4, b_7\right) + 2ZW^2Cov\left(b_5, b_7\right). </code>
</p>

<p>Wald <em>z</em> statistics are calculated (even for objects of class
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>) to test null hypotheses that simple
intercepts or slopes are 0.
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>

<ol>
<li> <p><code>SimpleIntercept</code>: The model-implied intercepts given each
combination of moderator values.
</p>
</li>
<li> <p><code>SimpleSlope</code>: The model-implied slopes given each combination
of moderator values.
</p>
</li></ol>

<p>In each element, the first column represents values of the first moderator
specified in the <code>valProbe1</code> argument. The second column represents
values of the second moderator specified in the <code>valProbe2</code> argument.
The third column is the simple intercept or simple slope. The fourth column
is the standard error of the simple intercept or simple slope. The fifth
column is the Wald (<em>z</em>) statistic, and the sixth column is its
associated <em>p</em> value to test the null hypothesis that each simple
intercept or simple slope equals 0.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Tutorial:
</p>
<p>Schoemann, A. M., &amp; Jorgensen, T. D. (2021). Testing and interpreting
latent variable interactions using the <code>semTools</code> package.
<em>Psych, 3</em>(3), 322&ndash;335. <a href="https://doi.org/10.3390/psych3030024">doi:10.3390/psych3030024</a>
</p>
<p>Background literature:
</p>
<p>Aiken, L. S., &amp; West, S. G. (1991). <em>Multiple regression: Testing
and interpreting interactions</em>. Newbury Park, CA: Sage.
</p>
<p>Marsh, H. W., Wen, Z., &amp; Hau, K. T. (2004). Structural equation models of
latent interactions: Evaluation of alternative estimation strategies and
indicator construction. <em>Psychological Methods, 9</em>(3), 275&ndash;300.
<a href="https://doi.org/10.1037/1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+indProd">indProd()</a></code> For creating the indicator products with no
centering, mean centering, double-mean centering, or residual centering.
</p>
</li>
<li> <p><code><a href="#topic+probe2WayMC">probe2WayMC()</a></code> For probing the two-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe2WayRC">probe2WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+probe3WayRC">probe3WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+plotProbe">plotProbe()</a></code> Plot the simple intercepts and slopes of the
latent interaction.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
dat3wayMC &lt;- indProd(dat3way, 1:3, 4:6, 7:9)

model3 &lt;- " ## define latent variables
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
## 2-way interactions
f12 =~ x1.x4 + x2.x5 + x3.x6
f13 =~ x1.x7 + x2.x8 + x3.x9
f23 =~ x4.x7 + x5.x8 + x6.x9
## 3-way interaction
f123 =~ x1.x4.x7 + x2.x5.x8 + x3.x6.x9
## outcome variable
f4 =~ x10 + x11 + x12

## latent regression model
f4 ~ b1*f1 + b2*f2 + b3*f3 + b12*f12 + b13*f13 + b23*f23 + b123*f123

## orthogonal terms among predictors
## (not necessary, but implied by double mean centering)
f1 ~~ 0*f12 + 0*f13 + 0*f123
f2 ~~ 0*f12 + 0*f23 + 0*f123
f3 ~~ 0*f13 + 0*f23 + 0*f123
f12 + f13 + f23 ~~ 0*f123
"

fitMC3way &lt;- sem(model3, data = dat3wayMC, meanstructure = TRUE)
summary(fitMC3way)

probe3WayMC(fitMC3way, nameX = c("f1" ,"f2" ,"f3",
                                 "f12","f13","f23", # this order matters!
                                 "f123"),           # 3-way interaction
            nameY = "f4", modVar = c("f1", "f2"),
            valProbe1 = c(-1, 0, 1), valProbe2 = c(-1, 0, 1))

</code></pre>

<hr>
<h2 id='probe3WayRC'>Probing three-way interaction on the residual-centered latent interaction</h2><span id='topic+probe3WayRC'></span>

<h3>Description</h3>

<p>Probing interaction for simple intercept and simple slope for the
residual-centered latent three-way interaction (Geldhof et al., 2013)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probe3WayRC(fit, nameX, nameY, modVar, valProbe1, valProbe2, group = 1L,
  omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="probe3WayRC_+3A_fit">fit</code></td>
<td>
<p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or
<a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object with a latent 2-way interaction.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_namex">nameX</code></td>
<td>
<p><code>character</code> vector of all 7 factor names used as the
predictors. The 3 lower-order factors must be listed first, followed by
the 3 second-order factors (specifically, the 4th element must be the
interaction between the factors listed first and second, the 5th element
must be the interaction between the factors listed first and third, and
the 6th element must be the interaction between the factors listed second
and third). The final name will be the factor representing the 3-way
interaction.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_namey">nameY</code></td>
<td>
<p>The name of factor that is used as the dependent variable.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_modvar">modVar</code></td>
<td>
<p>The name of two factors that are used as the moderators. The
effect of the independent factor on each combination of the moderator
variable values will be probed.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_valprobe1">valProbe1</code></td>
<td>
<p>The values of the first moderator that will be used to
probe the effect of the independent factor.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_valprobe2">valProbe2</code></td>
<td>
<p>The values of the second moderator that will be used to
probe the effect of the independent factor.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_group">group</code></td>
<td>
<p>In multigroup models, the label of the group for which the
results will be returned. Must correspond to one of
<code>lavInspect(fit, "group.label")</code>.</p>
</td></tr>
<tr><td><code id="probe3WayRC_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results. Ignored unless <code>fit</code> is of
class <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a>. Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Before using this function, researchers need to make the products of the
indicators between the first-order factors and residualize the products by
the original indicators (Lance, 1988; Little, Bovaird, &amp; Widaman, 2006). The
process can be automated by the <code><a href="#topic+indProd">indProd()</a></code> function. Note that
the indicator products can be made for all possible combination or
matched-pair approach (Marsh et al., 2004). Next, the hypothesized model
with the regression with latent interaction will be used to fit all original
indicators and the product terms (Geldhof et al., 2013). To use this
function the model must be fit with a mean structure. See the example for
how to fit the product term below. Once the lavaan result is obtained, this
function will be used to probe the interaction.
</p>
<p>The probing process on residual-centered latent interaction is based on
transforming the residual-centered result into the no-centered result. See
Geldhof et al. (2013) for further details. Note that this approach based on
a strong assumption that the first-order latent variables are normally
distributed. The probing process is applied after the no-centered result
(parameter estimates and their covariance matrix among parameter estimates)
has been computed. See the <code><a href="#topic+probe3WayMC">probe3WayMC()</a></code> for further details.
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>

<ol>
<li> <p><code>SimpleIntercept</code>: The model-implied intercepts given each
combination of moderator values.
</p>
</li>
<li> <p><code>SimpleSlope</code>: The model-implied slopes given each combination
of moderator values.
</p>
</li></ol>

<p>In each element, the first column represents values of the first moderator
specified in the <code>valProbe1</code> argument. The second column represents
values of the second moderator specified in the <code>valProbe2</code> argument.
The third column is the simple intercept or simple slope. The fourth column
is the <em>SE</em> of the simple intercept or simple slope. The fifth column
is the Wald (<em>z</em>) statistic, and the sixth column is its associated
<em>p</em> value to test the null hypothesis that each simple intercept or
simple slope equals 0.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Tutorial:
</p>
<p>Schoemann, A. M., &amp; Jorgensen, T. D. (2021). Testing and interpreting
latent variable interactions using the <code>semTools</code> package.
<em>Psych, 3</em>(3), 322&ndash;335. <a href="https://doi.org/10.3390/psych3030024">doi:10.3390/psych3030024</a>
</p>
<p>Background literature:
</p>
<p>Geldhof, G. J., Pornprasertmanit, S., Schoemann, A., &amp; Little,
T. D. (2013). Orthogonalizing through residual centering: Extended
applications and caveats. <em>Educational and Psychological Measurement,
73</em>(1), 27&ndash;46. <a href="https://doi.org/10.1177/0013164412445473">doi:10.1177/0013164412445473</a>
</p>
<p>Lance, C. E. (1988). Residual centering, exploratory and confirmatory
moderator analysis, and decomposition of effects in path models containing
interactions. <em>Applied Psychological Measurement, 12</em>(2), 163&ndash;175.
<a href="https://doi.org/10.1177/014662168801200205">doi:10.1177/014662168801200205</a>
</p>
<p>Little, T. D., Bovaird, J. A., &amp; Widaman, K. F. (2006). On the merits of
orthogonalizing powered and product terms: Implications for modeling
interactions. <em>Structural Equation Modeling, 13</em>(4), 497&ndash;519.
<a href="https://doi.org/10.1207/s15328007sem1304_1">doi:10.1207/s15328007sem1304_1</a>
</p>
<p>Marsh, H. W., Wen, Z., &amp; Hau, K. T. (2004). Structural equation models of
latent interactions: Evaluation of alternative estimation strategies and
indicator construction. <em>Psychological Methods, 9</em>(3), 275&ndash;300.
<a href="https://doi.org/10.1037/1082-989X.9.3.275">doi:10.1037/1082-989X.9.3.275</a>
</p>
<p>Pornprasertmanit, S., Schoemann, A. M., Geldhof, G. J., &amp; Little, T. D.
(submitted). <em>Probing latent interaction estimated with a residual
centering approach.</em>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+indProd">indProd()</a></code> For creating the indicator products with no
centering, mean centering, double-mean centering, or residual centering.
</p>
</li>
<li> <p><code><a href="#topic+probe2WayMC">probe2WayMC()</a></code> For probing the two-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe3WayMC">probe3WayMC()</a></code> For probing the three-way latent interaction
when the results are obtained from mean-centering, or double-mean centering
</p>
</li>
<li> <p><code><a href="#topic+probe2WayRC">probe2WayRC()</a></code> For probing the two-way latent interaction
when the results are obtained from residual-centering approach.
</p>
</li>
<li> <p><code><a href="#topic+plotProbe">plotProbe()</a></code> Plot the simple intercepts and slopes of the
latent interaction.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
dat3wayRC &lt;- orthogonalize(dat3way, 1:3, 4:6, 7:9)

model3 &lt;- " ## define latent variables
f1 =~ x1 + x2 + x3
f2 =~ x4 + x5 + x6
f3 =~ x7 + x8 + x9
## 2-way interactions
f12 =~ x1.x4 + x2.x5 + x3.x6
f13 =~ x1.x7 + x2.x8 + x3.x9
f23 =~ x4.x7 + x5.x8 + x6.x9
## 3-way interaction
f123 =~ x1.x4.x7 + x2.x5.x8 + x3.x6.x9
## outcome variable
f4 =~ x10 + x11 + x12

## latent regression model
f4 ~ b1*f1 + b2*f2 + b3*f3 + b12*f12 + b13*f13 + b23*f23 + b123*f123

## orthogonal terms among predictors
f1 ~~ 0*f12 + 0*f13 + 0*f123
f2 ~~ 0*f12 + 0*f23 + 0*f123
f3 ~~ 0*f13 + 0*f23 + 0*f123
f12 + f13 + f23 ~~ 0*f123

## identify latent means
x1 + x4 + x7 + x1.x4 + x1.x7 + x4.x7 + x1.x4.x7 + x10 ~ 0*1
f1 + f2 + f3 + f12 + f13 + f23 + f123 + f4 ~ NA*1
"

fitRC3way &lt;- sem(model3, data = dat3wayRC, meanstructure = TRUE)
summary(fitRC3way)

probe3WayMC(fitRC3way, nameX = c("f1" ,"f2" ,"f3",
                                 "f12","f13","f23", # this order matters!
                                 "f123"),           # 3-way interaction
            nameY = "f4", modVar = c("f1", "f2"),
            valProbe1 = c(-1, 0, 1), valProbe2 = c(-1, 0, 1))

</code></pre>

<hr>
<h2 id='quark'>Quark</h2><span id='topic+quark'></span>

<h3>Description</h3>

<p>The <code>quark</code> function provides researchers with the ability to calculate
and include component scores calculated by taking into account the variance
in the original dataset and all of the interaction and polynomial effects of
the data in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quark(data, id, order = 1, silent = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="quark_+3A_data">data</code></td>
<td>
<p>The data frame is a required component for <code>quark</code>.  In
order for <code>quark</code> to process a data frame, it must not contain any
factors or text-based variables.  All variables must be in numeric format.
Identifiers and dates can be left in the data; however, they will need to be
identified under the <code>id</code> argument.</p>
</td></tr>
<tr><td><code id="quark_+3A_id">id</code></td>
<td>
<p>Identifiers and dates within the dataset will need to be
acknowledged as <code>quark</code> cannot process these.  By acknowledging the
identifiers and dates as a vector of column numbers or variable names,
<code>quark</code> will remove them from the data temporarily to complete its main
processes.  Among many potential issues of not acknowledging identifiers and
dates are issues involved with imputation, product and polynomial effects,
and principal component analysis.</p>
</td></tr>
<tr><td><code id="quark_+3A_order">order</code></td>
<td>
<p>Order is an optional argument provided by quark that can be
used when the imputation procedures in mice fail.  Under some circumstances,
mice cannot calculate missing values due to issues with extreme missingness.
Should an error present itself stating a failure due to not having any
columns selected, set the argument <code>order = 2</code> in order to reorder the
imputation method procedure.  Otherwise, use the default <code>order = 1</code>.</p>
</td></tr>
<tr><td><code id="quark_+3A_silent">silent</code></td>
<td>
<p>If <code>FALSE</code>, the details of the <code>quark</code> process are
printed.</p>
</td></tr>
<tr><td><code id="quark_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="mice.html#topic+mice">mice::mice()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>quark</code> function calculates these component scores by first filling
in the data via means of multiple imputation methods and then expanding the
dataset by aggregating the non-overlapping interaction effects between
variables by calculating the mean of the interactions and polynomial
effects.  The multiple imputation methods include one of iterative sampling
and group mean substitution and multiple imputation using a polytomous
regression algorithm (mice). During the expansion process, the dataset is
expanded to three times its normal size (in width). The first third of the
dataset contains all of the original data post imputation, the second third
contains the means of the polynomial effects (squares and cubes), and the
final third contains the means of the non-overlapping interaction effects. A
full principal componenent analysis is conducted and the individual
components are retained. The subsequent <code><a href="#topic+combinequark">combinequark()</a></code> function
provides researchers the control in determining how many components to
extract and retain. The function returns the dataset as submitted (with
missing values) and the component scores as requested for a more accurate
multiple imputation in subsequent steps.
</p>


<h3>Value</h3>

<p>The output value from using the quark function is a list. It will
return a list with 7 components.
</p>
<table role = "presentation">
<tr><td><code>ID Columns</code></td>
<td>
<p>Is a vector of the identifier columns entered when
running quark.</p>
</td></tr>
<tr><td><code>ID Variables</code></td>
<td>
<p>Is a subset of the dataset that contains the identifiers
as acknowledged when running quark.</p>
</td></tr>
<tr><td><code>Used Data</code></td>
<td>
<p>Is a matrix / dataframe of the data provided by user as
the basis for quark to process.</p>
</td></tr>
<tr><td><code>Imputed Data</code></td>
<td>
<p>Is a matrix / dataframe of the data after the multiple
method imputation process.</p>
</td></tr>
<tr><td><code>Big Matrix</code></td>
<td>
<p>Is the expanded product and polynomial matrix.</p>
</td></tr>
<tr><td><code>Principal Components</code></td>
<td>
<p>Is the entire dataframe of principal components
for the dataset.  This dataset will have the same number of rows of the big
matrix, but will have 1 less column (as is the case with principal
component analyses).</p>
</td></tr>
<tr><td><code>Percent Variance Explained</code></td>
<td>
<p>Is a vector of the percent variance
explained with each column of principal components.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Steven R. Chesnut (University of Southern Mississippi;
<a href="mailto:Steven.Chesnut@usm.edu">Steven.Chesnut@usm.edu</a>)
</p>
<p>Danny Squire (Texas Tech University)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam)
</p>
<p>The PCA code is copied and modified from the <code>FactoMineR</code> package.
</p>


<h3>References</h3>

<p>Howard, W. J., Rhemtulla, M., &amp; Little, T. D. (2015). Using
Principal Components as Auxiliary Variables in Missing Data Estimation.
<em>Multivariate Behavioral Research, 50</em>(3), 285&ndash;299.
<a href="https://doi.org/10.1080/00273171.2014.999267">doi:10.1080/00273171.2014.999267</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+combinequark">combinequark()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
set.seed(123321)

dat &lt;- HolzingerSwineford1939[,7:15]
misspat &lt;- matrix(runif(nrow(dat) * 9) &lt; 0.3, nrow(dat))
dat[misspat] &lt;- NA
dat &lt;- cbind(HolzingerSwineford1939[,1:3], dat)

quark.list &lt;- quark(data = dat, id = c(1, 2))

final.data &lt;- combinequark(quark = quark.list, percent = 80)

## Example to rerun quark after imputation failure:
quark.list &lt;- quark(data = dat, id = c(1, 2), order = 2)


</code></pre>

<hr>
<h2 id='reliability-deprecated'>Composite Reliability using SEM</h2><span id='topic+reliability-deprecated'></span>

<h3>Description</h3>

<p>Calculate composite reliability from estimated factor-model parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reliability(object, what = c("alpha", "omega", "omega2", "omega3", "ave"),
            return.total = FALSE, dropSingle = TRUE, omit.factors = character(0),
            omit.indicators = character(0), omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reliability-deprecated_+3A_object">object</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object,
expected to contain only exogenous common factors (i.e., a CFA model).</p>
</td></tr>
<tr><td><code id="reliability-deprecated_+3A_what">what</code></td>
<td>
<p><code>character</code> vector naming any reliability indices to
calculate. All are returned by default. When indicators are ordinal,
both traditional <code>"alpha"</code> and Zumbo et al.'s (2007) so-called
&quot;ordinal alpha&quot; (<code>"alpha.ord"</code>) are returned, though the latter is
arguably of dubious value (Chalmers, 2018).</p>
</td></tr>
<tr><td><code id="reliability-deprecated_+3A_return.total">return.total</code></td>
<td>
<p><code>logical</code> indicating whether to return a final
column containing the reliability of a composite of all indicators (not
listed in <code>omit.indicators</code>) of factors not listed in
<code>omit.factors</code>.  Ignored in 1-factor models, and should only be set
<code>TRUE</code> if all factors represent scale dimensions that could be
meaningfully collapsed to a single composite (scale sum or scale mean).</p>
</td></tr>
<tr><td><code id="reliability-deprecated_+3A_dropsingle">dropSingle</code></td>
<td>
<p><code>logical</code> indicating whether to exclude factors
defined by a single indicator from the returned results. If <code>TRUE</code>
(default), single indicators will still be included in the <code>total</code>
column when <code>return.total = TRUE</code>.</p>
</td></tr>
<tr><td><code id="reliability-deprecated_+3A_omit.factors">omit.factors</code></td>
<td>
<p><code>character</code> vector naming any common factors
modeled in <code>object</code> whose composite reliability is not of
interest. For example, higher-order or method factors. Note that
<code><a href="#topic+reliabilityL2">reliabilityL2()</a></code> should be used to calculate composite
reliability of a higher-order factor.</p>
</td></tr>
<tr><td><code id="reliability-deprecated_+3A_omit.indicators">omit.indicators</code></td>
<td>
<p><code>character</code> vector naming any observed variables
that should be ignored when calculating composite reliability. This can
be useful, for example, to estimate reliability when an indicator is
removed.</p>
</td></tr>
<tr><td><code id="reliability-deprecated_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coefficient alpha (Cronbach, 1951) can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \alpha = \frac{k}{k - 1}\left[ 1 - \frac{\sum^{k}_{i = 1}
\sigma_{ii}}{\sum^{k}_{i = 1} \sigma_{ii} + 2\sum_{i &lt; j} \sigma_{ij}}
\right],</code>
</p>

<p>where <code class="reqn">k</code> is the number of items in a factor, <code class="reqn">\sigma_{ii}</code> is the
item <em>i</em> observed variances, <code class="reqn">\sigma_{ij}</code> is the observed
covariance of items <em>i</em> and <em>j</em>.
</p>
<p>Several coefficients for factor-analysis reliability have been termed
&quot;omega&quot;, which Cho (2021) argues is a misleading misnomer and argues for
using <code class="reqn">\rho</code> to represent them all, differentiated by descriptive
subscripts.  In our package, we number <code class="reqn">\omega</code> based on commonly
applied calculations.  Bentler (1968) first introduced factor-analysis
reliability for a unidimensional factor model with congeneric indicators.
However, assuming there are no cross-loadings in a multidimensional CFA,
this reliability coefficient can be calculated for each factor in the model.
</p>
<p style="text-align: center;"><code class="reqn"> \omega_1 =\frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right) + \sum^{k}_{i = 1} \theta_{ii} + 2\sum_{i &lt; j}
\theta_{ij} }, </code>
</p>

<p>where <code class="reqn">\lambda_i</code> is the factor loading of item <em>i</em>, <code class="reqn">\psi</code> is
the factor variance, <code class="reqn">\theta_{ii}</code> is the variance of measurement errors
of item <em>i</em>, and <code class="reqn">\theta_{ij}</code> is the covariance of measurement
errors from item <em>i</em> and <em>j</em>. McDonald (1999) later referred to
this <em>and other reliability coefficients</em> as &quot;omega&quot;, which is a source
of confusion when reporting coefficients (Cho, 2021).
</p>
<p>The additional coefficients generalize the first formula by accounting for
multidimenisionality (possibly with cross-loadings) and correlated errors.
By setting <code>return.total=TRUE</code>, one can estimate reliability for a
single composite calculated using all indicators in the multidimensional
CFA (Bentler, 1972, 2009).  <code>"omega2"</code> is calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \omega_2 = \frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\bold{1}^\prime \hat{\Sigma} \bold{1}}, </code>
</p>

<p>where <code class="reqn">\hat{\Sigma}</code> is the model-implied covariance matrix, and
<code class="reqn">\bold{1}</code> is the <code class="reqn">k</code>-dimensional vector of 1. The first and the
second coefficients omega will have the same value per factor in models with
simple structure, but they differ when there are (e.g.) cross-loadings
or method factors. The first coefficient omega can be viewed as the
reliability controlling for the other factors (like <code class="reqn">\eta^2_{partial}</code> in
ANOVA). The second coefficient omega can be viewed as the unconditional
reliability (like <code class="reqn">\eta^2</code> in ANOVA).
</p>
<p>The <code>"omega3"</code> coefficient (McDonald, 1999), sometimes referred to as
hierarchical omega, can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> \omega_3 =\frac{\left( \sum^{k}_{i = 1} \lambda_i \right)^{2}
Var\left( \psi \right)}{\bold{1}^\prime \Sigma \bold{1}}, </code>
</p>

<p>where <code class="reqn">\Sigma</code> is the observed covariance matrix. If the model fits the
data well, <code class="reqn">\omega_3</code> will be similar to <code class="reqn">\omega_2</code>. Note that if
there is a directional effect in the model, all coefficients are calculated
from total factor variances: <code>lavInspect(object, "cov.lv")</code>.
</p>
<p>In conclusion, <code class="reqn">\omega_1</code>, <code class="reqn">\omega_2</code>, and <code class="reqn">\omega_3</code> are
different in the denominator. The denominator of the first formula assumes
that a model is congeneric factor model where measurement errors are not
correlated. The second formula accounts for correlated measurement errors.
However, these two formulas assume that the model-implied covariance matrix
explains item relationships perfectly. The residuals are subject to sampling
error. The third formula use observed covariance matrix instead of
model-implied covariance matrix to calculate the observed total variance.
This formula is the most conservative method in calculating coefficient
omega.
</p>
<p>The average variance extracted (AVE) can be calculated by
</p>
<p style="text-align: center;"><code class="reqn"> AVE = \frac{\bold{1}^\prime
\textrm{diag}\left(\Lambda\Psi\Lambda^\prime\right)\bold{1}}{\bold{1}^\prime
\textrm{diag}\left(\hat{\Sigma}\right) \bold{1}}, </code>
</p>

<p>Note that this formula is modified from Fornell &amp; Larcker (1981) in the case
that factor variances are not 1. The proposed formula from Fornell &amp; Larcker
(1981) assumes that the factor variances are 1. Note that AVE will not be
provided for factors consisting of items with dual loadings. AVE is the
property of items but not the property of factors. AVE is calculated with
polychoric correlations when ordinal indicators are used.
</p>
<p>Coefficient alpha is by definition applied by treating indicators as numeric
(see Chalmers, 2018), which is consistent with the <code>alpha</code> function in
the <code>psych</code> package. When indicators are ordinal, <code>reliability</code>
additionally applies the standard alpha calculation to the polychoric
correlation matrix to return Zumbo et al.'s (2007) &quot;ordinal alpha&quot;.
</p>
<p>Coefficient omega for categorical items is calculated using Green and Yang's
(2009, formula 21) approach. Three types of coefficient omega indicate
different methods to calculate item total variances. The original formula
from Green and Yang is equivalent to <code class="reqn">\omega_3</code> in this function.
Green and Yang did not propose a method for
calculating reliability with a mixture of categorical and continuous
indicators, and we are currently unaware of an appropriate method.
Therefore, when <code>reliability</code> detects both categorical and continuous
indicators of a factor, an error is returned. If the categorical indicators
load on a different factor(s) than continuous indicators, then reliability
will still be calculated separately for those factors, but
<code>return.total</code> must be <code>FALSE</code> (unless <code>omit.factors</code> is used
to isolate factors with indicators of the same type).
</p>


<h3>Value</h3>

<p>Reliability values (coefficient alpha, coefficients omega, average
variance extracted) of each factor in each group. If there are multiple
factors, a <code>total</code> column can optionally be included.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>
<p>Yves Rosseel (Ghent University; <a href="mailto:Yves.Rosseel@UGent.be">Yves.Rosseel@UGent.be</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Bentler, P. M. (1972). A lower-bound method for the dimension-free
measurement of internal consistency. <em>Social Science Research, 1</em>(4),
343&ndash;357. <a href="https://doi.org/10.1016/0049-089X%2872%2990082-8">doi:10.1016/0049-089X(72)90082-8</a>
</p>
<p>Bentler, P. M. (2009). Alpha, dimension-free, and model-based internal
consistency reliability. <em>Psychometrika, 74</em>(1), 137&ndash;143.
<a href="https://doi.org/10.1007/s11336-008-9100-1">doi:10.1007/s11336-008-9100-1</a>
</p>
<p>Chalmers, R. P. (2018). On misconceptions and the limited usefulness of
ordinal alpha. <em>Educational and Psychological Measurement, 78</em>(6),
1056&ndash;1071. <a href="https://doi.org/10.1177/0013164417727036">doi:10.1177/0013164417727036</a>
</p>
<p>Cho, E. (2021) Neither Cronbach’s alpha nor McDonald’s omega: A commentary
on Sijtsma and Pfadt. <em>Psychometrika, 86</em>(4), 877&ndash;886.
<a href="https://doi.org/10.1007/s11336-021-09801-1">doi:10.1007/s11336-021-09801-1</a>
</p>
<p>Cronbach, L. J. (1951). Coefficient alpha and the internal structure of
tests. <em>Psychometrika, 16</em>(3), 297&ndash;334. <a href="https://doi.org/10.1007/BF02310555">doi:10.1007/BF02310555</a>
</p>
<p>Fornell, C., &amp; Larcker, D. F. (1981). Evaluating structural equation models
with unobservable variables and measurement errors. <em>Journal of
Marketing Research, 18</em>(1), 39&ndash;50. <a href="https://doi.org/10.2307/3151312">doi:10.2307/3151312</a>
</p>
<p>Green, S. B., &amp; Yang, Y. (2009). Reliability of summed item scores using
structural equation modeling: An alternative to coefficient alpha.
<em>Psychometrika, 74</em>(1), 155&ndash;167. <a href="https://doi.org/10.1007/s11336-008-9099-3">doi:10.1007/s11336-008-9099-3</a>
</p>
<p>McDonald, R. P. (1999). <em>Test theory: A unified treatment</em>. Mahwah, NJ:
Erlbaum.
</p>
<p>Raykov, T. (2001). Estimation of congeneric scale reliability using
covariance structure analysis with nonlinear constraints <em>British
Journal of Mathematical and Statistical Psychology, 54</em>(2), 315&ndash;323.
<a href="https://doi.org/10.1348/000711001159582">doi:10.1348/000711001159582</a>
</p>
<p>Zumbo, B. D., Gadermann, A. M., &amp; Zeisser, C. (2007). Ordinal versions of
coefficients alpha and theta for Likert rating scales.
<em>Journal of Modern Applied Statistical Methods, 6</em>(1), 21&ndash;29.
<a href="https://doi.org/10.22237/jmasm/1177992180">doi:10.22237/jmasm/1177992180</a>
</p>
<p>Zumbo, B. D., &amp; Kroc, E. (2019). A measurement is a choice and Stevens’
scales of measurement do not help make it: A response to Chalmers.
<em>Educational and Psychological Measurement, 79</em>(6), 1184&ndash;1197.
<a href="https://doi.org/10.1177/0013164419844305">doi:10.1177/0013164419844305</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(HolzingerSwineford1939)
HS9 &lt;- HolzingerSwineford1939[ , c("x7","x8","x9")]
HSbinary &lt;- as.data.frame( lapply(HS9, cut, 2, labels=FALSE) )
names(HSbinary) &lt;- c("y7","y8","y9")
HS &lt;- cbind(HolzingerSwineford1939, HSbinary)

HS.model &lt;- ' visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ y7 + y8 + y9 '

fit &lt;- cfa(HS.model, data = HS, ordered = c("y7","y8","y9"), std.lv = TRUE)

## works for factors with exclusively continuous OR categorical indicators
reliability(fit)

## reliability for ALL indicators only available when they are
## all continuous or all categorical
reliability(fit, omit.factors = "speed", return.total = TRUE)


## loop over visual indicators to calculate alpha if one indicator is removed
for (i in paste0("x", 1:3)) {
  cat("Drop x", i, ":\n")
  print(reliability(fit, omit.factors = c("textual","speed"),
                    omit.indicators = i, what = "alpha"))
}


## works for multigroup models and for multilevel models (and both)
data(Demo.twolevel)
## assign clusters to arbitrary groups
Demo.twolevel$g &lt;- ifelse(Demo.twolevel$cluster %% 2L, "type1", "type2")
model2 &lt;- ' group: type1
  level: within
    fac =~ y1 + L2*y2 + L3*y3
  level: between
    fac =~ y1 + L2*y2 + L3*y3

group: type2
  level: within
    fac =~ y1 + L2*y2 + L3*y3
  level: between
    fac =~ y1 + L2*y2 + L3*y3
'
fit2 &lt;- sem(model2, data = Demo.twolevel, cluster = "cluster", group = "g")
reliability(fit2, what = c("alpha","omega3"))

</code></pre>

<hr>
<h2 id='reliabilityL2-deprecated'>Calculate the reliability values of a second-order factor</h2><span id='topic+reliabilityL2-deprecated'></span>

<h3>Description</h3>

<p>Calculate the reliability values (coefficient omega) of a second-order
factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reliabilityL2(object, secondFactor, omit.imps = c("no.conv", "no.se"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="reliabilityL2-deprecated_+3A_object">object</code></td>
<td>
<p>A <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> or <a href="lavaan.mi.html#topic+lavaan.mi-class">lavaan.mi::lavaan.mi</a> object,
expected to contain a least one exogenous higher-order common factor.</p>
</td></tr>
<tr><td><code id="reliabilityL2-deprecated_+3A_secondfactor">secondFactor</code></td>
<td>
<p>The name of a single second-order factor in the
model fitted in <code>object</code>. The function must be called multiple
times to estimate reliability for each higher-order factor.</p>
</td></tr>
<tr><td><code id="reliabilityL2-deprecated_+3A_omit.imps">omit.imps</code></td>
<td>
<p><code>character</code> vector specifying criteria for omitting
imputations from pooled results.  Can include any of
<code>c("no.conv", "no.se", "no.npd")</code>, the first 2 of which are the
default setting, which excludes any imputations that did not
converge or for which standard errors could not be computed.  The
last option (<code>"no.npd"</code>) would exclude any imputations which
yielded a nonpositive definite covariance matrix for observed or
latent variables, which would include any &quot;improper solutions&quot; such
as Heywood cases.  NPD solutions are not excluded by default because
they are likely to occur due to sampling error, especially in small
samples.  However, gross model misspecification could also cause
NPD solutions, users can compare pooled results with and without
this setting as a sensitivity analysis to see whether some
imputations warrant further investigation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first formula of the coefficient omega (in the
<code><a href="#topic+reliability">reliability()</a></code>) will be mainly used in the calculation. The
model-implied covariance matrix of a second-order factor model can be
separated into three sources: the second-order common-factor variance,
the residual variance of the first-order common factors (i.e., not
accounted for by the second-order factor), and the measurement error of
observed indicators:
</p>
<p style="text-align: center;"><code class="reqn"> \hat{\Sigma} = \Lambda \bold{B} \Phi_2 \bold{B}^{\prime}
\Lambda^{\prime} + \Lambda \Psi_{u} \Lambda^{\prime} + \Theta, </code>
</p>

<p>where <code class="reqn">\hat{\Sigma}</code> is the model-implied covariance matrix,
<code class="reqn">\Lambda</code> contains first-order factor loadings, <code class="reqn">\bold{B}</code> contains
second-order factor loadings, <code class="reqn">\Phi_2</code> is the covariance matrix of the
second-order factor(s), <code class="reqn">\Psi_{u}</code> is the covariance matrix of residuals
from first-order factors, and <code class="reqn">\Theta</code> is the covariance matrix of the
measurement errors from observed indicators. Thus, we can calculate the
proportion of variance of a composite score calculated from the observed
indicators (e.g., a total score or scale mean) that is attributable to the
second-order factor, i.e. coefficient omega at Level 1:
</p>
<p style="text-align: center;"><code class="reqn"> \omega_{L1} = \frac{\bold{1}^{\prime} \Lambda \bold{B} \Phi_2
\bold{B}^{\prime} \Lambda^{\prime} \bold{1}}{\bold{1}^{\prime} \Lambda
\bold{B} \Phi_2 \bold{B} ^{\prime} \Lambda^{\prime} \bold{1} +
\bold{1}^{\prime} \Lambda \Psi_{u} \Lambda^{\prime} \bold{1} +
\bold{1}^{\prime} \Theta \bold{1}}, </code>
</p>

<p>where <code class="reqn">\bold{1}</code> is the <em>k</em>-dimensional vector of 1 and <em>k</em> is
the number of observed variables.
</p>
<p>The model-implied covariance matrix among first-order factors (<code class="reqn">\Phi_1</code>)
can be calculated as:
</p>
<p style="text-align: center;"><code class="reqn"> \Phi_1 = \bold{B} \Phi_2 \bold{B}^{\prime} + \Psi_{u}, </code>
</p>

<p>Thus, the proportion of variance among first-order common factors that is
attributable to the second-order factor (i.e., coefficient omega at Level 2)
can be calculated as:
</p>
<p style="text-align: center;"><code class="reqn"> \omega_{L2} = \frac{\bold{1}_F^{\prime} \bold{B} \Phi_2
\bold{B}^{\prime} \bold{1}_F}{\bold{1}_F^{\prime} \bold{B} \Phi_2
\bold{B}^{\prime} \bold{1}_F + \bold{1}_F^{\prime} \Psi_{u} \bold{1}_F}, </code>
</p>

<p>where <code class="reqn">\bold{1}_F</code> is the <em>F</em>-dimensional vector of 1 and <em>F</em>
is the number of first-order factors. This Level-2 omega can be interpreted
as an estimate of the reliability of a hypothetical composite calculated
from error-free observable variables representing the first-order common
factors. This might only be meaningful as a thought experiment.
</p>
<p>An additional thought experiment is possible: If the observed indicators
contained only the second-order common-factor variance and unsystematic
measurement error, then there would be no first-order common factors because
their unique variances would be excluded from the observed measures. An
estimate of this hypothetical composite reliability can be calculated as the
partial coefficient omega at Level 1, or the proportion of observed
variance explained by the second-order factor after partialling out the
uniqueness from the first-order factors:
</p>
<p style="text-align: center;"><code class="reqn"> \omega_{L1} = \frac{\bold{1}^{\prime} \Lambda \bold{B} \Phi_2
\bold{B}^{\prime} \Lambda^{\prime} \bold{1}}{\bold{1}^{\prime} \Lambda
\bold{B} \Phi_2 \bold{B}^{\prime} \Lambda^{\prime} \bold{1} +
\bold{1}^{\prime} \Theta \bold{1}}, </code>
</p>

<p>Note that if the second-order factor has a direct factor loading on some
observed variables, the observed variables will be counted as first-order
factors, which might not be desirable.
</p>


<h3>Value</h3>

<p>Reliability values at Levels 1 and 2 of the second-order factor, as
well as the partial reliability value at Level 1
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
HS.model3 &lt;- ' visual  =~ x1 + x2 + x3
               textual =~ x4 + x5 + x6
               speed   =~ x7 + x8 + x9
               higher =~ visual + textual + speed'

fit6 &lt;- cfa(HS.model3, data = HolzingerSwineford1939)
reliability(fit6) # Should provide a warning for the endogenous variables
reliabilityL2(fit6, "higher")

</code></pre>

<hr>
<h2 id='residualCovariate'>Residual-center all target indicators by covariates</h2><span id='topic+residualCovariate'></span>

<h3>Description</h3>

<p>This function will regress target variables on the covariate and replace the
target variables by the residual of the regression analysis. This procedure
is useful to control the covariate from the analysis model (Geldhof,
Pornprasertmanit, Schoemann, &amp; Little, 2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residualCovariate(data, targetVar, covVar)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residualCovariate_+3A_data">data</code></td>
<td>
<p>The desired data to be transformed.</p>
</td></tr>
<tr><td><code id="residualCovariate_+3A_targetvar">targetVar</code></td>
<td>
<p>Varible names or the position of indicators that users wish
to be residual centered (as dependent variables)</p>
</td></tr>
<tr><td><code id="residualCovariate_+3A_covvar">covVar</code></td>
<td>
<p>Covariate names or the position of the covariates using for
residual centering (as independent variables) onto target variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The data that the target variables replaced by the residuals
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Geldhof, G. J., Pornprasertmanit, S., Schoemann, A. M., &amp;
Little, T. D. (2013). Orthogonalizing through residual centering:
Extended applications and caveats. <em>Educational and Psychological
Measurement, 73</em>(1), 27&ndash;46. <a href="https://doi.org/10.1177/0013164412445473">doi:10.1177/0013164412445473</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+indProd">indProd()</a></code> For creating the indicator products with no
centering, mean centering, double-mean centering, or residual centering.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- residualCovariate(attitude, 2:7, 1)

</code></pre>

<hr>
<h2 id='rotate-deprecated'>Implement orthogonal or oblique rotation</h2><span id='topic+rotate-deprecated'></span>

<h3>Description</h3>

<p>These functions will implement orthogonal or oblique rotation on
standardized factor loadings from a lavaan output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orthRotate(object, method = "varimax", ...)

oblqRotate(object, method = "quartimin", ...)

funRotate(object, fun, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rotate-deprecated_+3A_object">object</code></td>
<td>
<p>A lavaan output</p>
</td></tr>
<tr><td><code id="rotate-deprecated_+3A_method">method</code></td>
<td>
<p>The method of rotations, such as <code>"varimax"</code>,
<code>"quartimax"</code>, <code>"geomin"</code>, <code>"oblimin"</code>, or any gradient
projection algorithms listed in the <code><a href="GPArotation.html#topic+GPA">GPA</a></code> function
in the <code>GPArotation</code> package.</p>
</td></tr>
<tr><td><code id="rotate-deprecated_+3A_fun">fun</code></td>
<td>
<p>The name of the function that users wish to rotate the
standardized solution. The functions must take the first argument as the
standardized loading matrix and return the <code>GPArotation</code> object. Check
this page for available functions: <code><a href="GPArotation.html#topic+rotations">rotations</a></code>.</p>
</td></tr>
<tr><td><code id="rotate-deprecated_+3A_...">...</code></td>
<td>
<p>Additional arguments for the <code><a href="GPArotation.html#topic+GPForth">GPForth</a></code>
function (for <code>orthRotate</code>), the <code><a href="GPArotation.html#topic+GPFoblq">GPFoblq</a></code>
function (for <code>oblqRotate</code>), or the function that users provide in the
<code>fun</code> argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions will rotate the unrotated standardized factor loadings by
orthogonal rotation using the <code><a href="GPArotation.html#topic+GPForth">GPForth</a></code> function or
oblique rotation using the <code><a href="GPArotation.html#topic+GPFoblq">GPFoblq</a></code> function the
<code>GPArotation</code> package. The resulting rotation matrix will be used to
calculate standard errors of the rotated standardized factor loading by
delta method by numerically computing the Jacobian matrix by the
<code><a href="lavaan.html#topic+lav_func_jacobian_simple">lav_func_jacobian_simple</a></code> function.
</p>


<h3>Value</h3>

<p>An <code>linkS4class{EFA}</code> object that saves the rotated EFA solution
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>


unrotated &lt;- efaUnrotate(HolzingerSwineford1939, nf = 3,
                         varList = paste0("x", 1:9), estimator = "mlr")

# Orthogonal varimax
out.varimax &lt;- orthRotate(unrotated, method = "varimax")
summary(out.varimax, sort = FALSE, suppress = 0.3)

# Orthogonal Quartimin
orthRotate(unrotated, method = "quartimin")

# Oblique Quartimin
oblqRotate(unrotated, method = "quartimin")

# Geomin
oblqRotate(unrotated, method = "geomin")

# Target rotation
library(GPArotation)
target &lt;- matrix(0, 9, 3)
target[1:3, 1] &lt;- NA
target[4:6, 2] &lt;- NA
target[7:9, 3] &lt;- NA
colnames(target) &lt;- c("factor1", "factor2", "factor3")
## This function works with GPArotation version 2012.3-1
funRotate(unrotated, fun = "targetQ", Target = target)


</code></pre>

<hr>
<h2 id='runMI-deprecated'>Fit a lavaan Model to Multiple Imputed Data Sets</h2><span id='topic+runMI-deprecated'></span><span id='topic+lavaan.mi-deprecated'></span><span id='topic+cfa.mi-deprecated'></span><span id='topic+sem.mi-deprecated'></span><span id='topic+growth.mi-deprecated'></span>

<h3>Description</h3>

<p>This function fits a lavaan model to a list of imputed data sets, and can
also implement multiple imputation for a single <code>data.frame</code> with
missing observations, using either the Amelia package or the mice package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runMI(model, data, fun = "lavaan", ...,
      m, miArgs = list(), miPackage = "Amelia", seed = 12345)

lavaan.mi(model, data, ...,
          m, miArgs = list(), miPackage = "Amelia", seed = 12345)

cfa.mi(model, data, ...,
       m, miArgs = list(), miPackage = "Amelia", seed = 12345)

sem.mi(model, data, ...,
       m, miArgs = list(), miPackage = "Amelia", seed = 12345)

growth.mi(model, data, ...,
          m, miArgs = list(), miPackage = "Amelia", seed = 12345)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runMI-deprecated_+3A_model">model</code></td>
<td>
<p>The analysis model can be specified using
<code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> or a <code><a href="lavaan.html#topic+parTable">lavaan::parTable()</a></code></p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> with missing observations, or a <code>list</code>
of imputed data sets (if data are imputed already). If <code>runMI()</code> has
already been called, then imputed data sets are stored in the
<code style="white-space: pre;">&#8288;@DataList&#8288;</code> slot, so <code style="white-space: pre;">&#8288;data=&#8288;</code> can also be an <code>OLDlavaan.mi</code> object
from which the same imputed data will be used for additional analyses.</p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_fun">fun</code></td>
<td>
<p><code>character</code>. Name of a specific lavaan function used to fit
<code style="white-space: pre;">&#8288;model=&#8288;</code> to <code style="white-space: pre;">&#8288;data=&#8288;</code> (i.e., <code>"lavaan"</code>, <code>"cfa"</code>, <code>"sem"</code>, or <code>"growth"</code>).
Only required for <code>runMI()</code>.</p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> or
<code><a href="lavaan.html#topic+lavaanList">lavaan::lavaanList()</a></code>. See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.
Note that <code>lavaanList</code> provides parallel computing options, as well as
a <code>FUN</code> argument so the user can extract custom output after the model
is fitted to each imputed data set (see <strong>Examples</strong>).  TIP: If a
custom <code>FUN</code> is used <em>and</em> <code>parallel = "snow"</code> is requested,
the user-supplied function should explicitly call <code>library</code> or use
<code><a href="base.html#topic++3A+3A">::</a></code> for any functions not part of the base distribution.</p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_m">m</code></td>
<td>
<p><code>integer</code>. Request the number of imputations. Ignored if <code style="white-space: pre;">&#8288;data=&#8288;</code> is
already a <code>list</code> of imputed data sets or an <code>OLDlavaan.mi</code> object.</p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_miargs">miArgs</code></td>
<td>
<p>Addition arguments for the multiple-imputation function
(<code>miPackage</code>). The arguments should be put in a list (see example
below). Ignored if <code style="white-space: pre;">&#8288;data=&#8288;</code> is already a <code>list</code> of imputed data
sets or an <code>OLDlavaan.mi</code> object.</p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_mipackage">miPackage</code></td>
<td>
<p>Package to be used for imputation. Currently these
functions only support <code>"Amelia"</code> or <code>"mice"</code> for imputation.
Ignored if <code>data</code> is already a <code>list</code> of imputed data sets or an
<code>OLDlavaan.mi</code> object.</p>
</td></tr>
<tr><td><code id="runMI-deprecated_+3A_seed">seed</code></td>
<td>
<p><code>integer</code>. Random number seed to be set before imputing the
data. Ignored if <code>data</code> is already a <code>list</code> of imputed data sets
or an <code>OLDlavaan.mi</code> object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="#topic+OLDlavaan.mi-class">OLDlavaan.mi</a> object
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Enders, C. K. (2010). <em>Applied missing data analysis</em>. New
York, NY: Guilford.
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys</em>.
New York, NY: Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>
<p><code><a href="#topic+semTools-deprecated">semTools-deprecated()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## See the new lavaan.mi package

</code></pre>

<hr>
<h2 id='semTools-deprecated'>Deprecated functions in package <span class="pkg">semTools</span>.</h2><span id='topic+semTools-deprecated'></span><span id='topic+efaUnrotate'></span><span id='topic+orthRotate'></span><span id='topic+oblqRotate'></span><span id='topic+funRotate'></span><span id='topic+longInvariance'></span><span id='topic+measurementInvariance'></span><span id='topic+measurementInvarianceCat'></span><span id='topic+reliability'></span><span id='topic+reliabilityL2'></span><span id='topic+lavTestLRT.mi'></span><span id='topic+lavTestWald.mi'></span><span id='topic+modindices.mi'></span><span id='topic+modificationIndices.mi'></span><span id='topic+modificationindices.mi'></span><span id='topic+lavTestScore.mi'></span><span id='topic+runMI'></span><span id='topic+lavaan.mi'></span><span id='topic+cfa.mi'></span><span id='topic+sem.mi'></span><span id='topic+growth.mi'></span><span id='topic+calculate.D2'></span>

<h3>Description</h3>

<p>The functions listed below are deprecated and will be defunct
in the near future. When possible, alternative functions with similar
functionality are also mentioned. Help pages for deprecated functions are
available at <code>help("semTools-deprecated")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>efaUnrotate(data = NULL, nf, varList = NULL, start = TRUE, aux = NULL,
  ...)

orthRotate(object, method = "varimax", ...)

oblqRotate(object, method = "quartimin", ...)

funRotate(object, fun, ...)

longInvariance(model, varList, auto = "all", constrainAuto = FALSE,
  fixed.x = TRUE, std.lv = FALSE, group = NULL, group.equal = "",
  group.partial = "", strict = FALSE, warn = TRUE, debug = FALSE,
  quiet = FALSE, fit.measures = "default", baseline.model = NULL,
  method = "satorra.bentler.2001", ...)

measurementInvariance(..., std.lv = FALSE, strict = FALSE, quiet = FALSE,
  fit.measures = "default", baseline.model = NULL,
  method = "satorra.bentler.2001")

measurementInvarianceCat(..., std.lv = FALSE, strict = FALSE,
  quiet = FALSE, fit.measures = "default", baseline.model = NULL,
  method = "default")

reliability(object, what = c("alpha", "omega", "omega2", "omega3", "ave"),
  return.total = FALSE, dropSingle = TRUE, omit.factors = character(0),
  omit.indicators = character(0), omit.imps = c("no.conv", "no.se"))

reliabilityL2(object, secondFactor, omit.imps = c("no.conv", "no.se"))

lavTestLRT.mi(object, h1 = NULL, test = c("D3", "D2"),
  omit.imps = c("no.conv", "no.se"), asymptotic = FALSE,
  pool.robust = FALSE, ...)

lavTestWald.mi(object, constraints = NULL, test = c("D1", "D2"),
  asymptotic = FALSE, scale.W = !asymptotic, omit.imps = c("no.conv",
  "no.se"), verbose = FALSE, warn = TRUE)

modindices.mi(object, test = c("D2", "D1"), omit.imps = c("no.conv",
  "no.se"), standardized = TRUE, cov.std = TRUE,
  information = "expected", power = FALSE, delta = 0.1, alpha = 0.05,
  high.power = 0.75, sort. = FALSE, minimum.value = 0,
  maximum.number = nrow(LIST), na.remove = TRUE, op = NULL)

modificationIndices.mi(object, test = c("D2", "D1"),
  omit.imps = c("no.conv", "no.se"), standardized = TRUE, cov.std = TRUE,
  information = "expected", power = FALSE, delta = 0.1, alpha = 0.05,
  high.power = 0.75, sort. = FALSE, minimum.value = 0,
  maximum.number = nrow(LIST), na.remove = TRUE, op = NULL)

modificationindices.mi(object, test = c("D2", "D1"),
  omit.imps = c("no.conv", "no.se"), standardized = TRUE, cov.std = TRUE,
  information = "expected", power = FALSE, delta = 0.1, alpha = 0.05,
  high.power = 0.75, sort. = FALSE, minimum.value = 0,
  maximum.number = nrow(LIST), na.remove = TRUE, op = NULL)

lavTestScore.mi(object, add = NULL, release = NULL, test = c("D2", "D1"),
  scale.W = !asymptotic, omit.imps = c("no.conv", "no.se"),
  asymptotic = is.null(add), univariate = TRUE, cumulative = FALSE,
  epc = FALSE, standardized = epc, cov.std = epc, verbose = FALSE,
  warn = TRUE, information = "expected")

runMI(model, data, fun = "lavaan", ..., m, miArgs = list(),
  miPackage = "Amelia", seed = 12345)

lavaan.mi(model, data, ..., m, miArgs = list(), miPackage = "Amelia",
  seed = 12345)

cfa.mi(model, data, ..., m, miArgs = list(), miPackage = "Amelia",
  seed = 12345)

sem.mi(model, data, ..., m, miArgs = list(), miPackage = "Amelia",
  seed = 12345)

growth.mi(model, data, ..., m, miArgs = list(), miPackage = "Amelia",
  seed = 12345)

calculate.D2(w, DF = 0L, asymptotic = FALSE)
</code></pre>


<h3>Support functions for exploratory factor analysis in <code>lavaan</code></h3>

<p>The <code>efaUnrotate</code>, <code>orthRotate</code>, <code>oblqRotate</code>, and
<code>funRotate</code> functions will no longer be supported. These functions
allowed users to estimate EFA parameters with <code>lavaan</code>. Instead, users
can now directly use <code>lavaan</code>'s <code><a href="lavaan.html#topic+efa">efa</a>()</code> function.
Exploratory SEM (ESEM) is also supported by lavaan using special operators
in <code>lavaan</code>'s <code><a href="lavaan.html#topic+model.syntax">model.syntax</a></code>; see
<a href="https://github.com/yrosseel/lavaan/issues/112">https://github.com/yrosseel/lavaan/issues/112</a> for details.
</p>


<h3>Previous measurement-invariance functions</h3>

<p>The <code>measurementInvariance</code>, <code>measurementInvarianceCat</code>, and
<code>longInvariance</code> functions will no longer be supported. Instead, use
the <code><a href="#topic+measEq.syntax">measEq.syntax()</a></code> function, which is much more flexible and
supports a wider range of data (e.g., any mixture of <code>numeric</code> and
<code>ordered</code> indicators, any combination of multiple groups and repeated
measures, models fit to multiple imputations with <code><a href="lavaan.mi.html#topic+lavaan.mi">lavaan.mi::lavaan.mi()</a></code>).
</p>


<h3>Reliability</h3>

<p>The original <code>reliability</code> function was suboptimally designed.
For example, AVE was returned, which is not a reliability index. Also,
alpha and several omega-type coefficients were returned, including the
original formula that was in appropriate for models with complex structure.
Some features could be controlled by the user for one but not both types of
index  For example, alpha for categorical indicators was returned on both
the observed and latent-response scales, but this was not an option for any
omega-type indices.  The omegas differed in terms of whether the observed or
model-implied covariance matrix was used in the denominator, but alpha was
only computed using the observed matrix.  These inconsistencies have been
resolved in the new <code><a href="#topic+compRelSEM">compRelSEM()</a></code> function, which returns only
one reliability index (per factor, optionally total score) according to the
user's requested features, for which there is much more flexibility.
Average variance extracted is now available in a dedicated <code><a href="#topic+AVE">AVE()</a></code>
function.
</p>


<h3>Higher-Order Reliability</h3>

<p>Originally, composite reliability of a single higher-order factor was
estimated in a separate function: <code>reliabilityL2</code>.  It is now available
for multiple higher-order factors in the same model, and from the same
<code><a href="#topic+compRelSEM">compRelSEM()</a></code> function that estimates reliability for first-order
factors, using the <code style="white-space: pre;">&#8288;higher=&#8288;</code> argument to name higher-order factors in
the fitted model.
</p>


<h3><code>runMI()</code> and the <code>lavaan.mi</code> class functionality</h3>

<p>The <code>runMI()</code> function and support for <code>lavaan.mi-class</code> objects became
such a large part of semTools that it made sense to move that functionality
to its own package.  The <span class="pkg">lavaan.mi</span> package is now available for users
to fit <code>lavaan</code> models to their multiply imputed data.  The new package
already fixes many bugs and provides many new features that make the
semTools <code>OLDlavaan.mi-class</code> obsolete.  Please immediately discontinue
your dependence on <code>semTools::runMI()</code> amd transition to the new
<span class="pkg">lavaan.mi</span> package, which also provides a more similar user interface
as the <span class="pkg">lavaan</span> package provides for a single <code style="white-space: pre;">&#8288;data=&#8288;</code> set. The README
on <a href="https://github.com/TDJorgensen/lavaan.mi">https://github.com/TDJorgensen/lavaan.mi</a> provides a list of analogous
functionality in <span class="pkg">lavaan</span> and <span class="pkg">lavaan.mi</span>, and the NEWS file
documents new features and other differences from the deprecated
<code>semTools::runMI()</code> functionality.
</p>

<hr>
<h2 id='simParcel'>Simulated Data set to Demonstrate Random Allocations of Parcels</h2><span id='topic+simParcel'></span>

<h3>Description</h3>

<p>A simulated data set with 2 factors with 9 indicators for each factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simParcel
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 800 observations of 18 variables.
</p>

<dl>
<dt>f1item1</dt><dd><p>Item 1 loading on factor 1</p>
</dd>
<dt>f1item2</dt><dd><p>Item 2 loading on factor 1</p>
</dd>
<dt>f1item3</dt><dd><p>Item 3 loading on factor 1</p>
</dd>
<dt>f1item4</dt><dd><p>Item 4 loading on factor 1</p>
</dd>
<dt>f1item5</dt><dd><p>Item 5 loading on factor 1</p>
</dd>
<dt>f1item6</dt><dd><p>Item 6 loading on factor 1</p>
</dd>
<dt>f1item7</dt><dd><p>Item 7 loading on factor 1</p>
</dd>
<dt>f1item8</dt><dd><p>Item 8 loading on factor 1</p>
</dd>
<dt>f1item9</dt><dd><p>Item 9 loading on factor 1</p>
</dd>
<dt>f2item1</dt><dd><p>Item 1 loading on factor 2</p>
</dd>
<dt>f2item2</dt><dd><p>Item 2 loading on factor 2</p>
</dd>
<dt>f2item3</dt><dd><p>Item 3 loading on factor 2</p>
</dd>
<dt>f2item4</dt><dd><p>Item 4 loading on factor 2</p>
</dd>
<dt>f2item5</dt><dd><p>Item 5 loading on factor 2</p>
</dd>
<dt>f2item6</dt><dd><p>Item 6 loading on factor 2</p>
</dd>
<dt>f2item7</dt><dd><p>Item 7 loading on factor 2</p>
</dd>
<dt>f2item8</dt><dd><p>Item 8 loading on factor 2</p>
</dd>
<dt>f2item9</dt><dd><p>Item 9 loading on factor 2</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data were generated using the <code>simsem</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(simParcel)
</code></pre>

<hr>
<h2 id='singleParamTest'>Single Parameter Test Divided from Nested Model Comparison</h2><span id='topic+singleParamTest'></span>

<h3>Description</h3>

<p>In comparing two nested models, <code class="reqn">\Delta\chi^2</code> test may indicate that
two models are different. However, like other omnibus tests, researchers do
not know which fixed parameters or constraints make these two models
different. This function will help researchers identify the significant
parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>singleParamTest(model1, model2, return.fit = FALSE,
  method = "satorra.bentler.2001")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="singleParamTest_+3A_model1">model1</code></td>
<td>
<p>Model 1.</p>
</td></tr>
<tr><td><code id="singleParamTest_+3A_model2">model2</code></td>
<td>
<p>Model 2. Note that two models must be nested models. Further,
the order of parameters in their parameter tables are the same. That is,
nested models with different scale identifications may not be able to test
by this function.</p>
</td></tr>
<tr><td><code id="singleParamTest_+3A_return.fit">return.fit</code></td>
<td>
<p>Return the submodels fitted by this function</p>
</td></tr>
<tr><td><code id="singleParamTest_+3A_method">method</code></td>
<td>
<p>The method used to calculate likelihood ratio test. See
<code><a href="lavaan.html#topic+lavTestLRT">lavaan::lavTestLRT()</a></code> for available options</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function first identifies the differences between these two models. The
model with more free parameters is referred to as parent model and the model
with fewer free parameters is referred to as nested model. Two tests are
implemented here:
</p>

<ol>
<li> <p><code>free</code>: The nested model is used as a template. Then,
one parameter indicating the differences between two models is freed. The new
model is compared with the nested model. This process is repeated for all
differences between two models.
</p>
</li>
<li><p><code>fix</code>: The parent model is used
as a template. Then, one parameter indicating the differences between two
models is fixed or constrained to be equal to other parameters. The new
model is then compared with the parent model. This process is repeated for
all differences between two models.
</p>
</li>
<li><p><code>mi</code>: No longer available
because the test of modification indices is not consistent. For example, if
two parameters are equality constrained, the modification index from the
first parameter is not equal to the second parameter.
</p>
</li></ol>

<p>Note that this function does not adjust for the inflated Type I error rate
from multiple tests.
</p>


<h3>Value</h3>

<p>If <code>return.fit = FALSE</code>, the result tables are provided.
<code class="reqn">\chi^2</code> and <em>p</em> value are provided for all methods. Note that the
<code class="reqn">\chi^2</code> is all based on 1 <em>df</em>. Expected parameter changes
and their standardized forms are also provided.
</p>
<p>If <code>return.fit = TRUE</code>, a list with two elements are provided. The
first element is the tabular result. The second element is the submodels
used in the <code>free</code> and <code>fix</code> methods.
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(lavaan)

# Nested model comparison by hand
HS.model1 &lt;- ' visual =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6'
HS.model2 &lt;- ' visual =~ a*x1 + a*x2 + a*x3
              textual =~ b*x4 + b*x5 + b*x6'

m1 &lt;- cfa(HS.model1, data = HolzingerSwineford1939, std.lv = TRUE,
          estimator = "MLR")
m2 &lt;- cfa(HS.model2, data = HolzingerSwineford1939, std.lv = TRUE,
          estimator = "MLR")
anova(m1, m2)
singleParamTest(m1, m2)

## Nested model comparison from the measurementInvariance function
HW.model &lt;- ' visual =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed =~ x7 + x8 + x9 '

models &lt;- measurementInvariance(model = HW.model, data = HolzingerSwineford1939,
                                group = "school")
singleParamTest(models[[1]], models[[2]])

## Note that the comparison between metric (Model 2) and scalar invariance
## (Model 3) cannot be done by this function because the metric invariance
## model fixes factor means as 0 in Group 2 but the strong invariance model
## frees the factor means in Group 2. Users may use this function to compare
## scalar invariance (Model 3) to a homogeneous-means model.

</code></pre>

<hr>
<h2 id='skew'>Finding skewness</h2><span id='topic+skew'></span>

<h3>Description</h3>

<p>Finding skewness (<code class="reqn">g_{1}</code>) of an object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skew(object, population = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="skew_+3A_object">object</code></td>
<td>
<p>A vector used to find a skewness</p>
</td></tr>
<tr><td><code id="skew_+3A_population">population</code></td>
<td>
<p><code>TRUE</code> to compute the parameter formula. <code>FALSE</code>
to compute the sample statistic formula.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The skewness computed by default is <code class="reqn">g_{1}</code>, the third standardized
moment of the empirical distribution of <code>object</code>.
The population parameter skewness <code class="reqn">\gamma_{1}</code> formula is
</p>
<p style="text-align: center;"><code class="reqn">\gamma_{1} = \frac{\mu_{3}}{\mu^{3/2}_{2}},</code>
</p>

<p>where <code class="reqn">\mu_{i}</code> denotes the <code class="reqn">i</code> order central moment.
</p>
<p>The skewness formula for sample statistic <code class="reqn">g_{1}</code> is
</p>
<p style="text-align: center;"><code class="reqn">g_{1} = \frac{k_{3}}{k^{2}_{2}},</code>
</p>

<p>where <code class="reqn">k_{i}</code> are the <code class="reqn">i</code> order <em>k</em>-statistic.
</p>
<p>The standard error of the skewness is
</p>
<p style="text-align: center;"><code class="reqn">Var(\hat{g}_1) = \frac{6}{N}</code>
</p>

<p>where <code class="reqn">N</code> is the sample size.
</p>


<h3>Value</h3>

<p>A value of a skewness with a test statistic if the population is
specified as <code>FALSE</code>
</p>


<h3>Author(s)</h3>

<p>Sunthud Pornprasertmanit (<a href="mailto:psunthud@gmail.com">psunthud@gmail.com</a>)
</p>


<h3>References</h3>

<p>Weisstein, Eric W. (n.d.). <em>Skewness</em>. Retrived from
<em>MathWorld</em>&ndash;A Wolfram Web Resource:
<a href="http://mathworld.wolfram.com/Skewness.html">http://mathworld.wolfram.com/Skewness.html</a>
</p>


<h3>See Also</h3>


<ul>
<li> <p><code><a href="#topic+kurtosis">kurtosis()</a></code> Find the univariate excessive kurtosis
of a variable
</p>
</li>
<li> <p><code><a href="#topic+mardiaSkew">mardiaSkew()</a></code> Find Mardia's multivariate skewness
of a set of variables
</p>
</li>
<li> <p><code><a href="#topic+mardiaKurtosis">mardiaKurtosis()</a></code> Find the Mardia's multivariate
kurtosis of a set of variables
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
skew(1:5)

</code></pre>

<hr>
<h2 id='splitSample'>Randomly Split a Data Set into Halves</h2><span id='topic+splitSample'></span>

<h3>Description</h3>

<p>This function randomly splits a data set into two halves, and saves the
resulting data sets to the same folder as the original.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitSample(dataset, path = "default", div = 2, type = "default",
  name = "splitSample")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="splitSample_+3A_dataset">dataset</code></td>
<td>
<p>The original data set to be divided. Can be a file path to a
*.csv or *.dat file (headers will automatically be detected) or an R object
(matrix or dataframe). (Windows users: file path must be specified using
FORWARD SLASHES (<code>/</code>) ONLY.)</p>
</td></tr>
<tr><td><code id="splitSample_+3A_path">path</code></td>
<td>
<p>File path to folder for output data sets. NOT REQUIRED if
dataset is a filename. Specify ONLY if dataset is an R object, or desired
output folder is not that of original data set. If path is specified as
&quot;object&quot;, output data sets will be returned as a list, and not saved to hard
drive.</p>
</td></tr>
<tr><td><code id="splitSample_+3A_div">div</code></td>
<td>
<p>Number of output data sets. NOT REQUIRED if default, 2 halves.</p>
</td></tr>
<tr><td><code id="splitSample_+3A_type">type</code></td>
<td>
<p>Output file format (&quot;dat&quot; or &quot;csv&quot;). NOT REQUIRED unless desired
output formatting differs from that of input, or dataset is an R object and
csv formatting is desired.</p>
</td></tr>
<tr><td><code id="splitSample_+3A_name">name</code></td>
<td>
<p>Output file name. NOT REQUIRED unless desired output name
differs from that of input, or input dataset is an R object. (If input is an
R object and name is not specified, name will be &quot;splitSample&quot;.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function randomly orders the rows of a data set, divides the data set
into two halves, and saves the halves to the same folder as the original
data set, preserving the original formatting. Data set type (*.csv or <em>.dat)
and formatting (headers) are automatically detected, and output data sets
will preserve input type and formatting unless specified otherwise. Input
can be in the form of a file path (</em>.dat or *.csv), or an R object (matrix or
dataframe). If input is an R object and path is default, output data sets
will be returned as a list object.
</p>


<h3>Value</h3>

<p>If <code>path = "object"</code>, <code>list</code> of output data sets.
Otherwise, output will saved to hard drive in the same format as input.
</p>


<h3>Author(s)</h3>

<p>Corbin Quick (University of Michigan; <a href="mailto:corbinq@umich.edu">corbinq@umich.edu</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#### Input is .dat file
#splitSample("C:/Users/Default/Desktop/MYDATA.dat")
#### Output saved to "C:/Users/Default/Desktop/" in .dat format
#### Names are "MYDATA_s1.dat" and "MYDATA_s2.dat"

#### Input is R object
## Split C02 dataset from the datasets package
library(datasets)
splitMyData &lt;- splitSample(CO2, path = "object")
summary(splitMyData[[1]])
summary(splitMyData[[2]])
#### Output object splitMyData becomes list of output data sets

#### Input is .dat file in "C:/" folder
#splitSample("C:/testdata.dat", path = "C:/Users/Default/Desktop/", type = "csv")
#### Output saved to "C:/Users/Default/Desktop/" in *.csv format
#### Names are "testdata_s1.csv" and "testdata_s2.csv"

#### Input is R object
#splitSample(myData, path = "C:/Users/Default/Desktop/", name = "splitdata")
#### Output saved to "C:/Users/Default/Desktop/" in *.dat format
#### Names are "splitdata_s1.dat" and "splitdata_s2.dat"

</code></pre>

<hr>
<h2 id='SSpower'>Power for model parameters</h2><span id='topic+SSpower'></span>

<h3>Description</h3>

<p>Apply Satorra &amp; Saris (1985) method for chi-squared power analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SSpower(powerModel, n, nparam, popModel, mu, Sigma, fun = "sem",
  alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SSpower_+3A_powermodel">powerModel</code></td>
<td>
<p>lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> for the model to
be analyzed. This syntax should constrain at least one nonzero parameter
to 0 (or another number).</p>
</td></tr>
<tr><td><code id="SSpower_+3A_n">n</code></td>
<td>
<p><code>integer</code>. Sample size used in power calculation, or a vector
of sample sizes if analyzing a multigroup model. If
<code>length(n) &lt; length(Sigma)</code> when <code>Sigma</code> is a list, <code>n</code> will
be recycled. If <code>popModel</code> is used instead of <code>Sigma</code>, <code>n</code>
must specify a sample size for each group, because that is used to infer
the number of groups.</p>
</td></tr>
<tr><td><code id="SSpower_+3A_nparam">nparam</code></td>
<td>
<p><code>integer</code>. Number of invalid constraints in <code>powerModel</code>.</p>
</td></tr>
<tr><td><code id="SSpower_+3A_popmodel">popModel</code></td>
<td>
<p>lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> specifying the
data-generating model. This syntax should specify values for all nonzero
parameters in the model. If <code>length(n) &gt; 1</code>, the same population
values will be used for each group, unless different population values are
specified per group, either in the lavaan <code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code>
or by utilizing a list of <code>Sigma</code> (and optionally <code>mu</code>).</p>
</td></tr>
<tr><td><code id="SSpower_+3A_mu">mu</code></td>
<td>
<p><code>numeric</code> or <code>list</code>. For a single-group model, a vector
of population means. For a multigroup model, a list of vectors (one per
group). If <code>mu</code> and <code>popModel</code> are missing, mean structure will
be excluded from the analysis.</p>
</td></tr>
<tr><td><code id="SSpower_+3A_sigma">Sigma</code></td>
<td>
<p><code>matrix</code> or <code>list</code>. For a single-group model,
a population covariance matrix. For a multigroup model, a list of matrices
(one per group). If missing, <code>popModel</code> will be used to generate a
model-implied Sigma.</p>
</td></tr>
<tr><td><code id="SSpower_+3A_fun">fun</code></td>
<td>
<p>character. Name of <code>lavaan</code> function used to fit
<code>powerModel</code> (i.e., <code>"cfa"</code>, <code>"sem"</code>, <code>"growth"</code>, or
<code>"lavaan"</code>).</p>
</td></tr>
<tr><td><code id="SSpower_+3A_alpha">alpha</code></td>
<td>
<p>Type I error rate used to set a criterion for rejecting H0.</p>
</td></tr>
<tr><td><code id="SSpower_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>.
See also <code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Specify all non-zero parameters in a population model, either by using
lavaan syntax (<code>popModel</code>) or by submitting a population covariance
matrix (<code>Sigma</code>) and optional mean vector (<code>mu</code>) implied by the
population model. Then specify an analysis model that places at least
one invalid constraint (note the number in the <code>nparam</code> argument).
</p>
<p>There is also a Shiny app called &quot;power4SEM&quot; that provides a graphical user
interface for this functionality (Jak et al., in press).  It can be accessed
at <a href="https://sjak.shinyapps.io/power4SEM/">https://sjak.shinyapps.io/power4SEM/</a>.
</p>


<h3>Author(s)</h3>

<p>Alexander M. Schoemann (East Carolina University; <a href="mailto:schoemanna@ecu.edu">schoemanna@ecu.edu</a>)
</p>
<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Satorra, A., &amp; Saris, W. E. (1985). Power of the likelihood ratio
test in covariance structure analysis. <em>Psychometrika, 50</em>(1), 83&ndash;90.
<a href="https://doi.org/10.1007/BF02294150">doi:10.1007/BF02294150</a>
</p>
<p>Jak, S., Jorgensen, T. D., Verdam, M. G., Oort, F. J., &amp; Elffers, L.
(2021). Analytical power calculations for structural equation modeling:
A tutorial and Shiny app. <em>Behavior Research Methods, 53</em>, 1385&ndash;1406.
<a href="https://doi.org/10.3758/s13428-020-01479-0">doi:10.3758/s13428-020-01479-0</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Specify population values. Note every parameter has a fixed value.
modelP &lt;- '
  f1 =~ .7*V1 + .7*V2 + .7*V3 + .7*V4
  f2 =~ .7*V5 + .7*V6 + .7*V7 + .7*V8
  f1 ~~ .3*f2
  f1 ~~ 1*f1
  f2 ~~ 1*f2
  V1 ~~ .51*V1
  V2 ~~ .51*V2
  V3 ~~ .51*V3
  V4 ~~ .51*V4
  V5 ~~ .51*V5
  V6 ~~ .51*V6
  V7 ~~ .51*V7
  V8 ~~ .51*V8
'
## Specify analysis model. Note parameter of interest f1~~f2 is fixed to 0.
modelA &lt;- '
  f1 =~ V1 + V2 + V3 + V4
  f2 =~ V5 + V6 + V7 + V8
  f1 ~~ 0*f2
'
## Calculate power
SSpower(powerModel = modelA, popModel = modelP, n = 150, nparam = 1,
        std.lv = TRUE)

## Get power for a range of sample sizes
Ns &lt;- seq(100, 500, 40)
Power &lt;- rep(NA, length(Ns))
for(i in 1:length(Ns)) {
  Power[i] &lt;- SSpower(powerModel = modelA, popModel = modelP,
                      n = Ns[i], nparam = 1, std.lv = TRUE)
}
plot(x = Ns, y = Power, type = "l", xlab = "Sample Size")


## Optionally specify different values for multiple populations

modelP2 &lt;- '
  f1 =~ .7*V1 + .7*V2 + .7*V3 + .7*V4
  f2 =~ .7*V5 + .7*V6 + .7*V7 + .7*V8
  f1 ~~ c(-.3, .3)*f2                  # DIFFERENT ACROSS GROUPS
  f1 ~~ 1*f1
  f2 ~~ 1*f2
  V1 ~~ .51*V1
  V2 ~~ .51*V2
  V3 ~~ .51*V3
  V4 ~~ .51*V4
  V5 ~~ .51*V5
  V6 ~~ .51*V6
  V7 ~~ .51*V7
  V8 ~~ .51*V8
'
modelA2 &lt;- '
  f1 =~ V1 + V2 + V3 + V4
  f2 =~ V5 + V6 + V7 + V8
  f1 ~~ c(psi21, psi21)*f2        # EQUALITY CONSTRAINT ACROSS GROUPS
'
## Calculate power
SSpower(powerModel = modelA2, popModel = modelP2, n = c(100, 100), nparam = 1,
        std.lv = TRUE)
## Get power for a range of sample sizes
Ns2 &lt;- cbind(Group1 = seq(10, 100, 10), Group2 = seq(10, 100, 10))
Power2 &lt;- apply(Ns2, MARGIN = 1, FUN = function(nn) {
  SSpower(powerModel = modelA2, popModel = modelP2, n = nn,
          nparam = 1, std.lv = TRUE)
})
plot(x = rowSums(Ns2), y = Power2, type = "l", xlab = "Total Sample Size",
     ylim = 0:1)
abline(h = c(.8, .9), lty = c("dotted","dashed"))
legend("bottomright", c("80% Power","90% Power"), lty = c("dotted","dashed"))

</code></pre>

<hr>
<h2 id='tukeySEM'>Tukey's WSD post-hoc test of means for unequal variance and sample size</h2><span id='topic+tukeySEM'></span>

<h3>Description</h3>

<p>This function computes Tukey's WSD post hoc test of means when variances and
sample sizes are not equal across groups. It can be used as a post hoc test
when comparing latent means in multiple group SEM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tukeySEM(m1, m2, var1, var2, n1, n2, ng)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tukeySEM_+3A_m1">m1</code></td>
<td>
<p>Mean of group 1.</p>
</td></tr>
<tr><td><code id="tukeySEM_+3A_m2">m2</code></td>
<td>
<p>Mean of group 2.</p>
</td></tr>
<tr><td><code id="tukeySEM_+3A_var1">var1</code></td>
<td>
<p>Variance of group 1.</p>
</td></tr>
<tr><td><code id="tukeySEM_+3A_var2">var2</code></td>
<td>
<p>Variance of group 2.</p>
</td></tr>
<tr><td><code id="tukeySEM_+3A_n1">n1</code></td>
<td>
<p>Sample size of group 1.</p>
</td></tr>
<tr><td><code id="tukeySEM_+3A_n2">n2</code></td>
<td>
<p>Sample size of group 2.</p>
</td></tr>
<tr><td><code id="tukeySEM_+3A_ng">ng</code></td>
<td>
<p>Total number of groups to be compared (i.e., the number of groups
compared in the omnibus test).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After conducting an omnibus test of means across three of more groups,
researchers often wish to know which sets of means differ at a particular
Type I error rate. Tukey's WSD test holds the error rate stable across
multiple comparisons of means. This function implements an adaptation of
Tukey's WSD test from Maxwell &amp; Delaney (2004), that allows variances and
sample sizes to differ across groups.
</p>


<h3>Value</h3>

<p>A vector with three elements:
</p>

<ol>
<li> <p><code>q</code>: The <em>q</em> statistic
</p>
</li>
<li> <p><code>df</code>: The degrees of freedom for the <em>q</em> statistic
</p>
</li>
<li> <p><code>p</code>: A <em>p</em> value based on the <em>q</em> statistic, <em>df</em>,
and the total number of groups to be compared
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Alexander M. Schoemann (East Carolina University;
<a href="mailto:schoemanna@ecu.edu">schoemanna@ecu.edu</a>)
</p>


<h3>References</h3>

<p>Maxwell, S. E., &amp; Delaney, H. D. (2004). <em>Designing
experiments and analyzing data: A model comparison perspective</em> (2nd ed.).
Mahwah, NJ: Lawrence Erlbaum Associates.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## For a case where three groups have been compared:
## Group 1: mean = 3.91, var = 0.46, n = 246
## Group 2: mean = 3.96, var = 0.62, n = 465
## Group 3: mean = 2.94, var = 1.07, n = 64

## compare group 1 and group 2
tukeySEM(3.91, 3.96, 0.46, 0.62, 246, 425, 3)

## compare group 1 and group 3
tukeySEM(3.91, 2.94, 0.46, 1.07, 246, 64, 3)

## compare group 2 and group 3
tukeySEM(3.96, 2.94, 0.62, 1.07, 465, 64, 3)

</code></pre>

<hr>
<h2 id='twostage'>Fit a lavaan model using 2-Stage Maximum Likelihood (TSML) estimation for
missing data.</h2><span id='topic+twostage'></span><span id='topic+cfa.2stage'></span><span id='topic+sem.2stage'></span><span id='topic+growth.2stage'></span><span id='topic+lavaan.2stage'></span>

<h3>Description</h3>

<p>This function automates 2-Stage Maximum Likelihood (TSML) estimation,
optionally with auxiliary variables.  Step 1 involves fitting a saturated
model to the partially observed data set (to variables in the hypothesized
model as well as auxiliary variables related to missingness).  Step 2
involves fitting the hypothesized model to the model-implied means and
covariance matrix (also called the &quot;EM&quot; means and covariance matrix) as if
they were complete data.  Step 3 involves correcting the Step-2 standard
errors (<em>SE</em>s) and chi-squared statistic to account for additional
uncertainty due to missing data (using information from Step 1; see
References section for sources with formulas).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twostage(..., aux, fun, baseline.model = NULL)

lavaan.2stage(..., aux = NULL, baseline.model = NULL)

cfa.2stage(..., aux = NULL, baseline.model = NULL)

sem.2stage(..., aux = NULL, baseline.model = NULL)

growth.2stage(..., aux = NULL, baseline.model = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twostage_+3A_...">...</code></td>
<td>
<p>Arguments passed to the <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> function
specified in the <code>fun</code> argument.  See also
<code><a href="lavaan.html#topic+lavOptions">lavaan::lavOptions()</a></code>.  At a minimum, the user must supply the
first two named arguments to <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code> (i.e.,
<code>model</code> and <code>data</code>).</p>
</td></tr>
<tr><td><code id="twostage_+3A_aux">aux</code></td>
<td>
<p>An optional character vector naming auxiliary variable(s) in
<code>data</code></p>
</td></tr>
<tr><td><code id="twostage_+3A_fun">fun</code></td>
<td>
<p>The character string naming the lavaan function used to fit the
Step-2 hypothesized model (<code>"cfa"</code>, <code>"sem"</code>, <code>"growth"</code>, or
<code>"lavaan"</code>).</p>
</td></tr>
<tr><td><code id="twostage_+3A_baseline.model">baseline.model</code></td>
<td>
<p>An optional character string, specifying the lavaan
<code><a href="lavaan.html#topic+model.syntax">lavaan::model.syntax()</a></code> for a user-specified baseline model.
Interested users can use the fitted baseline model to calculate incremental
fit indices (e.g., CFI and TLI) using the corrected chi-squared values (see
the <code>anova</code> method in <a href="#topic+twostage-class">twostage</a>).  If <code>NULL</code>,
the default &quot;independence model&quot; (i.e., freely estimated means and
variances, but all covariances constrained to zero) will be specified
internally.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All variables (including auxiliary variables) are treated as endogenous
varaibles in the Step-1 saturated model (<code>fixed.x = FALSE</code>), so data
are assumed continuous, although not necessarily multivariate normal
(dummy-coded auxiliary variables may be included in Step 1, but categorical
endogenous variables in the Step-2 hypothesized model are not allowed).  To
avoid assuming multivariate normality, request <code>se = "robust.huber.white"</code>.  CAUTION: In addition to setting <code>fixed.x = FALSE</code> and <code>conditional.x = FALSE</code> in <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>,
this function will automatically set <code>meanstructure = TRUE</code>,
<code>estimator = "ML"</code>, <code>missing = "fiml"</code>, and <code>test = "standard"</code>.  <code><a href="lavaan.html#topic+lavaan">lavaan::lavaan()</a></code>'s <code>se</code> option can only be
set to <code>"standard"</code> to assume multivariate normality or to
<code>"robust.huber.white"</code> to relax that assumption.
</p>


<h3>Value</h3>

<p>The <a href="#topic+twostage-class">twostage</a> object contains 3 fitted lavaan
models (saturated, target/hypothesized, and baseline) as well as the names
of auxiliary variables.  None of the individual models provide the correct
model results (except the point estimates in the target model are unbiased).
Use the methods in <a href="#topic+twostage-class">twostage</a> to extract corrected
<em>SE</em>s and test statistics.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam; <a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>References</h3>

<p>Savalei, V., &amp; Bentler, P. M. (2009). A two-stage approach to missing data:
Theory and application to auxiliary variables.
<em>Structural Equation Modeling, 16</em>(3), 477&ndash;497.
<a href="https://doi.org/10.1080/10705510903008238">doi:10.1080/10705510903008238</a>
</p>
<p>Savalei, V., &amp; Falk, C. F. (2014). Robust two-stage approach outperforms
robust full information maximum likelihood with incomplete nonnormal data.
<em>Structural Equation Modeling, 21</em>(2), 280&ndash;302.
<a href="https://doi.org/10.1080/10705511.2014.882692">doi:10.1080/10705511.2014.882692</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+twostage-class">twostage</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## impose missing data for example
HSMiss &lt;- HolzingerSwineford1939[ , c(paste("x", 1:9, sep = ""),
                                      "ageyr","agemo","school")]
set.seed(12345)
HSMiss$x5 &lt;- ifelse(HSMiss$x5 &lt;= quantile(HSMiss$x5, .3), NA, HSMiss$x5)
age &lt;- HSMiss$ageyr + HSMiss$agemo/12
HSMiss$x9 &lt;- ifelse(age &lt;= quantile(age, .3), NA, HSMiss$x9)

## specify CFA model from lavaan's ?cfa help page
HS.model &lt;- '
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  speed   =~ x7 + x8 + x9
'

## use ageyr and agemo as auxiliary variables
out &lt;- cfa.2stage(model = HS.model, data = HSMiss, aux = c("ageyr","agemo"))

## two versions of a corrected chi-squared test results are shown
out
## see Savalei &amp; Bentler (2009) and Savalei &amp; Falk (2014) for details

## the summary additionally provides the parameter estimates with corrected
## standard errors, test statistics, and confidence intervals, along with
## any other options that can be passed to parameterEstimates()
summary(out, standardized = TRUE)



## use parameter labels to fit a more constrained model
modc &lt;- '
  visual  =~ x1 + x2 + x3
  textual =~ x4 + x5 + x6
  speed   =~ x7 + a*x8 + a*x9
'
outc &lt;- cfa.2stage(model = modc, data = HSMiss, aux = c("ageyr","agemo"))


## use the anova() method to test this constraint
anova(out, outc)
## like for a single model, two corrected statistics are provided

</code></pre>

<hr>
<h2 id='twostage-class'>Class for the Results of 2-Stage Maximum Likelihood (TSML) Estimation for
Missing Data</h2><span id='topic+twostage-class'></span><span id='topic+show+2Ctwostage-method'></span><span id='topic+summary+2Ctwostage-method'></span><span id='topic+anova+2Ctwostage-method'></span><span id='topic+vcov+2Ctwostage-method'></span><span id='topic+coef+2Ctwostage-method'></span><span id='topic+fitted.values+2Ctwostage-method'></span><span id='topic+fitted+2Ctwostage-method'></span><span id='topic+residuals+2Ctwostage-method'></span><span id='topic+resid+2Ctwostage-method'></span><span id='topic+nobs+2Ctwostage-method'></span>

<h3>Description</h3>

<p>This class contains the results of 2-Stage Maximum Likelihood (TSML)
estimation for missing data.  The <code>summary</code>, <code>anova</code>, <code>vcov</code>
methods return corrected <em>SE</em>s and test statistics.  Other methods are
simply wrappers around the corresponding <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a>
methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'twostage'
show(object)

## S4 method for signature 'twostage'
summary(object, ...)

## S4 method for signature 'twostage'
anova(object, h1 = NULL, baseline = FALSE)

## S4 method for signature 'twostage'
nobs(object, type = c("ntotal", "ngroups",
  "n.per.group", "norig", "patterns", "coverage"))

## S4 method for signature 'twostage'
coef(object, type = c("free", "user"))

## S4 method for signature 'twostage'
vcov(object, baseline = FALSE)

## S4 method for signature 'twostage'
fitted.values(object, model = c("target", "saturated",
  "baseline"), type = "moments", labels = TRUE)

## S4 method for signature 'twostage'
fitted(object, model = c("target", "saturated",
  "baseline"), type = "moments", labels = TRUE)

## S4 method for signature 'twostage'
residuals(object, type = c("raw", "cor", "normalized",
  "standardized"))

## S4 method for signature 'twostage'
resid(object, type = c("raw", "cor", "normalized",
  "standardized"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twostage-class_+3A_object">object</code></td>
<td>
<p>An object of class <code>twostage</code>.</p>
</td></tr>
<tr><td><code id="twostage-class_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="lavaan.html#topic+parameterEstimates">lavaan::parameterEstimates()</a></code>.</p>
</td></tr>
<tr><td><code id="twostage-class_+3A_h1">h1</code></td>
<td>
<p>An object of class <code>twostage</code> in which <code>object</code> is
nested, so that their difference in fit can be tested using
<code>anova</code> (see <strong>Value</strong> section for details).</p>
</td></tr>
<tr><td><code id="twostage-class_+3A_baseline">baseline</code></td>
<td>
<p><code>logical</code> indicating whether to return results for the
baseline model, rather than the default target (hypothesized) model.</p>
</td></tr>
<tr><td><code id="twostage-class_+3A_type">type</code></td>
<td>
<p>The meaning of this argument varies depending on which method it
it used for. Find detailed descriptions in the <strong>Value</strong> section
under <code>coef</code>, <code>nobs</code>, and <code>residuals</code>.</p>
</td></tr>
<tr><td><code id="twostage-class_+3A_model">model</code></td>
<td>
<p><code>character</code> naming the slot for which to return the
model-implied sample moments (see <code>fitted.values</code> description.)</p>
</td></tr>
<tr><td><code id="twostage-class_+3A_labels">labels</code></td>
<td>
<p><code>logical</code> indicating whether the model-implied sample
moments should have (row/column) labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>show</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage"):&#8288;</code> The <code>show</code> function
is used to display the results of the <code>anova</code> method, as well as the
header of the (uncorrected) target model results.</p>
</td></tr>
<tr><td><code>summary</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", ...):&#8288;</code> The summary
function prints the same information from the <code>show</code> method, but also
provides (and returns) the output of
<code>parameterEstimates(object@target, ...)</code> with corrected
<em>SE</em>s, test statistics, and confidence intervals.  Additional
arguments can be passed to <code><a href="lavaan.html#topic+parameterEstimates">lavaan::parameterEstimates()</a></code>,
including <code>fmi = TRUE</code> to provide an estimate of the fraction of
missing information.</p>
</td></tr>
<tr><td><code>anova</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", h1 = NULL, baseline = FALSE):&#8288;</code>
The <code>anova</code> function returns the residual-based <code class="reqn">\chi^2</code> test
statistic result, as well as the scaled <code class="reqn">\chi^2</code> test statistic result,
for the model in the <code>target</code> slot, or for the model in the
<code>baseline</code> slot if <code>baseline = TRUE</code>.  The user can also provide
a single additional <code>twostage</code> object to the <code>h1</code> argument, in
which case <code>anova</code> returns residual-based and scaled
(<code class="reqn">\Delta</code>)<code class="reqn">\chi^2</code> test results, under the assumption that the
models are nested.  The models will be automatically sorted according their
degrees of freedom.</p>
</td></tr>
<tr><td><code>nobs</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", type = c("ntotal", "ngroups", "n.per.group", "norig", "patterns", "coverage")):&#8288;</code>
The <code>nobs</code> function will return the total sample sized used in the
analysis by default.  Also available are the number of groups or the sample
size per group, the original sample size (if any rows were deleted because
all variables were missing), the missing data patterns, and the matrix of
coverage (diagonal is the proportion of sample observed on each variable,
and off-diagonal is the proportion observed for both of each pair of
variables).</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", type = c("free", "user")):&#8288;</code>
This is simply a wrapper around the corresponding
<a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> method, providing point estimates from the
<code>target</code> slot.</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", baseline = FALSE):&#8288;</code> Returns
the asymptotic covariance matrix of the estimated parameters (corrected for
additional uncertainty due to missing data) for the model in the
<code>target</code> slot, or for the model in the <code>baseline</code> slot if
<code>baseline = TRUE</code>.</p>
</td></tr>
<tr><td><code>fitted.values</code>, <code>fitted</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", model = c("target", "saturated", "baseline")):&#8288;</code> This is simply a wrapper
around the corresponding <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> method, providing
model-implied sample moments from the slot specified in the <code>model</code>
argument.</p>
</td></tr>
<tr><td><code>residuals</code>, <code>resid</code></td>
<td>
<p><code style="white-space: pre;">&#8288;signature(object = "twostage", type = c("raw", "cor", "normalized", "standardized")):&#8288;</code> This is simply a wrapper around the
corresponding <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> method, providing residuals of
the specified <code>type</code> from the <code>target</code> slot.</p>
</td></tr>
</table>


<h3>Slots</h3>


<dl>
<dt><code>saturated</code></dt><dd><p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> object containing the
saturated model results</p>
</dd>
<dt><code>target</code></dt><dd><p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> object containing the
target/hypothesized model results</p>
</dd>
<dt><code>baseline</code></dt><dd><p>A fitted <a href="lavaan.html#topic+lavaan-class">lavaan::lavaan</a> object containing the
baseline/null model results</p>
</dd>
<dt><code>auxNames</code></dt><dd><p>A character string (potentially of <code>length == 0</code>) of any
auxiliary variable names, if used</p>
</dd>
</dl>


<h3>Objects from the Class</h3>

<p>Objects can be created via the
<code><a href="#topic+twostage">twostage()</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Terrence D. Jorgensen (University of Amsterdam;
<a href="mailto:TJorgensen314@gmail.com">TJorgensen314@gmail.com</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+twostage">twostage()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See the example from the twostage function

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
