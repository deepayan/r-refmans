<!DOCTYPE html><html><head><title>Help for package sClust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sClust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checking.gram.similarityMatrix'><p>Gram similarity matrix checker</p></a></li>
<li><a href='#compute.kclust'><p>Gram similarity matrix checker</p></a></li>
<li><a href='#compute.kclust2'><p>K clust compute selection V2</p></a></li>
<li><a href='#compute.laplacian.NJW'><p>Gram similarity matrix checker</p></a></li>
<li><a href='#compute.nbCluster.gap'><p>Recherche du nb de cluster par selon le critere du gap</p></a></li>
<li><a href='#compute.similarity.gaussien'><p>Calcule matrice de similarite gaussienn</p></a></li>
<li><a href='#compute.similarity.ZP'><p>Calcule matrice de similarite gaussienne selon Zelnik-Manor et Perona</p></a></li>
<li><a href='#fastClustering'><p>Fast Spectral Clustering</p></a></li>
<li><a href='#fastMSC'><p>Fast Multi-Level Spectral Clustering</p></a></li>
<li><a href='#HierarchicalClust'><p>Hierarchical Clustering</p></a></li>
<li><a href='#HierarchicalSC'><p>Hierarchical Spectral Clustering</p></a></li>
<li><a href='#kmeansQuantization'><p>Data quantization</p></a></li>
<li><a href='#MSC'><p>Multi-Level Spectral Clustering</p></a></li>
<li><a href='#PeronaFreemanSC'><p>Bi-parted Spectral Clustering. Peronna and Freeman.</p></a></li>
<li><a href='#recursClust'><p>Perform a multi level clustering</p></a></li>
<li><a href='#search.neighboor'><p>Recherche du voisin num id le plus proche</p></a></li>
<li><a href='#ShiMalikSC'><p>Bi-parted Spectral Clustering. Shi and Malik.</p></a></li>
<li><a href='#spectralPAM'><p>Spectral-PAM clustering</p></a></li>
<li><a href='#UnormalizedSC'><p>Unormalized Spectral Clustering Ng.</p></a></li>
<li><a href='#VonLuxburgSC'><p>Spectral Clustering based on the Von Luxburg algorithm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>R Toolbox for Unsupervised Spectral Clustering</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-08-20</td>
</tr>
<tr>
<td>Author:</td>
<td>Emilie Poisson-Caillault [aut, cre, cph],
  Alain Lefebvre [ctb],
  Erwan Vincent [aut],
  Pierre-Alexandre Hebert [ctb]</td>
</tr>
<tr>
<td>Description:</td>
<td>Toolbox containing a variety of spectral clustering tools functions. Among the tools available are the hierarchical spectral clustering algorithm, the Shi and Malik clustering algorithm, the Perona and Freeman algorithm, the non-normalized clustering, the Von Luxburg algorithm, the Partition Around Medoids clustering algorithm, a multi-level clustering algorithm, recursive clustering and the fast method for all clustering algorithm. As well as other tools needed to run these algorithms or useful for unsupervised spectral clustering. This toolbox aims to gather the main tools for unsupervised spectral classification. See <a href="http://mawenzi.univ-littoral.fr/">http://mawenzi.univ-littoral.fr/</a> for more information and documentation. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cluster, stats, grDevices, class</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-08-20 12:50:28 UTC; erwan</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Emilie Poisson-Caillault &lt;emilie.caillault@univ-littoral.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-08-23 18:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='checking.gram.similarityMatrix'>Gram similarity matrix checker</h2><span id='topic+checking.gram.similarityMatrix'></span>

<h3>Description</h3>

<p>Function to check if a similarity matrix is Gram or not
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checking.gram.similarityMatrix(W, flagDiagZero = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checking.gram.similarityMatrix_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix or not.</p>
</td></tr>
<tr><td><code id="checking.gram.similarityMatrix_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="checking.gram.similarityMatrix_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a Gram similarity matrix
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
W &lt;- checking.gram.similarityMatrix(W)

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(cars))
W &lt;- checking.gram.similarityMatrix(W)
</code></pre>

<hr>
<h2 id='compute.kclust'>Gram similarity matrix checker</h2><span id='topic+compute.kclust'></span>

<h3>Description</h3>

<p>Function which select the number of cluster to compute thanks to a selected method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.kclust(
  eigenValues,
  method = "default",
  Kmax = 20,
  tolerence = 1,
  threshold = 0.9,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.kclust_+3A_eigenvalues">eigenValues</code></td>
<td>
<p>The eigenvalues of the laplacian matrix.</p>
</td></tr>
<tr><td><code id="compute.kclust_+3A_method">method</code></td>
<td>
<p>The method that will be used. &quot;default&quot; to let the function choose the most suitable method. &quot;PEV&quot; for the Principal EigenValue method. &quot;GAP&quot; for the GAP method.</p>
</td></tr>
<tr><td><code id="compute.kclust_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of cluster which is allowed.</p>
</td></tr>
<tr><td><code id="compute.kclust_+3A_tolerence">tolerence</code></td>
<td>
<p>The tolerance allowed for the Principal EigenValue method.</p>
</td></tr>
<tr><td><code id="compute.kclust_+3A_threshold">threshold</code></td>
<td>
<p>The threshold to select the dominant eigenvalue for the GAP method.</p>
</td></tr>
<tr><td><code id="compute.kclust_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector which contain the number of cluster to compute.
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
W &lt;- checking.gram.similarityMatrix(W)
eigVal &lt;- compute.laplacian.NJW(W,verbose = TRUE)$eigen$values
K &lt;- compute.kclust(eigVal, method="default", Kmax=20, tolerence=0.99, threshold=0.9, verbose=TRUE)

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(cars))
W &lt;- checking.gram.similarityMatrix(W)
eigVal &lt;- compute.laplacian.NJW(W,verbose = TRUE)$eigen$values
K &lt;- compute.kclust(eigVal, method="default", Kmax=20, tolerence=0.99, threshold=0.9, verbose=TRUE)
</code></pre>

<hr>
<h2 id='compute.kclust2'>K clust compute selection V2</h2><span id='topic+compute.kclust2'></span>

<h3>Description</h3>

<p>Function which select the number of cluster to compute thanks to a selected method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.kclust2(
  eigenValues,
  method = "default",
  Kmax = 20,
  tolerence = 1,
  threshold = 0.9,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.kclust2_+3A_eigenvalues">eigenValues</code></td>
<td>
<p>The eigenvalues of the laplacian matrix.</p>
</td></tr>
<tr><td><code id="compute.kclust2_+3A_method">method</code></td>
<td>
<p>The method that will be used. &quot;default&quot; to let the function choose the most suitable method. &quot;PEV&quot; for the Principal EigenValue method. &quot;GAP&quot; for the GAP method.</p>
</td></tr>
<tr><td><code id="compute.kclust2_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of cluster which is allowed.</p>
</td></tr>
<tr><td><code id="compute.kclust2_+3A_tolerence">tolerence</code></td>
<td>
<p>The tolerance allowed for the Principal EigenValue method.</p>
</td></tr>
<tr><td><code id="compute.kclust2_+3A_threshold">threshold</code></td>
<td>
<p>The threshold to select the dominant eigenvalue for the GAP method.</p>
</td></tr>
<tr><td><code id="compute.kclust2_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector which contain the number of cluster to compute.
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>

<hr>
<h2 id='compute.laplacian.NJW'>Gram similarity matrix checker</h2><span id='topic+compute.laplacian.NJW'></span>

<h3>Description</h3>

<p>Function which select the number of cluster to compute thanks to a selected method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.laplacian.NJW(W, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.laplacian.NJW_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="compute.laplacian.NJW_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>Lsym: a NJW laplacian matrix
</p>
</li>
<li><p>eigen: a list that contain the eigenvectors ans eigenvalues
</p>
</li>
<li><p>diag: a diagonal matrix used for the laplacian matrix
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
W &lt;- checking.gram.similarityMatrix(W)
res &lt;- compute.laplacian.NJW(W,verbose = TRUE)

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(cars))
W &lt;- checking.gram.similarityMatrix(W)
res &lt;- compute.laplacian.NJW(W,verbose = TRUE)
</code></pre>

<hr>
<h2 id='compute.nbCluster.gap'>Recherche du nb de cluster par selon le critere du gap</h2><span id='topic+compute.nbCluster.gap'></span>

<h3>Description</h3>

<p>Recherche du nb de cluster par selon le critere du gap
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.nbCluster.gap(val, seuil = 0, fig = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.nbCluster.gap_+3A_val">val</code></td>
<td>
<p>#valeur propre d'une matrice de similarite</p>
</td></tr>
<tr><td><code id="compute.nbCluster.gap_+3A_seuil">seuil</code></td>
<td>
<p>seuil</p>
</td></tr>
<tr><td><code id="compute.nbCluster.gap_+3A_fig">fig</code></td>
<td>
<p>booleen</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Kli
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault v13/10/2015
</p>

<hr>
<h2 id='compute.similarity.gaussien'>Calcule matrice de similarite gaussienn</h2><span id='topic+compute.similarity.gaussien'></span>

<h3>Description</h3>

<p>Calcule matrice de similarite gaussienn
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.similarity.gaussien(points, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.similarity.gaussien_+3A_points">points</code></td>
<td>
<p>matrice pointsxattributs</p>
</td></tr>
<tr><td><code id="compute.similarity.gaussien_+3A_sigma">sigma</code></td>
<td>
<p>sigma</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mat
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault v13/10/2015
</p>

<hr>
<h2 id='compute.similarity.ZP'>Calcule matrice de similarite gaussienne selon Zelnik-Manor et Perona</h2><span id='topic+compute.similarity.ZP'></span>

<h3>Description</h3>

<p>sigma local, attention risque matrice non semi-def positive
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute.similarity.ZP(points, vois = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute.similarity.ZP_+3A_points">points</code></td>
<td>
<p>matrice pointsxattributs</p>
</td></tr>
<tr><td><code id="compute.similarity.ZP_+3A_vois">vois</code></td>
<td>
<p>nombre de voisin qui seront selectionnes</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mat
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault v13/10/2015
</p>

<hr>
<h2 id='fastClustering'>Fast Spectral Clustering</h2><span id='topic+fastClustering'></span>

<h3>Description</h3>

<p>This function will sample the data before performing a classification function on the samples and then applying K nearest neighbours.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastClustering(
  dataFrame,
  smplPoint,
  stopCriteria = 0.99,
  neighbours = 7,
  similarity = TRUE,
  clustFunction,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastClustering_+3A_dataframe">dataFrame</code></td>
<td>
<p>The dataFrame.</p>
</td></tr>
<tr><td><code id="fastClustering_+3A_smplpoint">smplPoint</code></td>
<td>
<p>maximum of sample number for reduction.</p>
</td></tr>
<tr><td><code id="fastClustering_+3A_stopcriteria">stopCriteria</code></td>
<td>
<p>criterion for minimizing intra-group distance and select final smplPoint.</p>
</td></tr>
<tr><td><code id="fastClustering_+3A_neighbours">neighbours</code></td>
<td>
<p>number of points that will be selected for the similarity computation.</p>
</td></tr>
<tr><td><code id="fastClustering_+3A_similarity">similarity</code></td>
<td>
<p>if True, will use the similarity matrix for the clustering function.</p>
</td></tr>
<tr><td><code id="fastClustering_+3A_clustfunction">clustFunction</code></td>
<td>
<p>the clustering function to apply on data.</p>
</td></tr>
<tr><td><code id="fastClustering_+3A_...">...</code></td>
<td>
<p>additional arguments for the clustering function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>results: clustering results
</p>
</li>
<li><p>sample: dataframe containing the sample used
</p>
</li>
<li><p>quantLabels: quantization labels
</p>
</li>
<li><p>clustLabels: results labels
</p>
</li>
<li><p>kmeans: kmeans quantization results
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
res &lt;- fastClustering(scale(sameTwoDisks),smplPoint = 500, 
                      stopCriteria = 0.99, neighbours = 7, similarity = TRUE,
                      clustFunction = UnormalizedSC, K = 2)
plot(sameTwoDisks, col = as.factor(res$clustLabels))

### Example 2: Speed and Stopping Distances of Cars
res &lt;- fastClustering(scale(iris[,-5]),smplPoint = 500, 
                      stopCriteria = 0.99, neighbours = 7, similarity = TRUE,
                      clustFunction = spectralPAM, K = 3)
plot(iris, col = as.factor(res$clustLabels))
table(res$clustLabels,iris$Species)
</code></pre>

<hr>
<h2 id='fastMSC'>Fast Multi-Level Spectral Clustering</h2><span id='topic+fastMSC'></span>

<h3>Description</h3>

<p>The function, for a given dataFrame, will separate the data using the Fast NJW clustering in several levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fastMSC(
  X,
  levelMax,
  silMin = 0.7,
  vois = 7,
  flagDiagZero = FALSE,
  method = "default",
  Kmax = 20,
  tolerence = 0.99,
  threshold = 0.7,
  minPoint = 7,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fastMSC_+3A_x">X</code></td>
<td>
<p>The dataFrame.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_levelmax">levelMax</code></td>
<td>
<p>The maximum depth level.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_silmin">silMin</code></td>
<td>
<p>The minimal silhouette allowed. Below this value, the cluster will be cut again.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_vois">vois</code></td>
<td>
<p>number of points that will be selected for the similarity computation.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_method">method</code></td>
<td>
<p>The method that will be used. &quot;default&quot; to let the function choose the most suitable method. &quot;PEV&quot; for the Principal EigenValue method. &quot;GAP&quot; for the GAP method.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of cluster which is allowed.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_tolerence">tolerence</code></td>
<td>
<p>The tolerance allowed for the Principal EigenValue method.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_threshold">threshold</code></td>
<td>
<p>The threshold to select the dominant eigenvalue for the GAP method.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_minpoint">minPoint</code></td>
<td>
<p>The minimum number of points required to compute a cluster.</p>
</td></tr>
<tr><td><code id="fastMSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a dataframe containing the results labels of each levels
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
res &lt;- fastMSC(scale(sameTwoDisks),levelMax=5, silMin=0.7, vois=7, 
           flagDiagZero=TRUE, method = "PEV", Kmax = 20, 
           tolerence = 0.99,threshold = 0.7, minPoint = 7, verbose = TRUE)
plot(sameTwoDisks, col = as.factor(res[,ncol(res)]))

### Example 2: Speed and Stopping Distances of Cars
res &lt;- fastMSC(scale(iris[,-5]),levelMax=5, silMin=0.7, vois=7, 
           flagDiagZero=TRUE, method = "PEV", Kmax = 20, 
           tolerence = 0.99,threshold = 0.9, minPoint = 7, verbose = TRUE)
plot(iris, col = as.factor(res[,ncol(res)]))
table(res[,ncol(res)],iris$Species)
</code></pre>

<hr>
<h2 id='HierarchicalClust'>Hierarchical Clustering</h2><span id='topic+HierarchicalClust'></span>

<h3>Description</h3>

<p>Hierarchical Clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HierarchicalClust(
  W,
  K = 5,
  method = "ward.D2",
  flagDiagZero = FALSE,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HierarchicalClust_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="HierarchicalClust_+3A_k">K</code></td>
<td>
<p>number of cluster to obtain.</p>
</td></tr>
<tr><td><code id="HierarchicalClust_+3A_method">method</code></td>
<td>
<p>method that will be used in the hierarchical clustering.</p>
</td></tr>
<tr><td><code id="HierarchicalClust_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="HierarchicalClust_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
<tr><td><code id="HierarchicalClust_+3A_...">...</code></td>
<td>
<p>Additional parameter for the hclust function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- HierarchicalClust(W,K=2,method="ward.D2",flagDiagZero=TRUE,verbose=TRUE)
plot(sameTwoDisks, col = res$cluster)

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[,-5]))
res &lt;- HierarchicalClust(W,K=2,method="ward.D2",flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
</code></pre>

<hr>
<h2 id='HierarchicalSC'>Hierarchical Spectral Clustering</h2><span id='topic+HierarchicalSC'></span>

<h3>Description</h3>

<p>Hierarchical Spectral Clustering
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HierarchicalSC(
  W,
  K = 5,
  method = "ward.D2",
  flagDiagZero = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HierarchicalSC_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="HierarchicalSC_+3A_k">K</code></td>
<td>
<p>number of cluster to obtain.</p>
</td></tr>
<tr><td><code id="HierarchicalSC_+3A_method">method</code></td>
<td>
<p>method that will be used in the hierarchical clustering.</p>
</td></tr>
<tr><td><code id="HierarchicalSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="HierarchicalSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>References</h3>

<p>Sanchez-Garcia, R., Fernnelly, M. and al. (2014). Hierarchical Spectral Clustering of Power Grids. In IEEE Transaction on Power Systems 29.5, pages 2229-2237. ISSN : 0885-8950.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- HierarchicalSC(W,K=2,method = "ward.D2",flagDiagZero=TRUE,verbose=TRUE)
plot(sameTwoDisks, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[,-5]))
res &lt;- HierarchicalSC(W,K=2,method="ward.D2",flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
</code></pre>

<hr>
<h2 id='kmeansQuantization'>Data quantization</h2><span id='topic+kmeansQuantization'></span>

<h3>Description</h3>

<p>The function use kmeans algorithm to perform data quantization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kmeansQuantization(dataFrame, maxData, stopCriteria = 0.99)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kmeansQuantization_+3A_dataframe">dataFrame</code></td>
<td>
<p>The dataFrame.</p>
</td></tr>
<tr><td><code id="kmeansQuantization_+3A_maxdata">maxData</code></td>
<td>
<p>maximum of sample number for reduction.</p>
</td></tr>
<tr><td><code id="kmeansQuantization_+3A_stopcriteria">stopCriteria</code></td>
<td>
<p>criterion for minimizing intra-group distance and select final smplPoint.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>kmeans result
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>

<hr>
<h2 id='MSC'>Multi-Level Spectral Clustering</h2><span id='topic+MSC'></span>

<h3>Description</h3>

<p>The function, for a given dataFrame, will separate the data using the NJW clustering in several levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MSC(
  X,
  levelMax,
  silMin = 0.7,
  vois = 7,
  flagDiagZero = FALSE,
  method = "default",
  Kmax = 20,
  tolerence = 0.99,
  threshold = 0.7,
  minPoint = 7,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MSC_+3A_x">X</code></td>
<td>
<p>The dataFrame.</p>
</td></tr>
<tr><td><code id="MSC_+3A_levelmax">levelMax</code></td>
<td>
<p>The maximum depth level.</p>
</td></tr>
<tr><td><code id="MSC_+3A_silmin">silMin</code></td>
<td>
<p>The minimal silhouette allowed. Below this value, the cluster will be cut again.</p>
</td></tr>
<tr><td><code id="MSC_+3A_vois">vois</code></td>
<td>
<p>number of points that will be selected for the similarity computation.</p>
</td></tr>
<tr><td><code id="MSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="MSC_+3A_method">method</code></td>
<td>
<p>The method that will be used. &quot;default&quot; to let the function choose the most suitable method. &quot;PEV&quot; for the Principal EigenValue method. &quot;GAP&quot; for the GAP method.</p>
</td></tr>
<tr><td><code id="MSC_+3A_kmax">Kmax</code></td>
<td>
<p>The maximum number of cluster which is allowed.</p>
</td></tr>
<tr><td><code id="MSC_+3A_tolerence">tolerence</code></td>
<td>
<p>The tolerance allowed for the Principal EigenValue method.</p>
</td></tr>
<tr><td><code id="MSC_+3A_threshold">threshold</code></td>
<td>
<p>The threshold to select the dominant eigenvalue for the GAP method.</p>
</td></tr>
<tr><td><code id="MSC_+3A_minpoint">minPoint</code></td>
<td>
<p>The minimum number of points required to compute a cluster.</p>
</td></tr>
<tr><td><code id="MSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>References</h3>

<p>Grassi, K. (2020) Definition multivariee et multi-echelle d'etats environnementaux par Machine Learning : Caracterisation de la dynamique phytoplanctonique.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
res &lt;- MSC(scale(sameTwoDisks),levelMax=5, silMin=0.7, vois=7, 
           flagDiagZero=TRUE, method = "default", Kmax = 20, 
           tolerence = 0.99,threshold = 0.7, minPoint = 7, verbose = TRUE)
plot(sameTwoDisks, col = as.factor(res[,ncol(res)]))

### Example 2: Speed and Stopping Distances of Cars
res &lt;- MSC(scale(iris[,-5]),levelMax=5, silMin=0.7, vois=7, 
           flagDiagZero=TRUE, method = "default", Kmax = 20, 
           tolerence = 0.99,threshold = 0.9, minPoint = 7, verbose = TRUE)
plot(iris, col = as.factor(res[,ncol(res)]))
table(res[,ncol(res)],iris$Species)
</code></pre>

<hr>
<h2 id='PeronaFreemanSC'>Bi-parted Spectral Clustering. Peronna and Freeman.</h2><span id='topic+PeronaFreemanSC'></span>

<h3>Description</h3>

<p>Bi-parted spectral clustering based on Peronna and Freeman algorithm, which separates the data into two distinct clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PeronaFreemanSC(W, flagDiagZero = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PeronaFreemanSC_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="PeronaFreemanSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="PeronaFreemanSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>References</h3>

<p>Perona, P. and Freeman, W. (1998). A factorization approach to grouping. In European Conference on Computer Vision, pages 655-670
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- PeronaFreemanSC(W,flagDiagZero=TRUE,verbose=TRUE)
plot(sameTwoDisks, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[,-5]))
res &lt;- PeronaFreemanSC(W,flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
</code></pre>

<hr>
<h2 id='recursClust'>Perform a multi level clustering</h2><span id='topic+recursClust'></span>

<h3>Description</h3>

<p>The function, for a given dataFrame, will separate the data using the input clustering method in several levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recursClust(
  dataFrame,
  levelMax = 2,
  clustFunction,
  similarity = TRUE,
  vois = 7,
  flagDiagZero = FALSE,
  biparted = FALSE,
  method = "default",
  tolerence = 0.99,
  threshold = 0.9,
  minPoint = 7,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recursClust_+3A_dataframe">dataFrame</code></td>
<td>
<p>The dataFrame.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_levelmax">levelMax</code></td>
<td>
<p>The maximum depth level.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_clustfunction">clustFunction</code></td>
<td>
<p>the clustering function to apply on data.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_similarity">similarity</code></td>
<td>
<p>if True, will use the similarity matrix for the clustering function.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_vois">vois</code></td>
<td>
<p>number of points that will be selected for the similarity computation.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_biparted">biparted</code></td>
<td>
<p>if True, the function will not automatically choose the number of clusters to compute.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_method">method</code></td>
<td>
<p>The method that will be used. &quot;default&quot; to let the function choose the most suitable method. &quot;PEV&quot; for the Principal EigenValue method. &quot;GAP&quot; for the GAP method.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_tolerence">tolerence</code></td>
<td>
<p>The tolerance allowed for the Principal EigenValue method.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_threshold">threshold</code></td>
<td>
<p>The threshold to select the dominant eigenvalue for the GAP method.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_minpoint">minPoint</code></td>
<td>
<p>The minimum number of points required to compute a cluster.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
<tr><td><code id="recursClust_+3A_...">...</code></td>
<td>
<p>additional arguments for the clustering function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: vector that contain the result of the last level
</p>
</li>
<li><p>allLevels: dataframe containing the clustering results of each levels
</p>
</li>
<li><p>nbLevels: the number of computed levels
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
res &lt;- recursClust(scale(sameTwoDisks),levelMax=3, clustFunction =ShiMalikSC,
                   similarity = TRUE, vois = 7, flagDiagZero = FALSE,
                   biparted = TRUE, verbose = TRUE)
plot(sameTwoDisks, col = as.factor(res$cluster))

### Example 2: Speed and Stopping Distances of Cars
res &lt;- recursClust(scale(iris[,-5]),levelMax=4, clustFunction = spectralPAM,
                   similarity = TRUE, vois = 7, flagDiagZero = FALSE,
                   biparted = FALSE, method = "PEV", tolerence =  0.99,
                   threshold = 0.9, verbose = TRUE)
plot(iris, col = as.factor(res$cluster))
</code></pre>

<hr>
<h2 id='search.neighboor'>Recherche du voisin num id le plus proche</h2><span id='topic+search.neighboor'></span>

<h3>Description</h3>

<p>Recherche du voisin num id le plus proche
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search.neighboor(vdist, vois)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="search.neighboor_+3A_vdist">vdist</code></td>
<td>
<p>vecteur de distance du point avec d'autres points</p>
</td></tr>
<tr><td><code id="search.neighboor_+3A_vois">vois</code></td>
<td>
<p>nombre de voisin a selectionner</p>
</td></tr>
</table>


<h3>Value</h3>

<p>id
</p>


<h3>Author(s)</h3>

<p>Emilie Poisson Caillault v13/10/2015
</p>

<hr>
<h2 id='ShiMalikSC'>Bi-parted Spectral Clustering. Shi and Malik.</h2><span id='topic+ShiMalikSC'></span>

<h3>Description</h3>

<p>Bi-parted spectral clustering based on Shi and Malik algorithm, which separates the data into two distinct clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ShiMalikSC(W, flagDiagZero = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ShiMalikSC_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="ShiMalikSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="ShiMalikSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>References</h3>

<p>Shi, J and Malik, J. (2000). Normalized cuts and image segmentation. In PAMI, Transactions on Pattern Analysis and Machine Intelligence, pages 888-905
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- ShiMalikSC(W,flagDiagZero=TRUE,verbose=FALSE)
plot(sameTwoDisks, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[,-5]))
res &lt;- ShiMalikSC(W,flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
</code></pre>

<hr>
<h2 id='spectralPAM'>Spectral-PAM clustering</h2><span id='topic+spectralPAM'></span>

<h3>Description</h3>

<p>The function, for a given similarity matrix, will separate the data using a spectral space.It is based on the Jordan and Weiss algorithm. This version uses K-medoid to split the clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spectralPAM(W, K, flagDiagZero = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spectralPAM_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="spectralPAM_+3A_k">K</code></td>
<td>
<p>number of cluster to obtain.</p>
</td></tr>
<tr><td><code id="spectralPAM_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="spectralPAM_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- spectralPAM(W,K=2,flagDiagZero=TRUE,verbose=TRUE)
plot(sameTwoDisks, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
abline(h=1,lty="dashed",col="red")

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[-5]))
res &lt;- spectralPAM(W,K=2,flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
abline(h=1,lty="dashed",col="red")
</code></pre>

<hr>
<h2 id='UnormalizedSC'>Unormalized Spectral Clustering Ng.</h2><span id='topic+UnormalizedSC'></span>

<h3>Description</h3>

<p>The function, for a given similarity matrix, will separate the data using a spectral space. It does not normalize the Laplacian matrix compared to other algorithms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UnormalizedSC(W, K = 5, flagDiagZero = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UnormalizedSC_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="UnormalizedSC_+3A_k">K</code></td>
<td>
<p>number of cluster to obtain.</p>
</td></tr>
<tr><td><code id="UnormalizedSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="UnormalizedSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- UnormalizedSC(W,K=2,flagDiagZero=TRUE,verbose=TRUE)
plot(sameTwoDisks, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[,-5]))
res &lt;- UnormalizedSC(W,K=2,flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
</code></pre>

<hr>
<h2 id='VonLuxburgSC'>Spectral Clustering based on the Von Luxburg algorithm</h2><span id='topic+VonLuxburgSC'></span>

<h3>Description</h3>

<p>The function, for a given similarity matrix, will separate the data using a spectral space. It uses the Von Luxburg algorithm to do this
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VonLuxburgSC(W, K = 5, flagDiagZero = FALSE, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VonLuxburgSC_+3A_w">W</code></td>
<td>
<p>Gram Similarity Matrix.</p>
</td></tr>
<tr><td><code id="VonLuxburgSC_+3A_k">K</code></td>
<td>
<p>number of cluster to obtain.</p>
</td></tr>
<tr><td><code id="VonLuxburgSC_+3A_flagdiagzero">flagDiagZero</code></td>
<td>
<p>if True, Put zero on the similarity matrix W.</p>
</td></tr>
<tr><td><code id="VonLuxburgSC_+3A_verbose">verbose</code></td>
<td>
<p>To output the verbose in the terminal.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list containing the following elements:
</p>

<ul>
<li><p>cluster: a vector containing the cluster
</p>
</li>
<li><p>eigenVect: a vector containing the eigenvectors
</p>
</li>
<li><p>eigenVal: a vector containing the eigenvalues
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Emilie Poisson Caillault and Erwan Vincent
</p>


<h3>References</h3>

<p>Von Luxburg, U. (2007). A Tutorial on Spectral Clustering. Statistics and  Computing,  Volume  17(4), pages 395-416
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Example 1: 2 disks of the same size
n&lt;-100 ; r1&lt;-1
x&lt;-(runif(n)-0.5)*2;
y&lt;-(runif(n)-0.5)*2
keep1&lt;-which((x*2+y*2)&lt;(r1*2))
disk1&lt;-data.frame(x+3*r1,y)[keep1,]
disk2 &lt;-data.frame(x-3*r1,y)[keep1,]
sameTwoDisks &lt;- rbind(disk1,disk2)
W &lt;- compute.similarity.ZP(scale(sameTwoDisks))
res &lt;- VonLuxburgSC(W,K=2,flagDiagZero=TRUE,verbose=TRUE)
plot(sameTwoDisks, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 

### Example 2: Speed and Stopping Distances of Cars
W &lt;- compute.similarity.ZP(scale(iris[,-5]))
res &lt;- VonLuxburgSC(W,K=2,flagDiagZero=TRUE,verbose=TRUE)
plot(iris, col = res$cluster)
plot(res$eigenVect[,1:2], col = res$cluster, main="spectral space",
     xlim=c(-1,1),ylim=c(-1,1)); points(0,0,pch='+');
plot(res$eigenVal, main="Laplacian eigenvalues",pch='+'); 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
