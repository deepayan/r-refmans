<!DOCTYPE html><html><head><title>Help for package fdm2id</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fdm2id}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#accident2014'><p>Sample of car accident location in the UK during year 2014.</p></a></li>
<li><a href='#ADABOOST'><p>Classification using AdaBoost</p></a></li>
<li><a href='#alcohol'><p>Alcohol dataset</p></a></li>
<li><a href='#APRIORI'><p>Classification using APRIORI</p></a></li>
<li><a href='#apriori-class'><p>APRIORI classification model</p></a></li>
<li><a href='#augmentation'><p>Duplicate and add noise to a dataset</p></a></li>
<li><a href='#autompg'><p>Auto MPG dataset</p></a></li>
<li><a href='#BAGGING'><p>Classification using Bagging</p></a></li>
<li><a href='#beetles'><p>Flea beetles dataset</p></a></li>
<li><a href='#birth'><p>Birth dataset</p></a></li>
<li><a href='#boosting-class'><p>Boosting methods model</p></a></li>
<li><a href='#boxclus'><p>Clustering Box Plots</p></a></li>
<li><a href='#britpop'><p>Population and location of 18 major british cities.</p></a></li>
<li><a href='#CA'><p>Correspondence Analysis (CA)</p></a></li>
<li><a href='#CART'><p>Classification using CART</p></a></li>
<li><a href='#cartdepth'><p>Depth</p></a></li>
<li><a href='#cartinfo'><p>CART information</p></a></li>
<li><a href='#cartleafs'><p>Number of Leafs</p></a></li>
<li><a href='#cartnodes'><p>Number of Nodes</p></a></li>
<li><a href='#cartplot'><p>CART Plot</p></a></li>
<li><a href='#CDA'><p>Classification using Canonical Discriminant Analysis</p></a></li>
<li><a href='#cda-class'><p>Canonical Disciminant Analysis model</p></a></li>
<li><a href='#closegraphics'><p>Close a graphics device</p></a></li>
<li><a href='#compare'><p>Comparison of two sets of clusters</p></a></li>
<li><a href='#compare.accuracy'><p>Comparison of two sets of clusters, using accuracy</p></a></li>
<li><a href='#compare.jaccard'><p>Comparison of two sets of clusters, using Jaccard index</p></a></li>
<li><a href='#compare.kappa'><p>Comparison of two sets of clusters, using kappa</p></a></li>
<li><a href='#confusion'><p>Confuion matrix</p></a></li>
<li><a href='#cookies'><p>Cookies dataset</p></a></li>
<li><a href='#cookplot'><p>Plot the Cook's distance of a linear regression model</p></a></li>
<li><a href='#correlated'><p>Correlated variables</p></a></li>
<li><a href='#cost.curves'><p>Plot Cost Curves</p></a></li>
<li><a href='#credit'><p>Credit dataset</p></a></li>
<li><a href='#data.diag'><p>Square dataset</p></a></li>
<li><a href='#data.gauss'><p>Gaussian mixture dataset</p></a></li>
<li><a href='#data.parabol'><p>Parabol dataset</p></a></li>
<li><a href='#data.target1'><p>Target1 dataset</p></a></li>
<li><a href='#data.target2'><p>Target2 dataset</p></a></li>
<li><a href='#data.twomoons'><p>Two moons dataset</p></a></li>
<li><a href='#data.xor'><p>XOR dataset</p></a></li>
<li><a href='#data1'><p>&quot;data1&quot; dataset</p></a></li>
<li><a href='#data2'><p>&quot;data2&quot; dataset</p></a></li>
<li><a href='#data3'><p>&quot;data3&quot; dataset</p></a></li>
<li><a href='#dataset-class'><p>Training set and test set</p></a></li>
<li><a href='#dbs-class'><p>DBSCAN model</p></a></li>
<li><a href='#DBSCAN'><p>DBSCAN clustering method</p></a></li>
<li><a href='#decathlon'><p>Decathlon dataset</p></a></li>
<li><a href='#distplot'><p>Plot a k-distance graphic</p></a></li>
<li><a href='#EM'><p>Expectation-Maximization clustering method</p></a></li>
<li><a href='#em-class'><p>Expectation-Maximization model</p></a></li>
<li><a href='#eucalyptus'><p>Eucalyptus dataset</p></a></li>
<li><a href='#evaluation'><p>Evaluation of classification or regression predictions</p></a></li>
<li><a href='#evaluation.accuracy'><p>Accuracy of classification predictions</p></a></li>
<li><a href='#evaluation.adjr2'><p>Adjusted R2 evaluation of regression predictions</p></a></li>
<li><a href='#evaluation.fmeasure'><p>F-measure</p></a></li>
<li><a href='#evaluation.fowlkesmallows'><p>Fowlkesâ€“Mallows index</p></a></li>
<li><a href='#evaluation.goodness'><p>Goodness</p></a></li>
<li><a href='#evaluation.jaccard'><p>Jaccard index</p></a></li>
<li><a href='#evaluation.kappa'><p>Kappa evaluation of classification predictions</p></a></li>
<li><a href='#evaluation.msep'><p>MSEP evaluation of regression predictions</p></a></li>
<li><a href='#evaluation.precision'><p>Precision of classification predictions</p></a></li>
<li><a href='#evaluation.r2'><p>R2 evaluation of regression predictions</p></a></li>
<li><a href='#evaluation.recall'><p>Recall of classification predictions</p></a></li>
<li><a href='#exportgraphics'><p>Open a graphics device</p></a></li>
<li><a href='#exportgraphics.off'><p>Toggle graphic exports</p></a></li>
<li><a href='#factorial-class'><p>Factorial analysis results</p></a></li>
<li><a href='#FEATURESELECTION'><p>Classification with Feature selection</p></a></li>
<li><a href='#filter.rules'><p>Filtering a set of rules</p></a></li>
<li><a href='#frequentwords'><p>Frequent words</p></a></li>
<li><a href='#general.rules'><p>Remove redundancy in a set of rules</p></a></li>
<li><a href='#getvocab'><p>Extract words and phrases from a corpus</p></a></li>
<li><a href='#GRADIENTBOOSTING'><p>Classification using Gradient Boosting</p></a></li>
<li><a href='#HCA'><p>Hierarchical Cluster Analysis method</p></a></li>
<li><a href='#intern'><p>Clustering evaluation through internal criteria</p></a></li>
<li><a href='#intern.dunn'><p>Clustering evaluation through Dunn's index</p></a></li>
<li><a href='#intern.interclass'><p>Clustering evaluation through interclass inertia</p></a></li>
<li><a href='#intern.intraclass'><p>Clustering evaluation through intraclass inertia</p></a></li>
<li><a href='#ionosphere'><p>Ionosphere dataset</p></a></li>
<li><a href='#kaiser'><p>Kaiser rule</p></a></li>
<li><a href='#KERREG'><p>Kernel Regression</p></a></li>
<li><a href='#KMEANS'><p>K-means method</p></a></li>
<li><a href='#kmeans.getk'><p>Estimation of the number of clusters for <em>K</em>-means</p></a></li>
<li><a href='#KNN'><p>Classification using k-NN</p></a></li>
<li><a href='#knn-class'><p>K Nearest Neighbours model</p></a></li>
<li><a href='#LDA'><p>Classification using Linear Discriminant Analysis</p></a></li>
<li><a href='#leverageplot'><p>Plot the leverage points of a linear regression model</p></a></li>
<li><a href='#LINREG'><p>Linear Regression</p></a></li>
<li><a href='#linsep'><p>Linsep dataset</p></a></li>
<li><a href='#loadtext'><p>load a text file</p></a></li>
<li><a href='#LR'><p>Classification using Logistic Regression</p></a></li>
<li><a href='#MCA'><p>Multiple Correspondence Analysis (MCA)</p></a></li>
<li><a href='#MEANSHIFT'><p>MeanShift method</p></a></li>
<li><a href='#meanshift-class'><p>MeanShift model</p></a></li>
<li><a href='#MLP'><p>Classification using Multilayer Perceptron</p></a></li>
<li><a href='#MLPREG'><p>Multi-Layer Perceptron Regression</p></a></li>
<li><a href='#model-class'><p>Generic classification or regression model</p></a></li>
<li><a href='#movies'><p>Movies dataset</p></a></li>
<li><a href='#NB'><p>Classification using Naive Bayes</p></a></li>
<li><a href='#NMF'><p>Non-negative Matrix Factorization</p></a></li>
<li><a href='#ozone'><p>Ozone dataset</p></a></li>
<li><a href='#params-class'><p>Learning Parameters</p></a></li>
<li><a href='#PCA'><p>Principal Component Analysis (PCA)</p></a></li>
<li><a href='#performance'><p>Performance estimation</p></a></li>
<li><a href='#plot.cda'><p>Plot function for cda-class</p></a></li>
<li><a href='#plot.factorial'><p>Plot function for factorial-class</p></a></li>
<li><a href='#plot.som'><p>Plot function for som-class</p></a></li>
<li><a href='#plotavsp'><p>Plot actual vs. predictions</p></a></li>
<li><a href='#plotcloud'><p>Plot word cloud</p></a></li>
<li><a href='#plotclus'><p>Generic Plot Method for Clustering</p></a></li>
<li><a href='#plotdata'><p>Advanced plot function</p></a></li>
<li><a href='#plotzipf'><p>Plot rank versus frequency</p></a></li>
<li><a href='#POLYREG'><p>Polynomial Regression</p></a></li>
<li><a href='#predict.apriori'><p>Model predictions</p></a></li>
<li><a href='#predict.boosting'><p>Model predictions</p></a></li>
<li><a href='#predict.cda'><p>Model predictions</p></a></li>
<li><a href='#predict.dbs'><p>Predict function for DBSCAN</p></a></li>
<li><a href='#predict.em'><p>Predict function for EM</p></a></li>
<li><a href='#predict.kmeans'><p>Predict function for K-means</p></a></li>
<li><a href='#predict.knn'><p>Model predictions</p></a></li>
<li><a href='#predict.meanshift'><p>Predict function for MeanShift</p></a></li>
<li><a href='#predict.model'><p>Model predictions</p></a></li>
<li><a href='#predict.selection'><p>Model predictions</p></a></li>
<li><a href='#predict.textmining'><p>Model predictions</p></a></li>
<li><a href='#print.apriori'><p>Print a classification model obtained by APRIORI</p></a></li>
<li><a href='#print.factorial'><p>Plot function for factorial-class</p></a></li>
<li><a href='#pseudoF'><p>Pseudo-F</p></a></li>
<li><a href='#QDA'><p>Classification using Quadratic Discriminant Analysis</p></a></li>
<li><a href='#query.docs'><p>Document query</p></a></li>
<li><a href='#query.words'><p>Word query</p></a></li>
<li><a href='#RANDOMFOREST'><p>Classification using Random Forest</p></a></li>
<li><a href='#reg1'><p>reg1 dataset</p></a></li>
<li><a href='#reg2'><p>reg2 dataset</p></a></li>
<li><a href='#regplot'><p>Plot function for a regression model</p></a></li>
<li><a href='#resplot'><p>Plot the studentized residuals of a linear regression model</p></a></li>
<li><a href='#roc.curves'><p>Plot ROC Curves</p></a></li>
<li><a href='#rotation'><p>Rotation</p></a></li>
<li><a href='#runningtime'><p>Running time</p></a></li>
<li><a href='#scatterplot'><p>Clustering Scatter Plots</p></a></li>
<li><a href='#selectfeatures'><p>Feature selection for classification</p></a></li>
<li><a href='#selection-class'><p>Feature selection</p></a></li>
<li><a href='#snore'><p>Snore dataset</p></a></li>
<li><a href='#SOM'><p>Self-Organizing Maps clustering method</p></a></li>
<li><a href='#som-class'><p>Self-Organizing Maps model</p></a></li>
<li><a href='#SPECTRAL'><p>Spectral clustering method</p></a></li>
<li><a href='#spectral-class'><p>Spectral clustering model</p></a></li>
<li><a href='#spine'><p>Spine dataset</p></a></li>
<li><a href='#splitdata'><p>Splits a dataset into training set and test set</p></a></li>
<li><a href='#stability'><p>Clustering evaluation through stability</p></a></li>
<li><a href='#STUMP'><p>Classification using one-level decision tree</p></a></li>
<li><a href='#summary.apriori'><p>Print summary of a classification model obtained by APRIORI</p></a></li>
<li><a href='#SVD'><p>Singular Value Decomposition</p></a></li>
<li><a href='#SVM'><p>Classification using Support Vector Machine</p></a></li>
<li><a href='#SVMl'><p>Classification using Support Vector Machine with a linear kernel</p></a></li>
<li><a href='#SVMr'><p>Classification using Support Vector Machine with a radial kernel</p></a></li>
<li><a href='#SVR'><p>Regression using Support Vector Machine</p></a></li>
<li><a href='#SVRl'><p>Regression using Support Vector Machine with a linear kernel</p></a></li>
<li><a href='#SVRr'><p>Regression using Support Vector Machine with a radial kernel</p></a></li>
<li><a href='#temperature'><p>Temperature dataset</p></a></li>
<li><a href='#TEXTMINING'><p>Text mining</p></a></li>
<li><a href='#textmining-class'><p>Text mining object</p></a></li>
<li><a href='#titanic'><p>Titanic dataset</p></a></li>
<li><a href='#treeplot'><p>Dendrogram Plots</p></a></li>
<li><a href='#TSNE'><p>t-distributed Stochastic Neighbor Embedding</p></a></li>
<li><a href='#universite'><p>University dataset</p></a></li>
<li><a href='#vectorize.docs'><p>Document vectorization</p></a></li>
<li><a href='#vectorize.words'><p>Word vectorization</p></a></li>
<li><a href='#vectorizer-class'><p>Document vectorization object</p></a></li>
<li><a href='#vowels'><p>Vowels dataset</p></a></li>
<li><a href='#wheat'><p>Wheat dataset</p></a></li>
<li><a href='#wine'><p>Wine dataset</p></a></li>
<li><a href='#zoo'><p>Zoo dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Data Mining and R Programming for Beginners</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.9</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions to simplify the use of data mining methods (classification, regression, clustering, etc.), for students and beginners in R programming. Various R packages are used and wrappers are built around the main functions, to standardize the use of data mining methods (input/output): it brings a certain loss of flexibility, but also a gain of simplicity. The package name came from the French "Fouille de DonnÃ©es en Master 2 Informatique DÃ©cisionnelle".</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), arules, arulesViz, FactoMineR</td>
</tr>
<tr>
<td>Imports:</td>
<td>mclust, methods, nnet, pls</td>
</tr>
<tr>
<td>Suggests:</td>
<td>car, caret, class, cluster, datasets, e1071, fds, flexclust,
fpc, glmnet, graphics, grDevices, ibr, irr, kohonen, leaps,
MASS, mda, meanShiftR, questionr, randomForest, ROCR, rpart,
rpart.plot, Rtsne, SnowballC, stats, text2vec, stopwords,
utils, wordcloud, xgboost</td>
</tr>
<tr>
<td>Enhances:</td>
<td>NMF</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-06-12 12:33:26 UTC; blansche</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexandre BlanschÃ© [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alexandre BlanschÃ© &lt;alexandre.blansche@univ-lorraine.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-06-12 13:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='accident2014'>Sample of car accident location in the UK during year 2014.</h2><span id='topic+accident2014'></span>

<h3>Description</h3>

<p>Longitude and latitude of 500 car accident during year 2014 (source: www.data.gov.uk).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>accident2014
</code></pre>


<h3>Format</h3>

<p>The dataset has 500 instances described by 2 variables (coordinates).
</p>


<h3>Source</h3>

<p><a href="https://www.data.gov.uk/">https://www.data.gov.uk/</a>
</p>

<hr>
<h2 id='ADABOOST'>Classification using AdaBoost</h2><span id='topic+ADABOOST'></span>

<h3>Description</h3>

<p>Ensemble learning, through AdaBoost Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ADABOOST(
  x,
  y,
  learningmethod,
  nsamples = 100,
  fuzzy = FALSE,
  tune = FALSE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ADABOOST_+3A_x">x</code></td>
<td>
<p>The dataset (description/predictors), a <code>matrix</code> or <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_y">y</code></td>
<td>
<p>The target (class labels or numeric values), a <code>factor</code> or <code>vector</code>.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_learningmethod">learningmethod</code></td>
<td>
<p>The boosted method.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_nsamples">nsamples</code></td>
<td>
<p>The number of samplings.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_fuzzy">fuzzy</code></td>
<td>
<p>Indicates whether or not fuzzy classification should be used or not.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
<tr><td><code id="ADABOOST_+3A_...">...</code></td>
<td>
<p>Other specific parameters for the leaning method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+BAGGING">BAGGING</a></code>, <code><a href="#topic+predict.boosting">predict.boosting</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
ADABOOST (iris [, -5], iris [, 5], NB)

## End(Not run)
</code></pre>

<hr>
<h2 id='alcohol'>Alcohol dataset</h2><span id='topic+alcohol'></span>

<h3>Description</h3>

<p>This dataset has been extracted from the WHO database and depict the alcool habits in the 27 european contries (in 2010).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alcohol
</code></pre>


<h3>Format</h3>

<p>The dataset has 27 instances described by 4 variables.
The variables are the average amount of alcool of different types per year par inhabitent.
</p>


<h3>Source</h3>

<p><a href="https://www.who.int/">https://www.who.int/</a>
</p>

<hr>
<h2 id='APRIORI'>Classification using APRIORI</h2><span id='topic+APRIORI'></span>

<h3>Description</h3>

<p>This function builds a classification model using the association rules method APRIORI.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>APRIORI(
  train,
  labels,
  supp = 0.05,
  conf = 0.8,
  prune = FALSE,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="APRIORI_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="APRIORI_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="APRIORI_+3A_supp">supp</code></td>
<td>
<p>The minimal support of an item set (numeric value).</p>
</td></tr>
<tr><td><code id="APRIORI_+3A_conf">conf</code></td>
<td>
<p>The minimal confidence of an item set (numeric value).</p>
</td></tr>
<tr><td><code id="APRIORI_+3A_prune">prune</code></td>
<td>
<p>A logical indicating whether to prune redundant rules or not (default: <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="APRIORI_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="APRIORI_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model, as an object of class <code>apriori</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.apriori">predict.apriori</a></code>, <code><a href="#topic+apriori-class">apriori-class</a></code>, <code><a href="arules.html#topic+apriori">apriori</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("datasets")
data (iris)
d = discretizeDF (iris,
    default = list (method = "interval", breaks = 3, labels = c ("small", "medium", "large")))
APRIORI (d [, -5], d [, 5], supp = .1, conf = .9, prune = TRUE)
</code></pre>

<hr>
<h2 id='apriori-class'>APRIORI classification model</h2><span id='topic+apriori-class'></span>

<h3>Description</h3>

<p>This class contains the classification model obtained by the APRIORI association rules method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>rules</code></dt><dd><p>The set of rules obtained by APRIORI.</p>
</dd>
<dt><code>transactions</code></dt><dd><p>The training set as a <code>transaction</code> object.</p>
</dd>
<dt><code>train</code></dt><dd><p>The training set (description). A <code>matrix</code> or <code>data.frame</code>.</p>
</dd>
<dt><code>labels</code></dt><dd><p>Class labels of the training set. Either a <code>factor</code> or an integer <code>vector</code>.</p>
</dd>
<dt><code>supp</code></dt><dd><p>The minimal support of an item set (numeric value).</p>
</dd>
<dt><code>conf</code></dt><dd><p>The minimal confidence of an item set (numeric value).</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+APRIORI">APRIORI</a></code>, <code><a href="#topic+predict.apriori">predict.apriori</a></code>, <code><a href="#topic+print.apriori">print.apriori</a></code>,
<code><a href="#topic+summary.apriori">summary.apriori</a></code>, <code><a href="arules.html#topic+apriori">apriori</a></code>
</p>

<hr>
<h2 id='augmentation'>Duplicate and add noise to a dataset</h2><span id='topic+augmentation'></span>

<h3>Description</h3>

<p>This function is a data augmentation technique. It duplicates rows and add gaussian noise to the duplicates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>augmentation(dataset, target, n = 5, sigma = 0.1, seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="augmentation_+3A_dataset">dataset</code></td>
<td>
<p>The dataset to be split (<code>data.frame</code> or <code>matrix</code>).</p>
</td></tr>
<tr><td><code id="augmentation_+3A_target">target</code></td>
<td>
<p>The column index of the target variable (class label or response variable).</p>
</td></tr>
<tr><td><code id="augmentation_+3A_n">n</code></td>
<td>
<p>The scaling factor (as an integer value).</p>
</td></tr>
<tr><td><code id="augmentation_+3A_sigma">sigma</code></td>
<td>
<p>The baseline variance for the noise generation.</p>
</td></tr>
<tr><td><code id="augmentation_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An augmented dataset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = augmentation (iris, 5)
summary (iris)
summary (d)
</code></pre>

<hr>
<h2 id='autompg'>Auto MPG dataset</h2><span id='topic+autompg'></span>

<h3>Description</h3>

<p>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.
The dataset was used in the 1983 American Statistical Association Exposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autompg
</code></pre>


<h3>Format</h3>

<p>The dataset has 392 instances described by 8 variables.
The seven first variables are numeric variables. The last variable is qualitative (car origin).
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/auto+mpg">https://archive.ics.uci.edu/ml/datasets/auto+mpg</a>
</p>

<hr>
<h2 id='BAGGING'>Classification using Bagging</h2><span id='topic+BAGGING'></span>

<h3>Description</h3>

<p>Ensemble learning, through Bagging Algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BAGGING(
  x,
  y,
  learningmethod,
  nsamples = 100,
  bag.size = nrow(x),
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BAGGING_+3A_x">x</code></td>
<td>
<p>The dataset (description/predictors), a <code>matrix</code> or <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="BAGGING_+3A_y">y</code></td>
<td>
<p>The target (class labels or numeric values), a <code>factor</code> or <code>vector</code>.</p>
</td></tr>
<tr><td><code id="BAGGING_+3A_learningmethod">learningmethod</code></td>
<td>
<p>The boosted method.</p>
</td></tr>
<tr><td><code id="BAGGING_+3A_nsamples">nsamples</code></td>
<td>
<p>The number of samplings.</p>
</td></tr>
<tr><td><code id="BAGGING_+3A_bag.size">bag.size</code></td>
<td>
<p>The size of the samples.</p>
</td></tr>
<tr><td><code id="BAGGING_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
<tr><td><code id="BAGGING_+3A_...">...</code></td>
<td>
<p>Other specific parameters for the leaning method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ADABOOST">ADABOOST</a></code>, <code><a href="#topic+predict.boosting">predict.boosting</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
BAGGING (iris [, -5], iris [, 5], NB)

## End(Not run)
</code></pre>

<hr>
<h2 id='beetles'>Flea beetles dataset</h2><span id='topic+beetles'></span>

<h3>Description</h3>

<p>Data were collected on the genus of flea beetle <em>Chaetocnema</em>, which contains three species:
<em>concinna</em>, <em>heikertingeri</em>, and <em>heptapotamica</em>.
Measurements were made on the width and angle of the aedeagus of each beetle.
The goal of the original study was to form a classification rule to distinguish the three species.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>beetles
</code></pre>


<h3>Format</h3>

<p>The dataset has 74 instances described by 3 variables.
The variables are as follows:
</p>

<dl>
<dt><code>Width</code></dt><dd><p>The maximal width of aedeagus in the forpart (in microns).</p>
</dd>
<dt><code>Angle</code></dt><dd><p>The front angle of the aedeagus (1 unit = 7.5 degrees).</p>
</dd>
<dt><code>Shot.put</code></dt><dd><p>Species of flea beetle from the genus <em>Chaetocnema</em>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Lubischew, A.A. (1962) On the use of discriminant functions in taxonomy. Biometrics, 18, 455-477.
</p>

<hr>
<h2 id='birth'>Birth dataset</h2><span id='topic+birth'></span>

<h3>Description</h3>

<p>Tutorial data set (vector).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>birth
</code></pre>


<h3>Format</h3>

<p>The dataset is a names vector of nine values (birth years).
</p>

<hr>
<h2 id='boosting-class'>Boosting methods model</h2><span id='topic+boosting-class'></span>

<h3>Description</h3>

<p>This class contains the classification model obtained by the CDA method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>models</code></dt><dd><p>List of models.</p>
</dd>
<dt><code>x</code></dt><dd><p>The learning set.</p>
</dd>
<dt><code>y</code></dt><dd><p>The target values.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+ADABOOST">ADABOOST</a></code>, <code><a href="#topic+BAGGING">BAGGING</a></code>, <code><a href="#topic+predict.boosting">predict.boosting</a></code>
</p>

<hr>
<h2 id='boxclus'>Clustering Box Plots</h2><span id='topic+boxclus'></span>

<h3>Description</h3>

<p>Produce a box-and-whisker plot for clustering results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boxclus(d, clusters, legendpos = "topleft", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boxclus_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="boxclus_+3A_clusters">clusters</code></td>
<td>
<p>Cluster labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="boxclus_+3A_legendpos">legendpos</code></td>
<td>
<p>Position of the legend</p>
</td></tr>
<tr><td><code id="boxclus_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+boxplot">boxplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
boxclus (iris [, -5], km$cluster)
</code></pre>

<hr>
<h2 id='britpop'>Population and location of 18 major british cities.</h2><span id='topic+britpop'></span>

<h3>Description</h3>

<p>Longitude and latitude and population of 18 major cities in the Great Britain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>britpop
</code></pre>


<h3>Format</h3>

<p>The dataset has 18 instances described by 3 variables.
</p>

<hr>
<h2 id='CA'>Correspondence Analysis (CA)</h2><span id='topic+CA'></span>

<h3>Description</h3>

<p>Performs Correspondence Analysis (CA) including supplementary row and/or column points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CA(
  d,
  ncp = 5,
  row.sup = NULL,
  col.sup = NULL,
  quanti.sup = NULL,
  quali.sup = NULL,
  row.w = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CA_+3A_d">d</code></td>
<td>
<p>A ddata frame or a table with n rows and p columns, i.e. a contingency table.</p>
</td></tr>
<tr><td><code id="CA_+3A_ncp">ncp</code></td>
<td>
<p>The number of dimensions kept in the results (by default 5).</p>
</td></tr>
<tr><td><code id="CA_+3A_row.sup">row.sup</code></td>
<td>
<p>A vector indicating the indexes of the supplementary rows.</p>
</td></tr>
<tr><td><code id="CA_+3A_col.sup">col.sup</code></td>
<td>
<p>A vector indicating the indexes of the supplementary columns.</p>
</td></tr>
<tr><td><code id="CA_+3A_quanti.sup">quanti.sup</code></td>
<td>
<p>A vector indicating the indexes of the supplementary continuous variables.</p>
</td></tr>
<tr><td><code id="CA_+3A_quali.sup">quali.sup</code></td>
<td>
<p>A vector indicating the indexes of the categorical supplementary variables.</p>
</td></tr>
<tr><td><code id="CA_+3A_row.w">row.w</code></td>
<td>
<p>An optional row weights (by default, a vector of 1 for uniform row weights); the weights are given only for the active individuals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The CA on the dataset.
</p>


<h3>See Also</h3>

<p><code><a href="FactoMineR.html#topic+CA">CA</a></code>, <code><a href="#topic+MCA">MCA</a></code>, <code><a href="#topic+PCA">PCA</a></code>, <code><a href="#topic+plot.factorial">plot.factorial</a></code>, <code><a href="#topic+factorial-class">factorial-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data (children, package = "FactoMineR")
CA (children, row.sup = 15:18, col.sup = 6:8)
</code></pre>

<hr>
<h2 id='CART'>Classification using CART</h2><span id='topic+CART'></span>

<h3>Description</h3>

<p>This function builds a classification model using CART.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CART(
  train,
  labels,
  minsplit = 1,
  maxdepth = log2(length(labels)),
  cp = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CART_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="CART_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="CART_+3A_minsplit">minsplit</code></td>
<td>
<p>The minimum leaf size during the learning.</p>
</td></tr>
<tr><td><code id="CART_+3A_maxdepth">maxdepth</code></td>
<td>
<p>Set the maximum depth of any node of the final tree, with the root node counted as depth 0.</p>
</td></tr>
<tr><td><code id="CART_+3A_cp">cp</code></td>
<td>
<p>The complexity parameter of the tree. Cross-validation is used to determine optimal cp if NULL.</p>
</td></tr>
<tr><td><code id="CART_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="CART_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cartdepth">cartdepth</a></code>, <code><a href="#topic+cartinfo">cartinfo</a></code>, <code><a href="#topic+cartleafs">cartleafs</a></code>, <code><a href="#topic+cartnodes">cartnodes</a></code>, <code><a href="#topic+cartplot">cartplot</a></code>, <code><a href="rpart.html#topic+rpart">rpart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
CART (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='cartdepth'>Depth</h2><span id='topic+cartdepth'></span>

<h3>Description</h3>

<p>Return the dept of a decision tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cartdepth(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cartdepth_+3A_model">model</code></td>
<td>
<p>The decision tree.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The depth.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CART">CART</a></code>, <code><a href="#topic+cartinfo">cartinfo</a></code>, <code><a href="#topic+cartleafs">cartleafs</a></code>, <code><a href="#topic+cartnodes">cartnodes</a></code>, <code><a href="#topic+cartplot">cartplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
model = CART (iris [, -5], iris [, 5])
cartdepth (model)
</code></pre>

<hr>
<h2 id='cartinfo'>CART information</h2><span id='topic+cartinfo'></span>

<h3>Description</h3>

<p>Return various information on a CART model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cartinfo(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cartinfo_+3A_model">model</code></td>
<td>
<p>The decision tree.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Various information organized into a vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CART">CART</a></code>, <code><a href="#topic+cartdepth">cartdepth</a></code>, <code><a href="#topic+cartleafs">cartleafs</a></code>, <code><a href="#topic+cartnodes">cartnodes</a></code>, <code><a href="#topic+cartplot">cartplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
model = CART (iris [, -5], iris [, 5])
cartinfo (model)
</code></pre>

<hr>
<h2 id='cartleafs'>Number of Leafs</h2><span id='topic+cartleafs'></span>

<h3>Description</h3>

<p>Return the number of leafs of a decision tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cartleafs(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cartleafs_+3A_model">model</code></td>
<td>
<p>The decision tree.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The number of leafs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CART">CART</a></code>, <code><a href="#topic+cartdepth">cartdepth</a></code>, <code><a href="#topic+cartinfo">cartinfo</a></code>, <code><a href="#topic+cartnodes">cartnodes</a></code>, <code><a href="#topic+cartplot">cartplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
model = CART (iris [, -5], iris [, 5])
cartleafs (model)
</code></pre>

<hr>
<h2 id='cartnodes'>Number of Nodes</h2><span id='topic+cartnodes'></span>

<h3>Description</h3>

<p>Return the number of nodes of a decision tree.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cartnodes(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cartnodes_+3A_model">model</code></td>
<td>
<p>The decision tree.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The number of nodes.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CART">CART</a></code>, <code><a href="#topic+cartdepth">cartdepth</a></code>, <code><a href="#topic+cartinfo">cartinfo</a></code>, <code><a href="#topic+cartleafs">cartleafs</a></code>, <code><a href="#topic+cartplot">cartplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
model = CART (iris [, -5], iris [, 5])
cartnodes (model)
</code></pre>

<hr>
<h2 id='cartplot'>CART Plot</h2><span id='topic+cartplot'></span>

<h3>Description</h3>

<p>Plot a decision tree obtained by CART.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cartplot(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cartplot_+3A_model">model</code></td>
<td>
<p>The decision tree.</p>
</td></tr>
<tr><td><code id="cartplot_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+CART">CART</a></code>, <code><a href="#topic+cartdepth">cartdepth</a></code>, <code><a href="#topic+cartinfo">cartinfo</a></code>, <code><a href="#topic+cartleafs">cartleafs</a></code>, <code><a href="#topic+cartnodes">cartnodes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
model = CART (iris [, -5], iris [, 5])
cartplot (model)
</code></pre>

<hr>
<h2 id='CDA'>Classification using Canonical Discriminant Analysis</h2><span id='topic+CDA'></span>

<h3>Description</h3>

<p>This function builds a classification model using Canonical Discriminant Analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CDA(train, labels, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CDA_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="CDA_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="CDA_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="CDA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model, as an object of class <code>glmnet</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.cda">plot.cda</a></code>, <code><a href="#topic+predict.cda">predict.cda</a></code>, <code><a href="#topic+cda-class">cda-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
CDA (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='cda-class'>Canonical Disciminant Analysis model</h2><span id='topic+cda-class'></span>

<h3>Description</h3>

<p>This class contains the classification model obtained by the CDA method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>proj</code></dt><dd><p>The projection of the dataset into the canonical base. A <code>data.frame</code>.</p>
</dd>
<dt><code>transform</code></dt><dd><p>The transformation matrix between. A <code>matrix</code>.</p>
</dd>
<dt><code>centers</code></dt><dd><p>Coordinates of the class centers. A <code>matrix</code>.</p>
</dd>
<dt><code>within</code></dt><dd><p>The intr-class covarianc matrix. A <code>matrix</code>.</p>
</dd>
<dt><code>eig</code></dt><dd><p>The eigen-values. A <code>matrix</code>.</p>
</dd>
<dt><code>dim</code></dt><dd><p>The number of dimensions of the canonical base (numeric value).</p>
</dd>
<dt><code>nb.classes</code></dt><dd><p>The number of clusters (numeric value).</p>
</dd>
<dt><code>train</code></dt><dd><p>The training set (description). A <code>data.frame</code>.</p>
</dd>
<dt><code>labels</code></dt><dd><p>Class labels of the training set. Either a <code>factor</code> or an integer <code>vector</code>.</p>
</dd>
<dt><code>model</code></dt><dd><p>The prediction model.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+CDA">CDA</a></code>, <code><a href="#topic+plot.cda">plot.cda</a></code>, <code><a href="#topic+predict.cda">predict.cda</a></code>
</p>

<hr>
<h2 id='closegraphics'>Close a graphics device</h2><span id='topic+closegraphics'></span>

<h3>Description</h3>

<p>Close the graphics device driver
</p>


<h3>Usage</h3>

<pre><code class='language-R'>closegraphics()
</code></pre>


<h3>See Also</h3>

<p><code><a href="#topic+exportgraphics">exportgraphics</a></code>, <code><a href="#topic+toggleexport">toggleexport</a></code>, <code><a href="grDevices.html#topic+dev.off">dev.off</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data (iris)
exportgraphics ("export.pdf")
plotdata (iris [, -5], iris [, 5])
closegraphics()

## End(Not run)
</code></pre>

<hr>
<h2 id='compare'>Comparison of two sets of clusters</h2><span id='topic+compare'></span>

<h3>Description</h3>

<p>Comparison of two sets of clusters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare(clus, gt, eval = "accuracy", comp = c("max", "pairwise", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="compare_+3A_gt">gt</code></td>
<td>
<p>The real clusters.</p>
</td></tr>
<tr><td><code id="compare_+3A_eval">eval</code></td>
<td>
<p>The evluation criterion.</p>
</td></tr>
<tr><td><code id="compare_+3A_comp">comp</code></td>
<td>
<p>Indicates whether a &quot;max&quot; or a &quot;pairwise&quot; evaluation should be used, or the evaluation for each individual &quot;cluster&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value indicating how much the two sets of clusters are similar.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare.accuracy">compare.accuracy</a></code>, <code><a href="#topic+compare.jaccard">compare.jaccard</a></code>, <code><a href="#topic+compare.kappa">compare.kappa</a></code>, <code><a href="#topic+intern">intern</a></code>, <code><a href="#topic+stability">stability</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
compare (km$cluster, iris [, 5])
## Not run: 
compare (km$cluster, iris [, 5], eval = c ("accuracy", "kappa"), comp = "pairwise")

## End(Not run)
</code></pre>

<hr>
<h2 id='compare.accuracy'>Comparison of two sets of clusters, using accuracy</h2><span id='topic+compare.accuracy'></span>

<h3>Description</h3>

<p>Comparison of two sets of clusters, using accuracy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.accuracy(clus, gt, comp = c("max", "pairwise", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare.accuracy_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="compare.accuracy_+3A_gt">gt</code></td>
<td>
<p>The real clusters.</p>
</td></tr>
<tr><td><code id="compare.accuracy_+3A_comp">comp</code></td>
<td>
<p>Indicates whether a &quot;max&quot; or a &quot;pairwise&quot; evaluation should be used, or the evaluation for each individual &quot;cluster&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value indicating how much the two sets of clusters are similar.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare.jaccard">compare.jaccard</a></code>, <code><a href="#topic+compare.kappa">compare.kappa</a></code>, <code><a href="#topic+compare">compare</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
compare.accuracy (km$cluster, iris [, 5])
</code></pre>

<hr>
<h2 id='compare.jaccard'>Comparison of two sets of clusters, using Jaccard index</h2><span id='topic+compare.jaccard'></span>

<h3>Description</h3>

<p>Comparison of two sets of clusters, using Jaccard index
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.jaccard(clus, gt, comp = c("max", "pairwise", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare.jaccard_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="compare.jaccard_+3A_gt">gt</code></td>
<td>
<p>The real clusters.</p>
</td></tr>
<tr><td><code id="compare.jaccard_+3A_comp">comp</code></td>
<td>
<p>Indicates whether a &quot;max&quot; or a &quot;pairwise&quot; evaluation should be used, or the evaluation for each individual &quot;cluster&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value indicating how much the two sets of clusters are similar.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare.accuracy">compare.accuracy</a></code>, <code><a href="#topic+compare.kappa">compare.kappa</a></code>, <code><a href="#topic+compare">compare</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
compare.jaccard (km$cluster, iris [, 5])
</code></pre>

<hr>
<h2 id='compare.kappa'>Comparison of two sets of clusters, using kappa</h2><span id='topic+compare.kappa'></span>

<h3>Description</h3>

<p>Comparison of two sets of clusters, using kappa
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare.kappa(clus, gt, comp = c("max", "pairwise", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compare.kappa_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="compare.kappa_+3A_gt">gt</code></td>
<td>
<p>The real clusters.</p>
</td></tr>
<tr><td><code id="compare.kappa_+3A_comp">comp</code></td>
<td>
<p>Indicates whether a &quot;max&quot; or a &quot;pairwise&quot; evaluation should be used, or the evaluation for each individual &quot;cluster&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric value indicating how much the two sets of clusters are similar.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare.accuracy">compare.accuracy</a></code>, <code><a href="#topic+compare.jaccard">compare.jaccard</a></code>, <code><a href="#topic+compare">compare</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
compare.kappa (km$cluster, iris [, 5])
</code></pre>

<hr>
<h2 id='confusion'>Confuion matrix</h2><span id='topic+confusion'></span>

<h3>Description</h3>

<p>Plot a confusion matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>confusion(predictions, gt, norm = TRUE, graph = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="confusion_+3A_predictions">predictions</code></td>
<td>
<p>The prediction.</p>
</td></tr>
<tr><td><code id="confusion_+3A_gt">gt</code></td>
<td>
<p>The ground truth.</p>
</td></tr>
<tr><td><code id="confusion_+3A_norm">norm</code></td>
<td>
<p>Whether or not the confusion matrix is normalized</p>
</td></tr>
<tr><td><code id="confusion_+3A_graph">graph</code></td>
<td>
<p>Whether or not a graphic is displayed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The confusion matrix.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation">evaluation</a></code>, <code><a href="#topic+performance">performance</a></code>, <code><a href="#topic+splitdata">splitdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("datasets")
data (iris)
d = splitdata (iris, 5)
model = NB (d$train.x, d$train.y)
pred = predict (model, d$test.x)
confusion (d$test.y, pred)
</code></pre>

<hr>
<h2 id='cookies'>Cookies dataset</h2><span id='topic+cookies'></span><span id='topic+cookies.desc.train'></span><span id='topic+cookies.desc.test'></span><span id='topic+cookies.y.train'></span><span id='topic+cookies.y.test'></span>

<h3>Description</h3>

<p>This data set contains measurements from quantitative NIR spectroscopy.
The example studied arises from an experiment done to test the feasibility of NIR spectroscopy to measure the composition of biscuit dough pieces (formed but unbaked biscuits).
Two similar sample sets were made up, with the standard recipe varied to provide a large range for each of the four constituents under investigation: fat, sucrose, dry flour, and water.
The calculated percentages of these four ingredients represent the 4 responses.
There are 40 samples in the calibration or training set (with sample 23 being an outlier).
There are a further 32 samples in the separate prediction or validation set (with example 21 considered as an outlier).
An NIR reflectance spectrum is available for each dough piece.
The spectral data consist of 700 points measured from 1100 to 2498 nanometers (nm) in steps of 2 nm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cookies
cookies.desc.train
cookies.desc.test
cookies.y.train
cookies.y.test
</code></pre>


<h3>Format</h3>

<p>The cookies.desc.* datasets contains the 700 columns that correspond to the NIR reflectance spectrum.
The cookies.y.* datasets contains four columns that correspond to the four constituents fat, sucrose, dry flour, and water.
The cookies.*.train contains 40 rows that correspond to the calibration data.
The cookies.*.test contains 32 rows that correspond to the prediction data.
</p>


<h3>Source</h3>

<p>P. J. Brown and T. Fearn and M. Vannucci (2001) &quot;Bayesian wavelet regression on curves with applications to a spectroscopic calibration problem&quot;, Journal of the American Statistical Association, 96(454), pp. 398-408.
</p>


<h3>See Also</h3>

<p><code><a href="fds.html#topic+labp">labp</a></code>, <code><a href="fds.html#topic+labc">labc</a></code>, <code><a href="fds.html#topic+nirp">nirp</a></code>, <code><a href="fds.html#topic+nirc">nirc</a></code>
</p>

<hr>
<h2 id='cookplot'>Plot the Cook's distance of a linear regression model</h2><span id='topic+cookplot'></span>

<h3>Description</h3>

<p>Plot the Cook's distance of a linear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cookplot(model, index = NULL, labels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cookplot_+3A_model">model</code></td>
<td>
<p>The model to be plotted.</p>
</td></tr>
<tr><td><code id="cookplot_+3A_index">index</code></td>
<td>
<p>The index of the variable used for for the x-axis.</p>
</td></tr>
<tr><td><code id="cookplot_+3A_labels">labels</code></td>
<td>
<p>The labels of the instances.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
model = LINREG (trees [, -3], trees [, 3])
cookplot (model)
</code></pre>

<hr>
<h2 id='correlated'>Correlated variables</h2><span id='topic+correlated'></span>

<h3>Description</h3>

<p>Return the list of correlated variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>correlated(d, threshold = 0.8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="correlated_+3A_d">d</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="correlated_+3A_threshold">threshold</code></td>
<td>
<p>The threshold on the (absolute) Pearson coefficient. If NULL, return the most correlated variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The list of correlated variables (as a matrix of column names).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data (iris)
correlated (iris)
</code></pre>

<hr>
<h2 id='cost.curves'>Plot Cost Curves</h2><span id='topic+cost.curves'></span>

<h3>Description</h3>

<p>This function plots Cost Curves of several classification predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cost.curves(predictions, gt, methods.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cost.curves_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="cost.curves_+3A_gt">gt</code></td>
<td>
<p>Actual labels of the dataset (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="cost.curves_+3A_methods.names">methods.names</code></td>
<td>
<p>The name of the compared methods (<code>vector</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+roc.curves">roc.curves</a></code>, <code><a href="#topic+performance">performance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
model.nb = NB (d [, -5], d [, 5])
model.lda = LDA (d [, -5], d [, 5])
pred.nb = predict (model.nb, d [, -5])
pred.lda = predict (model.lda, d [, -5])
cost.curves (cbind (pred.nb, pred.lda), d [, 5], c ("NB", "LDA"))
</code></pre>

<hr>
<h2 id='credit'>Credit dataset</h2><span id='topic+credit'></span>

<h3>Description</h3>

<p>This is a fake dataset simulating a bank database about loan clients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>credit
</code></pre>


<h3>Format</h3>

<p>The dataset has 66 instances described by 11 qualitative variables.
</p>

<hr>
<h2 id='data.diag'>Square dataset</h2><span id='topic+data.diag'></span>

<h3>Description</h3>

<p>Generate a random dataset shaped like a square divided by a custom function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.diag(
  n = 200,
  min = 0,
  max = 1,
  f = function(x) x,
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.diag_+3A_n">n</code></td>
<td>
<p>Number of observations in the dataset.</p>
</td></tr>
<tr><td><code id="data.diag_+3A_min">min</code></td>
<td>
<p>Minimum value on each variables.</p>
</td></tr>
<tr><td><code id="data.diag_+3A_max">max</code></td>
<td>
<p>Maximum value on each variables.</p>
</td></tr>
<tr><td><code id="data.diag_+3A_f">f</code></td>
<td>
<p>The fucntion that separate the classes.</p>
</td></tr>
<tr><td><code id="data.diag_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.diag_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.diag_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.parabol">data.parabol</a></code>, <code><a href="#topic+data.target1">data.target1</a></code>, <code><a href="#topic+data.target2">data.target2</a></code>, <code><a href="#topic+data.twomoons">data.twomoons</a></code>, <code><a href="#topic+data.xor">data.xor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.diag ()
</code></pre>

<hr>
<h2 id='data.gauss'>Gaussian mixture dataset</h2><span id='topic+data.gauss'></span>

<h3>Description</h3>

<p>Generate a random multidimentional gaussian mixture.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.gauss(
  n = 1000,
  k = 2,
  prob = rep(1/k, k),
  mu = cbind(rep(0, k), seq(from = 0, by = 3, length.out = k)),
  cov = rep(list(matrix(c(6, 0.9, 0.9, 0.3), ncol = 2, nrow = 2)), k),
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.gauss_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_k">k</code></td>
<td>
<p>The number of classes.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_prob">prob</code></td>
<td>
<p>The a priori probability of each class.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_mu">mu</code></td>
<td>
<p>The means of the gaussian distributions.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_cov">cov</code></td>
<td>
<p>The covariance of the gaussian distributions.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.gauss_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.diag">data.diag</a></code>, <code><a href="#topic+data.parabol">data.parabol</a></code>, <code><a href="#topic+data.target2">data.target2</a></code>, <code><a href="#topic+data.twomoons">data.twomoons</a></code>, <code><a href="#topic+data.xor">data.xor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.gauss ()
</code></pre>

<hr>
<h2 id='data.parabol'>Parabol dataset</h2><span id='topic+data.parabol'></span>

<h3>Description</h3>

<p>Generate a random dataset shaped like a parabol and a gaussian distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.parabol(
  n = c(500, 100),
  xlim = c(-3, 3),
  center = c(0, 4),
  coeff = 0.5,
  sigma = c(0.5, 0.5),
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.parabol_+3A_n">n</code></td>
<td>
<p>Number of observations in each class.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_xlim">xlim</code></td>
<td>
<p>Minimum and maximum on the x axis.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_center">center</code></td>
<td>
<p>Coordinates of the center of the gaussian distribution.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_coeff">coeff</code></td>
<td>
<p>Coefficient of the parabol.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_sigma">sigma</code></td>
<td>
<p>Variance in each class.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.parabol_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.diag">data.diag</a></code>, <code><a href="#topic+data.target1">data.target1</a></code>, <code><a href="#topic+data.target2">data.target2</a></code>, <code><a href="#topic+data.twomoons">data.twomoons</a></code>, <code><a href="#topic+data.xor">data.xor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.parabol ()
</code></pre>

<hr>
<h2 id='data.target1'>Target1 dataset</h2><span id='topic+data.target1'></span>

<h3>Description</h3>

<p>Generate a random dataset shaped like a target.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.target1(
  r = 1:3,
  n = 200,
  sigma = 0.1,
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.target1_+3A_r">r</code></td>
<td>
<p>Radius of each class.</p>
</td></tr>
<tr><td><code id="data.target1_+3A_n">n</code></td>
<td>
<p>Number of observations in each class.</p>
</td></tr>
<tr><td><code id="data.target1_+3A_sigma">sigma</code></td>
<td>
<p>Variance in each class.</p>
</td></tr>
<tr><td><code id="data.target1_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.target1_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.target1_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.diag">data.diag</a></code>, <code><a href="#topic+data.parabol">data.parabol</a></code>, <code><a href="#topic+data.target2">data.target2</a></code>, <code><a href="#topic+data.twomoons">data.twomoons</a></code>, <code><a href="#topic+data.xor">data.xor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.target1 ()
</code></pre>

<hr>
<h2 id='data.target2'>Target2 dataset</h2><span id='topic+data.target2'></span>

<h3>Description</h3>

<p>Generate a random dataset shaped like a target.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.target2(
  minr = c(0, 2),
  maxr = minr + 1,
  initn = 1000,
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.target2_+3A_minr">minr</code></td>
<td>
<p>Minimum radius of each class.</p>
</td></tr>
<tr><td><code id="data.target2_+3A_maxr">maxr</code></td>
<td>
<p>Maximum radius of each class.</p>
</td></tr>
<tr><td><code id="data.target2_+3A_initn">initn</code></td>
<td>
<p>Number of observations at the beginning of the generation process.</p>
</td></tr>
<tr><td><code id="data.target2_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.target2_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.target2_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.diag">data.diag</a></code>, <code><a href="#topic+data.parabol">data.parabol</a></code>, <code><a href="#topic+data.target1">data.target1</a></code>, <code><a href="#topic+data.twomoons">data.twomoons</a></code>, <code><a href="#topic+data.xor">data.xor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.target2 ()
</code></pre>

<hr>
<h2 id='data.twomoons'>Two moons dataset</h2><span id='topic+data.twomoons'></span>

<h3>Description</h3>

<p>Generate a random dataset shaped like two moons.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.twomoons(
  r = 1,
  n = 200,
  sigma = 0.1,
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.twomoons_+3A_r">r</code></td>
<td>
<p>Radius of each class.</p>
</td></tr>
<tr><td><code id="data.twomoons_+3A_n">n</code></td>
<td>
<p>Number of observations in each class.</p>
</td></tr>
<tr><td><code id="data.twomoons_+3A_sigma">sigma</code></td>
<td>
<p>Variance in each class.</p>
</td></tr>
<tr><td><code id="data.twomoons_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.twomoons_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.twomoons_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.diag">data.diag</a></code>, <code><a href="#topic+data.parabol">data.parabol</a></code>, <code><a href="#topic+data.target1">data.target1</a></code>, <code><a href="#topic+data.target2">data.target2</a></code>, <code><a href="#topic+data.xor">data.xor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.twomoons ()
</code></pre>

<hr>
<h2 id='data.xor'>XOR dataset</h2><span id='topic+data.xor'></span>

<h3>Description</h3>

<p>Generate &quot;XOR&quot; dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.xor(
  n = 100,
  ndim = 2,
  sigma = 0.25,
  levels = NULL,
  graph = TRUE,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.xor_+3A_n">n</code></td>
<td>
<p>Number of observations in each cluster.</p>
</td></tr>
<tr><td><code id="data.xor_+3A_ndim">ndim</code></td>
<td>
<p>The number of dimensions (2^ndim clusters are formed, grouped into two classes).</p>
</td></tr>
<tr><td><code id="data.xor_+3A_sigma">sigma</code></td>
<td>
<p>The variance.</p>
</td></tr>
<tr><td><code id="data.xor_+3A_levels">levels</code></td>
<td>
<p>Name of each class.</p>
</td></tr>
<tr><td><code id="data.xor_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="data.xor_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A randomly generated dataset.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+data.diag">data.diag</a></code>, <code><a href="#topic+data.gauss">data.gauss</a></code>, <code><a href="#topic+data.parabol">data.parabol</a></code>, <code><a href="#topic+data.target2">data.target2</a></code>, <code><a href="#topic+data.twomoons">data.twomoons</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data.xor ()
</code></pre>

<hr>
<h2 id='data1'>&quot;data1&quot; dataset</h2><span id='topic+data1'></span>

<h3>Description</h3>

<p>Synthetic dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data1
</code></pre>


<h3>Format</h3>

<p>240 observations described by 4 variables and grouped into 16 classes.
</p>


<h3>Author(s)</h3>

<p>Alexandre BlanschÃ© <a href="mailto:alexandre.blansche@univ-lorraine.fr">alexandre.blansche@univ-lorraine.fr</a>
</p>

<hr>
<h2 id='data2'>&quot;data2&quot; dataset</h2><span id='topic+data2'></span>

<h3>Description</h3>

<p>Synthetic dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data2
</code></pre>


<h3>Format</h3>

<p>500 observations described by 10 variables and grouped into 3 classes.
</p>


<h3>Author(s)</h3>

<p>Alexandre BlanschÃ© <a href="mailto:alexandre.blansche@univ-lorraine.fr">alexandre.blansche@univ-lorraine.fr</a>
</p>

<hr>
<h2 id='data3'>&quot;data3&quot; dataset</h2><span id='topic+data3'></span>

<h3>Description</h3>

<p>Synthetic dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data3
</code></pre>


<h3>Format</h3>

<p>300 observations described by 3 variables and grouped into 3 classes.
</p>


<h3>Author(s)</h3>

<p>Alexandre BlanschÃ© <a href="mailto:alexandre.blansche@univ-lorraine.fr">alexandre.blansche@univ-lorraine.fr</a>
</p>

<hr>
<h2 id='dataset-class'>Training set and test set</h2><span id='topic+dataset-class'></span>

<h3>Description</h3>

<p>This class contains a dataset divided into four parts: the training set and test set, description and class labels.
</p>


<h3>Slots</h3>


<dl>
<dt><code>train.x</code></dt><dd><p>the training set (description), as a <code>data.frame</code> or a <code>matrix</code>.</p>
</dd>
<dt><code>train.y</code></dt><dd><p>the training set (target), as a <code>vector</code> or a <code>factor</code>.</p>
</dd>
<dt><code>test.x</code></dt><dd><p>the training set (description), as a <code>data.frame</code> or a <code>matrix</code>.</p>
</dd>
<dt><code>test.y</code></dt><dd><p>the training set (target), as a <code>vector</code> or a <code>factor</code>.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+splitdata">splitdata</a></code>
</p>

<hr>
<h2 id='dbs-class'>DBSCAN model</h2><span id='topic+dbs-class'></span>

<h3>Description</h3>

<p>This class contains the model obtained by the DBSCAN method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>cluster</code></dt><dd><p>A vector of integers indicating the cluster to which each point is allocated.</p>
</dd>
<dt><code>eps</code></dt><dd><p>Reachability distance (parameter).</p>
</dd>
<dt><code>MinPts</code></dt><dd><p>Reachability minimum no. of points (parameter).</p>
</dd>
<dt><code>isseed</code></dt><dd><p>A logical vector indicating whether a point is a seed (not border, not noise).</p>
</dd>
<dt><code>data</code></dt><dd><p>The dataset that has been used to fit the map (as a <code>matrix</code>).</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+DBSCAN">DBSCAN</a></code>
</p>

<hr>
<h2 id='DBSCAN'>DBSCAN clustering method</h2><span id='topic+DBSCAN'></span>

<h3>Description</h3>

<p>Run the DBSCAN algorithm for clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DBSCAN(d, minpts, epsilonDist, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DBSCAN_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="DBSCAN_+3A_minpts">minpts</code></td>
<td>
<p>Reachability minimum no. of points.</p>
</td></tr>
<tr><td><code id="DBSCAN_+3A_epsilondist">epsilonDist</code></td>
<td>
<p>Reachability distance.</p>
</td></tr>
<tr><td><code id="DBSCAN_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A clustering model obtained by DBSCAN.
</p>


<h3>See Also</h3>

<p><code><a href="fpc.html#topic+dbscan">dbscan</a></code>, <code><a href="#topic+dbs-class">dbs-class</a></code>, <code><a href="#topic+distplot">distplot</a></code>, <code><a href="#topic+predict.dbs">predict.dbs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
DBSCAN (iris [, -5], minpts = 5, epsilonDist = 1)
</code></pre>

<hr>
<h2 id='decathlon'>Decathlon dataset</h2><span id='topic+decathlon'></span>

<h3>Description</h3>

<p>The dataset contains results from two athletics competitions.
The 2004 Olympic Games in Athens and the 2004 Decastar.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>decathlon
</code></pre>


<h3>Format</h3>

<p>The dataset has 41 instances described by 13 variables.
The variables are as follows:
</p>

<dl>
<dt><code>100m</code></dt><dd><p>In seconds.</p>
</dd>
<dt><code>Long.jump</code></dt><dd><p>In meters.</p>
</dd>
<dt><code>Shot.put</code></dt><dd><p>In meters.</p>
</dd>
<dt><code>High.jump</code></dt><dd><p>In meters.</p>
</dd>
<dt><code>400m</code></dt><dd><p>In seconds.</p>
</dd>
<dt><code>110m.h</code></dt><dd><p>In seconds.</p>
</dd>
<dt><code>Discus.throw</code></dt><dd><p>In meters.</p>
</dd>
<dt><code>Pole.vault</code></dt><dd><p>In meters.</p>
</dd>
<dt><code>Javelin.throw</code></dt><dd><p>In meters.</p>
</dd>
<dt><code>1500m</code></dt><dd><p>In seconds.</p>
</dd>
<dt><code>Rank</code></dt><dd><p>The rank at the competition.</p>
</dd>
<dt><code>Points</code></dt><dd><p>The number of points obtained by the athlete.</p>
</dd>
<dt><code>Competition</code></dt><dd><p><code>Olympics</code> or <code>Decastar</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://husson.github.io/data.html">https://husson.github.io/data.html</a>
</p>

<hr>
<h2 id='distplot'>Plot a k-distance graphic</h2><span id='topic+distplot'></span>

<h3>Description</h3>

<p>Plot the distance to the k's nearest neighbours of each object in decreasing order. Mostly used to determine the <code>eps</code> parameter for the <code><a href="fpc.html#topic+dbscan">dbscan</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distplot(k, d, h = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distplot_+3A_k">k</code></td>
<td>
<p>The <code>k</code> parameter.</p>
</td></tr>
<tr><td><code id="distplot_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="distplot_+3A_h">h</code></td>
<td>
<p>The y-coordinate at which a horizontal line should be drawn.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+DBSCAN">DBSCAN</a></code>, <code><a href="fpc.html#topic+dbscan">dbscan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
distplot (5, iris [, -5], h = .65)
</code></pre>

<hr>
<h2 id='EM'>Expectation-Maximization clustering method</h2><span id='topic+EM'></span>

<h3>Description</h3>

<p>Run the EM algorithm for clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EM(d, clusters, model = "VVV", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EM_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="EM_+3A_clusters">clusters</code></td>
<td>
<p>Either an integer (the number of clusters) or a (<code>vector</code>) indicating the cluster to which each point is initially allocated.</p>
</td></tr>
<tr><td><code id="EM_+3A_model">model</code></td>
<td>
<p>A character string indicating the model. The help file for <code><a href="mclust.html#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.</p>
</td></tr>
<tr><td><code id="EM_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A clustering model obtained by EM.
</p>


<h3>See Also</h3>

<p><code><a href="mclust.html#topic+em">em</a></code>, <code><a href="mclust.html#topic+mstep">mstep</a></code>, <code><a href="mclust.html#topic+mclustModelNames">mclustModelNames</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
EM (iris [, -5], 3) # Default initialization
km = KMEANS (iris [, -5], k = 3)
EM (iris [, -5], km$cluster) # Initialization with another clustering method
</code></pre>

<hr>
<h2 id='em-class'>Expectation-Maximization model</h2><span id='topic+em-class'></span>

<h3>Description</h3>

<p>This class contains the model obtained by the EM method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>modelName</code></dt><dd><p>A character string indicating the model. The help file for <code><a href="mclust.html#topic+mclustModelNames">mclustModelNames</a></code> describes the available models.</p>
</dd>
<dt><code>prior</code></dt><dd><p>Specification of a conjugate prior on the means and variances.</p>
</dd>
<dt><code>n</code></dt><dd><p>The number of observations in the dataset.</p>
</dd>
<dt><code>d</code></dt><dd><p>The number of variables in the dataset.</p>
</dd>
<dt><code>G</code></dt><dd><p>The number of components of the mixture.</p>
</dd>
<dt><code>z</code></dt><dd><p>A matrix whose <code>[i,k]</code>th entry is the conditional probability of the ith observation belonging to the kth component of the mixture.</p>
</dd>
<dt><code>parameters</code></dt><dd><p>A names list giving the parameters of the model.</p>
</dd>
<dt><code>control</code></dt><dd><p>A list of control parameters for EM.</p>
</dd>
<dt><code>loglik</code></dt><dd><p>The log likelihood for the data in the mixture model.</p>
</dd>
<dt><code>cluster</code></dt><dd><p>A vector of integers (from <code>1:k</code>) indicating the cluster to which each point is allocated.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+EM">EM</a></code>, <code><a href="mclust.html#topic+mclustModelNames">mclustModelNames</a></code>
</p>

<hr>
<h2 id='eucalyptus'>Eucalyptus dataset</h2><span id='topic+eucalyptus'></span>

<h3>Description</h3>

<p>Measuring the height of a tree is not an easy task. Is it possible to estimate the height as a function of the circumference of the trunk?
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eucalyptus
</code></pre>


<h3>Format</h3>

<p>The dataset has 1429 instances (eucalyptus trees) with 2 measurements: the height and the circumference.
</p>


<h3>Source</h3>

<p><a href="http://www.cmap.polytechnique.fr/~lepennec/fr/teaching/">http://www.cmap.polytechnique.fr/~lepennec/fr/teaching/</a>
</p>

<hr>
<h2 id='evaluation'>Evaluation of classification or regression predictions</h2><span id='topic+evaluation'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification or a regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation(
  predictions,
  gt,
  eval = ifelse(is.factor(gt), "accuracy", "r2"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation_+3A_gt">gt</code></td>
<td>
<p>The ground truth of the dataset (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation_+3A_eval">eval</code></td>
<td>
<p>The evaluation method.</p>
</td></tr>
<tr><td><code id="evaluation_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion</a></code>, <code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation.msep">evaluation.msep</a></code>, <code><a href="#topic+evaluation.r2">evaluation.r2</a></code>, <code><a href="#topic+performance">performance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
# Default evaluation for classification
evaluation (pred.nb, d$test.y)
# Evaluation with two criteria
evaluation (pred.nb, d$test.y, eval = c ("accuracy", "kappa"))
data (trees)
d = splitdata (trees, 3)
model.linreg = LINREG (d$train.x, d$train.y)
pred.linreg = predict (model.linreg, d$test.x)
# Default evaluation for regression
evaluation (pred.linreg, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.accuracy'>Accuracy of classification predictions</h2><span id='topic+evaluation.accuracy'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.accuracy(predictions, gt, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.accuracy_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.accuracy_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.accuracy_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>, <code><a href="#topic+evaluation.precision">evaluation.precision</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.accuracy (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.adjr2'>Adjusted R2 evaluation of regression predictions</h2><span id='topic+evaluation.adjr2'></span>

<h3>Description</h3>

<p>Evaluation predictions of a regression model according to R2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.adjr2(predictions, gt, nrow = length(predictions), ncol, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.adjr2_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a regression model (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.adjr2_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.adjr2_+3A_nrow">nrow</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="evaluation.adjr2_+3A_ncol">ncol</code></td>
<td>
<p>Number of variables</p>
</td></tr>
<tr><td><code id="evaluation.adjr2_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.msep">evaluation.msep</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
d = splitdata (trees, 3)
model.linreg = LINREG (d$train.x, d$train.y)
pred.linreg = predict (model.linreg, d$test.x)
evaluation.r2 (pred.linreg, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.fmeasure'>F-measure</h2><span id='topic+evaluation.fmeasure'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to the F-measure index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.fmeasure(predictions, gt, beta = 1, positive = levels(gt)[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.fmeasure_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.fmeasure_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.fmeasure_+3A_beta">beta</code></td>
<td>
<p>The weight given to precision.</p>
</td></tr>
<tr><td><code id="evaluation.fmeasure_+3A_positive">positive</code></td>
<td>
<p>The label of the positive class.</p>
</td></tr>
<tr><td><code id="evaluation.fmeasure_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>, <code><a href="#topic+evaluation.precision">evaluation.precision</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
d = splitdata (d, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.fmeasure (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.fowlkesmallows'>Fowlkesâ€“Mallows index</h2><span id='topic+evaluation.fowlkesmallows'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to the Fowlkesâ€“Mallows index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.fowlkesmallows(predictions, gt, positive = levels(gt)[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.fowlkesmallows_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.fowlkesmallows_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.fowlkesmallows_+3A_positive">positive</code></td>
<td>
<p>The label of the positive class.</p>
</td></tr>
<tr><td><code id="evaluation.fowlkesmallows_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>, <code><a href="#topic+evaluation.precision">evaluation.precision</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
d = splitdata (d, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.fowlkesmallows (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.goodness'>Goodness</h2><span id='topic+evaluation.goodness'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to Goodness index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.goodness(predictions, gt, beta = 1, positive = levels(gt)[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.goodness_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.goodness_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.goodness_+3A_beta">beta</code></td>
<td>
<p>The weight given to precision.</p>
</td></tr>
<tr><td><code id="evaluation.goodness_+3A_positive">positive</code></td>
<td>
<p>The label of the positive class.</p>
</td></tr>
<tr><td><code id="evaluation.goodness_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>, <code><a href="#topic+evaluation.precision">evaluation.precision</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
d = splitdata (d, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.goodness (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.jaccard'>Jaccard index</h2><span id='topic+evaluation.jaccard'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to Jaccard index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.jaccard(predictions, gt, positive = levels(gt)[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.jaccard_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.jaccard_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.jaccard_+3A_positive">positive</code></td>
<td>
<p>The label of the positive class.</p>
</td></tr>
<tr><td><code id="evaluation.jaccard_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>, <code><a href="#topic+evaluation.precision">evaluation.precision</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
d = splitdata (d, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.jaccard (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.kappa'>Kappa evaluation of classification predictions</h2><span id='topic+evaluation.kappa'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to kappa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.kappa(predictions, gt, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.kappa_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.kappa_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.kappa_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>, <code><a href="#topic+evaluation.precision">evaluation.precision</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.kappa (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.msep'>MSEP evaluation of regression predictions</h2><span id='topic+evaluation.msep'></span>

<h3>Description</h3>

<p>Evaluation predictions of a regression model according to MSEP
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.msep(predictions, gt, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.msep_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a regression model (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.msep_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.msep_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.r2">evaluation.r2</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
d = splitdata (trees, 3)
model.lin = LINREG (d$train.x, d$train.y)
pred.lin = predict (model.lin, d$test.x)
evaluation.msep (pred.lin, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.precision'>Precision of classification predictions</h2><span id='topic+evaluation.precision'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to precision. Works only for two classes problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.precision(predictions, gt, positive = levels(gt)[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.precision_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.precision_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.precision_+3A_positive">positive</code></td>
<td>
<p>The label of the positive class.</p>
</td></tr>
<tr><td><code id="evaluation.precision_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>,
<code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,<code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
d = splitdata (d, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.precision (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.r2'>R2 evaluation of regression predictions</h2><span id='topic+evaluation.r2'></span>

<h3>Description</h3>

<p>Evaluation predictions of a regression model according to R2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.r2(predictions, gt, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.r2_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a regression model (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.r2_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.r2_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.msep">evaluation.msep</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
d = splitdata (trees, 3)
model.linreg = LINREG (d$train.x, d$train.y)
pred.linreg = predict (model.linreg, d$test.x)
evaluation.r2 (pred.linreg, d$test.y)
</code></pre>

<hr>
<h2 id='evaluation.recall'>Recall of classification predictions</h2><span id='topic+evaluation.recall'></span>

<h3>Description</h3>

<p>Evaluation predictions of a classification model according to recall. Works only for two classes problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaluation.recall(predictions, gt, positive = levels(gt)[1], ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaluation.recall_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.recall_+3A_gt">gt</code></td>
<td>
<p>The ground truth (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="evaluation.recall_+3A_positive">positive</code></td>
<td>
<p>The label of the positive class.</p>
</td></tr>
<tr><td><code id="evaluation.recall_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
d = splitdata (d, 5)
model.nb = NB (d$train.x, d$train.y)
pred.nb = predict (model.nb, d$test.x)
evaluation.recall (pred.nb, d$test.y)
</code></pre>

<hr>
<h2 id='exportgraphics'>Open a graphics device</h2><span id='topic+exportgraphics'></span>

<h3>Description</h3>

<p>Starts the graphics device driver
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exportgraphics(file, type = tail(strsplit(file, split = "\\.")[[1]], 1), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exportgraphics_+3A_file">file</code></td>
<td>
<p>A character string giving the name of the file.</p>
</td></tr>
<tr><td><code id="exportgraphics_+3A_type">type</code></td>
<td>
<p>The type of graphics device.</p>
</td></tr>
<tr><td><code id="exportgraphics_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+closegraphics">closegraphics</a></code>, <code><a href="#topic+toggleexport">toggleexport</a></code>, <code><a href="grDevices.html#topic+Devices">Devices</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data (iris)
exportgraphics ("export.pdf")
plotdata (iris [, -5], iris [, 5])
closegraphics()

## End(Not run)
</code></pre>

<hr>
<h2 id='exportgraphics.off'>Toggle graphic exports</h2><span id='topic+exportgraphics.off'></span><span id='topic+exportgraphics.on'></span><span id='topic+toggleexport'></span><span id='topic+toggleexport.off'></span><span id='topic+toggleexport.on'></span>

<h3>Description</h3>

<p>Toggle graphic exports on and off
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exportgraphics.off()

exportgraphics.on()

toggleexport(export = NULL)

toggleexport.off()

toggleexport.on()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exportgraphics.off_+3A_export">export</code></td>
<td>
<p>If <code>TRUE</code>, exports are activated, if <code>FALSE</code>, exports are deactivated. If <code>null</code>, switches on and off.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+closegraphics">closegraphics</a></code>, <code><a href="#topic+exportgraphics">exportgraphics</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data (iris)
toggleexport (FALSE)
exportgraphics ("export.pdf")
plotdata (iris [, -5], iris [, 5])
closegraphics()
toggleexport (TRUE)
exportgraphics ("export.pdf")
plotdata (iris [, -5], iris [, 5])
closegraphics()

## End(Not run)
</code></pre>

<hr>
<h2 id='factorial-class'>Factorial analysis results</h2><span id='topic+factorial-class'></span>

<h3>Description</h3>

<p>This class contains the classification model obtained by the CDA method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CA">CA</a></code>, <code><a href="#topic+MCA">MCA</a></code>, <code><a href="#topic+PCA">PCA</a></code>, <code><a href="#topic+plot.factorial">plot.factorial</a></code>
</p>

<hr>
<h2 id='FEATURESELECTION'>Classification with Feature selection</h2><span id='topic+FEATURESELECTION'></span>

<h3>Description</h3>

<p>Apply a classification method after a subset of features has been selected.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FEATURESELECTION(
  train,
  labels,
  algorithm = c("ranking", "forward", "backward", "exhaustive"),
  unieval = if (algorithm[1] == "ranking") c("fisher", "fstat", "relief", "inertiaratio")
    else NULL,
  uninb = NULL,
  unithreshold = NULL,
  multieval = if (algorithm[1] == "ranking") NULL else c("cfs", "fstat", "inertiaratio",
    "wrapper"),
  wrapmethod = NULL,
  mainmethod = wrapmethod,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FEATURESELECTION_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_algorithm">algorithm</code></td>
<td>
<p>The feature selection algorithm.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_unieval">unieval</code></td>
<td>
<p>The (univariate) evaluation criterion. <code>uninb</code>, <code>unithreshold</code> or <code>multieval</code> must be specified.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_uninb">uninb</code></td>
<td>
<p>The number of selected feature (univariate evaluation).</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_unithreshold">unithreshold</code></td>
<td>
<p>The threshold for selecting feature (univariate evaluation).</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_multieval">multieval</code></td>
<td>
<p>The (multivariate) evaluation criterion.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_wrapmethod">wrapmethod</code></td>
<td>
<p>The classification method used for the wrapper evaluation.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_mainmethod">mainmethod</code></td>
<td>
<p>The final method used for data classification. If a wrapper evaluation is used, the same classification method should be used.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="FEATURESELECTION_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+selectfeatures">selectfeatures</a></code>, <code><a href="#topic+predict.selection">predict.selection</a></code>, <code><a href="#topic+selection-class">selection-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
FEATURESELECTION (iris [, -5], iris [, 5], uninb = 2, mainmethod = LDA)

## End(Not run)
</code></pre>

<hr>
<h2 id='filter.rules'>Filtering a set of rules</h2><span id='topic+filter.rules'></span>

<h3>Description</h3>

<p>This function facilitate the selection of a subset from a set of rules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>filter.rules(
  rules,
  pattern = NULL,
  left = pattern,
  right = pattern,
  removeMatches = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="filter.rules_+3A_rules">rules</code></td>
<td>
<p>A set of rules.</p>
</td></tr>
<tr><td><code id="filter.rules_+3A_pattern">pattern</code></td>
<td>
<p>A pattern to match (antecedent and consequent): a character string.</p>
</td></tr>
<tr><td><code id="filter.rules_+3A_left">left</code></td>
<td>
<p>A pattern to match (antecedent only): a character string.</p>
</td></tr>
<tr><td><code id="filter.rules_+3A_right">right</code></td>
<td>
<p>A pattern to match (consequent only): a character string.</p>
</td></tr>
<tr><td><code id="filter.rules_+3A_removematches">removeMatches</code></td>
<td>
<p>A logical indicating whether to remove matching rules (<code>TRUE</code>) or to keep those (<code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The filtered set of rules.
</p>


<h3>See Also</h3>

<p><code><a href="arules.html#topic+apriori">apriori</a></code>, <code><a href="arules.html#topic+subset">subset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("arules")
data ("Adult")
r = apriori (Adult)
filter.rules (r, right = "marital-status=")
subset (r, subset = rhs %pin% "marital-status=")
</code></pre>

<hr>
<h2 id='frequentwords'>Frequent words</h2><span id='topic+frequentwords'></span>

<h3>Description</h3>

<p>Most frequent words of the corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>frequentwords(
  corpus,
  nb,
  mincount = 5,
  minphrasecount = NULL,
  ngram = 1,
  lang = "en",
  stopwords = lang
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="frequentwords_+3A_corpus">corpus</code></td>
<td>
<p>The corpus of documents (a vector of characters) or the vocabulary of the documents (result of function <code>getvocab</code>).</p>
</td></tr>
<tr><td><code id="frequentwords_+3A_nb">nb</code></td>
<td>
<p>The number of words to be returned.</p>
</td></tr>
<tr><td><code id="frequentwords_+3A_mincount">mincount</code></td>
<td>
<p>Minimum word count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="frequentwords_+3A_minphrasecount">minphrasecount</code></td>
<td>
<p>Minimum collocation of words count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="frequentwords_+3A_ngram">ngram</code></td>
<td>
<p>maximum size of n-grams.</p>
</td></tr>
<tr><td><code id="frequentwords_+3A_lang">lang</code></td>
<td>
<p>The language of the documents (NULL if no stemming).</p>
</td></tr>
<tr><td><code id="frequentwords_+3A_stopwords">stopwords</code></td>
<td>
<p>Stopwords, or the language of the documents. NULL if stop words should not be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The most frequent words of the corpus.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+getvocab">getvocab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
frequentwords (text, 100)
vocab = getvocab (text)
frequentwords (vocab, 100)

## End(Not run)
</code></pre>

<hr>
<h2 id='general.rules'>Remove redundancy in a set of rules</h2><span id='topic+general.rules'></span>

<h3>Description</h3>

<p>This function remove every redundant rules, keeping only the most general ones.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>general.rules(r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="general.rules_+3A_r">r</code></td>
<td>
<p>A set of rules.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A set of rules, without redundancy.
</p>


<h3>See Also</h3>

<p><code><a href="arules.html#topic+apriori">apriori</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("arules")
data ("Adult")
r = apriori (Adult)
inspect (general.rules (r))
</code></pre>

<hr>
<h2 id='getvocab'>Extract words and phrases from a corpus</h2><span id='topic+getvocab'></span>

<h3>Description</h3>

<p>Extract words and phrases from a corpus of documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getvocab(
  corpus,
  mincount = 5,
  minphrasecount = NULL,
  ngram = 1,
  lang = "en",
  stopwords = lang,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getvocab_+3A_corpus">corpus</code></td>
<td>
<p>The corpus of documents (a vector of characters).</p>
</td></tr>
<tr><td><code id="getvocab_+3A_mincount">mincount</code></td>
<td>
<p>Minimum word count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="getvocab_+3A_minphrasecount">minphrasecount</code></td>
<td>
<p>Minimum collocation of words count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="getvocab_+3A_ngram">ngram</code></td>
<td>
<p>maximum size of n-grams.</p>
</td></tr>
<tr><td><code id="getvocab_+3A_lang">lang</code></td>
<td>
<p>The language of the documents (NULL if no stemming).</p>
</td></tr>
<tr><td><code id="getvocab_+3A_stopwords">stopwords</code></td>
<td>
<p>Stopwords, or the language of the documents. NULL if stop words should not be removed.</p>
</td></tr>
<tr><td><code id="getvocab_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vocabulary used in the corpus of documents.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plotzipf">plotzipf</a></code>, <code><a href="stopwords.html#topic+stopwords">stopwords</a></code>, <code><a href="text2vec.html#topic+create_vocabulary">create_vocabulary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
vocab1 = getvocab (text) # With stemming
nrow (vocab1)
vocab2 = getvocab (text, lang = NULL) # Without stemming
nrow (vocab2)

## End(Not run)
</code></pre>

<hr>
<h2 id='GRADIENTBOOSTING'>Classification using Gradient Boosting</h2><span id='topic+GRADIENTBOOSTING'></span>

<h3>Description</h3>

<p>This function builds a classification model using Gradient Boosting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GRADIENTBOOSTING(
  train,
  labels,
  ntree = 500,
  learningrate = 0.3,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GRADIENTBOOSTING_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="GRADIENTBOOSTING_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="GRADIENTBOOSTING_+3A_ntree">ntree</code></td>
<td>
<p>The number of trees in the forest.</p>
</td></tr>
<tr><td><code id="GRADIENTBOOSTING_+3A_learningrate">learningrate</code></td>
<td>
<p>The learning rate (between 0 and 1).</p>
</td></tr>
<tr><td><code id="GRADIENTBOOSTING_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="GRADIENTBOOSTING_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="xgboost.html#topic+xgboost">xgboost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
GRADIENTBOOSTING (iris [, -5], iris [, 5])

## End(Not run)
</code></pre>

<hr>
<h2 id='HCA'>Hierarchical Cluster Analysis method</h2><span id='topic+HCA'></span>

<h3>Description</h3>

<p>Run the HCA method for clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HCA(d, method = c("ward", "single"), k = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HCA_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="HCA_+3A_method">method</code></td>
<td>
<p>Character string defining the clustering method.</p>
</td></tr>
<tr><td><code id="HCA_+3A_k">k</code></td>
<td>
<p>The number of cluster.</p>
</td></tr>
<tr><td><code id="HCA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The cluster hierarchy (<code>hca</code> object).
</p>


<h3>See Also</h3>

<p><code><a href="cluster.html#topic+agnes">agnes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
HCA (iris [, -5], method = "ward", k = 3)
</code></pre>

<hr>
<h2 id='intern'>Clustering evaluation through internal criteria</h2><span id='topic+intern'></span>

<h3>Description</h3>

<p>Evaluation a clustering algorithm according to internal criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intern(clus, d, eval = "intraclass", type = c("global", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intern_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="intern_+3A_d">d</code></td>
<td>
<p>The dataset.</p>
</td></tr>
<tr><td><code id="intern_+3A_eval">eval</code></td>
<td>
<p>The evaluation criteria.</p>
</td></tr>
<tr><td><code id="intern_+3A_type">type</code></td>
<td>
<p>Indicates whether a &quot;global&quot; or a &quot;cluster&quot;-wise evaluation should be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the clustering.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare">compare</a></code>, <code><a href="#topic+stability">stability</a></code>, <code><a href="#topic+intern.dunn">intern.dunn</a></code>, <code><a href="#topic+intern.interclass">intern.interclass</a></code>, <code><a href="#topic+intern.intraclass">intern.intraclass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
intern (km$clus, iris [, -5])
intern (km$clus, iris [, -5], type = "cluster")
intern (km$clus, iris [, -5], eval = c ("intraclass", "interclass"))
intern (km$clus, iris [, -5], eval = c ("intraclass", "interclass"), type = "cluster")
</code></pre>

<hr>
<h2 id='intern.dunn'>Clustering evaluation through Dunn's index</h2><span id='topic+intern.dunn'></span>

<h3>Description</h3>

<p>Evaluation a clustering algorithm according to Dunn's index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intern.dunn(clus, d, type = c("global"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intern.dunn_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="intern.dunn_+3A_d">d</code></td>
<td>
<p>The dataset.</p>
</td></tr>
<tr><td><code id="intern.dunn_+3A_type">type</code></td>
<td>
<p>Indicates whether a &quot;global&quot; or a &quot;cluster&quot;-wise evaluation should be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the clustering.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+intern">intern</a></code>, <code><a href="#topic+intern.interclass">intern.interclass</a></code>, <code><a href="#topic+intern.intraclass">intern.intraclass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
intern.dunn (km$clus, iris [, -5])
</code></pre>

<hr>
<h2 id='intern.interclass'>Clustering evaluation through interclass inertia</h2><span id='topic+intern.interclass'></span>

<h3>Description</h3>

<p>Evaluation a clustering algorithm according to interclass inertia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intern.interclass(clus, d, type = c("global", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intern.interclass_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="intern.interclass_+3A_d">d</code></td>
<td>
<p>The dataset.</p>
</td></tr>
<tr><td><code id="intern.interclass_+3A_type">type</code></td>
<td>
<p>Indicates whether a &quot;global&quot; or a &quot;cluster&quot;-wise evaluation should be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the clustering.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+intern">intern</a></code>, <code><a href="#topic+intern.dunn">intern.dunn</a></code>, <code><a href="#topic+intern.intraclass">intern.intraclass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
intern.interclass (km$clus, iris [, -5])
</code></pre>

<hr>
<h2 id='intern.intraclass'>Clustering evaluation through intraclass inertia</h2><span id='topic+intern.intraclass'></span>

<h3>Description</h3>

<p>Evaluation a clustering algorithm according to intraclass inertia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>intern.intraclass(clus, d, type = c("global", "cluster"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="intern.intraclass_+3A_clus">clus</code></td>
<td>
<p>The extracted clusters.</p>
</td></tr>
<tr><td><code id="intern.intraclass_+3A_d">d</code></td>
<td>
<p>The dataset.</p>
</td></tr>
<tr><td><code id="intern.intraclass_+3A_type">type</code></td>
<td>
<p>Indicates whether a &quot;global&quot; or a &quot;cluster&quot;-wise evaluation should be used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the clustering.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+intern">intern</a></code>, <code><a href="#topic+intern.dunn">intern.dunn</a></code>, <code><a href="#topic+intern.interclass">intern.interclass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
intern.intraclass (km$clus, iris [, -5])
</code></pre>

<hr>
<h2 id='ionosphere'>Ionosphere dataset</h2><span id='topic+ionosphere'></span>

<h3>Description</h3>

<p>This is a dataset from the UCI repository.
This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. &quot;Good&quot; radar returns are those showing evidence of some type of structure in the ionosphere. &quot;Bad&quot; returns are those that do not; their signals pass through the ionosphere.
Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.
One attribute with constant value has been removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ionosphere
</code></pre>


<h3>Format</h3>

<p>The dataset has 351 instances described by 34. The last variable is the class.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/ionosphere">https://archive.ics.uci.edu/ml/datasets/ionosphere</a>
</p>

<hr>
<h2 id='kaiser'>Kaiser rule</h2><span id='topic+kaiser'></span>

<h3>Description</h3>

<p>Apply the Kaiser rule to determine the appropriate number of PCA axes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kaiser(pca)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kaiser_+3A_pca">pca</code></td>
<td>
<p>The PCA result (object of class <code>factorial-class</code>).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+PCA">PCA</a></code>, <code><a href="#topic+factorial-class">factorial-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
pca = PCA (iris, quali.sup = 5)
kaiser (pca)
</code></pre>

<hr>
<h2 id='KERREG'>Kernel Regression</h2><span id='topic+KERREG'></span>

<h3>Description</h3>

<p>This function builds a kernel regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KERREG(x, y, bandwidth = 1, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KERREG_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="KERREG_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="KERREG_+3A_bandwidth">bandwidth</code></td>
<td>
<p>The bandwidth parameter.</p>
</td></tr>
<tr><td><code id="KERREG_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="KERREG_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model, as an object of class <code><a href="#topic+model-class">model-class</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="ibr.html#topic+npregress">npregress</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
KERREG (trees [, -3], trees [, 3])
</code></pre>

<hr>
<h2 id='KMEANS'>K-means method</h2><span id='topic+KMEANS'></span>

<h3>Description</h3>

<p>Run K-means for clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KMEANS(
  d,
  k = 9,
  criterion = c("none", "pseudo-F"),
  graph = FALSE,
  nstart = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KMEANS_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="KMEANS_+3A_k">k</code></td>
<td>
<p>The number of cluster.</p>
</td></tr>
<tr><td><code id="KMEANS_+3A_criterion">criterion</code></td>
<td>
<p>The criterion for cluster number selection. If <code>none</code>, <code>k</code> is used, if not the number of cluster is selected between 2 and <code>k</code>.</p>
</td></tr>
<tr><td><code id="KMEANS_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted (cluster number selection).</p>
</td></tr>
<tr><td><code id="KMEANS_+3A_nstart">nstart</code></td>
<td>
<p>Define how many random sets should be chosen.</p>
</td></tr>
<tr><td><code id="KMEANS_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The clustering (<code>kmeans</code> object).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+kmeans">kmeans</a></code>, <code><a href="#topic+predict.kmeans">predict.kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
KMEANS (iris [, -5], k = 3)
KMEANS (iris [, -5], criterion = "pseudo-F") # With automatic detection of the nmber of clusters
</code></pre>

<hr>
<h2 id='kmeans.getk'>Estimation of the number of clusters for <em>K</em>-means</h2><span id='topic+kmeans.getk'></span>

<h3>Description</h3>

<p>Estimate the optimal number of cluster of the <em>K</em>-means clustering method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kmeans.getk(
  d,
  max = 9,
  criterion = "pseudo-F",
  graph = TRUE,
  nstart = 10,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kmeans.getk_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="kmeans.getk_+3A_max">max</code></td>
<td>
<p>The maximum number of clusters. Values from 2 to <code>max</code> are evaluated.</p>
</td></tr>
<tr><td><code id="kmeans.getk_+3A_criterion">criterion</code></td>
<td>
<p>The criterion to be optimized. <code>"pseudo-F"</code> is the only criterion implemented in the current version.</p>
</td></tr>
<tr><td><code id="kmeans.getk_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted.</p>
</td></tr>
<tr><td><code id="kmeans.getk_+3A_nstart">nstart</code></td>
<td>
<p>The number of random sets chosen for <code><a href="stats.html#topic+kmeans">kmeans</a></code> initialization.</p>
</td></tr>
<tr><td><code id="kmeans.getk_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The optimal number of cluster of the <em>K</em>-means clustering method according to the chosen criterion.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pseudoF">pseudoF</a></code>, <code><a href="stats.html#topic+kmeans">kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
kmeans.getk (iris [, -5])
</code></pre>

<hr>
<h2 id='KNN'>Classification using k-NN</h2><span id='topic+KNN'></span>

<h3>Description</h3>

<p>This function builds a classification model using Logistic Regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KNN(train, labels, k = 1:10, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="KNN_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="KNN_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="KNN_+3A_k">k</code></td>
<td>
<p>The k parameter.</p>
</td></tr>
<tr><td><code id="KNN_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="KNN_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="class.html#topic+knn">knn</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
KNN (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='knn-class'>K Nearest Neighbours model</h2><span id='topic+knn-class'></span>

<h3>Description</h3>

<p>This class contains the classification model obtained by the k-NN method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>train</code></dt><dd><p>The training set (description). A <code>data.frame</code>.</p>
</dd>
<dt><code>labels</code></dt><dd><p>Class labels of the training set. Either a <code>factor</code> or an integer <code>vector</code>.</p>
</dd>
<dt><code>k</code></dt><dd><p>The <code>k</code> parameter.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+KNN">KNN</a></code>, <code><a href="#topic+predict.knn">predict.knn</a></code>
</p>

<hr>
<h2 id='LDA'>Classification using Linear Discriminant Analysis</h2><span id='topic+LDA'></span>

<h3>Description</h3>

<p>This function builds a classification model using Linear Discriminant Analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LDA(train, labels, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LDA_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="LDA_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="LDA_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="LDA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+lda">lda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
LDA (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='leverageplot'>Plot the leverage points of a linear regression model</h2><span id='topic+leverageplot'></span>

<h3>Description</h3>

<p>Plot the leverage points of a linear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>leverageplot(model, index = NULL, labels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="leverageplot_+3A_model">model</code></td>
<td>
<p>The model to be plotted.</p>
</td></tr>
<tr><td><code id="leverageplot_+3A_index">index</code></td>
<td>
<p>The index of the variable used for for the x-axis.</p>
</td></tr>
<tr><td><code id="leverageplot_+3A_labels">labels</code></td>
<td>
<p>The labels of the instances.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
model = LINREG (trees [, -3], trees [, 3])
leverageplot (model)
</code></pre>

<hr>
<h2 id='LINREG'>Linear Regression</h2><span id='topic+LINREG'></span>

<h3>Description</h3>

<p>This function builds a linear regression model.
Standard least square method, variable selection, factorial methods are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LINREG(
  x,
  y,
  quali = c("none", "intercept", "slope", "both"),
  reg = c("linear", "subset", "ridge", "lasso", "elastic", "pcr", "plsr"),
  regeval = c("r2", "bic", "adjr2", "cp", "msep"),
  scale = TRUE,
  lambda = 10^seq(-5, 5, length.out = 101),
  alpha = 0.5,
  graph = TRUE,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LINREG_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_quali">quali</code></td>
<td>
<p>Indicates how to use the qualitative variables.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_reg">reg</code></td>
<td>
<p>The algorithm.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_regeval">regeval</code></td>
<td>
<p>The evaluation criterion for subset selection.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_scale">scale</code></td>
<td>
<p>If true, PCR and PLS use scaled dataset.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_lambda">lambda</code></td>
<td>
<p>The lambda parameter of Ridge, Lasso and Elastic net regression.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_alpha">alpha</code></td>
<td>
<p>The elasticnet mixing parameter.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not graphics should be plotted (ridge, LASSO and elastic net).</p>
</td></tr>
<tr><td><code id="LINREG_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="LINREG_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model, as an object of class <code><a href="#topic+model-class">model-class</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="leaps.html#topic+regsubsets">regsubsets</a></code>, <code><a href="pls.html#topic+mvr">mvr</a></code>, <code><a href="glmnet.html#topic+glmnet">glmnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
# With one independant variable
data (cars)
LINREG (cars [, -2], cars [, 2])
# With two independant variables
data (trees)
LINREG (trees [, -3], trees [, 3])
# With non numeric variables
data (ToothGrowth)
LINREG (ToothGrowth [, -1], ToothGrowth [, 1], quali = "intercept") # Different intersept
LINREG (ToothGrowth [, -1], ToothGrowth [, 1], quali = "slope") # Different slope
LINREG (ToothGrowth [, -1], ToothGrowth [, 1], quali = "both") # Complete model
# With multiple numeric variables
data (mtcars)
LINREG (mtcars [, -1], mtcars [, 1])
LINREG (mtcars [, -1], mtcars [, 1], reg = "subset", regeval = "adjr2")
LINREG (mtcars [, -1], mtcars [, 1], reg = "ridge")
LINREG (mtcars [, -1], mtcars [, 1], reg = "lasso")
LINREG (mtcars [, -1], mtcars [, 1], reg = "elastic")
LINREG (mtcars [, -1], mtcars [, 1], reg = "pcr")
LINREG (mtcars [, -1], mtcars [, 1], reg = "plsr")

## End(Not run)
</code></pre>

<hr>
<h2 id='linsep'>Linsep dataset</h2><span id='topic+linsep'></span>

<h3>Description</h3>

<p>Synthetic dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>linsep
</code></pre>


<h3>Format</h3>

<p>Class <code>A</code> contains 50 observations and class <code>B</code> contains 500 observations.
There are two numeric variables: <code>X</code> and <code>Y</code>.
</p>


<h3>Author(s)</h3>

<p>Alexandre BlanschÃ© <a href="mailto:alexandre.blansche@univ-lorraine.fr">alexandre.blansche@univ-lorraine.fr</a>
</p>

<hr>
<h2 id='loadtext'>load a text file</h2><span id='topic+loadtext'></span>

<h3>Description</h3>

<p>(Down)Load a text file (and extract it if it is in a zip file).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadtext(
  file = file.choose(),
  dir = "~/",
  collapse = TRUE,
  sep = NULL,
  categories = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadtext_+3A_file">file</code></td>
<td>
<p>The path or URL of the text file.</p>
</td></tr>
<tr><td><code id="loadtext_+3A_dir">dir</code></td>
<td>
<p>The (temporary) directory, where the file is downloaded. The file is deleted at the end of this function.</p>
</td></tr>
<tr><td><code id="loadtext_+3A_collapse">collapse</code></td>
<td>
<p>Indicates whether or not lines of each documents should collapse together or not.</p>
</td></tr>
<tr><td><code id="loadtext_+3A_sep">sep</code></td>
<td>
<p>Separator between text fields.</p>
</td></tr>
<tr><td><code id="loadtext_+3A_categories">categories</code></td>
<td>
<p>Columns that should be considered as categorial data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The text contained in the dowloaded file.
</p>


<h3>See Also</h3>

<p><code><a href="utils.html#topic+download.file">download.file</a></code>, <code><a href="utils.html#topic+unzip">unzip</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")

## End(Not run)
</code></pre>

<hr>
<h2 id='LR'>Classification using Logistic Regression</h2><span id='topic+LR'></span>

<h3>Description</h3>

<p>This function builds a classification model using Logistic Regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LR(train, labels, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LR_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="LR_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="LR_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="LR_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+multinom">multinom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
LR (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='MCA'>Multiple Correspondence Analysis (MCA)</h2><span id='topic+MCA'></span>

<h3>Description</h3>

<p>Performs Multiple Correspondence Analysis (MCA) with supplementary individuals, supplementary quantitative variables and supplementary categorical variables.
Performs also Specific Multiple Correspondence Analysis with supplementary categories and supplementary categorical variables.
Missing values are treated as an additional level, categories which are rare can be ventilated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MCA(
  d,
  ncp = 5,
  ind.sup = NULL,
  quanti.sup = NULL,
  quali.sup = NULL,
  row.w = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MCA_+3A_d">d</code></td>
<td>
<p>A ddata frame or a table with n rows and p columns, i.e. a contingency table.</p>
</td></tr>
<tr><td><code id="MCA_+3A_ncp">ncp</code></td>
<td>
<p>The number of dimensions kept in the results (by default 5).</p>
</td></tr>
<tr><td><code id="MCA_+3A_ind.sup">ind.sup</code></td>
<td>
<p>A vector indicating the indexes of the supplementary individuals.</p>
</td></tr>
<tr><td><code id="MCA_+3A_quanti.sup">quanti.sup</code></td>
<td>
<p>A vector indicating the indexes of the quantitative supplementary variables.</p>
</td></tr>
<tr><td><code id="MCA_+3A_quali.sup">quali.sup</code></td>
<td>
<p>A vector indicating the indexes of the categorical supplementary variables.</p>
</td></tr>
<tr><td><code id="MCA_+3A_row.w">row.w</code></td>
<td>
<p>An optional row weights (by default, a vector of 1 for uniform row weights); the weights are given only for the active individuals.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The MCA on the dataset.
</p>


<h3>See Also</h3>

<p><code><a href="FactoMineR.html#topic+MCA">MCA</a></code>, <code><a href="#topic+CA">CA</a></code>, <code><a href="#topic+PCA">PCA</a></code>, <code><a href="#topic+plot.factorial">plot.factorial</a></code>, <code><a href="#topic+factorial-class">factorial-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data (tea, package = "FactoMineR")
MCA (tea, quanti.sup = 19, quali.sup = 20:36)
</code></pre>

<hr>
<h2 id='MEANSHIFT'>MeanShift method</h2><span id='topic+MEANSHIFT'></span>

<h3>Description</h3>

<p>Run MeanShift for clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MEANSHIFT(
  d,
  mskernel = "NORMAL",
  bandwidth = rep(1, ncol(d)),
  alpha = 0,
  iterations = 10,
  epsilon = 1e-08,
  epsilonCluster = 1e-04,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MEANSHIFT_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_mskernel">mskernel</code></td>
<td>
<p>A string indicating the kernel associated with the kernel density estimate that the mean shift is optimizing over.</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_bandwidth">bandwidth</code></td>
<td>
<p>Used in the kernel density estimate for steepest ascent classification.</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_alpha">alpha</code></td>
<td>
<p>A scalar tuning parameter for normal kernels.</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_iterations">iterations</code></td>
<td>
<p>The number of iterations to perform mean shift.</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_epsilon">epsilon</code></td>
<td>
<p>A scalar used to determine when to terminate the iteration of a individual query point.</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_epsiloncluster">epsilonCluster</code></td>
<td>
<p>A scalar used to determine the minimum distance between distinct clusters.</p>
</td></tr>
<tr><td><code id="MEANSHIFT_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The clustering (<code>meanshift</code> object).
</p>


<h3>See Also</h3>

<p><code><a href="meanShiftR.html#topic+meanShift">meanShift</a></code>, <code><a href="#topic+predict.meanshift">predict.meanshift</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
MEANSHIFT (iris [, -5], bandwidth = .75)

## End(Not run)
</code></pre>

<hr>
<h2 id='meanshift-class'>MeanShift model</h2><span id='topic+meanshift-class'></span>

<h3>Description</h3>

<p>This class contains the model obtained by the MEANSHIFT method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>cluster</code></dt><dd><p>A vector of integers indicating the cluster to which each point is allocated.</p>
</dd>
<dt><code>value</code></dt><dd><p>A vector or matrix containing the location of the classified local maxima in the support.</p>
</dd>
<dt><code>data</code></dt><dd><p>The leaning set.</p>
</dd>
<dt><code>kernel</code></dt><dd><p>A string indicating the kernel associated with the kernel density estimate that the mean shift is optimizing over.</p>
</dd>
<dt><code>bandwidth</code></dt><dd><p>Used in the kernel density estimate for steepest ascent classification.</p>
</dd>
<dt><code>alpha</code></dt><dd><p>A scalar tuning parameter for normal kernels.</p>
</dd>
<dt><code>iterations</code></dt><dd><p>The number of iterations to perform mean shift.</p>
</dd>
<dt><code>epsilon</code></dt><dd><p>A scalar used to determine when to terminate the iteration of a individual query point.</p>
</dd>
<dt><code>epsilonCluster</code></dt><dd><p>A scalar used to determine the minimum distance between distinct clusters.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+MEANSHIFT">MEANSHIFT</a></code>
</p>

<hr>
<h2 id='MLP'>Classification using Multilayer Perceptron</h2><span id='topic+MLP'></span>

<h3>Description</h3>

<p>This function builds a classification model using Multilayer Perceptron.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLP(
  train,
  labels,
  hidden = ifelse(is.vector(train), 2:(1 + nlevels(labels)), 2:(ncol(train) +
    nlevels(labels))),
  decay = 10^(-3:-1),
  methodparameters = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLP_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="MLP_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="MLP_+3A_hidden">hidden</code></td>
<td>
<p>The size of the hidden layer (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="MLP_+3A_decay">decay</code></td>
<td>
<p>The decay (between 0 and 1) of the backpropagation algorithm (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="MLP_+3A_methodparameters">methodparameters</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>size</code> and <code>decay</code>.</p>
</td></tr>
<tr><td><code id="MLP_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="MLP_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+nnet">nnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
MLP (iris [, -5], iris [, 5], hidden = 4, decay = .1)

## End(Not run)
</code></pre>

<hr>
<h2 id='MLPREG'>Multi-Layer Perceptron Regression</h2><span id='topic+MLPREG'></span>

<h3>Description</h3>

<p>This function builds a regression model using MLP.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MLPREG(
  x,
  y,
  size = 2:(ifelse(is.vector(x), 2, ncol(x))),
  decay = 10^(-3:-1),
  params = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MLPREG_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="MLPREG_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="MLPREG_+3A_size">size</code></td>
<td>
<p>The size of the hidden layer (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="MLPREG_+3A_decay">decay</code></td>
<td>
<p>The decay (between 0 and 1) of the backpropagation algorithm (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="MLPREG_+3A_params">params</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>size</code> and <code>decay</code>.</p>
</td></tr>
<tr><td><code id="MLPREG_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="MLPREG_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model, as an object of class <code><a href="#topic+model-class">model-class</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="nnet.html#topic+nnet">nnet</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (trees)
MLPREG (trees [, -3], trees [, 3])

## End(Not run)
</code></pre>

<hr>
<h2 id='model-class'>Generic classification or regression model</h2><span id='topic+model-class'></span>

<h3>Description</h3>

<p>This is a wrapper class containing the classification model obtained by any classification or regression method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>model</code></dt><dd><p>The wrapped model.</p>
</dd>
<dt><code>method</code></dt><dd><p>The name of the method.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+predict.model">predict.model</a></code>, <code><a href="stats.html#topic+predict">predict</a></code>
</p>

<hr>
<h2 id='movies'>Movies dataset</h2><span id='topic+movies'></span>

<h3>Description</h3>

<p>Extract from the movie lens dataset. Missing values have been imputed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movies
</code></pre>


<h3>Format</h3>

<p>A set of 49 movies, rated by 55 users.
</p>


<h3>Source</h3>

<p><a href="https://grouplens.org/datasets/movielens/">https://grouplens.org/datasets/movielens/</a>
</p>

<hr>
<h2 id='NB'>Classification using Naive Bayes</h2><span id='topic+NB'></span>

<h3>Description</h3>

<p>This function builds a classification model using Naive Bayes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NB(train, labels, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NB_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="NB_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="NB_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="NB_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+naiveBayes">naiveBayes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
NB (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='NMF'>Non-negative Matrix Factorization</h2><span id='topic+NMF'></span>

<h3>Description</h3>

<p>Return the NMF decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NMF(x, rank = 2, nstart = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NMF_+3A_x">x</code></td>
<td>
<p>A numeric dataset (data.frame or matrix).</p>
</td></tr>
<tr><td><code id="NMF_+3A_rank">rank</code></td>
<td>
<p>Specification of the factorization rank.</p>
</td></tr>
<tr><td><code id="NMF_+3A_nstart">nstart</code></td>
<td>
<p>How many random sets should be chosen?</p>
</td></tr>
<tr><td><code id="NMF_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="NMF.html#topic+nmf">nmf</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
install.packages ("BiocManager")
BiocManager::install ("Biobase")
install.packages ("NMF")
require (datasets)
data (iris)
NMF (iris [, -5])

## End(Not run)
</code></pre>

<hr>
<h2 id='ozone'>Ozone dataset</h2><span id='topic+ozone'></span>

<h3>Description</h3>

<p>This dataset constains measurements on ozone level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ozone
</code></pre>


<h3>Format</h3>

<p>Each instance is described by the maximum level of ozone measured during the day.
Temperature, clouds, and wind are also recorded.
</p>


<h3>Source</h3>

<p><a href="https://r-stat-sc-donnees.github.io/ozone.txt">https://r-stat-sc-donnees.github.io/ozone.txt</a>
</p>

<hr>
<h2 id='params-class'>Learning Parameters</h2><span id='topic+params-class'></span>

<h3>Description</h3>

<p>This class contains main parameters for various learning methods.
</p>


<h3>Slots</h3>


<dl>
<dt><code>decay</code></dt><dd><p>The decay parameter.</p>
</dd>
<dt><code>hidden</code></dt><dd><p>The number of hidden nodes.</p>
</dd>
<dt><code>epsilon</code></dt><dd><p>The epsilon parameter.</p>
</dd>
<dt><code>gamma</code></dt><dd><p>The gamma parameter.</p>
</dd>
<dt><code>cost</code></dt><dd><p>The cost parameter.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+MLP">MLP</a></code>, <code><a href="#topic+MLPREG">MLPREG</a></code>, <code><a href="#topic+SVM">SVM</a></code>, <code><a href="#topic+SVR">SVR</a></code>
</p>

<hr>
<h2 id='PCA'>Principal Component Analysis (PCA)</h2><span id='topic+PCA'></span>

<h3>Description</h3>

<p>Performs Principal Component Analysis (PCA) with supplementary individuals, supplementary quantitative variables and supplementary categorical variables.
Missing values are replaced by the column mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PCA(
  d,
  scale.unit = TRUE,
  ncp = ncol(d) - length(quanti.sup) - length(quali.sup),
  ind.sup = NULL,
  quanti.sup = NULL,
  quali.sup = NULL,
  row.w = NULL,
  col.w = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PCA_+3A_d">d</code></td>
<td>
<p>A data frame with n rows (individuals) and p columns (numeric variables).</p>
</td></tr>
<tr><td><code id="PCA_+3A_scale.unit">scale.unit</code></td>
<td>
<p>A boolean, if TRUE (value set by default) then data are scaled to unit variance.</p>
</td></tr>
<tr><td><code id="PCA_+3A_ncp">ncp</code></td>
<td>
<p>The number of dimensions kept in the results (by default 5).</p>
</td></tr>
<tr><td><code id="PCA_+3A_ind.sup">ind.sup</code></td>
<td>
<p>A vector indicating the indexes of the supplementary individuals.</p>
</td></tr>
<tr><td><code id="PCA_+3A_quanti.sup">quanti.sup</code></td>
<td>
<p>A vector indicating the indexes of the quantitative supplementary variables.</p>
</td></tr>
<tr><td><code id="PCA_+3A_quali.sup">quali.sup</code></td>
<td>
<p>A vector indicating the indexes of the categorical supplementary variables.</p>
</td></tr>
<tr><td><code id="PCA_+3A_row.w">row.w</code></td>
<td>
<p>An optional row weights (by default, a vector of 1 for uniform row weights); the weights are given only for the active individuals.</p>
</td></tr>
<tr><td><code id="PCA_+3A_col.w">col.w</code></td>
<td>
<p>An optional column weights (by default, uniform column weights); the weights are given only for the active variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The PCA on the dataset.
</p>


<h3>See Also</h3>

<p><code><a href="FactoMineR.html#topic+PCA">PCA</a></code>, <code><a href="#topic+CA">CA</a></code>, <code><a href="#topic+MCA">MCA</a></code>, <code><a href="#topic+plot.factorial">plot.factorial</a></code>, <code><a href="#topic+kaiser">kaiser</a></code>, <code><a href="#topic+factorial-class">factorial-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
PCA (iris, quali.sup = 5)
</code></pre>

<hr>
<h2 id='performance'>Performance estimation</h2><span id='topic+performance'></span>

<h3>Description</h3>

<p>Estimate the performance of classification or regression methods using bootstrap or crossvalidation (accuracy, ROC curves, confusion matrices, ...)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>performance(
  methods,
  train.x,
  train.y,
  test.x = NULL,
  test.y = NULL,
  train.size = round(0.7 * nrow(train.x)),
  type = c("evaluation", "confusion", "roc", "cost", "scatter", "avsp"),
  protocol = c("bootstrap", "crossvalidation", "loocv", "holdout", "train"),
  eval = ifelse(is.factor(train.y), "accuracy", "r2"),
  nruns = 10,
  nfolds = 10,
  new = TRUE,
  lty = 1,
  seed = NULL,
  methodparameters = NULL,
  names = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="performance_+3A_methods">methods</code></td>
<td>
<p>The classification or regression methods to be evaluated.</p>
</td></tr>
<tr><td><code id="performance_+3A_train.x">train.x</code></td>
<td>
<p>The dataset (description/predictors), a <code>matrix</code> or <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="performance_+3A_train.y">train.y</code></td>
<td>
<p>The target (class labels or numeric values), a <code>factor</code> or <code>vector</code>.</p>
</td></tr>
<tr><td><code id="performance_+3A_test.x">test.x</code></td>
<td>
<p>The test dataset (description/predictors), a <code>matrix</code> or <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="performance_+3A_test.y">test.y</code></td>
<td>
<p>The (test) target (class labels or numeric values), a <code>factor</code> or <code>vector</code>.</p>
</td></tr>
<tr><td><code id="performance_+3A_train.size">train.size</code></td>
<td>
<p>The size of the training set (holdout estimation).</p>
</td></tr>
<tr><td><code id="performance_+3A_type">type</code></td>
<td>
<p>The type of evaluation (confusion matrix, ROC curve, ...)</p>
</td></tr>
<tr><td><code id="performance_+3A_protocol">protocol</code></td>
<td>
<p>The evaluation protocol (crossvalidation, bootstrap, ...)</p>
</td></tr>
<tr><td><code id="performance_+3A_eval">eval</code></td>
<td>
<p>The evaluation functions.</p>
</td></tr>
<tr><td><code id="performance_+3A_nruns">nruns</code></td>
<td>
<p>The number of bootstrap runs.</p>
</td></tr>
<tr><td><code id="performance_+3A_nfolds">nfolds</code></td>
<td>
<p>The number of folds (crossvalidation estimation).</p>
</td></tr>
<tr><td><code id="performance_+3A_new">new</code></td>
<td>
<p>A logical value indicating whether a new plot should be be created or not (cost curves or ROC curves).</p>
</td></tr>
<tr><td><code id="performance_+3A_lty">lty</code></td>
<td>
<p>The line type (and color) specified as an integer (cost curves or ROC curves).</p>
</td></tr>
<tr><td><code id="performance_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation (useful for testing different method with the same bootstap samplings).</p>
</td></tr>
<tr><td><code id="performance_+3A_methodparameters">methodparameters</code></td>
<td>
<p>Method parameters (if null tuning is done by cross-validation).</p>
</td></tr>
<tr><td><code id="performance_+3A_names">names</code></td>
<td>
<p>Method names.</p>
</td></tr>
<tr><td><code id="performance_+3A_...">...</code></td>
<td>
<p>Other specific parameters for the leaning method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion</a></code>, <code><a href="#topic+evaluation">evaluation</a></code>, <code><a href="#topic+cost.curves">cost.curves</a></code>, <code><a href="#topic+roc.curves">roc.curves</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require ("datasets")
data (iris)
# One method, one evaluation criterion, bootstrap estimation
performance (NB, iris [, -5], iris [, 5], seed = 0)
# One method, two evaluation criteria, train set estimation
performance (NB, iris [, -5], iris [, 5], eval = c ("accuracy", "kappa"),
             protocol = "train", seed = 0)
# Three methods, ROC curves, LOOCV estimation
performance (c (NB, LDA, LR), linsep [, -3], linsep [, 3], type = "roc",
             protocol = "loocv", seed = 0)
# List of methods in a variable, confusion matrix, hodout estimation
classif = c (NB, LDA, LR)
performance (classif, iris [, -5], iris [, 5], type = "confusion",
             protocol = "holdout", seed = 0, names = c ("NB", "LDA", "LR"))
# List of strings (method names), scatterplot evaluation, crossvalidation estimation
classif = c ("NB", "LDA", "LR")
performance (classif, iris [, -5], iris [, 5], type = "scatter",
             protocol = "crossvalidation", seed = 0)
# Actual vs. predicted
data (trees)
performance (LINREG, trees [, -3], trees [, 3], type = "avsp")

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.cda'>Plot function for cda-class</h2><span id='topic+plot.cda'></span>

<h3>Description</h3>

<p>Plot the learning set (and test set) on the canonical axes obtained by Canonical Discriminant Analysis (function <code>CDA</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cda'
plot(x, newdata = NULL, axes = 1:2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.cda_+3A_x">x</code></td>
<td>
<p>The classification model (object of class <code>cda-class</code>).</p>
</td></tr>
<tr><td><code id="plot.cda_+3A_newdata">newdata</code></td>
<td>
<p>The test set (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="plot.cda_+3A_axes">axes</code></td>
<td>
<p>The canonical axes to be printed (numeric <code>vector</code>).</p>
</td></tr>
<tr><td><code id="plot.cda_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+CDA">CDA</a></code>, <code><a href="#topic+predict.cda">predict.cda</a></code>, <code><a href="#topic+cda-class">cda-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
model = CDA (iris [, -5], iris [, 5])
plot (model)
</code></pre>

<hr>
<h2 id='plot.factorial'>Plot function for factorial-class</h2><span id='topic+plot.factorial'></span>

<h3>Description</h3>

<p>Plot PCA, CA or MCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factorial'
plot(x, type = c("ind", "cor", "eig"), axes = c(1, 2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.factorial_+3A_x">x</code></td>
<td>
<p>The PCA, CA or MCA result (object of class <code>factorial-class</code>).</p>
</td></tr>
<tr><td><code id="plot.factorial_+3A_type">type</code></td>
<td>
<p>The graph to plot.</p>
</td></tr>
<tr><td><code id="plot.factorial_+3A_axes">axes</code></td>
<td>
<p>The factorial axes to be printed (numeric <code>vector</code>).</p>
</td></tr>
<tr><td><code id="plot.factorial_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+CA">CA</a></code>, <code><a href="#topic+MCA">MCA</a></code>, <code><a href="#topic+PCA">PCA</a></code>, <code><a href="FactoMineR.html#topic+plot.CA">plot.CA</a></code>, <code><a href="FactoMineR.html#topic+plot.MCA">plot.MCA</a></code>, <code><a href="FactoMineR.html#topic+plot.PCA">plot.PCA</a></code>, <code><a href="#topic+factorial-class">factorial-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
pca = PCA (iris, quali.sup = 5)
plot (pca)
plot (pca, type = "cor")
plot (pca, type = "eig")
</code></pre>

<hr>
<h2 id='plot.som'>Plot function for som-class</h2><span id='topic+plot.som'></span>

<h3>Description</h3>

<p>Plot Kohonen's self-organizing maps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'som'
plot(x, type = c("scatter", "mapping"), col = NULL, labels = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.som_+3A_x">x</code></td>
<td>
<p>The Kohonen's map (object of class <code><a href="#topic+som-class">som-class</a></code>).</p>
</td></tr>
<tr><td><code id="plot.som_+3A_type">type</code></td>
<td>
<p>The type of plot.</p>
</td></tr>
<tr><td><code id="plot.som_+3A_col">col</code></td>
<td>
<p>Color of the data points</p>
</td></tr>
<tr><td><code id="plot.som_+3A_labels">labels</code></td>
<td>
<p>A <code>vector</code> of character strings to be printed instead of points in the plot.</p>
</td></tr>
<tr><td><code id="plot.som_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+SOM">SOM</a></code>, <code><a href="#topic+som-class">som-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
som = SOM (iris [, -5], xdim = 5, ydim = 5, post = "ward", k = 3)
plot (som) # Scatter plot (default)
plot (som, type = "mapping") # Kohonen map
</code></pre>

<hr>
<h2 id='plotavsp'>Plot actual vs. predictions</h2><span id='topic+plotavsp'></span>

<h3>Description</h3>

<p>Plot actual vs. predictions of a regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotavsp(predictions, gt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotavsp_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>vector</code>).</p>
</td></tr>
<tr><td><code id="plotavsp_+3A_gt">gt</code></td>
<td>
<p>The ground truth of the dataset (<code>vector</code>).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+confusion">confusion</a></code>, <code><a href="#topic+evaluation.accuracy">evaluation.accuracy</a></code>, <code><a href="#topic+evaluation.fmeasure">evaluation.fmeasure</a></code>, <code><a href="#topic+evaluation.fowlkesmallows">evaluation.fowlkesmallows</a></code>, <code><a href="#topic+evaluation.goodness">evaluation.goodness</a></code>, <code><a href="#topic+evaluation.jaccard">evaluation.jaccard</a></code>, <code><a href="#topic+evaluation.kappa">evaluation.kappa</a></code>,
<code><a href="#topic+evaluation.precision">evaluation.precision</a></code>, <code><a href="#topic+evaluation.recall">evaluation.recall</a></code>,
<code><a href="#topic+evaluation.msep">evaluation.msep</a></code>, <code><a href="#topic+evaluation.r2">evaluation.r2</a></code>, <code><a href="#topic+performance">performance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
model = LINREG (trees [, -3], trees [, 3])
pred = predict (model, trees [, -3])
plotavsp (pred, trees [, 3])
</code></pre>

<hr>
<h2 id='plotcloud'>Plot word cloud</h2><span id='topic+plotcloud'></span>

<h3>Description</h3>

<p>Plot a word cloud based on the word frequencies in the documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotcloud(corpus, k = NULL, stopwords = "en", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotcloud_+3A_corpus">corpus</code></td>
<td>
<p>The corpus of documents (a vector of characters) or the vocabulary of the documents (result of function <code>getvocab</code>).</p>
</td></tr>
<tr><td><code id="plotcloud_+3A_k">k</code></td>
<td>
<p>A categorial variable (vector or factor).</p>
</td></tr>
<tr><td><code id="plotcloud_+3A_stopwords">stopwords</code></td>
<td>
<p>Stopwords, or the language of the documents. NULL if stop words should not be removed.</p>
</td></tr>
<tr><td><code id="plotcloud_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plotzipf">plotzipf</a></code>, <code><a href="#topic+getvocab">getvocab</a></code>, <code><a href="wordcloud.html#topic+wordcloud">wordcloud</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
plotcloud (text)
vocab = getvocab (text, mincount = 1, lang = NULL, stopwords = "en")
plotcloud (vocab)

## End(Not run)
</code></pre>

<hr>
<h2 id='plotclus'>Generic Plot Method for Clustering</h2><span id='topic+plotclus'></span>

<h3>Description</h3>

<p>Plot a clustering according to various parameters
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotclus(
  clustering,
  d = NULL,
  type = c("scatter", "boxplot", "tree", "height", "mapping", "words"),
  centers = FALSE,
  k = NULL,
  tailsize = 9,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotclus_+3A_clustering">clustering</code></td>
<td>
<p>The clustering to be plotted.</p>
</td></tr>
<tr><td><code id="plotclus_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>), mandatory for some of the graphics.</p>
</td></tr>
<tr><td><code id="plotclus_+3A_type">type</code></td>
<td>
<p>The type of plot.</p>
</td></tr>
<tr><td><code id="plotclus_+3A_centers">centers</code></td>
<td>
<p>Indicates whether or not cluster centers should be plotted (used only in scatter plots).</p>
</td></tr>
<tr><td><code id="plotclus_+3A_k">k</code></td>
<td>
<p>Number of clusters (used only for hierarchical methods). If not specified an &quot;optimal&quot; value is determined.</p>
</td></tr>
<tr><td><code id="plotclus_+3A_tailsize">tailsize</code></td>
<td>
<p>Number of clusters showned (used only for height plots).</p>
</td></tr>
<tr><td><code id="plotclus_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+treeplot">treeplot</a></code>, <code><a href="#topic+scatterplot">scatterplot</a></code>, <code><a href="#topic+plot.som">plot.som</a></code>, <code><a href="#topic+boxclus">boxclus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
ward = HCA (iris [, -5], method = "ward", k = 3)
plotclus (ward, iris [, -5], type = "scatter") # Scatter plot
plotclus (ward, iris [, -5], type = "boxplot") # Boxplot
plotclus (ward, iris [, -5], type = "tree") # Dendrogram
plotclus (ward, iris [, -5], type = "height") # Distances between merging clusters
som = SOM (iris [, -5], xdim = 5, ydim = 5, post = "ward", k = 3)
plotclus (som, iris [, -5], type = "scatter") # Scatter plot for SOM
plotclus (som, iris [, -5], type = "mapping") # Kohonen map

## End(Not run)
</code></pre>

<hr>
<h2 id='plotdata'>Advanced plot function</h2><span id='topic+plotdata'></span>

<h3>Description</h3>

<p>Plot a dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotdata(
  d,
  k = NULL,
  type = c("pairs", "scatter", "parallel", "boxplot", "histogram", "barplot", "pie",
    "heatmap", "heatmapc", "pca", "cda", "svd", "nmf", "tsne", "som", "words"),
  legendpos = "topleft",
  alpha = 200,
  asp = 1,
  labels = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotdata_+3A_d">d</code></td>
<td>
<p>A numeric dataset (data.frame or matrix).</p>
</td></tr>
<tr><td><code id="plotdata_+3A_k">k</code></td>
<td>
<p>A categorial variable (vector or factor).</p>
</td></tr>
<tr><td><code id="plotdata_+3A_type">type</code></td>
<td>
<p>The type of graphic to be plotted.</p>
</td></tr>
<tr><td><code id="plotdata_+3A_legendpos">legendpos</code></td>
<td>
<p>Position of the legend</p>
</td></tr>
<tr><td><code id="plotdata_+3A_alpha">alpha</code></td>
<td>
<p>Color opacity (0-255).</p>
</td></tr>
<tr><td><code id="plotdata_+3A_asp">asp</code></td>
<td>
<p>Aspect ratio (default: 1).</p>
</td></tr>
<tr><td><code id="plotdata_+3A_labels">labels</code></td>
<td>
<p>Indicates whether or not labels (row names) should be showned on the (scatter) plot.</p>
</td></tr>
<tr><td><code id="plotdata_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
# Without classification
plotdata (iris [, -5]) # DÃ©fault (pairs)
# With classification
plotdata (iris [, -5], iris [, 5]) # DÃ©fault (pairs)
plotdata (iris, 5) # Column number
plotdata (iris) # Automatic detection of the classification (if only one factor column)
plotdata (iris, type = "scatter") # Scatter plot (PCA axis)
plotdata (iris, type = "parallel") # Parallel coordinates
plotdata (iris, type = "boxplot") # Boxplot
plotdata (iris, type = "histogram") # Histograms
plotdata (iris, type = "heatmap") # Heatmap
plotdata (iris, type = "heatmapc") # Heatmap (and hierarchalcal clustering)
plotdata (iris, type = "pca") # Scatter plot (PCA axis)
plotdata (iris, type = "cda") # Scatter plot (CDA axis)
plotdata (iris, type = "svd") # Scatter plot (SVD axis)
plotdata (iris, type = "som") # Kohonen map
# With only one variable
plotdata (iris [, 1], iris [, 5]) # DÃ©fault (data vs. index)
plotdata (iris [, 1], iris [, 5], type = "scatter") # Scatter plot (data vs. index)
plotdata (iris [, 1], iris [, 5], type = "boxplot") # Boxplot
# With two variables
plotdata (iris [, 3:4], iris [, 5]) # DÃ©fault (scatter plot)
plotdata (iris [, 3:4], iris [, 5], type = "scatter") # Scatter plot
data (titanic)
plotdata (titanic, type = "barplot") # Barplots
plotdata (titanic, type = "pie") # Pie charts
</code></pre>

<hr>
<h2 id='plotzipf'>Plot rank versus frequency</h2><span id='topic+plotzipf'></span>

<h3>Description</h3>

<p>Plot the frequency of words in a document agains the ranks of those words. It also plot the Zipf law.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotzipf(corpus)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotzipf_+3A_corpus">corpus</code></td>
<td>
<p>The corpus of documents (a vector of characters) or the vocabulary of the documents (result of function <code>getvocab</code>).</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+plotcloud">plotcloud</a></code>, <code><a href="#topic+getvocab">getvocab</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
plotzipf (text)
vocab = getvocab (text, mincount = 1, lang = NULL)
plotzipf (vocab)

## End(Not run)
</code></pre>

<hr>
<h2 id='POLYREG'>Polynomial Regression</h2><span id='topic+POLYREG'></span>

<h3>Description</h3>

<p>This function builds a polynomial regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>POLYREG(x, y, degree = 2, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="POLYREG_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="POLYREG_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="POLYREG_+3A_degree">degree</code></td>
<td>
<p>The polynom degree.</p>
</td></tr>
<tr><td><code id="POLYREG_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="POLYREG_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model, as an object of class <code><a href="#topic+model-class">model-class</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="mda.html#topic+polyreg">polyreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (trees)
POLYREG (trees [, -3], trees [, 3])

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.apriori'>Model predictions</h2><span id='topic+predict.apriori'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>apriori.classif</code>.
Observations that do not match any of the rules are labelled as &quot;unmatched&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apriori'
predict(object, test, unmatched = "Unknown", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.apriori_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code>apriori</code>, created by <code>apriori.classif</code>).</p>
</td></tr>
<tr><td><code id="predict.apriori_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>)</p>
</td></tr>
<tr><td><code id="predict.apriori_+3A_unmatched">unmatched</code></td>
<td>
<p>The class label given to the unmatched observations (a character string).</p>
</td></tr>
<tr><td><code id="predict.apriori_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+APRIORI">APRIORI</a></code>, <code><a href="#topic+apriori-class">apriori-class</a></code>, <code><a href="arules.html#topic+apriori">apriori</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("datasets")
data (iris)
d = discretizeDF (iris,
    default = list (method = "interval", breaks = 3, labels = c ("small", "medium", "large")))
model = APRIORI (d [, -5], d [, 5], supp = .1, conf = .9, prune = TRUE)
predict (model, d [, -5])
</code></pre>

<hr>
<h2 id='predict.boosting'>Model predictions</h2><span id='topic+predict.boosting'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by a boosting method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'boosting'
predict(object, test, fuzzy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.boosting_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+boosting-class">boosting-class</a></code>, created by <code><a href="#topic+ADABOOST">ADABOOST</a></code> or <code><a href="#topic+BAGGING">BAGGING</a></code>).</p>
</td></tr>
<tr><td><code id="predict.boosting_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>)</p>
</td></tr>
<tr><td><code id="predict.boosting_+3A_fuzzy">fuzzy</code></td>
<td>
<p>A boolean indicating whether fuzzy classification is used or not.</p>
</td></tr>
<tr><td><code id="predict.boosting_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ADABOOST">ADABOOST</a></code>, <code><a href="#topic+BAGGING">BAGGING</a></code>, <code><a href="#topic+boosting-class">boosting-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
d = splitdata (iris, 5)
model = BAGGING (d$train.x, d$train.y, NB)
predict (model, d$test.x)
model = ADABOOST (d$train.x, d$train.y, NB)
predict (model, d$test.x)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.cda'>Model predictions</h2><span id='topic+predict.cda'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code><a href="#topic+CDA">CDA</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cda'
predict(object, test, fuzzy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cda_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+cda-class">cda-class</a></code>, created by <code><a href="#topic+CDA">CDA</a></code>).</p>
</td></tr>
<tr><td><code id="predict.cda_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>)</p>
</td></tr>
<tr><td><code id="predict.cda_+3A_fuzzy">fuzzy</code></td>
<td>
<p>A boolean indicating whether fuzzy classification is used or not.</p>
</td></tr>
<tr><td><code id="predict.cda_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CDA">CDA</a></code>, <code><a href="#topic+plot.cda">plot.cda</a></code>, <code><a href="#topic+cda-class">cda-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model = CDA (d$train.x, d$train.y)
predict (model, d$test.x)
</code></pre>

<hr>
<h2 id='predict.dbs'>Predict function for DBSCAN</h2><span id='topic+predict.dbs'></span>

<h3>Description</h3>

<p>Return the closest DBSCAN cluster for a new dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dbs'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.dbs_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+dbs-class">dbs-class</a></code>, created by <code><a href="#topic+DBSCAN">DBSCAN</a></code>).</p>
</td></tr>
<tr><td><code id="predict.dbs_+3A_newdata">newdata</code></td>
<td>
<p>A new dataset (a <code>data.frame</code>), with same variables as the learning dataset.</p>
</td></tr>
<tr><td><code id="predict.dbs_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+DBSCAN">DBSCAN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model = DBSCAN (d$train.x, minpts = 5, eps = 0.65)
predict (model, d$test.x)
</code></pre>

<hr>
<h2 id='predict.em'>Predict function for EM</h2><span id='topic+predict.em'></span>

<h3>Description</h3>

<p>Return the closest EM cluster for a new dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'em'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.em_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+em-class">em-class</a></code>, created by <code><a href="#topic+EM">EM</a></code>).</p>
</td></tr>
<tr><td><code id="predict.em_+3A_newdata">newdata</code></td>
<td>
<p>A new dataset (a <code>data.frame</code>), with same variables as the learning dataset.</p>
</td></tr>
<tr><td><code id="predict.em_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+EM">EM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model = EM (d$train.x, 3)
predict (model, d$test.x)
</code></pre>

<hr>
<h2 id='predict.kmeans'>Predict function for K-means</h2><span id='topic+predict.kmeans'></span>

<h3>Description</h3>

<p>Return the closest K-means cluster for a new dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kmeans'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.kmeans_+3A_object">object</code></td>
<td>
<p>The classification model (created by <code><a href="#topic+KMEANS">KMEANS</a></code>).</p>
</td></tr>
<tr><td><code id="predict.kmeans_+3A_newdata">newdata</code></td>
<td>
<p>A new dataset (a <code>data.frame</code>), with same variables as the learning dataset.</p>
</td></tr>
<tr><td><code id="predict.kmeans_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+KMEANS">KMEANS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model = KMEANS (d$train.x, k = 3)
predict (model, d$test.x)
</code></pre>

<hr>
<h2 id='predict.knn'>Model predictions</h2><span id='topic+predict.knn'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code><a href="#topic+KNN">KNN</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'knn'
predict(object, test, fuzzy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.knn_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="class.html#topic+knn">knn</a></code>).</p>
</td></tr>
<tr><td><code id="predict.knn_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="predict.knn_+3A_fuzzy">fuzzy</code></td>
<td>
<p>A boolean indicating whether fuzzy classification is used or not.</p>
</td></tr>
<tr><td><code id="predict.knn_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+KNN">KNN</a></code>, <code><a href="#topic+knn-class">knn-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model = KNN (d$train.x, d$train.y)
predict (model, d$test.x)
</code></pre>

<hr>
<h2 id='predict.meanshift'>Predict function for MeanShift</h2><span id='topic+predict.meanshift'></span>

<h3>Description</h3>

<p>Return the closest MeanShift cluster for a new dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'meanshift'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.meanshift_+3A_object">object</code></td>
<td>
<p>The classification model (created by <code><a href="#topic+MEANSHIFT">MEANSHIFT</a></code>).</p>
</td></tr>
<tr><td><code id="predict.meanshift_+3A_newdata">newdata</code></td>
<td>
<p>A new dataset (a <code>data.frame</code>), with same variables as the learning dataset.</p>
</td></tr>
<tr><td><code id="predict.meanshift_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+MEANSHIFT">MEANSHIFT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
d = splitdata (iris, 5)
model = MEANSHIFT (d$train.x, bandwidth = .75)
predict (model, d$test.x)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.model'>Model predictions</h2><span id='topic+predict.model'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by any classification or regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'model'
predict(object, test, fuzzy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.model_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+cda-class">cda-class</a></code>, created by <code><a href="#topic+CDA">CDA</a></code>).</p>
</td></tr>
<tr><td><code id="predict.model_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="predict.model_+3A_fuzzy">fuzzy</code></td>
<td>
<p>A boolean indicating whether fuzzy classification is used or not.</p>
</td></tr>
<tr><td><code id="predict.model_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+model-class">model-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
model = LDA (d$train.x, d$train.y)
predict (model, d$test.x)
</code></pre>

<hr>
<h2 id='predict.selection'>Model predictions</h2><span id='topic+predict.selection'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by any classification or regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'selection'
predict(object, test, fuzzy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.selection_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+cda-class">cda-class</a></code>, created by <code><a href="#topic+CDA">CDA</a></code>).</p>
</td></tr>
<tr><td><code id="predict.selection_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="predict.selection_+3A_fuzzy">fuzzy</code></td>
<td>
<p>A boolean indicating whether fuzzy classification is used or not.</p>
</td></tr>
<tr><td><code id="predict.selection_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+FEATURESELECTION">FEATURESELECTION</a></code>, <code><a href="#topic+selection-class">selection-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
d = splitdata (iris, 5)
model = FEATURESELECTION (d$train.x, d$train.y, uninb = 2, mainmethod = LDA)
predict (model, d$test.x)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.textmining'>Model predictions</h2><span id='topic+predict.textmining'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained for text mining.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'textmining'
predict(object, test, fuzzy = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.textmining_+3A_object">object</code></td>
<td>
<p>The classification model (of class <code><a href="#topic+textmining-class">textmining-class</a></code>, created by <code><a href="#topic+TEXTMINING">TEXTMINING</a></code>.</p>
</td></tr>
<tr><td><code id="predict.textmining_+3A_test">test</code></td>
<td>
<p>The test set (a <code>data.frame</code>)</p>
</td></tr>
<tr><td><code id="predict.textmining_+3A_fuzzy">fuzzy</code></td>
<td>
<p>A boolean indicating whether fuzzy classification is used or not.</p>
</td></tr>
<tr><td><code id="predict.textmining_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predicted values (<code>factor</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+TEXTMINING">TEXTMINING</a></code>, <code><a href="#topic+textmining-class">textmining-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (text2vec)
data ("movie_review")
d = movie_review [, 2:3]
d [, 1] = factor (d [, 1])
d = splitdata (d, 1)
model = TEXTMINING (d$train.x, NB, labels = d$train.y, mincount = 50)
pred = predict (model, d$test.x)
evaluation (pred, d$test.y)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.apriori'>Print a classification model obtained by APRIORI</h2><span id='topic+print.apriori'></span>

<h3>Description</h3>

<p>Print the set of rules in the classification model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apriori'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.apriori_+3A_x">x</code></td>
<td>
<p>The model to be printed.</p>
</td></tr>
<tr><td><code id="print.apriori_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+APRIORI">APRIORI</a></code>, <code><a href="#topic+predict.apriori">predict.apriori</a></code>, <code><a href="#topic+summary.apriori">summary.apriori</a></code>,
<code><a href="#topic+apriori-class">apriori-class</a></code>, <code><a href="arules.html#topic+apriori">apriori</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("datasets")
data (iris)
d = discretizeDF (iris,
    default = list (method = "interval", breaks = 3, labels = c ("small", "medium", "large")))
model = APRIORI (d [, -5], d [, 5], supp = .1, conf = .9, prune = TRUE)
print (model)
</code></pre>

<hr>
<h2 id='print.factorial'>Plot function for factorial-class</h2><span id='topic+print.factorial'></span>

<h3>Description</h3>

<p>Print PCA, CA or MCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'factorial'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.factorial_+3A_x">x</code></td>
<td>
<p>The PCA, CA or MCA result (object of class <code>factorial-class</code>).</p>
</td></tr>
<tr><td><code id="print.factorial_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+CA">CA</a></code>, <code><a href="#topic+MCA">MCA</a></code>, <code><a href="#topic+PCA">PCA</a></code>, <code><a href="FactoMineR.html#topic+print.CA">print.CA</a></code>, <code><a href="FactoMineR.html#topic+print.MCA">print.MCA</a></code>, <code><a href="FactoMineR.html#topic+print.PCA">print.PCA</a></code>, <code><a href="#topic+factorial-class">factorial-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
pca = PCA (iris, quali.sup = 5)
print (pca)
</code></pre>

<hr>
<h2 id='pseudoF'>Pseudo-F</h2><span id='topic+pseudoF'></span>

<h3>Description</h3>

<p>Compute the pseudo-F of a clustering result obtained by the <em>K</em>-means method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseudoF(clustering)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pseudoF_+3A_clustering">clustering</code></td>
<td>
<p>The clustering result (obtained by the function <code><a href="stats.html#topic+kmeans">kmeans</a></code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The pseudo-F of the clustering result.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kmeans.getk">kmeans.getk</a></code>, <code><a href="#topic+KMEANS">KMEANS</a></code>, <code><a href="stats.html#topic+kmeans">kmeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
pseudoF (km)
</code></pre>

<hr>
<h2 id='QDA'>Classification using Quadratic Discriminant Analysis</h2><span id='topic+QDA'></span>

<h3>Description</h3>

<p>This function builds a classification model using Quadratic Discriminant Analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>QDA(train, labels, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QDA_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="QDA_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="QDA_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="QDA_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+qda">qda</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
QDA (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='query.docs'>Document query</h2><span id='topic+query.docs'></span>

<h3>Description</h3>

<p>Search for documents similar to the query.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>query.docs(docvectors, query, vectorizer, nres = 5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="query.docs_+3A_docvectors">docvectors</code></td>
<td>
<p>The vectorized documents.</p>
</td></tr>
<tr><td><code id="query.docs_+3A_query">query</code></td>
<td>
<p>The query (vectorized or raw text).</p>
</td></tr>
<tr><td><code id="query.docs_+3A_vectorizer">vectorizer</code></td>
<td>
<p>The vectorizer taht has been used to vectorize the documents.</p>
</td></tr>
<tr><td><code id="query.docs_+3A_nres">nres</code></td>
<td>
<p>The number of results.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The indices of the documents the most similar to the query.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vectorize.docs">vectorize.docs</a></code>, <code><a href="text2vec.html#topic+sim2">sim2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (text2vec)
data (movie_review)
vectorizer = vectorize.docs (corpus = movie_review$review,
                             minphrasecount = 50, returndata = FALSE)
docs = vectorize.docs (corpus = movie_review$review, vectorizer = vectorizer)
query.docs (docs, movie_review$review [1], vectorizer)
query.docs (docs, docs [1, ], vectorizer)

## End(Not run)
</code></pre>

<hr>
<h2 id='query.words'>Word query</h2><span id='topic+query.words'></span>

<h3>Description</h3>

<p>Search for words similar to the query.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>query.words(wordvectors, origin, sub = NULL, add = NULL, nres = 5, lang = "en")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="query.words_+3A_wordvectors">wordvectors</code></td>
<td>
<p>The vectorized words</p>
</td></tr>
<tr><td><code id="query.words_+3A_origin">origin</code></td>
<td>
<p>The query (character).</p>
</td></tr>
<tr><td><code id="query.words_+3A_sub">sub</code></td>
<td>
<p>Words to be substrated to the origin.</p>
</td></tr>
<tr><td><code id="query.words_+3A_add">add</code></td>
<td>
<p>Words to be Added to the origin.</p>
</td></tr>
<tr><td><code id="query.words_+3A_nres">nres</code></td>
<td>
<p>The number of results.</p>
</td></tr>
<tr><td><code id="query.words_+3A_lang">lang</code></td>
<td>
<p>The language of the words (NULL if no stemming).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The Words the most similar to the query.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vectorize.words">vectorize.words</a></code>, <code><a href="text2vec.html#topic+sim2">sim2</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
words = vectorize.words (text, minphrasecount = 50)
query.words (words, origin = "paris", sub = "france", add = "germany")
query.words (words, origin = "berlin", sub = "germany", add = "france")
query.words (words, origin = "new_zealand")

## End(Not run)
</code></pre>

<hr>
<h2 id='RANDOMFOREST'>Classification using Random Forest</h2><span id='topic+RANDOMFOREST'></span>

<h3>Description</h3>

<p>This function builds a classification model using Random Forest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RANDOMFOREST(
  train,
  labels,
  ntree = 500,
  nvar = if (!is.null(labels) &amp;&amp; !is.factor(labels)) max(floor(ncol(train)/3), 1) else
    floor(sqrt(ncol(train))),
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RANDOMFOREST_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="RANDOMFOREST_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="RANDOMFOREST_+3A_ntree">ntree</code></td>
<td>
<p>The number of trees in the forest.</p>
</td></tr>
<tr><td><code id="RANDOMFOREST_+3A_nvar">nvar</code></td>
<td>
<p>Number of variables randomly sampled as candidates at each split.</p>
</td></tr>
<tr><td><code id="RANDOMFOREST_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="RANDOMFOREST_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="randomForest.html#topic+randomForest">randomForest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
RANDOMFOREST (iris [, -5], iris [, 5])

## End(Not run)
</code></pre>

<hr>
<h2 id='reg1'>reg1 dataset</h2><span id='topic+reg1'></span><span id='topic+reg1.train'></span><span id='topic+reg1.test'></span>

<h3>Description</h3>

<p>Artificial dataset for simple regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reg1
reg1.train
reg1.test
</code></pre>


<h3>Format</h3>

<p>50 instances and 3 variables. <code>X</code>, a numeric, <code>K</code>, a factor, and <code>Y</code>, a numeric (the target variable).
</p>


<h3>Author(s)</h3>

<p>Alexandre BlanschÃ© <a href="mailto:alexandre.blansche@univ-lorraine.fr">alexandre.blansche@univ-lorraine.fr</a>
</p>

<hr>
<h2 id='reg2'>reg2 dataset</h2><span id='topic+reg2'></span><span id='topic+reg2.train'></span><span id='topic+reg2.test'></span>

<h3>Description</h3>

<p>Artificial dataset for simple regression tasks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reg2
reg2.train
reg2.test
</code></pre>


<h3>Format</h3>

<p>50 instances and 2 variables. <code>X</code> and <code>Y</code> (the target variable) are both numeric variables.
</p>


<h3>Author(s)</h3>

<p>Alexandre BlanschÃ© <a href="mailto:alexandre.blansche@univ-lorraine.fr">alexandre.blansche@univ-lorraine.fr</a>
</p>

<hr>
<h2 id='regplot'>Plot function for a regression model</h2><span id='topic+regplot'></span>

<h3>Description</h3>

<p>Plot a regresion model on a 2-D plot. The predictor <code>x</code> should be one-dimensional.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>regplot(model, x, y, margin = 0.1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="regplot_+3A_model">model</code></td>
<td>
<p>The model to be plotted.</p>
</td></tr>
<tr><td><code id="regplot_+3A_x">x</code></td>
<td>
<p>The predictor <code>vector</code>.</p>
</td></tr>
<tr><td><code id="regplot_+3A_y">y</code></td>
<td>
<p>The response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="regplot_+3A_margin">margin</code></td>
<td>
<p>A margin parameter.</p>
</td></tr>
<tr><td><code id="regplot_+3A_...">...</code></td>
<td>
<p>Other graphical parameters</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (cars)
model = POLYREG (cars [, -2], cars [, 2])
regplot (model, cars [, -2], cars [, 2])
</code></pre>

<hr>
<h2 id='resplot'>Plot the studentized residuals of a linear regression model</h2><span id='topic+resplot'></span>

<h3>Description</h3>

<p>Plot the studentized residuals of a linear regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resplot(model, index = NULL, labels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="resplot_+3A_model">model</code></td>
<td>
<p>The model to be plotted.</p>
</td></tr>
<tr><td><code id="resplot_+3A_index">index</code></td>
<td>
<p>The index of the variable used for for the x-axis.</p>
</td></tr>
<tr><td><code id="resplot_+3A_labels">labels</code></td>
<td>
<p>The labels of the instances.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (trees)
model = LINREG (trees [, -3], trees [, 3])
resplot (model) # Ordered by index
resplot (model, index = 0) # Ordered by variable "Volume" (dependant variable)
resplot (model, index = 1) # Ordered by variable "Girth" (independant variable)
resplot (model, index = 2) # Ordered by variable "Height" (independant variable)
</code></pre>

<hr>
<h2 id='roc.curves'>Plot ROC Curves</h2><span id='topic+roc.curves'></span>

<h3>Description</h3>

<p>This function plots ROC Curves of several classification predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>roc.curves(predictions, gt, methods.names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="roc.curves_+3A_predictions">predictions</code></td>
<td>
<p>The predictions of a classification model (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="roc.curves_+3A_gt">gt</code></td>
<td>
<p>Actual labels of the dataset (<code>factor</code> or <code>vector</code>).</p>
</td></tr>
<tr><td><code id="roc.curves_+3A_methods.names">methods.names</code></td>
<td>
<p>The name of the compared methods (<code>vector</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the predictions (numeric value).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cost.curves">cost.curves</a></code>, <code><a href="#topic+performance">performance</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = iris
levels (d [, 5]) = c ("+", "+", "-") # Building a two classes dataset
model.nb = NB (d [, -5], d [, 5])
model.lda = LDA (d [, -5], d [, 5])
pred.nb = predict (model.nb, d [, -5])
pred.lda = predict (model.lda, d [, -5])
roc.curves (cbind (pred.nb, pred.lda), d [, 5], c ("NB", "LDA"))
</code></pre>

<hr>
<h2 id='rotation'>Rotation</h2><span id='topic+rotation'></span>

<h3>Description</h3>

<p>Rotation on two variables of a numeric dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rotation(d, angle, axis = 1:2, range = 2 * pi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rotation_+3A_d">d</code></td>
<td>
<p>The dataset.</p>
</td></tr>
<tr><td><code id="rotation_+3A_angle">angle</code></td>
<td>
<p>The angle of the rotation.</p>
</td></tr>
<tr><td><code id="rotation_+3A_axis">axis</code></td>
<td>
<p>The axis.</p>
</td></tr>
<tr><td><code id="rotation_+3A_range">range</code></td>
<td>
<p>The range of the angle (360, 2*pi, 100, ...)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A rotated data matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d = data.parabol ()
d [, -3] = rotation (d [, -3], 45, range = 360)
plotdata (d [, -3], d [, 3])
</code></pre>

<hr>
<h2 id='runningtime'>Running time</h2><span id='topic+runningtime'></span>

<h3>Description</h3>

<p>Return the running time of a function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runningtime(FUN, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runningtime_+3A_fun">FUN</code></td>
<td>
<p>The function to be evaluated.</p>
</td></tr>
<tr><td><code id="runningtime_+3A_...">...</code></td>
<td>
<p>The parameters to be passes to function <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The running time of function <code>FUN</code>.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+difftime">difftime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sqrt (x = 1:100)
runningtime (sqrt, x = 1:100)
</code></pre>

<hr>
<h2 id='scatterplot'>Clustering Scatter Plots</h2><span id='topic+scatterplot'></span>

<h3>Description</h3>

<p>Produce a scatter plot for clustering results. If the dataset has more than two dimensions, the scatter plot will show the two first PCA axes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scatterplot(
  d,
  clusters,
  centers = NULL,
  labels = FALSE,
  ellipses = FALSE,
  legend = c("auto1", "auto2"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scatterplot_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="scatterplot_+3A_clusters">clusters</code></td>
<td>
<p>Cluster labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="scatterplot_+3A_centers">centers</code></td>
<td>
<p>Coordinates of the cluster centers.</p>
</td></tr>
<tr><td><code id="scatterplot_+3A_labels">labels</code></td>
<td>
<p>Indicates whether or not labels (row names) should be showned on the plot.</p>
</td></tr>
<tr><td><code id="scatterplot_+3A_ellipses">ellipses</code></td>
<td>
<p>Indicates whether or not ellipses should be drawned around clusters.</p>
</td></tr>
<tr><td><code id="scatterplot_+3A_legend">legend</code></td>
<td>
<p>Indicates where the legend is placed on the graphics.</p>
</td></tr>
<tr><td><code id="scatterplot_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
km = KMEANS (iris [, -5], k = 3)
scatterplot (iris [, -5], km$cluster)
</code></pre>

<hr>
<h2 id='selectfeatures'>Feature selection for classification</h2><span id='topic+selectfeatures'></span>

<h3>Description</h3>

<p>Select a subset of features for a classification task.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>selectfeatures(
  train,
  labels,
  algorithm = c("ranking", "forward", "backward", "exhaustive"),
  unieval = if (algorithm[1] == "ranking") c("fisher", "fstat", "relief", "inertiaratio")
    else NULL,
  uninb = NULL,
  unithreshold = NULL,
  multieval = if (algorithm[1] == "ranking") NULL else c("mrmr", "cfs", "fstat",
    "inertiaratio", "wrapper"),
  wrapmethod = NULL,
  keep = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="selectfeatures_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_algorithm">algorithm</code></td>
<td>
<p>The feature selection algorithm.</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_unieval">unieval</code></td>
<td>
<p>The (univariate) evaluation criterion. <code>uninb</code>, <code>unithreshold</code> or <code>multieval</code> must be specified.</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_uninb">uninb</code></td>
<td>
<p>The number of selected feature (univariate evaluation).</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_unithreshold">unithreshold</code></td>
<td>
<p>The threshold for selecting feature (univariate evaluation).</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_multieval">multieval</code></td>
<td>
<p>The (multivariate) evaluation criterion.</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_wrapmethod">wrapmethod</code></td>
<td>
<p>The classification method used for the wrapper evaluation.</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_keep">keep</code></td>
<td>
<p>If true, the dataset is kept in the returned result.</p>
</td></tr>
<tr><td><code id="selectfeatures_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+FEATURESELECTION">FEATURESELECTION</a></code>, <code><a href="#topic+selection-class">selection-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
selectfeatures (iris [, -5], iris [, 5], algorithm = "forward", multieval = "fstat")
selectfeatures (iris [, -5], iris [, 5], algorithm = "ranking", uninb = 2)
selectfeatures (iris [, -5], iris [, 5], algorithm = "ranking",
                multieval = "wrapper", wrapmethod = LDA)

## End(Not run)
</code></pre>

<hr>
<h2 id='selection-class'>Feature selection</h2><span id='topic+selection-class'></span>

<h3>Description</h3>

<p>This class contains the result of feature selection algorithms.
</p>


<h3>Slots</h3>


<dl>
<dt><code>selection</code></dt><dd><p>A vector of integers indicating the selected features.</p>
</dd>
<dt><code>unieval</code></dt><dd><p>The evaluation of the features (univariate).</p>
</dd>
<dt><code>multieval</code></dt><dd><p>The evaluation of the selected features (multivariate).</p>
</dd>
<dt><code>algorithm</code></dt><dd><p>The algorithm used to select features.</p>
</dd>
<dt><code>univariate</code></dt><dd><p>The evaluation criterion (univariate).</p>
</dd>
<dt><code>nbfeatures</code></dt><dd><p>The number of features to be kept.</p>
</dd>
<dt><code>threshold</code></dt><dd><p>The threshold to decide whether a feature is kept or not..</p>
</dd>
<dt><code>multivariate</code></dt><dd><p>The evaluation criterion (multivariate).</p>
</dd>
<dt><code>dataset</code></dt><dd><p>The dataset described by the selected features only.</p>
</dd>
<dt><code>model</code></dt><dd><p>The classification model.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+FEATURESELECTION">FEATURESELECTION</a></code>, <code><a href="#topic+predict.selection">predict.selection</a></code>, <code><a href="#topic+selectfeatures">selectfeatures</a></code>
</p>

<hr>
<h2 id='snore'>Snore dataset</h2><span id='topic+snore'></span>

<h3>Description</h3>

<p>This dataset has been used in a study on snoring in Angers hospital.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snore
</code></pre>


<h3>Format</h3>

<p>The dataset has 100 instances described by 7 variables.
The variables are as follows:
</p>

<dl>
<dt><code>Age</code></dt><dd><p>In years.</p>
</dd>
<dt><code>Weights</code></dt><dd><p>In kg.</p>
</dd>
<dt><code>Height</code></dt><dd><p>In cm.</p>
</dd>
<dt><code>Alcool</code></dt><dd><p>Number of glass of alcool per day.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>M for male or F for female.</p>
</dd>
<dt><code>Snore</code></dt><dd><p>Snoring diagnosis (Y or N).</p>
</dd>
<dt><code>Tobacco</code></dt><dd><p>Y or N.</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="http://forge.info.univ-angers.fr/~gh/Datasets/datasets.htm">http://forge.info.univ-angers.fr/~gh/Datasets/datasets.htm</a>
</p>

<hr>
<h2 id='SOM'>Self-Organizing Maps clustering method</h2><span id='topic+SOM'></span>

<h3>Description</h3>

<p>Run the SOM algorithm for clustering.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SOM(
  d,
  xdim = floor(sqrt(nrow(d))),
  ydim = floor(sqrt(nrow(d))),
  rlen = 10000,
  post = c("none", "single", "ward"),
  k = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SOM_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="SOM_+3A_xdim">xdim</code>, <code id="SOM_+3A_ydim">ydim</code></td>
<td>
<p>The dimensions of the grid.</p>
</td></tr>
<tr><td><code id="SOM_+3A_rlen">rlen</code></td>
<td>
<p>The number of iterations.</p>
</td></tr>
<tr><td><code id="SOM_+3A_post">post</code></td>
<td>
<p>The post-treatement method: <code>"none"</code> (None), <code>"single"</code> (Single link) or <code>"ward"</code> (Ward clustering).</p>
</td></tr>
<tr><td><code id="SOM_+3A_k">k</code></td>
<td>
<p>The number of cluster (only used if <code>post</code> is different from <code>"none"</code>).</p>
</td></tr>
<tr><td><code id="SOM_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The fitted Kohonen's map as an object of class <code>som</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.som">plot.som</a></code>, <code><a href="#topic+som-class">som-class</a></code>, <code><a href="kohonen.html#topic+som">som</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
SOM (iris [, -5], xdim = 5, ydim = 5, post = "ward", k = 3)
</code></pre>

<hr>
<h2 id='som-class'>Self-Organizing Maps model</h2><span id='topic+som-class'></span>

<h3>Description</h3>

<p>This class contains the model obtained by the SOM method.
</p>


<h3>Slots</h3>


<dl>
<dt><code>som</code></dt><dd><p>An object of class <code>kohonen</code> representing the fitted map.</p>
</dd>
<dt><code>nodes</code></dt><dd><p>A <code>vector</code> of integer indicating the cluster to which each node is allocated.</p>
</dd>
<dt><code>cluster</code></dt><dd><p>A <code>vector</code> of integer indicating the cluster to which each observation is allocated.</p>
</dd>
<dt><code>data</code></dt><dd><p>The dataset that has been used to fit the map (as a <code>matrix</code>).</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+plot.som">plot.som</a></code>, <code><a href="#topic+SOM">SOM</a></code>, <code><a href="kohonen.html#topic+som">som</a></code>
</p>

<hr>
<h2 id='SPECTRAL'>Spectral clustering method</h2><span id='topic+SPECTRAL'></span>

<h3>Description</h3>

<p>Run a Spectral clustering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPECTRAL(d, k, sigma = 1, graph = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SPECTRAL_+3A_d">d</code></td>
<td>
<p>The dataset (<code>matrix</code> or <code>data.frame</code>).</p>
</td></tr>
<tr><td><code id="SPECTRAL_+3A_k">k</code></td>
<td>
<p>The number of cluster.</p>
</td></tr>
<tr><td><code id="SPECTRAL_+3A_sigma">sigma</code></td>
<td>
<p>Width of the gaussian used to build the affinity matrix.</p>
</td></tr>
<tr><td><code id="SPECTRAL_+3A_graph">graph</code></td>
<td>
<p>A logical indicating whether or not a graphic should be plotted (projection on the spectral space of the affinity matrix).</p>
</td></tr>
<tr><td><code id="SPECTRAL_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+spectral-class">spectral-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
SPECTRAL (iris [, -5], k = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='spectral-class'>Spectral clustering model</h2><span id='topic+spectral-class'></span>

<h3>Description</h3>

<p>This class contains the model obtained by Spectral clustering.
</p>


<h3>Slots</h3>


<dl>
<dt><code>cluster</code></dt><dd><p>A <code>vector</code> of integer indicating the cluster to which each observation is allocated.</p>
</dd>
<dt><code>proj</code></dt><dd><p>The projection of the dataset in the spectral space.</p>
</dd>
<dt><code>centers</code></dt><dd><p>The cluster centers (on the spectral space).</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+SPECTRAL">SPECTRAL</a></code>
</p>

<hr>
<h2 id='spine'>Spine dataset</h2><span id='topic+spine'></span><span id='topic+spine.train'></span><span id='topic+spine.test'></span>

<h3>Description</h3>

<p>The data have been organized in two different but related classification tasks.
The first task consists in classifying patients as belonging to one out of three categories: Normal, Disk Hernia or Spondylolisthesis.
For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'.
Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal or Abnormal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spine
spine.train
spine.test
</code></pre>


<h3>Format</h3>

<p>The dataset has 310 instances described by 8 variables.
Variables V1 to V6 are biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine.
The variable Classif2 is the classification into two classes <code>AB</code> and <code>NO</code>.
The variable Classif3 is the classification into 3 classes <code>DH</code>, <code>SL</code> and <code>NO</code>.
<code>spine.train</code> contains 217 instances and <code>spine.test</code> contains 93.
</p>


<h3>Source</h3>

<p><a href="http://archive.ics.uci.edu/ml/datasets/vertebral+column">http://archive.ics.uci.edu/ml/datasets/vertebral+column</a>
</p>

<hr>
<h2 id='splitdata'>Splits a dataset into training set and test set</h2><span id='topic+splitdata'></span>

<h3>Description</h3>

<p>This function splits a dataset into training set and test set. Return an object of class <code><a href="#topic+dataset-class">dataset-class</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitdata(dataset, target, size = round(0.7 * nrow(dataset)), seed = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitdata_+3A_dataset">dataset</code></td>
<td>
<p>The dataset to be split (<code>data.frame</code> or <code>matrix</code>).</p>
</td></tr>
<tr><td><code id="splitdata_+3A_target">target</code></td>
<td>
<p>The column index of the target variable (class label or response variable).</p>
</td></tr>
<tr><td><code id="splitdata_+3A_size">size</code></td>
<td>
<p>The size of the training set (as an integer value).</p>
</td></tr>
<tr><td><code id="splitdata_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+dataset-class">dataset-class</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dataset-class">dataset-class</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
d = splitdata (iris, 5)
str (d)
</code></pre>

<hr>
<h2 id='stability'>Clustering evaluation through stability</h2><span id='topic+stability'></span>

<h3>Description</h3>

<p>Evaluation a clustering algorithm according to stability, through a bootstrap procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stability(
  clusteringmethods,
  d,
  originals = NULL,
  eval = "jaccard",
  type = c("cluster", "global"),
  nsampling = 10,
  seed = NULL,
  names = NULL,
  graph = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stability_+3A_clusteringmethods">clusteringmethods</code></td>
<td>
<p>The clustering methods to be evaluated.</p>
</td></tr>
<tr><td><code id="stability_+3A_d">d</code></td>
<td>
<p>The dataset.</p>
</td></tr>
<tr><td><code id="stability_+3A_originals">originals</code></td>
<td>
<p>The original clustering.</p>
</td></tr>
<tr><td><code id="stability_+3A_eval">eval</code></td>
<td>
<p>The evaluation criteria.</p>
</td></tr>
<tr><td><code id="stability_+3A_type">type</code></td>
<td>
<p>The comparison method.</p>
</td></tr>
<tr><td><code id="stability_+3A_nsampling">nsampling</code></td>
<td>
<p>The number of bootstrap runs.</p>
</td></tr>
<tr><td><code id="stability_+3A_seed">seed</code></td>
<td>
<p>A specified seed for random number generation (useful for testing different method with the same bootstap samplings).</p>
</td></tr>
<tr><td><code id="stability_+3A_names">names</code></td>
<td>
<p>Method names.</p>
</td></tr>
<tr><td><code id="stability_+3A_graph">graph</code></td>
<td>
<p>Indicates wether or not a graphic is potted for each sample.</p>
</td></tr>
<tr><td><code id="stability_+3A_...">...</code></td>
<td>
<p>Parameters to be passed to the clustering algorithms.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The evaluation of the clustering algorithm(s) (numeric values).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+compare">compare</a></code>, <code><a href="#topic+intern">intern</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
stability (KMEANS, iris [, -5], seed = 0, k = 3)
stability (KMEANS, iris [, -5], seed = 0, k = 3, eval = c ("jaccard", "accuracy"), type = "global")
stability (KMEANS, iris [, -5], seed = 0, k = 3, type = "cluster")
stability (KMEANS, iris [, -5], seed = 0, k = 3, eval = c ("jaccard", "accuracy"), type = "cluster")
stability (c (KMEANS, HCA), iris [, -5], seed = 0, k = 3)
stability (c (KMEANS, HCA), iris [, -5], seed = 0, k = 3,
eval = c ("jaccard", "accuracy"), type = "global")
stability (c (KMEANS, HCA), iris [, -5], seed = 0, k = 3, type = "cluster")
stability (c (KMEANS, HCA), iris [, -5], seed = 0, k = 3,
eval = c ("jaccard", "accuracy"), type = "cluster")
stability (KMEANS, iris [, -5], originals = KMEANS (iris [, -5], k = 3)$cluster, seed = 0, k = 3)
stability (KMEANS, iris [, -5], originals = KMEANS (iris [, -5], k = 3), seed = 0, k = 3)

## End(Not run)
</code></pre>

<hr>
<h2 id='STUMP'>Classification using one-level decision tree</h2><span id='topic+STUMP'></span>

<h3>Description</h3>

<p>This function builds a classification model using CART with maxdepth = 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>STUMP(train, labels, randomvar = TRUE, tune = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="STUMP_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="STUMP_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="STUMP_+3A_randomvar">randomvar</code></td>
<td>
<p>If true, the model uses a random variable.</p>
</td></tr>
<tr><td><code id="STUMP_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="STUMP_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+CART">CART</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
STUMP (iris [, -5], iris [, 5])
</code></pre>

<hr>
<h2 id='summary.apriori'>Print summary of a classification model obtained by APRIORI</h2><span id='topic+summary.apriori'></span>

<h3>Description</h3>

<p>Print summary of the set of rules in the classification model obtained by APRIORI.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'apriori'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.apriori_+3A_object">object</code></td>
<td>
<p>The model to be printed.</p>
</td></tr>
<tr><td><code id="summary.apriori_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+APRIORI">APRIORI</a></code>, <code><a href="#topic+predict.apriori">predict.apriori</a></code>, <code><a href="#topic+print.apriori">print.apriori</a></code>,
<code><a href="#topic+apriori-class">apriori-class</a></code>, <code><a href="arules.html#topic+apriori">apriori</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require ("datasets")
data (iris)
d = discretizeDF (iris,
    default = list (method = "interval", breaks = 3, labels = c ("small", "medium", "large")))
model = APRIORI (d [, -5], d [, 5], supp = .1, conf = .9, prune = TRUE)
summary (model)
</code></pre>

<hr>
<h2 id='SVD'>Singular Value Decomposition</h2><span id='topic+SVD'></span>

<h3>Description</h3>

<p>Return the SVD decomposition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVD(x, ndim = min(nrow(x), ncol(x)), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVD_+3A_x">x</code></td>
<td>
<p>A numeric dataset (data.frame or matrix).</p>
</td></tr>
<tr><td><code id="SVD_+3A_ndim">ndim</code></td>
<td>
<p>The number of dimensions.</p>
</td></tr>
<tr><td><code id="SVD_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="base.html#topic+svd">svd</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
SVD (iris [, -5])
</code></pre>

<hr>
<h2 id='SVM'>Classification using Support Vector Machine</h2><span id='topic+SVM'></span>

<h3>Description</h3>

<p>This function builds a classification model using Support Vector Machine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVM(
  train,
  labels,
  gamma = 2^(-3:3),
  cost = 2^(-3:3),
  kernel = c("radial", "linear"),
  methodparameters = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVM_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="SVM_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="SVM_+3A_gamma">gamma</code></td>
<td>
<p>The gamma parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVM_+3A_cost">cost</code></td>
<td>
<p>The cost parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVM_+3A_kernel">kernel</code></td>
<td>
<p>The kernel type.</p>
</td></tr>
<tr><td><code id="SVM_+3A_methodparameters">methodparameters</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>gamma</code> and <code>cost</code>.</p>
</td></tr>
<tr><td><code id="SVM_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="SVM_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+SVMl">SVMl</a></code>, <code><a href="#topic+SVMr">SVMr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
SVM (iris [, -5], iris [, 5], kernel = "linear", cost = 1)
SVM (iris [, -5], iris [, 5], kernel = "radial", gamma = 1, cost = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='SVMl'>Classification using Support Vector Machine with a linear kernel</h2><span id='topic+SVMl'></span>

<h3>Description</h3>

<p>This function builds a classification model using Support Vector Machine with a linear kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVMl(
  train,
  labels,
  cost = 2^(-3:3),
  methodparameters = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVMl_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="SVMl_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="SVMl_+3A_cost">cost</code></td>
<td>
<p>The cost parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVMl_+3A_methodparameters">methodparameters</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>gamma</code> and <code>cost</code>.</p>
</td></tr>
<tr><td><code id="SVMl_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="SVMl_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+SVM">SVM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
SVMl (iris [, -5], iris [, 5], cost = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='SVMr'>Classification using Support Vector Machine with a radial kernel</h2><span id='topic+SVMr'></span>

<h3>Description</h3>

<p>This function builds a classification model using Support Vector Machine with a radial kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVMr(
  train,
  labels,
  gamma = 2^(-3:3),
  cost = 2^(-3:3),
  methodparameters = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVMr_+3A_train">train</code></td>
<td>
<p>The training set (description), as a <code>data.frame</code>.</p>
</td></tr>
<tr><td><code id="SVMr_+3A_labels">labels</code></td>
<td>
<p>Class labels of the training set (<code>vector</code> or <code>factor</code>).</p>
</td></tr>
<tr><td><code id="SVMr_+3A_gamma">gamma</code></td>
<td>
<p>The gamma parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVMr_+3A_cost">cost</code></td>
<td>
<p>The cost parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVMr_+3A_methodparameters">methodparameters</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>gamma</code> and <code>cost</code>.</p>
</td></tr>
<tr><td><code id="SVMr_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="SVMr_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+SVM">SVM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (iris)
SVMr (iris [, -5], iris [, 5], gamma = 1, cost = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='SVR'>Regression using Support Vector Machine</h2><span id='topic+SVR'></span>

<h3>Description</h3>

<p>This function builds a regression model using Support Vector Machine.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVR(
  x,
  y,
  gamma = 2^(-3:3),
  cost = 2^(-3:3),
  kernel = c("radial", "linear"),
  epsilon = c(0.1, 0.5, 1),
  params = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVR_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="SVR_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="SVR_+3A_gamma">gamma</code></td>
<td>
<p>The gamma parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVR_+3A_cost">cost</code></td>
<td>
<p>The cost parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVR_+3A_kernel">kernel</code></td>
<td>
<p>The kernel type.</p>
</td></tr>
<tr><td><code id="SVR_+3A_epsilon">epsilon</code></td>
<td>
<p>The epsilon parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVR_+3A_params">params</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>epsilon</code>, <code>gamma</code> and <code>cost</code>.</p>
</td></tr>
<tr><td><code id="SVR_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="SVR_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+SVRl">SVRl</a></code>, <code><a href="#topic+SVRr">SVRr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (trees)
SVR (trees [, -3], trees [, 3], kernel = "linear", cost = 1)
SVR (trees [, -3], trees [, 3], kernel = "radial", gamma = 1, cost = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='SVRl'>Regression using Support Vector Machine with a linear kernel</h2><span id='topic+SVRl'></span>

<h3>Description</h3>

<p>This function builds a regression model using Support Vector Machine with a linear kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVRl(
  x,
  y,
  cost = 2^(-3:3),
  epsilon = c(0.1, 0.5, 1),
  params = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVRl_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="SVRl_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="SVRl_+3A_cost">cost</code></td>
<td>
<p>The cost parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVRl_+3A_epsilon">epsilon</code></td>
<td>
<p>The epsilon parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVRl_+3A_params">params</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>epsilon</code>, <code>gamma</code> and <code>cost</code>.</p>
</td></tr>
<tr><td><code id="SVRl_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="SVRl_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+SVR">SVR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (trees)
SVRl (trees [, -3], trees [, 3], cost = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='SVRr'>Regression using Support Vector Machine with a radial kernel</h2><span id='topic+SVRr'></span>

<h3>Description</h3>

<p>This function builds a regression model using Support Vector Machine with a radial kernel.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SVRr(
  x,
  y,
  gamma = 2^(-3:3),
  cost = 2^(-3:3),
  epsilon = c(0.1, 0.5, 1),
  params = NULL,
  tune = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SVRr_+3A_x">x</code></td>
<td>
<p>Predictor <code>matrix</code>.</p>
</td></tr>
<tr><td><code id="SVRr_+3A_y">y</code></td>
<td>
<p>Response <code>vector</code>.</p>
</td></tr>
<tr><td><code id="SVRr_+3A_gamma">gamma</code></td>
<td>
<p>The gamma parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVRr_+3A_cost">cost</code></td>
<td>
<p>The cost parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVRr_+3A_epsilon">epsilon</code></td>
<td>
<p>The epsilon parameter (if a vector, cross-over validation is used to chose the best size).</p>
</td></tr>
<tr><td><code id="SVRr_+3A_params">params</code></td>
<td>
<p>Object containing the parameters. If given, it replaces <code>epsilon</code>, <code>gamma</code> and <code>cost</code>.</p>
</td></tr>
<tr><td><code id="SVRr_+3A_tune">tune</code></td>
<td>
<p>If true, the function returns paramters instead of a classification model.</p>
</td></tr>
<tr><td><code id="SVRr_+3A_...">...</code></td>
<td>
<p>Other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The classification model.
</p>


<h3>See Also</h3>

<p><code><a href="e1071.html#topic+svm">svm</a></code>, <code><a href="#topic+SVR">SVR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (datasets)
data (trees)
SVRr (trees [, -3], trees [, 3], gamma = 1, cost = 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='temperature'>Temperature dataset</h2><span id='topic+temperature'></span>

<h3>Description</h3>

<p>The data contains temperature measurement and geographic coordinates of 35 european cities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>temperature
</code></pre>


<h3>Format</h3>

<p>The dataset has 35 instances described by 17 variables.
Average temperature of the 12 month. Mean and amplitude of the temperature. Latitude and longitude of the city. Localisation in Europe.
</p>

<hr>
<h2 id='TEXTMINING'>Text mining</h2><span id='topic+TEXTMINING'></span>

<h3>Description</h3>

<p>Apply data mining function on vectorized text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TEXTMINING(corpus, miningmethod, vector = c("docs", "words"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TEXTMINING_+3A_corpus">corpus</code></td>
<td>
<p>The corpus.</p>
</td></tr>
<tr><td><code id="TEXTMINING_+3A_miningmethod">miningmethod</code></td>
<td>
<p>The data mining method.</p>
</td></tr>
<tr><td><code id="TEXTMINING_+3A_vector">vector</code></td>
<td>
<p>Indicates the type of vectorization, documents (TF-IDF) or words (GloVe).</p>
</td></tr>
<tr><td><code id="TEXTMINING_+3A_...">...</code></td>
<td>
<p>Parameters passed to the vectorisation and to the data mining method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The result of the data mining method.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.textmining">predict.textmining</a></code>, <code><a href="#topic+textmining-class">textmining-class</a></code>, <code><a href="#topic+vectorize.docs">vectorize.docs</a></code>, <code><a href="#topic+vectorize.words">vectorize.words</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (text2vec)
data ("movie_review")
d = movie_review [, 2:3]
d [, 1] = factor (d [, 1])
d = splitdata (d, 1)
model = TEXTMINING (d$train.x, NB, labels = d$train.y, mincount = 50)
pred = predict (model, d$test.x)
evaluation (pred, d$test.y)
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
clusters = TEXTMINING (text, HCA, vector = "words", k = 9, maxwords = 100)
plotclus (clusters$res, text, type = "tree", labels = TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='textmining-class'>Text mining object</h2><span id='topic+textmining-class'></span>

<h3>Description</h3>

<p>Object used for text mining.
</p>


<h3>Slots</h3>


<dl>
<dt><code>vectorizer</code></dt><dd><p>The vectorizer.</p>
</dd>
<dt><code>vectors</code></dt><dd><p>The vectorized dataset.</p>
</dd>
<dt><code>res</code></dt><dd><p>The result of the text mining method.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+TEXTMINING">TEXTMINING</a></code>, <code><a href="#topic+vectorize.docs">vectorize.docs</a></code>
</p>

<hr>
<h2 id='titanic'>Titanic dataset</h2><span id='topic+titanic'></span>

<h3>Description</h3>

<p>This dataset from the British Board of Trade depict the fate of the passengers and crew during the RMS Titanic disaster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>titanic
</code></pre>


<h3>Format</h3>

<p>The dataset has 2201 instances described by 4 variables.
The variables are as follows:
</p>

<dl>
<dt><code>Category</code></dt><dd><p>1st, 2nd, 3rd Class or Crew.</p>
</dd>
<dt><code>Age</code></dt><dd><p>Adult or Child.</p>
</dd>
<dt><code>Sex</code></dt><dd><p>Female or Male.</p>
</dd>
<dt><code>Fate</code></dt><dd><p>Casualty or Survivor.</p>
</dd>
</dl>



<h3>Source</h3>

<p>British Board of Trade (1990), Report on the Loss of the â€˜Titanicâ€™ (S.S.). British Board of Trade Inquiry Report (reprint). Gloucester, UK: Allan Sutton Publishing.
</p>


<h3>See Also</h3>

<p><code><a href="datasets.html#topic+Titanic">Titanic</a></code>
</p>

<hr>
<h2 id='treeplot'>Dendrogram Plots</h2><span id='topic+treeplot'></span>

<h3>Description</h3>

<p>Draws a dendrogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>treeplot(
  clustering,
  labels = FALSE,
  k = NULL,
  split = TRUE,
  horiz = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="treeplot_+3A_clustering">clustering</code></td>
<td>
<p>The dendrogram to be plotted (result of <code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="cluster.html#topic+agnes">agnes</a></code> or <code><a href="#topic+HCA">HCA</a></code>).</p>
</td></tr>
<tr><td><code id="treeplot_+3A_labels">labels</code></td>
<td>
<p>Indicates whether or not labels (row names) should be showned on the plot.</p>
</td></tr>
<tr><td><code id="treeplot_+3A_k">k</code></td>
<td>
<p>Number of clusters. If not specified an &quot;optimal&quot; value is determined.</p>
</td></tr>
<tr><td><code id="treeplot_+3A_split">split</code></td>
<td>
<p>Indicates wheather or not the clusters should be highlighted in the graphics.</p>
</td></tr>
<tr><td><code id="treeplot_+3A_horiz">horiz</code></td>
<td>
<p>Indicates if the dendrogram should be drawn horizontally or not.</p>
</td></tr>
<tr><td><code id="treeplot_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dendrogram">dendrogram</a></code>, <code><a href="#topic+HCA">HCA</a></code>, <code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="cluster.html#topic+agnes">agnes</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
hca = HCA (iris [, -5], method = "ward", k = 3)
treeplot (hca)
</code></pre>

<hr>
<h2 id='TSNE'>t-distributed Stochastic Neighbor Embedding</h2><span id='topic+TSNE'></span>

<h3>Description</h3>

<p>Return the t-SNE dimensionality reduction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TSNE(x, perplexity = 30, nstart = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TSNE_+3A_x">x</code></td>
<td>
<p>A numeric dataset (data.frame or matrix).</p>
</td></tr>
<tr><td><code id="TSNE_+3A_perplexity">perplexity</code></td>
<td>
<p>Specification of the perplexity.</p>
</td></tr>
<tr><td><code id="TSNE_+3A_nstart">nstart</code></td>
<td>
<p>How many random sets should be chosen?</p>
</td></tr>
<tr><td><code id="TSNE_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="Rtsne.html#topic+Rtsne">Rtsne</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require (datasets)
data (iris)
TSNE (iris [, -5])
</code></pre>

<hr>
<h2 id='universite'>University dataset</h2><span id='topic+universite'></span>

<h3>Description</h3>

<p>The dataset presents a french university demographics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>universite
</code></pre>


<h3>Format</h3>

<p>The dataset has 10 instances (university departments) described by 12 variables.
The fist six variables are the number of female and male student
studying for bachelor degree (Licence), master degree (Master) and doctorate (Doctorat).
The six last variables are obtained by combining the first ones.
</p>


<h3>Source</h3>

<p><a href="https://husson.github.io/data.html">https://husson.github.io/data.html</a>
</p>

<hr>
<h2 id='vectorize.docs'>Document vectorization</h2><span id='topic+vectorize.docs'></span>

<h3>Description</h3>

<p>Vectorize a corpus of documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vectorize.docs(
  vectorizer = NULL,
  corpus = NULL,
  lang = "en",
  stopwords = lang,
  ngram = 1,
  mincount = 10,
  minphrasecount = NULL,
  transform = c("tfidf", "lsa", "l1", "none"),
  latentdim = 50,
  returndata = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vectorize.docs_+3A_vectorizer">vectorizer</code></td>
<td>
<p>The document vectorizer.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_corpus">corpus</code></td>
<td>
<p>The corpus of documents (a vector of characters).</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_lang">lang</code></td>
<td>
<p>The language of the documents (NULL if no stemming).</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_stopwords">stopwords</code></td>
<td>
<p>Stopwords, or the language of the documents. NULL if stop words should not be removed.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_ngram">ngram</code></td>
<td>
<p>maximum size of n-grams.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_mincount">mincount</code></td>
<td>
<p>Minimum word count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_minphrasecount">minphrasecount</code></td>
<td>
<p>Minimum collocation of words count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_transform">transform</code></td>
<td>
<p>Transformation (TF-IDF, LSA, L1 normanization, or nothing).</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_latentdim">latentdim</code></td>
<td>
<p>Number of latent dimensions if LSA transformation is performed.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_returndata">returndata</code></td>
<td>
<p>If true, the vectorized documents are returned. If false, a &quot;vectorizer&quot; is returned.</p>
</td></tr>
<tr><td><code id="vectorize.docs_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vectorized documents.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+query.docs">query.docs</a></code>, <code><a href="stopwords.html#topic+stopwords">stopwords</a></code>, <code><a href="text2vec.html#topic+vectorizers">vectorizers</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require (text2vec)
data ("movie_review")
# Clustering
docs = vectorize.docs (corpus = movie_review$review, transform = "tfidf")
km = KMEANS (docs [sample (nrow (docs), 100), ], k = 10)
# Classification
d = movie_review [, 2:3]
d [, 1] = factor (d [, 1])
d = splitdata (d, 1)
vectorizer = vectorize.docs (corpus = d$train.x,
                             returndata = FALSE, mincount = 50)
train = vectorize.docs (corpus = d$train.x, vectorizer = vectorizer)
test = vectorize.docs (corpus = d$test.x, vectorizer = vectorizer)
model = NB (as.matrix (train), d$train.y)
pred = predict (model, as.matrix (test))
evaluation (pred, d$test.y)

## End(Not run)
</code></pre>

<hr>
<h2 id='vectorize.words'>Word vectorization</h2><span id='topic+vectorize.words'></span>

<h3>Description</h3>

<p>Vectorize words from a corpus of documents.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vectorize.words(
  corpus = NULL,
  ndim = 50,
  maxwords = NULL,
  mincount = 5,
  minphrasecount = NULL,
  window = 5,
  maxcooc = 10,
  maxiter = 10,
  epsilon = 0.01,
  lang = "en",
  stopwords = lang,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vectorize.words_+3A_corpus">corpus</code></td>
<td>
<p>The corpus of documents (a vector of characters).</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_ndim">ndim</code></td>
<td>
<p>The number of dimensions of the vector space.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_maxwords">maxwords</code></td>
<td>
<p>The maximum number of words.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_mincount">mincount</code></td>
<td>
<p>Minimum word count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_minphrasecount">minphrasecount</code></td>
<td>
<p>Minimum collocation of words count to be considered as frequent.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_window">window</code></td>
<td>
<p>Window for term-co-occurence matrix construction.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_maxcooc">maxcooc</code></td>
<td>
<p>Maximum number of co-occurrences to use in the weighting function.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iteration to fit the GloVe model.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_epsilon">epsilon</code></td>
<td>
<p>Defines early stopping strategy when fit the GloVe model.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_lang">lang</code></td>
<td>
<p>The language of the documents (NULL if no stemming).</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_stopwords">stopwords</code></td>
<td>
<p>Stopwords, or the language of the documents. NULL if stop words should not be removed.</p>
</td></tr>
<tr><td><code id="vectorize.words_+3A_...">...</code></td>
<td>
<p>Other parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The vectorized words.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+query.words">query.words</a></code>, <code><a href="stopwords.html#topic+stopwords">stopwords</a></code>, <code><a href="text2vec.html#topic+vectorizers">vectorizers</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
text = loadtext ("http://mattmahoney.net/dc/text8.zip")
words = vectorize.words (text, minphrasecount = 50)
query.words (words, origin = "paris", sub = "france", add = "germany")
query.words (words, origin = "berlin", sub = "germany", add = "france")
query.words (words, origin = "new_zealand")

## End(Not run)
</code></pre>

<hr>
<h2 id='vectorizer-class'>Document vectorization object</h2><span id='topic+vectorizer-class'></span>

<h3>Description</h3>

<p>This class contains a vectorization model for textual documents.
</p>


<h3>Slots</h3>


<dl>
<dt><code>vectorizer</code></dt><dd><p>The vectorizer.</p>
</dd>
<dt><code>transform</code></dt><dd><p>The transformation to be applied after vectorization (normalization, TF-IDF).</p>
</dd>
<dt><code>phrases</code></dt><dd><p>The phrase detection method.</p>
</dd>
<dt><code>tfidf</code></dt><dd><p>The TF-IDF transformation.</p>
</dd>
<dt><code>lsa</code></dt><dd><p>The LSA transformation.</p>
</dd>
<dt><code>tokens</code></dt><dd><p>The token from the original document.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+vectorize.docs">vectorize.docs</a></code>, <code><a href="#topic+query.docs">query.docs</a></code>
</p>

<hr>
<h2 id='vowels'>Vowels dataset</h2><span id='topic+vowels'></span><span id='topic+vowels.train'></span><span id='topic+vowels.test'></span>

<h3>Description</h3>

<p>Excerpt of the Letter Recognition Data Set (UCI repository).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vowels
vowels.train
vowels.test
</code></pre>


<h3>Format</h3>

<p>The dataset has 4664 instances described by 17 variables. The first variable is the classification into 6 classes (letter A, E, I, O, U and Y).
<code>vowels.train</code> contains 233 instances and <code>vowels.test</code> contains 4431.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/letter+recognition">https://archive.ics.uci.edu/ml/datasets/letter+recognition</a>
</p>

<hr>
<h2 id='wheat'>Wheat dataset</h2><span id='topic+wheat'></span>

<h3>Description</h3>

<p>The data contains kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected.
High quality visualization of the internal kernel structure was detected using a soft X-ray technique. The images were recorded on 13x18 cm X-ray KODAK plates.
Source : Institute of Agrophysics of the Polish Academy of Sciences in Lublin.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wheat
</code></pre>


<h3>Format</h3>

<p>The dataset has 210 instances described by 8 variables:
area, perimeter, compactness, length, width, asymmetry coefficient, groove length and variery.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/seeds">https://archive.ics.uci.edu/ml/datasets/seeds</a>
</p>

<hr>
<h2 id='wine'>Wine dataset</h2><span id='topic+wine'></span>

<h3>Description</h3>

<p>These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars.
The analysis determined the quantities of 13 constituents found in each of the three types of wines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wine
</code></pre>


<h3>Format</h3>

<p>There are 178 observations and 14 variables.
The first variable is the class label (<code>1</code>, <code>2</code>, <code>3</code>).
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/wine">https://archive.ics.uci.edu/ml/datasets/wine</a>
</p>

<hr>
<h2 id='zoo'>Zoo dataset</h2><span id='topic+zoo'></span>

<h3>Description</h3>

<p>Animal description based on various features.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zoo
</code></pre>


<h3>Format</h3>

<p>The dataset has 101 instances described by 17 qualitative variables.
</p>


<h3>Source</h3>

<p><a href="https://archive.ics.uci.edu/ml/datasets/zoo">https://archive.ics.uci.edu/ml/datasets/zoo</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
