<!DOCTYPE html><html lang="en"><head><title>Help for package tea</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {tea}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#tea-package'>
<p>Threshold Estimation Approaches</p></a></li>
<li><a href='#althill'><p>Alternative Hill Plot</p></a></li>
<li><a href='#avhill'><p>Averaged Hill Plot</p></a></li>
<li><a href='#dAMSE'><p>Minimizing the AMSE of the Hill estimator with respect to k</p></a></li>
<li><a href='#danielsson'><p>A Double Bootstrap Procedure for Choosing the Optimal Sample Fraction</p></a></li>
<li><a href='#danish'>
<p>Danish Fire Insurance Claims</p></a></li>
<li><a href='#DK'><p>A Bias-based procedure for Choosing the Optimal Sample Fraction</p></a></li>
<li><a href='#eye'><p>Automated Approach for Interpreting the Hill-Plot</p></a></li>
<li><a href='#ggplot'><p>Gerstengarbe Plot</p></a></li>
<li><a href='#GH'><p>A Bias-based procedure for Choosing the Optimal Threshold</p></a></li>
<li><a href='#gomes'><p>A Double Bootstrap Procedure for Choosing the Optimal Sample Fraction</p></a></li>
<li><a href='#gpd'><p>The Generalized Pareto Distribution (GPD)</p></a></li>
<li><a href='#gpdFit'><p>Parameter estimation for the Generalized Pareto Distribution (GPD)</p></a></li>
<li><a href='#hall'><p>A Single Bootstrap Procedure for Choosing the Optimal Sample Fraction</p></a></li>
<li><a href='#Himp'><p>A Single Bootstrap Procedure for Choosing the Optimal Sample Fraction</p></a></li>
<li><a href='#HW'><p>Minimizing the AMSE of the Hill estimator with respect to k</p></a></li>
<li><a href='#mindist'><p>Minimizing the distance between the empirical tail and a theoretical Pareto tail with respect to k.</p></a></li>
<li><a href='#PS'><p>Sample Path Stability Algorithm</p></a></li>
<li><a href='#qqestplot'><p>QQ-Estimator-Plot</p></a></li>
<li><a href='#qqgpd'><p>QQ-Plot against the generalized Pareto distribution for given number of exceedances</p></a></li>
<li><a href='#RT'><p>Adaptive choice of the optimal sample fraction in tail index estimation</p></a></li>
<li><a href='#sumplot'><p>Sum Plot</p></a></li>
<li><a href='#TH'><p>Sequential Goodness of Fit Testing for the Generalized Pareto Distribution</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Threshold Estimation Approaches</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-04-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Johannes Ossberger</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johannes Ossberger &lt;johannes.ossberger@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Different approaches for selecting the threshold in generalized Pareto distributions. Most of them are based on minimizing the AMSE-criterion or at least by reducing the bias of the assumed GPD-model. Others are heuristically motivated by searching for stable sample paths, i.e. a nearly constant region of the tail index estimator with respect to k, which is the number of data in the tail. The third class is motivated by graphical inspection. In addition, a sequential testing procedure for GPD-GoF-tests is also implemented here.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Matrix, stats, graphics</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-04-17 22:36:12 UTC; J.Ossberger</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-04-19 15:00:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='tea-package'>
Threshold Estimation Approaches
</h2><span id='topic+tea-package'></span><span id='topic+tea'></span>

<h3>Description</h3>

<p>This package contains implementations of many of the threshold estimation approaches proposed in the literature. The estimation of the threshold is of great interest in statistics of extremes. Estimating the threshold is equivalent to choose the optimal sample fraction in tail index estimation. The sample fraction is given by <code>k/n</code> with <code>n</code> the sample size and <code>k</code> the number of extremes in the data or, if you wish, the exceedances over a high unknown threshold <code>u</code>.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> tea</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.1</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2020-04-17</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-3</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Johannes Ossberger
</p>
<p>Maintainer: Johannes Ossberger &lt;johannes.ossberger@gmail.com&gt;
</p>


<h3>References</h3>

<p>Caeiro and Gomes (2016) &lt;doi:10.1201/b19721-5&gt;
</p>
<p>Cebrian et al. (2003) &lt;doi:10.1080/10920277.2003.10596098&gt;
</p>
<p>Danielsson et al. (2001) &lt;doi:10.1006/jmva.2000.1903&gt;
</p>
<p>Danielsson et al. (2016) &lt;doi:10.2139/ssrn.2717478&gt;
</p>
<p>De Sousa and Michailidis (2004) &lt;doi:10.1198/106186004X12335&gt;
</p>
<p>Drees and Kaufmann (1998) &lt;doi:10.1016/S0304-4149(98)00017-9&gt;
</p>
<p>Hall (1990) &lt;doi:10.1016/0047-259X(90)90080-2&gt;
</p>
<p>Hall and Welsh (1985) &lt;doi:10.1214/aos/1176346596&gt;
</p>
<p>Kratz and Resnick (1996) &lt;doi:10.1080/15326349608807407&gt;
</p>
<p>Gomes et al. (2011) &lt;doi:10.1080/03610918.2010.543297&gt;
</p>
<p>Gomes et al. (2012) &lt;doi:10.1007/s10687-011-0146-6&gt;
</p>
<p>Gomes et al. (2013) &lt;doi:10.1080/00949655.2011.652113&gt;
</p>
<p>G'Sell et al. (2016) &lt;doi:10.1111/rssb.12122&gt;
</p>
<p>Guillou and Hall &lt;doi:10.1111/1467-9868.00286&gt;
</p>
<p>Reiss and Thomas (2007) &lt;doi:10.1007/978-3-0348-6336-0&gt;
</p>
<p>Resnick and Starica (1997) &lt;doi:10.1017/S0001867800027889&gt;
</p>
<p>Thompson et al. (2009) &lt;doi:10.1016/j.coastaleng.2009.06.003&gt;
</p>

<hr>
<h2 id='althill'>Alternative Hill Plot</h2><span id='topic+althill'></span>

<h3>Description</h3>

<p>Plots the Alternative Hill Plot and an averaged version of it against the upper order statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>althill(data, u = 2, kmin = 5, conf.int = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="althill_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="althill_+3A_u">u</code></td>
<td>
<p>gives the amount of which the Hill estimator is averaged. Default ist set to <code>u=2</code>.</p>
</td></tr>
<tr><td><code id="althill_+3A_kmin">kmin</code></td>
<td>
<p>gives the minimal <code>k</code> for which the graph is plotted. Default ist set to <code>kmin=5</code>.</p>
</td></tr>
<tr><td><code id="althill_+3A_conf.int">conf.int</code></td>
<td>
<p><code>logical</code>. If FALSE (default) no confidence intervals are plotted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Alternative Hill Plot is just a normal Hill Plot scaled to the <code>[0,1]</code> interval which can make interpretation much easier. See references for more information.
</p>


<h3>Value</h3>

<p>The normal black line gives a simple Hill Plot scaled to <code>[0,1]</code>. The red dotted line is an averaged version that smoothes the Hill Plot by taking the mean of <code>k(u-1)</code> subsequent Hill estimations with respect to <code>k</code>. See references for more information.
</p>


<h3>References</h3>

<p>Resnick, S. and Starica, C. (1997). Smoothing the Hill estimator. <em>Advances in Applied Probability</em>, 271&ndash;293.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data=rexp(500)
althill(data) 
</code></pre>

<hr>
<h2 id='avhill'>Averaged Hill Plot</h2><span id='topic+avhill'></span>

<h3>Description</h3>

<p>Plots an averaged version of the classical Hill Plot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>avhill(data, u = 2, kmin = 5, conf.int = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="avhill_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="avhill_+3A_u">u</code></td>
<td>
<p>gives the amount of which the Hill estimator is averaged. Default ist set to <code>u=2</code>.</p>
</td></tr>
<tr><td><code id="avhill_+3A_kmin">kmin</code></td>
<td>
<p>gives the minimal <code>k</code> for which the graph is plotted. Default ist set to <code>kmin=5</code>.</p>
</td></tr>
<tr><td><code id="avhill_+3A_conf.int">conf.int</code></td>
<td>
<p><code>logical</code>. If FALSE (default) no confidence intervals are plotted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Averaged Hill Plot is a smoothed version of the classical Hill Plot by taking the mean of values of the Hill estimator for subsequent <code>k</code>, i.e. upper order statistics. For more information see references.
</p>


<h3>Value</h3>

<p>The normal black line gives the classical Hill Plot. The red dotted line is an averaged version that smoothes the Hill Plot by taking the mean of <code>k(u-1)</code> subsequent Hill estimations with respect to <code>k</code>. See references for more information.
</p>


<h3>References</h3>

<p>Resnick, S. and Starica, C. (1997). Smoothing the Hill estimator. <em>Advances in Applied Probability</em>, 271&ndash;293.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
avhill(danish) 
</code></pre>

<hr>
<h2 id='dAMSE'>Minimizing the AMSE of the Hill estimator with respect to k</h2><span id='topic+dAMSE'></span>

<h3>Description</h3>

<p>Gives the optimal number of upper order statistics <code>k</code> for the Hill estimator by minimizing the AMSE-criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dAMSE(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dAMSE_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimal number of upper order statistics is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. This number is identified by minimizing the AMSE criterion with respect to <code>k</code>. The optimal number, denoted <code>k0</code> here, can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>second.order.par</code></td>
<td>
<p>gives an estimation of the second order parameter <code>beta</code> and <code>rho</code>.</p>
</td></tr>
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Caeiro, J. and Gomes, M.I. (2016). Threshold selection in extreme value analysis. <em>Extreme Value Modeling and Risk Analysis:Methids and Applications</em>, 69&ndash;86.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
dAMSE(danish)
</code></pre>

<hr>
<h2 id='danielsson'>A Double Bootstrap Procedure for Choosing the Optimal Sample Fraction</h2><span id='topic+danielsson'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Danielsson et al. (2001) for selecting the optimal sample fraction in tail index estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>danielsson(data, B = 500, epsilon = 0.9)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="danielsson_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="danielsson_+3A_b">B</code></td>
<td>
<p>number of Bootstrap replications</p>
</td></tr>
<tr><td><code id="danielsson_+3A_epsilon">epsilon</code></td>
<td>
<p>gives the amount of the first resampling size <code>n1</code> by choosing <code>n1 = n^epsilon</code>. Default is set to <code>epsilon=0.9</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Double Bootstrap procedure simulates the AMSE criterion of the Hill estimator using an auxiliary statistic. Minimizing this statistic gives a consistent estimator of the sample fraction <code>k/n</code> with <code>k</code> the optimal number of upper order statistics. This number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>second.order.par</code></td>
<td>
<p>gives an estimation of the second order parameter <code>rho</code>.</p>
</td></tr>
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Danielsson, J. and Haan, L. and Peng, L. and Vries, C.G. (2001). Using a bootstrap method to choose the sample fraction in tail index estimation. <em>Journal of Multivariate analysis</em>, <b>2</b>, 226-248.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data=rexp(100)
danielsson(data, B=200)
</code></pre>

<hr>
<h2 id='danish'>
Danish Fire Insurance Claims
</h2><span id='topic+danish'></span>

<h3>Description</h3>

<p>These data describe large fire insurance claims in Denmark from Thursday 3rd January 1980 until Monday 31st December 1990. The data are contained in a numeric vector. They were supplied by Mette Rytgaard of Copenhagen Re</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("danish")</code></pre>


<h3>Format</h3>

<p>The format is:
atomic [1:2167] 1.68 2.09 1.73 1.78 4.61 ...
- attr(*, &quot;times&quot;)= POSIXt[1:2167], format: &quot;1980-01-03 01:00:00&quot; &quot;1980-01-04 01:00:00&quot; ...
</p>


<h3>Source</h3>

<p>The data is taken from package <code>evir</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
</code></pre>

<hr>
<h2 id='DK'>A Bias-based procedure for Choosing the Optimal Sample Fraction</h2><span id='topic+DK'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Drees &amp; Kaufmann (1998) for selecting the optimal sample fraction in tail index estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DK(data, r = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DK_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="DK_+3A_r">r</code></td>
<td>
<p>tuning parameter for the stopping criterion. <code>default</code> is set to <code>1</code>. Change only if recommended by the output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure proposed in Drees &amp; Kaufmann (1998) is based on bias reduction. A stopping criterion with respect to <code>k</code> is implemented to find the optimal tail fraction, i.e. <code>k/n</code> with <code>k</code> the optimal number of upper order statistics. This number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. If the above mentioned stopping criterion exceedes a certain value <code>r</code>, the bias of the assumed extreme model has become prominent and therefore <code>k</code> should not be chosen higher. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>second.order.par</code></td>
<td>
<p>gives an estimation of the second order parameter <code>rho</code>.</p>
</td></tr>
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail</p>
</td></tr>
</table>


<h3>References</h3>

<p>Drees, H. and Kaufmann, E. (1998). Selecting the optimal sample fraction in univariate extreme value estimation. <em>Stochastic Processes and their Applications</em>, <b>75(2)</b>, 149&ndash;172.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
DK(danish)
</code></pre>

<hr>
<h2 id='eye'>Automated Approach for Interpreting the Hill-Plot</h2><span id='topic+eye'></span>

<h3>Description</h3>

<p>An Implementation of the so called Eye-balling Technique proposed in Danielsson et al. (2016)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eye(data, ws = 0.01, epsilon = 0.3, h = 0.9)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="eye_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="eye_+3A_ws">ws</code></td>
<td>
<p>size of the moving window. <code>Default</code> is one percent of the data</p>
</td></tr>
<tr><td><code id="eye_+3A_epsilon">epsilon</code></td>
<td>
<p>size of the range in which the estimates can vary</p>
</td></tr>
<tr><td><code id="eye_+3A_h">h</code></td>
<td>
<p>percentage of data inside the moving window that should lie in the tolerable range</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure searches for a stable region in the Hill-Plot by defining a moving window. Inside this window the estimates of the Hill estimator with respect to <code>k</code> have to be in a pre-defined range around the first estimate within this window. It is sufficient to claim that only <code>h</code> percent of the estimates within this window lie in this range. The smallest <code>k</code> that accomplishes this is then the optimal number of upper order statistics, i.e. data in the tail.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index by plugging in <code>k0</code> into the hill estimator</p>
</td></tr>
</table>


<h3>References</h3>

<p>Danielsson, J. and Ergun, L.M. and de Haan, L. and de Vries, C.G. (2016). Tail Index Estimation: Quantile Driven Threshold Selection.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
eye(danish)
</code></pre>

<hr>
<h2 id='ggplot'>Gerstengarbe Plot</h2><span id='topic+ggplot'></span>

<h3>Description</h3>

<p>Performs a sequential Mann-Kendall Plot also known as Gerstengarbe Plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ggplot(data, nexceed = min(data) - 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ggplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="ggplot_+3A_nexceed">nexceed</code></td>
<td>
<p>number of exceedances. Default is the minimum of the data to make sure the whole dataset is considered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Gerstengarbe Plot, referring to Gerstengarbe and Werner (1989), is a sequential version of the Mann-Kendall-Test. This test searches for change points within a time series. This method is adopted for finding a threshold in a POT-model. The basic idea is that the differences of order statistics of a given dataset behave different between the body and the tail of a heavy-tailed distribution. So there should be a change point if the POT-model holds. 
To identify this change point the sequential test is done twice, for the differences from start to the end of the dataset and vice versa. The intersection point of these two series can then be associated with the change point of the sample data. For more informations see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. the change point of the dataset</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>Authors</h3>

<p>Ana Cebrian
Johannes Ossberger
</p>


<h3>Acknowledgements</h3>

<p>Great thanks to A. Cebrian for providing a basic version of this code.
</p>


<h3>References</h3>

<p>Gerstengarbe, F.W. and Werner, P.C. (1989). A method for statistical definition of extreme-value regions and their application to meteorological time series. <em>Zeitschrift fuer Meteorologie</em>, <b>39(4)</b>, 224&ndash;226.
</p>
<p>Cebrian, A., and Denuit, M. and Lambert, P. (2003). Generalized pareto fit to the society of actuaries large claims database. <em>North American Actuarial Journal</em>, <b>7(3)</b>, 18&ndash;36.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
ggplot(danish)
</code></pre>

<hr>
<h2 id='GH'>A Bias-based procedure for Choosing the Optimal Threshold</h2><span id='topic+GH'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Guillou &amp; Hall(2001) for selecting the optimal threshold in extreme value analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GH(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GH_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure proposed in Guillou &amp; Hall (2001) is based on bias reduction. Due to the fact that the log-spacings of the order statistics are approximately exponentially distributed if the tail of the underlying distribution follows a Pareto distribution, an auxilliary statistic with respect to <code>k</code> is implemented with the same properties. The method then behaves like an asymptotic test for mean <code>0</code>. If some critical value <code>crit</code> is exceeded the hypothesis of zero mean is rejected. Thus the bias has become too large and the assumed exponentiality and therefore the assumed Pareto tail can not be hold.  From this an optimal number of <code>k</code> can be found such that the critical value is not exceeded. This optimal number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by 
coosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Guillou, A. and Hall, P. (2001). A Diagnostic for Selecting the Threshold in Extreme Value Analysis. <em>Journal of the Royal Statistical Society</em>, <b>63(2)</b>, 293&ndash;305.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
GH(danish)
</code></pre>

<hr>
<h2 id='gomes'>A Double Bootstrap Procedure for Choosing the Optimal Sample Fraction</h2><span id='topic+gomes'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Gomes et al. (2012) and Caeiro et al. (2016) for selecting the optimal sample fraction in tail index estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gomes(data, B = 1000, epsilon = 0.995)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gomes_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="gomes_+3A_b">B</code></td>
<td>
<p>number of Bootstrap replications</p>
</td></tr>
<tr><td><code id="gomes_+3A_epsilon">epsilon</code></td>
<td>
<p>gives the amount of the first resampling size <code>n1</code> by choosing <code>n1 = n^epsilon</code>. Default is set to <code>epsilon=0.995</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Double Bootstrap procedure simulates the AMSE criterion of the Hill estimator using an auxiliary statistic. Minimizing this statistic gives a consistent estimator of the sample fraction <code>k/n</code> with <code>k</code> the optimal number of upper order statistics. This number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>second.order.par</code></td>
<td>
<p>gives an estimation of the second order parameter <code>rho</code>.</p>
</td></tr>
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail</p>
</td></tr>
</table>


<h3>References</h3>

<p>Gomes, M.I. and Figueiredo, F. and Neves, M.M. (2012). Adaptive estimation of heavy right tails: resampling-based methods in action. <em>Extremes</em>, <b>15</b>, 463&ndash;489.
</p>
<p>Caeiro, F. and Gomes, I. (2016). Threshold selection in extreme value analysis. <em>Extreme Value Modeling and Risk Analysis: Methods and Applications</em>, 69&ndash;86.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
gomes(danish)
</code></pre>

<hr>
<h2 id='gpd'>The Generalized Pareto Distribution (GPD)</h2><span id='topic+gpd'></span><span id='topic+dgpd'></span><span id='topic+rgpd'></span><span id='topic+qgpd'></span><span id='topic+pgpd'></span>

<h3>Description</h3>

<p>Density, distribution function, quantile function and random number generation for the Generalized Pareto
distribution with location, scale, and shape parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgpd(x, loc = 0, scale = 1, shape = 0, log.d = FALSE)

rgpd(n, loc = 0, scale = 1, shape = 0)

qgpd(p, loc = 0, scale = 1, shape = 0, lower.tail = TRUE,
  log.p = FALSE)

pgpd(q, loc = 0, scale = 1, shape = 0, lower.tail = TRUE,
  log.p = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpd_+3A_x">x</code></td>
<td>
<p>Vector of observations.</p>
</td></tr>
<tr><td><code id="gpd_+3A_loc">loc</code>, <code id="gpd_+3A_scale">scale</code>, <code id="gpd_+3A_shape">shape</code></td>
<td>
<p>Location, scale, and shape parameters. Can be vectors, but
the lengths must be appropriate.</p>
</td></tr>
<tr><td><code id="gpd_+3A_log.d">log.d</code></td>
<td>
<p>Logical; if TRUE, the log density is returned.</p>
</td></tr>
<tr><td><code id="gpd_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="gpd_+3A_p">p</code></td>
<td>
<p>Vector of probabilities.</p>
</td></tr>
<tr><td><code id="gpd_+3A_lower.tail">lower.tail</code></td>
<td>
<p>Logical; if TRUE (default), probabilities are P[X &lt;= x], otherwise, P[X &gt; x].</p>
</td></tr>
<tr><td><code id="gpd_+3A_log.p">log.p</code></td>
<td>
<p>Logical; if TRUE, probabilities p are given as log(p).</p>
</td></tr>
<tr><td><code id="gpd_+3A_q">q</code></td>
<td>
<p>Vector of quantiles.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Pareto distribution function is given (Pickands, 1975)
by </p>
<p style="text-align: center;"><code class="reqn">H(y) = 1 - \Big[1 + \frac{\xi (y - \mu)}{\sigma}\Big]^{-1/\xi}</code>
</p>
<p> defined
on <code class="reqn">\{y : y &gt; 0, (1 + \xi (y - \mu) / \sigma) &gt; 0 \}</code>, with location <code class="reqn">\mu</code>,
scale <code class="reqn">\sigma &gt; 0</code>, and shape parameter <code class="reqn">\xi</code>.
</p>


<h3>References</h3>

<p>Brian Bader, Jun Yan. &quot;eva: Extreme Value Analysis with Goodness-of-Fit Testing.&quot; R package version (2016)
</p>
<p>Pickands III, J. (1975). Statistical inference using extreme order statistics. Annals of Statistics, 119-131.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dgpd(2:4, 1, 0.5, 0.01)
dgpd(2, -2:1, 0.5, 0.01)
pgpd(2:4, 1, 0.5, 0.01)
qgpd(seq(0.9, 0.6, -0.1), 2, 0.5, 0.01)
rgpd(6, 1, 0.5, 0.01)

## Generate sample with linear trend in location parameter
rgpd(6, 1:6, 0.5, 0.01)

## Generate sample with linear trend in location and scale parameter
rgpd(6, 1:6, seq(0.5, 3, 0.5), 0.01)

p &lt;- (1:9)/10
pgpd(qgpd(p, 1, 2, 0.8), 1, 2, 0.8)
## [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9

## Incorrect syntax (parameter vectors are of different lengths other than 1)
# rgpd(1, 1:8, 1:5, 0)

## Also incorrect syntax
# rgpd(10, 1:8, 1, 0.01)

</code></pre>

<hr>
<h2 id='gpdFit'>Parameter estimation for the Generalized Pareto Distribution (GPD)</h2><span id='topic+gpdFit'></span>

<h3>Description</h3>

<p>Fits exceedances above a chosen threshold to the Generalized Pareto model. Various estimation procedures can be used,
including maximum likelihood, probability weighted moments, and maximum product spacing. It also allows
generalized linear modeling of the parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpdFit(data, threshold = NA, nextremes = NA, npp = 365,
  method = c("mle", "mps", "pwm"), information = c("expected",
  "observed"), scalevars = NULL, shapevars = NULL, scaleform = ~1,
  shapeform = ~1, scalelink = identity, shapelink = identity,
  start = NULL, opt = "Nelder-Mead", maxit = 10000, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpdFit_+3A_data">data</code></td>
<td>
<p>Data should be a numeric vector from the GPD.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_threshold">threshold</code></td>
<td>
<p>A threshold value or vector of the same length as the data.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_nextremes">nextremes</code></td>
<td>
<p>Number of upper extremes to be used (either this or the threshold must be given, but not both).</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_npp">npp</code></td>
<td>
<p>Length of each period (typically year). Is used in return level estimation. Defaults to 365.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_method">method</code></td>
<td>
<p>Method of estimation - maximum likelihood (mle), maximum product spacing (mps), and
probability weighted moments (pwm). Uses mle by default. For pwm, only the stationary model can be fit.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_information">information</code></td>
<td>
<p>Whether standard errors should be calculated via observed or expected (default) information. For probability
weighted moments, only expected information will be used if possible. For non-stationary models, only observed
information is used.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_scalevars">scalevars</code>, <code id="gpdFit_+3A_shapevars">shapevars</code></td>
<td>
<p>A dataframe of covariates to use for modeling of the each parameter. Parameter
intercepts are automatically handled by the function. Defaults to NULL for the stationary model.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_scaleform">scaleform</code>, <code id="gpdFit_+3A_shapeform">shapeform</code></td>
<td>
<p>An object of class &lsquo;formula&rsquo; (or one that can be coerced into that class), specifying the model
of each parameter. By default, assumes stationary (intercept only) model. See details.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_scalelink">scalelink</code>, <code id="gpdFit_+3A_shapelink">shapelink</code></td>
<td>
<p>A link function specifying the relationship between the covariates and each parameter. Defaults to
the identity function. For the stationary model, only the identity link should be used.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_start">start</code></td>
<td>
<p>Option to provide a set of starting parameters to optim; a vector of scale and shape, in that order. Otherwise,
the routine attempts to find good starting parameters. See details.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_opt">opt</code></td>
<td>
<p>Optimization method to use with optim.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_maxit">maxit</code></td>
<td>
<p>Number of iterations to use in optimization, passed to optim. Defaults to 10,000.</p>
</td></tr>
<tr><td><code id="gpdFit_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to optim.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The base code for finding probability weighted moments is taken from the R package evir. See citation.
In the stationary case (no covariates), starting parameters for mle and mps estimation are the probability weighted moment estimates.
In the case where covariates are used, the starting intercept parameters are the probability weighted moment estimates from the
stationary case and the parameters based on covariates are initially set to zero. For non-stationary parameters, the
first reported estimate refers to the intercept term. Covariates are centered and scaled automatically to speed up optimization,
and then transformed back to original scale. <br />
Formulas for generalized linear modeling of the parameters should be given in the form '~ var1 + var2 + <code class="reqn">\cdots</code>'. Essentially,
specification here is the same as would be if using function &lsquo;lm&rsquo; for only the right hand side of the equation. Interactions,
polynomials, etc. can be handled as in the &lsquo;formula&rsquo; class. <br />
Intercept terms are automatically handled by the function. By default, the link functions are the identity function and
the covariate dependent scale parameter estimates are forced to be positive. For some link function <code class="reqn">f(\cdot)</code> and for
example, scale parameter <code class="reqn">\sigma</code>, the link is written as <code class="reqn">\sigma = f(\sigma_1 x_1 + \sigma_2 x_2 + \cdots + \sigma_k x_k)</code>. <br />
Maximum likelihood estimation and maximum product spacing estimation can be used in all cases. Probability weighted moments
can only be used for stationary models.
</p>


<h3>Value</h3>

<p>A class object &lsquo;gpdFit&rsquo; describing the fit, including parameter estimates and standard errors.
</p>


<h3>References</h3>

<p>Brian Bader, Jun Yan. &quot;eva: Extreme Value Analysis with Goodness-of-Fit Testing.&quot; R package version (2016)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Fit data using the three different estimation procedures
set.seed(7)
x &lt;- rgpd(2000, loc = 0, scale = 2, shape = 0.2)
## Set threshold at 4
mle_fit &lt;- gpdFit(x, threshold = 4, method = "mle")
pwm_fit &lt;- gpdFit(x, threshold = 4, method = "pwm")
mps_fit &lt;- gpdFit(x, threshold = 4, method = "mps")
## Look at the difference in parameter estimates and errors
mle_fit$par.ests
pwm_fit$par.ests
mps_fit$par.ests

mle_fit$par.ses
pwm_fit$par.ses
mps_fit$par.ses

## A linear trend in the scale parameter
set.seed(7)
n &lt;- 300
x2 &lt;- rgpd(n, loc = 0, scale = 1 + 1:n / 200, shape = 0)

covs &lt;- as.data.frame(seq(1, n, 1))
names(covs) &lt;- c("Trend1")

result1 &lt;- gpdFit(x2, threshold = 0, scalevars = covs, scaleform = ~ Trend1)

## Show summary of estimates
result1

</code></pre>

<hr>
<h2 id='hall'>A Single Bootstrap Procedure for Choosing the Optimal Sample Fraction</h2><span id='topic+hall'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Hall (1990) for selecting the optimal sample fraction in tail index estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hall(data, B = 1000, epsilon = 0.955, kaux = 2 * sqrt(length(data)))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="hall_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="hall_+3A_b">B</code></td>
<td>
<p>number of Bootstrap replications</p>
</td></tr>
<tr><td><code id="hall_+3A_epsilon">epsilon</code></td>
<td>
<p>gives the amount of the first resampling size <code>n1</code> by choosing <code>n1 = n^epsilon</code>. Default is set to <code>epsilon=0.955</code></p>
</td></tr>
<tr><td><code id="hall_+3A_kaux">kaux</code></td>
<td>
<p>tuning parameter for the hill estimator</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Bootstrap procedure simulates the AMSE criterion of the Hill estimator. The unknown theoretical parameter of the inverse tail index <code>gamma</code> is replaced by a consistent estimation using a tuning parameter <code>kaux</code> for the Hill estimator. Minimizing this statistic gives a consistent estimator of the sample fraction <code>k/n</code> with <code>k</code> the optimal number of upper order statistics. This number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hall, P. (1990). Using the Bootstrap to Estimate Mean Squared Error and Select Smoothing Parameter in Nonparametric Problems. <em>Journal of Multivariate Analysis</em>, <b>32</b>, 177&ndash;203.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
hall(danish)
</code></pre>

<hr>
<h2 id='Himp'>A Single Bootstrap Procedure for Choosing the Optimal Sample Fraction</h2><span id='topic+Himp'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Caeiro &amp; Gomes (2012) for selecting the optimal sample fraction in tail index estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Himp(data, B = 1000, epsilon = 0.955)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Himp_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="Himp_+3A_b">B</code></td>
<td>
<p>number of Bootstrap replications</p>
</td></tr>
<tr><td><code id="Himp_+3A_epsilon">epsilon</code></td>
<td>
<p>gives the amount of the first resampling size <code>n1</code> by choosing <code>n1 = n^epsilon</code>. Default is set to <code>epsilon=0.955</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This procedure is an improvement of the one introduced in Hall (1990) by overcoming the restrictive assumptions through estimation of the necessary parameters. The Bootstrap procedure simulates the AMSE criterion of the Hill estimator using an auxiliary statistic. Minimizing this statistic gives a consistent estimator of the sample fraction <code>k/n</code> with <code>k</code> the optimal number of upper order statistics. This number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>second.order.par</code></td>
<td>
<p>gives an estimation of the second order parameter <code>rho</code>.</p>
</td></tr>
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hall, P. (1990). Using the Bootstrap to Estimate Mean Squared Error and Select Smoothing Parameter in Nonparametric Problems. <em>Journal of Multivariate Analysis</em>, <b>32</b>, 177&ndash;203.
</p>
<p>Caeiro, F. and Gomes, M.I. (2014). On the bootstrap methodology for the estimation of the tail sample fraction. <em>Proceedings of COMPSTAT</em>, 545&ndash;552.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
Himp(danish)
</code></pre>

<hr>
<h2 id='HW'>Minimizing the AMSE of the Hill estimator with respect to k</h2><span id='topic+HW'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Hall &amp; Welsh (1985) for obtaining the optimal number of upper order statistics <code>k</code> for the Hill estimator by minimizing the AMSE-criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HW(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="HW_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The optimal number of upper order statistics is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. This number is identified by minimizing the AMSE criterion with respect to <code>k</code>. The optimal number, denoted <code>k0</code> here, can then be associated with the unknown threshold <code>u</code> of the GPD by choosing <code>u</code> as the <code>n-k0</code>th upper order statistic. For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>second.order.par</code></td>
<td>
<p>gives an estimation of the second order parameter <code>rho</code>.</p>
</td></tr>
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Hall, P. and Welsh, A.H. (1985). Adaptive estimates of parameters of regular variation. <em>The Annals of Statistics</em>, <b>13(1)</b>, 331&ndash;341.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
HW(danish)
</code></pre>

<hr>
<h2 id='mindist'>Minimizing the distance between the empirical tail and a theoretical Pareto tail with respect to k.</h2><span id='topic+mindist'></span>

<h3>Description</h3>

<p>An Implementation of the procedure proposed in Danielsson et al. (2016) for selecting the optimal threshold in extreme value analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mindist(data, ts = 0.15, method = "mad")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mindist_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="mindist_+3A_ts">ts</code></td>
<td>
<p>size of the upper tail the procedure is applied to. Default is 15 percent of the data</p>
</td></tr>
<tr><td><code id="mindist_+3A_method">method</code></td>
<td>
<p>should be one of <code>ks</code> for the &quot;Kolmogorov-Smirnov&quot; distance metric or <code>mad</code> for the mean absolute deviation (default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure proposed in Danielsson et al. (2016) minimizes the distance between the largest upper order statistics of the dataset, i.e. the empirical tail, and the theoretical tail of a Pareto distribution. The parameter of this distribution are estimated using Hill's estimator. Therefor one needs the optimal number of upper order statistics <code>k</code>. The distance is then minimized with respect to this <code>k</code>. The optimal number, denoted <code>k0</code> here, is equivalent to the number of extreme values or, if you wish, the number of exceedances in the context of a POT-model like the generalized Pareto distribution. <code>k0</code> can then be associated with the unknown threshold <code>u</code> of the GPD by saying <code>u</code> is the <code>n-k0</code>th upper order statistic. For the distance metric in use one could choose the mean absolute deviation called <code>mad</code> here, or the maximum absolute deviation, also known as the &quot;Kolmogorov-Smirnov&quot; distance metric (<code>ks</code>). For more information see references.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index by plugging in <code>k0</code> into the hill estimator</p>
</td></tr>
</table>


<h3>References</h3>

<p>Danielsson, J. and Ergun, L.M. and de Haan, L. and de Vries, C.G. (2016). Tail Index Estimation: Quantile Driven Threshold Selection.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
mindist(danish,method="mad")
</code></pre>

<hr>
<h2 id='PS'>Sample Path Stability Algorithm</h2><span id='topic+PS'></span>

<h3>Description</h3>

<p>An Implementation of the heuristic algorithm for choosing the optimal sample fraction proposed in Caeiro &amp; Gomes (2016), among others.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PS(data, j = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PS_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="PS_+3A_j">j</code></td>
<td>
<p>digits to round to. Should be <code>0</code> or <code>1</code> (default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm searches for a stable region of the sample path, i.e. the plot of a tail index estimator with respect to <code>k</code>. This is done in two steps. First the estimation of the tail index for every <code>k</code> is rounded to <code>j</code> digits and the longest set of equal consecutive values is chosen. For this set the estimates are rounded to <cite>j+2</cite> digits and the mode of this subset is determined. The corresponding biggest k-value, denoted <code>k0</code> here, is the optimal number of data in the tail.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding threshold</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail index</p>
</td></tr>
</table>


<h3>References</h3>

<p>Caeiro, J. and Gomes, M.I. (2016). Threshold selection in extreme value analysis. <em>Extreme Value Modeling and Risk Analysis:Methids and Applications</em>, 69&ndash;86.
</p>
<p>Gomes, M.I. and Henriques-Rodrigues, L. and Fraga Alves, M.I. and Manjunath, B. (2013). Adaptive PORT-MVRB estimation: an empirical comparison of two heuristic algorithms. <em>Journal of Statistical Computation and Simulation</em>, <b>83</b>, 1129&ndash;1144.
</p>
<p>Gomes, M.I. and Henriques-Rodrigues, L. and Miranda, M.C. (2011). Reduced-bias location-invariant extreme value index estimation: a simulation study. <em>Communications in Statistic-Simulation and Computation</em>, <b>40</b>, 424&ndash;447.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
PS(danish)
</code></pre>

<hr>
<h2 id='qqestplot'>QQ-Estimator-Plot</h2><span id='topic+qqestplot'></span>

<h3>Description</h3>

<p>Plots the QQ-Estimator against the upper order statistics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qqestplot(data, kmin = 5, conf.int = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qqestplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="qqestplot_+3A_kmin">kmin</code></td>
<td>
<p>gives the minimal <code>k</code> for which the graph is plotted. Default ist set to <code>kmin=5</code></p>
</td></tr>
<tr><td><code id="qqestplot_+3A_conf.int">conf.int</code></td>
<td>
<p><code>logical</code>. If FALSE (default) no confidence intervals are plotted</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The QQ-Estimator is a Tail Index Estimator based on regression diagnostics. Assuming a Pareto tail behaviour of the data at hand a QQ-Plot of the theoretical quantiles of an exponential distribution against the empirical quantiles of the log-data should lead to a straight line above some unknown upper order statistic <code>k</code>. The slope of this line is an estimator for the tail index. Computing this estimator via linear regression for every <code>k</code> the plot should stabilize for the correct number of upper order statistics, denoted <code>k0</code> here.
</p>


<h3>Value</h3>

<p>The plot shows the values of the QQ-Estimator with respect to <code>k</code>. See references for more information.
</p>


<h3>References</h3>

<p>Kratz, M. and Resnick, S.I. (1996). The QQ-estimator and heavy tails. <em>Stochastic Models</em>, <b>12(4)</b>, 699&ndash;724.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
qqestplot(danish)
</code></pre>

<hr>
<h2 id='qqgpd'>QQ-Plot against the generalized Pareto distribution for given number of exceedances</h2><span id='topic+qqgpd'></span>

<h3>Description</h3>

<p>Plots the empirical observations above a given threshold against the theoretical quantiles of a generalized Pareto distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qqgpd(data, nextremes, scale, shape)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qqgpd_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="qqgpd_+3A_nextremes">nextremes</code></td>
<td>
<p>number of exceedances</p>
</td></tr>
<tr><td><code id="qqgpd_+3A_scale">scale</code></td>
<td>
<p>scale parameter of GPD</p>
</td></tr>
<tr><td><code id="qqgpd_+3A_shape">shape</code></td>
<td>
<p>shape parameter of GPD</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the fitted GPD model provides a reasonable approximation of the underlying sample data the empirical and theoretical quantiles should coincide. So plotting them against each other should result in a straight line. Deviations from that line speak for a bad model fit and against a GPD assumption.
</p>


<h3>Value</h3>

<p>The straight red line gives the line of agreement. The dashed lines are simulated 95 percent confidence intervals. Therefor the fitted GPD model is simulated 1000 times using Monte Carlo. The sample size of each simulation equals the number of exceedances.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data=rexp(1000) #GPD with scale=1, shape=0
qqgpd(data,1000,1,0)
</code></pre>

<hr>
<h2 id='RT'>Adaptive choice of the optimal sample fraction in tail index estimation</h2><span id='topic+RT'></span>

<h3>Description</h3>

<p>An implementation of the minimization criterion proposed in Reiss &amp; Thomas (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RT(data, beta = 0, kmin = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RT_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="RT_+3A_beta">beta</code></td>
<td>
<p>a factor for weighting the expression below. Default is set to <code>beta=0</code></p>
</td></tr>
<tr><td><code id="RT_+3A_kmin">kmin</code></td>
<td>
<p>gives a minimum value for <code>k</code>. Default ist set to <code>kmin=2</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure proposed in Reiss &amp; Thomas (2007) chooses the lowest upper order statistic <code>k</code> to minimize the expression
<code>1/k sum_i=1^k i^beta |gamma_i-median(gamma_1,...,gamma_k)|</code>
or an alternative of that by replacing the absolute deviation with a squared deviation and the median just with <code>gamma_k</code>, where <code>gamma</code> denotes the Hill estimator
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>k0</code></td>
<td>
<p>optimal number of upper order statistics, i.e. number of exceedances or data in the tail for both metrics, i.e. the absolute and squared deviation.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>the corresponding thresholds.</p>
</td></tr>
<tr><td><code>tail.index</code></td>
<td>
<p>the corresponding tail indices</p>
</td></tr>
</table>


<h3>References</h3>

<p>Reiss, R.-D. and Thomas, M. (2007). Statistical Analysis of Extreme Values: With Applications to Insurance, Finance, Hydrology and Other Fields. <em>Birkhauser, Boston</em>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
RT(danish)
</code></pre>

<hr>
<h2 id='sumplot'>Sum Plot</h2><span id='topic+sumplot'></span>

<h3>Description</h3>

<p>An implementation of the so called sum plot proposed in de Sousa &amp; Michailidis (2004)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sumplot(data, kmin = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sumplot_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="sumplot_+3A_kmin">kmin</code></td>
<td>
<p>gives the minimal <code>k</code> for which the graph is plotted. Default ist set to <code>kmin=5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The sum plot is based on the plot <code>(k,S_k)</code> with <code>S_k:=k*gamma_k</code> where <code>gamma_k</code> denotes the Hill estimator. So the sum plot and the Hill plot are statistically equivalent. The sum plot should be approximately linear for the <code>k</code>-values where <code>gamma_k=gamma</code>. So the linear part of the graph can be used as an estimator of the (inverse) tail index. The sum plot leads to the estimation of the slope while the classical Hill plot leads to estimation of the intercept. The optimal number of order statistics, also known as the threshold, can then be derived as the value <code>k</code> where the plot differs from a straight line with slope <code>gamma</code>. See references for more information.
</p>


<h3>Value</h3>

<p>The plot shows the values of <code>S_k=k*gamma_k</code> for different <code>k</code>. See references for more information.
</p>


<h3>References</h3>

<p>De Sousa, Bruno and Michailidis, George (2004). A diagnostic plot for estimating the tail index of a distribution. <em>Journal of Computational and Graphical Statistics</em> <b>13(4)</b>, 1&ndash;22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(danish)
sumplot(danish)
</code></pre>

<hr>
<h2 id='TH'>Sequential Goodness of Fit Testing for the Generalized Pareto Distribution</h2><span id='topic+TH'></span>

<h3>Description</h3>

<p>An implementation of the sequential testing procedure proposed in Thompson et al. (2009) for automated threshold selection
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TH(data, thresholds)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="TH_+3A_data">data</code></td>
<td>
<p>vector of sample data</p>
</td></tr>
<tr><td><code id="TH_+3A_thresholds">thresholds</code></td>
<td>
<p>a sequence of pre-defined thresholds to check for GPD assumption</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure proposed in Thompson et al. (2009) is based on sequential goodness of fit testing. First, one has to choose a equally spaced grid of posssible thresholds. The authors recommend 100 thresholds between the 50 percent and 98 percent quantile of the data, provided there are enough observations left (about 100 observations above the last pre-defined threshold). Then the parameters of a GPD for each threshold are estimated. One can show that the differences of subsequent scale parameters are approximately normal distributed. So a Pearson chi-squared test for normality is applied to all the differences, striking the smallest thresholds out until the test is not rejected anymore.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>threshold</code></td>
<td>
<p>the threshold used for the test</p>
</td></tr>
<tr><td><code>num.above</code></td>
<td>
<p>the number of observations above the given threshold</p>
</td></tr>
<tr><td><code>p.values</code></td>
<td>
<p>raw p-values for the thresholds tested</p>
</td></tr>
<tr><td><code>ForwardStop</code></td>
<td>
<p>transformed p-values according to the ForwardStop criterion. See G'Sell et al (2016) for more information</p>
</td></tr>
<tr><td><code>StrongStop</code></td>
<td>
<p>transformed p-values according to the StrongStop criterion. See G'Sell et al (2016) for more information</p>
</td></tr>
<tr><td><code>est.scale</code></td>
<td>
<p>estimated scale parameter for the given threshold</p>
</td></tr>
<tr><td><code>est.shape</code></td>
<td>
<p>estimated shape parameter for the given threshold</p>
</td></tr>
</table>


<h3>References</h3>

<p>Thompson, P. and Cai, Y. and Reeve, D. (2009). Automated threshold selection methods for extreme wave analysis. <em>Coastal Engineering</em>, <b>56</b>(10), 1013&ndash;1021.
</p>
<p>G'Sell, M.G. and Wager, S. and Chouldechova, A. and Tibshirani, R. (2016). Sequential selection procedures and false discovery rate control. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> <b>78</b>(2), 423&ndash;444.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data=rexp(1000)
u=seq(quantile(data,.1),quantile(data,.9),,100)
A=TH(data,u);A
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
