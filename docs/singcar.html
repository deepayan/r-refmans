<!DOCTYPE html><html><head><title>Help for package singcar</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {singcar}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BSDT'><p>Bayesian Standardised Difference Test</p></a></li>
<li><a href='#BSDT_cov'><p>Bayesian Standardised Difference Test with Covariates</p></a></li>
<li><a href='#BSDT_cov_power'><p>Power calculator for BSDT_cov</p></a></li>
<li><a href='#BSDT_power'><p>Power calculator for BSDT</p></a></li>
<li><a href='#BTD'><p>Bayesian Test of Deficit</p></a></li>
<li><a href='#BTD_cov'><p>Bayesian Test of Deficit with Covariates</p></a></li>
<li><a href='#BTD_cov_power'><p>Power calculator for BTD_cov</p></a></li>
<li><a href='#BTD_power'><p>Power calculator for BTD</p></a></li>
<li><a href='#MTD'><p>Multivariate Test of deficit</p></a></li>
<li><a href='#RSDT'><p>Revised Standardised Difference Test</p></a></li>
<li><a href='#RSDT_power'><p>Power calculator for RSDT</p></a></li>
<li><a href='#singcar'><p>singcar: Comparing Single Cases to Small Samples</p></a></li>
<li><a href='#size_weight_illusion'><p>Data from one patient and 28 controls on the size-weight illusion</p></a></li>
<li><a href='#TD'><p>Test of Deficit</p></a></li>
<li><a href='#TD_power'><p>Power calculator for TD</p></a></li>
<li><a href='#UDT'><p>Unstandardised Difference Test</p></a></li>
<li><a href='#UDT_power'><p>Power calculator for UDT</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Comparing Single Cases to Small Samples</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.5</td>
</tr>
<tr>
<td>Description:</td>
<td>When comparing single cases to control populations and no parameters are known researchers and clinicians must estimate these with a control sample. This is often done when testing a case's abnormality on some variable or testing abnormality of the discrepancy between two variables. Appropriate frequentist and Bayesian methods for doing this are here implemented, including tests allowing for the inclusion of covariates. These have been developed first and foremost by John Crawford and Paul Garthwaite, e.g. in Crawford and Howell (1998) &lt;<a href="https://doi.org/10.1076%2Fclin.12.4.482.7241">doi:10.1076/clin.12.4.482.7241</a>&gt;, Crawford and Garthwaite (2005) &lt;<a href="https://doi.org/10.1037%2F0894-4105.19.3.318">doi:10.1037/0894-4105.19.3.318</a>&gt;, Crawford and Garthwaite (2007) &lt;<a href="https://doi.org/10.1080%2F02643290701290146">doi:10.1080/02643290701290146</a>&gt; and Crawford, Garthwaite and Ryan (2011) &lt;<a href="https://doi.org/10.1016%2Fj.cortex.2011.02.017">doi:10.1016/j.cortex.2011.02.017</a>&gt;. The package is also equipped with power calculators for each method. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, CholWishart, MASS, withr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, bookdown, lme4, lmerTest, testthat (&ge;
2.1.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/jorittmo/singcar">https://github.com/jorittmo/singcar</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jorittmo/singcar/issues">https://github.com/jorittmo/singcar/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-16 07:32:13 UTC; jritt</td>
</tr>
<tr>
<td>Author:</td>
<td>Jonathan Rittmo <a href="https://orcid.org/0000-0001-5075-0166"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Robert McIntosh <a href="https://orcid.org/0000-0002-7615-6699"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jonathan Rittmo &lt;j.rittmo@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-16 09:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='BSDT'>Bayesian Standardised Difference Test</h2><span id='topic+BSDT'></span>

<h3>Description</h3>

<p>A test on the discrepancy between two tasks in a single case, by comparison
to the discrepancy of means in the same two tasks in a control sample. Can
take both tasks measured on the same scale with the same underlying
distribution or tasks measured on different scales by setting
<code>unstandardised</code> to <code>TRUE</code> or <code>FALSE</code> (default). Calculates a
standardised effects size of task discrepancy as well as a point estimate of
the proportion of the control population that would be expected to show a
more extreme discrepancy as well as relevant credible intervals. This test
is based on random number generation which means that results may vary
between runs. This is by design and the reason for not using <code>set.seed()</code>
to reproduce results inside the function is to emphasise the randomness of
the test. To get more accurate and stable results please increase the number
of iterations by increasing <code>iter</code> whenever feasible. Developed by
Crawford and Garthwaite (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BSDT(
  case_a,
  case_b,
  controls_a,
  controls_b,
  sd_a = NULL,
  sd_b = NULL,
  sample_size = NULL,
  r_ab = NULL,
  alternative = c("two.sided", "greater", "less"),
  int_level = 0.95,
  iter = 10000,
  unstandardised = FALSE,
  calibrated = TRUE,
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BSDT_+3A_case_a">case_a</code></td>
<td>
<p>Case's score on task A.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_case_b">case_b</code></td>
<td>
<p>Case's score on task B.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_controls_a">controls_a</code></td>
<td>
<p>Controls' scores on task A. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task A while mean and SD for task B.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_controls_b">controls_b</code></td>
<td>
<p>Controls' scores on task A. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task B while mean and SD for task A.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_sd_a">sd_a</code></td>
<td>
<p>If single value for task A is given as input you must
supply the standard deviation of the sample.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_sd_b">sd_b</code></td>
<td>
<p>If single value for task B is given as input you must
supply the standard deviation of the sample.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_sample_size">sample_size</code></td>
<td>
<p>If A or B is given as mean and SD you must supply the
sample size. If controls_a is given as vector and controls_b as mean and
SD, sample_size must equal the number of observations in controls_a.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_r_ab">r_ab</code></td>
<td>
<p>If A or B is given as mean and SD you must supply the
correlation between the tasks.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as A and which is set
as B, be very careful if changing this parameter.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_int_level">int_level</code></td>
<td>
<p>Level of confidence for credible intervals, defaults to 95%.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_iter">iter</code></td>
<td>
<p>Number of iterations, defaults to 10000. Greater number gives better
estimation but takes longer to calculate.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_unstandardised">unstandardised</code></td>
<td>
<p>Estimate z-value based on standardised or
unstandardised task scores. Set to <code>TRUE</code> only if tasks are measured on the
same scale with the same underlying distribution.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_calibrated">calibrated</code></td>
<td>
<p><code>TRUE</code> is default. Whether or not to use the standard theory (Jeffreys) prior
distribution (if set to <code>FALSE</code>) or a calibrated prior examined by
Berger and Sun (2008). The sample estimation of the covariance matrix is
based on the sample size being n - 1 when the calibrated prior is used. See
Crawford et al. (2011) for further information. Calibrated prior is
recommended.</p>
</td></tr>
<tr><td><code id="BSDT_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove <code>NA</code>s from controls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses random generation of inverse wishart distributions from the
CholWishart package (Geoffrey Thompson, 2019).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>statistic</code>   </td><td style="text-align: left;"> the mean z-value over <code>iter</code>
  number of iterations. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>parameter</code> </td><td style="text-align: left;"> the degrees of freedom
  used to specify the posterior distribution. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>p.value</code>    </td><td style="text-align: left;">
  the mean p-value over <code>iter</code> number of iterations. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>estimate</code> </td><td style="text-align: left;"> case scores expressed as z-scores on task A and B.
  Standardised effect size (Z-DCC) of task difference between case and
  controls and point estimate of the proportion of the control population
  estimated to show a more extreme task difference. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">  <code>null.value</code>
  </td><td style="text-align: left;"> the value of the difference under the null hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>alternative</code>     </td><td style="text-align: left;"> a character string describing the alternative
  hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character string indicating what
  type of test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>data.name</code> </td><td style="text-align: left;"> a character string
  giving the name(s) of the data</td>
</tr>

</table>



<h3>References</h3>

<p>Berger, J. O., &amp; Sun, D. (2008). Objective Priors for the Bivariate Normal
Model. <em>The Annals of Statistics, 36</em>(2), 963-982. JSTOR.
</p>
<p>Crawford, J. R., &amp; Garthwaite, P. H. (2007). Comparison of a single case to a
control or normative sample in neuropsychology: Development of a Bayesian
approach. <em>Cognitive Neuropsychology, 24</em>(4), 343-372.
<a href="https://doi.org/10.1080/02643290701290146">doi:10.1080/02643290701290146</a>
</p>
<p>Crawford, J. R., Garthwaite, P. H., &amp; Ryan, K. (2011). Comparing a single
case to a control sample: Testing for neuropsychological deficits and
dissociations in the presence of covariates. <em>Cortex, 47</em>(10),
1166-1178. <a href="https://doi.org/10.1016/j.cortex.2011.02.017">doi:10.1016/j.cortex.2011.02.017</a>
</p>
<p>Geoffrey Thompson (2019). CholWishart: Cholesky Decomposition of the Wishart
Distribution. R package version 1.1.0.
<a href="https://CRAN.R-project.org/package=CholWishart">https://CRAN.R-project.org/package=CholWishart</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BSDT(-3.857, -1.875, controls_a = 0, controls_b = 0, sd_a = 1,
sd_b = 1, sample_size = 20, r_ab = 0.68, iter = 100)

BSDT(case_a = size_weight_illusion[1, "V_SWI"], case_b = size_weight_illusion[1, "K_SWI"],
 controls_a = size_weight_illusion[-1, "V_SWI"],
 controls_b = size_weight_illusion[-1, "K_SWI"], iter = 100)

</code></pre>

<hr>
<h2 id='BSDT_cov'>Bayesian Standardised Difference Test with Covariates</h2><span id='topic+BSDT_cov'></span>

<h3>Description</h3>

<p>Takes two single observations from a case on two variables (A and B) and
compares their standardised discrepancy to the discrepancies of the variables
in a control sample, while controlling for the effects of covariates, using
Bayesian methodology. This test is used when assessing a case conditioned on
some other variable, for example, assessing abnormality of discrepancy when
controlling for years of education or sex. Under the null hypothesis the case
is an observation from the distribution of discrepancies between the tasks of
interest coming from observations having the same score as the case on the
covariate(s). Returns a significance test, point and interval estimates of
difference between the case and the mean of the controls as well as point and
interval estimates of abnormality, i.e. an estimation of the proportion of
controls that would exhibit a more extreme conditioned score. This test is
based on random number generation which means that results may vary between
runs. This is by design and the reason for not using <code>set.seed()</code> to
reproduce results inside the function is to emphasise the randomness of the
test. To get more accurate and stable results please increase the number of
iterations by increasing <code>iter</code> whenever feasible. Developed by
Crawford, Garthwaite and Ryan (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BSDT_cov(
  case_tasks,
  case_covar,
  control_tasks,
  control_covar,
  alternative = c("two.sided", "greater", "less"),
  int_level = 0.95,
  calibrated = TRUE,
  iter = 10000,
  use_sumstats = FALSE,
  cor_mat = NULL,
  sample_size = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BSDT_cov_+3A_case_tasks">case_tasks</code></td>
<td>
<p>A vector of length 2. The case scores from the two tasks.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_case_covar">case_covar</code></td>
<td>
<p>A vector containing the case scores on all covariates
included.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_control_tasks">control_tasks</code></td>
<td>
<p>A matrix or dataframe with 2 columns and n rows
containing the control scores for the two tasks. Or if <code>use_sumstats</code>
is set to <code>TRUE</code> a 2x2 matrix or dataframe
containing summary statistics where the first column represents the means
for each task and the second column represents the standard deviation.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_control_covar">control_covar</code></td>
<td>
<p>A matrix or dataframe containing the control scores on
the covariates included. Or if <code>use_sumstats</code>
is set to <code>TRUE</code> a matrix or dataframe containing summary
statistics where the first column represents the means for each covariate
and the second column represents the standard deviation.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as A and which is set
as B, be very careful if changing this parameter.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_int_level">int_level</code></td>
<td>
<p>The probability level on the Bayesian credible intervals, defaults to 95%.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_calibrated">calibrated</code></td>
<td>
<p>Whether or not to use the standard theory (Jeffreys) prior
distribution (if set to <code>FALSE</code>) or a calibrated prior examined by
Berger and Sun (2008). The sample estimation of the covariance matrix is based on
the sample size being n - 1 when the calibrated prior is used. See Crawford
et al. (2011) for further information. Calibrated prior is recommended.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_iter">iter</code></td>
<td>
<p>Number of iterations to be performed. Greater number gives better
estimation but takes longer to calculate. Defaults to 10000.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_use_sumstats">use_sumstats</code></td>
<td>
<p>If set to <code>TRUE</code>, <code>control_tasks</code> and
<code>control_covar</code> are treated as matrices with summary statistics. Where
the first column represents the means for each variable and the second
column represents the standard deviation.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_cor_mat">cor_mat</code></td>
<td>
<p>A correlation matrix of all variables included. NOTE: the two
first variables should be the tasks of interest. Only needed if <code>use_sumstats</code>
is set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="BSDT_cov_+3A_sample_size">sample_size</code></td>
<td>
<p>An integer specifying the sample size of the controls.
Only needed if <code>use_sumstats</code>
is set to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses random generation of inverse wishart distributions from the
CholWishart package (Geoffrey Thompson, 2019).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>statistic</code>   </td><td style="text-align: left;"> the average z-value over
  <code>iter</code> number of iterations. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>parameter</code> </td><td style="text-align: left;"> the degrees
  of freedom used to specify the posterior distribution. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>p.value</code>    </td><td style="text-align: left;"> the average p-value over <code>iter</code> number of
  iterations. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code> </td><td style="text-align: left;"> case scores expressed as z-scores
  on task A and B. Standardised effect size (Z-DCCC) of task difference
  between case and controls and point estimate of the proportion of the
  control population estimated to show a more extreme task difference. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>null.value</code>   </td><td style="text-align: left;"> the value of the difference between tasks under
  the null hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>interval</code> </td><td style="text-align: left;"> named numerical vector
  containing level of confidence and confidence intervals for both effect
  size and p-value.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>desc</code>     </td><td style="text-align: left;"> data frame containing means
  and standard deviations for controls as well as case scores. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>cor.mat</code> </td><td style="text-align: left;"> matrix giving the correlations between the tasks of
  interest and the covariates included. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>sample.size</code>     </td><td style="text-align: left;">
  number of controls. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>alternative</code> </td><td style="text-align: left;"> a character string
  describing the alternative hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character
  string indicating what type of test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>data.name</code>
  </td><td style="text-align: left;"> a character string giving the name(s) of the data</td>
</tr>

</table>



<h3>References</h3>

<p>Berger, J. O., &amp; Sun, D. (2008). Objective Priors for the Bivariate Normal
Model. <em>The Annals of Statistics, 36</em>(2), 963-982. JSTOR.
</p>
<p>Crawford, J. R., Garthwaite, P. H., &amp; Ryan, K. (2011). Comparing a single
case to a control sample: Testing for neuropsychological deficits and
dissociations in the presence of covariates. <em>Cortex, 47</em>(10),
1166-1178. <a href="https://doi.org/10.1016/j.cortex.2011.02.017">doi:10.1016/j.cortex.2011.02.017</a>
</p>
<p>#' Geoffrey Thompson (2019). CholWishart: Cholesky Decomposition of the Wishart
Distribution. R package version 1.1.0.
<a href="https://CRAN.R-project.org/package=CholWishart">https://CRAN.R-project.org/package=CholWishart</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BSDT_cov(case_tasks = c(size_weight_illusion[1, "V_SWI"],
                        size_weight_illusion[1, "K_SWI"]),
         case_covar = size_weight_illusion[1, "YRS"],
         control_tasks = cbind(size_weight_illusion[-1, "V_SWI"],
                               size_weight_illusion[-1, "K_SWI"]),
         control_covar = size_weight_illusion[-1, "YRS"], iter = 100)

</code></pre>

<hr>
<h2 id='BSDT_cov_power'>Power calculator for BSDT_cov</h2><span id='topic+BSDT_cov_power'></span>

<h3>Description</h3>

<p>Computationally intense. Lower <code>iter</code> and/or <code>nsim</code> for faster but
less precise calculations. Calculates approximate power, given sample size,
using Monte Carlo simulation for BSDT with covariates
for specified (expected) case score, means and standard deviations for the
control sample on the task of interest and included covariates. The number of
covariates defaults to 1, means and standard deviations for the tasks and
covariate default to 0 and 1, so if no other values are given the case scores
is interpreted as deviation from the mean in standard deviations for both tasks
and covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BSDT_cov_power(
  case_tasks,
  case_cov,
  control_tasks = matrix(c(0, 0, 1, 1), ncol = 2),
  control_covar = c(0, 1),
  cor_mat = diag(3) + 0.3 - diag(c(0.3, 0.3, 0.3)),
  sample_size,
  alternative = c("two.sided", "greater", "less"),
  alpha = 0.05,
  nsim = 1000,
  iter = 1000,
  calibrated = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BSDT_cov_power_+3A_case_tasks">case_tasks</code></td>
<td>
<p>A vector of length 2. The expected case scores from the
tasks of interest.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_case_cov">case_cov</code></td>
<td>
<p>A vector containing the expected case scores on all
covariates included.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_control_tasks">control_tasks</code></td>
<td>
<p>A 2x2 matrix or dataframe containing the expected means
(first column) and standard deviations (second column). Defaults to two
variables with means 0 and sd = 1.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_control_covar">control_covar</code></td>
<td>
<p>A px2 matrix or dataframe containing the expected means
(first column) and standard deviations (second column), p being the number
of covariates. Defaults to one covariate with mean 0 and sd = 1.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_cor_mat">cor_mat</code></td>
<td>
<p>A correlation matrix containing the correlations of the tasks
of interest and the coviariate(s). The first two variables are treated as
the tasks of interest. Defaults pairwise correlations between the variates of 0.3.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_sample_size">sample_size</code></td>
<td>
<p>Single value giving the size of the control sample for which you wish
to calculate power.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;less&quot;,
&quot;greater&quot; or &quot;two.sided&quot; (default).</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate, default is 0.05. This can be
varied, with effects on power.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations for the power calculation. Defaults to
1000 due to BSDT already being computationally intense. Increase for better
accuracy.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_iter">iter</code></td>
<td>
<p>The number of simulations used by the BSDT_cov, defaults to 1000.
Increase for better accuracy.</p>
</td></tr>
<tr><td><code id="BSDT_cov_power_+3A_calibrated">calibrated</code></td>
<td>
<p>Whether or not to use the standard theory (Jeffreys) prior
distribution (if set to <code>FALSE</code>) or a calibrated prior. See Crawford
et al. (2011) for further information. Calibrated prior is recommended.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single value approximating the power of the test for the
given parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BSDT_cov_power(c(-2, 0), case_cov = c(0, 0, 0),
control_covar = matrix(c(0, 0, 0, 1, 1, 1), ncol= 2),
sample_size = 10, cor_mat = diag(5), iter = 20, nsim = 20)
</code></pre>

<hr>
<h2 id='BSDT_power'>Power calculator for BSDT</h2><span id='topic+BSDT_power'></span>

<h3>Description</h3>

<p>Calculates approximate power, given sample size, using Monte Carlo
simulation, for specified case scores, means and standard deviations for the
control sample. The means and standard deviations default to 0 and 1
respectively, so if no other values are given the case scores are interpreted
as deviations from the mean in standard deviations. Hence, the effect size of
the dissociation (Z-DCC) would in that case be the difference between the two
case scores. Is computationally heavy and might therefore take a few seconds.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BSDT_power(
  case_a,
  case_b,
  mean_a = 0,
  mean_b = 0,
  sd_a = 1,
  sd_b = 1,
  r_ab = 0.5,
  sample_size,
  alternative = c("two.sided", "greater", "less"),
  alpha = 0.05,
  nsim = 1000,
  iter = 1000,
  calibrated = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BSDT_power_+3A_case_a">case_a</code></td>
<td>
<p>A single value from the expected case observation on task A.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_case_b">case_b</code></td>
<td>
<p>A single value from the expected case observation on task B.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_mean_a">mean_a</code></td>
<td>
<p>The expected mean from the control sample on task A. Defaults
to 0.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_mean_b">mean_b</code></td>
<td>
<p>The expected mean from the control sample on task B. Defaults
to 0.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_sd_a">sd_a</code></td>
<td>
<p>The expected standard deviation from the control sample on task
A. Defaults to 1.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_sd_b">sd_b</code></td>
<td>
<p>The expected standard deviation from the control sample on task
B. Defaults to 1.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_r_ab">r_ab</code></td>
<td>
<p>The expected correlation between the tasks. Defaults to 0.5</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_sample_size">sample_size</code></td>
<td>
<p>The size of the control sample, vary this parameter to see
how the sample size affects power.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;two.sided&quot;
(default) or &quot;one.sided&quot;.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate. This can be varied, with
effects on power. Defaults to 0.05.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations to run. Higher number gives better
accuracy, but low numbers such as 10000 or even 1000 are usually sufficient
for the purposes of this calculator. Defaults to 1000 due to the
computationally intense <code>BSTD</code>.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_iter">iter</code></td>
<td>
<p>The number simulations used by <code>BSTD</code>. Defaults to 1000.</p>
</td></tr>
<tr><td><code id="BSDT_power_+3A_calibrated">calibrated</code></td>
<td>
<p>Whether or not to use the standard theory (Jeffreys) prior
distribution (if set to <code>FALSE</code>) or a calibrated prior. See Crawford
et al. (2011) for further information. Calibrated prior is recommended.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single value approximating the power of the test for the
given parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BSDT_power(case_a = -3, case_b = -1, mean_a = 0, mean_b = 0,
           sd_a = 1, sd_b = 1, r_ab = 0.5, sample_size = 20, nsim = 100, iter = 100)
</code></pre>

<hr>
<h2 id='BTD'>Bayesian Test of Deficit</h2><span id='topic+BTD'></span>

<h3>Description</h3>

<p>Takes a single observation and compares it to a distribution estimated by a
control sample using Bayesian methodology. Calculates standardised difference
between the case score and the mean of the controls and proportions falling
above or below the case score, as well as associated credible intervals. This
approach was developed by Crawford and Garthwaite (2007) but converge to the
results of <code><a href="#topic+TD">TD</a>()</code>, which is faster. Returns the point estimate of
the standardised difference between the case score and the mean of the
controls and the point estimate of the p-value (i.e. the percentage of the
population that would be expected to obtain a lower or higher score,
depending on the alternative hypothesis). This test is based on random number
generation which means that results may vary between runs. This is by design
and the reason for not using <code>set.seed()</code> to reproduce results inside
the function is to emphasise the randomness of the test. To get more accurate
and stable results please increase the number of iterations by increasing
<code>iter</code> whenever feasible.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BTD(
  case,
  controls,
  sd = NULL,
  sample_size = NULL,
  alternative = c("less", "greater", "two.sided"),
  int_level = 0.95,
  iter = 10000,
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BTD_+3A_case">case</code></td>
<td>
<p>Case observation, can only be a single value.</p>
</td></tr>
<tr><td><code id="BTD_+3A_controls">controls</code></td>
<td>
<p>Numeric vector of observations from the control sample. If
single value, treated as mean.</p>
</td></tr>
<tr><td><code id="BTD_+3A_sd">sd</code></td>
<td>
<p>If input of controls is single value, the standard
deviation of the sample must be given as well.</p>
</td></tr>
<tr><td><code id="BTD_+3A_sample_size">sample_size</code></td>
<td>
<p>If input of controls is single value, the size of the
sample must be given as well.</p>
</td></tr>
<tr><td><code id="BTD_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"less"</code> (default), <code>"greater"</code> or
<code>"two.sided"</code>. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="BTD_+3A_int_level">int_level</code></td>
<td>
<p>Level of confidence for credible intervals, defaults to 95%.</p>
</td></tr>
<tr><td><code id="BTD_+3A_iter">iter</code></td>
<td>
<p>Number of iterations. Set to higher for more accuracy, set to
lower for faster calculations.</p>
</td></tr>
<tr><td><code id="BTD_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove <code>NA</code>s from controls.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>statistic</code>   </td><td style="text-align: left;"> the mean z-value over <code>iter</code> number of
iterations </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">  <code>parameter</code> </td><td style="text-align: left;"> the degrees of freedom used to
specify the posterior distribution. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>p.value</code>    </td><td style="text-align: left;"> the mean p-value
for all simulated Z-scores.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code>    </td><td style="text-align: left;"> estimated standardised difference
(Z-CC) and point estimate of p-value. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>null.value</code>   </td><td style="text-align: left;"> the
value of the difference under the null hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>interval</code>
</td><td style="text-align: left;"> named numerical vector containing credibility level and intervals for
both Z-CC and estimated proportion. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>desc</code>     </td><td style="text-align: left;"> named
numerical containing descriptive statistics: mean and standard deviations of
controls as well as sample size. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>alternative</code>     </td><td style="text-align: left;"> a
character string describing the alternative hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code>
</td><td style="text-align: left;"> a character string indicating what type of test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>data.name</code> </td><td style="text-align: left;"> a character string giving the name(s) of the data as
well as summaries. </td>
</tr>

</table>



<h3>References</h3>

<p>Crawford, J. R., &amp; Garthwaite, P. H. (2007). Comparison of a single case to a
control or normative sample in neuropsychology: Development of a Bayesian
approach. <em>Cognitive Neuropsychology, 24</em>(4), 343-372.
<a href="https://doi.org/10.1080/02643290701290146">doi:10.1080/02643290701290146</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BTD(case = -2, controls = 0, sd = 1, sample_size = 20, iter = 1000)

BTD(case = size_weight_illusion[1, "V_SWI"],
    controls = size_weight_illusion[-1, "V_SWI"], alternative = "l", iter = 1000)

</code></pre>

<hr>
<h2 id='BTD_cov'>Bayesian Test of Deficit with Covariates</h2><span id='topic+BTD_cov'></span>

<h3>Description</h3>

<p>Takes a single observation and compares it to a distribution estimated by a
control sample, while controlling for the effect of covariates, using
Bayesian methodology. This test is used when assessing a case conditioned on
some other variable, for example, assessing abnormality when controlling for
years of education or sex. Under the null hypothesis the case is an
observation from the distribution of scores from the task of interest coming
from observations having the same score as the case on the covariate(s).
Returns a significance test, point and interval estimates of difference
between the case and the mean of the controls as well as point and interval
estimates of abnormality, i.e. an estimation of the proportion of controls
that would exhibit a more extreme conditioned score. This test is based on
random number generation which means that results may vary between runs. This
is by design and the reason for not using <code>set.seed()</code> to reproduce
results inside the function is to emphasise the randomness of the test. To
get more accurate and stable results please increase the number of iterations
by increasing <code>iter</code> whenever feasible. Developed by Crawford,
Garthwaite and Ryan (2011).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BTD_cov(
  case_task,
  case_covar,
  control_task,
  control_covar,
  alternative = c("less", "two.sided", "greater"),
  int_level = 0.95,
  iter = 10000,
  use_sumstats = FALSE,
  cor_mat = NULL,
  sample_size = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BTD_cov_+3A_case_task">case_task</code></td>
<td>
<p>The case score from the task of interest. Must be a single
value.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_case_covar">case_covar</code></td>
<td>
<p>A vector containing the case scores on all covariates
included. Can be of any length except 0, in that case use
<code><a href="#topic+BTD">BTD</a></code>.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_control_task">control_task</code></td>
<td>
<p>A vector containing the scores from the controls on the
task of interest. Or a vector of length 2 containing the mean and standard
deviation of the task. In that order.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_control_covar">control_covar</code></td>
<td>
<p>A vector, matrix or dataframe containing the control
scores on the covariates included. If matrix or dataframe each column
represents a covariate. Or a matrix or dataframe containing summary
statistics where the first column represents the means for each covariate
and the second column represents the standard deviation.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_int_level">int_level</code></td>
<td>
<p>The probability level on the Bayesian credible intervals, defaults to 95%.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_iter">iter</code></td>
<td>
<p>Number of iterations to be performed. Greater number gives better
estimation but takes longer to calculate. Defaults to 10000.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_use_sumstats">use_sumstats</code></td>
<td>
<p>If set to <code>TRUE</code>, <code>control_tasks</code> and
<code>control_covar</code> are treated as matrices with summary statistics. Where
the first column represents the means for each variable and the second
column represents the standard deviation.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_cor_mat">cor_mat</code></td>
<td>
<p>A correlation matrix of all variables included. NOTE: the
first variable should be the task of interest.</p>
</td></tr>
<tr><td><code id="BTD_cov_+3A_sample_size">sample_size</code></td>
<td>
<p>An integer specifying the sample size of the controls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses random generation of inverse wishart distributions from the
CholWishart package (Geoffrey Thompson, 2019).
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>statistic</code>   </td><td style="text-align: left;"> the average z-value over
  <code>iter</code> number of iterations. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>parameter</code> </td><td style="text-align: left;"> the degrees
  of freedom used to specify the posterior distribution. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>p.value</code>    </td><td style="text-align: left;"> the average p-value over <code>iter</code> number of
  iterations. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code> </td><td style="text-align: left;"> case scores expressed as z-scores
  on task X and Y. Standardised effect size (Z-CCC) of task difference
  between case and controls and point estimate of the proportion of the
  control population estimated to show a more extreme task difference. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>null.value</code>   </td><td style="text-align: left;"> the value of the difference between tasks under
  the null hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>interval</code> </td><td style="text-align: left;"> named numerical vector
  containing level of confidence and confidence intervals for both effect
  size and p-value.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>desc</code>     </td><td style="text-align: left;"> data frame containing means
  and standard deviations for controls as well as case scores. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>cor.mat</code> </td><td style="text-align: left;"> matrix giving the correlations between the task of
  interest and the covariates included. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>sample.size</code> </td><td style="text-align: left;"> number
  of controls..</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>alternative</code>     </td><td style="text-align: left;"> a character string
  describing the alternative hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character
  string indicating what type of test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>data.name</code>
  </td><td style="text-align: left;"> a character string giving the name(s) of the data</td>
</tr>

</table>



<h3>References</h3>

<p>Crawford, J. R., Garthwaite, P. H., &amp; Ryan, K. (2011). Comparing
a single case to a control sample: Testing for neuropsychological deficits
and dissociations in the presence of covariates. <em>Cortex, 47</em>(10),
1166-1178. <a href="https://doi.org/10.1016/j.cortex.2011.02.017">doi:10.1016/j.cortex.2011.02.017</a>
</p>
<p>Geoffrey Thompson (2019). CholWishart: Cholesky Decomposition of the Wishart
Distribution. R package version 1.1.0.
<a href="https://CRAN.R-project.org/package=CholWishart">https://CRAN.R-project.org/package=CholWishart</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
BTD_cov(case_task = size_weight_illusion[1, "V_SWI"],
         case_covar = size_weight_illusion[1, "YRS"],
         control_task = size_weight_illusion[-1, "V_SWI"],
         control_covar = size_weight_illusion[-1, "YRS"], iter = 100)

</code></pre>

<hr>
<h2 id='BTD_cov_power'>Power calculator for BTD_cov</h2><span id='topic+BTD_cov_power'></span>

<h3>Description</h3>

<p>Computationally intense. Lower <code>iter</code> and/or <code>nsim</code> for less exact
but faster calculations. Calculates approximate power, given sample size,
using Monte Carlo simulation for the Bayesian test of deficit with covariates
for specified (expected) case score, means and standard deviations for the
control sample on the task of interest and included covariates. The number of
covariates defaults to 1, means and standard deviations for the task and
covariate defaults to 0 and 1, so if no other values are given the case score
is interpreted as deviation from the mean in standard deviations for both task
and covariate.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BTD_cov_power(
  case,
  case_cov,
  control_task = c(0, 1),
  control_covar = c(0, 1),
  cor_mat = diag(2) + 0.3 - diag(c(0.3, 0.3)),
  sample_size,
  alternative = c("less", "greater", "two.sided"),
  alpha = 0.05,
  nsim = 1000,
  iter = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BTD_cov_power_+3A_case">case</code></td>
<td>
<p>A single value from the expected case observation on the task of
interest.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_case_cov">case_cov</code></td>
<td>
<p>A vector of expected case observations from covariates of
interest.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_control_task">control_task</code></td>
<td>
<p>A vector of length 2 containing the expected mean and standard
deviation of the task of interest. In that order.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_control_covar">control_covar</code></td>
<td>
<p>A matrix with 2 columns containing expected means (in the 1st
column) and standard deviations (in the 2nd column) of the included
covariates.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_cor_mat">cor_mat</code></td>
<td>
<p>A correlation matrix containing the correlations of the
task of interest and the coviariate(s). The first variable is treated as
the task of interest. Defaults to a correlation of 0.3 between the covariate
and the variate of interest.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_sample_size">sample_size</code></td>
<td>
<p>Single value of the size of the sample for which you wish
to calculate power.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;less&quot; (default),
&quot;greater&quot; or &quot;two.sided&quot;.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate. This can also be varied, with
effects on power.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations for the power calculation. Defaults to
1000 due to BTD_cov already being computationally intense.</p>
</td></tr>
<tr><td><code id="BTD_cov_power_+3A_iter">iter</code></td>
<td>
<p>The number of simulations used by the BTD_cov. Defaults to 1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single value approximating the power of the test for the
given parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cor_mat = matrix(c(1, 0.2, 0.3, 0.2, 1, 0.4, 0.3, 0.4, 1), ncol = 3)

BTD_cov_power(case = -2, case_cov = c(105, 30), control_task = c(0, 1),
control_covar = matrix(c(100, 40, 15, 10), ncol = 2), sample_size = 15,
cor_mat = cor_mat, iter = 20, nsim = 20)
</code></pre>

<hr>
<h2 id='BTD_power'>Power calculator for BTD</h2><span id='topic+BTD_power'></span>

<h3>Description</h3>

<p>Calculates approximate power, given sample size, using Monte Carlo simulation for the
Bayesian test of deficit for a specified case score, mean and standard
deviation for the control sample. The mean and standard deviation defaults to
0 and 1, so if no other values are given the case score is interpreted as
deviation from the mean in standard deviations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BTD_power(
  case,
  mean = 0,
  sd = 1,
  sample_size,
  alternative = c("less", "greater", "two.sided"),
  alpha = 0.05,
  nsim = 1000,
  iter = 1000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BTD_power_+3A_case">case</code></td>
<td>
<p>A single value from the expected case observation.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_mean">mean</code></td>
<td>
<p>The expected mean of the control sample.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_sd">sd</code></td>
<td>
<p>The expected standard deviation of the control sample.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_sample_size">sample_size</code></td>
<td>
<p>The size of the control sample, vary this parameter to see
how the sample size affects power.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;less&quot; (default),
&quot;greater&quot; or &quot;two.sided&quot;.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate. This can also be varied, with
effects on power.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations for the power calculation. Defaults to
1000 due to BTD already being computationally intense.</p>
</td></tr>
<tr><td><code id="BTD_power_+3A_iter">iter</code></td>
<td>
<p>The number of simulations used by the BTD. Defaults to 1000.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single value approximating the power of the test for the
given parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>BTD_power(case = -2, mean = 0, sd = 1, sample_size = 20)
</code></pre>

<hr>
<h2 id='MTD'>Multivariate Test of deficit</h2><span id='topic+MTD'></span>

<h3>Description</h3>

<p>Testing for abnormality in the distance between a a vector of observations
for a single case and a vector of population means. Please see vignette
for further details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MTD(
  case,
  controls,
  conf_level = 0.95,
  method = c("pd", "pchi", "pf", "pmd"),
  mahalanobis_dist = NULL,
  k = NULL,
  n = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MTD_+3A_case">case</code></td>
<td>
<p>Vector of case scores</p>
</td></tr>
<tr><td><code id="MTD_+3A_controls">controls</code></td>
<td>
<p>Matrix or data frame with scores from the control sample, each column representing a variable</p>
</td></tr>
<tr><td><code id="MTD_+3A_conf_level">conf_level</code></td>
<td>
<p>Level of confidence for the confidence intervals</p>
</td></tr>
<tr><td><code id="MTD_+3A_method">method</code></td>
<td>
<p>One out of &quot;pd&quot;, &quot;pchi&quot;, &quot;pf&quot; and &quot;pmd&quot;. Use &quot;pmd&quot; if the Mahalanobi's distance seems suspiciously small</p>
</td></tr>
<tr><td><code id="MTD_+3A_mahalanobis_dist">mahalanobis_dist</code></td>
<td>
<p>Mahalanobi's distance of the case if summary statistics are used</p>
</td></tr>
<tr><td><code id="MTD_+3A_k">k</code></td>
<td>
<p>The number of dimensions, if summary statistics are used</p>
</td></tr>
<tr><td><code id="MTD_+3A_n">n</code></td>
<td>
<p>The size of the control sample</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>statistic</code>   </td><td style="text-align: left;"> Hotelling's T^2 statistic for the
  case's Mahalanobi's distance </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>p.value</code>    </td><td style="text-align: left;"> The p value associated with the Hotelling statistic
   </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code> </td><td style="text-align: left;"> Estimates of the case Mahalanobis distance
   and index as well as abnormality </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>interval</code> </td><td style="text-align: left;">  List
   of interval measure for the estimates </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>sample.size</code> </td><td style="text-align: left;"> number
  of controls.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character
  string indicating what type of test was performed and which abnormality measure
  used</td>
</tr>

</table>



<h3>Examples</h3>

<pre><code class='language-R'>
caseA &lt;- size_weight_illusion[1, "V_SWI"]
contA &lt;- size_weight_illusion[-1, "V_SWI"]
caseB &lt;- size_weight_illusion[1, "K_SWI"]
contB &lt;- size_weight_illusion[-1, "K_SWI"]

MTD(case = c(caseA, caseB), controls = cbind(contA, contB),
  conf_level = 0.95, method = c("pd", "pchi", "pf", "pmd"),
  mahalanobis_dist = NULL, k = NULL, n = NULL)


</code></pre>

<hr>
<h2 id='RSDT'>Revised Standardised Difference Test</h2><span id='topic+RSDT'></span>

<h3>Description</h3>

<p>A test on the discrepancy between two tasks in a single case, by comparison
to the discrepancy of means in the same two tasks in a control sample.
Standardises task scores as well as task discrepancy, so the tasks do not
need to be measured on the same scale. Calculates a standardised effect size
(Z-DCC) of task discrepancy as well as a point estimate of the proportion of
the control population that would be expected to show a more extreme
discrepancy. Developed by Crawford and Garthwaite (2005).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSDT(
  case_a,
  case_b,
  controls_a,
  controls_b,
  sd_a = NULL,
  sd_b = NULL,
  sample_size = NULL,
  r_ab = NULL,
  alternative = c("two.sided", "greater", "less"),
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSDT_+3A_case_a">case_a</code></td>
<td>
<p>Case's score on task A.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_case_b">case_b</code></td>
<td>
<p>Case's score on task B.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_controls_a">controls_a</code></td>
<td>
<p>Controls' scores on task A. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task A while mean and SD for task B.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_controls_b">controls_b</code></td>
<td>
<p>Controls' scores on task B. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task B while mean and SD for task A.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_sd_a">sd_a</code></td>
<td>
<p>If single value for task A is given as input you must
supply the standard deviation of the sample.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_sd_b">sd_b</code></td>
<td>
<p>If single value for task B is given as input you must
supply the standard deviation of the sample.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_sample_size">sample_size</code></td>
<td>
<p>If A or B is given as mean and SD you must supply the
sample size. If controls_a is given as vector and controls_b as mean and
SD, sample_size must equal the number of observations in controls_a.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_r_ab">r_ab</code></td>
<td>
<p>If A or B is given as mean and SD you must supply the
correlation between the tasks.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as A and which is set
as B, be very careful if changing this parameter.</p>
</td></tr>
<tr><td><code id="RSDT_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove <code>NA</code>s from controls.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>statistic</code>   </td><td style="text-align: left;"> Returns the value of a approximate
  t-statistic, however, because of the underlying equation, it cannot be
  negative. See effect direction from Z-DCC. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>parameter</code> </td><td style="text-align: left;"> the
  degrees of freedom for the t-statistic.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>p.value</code>    </td><td style="text-align: left;"> the
  p-value for the test.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code> </td><td style="text-align: left;"> case scores expressed as
  z-scores on task A and Y. Standardised effect size (Z-DCC) of task
  difference between case and controls and point estimate of the proportion
  of the control population estimated to show a more extreme task
  discrepancy. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>sample.size</code>   </td><td style="text-align: left;"> the size of the control
  sample</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>null.value</code>   </td><td style="text-align: left;"> the value of the discrepancy under
  the null hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">  <code>alternative</code>     </td><td style="text-align: left;"> a character string
  describing the alternative hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character
  string indicating what type of test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>data.name</code>
  </td><td style="text-align: left;"> a character string giving the name(s) of the data</td>
</tr>

</table>



<h3>References</h3>

<p>Crawford, J. R., &amp; Garthwaite, P. H. (2005). Testing for
Suspected Impairments and Dissociations in Single-Case Studies in
Neuropsychology: Evaluation of Alternatives Using Monte Carlo Simulations and
Revised Tests for Dissociations. <em>Neuropsychology, 19</em>(3), 318 - 331.
<a href="https://doi.org/10.1037/0894-4105.19.3.318">doi:10.1037/0894-4105.19.3.318</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RSDT(-3.857, -1.875, controls_a = 0, controls_b = 0, sd_a = 1,
sd_b = 1, sample_size = 20, r_ab = 0.68)

RSDT(case_a = size_weight_illusion[1, "V_SWI"], case_b = size_weight_illusion[1, "K_SWI"],
 controls_a = size_weight_illusion[-1, "V_SWI"], controls_b = size_weight_illusion[-1, "K_SWI"])

</code></pre>

<hr>
<h2 id='RSDT_power'>Power calculator for RSDT</h2><span id='topic+RSDT_power'></span>

<h3>Description</h3>

<p>Calculates approximate power, given sample size, using Monte Carlo
simulation, for specified case scores, means and standard deviations for the
control sample. The means and standard deviations defaults to 0 and 1
respectively, so if no other values are given the case scores are interpreted
as deviations from the mean in standard deviations. Hence, the effect size of
the dissociation (Z-DCC) would in that case be the difference between the two
case scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RSDT_power(
  case_a,
  case_b,
  mean_a = 0,
  mean_b = 0,
  sd_a = 1,
  sd_b = 1,
  r_ab = 0.5,
  sample_size,
  alternative = c("two.sided", "greater", "less"),
  alpha = 0.05,
  nsim = 10000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RSDT_power_+3A_case_a">case_a</code></td>
<td>
<p>A single value from the expected case observation on task A.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_case_b">case_b</code></td>
<td>
<p>A single value from the expected case observation on task B.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_mean_a">mean_a</code></td>
<td>
<p>The expected mean from the control sample on task A. Defaults
to 0.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_mean_b">mean_b</code></td>
<td>
<p>The expected mean from the control sample on task B. Defaults
to 0.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_sd_a">sd_a</code></td>
<td>
<p>The expected standard deviation from the control sample on task
A. Defaults to 1.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_sd_b">sd_b</code></td>
<td>
<p>The expected standard deviation from the control sample on task
B. Defaults to 1.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_r_ab">r_ab</code></td>
<td>
<p>The expected correlation between the tasks. Defaults to 0.5</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_sample_size">sample_size</code></td>
<td>
<p>The size of the control sample, vary this parameter to see
how the sample size affects power.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;two.sided&quot;
(default) or &quot;one.sided&quot;.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate. This can also be varied, with
effects on power. Defaults to 0.05.</p>
</td></tr>
<tr><td><code id="RSDT_power_+3A_nsim">nsim</code></td>
<td>
<p>The number of simulations to run. Higher number gives better
accuracy, but low numbers such as 10000 or even 1000 are usually sufficient
for the purposes of this calculator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single value approximating the power of the test for the
given parameters.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RSDT_power(case_a = -3, case_b = -1, mean_a = 0, mean_b = 0,
           sd_a = 1, sd_b = 1, r_ab = 0.5, sample_size = 20, nsim = 1000)
</code></pre>

<hr>
<h2 id='singcar'>singcar: Comparing Single Cases to Small Samples</h2><span id='topic+singcar'></span>

<h3>Description</h3>

<p>The aim of <span class="pkg">singcar</span> is to provide and encourage usage of appropriate
statistical methods for comparing a case against a control sample. For
instance, they may commonly be done in a neuropsychological context, in which
an individual has incurred a specific brain injury and we wish to test
whether this damage has led to an impairment of some cognitive function and
whether two different functions are dissociable. For many cognitive functions
there is normed data available which the patient can be compared against
directly. However, when this is not possible a control sample estimating the
population, against which we wish to compare the patient, must be used. Both
frequentist and Bayesian methods have been developed to do this, first and
foremost by John Crawford and Paul Garthwaite (Crawford et al., 2011;
Crawford &amp; Garthwaite, 2002, 2007, 2005; Crawford &amp; Howell, 1998). It is
these methods that <span class="pkg">singcar</span> implements. Power calculators for each respective
test are also provided. Although the canonical applications for these tests
are in Cognitive Neuropsychology or Clinical Neuropsychology, they are
potentially applicable to any circumstance in which a measure taken from a
single individual is to be compared against data from a normative sample
(i.e. a control group). It should be noted that these statistical methods
could also be applied as a general method of outlier detection in small
samples.
</p>


<h3>singcar functions</h3>

<p><code><a href="#topic+TD">TD</a>()</code>
</p>
<p><code><a href="#topic+BTD">BTD</a>()</code>
</p>
<p><code><a href="#topic+BTD_cov">BTD_cov</a>()</code>
</p>
<p><code><a href="#topic+RSDT">RSDT</a>()</code>
</p>
<p><code><a href="#topic+UDT">UDT</a>()</code>
</p>
<p><code><a href="#topic+BSDT">BSDT</a>()</code>
</p>
<p><code><a href="#topic+BSDT_cov">BSDT_cov</a>()</code>
</p>
<p><code><a href="#topic+TD_power">TD_power</a>()</code>
</p>
<p><code><a href="#topic+BTD_power">BTD_power</a>()</code>
</p>
<p><code><a href="#topic+BTD_cov_power">BTD_cov_power</a>()</code>
</p>
<p><code><a href="#topic+RSDT_power">RSDT_power</a>()</code>
</p>
<p><code><a href="#topic+UDT_power">UDT_power</a>()</code>
</p>
<p><code><a href="#topic+BSDT_power">BSDT_power</a>()</code>
</p>
<p><code><a href="#topic+BSDT_cov_power">BSDT_cov_power</a>()</code>
</p>


<h3>References</h3>

<p>Crawford, J., &amp; Garthwaite, P. (2002). Investigation of the single case in
neuropsychology: Confidence limits on the abnormality of test scores and test
score differences. Neuropsychologia, 40(8), 1196-1208.
https://doi.org/10.1016/S0028-3932(01)00224-X
</p>
<p>Crawford, J., &amp; Garthwaite, P. (2007). Comparison of a single case to a
control or normative sample in neuropsychology: Development of a Bayesian
approach. Cognitive Neuropsychology, 24(4), 343-372.
https://doi.org/10.1080/02643290701290146
</p>
<p>Crawford, J., &amp; Garthwaite, P. (2005). Testing for Suspected Impairments and
Dissociations in Single-Case Studies in Neuropsychology: Evaluation of
Alternatives Using Monte Carlo Simulations and Revised Tests for
Dissociations. Neuropsychology, 19(3), 318-331.
https://doi.org/10.1037/0894-4105.19.3.318
</p>
<p>Crawford, J., Garthwaite, P., &amp; Ryan, K. (2011). Comparing a single case to a
control sample: Testing for neuropsychological deficits and dissociations in
the presence of covariates. Cortex, 47(10), 1166-1178.
https://doi.org/10.1016/j.cortex.2011.02.017
</p>
<p>Crawford, J., &amp; Howell, D. (1998). Comparing an Individual's Test Score
Against Norms Derived from Small Samples. The Clinical Neuropsychologist,
12(4), 482-486. https://doi.org/10.1076/clin.12.4.482.7241
</p>

<hr>
<h2 id='size_weight_illusion'>Data from one patient and 28 controls on the size-weight illusion</h2><span id='topic+size_weight_illusion'></span>

<h3>Description</h3>

<p>A dataset containing data from 28 healthy controls and one patient, DF, with
visual form agnosia (inability to perceive the form of objects) from
bilateral lesions to the lateral occipital complex. The size-weight illusion
occurs when a person underestimates the weight of a larger item when compared
to a smaller of equal weight (Charpentier, 1891). From these data, one can
assess the magnitude of the illusion for patient DF by comparison to
age-matched controls under visual and kinaesthetic cue conditions. The
measure of the size-weight illusion is a scaled measure expressing the
number of grams weight difference perceived per cubic cm of volume change
(Hassan et al, 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>size_weight_illusion
</code></pre>


<h3>Format</h3>

<p>A data frame with 29 rows and 6 variables:
</p>

<dl>
<dt>GROUP</dt><dd><p>factor with patient (SC) or control group (HC)</p>
</dd>
<dt>PPT</dt><dd><p>participant identifier</p>
</dd>
<dt>SEX</dt><dd><p>gender of partcipants</p>
</dd>
<dt>YRS</dt><dd><p>age of participants</p>
</dd>
<dt>V_SWI</dt><dd><p>SWI measure from the visual task</p>
</dd>
<dt>K_SWI</dt><dd><p>SWI measure from the kinaesthetic task</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://osf.io/3s2fp/?view_only=50c8af0b39ee436b85d292b0a701cc3b">https://osf.io/3s2fp/?view_only=50c8af0b39ee436b85d292b0a701cc3b</a>
</p>


<h3>References</h3>

<p>Hassan, E. K., Sedda, A., Buckingham, G., &amp; McIntosh, R. D. (2020). The
size-weight illusion in visual form agnosic patient DF. Neurocase, 1-8.
https://doi.org/10.1080/13554794.2020.1800748
</p>

<hr>
<h2 id='TD'>Test of Deficit</h2><span id='topic+TD'></span>

<h3>Description</h3>

<p>Crawford and Howell's (1998) modified t-test. Takes a single observation and
compares it to a distribution estimated by a control sample. Calculates
standardised difference between the case score and the mean of the controls
and proportions falling above or below the case score, as well as associated
confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TD(
  case,
  controls,
  sd = NULL,
  sample_size = NULL,
  alternative = c("less", "greater", "two.sided"),
  conf_int = TRUE,
  conf_level = 0.95,
  conf_int_spec = 0.01,
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TD_+3A_case">case</code></td>
<td>
<p>Case observation, can only be a single value.</p>
</td></tr>
<tr><td><code id="TD_+3A_controls">controls</code></td>
<td>
<p>Numeric vector of observations from the control sample. If
single value, treated as mean.</p>
</td></tr>
<tr><td><code id="TD_+3A_sd">sd</code></td>
<td>
<p>If input of controls is single value, the standard
deviation of the sample must be given as well.</p>
</td></tr>
<tr><td><code id="TD_+3A_sample_size">sample_size</code></td>
<td>
<p>If input of controls is single value, the size of the
sample must be gven as well.</p>
</td></tr>
<tr><td><code id="TD_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"less"</code> (default), <code>"greater"</code> or
<code>"two.sided"</code>. You can specify just the initial letter.</p>
</td></tr>
<tr><td><code id="TD_+3A_conf_int">conf_int</code></td>
<td>
<p>Initiates a search algorithm for finding confidence
intervals. Defaults to <code>TRUE</code>, set to <code>FALSE</code> for faster
calculation (e.g. for simulations).</p>
</td></tr>
<tr><td><code id="TD_+3A_conf_level">conf_level</code></td>
<td>
<p>Level of confidence for intervals, defaults to 95%.</p>
</td></tr>
<tr><td><code id="TD_+3A_conf_int_spec">conf_int_spec</code></td>
<td>
<p>The size of iterative steps for calculating confidence
intervals. Smaller values gives more precise intervals but takes longer to
calculate. Defaults to a specificity of 0.01.</p>
</td></tr>
<tr><td><code id="TD_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove <code>NA</code>s from controls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the point estimate of the standardised difference
between the case score and the mean of the controls and the point estimate
of the p-value (i.e. the percentage of the population that would be
expected to obtain a lower or higher score, depending on the alternative
hypothesis).
</p>


<h3>Value</h3>

<p>A list of class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;">
<code>statistic</code>   </td><td style="text-align: left;"> the value of the t-statistic.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">  <code>parameter</code>
</td><td style="text-align: left;"> the degrees of freedom for the t-statistic.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>p.value</code>    </td><td style="text-align: left;">
the p-value for the test.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code>    </td><td style="text-align: left;"> estimated
standardised difference (Z-CC) and point estimate of p-value. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>null.value</code>   </td><td style="text-align: left;"> the value of the difference under the null
hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>interval</code>     </td><td style="text-align: left;"> named numerical vector containing
level of confidence and confidence intervals for both Z-CC and p-value. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
<code>desc</code>     </td><td style="text-align: left;"> named numerical containing descriptive statistics: mean
and standard deviations of controls as well as sample size and standard error
used in the t-formula. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>alternative</code>     </td><td style="text-align: left;"> a character string
describing the alternative hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character
string indicating what type of t-test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>data.name</code>
</td><td style="text-align: left;"> a character string giving the name(s) of the data as well as
summaries. </td>
</tr>

</table>



<h3>Note of caution</h3>

<p>Calculating the confidence intervals relies on finding non-centrality
parameters for non-central t-distributions. Depending on the degrees of
freedom, the confidence level and the effect size exact accuracy from the
<code>stats::qt()</code> function used can not be guaranteed. However, the
approximations should be good enough for most cases.
See <a href="https://stat.ethz.ch/pipermail/r-help/2008-June/164843.html">https://stat.ethz.ch/pipermail/r-help/2008-June/164843.html</a>.
</p>


<h3>References</h3>

<p>Crawford, J. R., &amp; Howell, D. C. (1998). Comparing an Individual's Test Score
Against Norms Derived from Small Samples. <em>The Clinical Neuropsychologist,
12</em>(4), 482 - 486. <a href="https://doi.org/10.1076/clin.12.4.482.7241">doi:10.1076/clin.12.4.482.7241</a>
</p>
<p>Crawford, J. R., &amp; Garthwaite, P. H. (2002). Investigation of the single case
in neuropsychology: Confidence limits on the abnormality of test scores and
test score differences. <em>Neuropsychologia, 40</em>(8), 1196-1208.
<a href="https://doi.org/10.1016/S0028-3932%2801%2900224-X">doi:10.1016/S0028-3932(01)00224-X</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TD(case = -2, controls = 0, sd = 1, sample_size = 20)

TD(case = size_weight_illusion[1, "V_SWI"],
   controls = size_weight_illusion[-1, "V_SWI"], alternative = "l")

</code></pre>

<hr>
<h2 id='TD_power'>Power calculator for TD</h2><span id='topic+TD_power'></span>

<h3>Description</h3>

<p>Calculates exact power given sample size or sample size given power, using
analytical methods for the frequentist test of deficit for a specified case
score and mean and standard deviation for the control sample. The mean and
standard deviation defaults to 0 and 1, so if no other values are given the
case score is interpreted as deviation from the mean in standard deviations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TD_power(
  case,
  mean = 0,
  sd = 1,
  sample_size = NULL,
  power = NULL,
  alternative = c("less", "greater", "two.sided"),
  alpha = 0.05,
  spec = 0.005
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TD_power_+3A_case">case</code></td>
<td>
<p>A single value from the expected case observation.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_mean">mean</code></td>
<td>
<p>The expected mean of the control sample.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_sd">sd</code></td>
<td>
<p>The expected standard deviation of the control sample.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_sample_size">sample_size</code></td>
<td>
<p>The size of the control sample, vary this parameter to see
how the sample size affects power. One of sample size or power must be
specified, not both.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_power">power</code></td>
<td>
<p>A single value between 0 and 1 specifying desired power for
calculating necessary sample size. One of sample size or power must be
specified, not both.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;less&quot; (default),
&quot;greater&quot; or &quot;two.sided&quot;.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate. This can also be varied, with
effects on power.</p>
</td></tr>
<tr><td><code id="TD_power_+3A_spec">spec</code></td>
<td>
<p>A single value between 0 and 1. If desired power is given as
input the function will utilise a search algorithm to find the sample size
needed to reach the desired power. However, if the power specified is
greater than what is actually possible to achieve the algorithm could
search forever. Hence, when power does not increase substantially for
any additional participant in the sample, the algorithm stops.
By default the algorithm stops when power does not increase more
than 0.5% for any added participant, but by varying <code>spec</code>,
this specificity can be changed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either a single value of the exact power, if sample size is given. Or
a dataframe consisting of both the sample size and the exact power such
size would yield.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>TD_power(case = -2, mean = 0, sd = 1, sample_size = 20)
TD_power(case = -2, mean = 0, sd = 1, power = 0.8)
</code></pre>

<hr>
<h2 id='UDT'>Unstandardised Difference Test</h2><span id='topic+UDT'></span>

<h3>Description</h3>

<p>A test on the discrepancy between two tasks in a single case, by comparison
to the mean of discrepancies of the same two tasks in a control sample. Use
<em>only</em> when the two tasks are measured on the same scale with the same
underlying distribution because no standardisation is performed on task
scores. As a rule-of-thumb, the UDT may be applicable to pairs of tasks for
which it would be sensible to perform a paired t-test within the control
group. Calculates however a standardised effect size in the same manner as
<code><a href="#topic+RSDT">RSDT</a>()</code>. This is original behaviour from Crawford and Garthwaite
(2005) but might not be appropriate. So use this standardised effect size
with caution. Calculates a standardised effect size of task discrepancy as
well as a point estimate of the proportion of the control population that
would be expected to show a more extreme discrepancy and respective
confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UDT(
  case_a,
  case_b,
  controls_a,
  controls_b,
  sd_a = NULL,
  sd_b = NULL,
  sample_size = NULL,
  r_ab = NULL,
  alternative = c("two.sided", "greater", "less"),
  conf_int = TRUE,
  conf_level = 0.95,
  conf_int_spec = 0.01,
  na.rm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UDT_+3A_case_a">case_a</code></td>
<td>
<p>Case's score on task A.</p>
</td></tr>
<tr><td><code id="UDT_+3A_case_b">case_b</code></td>
<td>
<p>Case's score on task B.</p>
</td></tr>
<tr><td><code id="UDT_+3A_controls_a">controls_a</code></td>
<td>
<p>Controls' scores on task A. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task A while mean and SD for task B.</p>
</td></tr>
<tr><td><code id="UDT_+3A_controls_b">controls_b</code></td>
<td>
<p>Controls' scores on task B. Takes either a vector of
observations or a single value interpreted as mean. <em>Note</em>: you can
supply a vector as input for task B while mean and SD for task A.</p>
</td></tr>
<tr><td><code id="UDT_+3A_sd_a">sd_a</code></td>
<td>
<p>If single value for task A is given as input you must
supply the standard deviation of the sample.</p>
</td></tr>
<tr><td><code id="UDT_+3A_sd_b">sd_b</code></td>
<td>
<p>If single value for task B is given as input you must
supply the standard deviation of the sample.</p>
</td></tr>
<tr><td><code id="UDT_+3A_sample_size">sample_size</code></td>
<td>
<p>If A or B is given as mean and SD you must supply the
sample size. If controls_a is given as vector and controls_b as mean and
SD, sample_size must equal the number of observations in controls_a.</p>
</td></tr>
<tr><td><code id="UDT_+3A_r_ab">r_ab</code></td>
<td>
<p>If A and/or B is given as mean and SD you must supply the
correlation between the tasks.</p>
</td></tr>
<tr><td><code id="UDT_+3A_alternative">alternative</code></td>
<td>
<p>A character string specifying the alternative hypothesis,
must be one of <code>"two.sided"</code> (default), <code>"greater"</code> or
<code>"less"</code>. You can specify just the initial letter. Since the direction
of the expected effect depends on which task is set as A and which is set
as B, be very careful if changing this parameter.</p>
</td></tr>
<tr><td><code id="UDT_+3A_conf_int">conf_int</code></td>
<td>
<p>Initiates a search algorithm for finding confidence
intervals. Defaults to <code>TRUE</code>, set to <code>FALSE</code> for faster
calculation (e.g. for simulations).</p>
</td></tr>
<tr><td><code id="UDT_+3A_conf_level">conf_level</code></td>
<td>
<p>Level of confidence for intervals, defaults to 95%.</p>
</td></tr>
<tr><td><code id="UDT_+3A_conf_int_spec">conf_int_spec</code></td>
<td>
<p>The size of iterative steps for calculating confidence
intervals. Smaller values gives more precise intervals but takes longer to
calculate. Defaults to a specificity of 0.01.</p>
</td></tr>
<tr><td><code id="UDT_+3A_na.rm">na.rm</code></td>
<td>
<p>Remove <code>NA</code>s from controls.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Running  <code>UDT</code> is equivalent to running <code>TD</code> on discrepancy scores
making it possible to run unstandardised tests with covariates by applying
<code>BTD_cov</code> to discrepancy scores.
</p>


<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<table>
<tr>
 <td style="text-align: left;"> <code>statistic</code>   </td><td style="text-align: left;"> the t-statistic. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>parameter</code> </td><td style="text-align: left;"> the degrees of freedom for the t-statistic.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>p.value</code>    </td><td style="text-align: left;"> the p-value of the test.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>estimate</code> </td><td style="text-align: left;">
  unstandardised case scores, task difference and pont estimate of proportion
  control population expected to above or below the observed task difference.
  </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>control.desc</code>   </td><td style="text-align: left;"> named numerical with descriptive
  statistics of the control samples. </td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>null.value</code>   </td><td style="text-align: left;"> the
  value of the difference under the null hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;">
  <code>alternative</code>     </td><td style="text-align: left;"> a character string describing the alternative
  hypothesis.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>method</code> </td><td style="text-align: left;"> a character string indicating what
  type of test was performed.</td>
</tr>
<tr>
 <td style="text-align: left;"></td>
</tr>
<tr>
 <td style="text-align: left;"> <code>data.name</code> </td><td style="text-align: left;"> a character string
  giving the name(s) of the data</td>
</tr>

</table>



<h3>References</h3>

<p>Crawford, J. R., &amp; Garthwaite, P. H. (2005). Testing for
Suspected Impairments and Dissociations in Single-Case Studies in
Neuropsychology: Evaluation of Alternatives Using Monte Carlo Simulations and
Revised Tests for Dissociations. <em>Neuropsychology, 19</em>(3), 318 - 331.
<a href="https://doi.org/10.1037/0894-4105.19.3.318">doi:10.1037/0894-4105.19.3.318</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>UDT(-3.857, -1.875, controls_a = 0, controls_b = 0, sd_a = 1,
sd_b = 1, sample_size = 20, r_ab = 0.68)

UDT(case_a = size_weight_illusion[1, "V_SWI"], case_b = size_weight_illusion[1, "K_SWI"],
 controls_a = size_weight_illusion[-1, "V_SWI"], controls_b = size_weight_illusion[-1, "K_SWI"])

</code></pre>

<hr>
<h2 id='UDT_power'>Power calculator for UDT</h2><span id='topic+UDT_power'></span>

<h3>Description</h3>

<p>Calculates exact power given sample size or sample size given power, using
analytical methods for the frequentist test of deficit for a specified case
scores, means and standard deviations for the control sample. The means and
standard deviations defaults to 0 and 1 respectively, so if no other values
are given, the case scores are interpreted as deviations from the mean in
standard deviations. The returned value will approximate the power for the
given parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UDT_power(
  case_a,
  case_b,
  mean_a = 0,
  mean_b = 0,
  sd_a = 1,
  sd_b = 1,
  r_ab = 0.5,
  sample_size = NULL,
  power = NULL,
  alternative = c("two.sided", "greater", "less"),
  alpha = 0.05,
  spec = 0.005
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UDT_power_+3A_case_a">case_a</code></td>
<td>
<p>A single value from the expected case observation on task A.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_case_b">case_b</code></td>
<td>
<p>A single value from the expected case observation on task B.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_mean_a">mean_a</code></td>
<td>
<p>The expected mean from the control sample on task A. Defaults
to 0.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_mean_b">mean_b</code></td>
<td>
<p>The expected mean from the control sample on task B. Defaults
to 0.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_sd_a">sd_a</code></td>
<td>
<p>The expected standard deviation from the control sample on task
A. Defaults to 1.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_sd_b">sd_b</code></td>
<td>
<p>The expected standard deviation from the control sample on task
B. Defaults to 1.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_r_ab">r_ab</code></td>
<td>
<p>The expected correlation between the tasks. Defaults to 0.5</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_sample_size">sample_size</code></td>
<td>
<p>The size of the control sample, vary this parameter to see
how the sample size affects power. One of sample size or power must be
specified, not both.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_power">power</code></td>
<td>
<p>A single value between 0 and 1 specifying desired power for
calculating necessary sample size. One of sample size or power must be
specified, not both.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_alternative">alternative</code></td>
<td>
<p>The alternative hypothesis. A string of either &quot;two.sided&quot;
(default) or &quot;one.sided&quot;.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_alpha">alpha</code></td>
<td>
<p>The specified Type I error rate. This can also be varied, with
effects on power. Defaults to 0.05.</p>
</td></tr>
<tr><td><code id="UDT_power_+3A_spec">spec</code></td>
<td>
<p>A single value between 0 and 1. If desired power is given as
input the function will utilise a search algorithm to find the sample size
needed to reach the desired power. However, if the power specified is
greater than what is actually possible to achieve the algorithm could
search forever. Hence, when power does not increase substantially for any
additional participant in the sample, the algorithm stops. By default the
algorithm stops when power does not increase more than 0.5
participant, but by varying <code>spec</code>, this specificity can be changed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either a single value of the exact power, if sample size is given. Or
a dataframe consisting of both the sample size and the exact power such
size would yield.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>UDT_power(case_a = -3, case_b = -1, mean_a = 0, mean_b = 0,
          sd_a = 1, sd_b = 1, r_ab = 0.5, sample_size = 20)
UDT_power(case_a = -3, case_b = -1, power = 0.8)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
