<!DOCTYPE html><html><head><title>Help for package pomdpSolve</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pomdpSolve}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#find_pomdp_solve'><p>Find the executable for 'pomdp-solve'</p></a></li>
<li><a href='#pomdp_solve'><p>Solving a POMDP with 'pomdp-solve'</p></a></li>
<li><a href='#pomdpSolve-package'><p>pomdpSolve: Interface to 'pomdp-solve' for Partially Observable Markov Decision Processes</p></a></li>
<li><a href='#read_write'><p>Read and Write Files for 'pomdp-solve'</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Interface to 'pomdp-solve' for Partially Observable Markov
Decision Processes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-31</td>
</tr>
<tr>
<td>Description:</td>
<td>Installs an updated version of 'pomdp-solve', a program to solve Partially Observable Markov Decision Processes (POMDPs) using a variety of exact and approximate value iteration algorithms. A convenient R infrastructure is provided in the separate package pomdp. Kaelbling, Littman and Cassandra (1998) &lt;<a href="https://doi.org/10.1016%2FS0004-3702%2898%2900023-X">doi:10.1016/S0004-3702(98)00023-X</a>&gt;.</td>
</tr>
<tr>
<td>Classification/ACM:</td>
<td>G.4, G.1.6, I.2.6</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mhahsler/pomdpSolve">https://github.com/mhahsler/pomdpSolve</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mhahsler/pomdpSolve/issues">https://github.com/mhahsler/pomdpSolve/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>pomdp</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Copyright:</td>
<td>pomdp-solve is Copyright (C) Anthony R. Cassandra; LASPack
is Copyright (C) Tomas Skalicky; lp-solve is Copyright (C)
Michel Berkelaar, Kjell Eikland, Peter Notebaert; all other
code is Copyright (C) Michael Hahsler.</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-31 18:26:18 UTC; hahsler</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Hahsler <a href="https://orcid.org/0000-0003-2716-1405"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cph, cre],
  Anthony R. Cassandra [aut, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Hahsler &lt;mhahsler@lyle.smu.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-31 19:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='find_pomdp_solve'>Find the executable for 'pomdp-solve'</h2><span id='topic+find_pomdp_solve'></span><span id='topic+pomdp-solve'></span><span id='topic+pomdpsolve'></span>

<h3>Description</h3>

<p>Find the <code>pomdp-solve</code> executable
to solve Partially Observable Decision Processes (POMDPs) (Kaelbling et al, 1998)
installed by the <span class="pkg">pomdpSolve</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_pomdp_solve()
</code></pre>


<h3>Details</h3>

<p>This package only provides a direct interface to the executable.
A more convenient and powerful interface is provided by the function
<code><a href="pomdp.html#topic+solve_POMDP">pomdp::solve_POMDP()</a></code> in package <span class="pkg">pomdp</span>.
</p>
<p>The executable of <code>pomdp-solve</code> in this direct interface needs to be called with
<code><a href="base.html#topic+system2">system2()</a></code> and runs in a separate process. This way, a failure in the solver will not compromise the
R session. <code>pomdp-solve</code> creates files with the value function and
the policy graph (see <a href="#topic+read_write">read_write</a>).
</p>


<h3>Value</h3>

<p>returns the path to the 'pomdp-solve' executable as a string or stops with an error.
</p>


<h3>References</h3>

<p>Kaelbling, L.P., Littman, M.L., Cassandra, A.R. (1998).
Planning and acting in partially observable stochastic domains.
<em>Artificial Intelligence.</em> <strong>101</strong> (1â€“2): 99-134.
<a href="https://doi.org/10.1016/S0004-3702%2898%2900023-X">doi:10.1016/S0004-3702(98)00023-X</a>
</p>
<p>Anthony R. Cassandra, pomdp-solve documentation,
<a href="https://www.pomdp.org/code/index.html">https://www.pomdp.org/code/index.html</a>
</p>


<h3>See Also</h3>

<p>read_write
</p>


<h3>Examples</h3>

<pre><code class='language-R'># find the location of the pomdp-solve executable
find_pomdp_solve()

# get pomdp-solve options
system2(find_pomdp_solve(), args = "-h")

# an example of how to solve a simple POMDP can be found in the man page
# for read_write.
</code></pre>

<hr>
<h2 id='pomdp_solve'>Solving a POMDP with 'pomdp-solve'</h2><span id='topic+pomdp_solve'></span><span id='topic+pomdp_solve_help'></span>

<h3>Description</h3>

<p>This function provides a bare bones interface to run pomdp-solve on a POMDP
file. The results can be read with the function provides in <a href="#topic+read_write">read_write</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pomdp_solve(pomdp, options = list(), verbose = TRUE)

pomdp_solve_help()
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pomdp_solve_+3A_pomdp">pomdp</code></td>
<td>
<p>the POMDP file to solve.</p>
</td></tr>
<tr><td><code id="pomdp_solve_+3A_options">options</code></td>
<td>
<p>a list with options for pomdp-solve.</p>
</td></tr>
<tr><td><code id="pomdp_solve_+3A_verbose">verbose</code></td>
<td>
<p>logical; show the program text output?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calling <code>solve_pomdp()</code> first cleans results from previous runs and then executes pomdp-solve with the specified options.
</p>
<p>The options are specified in <code>options</code> as a list with entries of the form <code style="white-space: pre;">&#8288;&lt;option&gt; = &lt;value&gt;&#8288;</code>.
<code>pomdp_solve_help()</code> displays the available options. Note that the leading dash is not used on the option name. For example:
<code>list(method = "grid", epsilon = 0.1)</code> sets the method option to grid and epsilon to 0.1.
Here is a slightly more <a href="https://mhahsler.github.io/pomdpSolve/pomdp-solve_manual">detailed description of pomdp-solve's options.</a>
</p>


<h3>Value</h3>

<p>nothing
</p>


<h3>References</h3>

<p>Anthony R. Cassandra, pomdp-solve documentation,
<a href="https://www.pomdp.org/code/index.html">https://www.pomdp.org/code/index.html</a>
</p>


<h3>See Also</h3>

<p>find_pomdp_solve read_write
</p>


<h3>Examples</h3>

<pre><code class='language-R'># display available options
pomdp_solve_help()

# solve a POMDP file that ships with this package in a temporary directory
old_wd &lt;- setwd(tempdir())

file.copy(system.file("tiger.aaai.POMDP", package = "pomdpSolve"), "./tiger.aaai.POMDP")

# Example 1: run solver to completion
pomdp_solve("tiger.aaai.POMDP", options = list(method = "incprune"))
dir()
# you can inspect the files with file.show()

# read the raw policy graph (-0 means infinite horizon solution)
read_pg_file("tiger.aaai-0.pg")

# read the raw value function
read_alpha_file("tiger.aaai-0.alpha")

# Example 2: use method finite grid (point-based algorithm) and save the used belief points
pomdp_solve("tiger.aaai.POMDP", options = list(method = "grid", fg_save = TRUE))
dir()

read_belief_file("tiger.aaai-0.belief")

# Example 3: Stop value iteration after 50 epochs and then continue with a second call
pomdp_solve("tiger.aaai.POMDP", options = list(method = "incprune", horizon = 50))
alpha &lt;- read_alpha_file("tiger.aaai-0.alpha")

write_terminal_values("terminal.alpha", alpha)
pomdp_solve("tiger.aaai.POMDP", options = list(method = "incprune", 
  terminal_values = "terminal.alpha"))

# return to the old directory
setwd(old_wd)
</code></pre>

<hr>
<h2 id='pomdpSolve-package'>pomdpSolve: Interface to 'pomdp-solve' for Partially Observable Markov Decision Processes</h2><span id='topic+pomdpSolve-package'></span>

<h3>Description</h3>

<p>Installs an updated version of 'pomdp-solve', a program to solve Partially Observable Markov Decision Processes (POMDPs) using a variety of exact and approximate value iteration algorithms. This package only provides the executable and a few reading routines. A convenient R infrastructure to use the solver is provided in the separate package <span class="pkg">pomdp</span> (<a href="pomdp.html#topic+pomdp-package">pomdp::pomdp-package</a>).
</p>


<h3>Key functions</h3>


<ul>
<li><p> Solve a POMDP file with pomdp-solve using <code><a href="#topic+pomdp_solve">pomdp_solve()</a></code>.
</p>
</li>
<li><p> Read and write files for pomdp-solve (see <a href="#topic+read_write">read_write</a>).
</p>
</li>
<li><p> Find the pomdp-solve executable using <code><a href="#topic+find_pomdp_solve">find_pomdp_solve()</a></code>.
</p>
</li></ul>

<p>Package pomdp provides more convenient support to
</p>

<ul>
<li><p> Define a POMDP using <a href="pomdp.html#topic+POMDP">pomdp::POMDP</a>
</p>
</li>
<li><p> Solve a POMDP using <code><a href="pomdp.html#topic+solve_POMDP">pomdp::solve_POMDP()</a></code>
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Michael Hahsler
</p>

<hr>
<h2 id='read_write'>Read and Write Files for 'pomdp-solve'</h2><span id='topic+read_write'></span><span id='topic+read_alpha_file'></span><span id='topic+read_pg_file'></span><span id='topic+read_belief_file'></span><span id='topic+write_grid_file'></span><span id='topic+write_terminal_values'></span>

<h3>Description</h3>

<p>Read and write files for the pomdp-solve executable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_alpha_file(file)

read_pg_file(file)

read_belief_file(file)

write_grid_file(file, belief_points, digits = 7)

write_terminal_values(file, alpha, digits = 7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_write_+3A_file">file</code></td>
<td>
<p>name of the file to read from or to write to.</p>
</td></tr>
<tr><td><code id="read_write_+3A_belief_points">belief_points</code></td>
<td>
<p>a numeric matrix with the number of states columns. Rows represent belief points.</p>
</td></tr>
<tr><td><code id="read_write_+3A_digits">digits</code></td>
<td>
<p>number of digits used to write files.</p>
</td></tr>
<tr><td><code id="read_write_+3A_alpha">alpha</code></td>
<td>
<p>a numeric alpha vector with the length of the number of states.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>pomdp-solve uses text format for its input and output. The input is a <a href="https://www.pomdp.org/code/pomdp-file-spec.html">POMDP file</a>. The outputs are the following.
</p>
<p><strong>Value Function</strong>
</p>
<p>The value function is returned as files with the extension <code>.alpha</code>
in the format:
</p>
<pre>
A
V1 V2 V3 ... VN

A
V1 V2 V3 ... VN

...
</pre>
<p>Where <code>A</code> is an action number and the <code>V1</code> through <code>VN</code> are real values
representing the components of a particular vector that has the
associated action. The action number is the 0-based index of
the action as specified in
the input POMDP file. The vector represents the coefficients of a hyperplane
representing one facet of the piecewise linear and convex (PWLC) value
function. Note that the length of the lists needs to be equal to the
number of states in the POMDP.
</p>
<p><code>read_alpha_file()</code> reads the V components from the file and returns a matrix.
</p>
<p><strong>Policy Graph</strong>
</p>
<p>The policy graph is returned as a file with the extension <code>.pg</code>.
Each line of the file represents one node of the policy graph and
its contents are:
</p>
<pre>
N A  Z1 Z2 Z3 ...
...
</pre>
<p>Here <code>N</code> is a node ID giving the node a unique name, numbered sequentially
and lining up with the value function vectors in the
corresponding output <code>.alpha</code> file above.
</p>
<p>The <code>A</code> is the action number defined for this node; it is an integer referring
to the the POMDP file actions by its 0-based index number.
These are followed by a list of node IDs, one for each observation. Thus the
list will have a length equal to the number of observations in the POMDP.
This list specifies the transitions in the policy graph. The nth number in
the list will be the index of the node that follows this one when the
observation received is <code>n</code>.
</p>
<p><code>read_pg_file()</code> returns a data.frame with the nodes in the policy graph as rows.
</p>
<p><strong>Terminal Values</strong>
</p>
<p>Terminal values can be specified as a single alpha vector.
</p>
<p><strong>Grid-based Solver Specific Files</strong>
</p>
<p>The grid-based method can write the used belief points do disk (command line option <code>-fg_save</code>). The
file can be read using <code>read_belief_file()</code>.
</p>
<p>A matrix with belief points can be written using <code>write_grid_file()</code>. This file can be used
</p>
<p>Details about the file formats and pomdp-solve can be found in the References section.
</p>
<p>See <code><a href="#topic+pomdp_solve">pomdp_solve()</a></code> for examples.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>read_alpha_file()</code> returns the value function (alpha vectors) as a matrix.
</p>
</li>
<li> <p><code>read_pg_file()</code> returns the policy graph as a data.frame.
</p>
</li>
<li> <p><code>read_belief_file()</code> returns a matrix if the solver wrote a belief file.
</p>
</li>
<li> <p><code>write_grid_file()</code> returns nothing.
</p>
</li>
<li> <p><code>write_terminal_values()</code> returns nothing.
</p>
</li></ul>



<h3>References</h3>

<p>Anthony R. Cassandra, pomdp-solve documentation,
<a href="https://www.pomdp.org/code/index.html">https://www.pomdp.org/code/index.html</a>
</p>


<h3>See Also</h3>

<p>find_pomdp_solve
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
