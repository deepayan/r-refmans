<!DOCTYPE html><html><head><title>Help for package cv</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {cv}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cv'><p>Cross-Validate Regression Models</p></a></li>
<li><a href='#cvMixed'><p>Cross-Validate Mixed-Effects Model</p></a></li>
<li><a href='#cvSelect'><p>Cross-Validate a Model-Selection Procedure</p></a></li>
<li><a href='#GetResponse'><p>Extract Response Variable</p></a></li>
<li><a href='#models'><p>Cross-Validate Several Models Fit to the Same Data</p></a></li>
<li><a href='#mse'><p>Cost Functions for Fitted Regression Models</p></a></li>
<li><a href='#Pigs'><p>Body Weights of 48 Pigs in 9 Successive Weeks</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Cross-Validation of Regression Models</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-10</td>
</tr>
<tr>
<td>Description:</td>
<td>Cross-validation methods of regression models that exploit features of various
    modeling functions to improve speed. Some of the methods implemented in the package are
    novel, as described in the package vignettes; for general introductions to cross-validation,
    see, for example, Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani 
    (2021, ISBN 978-1-0716-1417-4, Secs. 5.1, 5.3), "An Introduction to Statistical Learning with 
    Applications in R, Second Edition", and Trevor Hastie, Robert Tibshirani, 
    and Jerome Friedman (2009, ISBN 978-0-387-84857-0, Sec. 7.10), "The Elements of Statistical 
    Learning, Second Edition".</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), doParallel</td>
</tr>
<tr>
<td>Imports:</td>
<td>car, foreach, insight, lme4, MASS, methods, nlme</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, carData, dplyr, effects, glmmTMB, ISLR2, knitr,
lattice, latticeExtra, leaps, Metrics, microbenchmark, nnet,
rmarkdown, spelling, testthat</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://gmonette.github.io/cv/">https://gmonette.github.io/cv/</a>,
<a href="https://CRAN.R-project.org/package=cv">https://CRAN.R-project.org/package=cv</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/gmonette/cv/issues">https://github.com/gmonette/cv/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-23 18:28:46 UTC; johnfox</td>
</tr>
<tr>
<td>Author:</td>
<td>John Fox <a href="https://orcid.org/0000-0002-1196-8012"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Georges Monette [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Georges Monette &lt;georges+cv@yorku.ca&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-27 18:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='cv'>Cross-Validate Regression Models</h2><span id='topic+cv'></span><span id='topic+cv.default'></span><span id='topic+print.cv'></span><span id='topic+print.cvList'></span><span id='topic+cv.lm'></span><span id='topic+cv.glm'></span><span id='topic+cv.rlm'></span>

<h3>Description</h3>

<p>A parallelized generic k-fold (including n-fold, i.e., leave-one-out)
cross-validation function, with a default method, and
specific methods for linear and generalized-linear models that can be much
more computationally efficient.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(model, data, criterion, k, reps = 1, seed, ...)

## Default S3 method:
cv(
  model,
  data = insight::get_data(model),
  criterion = mse,
  k = 10,
  reps = 1,
  seed,
  confint = n &gt;= 400,
  level = 0.95,
  ncores = 1,
  type = "response",
  ...
)

## S3 method for class 'cv'
print(x, digits = getOption("digits"), ...)

## S3 method for class 'cvList'
print(x, ...)

## S3 method for class 'lm'
cv(
  model,
  data = insight::get_data(model),
  criterion = mse,
  k = 10,
  reps = 1,
  seed,
  confint = n &gt;= 400,
  level = 0.95,
  method = c("auto", "hatvalues", "Woodbury", "naive"),
  ncores = 1,
  ...
)

## S3 method for class 'glm'
cv(
  model,
  data = insight::get_data(model),
  criterion = mse,
  k = 10,
  reps = 1,
  seed,
  confint = n &gt;= 400,
  level = 0.95,
  method = c("exact", "hatvalues", "Woodbury"),
  ncores = 1,
  ...
)

## S3 method for class 'rlm'
cv(model, data, criterion, k, reps = 1, seed, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_+3A_model">model</code></td>
<td>
<p>a regression model object (see Details).</p>
</td></tr>
<tr><td><code id="cv_+3A_data">data</code></td>
<td>
<p>data frame to which the model was fit (not usually necessary).</p>
</td></tr>
<tr><td><code id="cv_+3A_criterion">criterion</code></td>
<td>
<p>cross-validation criterion (&quot;cost&quot; or lack-of-fit) function of form <code>f(y, yhat)</code>
where <code>y</code> is the observed values of the response and
<code>yhat</code> the predicted values; the default is <code><a href="#topic+mse">mse</a></code>
(the mean-squared error).</p>
</td></tr>
<tr><td><code id="cv_+3A_k">k</code></td>
<td>
<p>perform k-fold cross-validation (default is <code>10</code>); <code>k</code>
may be a number or <code>"loo"</code> or <code>"n"</code> for n-fold (leave-one-out)
cross-validation.</p>
</td></tr>
<tr><td><code id="cv_+3A_reps">reps</code></td>
<td>
<p>number of times to replicate k-fold CV (default is <code>1</code>)</p>
</td></tr>
<tr><td><code id="cv_+3A_seed">seed</code></td>
<td>
<p>for R's random number generator; optional, if not
supplied a random seed will be selected and saved; not needed
for n-fold cross-validation</p>
</td></tr>
<tr><td><code id="cv_+3A_...">...</code></td>
<td>
<p>to match generic; passed to <code>predict()</code> for the default method.</p>
</td></tr>
<tr><td><code id="cv_+3A_confint">confint</code></td>
<td>
<p>if <code>TRUE</code> (the default if the number of cases is 400
or greater), compute a confidence interval for the bias-corrected CV
criterion, if the criterion is the average of casewise components.</p>
</td></tr>
<tr><td><code id="cv_+3A_level">level</code></td>
<td>
<p>confidence level (default <code>0.95</code>).</p>
</td></tr>
<tr><td><code id="cv_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to use for parallel computations
(default is <code>1</code>, i.e., computations aren't done in parallel)</p>
</td></tr>
<tr><td><code id="cv_+3A_type">type</code></td>
<td>
<p>for the default method, value to be passed to the
<code>type</code> argument of <code>predict()</code>;
the default is <code>type="response"</code>, which is appropriate, e.g., for a <code>"glm"</code> model
and may be recognized or ignored by <code>predict()</code> methods for other model classes.</p>
</td></tr>
<tr><td><code id="cv_+3A_x">x</code></td>
<td>
<p>a <code>"cv"</code> or <code>"cvList"</code> object to be printed</p>
</td></tr>
<tr><td><code id="cv_+3A_digits">digits</code></td>
<td>
<p>significant digits for printing,
default taken from the <code>"digits"</code> option</p>
</td></tr>
<tr><td><code id="cv_+3A_method">method</code></td>
<td>
<p>computational method to apply to a linear (i.e. <code>"lm"</code>) model
or to a generalized linear (i.e., <code>"glm"</code>) model. See Details for an explanation
of the available options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default <code>cv()</code> method uses <code><a href="stats.html#topic+update">update</a>()</code> to refit the model
to each fold, and should work if there are appropriate <code>update()</code>
and <code><a href="stats.html#topic+predict">predict</a>()</code> methods, and if the default method for <code><a href="#topic+GetResponse">GetResponse</a>()</code>
works or if a <code>GetResponse()</code> method is supplied.
</p>
<p>The <code>"lm"</code> and <code>"glm"</code> methods can use much faster computational
algorithms, as selected by the <code>method</code> argument. The linear-model
method accommodates weighted linear models.
</p>
<p>For both classes of models, for the leave-one-out (n-fold) case, fitted values
for the folds can be computed from the hat-values via
<code>method="hatvalues"</code> without refitting the model;
for GLMs, this method is approximate, for LMs it is exact.
</p>
<p>Again for both classes of models, when more than one case is omitted
in each fold, fitted values may be obtained without refitting the
model by exploiting the Woodbury matrix identity via <code>method="Woodbury"</code>.
As for hatvalues, this method is exact for LMs and approximate for
GLMs.
</p>
<p>The default for linear models is <code>method="auto"</code>,
which is equivalent to <code>method="hatvalues"</code> for n-fold cross-validation
and <code>method="Woodbury"</code> otherwise; <code>method="naive"</code> refits
the model via <code>update()</code> and is generally much slower. The
default for generalized linear models is <code>method="exact"</code>,
which employs <code>update()</code>.
</p>
<p>There is also a method for robust linear models fit by
<code><a href="MASS.html#topic+rlm">rlm</a>()</code> in the <span class="pkg">MASS</span> package (to avoid
inheriting the <code>"lm"</code> method for which the default <code>"auto"</code>
computational method would be inappropriate).
</p>
<p>For additional details, see the &quot;Cross-validation of regression models&quot;
vignette (<code>vignette("cv", package="cv")</code>).
</p>
<p><code>cv()</code> is designed to be extensible to other classes of regression
models; see the &quot;Extending the cv package&quot; vignette
(<code>vignette("cv-extend", package="cv")</code>).
</p>


<h3>Value</h3>

<p>The <code>cv()</code> methods return an object of class <code>"cv"</code>, with the CV criterion
(<code>"CV crit"</code>), the bias-adjusted CV criterion (<code>"adj CV crit"</code>),
the criterion for the model applied to the full data (<code>"full crit"</code>),
the confidence interval and level for the bias-adjusted CV criterion (<code>"confint"</code>),
the number of folds (<code>"k"</code>), and the seed for R's random-number
generator (<code>"seed"</code>). Some methods may return a
subset of these components and may add additional information.
If <code>reps</code> &gt; <code>1</code>, then an object of class <code>"cvList"</code> is returned,
which is literally a list of <code>"cv"</code> objects.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>cv(default)</code>: <code>default</code> method
</p>
</li>
<li> <p><code>cv(lm)</code>: <code>"lm"</code> method
</p>
</li>
<li> <p><code>cv(glm)</code>: <code>"glm"</code> method
</p>
</li>
<li> <p><code>cv(rlm)</code>: <code>"rlm"</code> method (to avoid inheriting the <code>"lm"</code> method)
</p>
</li></ul>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>print(cv)</code>: <code>print()</code> method
</p>
</li></ul>


<h3>Functions</h3>


<ul>
<li> <p><code>print(cvList)</code>: <code>print()</code> method
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="#topic+cvMixed">cvMixed</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Auto", package="ISLR2")
m.auto &lt;- lm(mpg ~ horsepower, data=Auto)
cv(m.auto,  k="loo")
cv(m.auto, seed=1234)
cv(m.auto, seed=1234, reps=3)

data("Mroz", package="carData")
m.mroz &lt;- glm(lfp ~ ., data=Mroz, family=binomial)
cv(m.mroz, criterion=BayesRule, seed=123)

data("Duncan", package="carData")
m.lm &lt;- lm(prestige ~ income + education, data=Duncan)
m.rlm &lt;- MASS::rlm(prestige ~ income + education,
                   data=Duncan)
cv(m.lm, k="loo", method="Woodbury")
cv(m.rlm, k="loo")
</code></pre>

<hr>
<h2 id='cvMixed'>Cross-Validate Mixed-Effects Model</h2><span id='topic+cvMixed'></span><span id='topic+cv.merMod'></span><span id='topic+cv.lme'></span><span id='topic+cv.glmmTMB'></span>

<h3>Description</h3>

<p><code><a href="#topic+cv">cv</a>()</code> methods for models of class <code>"merMod"</code>, fit
by the <code><a href="lme4.html#topic+lmer">lmer</a>()</code> and <code><a href="lme4.html#topic+glmer">glmer</a>()</code> functions
in the <span class="pkg">lme4</span> package; for models of class <code>"lme"</code>
fit by the <code><a href="nlme.html#topic+lme">lme</a>()</code> function in the <span class="pkg">nlme</span>
package; and for models of class <code>"glmmTMB"</code> fit by the
<code><a href="glmmTMB.html#topic+glmmTMB">glmmTMB</a>()</code> function in the <span class="pkg">glmmTMB</span> package.
The <code>cvMixed()</code> function is meant to be called by
<code>cv()</code> methods for mixed-effect models and not directly by the user.
It can be used to extend <code>cv()</code> to other classes of mixed-effects models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvMixed(
  model,
  package,
  data = insight::get_data(model),
  criterion = mse,
  k,
  reps = 1,
  confint,
  level = 0.95,
  seed,
  ncores = 1,
  clusterVariables,
  predict.clusters.args = list(object = model, newdata = data),
  predict.cases.args = list(object = model, newdata = data),
  ...
)

## S3 method for class 'merMod'
cv(
  model,
  data = insight::get_data(model),
  criterion = mse,
  k,
  reps = 1,
  seed,
  ncores = 1,
  clusterVariables,
  ...
)

## S3 method for class 'lme'
cv(
  model,
  data = insight::get_data(model),
  criterion = mse,
  k,
  reps = 1,
  seed,
  ncores = 1,
  clusterVariables,
  ...
)

## S3 method for class 'glmmTMB'
cv(
  model,
  data = insight::get_data(model),
  criterion = mse,
  k,
  reps = 1,
  seed,
  ncores = 1,
  clusterVariables,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvMixed_+3A_model">model</code></td>
<td>
<p>a mixed-effects model object for which a <code>cv()</code> method is available.</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_package">package</code></td>
<td>
<p>the name of the package in which mixed-modeling function (or functions) employed resides;
used to get the namespace of the package.</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_data">data</code></td>
<td>
<p>data frame to which the model was fit (not usually necessary)</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_criterion">criterion</code></td>
<td>
<p>cross-validation (&quot;cost&quot; or lack-of-fit) criterion function of form <code>f(y, yhat)</code>
where <code>y</code> is the observed values of the response and
<code>yhat</code> the predicted values; the default is <code><a href="#topic+mse">mse</a></code>
(the mean-squared error)</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_k">k</code></td>
<td>
<p>perform k-fold cross-validation; <code>k</code>
may be a number or <code>"loo"</code> or <code>"n"</code> for n-fold (leave-one-out)
cross-validation; the default is <code>10</code> if cross-validating individual
cases and <code>"loo"</code> if cross-validating clusters.</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_reps">reps</code></td>
<td>
<p>number of times to replicate k-fold CV (default is <code>1</code>),</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_confint">confint</code></td>
<td>
<p>if <code>TRUE</code> (the default if the number of cases is 400
or greater), compute a confidence interval for the bias-corrected CV
criterion, if the criterion is the average of casewise components.</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_level">level</code></td>
<td>
<p>confidence level (default <code>0.95</code>).</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_seed">seed</code></td>
<td>
<p>for R's random number generator; optional, if not
supplied a random seed will be selected and saved; not needed
for n-fold cross-validation</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to use for parallel computations
(default is <code>1</code>, i.e., computations aren't done in parallel)</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_clustervariables">clusterVariables</code></td>
<td>
<p>a character vector of names of the variables
defining clusters for a mixed model with nested or crossed random effects;
if missing, cross-validation is performed for individual cases rather than
for clusters</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_predict.clusters.args">predict.clusters.args</code></td>
<td>
<p>a list of arguments to be used to predict
the whole data set from a mixed model when performing CV on clusters;
the first two elements should be
<code>model</code> and <code>newdata</code>; see the &quot;Extending the cv package&quot; vignette
(<code>vignette("cv-extend", package="cv")</code>).</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_predict.cases.args">predict.cases.args</code></td>
<td>
<p>a list of arguments to be used to predict
the whole data set from a mixed model when performing CV on cases;
the first two elements should be
<code>model</code> and <code>newdata</code>; see the &quot;Extending the cv package&quot; vignette
(<code>vignette("cv-extend", package="cv")</code>).</p>
</td></tr>
<tr><td><code id="cvMixed_+3A_...">...</code></td>
<td>
<p>for <code>cv()</code> methods, to match generic,
and for <code>cvMixed()</code>, arguments to be passed to <code>update()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For mixed-effects models, cross-validation can be done by &quot;clusters&quot; or by
individual observations. If the former, predictions are based only on fixed
effects; if the latter, predictions include the random effects (i.e., are the
best linear unbiased predictors or &quot;BLUPS&quot;).
</p>


<h3>Value</h3>

<p><code>cvMixed()</code>, and functions based on it, such as the methods
<code>cv.merMod()</code>, <code>cv.lme()</code>, and <code>cv.glmmTMB()</code>, return objects of class <code>"cv"</code>, or,
if <code>reps &gt; 1</code>, of class <code>"cvList"</code> (see <code><a href="#topic+cv">cv</a>()</code>).
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>cvMixed()</code>: not to be called directly
</p>
</li>
<li> <p><code>cv(merMod)</code>: <code>cv()</code> method
</p>
</li>
<li> <p><code>cv(lme)</code>: <code>cv()</code> method
</p>
</li>
<li> <p><code>cv(glmmTMB)</code>: <code>cv()</code> method
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code>, <code><a href="lme4.html#topic+lmer">lmer</a></code>, <code><a href="lme4.html#topic+glmer">glmer</a></code>,
<code><a href="nlme.html#topic+lme">lme</a></code>, <code><a href="glmmTMB.html#topic+glmmTMB">glmmTMB</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("lme4")
# from ?lmer:
(fm1 &lt;- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
cv(fm1, clusterVariables="Subject") # LOO CV of clusters
cv(fm1, seed=447) # 10-fold CV of cases
cv(fm1, clusterVariables="Subject", k=5,
   seed=834, reps=3) # 5-fold CV of clusters, repeated 3 times

library(nlme)
# from ?lme
(fm2 &lt;- lme(distance ~ age + Sex, data = Orthodont,
            random = ~ 1))
cv(fm2) # LOO CV of cases
cv(fm2, clusterVariables="Subject", k=5, seed=321) # 5-fold CV of clusters

library("glmmTMB")
# from ?glmmTMB
(m1 &lt;- glmmTMB(count ~ mined + (1|site),
               zi=~mined,
               family=poisson, data=Salamanders))
cv(m1, seed=97816, k=5, clusterVariables="site") # 5-fold CV of clusters
cv(m1, seed=34506, k=5) # 5-fold CV of cases
</code></pre>

<hr>
<h2 id='cvSelect'>Cross-Validate a Model-Selection Procedure</h2><span id='topic+cvSelect'></span><span id='topic+selectStepAIC'></span><span id='topic+selectTrans'></span><span id='topic+selectTransStepAIC'></span><span id='topic+compareFolds'></span><span id='topic+coef.cvSelect'></span>

<h3>Description</h3>

<p><code>cvSelect()</code> is a general function to cross-validate a model-selection procedure;
<code>selectStepAIC()</code> is a procedure that applies the <code><a href="MASS.html#topic+stepAIC">stepAIC</a>()</code>
model-selection function in the <span class="pkg">MASS</span> package; <code>selectTrans()</code> is a procedure
for selecting predictor and response transformations in regression, which
uses the <code><a href="car.html#topic+powerTransform">powerTransform</a>()</code> function in the
<span class="pkg">car</span> package; and <code>selectTransAndStepAIC()</code> combines predictor and response
transformation with predictor selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cvSelect(
  procedure,
  data,
  criterion = mse,
  model,
  y.expression,
  k = 10,
  confint = n &gt;= 400,
  level = 0.95,
  reps = 1,
  save.coef = k &lt;= 10,
  seed,
  ncores = 1,
  ...
)

selectStepAIC(
  data,
  indices,
  model,
  criterion = mse,
  AIC = TRUE,
  save.coef = TRUE,
  ...
)

selectTrans(
  data,
  indices,
  save.coef = TRUE,
  model,
  criterion = mse,
  predictors,
  response,
  family = c("bcPower", "bcnPower", "yjPower", "basicPower"),
  family.y = c("bcPower", "bcnPower", "yjPower", "basicPower"),
  rounded = TRUE,
  ...
)

selectTransStepAIC(
  data,
  indices,
  save.coef = TRUE,
  model,
  criterion = mse,
  predictors,
  response,
  family = c("bcPower", "bcnPower", "yjPower", "basicPower"),
  family.y = c("bcPower", "bcnPower", "yjPower", "basicPower"),
  rounded = TRUE,
  AIC = TRUE,
  ...
)

compareFolds(object, digits = 3, ...)

## S3 method for class 'cvSelect'
coef(object, average, NAs = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cvSelect_+3A_procedure">procedure</code></td>
<td>
<p>a model-selection procedure function (see Details).</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_data">data</code></td>
<td>
<p>full data frame for model selection.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_criterion">criterion</code></td>
<td>
<p>a CV criterion (&quot;cost&quot; or lack-of-fit) function.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_model">model</code></td>
<td>
<p>a regression model object fit to data.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_y.expression">y.expression</code></td>
<td>
<p>normally the response variable is found from the
<code>model</code> argument; but if, for a particular selection procedure, the
<code>model</code> argument is absent, or if the response can't be inferred from the
model, the response can be specified by an expression, such as <code>expression(log(income))</code>,
to be evaluated within the data set provided by the <code>data</code> argument.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_k">k</code></td>
<td>
<p>perform k-fold cross-validation (default is 10); <code>k</code>
may be a number or <code>"loo"</code> or <code>"n"</code> for n-fold (leave-one-out)
cross-validation.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_confint">confint</code></td>
<td>
<p>if <code>TRUE</code> (the default if the number of cases is 400
or greater), compute a confidence interval for the bias-corrected CV
criterion, if the criterion is the average of casewise components.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_level">level</code></td>
<td>
<p>confidence level (default <code>0.95</code>).</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_reps">reps</code></td>
<td>
<p>number of times to replicate k-fold CV (default is <code>1</code>)</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_save.coef">save.coef</code></td>
<td>
<p>save the coefficients from the selected models? (default is <code>TRUE</code> if
<code>k</code> is 10 or smaller, <code>FALSE</code> otherwise)</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_seed">seed</code></td>
<td>
<p>for R's random number generator; not used for n-fold cross-validation.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_ncores">ncores</code></td>
<td>
<p>number of cores to use for parallel computations
(default is <code>1</code>, i.e., computations aren't done in parallel)</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_...">...</code></td>
<td>
<p>for <code>cvSelect()</code>, arguments to be passed to <code>procedure()</code>;
for <code>selectStepAIC()</code>, arguments to be passed to <code>stepAIC()</code>.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_indices">indices</code></td>
<td>
<p>indices of cases in data defining the current fold.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_aic">AIC</code></td>
<td>
<p>if <code>TRUE</code> (the default) use the AIC as the
model-selection criterion; if <code>FALSE</code>, use the BIC.
The <code>k</code> argument to <code><a href="MASS.html#topic+stepAIC">stepAIC</a>()</code>
is set accordingly (note that this is distinct from the number of
folds <code>k</code>).</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_predictors">predictors</code></td>
<td>
<p>character vector of names of the predictors in the model
to transform; if missing, no predictors will be transformed.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_response">response</code></td>
<td>
<p>name of the response variable; if missing, the response
won't be transformed.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_family">family</code></td>
<td>
<p>transformation family for the predictors, one of
<code>"bcPower", "bcnPower", "yjPower", "basicPower"</code>,
with <code>"bcPower"</code> as the default. These are the names of transformation
functions in the <span class="pkg">car</span> package; see <code><a href="car.html#topic+bcPower">bcPower</a>()</code></p>
</td></tr>
<tr><td><code id="cvSelect_+3A_family.y">family.y</code></td>
<td>
<p>transformation family for the response,
with <code>"bcPower"</code> as the default.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_rounded">rounded</code></td>
<td>
<p>if <code>TRUE</code> (the default) use nicely rounded versions
of the estimated transformation parameters (see <code><a href="car.html#topic+bcPower">bcPower</a>()</code>).</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_object">object</code></td>
<td>
<p>an object of class <code>"cvSelect"</code>.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_digits">digits</code></td>
<td>
<p>significant digits for printing coefficients
(default <code>3</code>).</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_average">average</code></td>
<td>
<p>if supplied, a function, such as <code>mean</code> or <code>median</code>,
to use us in averaging estimates across folds; if missing, the
estimates for each fold are returned.</p>
</td></tr>
<tr><td><code id="cvSelect_+3A_nas">NAs</code></td>
<td>
<p>values to substitute for <code>NA</code>s in calculating
averaged estimates; the default, <code>0</code>, is appropriate, e.g.,
for regression coefficients; the value <code>1</code> might be appropriate
for power-transformation estimates.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model-selection function supplied as the <code>procedure</code> argument
to <code>cvSelect()</code> should accept the following arguments:
</p>

<dl>
<dt><code>data</code></dt><dd><p>set to the <code>data</code> argument to <code>cvSelect()</code>.</p>
</dd>
<dt><code>indices</code></dt><dd><p>the indices of the rows of <code>data</code> defining the current fold; if missing,
the model-selection procedure is applied to the full <code>data</code>.</p>
</dd>
<dt>other arguments</dt><dd><p>to be passed via <code>...</code>
from <code>cvSelect()</code>.</p>
</dd>
</dl>

<p><code>procedure()</code> should return a list with the following
named elements: <code>fit.i</code>, the vector of predicted values for the cases in
the current fold computed from the model omitting these cases;
<code>crit.all.i</code>, the CV criterion computed for all of the cases using
the model omitting the current fold; and (optionally) <code>coefficients</code>,
parameter estimates from the model computed omitting the current fold.
</p>
<p>When the <code>indices</code> argument is missing, <code>procedure()</code> returns the cross-validation criterion for all of the cases based on
the model fit to all of the cases.
</p>
<p>For examples of model-selection functions for the <code>procedure</code>
argument, see the code for <code>selectStepAIC()</code>,
<code>selectTrans()</code>, and <code>selectTransAndStepAIC()</code>.
</p>
<p>For additional information, see the &quot;Cross-validation of regression
models&quot; vignette (<code>vignette("cv", package="cv")</code>)
and the &quot;Extending the cv package&quot; vignette
(<code>vignette("cv-extend", package="cv")</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"cvSelect"</code>,
inheriting from class <code>"cv"</code>, with the CV criterion
(<code>"CV crit"</code>), the bias-adjusted CV criterion (<code>"adj CV crit"</code>),
the criterion for the model applied to the full data (<code>"full crit"</code>),
the confidence interval and level for the bias-adjusted CV criterion (<code>"confint"</code>),
the number of folds (<code>"k"</code>), the seed for R's random-number
generator (<code>"seed"</code>), and (optionally) a list of coefficients
(or, in the case of <code>selectTrans()</code>, estimated transformation
parameters, and in the case of <code>selectTransAndStepAIC()</code>, both regression coefficients
and transformation parameters) for the selected models
for each fold (<code>"coefficients"</code>).
If <code>reps</code> &gt; <code>1</code>, then an object of class <code>c("cvSelectList", "cvList")</code> is returned,
which is literally a list of <code>c("cvSelect", "cv")</code> objects.
</p>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>coef(cvSelect)</code>: extract the coefficients from the selected models
for the several folds and possibly average them.
</p>
</li></ul>


<h3>Functions</h3>


<ul>
<li> <p><code>cvSelect()</code>: apply cross-validation to a model-selection procedure.
</p>
</li>
<li> <p><code>selectStepAIC()</code>: select a model using the <code><a href="MASS.html#topic+stepAIC">stepAIC</a>()</code> function in the
<span class="pkg">MASS</span> package.
</p>
</li>
<li> <p><code>selectTrans()</code>: select transformations of the predictors and response.
</p>
</li>
<li> <p><code>selectTransStepAIC()</code>: select transformations of the predictors and response,
and then select predictors.
</p>
</li>
<li> <p><code>compareFolds()</code>: print the coefficients from the selected models
for the several folds.
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+stepAIC">stepAIC</a></code>, <code><a href="car.html#topic+bcPower">bcPower</a></code>,
<code><a href="car.html#topic+powerTransform">powerTransform</a></code>, <code><a href="#topic+cv">cv</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Auto", package="ISLR2")
m.auto &lt;- lm(mpg ~ . - name - origin, data=Auto)
cvSelect(selectStepAIC, Auto, seed=123, model=m.auto)
cvSelect(selectStepAIC, Auto, seed=123, model=m.auto,
         AIC=FALSE, k=5, reps=3) # via BIC

data("Prestige", package="carData")
m.pres &lt;- lm(prestige ~ income + education + women,
             data=Prestige)
cvt &lt;- cvSelect(selectTrans, data=Prestige, model=m.pres, seed=123,
                predictors=c("income", "education", "women"),
                response="prestige", family="yjPower")
cvt
compareFolds(cvt)
coef(cvt, average=median, NAs=1) # NAs not really needed here
cv(m.pres, seed=123)

Auto$year &lt;- as.factor(Auto$year)
Auto$origin &lt;- factor(Auto$origin,
                      labels=c("America", "Europe", "Japan"))
rownames(Auto) &lt;- make.names(Auto$name, unique=TRUE)
Auto$name &lt;- NULL
m.auto &lt;- lm(mpg ~ . , data=Auto)
cvs &lt;- cvSelect(selectTransStepAIC, data=Auto, seed=76692, model=m.auto,
                criterion=medAbsErr,
                predictors=c("cylinders", "displacement", "horsepower",
                             "weight", "acceleration"),
                response="mpg", AIC=FALSE)
cvs
compareFolds(cvs)
</code></pre>

<hr>
<h2 id='GetResponse'>Extract Response Variable</h2><span id='topic+GetResponse'></span><span id='topic+GetResponse.default'></span><span id='topic+GetResponse.merMod'></span><span id='topic+GetResponse.lme'></span><span id='topic+GetResponse.glmmTMB'></span>

<h3>Description</h3>

<p>Generic function to extract the response variable from a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetResponse(model, ...)

## Default S3 method:
GetResponse(model, ...)

## S3 method for class 'merMod'
GetResponse(model, ...)

## S3 method for class 'lme'
GetResponse(model, ...)

## S3 method for class 'glmmTMB'
GetResponse(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GetResponse_+3A_model">model</code></td>
<td>
<p>a fitted model</p>
</td></tr>
<tr><td><code id="GetResponse_+3A_...">...</code></td>
<td>
<p>additional parameters for specific methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The supplied <code>default</code> method returns the <code>model$y</code> component
of the model object, or, if <code>model</code> is an S4 object, the result
returned by the <code><a href="insight.html#topic+get_response">get_response</a>()</code> function in
the <span class="pkg">insight</span> package. If this result is <code>NULL</code>, the result of
<code>model.response(model.frame(model))</code> is returned, checking in any case whether
the result is a numeric vector.
</p>
<p>There is also an <code>"lme"</code> method, and <code>"merMod"</code>
and <code>"glmmTMB"</code> methods that convert factor
responses to numeric 0/1 responses, as would be appropriate
for a generalized linear mixed model with a binary response.
</p>


<h3>Value</h3>

<p>a numeric vector containing the values of the response variable.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>GetResponse(default)</code>: <code>default</code> method
</p>
</li>
<li> <p><code>GetResponse(merMod)</code>: <code>merMod</code> method
</p>
</li>
<li> <p><code>GetResponse(lme)</code>: <code>merMod</code> method
</p>
</li>
<li> <p><code>GetResponse(glmmTMB)</code>: <code>glmmTMB</code> method
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>    fit &lt;- lm(mpg ~ gear, mtcars)
    GetResponse(fit)
</code></pre>

<hr>
<h2 id='models'>Cross-Validate Several Models Fit to the Same Data</h2><span id='topic+models'></span><span id='topic+cv.modList'></span><span id='topic+print.cvModList'></span><span id='topic+plot.cvModList'></span>

<h3>Description</h3>

<p>A <code><a href="#topic+cv">cv</a>()</code> method for an object of class  <code>"modlist"</code>,
created by the <code>models()</code> function. This <code>cv()</code> method simplifies
the process of cross-validating several models on the same set of CV folds.
<code>models()</code> performs some
&quot;sanity&quot; checks, warning if the models are of different classes, and
reporting an error if they are fit to apparently different data sets or
different response variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>models(...)

## S3 method for class 'modList'
cv(model, data, criterion = mse, k, reps = 1, seed, quietly = TRUE, ...)

## S3 method for class 'cvModList'
print(x, ...)

## S3 method for class 'cvModList'
plot(
  x,
  y,
  spread = c("range", "sd"),
  confint = TRUE,
  xlab = "",
  ylab,
  main,
  axis.args = list(labels = names(x), las = 3L),
  col = palette()[2L],
  lwd = 2,
  grid = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="models_+3A_...">...</code></td>
<td>
<p>for <code>models()</code>, two or more competing models fit to the
the same data; the several models may be named.
For <code>cv()</code>, additional arguments to be passed to the <code>cv()</code> method
applied to each model. For the <code>print()</code>
method, arguments to be passed to the <code>print()</code> method for
the individual model cross-validations. For the <code>plot()</code>,
method, arguments to be passed to the base <code><a href="base.html#topic+plot">plot</a>()</code>
function.</p>
</td></tr>
<tr><td><code id="models_+3A_model">model</code></td>
<td>
<p>a list of regression model objects,
created by <code>models()</code>.</p>
</td></tr>
<tr><td><code id="models_+3A_data">data</code></td>
<td>
<p>(required) the data set to which the models were fit.</p>
</td></tr>
<tr><td><code id="models_+3A_criterion">criterion</code></td>
<td>
<p>the CV criterion (&quot;cost&quot; or lack-of-fit) function, defaults to
<code><a href="#topic+mse">mse</a></code>.</p>
</td></tr>
<tr><td><code id="models_+3A_k">k</code></td>
<td>
<p>the number of CV folds; may be omitted, in which case the value
will depend on the default for the <code>cv()</code> method invoked for the
individual models.</p>
</td></tr>
<tr><td><code id="models_+3A_reps">reps</code></td>
<td>
<p>number of replications of CV for each model.</p>
</td></tr>
<tr><td><code id="models_+3A_seed">seed</code></td>
<td>
<p>(optional) seed for R's pseudo-random-number generator,
to be used to create the same set of CV folds for all of the models;
if omitted, a seed will be randomly generated and saved.</p>
</td></tr>
<tr><td><code id="models_+3A_quietly">quietly</code></td>
<td>
<p>if <code>TRUE</code> (the default), simple messages (for example about the
value to which the random-number generator seed is set), but not warnings or
errors, are suppressed.</p>
</td></tr>
<tr><td><code id="models_+3A_x">x</code></td>
<td>
<p>an object of class <code>"cvModList"</code> to be printed or plotted.</p>
</td></tr>
<tr><td><code id="models_+3A_y">y</code></td>
<td>
<p>the name of the element in each <code>"cv"</code> object to be
plotted; defaults to <code>"adj CV crit"</code>, if it exists, or to
<code>"CV crit"</code>.</p>
</td></tr>
<tr><td><code id="models_+3A_spread">spread</code></td>
<td>
<p>if <code>"range"</code>, the default, show the range of CV criteria
for each model along with their average; if <code>"sd"</code>, show the average
plus or minus 1 standard deviation.</p>
</td></tr>
<tr><td><code id="models_+3A_confint">confint</code></td>
<td>
<p>if <code>TRUE</code> (the default) and if confidence intervals are
in any of the <code>"cv"</code> objects, then plot the confidence intervals around the
CV criteria.</p>
</td></tr>
<tr><td><code id="models_+3A_xlab">xlab</code></td>
<td>
<p>label for the x-axis (defaults to blank).</p>
</td></tr>
<tr><td><code id="models_+3A_ylab">ylab</code></td>
<td>
<p>label for the y-axis (if missing, a label is constructed).</p>
</td></tr>
<tr><td><code id="models_+3A_main">main</code></td>
<td>
<p>main title for the graph (if missing, a label is constructed).</p>
</td></tr>
<tr><td><code id="models_+3A_axis.args">axis.args</code></td>
<td>
<p>a list of arguments for the <code><a href="graphics.html#topic+axis">axis</a>()</code>
function, used to draw the horizontal axis. In addition to
the axis arguments given explicitly, <code>side=1</code> (the horizontal
axis) and <code>at=seq(along=x)</code> (i.e., 1 to the number of models)
are used and can't be modified.</p>
</td></tr>
<tr><td><code id="models_+3A_col">col</code></td>
<td>
<p>color for the line and points, defaults to the second
element of the color palette; see <code><a href="grDevices.html#topic+palette">palette</a>()</code>.</p>
</td></tr>
<tr><td><code id="models_+3A_lwd">lwd</code></td>
<td>
<p>line width for the line (defaults to 2).</p>
</td></tr>
<tr><td><code id="models_+3A_grid">grid</code></td>
<td>
<p>if <code>TRUE</code> (the default), include grid lines on the graph.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>models()</code> returns a <code>"modList"</code> object, the
<code>cv()</code> method for which returns a <code>"cvModList"</code> object.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>models()</code>: create a list of models
</p>
</li>
<li> <p><code>cv(modList)</code>: <code>cv()</code> method for <code>"modList"</code> objects
</p>
</li>
<li> <p><code>print(cvModList)</code>: <code>print()</code> method for <code>"cvModList"</code> objects
</p>
</li>
<li> <p><code>plot(cvModList)</code>: <code>plot()</code> method for <code>"cvModList"</code> objects
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code>, <code><a href="#topic+cvMixed">cvMixed</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Duncan", package="carData")
m1 &lt;- lm(prestige ~ income + education, data=Duncan)
m2 &lt;- lm(prestige ~ income + education + type, data=Duncan)
m3 &lt;- lm(prestige ~ (income + education)*type, data=Duncan)
(cv.models &lt;- cv(models(m1=m1, m2=m2, m3=m3),
                 data=Duncan, seed=7949, reps=5))
plot(cv.models)
(cv.models.ci &lt;- cv(models(m1=m1, m2=m2, m3=m3),
                    data=Duncan, seed=5962, confint=TRUE, level=0.50))
                 # nb: n too small for accurate CIs
plot(cv.models.ci)
</code></pre>

<hr>
<h2 id='mse'>Cost Functions for Fitted Regression Models</h2><span id='topic+mse'></span><span id='topic+costFunctions'></span><span id='topic+rmse'></span><span id='topic+medAbsErr'></span><span id='topic+BayesRule'></span><span id='topic+BayesRule2'></span>

<h3>Description</h3>

<p>Compute cost functions (cross-validation criteria) for fitted
regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(y, yhat)

rmse(y, yhat)

medAbsErr(y, yhat)

BayesRule(y, yhat)

BayesRule2(y, yhat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mse_+3A_y">y</code></td>
<td>
<p>response</p>
</td></tr>
<tr><td><code id="mse_+3A_yhat">yhat</code></td>
<td>
<p>fitted value</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Cost functions (cross-validation criteria) are meant to measure lack-of-fit. Several cost functions are provided:
</p>

<ol>
<li> <p><code>mse()</code> returns the mean-squared error of prediction for
a numeric response variable <code>y</code> and predictions <code>yhat</code>; and
<code>rmse()</code> returns the root-mean-squared error and is just the
square-root of <code>mse()</code>.
</p>
</li>
<li> <p><code>medAbsErr()</code> returns the median absolute error of prediction for a numeric
response <code>y</code> and predictions <code>yhat</code>.
</p>
</li>
<li> <p><code>BayesRule()</code> and <code>BayesRule2()</code> report the proportion
of incorrect predictions for a dichotomous response variable <code>y</code>, assumed
coded (or coercible to) <code>0</code> and <code>1</code>. The <code>yhat</code> values are
predicted probabilities and are rounded to 0 or 1. The distinction
between <code>BayesRule()</code> and <code>BayesRule2()</code> is that the former
checks that the <code>y</code> values are all either <code>0</code> or <code>1</code>
and that the <code>yhat</code> values are all between 0 and 1, while
the latter doesn't and is therefore faster.
</p>
</li></ol>



<h3>Value</h3>

<p>In general, cost functions should return a single numeric
value measuring lack-of-fit. <code>mse()</code> returns the mean-squared error;
<code>rmse()</code> returns the root-mean-squared error;
<code>medAbsErr()</code> returns the median absolute error;
and BayesRule()<code>and</code>BayesRule2()' return the proportion of misclassified cases.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>mse()</code>: Mean-square error
</p>
</li>
<li> <p><code>rmse()</code>: Root-mean-square error
</p>
</li>
<li> <p><code>medAbsErr()</code>: Median absolute error
</p>
</li>
<li> <p><code>BayesRule()</code>: Bayes Rule for a binary response
</p>
</li>
<li> <p><code>BayesRule2()</code>: Bayes rule for a binary response (without bounds checking)
</p>
</li></ul>


<h3>See Also</h3>

<p><code><a href="#topic+cv">cv</a></code>, <code><a href="#topic+cvSelect">cvSelect</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Duncan", package="carData")
m.lm &lt;- lm(prestige ~ income + education, data=Duncan)
mse(Duncan$prestige, fitted(m.lm))

data("Mroz", package="carData")
m.glm &lt;- glm(lfp ~ ., data=Mroz, family=binomial)
BayesRule(Mroz$lfp == "yes", fitted(m.glm))
</code></pre>

<hr>
<h2 id='Pigs'>Body Weights of 48 Pigs in 9 Successive Weeks</h2><span id='topic+Pigs'></span>

<h3>Description</h3>

<p>This data set appears in Table 3.1 of Diggle, Liang,
and Zeger (1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("Pigs", package = "cv")
</code></pre>


<h3>Format</h3>

<p>A data frame with 432 rows and 3 columns.
</p>

<dl>
<dt>id</dt><dd><p>Pig id number, 1&ndash;48.</p>
</dd>
<dt>week</dt><dd><p>Week number, 1&ndash;9.</p>
</dd>
<dt>weight</dt><dd><p>Weight in kg.</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Diggle, K.-Y. Liang, and S. L. Zeger,
<em>Analysis of Longitudinal Data</em> (Oxford, 1994).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("lme4")
m.p &lt;- lmer(weight ~ week + (1 | id) + (1 | week),
            data=Pigs, REML=FALSE,
            control=lmerControl(optimizer="bobyqa"))
summary(m.p)
cv(m.p, clusterVariables=c("id", "week"), k=10, seed=8469)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
